<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-193"><a id="_idTextAnchor199"/>14</h1>
<h1 id="_idParaDest-194"><a id="_idTextAnchor200"/>Writing Generic Containers with Allocator Support</h1>
<p>We have come a long way since the beginning of this book. Recent chapters examined how one can write memory-efficient containers, describing how to do so when memory management is done explicitly (in <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a>) and when it is done implicitly, through smart pointers (in <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a>). Choosing a memory management approach is not an either/or proposition; each one is useful in its own way and solves real-life use cases depending on one’s application domain.</p>
<p>However, none of the approaches we have covered so far match what standard library containers do. Indeed, standard library containers (as well as many other standard library types that can dynamically allocate memory) are <code>std::vector</code> whose memory comes from an arena (see <a href="B21071_10.xhtml#_idTextAnchor153"><em class="italic">Chapter 10</em></a>) or from a fixed-capacity buffer on the stack.</p>
<p>Allocators officially came to the C++ language, along with the standard library containers, in C++98, but they evolved and diversified themselves over time. Writing an allocator became significantly simpler with C++11, and C++17 introduced an entirely new approach to memory allocation<a id="_idIndexMarker767"/> with <strong class="bold">polymorphic memory resource</strong> (<strong class="bold">PMR</strong>) allocators and containers.</p>
<p>In this chapter, you will do the following:</p>
<ul>
<li>Understand and use traditional allocators</li>
<li>Write a traditional allocator for a specialized application domain</li>
<li>Learn how to manage the allocator lifetime when a container is moved or copied</li>
<li>Clone an allocator’s type</li>
<li>Understand and use PMR allocators and containers</li>
</ul>
<p>Equipped with a knowledge of allocators and how they interact with containers, this chapter will enrich your memory management toolbox and open up new ways to combine data organization with the way storage is obtained. Understanding allocators might even make writing new containers less of a necessity; sometimes, instead of trying to create an entirely new container, the solution is just a matter of combining the right data organization strategy with the right storage management approach.</p>
<h1 id="_idParaDest-195"><a id="_idTextAnchor201"/>Technical requirements</h1>
<p>You can find the code files for this chapter in the book’s GitHub repository here: <a href="https://github.com/PacktPublishing/C-Plus-Plus-Memory-Management/tree/main/chapter14">https://github.com/PacktPublishing/C-Plus-Plus-Memory-Management/tree/main/chapter14</a>.</p>
<p class="callout-heading">A word about the examples in this chapter</p>
<p class="callout">As was the case with <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a>, this chapter will show incomplete examples to avoid redundancy with the excerpts found earlier, particularly those in <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a>. Allocators change the way in which containers interact with memory management facilities, but they do not require rewriting containers entirely, so a lot of code written for a given container remains stable regardless of how memory is managed. The code you will find in the GitHub repository is, of course, complete.</p>
<p class="callout">Also note that this chapter discusses allocators in the context of containers, but the idea can be extended to many types that need to dynamically allocate memory. It is sometimes difficult to do so; for example, support for allocators in <code>std::function</code> was removed in C++17 as no known standard library implementation had managed to make it work. Still, allocators can be seen as a general idea, not something that is limited to containers, and you can envision using allocators in other contexts.</p>
<h1 id="_idParaDest-196"><a id="_idTextAnchor202"/>Why allocators?</h1>
<p>Allocators tend to scare people, including<a id="_idIndexMarker768"/> some experts, but you will not be scared as you are already in possession of significant memory management knowledge and skills (and you are probably curious to know more about the topic given the fact that you are reading this book). Knowing this, the first question we need to address, before even expressing what an allocator is, is “Why do allocators exist?”. Why would we concern ourselves with an additional layer of complexity in our memory management code?</p>
<p>Well, this is C++, and C++ is all about giving users <em class="italic">control</em>, so that’s where our explanation begins. To make an analogy, think about iterators: why they are useful, and how they make your life as a programmer better. They decouple iterating over elements of a sequence from how the elements are organized in that sequence, such that you can write code that computes something such as the sum of the values in <code>std::list&lt;int&gt;</code> or <code>std::vector&lt;short&gt;</code> without having to know that in the first case, you are navigating through nodes linked to one another by pointers and in the second case, you are iterating through objects stored in contiguous memory.</p>
<p>The beauty of iterators is this decoupling between iteration and data organization. Similarly, allocators decouple data organization from the way the underlying storage is obtained or freed. This allows us to reason about the properties of containers independently from the properties of memory management and makes containers useful in even more situations than they would otherwise be.</p>
<p class="callout-heading">A very, very thin layer…</p>
<p class="callout">To a container, an allocator (at least those in the “traditional” model that we are about to discuss) represents a thin (<em class="italic">very</em> thin) layer of abstraction over the hardware. To a container, an allocator expresses such things as “What is an address?”, “How does one put an object somewhere?”, “How does one destroy an object at some location?”, and so on. In a way, for a container, the allocator essentially <em class="italic">is</em> the hardware.</p>
<h1 id="_idParaDest-197"><a id="_idTextAnchor203"/>Traditional allocators</h1>
<p>As mentioned <a id="_idIndexMarker769"/>already, allocators have been a mainstay of C++ for decades now, but they have existed in a few different guises and shapes. In this chapter, we will adopt a sort of chronological approach, starting from the earlier (and more complicated) allocator types and progressing toward the simpler (and more versatile) ones.</p>
<p>To understand this chapter, one key idea to keep in mind is that a container type such as <code>std::vector&lt;T&gt;</code> does not really exist. What does exist is the <code>std::vector&lt;T,A&gt;</code> type where, by default, <code>A</code> is <code>std::allocator&lt;T&gt;</code>, which allocates through <code>::operator new()</code> and deallocates through <code>::operator delete()</code>. By <strong class="bold">traditional allocator</strong>, we mean an allocator type that is part of the type of a container (this is not the only possible approach to writing allocators today, as we will see when we discuss PMR allocators later in this chapter).</p>
<p>We will first examine what was required to write an allocator before C++11, and how a container such as <code>std::vector&lt;T,A&gt;</code> could use an object of the <code>A</code> type to abstract away its memory<a id="_idIndexMarker770"/> allocation tasks. Improvements to the way allocators are expressed will follow in later sections of this chapter.</p>
<h2 id="_idParaDest-198"><a id="_idTextAnchor204"/>Before C++11</h2>
<p>Traditional allocators <a id="_idIndexMarker771"/>written before C++11 had to implement a wide array of members, which made the task of writing allocators seem daunting to many. Consider what one had to write in those days, and please note that not all of what follows remains true as of this writing since the API of allocators has evolved over time.</p>
<p class="callout-heading">On the difficulty of tracking an evolving API</p>
<p class="callout">What is required of allocators changed with every version of C++ since C++03, and these days, it is not always easy (or relevant) to write examples that compile for C++11. For this reason, the examples we will write in a detailed manner will use C++11 allocators, to show what that actually meant, but will compile with the C++17 standard to make the code more pleasant to read (and write).</p>
<p>We will examine such an allocator, <code>small_allocator&lt;T&gt;</code>, and implement it in a way that resembles <code>std::allocator&lt;T&gt;</code> in order to highlight what it meant to write an allocator in the C++11 era, and then compare that with an equivalent expressed for a more recent version of the standard. We will use C++17 features in our implementation as we do not want to introduce unnecessary complexity in an already subtle topic.</p>
<p>After introducing <code>small_allocator&lt;T&gt;</code>, we will show how <code>Vector&lt;T&gt;</code> from <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a> and <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a> can be<a id="_idIndexMarker772"/> enhanced and become <code>Vector&lt;T,A&gt;</code>, and how <code>A</code> can be <code>std::allocator&lt;T&gt;</code>, <code>small_allocator&lt;T&gt;</code>, or any other conforming allocator type.</p>
<h3>Type aliases</h3>
<p>An allocator of the <code>T</code> type <a id="_idIndexMarker773"/>had to expose type aliases for <code>value_type</code>, <code>size_type</code>, <code>difference_type</code> (the type one would get from subtracting two <code>pointer</code> objects), <code>pointer</code>, <code>const_pointer</code>, <code>reference</code>, and <code>const_reference</code>. One way to think about this is that to a container, the allocator represents the underlying memory and consequently defines the types that best describe these low-level ideas. Containers could then map their own aliases to those of their allocator for conformity.</p>
<p>In our <code>small_allocator&lt;T&gt;</code> type, this would translate to the following:</p>
<pre class="source-code">
template &lt;class T&gt;
struct small_allocator {
   using value_type = T;
   using pointer = T*;
   using const_pointer = const T*;
   using reference = T&amp;;
   using const_reference = const T&amp;;
   using size_type = std::size_t;
   using difference_type = std::ptrdiff_t;
   // ...</pre> <p>In practice, for an allocator of <code>T</code>, one could expect these type aliases to correspond to those shown here for <code>small_allocator&lt;T&gt;</code> in all but the strangest cases: as long as <code>value_type</code> is defined, we can almost always infer the others.</p>
<h3>Member functions</h3>
<p>An allocator<a id="_idIndexMarker774"/> of the <code>T</code> type had to expose a member function, <code>max_size()</code>, that was supposed to return the size of the largest block that this allocator could actually allocate.</p>
<p>In practice, that often proved to be unimplementable as, with some operating systems, allocation always succeeds (but usage of the allocated memory may fail if the program is over-allocated) so that function usually turned out to be implemented on a best-effort basis on a given platform. A possible implementation would be the following:</p>
<pre class="source-code">
   // ...
   constexpr size_type max_size() const {
      return std::numeric_limits&lt;size_type&gt;::max(); // bah
   }
   // ...</pre> <p>An allocator of the <code>T</code> type also had to expose two overloads of a function that uses all the words this author’s students “love” in a single signature (appreciate the irony!). Consider <code>pointer address(reference r)</code> as well as the equivalent for <code>const</code> objects, which is <code>const_pointer address(const_reference r)</code>. The intent here is to abstract the ways in which one would get the address of an object.</p>
<p>It would be tempting to implement each of these functions as <code>return &amp;r;</code> but in practice, this is perilous as users are allowed to overload the unary <code>operator&amp;()</code> for their types, and this means such an implementation would call arbitrary code, a scary prospect indeed… Avoid overloading something as fundamental as “taking the address of an object” unless you really, <em class="italic">really</em> have a good reason to do so, and even then, consider alternative approaches to solving your problem!</p>
<p>A better implementation technique is to express these functions through <code>return std::addressof(r);</code> where <code>std::addressof()</code> is a “magical” standard library function from <code>&lt;memory&gt;</code> (that is, <code>constexpr</code>) and returns the address of an object without going through an overloadable facility:</p>
<pre class="source-code">
   // ...
   constexpr pointer address(reference r) const {
      return std::addressof(r);
   }
   constexpr
      const_pointer address(const_reference r) const {
      return std::addressof(r);
   }
   // ...</pre> <p>Obviously, an allocator needs to expose member functions to perform the actual memory allocation. The signatures for these are <code>allocate(size_type n)</code> and <code>deallocate(pointer p, size_type n)</code>. A simple implementation of these two functions <a id="_idIndexMarker775"/>could be the following:</p>
<pre class="source-code">
   // ...
   pointer allocate(size_type n) {
      auto p = static_cast&lt;pointer&gt;(
         malloc(n * sizeof(value_type))
      );
      if (!p) throw std::bad_alloc{};
      return p;
   }
   void deallocate(pointer p, size_type) {
      free(p);
   }
   // ...</pre> <p>The <code>allocate()</code> member <a id="_idIndexMarker776"/>function used to take a second argument of the <code>void*</code> type named <code>hint</code>, which was initialized to <code>nullptr</code> by default. This argument was meant to inform the allocator of a location that could be used to provide storage, in case the container knew of such a location. That feature seemed rarely (if ever) used in practice, and was deprecated in C++17 and then removed in C++20.</p>
<p>These two functions are the essence of why allocators exist: <code>allocate()</code> returns a chunk of memory big enough to hold <code>n</code> contiguous elements of <code>value_type</code>, throwing <code>bad_alloc</code> on failure, and <code>deallocate()</code> deallocates a chunk of memory big enough to hold <code>n</code> contiguous elements of <code>value_type</code>. When one writes an allocator, one usually seeks to provide an answer to this specific problem.</p>
<p class="callout-heading">Bytes or objects</p>
<p class="callout">Interestingly, contrary to <code>operator new()</code>, which takes a number of <em class="italic">bytes</em> as argument, <code>allocate()</code> and <code>deallocate()</code> both take as argument a number of <em class="italic">objects</em>. That is because traditional allocators are type-aware (they are allocators of some type <code>T</code> after all), whereas <code>operator new()</code> and friends are (mostly) type-agnostic. You will notice later in this chapter that PMR allocators (which one might call “a step back”) use memory resources that are type-agnostic such as <code>malloc()</code> or <code>operator new()</code>.</p>
<p>Both <code>allocate()</code> and <code>deallocate()</code> deliberately lie<a id="_idIndexMarker777"/> to client <a id="_idIndexMarker778"/>code: they trade in raw memory and neither create nor destroy objects of type <code>T</code>, yet <code>allocate()</code> returns a <code>pointer</code> (a <code>T*</code>, essentially) and <code>deallocate()</code> accepts a <code>pointer</code> as argument even though all <code>T</code> objects are assumed to have been destroyed beforehand.</p>
<p>The fact that these <a id="_idIndexMarker779"/>functions lie to the type system is a good thing in a way, as it relieves the container from the task of doing so. Of course, the container has to be aware of what these functions do and should not assume the presence of objects in memory returned by <code>allocate()</code> or passed to <code>deallocate()</code>.</p>
<p>Finally, an allocator had to expose member functions to turn raw memory into objects and conversely. The <code>construct(pointer p,const_reference r)</code> and <code>destroy(pointer p)</code> functions are respectively meant to construct a copy of <code>r</code> at location <code>p</code> (which is assumed to have been allocated beforehand), and destroy the object at location <code>p</code> (without deallocating the underlying storage):</p>
<pre class="source-code">
   // ...
   void construct(pointer p, const_reference r) {
      new (static_cast&lt;void*&gt;(p)) value_type(r);
   }
   void destroy(const_pointer p) {
      if(p) p-&gt;~value_type();
   }
   // ...
   template &lt;class U&gt;
   struct rebind {
      using other = small_allocator&lt;U&gt;;
   };
};</pre> <p>One can expect that most implementations will do essentially what the preceding code does. There are alternatives, but they are rarely met in practice.</p>
<p>Again, these functions lie to the type system: <code>construct()</code> takes a <code>pointer</code> (a <code>T*</code>, in practice) as argument but when the function is called, that pointer points to raw memory, not to an object of type <code>T</code>.</p>
<p class="callout-heading">What about rebind?</p>
<p class="callout">You will notice that we did not<a id="_idIndexMarker780"/> discuss the <code>rebind</code> public template type, but that is only because the idea behind this type is easier to understand when facing the kind of problem it is meant to solve. We will face such a situation when discussing allocator-aware node-based containers through our <code>ForwardList&lt;T,A&gt;</code> class later in this chapter.</p>
<p>Past this point, the<a id="_idIndexMarker781"/> requirement for an allocator is to define whether two allocator objects of different types are equal or not. A possible implementation would be the following:</p>
<pre class="source-code">
// ...
template &lt;class T, class U&gt;
constexpr bool operator==(const small_allocator&lt;T&gt;&amp;,
                          const small_allocator&lt;U&gt;&amp;) {
   return true;
}
template &lt;class T, class U&gt;
constexpr bool operator!=(const small_allocator&lt;T&gt;&amp;,
                          const small_allocator&lt;U&gt;&amp;) {
   return false;
}</pre> <p>Expressed otherwise, two <code>small_allocator</code> specializations for distinct types describe the same strategy and are thus considered equal. “But wait!” you say, “Where do you take into account the state of the allocators in this computation?”. But here’s a revelation: pre-C++11 allocators were essentially assumed to be <em class="italic">stateless</em>.</p>
<p>Well, they were not, but it was unclear what would happen to an allocator if it was associated with a container object and that object was copied. You see, if an allocator has <em class="italic">state</em>, we have to know what to do with that state when the allocator is copied. Is the state copied? Is it shared? In the pre-C++11 era, we did not know what to do in such a situation, so unless a container was used in a context where it would not be copied, as in the case of a vector local to a function and associated with an allocator that uses stack space as storage, most people avoided stateful allocators altogether.</p>
<p class="callout-heading">But what about stateful allocators?</p>
<p class="callout">As hinted, stateful allocators<a id="_idIndexMarker782"/> were a possibility back then (they existed, and they were used in practice). How is one expected to define allocator equality for stateful allocators (and for allocators in general)? The general idea is that two allocators should compare equally if memory allocated from one can be deallocated from the other. With an allocator that delegates allocation tasks to free functions such as <code>std::malloc()</code> or <code>::operator new()</code>, equality is trivially <code>true</code>, but stateful allocators require us to think about how to define this relation.</p>
<p>Before we look at how we could write allocator-aware containers, we will take a step back and see how <a id="_idIndexMarker783"/>we could adapt some of the uninitialized memory algorithms used in <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a> and <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a> to use the services of an allocator. This will reduce the refactoring effort required later in the process.</p>
<h3>Some allocator-aware support algorithms</h3>
<p>Since we are using<a id="_idIndexMarker784"/> allocators to bridge the gap between raw storage and objects, we will not be able to use the raw memory algorithms seen in <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a> and <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a> in our allocator-aware implementations.</p>
<p>We have the option of writing our own versions of these algorithms in detail at each call site within our containers, but that would be tedious (and bug-prone). Instead, we will write somewhat simplified versions of these low-level memory management algorithms and make these simplified versions use an allocator passed as an argument. In so doing, we will reduce the impact of making containers allocator-aware on our implementation.</p>
<p>The first three of these algorithms will be allocator-aware versions of algorithms that initialize a range of values, as well as one that destroys such a range. To minimize the impact on the existing implementations, we will essentially use the same signature as their non-allocator-aware counterpart, but with an added argument that is a reference to the allocator. For the algorithm that fills a block of raw memory with some value, we have the following:</p>
<pre class="source-code">
template &lt;<strong class="bold">class A</strong>, class IIt, class T&gt;
void uninitialized_fill_with_allocator(
   <strong class="bold">A&amp; alloc</strong>, IIt bd, IIt ed, T init
) {
   // bd: beginning of destination¸
   // ed: end of destination
   auto p = bd;
   try {
      for (; p != ed; ++p)
         <strong class="bold">alloc.construct(p, init);</strong>
   } catch (...) {
      for (auto q = bd; q != p; ++q)
         <strong class="bold">alloc.destroy(q);</strong>
      throw;
   }
}</pre> <p>Then, for the algorithm that copies a sequence of values to a block of raw memory, we have the following:</p>
<pre class="source-code">
template &lt;<strong class="bold">class A</strong>, class IIt, class OIt&gt;
void uninitialized_copy_with_allocator(
   <strong class="bold">A&amp; alloc</strong>, IIt bs, IIt es, OIt bd
) {
   // bs: beginning of source
   // es: end of source
   // bd: beginning of destination¸
   auto p = bd;
   try {
      for (auto q = bs; q != es; ++q) {
         <strong class="bold">alloc.construct(p, *q);</strong>
         ++p;
      }
   } catch (...) {
      for (auto q = bd; q != p; ++q)
         <strong class="bold">alloc.destroy(q);</strong>
      throw;
   }
}</pre> <p>For the algorithm<a id="_idIndexMarker785"/> that moves a sequence of values to a block of raw memory, we have the following:</p>
<pre class="source-code">
template &lt;<strong class="bold">class A</strong>, class IIt, class OIt&gt;
void uninitialized_move_with_allocator(
   <strong class="bold">A&amp; alloc</strong>, IIt bs, IIt es, OIt bd
) {
   // bs: beginning of source
   // es: end of source
   // bd: beginning of destination¸
   auto p = bd;
   try {
      for (auto q = bs; q != es; ++q) {
         <strong class="bold">alloc.construct(p, std::move(*q));</strong>
         ++p;
      }
   } catch (...) {
      for (auto q = bd; q != p; ++q)
         <strong class="bold">alloc.destroy(q);</strong>
      throw;
   }
}</pre> <p>Finally, for the <a id="_idIndexMarker786"/>algorithm that transforms a sequence of objects into a block of raw memory, we have the following:</p>
<pre class="source-code">
template &lt;<strong class="bold">class A</strong>, class It&gt;
   void destroy_with_allocator(<strong class="bold">A &amp;alloc</strong>, It b, It e) {
      for (; b != e; ++b)
         <strong class="bold">alloc.destroy(b);</strong>
   }</pre> <p>Note that in each case, the implementation would be more conformant if, when an exception occurs, objects were destroyed in reverse order of construction. Feel free to implement this slight adjustment; it’s not difficult but it would introduce some noise in our example.</p>
<p>The other standard facility we will rewrite is <code>cmp_less()</code>, which allows comparing a signed value with an unsigned value without getting caught by the integer promotion rules of the C language. It’s not directly memory-related, but we need it in our <code>Vector&lt;T&gt;</code> implementation, and it’s a C++20 feature, which makes it unavailable when we compile for C++17:</p>
<pre class="source-code">
template&lt;class T, class U&gt;
   constexpr bool cmp_less(T a, U b) noexcept {
      if constexpr (std::is_signed_v&lt;T&gt; ==
                    std::is_signed_v&lt;U&gt;)
         return a &lt; b;
      else if constexpr (std::is_signed_v&lt;T&gt;)
         return a &lt; 0 || std::make_unsigned_t&lt;T&gt;(a) &lt; b;
      else
         return b &gt;= 0 &amp;&amp; a &lt; std::make_unsigned_t&lt;U&gt;(b);
   }</pre> <p>Both<a id="_idIndexMarker787"/> the <code>std::is_signed&lt;T&gt;</code> trait as well as the <code>std::make_unsigned&lt;T&gt;()</code> function can be found in header <code>&lt;type_traits&gt;</code>.</p>
<p class="callout-heading">Conditional compilation and feature test macros</p>
<p class="callout">As an aside, if you find yourself having to maintain code where a feature such as <code>std::cmp_less()</code> might or might not be available, such as a source file that is sometimes compiled for C++20 and sometimes compiled for C++17, consider conditional inclusion of your “homemade workaround” version by testing the associated feature test macro.</p>
<p class="callout">For this specific case, one could wrap the definition of our personal version of <code>cmp_less()</code> with <code>#ifndef __cpp_lib_integer_comparison_functions</code> to make sure it is only provided if there is no version provided by one’s standard library implementation.</p>
<p>Now, let’s see how these allocators and our support algorithms can be used by a container, first with <a id="_idIndexMarker788"/>a container that uses contiguous storage (our <code>Vector&lt;T,A&gt;</code> class) and then with a node-based container (our <code>ForwardList&lt;T,A&gt;</code> class).</p>
<h3>An allocator-aware Vector&lt;T,A&gt; class</h3>
<p>We are now ready<a id="_idIndexMarker789"/> to look at how <a id="_idIndexMarker790"/>introducing allocator awareness in a container that uses contiguous memory (more specifically, our <code>Vector&lt;T&gt;</code> class) impacts the implementation of that container. Note that we will use the explicit memory management approach from <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a> as a baseline in this case since we want to explore the impact of allocator awareness and this will help us make the implementation changes more apparent. Feel free to adapt the code in this chapter with an implicit approach to memory management if you are so inclined.</p>
<p>Starting with the template’s signature itself, we now have a two-type template with <code>T</code> being the type of the elements and <code>A</code> being the type for the allocator, but with a reasonable default type for <code>A</code> such that casual users will not need to worry about such technical details:</p>
<pre class="source-code">
template &lt;class T<strong class="bold">, class A = std::allocator&lt;T&gt;</strong>&gt;
class Vector <strong class="bold">: A</strong> { // note: private inheritance
public:
   using value_type = <strong class="bold">typename A::value_type</strong>;
   using size_type = <strong class="bold">typename A::size_type</strong>;
   using pointer = <strong class="bold">typename A::pointer</strong>;
   using const_pointer = <strong class="bold">typename A::const_pointer</strong>;
   using reference = <strong class="bold">typename A::reference</strong>;
   using const_reference = <strong class="bold">typename A::const_reference</strong>;
private:
<strong class="bold">   // deliberately self-exposing selected members</strong>
<strong class="bold">   // of the private base class as our own</strong>
<strong class="bold">   using A::allocate;</strong>
<strong class="bold">   using A::deallocate;</strong>
<strong class="bold">   using A::construct;</strong>
<strong class="bold">   using A::destroy;</strong>
   // ...</pre> <p>Note some techniques here:</p>
<ul>
<li>Since we expect <code>A</code> to be stateless, we used private inheritance and made <code>A</code> a base class of <code>Vector&lt;T,A&gt;</code>, enabling the empty base optimization. Alternatively, we could also have used a data member of type <code>A</code> inside each <code>Vector&lt;T,A&gt;</code> object (perhaps incurring a small size penalty).</li>
<li>We deduced the<a id="_idIndexMarker791"/> type <a id="_idIndexMarker792"/>aliases of the container from those of its allocator. This probably changes nothing in practice with respect to the aliases we used in previous chapters, but <code>A</code> might be doing some “fancy tricks” (one can never be too careful).</li>
<li>In a private section of our class, we expose some selected members of our base class as our own. This will make the code less verbose later on, allowing us to write <code>allocate(n)</code> instead of <code>this-&gt;A::allocate(n)</code>, for example.</li>
</ul>
<p>The non-allocating members of our class do not change, unsurprisingly. Data members stay the same, and so do basic accessors such as <code>size()</code>, <code>empty()</code>, <code>begin()</code>, <code>end()</code>, <code>front()</code>, <code>operator[]</code>, and so on. Even the default constructor remains unchanged since it does not allocate memory and so does not need to interact with its allocator.</p>
<p>There is a new constructor needed, one that accepts as argument an allocator. This one is particularly useful in the case of stateful allocators:</p>
<pre class="source-code">
   // ...
<strong class="bold">   Vector(A &amp;alloc) : A{ alloc } {</strong>
<strong class="bold">   }</strong>
   // ...</pre> <p>Of course, when reaching the constructors that do need to allocate memory, the situation becomes more interesting. Take, for example, the constructor that takes as argument a number <a id="_idIndexMarker793"/>of elements <a id="_idIndexMarker794"/>and an initial value:</p>
<pre class="source-code">
   // ...
   Vector(size_type n, const_reference init)
      : <strong class="bold">A{}</strong>,<strong class="bold">elems{ allocate(n) }</strong>,
        nelems{ n }, cap{ n } {
      try {
         <strong class="bold">uninitialized_fill_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end(), init
         );
      } catch (...) {
         <strong class="bold">deallocate(elems, capacity());</strong>
         throw;
      }
   }
   // ...</pre> <p>There is a lot to say here:</p>
<ul>
<li>The memory block that will serve as the underlying storage for our container is allocated through a call to our base class’s <code>allocate()</code> member function. Remember that even though this yields a <code>pointer</code> (a <code>T*</code>), that is a lie and there are no <code>T</code> objects in the newly allocated block.</li>
<li>We fill that uninitialized memory block with <code>T</code> objects through our homemade allocator-aware version of <code>std::uninitialized_fill()</code> (see the <code>_with_allocator</code> suffix). Note how we pass the allocator as an argument to the algorithm: the inheritance relationship between <code>Vector&lt;T,A&gt;</code> and <code>A</code> is <code>private</code>, but the derived class is aware of it and can use that information through <code>static_cast</code>.</li>
<li>If one of the constructors used in the process of initializing that memory block throws, the algorithm destroys the objects it had created, as usual (no one else really could do it anyway), after which we intercept that exception and deallocate the storage before re-throwing said exception in the interest of exception neutrality.</li>
</ul>
<p>Similar maneuvers are used in other allocating constructors, with different algorithms used to initialize the allocated storage. The move constructor and the <code>swap()</code> member function do not allocate memory and, for that reason, remain unchanged, and the same goes for the assignment operators: they are built from other member functions and do not need to allocate or deallocate memory by themselves.</p>
<p>As you probably<a id="_idIndexMarker795"/> suspected <a id="_idIndexMarker796"/>already, the destructor of our container will use the allocator to destroy the objects and deallocate the underlying storage:</p>
<pre class="source-code">
   // ...
   ~Vector() {
      <strong class="bold">destroy_with_allocator</strong>(
         <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end()
      );
      <strong class="bold">deallocate(elems, capacity());</strong>
   }
   // ...</pre> <p>The <code>push_back()</code> and <code>emplace_back()</code> member functions do not allocate by themselves, delegating to our private <code>grow()</code> member function, which, in turn, delegates to <code>reserve()</code> for the allocation, but they do need to <code>construct()</code> an object at the end of the container:</p>
<pre class="source-code">
   // ...
   void push_back(const_reference val) {
      if (full()) grow();
      <strong class="bold">construct(end(), val);</strong>
      ++nelems;
   }
   void push_back(T&amp;&amp; val) {
      if (full()) grow();
      <strong class="bold">construct(end(), std::move(val));</strong>
      ++nelems;
   }
   template &lt;class ... Args&gt;
   reference emplace_back(Args &amp;&amp;...args) {
      if (full()) grow();
      <strong class="bold">construct(end(), std::forward&lt;Args&gt;(args)...);</strong>
      ++nelems;
      return back();
   }
   // ...</pre> <p>The principal<a id="_idIndexMarker797"/> tools for<a id="_idIndexMarker798"/> memory allocation in our class are probably <code>reserve()</code> and <code>resize()</code>. In both cases, the algorithm remains as it was, but the low-level memory management tasks are delegated to the allocator. For <code>reserve()</code>, this leads us to the following:</p>
<pre class="source-code">
   // ...
   void reserve(size_type new_cap) {
      if (new_cap &lt;= capacity()) return;
      <strong class="bold">auto p = allocate(new_cap);</strong>
      if constexpr (std::is_nothrow_move_assignable_v&lt;T&gt;) {
         <strong class="bold">uninitialized_move_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end(), p
         );
      } else {
         auto src_p = begin();
         auto b = p, e = p + size();
         try {
            <strong class="bold">uninitialized_copy_with_allocator</strong>(
               <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end(), p
            );
         } catch (...) {
            <strong class="bold">deallocate(p, new_cap);</strong>
            throw;
         }
      }
      <strong class="bold">deallocate(elems, capacity());</strong>
      elems = p;
      cap = new_cap;
   }
   // ...</pre> <p>Whereas, for <code>resize()</code>, we now <a id="_idIndexMarker799"/>have <a id="_idIndexMarker800"/>the following:</p>
<pre class="source-code">
   // ...
   void resize(size_type new_cap) {
      if (new_cap &lt;= capacity()) return;
      auto p = <strong class="bold">allocate(new_cap)</strong>;
      if constexpr (std::is_nothrow_move_assignable_v&lt;T&gt;) {
         <strong class="bold">uninitialized_move_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end(), p
         );
      } else {
         <strong class="bold">uninitialized_copy_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end(), p
         );
      }
      try {
         <strong class="bold">uninitialized_fill_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>,
            p + size(), p + new_cap, value_type{}
         );
         <strong class="bold">destroy_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, begin(), end()
         );
         <strong class="bold">deallocate(elems, capacity())</strong>;
         elems = p;
         nelems = cap = new_cap;
      } catch(...) {
         <strong class="bold">destroy_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>, p, p + size()
         );
         <strong class="bold">deallocate(p, new_cap)</strong>;
         throw;
      }
   }
   // ...</pre> <p>In previous implementations of the <code>Vector&lt;T&gt;</code> class, we had implemented one version each of <code>insert()</code> and <code>erase()</code>, as implementing the whole set of these functions would make this book unreasonably large. Since both functions meddle with initialized and uninitialized memory, they need to be adapted to use the services of the allocator rather than doing their own memory management.</p>
<p>In the case of <code>insert()</code>, the key aspects of the function that need to be adjusted are those that<a id="_idIndexMarker801"/> copy or move<a id="_idIndexMarker802"/> objects into raw memory:</p>
<pre class="source-code">
   // ...
   template &lt;class It&gt;
   iterator insert(const_iterator pos, It first, It last) {
      iterator pos_ = const_cast&lt;iterator&gt;(pos);
      const auto remaining = capacity() - size();
      const auto n = std::distance(first, last);
<strong class="bold">//      if (std::cmp_less(remaining, n)) { // needs C++20</strong>
<strong class="bold">      if(cmp_less(remaining, n)) {</strong>
         auto index = std::distance(begin(), pos_);
         reserve(capacity() + n - remaining);
         pos_ = std::next(begin(), index);
      }
      const auto nb_to_uninit_displace =
         std::min&lt;std::ptrdiff_t&gt;(n, end() - pos_);
      auto where_to_uninit_displace =
         end() + n - nb_to_uninit_displace;
      if constexpr (
         std::is_nothrow_move_constructible_v&lt;T&gt;
      )
         <strong class="bold">uninitialized_move_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>,
            end() - nb_to_uninit_displace, end(),
            where_to_uninit_displace
         );
      else
         <strong class="bold">uninitialized_copy_with_allocator</strong>(
            <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>,
            end() - nb_to_uninit_displace, end(),
            where_to_uninit_displace
         );
      // note : might be zero
      const auto nb_to_uninit_insert =
         std::max&lt;std::ptrdiff_t&gt;(
            0, n - nb_to_uninit_displace
         );
      auto where_to_uninit_insert = end();
      <strong class="bold">uninitialized_copy_with_allocator</strong>(
         <strong class="bold">*static_cast&lt;A*&gt;(this)</strong>,
         last - nb_to_uninit_insert, last,
         where_to_uninit_insert
      );
      // note : might be zero
      const auto nb_to_backward_displace =
         std::max&lt;std::ptrdiff_t&gt;(
            0, end() - pos_ - nb_to_uninit_displace
         );
      auto where_to_backward_displace = end();
      if constexpr (std::is_nothrow_move_assignable_v&lt;T&gt;)
         std::move_backward(
            pos_, pos_ + nb_to_backward_displace,
            where_to_backward_displace
         );
      else
         std::copy_backward(
            pos_, pos_ + nb_to_backward_displace,
            where_to_backward_displace
         );
      std::copy(
         first, first + n - nb_to_uninit_insert, pos_
      );
      nelems += n;
      return pos_;
   }
   // ...</pre> <p>In the case of <code>erase()</code>, what<a id="_idIndexMarker803"/> we <a id="_idIndexMarker804"/>do is copy all objects after the erased one “to the left” by one position; the object at the end of the sequence after this copying has been performed has to be destroyed, and for this, we need to use the allocator’s services. An example follows:</p>
<pre class="source-code">
   // ...
   iterator erase(const_iterator pos) {
      iterator pos_ = const_cast&lt;iterator&gt;(pos);
      if (pos_ == end()) return pos_;
      std::copy(std::next(pos_), end(), pos_);
      <strong class="bold">destroy(std::prev(end()));</strong>
      --nelems;
      return pos_;
   }
};</pre> <p>As you have probably gathered at this point, we could optimize or simplify these functions in <a id="_idIndexMarker805"/>numerous<a id="_idIndexMarker806"/> ways, such as the following:</p>
<ul>
<li>There is a common core functionality between <code>reserve()</code> and <code>resize()</code>, so we could essentially claim that <code>resize()</code> is in large part like <code>reserve()</code> followed by an uninitialized fill and express it as such.</li>
<li>In the case of <code>erase()</code>, at compile time, we could test the value of the <code>std::is_nothrow_move_assignable_v&lt;T&gt;</code> trait and, if that condition holds, replace the call to <code>std::copy()</code> with a call to <code>std::move()</code>.</li>
<li>We could make <code>insert()</code> and <code>erase()</code> more exception-safe than they are, although this would make the code a bit long for a book such as this one.</li>
</ul>
<p>At this point, we have an allocator-aware container that manages contiguous memory. It will now be interesting to see what the impacts of allocator awareness will be on a node-based container, something we will address through an allocator-aware version of the <code>ForwardList&lt;T&gt;</code> class.</p>
<h3>An allocator-aware ForwardList&lt;T,A&gt; class</h3>
<p>A funny thing <a id="_idIndexMarker807"/>happens when writing allocator-aware node-based containers. Pay attention to the beginning of our <code>ForwardList&lt;T,A&gt;</code> class:</p>
<pre class="source-code">
template &lt;class T<strong class="bold">, class A = std::allocator&lt;T&gt;</strong>&gt;
class ForwardList {
public:
<strong class="bold">   using value_type = typename A::value_type;</strong>
<strong class="bold">   // likewise for the other aliases</strong>
private:
<strong class="bold">   struct Node {</strong>
      value_type value;
      Node *next = nullptr;
      Node(const_reference value) : value { value } {
      }
      Node(value_type &amp;&amp;value)
         : value { std::move(value) } {
      }
   };
<strong class="bold">   Node *head {};</strong>
   size_type nelems {};
   // ...</pre> <p>Did you notice<a id="_idIndexMarker808"/> something interesting about type <code>A</code>? Think about it…</p>
<p>Yes, that’s it: <code>A</code> <em class="italic">is the wrong type</em>! A node-based container such as <code>ForwardList&lt;T,A&gt;</code> never allocates objects of type <code>T</code>: it allocates <em class="italic">nodes</em> that (most probably) contain <code>T</code> objects and other things such as, in this case, a pointer to the next <code>Node</code> in the sequence.</p>
<p>Knowing this, if we were supplied some allocator <code>A</code> that modeled a size-aware allocation strategy akin to what we used in our arena for <code>Orc</code> objects in <a href="B21071_10.xhtml#_idTextAnchor153"><em class="italic">Chapter 10</em></a>, making the allocator aware of <code>T</code> (and thus, of <code>sizeof(T)</code>) would lead to an arena that manages objects of the wrong size. This is not good!</p>
<p>We are faced with an interesting conundrum: user code provides us with an allocator because it wants our container to put an <em class="italic">allocation strategy</em> to good use. That allocation strategy appears as a template parameter of our container, which is why it is associated with the type of its elements (we do not know what the nodes will be at this point in the definition of our container class). Only later, when we have defined what a node will be for our container, are we really ready to say what will need to be allocated, but then <code>A</code> already exists and is already associated to <code>T</code>, not to the type we really need, which is <code>ForwardList&lt;T,A&gt;::Node</code>.</p>
<p>Note that we have instantiated type <code>A</code> but have not constructed any object of that type. Lucky for us, as that would have been wasteful (we would never use it!). What we do need is a type that is just like <code>A</code>, but able to allocate objects of our <code>Node</code> type instead of objects of type <code>T</code>. We need a way to <em class="italic">clone the allocation strategy</em> described by <code>A</code> and apply it to another type.</p>
<p>This is exactly what <code>rebind</code> is for. Remember that we mentioned this template type when writing <code>small_allocator&lt;T&gt;</code> earlier but said we would return to it when we could put it to good use? There we are, dear reader. As a reminder, in the context of an allocator, <code>rebind</code> presents<a id="_idIndexMarker809"/> itself<a id="_idIndexMarker810"/> as follows:</p>
<pre class="source-code">
template &lt;<strong class="bold">class T</strong>&gt;
   class <strong class="bold">small_allocator</strong> { // for example
   // ...
<strong class="bold">   template &lt;class U&gt;</strong>
<strong class="bold">      struct rebind {</strong>
<strong class="bold">         using other = small_allocator&lt;U&gt;;</strong>
<strong class="bold">      };</strong>
   // ...
};</pre> <p>You can see <code>rebind</code> as some kind of weird code poetry: it is a way for the allocator to say “If you want the same type as myself but applied to some <code>U</code> type instead of <code>T</code>, here’s what that type would be.”</p>
<p>Returning to our <code>ForwardList&lt;T,A&gt;</code> class, now that we know what <code>rebind</code> is for, we can create our own internal allocator type, <code>Alloc</code>. This will be “like the allocator type <code>A</code> but applied to <code>Node</code>, not to <code>T</code>” and create an object of that type (incidentally named <code>alloc</code> in our implementation), which we will use to perform the memory management tasks in our container:</p>
<pre class="source-code">
   // ...
   <strong class="bold">using Alloc = typename A::rebind&lt;Node&gt;::other;</strong>
   <strong class="bold">Alloc alloc;</strong>
   // ...</pre> <p>It’s a nice trick, isn’t it? Remember that we cloned the <em class="italic">strategy</em>, the type, not an actual object so any state some hypothetical <code>A</code> object would have had would not necessarily be part of our new <code>Alloc</code> type (at least not without performing some non-trivial acrobatics). This is yet another reminder that with traditional allocators as they were originally designed, copying and moving allocator state was a complex problem.</p>
<p>As was the case for the transformation from <code>Vector&lt;T&gt;</code> to <code>Vector&lt;T,A&gt;</code>, a significant portion of our <code>List&lt;T&gt;</code> implementation involved no memory allocation and thus needs not change with <code>List&lt;T,A&gt;</code>. This includes the <code>size()</code>, <code>empty()</code>, <code>begin()</code>, <code>end()</code>, <code>swap()</code>, <code>front()</code>, and <code>operator==()</code> member functions, among others, as well as most of the <code>List&lt;T,A&gt;::Iterator&lt;U&gt;</code> class definition. As our implementation of <code>ForwardList&lt;T,A&gt;</code> will need to access private data member <code>cur</code> of its<a id="_idIndexMarker811"/> iterators on <a id="_idIndexMarker812"/>occasion, we give it <code>friend</code> privileges over <code>Iterator&lt;U&gt;</code>:</p>
<pre class="source-code">
   // ...
   template &lt;class U&gt; class Iterator {
      // ...
   private:
      Node *cur {};
      <strong class="bold">friend class ForwardList&lt;T,A&gt;;</strong>
      // ...
   };
   // ...</pre> <p>There are, of course, member functions of <code>ForwardList&lt;T,A&gt;</code> that use memory allocation mechanisms. One of them is <code>clear()</code>, whose role is to destroy the nodes in the container. The destruction and deallocation of <code>Node</code> objects have to be performed through the allocator, replacing the call to <code>operator delete()</code> with a pair of function calls:</p>
<pre class="source-code">
   // ...
   void clear() noexcept {
      for(auto p = head; p; ) {
         auto q = p-&gt;next;
<strong class="bold">         alloc.destroy(p);</strong>
<strong class="bold">         alloc.deallocate(p, 1);</strong>
         p = q;
      }
      nelems = 0;
   }
   // ...</pre> <p>In <code>ForwardList&lt;T&gt;</code>, we made all of the allocating constructors converge toward a single sequence constructor that accepted a pair of iterators (type <code>It</code>) as arguments. This localizes the changes required for constructors in <code>ForwardList&lt;T,A&gt;</code> to that single function, something <a id="_idIndexMarker813"/>that <a id="_idIndexMarker814"/>simplifies our task.</p>
<p>In <code>ForwardList&lt;T&gt;</code>, we had constrained template parameter <code>It</code> by the <code>std::forward_iterator</code> concept, but concepts are a C++20 feature and we are compiling this implementation in C++17 so we will (sadly) let go of this constraint for the time being.</p>
<p>Having to perform allocation and construction in separate steps complicates our implementation a little, but I think you esteemed readers, will not find this to be unsurmountable:</p>
<pre class="source-code">
   // ...
   <strong class="bold">template &lt;class It&gt; // &lt;std::forward_iterator It&gt;</strong>
      ForwardList(It b, It e) {
         if(b == e) return;
         try {
<strong class="bold">            head = alloc.allocate(1);</strong>
<strong class="bold">            alloc.construct(head, *b);</strong>
            auto q = head;
            ++nelems;
            for(++b; b != e; ++b) {
<strong class="bold">               auto ptr = alloc.allocate(1);</strong>
<strong class="bold">               alloc.construct(ptr, *b);</strong>
<strong class="bold">               q-&gt;next = ptr;</strong>
               q = q-&gt;next;
               ++nelems;
            }
         } catch (...) {
            clear();
            throw;
         }
      }
   // ...</pre> <p>We also had <a id="_idIndexMarker815"/>written<a id="_idIndexMarker816"/> insertion member functions for <code>ForwardList&lt;T&gt;</code>, so these will also need to be adapted to use allocators in <code>ForwardList&lt;T,A&gt;</code>. We had two overloads of <code>push_front()</code>:</p>
<pre class="source-code">
   // ...
   void push_front(const_reference val) {
<strong class="bold">      auto p = alloc.allocate(1);</strong>
<strong class="bold">      alloc.construct(p, val);</strong>
      p-&gt;next = head;
      head = p;
      ++nelems;
   }
   void push_front(T&amp;&amp; val) {
<strong class="bold">      auto p = alloc.allocate(1);</strong>
<strong class="bold">      alloc.construct(p, std::move(val));</strong>
      p-&gt;next = head;
      head = p;
      ++nelems;
   }
   // ...</pre> <p>We also had two overloads of <code>insert_after()</code>, one that inserted a single value and one that inserted <a id="_idIndexMarker817"/>the elements<a id="_idIndexMarker818"/> in a half-open range. In the latter case, we will need to put aside the <code>std::forward_iterator</code> constraint on type <code>It</code> again as we are compiling for C++17:</p>
<pre class="source-code">
   // ...
   iterator
      insert_after(iterator pos, const_reference value) {
<strong class="bold">      auto p = alloc.allocate(1);</strong>
<strong class="bold">      alloc.construct(p, value);</strong>
      p-&gt;next = pos.cur-&gt;next;
      pos.cur-&gt;next = p;
      ++nelems;
      return { p };
   }
<strong class="bold">   template &lt;class It&gt; // &lt;std::input_iterator It&gt;</strong>
      iterator insert_after(iterator pos, It b, It e) {
         for(; b != e; ++b)
            pos = insert_after(pos, *b);
         return pos;
      }
   // ...</pre> <p>Our <code>erase_after()</code> member function is similarly adjusted:</p>
<pre class="source-code">
   // ...
   iterator erase_after(iterator pos) {
      if (pos == end() || std::next(pos) == end())
         return end();
      auto p = pos.cur-&gt;next-&gt;next;
<strong class="bold">      alloc.destroy(pos.cur-&gt;next);</strong>
<strong class="bold">      alloc.deallocate(pos.cur-&gt;next, 1);</strong>
      --nelems;
      pos.cur-&gt;next = p;
      return { p-&gt;next };
   }
};</pre> <p>That concludes our<a id="_idIndexMarker819"/> transformation<a id="_idIndexMarker820"/> of <code>ForwardList&lt;T&gt;</code> into an allocator-aware <code>ForwardList&lt;T,A&gt;</code> class. I hope, dear reader, that this was not as difficult as some might have feared: given our understanding of the principles and fundamental techniques presented in this book, integrating allocator awareness in a container should make some sort of sense to most of us at this point.</p>
<p>Now that we have seen how to write a “traditional” iterator as well as examples of how one can make a<a id="_idIndexMarker821"/> container<a id="_idIndexMarker822"/> allocator-aware, you might be wondering about the benefits of using allocators. We know that allocators give use code control over the ways in which containers manage memory, but what can we gain from that control?</p>
<h3>Example usage – a sequential buffer allocator</h3>
<p>A classical example of allocator usage is <a id="_idIndexMarker823"/>one that, instead<a id="_idIndexMarker824"/> of allocating memory from the free store, manages a pre-allocated chunk of memory. That memory does not have to come from the execution stack of a thread, but that’s often what is done in practice, so that’s what our example code will do.</p>
<p>What you need to know before reading the following example is this:</p>
<ul>
<li>This sort of allocator is a specialized tool for specialized users. We expect users to know what they are doing.</li>
<li>The pre-allocated buffer that will be managed by the allocator in our example has to be properly aligned for the objects that will be stored therein. If you want to adapt this example to handle memory allocation for any naturally aligned object, some additional effort will be required (you will want the allocator to yield addresses aligned on a <code>std::max_align_t</code> boundary, something our example allocator does not do).</li>
<li>Some care will need to be taken if client code tries to “,over-allocate,” asking for more memory than what the managed buffer could provide. In this example, we will throw <code>std::bad_alloc</code> as usual, but alternatives exist.</li>
</ul>
<p class="callout-heading">When bad_alloc is not an option…</p>
<p class="callout">For some applications, throwing or otherwise failing to allocate is not an option. The fact that a specialized allocator cannot meet an allocation request should not, for these applications, result in throwing an exception as throwing means “I cannot meet the postconditions of this function.”</p>
<p class="callout">One thing that some applications do when a sequential buffer allocator runs out of memory is simply call <code>::operator new()</code> and take the indeterministic allocation time “hit” but leave a trace somewhere (a log, maybe) that this happened. This means the program will leak memory, but for some applications (say, a stock market exchange program that is restarted every day), one can expect those leaks to be relatively low in number, and the fact that there is a trace that something leaked will let programmers look at the problem and (hopefully) fix it before the next day. The “lesser of two evils,” as some might say.</p>
<p>Our sequential <a id="_idIndexMarker825"/>buffer allocator<a id="_idIndexMarker826"/> will look like this:</p>
<pre class="source-code">
#include &lt;cstdint&gt;
template &lt;class T&gt;
struct seq_buf_allocator {
   using value_type = T;
   // pointer, reference and other aliases are as
   // usual, and so is max_size()
<strong class="bold">private:</strong>
<strong class="bold">   char *buf;</strong>
<strong class="bold">   pointer cur;</strong>
<strong class="bold">   size_type cap;</strong>
<strong class="bold">public:</strong>
<strong class="bold">   seq_buf_allocator(char *buf, size_type cap) noexcept</strong>
<strong class="bold">      : buf{ buf }, cap{ cap } {</strong>
<strong class="bold">      cur = reinterpret_cast&lt;pointer&gt;(buf);</strong>
<strong class="bold">   }</strong>
   // ...</pre> <p>As you can see, the state for this allocator resembles what we did for the size-based arena in <a href="B21071_10.xhtml#_idTextAnchor153"><em class="italic">Chapter 10</em></a>: we know where the buffer to manage starts (<code>buf</code>), how big it is (<code>cap</code>), and where we are at in our sequential allocation process (<code>cur</code>).</p>
<p>We make <code>cur</code> a <code>pointer</code>-type object to simplify computation later, in the <code>allocate()</code>member function, but it’s a convenience, not a necessity.</p>
<p>The <code>allocate()</code> member function is very simple in the sense that it performs a constant-time computation, returning contiguously allocated objects from the underlying storage without even having to reuse that memory after it has been deallocated. Part of the work done in <code>allocate()</code> requires avoiding over-allocating, and to do this, we will compare pointers, but we might have to compare a pointer within the allocated memory block with one that is not within that block (it all depends on the value of our arguments). This would lead us into undefined behavior, something we need to avoid, so <a id="_idIndexMarker827"/>we cast our<a id="_idIndexMarker828"/> pointers to <code>std::intptr_t</code> objects and compare the resulting integral values instead.</p>
<p class="callout-heading">What if std::intptr_t is not offered on my platform?</p>
<p class="callout">Types <code>std::intptr_t</code> and <code>std::uintptr_t</code> are conditionally supported in C++, which means that there might be vendors that do not offer these type aliases. If you find yourself in this unlikely but not impossible situation, you can simply keep track of the number of objects allocated and compare this with the <code>cap</code> data member to achieve the same effect.</p>
<p>We end up with the following <code>allocate()</code> implementation, accompanied by the corresponding <code>deallocate()</code> member function, which is, in this case, effectively a no-op:</p>
<pre class="source-code">
   // ...
   // rebind, address(), construct() and destroy()
   // are all as usual
   pointer allocate(size_type n) {
<strong class="bold">      auto</strong>
<strong class="bold">         request = reinterpret_cast&lt;</strong>
<strong class="bold">            std::intptr_t</strong>
<strong class="bold">         &gt;(cur + n),</strong>
<strong class="bold">         limit = reinterpret_cast&lt;</strong>
<strong class="bold">            std::intptr_t</strong>
<strong class="bold">         &gt;(buf + cap);</strong>
<strong class="bold">      if(request &gt;= limit)</strong>
<strong class="bold">         throw std::bad_alloc{};</strong>
<strong class="bold">      auto q = cur;</strong>
<strong class="bold">      cur += n;</strong>
<strong class="bold">      return q;</strong>
   }
<strong class="bold">   void deallocate(pointer, size_type) {</strong>
<strong class="bold">   }</strong>
};
// ...</pre> <p>As this allocator <a id="_idIndexMarker829"/>is<a id="_idIndexMarker830"/> stateful, we need to give some thought to allocator equality. What we will do in this case is the following:</p>
<pre class="source-code">
template &lt;class T, class U&gt;
  constexpr bool operator==(const seq_buf_allocator&lt;T&gt; &amp;a,
                            const seq_buf_allocator&lt;U&gt; &amp;b){
     return a.cur == b.cur; // maybe?
  }
template &lt;class T, class U&gt;
  constexpr bool operator!=(const seq_buf_allocator&lt;T&gt; &amp;a,
                            const seq_buf_allocator&lt;U&gt; &amp;b){
     return !(a == b);
  }</pre> <p>These equality operators make sense at a specific moment in time only, but then this allocator type is not really meant to be copied in practice; if you plan to use a buffer such as this and share its internal state, you will need to give some thought to the way the original and the copy share their internal state and remain coherent with one another – something we do not need to do in this case.</p>
<p>As you can see, we test for overflow on allocation and throw <code>std::bad_alloc</code> if an allocation<a id="_idIndexMarker831"/> request <a id="_idIndexMarker832"/>would lead to a buffer overflow, but that’s only one option among others, as we have discussed earlier in this chapter:</p>
<pre class="source-code">
#include &lt;chrono&gt;
#include &lt;utility&gt;
template &lt;class F, class ... Args&gt;
   auto test(F f, Args &amp;&amp;... args) {
      using namespace std;
      using namespace std::chrono;
      auto pre = high_resolution_clock::now();
      auto res = f(std::forward&lt;Args&gt;(args)...);
      auto post = high_resolution_clock::now();
      return pair{ res, post - pre };
   }
#include &lt;iostream&gt;
#include &lt;vector&gt;
<strong class="bold">struct Data { int n; };</strong>
int main() {
   using namespace std::chrono;
   enum { N = 500'000 };
   {
<strong class="bold">      std::vector&lt;Data&gt; v;</strong>
      auto [r, dt] = test([](auto &amp; v) {
         v.reserve(N);
         for(int i = 0; i != N; ++i)
            v.push_back({ i + 1 });
         return v.back();
      }, v);
      std::cout &lt;&lt; "vector&lt;Data&gt;:\n\t"
                &lt;&lt; v.size()
                &lt;&lt; " insertions in "
                &lt;&lt; duration_cast&lt;microseconds&gt;(dt).count()
                &lt;&lt; " us\n";
   }
   {
<strong class="bold">      alignas(Data) char buf[N * sizeof(Data)];</strong>
<strong class="bold">      seq_buf_allocator&lt;Data&gt; alloc{ buf, sizeof buf };</strong>
<strong class="bold">      std::vector&lt;Data, seq_buf_allocator&lt;Data&gt;&gt; v(alloc);</strong>
      auto [r, dt] = test([](auto &amp; v) {
         v.reserve(N);
         for(int i = 0; i != N; ++i)
            v.push_back({ i + 1 });
         return v.back();
      }, v);
      std::cout
         &lt;&lt; "vector&lt;Data, seq_buf_allocator&lt;Data&gt;&gt;:\n\t"
         &lt;&lt; v.size()
         &lt;&lt; " insertions in "
         &lt;&lt; duration_cast&lt;microseconds&gt;(dt).count()
         &lt;&lt; " us\n";
   }
<strong class="bold">   // do the same replacing std::vector with Vector</strong>
}</pre> <p>Here are a few <a id="_idIndexMarker833"/>things you might want to note at this<a id="_idIndexMarker834"/> point:</p>
<ul>
<li>The test code is the same irrespective of the chosen allocator.</li>
<li>When using a stateful allocator, we need to use a parametric constructor that accepts the allocator as argument.</li>
<li>The responsibility with respect to the size and alignment of the buffer used by the <code>seq_buf_allocator&lt;T&gt;</code> falls on the (metaphorical) shoulders of user code. Again, remember that this is a specialized tool, so users are expected to know what they are doing.</li>
<li>If you run this test on a conforming compiler, you might notice interesting performances with the sequential buffer allocator, and you might notice that <code>Vector&lt;T,A&gt;</code> outperforms <code>std::vector&lt;T,A&gt;</code>, but <code>Vector&lt;T,A&gt;</code> is not as complete and rigorous as its <code>std::</code> counterpart. Prefer the standard facilities in practice.</li>
<li>There are limitations to the size of the buffer provided to a sequential buffer allocator as stack space is a limited resource (often one or two megabytes overall, so we have less than this to work with). Still, this technique is useful and used in practice in low-latency systems.</li>
<li>If you apply this sort of allocator with a node-based container list <code>ForwardList&lt;T,A&gt;</code>, remember that there is a size overhead to each node so plan the size of the buffer to provide accordingly.</li>
</ul>
<p>Of course, that <a id="_idIndexMarker835"/>was an implementation <a id="_idIndexMarker836"/>that respects C++17 standards. What has changed with respect to allocators since then?</p>
<h2 id="_idParaDest-199"><a id="_idTextAnchor205"/>Traditional allocators with contemporary standards</h2>
<p>As mentioned <a id="_idIndexMarker837"/>already, the traditional approach<a id="_idIndexMarker838"/> of ensconcing the allocator type in the associated container type still exists as of this writing, but the way allocators themselves are expressed has changed over time, and the allocators from the previous section, whether <code>small_allocator&lt;T&gt;</code> or <code>seq_buf_allocator&lt;T&gt;</code>, do not compile as written on a C++20 compiler. Before thinking this is sad, know that we can still write these allocators, but we have to write them in a simpler manner. Whew!</p>
<h3>Simplification and the advent of a traits-based implementation</h3>
<p>The first step in a simplification effort of allocators was the recognition that in most cases, a significant part of the code written in an allocator is what we call “boilerplate code,” code that is the same from class to class and could be qualified as “noise.”</p>
<p>To that effect, C++11 introduced <code>std::allocator_traits&lt;A&gt;</code>. The idea is that given some <code>typename A::value_type</code> type, one can generate a reasonable and efficient default implementation for most allocator services (including type aliases such as <code>pointer</code> or <code>size_type</code>) as long as one provides implementations for <code>allocate()</code> and <code>deallocate()</code>.</p>
<p>Using <code>small_allocator&lt;T&gt;</code> as an illustration, we would now be able to simply express that entire allocator type with the following:</p>
<pre class="source-code">
template &lt;class T&gt;
struct small_allocator {
<strong class="bold">   using value_type = T;</strong>
   <strong class="bold">T* allocate(std::size_t n)</strong> {
      auto p = <strong class="bold">static_cast&lt;T*&gt;</strong>(
         malloc(n * sizeof(value_type))
      );
      if (!p) throw std::bad_alloc{};
      return p;
   }
   <strong class="bold">void deallocate(T *p, std::size_t)</strong> {
      free(p);
   }
};
// ... insert the equality operators here</pre> <p>As you can see, this is quite a simplification! This way, a container such as <code>Vector&lt;T,A&gt;</code> could now use <code>std::allocator_traits&lt;A&gt;</code> instead of <code>A</code> directly when referring to some allocator <code>A</code>’s members. With traits being this very thin layer of abstraction that brings no runtime cost to speak of, what they do for some member <code>M</code> is essentially “If <code>A</code> exposes <a id="_idIndexMarker839"/>member “<code>M</code>, then <a id="_idIndexMarker840"/>use <code>A::M</code>; otherwise, here is some reasonable default implementation instead.” Of course, there will be no branching here in practice as everything is determined at compile time.</p>
<p>For example, based on our previous <code>small_allocator&lt;T&gt;</code> type, given that <code>small_allocator&lt;T&gt;::allocate()</code> returns <code>T*</code>, then we can determine that <code>std::allocator_traits&lt;small_allocator&lt;T&gt;&gt;::pointer</code> will be equivalent to <code>T*</code>, and a container such as <code>Vector&lt;T,A&gt;</code> will make its <code>pointer</code> type alias correspond to the type expressed by <code>std::allocator_traits&lt;A&gt;::pointer</code>.</p>
<p>For another example, <code>seq_buf_allocator&lt;T&gt;</code> would now be expressed as follows:</p>
<pre class="source-code">
template &lt;class T&gt;
struct seq_buf_allocator {
<strong class="bold">   using value_type = T;</strong>
<strong class="bold">   using pointer = T*;</strong>
<strong class="bold">   using size_type = std::size_t;</strong>
   char* buf;
   pointer cur;
   size_type cap;
   seq_buf_allocator(char* buf, size_type cap) noexcept
      : buf{ buf }, cap{ cap } {
      cur = reinterpret_cast&lt;pointer&gt;(buf);
   }
   pointer allocate(size_type n) {
      auto request =
         reinterpret_cast&lt;std::intptr_t&gt;(cur + n),
           limit =
         reinterpret_cast&lt;std::intptr_t&gt;(buf + cap);
      if (request &gt; limit) {
         throw std::bad_alloc{};
      }
      auto q = cur;
      cur += n;
      return q;
   }
   void deallocate(pointer, size_type) {
   }
};
// ... insert equality operators here</pre> <p>In this<a id="_idIndexMarker841"/> case, even <a id="_idIndexMarker842"/>though it was not necessary, type <code>seq_buf_allocator&lt;T&gt;</code> exposes the <code>pointer</code> and <code>size_type</code> aliases, which means that for this type, the <code>std::allocator_traits</code> will use the allocator-provided versions instead of trying to synthesize an alternative. As you can see, the contemporary traits-based approach to allocators is very convenient.</p>
<p>What services does type <code>std::allocator_traits&lt;A&gt;</code> provide exactly? Well, as could be expected, this type exposes the usual type aliases of <code>value_type</code> (itself being an alias for <code>A::value_type</code>), <code>pointer</code>, <code>const_pointer</code>, <code>size_type</code>, and <code>difference_type</code>. For convenience, it also exposes aliases <code>allocator_type</code> (equivalent to <code>A</code>): <code>void_pointer</code> and <code>const_void_pointer</code> (respectively equivalent to <code>void*</code> and <code>const void*</code> in most cases). Remember that traits can be specialized, and for that reason, these seemingly evident type aliases could map to more exotic constructs on occasion.</p>
<p>Type <code>std::allocator_traits&lt;A&gt;</code> also exposes the traditional services of an allocator, but in the form of <code>static</code> member functions that take the allocator as first argument, including <code>construct()</code>, <code>destroy()</code>, <code>allocate()</code>, <code>deallocate()</code>, and <code>max_size()</code>. C++23 adds another <code>static</code> member function to this set: <code>allocate_at_least()</code>. This function returns a <code>std::allocation_result</code> object made of the allocated pointer and the actual size of the allocated chunk, expressed as a <a id="_idIndexMarker843"/>number<a id="_idIndexMarker844"/> of objects (even though, as usual, there is no object in that memory block after allocation has completed).</p>
<p>The <code>rebind</code> mechanism is expressed through types <code>std::rebind_alloc&lt;A&gt;</code> and <code>std::rebind_traits&lt;T&gt;</code>. When cloning an allocation strategy (for node containers, mostly), the equivalent of <code>typename A::rebind&lt;T&gt;::other</code> through these facilities is somewhat more verbose:</p>
<pre class="source-code">
// ...
<strong class="bold">   typename std::allocator_traits&lt;</strong>
<strong class="bold">      A</strong>
<strong class="bold">   &gt;::template rebind_alloc&lt;Node&gt;;</strong>
// ...</pre> <p>Note the presence of the <code>template</code> keyword required for grammatical disambiguation Yes, I know what you are thinking now: what a complex language! But we rarely need to use that keyword in practice, and only in those strange situations where the compiler would get confused looking at the following <code>&lt;</code> and not knowing whether it’s part of a template signature or whether it’s the less-than operator.</p>
<p>There are also new facilities that come with <code>std::allocator_traits&lt;A&gt;</code> and deal with allocator lifetime management, something we learned to do over the years:</p>
<ul>
<li>Three type aliases that inform containers as to what should be done with the allocator at key moments in the container’s life. These types are <code>propagate_on_container_copy_assignment</code> (also known as <code>propagate_on_container_move_assignment</code> (also known as <code>propagate_on_container_swap</code> (also known as <code>constexpr</code> functions that yield <code>true</code> or <code>false</code> (they are equivalent to <code>std::false_type</code> by default as, by default, allocators are not meant to be copied or moved). For example, if an allocator exposes type alias POCMA equivalent to <code>std::true_type</code>, then a container with that allocator should move the allocator along with the allocated data. Note that in all three cases, this trait being <a id="_idIndexMarker848"/>equivalent <a id="_idIndexMarker849"/>to <code>std::true_type</code> implies a <code>noexcept</code> copy, move, or swap (respectively) operation for the allocator.</li>
<li>Type alias <code>is_always_equal</code>; which means that allocators of that type will compare equally irrespective of the type of object to allocate (this alleviates the need for <code>operator==()</code> and <code>operator!=()</code>, which compare two allocators of the same template but different <code>value_type</code> aliases). Don’t spend too much time on this one though; it has been deprecated in C++23 and will most likely be removed in C++26.</li>
<li>The <code>select_on_container_copy_construction()</code> member function. This is a <code>static</code> member function that takes an allocator and copies it if its allocator traits express that this is the right thing to do, or returns the original allocator otherwise.</li>
</ul>
<p>Okay, this allocator <a id="_idIndexMarker850"/>lifetime<a id="_idIndexMarker851"/> management is new and might be surprising. What do we do with this information?</p>
<h2 id="_idParaDest-200"><a id="_idTextAnchor206"/>Managing traditional allocator lifetime</h2>
<p>What should a container<a id="_idIndexMarker852"/> do with allocators within a move or a copy operation? Well, here are the details.</p>
<p>In a container’s copy constructor, the best thing to do is probably to use <code>select_on_container_copy_construction()</code>. It is that function’s purpose, after all. Please do not use that function elsewhere: it is really meant for the copy constructor of a container. Once the container under construction has obtained its allocator, this allocator can be used to perform the remainder of the memory allocation tasks.</p>
<p>In a container’s move constructor, the thing to do is move construct the allocator and steal the resources from the source container.</p>
<p>In a container’s copy assignment operator, if type alias <code>propagate_on_container_copy_assignment</code> is equivalent to <code>std::true_type</code> and both allocators compare unequally, the destination container first has to deallocate all memory (that might not be possible later on in the process). Past this point, if <code>propagate_on_container_copy_assignment</code> is equivalent to <code>std::true_type</code>, then the allocators should be copy-assigned. Only once this is all done should the elements be copied.</p>
<p>The container’s move assignment operator is trickier (remember that <em class="italic">move</em> is an optimization, and we want it to pay off!). The options we face are as follows:</p>
<ul>
<li>Type alias <code>propagate_on_container_move_assignment</code> is equivalent to <code>std::true_type</code>. In this situation, the steps to perform are (a) ensure that the destination container deallocates all memory under its responsibility (it might not be able to do so later on), (b) move-assign the allocator, and then (c) transfer memory ownership from the source container to the destination container.</li>
<li>Type alias <code>propagate_on_container_move_assignment</code> is equivalent to <code>std::false_type</code> and the allocators compare equally. In this situation, you can do the same steps as in the previous case but do not move the container.</li>
<li>Type alias <code>propagate_on_container_move_assignment</code> is equivalent to <code>std::false_type</code> and the allocators compare unequally. In this case, ownership cannot really be transferred, so the best one can do is move the objects themselves from the source container to the destination container.</li>
</ul>
<p>Luckily, all of these<a id="_idIndexMarker853"/> allocator properties can be tested at compile time so the decision-making process does not need to incur any runtime cost.</p>
<p class="callout-heading">Things we do for concision…</p>
<p class="callout">You will notice our <code>Vector&lt;T,A&gt;</code> and <code>ForwardList&lt;T,A&gt;</code> types do not do the entire “allocator lifetime management dance” in order to keep our examples reasonably short, and because the way in which we manage allocator copy and movement is an interesting design aspect that would require adding at least one chapter to this already rather big book. Please be tolerant, dear reader.</p>
<h3>Using traits-based allocators in allocator-aware containers</h3>
<p>The remaining<a id="_idIndexMarker854"/> question with<a id="_idIndexMarker855"/> traditional allocators in a traits-based approach is: how do containers use them?</p>
<p>The first thing we will need to do is to adapt our allocator-aware adaptation of the standard uninitialized memory algorithms. For example, our personal adaptation of <code>std::uninitialized_copy()</code> becomes the following:</p>
<pre class="source-code">
template &lt;class A, class IIt, class OIt&gt;
void uninitialized_copy_with_allocator
   (A &amp;a, IIt bs, IIt es, OIt bd) {
   auto p = bd;
   try {
      for (auto q = bs; q != es; ++q) {
<strong class="bold">         std::allocator_traits&lt;A&gt;::construct(a, p, *q);</strong>
         ++p;
      }
   } catch (...) {
      for (auto q = bd; q != p; ++q)
<strong class="bold">         std::allocator_traits&lt;A&gt;::destroy(a, q);</strong>
      throw;
   }
}</pre> <p>As you can see, we are now using <code>std::allocator_traits&lt;A&gt;</code> instead of <code>A</code> directly, opening up customization opportunities, and passing the allocator as first argument since the <code>std::allocator_traits&lt;A&gt;</code> member functions are all <code>static</code>. The same adjustment can be applied to the other allocator-aware versions of the algorithms we wrote, with the same calling pattern and passing the allocator as first argument.</p>
<p>Then, we<a id="_idIndexMarker856"/> reach<a id="_idIndexMarker857"/> our <code>Vector&lt;T,A&gt;</code> type. How do we adjust its implementation to use the contemporary traits-based allocators? The first thing to do is to adjust the source of the container’s type aliases:</p>
<pre class="source-code">
template &lt;class T, class A = std::allocator&lt;T&gt;&gt;
class Vector : A { // note: private inheritance
public:
   using value_type =
      typename <strong class="bold">std::allocator_traits&lt;A&gt;::value_type</strong>;
   using size_type =
      typename <strong class="bold">std::allocator_traits&lt;A&gt;::size_type</strong>;
   using pointer =
      typename <strong class="bold">std::allocator_traits&lt;A&gt;::pointer</strong>;
   using const_pointer =
      typename <strong class="bold">std::allocator_traits&lt;A&gt;::const_pointer</strong>;
<strong class="bold">   using reference = value_type&amp;;</strong>
<strong class="bold">   using const_reference = const value_type&amp;;</strong>
   // ...</pre> <p>You might be surprised that type aliases <code>reference</code> and <code>const_reference</code> are not taken from <code>std::allocator_traits&lt;A&gt;</code>, but there is a reason for this. In C++, as in this writing, we can design types that behave like “smart pointers” (we have even done so in this book; see <a href="B21071_06.xhtml#_idTextAnchor096"><em class="italic">Chapter 6</em></a>), so an abstraction is useful in case the allocator provides pointers that are not raw pointers, but there is no known way to write “smart references” (that would require being able to overload <code>operator.()</code> and proposals to that effect have so far failed to be accepted).</p>
<p>The only reference type that behaves like a reference to <code>T</code> is… well, <code>T&amp;</code>. For that reason, these type aliases were deprecated in C++17 and removed in C++20. We can still provide them to clarify our <a id="_idIndexMarker858"/>type’s<a id="_idIndexMarker859"/> member function signatures, but they are no longer required by the standard.</p>
<p>As far as the member functions of <code>Vector&lt;T,A&gt;</code> go, the general idea is that all calls to member functions of <code>A</code> are replaced with calls to <code>static</code> member functions of <code>std::allocator_traits&lt;A&gt;</code> that take a reference to the <code>A</code> object as argument (remember that in our <code>Vector&lt;T,A&gt;</code> implementation, <code>A</code> is a <code>private</code> base class of the container). Here is an example:</p>
<pre class="source-code">
   Vector(size_type n, const_reference init)
      : <strong class="bold">A{}</strong>,
<strong class="bold">        elems{ std::allocator_traits&lt;A&gt;::allocate(</strong>
<strong class="bold">           static_cast&lt;A&amp;&gt;(*this), n)</strong>
<strong class="bold">        },</strong>
        nelems{ n }, cap{ n } {
      try {
         <strong class="bold">uninitialized_fill_with_allocator</strong>(
            <strong class="bold">static_cast&lt;A&amp;&gt;(*this)</strong>, begin(), end(), init
         );
      } catch (...) {
<strong class="bold">         std::allocator_traits&lt;A&gt;::deallocate(</strong>
<strong class="bold">            static_cast&lt;A&amp;&gt;(*this), elems, capacity()</strong>
<strong class="bold">         );</strong>
         throw;
      }
   }</pre> <p>If you feel discomfort with the use of <code>*this</code> in the data member initializers, you can relax as we are only using the <code>A</code> part of <code>*this</code> and that base class sub-object has been fully initialized at that point. It’s a safe part of <code>*this</code> to use.</p>
<p>The same adjustment has to be applied throughout the container (in dozens of places) and obviously makes the source code more verbose, but the good news is that this has gained us a zero-cost-at-runtime layer of abstraction and helped everyone who actually writes allocators.</p>
<p>For a node-based<a id="_idIndexMarker860"/> container <a id="_idIndexMarker861"/>such as <code>ForwardList&lt;T,A&gt;</code>, the situation is similar yet slightly different. For one thing, the type aliases are tricky; some of them are meant for user code and should be expressed with respect to the <code>value_type</code> of the container, and others should be based on the types of the allocator as expressed through its traits:</p>
<pre class="source-code">
template &lt;class T, class A = std::allocator&lt;T&gt;&gt;
class ForwardList {
public:
   // note: these are the forward-facing types, expressed
   // in terms where T is the value_type
<strong class="bold">   using value_type = T;</strong>
<strong class="bold">   using size_type =</strong>
<strong class="bold">      typename std::allocator_traits&lt;A&gt;::size_type;</strong>
<strong class="bold">   using pointer = value_type*;</strong>
<strong class="bold">   using const_pointer = const value_type*;</strong>
<strong class="bold">   using reference = value_type&amp;;</strong>
<strong class="bold">   using const_reference = const value_type&amp;;</strong>
   // ...</pre> <p>Within the container, we<a id="_idIndexMarker862"/> need <a id="_idIndexMarker863"/>to rebind <code>A</code> to an allocator of our internal <code>Node</code> type:</p>
<pre class="source-code">
   // ...
private:
   struct Node {
      value_type value;
      Node *next = nullptr;
      Node(const_reference value) : value { value } {
      }
      Node(value_type &amp;&amp;value) : value{ std::move(value) }{
      }
   };
<strong class="bold">   using Alloc = typename std::allocator_traits&lt;</strong>
<strong class="bold">      A</strong>
<strong class="bold">   &gt;::template rebind_alloc&lt;Node&gt;;</strong>
<strong class="bold">   Alloc alloc;</strong>
   // ...</pre> <p>Past this point, what we will do to perform memory management tasks is use <code>static</code> member functions from the <code>std::allocator_traits&lt;Alloc&gt;</code> type, passing the <code>alloc</code> data member as argument, as in this example:</p>
<pre class="source-code">
   // ...
   void clear() noexcept {
      for(auto p = head; p; ) {
         auto q = p-&gt;next;
<strong class="bold">         std::allocator_traits&lt;Alloc&gt;::destroy(alloc, p); </strong>
<strong class="bold">         std::allocator_traits&lt;Alloc&gt;::deallocate(</strong>
<strong class="bold">            alloc, p, 1</strong>
<strong class="bold">         );</strong>
         p = q;
      }
      nelems = 0;
   }
   template &lt;std::forward_iterator It&gt;
      ForwardList(It b, It e) {
         if(b == e) return;
         try {
<strong class="bold">            head = std::allocator_traits&lt;</strong>
<strong class="bold">               Alloc</strong>
<strong class="bold">            &gt;::allocate(alloc, 1);</strong>
<strong class="bold">            std::allocator_traits&lt;Alloc&gt;::construct(</strong>
<strong class="bold">               alloc, head, *b</strong>
<strong class="bold">            );</strong>
            auto q = head;
            ++nelems;
            for(++b; b != e; ++b) {
<strong class="bold">               auto ptr = std::allocator_traits&lt;</strong>
<strong class="bold">                  Alloc</strong>
<strong class="bold">               &gt;::allocate(alloc, 1);</strong>
<strong class="bold">               std::allocator_traits&lt;</strong>
<strong class="bold">                  Alloc</strong>
<strong class="bold">               &gt;::construct(alloc, ptr, *b);</strong>
               q-&gt;next = ptr;
               q = q-&gt;next;
               ++nelems;
            }
         } catch (...) {
            clear();
            throw;
         }
      }
   // ...</pre> <p>The same technique needs to be applied throughout the container, of course, but the complexity remains the same.</p>
<p>Now that we have seen how traditional allocators, ensconced in the type of their container, have evolved from their original (rather involved) contract to their contemporary <a id="_idIndexMarker864"/>traits-based <a id="_idIndexMarker865"/>and simplified implementation (with somewhat more verbose containers), it’s tempting to think that we have reached some form of optimality. This is both right and wrong.</p>
<h2 id="_idParaDest-201"><a id="_idTextAnchor207"/>Irritants with traditional allocators</h2>
<p>The traditional approach <a id="_idIndexMarker866"/>to allocators is optimal at runtime in the sense that the services of such an allocator can be called without any overhead, and if an allocator is stateless, the introduction of an allocator in a container can be achieved without any costs in terms of space. Not bad!</p>
<p>Of course, the absence of runtime costs is not the absence of costs altogether:</p>
<ul>
<li>A container’s implementation can become somewhat complex due to the additional (compile-time) layering, and there is a cost to writing, understanding, and maintaining source code. This sort of expertise is not universal; you have it, of course, dear reader, but others do not necessarily share that upside with you.</li>
<li>Two containers that are identical in essentially every respect but differ in the way they manage memory (two containers that use different allocators) will in practice be different types, which might slow down compile times in programs that have multiple container-allocator combinations.</li>
<li>Some operations that should probably be simple become more complicated. For example, if one seeks to compare containers <code>v0</code> and <code>v1</code> for equality, and if <code>v0</code> is a <code>Vector&lt;T,A0&gt;</code> while <code>v1</code> is a <code>Vector&lt;T,A1&gt;</code>, then one needs to write an <code>operator==()</code> function that deals with two different types… even though the allocator of a container is probably not one of its salient properties and, as such, should not be a concern when comparing two containers with respect to their sizes and values.</li>
</ul>
<p>The same reasoning goes for many other container-related operations: an allocator is (traditionally) part of its container’s type with the traditional approach, but many operations are <code>value_type</code>-related and have nothing to do with allocators. We are runtime optimal, but we have additional costs with respect to code generation complexity (which might lead to bigger binaries, which might have runtime speed impacts), and increasing the maintenance effort (including understanding code from its source) has a price.</p>
<p>Even something as seemingly simple as making allocators type-aware (traditional allocators are allocators of <code>T</code> for some type <code>T</code> after all) is sometimes controversial. Low-level memory allocation functions such as <code>std::malloc()</code> or <code>::operator new()</code> deal in raw bytes<a id="_idIndexMarker867"/> after all, so is it a sign that our traditional allocator model is perfectible?</p>
<h1 id="_idParaDest-202"><a id="_idTextAnchor208"/>Polymorphic memory resource allocators</h1>
<p>With C++17, the C++ language <a id="_idIndexMarker868"/>added so-called PMR allocators. A PMR container stores allocator information as a runtime value, not as a compile-time part of its type. In this model, a PMR container holds a pointer to a PMR allocator, reducing the number of types required but adding virtual function calls whenever using memory allocation services.</p>
<p>This is again not a no-cost decision, and there are trade-offs with the traditional model:</p>
<ul>
<li>This new allocator model supposes that containers store a pointer to an allocation strategy, which generally (not always) makes PMR containers larger than their non-PMR counterparts. Interestingly, it also means that a <code>std::pmr::vector&lt;T&gt;</code> is a different container from a <code>std::vector&lt;T&gt;</code>, which sometimes causes very real annoyances. For example, there is no implicit way to copy the contents of a <code>std::pmr::string</code> into a <code>std::string</code>, but luckily, writing such a function is very easy.</li>
<li>Every allocation or deallocation service call incurs a polymorphic indirection cost. This will be minor to unnoticeable in programs where the called function performs some significant computation, but the same costs can be painful when the called function<a id="_idIndexMarker869"/> performs little computation.</li>
<li>PMR containers are parameterized on memory resources, and PMR memory resources trade in bytes, not in objects. It’s unclear whether this is a good thing or a bad thing (it’s probably a matter of perspective), as both approaches work, but trading in bytes (the simplest common denominator) makes it easier to reduce the number of types in a program.</li>
</ul>
<p>There are also advantages to the PMR approach:</p>
<ul>
<li>The type of a container is not influenced by the type of its allocator. All PMR containers simply hold a pointer to the base class of all PMR memory resources named <code>std::pmr::memory_resource</code>.</li>
<li>The work required to implement a PMR allocator is very small as one only needs to override three virtual member functions. This opens up avenues to express reusable allocator libraries, for example.</li>
</ul>
<p>Under the PMR model, a <code>std::pmr::polymorphic_allocator&lt;T&gt;</code> object uses a <code>std::pmr::memory_resource*</code> to determine how memory is managed. In most cases, when designing a memory allocation strategy, what one does is write a class that specializes <code>std::memory_resource</code> and determines what it means to allocate or deallocate memory with that strategy.</p>
<p>Let’s look at a simple example of a PMR container with a sequential buffer memory resource, as we just <a id="_idIndexMarker870"/>implemented such a mechanism with traditional allocators:</p>
<pre class="source-code">
#include &lt;print&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
<strong class="bold">#include &lt;memory_resource&gt;</strong>
int main() {
   enum { N = 10'000 };
<strong class="bold">   alignas(int) char buf[N * sizeof(int)]{};</strong>
<strong class="bold">   std::pmr::monotonic_buffer_resource</strong>
<strong class="bold">      res{ std::begin(buf), std::size(buf) };</strong>
<strong class="bold">   std::pmr::vector&lt;int&gt; v{ &amp;res };</strong>
   v.reserve(N);
   for (int i = 0; i != N; ++i)
      v.emplace_back(i + 1);
   for (auto n : v)
      std::print("{} ", n);
   std::print("\n {}\n", std::string(70, '-'));
   for (char * p = buf; p != buf + std::size(buf);
        p += sizeof(int))
      std::print("{} ", *reinterpret_cast&lt;int*&gt;(p));
}</pre> <p>That’s quite simple, isn’t it? You might want to pay attention to the following:</p>
<ul>
<li>This program aims to “allocate” objects in a byte buffer located on the thread’s execution stack. With these objects being of type <code>int</code>, we ensure that buffer <code>buf</code> is appropriately aligned and is of sufficient size to hold the objects that are meant to be stored therein.</li>
<li>A <code>std::pmr::monotonic_buffer_resource</code> object named <code>res</code> knows where the buffer to manage starts and how big it is. It represents a perspective on contiguous memory.</li>
<li>The <code>std::pmr::vector&lt;int&gt;</code> used in this program knows about <code>res</code> and uses that resource to allocate and deallocate memory.</li>
</ul>
<p>That’s all there is to it. In practice, this program does not allocate even a single byte from the free store in order to store the <code>int</code> objects. Compared to what we had to do to achieve similar effects in the past, this might seem rejoiceful somewhat. At the end of the program, iterating through the byte buffer and iterating through the container yield the same results.</p>
<p>That works nicely <a id="_idIndexMarker871"/>and requires very little coding effort, but what if we wanted to express something like a vector of <code>string</code> objects but wanted both the vector and the <code>string</code> objects it stores to use the same allocation strategy?</p>
<h2 id="_idParaDest-203"><a id="_idTextAnchor209"/>Nested allocators</h2>
<p>Well, it so <a id="_idIndexMarker872"/>happens that PMR allocators propagate allocation strategies by default. Consider the following example:</p>
<pre class="source-code">
#include &lt;print&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
<strong class="bold">#include &lt;memory_resource&gt;</strong>
int main() {
<strong class="bold">   auto make_str = [](const char *p, int n) -&gt;</strong>
<strong class="bold">      std::pmr::string {</strong>
<strong class="bold">      auto s = std::string{ p } + std::to_string(n);</strong>
<strong class="bold">      return { std::begin(s), std::end(s) };</strong>
<strong class="bold">   };</strong>
   enum { N = 2'000 };
<strong class="bold">   alignas(std::pmr::string) char buf[N]{};</strong>
<strong class="bold">   std::pmr::monotonic_buffer_resource</strong>
<strong class="bold">      res{ std::begin(buf), std::size(buf) };</strong>
<strong class="bold">   std::pmr::vector&lt;std::pmr::string&gt; v{ &amp;res };</strong>
   for (int i = 0; i != 10; ++i)
      v.emplace_back(make_str("I love my instructor ", i));
   for (const auto &amp;s : v)
      std::print("{} ", s);
   std::print("\n {}\n", std::string(70, '-'));
   for (char c : buf)
      std::print("{} ", c);
}</pre> <p>This example also uses a buffer on the stack, but that buffer is used both for the <code>std::pmr::vector</code> object and its metadata and for the <code>std::string</code> objects therein. Propagation of<a id="_idIndexMarker873"/> the allocation strategy from the enclosing container to the enclosed containers is implicit.</p>
<p>Do note that the <code>make_str</code> lambda expression in that program is used to convert <code>std::string</code> (formatted to end with an integer) to a <code>std::pmr::string</code>. As mentioned earlier, the integration of types from namespace <code>std</code> and types from namespace <code>std::pmr</code> sometimes requires a little bit of effort, but the APIs of classes in these namespaces are sufficiently similar for this effort to remain reasonable.</p>
<p>If you use this program, you will notice that the <code>std::pmr::string</code> objects contain the expected text, but you will also probably notice from the last loop that buffer <code>buf</code> contains (among other things) the text in the strings. That’s because our strings are rather short and, in most standard library implementations, the <code>std::pmr::string</code> instead of being allocated separately. This shows clearly that the same allocation strategy, represented by our object of type <code>std::pmr::monotonic_buffer_resource</code>, has propagated from the <code>std::pmr::vector</code> object to the enclosed <code>std::pmr::string</code> objects.</p>
<p class="callout-heading">Scoped allocators and the traditional model</p>
<p class="callout">It is possible<a id="_idIndexMarker875"/> to use a<a id="_idIndexMarker876"/> scoped allocator system with the traditional allocator approach, even though we did not do so in this book. If you are curious, feel free to explore type <code>std::scoped_allocator_adapter</code> for more information.</p>
<p>We will now look at<a id="_idIndexMarker877"/> one last example that uses allocators to track the memory allocation process.</p>
<h2 id="_idParaDest-204"><a id="_idTextAnchor210"/>Allocators and data collection</h2>
<p>As we saw in <a href="B21071_08.xhtml#_idTextAnchor128"><em class="italic">Chapter 8</em></a> when<a id="_idIndexMarker878"/> we wrote our own humble yet functional leak detector, memory management tools are often used to gather information. For a non-exhaustive list, know that some companies use them to track memory fragmentation or otherwise assess where objects are placed in memory, maybe in a quest to optimize cache usage. Others want to evaluate when and where allocations occur in the course of program execution to know whether a reorganization of the code could lead to better performances. Of course, detecting leaks is useful, but we already knew that.</p>
<p>As our third and last example of PMR allocation usage, we will implement a <em class="italic">tracing resource</em>, in the sense<a id="_idIndexMarker879"/> that we will track allocation and deallocation requests from a container to understand some implementation choices made by that container. For the sake of this example, we will use a standard library’s <code>std::pmr::vector</code> and try to understand its approach to increasing its capacity when trying to insert objects into a full container. Remember that the standard mandates an amortized constant complexity for operations such as <code>push_back()</code>, meaning that capacity should grow rarely and most insert-at-end operations should take constant time. However, it does not impose a specific growth policy: for example, one implementation could grow by a factor of 2, another by a factor of 1.5, and another could prefer 1.67. Other options exist; each one has trade-offs, and each library makes its own choices.</p>
<p>We will express this tool as class <code>tracing_resource</code>, which derives from <code>std::pmr::memory_resource</code> as expected by <code>std::pmr</code> containers. This lets us show how easy it is to add a memory resource type to this framework:</p>
<ul>
<li>The base class exposes three member functions that we need to override: <code>do_allocate()</code>, which is meant to perform an allocation request, <code>do_deallocate()</code>, whose role is, unsurprisingly, to deallocate memory that is presumed to have been allocated through <code>do_allocate()</code>, and <code>do_is_equal()</code>, which is meant to let user code test two memory resources for equality. Note that “equality” in this sense means that memory allocated from one could be deallocated from the other.</li>
<li>Since we want to trace allocation requests but do not want to implement an actual memory <a id="_idIndexMarker880"/>allocation strategy ourselves, we will use an <code>upstream</code> resource that will do the allocation and deallocation for us. In our test implementation, that resource will be a global resource obtained from <code>std::pmr::new_delete_resource()</code> that calls <code>::operator new()</code> and <code>::operator delete()</code> to achieve this objective.</li>
<li>For this reason, our allocation functions will simply “log” (in our case, print) the requested allocation and deallocation sizes, then delegate the allocation work to the <code>upstream</code> resource.</li>
</ul>
<p>A complete implementation follows:</p>
<pre class="source-code">
#include &lt;print&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
<strong class="bold">#include &lt;memory_resource&gt;</strong>
<strong class="bold">class tracing_resource : public std::pmr::memory_resource {</strong>
<strong class="bold">   void* do_allocate(</strong>
<strong class="bold">      std::size_t bytes, std::size_t alignment</strong>
<strong class="bold">   ) override {</strong>
<strong class="bold">       std::print ("do_allocate of {} bytes\n", bytes);</strong>
<strong class="bold">       return upstream-&gt;allocate(bytes, alignment);</strong>
<strong class="bold">   }</strong>
<strong class="bold">   void do_deallocate(</strong>
<strong class="bold">      void* p, std::size_t bytes, std::size_t alignment</strong>
<strong class="bold">   ) override {</strong>
<strong class="bold">       std::print ("do_deallocate of {} bytes\n", bytes);</strong>
<strong class="bold">       return upstream-&gt;deallocate(p, bytes, alignment);</strong>
<strong class="bold">   }</strong>
<strong class="bold">   bool do_is_equal(</strong>
<strong class="bold">      const std::pmr::memory_resource&amp; other</strong>
<strong class="bold">   ) const noexcept override {</strong>
<strong class="bold">       return upstream-&gt;is_equal(other);</strong>
<strong class="bold">   }</strong>
<strong class="bold">   std::pmr::memory_resource *upstream;</strong>
<strong class="bold">public:</strong>
<strong class="bold">   tracing_resource(std::pmr::memory_resource *upstream)</strong>
<strong class="bold">      noexcept : upstream{ upstream } {</strong>
<strong class="bold">   }</strong>
<strong class="bold">};</strong>
int main() {
   enum { N = 100 };
<strong class="bold">   tracing_resource tracer{</strong>
<strong class="bold">      std::pmr::new_delete_resource()</strong>
<strong class="bold">   };</strong>
<strong class="bold">   std::pmr::vector&lt;int&gt; v{ &amp;tracer };</strong>
   for (int i = 0; i != N; ++i)
      v.emplace_back(i + 1);
   for (auto s : v)
      std::print("{} ", s);
}</pre> <p>If you run this very simple program, you will develop an intuition for the growth strategy of your standard <a id="_idIndexMarker881"/>library <code>std::pmr::vector</code> implementation.</p>
<h2 id="_idParaDest-205"><a id="_idTextAnchor211"/>Upsides and costs</h2>
<p>As we have seen, there’s<a id="_idIndexMarker882"/> a lot to love about the PMR model. It is simple to use, relatively simple to understand, and easy to extend. In many application domains, it is fast enough to meet most programmers’ needs.</p>
<p>There are, of course, also domains that need the increased control over execution time and runtime behavior that the traditional allocator model allows: no indirection that stems from the model, no overhead in terms of object size… Sometimes, you just need all the control you can get. This means that both models work and have their own valid reasons for being.</p>
<p>One very real benefit of PMR allocators is that they make it easier to build allocator and resource libraries that one can combine and build from. The standard library offers a few useful examples from the <code>&lt;</code><code>memory_resource&gt;</code> header:</p>
<ul>
<li>We have already seen function <code>std::pmr::new_delete_resource()</code>, which provides a system-wide resource where allocation and deallocation are implemented through <code>::operator new()</code> and <code>::operator delete()</code>, just as we have seen class <code>std::pmr::monotonic_buffer_resource</code>, which formalizes the process of sequential allocation within an existing buffer.</li>
<li>The <code>std::pmr::synchronized_pool_resource</code> and <code>std::pmr::unsynchronized_pool_resource</code> classes model the allocation of objects from pools of blocks of some sizes. Use the synchronized one for multithreaded code, of course.</li>
<li>There are <code>std::pmr::get_default_resource()</code> and <code>std::pmr::set_default_resource()</code> functions that respectively obtain or replace the default memory resource of a program. The default memory resource is, as could be expected, the same as what is returned by function <code>std::pmr::new_delete_resource()</code>.</li>
<li>There is also a function <code>std::pmr::null_memory_resource()</code> that returns a resource that never allocates (its <code>do_allocate()</code> member function, when called, throws <code>std::bad_alloc</code>). This is interesting as an “upstream” measure: consider a sequential buffer allocator system implemented through <code>std::pmr::monotonic_buffer_resource</code> in which a request for memory allocation leads to a possible buffer overflow. Since, by default, the <code>upstream</code> of a memory resource uses another resource that calls <code>::operator new()</code> and <code>::operator delete()</code>, this potential overflow will lead to an actual allocation, which could have an undesirable impact on performance. Choosing a <code>std::pmr::null_memory_resource</code> for the <code>upstream</code> resource ensures no such allocation will occur.</li>
</ul>
<p>As we have seen and<a id="_idIndexMarker883"/> done, it is simple to add to this small set of memory resources and customize the behavior of your containers to suit your needs with the PMR model.</p>
<h1 id="_idParaDest-206"><a id="_idTextAnchor212"/>Summary</h1>
<p>This has been an eventful chapter, has it not? After venturing into explicit and implicit memory allocation implementations in <a href="B21071_12.xhtml#_idTextAnchor172"><em class="italic">Chapter 12</em></a> and <a href="B21071_13.xhtml#_idTextAnchor187"><em class="italic">Chapter 13</em></a>, this chapter explored allocators and how these facilities let us customize the behavior of memory allocation in containers to match our needs.</p>
<p>We saw how a traditional allocator, ensconced in the type of its enclosing container, can be implemented and used. We did so with a container that trades in contiguous memory as well as with a node-based container. We also looked at how the task of writing (and using) such allocators evolved through the years to become the contemporary traits-based allocators that implicitly synthesize default implementations for most allocator services.</p>
<p>We then looked at the more recent PMR allocator model that represents a different take on memory allocation and discussed its upsides and downsides. Equipped with the knowledge in this chapter, you should have ideas of ways in which containers can be customized to meet your needs.</p>
<p>We are nearing the end of our journey. In our next (and last) chapter, we will look at some contemporary problems of memory allocation in C++ and start to think about what awaits us in the near future.</p>
</div>
</body></html>