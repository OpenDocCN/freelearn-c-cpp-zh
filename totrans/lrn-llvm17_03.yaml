- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Structure of a Compiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compiler technology is a well-studied field of computer science. The high-level
    task is to translate a source language into machine code. Typically, this task
    is divided into three parts, the **frontend**, the **middle end**, and the **backend**.
    The frontend deals mainly with the source language, while the middle end performs
    transformation to improve the code and the backend is responsible for the generation
    of machine code. Since the LLVM core libraries provide the middle end and the
    backend, we will focus on the frontend within this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will cover the following sections and topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Building blocks of a compiler*, in which you will learn about the components
    typically found in a compiler'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*An arithmetic expression language*, which will introduce you to an example
    language and show how grammar is used to define a language'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lexical analysis*, which discusses how to implement a lexer for the language'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Syntactical analysis*, which covers the construction of a parser from the
    grammar'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Semantic analysis*, in which you will learn how a semantic check can be implemented'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Code generation with the LLVM backend*, which discusses how to interface with
    the LLVM backend and glue all the preceding phases together to create a complete
    compiler'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building blocks of a compiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since computers became available, thousands of programming languages have been
    developed. It turns out that all compilers must solve the same tasks and that
    the implementation of a compiler is best structured according to these tasks.
    At a high level, there are three components. The frontend turns the source code
    into an **intermediate representation** (**IR**). Then the middle end performs
    transformations on the IR, with the goal of either improving performance or reducing
    the size of the code. Finally, the backend produces machine code from the IR.
    The LLVM core libraries provide a middle end consisting of very sophisticated
    transformations and backends for all popular platforms. Furthermore, the LLVM
    core libraries also defines an intermediate representation used as input for the
    middle end and the backend. This design has the advantage that you only need to
    care about the frontend for the programming language you want to implement.
  prefs: []
  type: TYPE_NORMAL
- en: The input for the frontend is the source code, usually a text file. To make
    sense of it, the frontend first identifies the words of the language, such as
    numbers and identifiers, which are usually called tokens. This step is performed
    by the **lexer**. Next, the syntactical structure formed by the tokens is analyzed.
    The so-called **parser** performs this step, and the result is the **abstract
    syntax tree** (**AST**). Last, the frontend needs to check that the rules of the
    programming language are obeyed, which is done by the **semantic analyzer**. If
    no errors were detected, then the AST is transformed into IR and handed over to
    the middle end.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will construct a compiler for an expression language,
    which produces LLVM IR from its input. The LLVM `llc` static compiler, representing
    the backend, can then be used to compile the IR into object code. It all begins
    with defining the language. Keep in mind that all of the C++ implementation of
    the files within this chapter will be contained within a directory called `src/`.
  prefs: []
  type: TYPE_NORMAL
- en: An arithmetic expression language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Arithmetic expressions are a part of every programming language. Here is an
    example of an arithmetic expression calculation language called **calc**. The
    calc expressions are compiled into an application that evaluates the following
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The used variables in the expression must be declared with the keyword, `with`.
    This program is compiled into an application that asks the user for the values
    of the `a` and `b` variables and prints the result.
  prefs: []
  type: TYPE_NORMAL
- en: Examples are always welcome but, as a compiler writer, you need a more thorough
    specification than this for implementation and testing. The vehicle for the syntax
    of the programming language is the grammar.
  prefs: []
  type: TYPE_NORMAL
- en: Formalism for specifying the syntax of a programming language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The elements of a language, for example, keywords, identifiers, strings, numbers,
    and operators, are called **tokens**. In this sense, a program is a sequence of
    tokens, and the grammar specifies which sequences are valid.
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, grammar is written in the **extended Backus-Naur form** (**EBNF**).
    A rule in grammar has a left and a right side. The left side is just a single
    symbol called **non-terminal**. The right side of a rule consists of non-terminals,
    tokens, and meta-symbols for alternatives and repetitions. Let’s have a look at
    the grammar of the calc language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the first line, `calc` is a non-terminal. If not otherwise stated, then the
    first non-terminal of a grammar is the start symbol. The colon (`:`) is the separator
    between the left and the right side of the rule. Here, `"with"`, `","` and `":"`
    are tokens that represent this string. Parentheses are used for grouping. A group
    can be optional or repeated. A question mark (`?`) after the closing parenthesis
    denotes an optional group. A star `*` denotes zero or more repetitions and a plus
    `+` denotes one or more repetitions. `Ident` and `expr` are non-terminals. For
    each of them, another rule exists. The semicolon (`;`) marks the end of a rule.
    The pipe `|`, in the second line, denotes an alternative. And last, the brackets
    `[ ]`, in the last two lines, denote a character class. The valid characters are
    written inside the brackets. For example, the character class `[a-zA-Z]` matches
    an upper- or lower-case letter, and `([a-zA-Z])+` matches one or more of these
    letters. This corresponds to a regular expression.
  prefs: []
  type: TYPE_NORMAL
- en: How does grammar help the compiler writer?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Such grammar may look like a theoretical toy, but it is of value to the compiler
    writer. First, all the tokens are defined, which is needed to create the lexical
    analyzer. The rules of the grammar can be translated into the parser. And of course,
    if questions arise about whether the parser works correctly, then the grammar
    serves as a good specification.
  prefs: []
  type: TYPE_NORMAL
- en: However, grammar does not define all aspects of a programming language. The
    meaning – the semantics – of the syntax must also be defined. Formalisms for this
    purpose were developed, too, but very often, they are specified in plain text,
    as they were usually drawn up at the initial introduction of the language.
  prefs: []
  type: TYPE_NORMAL
- en: Equipped with this knowledge, the next two sections show how the lexical analysis
    turns the input into a sequence of tokens and how the grammar is coded in C++
    for the syntactical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Lexical analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already seen in the example in the previous section, a programming language
    consists of many elements such as keywords, identifiers, numbers, operators, and
    so on. The task of the lexical analyzer is to take the textual input and create
    a sequence of tokens from it. The calc language consists of the tokens `with`,
    `:`, `+`, `-`, `*`, `/`, `(`, `)`, and regular expressions `([a-zA-Z])+` (an identifier)
    and `([0-9])+` (a number). We assign a unique number to each token to make the
    handling of tokens easier.
  prefs: []
  type: TYPE_NORMAL
- en: A hand-written lexer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The implementation of a lexical analyzer is often called `Lexer`. Let’s create
    a header file called `Lexer.h` and get started with the definition of `Token`.
    It begins with the usual header guard and the inclusion of the required headers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `llvm::MemoryBuffer` class provides read-only access to a block of memory,
    filled with the content of a file. On request, a trailing zero character (`'\x00'`)
    is added to the end of the buffer. We use this feature to read through the buffer
    without checking the length of the buffer at each access. The `llvm::StringRef`
    class encapsulates a pointer to a C string and its length. Because the length
    is stored, the string need not be terminated with a zero character (`'\x00'`)
    like normal C strings. This allows an instance of `StringRef` to point to the
    memory managed by `MemoryBuffer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, we begin by implementing the `Lexer` class:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the `Token` class contains the definition of the enumeration for the
    unique token numbers mentioned previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Besides defining a member for each token, we added two additional values: `eoi`
    and `unknown`. `eoi` stands for *end of input* and is returned when all characters
    of the input are processed. `unknown` is used in the event of an error at the
    lexical level, e.g., `#` is no token of the language and would therefore be mapped
    to `unknown`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In addition to the enumeration, the class has a `Text` member, which points
    to the start of the text of the token. It uses the `StringRef` class mentioned
    previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is useful for semantic processing, e.g., for an identifier, it is useful
    to know the name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `is()` and `isOneOf()` methods are used to test whether the token is of
    a certain kind. The `isOneOf()` method uses a variadic template, allowing a variable
    number of arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `Lexer` class itself has a similar simple interface and comes next in the
    header file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Except for the constructor, the public interface has only the `next()` method,
    which returns the next token. The method acts like an iterator, always advancing
    to the next available token. The only members of the class are pointers to the
    beginning of the input and the next unprocessed character. It is assumed that
    the buffer ends with a terminating `0` (just like a C string).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s implement the `Lexer` class in the `Lexer.cpp` file. It begins with some
    helper functions to classify characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These functions are used to make conditions more readable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We are not using the functions provided by the `<cctype>` standard library header
    for two reasons. First, these functions change behavior based on the locale defined
    in the environment. For example, if the locale is a German-language area, then
    German umlauts can be classified as letters. This is usually not wanted in a compiler.
    Second, since the functions have `int` as a parameter type, a conversion from
    the `char` type is required. The result of this conversion depends on whether
    `char` is treated as a signed or unsigned type, causing portability problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the grammar in the previous section, we know all the tokens of the language.
    But the grammar does not define the characters that should be ignored. For example,
    a space or newline character adds only whitespace and are often ignored. The `next()`
    method begins with ignoring these characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, make sure that there are still characters left to process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There is at least one character to process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We first check whether the character is lowercase or uppercase. In this case,
    the token is either an identifier or the `with` keyword, because the regular expression
    for the identifier also matches the keyword. The most common solution here is
    to collect the characters matched by the regular expression and check whether
    the string happens to be the keyword:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `formToken()` private method is used to populate the token.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we check for a number. The code for this is very similar to the preceding
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now only the tokens defined by fixed strings are left.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This is done easily with a `switch`. As all of these tokens have only one character,
    the `CASE` preprocessor macro is used to reduce typing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Last, we need to check for unexpected characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Only the `formToken()` private helper method is still missing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'It populates the members of the `Token` instance and updates the pointer to
    the next unprocessed character:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next section, we have a look at how to construct a parser for syntactical
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Syntactical analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The syntactical analysis is done by the parser, which we will implement next.
    The base of this is the grammar and the lexer from the previous sections. The
    result of the parsing process is a dynamic data structure called an **abstract
    syntax tree** (**AST**). The AST is a very condensed representation of the input
    and is well-suited for semantic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will implement the parser, and after that, we will have a look at
    the parsing process within the AST.
  prefs: []
  type: TYPE_NORMAL
- en: A hand-written parser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The interface of the parser is defined in the header file, `Parser.h`. It begins
    with some `include` declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `AST.h` header file declares the interface for the AST and is shown later.
    The coding guidelines from LLVM forbid the use of the `<iostream>` library, therefore,
    the header of the equivalent LLVM functionality is included. It is needed to emit
    an error message:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Parser` class first declares some private members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`Lex` and `Tok` are instances of the classes from the previous section. `Tok`
    stores the next token (the look-ahead) and `Lex` is used to retrieve the next
    token from the input. The `HasError` flag indicates whether an error was detected.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A couple of methods deal with the token:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`advance()` retrieves the next token from the lexer. `expect()` tests whether
    the look-ahead has the expected kind and emits an error message if not. Finally,
    `consume()` retrieves the next token if the look-ahead has the expected kind.
    If an error message is emitted, the `HasError` flag is set to true.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For each non-terminal of the grammar, a method to parse the rule is declared:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: There are no methods for `ident` and `number`. Those rules only return the token
    and are replaced by the corresponding token.
  prefs: []
  type: TYPE_NORMAL
- en: 'The public interface follows. The constructor initializes all members and retrieves
    the first token from the lexer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A function is required to get the value of the error flag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And finally, the `parse()` method is the main entry point into parsing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Parser implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s dive into the implementation of the parser!
  prefs: []
  type: TYPE_NORMAL
- en: 'Our implementation in the `Parser.cpp` file and begins with the `parse()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The main point of the `parse()` method is that the whole input has been consumed.
    Do you remember that the parsing example in the first section added a special
    symbol to denote the end of the input? We check it here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `parseCalc()` method implements the corresponding rule. It’s worth having
    a closer look at this method as the other parsing methods follow the same patterns.
    Let’s recall the rule from the first section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The method begins with declaring some local variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first decision to be made is whether the optional group must be parsed
    or not. The group begins with the `with` token, so we compare the token to this
    value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we expect an identifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If there is an identifier, then we save it in the `Vars` vector. Otherwise,
    it is a syntax error, which is handled separately.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next in the grammar follows a repeating group, which parses more identifiers,
    separated with commas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By now, this should not be surprising. The repetition group begins with the
    token (`,`). The test for the token becomes the condition of the `while` loop,
    implementing zero or more repetition. The identifier inside the loop is treated
    as before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, the optional group requires a colon at the end:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Last, the rule for `expr` must be parsed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With this call, the parsing of the rule is finished successfully. The collected
    information is now used to create the AST node for this rule:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now only the error handling is missing. Detecting a syntax error is easy but
    recovering from it is surprisingly complicated. Here, a simple approach called
    **panic mode** is used.
  prefs: []
  type: TYPE_NORMAL
- en: In panic mode, tokens are deleted from the token stream until one is found that
    the parser can use to continue its work. Most programming languages have symbols
    that denote an end, e.g., in C++, a `;` (end of a statement) or a `}` (end of
    a block). Such tokens are good candidates to look for.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the error can be that the symbol we are looking for is missing.
    In this case, probably a lot of tokens are deleted before the parser can continue.
    This is not as bad as it sounds. Today, it is more important that a compiler is
    fast. In the event of an error, the developer looks at the first error message,
    fixes it, and restarts the compiler. This is quite different from using punch
    cards, where it was important to get as many error messages as possible, as the
    next run of the compiler would possibly be only on the next day.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Instead of using some arbitrary tokens to look for, another set of tokens is
    used here. For each non-terminal, there is a set of tokens that can follow this
    non-terminal in a rule:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of `calc`, only the end of input follows this non-terminal. The
    implementation is trivial:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The other parsing methods are similarly constructed. `parseExpr()` is the translation
    of the rule for `expr`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The repeated group inside the rule is translated as a `while` loop. Note how
    the use of the `isOneOf()` method simplifies the check for several tokens.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The coding of the `term` rule looks the same:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This method is strikingly similar to `parseExpr()`, and you may be tempted to
    combine them into one. In a grammar, it is possible to have one rule dealing with
    multiplicative and additive operators. The advantage of using two rules instead
    is that then the precedence of the operators fits well with the mathematical order
    of evaluation. If you combine both rules, then you need to figure out the evaluation
    order somewhere else.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Last, you need to implement the rule for `factor`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Instead of using a chain of `if` and `else if` statements, a `switch` statement
    seems more suitable here, because each alternative begins with just one token.
    In general, you should think about which translation patterns you like to use.
    If you later need to change the parsing methods, then it is an advantage if not
    every method has a different way of implementing a grammar rule.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you use a `switch` statement, then error handling happens in the `default`
    case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We guard emitting the error message here because of the fall-through.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If there was a syntax error in the parenthesis’s expression, then an error
    message was already emitted. The guard prevents a second error message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That was easy, wasn’t it? Once you have memorized the patterns used, it is almost
    tedious work to code the parser based on the grammar rules. This type of parser
    is called a **recursive** **descent parser**.
  prefs: []
  type: TYPE_NORMAL
- en: A recursive descent parser can’t be constructed from every grammar
  prefs: []
  type: TYPE_NORMAL
- en: 'A grammar must satisfy certain conditions to be suitable for the construction
    of a recursive descent parser. This class of grammar is called LL(1). In fact,
    most grammar that you can find on the internet does not belong to this class of
    grammar. Most books about the theory of compiler constructions explain the reason
    for this. The classic book on this topic is the so-called *dragon book*, *Compilers:
    Principles, Techniques, and Tools* by Aho, Lam, Sethi, and Ullman.'
  prefs: []
  type: TYPE_NORMAL
- en: The abstract syntax tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The result of the parsing process is the AST. The AST is another compact representation
    of the input program. It captures the essential information. Many programming
    languages have symbols that are needed as separators but do not carry further
    meaning. For example, in C++, a semicolon`;` denotes the end of a single statement.
    Of course, this information is important for the parser. As soon as we turn the
    statement into an in-memory representation, the semicolon is not important anymore
    and can be dropped.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at the first rule of the example expression language, then it is
    clear that the `with` keyword, the comma (`,`), and the colon (`:`) are not important
    for the meaning of a program. What is important is the list of declared variables,
    which could be used in the expression. The result is that only a couple of classes
    are required to record the information: `Factor` holds a number or an identifier,
    `BinaryOp` holds the arithmetic operator and the left and right sides of an expression,
    and `WithDecl` stores the list of declared variables and the expression. `AST`
    and `Expr` are only used to create a common class hierarchy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the information from the parsed input, tree traversal using
    the `AST.h` header file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'It begins with the visitor interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The visitor pattern needs to know each class to visit. Because each class also
    refers to the visitor, we declare all classes at the top of the file. Please note
    that the `visit()` methods for `AST` and `Expr` have a default implementation,
    which does nothing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `AST` class is the root of the hierarchy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, `Expr` is the root for `AST` classes related to expressions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `Factor` class stores a number or the name of a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, numbers and variables are treated almost identically, therefore,
    we decided to create only one AST node class to represent them. The `Kind` member
    tells us which of both cases the instances represent. In more complex languages,
    you usually want to have different AST classes, such as a `NumberLiteral` class
    for numbers and a `VariableAccess` class for a reference to a variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `BinaryOp` class holds the data needed for evaluating an expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In contrast to the parser, the `BinaryOp` class makes no distinction between
    multiplicative and additive operators. The precedence of the operators is implicitly
    available in the tree structure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'And last, the `WithDecl` class stores the declared variables and the expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The AST is constructed during parsing. The semantic analysis checks that the
    tree adheres to the meaning of the language (e.g., that used variables are declared)
    and possibly augments the tree. After that, the tree is used for code generation.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The semantic analyzer walks the AST and checks various semantic rules of the
    language, e.g. a variable must be declared before use or types of variables must
    be compatible in an expression. The semantic analyzer can also print out warnings
    if it finds a situation that can be improved. For the example expression language,
    the semantic analyzer must check that each used variable is declared because that
    is what the language requires. A possible extension (which is not implemented
    here) is to print a warning if a declared variable is not used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The semantic analyzer is implemented in the `Sema` class, which is performed
    by the `semantic()` method. Here is the complete `Sema.h` header file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation is in the `Sema.cpp` file. The interesting part is the semantic
    analysis, which is implemented using a visitor. The basic idea is that the name
    of each declared variable is stored in a set. During the creation of the set,
    each name can be checked for uniqueness, and later it can be checked that the
    given name is in the set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the `Parser` class, a flag is used to indicate that an error occurred.
    The names are stored in a set called `Scope`. On a `Factor` node that holds a
    variable name, it is checked that the variable name is in the set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For a `BinaryOp` node, there is nothing to check other than that both sides
    exist and are visited:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'On a `WithDecl` node, the set is populated and the walk over the expression
    is started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `semantic()` method only starts the tree walk and returns the error flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: If required, much more could be done here. It would also be possible to print
    a warning if a declared variable is not used. We leave this for you to implement
    as an exercise. If the semantic analysis finishes without error, then we can generate
    the LLVM IR from the AST. This is done in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Generating code with the LLVM backend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The task of the backend is to create optimized machine code from the LLVM IR
    of a module. The IR is the interface to the backend and can be created using a
    C++ interface or in textual form. Again, the IR is generated from the AST.
  prefs: []
  type: TYPE_NORMAL
- en: Textual representation of LLVM IR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before trying to generate the LLVM IR, it should be clear what we want to generate.
    For our example expression language, the high-level plan is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Ask the user for the value of each variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the value of the expression.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To ask the user to provide a value for a variable and to print the result,
    two library functions are used: `calc_read()` and `calc_write()`. For the `with
    a: 3*a` expression, the generated IR is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The library functions must be declared, like in C. The syntax also resembles
    C. The type before the function name is the return type. The type names surrounded
    by parenthesis are the argument types. The declaration can appear anywhere in
    the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `calc_read()` function takes the variable name as a parameter. The following
    construct defines a constant, holding `a` and the null byte used as a string terminator
    in C:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It follows the `main()` function. The parameter names are omitted because they
    are not used. Just as in C, the body of the function is enclosed in braces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Each basic block must have a label. Because this is the first basic block of
    the function, we name it `entry`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `calc_read()` function is called to read the value for the `a` variable.
    The nested `getelemenptr` instruction performs an index calculation to compute
    the pointer to the first element of the string constant. The function result is
    assigned to the unnamed `%``2` variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, the variable is multiplied by `3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is printed on the console via a call to the `calc_write()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Last, the `main()` function returns `0` to indicate a successful execution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Each value in the LLVM IR is typed, with `i32` denoting the 32-bit bit integer
    type and `ptr` denoting a pointer.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Previous versions of LLVM used typed pointers. For example, a pointer to a byte
    was expressed as i8* in LLVM. Since LLVM 16, `ptr`.
  prefs: []
  type: TYPE_NORMAL
- en: Since it is now clear what the IR looks like, let’s generate it from the AST.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the IR from the AST
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The interface, provided in the `CodeGen.h` header file, is very small:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the AST contains the information, the basic idea is to use a visitor
    to walk the AST. The `CodeGen.cpp` file is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The required includes are at the top of the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The namespace of the LLVM libraries is used for name lookups:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, some private members are declared in the visitor. Each compilation unit
    is represented in LLVM by the `Module` class and the visitor has a pointer to
    the module called `M`. For easy IR generation, the `Builder` (of type `IRBuilder<>)`
    is used. LLVM has a class hierarchy to represent types in IR. You can look up
    the instances for basic types such as `i32` from the LLVM context.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These basic types are used very often. To avoid repeated lookups, we cache
    the needed type instances: `VoidTy`, `Int32Ty`, `PtrTy`, and `Int32Zero`. The
    `V` member is the current calculated value, which is updated through the tree
    traversal. And last, `nameMap` maps a variable name to the value returned from
    the `calc_read()` function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The constructor initializes all members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each function, a `FunctionType` instance must be created. In C++ terminology,
    this is a function prototype. A function itself is defined with a `Function` instance.
    The `run()` method defines the `main()` function in the LLVM IR first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we create the `BB` basic block with the `entry` label, and attach it to
    the IR builder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With this preparation done, the tree traversal can begin:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After the tree traversal, the computed value is printed via a call to the `calc_write()`
    function. Again, a function prototype (an instance of `FunctionType`) has to be
    created. The only parameter is the current value, `V`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The generation finishes by returning `0` from the `main()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A `WithDecl` node holds the names of the declared variables. First, we create
    a function prototype for the `calc_read()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The method loops through the variable names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each variable, a string with a variable name is created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then the IR code to call the `calc_read()` function is created. The string
    created in the previous step is passed as a parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The returned value is stored in the `mapNames` map for later use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The tree traversal continues with the expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A `Factor` node is either a variable name or a number. For a variable name,
    the value is looked up in the `mapNames` map. For a number, the value is converted
    to an integer and turned into a constant value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And last, for a `BinaryOp` node, the right calculation operation must be used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With this, the visitor class is complete. The `compile()` method creates the
    global context and the module, runs the tree traversal, and dumps the generated
    IR to the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We now have implemented the frontend of the compiler, from reading the source
    up to generating the IR. Of course, all these components must work together on
    user input, which is the task of the compiler driver. We also need to implement
    the functions needed at runtime. Both are topics of the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The missing pieces – the driver and the runtime library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the phases from the previous sections are glued together by the `Calc.cpp`
    driver, which we implement as follows: a parameter for the input expression is
    declared, LLVM is initialized, and all the phases from the previous sections are
    called:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we include the required header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'LLVM comes with its own system for declaring command-line options. You only
    need to declare a static variable for each option you need. In doing so, the option
    is registered with a global command line parser. The advantage of this approach
    is that each component can add command-line options when needed. We declare an
    option for the input expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `main()` function, the LLVM libraries are initialized first. You
    need to call the `ParseCommandLineOptions()` function to handle the options given
    on the command line. This also handles the printing of help information. In the
    event of an error, this method exits the application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we call the lexer and the parser. After the syntactical analysis, we
    check whether any errors occurred. If this is the case, then we exit the compiler
    with a return code indicating a failure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And we do the same if there was a semantic error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the last step in the driver, the code generator is called:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we have successfully created some IR code for the user input. We delegate
    the object code generation to the LLVM `llc` static compiler, so this finishes
    the implementation of our compiler. We link all the components together to create
    the `calc` application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The runtime library consists of a single file, `rtcalc.c`. It has the implementation
    for the `calc_read()` and `calc_write()` functions, written in C:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '`calc_write()` only writes the result value to the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '`calc_read()` reads an integer number from the terminal. Nothing prevents the
    user from entering letters or other characters, so we must carefully check the
    input. If the input is not a number, we exit the application. A more complex approach
    would be to make the user aware of the problem and ask for a number again.'
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to build and try out our compiler, `calc`, which is an application
    that creates IR from an expression.
  prefs: []
  type: TYPE_NORMAL
- en: Building and testing the calc application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to build `calc`, we first need to create a new `CMakeLists.txt` file
    outside of the original `src` directory that contains all of the source file implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we set the minimum required CMake version to the number required by
    LLVM, and give the project the name `calc`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, the LLVM package needs to be loaded, and we add the directory of the
    CMake modules provided by LLVM to the search path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also need to add the definitions and the include path from LLVM. The used
    LLVM components are mapped to the library names with a function call:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, we indicate that we need to include the `src` subdirectory in our build,
    as this is where all of the C++ implementation that was done within this chapter
    resides:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There also needs to be a new `CMakeLists.txt` file inside of the `src` subdirectory.
    This CMake description inside the `src` directory appears as follows. We simply
    define the name of the executable, called `calc`, then list the source files to
    compile and the library to link against:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can begin building the `calc` application. Outside of the `src`
    directory, we create a new build directory and change into it. Afterwards, we
    can run the CMake and build invocation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: We now should have a newly built, functional `calc` application that can generate
    LLVM IR code. This can further be used with `llc`, which is the LLVM static backend
    compiler, to compile the IR code into an object file.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then use your favorite C compiler to link against the small runtime
    library. On Unix on X86, you can type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: On other Unix platforms such as AArch64 or PowerPC, you have to remove the `-``relocation-model=pic`
    option.
  prefs: []
  type: TYPE_NORMAL
- en: 'On Windows, you need to use the `cl` compiler as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: You have now created your first LLVM-based compiler! Please take some time to
    play around with various expressions. Especially check that multiplicative operators
    are evaluated before additive operators and that using parentheses changes the
    evaluation order, as we would expect from a basic calculator.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned about the typical components of a compiler. An
    arithmetic expression language was used to introduce you to the grammar of programming
    languages. You learned how to develop the typical components of a frontend for
    this language: a lexer, a parser, a semantic analyzer, and a code generator. The
    code generator only produced LLVM IR, and the LLVM `llc` static compiler was used
    to create object files from it. You have now developed your first LLVM-based compiler!'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will deepen this knowledge, constructing the frontend
    for a programming language.
  prefs: []
  type: TYPE_NORMAL
