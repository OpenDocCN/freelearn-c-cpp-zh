<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-135"><a id="_idTextAnchor148"/>10</h1>
<h1 id="_idParaDest-136"><a id="_idTextAnchor149"/>Optimization through Patterns</h1>
<p>In this last chapter, we are going to discuss the last thing we should think about before releasing our games: optimization. Optimization patterns are <a id="_idIndexMarker427"/>designed to leave our code functioning as it was before but in a faster, more elegant way that impacts our hardware less. This chapter is quite wordy, but the underlying principles that guide these patterns require a certain understanding of how the hardware resources at our disposal work. By the end, we will have covered everything from how to help the CPU do its job better to making a system you can plug into any game to make it potentially faster at runtime.</p>
<p>The patterns making this possible are the following:</p>
<ul>
<li><strong class="bold">Dirty Flag</strong>, which focuses on reducing the number of times we need to update calculated values.</li>
<li><strong class="bold">Data Locality</strong>, which concerns optimizing the code layout to work with the way the CPU’s memory works. As a description, this sounds much more complicated than the reality of the application.</li>
<li><strong class="bold">Object Pooling</strong>, where we offset as much of the heavy memory allocation processing to the start of the game, where it can be excused under a loading screen, so as not to impact runtime efficiency.</li>
</ul>
<p>So, in this chapter, we will cover the following topics:</p>
<ul>
<li>Using dirty flags to reduce unnecessary processing</li>
<li>How data locality affects code efficiency</li>
<li>Object pooling our resources to save time later</li>
</ul>
<h1 id="_idParaDest-137"><a id="_idTextAnchor150"/>Technical requirements</h1>
<p>The starting point for this chapter can really be from any project, but we have a branch of the GitHub repository that carries on from where <a href="B18297_09.xhtml#_idTextAnchor130"><em class="italic">Chapter 9</em></a> left off. This provides a set of systems we can integrate with the Object Pooler we will be building. You can find this starting point in the <a href="B18297_10.xhtml#_idTextAnchor148"><em class="italic">Chapter 10</em></a> branch here:</p>
<p><a href="https://github.com/PacktPublishing/Game-Development-Patterns-with-Unreal-Engine-5/tree/main/Chapter10">https://github.com/PacktPublishing/Game-Development-Patterns-with-Unreal-Engine-5/tree/main/Chapter10</a></p>
<h1 id="_idParaDest-138"><a id="_idTextAnchor151"/>Using dirty flags to reduce unnecessary processing</h1>
<p>Dirty flag <a id="_idIndexMarker428"/>involves updating values only when they are needed. The best explanation of how it works comes in the context of base-level engine development and the transform hierarchy. When you set a local location on a transform, you are indicating that you want to be <em class="italic">x</em>, <em class="italic">y</em>, and <em class="italic">z</em> units away from the parent’s location. This is easy enough to update, but in doing this, we are also changing the transform’s world space location. It is easy to calculate the matrix that will deal with this local-to-world space conversion, then multiply our vector by it; that process doesn’t even cost many resources. Then, we must remember that this is a hierarchy. What if we were moving the root of a tree that is hundreds of transforms deep? Not a great position to be in for multiple reasons, but if the parent of a transform moves, then the child moves with it, and so on, recursively. This presents a lot of world space value transforms that need to be updated every time any parent in the tree is changed.</p>
<p>To make the utility of dirty flag easier to quantify, we can consider a hypothetical situation where we have a hierarchy of transforms that is 100 parent-child connections deep. We want to move each of them like they are a chain with a torque ripple. Starting at the top of the hierarchy and moving down, at every step, we update the position of the transform at that level to a new local location defined by some periodic function. With each local update, we also update the local-to-world matrix for every transform lower in the hierarchy as they will have moved in world space, as shown in <em class="italic">Figure 10</em><em class="italic">.1</em>. This would require (101-n) matrix updates at each step, which means to move the entire hierarchy of 100 transforms, we will end up with the 100th triangular number, which is 5,050. I think we can safely say that’s ridiculous and there has to be a better way. Consider the utility of the work done. Why are we updating these transforms? So that something else can read its world space location and get an accurate, up-to-date value. Have we read the world space location at any point in this algorithm? No. The function for setting the local location doesn’t need the world space location. So, do we need to update the local to world matrices of these objects? Not until something else needs us to or the end of the frame is reached. For the best case, that means we could get away with only 100 matrix updates <a id="_idIndexMarker429"/>at the very end. That is the purpose of the dirty flag pattern.</p>
<div><div><img alt="Figure 10.1 – Diagram showing a local location change affecting the world space location of its child" src="img/Figure_10.01_B18297.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Diagram showing a local location change affecting the world space location of its child</p>
<p>Now, let’s look at the application of dirty flags.</p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor152"/>Application of dirty flags</h2>
<p>In practice, this whole pattern is <a id="_idIndexMarker430"/>just a Boolean value; when the object is considered <em class="italic">dirty</em>, the Boolean is one value, and when it is <em class="italic">clean</em>, it is the other. Which way around that is doesn’t matter, as long as it’s consistent with the naming. An object is dirty if it has pending changes that still need to be made to the values it represents. In our example, we postpone the local-to-world matrix update until something requests the matrix or the end of the frame is reached. During the time between the change to the local location and the matrix update, the transform is considered dirty.</p>
<p>The mechanics of how this is dealt with then extend beyond the Boolean value. On raising a dirty flag, that object is added to a relevant static dirty list of objects. For our transform, that means it, and all the transforms below it in the hierarchy, will be added recursively to a static list of other dirty transforms. We then have some cleaning function that describes how to go from a dirty state to a clean state. With the transform, that would be a function that calculates the updated local-to-world matrix.</p>
<p>That example is only something you’d have to be worried about if you were designing your own engine, but the dirty flag pattern can be applied to great effect anywhere you have a value that may be updated several times before it is needed. You can find this pattern<a id="_idIndexMarker431"/> in <code>destroy</code> command, which marks actors for destruction at the end of the frame due to the trickle-down effects of removing them. There will be cases where you are storing data that needs to be displayed to the UI and the <a id="_idIndexMarker432"/>dirty flag pattern can reduce the number of times you tell the UI to update per frame; it should only happen once at most per frame.</p>
<p>Next, we’ll go deeper, from a one-variable pattern to a guiding principle of optimization that we can apply anywhere.</p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor153"/>How data locality affects code efficiency</h1>
<p>This is a simple <a id="_idIndexMarker433"/>concept that requires very little to implement. We all actively think about how variables take up memory. We tend to forget that instructions also take up memory. They must be loaded from storage into faster memory, then into the CPU to be executed. CPUs try to make things run quicker by leveraging the fact that they have very fast, very small storage within them called the cache. The cache allows the CPU to pre-load instructions ready for execution and store its state in case of temporary context switching. This pre-loading behavior is necessary for the CPU to run at its most efficient as while there has been a technology race in CPU speeds, that hasn’t been mirrored in the world of RAM. You might be able to store massive programs entirely in your RAM but the bus speed of the motherboard limits how many instructions can be sent to the CPU per second. When we reach the bottleneck, it doesn’t matter how fast the CPU cores are at calculating results, as they would spend most of their time idle, waiting for instruction. Pre-loading provides a mechanism that has the potential to fix this by sending large chunks of instructions to the CPU cache for processing. We say <em class="italic">potential to fix</em> as when pulling instructions from RAM, there is no way of knowing which instructions will be next. That information is in the instruction daisy chain and can only be accessed once the work is done. This means that the contents of the CPU cache are entirely dictated by the geography of our system architecture.</p>
<p>That’s lots of technical terms, so let’s explain it with an analogy. Imagine working in a factory where your job is to build flatpack furniture. You’re really fast at your job when you have the materials and can put together each piece lighting fast. The catch is, you can only see one instruction at a time, and when you need pieces, you must request them from a porter. These resources, such as panels and screws, are stored in a warehouse miles away. When you request something, the porter spends a day traveling to and from the warehouse, which means you can only get one instruction completed per day regardless of how fast you work. Most of your time is spent staring at the wall. In this example, you are the CPU, executing instructions, and the porter is the data bus, ferrying instructions from RAM to be executed.</p>
<p>One day, a new manager is brought in who decides to revamp the process. They change the material request process so that now, when the porter gets the required item, they also get everything else within arm’s reach. This bundle of screws and panels is then dumped on the ground in your workstation. In real terms, we call this the CPU cache, a tiny amount of extremely fast memory within the CPU. The benefit of this is that when you get your next instruction, there is a chance you already have the required materials next to you. If not, then all the materials need to be taken back and a new bunch collected. It then stands to reason that if the warehouse is organized so that materials that are often requested together are placed near each other, the porter is more likely to take the correct materials for the next instruction as well. Nothing needs to change about the porter’s knowledge of the situation or skills, simply proper planning at the start to achieve an efficient outcome.</p>
<p>As programmers, we<a id="_idIndexMarker434"/> can be the warehouse manager in that example, making sure that the data a function requires is physically close to that function so that when the CPU request for resources comes in, the cache is more likely to fill with useful data. When the CPU can execute from the cache, that is called a cache hit. Likewise, when the data needs to be requested, that is a cache miss. We want to achieve as many cache hits as possible to reduce the number of times the cache needs to be refilled. The gains from achieving high levels of cache hits are surprising; sometimes, they can be up to 50 times faster due to organizing data effectively.</p>
<p>We’re going to have a look at two methods for implementing data locality as a principle but there are doubtless others that, now that you understand the problem, will make more sense as implementations. Let’s look at the two methods.</p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor154"/>Hot/cold splitting</h2>
<p>The first technique is <a id="_idIndexMarker435"/>very similar to how the type object pattern from <a href="B18297_09.xhtml#_idTextAnchor130"><em class="italic">Chapter 9</em></a> needed to consider implicit and explicit data, but instead of thinking about what the values are defining, we look at how frequently they are accessed. The go-to example of this would be an NPC in a game with loot drops. The NPC’s health is accessed regularly as they heal and take damage over their life cycle, whereas the loot table, which describes what items they drop on, is accessed once at the end of the object’s life. We can classify the frequently accessed data as hot; this can stay in the object as member variables. The more single-use data, such as loot tables, is then marked as cold and separated off into a struct, held inside the object as a pointer.</p>
<p>Why do all this? It has to do with the size of the object when being pulled into the cache. When the object is pulled in, all data it directly contains makes up the amount of space it takes up in the cache. That means that all pointers effectively only take up the space of <code>uint64_t</code>. The data they point to is not necessarily loaded until it is directly accessed, as it is declared physically elsewhere, hence the pointer. Without separating our hot and cold data, as we described previously, our class takes up more cache memory than is necessary with data that is unlikely to be needed, increasing the chance of a cache miss.</p>
<h2 id="_idParaDest-142"><a id="_idTextAnchor155"/>Contiguous arrays</h2>
<p>The second technique is using contiguous arrays<a id="_idIndexMarker436"/> of data. We know that there are two types of memory: stack and heap. Data locality is the main reason why stack memory is considered faster. Everything in the stack has been defined before the program runs and so it is neatly organized. Arrays of data are held in the stack and are defined together in one continuous line. This makes the CPU cache more efficient when looping over these elements as they have been stored physically closer to one another. This is part of the reason why data-oriented ECS is faster, as discussed back in <a href="B18297_04.xhtml#_idTextAnchor057"><em class="italic">Chapter 4</em></a>. However, dynamic collections and pointers are declared in heap memory at runtime. We sacrifice that benefit of efficiency for the flexibility of defining data at a later point. Data on the heap uses whatever free space is available and because of this may end up defining multiple objects large distances from each other. <em class="italic">Figure 10</em><em class="italic">.2</em> shows visually how storing an array of values instead of an array of pointers can make a difference to what is loaded into the cache. This is a concept to keep in mind when we implement an object pool later in this chapter. When we spawn objects, they are held as <code>TObjectPtrs</code> in a <code>TArray</code>. Could this array be made into a standard C++ array? What dynamic property would we have to sacrifice to do this? It would likely be dynamic sizing, but do you need that in your context?</p>
<div><div><img alt="Figure 10.2 – Possible layout of an array of pointers versus an array of values in memory" src="img/Figure_10.02_B18297.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Possible layout of an array of pointers versus an array of values in memory</p>
<p>So, is the solution to just use <a id="_idIndexMarker437"/>arrays of data all the time? Well, no. There are many situations where pointers and dynamic collections are still necessary within object-oriented programming. This is more a point to consider their usage, and if you can replace a dynamic collection with a static array, then do so. This point is especially important to remember in our last pattern of the book coming up next: Object Pooling.</p>
<h1 id="_idParaDest-143"><a id="_idTextAnchor156"/>Object pooling our resources to save time later</h1>
<p>The last pattern we <a id="_idIndexMarker438"/>are discussing in this book is object pooling. This pattern <a id="_idIndexMarker439"/>aims to tackle one of the core problems with the CPU: allocating and deallocating memory is a slow process. Every time you spawn a new actor, the space it needs in memory must be reserved in the right subdivisions for each variable and handed back to the game process ready to receive data. Every time you delete an actor, that memory must be freed from all references and returned to the heap. For something such as a minigun spawning 3,000 projectiles per minute, that means a lot of allocation of the chunks for memory, which are all the same size. Object pooling is the practice of predicting this massive cost and offsetting it to a place where the lag it causes is not so noticeable. This for us means spawning all the projectiles we could possibly need at the start of the game and hiding them. When one is required, it is taken from the shelf of deactivated projectiles, teleported to the right position, and activated. Then, to preserve the pool’s integrity, when it would have been destroyed, it is simply deactivated and returned to the shelf with the other pooled items. Although this pattern does make the one frame when the level has just loaded much worse, as we are spawning all the projectiles at once, we can disguise this under a loading screen. This offset can dramatically increase the processing speed during hectic gameplay sequences<a id="_idIndexMarker440"/> when there would have been a lot of spawning and destroying <a id="_idIndexMarker441"/>occurring. Our pool then stays active until the end of the level when all objects are destroyed together, again under a loading screen.</p>
<p>With the theory covered, let’s make some object pools.</p>
<h2 id="_idParaDest-144"><a id="_idTextAnchor157"/>Implementing object pooling</h2>
<p>There are a few ways we could look<a id="_idIndexMarker442"/> at implementing this and, realistically, if it works to spawn the objects you need in a place where you can access them, then it is the best method for you. The implementation options are as a world subsystem, level actor component, game mode component, or floating actor in the level.</p>
<h3>World subsystem</h3>
<p>Subsystems <a id="_idIndexMarker443"/>are Unreal’s effort at <a id="_idIndexMarker444"/>implementing a standardized form of the singleton pattern we covered in <a href="B18297_08.xhtml#_idTextAnchor113"><em class="italic">Chapter 8</em></a> with limited scope. This form it takes means that we can make an almost static class that we know will exist for the lifetime of whatever it is attached to. Subsystems are, however, not well protected with regard to access as anything with reference to their attached object can call functions on them. This is why they tend to be used for hidden logic behavior systems that run regardless of interaction. This results in most of the public functions on them being getters to get the state of something they are processing. There are five levels of subsystem that exist. Let’s describe them in order of decreasing lifetime:</p>
<ul>
<li><strong class="bold">Engine</strong>: Exists <a id="_idIndexMarker445"/>in both the editor and the game for the length of the executable running.</li>
<li><strong class="bold">Editor</strong>: Runs as an <a id="_idIndexMarker446"/>editor tool and will not build with the game.</li>
<li><code>UGameInstance</code> and so exists for the play session while the executable is running. Only one instance can exist at a time.</li>
<li><code>ULocalPlayer</code> it is attached to and moves between levels in the same way. There is one instance per local player.</li>
<li><code>UWorld</code> it is attached to. There is one instance per <code>UWorld</code> that is currently loaded.</li>
</ul>
<p>It is important to consider the scope of the system being created and match it to the parent that best describes its lifetime. For an object pooler, this would be a world subsystem as any objects spawned in a pool will exist within a world so when that world is unloaded, they will be too. If the system was made as a local player subsystem, this would break references when changing maps and possibly spawn items in menu worlds where they are unnecessary.</p>
<h3>LevelScriptActor child</h3>
<p>The<code> ALevelScriptActor</code> is what<a id="_idIndexMarker450"/> people know on the blueprint side as the level blueprint. It provides a place for level-specific code to execute. This can be useful for tutorials where the mechanics are built badly in order to introduce them slowly, or for map-based mechanics, such as the “Levolutions” in Battlefield 4, where each map has the ability to completely change if different conditions are met. What isn’t advertised very well in the Unreal documentation is that we can change the level blueprint in the C++ layer. Simply create a new C++ child of <code>ALevelScriptActor</code> and add your code here. This new child can be where we set up systems for object pooling as the <code>ALevelScriptActor</code> exists in a hidden state for as long as our world exists and has easy access to anything else within the world outliner for that particular map. The downside of this is that every new map created in the editor comes with a level blueprint that already inherits from the base <code>ALevelScriptActor</code> class. This means every new map would have to have its level blueprint manually reparented to your custom C++ type, which could lead to a lot of admin with easily missable steps.</p>
<h3>Game mode component</h3>
<p>The game mode<a id="_idIndexMarker451"/> is a class that is guaranteed to be in every level, so there is the option to make the object pooler an actor component that is attached to it, or consolidate the behavior into the game mode inheritance hierarchy with a custom pooling game mode, which innately has the logic for running an object pool built in. This approach would require some diligence on the part of the designers as making a new level or prototyping a new game mode would require the component to be added or the correct parent to be selected; but it would make the implementation easy seeing as it is collected in one place and self-contained within an easily accessible system.</p>
<h3>Floating actor</h3>
<p>The last method of getting an object <a id="_idIndexMarker452"/>pooler to work is the simplest but least elegant solution: making it into an actor that you spawn into the level. The benefit of this is you can easily have multiple object pools for different things or segregate your object pools by area if you are dealing using world partition, the system we discussed back in <a href="B18297_03.xhtml#_idTextAnchor046"><em class="italic">Chapter 3</em></a>. The setup is also simple as all the GUI for setting it up is collected into the details panel for that object pool. The reason we call this method inelegant is down to how it must be managed. With there being no central method for referencing it or making sure the required functions have been called, it leaves a lot up to the end user and therefore is error prone.</p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor158"/>Making an object pool</h2>
<p>Before we start, the object<a id="_idIndexMarker453"/> pooling pattern is probably the most useful pattern to have in a plugin that we can take between projects. So, anything we make here should probably be done as part of a new plugin, which we can make within rider using the right-click menu on the game project. Simply select <code>ObjectPooler</code>. Then, just be sure to add new classes for the object pooler under the new folder this creates in the <strong class="bold">Source</strong> directory.</p>
<div><div><img alt="Figure 10.3 – Screenshot of the plugin creation process within Rider" src="img/Figure_10.03_B18297.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Screenshot of the plugin creation process within Rider</p>
<p>Our first step is to make<a id="_idIndexMarker454"/> the struct that will define the attributes of a single type of pool. The code for this is presented next, but let’s explain some of the key points. First, the <code>BlueprintType</code> property in the <code>USTRUCT</code> block, in combination with the <code>EditAnywhere</code> property specifiers, will allow the end user to change the pool behavior in the editor. There is also the constructor, which must give every property a value as a struct cannot be a <code>nullptr</code> in memory. Saving the <code>_ActorName</code> variable as an <code>FString</code> is done to make debugging easier, but if you prefer to save it as an <code>FName</code>, that works and will save some processing when the pool is warming up:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">PooledObjectData.h struct</p>
<pre class="source-code">
USTRUCT(BlueprintType)
struct FPooledObjectData
{
    GENERATED_BODY()
    UPROPERTY(EditAnywhere)
    TSubclassOf&lt;AActor&gt; _ActorTemplate;
    UPROPERTY(EditAnywhere)
    int _PoolSize;
    UPROPERTY(EditAnywhere)
    bool _CanGrow;
    UPROPERTY(EditAnywhere)
    FString _ActorName;
    FPooledObjectData()
    {
        _ActorTemplate = nullptr;
        _PoolSize = 1;
        _CanGrow = false;
        _ActorName = "default";
    }
};</pre> <p>Next, we’ll turn our attention<a id="_idIndexMarker455"/> to the component that will be on every object that came from the pool. We use an actor component instead of making a new child of <code>AActor</code> that must then be inherited from as it provides a clean separation between the object existing and doing what it needs to and the hook that attaches it back to the pool it came from. With this setup, we can dynamically spawn the component at runtime and attach it to the object when it joins the pool, keeping reference only to the component. This should make the pool totally class agnostic, improving its versatility.</p>
<p>Elements to note in the following class definition would be the custom initializer function allowing us to set the component up properly (more on that when we get to the object pool side) and the <code>BlueprintCallable</code> function used to recycle the actor. The recycle function is to be used instead of the standard <code>Destroy</code> on the actor as it will return its owning actor to the pool it came from. A useful extension you might want to add here would be to save the index of the pool it is supposed to return to. This will save some string comparisons later:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">PooledObject.h</p>
<pre class="source-code">
class AObjectPool;
UCLASS(ClassGroup=(Utility), meta=(BlueprintSpawnableComponent))
class RTS_AI_API UPooledObject : public UActorComponent
{
    GENERATED_BODY()
public:
    UPROPERTY(VisibleInstanceOnly, BlueprintReadOnly)
    bool _IsActive;
    void Init(AObjectPool* owner);
    UFUNCTION(BlueprintCallable)
    void RecycleSelf();
private:
    TObjectPtr&lt;AObjectPool&gt; _ObjectPool;
    virtual void OnComponentDestroyed(bool bDestroyingHierarchy)
    override;
};</pre> <p>The implementation of these<a id="_idIndexMarker456"/> functions is then very simple as most of the logic will be run in the pool itself. The only interesting point of note here is the <code>OnComponentDestroyed</code> override. This function removes the <code>RecycleSelf</code> function as a listener to a delegate on the pooler as a safety in case the pooler functionality is ignored, and the object is deleted in error:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">PooledObject.cpp</p>
<pre class="source-code">
void UPooledObject::Init(AObjectPool* owner)
{
    _IsActive = false;
    _ObjectPool = owner;
}
void UPooledObject::RecycleSelf()
{
    _ObjectPool-&gt;RecyclePooledObject(this);
}
void UPooledObject::OnComponentDestroyed(
    bool bDestroyingHierarchy)
{
    _ObjectPool-&gt;OnPoolerCleanup.RemoveDynamic(this,
        &amp;UPooledObject::RecycleSelf);
    Super::OnComponentDestroyed(bDestroyingHierarchy);
}</pre> <p>Now for the main event, the <a id="_idIndexMarker457"/>object pool itself. Breaking down the definition, we start with a new delegate type with no arguments. This exists as a tether for each of the objects taken from the pool. If we need to recall them due to a level change, we can broadcast this delegate to recycle all active objects. We then have the definition of a new struct type. This only exists as a workaround for the fact that the template collections inside Unreal do not cater to multi-dimensional arrays. We would like to store an array of pools that in themselves are arrays. So, to get around this limitation, we define a new struct type that will hold all the objects we consider to be a part of one pool:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.h excerpt part 1</p>
<pre class="source-code">
DECLARE_DYNAMIC_MULTICAST_DELEGATE(FPoolerCleanupSignature);
class UPooledObject;
USTRUCT(BlueprintType)
struct FSingleObjectPool
{
    GENERATED_BODY()
    UPROPERTY(VisibleInstanceOnly, BlueprintReadOnly)
    TArray&lt;TObjectPtr&lt;UPooledObject&gt;&gt; _PooledObjects;
};</pre> <p>Next is the object <a id="_idIndexMarker458"/>pooler class. An exception to the rule, we don’t mark this as abstract. The reason for this is this actor just needs to exist. There is no need for any visual elements and so it can exist entirely on the C++ side, calling back to our separation rules for establishing the fuzzy layer in <a href="B18297_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>. The API includes functions for broadcasting the cleanup delegate, getting an object from the pool, and two methods for returning an object to the pool with either a <code>UPooledObject</code> component reference or a straight <code>AActor</code> reference. We’ll go over why there are two later in the definitions. In the protected section, we need a <code>BeginPlay</code> override, an array of the data about the pools marked as <code>EditAnywhere</code> for designers to use the tool, and an array of the struct we made earlier to store a reference to every object this pool spawns. You could make this simpler by having a different object pool per object type, but that creates more actors than is necessary in the scene. Lastly, there is a private function for regenerating objects that have<a id="_idIndexMarker459"/> been deleted, leaving holes in the pool:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.h excerpt part 2</p>
<pre class="source-code">
UCLASS()
class RTS_AI_API AObjectPool : public AActor
{
    GENERATED_BODY()
public:
    UPROPERTY()
    FPoolerCleanupSignature OnPoolerCleanup;
    UFUNCTION(BlueprintCallable)
    void Broadcast_PoolerCleanup();
    UFUNCTION(BlueprintCallable)
    AActor* GetPooledActor(FString name);
    UFUNCTION(BlueprintCallable)
    void RecyclePooledObject(UPooledObject* poolCompRef);
    UFUNCTION(BlueprintCallable)
    void RecycleActor(AActor* pooledActor);
protected:
    virtual void BeginPlay() override;
    UPROPERTY(EditAnywhere, BlueprintReadWrite)
    TArray&lt;FPooledObjectData&gt; _PooledObjectData;
    UPROPERTY(VisibleInstanceOnly, BlueprintReadWrite)
    TArray&lt;FSingleObjectPool&gt; _Pools;
private:
    void RegenItem(int poolIndex, int positionIndex);
};</pre> <p>With everything declared, we<a id="_idIndexMarker460"/> can move on to the definitions of our functions. To start, we have the <code>broadcast</code> function, which works as its name suggests, and the <code>BeginPlay</code> override for <em class="italic">warming up</em> the pool by spawning all the requested objects. Each pool iterates over the predefined number of times spawning new actors in the world. The code here names them and crucially adds an instance of the <code>UPooledObject</code> component to them. Having the pooler add this component dynamically means that the person who developed the actor being pooled didn’t need to know this was going to be added as a pooled class. This implementation uses <code>NewObject&lt;&gt;</code>, <code>RegisterComponent</code>, and <code>AddInstanceComponent</code> to create and add the component to the new actor as we are in runtime, and we would like to see the component in the actor details panel for debugging purposes. The new component needs its initialization function running before we hide it from view, disable its collisio<a id="_idTextAnchor159"/>n, and stop it from executing:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.cpp excerpt part 1</p>
<pre class="source-code">
void AObjectPool::Broadcast_PoolerCleanup() {
    OnPoolerCleanup.Broadcast();
}
void AObjectPool::BeginPlay() {
    Super::BeginPlay();
    FActorSpawnParameters spawnParams;
    for(int poolIndex = 0; poolIndex &lt;
        _PooledObjectData.Num(); poolIndex++)
    {
        FSingleObjectPool currentPool;
        spawnParams.Name =
            FName(_PooledObjectData[poolIndex]._ActorName);
        spawnParams.NameMode =
            FActorSpawnParameters::ESpawnActorNameMode:: Requested;
        spawnParams.SpawnCollisionHandlingOverride =
           ESpawnActorCollisionHandlingMethod::AlwaysSpawn;
        for(int objectIndex = 0; objectIndex &lt;
            _PooledObjectData[poolIndex]._PoolSize;
                objectIndex++)
        {
            AActor* spawnedActor = GetWorld()-&gt;
                SpawnActor(_PooledObjectData[poolIndex].
                    _ActorTemplate, &amp;FVector::ZeroVector,
                        &amp;FRotator::ZeroRotator,
                            spawnParams);
            UPooledObject* poolComp =
                NewObject&lt;UPooledObject&gt;(spawnedActor);
            poolComp-&gt;RegisterComponent();
            spawnedActor-&gt;AddInstanceComponent(poolComp);
            poolComp-&gt;Init(this);
            currentPool._PooledObjects.Add(poolComp);
            spawnedActor-&gt;SetActorHiddenInGame(true);
            spawnedActor-&gt;SetActorEnableCollision(false);
            spawnedActor-&gt;SetActorTickEnabled(false);
            spawnedActor-&gt;AttachToActor(this,
                FAttachmentTransformRules::
                    SnapToTargetNotIncludingScale);
        }
        _Pools.Add(currentPool);
    }
}</pre> <p>The method for getting an object from the pool has been made with an FString argument to make it as foolproof as possible, but it is advised that you establish an enum type that can be used <a id="_idIndexMarker461"/>to reference the pools as indexes. In its current form, it goes through a few steps:</p>
<ol>
<li>Finds the index of the pool that matches the input string, returning <code>out</code> if one isn’t found.</li>
<li>Loops through the objects in the found pool to find the next object, which is marked as inactive:<ol><li class="upper-roman">If a <code>nullptr</code> is found, then regenerate an object at that position and return it as it will be available.</li><li class="upper-roman">If the end of the list is reached, then check whether the pool is allowed to grow. If it can, then make and return the new item; otherwise, it would be sensible to output a warning so that the designers know the pool probably needs expanding.</li></ol></li>
</ol>
<p>In the following code, the<a id="_idIndexMarker462"/> section for returning the object, if it is new or existing, is repeated due to the slightly different situations where a new object must have the component added and initialized but then does not need to be deactivated:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.cpp excerpt part 2</p>
<pre class="source-code">
AActor* AObjectPool::GetPooledActor(FString name)
{
    int poolCount = _Pools.Num();
    int currentPool = -1;
    for(int i = 0; i &lt; poolCount; i++)
    {
        if(_PooledObjectData[i]._ActorName == name)
        {
            currentPool = i;
            break;
        }
    }
    if(currentPool == -1) { return nullptr; }
    int pooledObjectCount =
        _Pools[currentPool]._PooledObjects.Num();
    int firstAvailable = -1;
    for(int i = 0; i &lt; pooledObjectCount; i++)
    {
        if(_Pools[currentPool]._PooledObjects[i] !=
            nullptr)
        {
            if(!_Pools[currentPool]._PooledObjects[i]-&gt;
                _IsActive)
            {
                firstAvailable = i;
                break;
            }
        }
        else
        {
            RegenItem(currentPool, i);
            firstAvailable = i;
            break;
        }
    }
    if(firstAvailable &gt;= 0)
    {
        UPooledObject* toReturn =
            _Pools[currentPool]._PooledObjects[firstAvailable];
        toReturn-&gt;_IsActive = true;
        OnPoolerCleanup.AddUniqueDynamic(toReturn,
            &amp;UPooledObject::RecycleSelf);
        AActor* toReturnActor = toReturn-&gt;GetOwner();
        toReturnActor-&gt;SetActorHiddenInGame(false);
        toReturnActor-&gt;SetActorEnableCollision(true);
        toReturnActor-&gt;SetActorTickEnabled(true);
        toReturnActor-&gt;AttachToActor(nullptr,
            FAttachmentTransformRules::
                SnapToTargetNotIncludingScale);
        return toReturnActor;
    }
    if(!_PooledObjectData[currentPool]._CanGrow) { return
        nullptr; }
    FActorSpawnParameters spawnParams;
    spawnParams.Name =
        FName(_PooledObjectData[currentPool]._ActorName);
    spawnParams.NameMode =
        FActorSpawnParameters::ESpawnActorNameMode::
            Requested;
    spawnParams.SpawnCollisionHandlingOverride =
        ESpawnActorCollisionHandlingMethod::AlwaysSpawn;
    AActor* spawnedActor = GetWorld()-&gt;
        SpawnActor(_PooledObjectData[currentPool].
            _ActorTemplate, &amp;FVector::ZeroVector,
                &amp;FRotator::ZeroRotator, spawnParams);
    UPooledObject* poolComp =
        NewObject&lt;UPooledObject&gt;(spawnedActor);
    poolComp-&gt;RegisterComponent();
    spawnedActor-&gt;AddInstanceComponent(poolComp);
    poolComp-&gt;Init(this);
    _Pools[currentPool]._PooledObjects.Add(poolComp);
    poolComp-&gt;_IsActive = true;
    OnPoolerCleanup.AddUniqueDynamic(poolComp,
        &amp;UPooledObject::RecycleSelf);
    return spawnedActor;
}</pre> <p>The two recycling functions act as a way to do overloading with <code>UFUNCTION</code>s. Unreal does not support this standard C++ practice out of the box, and so we must define new functions for each as a workaround. In this case, the <code>RecycleActor</code> function tries to get a <code>UPooledObject</code> component reference from the input actor. It may be worth adding a summary comment above this function, with triple forward slashes, letting the user know that it may fail and a better method would be to use the <code>UPooledObject</code> version. If it succeeds, it then<a id="_idIndexMarker463"/> calls the <code>RecyclePooledObject</code> function with this new information. Otherwise, it currently does nothing, but this may be a good place to log out the situation as a warning and maybe have the function return a Boolean value on successful recycling as feedback on the action. The main recycling function simply returns the object to its initial disabled and hidden state in the pool, resetting the <code>_IsActive</code> flag in the pooled component:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.cpp excerpt part 3</p>
<pre class="source-code">
void AObjectPool::RecyclePooledObject(UPooledObject* poolCompRef)
{
    OnPoolerCleanup.RemoveDynamic(poolCompRef,
        &amp;UPooledObject::RecycleSelf);
    poolCompRef-&gt;_IsActive = false;
    AActor* returningActor = poolCompRef-&gt;GetOwner();
    returningActor-&gt;SetActorHiddenInGame(true);
    returningActor-&gt;SetActorEnableCollision(false);
    returningActor-&gt;SetActorTickEnabled(false);
    returningActor-&gt;AttachToActor(this,
        FAttachmentTransformRules::SnapToTargetNotIncludingScale);
}
void AObjectPool::RecycleActor(AActor* pooledActor)
{
    if(UPooledObject* poolCompRef =
        Cast&lt;UPooledObject&gt;(pooledActor-&gt;
            GetComponentByClass(UPooledObject::StaticClass())))
    {
        RecyclePooledObject(poolCompRef);
    }
}</pre> <p>The last function rounding out our object pooler is a function for regenerating items. This could maybe be separated better to make it more useful, in the <code>GetPooledActor</code> function, but as it stands, this follows the standard object generation as in the <code>BeginPlay</code> method, just with a twist. It uses indexes to add an object to a specific place in the pooled array. There is a lot of room for improvement with this function to make it more versatile, but <a id="_idIndexMarker464"/>that is left to your implementation’s needs:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ObjectPool.cpp excerpt part 4</p>
<pre class="source-code">
void AObjectPool::RegenItem(int poolIndex, int positionIndex)
{
    FActorSpawnParameters spawnParams;
    spawnParams.Name =
        FName(_PooledObjectData[poolIndex]._ActorName);
    spawnParams.NameMode =
        FActorSpawnParameters::ESpawnActorNameMode::Requested;
    spawnParams.SpawnCollisionHandlingOverride =
        ESpawnActorCollisionHandlingMethod::AlwaysSpawn;
    AActor* spawnedActor = GetWorld()-&gt;
        SpawnActor(_PooledObjectData[poolIndex].
            _ActorTemplate, &amp;FVector::ZeroVector,
                &amp;FRotator::ZeroRotator, spawnParams);
    UPooledObject* poolComp =
        NewObject&lt;UPooledObject&gt;(spawnedActor);
    poolComp-&gt;RegisterComponent();
    spawnedActor-&gt;AddInstanceComponent(poolComp);
    poolComp-&gt;Init(this);
    _Pools[poolIndex]._PooledObjects.Insert(poolComp,
        positionIndex);
    spawnedActor-&gt;SetActorHiddenInGame(true);
    spawnedActor-&gt;SetActorEnableCollision(false);
    spawnedActor-&gt;SetActorTickEnabled(false);
    spawnedActor-&gt;AttachToActor(this,FAttachmentTransformRules::
    SnapToTargetNotIncludingScale);
}</pre> <p>As stated a few times <a id="_idIndexMarker465"/>previously, this object pooler will do the job, but it is very basic in its utility. There are many extensions that you could, and probably should, consider, such as having pool groups so that objects are pooled based on the requested groups from the level or making it into a world subsystem that is universal to that world, allowing easy setup via the P<strong class="bold">roject Settings</strong> panel. However, the principle use of it stays the same: to offset the cost of spawning to the start of a level, where it can be hidden under a loading screen.</p>
<p>Using what we have <a id="_idIndexMarker466"/>created in its current form is quite simple. Simply drag an instance of the object pooler into your world from the Project panel and set up its data variable in the details panel. Once the game starts, it will spawn all the required objects in and hide them. To get an object, all you need to do is obtain a reference to the pooler somehow and call the <code>GetPooledObject</code> function, as shown in <em class="italic">Figure 10</em><em class="italic">.4</em>.</p>
<div><div><img alt="Figure 10.4 – Screenshot of the blueprint usage of the object pooler" src="img/Figure_10.04_B18297.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Screenshot of the blueprint usage of the object pooler</p>
<p>With that, we are at the<a id="_idIndexMarker467"/> end of our journey through object pooling. If you have been following along, you will not only have an object pooler that you can migrate between projects but also an idea of how you can remake and improve it to suit specific needs as and when required. Not only this, but the end of this section also brings us to the end of the chapter and the book. Even though this wasn’t specifically designed as a book to be read in order, from cover to cover, if you have been following this journey from the beginning, then you have a good set of practical skills and templates for how to improve your code in numerous ways. There will be some more parting words of wisdom after this, but let’s round this chapter content out by saying that it is more important to get something working than to build it exactly correct from the start, which is why the term refactoring exists.</p>
<h1 id="_idParaDest-146"><a id="_idTextAnchor160"/>Summary</h1>
<p>In this last chapter, we have covered three patterns that will boost the efficiency of your game, if implemented correctly. In game development, optimization should not be something you consider until it becomes a problem. It is far more important that you get something working first. Data locality should probably be considered as a first measure as it requires the least refactoring of code. Likewise, an object pool is something we would always recommend you have in your project, via a plugin, on standby for when you start to spawn a lot of the same object. The dirty flag pattern is much more situational, though, and is only applicable when an object has lots of edits versus few read actions per second. Armed with these tools, you should be able to make a dent in the frame rate, destroying the spaghetti mess that all projects become before release. There are always more ways to optimize code beyond this too – some not quite so obvious – but the key is to remember that all data and all instructions are stored somewhere and actions using them require them to be moved, which takes time.</p>
<p>You can find the finished project with all the elements from this book completed on GitHub in the same place as the other chapters in the <code>Complete</code> branch. Feel free to create a fork from here and make your own improvements to each of these patterns:</p>
<p><a href="https://github.com/PacktPublishing/Game-Development-Patterns-with-Unreal-Engine-5/tree/main/Complete">https://github.com/PacktPublishing/Game-Development-Patterns-with-Unreal-Engine-5/tree/main/Complete</a></p>
<p>A final rule: Good code doesn’t make a game good, but it does make your team better.</p>
</div>
</body></html>