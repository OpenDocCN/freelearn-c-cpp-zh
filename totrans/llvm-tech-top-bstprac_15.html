<html><head></head><body>
		<div id="_idContainer054">
			<h1 id="_idParaDest-166"><em class="italic"><a id="_idTextAnchor174"/>Chapter 12</em>: Learning LLVM IR Instrumentation</h1>
			<p>In the previous chapter, we learned how to leverage various utilities to improve our productivity while developing with LLVM. Those skills can give us a smoother experience when diagnosing problems that are raised by LLVM. Some of these utilities can even reduce the number of potential mistakes that are made by compiler engineers. In this chapter, we are going to learn how instrumentation works in LLVM IR.</p>
			<p>The <strong class="bold">instrumentation</strong> we are referring to here is a kind of technique that inserts some <em class="italic">probes</em> into the code we are compiling in order to collect runtime information. For example, we can collect information about how many times a certain function was called – which is only available once the target program has been executed. The advantage of this technique is that it provides extremely accurate information about the target program's behavior. This information can be used in several different ways. For instance, we can use the collected values to compile and optimize the same code <em class="italic">again</em> – but this time, since we have accurate data, we can perform more aggressive optimizations that couldn't be done previously. This technique is also called <strong class="bold">Profile-Guided Optimization</strong> (<strong class="bold">PGO</strong>). In another example, will be using the inserted probes to catch undesirable incidents that happened at runtime – buffer overflows, race conditions, and double-free memory, to name a few. The probe that's used for this purpose is also called a <strong class="bold">sanitizer</strong>.</p>
			<p>To implement instrumentation in LLVM, we not only need the help of LLVM pass, but also the synergy between <em class="italic">multiple</em> subprojects in LLVM – <strong class="bold">Clang</strong>, <strong class="bold">LLVM IR Transformation</strong>, and <strong class="bold">Compiler-RT</strong>. We already know about the first two from earlier chapters. In this chapter, we are going to introduce Compiler-RT and, more importantly, how can we <em class="italic">combine</em> these subsystems for the purpose of instrumentation.</p>
			<p>Here is the list of topics we are going to cover:</p>
			<ul>
				<li>Developing a sanitizer</li>
				<li>Working with PGO</li>
			</ul>
			<p>In the first part of this chapter, we are going to see how a sanitizer is implemented in Clang and LLVM, before creating a simple one by ourselves. The second half of this chapter is going to show you how to use the PGO framework in LLVM and how we can <em class="italic">extend</em> it.</p>
			<h1 id="_idParaDest-167"><a id="_idTextAnchor175"/>Technical requirements</h1>
			<p>In this chapter, we are going to work with multiple subprojects. One of them – Compiler-RT – needs to be included in your build by us modifying the CMake configuration. Please open the <strong class="source-inline">CMakeCache.txt</strong> file in your build folder and add the <strong class="source-inline">compiler-rt</strong> string to the value of the <strong class="source-inline">LLVM_ENABLE_PROJECTS</strong> variable. Here is an example:</p>
			<p class="source-code">//Semicolon-separated list of projects to build…</p>
			<p class="source-code">LLVM_ENABLE_PROJECTS:STRING="<strong class="bold">clang;compiler-rt</strong>"</p>
			<p>After editing the file, launch a build with any build target. CMake will try to reconfigure itself.</p>
			<p>Once everything has been set up, we can build the components we need for this chapter. Here is an example command:</p>
			<p class="source-code">$ ninja clang compiler-rt opt llvm-profdata</p>
			<p>This will build the <strong class="source-inline">clang</strong> tool we're all familiar with and a collection of Compiler-RT libraries, which we are going to introduce shortly.</p>
			<p>You can find the sample code for this chapter in the same GitHub repository: <a href="https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter12">https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter12</a>.</p>
			<h1 id="_idParaDest-168"><a id="_idTextAnchor176"/>Developing a sanitizer</h1>
			<p>A sanitizer is a <a id="_idIndexMarker661"/>kind of technique that checks certain runtime properties of the code (<strong class="source-inline">probe</strong>) that's inserted by the compiler. People usually use a sanitizer to ensure program correctness or enforce security policies. To give you <a id="_idIndexMarker662"/>an idea of how a sanitizer works, let's use one of the most popular sanitizers in Clang as an example – the <strong class="bold">address sanitizer</strong>.</p>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor177"/>An example of using an address sanitizer</h2>
			<p>Let's assume <a id="_idIndexMarker663"/>we have some simple C code, such <a id="_idIndexMarker664"/>as the following:</p>
			<p class="source-code">int main(int argc, char **argv) {</p>
			<p class="source-code">  int <strong class="bold">buffer[3]</strong>;</p>
			<p class="source-code">  for (int i = 1; i &lt; argc; ++i)</p>
			<p class="source-code">    <strong class="bold">buffer[i-1]</strong> = atoi(argv[i]);</p>
			<p class="source-code">  for (int i = 1; i &lt; argc; ++i)</p>
			<p class="source-code">    printf("%d ", buffer[i-1]);</p>
			<p class="source-code">  printf("\n");</p>
			<p class="source-code">  return 0;</p>
			<p class="source-code">}</p>
			<p>The preceding code converted the command-line arguments into integers and stored them in a buffer of size 3. Then, we printed them out.</p>
			<p>You should be able to easily spot an outstanding problem: the value of <strong class="source-inline">argc</strong> can be arbitrarily big when it's larger than 3 – the size of <strong class="source-inline">buffer</strong>. Here, we are storing the value in an <em class="italic">invalid</em> memory location. However, when we compile this code, the compiler will say nothing. Here is an example:</p>
			<p class="source-code">$ clang -Wall buffer_overflow.c -o buffer_overflow</p>
			<p class="source-code">$ # No error or warning</p>
			<p>In the preceding command, even if we enable all the compiler warnings via the <strong class="source-inline">-Wall</strong> flag, <strong class="source-inline">clang</strong> won't complain about the potential bug.</p>
			<p>If we try to execute the <strong class="source-inline">buffer_overflow</strong> program, the program will crash at some time point after we pass more than three command-line arguments to it; for example:</p>
			<p class="source-code">$ ./buffer_overflow 1 2 3</p>
			<p class="source-code">1 2 3</p>
			<p class="source-code">$ ./buffer_overflow 1 2 3 4</p>
			<p class="source-code"><strong class="bold">Segmentation fault (core dumped)</strong></p>
			<p class="source-code">$</p>
			<p>What's worse, the number of command-line arguments to crash <strong class="source-inline">buffer_overflow</strong> actually <em class="italic">varies</em> from machine to machine. This makes it even more difficult to debug if the example shown here were a real-world bug. To summarize, the problem we're encountering here is caused by the fact that <strong class="source-inline">buffer_overflow</strong> only goes rogue on <em class="italic">some</em> inputs and the compiler failed to catch the problem.</p>
			<p>Now, let's <a id="_idIndexMarker665"/>try to use an address sanitizer <a id="_idIndexMarker666"/>to catch this bug. The following command asks <strong class="source-inline">clang</strong> to compile the same code with an address sanitizer:</p>
			<p class="source-code">$ clang <strong class="bold">-fsanitize=address</strong> buffer_overflow.c -o san_buffer_overflow</p>
			<p>Let's execute the program again. Here is the output:</p>
			<p class="source-code">$ ./san_buffer_overflow 1 2 3</p>
			<p class="source-code">1 2 3</p>
			<p class="source-code">$ ./san_buffer_overflow 1 2 3 4</p>
			<p class="source-code">=================================================================</p>
			<p class="source-code">==137791==<strong class="bold">ERROR: AddressSanitizer: stack-buffer-overflow</strong> on address 0x7ffea06bccac at pc 0x0000004f96df bp 0x7ffea06bcc70…</p>
			<p class="source-code">WRITE of size 4 at 0x7ffea06bccac thread T0</p>
			<p class="source-code">…</p>
			<p class="source-code">  This frame has 1 object(s):</p>
			<p class="source-code">    [32, 44) <strong class="bold">'buffer' &lt;== Memory access at offset 44 overflows this variable</strong></p>
			<p class="source-code">…</p>
			<p class="source-code">==137791==ABORTING</p>
			<p class="source-code">$</p>
			<p>Instead of just crashing, the address sanitizer gave us many details about the issue that was raised at runtime: the sanitizer told us that it detected a <em class="italic">buffer overflow</em> on the stack, which might be the <strong class="source-inline">buffer</strong> variable.</p>
			<p>These messages were extremely useful. Imagine that you are working on a much more complicated software project. When a strange memory bug occurs, rather than just crash or silently change the program's logic, the address sanitizer can point out the problematic area – with high accuracy – right away.</p>
			<p>To go a <a id="_idIndexMarker667"/>little deeper into its mechanisms, the <a id="_idIndexMarker668"/>following diagram illustrates how the address sanitizer detects the buffer overflow:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B14590_12.1.jpg" alt="Figure 12.1 – Instrumentation code inserted by the address sanitizer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.1 – Instrumentation code inserted by the address sanitizer</p>
			<p>Here, we can see that the address sanitizer is effectively inserting a boundary check into the array index that's used for accessing <strong class="source-inline">buffer</strong>. With this extra check – which will be executed at runtime – the target program can bail out with error details before violating the memory access. More generally speaking, during the compilation, a sanitizer inserts some instrumentation code (into the target program) that will eventually be executed at runtime to check or <em class="italic">guard</em> certain properties.</p>
			<p class="callout-heading">Detecting overflow using an address sanitizer</p>
			<p class="callout">The preceding diagram shows a simplified version of how an address sanitizer works. In reality, the address sanitizer will leverage multiple strategies to monitor memory access in a program. For example, an address sanitizer can use a special memory allocator that allocates memory with <strong class="source-inline">traps</strong> put at the invalid memory region.</p>
			<p>While an <a id="_idIndexMarker669"/>address sanitizer is specialized in catching illegal memory access, a <strong class="bold">ThreadSanitizer</strong> can be used to catch data race conditions; that is, invalid access from multiple threads on the same chunk of data. Some other examples of sanitizers in Clang are the <strong class="bold">LeakSanitizer</strong>, which is used for detecting sensitive data such as <a id="_idIndexMarker670"/>passwords being leaked, and <strong class="bold">MemorySanitizer</strong>, which is used for <a id="_idIndexMarker671"/>detecting reads to uninitialized memory.</p>
			<p>Of course, there are some downsides to using sanitizers. The most prominent problem is the performance impact: using a thread sanitizer (in Clang) as an example, programs that are compiled with one are <em class="italic">5~15 times slower</em> than the original version. Also, since sanitizers insert extra code into the program, it might hinder some optimization opportunities, or even affect the original program's logic! In other words, it is a trade-off between the <em class="italic">robustness</em> and <em class="italic">performance</em> of the target program.</p>
			<p>With that, you've learned about the high-level idea of a sanitizer. Let's try to create a real one <a id="_idIndexMarker672"/>by ourselves to understand how Clang <a id="_idIndexMarker673"/>and LLVM implement a sanitizer. The following section contains more code than any of the examples in previous chapters, not to mention the changes are spread across different subprojects in LLVM. To focus on the most important knowledge, we won't go into the details of some <em class="italic">supporting</em> code – for example, changes that are made to CMake build scripts. Instead, we will go through them by providing a brief introduction and pointing out where you can find it in this book's GitHub repository.</p>
			<p>Let's start by providing an overview of the project we are going to create.</p>
			<h2 id="_idParaDest-170"><a id="_idTextAnchor178"/>Creating a loop counter sanitizer</h2>
			<p>To (slightly) simplify <a id="_idIndexMarker674"/>our task, the sanitizer <a id="_idIndexMarker675"/>we are going to create – a loop <a id="_idIndexMarker676"/>counter sanitizer, or <strong class="bold">LPCSan</strong> for short – looks just like a sanitizer except that it is not checking any serious program properties. Instead, we want to use it to print out the real, concrete <strong class="bold">trip count</strong> – the number of iterations – of a loop, which is only available during runtime.</p>
			<p>For example, let's assume we have the following input code:</p>
			<p class="source-code">void foo(int S, int E, int ST, int *a) {</p>
			<p class="source-code">  for (int i = S; i &lt; E; i += ST) {</p>
			<p class="source-code">    a[i] = a[i + 1];</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p class="source-code">int main(int argc, char **argv) {</p>
			<p class="source-code">  int start = atoi(argv[1]),</p>
			<p class="source-code">      end = atoi(argv[2]),</p>
			<p class="source-code">      step = atoi(argv[3]);</p>
			<p class="source-code">  int a[100];</p>
			<p class="source-code">  foo(start, end, step, a);</p>
			<p class="source-code">  return 0;</p>
			<p class="source-code">}</p>
			<p>We can compile it with a LPCSan using the following command:</p>
			<p class="source-code">$ clang <strong class="bold">-O1 -fsanitize=loop-counter</strong> test_lpcsan.c -o test_lpcsan</p>
			<p>Note that compiling with optimization greater than <strong class="source-inline">-O0</strong> is necessary; we will explain why later.</p>
			<p>When we <a id="_idIndexMarker677"/>execute <strong class="source-inline">test_lpcsan</strong> (with some command-line argument), we can print out the precise trip count <a id="_idIndexMarker678"/>of the loop in the <strong class="source-inline">foo</strong> function. For example, look at the following code:</p>
			<p class="source-code">$ ./test_lpcsan 0 100 1</p>
			<p class="source-code">==143813==<strong class="bold">INFO: Found a loop with trip count 100</strong></p>
			<p class="source-code">$ ./test_lpcsan 0 50 2</p>
			<p class="source-code">==143814==INFO: Found a loop with trip count 25</p>
			<p class="source-code">$</p>
			<p>The message highlighted in the preceding code was printed by our sanitizer code.</p>
			<p>Now, let's dive into the steps for creating the LPCSan. We will divide this tutorial into three parts: </p>
			<ul>
				<li>Developing an IR transformation</li>
				<li>Adding Compiler-RT components</li>
				<li>Adding the LPCSan to Clang</li>
			</ul>
			<p>We will start with the IR transformation part of this sanitizer.</p>
			<h3>Developing an IR transformation</h3>
			<p>Previously, we learned that an address sanitizer – or just a sanitizer in general – usually inserts <a id="_idIndexMarker679"/>code into the target <a id="_idIndexMarker680"/>program to check certain runtime properties or collect data. In <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager</em>, and <a href="B14590_10_Final_JC_ePub.xhtml#_idTextAnchor141"><em class="italic">Chapter 10</em></a>, <em class="italic">Processing LLVM IR</em>, we learned how to modify/transform LLVM IR, including inserting new code into it, so this seems to be a good starting point for crafting our LPCSan.</p>
			<p>In this section, we are going to develop an LLVM pass called <strong class="source-inline">LoopCounterSanitizer</strong> that inserts special function calls to collect the exact trip count of every loop in <strong class="source-inline">Module</strong>. Here are the detailed steps:</p>
			<ol>
				<li>First, let's create two files: <strong class="source-inline">LoopCounterSanitizer.cpp</strong> under the <strong class="source-inline">llvm/lib/Transforms/Instrumentation</strong> folder and its corresponding header file inside the <strong class="source-inline">llvm/include/llvm/Transforms/Instrumentation</strong> folder. Inside the header file, we will place the declaration of this pass, as shown here:<p class="source-code">struct LoopCounterSanitizer</p><p class="source-code">  : public PassInfoMixin&lt;LoopCounterSanitizer&gt; {</p><p class="source-code">  PreservedAnalyses run(Loop&amp;, LoopAnalysisManager&amp;,</p><p class="source-code">                        LoopStandardAnalysisResults&amp;, </p><p class="source-code">                        LPMUpdater&amp;);</p><p class="source-code">private:</p><p class="source-code">  // Sanitizer functions</p><p class="source-code">  <strong class="bold">FunctionCallee LPCSetStartFn, LPCAtEndFn;</strong></p><p class="source-code">  void initializeSanitizerFuncs(Loop&amp;);</p><p class="source-code">};</p><p>The preceding code shows the typical loop pass structure we saw in <a href="B14590_10_Final_JC_ePub.xhtml#_idTextAnchor141"><em class="italic">Chapter 10</em></a>, <em class="italic">Processing LLVM IR</em>. The only notable changes are the <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong> memory variables – they will store the <strong class="source-inline">Function</strong> instances that collect loop trip counts (<strong class="source-inline">FunctionCallee</strong> is a thin wrapper around <strong class="source-inline">Function</strong> that provides additional function signature information).</p></li>
				<li>Finally, in <strong class="source-inline">LoopCounterSanitizer.cpp</strong>, we are placing the skeleton code for our pass, as shown here:<p class="source-code">PreservedAnalyses</p><p class="source-code">LoopCounterSanitizer::run(Loop &amp;LP, LoopAnalysisManager &amp;LAM, LoopStandardAnalysisResults &amp;LSR, LPMUpdater &amp;U) {</p><p class="source-code">  <strong class="bold">initializeSanitizerFuncs(LP);</strong></p><p class="source-code">  return PreservedAnalyses::all();</p><p class="source-code">}</p><p>The <strong class="source-inline">initializeSanitizerFuncs</strong> method <a id="_idIndexMarker681"/>in the preceding code will populate <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong>. Before we go into the details of <strong class="source-inline">initializeSanitizerFuncs</strong>, let's talk more about <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong>.</p></li>
				<li>To <a id="_idIndexMarker682"/>figure out the exact trip count, the <strong class="source-inline">Function</strong> instance stored in <strong class="source-inline">LPCSetStartFn</strong> will be used to collect the <em class="italic">initial</em> induction variable value of a loop. On the other hand, the <strong class="source-inline">Function</strong> instance stored in <strong class="source-inline">LPCAtEndFn</strong> will be used to collect the <em class="italic">final</em> induction variable value and the step value of the loop. To give you a concrete idea of how these two <strong class="source-inline">Function</strong> instances work together, let's assume we have the following pseudocode as our input program:<p class="source-code">void foo(int S, int E, int ST) {</p><p class="source-code">  for (int i = S; i &lt; E; i += ST) {</p><p class="source-code">    …</p><p class="source-code">  }</p><p class="source-code">}</p><p>In the preceding code, the <strong class="source-inline">S</strong>, <strong class="source-inline">E</strong>, and <strong class="source-inline">ST</strong> variables represent the initial, final, and step <a id="_idIndexMarker683"/>values of a loop, respectively. The goal of the <strong class="source-inline">LoopCounterSanitizer</strong> pass is to insert <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong> in the following way:</p><p class="source-code">void foo(int S, int E, int ST) {</p><p class="source-code">  for (int i = S; i &lt; E; i += ST) {</p><p class="source-code">    <strong class="bold">lpc_set_start(S);</strong></p><p class="source-code">    …</p><p class="source-code">    <strong class="bold">lpc_at_end(E, ST);</strong></p><p class="source-code">  }</p><p class="source-code">}</p><p><strong class="source-inline">lpc_set_start</strong> and <strong class="source-inline">lpc_at_end</strong> in the preceding code are <strong class="source-inline">Function</strong> instances that <a id="_idIndexMarker684"/>are stored in <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong>, respectively. Here is one of the possible (pseudo) implementations of these two functions:</p><p class="source-code">static int CurrentStartVal = 0;</p><p class="source-code">void lpc_set_start(int start) {</p><p class="source-code">  <strong class="bold">CurrentStartVal = start;</strong></p><p class="source-code">}</p><p class="source-code">void lpc_at_end(int end, int step) {</p><p class="source-code">  int trip_count = (end – <strong class="bold">CurrentStartVal</strong>) / step;</p><p class="source-code">  <strong class="bold">printf("Found a loop with trip count %d\n",    trip_count);</strong></p><p class="source-code">}</p><p>Now that we know the roles of <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong>, it's time to take a look at how <strong class="source-inline">initializeSanitizerFuncs</strong> initializes them.</p></li>
				<li>Here is the code inside <strong class="source-inline">initializeSanitizerFuncs</strong>:<p class="source-code">void LoopCounterSanitizer::initializeSanitizerFuncs(Loop &amp;LP) {</p><p class="source-code">  Module &amp;M = *LP.getHeader()-&gt;getModule();</p><p class="source-code">  auto &amp;Ctx = M.getContext();</p><p class="source-code">  Type *VoidTy = Type::<strong class="bold">getVoidTy</strong>(Ctx),</p><p class="source-code">       *ArgTy = Type::<strong class="bold">getInt32Ty</strong>(Ctx);</p><p class="source-code">  LPCSetStartFn</p><p class="source-code">    = M.<strong class="bold">getOrInsertFunction</strong>("<strong class="bold">__lpcsan_set_loop_start</strong>",</p><p class="source-code">                            VoidTy, ArgTy);</p><p class="source-code">  LPCAtEndFn = M.getOrInsertFunction("<strong class="bold">__lpcsan_at_loop_   end</strong>", VoidTy, ArgTy, ArgTy);</p><p class="source-code">}</p><p>The <a id="_idIndexMarker685"/>previous code is basically fetching two functions, <strong class="source-inline">__lpcsan_set_loop_start</strong> and <strong class="source-inline">__lpcsan_at_loop_end</strong>, from the module <a id="_idIndexMarker686"/>and storing their <strong class="source-inline">Function</strong> instances in <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong>, respectively.</p><p>The <strong class="source-inline">Module::getOrInsertFunction</strong> method either grabs the <strong class="source-inline">Function</strong> instance of the given function name from the module or creates one if it doesn't exist. If it's a newly created instance, it has an empty function body; in other words, it only has a function <em class="italic">declaration</em>.</p><p>It is also worth noting that the second argument of <strong class="source-inline">Module::getOrInsertFunction</strong> is the return type of the <strong class="source-inline">Function</strong> inquiry. The rest (the arguments for <strong class="source-inline">getOrInsertFunction</strong>) represent the argument types of that <strong class="source-inline">Function</strong>.</p><p>With <strong class="source-inline">LPCSetStartFn</strong> and <strong class="source-inline">LPCAtEndFn</strong> set up, let's see how we can insert them into the right place in IR.</p></li>
				<li>Recall that in <a href="B14590_10_Final_JC_ePub.xhtml#_idTextAnchor141"><em class="italic">Chapter 10</em></a>, <em class="italic">Processing LLVM IR</em>, we learned about several utility classes for working with <strong class="source-inline">Loop</strong>. One of them – <strong class="source-inline">LoopBounds</strong> – can give us the boundary of a <strong class="source-inline">Loop</strong>. We can do this by including the start, end, and step values <a id="_idIndexMarker687"/>of an induction variable, which is exactly <a id="_idIndexMarker688"/>the information we are looking for. Here is the code that tries to retrieve a <strong class="source-inline">LoopBounds</strong> instance:<p class="source-code">PreservedAnalyses</p><p class="source-code">LoopCounterSanitizer::run(Loop &amp;LP, LoopAnalysisManager &amp;LAM, LoopStandardAnalysisResults &amp;LSR, LPMUpdater &amp;U) {</p><p class="source-code">  initializeSanitizerFuncs(LP);</p><p class="source-code">  <strong class="bold">ScalarEvolution &amp;SE = LSR.SE;</strong></p><p class="source-code">  using LoopBounds = typename Loop::LoopBounds;</p><p class="source-code">  auto MaybeLB = <strong class="bold">LP.getBounds(SE);</strong></p><p class="source-code">  if (!MaybeLB) {</p><p class="source-code">    errs() &lt;&lt; "WARNING: Failed to get loop bounds\n";</p><p class="source-code">    return PreservedAnalyses::all();</p><p class="source-code">  }</p><p class="source-code">  <strong class="bold">LoopBounds &amp;LB = *MaybeLB;</strong></p><p class="source-code">  …</p><p class="source-code">  Value *StartVal = &amp;LB.<strong class="bold">getInitialIVValue</strong>(),</p><p class="source-code">        *EndVal = &amp;LB.<strong class="bold">getFinalIVValue</strong>(),</p><p class="source-code">        *StepVal = LB.<strong class="bold">getStepValue</strong>();</p><p class="source-code">}</p><p><strong class="source-inline">Loop::getBounds</strong> from the preceding code returned an <strong class="source-inline">Optional&lt;LoopBounds&gt;</strong> instance. The <strong class="source-inline">Optional&lt;T&gt;</strong> class is a useful container that <a id="_idIndexMarker689"/>either stores an instance of the <strong class="source-inline">T</strong> type or is <em class="italic">empty</em>. You can <a id="_idIndexMarker690"/>think of it as a replacement for the <strong class="bold">null pointer</strong>: usually, people use <strong class="source-inline">T*</strong> to represent a computation result where a null pointer <a id="_idIndexMarker691"/>means an empty value. However, this has the risk of dereferencing a null pointer if the programmer forgets to check the pointer first. The <strong class="source-inline">Optional&lt;T&gt;</strong> class doesn't have this problem.</p><p>With a <strong class="source-inline">LoopBounds</strong> instance, we can retrieve the induction variable's range and store it in the <strong class="source-inline">StartVal</strong>, <strong class="source-inline">EndVal</strong>, and <strong class="source-inline">StepVal</strong> variables.</p></li>
				<li><strong class="source-inline">StartVal</strong> is the <strong class="source-inline">Value</strong> instance to be collected by <strong class="source-inline">__lpcsan_set_loop_start</strong>, whereas <strong class="source-inline">__lpcsan_at_loop_end</strong> is going to collect <strong class="source-inline">EndVal</strong> and <strong class="source-inline">StepVal</strong> at runtime. Now, the question is, <em class="italic">where</em> should we insert function calls to <strong class="source-inline">__lpcsan_set_loop_start</strong> and <strong class="source-inline">__lpcsan_at_loop_end</strong> to correctly collect those values?<p>The rule of thumb is that we need to insert those function calls after the <em class="italic">definition</em> of those values. While we can find the exact locations where those values were defined, let's try to simplify the problem by inserting instrumentation function calls at some fixed locations – locations where our target values are <em class="italic">always</em> available.</p><p>For <strong class="source-inline">__lpcsan_set_loop_start</strong>, we are inserting it at the end of the <strong class="bold">loop header</strong> block, because the initial induction variable value will never be defined after this block. Here is the code:</p><p class="source-code">// Inside LoopCounterSanitizer::run …</p><p class="source-code">…</p><p class="source-code">BasicBlock *Header = LP.<strong class="bold">getHeader</strong>();</p><p class="source-code">Instruction *LastInst = Header-&gt;<strong class="bold">getTerminator</strong>();</p><p class="source-code">IRBuilder&lt;&gt; Builder(LastInst);</p><p class="source-code">Type *ArgTy = LPCSetStartFn.getFunctionType()-&gt;getParamType(0);</p><p class="source-code">if (StartVal-&gt;getType() != ArgTy) {</p><p class="source-code">  // cast to argument type first</p><p class="source-code">  <strong class="bold">StartVal</strong> = Builder.<strong class="bold">CreateIntCast</strong>(<strong class="bold">StartVal</strong>, ArgTy, true);</p><p class="source-code">}</p><p class="source-code"><strong class="bold">Builder.CreateCall(LPCSetStartFn, {StartVal});</strong></p><p class="source-code">…</p><p>In the <a id="_idIndexMarker692"/>preceding code, we used <strong class="source-inline">getTerminator</strong> to get the last <strong class="source-inline">Instruction</strong> from the header block. Then, we used <strong class="source-inline">IRBuilder&lt;&gt;</strong> – with the last instruction as the insertion point – to insert new <strong class="source-inline">Instruction</strong> instances.</p><p>Before <a id="_idIndexMarker693"/>we can pass <strong class="source-inline">StartVal</strong> as an argument to the new <strong class="source-inline">__lpcsan_set_loop_start</strong> function call, we need to convert its IR type (represented by the <strong class="source-inline">Type</strong> class) into a compatible one. <strong class="source-inline">IRBuilder::CreateInstCast</strong> is a handy utility that automatically generates either an instruction to <em class="italic">extend</em> the integer bit width or an instruction to <em class="italic">truncate</em> the bit width, depending on the given <strong class="source-inline">Value</strong> and <strong class="source-inline">Type</strong> instances.</p><p>Finally, we can create a function call to <strong class="source-inline">__lpcsan_set_loop_start</strong> via <strong class="source-inline">IRBuilder::CreateCall</strong>, with <strong class="source-inline">StartVal</strong> as the function call argument.</p></li>
				<li>For <strong class="source-inline">__lpcsan_at_loop_end</strong>, we are using the same trick to collect the runtime values of <strong class="source-inline">EndVal</strong> and <strong class="source-inline">StepVal</strong>. Here is the code:<p class="source-code">BasicBlock *ExitBlock = LP.<strong class="bold">getExitBlock</strong>();</p><p class="source-code">Instruction *FirstInst = ExitBlock-&gt;<strong class="bold">getFirstNonPHI</strong>();</p><p class="source-code">IRBuilder&lt;&gt; Builder(<strong class="bold">FirstInst</strong>);</p><p class="source-code">FunctionType *LPCAtEndTy = LPCAtEndFn.getFunctionType();</p><p class="source-code">Type *EndArgTy = LPCAtEndTy-&gt;getParamType(0),</p><p class="source-code">     *StepArgTy = LPCAtEndTy-&gt;getParamType(1);</p><p class="source-code">if (EndVal-&gt;getType() != EndArgTy)</p><p class="source-code">  EndVal = Builder.<strong class="bold">CreateIntCast</strong>(EndVal, EndArgTy, true);</p><p class="source-code">if (StepVal-&gt;getType() != StepArgTy)</p><p class="source-code">  StepVal = Builder.<strong class="bold">CreateIntCast</strong>(StepVal, StepArgTy,   true);</p><p class="source-code"><strong class="bold">Builder.CreateCall(LPCAtEndFn, {EndVal, StepVal});</strong></p><p>Different from the previous step, we are inserting the function call to <strong class="source-inline">__lpcsan_at_loop_end</strong> at the beginning of the <em class="italic">exit block</em>. This is because we can always expect the end value and the step value of the induction variable being <a id="_idIndexMarker694"/>defined before we leave the loop.</p><p>These <a id="_idIndexMarker695"/>are all the implementation details for the <strong class="source-inline">LoopCounterSanitizer</strong> pass.</p></li>
				<li>Before we wrap up this section, we need to edit a few more files to make sure everything works. Please look at the <strong class="source-inline">Changes-LLVM.diff</strong> file in the sample code folder for this chapter. Here is the summary of the changes that were made in other supporting files:<p>i. Changes in <strong class="source-inline">llvm/lib/Transforms/Instrumentation/CMakeLists.txt</strong>: Add our new pass source file to the build.</p><p>ii. Changes in <strong class="source-inline">llvm/lib/Passes/PassRegistry.def</strong>: Add our pass to the list of available passes so that we can test it using our old friend <strong class="source-inline">opt</strong>.</p></li>
			</ol>
			<p>With that, we've finally finished making all the necessary modifications to the LLVM part.</p>
			<p>Before we move on to the next section, let's test our newly created <strong class="source-inline">LoopCounterSanitizer</strong> pass. We are going to be using the same C code we saw earlier in this section. Here is the function that contains the loop we want to instrument:</p>
			<p class="source-code">void foo(int S, int E, int ST, int *a) {</p>
			<p class="source-code">  for (int i = S; i &lt; E; i += ST) {</p>
			<p class="source-code">    a[i] = a[i + 1];</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>Note that <a id="_idIndexMarker696"/>although we didn't explicitly check the loop <a id="_idIndexMarker697"/>form in our pass, some of the APIs that were used in the pass actually required the loop to be <em class="italic">rotated</em>, so please generate the LLVM IR code with an O1 optimization level to make sure the loop rotation's Pass has kicked in:</p>
			<p>Here is the simplified LLVM IR for the <strong class="source-inline">foo</strong> function:</p>
			<p class="source-code">define void @foo(i32 %S, i32 %E, i32 %ST, i32* %a) {</p>
			<p class="source-code">  %cmp9 = icmp slt i32 %S, %E</p>
			<p class="source-code">  br i1 %cmp9, label %for.body.preheader, label %for.cond.   cleanup</p>
			<p class="source-code"><strong class="bold">for.body.preheader</strong>:  </p>
			<p class="source-code">  %0 = sext i32 %S to i64</p>
			<p class="source-code">  %1 = sext i32 %ST to i64</p>
			<p class="source-code">  %2 = sext i32 %E to i64</p>
			<p class="source-code">  br label %for.body</p>
			<p class="source-code">…</p>
			<p class="source-code"><strong class="bold">for.body</strong>:                                         </p>
			<p class="source-code">  %indvars.iv = phi i64 [ %0, %for.body.preheader ], [   %indvars.iv.next, %for.body ]</p>
			<p class="source-code">  …</p>
			<p class="source-code">  %indvars.iv.next = add i64 %indvars.iv, %1</p>
			<p class="source-code">  %cmp = icmp slt i64 %indvars.iv.next, %2</p>
			<p class="source-code">  br i1 %cmp, label %for.body, label %for.cond.cleanup</p>
			<p class="source-code">}</p>
			<p>The highlighted labels are the preheader and loop body blocks for this loop. Since this loop <a id="_idIndexMarker698"/>has been rotated, the <strong class="source-inline">for.body</strong> block is both the header, latch, and exiting block for this loop.</p>
			<p>Now, let's transform this IR with <strong class="source-inline">opt</strong> using the following command:</p>
			<p class="source-code">$ opt -S –passes="loop(<strong class="bold">lpcsan</strong>)" input.ll -o -</p>
			<p>In the <strong class="source-inline">–passes</strong> command-line option, we asked <strong class="source-inline">opt</strong> to run our <strong class="source-inline">LoopCounterSanitizer</strong> pass (with the name <strong class="source-inline">lpcsan</strong>, which is registered in the <strong class="source-inline">PassRegistry.def</strong> file). The enclosing <strong class="source-inline">loop(…)</strong> string is simply telling <strong class="source-inline">opt</strong> that <strong class="source-inline">lpcsan</strong> is a loop pass (you can actually omit <a id="_idIndexMarker699"/>this decoration since <strong class="source-inline">opt</strong> can find the right pass most of the time).</p>
			<p>Here is the simplified result:</p>
			<p class="source-code"><strong class="bold">declare void @__lpcsan_set_loop_start(i32)</strong></p>
			<p class="source-code"><strong class="bold">declare void @__lpcsan_at_loop_end(i32, i32)</strong></p>
			<p class="source-code">define void @foo(i32 %S, i32 %E, i32* %a) {</p>
			<p class="source-code">  %cmp8 = icmp slt i32 %S, %E</p>
			<p class="source-code">  br i1 %cmp8, label %for.body.preheader, label %for.cond.cleanup</p>
			<p class="source-code">for.body.preheader: </p>
			<p class="source-code">  %0 = sext i32 %S to i64</p>
			<p class="source-code">  %wide.trip.count = sext i32 %E to i64</p>
			<p class="source-code">  br label %for.body</p>
			<p class="source-code"><strong class="bold">for.cond.cleanup.loopexit</strong>:                        </p>
			<p class="source-code">  %1 = trunc i64 %wide.trip.count to i32</p>
			<p class="source-code">  <strong class="bold">call void @__lpcsan_at_loop_end(i32 %1, i32 1)</strong></p>
			<p class="source-code">  br label %for.cond.cleanup</p>
			<p class="source-code"><strong class="bold">for.body</strong>:</p>
			<p class="source-code">  …</p>
			<p class="source-code">  %3 = trunc i64 %0 to i32</p>
			<p class="source-code">  <strong class="bold">call void @__lpcsan_set_loop_start(i32 %3)</strong></p>
			<p class="source-code">  br i1 %exitcond.not, label %for.cond.cleanup.loopexit, label    %for.body</p>
			<p class="source-code">}</p>
			<p>As you can see, <strong class="source-inline">__lpcsan_set_loop_start</strong> and <strong class="source-inline">__lpcsan_at_loop_end</strong> have been correctly <a id="_idIndexMarker700"/>inserted into the header block and exit block, respectively. They are also collecting the desired values related to the loop trip count.</p>
			<p>Now, the <a id="_idIndexMarker701"/>biggest question is: where are the <em class="italic">function bodies</em> for <strong class="source-inline">__lpcsan_set_loop_start</strong> and <strong class="source-inline">__lpcsan_at_loop_end</strong>? Both only have declarations in the preceding IR code.</p>
			<p>In the next section, we will use Compiler-RT to answer this question.</p>
			<h3>Adding the Compiler-RT component</h3>
			<p>The <a id="_idIndexMarker702"/>name <strong class="bold">Compiler-RT</strong> stands <a id="_idIndexMarker703"/>for <strong class="bold">Compiler RunTime</strong>. The usage of <em class="italic">runtime</em> is a <a id="_idIndexMarker704"/>little ambiguous here because too many things can be called a runtime in a normal compilation pipeline. But the truth is that Compiler-RT <em class="italic">does</em> contain a wide range of libraries for completely different tasks. What these libraries have in common is that they provide <em class="italic">supplement</em> code for the target program to implement enhancement features or functionalities that were otherwise absent. It is important to remember that Compiler-RT libraries are NOT used for building a compiler or related tool – they should be linked with the program we are compiling.</p>
			<p>One of the most used <a id="_idIndexMarker705"/>features in Compiler-RT is the <strong class="bold">builtin function</strong>. As you might have heard, more and more computer architectures nowadays support <em class="italic">vector operation</em> natively. That is, you can process multiple data elements at the <a id="_idIndexMarker706"/>same time with the support <a id="_idIndexMarker707"/>from hardware. Here is some example code, written in C, that uses vector operations:</p>
			<p class="source-code">typedef int v4si __attribute__((__vector_size__(16)));</p>
			<p class="source-code">v4si v1 = (v4si){1, 2, 3, 4};</p>
			<p class="source-code">v4si v2 = (v4si){5, 6, 7, 8};</p>
			<p class="source-code">v4si v3 = <strong class="bold">v1 + v2</strong>; // = {6, 8, 10, 12}</p>
			<p>The preceding code used a non-standardized (currently, you can only use this syntax in Clang and GCC) C/C++ vector extension to declare two vectors, <strong class="source-inline">v1</strong> and <strong class="source-inline">v2</strong>, before adding them to yield a third one.</p>
			<p>On X86-64 <a id="_idIndexMarker708"/>platforms, this code will be compiled to use one of <a id="_idIndexMarker709"/>the vector instruction sets, such as <strong class="bold">SSE</strong> or <strong class="bold">AVX</strong>. On the <a id="_idIndexMarker710"/>ARM platform, the resulting binary might be using the <strong class="bold">NEON</strong> vector instruction set. But what if your target platform does NOT have a vector instruction set? The most obvious solution would be "synthesizing" these unsupported operations with the available instructions. For example, we should write a <strong class="source-inline">for-loop</strong> to replace vector summation in this case. More specifically, whenever we see a vector summation at compilation time, we replace it with a call to a function that contains the synthesis implementation using <strong class="source-inline">for-loop</strong>. The function body can be put anywhere, as long as it is eventually linked with the program. The following diagram illustrates this process:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B14590_12.2.jpg" alt="Figure 12.2 – Workflow of the Compiler-RT builtin&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.2 – Workflow of the Compiler-RT builtin</p>
			<p>As you <a id="_idIndexMarker711"/>may have <a id="_idIndexMarker712"/>noticed, the workflow shown here is similar to our requirement in the LPCSan: in the previous section, we developed an LLVM pass that inserted extra function calls to collect the loop trip count, but we still need to implement those collector functions. If we leverage the workflow shown in the preceding diagram, we can come up with a design, as shown in the following diagram:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B14590_12.3.jpg" alt="Figure 12.3 – Workflow of the Compiler-RT LPCSan component&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.3 – Workflow of the Compiler-RT LPCSan component</p>
			<p>The previous diagram shows that the function bodies of <strong class="source-inline">__lpcsan_set_loop_start</strong> and <strong class="source-inline">__lpcsan_at_loop_end</strong> are put inside a Compiler-RT library that will eventually be linked with the final binary. Inside these two functions, we calculate the trip count using the <a id="_idIndexMarker713"/>input arguments and print the result. In the rest of this section, we'll show you how to create such <a id="_idIndexMarker714"/>a Compiler-RT library for the LPCSan. Let's get started:</p>
			<ol>
				<li value="1">First, switch the folder to <strong class="source-inline">llvm-project/compiler-rt</strong>, the root of Compiler-RT. Inside this subproject, we must create a new folder called <strong class="source-inline">lib/lpcsan</strong> before we put a new <strong class="source-inline">lpcsan.cpp</strong> file inside it. Within this file, let's create the skeleton for our instrumentation functions. Here is the code:<p class="source-code">#include "sanitizer_common/sanitizer_common.h"</p><p class="source-code">#include "sanitizer_common/sanitizer_internal_defs.h"</p><p class="source-code">using namespace __sanitizer;</p><p class="source-code">extern "C" SANITIZER_INTERFACE_ATTRIBUTE</p><p class="source-code">void <strong class="bold">__lpcsan_set_loop_start(s32 start)</strong>{</p><p class="source-code">  // TODO</p><p class="source-code">}</p><p class="source-code">extern "C" SANITIZER_INTERFACE_ATTRIBUTE</p><p class="source-code">void <strong class="bold">__lpcsan_at_loop_end(s32 end, s32 step)</strong>{</p><p class="source-code"> // TODO</p><p class="source-code">}</p><p>There are two things worth noting here: first, use the primitive data types provided by Compiler-RT. For example, in the preceding code, we used <strong class="source-inline">s32</strong> – available under the <strong class="source-inline">__sanitizer</strong> namespace – for a signed 32-bit integer rather than the normal <strong class="source-inline">int</strong>. The rationale behind this is that we might need to build Compiler-RT libraries for different hardware architectures or platforms, and the width of <strong class="source-inline">int</strong> might not be 32 bits on some of them.</p><p>Second, although we are using C++ to implement our instrumentation functions, we <a id="_idIndexMarker715"/>need to expose them as C functions because C functions have a more stable <strong class="bold">Application Binary Interface</strong> (<strong class="bold">ABI</strong>). Therefore, please make sure to add <strong class="source-inline">extern "C"</strong> to functions you want to export. The <strong class="source-inline">SANITIZER_INTERFACE_ATTRIBUTE</strong> macro also ensures that the function <a id="_idIndexMarker716"/>will be exposed at the library interface correctly, so please add this as well.</p></li>
				<li>Next, we <a id="_idIndexMarker717"/>will add the necessary code to these two functions. Here is how we do this:<p class="source-code">static <strong class="bold">s32 CurLoopStart</strong> = 0;</p><p class="source-code">extern "C" SANITIZER_INTERFACE_ATTRIBUTE</p><p class="source-code">void __lpcsan_set_loop_start(s32 start){</p><p class="source-code">  <strong class="bold">CurLoopStart = start;</strong></p><p class="source-code">}</p><p class="source-code">extern "C" SANITIZER_INTERFACE_ATTRIBUTE</p><p class="source-code">void __lpcsan_at_loop_end(s32 end, s32 step){</p><p class="source-code">  s32 trip_count = (end - <strong class="bold">CurLoopStart</strong>) / step;</p><p class="source-code">  s32 abs_trip_count</p><p class="source-code">    = trip_count &gt;= 0? trip_count : -trip_count;</p><p class="source-code">  <strong class="bold">Report("INFO: Found a loop with "</strong></p><p class="source-code"><strong class="bold">         "trip count %d\n", abs_trip_count);</strong></p><p class="source-code">}</p><p>The implementation we used here is pretty straightforward: <strong class="source-inline">CurLoopStart</strong> is a global variable that memorizes the <em class="italic">initial</em> induction variable value of the current loop. This is updated by <strong class="source-inline">__lpcsan_set_loop_start</strong>.</p><p>Recall that when a loop is complete, <strong class="source-inline">__lpcsan_at_loop_end</strong> will be invoked. When that happens, we use the value stored in <strong class="source-inline">CurLoopStart</strong> and the <strong class="source-inline">end</strong> and <strong class="source-inline">step</strong> arguments to calculate the exact trip count of the current loop, before printing the result.</p></li>
				<li>Now <a id="_idIndexMarker718"/>that we have <a id="_idIndexMarker719"/>implemented the core logic, it's time to build this library. Inside the <strong class="source-inline">lib/lpcsan</strong> folder, create a new <strong class="source-inline">CMakeLists.txt</strong> file and insert the following code:<p class="source-code">…</p><p class="source-code">set(LPCSAN_RTL_SOURCES</p><p class="source-code">    lpcsan.cpp)</p><p class="source-code"><strong class="bold">add_compiler_rt_component(lpcsan)</strong></p><p class="source-code">foreach(<strong class="bold">arch ${LPCSAN_SUPPORTED_ARCH}</strong>)</p><p class="source-code">  set(LPCSAN_CFLAGS ${LPCSAN_COMMON_CFLAGS})</p><p class="source-code">  <strong class="bold">add_compiler_rt_runtime</strong>(clang_rt.lpcsan</p><p class="source-code">    STATIC</p><p class="source-code">    ARCHS ${arch}</p><p class="source-code">    SOURCES ${LPCSAN_RTL_SOURCES}</p><p class="source-code">           $&lt;<strong class="bold">TARGET_OBJECTS:RTSanitizerCommon</strong>.${arch}&gt;</p><p class="source-code">           $&lt;<strong class="bold">TARGET_OBJECTS:RTSanitizerCommonLibc</strong>.${arch}&gt;</p><p class="source-code">    ADDITIONAL_HEADERS ${LPCSAN_RTL_HEADERS}</p><p class="source-code">    CFLAGS ${LPCSAN_CFLAGS}</p><p class="source-code">    PARENT_TARGET lpcsan)</p><p class="source-code">  …</p><p class="source-code">endforeach()</p><p>In the preceding code, we are only showing the most important part of our <strong class="source-inline">CMakeLists.txt</strong>. Here are some highlights:</p><p>i. Compiler-RT creates its own set of CMake macros/functions. Here, we are using two of them, <strong class="source-inline">add_compiler_rt_component</strong> and <strong class="source-inline">add_compiler_rt_runtime</strong>, to create a pseudo build target for the entire LPCSan and the real library build target, respectively.</p><p>ii. Different from a conventional build target, if a sanitizer wants to use supporting/utility libraries in Compiler-RT – for example, <strong class="source-inline">RTSanitizerCommon</strong> in the preceding code – we usually link against their <em class="italic">object files</em> rather than their library files. More specifically, we can use the <strong class="source-inline">$&lt;TARGET_OBJECTS:…&gt;</strong> directive to import supporting/utility components as one of the input sources.</p><p>iii. A sanitizer library can support multiple architectures and platforms. In Compiler-RT, we are enumerating all the supported architectures and creating a sanitizer library for each of them.</p><p>Again, the <a id="_idIndexMarker720"/>preceding snippet is just a small part of our build script. Please refer to our sample code folder for the complete <strong class="source-inline">CMakeLists.txt</strong> file.</p></li>
				<li>To <a id="_idIndexMarker721"/>successfully build the LPCSan, we still need to make some changes in Compiler-RT. The <strong class="source-inline">Base-CompilerRT.diff</strong> patch in the same code folder provides the rest of the changes that are necessary to build our sanitizer. Apply it to Compiler-RT's source tree. Here is the summary of this patch:<p>i. Changes in <strong class="source-inline">compiler-rt/cmake/config-ix.cmake</strong> basically specify the supported architectures and operating systems of the LPCSan. The <strong class="source-inline">LPCSAN_SUPPORTED_ARCH</strong> CMake variable we saw in the previous snippet comes from here.</p><p>ii. The entire <strong class="source-inline">compiler-rt/test/lpcsan</strong> folder is actually a placeholder. For some reason, having tests is a <em class="italic">requirement</em> for every sanitizer in Compiler-RT – which is different from LLVM. Therefore, we are putting an empty test folder here to pass this requirement that's being imposed by the build infrastructure.</p></li>
			</ol>
			<p>These are <a id="_idIndexMarker722"/>all the steps for producing a Compiler-RT component for our LPCSan.</p>
			<p>To just <a id="_idIndexMarker723"/>build our LPCSan library, invoke the following command:</p>
			<p class="source-code">$ ninja lpcsan</p>
			<p>Unfortunately, we can't test this LPCSan library until we've modified the compilation pipeline in Clang. In the last part of this section, we are going to learn how to achieve this task.</p>
			<h3>Adding the LPCSan to Clang</h3>
			<p>In the previous section, we learned how Compiler-RT libraries provide supplement functionalities <a id="_idIndexMarker724"/>to the target program or assist with special instrumentation, such as the sanitizer we just created. In this section, we are going to put everything together so that we can use our LPCSan simply by passing the <strong class="source-inline">-fsanitize=loop-counter</strong> flag to <strong class="source-inline">clang</strong>.</p>
			<p>Recall that in <em class="italic">Figure 12.3</em>, Compiler-RT libraries need to be linked with the program we are compiling. Also, recall that in order to insert the instrumentation code into the target program, we must run our <strong class="source-inline">LoopCounterSanitizer</strong> pass. In this section, we are going to modify the compilation pipeline in Clang so that it runs our LLVM pass at a certain time and sets up the correct configuration for our Compiler-RT library. More specifically, the following diagram shows the tasks that each component needs to complete to run our LPCSan:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B14590_12.4.jpg" alt="Figure 12.4 – Tasks for each component in the pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.4 – Tasks for each component in the pipeline</p>
			<p>Here are the descriptions for each of the numbers (enclosed in circles) in the preceding diagram:</p>
			<ol>
				<li value="1">The driver needs to recognize the <strong class="source-inline">-fsanitize=loop-counter</strong> flag.</li>
				<li>When the frontend is about to generate LLVM IR from an <strong class="bold">Abstract Syntax Tree (AST)</strong>, it needs to correctly configure the LLVM pass pipeline so that it includes the <strong class="source-inline">LoopCounterSanitizer</strong> pass.</li>
				<li>The LLVM pass pipeline needs to run our <strong class="source-inline">LoopCounterSanitizer</strong> (we don't need to worry about this task if the previous task is done correctly). </li>
				<li>The linker needs to link our Compiler-RT library to the target program.</li>
			</ol>
			<p>Although this workflow looks a little scary, don't be overwhelmed by the prospective workload – Clang can actually do most of these tasks for you, as long as you provide sufficient information. In the rest of this section, we'll show you how to implement the tasks <a id="_idIndexMarker725"/>shown in the preceding diagram to fully integrate our LPCSan into the Clang compilation pipeline (the following tutorial works inside the <strong class="source-inline">llvm-project/clang</strong> folder). Let's get started:</p>
			<ol>
				<li value="1">First, we must modify <strong class="source-inline">include/clang/Basic/Sanitizers.def</strong> to add our sanitizer:<p class="source-code">…</p><p class="source-code">// Shadow Call Stack</p><p class="source-code">SANITIZER("shadow-call-stack", ShadowCallStack)</p><p class="source-code">// Loop Counter Sanitizer</p><p class="source-code"><strong class="bold">SANITIZER("loop-counter", LoopCounter)</strong></p><p class="source-code">…</p><p>This effectively adds a new enum value, <strong class="source-inline">LoopCounter</strong>, to the <strong class="source-inline">SanitizerKind</strong> class.</p><p>It turns out that the driver will parse the <strong class="source-inline">-fsanitize</strong> command-line option and <em class="italic">automatically</em> translate <strong class="source-inline">loop-counter</strong> into <strong class="source-inline">SanitizerKind::LoopCounter</strong> based on the information we provided in <strong class="source-inline">Sanitizers.def</strong>.</p></li>
				<li>Next, let's work on the driver part. Open <strong class="source-inline">include/clang/Driver/SanitizerArgs.h</strong> and add a new utility method, <strong class="source-inline">needsLpcsanRt</strong>, to the <strong class="source-inline">SanitizerArgs</strong> class. Here is the code:<p class="source-code">bool needsLsanRt() const {…}</p><p class="source-code">bool <strong class="bold">needsLpcsanRt</strong>() const {</p><p class="source-code">  return <strong class="bold">Sanitizers.has(SanitizerKind::LoopCounter)</strong>;</p><p class="source-code">}</p><p>The utility <a id="_idIndexMarker726"/>method we created here can be used by other places in the driver to check if our sanitizer needs a Compiler-RT component.</p></li>
				<li>Now, let's navigate to the <strong class="source-inline">lib/Driver/ToolChains/CommonArgs.cpp</strong> file. Here, we're adding a few lines to the <strong class="source-inline">collectSanitizerRuntimes</strong> function. Here is the code:<p class="source-code">…</p><p class="source-code">if (SanArgs.needsLsanRt() &amp;&amp; SanArgs.linkRuntimes())</p><p class="source-code">  StaticRuntimes.push_back("lsan");</p><p class="source-code">if (<strong class="bold">SanArgs.needsLpcsanRt()</strong> &amp;&amp; SanArgs.linkRuntimes())</p><p class="source-code">  <strong class="bold">StaticRuntimes.push_back("lpcsan");</strong></p><p class="source-code">…</p><p>The preceding snippet effectively makes the linker link the correct Compiler-RT library to the target binary.</p></li>
				<li>The last change we will make to the driver is in <strong class="source-inline">lib/Driver/ToolChains/Linux.cpp</strong>. Here, we add the following lines to the <strong class="source-inline">Linux::getSupportedSanitizers</strong> method:<p class="source-code">SanitizerMask Res = ToolChain::getSupportedSanitizers();</p><p class="source-code">…</p><p class="source-code"><strong class="bold">Res |= SanitizerKind::LoopCounter;</strong></p><p class="source-code">…</p><p>The previous code is essentially telling the driver that we support the LPCSan in the current toolchain – the toolchain for Linux. Note that to simplify our example, we are <a id="_idIndexMarker727"/>only supporting the LPCSan in Linux. If you want to support this custom sanitizer in other platforms and architectures, modify the other toolchain implementations. Please refer to <a href="B14590_08_Final_JC_ePub.xhtml#_idTextAnchor108"><em class="italic">Chapter 8</em></a>, <em class="italic">Working with Compiler Flags and Toolchains</em>, for more details if needed.</p></li>
				<li>Finally, we are going to insert our <strong class="source-inline">LoopCounterSanitizer</strong> pass into the LLVM pass pipeline. Open <strong class="source-inline">lib/CodeGen/BackendUtil.cpp</strong> and add the following lines to the <strong class="source-inline">addS<a id="_idTextAnchor179"/>anitizers</strong> function:<p class="source-code">…</p><p class="source-code">// `PB` has the type of `<strong class="bold">PassBuilder</strong>`</p><p class="source-code">PB.<strong class="bold">registerOptimizerLastEPCallback</strong>(</p><p class="source-code">  [&amp;](<strong class="bold">ModulePassManager</strong> &amp;MPM, </p><p class="source-code">      PassBuilder::OptimizationLevel Level) {</p><p class="source-code">    …</p><p class="source-code">    if (<strong class="bold">LangOpts.Sanitize.has(SanitizerKind::LoopCounter)</strong>) {</p><p class="source-code">      auto FA</p><p class="source-code">       = createFunctionToLoopPassAdaptor (<strong class="bold">LoopCounterSanitizer</strong>());</p><p class="source-code">      <strong class="bold">MPM.addPass</strong>(</p><p class="source-code">         createModuleToFunctionPassAdaptor (std::move(FA)));</p><p class="source-code">    }   </p><p class="source-code">  });</p><p class="source-code">…</p><p>The enclosing folder for this file, <strong class="source-inline">CodeGen</strong>, is a place where the Clang and LLVM libraries meet. Therefore, we will see several LLVM APIs appear in this place. There are primarily two tasks for this <strong class="source-inline">CodeGen</strong> component:</p><p>a. Converting the Clang AST into its equivalent LLVM IR <strong class="source-inline">module</strong></p><p>b. Constructing an LLVM pass pipeline to optimize the IR and generate machine code</p><p>The previous snippet was trying to customize the second task – that is, customizing the LLVM Pass pipeline. The specific function – <strong class="source-inline">addSanitizers</strong> – we are <a id="_idIndexMarker728"/>modifying here is responsible for putting sanitizer passes into the pass pipeline. To have a better understanding of this code, let's focus on two of its components:</p><p>i. <strong class="source-inline">PassBuilder</strong>: This class provides predefined pass pipeline configurations for each optimization level – that is, the O0 ~ O3 notations (as well as Os and Oz for size optimization) we are familiar with. In addition to these predefined layouts, developers <a id="_idIndexMarker729"/>are free to customize the pipeline by leveraging the <strong class="bold">extension point (EP)</strong>.</p><p>An EP is a certain position in the (predefined) pass pipeline where you can insert new passes. Currently, <strong class="source-inline">PassBuilder</strong> supports several EPs, such as at the <em class="italic">beginning</em> of the pipeline, at the <em class="italic">end</em> of the pipeline, or at the end of the vectorization process, to name a few. An example of using EP can be found in the preceding code, where we used the <strong class="source-inline">PassBuilder::registerOptimizerLastEPCallback</strong> method and a lambda function to customize the EP located at the <em class="italic">end</em> of the Pass pipeline. The lambda function has two arguments: <strong class="source-inline">ModulePassManager</strong> – which represents the pass pipeline – and the current optimization level. Developers can use <strong class="source-inline">ModulePassManager::addPass</strong> to insert arbitrary LLVM passes into this EP.</p><p>ii. <strong class="source-inline">ModulePassManager</strong>: This class represents a Pass pipeline – or, more specifically, the pipeline for <strong class="source-inline">Module</strong>. There are, of course, other PassManager classes for different IR units, such as <strong class="source-inline">FunctionPassManager</strong> for <strong class="source-inline">Function</strong>. </p><p>In the <a id="_idIndexMarker730"/>preceding code, we were trying to use the <strong class="source-inline">ModulePassManager</strong> instance to insert our <strong class="source-inline">LoopCounterSanitizer</strong> pass whenever <strong class="source-inline">SanitizerKind::LoopCounter</strong> was one of the sanitizers that had been designated by the user. Since <strong class="source-inline">LoopCounterSanitizer</strong> is a loop pass rather than a module pass, we need to add some <em class="italic">adaptors</em> between the pass and PassManager. The <strong class="source-inline">createFunctionToLoopPassAdaptor</strong> and <strong class="source-inline">createModuleToFunctionPassAdaptor</strong> functions we were using here created a special instance that adapts a pass to a PassManager of a different IR unit.</p><p>This is all the program logic that supports our LPCSan in the Clang compilation pipeline.</p></li>
				<li>Last but not least, we must make a small modification to the build system. Open the <strong class="source-inline">runtime/CMakeLists.txt</strong> file and change the following CMake variable:<p class="source-code">…</p><p class="source-code">set(<strong class="bold">COMPILER_RT_RUNTIMES</strong> fuzzer asan builtins … <strong class="bold">lpcsan</strong>)</p><p class="source-code">foreach(runtime ${COMPILER_RT_RUNTIMES})</p><p class="source-code">…</p><p>The change we made to <strong class="source-inline">COMPILER_RT_RUNTIMES</strong> effectively imports our LPCSan Compiler-RT libraries into the build.</p></li>
			</ol>
			<p>These are all the steps necessary to support the LPCSan in Clang. Now, we can finally use the LPCSan in the same way we showed you at the beginning of this section:</p>
			<p class="source-code">$ clang -O1 <strong class="bold">-fsanitize=loop-counter</strong> input.c -o input</p>
			<p>In this section, we learned how to create a sanitizer. A sanitizer is a useful tool for capturing runtime behaviors without modifying the original program code. The ability to create a <a id="_idIndexMarker731"/>sanitizer increases the flexibility for compiler developers to create custom diagnosing tools tailored for their own use cases. Developing a sanitizer requires comprehensive knowledge of Clang, LLVM, and Compiler-RT: creating a new LLVM pass, making a new Compiler-RT component, and customizing the compilation pipeline in Clang. You can use the content in this section, to reinforce what you've learned in previous chapters of this book. </p>
			<p>In the last <a id="_idIndexMarker732"/>section of this chapter, we are going to look at one more instrumentation technique: <strong class="bold">PGO</strong>.</p>
			<h1 id="_idParaDest-171"><a id="_idTextAnchor180"/>Working with PGO</h1>
			<p>In the previous section, we learned how a sanitizer assists developers in performing sanity checks <a id="_idIndexMarker733"/>with higher precision using data that is only available at runtime. We also learned how to create a custom sanitizer. In this section, we will follow up on the idea of leveraging runtime data. We are going to learn an alternative use for such information – using it for compiler optimization.</p>
			<p>PGO is a technique that uses statistics that have been collected during runtime to enable more aggressive compiler optimizations. The <em class="italic">profile</em> in its name refers to the runtime data that's been collected. To give you an idea of how such data enhances an optimization, let's assume we have the following C code:</p>
			<p class="source-code">void foo(int N) {</p>
			<p class="source-code">  if (<strong class="bold">N &gt; 100</strong>)</p>
			<p class="source-code">    bar();</p>
			<p class="source-code">  else</p>
			<p class="source-code">    zoo();</p>
			<p class="source-code">}</p>
			<p>In this code, we have three functions: <strong class="source-inline">foo</strong>, <strong class="source-inline">bar</strong>, and <strong class="source-inline">zoo</strong>. The first function conditionally calls the latter two.</p>
			<p>When we try to optimize this code, the optimizer usually tries to <em class="italic">inline</em> callee functions into the caller. In this case, <strong class="source-inline">bar</strong> or <strong class="source-inline">zoo</strong> might be inlined into <strong class="source-inline">foo</strong>. However, if either <strong class="source-inline">bar</strong> or <strong class="source-inline">zoo</strong> has a large function body, inlining <em class="italic">both</em> might bloat the size of the final binary. Ideally, it will be great if we could inline only the one that executes the most frequently. Sadly, from a statistics point of view, we have no clue about which function has the highest execution frequency, because the <strong class="source-inline">foo</strong> function conditionally calls either of them based on a (non-constant) variable.</p>
			<p>With PGO, we <a id="_idIndexMarker734"/>can collect the execution frequencies of both <strong class="source-inline">bar</strong> and <strong class="source-inline">zoo</strong> at runtime and use the data to compile (and optimize) the same code <em class="italic">again</em>. The following diagram shows the high-level overview of this idea:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B14590_12.5.jpg" alt="Figure 12.5 – PGO workflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.5 – PGO workflow</p>
			<p>Here, the first compilation phase compiled and optimized the code normally. After we executed the compiled program (an arbitrary number of times), we were able to collect the profile data files. In the second compilation phase, we not only optimized the code, as we did previously, but also integrated the profile data into the optimizations to make them act more aggressively.</p>
			<p>There are <a id="_idIndexMarker735"/>primarily two ways for PGO to collect runtime profiling data: inserting <strong class="bold">instrumentation</strong> code or leveraging <strong class="bold">sampling</strong> data. Let's introduce both.</p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor181"/>Introduction to instrumentation-based PGO</h2>
			<p>Instrumentation-based PGO inserts instrumentation code into the target program during the <a id="_idIndexMarker736"/>first compilation phase. This code measures the execution frequency of the program constructions we're interested in – for example, basic blocks and functions – and writes the result in a file. This is similar to how a sanitizer works.</p>
			<p>Instrumentation-based PGO usually generates profiling data with higher precision. This is because the compiler can insert instrumentation code in a way that provides the greatest benefit for other optimizations. However, just like the sanitizer, instrumentation-based PGO changes the execution flow of the target program, which increases the risk of performance regression (for the binary that was generated from the first compilation phase).</p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor182"/>Introduction to sampling-based PGO</h2>
			<p>Sampling-based PGO uses <em class="italic">external</em> tools to collect profiling data. Developers use profilers such as <strong class="source-inline">perf</strong> or <strong class="source-inline">valgrind</strong> to diagnose performance issues. These tools usually leverage <a id="_idIndexMarker737"/>advanced system features or even hardware features to collect the runtime behavior of a program. For example, <strong class="source-inline">perf</strong> can give you insights into branch prediction and cache line misses.</p>
			<p>Since we are leveraging data from other tools, there is no need to modify the original code to collect profiles. Therefore, sampling-based PGO usually has an extremely low runtime overhead (usually, this is less than 1%). Also, we don't need to recompile the code for profiling purposes. However, profiling data that's generated in this way is usually less precise. It's also more difficult to map the profiling data back to the original code during the second compilation phase.</p>
			<p>In the rest of this section, we are going to focus on instrumentation-based PGO. We are going to learn how to leverage it with LLVM IR. Nevertheless, as we will see shortly, these two PGO strategies in LLVM share lots of common infrastructures, so the code is portable. Here is the list of topics we are going to cover:</p>
			<ul>
				<li>Working with profiling data</li>
				<li>Learning about the APIs for accessing profiling data</li>
			</ul>
			<p>The first topic <a id="_idIndexMarker738"/>will show us how to create and use instrumentation-based PGO profiles with Clang, as well as some of the tools that can help us inspect and modify profiling data. The second topic will give you more details on how to access profiling data using LLVM APIs. This is useful if you want to create your own PGO pass.</p>
			<h3>Working with profiling data</h3>
			<p>In this section, we are <a id="_idIndexMarker739"/>going to learn how to use generate, inspect, and even modify instrumentation-based profiling data. Let's start with the following example:</p>
			<p class="source-code">__attribute__((noinline))</p>
			<p class="source-code">void foo(int x) {</p>
			<p class="source-code">  if (<strong class="bold">get_random() &gt; 5</strong>)</p>
			<p class="source-code">    printf("Hello %d\n", x * 3);</p>
			<p class="source-code">}</p>
			<p class="source-code">int main(int argc, char **argv) {</p>
			<p class="source-code">  <strong class="bold">for (int i = 0; i &lt; argc + 10; ++i)</strong> {</p>
			<p class="source-code">    foo(i);</p>
			<p class="source-code">  }</p>
			<p class="source-code">  return 0;</p>
			<p class="source-code">}</p>
			<p>In the preceding code, <strong class="source-inline">get_random</strong> is a function that generates a random number from 1 to 10 with uniform distribution. In other words, the highlighted <strong class="source-inline">if</strong> statement in the <strong class="source-inline">foo</strong> function should have a 50% chance of being taken. In addition to the <strong class="source-inline">foo</strong> function, the trip count of the <strong class="source-inline">for</strong> loop within <strong class="source-inline">main</strong> depends on the number of command-line arguments there are.</p>
			<p>Now, let's try to build this code with instrumentation-based PGO. Here are the steps:</p>
			<ol>
				<li value="1">The first thing we are going to do is generate an executable for PGO profiling. Here is the command:<p class="source-code">$ clang -O1 <strong class="bold">-fprofile-generate=pgo_prof.dir</strong> pgo.cpp -o pgo</p><p>The <strong class="source-inline">-fprofile-generate</strong> option enables instrumentation-based PGO. The path that we added after this flag is the directory where profiling data will be stored.</p></li>
				<li>Next, we must <a id="_idIndexMarker740"/>run the <strong class="source-inline">pgo</strong> program with three command-line arguments:<p class="source-code">$ ./pgo `seq 1 3`</p><p class="source-code">Hello 0</p><p class="source-code">Hello 6</p><p class="source-code">…</p><p class="source-code">Hello 36</p><p class="source-code">Hello 39</p><p class="source-code">$</p><p>You might get a totally different output since there is only a 50% of chance of the string being printed.</p><p>After this, the <strong class="source-inline">pgo_prof.dir</strong> folder should contain the <strong class="source-inline">default_&lt;hash&gt;_&lt;n&gt;.profraw</strong> file, as shown here:</p><p class="source-code">$ ls pgo_prof.dir</p><p class="source-code">default_10799426541722168222_0.profraw</p><p>The <em class="italic">hash</em> in the filename is a hash that's calculated based on your code.</p></li>
				<li>We cannot directly use the <strong class="source-inline">*.profraw</strong> file for our second compilation phase. Instead, we must convert it into another kind of binary form using the <strong class="source-inline">llvm-profdata</strong> tool. Here is the command:<p class="source-code">$ llvm-profdata <strong class="bold">merge</strong> pgo_prof.dir/ -o <strong class="bold">pgo_prof.profdata</strong> </p><p><strong class="source-inline">llvm-profdata</strong> is a powerful tool for inspecting, converting, and merging profiling data files. We will look at it in more detail later. In the preceding command, we are merging and converting all the data files under <strong class="source-inline">pgo_prof.dir</strong> into a <em class="italic">single</em> <strong class="source-inline">*.profdata</strong> file.</p></li>
				<li>Finally, we can <a id="_idIndexMarker741"/>use the file we just merged for the second stage of compilation. Here is the command:<p class="source-code">$ clang -O1 <strong class="bold">-fprofile-use=pgo_prof.profdata</strong> pgo.cpp \</p><p class="source-code">        -emit-llvm -S -o pgo.after.ll</p></li>
			</ol>
			<p>Here, the <strong class="source-inline">-fprofile-use</strong> option told <strong class="source-inline">clang</strong> to use the profiling data stored in <strong class="source-inline">pgo_prof.profdata</strong> to optimize the code. We are going to look at the LLVM IR code after we've done this optimization.</p>
			<p>Open <strong class="source-inline">pgo.after.ll</strong> and navigate to the <strong class="source-inline">foo</strong> function. Here is a simplified version of <strong class="source-inline">foo</strong>:</p>
			<p class="source-code">define void @foo(i32 %x) <strong class="bold">!prof !71</strong> {</p>
			<p class="source-code">entry:</p>
			<p class="source-code">  %call = call i32 @get_random()</p>
			<p class="source-code">  %cmp = icmp sgt i32 %call, 5</p>
			<p class="source-code">  br i1 %cmp, label %if.then, label %if.end, <strong class="bold">!prof !72</strong></p>
			<p class="source-code">if.then:                                          </p>
			<p class="source-code">  %mul = mul nsw i32 %x, 3</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>In the preceding LLVM IR code, two places were different from the original IR; that is, the <strong class="source-inline">!prof</strong> tags that followed after both the function header and the branch instruction, which correspond to the <strong class="source-inline">if(get_random() &gt; 5)</strong> code we saw earlier.</p>
			<p>In LLVM IR, we can attach <strong class="bold">metadata</strong> to different IR units to provide supplementary information. Metadata will show up as a tag starting with exclamation mark (<strong class="source-inline">'!'</strong>) in the textual LLVM IR.<strong class="source-inline">!prof</strong>, <strong class="source-inline">!71</strong>, and <strong class="source-inline">!72</strong> in the preceding code are metadata tags that represent the profiling data we collected. More specifically, if we have profiling data associated with an IR unit, it always starts with <strong class="source-inline">!prof</strong>, followed by another metadata tag that contains the required values. These metadata values are put at the very bottom of the IR file. If we navigate there, we will see the content of <strong class="source-inline">!71</strong> and <strong class="source-inline">!72</strong>. Here is the code:</p>
			<p class="source-code">!71 = !{!"<strong class="bold">function_entry_count</strong>", i64 110}</p>
			<p class="source-code">!72 = !{!"<strong class="bold">branch_weights</strong>", i32 57, i32 54}</p>
			<p>These two <a id="_idIndexMarker742"/>metadata are tuples with two and three elements. <strong class="source-inline">!71</strong>, as suggested by its first element, represents the number of times the <strong class="source-inline">foo</strong> function was called (in this case, it was called 110 times).</p>
			<p>On the other hand,<strong class="source-inline">!72</strong> marks the number of times each branch in the <strong class="source-inline">if(get_random() &gt; 5)</strong> statement was taken. In this case, the true branch was taken 57 times and the false branch was taken 54 times. We got these numbers because we were using uniform distribution for random number generation (namely, a ~50% chance for each branch).</p>
			<p>In the second part of this section, we will learn how to access these values for the sake of developing a more aggressive compiler optimization. Before we do that, though, let's take a deeper look at the profiling data file we just collected.</p>
			<p>The <strong class="source-inline">llvm-profdata</strong> tool we just used can not only help us convert the format of the profiling data, but also gives us a quick preview of its content. The following command prints out the summary for <strong class="source-inline">pgo_prof.profdata</strong>, including the profiling values that were collected from every function:</p>
			<p class="source-code">$ llvm-profdata <strong class="bold">show –-all-functions –-counts</strong> pgo_prof.profdata</p>
			<p class="source-code">…</p>
			<p class="source-code">  <strong class="bold">foo:</strong></p>
			<p class="source-code">    Hash: 0x0ae15a44542b0f02</p>
			<p class="source-code">    Counters: 2</p>
			<p class="source-code">    <strong class="bold">Block counts: [54, 57]</strong></p>
			<p class="source-code">  main:</p>
			<p class="source-code">    Hash: 0x0209aa3e1d398548</p>
			<p class="source-code">    Counters: 2</p>
			<p class="source-code">    Block counts: [110, 1]</p>
			<p class="source-code">…</p>
			<p class="source-code">Instrumentation level: IR  entry_first = 0</p>
			<p class="source-code">Functions shown: 9</p>
			<p class="source-code">Total functions: 9</p>
			<p class="source-code">Maximum function count: …</p>
			<p class="source-code">Maximum internal block count: …</p>
			<p>Here, we can <a id="_idIndexMarker743"/>see the profiling data entries for each function. Each entry has a list of numbers representing the <em class="italic">execution frequency</em> of all the enclosing basic blocks.</p>
			<p>Alternatively, you can inspect the same profiling data file by converting it into a textual file first. Here is the command:</p>
			<p class="source-code">$ llvm-profdata merge <strong class="bold">–-text</strong> pgo_prof.profdata -o pgo_prof.proftext</p>
			<p class="source-code">$ cat pgo_prof.proftext</p>
			<p class="source-code"># IR level Instrumentation Flag</p>
			<p class="source-code">:ir</p>
			<p class="source-code">…</p>
			<p class="source-code"><strong class="bold">foo</strong></p>
			<p class="source-code"># Func Hash:</p>
			<p class="source-code">784007059655560962</p>
			<p class="source-code"># Num Counters:</p>
			<p class="source-code">2</p>
			<p class="source-code"><strong class="bold"># Counter Values:</strong></p>
			<p class="source-code">54</p>
			<p class="source-code">57</p>
			<p class="source-code">…</p>
			<p>The <strong class="source-inline">*.proftext</strong> file is in a human-readable textual format where all the profiling data is simply put in its own line.</p>
			<p>This textual <a id="_idIndexMarker744"/>representation can actually be converted <em class="italic">back</em> into the <strong class="source-inline">*.profdata</strong> format using a similar command. Here is an example:</p>
			<p class="source-code">$ llvm-profdata merge <strong class="bold">–-binary</strong> pgo_prof.proftext -o pgo_prof.profdata</p>
			<p>Therefore, <strong class="source-inline">*.proftext</strong> is especially useful when you want to <em class="italic">edit</em> the profiling data manually.</p>
			<p>Before we dive into the APIs for PGO, there is one more concept we need to learn about: the instrumentation level.</p>
			<h3>Understanding the instrumentation level</h3>
			<p>So far, we've <a id="_idIndexMarker745"/>learned that instrumentation-based PGO can insert instrumentation code for collecting runtime profiling data. On top of this fact, the places where we insert this instrumentation code and its <a id="_idIndexMarker746"/>granularity also matter. This property is called the <strong class="bold">instrumentation level</strong> in instrumentation-based PGO. LLVM currently supports three different instrumentation levels. Here are descriptions of each:</p>
			<ul>
				<li><strong class="bold">IR</strong>: Instrumentation code is inserted based on LLVM IR. For example, the code to collect the number of taken branches is directly inserted before a branch instruction. The <strong class="source-inline">-fprofile-generate</strong> command-line option we introduced earlier will generate profiling data with this instrumentation level. For example, let's say we have the following C code:<p class="source-code">void foo(int x) {</p><p class="source-code">  if (x &gt; 10)</p><p class="source-code">    puts("hello");</p><p class="source-code">  else</p><p class="source-code">    puts("world");</p><p class="source-code">}</p><p>The <a id="_idIndexMarker747"/>corresponding IR – without enabling instrumentation-based PGO – is shown here:</p><p class="source-code">define void @foo(i32 %0) {</p><p class="source-code">  …</p><p class="source-code">  %4 = icmp sgt i32 %3, 10</p><p class="source-code">  <strong class="bold">br i1 %4, label %5, label %7</strong></p><p class="source-code"><strong class="bold">5:</strong></p><p class="source-code">  %6 = call i32 @puts(…"hello"…)</p><p class="source-code">  br label %9</p><p class="source-code"><strong class="bold">7: </strong></p><p class="source-code">  %8 = call i32 @puts(…"world"…)</p><p class="source-code">  br label %9</p><p class="source-code">9:      </p><p class="source-code">  ret void</p><p class="source-code">}</p><p>As we can see, there is a branch to either basic block; that is, <strong class="source-inline">%5</strong> or <strong class="source-inline">%7</strong>. Now, let's generate the IR with instrumentation-based PGO enabled with the following command:</p><p class="source-code">$ clang <strong class="bold">-fprofile-generate</strong> -emit-llvm -S input.c</p><p>This is the same command we used for the first PGO compilation phase in the <em class="italic">Working with profiling data</em> section, except that we are generating LLVM IR instead <a id="_idIndexMarker748"/>of an executable. The resulting IR is shown here:</p><p class="source-code">define void @foo(i32 %0) {</p><p class="source-code">  …</p><p class="source-code">  %4 = icmp sgt i32 %3, 10</p><p class="source-code">  <strong class="bold">br i1 %4, label %5, label %9</strong></p><p class="source-code"><strong class="bold">5:</strong></p><p class="source-code">  %6 = load i64, i64* … <strong class="bold">@__profc_foo.0</strong>, align 8</p><p class="source-code">  <strong class="bold">%7 = add i64 %6, 1</strong></p><p class="source-code">  store i64 %7, i64* … <strong class="bold">@__profc_foo.0</strong>, align 8</p><p class="source-code">  %8 = call i32 @puts(…"hello"…)</p><p class="source-code">  br label %13</p><p class="source-code"><strong class="bold">9: </strong></p><p class="source-code">  %10 = load i64, i64* … <strong class="bold">@__profc_foo.1</strong>, align 8</p><p class="source-code">  <strong class="bold">%11 = add i64 %10, 1</strong></p><p class="source-code">  store i64 %11, i64* … <strong class="bold">@__profc_foo.1</strong>, align 8</p><p class="source-code">  %12 = call i32 @puts(…"world"…)</p><p class="source-code">  br label %13</p><p class="source-code">13:  </p><p class="source-code">  ret void</p><p class="source-code">}</p><p>In the preceding IR, the basic blocks in both branches have new code in them. More specifically, both increment the value in a global variable – either <strong class="source-inline">@__profc_foo.0</strong> or <strong class="source-inline">@__profc_foo.1</strong> – by one. The values in these two variables will eventually be exported as the profiling data for branches, representing the number of times each branch was taken. </p><p>This instrumentation level provides decent precision but suffers from compiler changes. More specifically, if Clang changes the way it emits LLVM IR, the places where the instrumentation code will be inserted will also be different. This effectively means that for the same input code, the profiling data that's generated with an older version of LLVM might be incompatible with the profiling data that's generated with a newer LLVM.</p></li>
				<li><strong class="bold">AST</strong>: Instrumentation code is inserted based on an AST. For example, the code to collect the number of taken branches might be inserted as a new <strong class="source-inline">Stmt</strong> AST node inside an <strong class="source-inline">IfStmt</strong> (an AST node). With this method, the instrumentation code is barely affected by compiler changes and we can have a more stable profiling data format across different compiler versions. The downside of this instrumentation level is that it has less precision than the IR instrumentation level.<p>You can <a id="_idIndexMarker749"/>adopt this instrumentation level by simply using the <strong class="source-inline">-fprofile-instr-generate</strong> command-line option in place of <strong class="source-inline">-fprofile-generate</strong> when invoking <strong class="source-inline">clang</strong> for the first compilation. You don't need to change the command for the second compilation, though. </p></li>
				<li><strong class="bold">Context-sensitive</strong>: In the <em class="italic">Working with profiling data</em> section, we learned that we could collect information about the number of times a branch has been taken. However, with the IR instrumentation level, it's nearly impossible to tell which <em class="italic">caller function</em> leads to the most branch that has been taken the most. In other words, the conventional IR instrumentation level loses the calling <em class="italic">context</em>. The context-sensitive instrumentation level tries to address this problem by collecting the profiles again once the functions have been inlined, thus creating profiling data with higher precision.<p>However, it's slightly cumbersome to use this feature in Clang – we need to compile the same code <em class="italic">three</em> times rather than twice. Here are the steps for using context-sensitive PGO:</p><p class="source-code">$ clang <strong class="bold">-fprofile-generate=first_prof</strong> foo.c -o foo_exe</p><p class="source-code">$ ./foo_exe …</p><p class="source-code">$ llvm-profdata merge first_prof -o <strong class="bold">first_prof.profdata</strong></p><p>First, generate some normal (IR instrumentation level) profiling data using what we learned in the <em class="italic">Working with profiling data</em> section:</p><p class="source-code">$ clang <strong class="bold">-fprofile-use=first_prof.profdata</strong> \</p><p class="source-code">      <strong class="bold">-fcs-profile-generate=second_prof</strong> foo.c -o foo_exe2</p><p class="source-code">$ ./foo_exe2</p><p class="source-code">$ llvm-profdata merge <strong class="bold">first_prof.profdata</strong> <strong class="bold">second_prof</strong> \</p><p class="source-code">                      -o combined_prof.profdata</p><p>Then, run <strong class="source-inline">clang</strong> with two PGO command-line options, <strong class="source-inline">-fprofile-use</strong> and <strong class="source-inline">-fcs-profile-generate</strong>, with the path to the profiling file from the previous step and the prospective <a id="_idIndexMarker750"/>output path, respectively. When we use <strong class="source-inline">llvm-profdata</strong> to do the post-processing, we are merging all the profiling data files we have:</p><p class="source-code">$ clang <strong class="bold">-fprofile-use=combined_prof.profdata</strong> \</p><p class="source-code">        foo.c -o optimized_foo</p><p>Finally, feed the combined profiling file into Clang so that it can use this context-sensitive profiling data to get a more accurate portrait of the program's runtime behavior.</p></li>
			</ul>
			<p>Note that different instrumentation levels only affect the accuracy of the profiling data; they don't affect how we <em class="italic">retrieve</em> this data, which we are going to talk about in the next section.</p>
			<p>In the last <a id="_idIndexMarker751"/>part of this section, we are going to learn how to access this profiling data inside an LLVM pass via the APIs provided by LLVM.</p>
			<h3>Learning about the APIs for accessing profiling data</h3>
			<p>In the previous section, we learned how to run the instrumentation-based PGO using Clang <a id="_idIndexMarker752"/>and view the profiling data file using <strong class="source-inline">llvm-profdata</strong>. In this section, we are going to learn how to access that data within an LLVM pass to help us develop our own PGO.</p>
			<p>Before we go into the development details, let's learn how to <em class="italic">consume</em> those profiling data files into <strong class="source-inline">opt</strong>, since it's easier to test individual LLVM pass using it. Here is a sample command:</p>
			<p class="source-code">$ opt <strong class="bold">-pgo-test-profile-file=pgo_prof.profdata</strong> \</p>
			<p class="source-code">      --passes="<strong class="bold">pgo-instr-use</strong>,my-pass…" pgo.ll …</p>
			<p>There are two keys in the preceding command:</p>
			<ul>
				<li>Use <strong class="source-inline">-pgo-test-profile-file</strong> to designate the profiling data file you want to put in.</li>
				<li>The "<strong class="source-inline">pgo-instr-use</strong>" string represents the <strong class="source-inline">PGOInstrumentaitonUse</strong> pass, which reads (instrumentation-based) profiling files and <em class="italic">annotates</em> the data on an LLVM IR. However, it is not run by default, even in the predefined optimization levels (that is, O0 ~ O3, Os, and Oz). Without this pass being ahead in the Pass pipeline, we are unable to access any profiling data. Therefore, we need to explicitly add it to the optimization pipeline. The preceding sample command demonstrated how to run it before a custom LLVM pass, <strong class="source-inline">my-pass</strong>, in the pipeline. If you want to run it before any of the predefined optimization pipelines – for instance, O1 – you must specify the <strong class="source-inline">--passes="pgo-instr-use,default&lt;O1&gt;"</strong> command-line option.</li>
			</ul>
			<p>Now, you might be wondering, what happens after the profiling data is read into <strong class="source-inline">opt</strong>? It turns out that the LLVM IR file that was generated by the <em class="italic">second</em> compilation phase – <strong class="source-inline">pgo.after.ll</strong> – has provided us with some answers to this question.</p>
			<p>In <strong class="source-inline">pgo.after.ll</strong>, we saw that some branches were <em class="italic">decorated</em> with <strong class="bold">metadata</strong> specifying the number of times they were taken. Similar metadata appeared in functions, which represented the total number of times those functions were called. </p>
			<p>More generally speaking, LLVM directly <em class="italic">combines</em> the profiling data – read from the file – with its associated IR constructions via <strong class="bold">metadata</strong>. The biggest advantage of this strategy is that we don't need to carry the raw profiling data throughout the entire optimization pipeline – the IR itself contains this profiling information.</p>
			<p>Now, the question becomes, how can we access metadata that's been attached to IR? LLVM's metadata can be attached to many kinds of IR units. Let's take a look at the most common <a id="_idIndexMarker753"/>one first: accessing metadata attached to an <strong class="source-inline">Instruction</strong>. The following code shows us how to read the profiling metadata –<strong class="source-inline">!prof !71</strong>, which we saw previously – that's attached to a branch instruction:</p>
			<p class="source-code">// `BB` has the type of `BasicBlock&amp;`</p>
			<p class="source-code">Instruction *BranchInst = BB.getTerminator();</p>
			<p class="source-code"><strong class="bold">MDNode</strong> *<strong class="bold">BrWeightMD</strong> = BranchInst-&gt;getMetadata(<strong class="bold">LLVMContext::MD_prof</strong>);</p>
			<p>In the preceding snippet, we are using <strong class="source-inline">BasicBlock::getTerminator</strong> to get the last instruction in a basic block, which is a branch instruction most of the time. Then, we tried to retrieve the profiling metadata with the <strong class="source-inline">MD_prof</strong> metadata. <strong class="source-inline">BrWeightMD</strong> is the result we are looking for.</p>
			<p>The type of <strong class="source-inline">BrWeightMD</strong>, <strong class="source-inline">MDNode</strong>, represents a single metadata node. Different <strong class="source-inline">MDNode</strong> instances can be <em class="italic">composed</em> together. More specifically, a <strong class="source-inline">MDNode</strong> instance can use other <strong class="source-inline">MDNode</strong> instances as its operands – similar to the <strong class="source-inline">Value</strong> and <strong class="source-inline">User</strong> instances we saw in <a href="B14590_10_Final_JC_ePub.xhtml#_idTextAnchor141"><em class="italic">Chapter 10</em></a>, <em class="italic">Processing LLVM IR</em>. The compound <strong class="source-inline">MDNode</strong> can express more complex concepts.</p>
			<p>For example, in this case, each operand in <strong class="source-inline">BrWeightMD</strong> represents the number of times each branch was taken. Here is the code to access them:</p>
			<p class="source-code">if (BrWeightMD-&gt;getNumOperands() &gt; 2) {</p>
			<p class="source-code">  // Taken counts for true branch</p>
			<p class="source-code">  <strong class="bold">MDNode</strong> *TrueBranchMD = BrWeightMD-&gt;<strong class="bold">getOperand</strong>(1);</p>
			<p class="source-code">  // Taken counts for false branch</p>
			<p class="source-code">  <strong class="bold">MDNode</strong> *FalseBranchMD = BrWeightMD-&gt;getOperand(2);</p>
			<p class="source-code">}</p>
			<p>As you can see, the taken counts are also expressed as <strong class="source-inline">MDNode</strong>. </p>
			<p class="callout-heading">Operand indices for both branches</p>
			<p class="callout">Note that the data for both branches is placed at the operands starting from index 1 rather than index 0.</p>
			<p>If we <a id="_idIndexMarker754"/>want to convert these branch <strong class="source-inline">MDNode</strong> instances into constants, we can leverage a small utility provided by the <strong class="source-inline">mdconst</strong> namespace. Here is an example:</p>
			<p class="source-code">if (BrWeightMD-&gt;getNumOperands() &gt; 2) {</p>
			<p class="source-code">  // Taken counts for true branch</p>
			<p class="source-code">  MDNode *TrueBranchMD = BrWeightMD-&gt;getOperand(1);</p>
			<p class="source-code">  <strong class="bold">ConstantInt</strong> *NumTrueBrTaken</p>
			<p class="source-code">    = <strong class="bold">mdconst::dyn_extract&lt;ConstantInt&gt;</strong>(TrueBranchMD);</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The previous code <em class="italic">unwrapped</em> an <strong class="source-inline">MDNode</strong> instance and extracted the underlying <strong class="source-inline">ConstantInt</strong> instance. </p>
			<p>For <strong class="source-inline">Function</strong>, we can get the number of times it was called in an even easier way. Here is the code:</p>
			<p class="source-code">// `F` has the type of `Function&amp;`</p>
			<p class="source-code"><strong class="bold">Function::ProfileCount</strong> EntryCount = F.getEntryCount();</p>
			<p class="source-code">uint64_t EntryCountVal = EntryCount.<strong class="bold">getCount</strong>();</p>
			<p><strong class="source-inline">Function</strong> is using a slightly different way to present its called frequency. But retrieving the numerical profiling value is still pretty easy, as shown in the preceding snippet.</p>
			<p>It is worth noting that although we only focused on instrumentation-based PGO here, for <em class="italic">sampling</em>-based PGO, LLVM also uses the same programming interface to expose its data. In other words, even if you're using profiling data that's been collected from sampling tools with a different <strong class="source-inline">opt</strong> command, the profiling data will also be annotated on IR units and you can still access it using the aforementioned method. In fact, the tools and APIs we are going to introduce in the rest of this section are mostly profiling-data-source agnostic.</p>
			<p>So far, we have been dealing with real values that have been retrieved from the profiling data. However, these low-level values cannot help us go far in terms of developing a compiler <a id="_idIndexMarker755"/>optimization or program analysis algorithm – usually, we are more interested in high-level concepts such as "functions that are executed <em class="italic">most frequently</em>" or "branches that are <em class="italic">least taken</em>". To address these demands, LLVM builds several analyses on top of profiling data to deliver such high-level, structural information.</p>
			<p>In the next section, we are going to introduce some of these analyses and their usages in LLVM Pass.</p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor183"/>Using profiling data analyses</h2>
			<p>In this section, we are <a id="_idIndexMarker756"/>going to learn three analysis classes that can help us reason about the execution frequency of basic blocks and functions at runtime. They are as follows:</p>
			<ul>
				<li><strong class="source-inline">BranchProbabilityInfo</strong></li>
				<li><strong class="source-inline">BlockFrequencyInfo</strong></li>
				<li><strong class="source-inline">ProfileSummaryInfo</strong></li>
			</ul>
			<p>This list is ordered by their analyzing scope in the IR – from local to global. Let's start with <a id="_idIndexMarker757"/>the first two.</p>
			<h3>Using BranchProbabilityInfo and BlockFrequencyInfo</h3>
			<p>In the <a id="_idIndexMarker758"/>previous <a id="_idIndexMarker759"/>section, we <a id="_idIndexMarker760"/>learned how to access the profiling metadata that's attached to each branch instruction – the <strong class="bold">branch weight</strong>. The analysis <a id="_idIndexMarker761"/>framework in LLVM provides you with an even easier way to access these values via the <strong class="source-inline">BranchProbabilityInfo</strong> class. Here is some example code showing how to use it in a (function) Pass:</p>
			<p class="source-code">#include "llvm/Analysis/BranchProbabilityInfo.h"</p>
			<p class="source-code">PreservedAnalyses run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p>
			<p class="source-code">  <strong class="bold">BranchProbabilityInfo</strong> &amp;BPI</p>
			<p class="source-code">    = FAM.getResult&lt;<strong class="bold">BranchProbabilityAnalysis</strong>&gt;(F);</p>
			<p class="source-code">  BasicBlock *Entry = F.getEntryBlock();</p>
			<p class="source-code">  BranchProbability BP = BPI.<strong class="bold">getEdgeProbability</strong>(Entry, 0);</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The previous code retrieved a <strong class="source-inline">BranchProbabilityInfo</strong> instance, which is the result of <strong class="source-inline">BranchProbabilityAnalysis</strong>, and tried to get the weight from the entry block to its first successor block.</p>
			<p>The returned <a id="_idIndexMarker762"/>value, a <strong class="source-inline">BranchProbability</strong> instance, gives <a id="_idIndexMarker763"/>you the branch's probability <a id="_idIndexMarker764"/>in the form of a percentage. You <a id="_idIndexMarker765"/>can use <strong class="source-inline">BranchProbability::getNumerator</strong> to retrieve the value (the "denominator" is 100 by default). The <strong class="source-inline">BranchProbability</strong> class also provides some handy utility methods for performing arithmetic between two branch probabilities or scaling the probability by a specific factor. Although we can easily tell which branch is more likely to be taken using <strong class="source-inline">BranchProbabilityInfo</strong>, without additional data, we can't tell the branch's probability (to be taken) in the <em class="italic">whole function</em>. For example, let's assume we have the following CFG:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B14590_12.6.jpg" alt="Figure 12.6 – CFG with nested branches&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.6 – CFG with nested branches</p>
			<p>For the preceding diagram, we have profiling counter values for the following basic blocks:</p>
			<ul>
				<li><strong class="bold">if.then4</strong>: 2</li>
				<li><strong class="bold">if.else</strong>: 10</li>
				<li><strong class="bold">if.else7</strong>: 20</li>
			</ul>
			<p>If we <em class="italic">only</em> look at the branch weight metadata toward blocks <strong class="source-inline">if.then4</strong> and <strong class="source-inline">if.else</strong> – that is, the true and false branches for <strong class="source-inline">if.then</strong>, respectively – we might come under the <em class="italic">illusion</em> that the <strong class="source-inline">if.else</strong> block has a ~83% chance of being taken. But the truth is, it only has a ~31% chance because the control flow has a higher probability to go into <strong class="source-inline">if.else7</strong> before even <a id="_idIndexMarker766"/>entering the <strong class="source-inline">if.then</strong> region. Of <a id="_idIndexMarker767"/>course, in this case, we can do simple math to <a id="_idIndexMarker768"/>figure out the correct answer, but when the CFG is <a id="_idIndexMarker769"/>getting bigger and more complex, we might have a hard time doing this by ourselves.</p>
			<p>The <strong class="source-inline">BlockFrequencyInfo</strong> class provides a shortcut to this problem. It can tell us the frequency of each basic block to be taken under the context of its enclosing function. Here is an example of its usage in a Pass:</p>
			<p class="source-code">#include "llvm/Analysis/BlockFrequencyInfo.h"</p>
			<p class="source-code">PreservedAnalyses run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p>
			<p class="source-code">  <strong class="bold">BlockFrequencyInfo</strong> &amp;BFI</p>
			<p class="source-code">    = FAM.getResult&lt;<strong class="bold">BlockFrequencyAnalysis</strong>&gt;(F);</p>
			<p class="source-code">  for (BasicBlock *BB : F) {</p>
			<p class="source-code">    <strong class="bold">BlockFrequency</strong> BF = BFI.<strong class="bold">getBlockFreq</strong>(BB);</p>
			<p class="source-code">  }</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The previous code retrieved a <strong class="source-inline">BlockFrequencyInfo</strong> instance, which is the result of <strong class="source-inline">BlockFrequencyAnalysis</strong>, and tried to evaluate the block frequency of each basic block in the function.</p>
			<p>Similar to the <strong class="source-inline">BranchProbability</strong> class, <strong class="source-inline">BlockFrequency</strong> also provides nice utility methods to calculate with other <strong class="source-inline">BlockFrequency</strong> instances. But different from <strong class="source-inline">BranchProbability</strong>, the numeric value that's retrieved from <strong class="source-inline">BlockFrequency</strong> is not presented <a id="_idIndexMarker770"/>as a percentage. More <a id="_idIndexMarker771"/>specifically, <strong class="source-inline">BlockFrequency::getFrequency</strong> returns an integer that is the frequency <em class="italic">relative</em> to the entry <a id="_idIndexMarker772"/>block of the current function. In other words, to get <a id="_idIndexMarker773"/>a percentage-based frequency, we can use the following snippet:</p>
			<p class="source-code">// `BB` has the type of `BasicBlock*`</p>
			<p class="source-code">// `Entry` has the type of `BasicBlock*` and represents entry // block</p>
			<p class="source-code">BlockFrequency BBFreq = BFI.getBlockFreq(BB),</p>
			<p class="source-code">               EntryFreq = BFI.getBlockFreq(Entry);</p>
			<p class="source-code">auto <strong class="bold">FreqInPercent</strong></p>
			<p class="source-code">  = (BBFreq.<strong class="bold">getFrequency</strong>() / EntryFreq.<strong class="bold">getFrequency</strong>()) * 100;</p>
			<p>The highlighted <strong class="source-inline">FreqInPercent</strong> is the block frequency of <strong class="source-inline">BB</strong>, expressed as a percentage.</p>
			<p><strong class="source-inline">BlockFrequencyInfo</strong> calculates the frequency of a specific basic block under the context of a function – but what about the entire <em class="italic">module</em>? More specifically, if we bring a <strong class="bold">call graph</strong> into this situation, can we multiply the block frequency we just learned with the <a id="_idIndexMarker774"/>frequency of the enclosing function being called, in order to get the execution frequency in the <em class="italic">global</em> scope? Fortunately, LLVM has prepared a useful class to answer this question – <strong class="source-inline">ProfileSummaryInfo</strong>.</p>
			<h3>Using ProfileSummaryInfo</h3>
			<p>The <strong class="source-inline">ProfileSummaryInfo</strong> class gives you a global view of all the profiling data in a <strong class="source-inline">Module</strong>. Here <a id="_idIndexMarker775"/>is an example of retrieving <a id="_idIndexMarker776"/>an instance of it inside a module Pass:</p>
			<p class="source-code">#include "llvm/Analysis/ProfileSummaryInfo.h"</p>
			<p class="source-code">PreservedAnalyses run(Module &amp;M, ModuleAnalysisManager &amp;MAM) {</p>
			<p class="source-code">  <strong class="bold">ProfileSummaryInfo</strong> &amp;PSI = MAM.  getResult&lt;<strong class="bold">ProfileSummaryAnalysis</strong>&gt;(M);</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p><strong class="source-inline">ProfileSummaryInfo</strong> provides <a id="_idIndexMarker777"/>a wide variety of functionalities. Let's take a look at three of its most interesting methods:</p>
			<ul>
				<li><strong class="source-inline">isFunctionEntryCold/Hot(Function*)</strong>: These two methods compare the entry count of a <strong class="source-inline">Function</strong> – which effectively reflects the number of times a function was called –against that of other functions in the same module and tell us if the inquiry function is ranking high or low in this metric.</li>
				<li><strong class="source-inline">isHot/ColdBlock(BasicBlock*, BlockFrequencyInfo&amp;)</strong>: These two methods work similarly to the previous bullet one but compare the execution frequency of a <strong class="source-inline">BasicBlock</strong> against <em class="italic">all</em> the other blocks in the module.</li>
				<li><strong class="source-inline">isFunctionCold/HotInCallGraph(Function*, BlockFrequencyInfo&amp;)</strong>: These two methods combine the methods from the previous two bullet points they can tell you whether a function is considered hot or cold based on its entry count or the execution frequency of its enclosing basic blocks. This is useful when a function has a low entry count – that is, it was not called often – but contains a <em class="italic">loop</em> that has extremely a high basic block execution frequency. In this case, the <strong class="source-inline">isFunctionHotInCallGraph</strong> method can give us a more accurate assessment.</li>
			</ul>
			<p>These APIs also have variants where you can designate the cutoff point as being "hot" or "cold." Please refer to the API documentation for more information.</p>
			<p>For a long time, the compiler was only able to analyze and optimize the source code with a static view. For dynamic factors inside a program – for instance, the branch taken count – compilers could only make an approximation. PGO opened an alternative path to provide <a id="_idIndexMarker778"/>extra information for compilers <a id="_idIndexMarker779"/>to peek into the target program's runtime behavior, for the sake of making less ambiguous and more aggressive decisions. In this section, we learned how to collect and use runtime profiling information – the key to PGO – with LLVM. We learned how to use the related infrastructure in LLVM to collect and generate such profiling data. We also learned about the programming interface we can use to access that data – as well as some high-level analyses built on top of it – to assist our development inside an LLVM Pass. With these abilities, LLVM developers can plug in this runtime information to further improve the quality and precision of their existing optimization Passes.</p>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor184"/>Summary</h1>
			<p>In this chapter, we <em class="italic">augmented</em> the workspace of the compiler by processing the static source code and capturing the program's runtime behaviors. In the first part of this chapter, we learned how to use the infrastructure provided by LLVM to create a sanitizer – a technique that inserts instrumentation code into the target program for the sake of checking certain runtime properties. By using a sanitizer, software engineers can improve their development quality with ease and with high precision. In the second part of this chapter, we extended the usages of such runtime data to the domain of compiler optimization; PGO is a technique that uses dynamic information, such as the execution frequency of basic blocks or functions, to make more aggressive decisions for optimizing the code. Finally, we learned how to access such data with an LLVM Pass, which enables us to add PGO enhancement to existing optimizations.</p>
			<p>Congratulations, you've just finished the last chapter! Thank you so much for reading this book. Compiler development has never been an easy subject – if not an obscure one – in computer science. In the past decade, LLVM has significantly lowered the difficulties of this subject by providing robust yet flexible modules that fundamentally change how people think about compilers. A compiler is not just a single executable such as <strong class="source-inline">gcc</strong> or <strong class="source-inline">clang</strong> anymore – it is a collection of building blocks that provide developers with <em class="italic">countless</em> ways to create tools to deal with hard problems in the programming language field.</p>
			<p>However, with so many choices, I often became lost and confused when I was still a newbie to LLVM. There was documentation for every single API in this project, but I had no idea how to put them together. I wished there was a book that pointed in the general direction of each important component in LLVM, telling me <em class="italic">what</em> it is and <em class="italic">how</em> I can take advantage of it. And here it is, the book I wished I could have had at the beginning of my LLVM career – the book you just finished – come to life. I hope you won't stop your expedition of LLVM after finishing this book. To improve your skills even further and reinforce what you've learned from this book, I recommend you to check out the official document pages (<a href="https://llvm.org/docs">https://llvm.org/docs</a>) for content that complements this book. More importantly, I encourage you to participate in the LLVM community via either their mailing list (<a href="https://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-dev">https://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-dev</a>) or Discourse forum (https://llvm.discourse.group/), especially the first one – although a mailing list might sound old-school, there are many talented people there willing to answer your questions and provide useful learning resources. Last but not least, annual LLVM dev meetings (<a href="https://llvm.org/devmtg/">https://llvm.org/devmtg/</a>), in both the United States and Europe, are some of the best events where you can learn new LLVM skills and chat face-to-face with people who literally built LLVM.</p>
			<p>I hope this book enlightened you on your path to mastering LLVM and helped you find joy in crafting compilers.</p>
		</div>
	</body></html>