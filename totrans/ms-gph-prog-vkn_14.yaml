- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding Dynamic Diffuse Global Illumination with Ray Tracing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, illumination has been based on direct lighting coming from
    point lights. In this chapter, we will enhance lighting by adding indirect lighting,
    often referred to as global illumination in the context of video games.
  prefs: []
  type: TYPE_NORMAL
- en: This type of illumination comes from emulating the behavior of light. Without
    going into quantum physics and optics, the information we need to consider is
    that light bounces off surfaces a few times until its energy becomes zero.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout movies and video games, global illumination has always been an important
    aspect of lighting, but often impossible to perform in real time.
  prefs: []
  type: TYPE_NORMAL
- en: With movies, it often took minutes (if not hours) to render a single frame,
    until global illumination was pioneered. Video games were inspired by this and
    now include it in their lighting.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discover how to implement real-time global illumination
    by covering these topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to indirect lighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to **Dynamic Diffuse Global** **Illumination** (**DDGI**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing DDGI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each topic will contain subsections so that you can expand upon the knowledge
    provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows how the code from this chapter helps contribute
    to indirect lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Indirect lighting output](img/B18395_14_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – Indirect lighting output
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 14**.1*, the scene has a point light on the left. We can see the
    green color from the light bouncing off the left curtain onto the floor and the
    right pillars and curtains.
  prefs: []
  type: TYPE_NORMAL
- en: On the floor in the distance, we can see the color of the sky tinting the walls.
    The occlusion given by its visibility provides a very low light contribution to
    the arches.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter14](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter14).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to indirect lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Going back to direct and indirect lighting, direct lighting just shows the first
    interaction between light and matter, but light continues to travel in space,
    bouncing at times.
  prefs: []
  type: TYPE_NORMAL
- en: From a rendering perspective, we use the G-buffer information to calculate the
    first light interaction with surfaces that are visible from our point of view,
    but we have little data on what is outside of our view.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows direct lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Direct lighting](img/B18395_14_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Direct lighting
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.2* describes the current lighting setup. There are light-emitting
    rays, and those rays interact with surfaces. Light bounces off these surfaces
    and is captured by the camera, becoming the pixel color. This is an extremely
    simplified vision of the phenomena, but it contains all the basics we need.'
  prefs: []
  type: TYPE_NORMAL
- en: For indirect lighting, relying only on the camera’s point of view is insufficient
    as we need to calculate how other lights and geometries can contribute and still
    affect the visible part of the scene but are outside of the view, as well as the
    visible surfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this matter, **ray tracing** is the best tool: it’s a way to query the
    scene spacially as we can use it to calculate how different bounces of light contribute
    to the final value of a given fragment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a diagram showing indirect lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Indirect lighting](img/B18395_14_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Indirect lighting
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.3* shows indirect rays bouncing off surfaces until they hit the
    camera again.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two rays highlighted in this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Indirect Ray 0**, bouncing off a hidden surface onto the blue floor and finally
    into the camera'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Indirect Ray 0**, bouncing off another surface and bouncing off the red wall,
    and finally into the camera'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With indirect illumination, we want to capture the phenomena of rays of light
    bouncing off surfaces, both hidden and not.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in this setup, there are some rays between the red and blue surfaces
    that will bounce within each other, tinting the closer parts of the surfaces of
    the respective colors.
  prefs: []
  type: TYPE_NORMAL
- en: Adding indirect illumination to lighting enhances the realism and visual quality
    of the image, but how can we achieve that?
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will talk about the implementation that we chose: **Dynamic
    Diffuse Global Illumination**, or **DDGI**, which was developed mainly by researchers
    at Nvidia but is rapidly becoming one of the most used solutions in AAA games.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Dynamic Diffuse Global Illumination (DDGI)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will explain the algorithm behind DDGI. DDGI is based on
    two main tools: light probes and irradiance volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Light probes** are points in space, represented as spheres, that encode light
    information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Irradiance volumes** are defined as spaces that contain three-dimensional
    grids of light probes with fixed spacing between them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling is easier when the layout is regular, even though we will see some
    improvements to placements later. Probes are encoded using octahedral mapping,
    a convenient way to map a square to a sphere. Links to the math behind octahedral
    mapping have been provided in the *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea behind DDGI is to dynamically update probes using ray tracing:
    for each probe, we will cast some rays and calculate the radiance at the triangle
    intersection. Radiance is calculated with the dynamic lights present in the engine,
    reacting in real time to any light or geometry changes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the low resolution of the grid compared to the pixels on the screen,
    the only lighting phenomenon possible is diffuse lighting. The following diagram
    provides an overview of the algorithm, showing the relationships and the sequences
    between shaders (green rectangles) and textures (yellow ellipses):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.4 – Algorithm overview](img/B18395_14_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Algorithm overview
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s provide a quick overview of the algorithm before looking at each step
    in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform ray tracing for each probe and calculate the radiance and distance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the irradiance of all probes with the radiance calculated while applying
    some hysteresis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the visibility data of all probes with the distance calculated in the
    ray tracing pass, again with some hysteresis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Optional) Calculate the per-probe offset position using the ray tracing distance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate indirect lighting by reading the updated irradiance, visibility, and
    probe offsets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following subsections, we will cover each step of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Ray tracing for each probe
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the first step of the algorithm. For each ray of each probe that needs
    an update, we must ray trace the scene using dynamic lighting.
  prefs: []
  type: TYPE_NORMAL
- en: In the ray tracing hit shader, we calculate the world position and normal of
    the hit triangle and perform a simplified diffuse lighting calculation. Optionally,
    but more expensive, we can read the other irradiance probes to add an infinite
    number of bounces to the lighting calculation, giving it an even more realistic
    look.
  prefs: []
  type: TYPE_NORMAL
- en: 'Especially important here is the texture layout: each row represents the rays
    for a single probe. So, if we have 128 rays per probe, we will have a row of 128
    texels, while each column represents a probe.'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, a configuration with 128 rays and 24 probes will result in a 128x24 texture
    dimension. We store the lighting calculation as radiance in the RGB channels of
    the texture, and the hit distance in the Alpha channel.
  prefs: []
  type: TYPE_NORMAL
- en: Hit distance will be used to help with light leaks and calculating probe offsets.
  prefs: []
  type: TYPE_NORMAL
- en: Probes offsetting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Probes offsetting is a step that’s done when an irradiance volume is loaded
    into the world, or its properties are changed (such as spacing or position). Using
    the hit distances from the ray tracing step, we can calculate if a probe is placed
    straight into a surface and then create an offset for it.
  prefs: []
  type: TYPE_NORMAL
- en: The offsetting amount cannot be bigger than half the distance to other probes
    so that the grid still maintains some coherency between the grid indices and their
    position. This step is only done a few times (normally, around five is a suitable
    number) as having it run continuously will indefinitely move the probes, thus
    causing light flickering.
  prefs: []
  type: TYPE_NORMAL
- en: Once the offsets have been calculated, every probe will have the final world
    position, drastically increasing the visual quality of indirect lighting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see the improvement after calculating these offsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 14.5 – Global illumination with (left) and without (right) probe
    offsets](img/B18395_14_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Global illumination with (left) and without (right) probe offsets
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the probes that are inside a geometry not only give no lighting
    contribution to the sampling but can create visual artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to probe offsetting, we can place probes in a better position.
  prefs: []
  type: TYPE_NORMAL
- en: Probes irradiance and visibility updates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have the result of each ray that’s been traced for each probe with dynamic
    lighting applied. How can we encode this information? As seen in the *Introduction
    to Dynamic Diffuse Global Illumination (DDGI)* section, one of the ways is to
    use octahedral mapping, which unwraps a sphere into a rectangle.
  prefs: []
  type: TYPE_NORMAL
- en: Given that we are storing each probe’s radiance as a 3D volume, we need a texture
    that contains a rectangle for each probe. We will choose to create a single texture
    with a row that contains a *layer* of probes as MxN, while the height contains
    the other layers.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we have a grid of 3x2x4 probes, each row will contain 6 probes
    (3x2) and the final texture will have 4 rows. We will execute this step two times,
    one to update the irradiance from the radiance, and the other to update the visibility
    from the distance of each probe.
  prefs: []
  type: TYPE_NORMAL
- en: Visibility is crucial for minimizing light leaks, and irradiance and visibility
    are stored in different textures and can have different sizes.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to be aware of is that to add support for bilinear filtering, we need
    to store an additional 1-pixel border around each rectangle; this will be updated
    here as well.
  prefs: []
  type: TYPE_NORMAL
- en: The shader will read the new radiance and distances calculated and the previous
    frame’s irradiance and visibility textures to blend the values to avoid flickering,
    as Volumetric Fog does with temporal reprojection, using a simple hysteresis.
  prefs: []
  type: TYPE_NORMAL
- en: Hysteresis can be changed dynamically if the lighting conditions change drastically
    to counteract slow updates using hysteresis. The results will normally be slower
    to react to light movements, but it is a drawback needed to avoid flickering.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last part of the shader involves updating the borders for bilinear filtering.
    Bilinear filtering requires samples to be read in a specific order, as highlighted
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Bilinear filtering samples. The outer grid copies pixels from
    the written pixel positions inside each rectangle](img/B18395_14_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.6 – Bilinear filtering samples. The outer grid copies pixels from
    the written pixel positions inside each rectangle
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 14**.6* shows the coordinate calculations for copying pixels: the center
    area is the one that did the full irradiance/visibility update, while the borders
    copy the values from the pixels at the specified coordinates.'
  prefs: []
  type: TYPE_NORMAL
- en: We will run two different shaders – one to update probe irradiance and one to
    update probe visibility.
  prefs: []
  type: TYPE_NORMAL
- en: In the shader code, we will see the actual code to do this. We are now ready
    to sample the irradiance of the probes, as seen in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Probes sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step involves reading the irradiance probes and calculating the indirect
    lighting contribution. We will render from the main camera’s point of view, and
    we will sample the eight closest probes given a world position and direction.
    The visibility texture is used to minimize leakage and soften the lighting results.
  prefs: []
  type: TYPE_NORMAL
- en: Given the soft lighting nature of diffuse indirect components and to obtain
    better performance, we have opted to sample this at a quarter resolution, so we
    need to take extra care of where we sample to avoid pixel inaccuracies.
  prefs: []
  type: TYPE_NORMAL
- en: While looking at probe ray tracing, irradiance updates, visibility updates,
    probe offsetting, and probe sampling, we described all the basic steps necessary
    to have a working DDGI implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Other steps can be included to make the rendering even faster, such as using
    the distances to calculate inactive probes. Other extensions can also be included,
    such as those that contain a cascade of volumes and hand-placed volumes that give
    DDGI the best flexibility needed to be used in video games, where different hardware
    configurations can dictate algorithmic choices.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to implement DDGI.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing DDGI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first shaders we will read are the ray tracing shaders. These, as we saw
    in [*Chapter 12*](B18395_12.xhtml#_idTextAnchor205), *Getting Started with Ray
    Tracing*, come as a bundle that includes the ray-generation, ray-hit, and ray-miss
    shaders.
  prefs: []
  type: TYPE_NORMAL
- en: There are a set of different methods that convert from world space into grid
    indices and vice versa that will be used here; they are included with the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we want to define the ray payload – that is, the information that’s
    cached after the ray tracing query is performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Ray-generation shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first shader is called ray-generation. It spawns rays from the probe’s position
    using random directions on a sphere using spherical Fibonacci sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like dithering for TAA and Volumetric Fog, using random directions and temporal
    accumulation (which happens in the Probe Update shader) allows us to have more
    information about the scene, thus enhancing the visuals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Ray-hit shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is where all the heavy lifting happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must declare the payload and the barycentric coordinates to calculate
    the correct triangle data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, check for back-facing triangles, storing only the distance as lighting
    is not needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, calculate the triangle data and perform lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, read the mesh instance data and read the index buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can read the vertices from the mesh buffer and calculate the world
    space position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the world position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As we did for the vertex positions, read the UV buffer and calculate the final
    UVs of the triangle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Read the diffuse texture. We can also read a lower MIP to improve performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Read the triangle normals and calculate the final normal. You don’t need to
    read the normal texture as the cached result is so small that those details are
    lost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can calculate the world position and the normal, and then calculate the
    direct lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can cache the radiance and the distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s write the results to the payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Ray-miss shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this shader, we simply return the sky color. Alternatively, if present,
    an environment cube map can be added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Updating probes irradiance and visibility shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This compute shader will read the previous frame’s irradiance/visibility and
    the current frame’s radiance/distance and update the octahedral representation
    of each probe. This shader will be executed twice – once to update the irradiance
    and once to update the visibility. It will also update the borders to add support
    for bilinear filtering.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must check if the current pixel is a border. If so, we must change
    modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'For non-border pixels, calculate a weight based on ray direction and the direction
    of the sphere encoded with octahedral coordinates, and calculate the irradiance
    as the summed weight of the radiances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the contribution from each ray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Read the distance for this ray and early out if there are too many back faces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: At this point, depending on if we are updating the irradiance or the visibility,
    we perform different calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For **irradiance**, we must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'For **visibility**, we must read and limit the distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, apply the weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can read the previous frame’s irradiance or visibility and blend it
    using hysteresis.
  prefs: []
  type: TYPE_NORMAL
- en: 'For **irradiance**, we must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'For **visibility**, we must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we end the shader for non-border pixels. We will wait for the
    local group to finish and copy the pixels to the borders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Next, we must operate on the border pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Given that we are working on a local thread group that’s as big as each square,
    when a group is finished, we can copy the border pixels with the currently updated
    data. This is an optimization process that helps us avoid dispatching two other
    shaders and adding barriers to wait for the updates to be done.
  prefs: []
  type: TYPE_NORMAL
- en: 'After implementing the preceding code, we must wait for the group to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Once those barriers are in the shader code, all the groups will be completed.
  prefs: []
  type: TYPE_NORMAL
- en: We have the final irradiance/visibility stored in the texture, so we can copy
    the border pixels to add bilinear sampling support. As shown in *Figure 14**.6*,
    we need to read the pixels in a specific order to ensure bilinear filtering is
    working properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must calculate the source pixel coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Next, we must copy the source pixels to the current border.
  prefs: []
  type: TYPE_NORMAL
- en: 'For **irradiance**, we must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'For **visibility**, we must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We now have the updated irradiance and visibility ready to be sampled by the
    scene.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect lighting sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This compute shader is responsible for reading the indirect irradiance so that
    it’s ready to be used by the illumination. It uses a utility method called `sample_irradiance`,
    which is also used inside the ray-hit shader to simulate an infinite bounce.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, though, let’s look at the compute shader. When using the quarter resolution,
    cycle through a neighborhood of 2x2 pixels and get the closest depth, and save
    the pixel index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'With the cached index of the closest depth, read the normal as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have calculated the depth and the normal, we can gather the world
    position and use the normal to sample the irradiance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The second part of this shader is about the `sample_irradiance` function, which
    does the actual heavy lifting.
  prefs: []
  type: TYPE_NORMAL
- en: 'It starts by calculating a bias vector to move the sampling so that it’s a
    little bit in front of the geometry, to help with leaks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We now have the grid world position and indices at the sampling world position
    (plus the bias).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we must calculate a per-axis value of where the sampling position is within
    the cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we can sample the eight adjacent probes to the sampling point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'For each probe, we must calculate its world space position from the indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the trilinear weights based on the grid cell vertex to smoothly transition
    between probes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can see how the visibility texture is used. It stores depth and depth
    squared values, and helps tremendously with light leaking.
  prefs: []
  type: TYPE_NORMAL
- en: 'This test is based on variance, such as Variance Shadow Map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Check if the sampled probe is in “shadow” and calculate the Chebyshev weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'With the weight calculated for this probe, we can apply the trilinear offset,
    read the irradiance, and calculate its contribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'With all the probes sampled, the final irradiance is scaled accordingly and
    returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: With that, we’ve finished looking at the irradiance sampling compute shader
    and utility functions.
  prefs: []
  type: TYPE_NORMAL
- en: More filters can be applied to the sampling to further smooth the image, but
    this is the most basic version that’s enhanced by the visibility data.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn how the `calculate_lighting` method can be modified to add
    diffuse indirect.
  prefs: []
  type: TYPE_NORMAL
- en: Modifications to the calculate_lighting method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our `lighting.h` shader file, add the following lines once the direct lighting
    computations have been done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Here, `base_colour` is the albedo coming from the G-buffer and `final_color`
    is the pixel color with all the direct lighting contributions calculated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic algorithm is complete, but there is one last shader to have a look
    at: the Probe Offset shader. It calculates a per-probe world-space offset to avoid
    intersecting probes with geometries.'
  prefs: []
  type: TYPE_NORMAL
- en: Probe offsets shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This compute shader cleverly uses the per-ray distances coming from the ray
    tracing pass to calculate the offset based on backface and frontface counts.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must check for an invalid probe index to avoid writing to the wrong
    memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Now, we must search for front and backface hits based on the ray tracing distance
    that’s been calculated.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, declare all the necessary variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'For each ray of this probe, read the distance and calculate if it is a front
    or backface. We store negative distances for backfaces in the hit shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We know the front and backface indices and distances for this probe. Given
    that we incrementally move the probe, read the previous frame’s offset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we must check if the probe can be considered inside a geometry and calculate
    an offset moving away from that direction, but within the probe spacing limit,
    that we can call a `cell`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Find the maximum offset inside the cell to move the probe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have not hit a backface, we must move the probe slightly to put it in
    a resting position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the offset only if it is within the spacing or inside the cell limits.
    Then, store the value in the appropriate texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have calculated the probe offsets.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this shader demonstrates how to cleverly use information you already
    have – in this case, the per-ray probe distances – to move probes outside of intersecting
    geometries.
  prefs: []
  type: TYPE_NORMAL
- en: We presented a fully funcitonal version of DDGI, but there are some improvements
    that can be made and the technique can be expanded in different directions. Some
    examples of improvements are a classification system to disable non contributing
    probes, or adding a moving grid with cascades of different grid spacing centered
    around the camera. Combined with hand-placed volumes can create a complete diffuse
    global-illumination system.
  prefs: []
  type: TYPE_NORMAL
- en: While having a GPU with ray-tracing capabilities is necessary for this technique,
    we could bake irradiance and visibility for static scene parts and use them on
    older GPUs. Another improvement can be changing hysteresis based on probe luminance
    changes, or adding a staggered probe update based on distance and importance.
  prefs: []
  type: TYPE_NORMAL
- en: All these ideas show how powerful and configurable DDGI is and we encourage
    the reader to experiment and create other improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the DDGI technique. We started by talking about
    global illumination, the lighting phenomena that is implemented by DDGI. Then,
    we provided an overview of the algorithm, explaining each step in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we wrote and commented on all the shaders in the implementation. DDGI
    already enhances the lighting of the rendered frame, but it can be improved and
    optimized.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the aspects of DDGI that makes it useful is its configurability: you
    can change the resolution of irradiance and visibility textures and change the
    number of rays, number of probes, and spacing of probes to support lower-end ray
    tracing-enabled GPUs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter we are going to add another element that will help us increase
    the accuracy of our lighting solution: reflections!'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Global illumination is an incredibly big topic that’s covered extensively in
    all rendering literature, but we wanted to highlight links that are more connected
    to the implementation of DDGI.
  prefs: []
  type: TYPE_NORMAL
- en: DDGI itself is an idea that mostly came from a team at Nvidia in 2017, with
    the central ideas described at [https://morgan3d.github.io/articles/2019-04-01-ddgi/index.xhtml](https://morgan3d.github.io/articles/2019-04-01-ddgi/index.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'The original articles on DDGI and its evolution are as follows. They also contain
    supplemental code that was incredibly helpful in implementing the technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://casual-effects.com/research/McGuire2017LightField/index.xhtml](https://casual-effects.com/research/McGuire2017LightField/index.xhtml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.jcgt.org/published/0008/02/01/](https://www.jcgt.org/published/0008/02/01/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://jcgt.org/published/0010/02/01/](https://jcgt.org/published/0010/02/01/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is a great overview of DDGI with Spherical Harmonics support,
    and the only diagram to copy the border pixels for bilinear interpolation. It
    also describes other interesting topics: [https://handmade.network/p/75/monter/blog/p/7288-engine_work__global_illumination_with_irradiance_probes](https://handmade.network/p/75/monter/blog/p/7288-engine_work__global_illumination_with_irradiance_probes).'
  prefs: []
  type: TYPE_NORMAL
- en: The DDGI presentation by Nvidia can be found at [https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9900-irradiance-fields-rtx-diffuse-global-illumination-for-local-and-cloud-graphics.pdf](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9900-irradiance-fields-rtx-diffuse-global-illumination-for-local-and-cloud-graphics.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an intuitive introduction to global illumination: [https://www.scratchapixel.com/lessons/3d-basic-rendering/global-illumination-path-tracing](https://www.scratchapixel.com/lessons/3d-basic-rendering/global-illumination-path-tracing).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Global Illumination* *Compendium*: [https://people.cs.kuleuven.be/~philip.dutre/GI/](https://people.cs.kuleuven.be/~philip.dutre/GI/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, here is the greatest website for real-time rendering: [https://www.realtimerendering.com/](https://www.realtimerendering.com/).'
  prefs: []
  type: TYPE_NORMAL
