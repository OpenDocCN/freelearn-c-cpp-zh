- en: 6 Physically Based Rendering Using the glTF 2.0 Shading Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Join our book community on Discord
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/file40.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/unitydev](https://packt.link/unitydev)'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will cover the integration of **physically based rendering** (**PBR**)
    into your graphics applications. We use the glTF 2.0 shading model as an example.
    PBR is not a single specific technique but rather a set of concepts, like using
    measured surface values and realistic shading models, to accurately represent
    real-world materials. Adding PBR to your graphics application or retrofitting
    an existing rendering engine with PBR might be challenging, as it requires multiple
    big tasks that work simultaneously before a correct image can be rendered.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal here is to show how to implement all these steps from scratch. Some
    of these steps, like precomputing irradiance maps or **bidirectional reflectance
    distribution function** (**BRDF**) look-up tables, require additional tools to
    be written. We are not going to use any third-party tools here and will show how
    to implement the entire skeleton of a PBR pipeline from the ground up, including
    creating rudimental tools to work with. Some pre-calculations can be done using
    **General-Purpose Graphics Processing Unit** (**GPGPU**) techniques and compute
    shaders, all of which will be covered here as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to the glTF 2.0 physically based shading model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rendering unlit glTF 2.0 materials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precomputing BRDF look-up tables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precomputing irradiance maps and diffuse convolution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the glTF 2.0 core metallic-roughness shading model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the glTF 2.0 core specular-glossiness shading model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all future references to glTF, we mean the glTF 2.0 specification. Since
    glTF 1.0 is obsolete and deprecated, we do not cover it in this book.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An introduction to the glTF 2.0 physically based shading model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will learn the PBR Material basics and provide enough context
    for the actual implementation of some ratified glTF 2.0 PBR extensions. The actual
    code will be presented in the subsequent recipes and chapters. Since the topic
    of PBR rendering is vast, we will focus on a minimalistic implementation just
    to guide you and get you started. In this section, we will focus on the GLSL shader
    code for the glTF 2.0 PBR shading model. Roughly speaking, rendering a physically
    based image is nothing more than running a fancy pixel shader with a set of textures.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We assume you already have some basic understanding of linear algebra and calculus.
    It is recommended to get yourself familiar with the glTF 2.0 specification, which
    can be found at [https://registry.khronos.org/glTF/specs/2.0/glTF-2.0.xhtml](https://registry.khronos.org/glTF/specs/2.0/glTF-2.0.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: What is PBR?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Physically based rendering** (**PBR**) is a set of techniques that aim to
    simulate how light interacts with real-world materials. By using realistic models
    for light scattering and reflection, PBR materials can create much more believable
    and immersive visuals compared to traditional methods.'
  prefs: []
  type: TYPE_NORMAL
- en: The glTF PBR material model is a standardized way of representing physically
    based materials in the glTF 2.0 format. This model allows you to create highly
    realistic 3D content across diverse platforms and applications, making it a crucial
    tool for modern 3D development.
  prefs: []
  type: TYPE_NORMAL
- en: Light-object interactions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s step back and see what a ray of light is as a physical phenomenon – it’s
    a geometric line along which light energy travels, or a beam of light. It has
    a starting point and a direction of propagation. Two important interactions of
    light with surfaces are **reflection** and **diffusion** (also known as “specular”
    and “diffuse” reflection, respectively). While we intuitively understand these
    concepts through everyday experience, their physical characteristics may be less
    familiar.
  prefs: []
  type: TYPE_NORMAL
- en: When light encounters a surface, part of it bounces back in the opposite direction
    of the surface’s normal, like how a ball rebounds at an angle off a wall. This
    type of reflection, occurring on smooth surfaces, creates a mirror-like effect
    called **specular reflection** (derived from speculum, a Latin word for “mirror”).
  prefs: []
  type: TYPE_NORMAL
- en: However, not all light reflects. Some light penetrates the surface, where it
    can either be absorbed, converted into heat, or scattered in various directions.
    The scattered light that exits the surface again is known as **diffuse light**,
    **photon diffusion**, or **subsurface scattering**. These terms all refer to the
    same physical phenomenon of photon movement. However, diffusion and scattering
    are different in how they disperse photons. Scattering involves photons being
    redirected in various directions, while diffusion involves photons spreading out
    evenly.
  prefs: []
  type: TYPE_NORMAL
- en: The way materials absorb and scatter diffuse light varies for different wavelengths
    of light, giving objects their distinct colors. For example, an object that absorbs
    most colors but scatters blue light will appear blue. This scattering is often
    so chaotic that it appears the same from all directions, unlike a specular mirror-like
    reflection.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: Diffuse and specular reflection](img/file41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: Diffuse and specular reflection'
  prefs: []
  type: TYPE_NORMAL
- en: Simulating this behavior in computer graphics often requires only a single input,
    **albedo**, which represents the color defined by the mix of the fractions of
    various light wavelengths that scatter back out across a surface. The term **diffuse
    color** is often used interchangeably with albedo.
  prefs: []
  type: TYPE_NORMAL
- en: When materials have wider scattering angles, such as human skin or milk, simulating
    their lighting requires more complex approaches than simple light interaction
    with a surface. This is because the light scattering in these materials is not
    just limited to the surface; it also occurs within the material itself.
  prefs: []
  type: TYPE_NORMAL
- en: For thin objects, the light can even scatter out of their back side, making
    them **translucent**. As the scattering further decreases, like in glass, the
    material becomes transparent, allowing entire images to pass through it, preserving
    their visible shape.
  prefs: []
  type: TYPE_NORMAL
- en: These unique light scattering behaviors are significantly different from the
    typical “close to the surface” diffusion, requiring special handling for accurate
    rendering.
  prefs: []
  type: TYPE_NORMAL
- en: Energy conservation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The fundamental principle in PBR revolves around the law of conservation of
    energy. This law asserts that within an isolated system, the overall energy remains
    unchanged. In the context of rendering, it signifies that the quantity of incoming
    light at any given location in the scene equals the combined amount of light that
    is reflected, transmitted, and absorbed at that location.
  prefs: []
  type: TYPE_NORMAL
- en: Enforcing energy conservation is crucial for PBS. It allows assets to adjust
    reflectivity and albedo values for a material without inadvertently violating
    the laws of physics, which often leads to unnatural- looking results. Implementing
    these constraints in code prevents assets from deviating too far from the reality
    or becoming inconsistent under varying lighting conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing this principle in a shading system is straightforward. We simply
    subtract reflected light before computing the diffuse shading. This implies that
    highly reflective objects will exhibit minimal to no diffuse light, as most of
    the light is reflected instead of penetrating the surface. Conversely, materials
    with strong diffusion cannot be particularly reflective.
  prefs: []
  type: TYPE_NORMAL
- en: Surface properties
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In any given environment, you can readily observe various complex surfaces that
    exhibit distinct light interactions. These unique surface properties are represented
    by general mathematical functions, known as **Bidirectional Scattering Distribution
    Functions** (**BSDFs**).
  prefs: []
  type: TYPE_NORMAL
- en: Think of a BSDF as an equation that describes how light scatters upon encountering
    a surface. It considers the surface’s physical properties and predicts probabilities
    of incident light coming from one direction getting scattered in other directions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the term BSDF might sound complex, let’s break it down:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bidirectional**: This refers to the two-way nature of light interaction with
    a surface. Incident light arrives at a surface from one direction and then scatters
    in various directions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scattering**: This describes how incident light can be redirected into multiple
    outgoing directions. This can involve reflection, transmission, or a combination
    of both.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution function**: This defines the probability of light scattering
    in a particular direction based on the surface’s characteristics. The distribution
    can range from perfectly uniform scattering to a concentrated reflection in a
    single direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In practice, the BSDF is usually split into two parts that are treated separately:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bidirectional Reflectance Distribution Functions** (**BRDFs**): These functions
    specifically describe how incident light is reflected from a surface. They explain
    why a seemingly white light source illuminating a banana makes it appear yellow
    instead. The BRDF reveals that the banana primarily reflects light in the yellow
    part of the spectrum while absorbing or transmitting other wavelengths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bidirectional Transmittance Distribution Functions** (**BTDFs**): These functions
    specifically describe how light is transmitted through a material. This is evident
    in materials such as glass and plastics, where we see how incident light passes
    through the material.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, other types of BSDFs exist to account for more complex light interaction
    phenomena, such as subsurface scattering. This occurs when light enters a material
    and bounces around before re-emerging in a new direction, at points significantly
    distant from the points of incidence of the incident rays.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2: BRDF and BTDF](img/file42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: BRDF and BTDF'
  prefs: []
  type: TYPE_NORMAL
- en: Types of reflection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are four primary surface types characterized by their BRDFs, which define
    the likelihood of light scattering in various directions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Diffuse surfaces** scatter light uniformly in all directions, exemplified
    by the consistent color of matte paint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Glossy specular surfaces** preferentially scatter light in specific reflected
    directions, exhibiting blurred reflections, such as specular highlights on plastic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Perfect specular surfaces** scatter light precisely in a single outgoing
    direction, mirroring the incident light with respect to the surface normal—similar
    to flawless reflections seen in perfect mirrors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retro-reflective surfaces** scatter light predominantly back along the incident
    direction to the light source, akin to the specular highlights observed on velvet
    or road signs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, it’s improbable that a real-world surface strictly adheres to only
    one of these models. As a result, most materials can be modeled as intricate combinations
    of these surface types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, each type of reflection— diffuse, glossy specular, perfect specular,
    and retro-reflective— can exhibit isotropic or anisotropic distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Isotropic reflections** maintain a consistent amount of reflected light at
    a point, irrespective of the object rotation angle. This characteristic aligns
    with the behavior of most surfaces encountered in daily life.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anisotropic reflections** vary in the amount of reflected light based on
    the orientation of an object to the light source. This occurs due to the alignment
    of small surface irregularities aligned predominantly in one direction, resulting
    in elongated and blurry reflections. Such behavior is noticeable in materials
    such as brushed metal and velvet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transmission
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reflection distribution types can be used for transmission as well, except for
    retro-reflection. Conversely, when light passes through a material, its path is
    affected by the material’s properties. To illustrate how this differs from reflection,
    consider a single light ray passing through a material, like perfect specular
    transmission. In perfect specular transmission, the medium’s refractive index
    determines the direction in which light travels. This behavior adheres to **Snell’s
    Law**, which is described using the equation n1θ1 = n2θ2n2θ2.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3: The index of refraction](img/file43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: The index of refraction'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `n` represents the refractive index of the first and second media, while
    `θ` denotes the angle of the incoming light concerning the surface normal. Consequently,
    when both media share identical refractive indices, light proceeds in a perfectly
    straight path. Conversely, if the refractive indices differ, the light changes
    its direction upon transitioning into the next medium. A notable instance of this
    is when light shifts direction upon entering water from air, leading to distortions
    in our underwater observations. This contrasts with perfect specular reflection,
    where the incoming angle always equals the outgoing angle.
  prefs: []
  type: TYPE_NORMAL
- en: Fresnel equation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is important for physically based renderers to know how much light is reflected
    or transmitted on the surface. It is a combination of these effects that describes
    substances such as honey and stained glass, which both have color and can be seen
    through.
  prefs: []
  type: TYPE_NORMAL
- en: These amounts are directly related to each other and are described by the **Fresnel
    equations**.
  prefs: []
  type: TYPE_NORMAL
- en: These equations are tailored for two types of media, **conductors** (**metals**)
    and **dielectrics** (**nonmetals**). Metals do not transmit light; they only reflect
    it entirely, or practically entirely. Dielectrics possess the property of diffuse
    reflection—light rays pass beneath the surface of the material and some of them
    are absorbed, while some are returned in the form of reflection. This is particularly
    evident in the specular highlight of these materials—for metals, it will be colored,
    while for dielectrics, it appears white or, more accurately, retains the color
    of the incident light.
  prefs: []
  type: TYPE_NORMAL
- en: Although both conductors and dielectrics are subject to the same set of Fresnel
    equations, glTF 2.0 opts to develop a distinct evaluation function for dielectrics.
    This choice is made to leverage the notably straightforward structure that these
    equations assume when the refractive indices are definitely real numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Nonmetals (dielectrics)**: These are materials like glass, plastic, and ceramics,
    which lack distinctive metallic properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metals (conductors)**: These materials can conduct both heat and electricity
    to a certain extent. Examples include many metals, such as copper, silver, and
    gold, although not all metals exhibit this property. Unlike dielectrics, conductors
    do not transmit light; rather, they absorb some of the incident light, converting
    it into heat.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microfacets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to the microfacet theory, a rough surface is composed of countless
    microfacets or tiny surface elements, each having its own orientation with respect
    to the surface normal. These microfacets scatter incoming light in different directions
    due to their orientations, resulting in a diffused reflection rather than a perfect
    mirror-like reflection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Blinn-Phong Model**: It was introduced by James F. Blinn in 1977 as an enhancement
    of the empirical Phong reflection model, devised by Bui Tuong Phong in 1973.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This model computes the intensity of the reflected light based on the angle
    between the viewer’s direction and the halfway vector `h=(L+V)/length(L+V)`, which
    is halfway between the light direction `L` and the view direction `V`. The model
    includes a specular term that provides a highlight on the surface, simulating
    the effect of a shiny surface.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cook-Torrance Model**: In 1982, Robert Cook and Kenneth Torrance introduced
    a reflectance model that offered a more precise depiction of light reflectance
    in comparison to the Phong and Blinn-Phong models. The microfacet BRDF equation
    is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*f*[r]​(*ω*[i]​,*ω*[o]​) is the microfacet BRDF'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*F*(*ω*[i]​,*h*) is the Fresnel term'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*D*(*h*) is the microfacet distribution function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*G*(*ω*[i]​,*ω*[o]​,*h*) is the geometry function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ω*[i​] is the incident light direction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ω*[o]​ is the outgoing light direction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*h* is the half vector'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*n* is the surface normal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The proposed approach is versatile, featuring **three interchangeable component**
    functions, `F`, `D`, and `G`, which can be substituted with equations of your
    preference. Additionally, it proves efficient in accurately representing a wide
    range of real-world materials.
  prefs: []
  type: TYPE_NORMAL
- en: This equation represents the amount of light reflected in a specific direction
    `ωo`​, given an incident light direction `ωi`​ and the surface properties. The
    initial component `F` represents the Fresnel effect, the subsequent component
    `D` is a **normal distribution function** (**NDF**), and the final component accounts
    for the shadowing factor `G`, referred to as the **G term**.
  prefs: []
  type: TYPE_NORMAL
- en: Of all the factors in this formulation, the NDF term typically exerts the greatest
    importance. The specific form of the NDF is heavily influenced by the roughness
    of the BRDF. To sample the microfacet BRDF model efficiently, it is customary
    to first sample the NDF, obtain a random microfacet normal that conforms to the
    NDF, and subsequently reflect the incident radiance along this normal to determine
    the outgoing direction.
  prefs: []
  type: TYPE_NORMAL
- en: The normalization requirement for the NDF in microfacet theory ensures that
    the total amount of energy reflected or transmitted by a surface remains consistent
    across different roughness levels.
  prefs: []
  type: TYPE_NORMAL
- en: In microfacet theory, the NDF describes the statistical distribution of microfacet
    normals on a surface. It specifies the probability density of finding a microfacet
    with a particular orientation. When integrating the BRDF over all possible directions,
    the integral should yield a value representing the total reflectance or transmittance
    of the surface.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization of the NDF guarantees that the total amount of light reflected
    or transmitted by the surface remains constant, regardless of the surface roughness.
    This ensures energy conservation, a fundamental principle in physics, stating
    that energy cannot be created or destroyed, only transformed or transferred.
  prefs: []
  type: TYPE_NORMAL
- en: Several NDFs are commonly used to simulate the behavior of surfaces with microscale
    roughness. Some examples are GGX, Beckmann, and Blinn. In the next recipes, we
    will learn how to implement some of them.
  prefs: []
  type: TYPE_NORMAL
- en: What is a material?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Materials serve as high-level descriptions utilized to represent surfaces, defined
    by combinations of BRDFs and BTDFs. These BSDFs are articulated as parameters
    that govern the visual characteristics of the material. For instance, a matte
    material can be delineated by specifying a diffuse reflection value to elucidate
    how light interacts with the surface, along with a scalar roughness value to characterize
    its texture. Transitioning from a matte to a plastic material could be achieved
    by simply appending a glossy specular reflection value to the matte material,
    thus recreating the specular highlights typical of plastics.
  prefs: []
  type: TYPE_NORMAL
- en: glTF PBR specification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The glTF PBR specification approaches material representation in a manner that
    emphasizes realism, efficiency, and consistency across different rendering engines
    and applications.
  prefs: []
  type: TYPE_NORMAL
- en: One key aspect of the glTF PBR specification is its adherence to physically
    based principles. This means that the materials defined in glTF accurately simulate
    real-world behavior, such as how light interacts with surfaces. Parameters like
    base color (albedo), roughness, metallic, and specular are used to describe materials,
    aligning with physical properties like surface color, smoothness, metallicity,
    and specular reflectivity.
  prefs: []
  type: TYPE_NORMAL
- en: Another notable feature of the glTF PBR approach is its simplicity and ease
    of implementation. By standardizing the parameters used to describe materials,
    glTF simplifies the process of creating and exporting 3D models with PBR materials.
    This consistency across different applications and rendering engines streamlines
    the workflow for artists and developers, enabling them to work more efficiently
    and interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the glTF PBR specification is designed for real-time rendering
    applications, making it well-suited for use in interactive experiences, games,
    and other real-time graphics applications. Its efficient representation of materials
    and optimized file format contribute to faster loading times and better performance
    in real-time rendering scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the glTF PBR specification stands out for its commitment to physical
    accuracy, simplicity, and efficiency, making it a preferred choice to represent
    materials in 3D graphics applications. Its widespread adoption and support across
    various platforms further cement its status as a leading standard for PBR material
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *Khronos 3D Formats Working Group* continually strives to enhance PBR material
    capabilities by introducing new extension specifications. You can always stay
    updated on the status of ratified extensions by visiting the Khronos GitHub page:
    [https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md](https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For those who wish to acquire deeper knowledge, make sure you read the free
    book *Physically Based Rendering: From Theory to Implementation* by Matt Pharr,
    Wenzel Jakob, and Greg Humphreys, available online at [http://www.pbr-book.org](http://www.pbr-book.org).
    Another great reference is the book *Real Time Rendering, 4th Edition* by Tomas
    Akenine-Möller, Eric Haines, and Naty Hoffman.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we recommend SIGGRAPH’s *Physically Based Rendering* courses. For example,
    you can find a comprehensive collection of links on GitHub: [https://github.com/neil3d/awesome-pbr](https://github.com/neil3d/awesome-pbr).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides that, the *Filament* rendering engine provides a very comprehensive
    explanation of PBR materials: [https://google.github.io/filament/Filament.md.xhtml](https://google.github.io/filament/Filament.md.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Rendering unlit glTF 2.0 materials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we will start to develop a code framework that allows us to
    load and render glTF 2.0 assets.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with the `unlit` material because it is the simplest glTF 2.0 PBR
    material extension, and the actual shader implementation is very simple and straightforward.
    The official name of the extension is `KHR_materials_unlit`. Here is the link
    to its specification: [https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_unlit](https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_unlit).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `unlit` material technically is not PBR-based, as it might break the energy
    conservation assumptions or provide any artistic representations that do not reflect
    any law of physics. The `unlit` material was designed with the following motivations
    in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Mobile devices with limited resources, where unlit materials offer a performant
    alternative to higher-quality shading models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Photogrammetry, in which the lighting information is already prebaked into the
    texture data and additional lighting should not be applied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stylized materials (like those resembling “anime” or hand-drawn art) in which
    lighting is undesirable for aesthetic reasons.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started with the basic implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The source code for this recipe is in `Chapter06/01_Unlit/main.cpp`. The corresponding
    GLSL vertex and fragment shaders are in `main.vert` and `main.frag`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will create a feature-rich glTF viewer in the following chapters. In this
    chapter, we start building a simple framework that allows us to load and render
    basic glTF models.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `VulkanApp` and the *Assimp* library from previous chapters. As
    usual, most of the error checking is omitted from the book text but is present
    in the actual source code files:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s load our `.gltf` file using *Assimp*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the loading function is a single line of code. *Assimp* supports
    loading `.gltf` and `.glb` files out of the box. We use the *DamagedHelmet* asset
    from the official Khronos repository: [https://github.com/KhronosGroup/glTF-Sample-Assets/tree/main/Models/DamagedHelmet](https://github.com/KhronosGroup/glTF-Sample-Assets/tree/main/Models/DamagedHelmet).
    This model uses the **Metallic-Roughness** material, but for demonstration purposes,
    we will apply the `unlit` shader to it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next step is to build the mesh geometry. The `unlit` material uses only
    the `baseColor` property of the material in three different input forms: as a
    vertex attribute, as a static fragment shader color factor, and as a base color
    texture input. For our vertex format, it means we need to provide the following
    three per-vertex attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To fill in these attributes, we will use the following code. Empty colors are
    filled with the white color value `(1, 1, 1, 1),` and the empty texture coordinates
    are filled with zeroes `(0, 0, 0)` according to the glTF specification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If a vertex color is not presented in the mesh, then we replace it with the
    default white color. It is a convenient way to simplify the final shader permutation,
    where we can just combine all three inputs in a simple manner. We will come back
    to it later in this recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We build the index buffer using the *Assimp* mesh faces information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we should load a diffuse or albedo base color texture. For simplicity,
    we will use the hardcoded file path here instead of obtaining it from the `.gltf`
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex and index data are static and can be uploaded into corresponding
    Vulkan buffers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To finish the mesh setup, we need to load GLSL shaders and create a render
    pipeline. The member fields of the `VertexInput` struct correspond to the `Vertex`
    struct mentioned above:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This was the preparation code. Let’s now look inside the application’s main
    loop:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the rendering loop, we prepare the model-view-projection matrix `mvp`
    and pass it into GLSL shaders, using push constants and the `PerFrameData` structure,
    together with the base color value and the albedo texture ID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the actual 3D mesh rendering is simple, so we post the code here in its
    entirety:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, lets add a few nice touches at the end to render the infinite grid,
    as described in the *Chapter 5* recipe, *Implementing an infinite grid GLSL shader*,
    and the FPS counter, as described in the *Chapter 4* recipe *Adding a frames-per-second
    counter*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This was all the C++ code. Now, let’s dive into the GLSL shaders for this example.
    They’re straightforward and short:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader `Chapter06/01_Unlit/src/main.vert` does the vertex transformation
    and pre-multiplies the per-vertex color with the provided base color value from
    push constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader `Chapter06/01_Unlit/src/main.frag` is very simple as well.
    All it does is multiply the precomputed per-vertex base color value by the color
    value sampled from the albedo texture. The glTF 2.0 specification guarantees to
    provide at least one `baseColorFactor` value for the Metallic-Roughness property,
    and this guarantees the correctness of the result as long as we keep all the remaining
    parameters equal to `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The running application `Chapter06/01_Unlit/src/main.cpp` should look like the
    following screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.4: Unlit glTF 2.0 model](img/file44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Unlit glTF 2.0 model'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we enforced the use of the albedo texture for rendering to
    keep the code simple, making it easier to understand. In the subsequent chapters,
    we’ll fully support various combinations of material parameters as specified in
    the glTF 2.0 specification, providing a more accurate and complete glTF 2.0 viewer
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Precomputing BRDF look-up tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous recipes, we learned the basic theory behind glTF 2.0 PBR and
    implemented a simple unlit glTF 2.0 renderer. Let’s continue our PBR exploration
    and learn how to precompute the Smith GGX BRDF **look-up table (LUT)** for our
    upcoming glTF 2.0 viewer.
  prefs: []
  type: TYPE_NORMAL
- en: To render a PBR image, we have to evaluate the BRDF at each point on the surface
    being rendered, considering the surface properties and the viewing direction.
    This is computationally expensive, and many real-time implementations, including
    the reference glTF-Sample-Viewer from Khronos, use precalculated tables of some
    sort to find the BRDF value, based on surface roughness and the viewing direction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: BRDF LUT can be stored as a two-dimensional texture. The X-axis represents the
    dot product between the surface normal vector and the viewing direction, while
    the Y-axis represents the surface roughness values `0...1`. Each texel holds three
    16-bit floating point values. The first two values represent the scale and bias
    to F0, *which is the specular reflectance at normal incidence*. The third value
    is utilized for the sheen material extension, which will be covered in the following
    chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are going to use Vulkan to calculate this LUT texture on the GPU and implement
    a compute shader to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is helpful to revisit the Vulkan compute pipeline creation from the *Chapter
    5* recipe *Generating textures in Vulkan using compute shaders*. Our implementation
    is based on a shader from [http://github.com/KhronosGroup/glTF-Sample-Viewer/blob/main/source/shaders/ibl_filtering.frag](http://github.com/KhronosGroup/glTF-Sample-Viewer/blob/main/source/shaders/ibl_filtering.frag),
    which runs very similar computations in a fragment shader. Our GLSL compute shader
    can be found in `Chapter06/02_BRDF_LUT/src/main.comp`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why precompute?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Earlier in this chapter, we explained what BRDF is and introduced its major
    components, such as the Fresnel term `F`, the Normal Distribution Function `NDF`,
    and the Geometry term `G`. As you may notice, the BRDF results depend on several
    factors, such as the incident and outgoing light directions, surface normal, and
    viewer’s direction:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Where the individual terms have the following meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: '`D` is the GGX NDF microfacet distribution function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`G` accounts for mutual shadowing of microfacets and looks as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Fresnel `F` term defines the amount of light reflected off the surface
    under the given angle of incidence:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we check any component of the BRDF, we will see that all of them are quite
    complex for real-time per-pixel calculations. Therefore, we can use an offline
    process to precompute some parts of the BRDF equation.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the `G` term and some parts of the `F` term depend only on the
    `v`, `h`, and `Roughness` parameters. We will take advantage of this to do precomputation.
    Also, please note that we never need `n` and `v` separately, so we can always
    use their dot product instead.
  prefs: []
  type: TYPE_NORMAL
- en: One important question remains. How can we iterate all possible `v` and `n`
    combinations? To do that, we need to integrate over all angles on a hemisphere,
    but we can use a simpler approximation for that. To make it efficient, we use
    two assumptions. First, we need to find a way to integrate with a limited number
    of samples. Second, we need to choose samples wisely, not just randomly.
  prefs: []
  type: TYPE_NORMAL
- en: As described in *Chapter 20*, *GPU-Based Importance Sampling*, of the book *GPU
    Gems 3* [https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling),
    the solution is to use the **Monte Carlo estimation** with **importance sampling**.
    The Monte Carlo estimation lets us approximate an integral by a weighted sum of
    random samples. Importance sampling exploits the idea that certain values of random
    points over a hemisphere have more impact on the function being estimated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The paper *Real Shading in Unreal Engine 4* by Brian Karis provides a detailed
    explanation of all the mathematical aspects. We strongly recommend reading it
    for a better understanding of the math behind PBR: [https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf](https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we investigate the GLSL shader code, let’s implement all the necessary
    C++ code to process data arrays on the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'To manipulate data buffers on the GPU and utilize the data effectively, we
    require four basic operations: loading a shader module, creating a compute pipeline,
    creating a buffer, and dispatching compute commands. After that, we need to transfer
    the data from the GPU buffer to the host memory and save it as a texture file.
    Let’s walk through these steps by examining the code in `Chapter06/02_BRDF_LUT/src/main.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The function `calculateLUT()` implements most of the described functionality.
    We will start with the shader module loading and compute pipeline creation. The
    GLSL shader is specialized using the constant `kNumSamples`, which defines the
    number of Monte Carlo trials for our LUT calculation. We will store 16-bit float
    RGBA values in the buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create a GPU storage buffer for our output data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we acquire a command buffer, update push constants, and dispatch the
    compute commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Before reading the generated data back to the CPU memory, we must wait for
    the GPU to finish processing the buffer. It can be done using the `wait()` function,
    which waits for a command buffer to finish. We discussed this in the *Chapter
    2* recipe *Using Vulkan command buffers*. Once the GPU has finished working, we
    can copy the memory-mapped buffer back to the CPU memory, referenced by the pointer
    `output`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'That was the C++ part. Now, let’s investigate the GLSL shader compute code
    in `Chapter06/02_BRDF_LUT/src/main.comp`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To break down our work into smaller pieces, we will start with the shader preamble
    and the `main()` function of the BRDF LUT calculation shader. The preamble code
    sets the compute shader dispatching parameters. In our case, a 16x16 chunk of
    the LUT texture is calculated by one GPU work group. The number of Monte Carlo
    trials for numeric integration is declared as a specialization constant that we
    can override from the C++ code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We use user-provided width and height to calculate our output buffer dimensions.
    `PI` is the global “physical” constant we use in the shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main()` function wraps the `BRDF()` function call and stores the results.
    First, we recalculate the worker ID to output array indices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `BRDF()` function does all the actual work. The calculated value is put
    into the output array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we use three channels of the texture. The `R` and `G` channels
    are used for GGX BRDF LUT, and the third channel is used for Charlie BRDF LUT,
    which is required for the **Sheen** material extension and will be covered in
    *Chapter 7*, *Advanced PBR Extensions*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have described the scaffolding parts of our compute shader, we
    can see how the BRDF LUT values are calculated. Let’s look at the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate random directions in a hemisphere, we will use so-called Hammersley
    points, calculated by the following function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The code is based on the following post: [http://holger.dammertz.org:80/stuff/notes_HammersleyOnHemisphere.xhtml](http://holger.dammertz.org:80/stuff/notes_HammersleyOnHemisphere.xhtml).
    The bit-shifting magic for this and many other applications are thoroughly examined
    in Henry J. Warren’s book called *Hacker’s Delight*. Interested readers may also
    look up the “Van der Corput sequence” to see why this can be used as a series
    of random directions on a hemisphere.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We also need some kind of a pseudorandom number generator. We use the output
    array indices as an input and pass them through another magic set of formulas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out this link to find some useful details about this code: [http://byteblacksmith.com/improvements-to-the-canonical-one-liner-glsl-rand-for-opengl-es-2-0](http://byteblacksmith.com/improvements-to-the-canonical-one-liner-glsl-rand-for-opengl-es-2-0).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s look at how importance sampling is implemented according to the paper
    *Real Shading in Unreal Engine 4* by Brian Karis. Check out the fourth page of
    [https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf](https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf).
    This function maps an `i`-th 2D point, `Xi`, to a hemisphere with spread based
    on the surface roughness:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculations are done in tangent space, defined by the vectors `up`, `tangentX`,
    and `tangentY`, and then converted to world space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Another utility function, `G_SchlicksmithGGX()`, calculates the GGX geometric
    shadowing factor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We also precalculate LUT for the Sheen material, so there are two more helper
    functions, `V_Ashikhmin()` and `D_Charlie()`. They are based on the code from
    the Filament engine: [https://github.com/google/filament/blob/master/shaders/src/brdf.fs#L136](https://github.com/google/filament/blob/master/shaders/src/brdf.fs#L136):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a corresponding sampling function, `importanceSample_Charlie()`, for
    the Sheen material, which is very similar to `importanceSample_GGX()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The value of BRDF is calculated the following way, using all of the helper
    functions we declared above. The number of Monte Carlo trials, `NUM_SAMPLES`,
    is set earlier to be `1024`. The normal vector `N` always points along the Z-axis
    for the 2D look-up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The first loop calculates the `R` and `G` components of our LUT, which correspond
    to the scale and bias to `F0`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The third component, `B`, used for the sheen material is calculated in another
    loop. We will revisit it in *Chapter 7*, *Advanced PBR Extensions*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: That is the entire GLSL compute shader used to precalculate the look-up table.
    Let’s now see how it works with the C++ `main()` function.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `main()` function creates a KTX texture using the *KTX-Software* library
    so that our 16-bit RGBA LUT texture can be saved in the `.ktx` format, preserving
    the data. Then, it calls the `calculateLUT()` function we discussed above, which
    outputs the generated LUT data into the KTX texture. The texture is saved in `data/brdfLUT.ktx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use *Pico Pixel* ([https://pixelandpolygon.com](https://pixelandpolygon.com))
    to view the generated image. It should resemble the screenshot below. The horizontal
    axis represents the dot product between the surface normal vector and the viewing
    direction, while the vertical axis represents the surface roughness values `0...1`.
    Each texel holds three 16-bit floating point values. The first two values represent
    the scale and bias to `F0`, which is the specular reflectance at normal incidence.
    The third value is utilized for the sheen material extension, which will be covered
    in the next chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.5: BRDF lookup table](img/file45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: BRDF lookup table'
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the BRDF lookup table tool description. We will need yet another
    tool to calculate an irradiance cube map from an environment cube map, which we
    will cover in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The method described above can be used to precompute BRDF look-up tables, using
    high-quality Monte Carlo integration, and store them as textures. Dependent texture
    fetches can be expensive on some mobile platforms. There is an interesting runtime
    approximation used in Unreal Engine that does not rely on any precomputation,
    as described in the blog post *Physically Based Shading on Mobile* by Brian Karis:
    [https://www.unrealengine.com/en-US/blog/physically-based-shading-on-mobile](https://www.unrealengine.com/en-US/blog/physically-based-shading-on-mobile).
    Here is the GLSL source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Precomputing irradiance maps and diffuse convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed earlier in the recipe *An introduction to the glTF 2.0 Physically
    Based Shading Model*, the second part of the split sum approximation necessary
    to calculate the glTF 2.0 physically based shading model comes from the irradiance
    cube map, which is precalculated by convolving the input environment cube map
    with the GGX distribution of our shading model. Our implementation is based on
    the code at [https://github.com/KhronosGroup/glTF-Sample-Viewer/blob/main/source/shaders/ibl_filtering.frag](https://github.com/KhronosGroup/glTF-Sample-Viewer/blob/main/source/shaders/ibl_filtering.frag).
  prefs: []
  type: TYPE_NORMAL
- en: '**Image-based lighting** (**IBL**) is a technique for illuminating a scene
    using captured light information. This information can be stored as panoramic
    photo images (for example, see *Figure 6.6*). It is very hard to simulate entire
    real-world environments, so capturing the real world and using images is a very
    common technique nowadays to produce realistic renders. Using IBL allows us to
    precompute the parts of the diffuse and specular BRDF equations and make them
    more runtime-friendly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that precomputing irradiance and diffusion is quite a mathematical process.
    If you want to learn more about the theory behind these computations, make sure
    you read Brian Karis’s paper *Real Shading in Unreal Engine 4*: [https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf](https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Check out the source code for this recipe in `Chapter06/03_FilterEnvmap`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will do Monte-Carlo integration inside a fragment shader, which is located
    here: `Chapter06/03_FilterEnvmap/src/main.frag`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The C++ source code can be found in the `Chapter06/03_FilterEnvmap/src/main.cpp`
    file. Let’s go through the function `prefilterCubemap()` to precompute the irradiance
    and diffuse maps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to create a cube map texture to store the results of prefiltering.
    We will use the 32-bit RGBA floating point pixel format because most of our color-related
    calculations happen in linear space. Low-end mobile devices might be not performant
    enough, and in this case, the dynamic range can be clamped to 16-bit or even 8-bit,
    but that might significantly impact the visual fidelity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We use cubemap mip-levels to precompute multiple lookups for different values
    of material roughness `0…1`. The function takes in the `distribution` parameter,
    which is passed to the shader to select an appropriate distribution, Lambertian,
    GGX, or Charlie:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We require GLSL shader modules and a rendering pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can start doing the actual rendering in the cubemap. One command buffer
    is filled with all the commands necessary to render in `6` cubemap faces, with
    all the required mip-levels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We set the cube map face and the specific mip-level we want to render:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Push constants are used to pass all the data into the shaders:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, a full-screen triangle is rendered to cover the entire cube face and
    let the fragment shader do its work. After the command buffer is filled up, we
    can submit it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The remaining part of the `prefilterCubemap()` function retrieves the generated
    cubemap data from the GPU and saves it in a `.ktx` file. Let’s look at the GLSL
    fragment shader code, which does all the heavy lifting in `Chapter06/03_FilterEnvmap/src/main.frag`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To unwind the shader logic, let’s start with the entry point, `main()`. The
    code is trivial and invokes two functions. The function `uvToXYZ()` converts a
    cubemap face index and `vec2` coordinates into a `vec3` cubemap sampling direction.
    The function `filterColor()` does the actual Monte Carlo sampling, which we will
    come back to in a moment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the code of `uvToXYZ()` for your reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `filterColor()` does the integration part for irradiance and Lambertian
    diffuse convolution. The argument `N` is the cubemap sampling direction vector.
    We iterate `sampleCount` samples and get the importance sampling information,
    which includes the importance sample direction and the **probability distribution
    function** (**PDF**) for this direction. The mathematical part is described in
    detail in this blog post: [https://bruop.github.io/ibl](https://bruop.github.io/ibl).
    Here, we will focus on putting a minimalistic working implementation together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Mipmap samples are filtered as described in *GPU Gems 3* at section *20.4*,
    *Mapping and Distortion.* Sample Lambertian at a lower resolution to avoid pixels
    that are too bright, also known as **fireflies**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output color value is renormalized using the sum of all `NdotL` weights,
    or the number of samples for the Lambertian case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The importance sampling function `getImportanceSample()` returns a `vec4` value,
    with an importance sample direction in the `.xyz` components and the PDF scalar
    value in the `.w` component. We generate a Hammersley point, as we described earlier
    in the previous recipe, *Precomputing BRDF look-up tables*, and then, based on
    the distribution type (Lambertian, GGX, or Charlie), we generate a sample and
    rotate it in the normal direction. This function uses a helper structure, `MicrofacetDistributionSample`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate points on a hemisphere with a mapping corresponding to the desired
    distribution. For example, Lambertian distribution uses a cosine importance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Transform the hemisphere sample point into the tangent coordinate frame. The
    helper function `generateTBN()` generates a tangent-bitangent-normal coordinate
    frame from the provided normal vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We will skip the details of the individual distribution calculation functions
    `Lambertian()`, `GGX()`, and `Charlie()`. The actual GLSL shader `Chapter06/03_FilterEnvmap/src/main.frag`
    contains all the necessary code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The process of importance sampling can introduce visual artifacts. One way
    to improve visual quality without compromising performance is by utilizing hardware-accelerated
    mip-mapping for swift filtering and sampling. This idea was proposed in the following
    paper: [https://cgg.mff.cuni.cz/~jaroslav/papers/2007-sketch-fis/Final_sap_0073.pdf](https://cgg.mff.cuni.cz/~jaroslav/papers/2007-sketch-fis/Final_sap_0073.pdf).
    This link has a more detailed treatment of the subject: [https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling).
    Here, we use a formula that takes a **PDF** value and calculates a proper mip-map
    LOD level for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The rest of the code involves purely mechanical tasks, such as loading the
    cube map image from a file, calling the rendering functions for various distribution
    types (Lambertian, GGX, and Charlie), and saving the result using the KTX library.
    Let’s check out the results of prefiltering for the following input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6: Environment cube map](img/file46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: Environment cube map'
  prefs: []
  type: TYPE_NORMAL
- en: 'The convolved image should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7: Prefiltered environment cube map using diffuse convolution](img/file47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: Prefiltered environment cube map using diffuse convolution'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have all supplementary parts in place to render a PBR image. In the
    next recipe, *Implementing the glTF 2.0 metallic-roughness shading model*, we
    are going to put everything together into a simple application to render a physically
    based glTF 2.0 3D model.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Paul Bourke created a set of tools and a great resource that explains how to
    convert cube maps into different formats. Make sure to check it out: [http://paulbourke.net/panorama/cubemaps/index.xhtml](http://paulbourke.net/panorama/cubemaps/index.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the glTF 2.0 metallic-roughness shading model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe will cover how to integrate PBR into your graphics pipeline. Since
    the topic of PBR is vast, we will focus on a minimalistic implementation just
    to guide you and get you started. In this section, we will focus on the metallic-roughness
    shading model and minimalistic C++ viewer implementation. In the following chapters,
    we will create a more complex and feature-rich glTF viewer, including advanced
    material extensions and geometry features.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is recommended to revisit the recipe *An introduction to the glTF 2.0 physically
    based shading model* before you proceed with this one. A lightweight introduction
    to the glTF 2.0 shading model can be found at [https://github.com/KhronosGroup/glTF-Sample-Viewer/tree/glTF-WebGL-PBR](https://github.com/KhronosGroup/glTF-Sample-Viewer/tree/glTF-WebGL-PBR).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The C++ source code for this recipe is in the `Chapter06/04_MetallicRoughness`
    folder. The GLSL shader code responsible for PBR calculations can be found in
    `Chapter06/04_MetallicRoughness/src/PBR.sp`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we dive deep into the GLSL code, we’ll look at how the input data is
    set up from the C++ side. We are going to use the *Damaged Helmet* 3D model provided
    by Khronos. You can find the glTF file here: [https://github.com/KhronosGroup/glTF-Sample-Models/blob/main/2.0/DamagedHelmet/glTF/DamagedHelmet.gltf](https://github.com/KhronosGroup/glTF-Sample-Models/blob/main/2.0/DamagedHelmet/glTF/DamagedHelmet.gltf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with structures and helper functions first:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The helper struct `GLTFGlobalSamplers` contains three samplers necessary to
    access glTF IBL textures. It is declared in `shared/UtilsGLTF.h`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `GLTFGlobalSamplers` constructor creates all three samplers in the following
    way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The helper struct `EnvironmentMapTextures` stores all IBL environment map textures
    and the BRDF look-up table, providing default textures for the sake of simplicity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Check the previous recipe *Precomputing irradiance maps and diffuse convolution*
    for details on how to precalculate the IBL textures. The BRDF look-up table was
    precalculated in the recipe *Precomputing BRDF look-up tables*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The structure `GLTFMaterialTextures` contains all the textures necessary to
    render any glTF 2.0 model we support in our demos. It is a container for many
    `Holder<TextureHandle>` objects, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The helper function `loadMaterialTextures()` is not shared and will be different
    in each app. This variant of the function loads a subset of necessary textures
    for our metallic-roughness demo:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'One important step is to load the material data and fill out the `MetallicRoughnessDataGPU`
    structure. We will use the Assimp API to retrieve the material properties and
    fill out the corresponding values. The glTF specification requires well-defined
    default values for non-optional and optional properties, so we fill them out in
    this snippet as well. For each texture, we read and set the data for a sampler
    state and a `uv` coordinates index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Here, we pack the `metallicFactor`, `roughnessFactor`, `normalScale`, and `occlusionStrength`
    glTF properties into one `vec4` member field, `metallicRoughnessNormalOcclusion`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We do this packing as a very basic optimization. GPU stores this data in vector
    registers, and reading it will be more efficient if we pack all the parameters
    into a single `vec4` value. Another reason is avoiding any additional alignment
    requirements, especially for `vec3` types. Similar packing is done for a `vec3`
    glTF property, `emissiveFactor`, and a `float`, `alphaCutoff`, both of which are
    packed into a single `vec4` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The other member fields hold texture and sampler IDs for our bindless shaders.
    They have no default values other than `0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The `alphaMode` property defines how the alpha value is interpreted. The alpha
    value itself should be taken from the `4`-th component of the base color for the
    metallic-roughness material model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The `MetallicRoughnessDataGPU` structure is filled out using a helper function,
    `setupMetallicRoughnessData()`. The structure `GLTFMaterialTextures` was discussed
    above:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The rest of the function continues to read various glTF material properties,
    using the Assimp API. We paste just the beginning of its code here. All other
    material properties are loaded in a similarly repeating pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The helper function `assignUVandSampler()` looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s go through the `main()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we load the glTF file using Assimp. We support only triangulated topology;
    hence, the flag `aiProcess_Triangulate` is used to instruct Assimp to triangulate
    the mesh during the import:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We populate the vertex data. The struct Vertex is shared across all glTF demos
    and is declared in `shared/UtilsGLTF.h`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'A glTF model commonly uses two sets of UV texture coordinates. The first set,
    `uv0`, is used for the primary texture mapping, such as diffuse color, specular
    reflection, or normal mapping. These coordinates are typically used for surface
    details and color information. The second set, `uv1`, is commonly used for lightmaps
    or reflection maps. These maps often need separate texture coordinates to be mapped
    correctly onto the model, distinct from the primary texture coordinates. The glTF
    specification says that a viewer app should support at least two texture coordinate
    sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s set up indices that define our triangles and upload the resulting vertex
    and index data into the corresponding buffers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to load all the material textures. We use the same combination
    of textures for most of our glTF demos, so we store them in a structure, `GLTFMaterialTextures`,
    declared in `shared/UtilsGLTF.h`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we continue with the graphics pipeline creation and rendering, we have
    to set up IBL samplers, textures, and BRDF look-up tables. This data is shared
    between all our demos, so we have introduced a couple of helper structs to do
    all this work for us. Here are the definitions within the `main()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create a render pipeline step for our glTF rendering. We
    must provide a vertex input description. Here’s how to create one for our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'A rendering pipeline should be created as follows. We will investigate the
    GLSL shaders in the *How it works…* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'We can call `setupMetallicRoughnessData()` to load all the material data from
    glTF and properly pack it on the CPU side:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: We store the material data inside a dedicated Vulkan buffer and access it in
    GLSL shaders, using a buffer device address. This address is passed into shaders
    through Vulkan push constants.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The same treatment applies to our environment textures. They should be packed
    for the GPU, too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The maximum allowed push constant size is 128 bytes. In order to handle data
    exceeding this size, we will set up a couple of round-robin buffers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything else is just mesh rendering, similar to how it was done in the previous
    chapters. Here is how `draw` commands to render a glTF mesh are generated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Let’s skip the rest of the C++ code, which contains trivial command buffer submission
    and other scaffolding, and check how GLSL shaders work.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two GLSL shaders that are used to render our metallic-roughness PBR
    model, a vertex shader `Chapter06/04_MetallicRoughness/src/main.vert`, and a fragment
    shader, `Chapter06/04_MetallicRoughness/src/main.frag`, which include additional
    files for shared input declarations and our glTF PBR code GLSL library. The vertex
    shader uses programmable-vertex-pulling to read the vertex data from buffers.
    The most important aspect of the vertex shader is that we define our own functions,
    such as `getModel()` or `getTexCoord()`, to hide the implementation details of
    vertex pulling. It allows us to be flexible when we want to change the structure
    of our input data. We use a similar approach for fragment shaders.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is the fragment shader that does the actual work. Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we check our inputs. We will use buffer references for materials and
    environment buffers that correspond to the C++ structures `MetallicRoughnessDataGPU`
    and `EnvironmentMapDataGPU`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We use four helper functions, `getMaterialId()`, `getMaterial()`, `getEnvironmentId()`,
    and `getEnvironment()`, as shortcuts to access the buffer references provided
    in the push constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the file `Chapter06/04_MetallicRoughness/src/inputs.frag`, there are
    a bunch of helper functions – such as `sampleAO()`, `samplerEmissive()`, `sampleAlbedo()`,
    and many others – to sample from various glTF PBR texture maps based on the material
    `mat`. All of them use bindless textures and samplers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the fragment shader’s `main()` function, we use these helper functions
    to sample the texture maps based on the material ID value returned by `getMaterialId()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: To calculate the proper normal mapping effect based on a provided normal map,
    we evaluate the normal vector per pixel. We do it in world space. The normal map
    is in tangent space. Hence, the function `perturbNormal()` calculates the tangent
    space per pixel using the derivatives of texture coordinates, which is implemented
    in `data/shaders/UtilsPBR.sp`, and transforms the perturbed normal to world space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The last step here is to negate the normal for double-sided materials. We use
    the `gl_FrontFacing` intrinsic variable to do the check:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to fill out the `PBRInfo` structure, which holds multiple
    inputs utilized later by the various functions in the PBR shading equation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to calculate the specular and diffuse color contributions
    from the IBL environment lighting. We can directly add `diffuse_color` and `specular_color`
    because our precalculated BRDF LUT already takes care of energy conservation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'For this demo application, we use only one hardcoded directional light source,
    `(0, 0, -5)`. Let’s calculate its lighting contribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we should multiply the color by the ambient occlusion factor. Use `1.0`
    if there is no ambient occlusion texture available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we apply the emissive color contribution. Before writing the framebuffer
    output, we convert the resulting color back into the sRGB color space using a
    hardcoded gamma value of `2.2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'We mentioned a bunch of helper functions that use the `PBRInfo` structure,
    such as `getIBLRadianceContributionGGX()`, `getIBLRadianceLambertian()`, and `calculatePBRLightContribution()`.
    Let’s look inside `Chapter06/04_MetallicRoughness/src/PBR.sp` to see how they
    work. Our implementation is based on the reference implementation of the glTF
    2.0 Sample Viewer from Khronos: [https://github.com/ KhronosGroup/glTF-Sample-Viewer/tree/glTF-WebGL-PBR](https://github.com/):'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, here is the `PBRInfo` structure, which holds various input parameters
    for our metallic-roughness glTF PBR shading model. The first values represent
    the geometric properties of the surface at the current point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The following values represent the material properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The sRGB to linear color space conversion routine is implemented this way.
    It is a popular rough approximation done for simplicity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculation of the lighting contribution from an image-based light source is
    split into two parts – diffuse irradiance and specular radiance. First, let’s
    start with the radiance part. We will use the Lambertian diffuse term. Khronos
    implementation is quite complex; here, we will skip some of its details. For those
    looking into the underlying math theory, check out [https://bruop.github.io/ibl/#single_scattering_results](https://bruop.github.io/ibl/#single_scattering_results):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Radiance contribution uses the GGX model. Please note that we use roughness
    as an LOD level for the precomputed mip lookup. This trick allows us to save performance
    to avoid excessive texture lookups and integration over them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Retrieve a scale and bias to `F0` from the BRDF lookup table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Fetch values from the cube map. No conversion to the linear color space is
    required, since HDR cube maps are already linear:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s go through all the helper functions that are necessary to calculate
    different parts of the rendering equation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `diffuseBurley()` function implements the diffuse term, as discussed in
    the paper *Physically-Based Shading at Disney* by Brent Burley: [http://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdfhttp://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdf](http://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdfhttp://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdf):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'The next function models the Fresnel specular reflectance term of the rendering
    equation, also known as the `F` term:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `geometricOcclusion()` calculates the specular geometric attenuation
    `G`, where materials with a higher roughness will reflect back less light to the
    viewer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `microfacetDistribution()` models the distribution `D` of microfacet
    normals across the area being drawn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: This implementation is based on the paper *Average Irregularity Representation
    of a Roughened Surface for Ray Reflection* by T. S. Trowbridge and K. P. Reitz.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The utility function `perturbNormal()` provides a normal in world space based
    on inputs. It expects a sample from the normal map `normalSample`, sampled at
    `uv` texture coordinates, a vertex normal, `n`, and a vertex position, `v`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `cotangentFrame()` creates tangent space based on the vertex position
    `p`, the per-vertex normal vector `N`, and `uv` texture coordinates. This is not
    the best way to get the tangent basis, as it suffers from `uv` mapping discontinuities,
    but it’s acceptable to use it in cases where a per-vertex precalculated tangent
    basis is not provided:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the handedness of the resulting cotangent frame and adjust the tangent
    vector if necessary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'There’s a lot of scaffolding, so to speak, that is necessary to implement the
    glTF PBR shading model. Before we can calculate light contribution from a light
    source, we should fill in the `PBRInfo` structure fields. Let’s take a look at
    the code of `calculatePBRInputsMetallicRoughness()` to understand how this is
    done:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As it is supposed to be in glTF 2.0, roughness is stored in the `green` channel,
    and metallicity is stored in the `blue` channel. This layout intentionally reserves
    the `red` channel for optional occlusion map data. We set the minimal roughness
    value to `0.04`. It is a widely used constant for many PBR implementations. It
    comes from the assumption that even dielectrics have at least 4% specular reflection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Roughness is authored as perceptual roughness; by convention, we convert to
    material roughness by squaring the perceptual roughness. Perceptual roughness
    was introduced by Burley ([https://disneyanimation.com/publications/physically-based-shading-at-disney](https://disneyanimation.com/publications/physically-based-shading-at-disney))
    to make the roughness distribution more linear. The albedo value may be defined
    from a base texture or a flat color. Let’s compute specular reflectance the following
    way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'For a typical incident reflectance range between 4% to 100%, we should set
    the grazing reflectance to 100% for the typical Fresnel effect. For a very low
    reflectance range on highly diffuse objects, below 4%, incrementally reduce grazing
    reflectance to 0%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we should fill in the `PBRInfo` structure with these values. It is
    used to calculate the contributions of each individual light in the scene:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The lighting contribution from a single light source can be calculated in the
    following way, using the precalculated values from `PBRInfo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here, `ld` is the vector from the surface point to the light source, and `h`
    is the half vector between `ld` and `v`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Check if the light direction is correct and calculate the shading terms `F`,
    `G`, and `D` for the microfacet specular shading model, using the helper functions
    described earlier in this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the analytical lighting contribution. We obtain the final intensity
    as reflectance (BRDF), scaled by the energy of the light (the cosine law):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'That is all and should be sufficient to implement the glTF metallic-roughness
    PBR shading model. The resulting demo application should render the following
    image. Also, try using different glTF 2.0 files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.8: Physically based rendering of the Damaged Helmet glTF 2.0 model](img/file48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: Physically based rendering of the Damaged Helmet glTF 2.0 model'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The whole area of physically based rendering is vast, and given the book volume
    constraints, it is possible to only scratch its surface. In real life, much more
    complicated PBR implementations can be created, which are normally based on the
    requirements of content production pipelines. For an endless source of inspiration
    to see what can be done, we recommend looking at the Unreal Engine source code,
    which is available for free on GitHub: [https://github.com/EpicGames/UnrealEngine/tree/release/Engine/Shaders/Private](https://github.com/EpicGames/UnrealEngine/tree/release/Engine/Shaders/Private).'
  prefs: []
  type: TYPE_NORMAL
- en: In the next recipe, we will explore one more important PBR shading model, the
    glTF 2.0 specular-glossiness model, and implement a demo application for it.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the glTF 2.0 specular-glossiness shading model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Specular-glossiness is a deprecated and archived extension in the official Khronos
    repository, but we’d like to demonstrate how to use it because it’s still available
    for many existing assets. In the next chapter, we will introduce a new glTF specular
    extension that supersedes this old specular-glossiness shading model. We will
    show how to convert from this old specular glossiness to the new specular extension.
    The specular-glossiness model was initially added to glTF PBR as an extension
    to address an artistic-driven approach. For example, game development often requires
    greater flexibility in controlling the accuracy of specular effects, and the ability
    to adjust glossiness is a common necessity in such scenarios. Later on, the glTF
    PBR shading model received more advanced extensions that contradicted this initial
    one. A new specular extension was introduced to offer similar functionality to
    the standard metallic-roughness model. Consequently, Khronos recommended discontinuing
    the use of this extension, and it archived it. However, we will explore it, considering
    how many existing 3D models were created using this specular-glossiness shading
    model.
  prefs: []
  type: TYPE_NORMAL
- en: What is specular glossiness?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you may have noticed from the PBR section above, PBR doesn’t enforce how
    the material model should be expressed. The metallic-roughness model uses a simplified
    and intuitive way to describe any surface as non-metal-metal and smooth-rough.
    These parameters are still non-physically correct, but they express a wide variety
    of materials for real-life objects around us. In some cases, it’s not enough to
    express the variations in the appearance of materials, and the specular-glossiness
    model provides this flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The specular-glossiness workflow is a technique for characterizing materials
    based on their specular features. Within this method, materials are described
    using three maps: albedo, specular, and glossiness. The albedo map determines
    the material’s color, the specular map defines its reflectivity or the specular
    color of the material, and the glossiness map defines its glossiness or smoothness.'
  prefs: []
  type: TYPE_NORMAL
- en: A distinguishing factor between the metallic-roughness and specular-glossiness
    workflows lies in the specular property that specifies material reflectivity in
    RGB channels. Each channel—red, green, and blue—represents reflectivity at different
    angles, providing a wider array of material appearances compared to metallic-roughness.
    Another difference is that this property has one significant flow that cannot
    be used within the glTF PBR model. By its very nature, this value cannot distinguish
    between dielectrics and metals, and that’s the reason why the majority of glTF
    PBR extensions are not compatible with the specular-glossiness model. The Khronos
    group introduced the **KHR materials specular** extension that allows you to add
    a spectral specular color to the metallic-roughness model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The C++ source code for this recipe is in the `Chapter06/05_SpecularGlossiness`
    folder. The GLSL shader code responsible for PBR calculations can be found in
    `Chapter06/05_ SpecularGlossiness/src/PBR.sp`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This recipe is very similar to the previous one. In fact, much of the model
    loading and rendering code remains unchanged, except for retrieving values for
    different material properties. We extend the metallic-roughness data to include
    specular-glossiness parameters, and then we apply these parameters in the shader
    based on the material type.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use the 3D model *SpecGlossVsMetalRough* provided by Khronos.
    It provides a side-by-side comparison of the same model, rendered with metallic-roughness
    shading and specular-glossiness shading. You can find the glTF file here: `deps/src/glTF-Sample-Assets/Models/SpecGlossVsMetalRough/glTF/`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get started. Here are the C++ code changes necessary to accommodate specular-glossiness
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: We will modify our material data structure by adding two new data members, `vec4
    specularGlossiness` and `uint32_t materialType`. The first one will provide the
    necessary parameters for the specular-glossiness material, and the second one
    will specify the exact material type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Please notice the padding member at the end of the structure. We need it to
    keep the binary representation of this structure aligned with GLSL shader inputs.
    The GLSL `st430` layout and alignment rules are not complex but might not be correctly
    implemented by different hardware vendors, especially on mobile devices. In this
    case, manual padding is just an easy and good enough way to fix compatibility
    between all GPUs. For further reading, we recommend the official Khronos Vulkan
    Guide documentation ([https://github.com/KhronosGroup/Vulkan-Guide/blob/main/chapters/shader_memory_layout.adoc](https://github.com/KhronosGroup/Vulkan-Guide/blob/main/chapters/shader_memory_layout.adoc)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how we identify a glTF material type. We implement a helper function,
    `detectMaterialType()`, in `shared/UtilsGLTF.cpp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'The next difference is how we load extra material properties. Nothing interesting
    here; just load and assign the values using the Assimp API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: The rest of the C++ code is mostly identical to the previous recipe, *Implementing
    the glTF 2.0 metallic-roughness shading model*. The highlighted differences related
    to adjusting to the different material properties and providing necessary data.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now look at the corresponding GLSL shaders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The differences are introduced in the code of the fragment shader `05_SpecularGlossinesss/src/main.frag`,
    where we calculate and apply `PBRInfo` parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will identify the specular-glossiness material type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the material type, we will calculate `perceptualRoughness` and `f0`,
    as well as the diffuse and specular color contributions. We will follow the official
    Khronos recommendations ([https://kcoley.github.io/glTF/extensions/2.0/Khronos/KHR_materials_pbrSpecularGlossiness](https://kcoley.github.io/glTF/extensions/2.0/Khronos/KHR_materials_pbrSpecularGlossiness))
    to convert values from specular-glossiness to metallic-roughness:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'The remaining fragment shader code remains the same. The resulting image produced
    by this example should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9: Specular-glossiness versus metallic-roughness materials](img/file49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.9: Specular-glossiness versus metallic-roughness materials'
  prefs: []
  type: TYPE_NORMAL
- en: One bottle has a metallic-roughness material and the other uses a specular-glossiness
    one. As you can see, the objects appear identical, and by adjusting the specular
    and glossiness values within a compatible range, you can achieve the exact same
    result with two different shading models.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here’s an article by Don McCurdy explaining the reasons for switching over
    from the specular-glossiness shading model to the metallic-roughness one: [https://www.donmccurdy.com/2022/11/28/converting-gltf-pbr-materials-from-specgloss-to-metalrough](https://www.donmccurdy.com/2022/11/28/converting-gltf-pbr-materials-from-specgloss-to-metalrough).'
  prefs: []
  type: TYPE_NORMAL
