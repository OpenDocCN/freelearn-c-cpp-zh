- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debunking Common Myths about C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing software for microcontrollers and embedded systems is challenging. In
    order to get the most out of resource-constrained systems, embedded developers
    need to have a good knowledge of platform architecture. They need to be aware
    of available resources, including processor capabilities, available memory, and
    peripherals. The need to have direct access to hardware through memory-mapped
    peripherals has made **C** the language of choice for embedded systems for half
    a century.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of any programming language is to carry out the process of converting
    application-specific abstractions into code that can be transformed into machine
    code. For instance, **Common Business-Oriented Language** (**COBOL**) is used
    for banking applications, and **Fortran** is used for scientific research and
    heavy mathematic calculations. C is, on the other hand, a general-purpose programming
    language commonly used in **operating systems** (**OSs**) and embedded system
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: C is a language with a simple and easy-to-learn syntax. Having a simple syntax
    means it is incapable of expressing complex ideas. C allows for complex operations
    but requires more explicit and detailed code to manage complexity, compared to
    higher-level languages that abstract these details away.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the late 1970s, high-level languages couldn’t meet the performance of C.
    This motivated Danish computer scientist Bjarne Stroustrup to start working on
    **C with Classes**, a predecessor to C++. Nowadays, C++ is a multiparadigm language
    designed with performance in mind. The origin of C++ is still a source of some
    myths, which often causes hesitation in adopting it for embedded systems programming.
    This chapter will introduce you to those myths and debunk them. The following
    topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A short history of C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C with Classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bloat and runtime overhead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get the most out of this chapter, I strongly recommend using Compiler Explorer
    ([https://godbolt.org/](https://godbolt.org/)) as you read through the examples.
    Select GCC as your compiler and target x86 architecture. This will allow you to
    see standard output (stdio) results and better observe the code’s behavior. The
    examples from this chapter are available on GitHub ([https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter01](https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter01)).
  prefs: []
  type: TYPE_NORMAL
- en: A short history of C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the mid-60s, the simulation programming language **SIMULA** introduced classes
    and objects to the world of software development. **Classes** are abstractions
    that allow us to represent real-world concepts in programming in a concise way,
    making the code more human-readable. In embedded development, **UART**, **SPI**,
    **TemperatureSensor**, **PidController**, and **TemperatureController** are some
    concepts that can be implemented as classes. SIMULA also introduced hierarchical
    relationships between classes. For example, `PT100` class is also a `TemperatureSensor`
    class, and `TemperatureController` class has a member instance (object) of `TemperatureSensor`
    and a `PidController`. This became known as **object-oriented programming** (**OOP**).
  prefs: []
  type: TYPE_NORMAL
- en: 'In reflecting on the evolution of programming languages, Bjarne Stroustrup,
    the creator of C++, shared his approach to designing C++. Stroustrup aimed to
    bridge the gap between high-level abstractions and low-level efficiency. He said
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: My idea was very simple. To take ideas from SIMULA for general abstractions
    for the benefits of humans representing things, so humans could get it, with low-level
    stuff, which at that time the best language for that was C, which was done at
    Bell Labs by Dennis Ritchie. And take those two ideas and bring them together
    so that you could do high-level abstraction, but efficiently enough and close
    enough to hardware, for really demanding computing tasks
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Originally started as C with Classes by Bjarne Stroustrup, C++ transformed into
    a modern programming language that still provides direct access to hardware and
    memory-mapped peripherals. Using powerful abstractions makes writing expressive
    and highly modular code possible in C++. C++ is a general-purpose, multiparadigm
    language supporting procedural, object-oriented, and, to some extent, functional
    programming paradigms.
  prefs: []
  type: TYPE_NORMAL
- en: While C is still the language of choice for embedded development, accounting
    for up to 60% of embedded projects, the adoption of C++ has grown steadily. With
    an estimated usage of 20-30% in the embedded development field, C++ offers classes,
    improved type safety, and compile-time computation, among other features.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the features that C++ offers, C is still dominant in embedded programming.
    There are many reasons for this, and this chapter will address some of them. C++
    is a more complex language than C, making it harder for beginner developers. C
    is easier to learn and makes it possible to involve beginner developers in a project
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: The simplicity of C is good as it allows beginner developers to start contributing
    to projects faster, but it also makes writing complex logic too verbose. This
    usually results in a larger code base due to a lack of expressiveness. This is
    where C++ steps in with higher abstractions, which, if embraced, make code easier
    to read and comprehend.
  prefs: []
  type: TYPE_NORMAL
- en: The other reasons why C++ is not more widely adopted are related to myths about
    C++. It is still believed that C++ is just “C with classes,” that using C++ is
    absolutely unacceptable for safety-critical systems due to dynamic memory allocation
    in the standard library, or that it produces bloat code and adds space and time
    overhead. This chapter will address some of the most common myths about C++ in
    the context of embedded development. Let’s debunk these myths and shine a new
    light on C++ in embedded systems!
  prefs: []
  type: TYPE_NORMAL
- en: C with Classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Historically speaking, C++ started as C with Classes. The first C++ compiler,
    **Cfront**, converted C++ to C, but that was a long time ago. Over time, C and
    C++ evolved separately and are now defined by separate language standards. C has
    maintained its simplicity, while C++ has become a modern language that enables
    abstract solutions for problems without sacrificing performance levels. But C++
    is still sometimes called C with Classes, which implies that there is no added
    value in C++ except the classes.
  prefs: []
  type: TYPE_NORMAL
- en: The C++11 standard was released in 2011, and it is the second major version
    of C++. It is packed with features that modernize the language, such as range-based
    loops, lambdas, and `constexpr`. Subsequent releases, C++14, C++17, C++20, and
    C++23, kept modernizing the language and introducing features that make C with
    Classes merely a distant predecessor of modern C++.
  prefs: []
  type: TYPE_NORMAL
- en: Modern C++
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To demonstrate that C++ is not just C with Classes, let’s explore a couple
    of short C code examples and their modern C++ equivalents. Let’s start with a
    simple example of printing elements from an integer buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding C code can be translated into the following C++ code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we notice is that the C++ version is shorter. It has fewer words,
    and it’s closer to English than the C code. It is easier to read. Now, if you
    come from a C background and have not been exposed to higher-level languages,
    the first version may look easier to read, but let’s compare them. The first thing
    we notice is that the C code has defined the constant `N`, which determines the
    size of `buffer`. This constant is used to define `buffer` and as a boundary for
    the `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: Range-based loops, introduced in C++11, remove the cognitive burden of using
    the size of the container in the loop stop condition. The size information is
    already contained in the `std::array` container, which is utilized by the range-based
    loop to iterate through the array effortlessly. Also, there is no indexing of
    the buffer, as elements are accessed using constant reference, ensuring that the
    elements are not modified inside the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at some simple C code that copies all elements from the `array_a`
    integer to `array_b` if smaller than `10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the C++ code with the same functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of manually iterating through `array_a` and copying elements to `array_b`
    only if they exceed `10`, we can use the `copy_if` function from C++’s standard
    template library. The first two arguments for `std::copy_if` are iterators that
    define the range of elements to consider in `array_a`: the first iterator points
    to the beginning of the array, and the second iterator points to the position
    just beyond the last element. The third argument is the iterator pointing to the
    start of `array_b`, and the fourth is the `less_than_10` lambda expression.'
  prefs: []
  type: TYPE_NORMAL
- en: A lambda expression is an anonymous function object that can be declared at
    a location where it’s invoked or passed as an argument to a function. Please note
    that lambdas will be covered in more detail in [*Chapter 10*](Chapter_10.xhtml).
    In the case of `std::copy_if`, the `less_than_10` lambda is used to determine
    whether elements from `array_a` are to be copied to `array_b`. We could also define
    a standalone `less_than_10` function that accepts an integer and returns a Boolean
    if it is larger than 10, but using a lambda, we can write this functionality close
    to the place where we pass it to an algorithm, which makes code more compact and
    expressive.
  prefs: []
  type: TYPE_NORMAL
- en: Generic types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previous examples used the `std::array` standard library container. It is a
    class template that wraps a C-style array along with its size information. Please
    note that templates will be covered in more detail in [*Chapter 8*](Chapter_08.xhtml).
    When you use `std::array` with a specific underlying type and size, the compiler
    defines a new type in the process of **instantiation**.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::array<int, 10>` creates a container type that has an underlying C-style
    array of integers with a size of `10`. The `std::array<int, 20>` is a container
    type that has an underlying C-style array of integers with a size of `20`. The
    `std::array<int, 10>` and `std::array<int, 20>` are different types. Both have
    the same underlying type, but a different size.'
  prefs: []
  type: TYPE_NORMAL
- en: '`std::array<float, 10>` would result in a third type, as it differs from `std::array<int,
    10>` by the underlying type. Using different parameters yields different types.
    Template types are generic types that become concrete only upon instantiation.'
  prefs: []
  type: TYPE_NORMAL
- en: To better understand generic types and appreciate them, let’s examine the implementation
    of a ring buffer in C and compare it with a template-based solution in C++.
  prefs: []
  type: TYPE_NORMAL
- en: Ring buffer in C
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A **ring** or **circular buffer** is a commonly used data structure in embedded
    programming. It is commonly implemented as a set of functions around an array
    with write and read indexes used to access elements of the array. The `count`
    variable is used for array space management. The interface consists of push and
    pop functions, which are explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: A **push** function is used to store elements in a ring buffer. On every push,
    a data element is stored in the array, and the write index is incremented. If
    the write index becomes equal to the number of elements in the data array, it
    is reset to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **pop** function is used to retrieve an element from a ring buffer. On every
    pop, if the underlying array is not empty, we return an element of the array indexed
    with the read index. We increment the read index.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On every push, we increment the `count` variable and decrement it on pop. If
    the count becomes equal to the size of the data array, we need to move the read
    index forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us define the implementation requirements of the ring buffer we want to
    implement in our C module:'
  prefs: []
  type: TYPE_NORMAL
- en: It should not use dynamic memory allocation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the buffer is full, we will overwrite the oldest element
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide push and pop functions for storing data in the buffer and retrieving
    it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integers will be stored in the ring buffer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a simple solution for the preceding requirements in C:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We are using a `for` loop to initialize the buffer. As the buffer size is `5`,
    values from `5` to `9` will be stored in the buffer as the ring buffer overwrites
    the existing data. Now, what if we want to store floats in our ring buffer, chars,
    or a user-defined data structure? We could implement the same logic for different
    types and create a new set of data structures and functions called `float_ring_buffer`
    or `char_ring_buffer`. Can we make a solution that could store different data
    types and use the same functions?
  prefs: []
  type: TYPE_NORMAL
- en: 'We could use an `unsigned char` array as storage for different data types and
    use a `void` pointer to pass different data types to push and pop functions. The
    only thing that’s missing is knowing the size of the data type, and we can address
    that by adding a `size_t elem_size` member to the `ring_buffer` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This ring buffer solution can be used to store different data types. As we avoid
    using dynamic memory allocation and the `data` buffer size was determined at compile
    time, we are not flexible when it comes to defining the size of the memory needed
    for different instances of the ring buffer. Another problem we have is type safety.
    We can easily call `ring_buffer_push` with a pointer to a float and `ring_buffer_pop`
    with a pointer to an integer. The compiler can’t address this concern, and the
    possibility of a catastrophe is real. Also, by using a void pointer, we added
    a layer of indirection as we have to rely on memory to retrieve data from the
    data buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we address type-safety concerns and make it possible to define the size
    of the ring buffer in C? We can use the token-pasting (`##`) operator to create
    a set of functions for different types and sizes using macros. Let’s quickly go
    through a simple example of using the `##` operator before jumping into ring buffer
    implementation using this technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`DEFINE_SUM_FUNCTION(int)` will create a `sum_int` function that accepts and
    returns integers. If we call the `DEFINE_SUM_FUNCTION` macro with `float`, it
    will result in creating `sum_float`. Now that we have a good understanding of
    the token-pasting operator, let’s continue with ring buffer implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, this solution solves our problems of type safety and defining the size
    of a ring buffer, but it suffers from readability, both in implementation and
    when using it. We need to “call” `DECLARE_RING_BUFFER` outside of any function,
    as it is basically a macro that defines a set of functions. We also need to know
    what it does and the signature of functions it will generate. We can do this better
    with templates. Let’s see what an implementation of a ring buffer looks like in
    C++.
  prefs: []
  type: TYPE_NORMAL
- en: Ring buffer in C++
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s make a generic implementation of a ring buffer using templates. We can
    use a `std::array` class template as the underlying type and wrap our push-and-pop
    logic around it. The following is code that illustrates how the `ring_buffer`
    type could look in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The ring buffer implementation in C++ using templates is more readable and easier
    to use than the token-pasting-based solution in C. The `ring_buffer` template
    class can be used to instantiate ring buffer types with integer, float, or any
    other underlying types with different sizes. The same push-and-pop logic can be
    applied to ring buffers with different underlying types. We can apply the **Don’t
    Repeat Yourself** (**DRY**) principle to different types thanks to templates.
    **Templates** make generic types easy to implement, something that’s quite challenging
    and verbose in C.
  prefs: []
  type: TYPE_NORMAL
- en: Templates are also used for **template metaprogramming** (**TMP**), a programming
    technique in which a compiler uses templates to generate temporary source code,
    which is merged by the compiler with the rest of the source code and then compiled.
    One of the most famous examples of TMP is calculating a **factorial at compile
    time**. TMP is an advanced technique that will be covered in [*Chapter 8*](Chapter_08.xhtml).
    Modern C++ also features the `constexpr` specifier, a much more beginner-friendly
    technique for compile-time computation.
  prefs: []
  type: TYPE_NORMAL
- en: constexpr
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'C++11 introduced the `constexpr` specifier, which declares that it is possible
    to evaluate the value of the function or a variable at compile time. The specifier
    evolved over time, extending the functionality. A `constexpr` variable must be
    immediately initialized, and its type must be a `literal` type (int, float, etc.).
    This is how we declare a `constexpr` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `constexpr` specifier is the preferred way of declaring compile-time
    constants in C++ over using a C-style approach with macros. Let’s analyze a simple
    example using C-style macros:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Both `VOLTAGE` and `CURRENT` are parsed as integer `literal`s, and so is the
    result of the division. Floating-point `literal`s are declared using the `f` suffix,
    which was omitted in this case. Using `constexpr` to define compile-time constants
    is safer, as it allows us to specify the type of a constant. This is how we would
    write the same example using `constexpr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This simple example shows that `constexpr` compile-time constants are both
    safer and easier to read than traditional C-style macro constants. The other major
    usage of the `constexpr` specifier is to hint to the compiler that a function
    can be evaluated at compile time. Some of the requirements that a `constexpr`
    function must meet are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The return type must be a `literal` type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the function parameters must be a `literal` type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `constexpr` function is not a constructor, it needs to have precisely
    one `return` statement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us examine a simple example utilizing `constexpr` functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To better understand what is going on under the hood, we will inspect the assembly
    output of the preceding code. Assembly is quite close to the machine code, or
    the instructions that will be executed on our target, thus inspecting it gives
    us an estimate of the work (number of instructions) performed by the processor.
    The assembly output of the compilation of the preceding program for the ARM architecture
    using an ARM GCC compiler and no optimization is shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting assembly code is doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating the stack pointer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling the square function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing value returned by `r0` to address contained into `r7` with offset `4`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the value from address stored in `r7` with offset `4` into `r3`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving the value from `r3` to `r0`, which is the ARM calling convention’s designated
    register for storing return values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can see that there are some unnecessary operations in the output binary,
    which both increase the binary size and affect the performance. This example is,
    both valid C and valid C++ code, and compiling it with both C and C++ compilers
    will yield the same assembly code.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the `constexpr` specifier for the `square` function, we are instructing
    the compiler that it is possible to evaluate it at compile time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This code results in a compile-time evaluation of the `square(2)` expression,
    making the `val` integer a `constexpr` variable, that is, a compile-time constant.
    The following is the resulting assembly code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the program returns the value `4`, which is the result of the
    `square(2)` compile-time computation. There is no `square` function in the generated
    assembly, just the result of the calculation that the compiler performed for us.
    This simple example demonstrates the power of compile-time computing. We can move
    heavy computation from runtime to compile time whenever we know all the computation
    parameters, which is often. This approach can be used to generate lookup tables
    or complex mathematical signals, which will be demonstrated in the following chapters
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: C++ has come a long way since C with Classes. The examples in this chapter show
    what C++ can offer over C – expressive, more readable, compact code; standard
    template library containers; algorithms; user-defined generic types; and compile-time
    computation, just to start with. I hope I managed to debunk the myth that C++
    is just C with classes. The next common myth about C++ is that it makes bloated
    code and adds runtime overhead. Let’s keep debunking the myths about C++!
  prefs: []
  type: TYPE_NORMAL
- en: Bloat and runtime overhead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **bloatware** describes unwanted software that is preinstalled with
    an OS on a device. Unwanted software in the world of programming describes code
    inserted in a binary by a framework, a library, or a language construct itself.
    Language constructs in C++ that are blamed for causing code bloat are constructors,
    destructors, and templates. We will analyze these misconceptions by examining
    assembly output generated from C++ code.
  prefs: []
  type: TYPE_NORMAL
- en: Constructors and destructors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing that comes to mind to non-C++ developers when you mention C++
    is that it is an object-oriented language and that you are bound to instantiate
    objects. Objects are instances of classes. They are variables that occupy memory.
    Special functions, called **constructors**, are used to construct or instantiate
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: Constructors are used to initialize objects, including the initialization of
    class members, and destructors are used to clean up resources. They are tightly
    tied to an object’s life cycle. An object is created using a constructor, and
    when the object variable goes out of scope, the **destructor** is called.
  prefs: []
  type: TYPE_NORMAL
- en: 'Constructors and destructors both increase the size of the binary and add runtime
    overhead, as their execution takes time. We will examine the impact of constructors
    and destructors on a simple example of a class with one private member, a constructor,
    a destructor, and a getter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '`MyClass` is a very simple class that has one private member, which we set
    through the constructor. We can access it through a getter, and just for good
    measure, we declared a destructor, which is empty. The following is the assembly
    equivalent of the preceding code compiled with no optimization enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Don’t worry about the assembly if you don’t understand it. We can see there
    are some labels for functions and a whole lot of instructions. That’s a lot of
    instructions for a simple abstraction of a class; this is the bloat code that
    we don’t want in our binary. To be more precise, we have 59 lines of assembly
    code. If we were to enable optimization, the resulting assembly would be a couple
    of lines long, but let’s keep analyzing this problem with no optimization involved.
    The first thing we are noticing is that the destructor doesn’t do anything useful.
    If we remove it from the C++ code, the resulting assembly is 44 lines long:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there is no call to the destructor, and there is no destructor
    code in the binary. The lesson is *you don’t pay for what you don’t use*. This
    is one of the design principles of C++. By deleting the destructor, there is no
    need for the compiler to generate any code for it and to call it when the object
    variable goes out of the scope.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing we must realize is that C++ is not an OOP language. It is a
    multiparadigm language. It is procedural, object-oriented, generic, and even a
    little bit functional at the same time. If we want to have private members that
    can be set only through constructors, then we need to pay the price for that.
    Structs in C++ have public members by default, so let’s change the `MyClass` class
    to a `MyClass` struct with no constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Setter and getter functions are common in the OOP paradigm, but C++ is not
    (just) an OOP language and we are not bound to using setters and getters. When
    we remove the `getNum` getter, we have a very basic example of a struct with just
    one member. The resulting assembly is only 14 lines long:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As trivial as this example is, its purpose is to establish two ground truths:'
  prefs: []
  type: TYPE_NORMAL
- en: You don’t pay for what you don’t use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using C++ doesn’t mean you are bound to an OOP paradigm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to pay the price in binary size if we want to use abstractions such
    as constructors and destructors. Using types (classes and structs) without instantiating
    objects in C++ offers significant benefits to your embedded software design beyond
    traditional object-oriented approaches. We’ll explore this through detailed examples
    in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this and previous examples, we compiled C++ code with disabled optimizations,
    and we were able to see the resulting assembly code results in unnecessary operations
    that can be removed. Let’s check the assembly code for the last example with the
    `O3` optimization level enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The preceding assembly is the output of the original example with the class,
    constructor, destructor, and getter function. The resulting program has just two
    instructions. The value of the `num` member of the `obj` variable is stored in
    the `r0` register as the return value. Assembly code is stripped of all necessary
    instructions related to stack manipulation and usage of `r3` to store a value
    in a stack pointer with an offset of `4`, reload it to `r3`, and move it to `r0`.
    The resulting assembly is just a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Removing unnecessary instructions is a job for the optimization process. Yet,
    optimization is often avoided in embedded projects, as some claim that it breaks
    code. But is that true?
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unoptimized code results in unnecessary instructions affecting binary size and
    performance. However, many embedded projects are still built with disabled optimization,
    as developers *do not trust the compiler* and are afraid it will *break the program*.
    There is some truth to this, but as it turns out, this happens when the program
    is not well formed. The program is not well formed if it contains undefined behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the best-known examples of undefined behavior is signed **integer overflow**.
    The standard doesn’t define what happens if you add `1` to the maximum value of
    the signed integer on your platform. The compiled program is not required to do
    anything meaningful. A program is not well formed. Let’s examine the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Compiling the code using GCC for both x86 and Arm Cortex-M4 will yield the same
    results. If the program is compiled without the optimization, the `foo` function
    returns `0`, and you can see **X is NOT larger than X + 1\. Oh nooo !** in the
    output. The compiler does the integer overflow, and if we pass the maximum integer
    value to `foo`, it will return `0`. Keep in mind that the standard does not specify
    this, and this behavior depends on the compiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we compile the program with optimization enabled, the output is **X is larger
    than X + 1**`,` which means that `foo` returns `1`. Let’s examine the assembly
    output of the program compiled with the optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `foo` doesn’t perform any calculations. The compiler assumes
    that the program is well formed and that there is no undefined behavior. `foo`
    will always return `1`. It is up to the developer to ensure that there is no undefined
    behavior in the program. This is exactly the reason why the myth that the optimization
    breaks the program is still alive. It is easier to blame the compiler for not
    handling the undefined behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, it is possible that there is a bug in a compiler that breaks the
    functionality of the program if the optimization is used, and the program works
    fine if it is disabled. This is very rare but not unheard of, and that’s why there
    are verification techniques such as unit and integration testing that ensure the
    functionality of the code, whether it is built with or without the optimization
    enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization is reducing the binary size and improving performance by removing
    unnecessary instructions from the machine code. Undefined behavior is compiler-dependent
    and must be handled by the developer to ensure the program is well formed. Techniques
    such as unit and integration testing should be put in place to validate the functionality
    of the program, mitigating the risk of compiler malforming the program. The optimization
    process is essential for using abstractions in C++ code while keeping the binary
    footprint minimum and performance at a maximum. We will use the highest optimization
    level, `O3`, in the rest of the book.
  prefs: []
  type: TYPE_NORMAL
- en: The next suspect for code bloat that we will examine are templates. How do they
    cause the code bloat, and what value do they bring to our embedded code bases?
  prefs: []
  type: TYPE_NORMAL
- en: Templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instantiating **templates** with different parameters will result in the compiler
    generating distinct types, which effectively increases the binary size. This is
    to be expected. We have the exact same situation with the generic implementation
    of a ring buffer in C using the token-pasting operator and macros. An alternative
    is type erasure, which we used in C implementation using a void pointer. It suffers
    in flexibility if we impose the restriction of static data allocation and performance
    due to pointer indirection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using generic types is a choice of design. We can use them and pay the price
    in increased binary size, but that would also happen if we were to implement ring
    buffers for different data types separately (`ring_buffer_int`, `ring_buffer_float`,
    etc.). Maintaining a single templated type is much easier than fixing the same
    bug in a few different places in the code base. The usage of generic types doesn’t
    result in a binary size any larger than the size of an equivalent implementation
    of individual types. Let’s examine the impact of templates on binary size in relation
    to separate implementations using the `ring_buffer` example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The program will use a generic `ring_buffer type` if built with `USE_TEMPLATES`
    defined, and it will use the `ring_buffer_int` and `ring_buffer_float` types otherwise.
    If we build this example with GCC with no optimization enabled, it will result
    in a slightly bigger binary size in the template version (24 bytes). This is due
    to larger symbols in the symbol table when using the templated version. If we
    strip the symbol table from the object files, they will result in the same size.
    Also, building two versions with `O3` results in the same binary size.
  prefs: []
  type: TYPE_NORMAL
- en: Generic types do not increase the binary size more than if we wrote instantiated
    types by hand as separate types. Templates have an effect on the build time due
    to the instantiation of concrete types in different compilation units, and there
    are techniques to avoid this if needed. All functions related to the instantiated
    types with the same parameters will result in a single function in the binary,
    as the linker will remove duplicate symbols.
  prefs: []
  type: TYPE_NORMAL
- en: RTTI and exceptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Runtime type information** (**RTTI**) in C++ is a mechanism that allows the
    type of an object to be determined at runtime. Most compilers implement RTTI using
    the virtual tables. Each polymorphic class (a class with at least one virtual
    function) has a virtual table that, among other things, includes type information
    for runtime type identification. RTTI imposes both time and space costs. It increases
    binary size and affects the runtime performance if type identification is used.
    This is the reason why compilers have a way of disabling RTTI. Let’s examine a
    simple example with a base and derived class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Classes with virtual functions have vtables that are used for dynamic dispatching.
    Dynamic dispatch is a process of selecting which implementation of a polymorphic
    function is used. The `printer` function accepts a reference to the `Base` class.
    Depending on the type of reference passed to `printer` (`Base` or `Derived`),
    the dynamic dispatching process will select the `print` method from either the
    `Base` or `Derived` class. Vtables are also used to store type information.
  prefs: []
  type: TYPE_NORMAL
- en: 'By using `dynamic_cast`, as a part of the RTTI mechanism, we can find the information
    about the type using a reference or pointer to the superclass. Let’s modify the
    `printer` method from the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'As we already mentioned, RTTI can be disabled. In GCC, we can do this by passing
    the `-fno-rtti` flag to the compiler. If we try to compile the modified example
    using this flag, the compiler will raise `error: dynamic_cast'' not permitted
    with ''-fno-rtti''`. If we restore the `printer` method to the original implementation,
    remove the `if` statement, and build it with both RTTI enabled and then disabled,
    we can notice that the binary size is larger when RTTI is enabled. RTTI is useful
    in certain scenarios, but it adds a massive overhead to resource-constrained devices,
    so we will leave it disabled.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another C++ feature that is often disabled in embedded projects in C++ is exceptions.
    **Exceptions** are an error-handling mechanism based on a try-catch block. Let’s
    take a look at a simple example utilizing exceptions to understand them better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In this simple example, `foo` is called in the `try` block. It creates a local
    object, `a`, and calls `bar`. The `bar` function creates a local object, `b`,
    and throws an exception. In the output, we see that `A` and `B` are created, then
    `B` gets destroyed, then `A` gets destroyed, and we finally see that the `catch`
    block gets executed. This is called **stack unwinding**, and for it to happen,
    standard implementations most commonly utilize unwind tables, which store information
    about catch handlers, destructors to be called, and so on. Unwind tables can grow
    large and become complex, which increases the memory footprint of the application
    and introduces non-determinism due to the mechanism used at runtime for exception
    handling. This is why exceptions are often disabled in embedded system projects.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C++ is guided by the **zero-overhead principle**. The only two language features
    that do not follow it are RTTI and exceptions, and that’s why compilers support
    a switch for turning them off.
  prefs: []
  type: TYPE_NORMAL
- en: 'The zero-overhead principle is based on two statements that we established
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: You don’t pay for what you don’t use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What you do use is just as efficient as what you could reasonably write by hand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RTTI and exceptions are disabled in most embedded projects, so you don’t pay
    for them. Using generic types and templates is a design choice and is no more
    expensive than writing individual types by hand (`ring_buffer_int`, `ring_buffer_float`,
    and so on), but it lets you reuse the code logic for different types, makes the
    code more readable and easier for maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Working on high-risk systems is not a reason to disable compiler optimization
    capabilities. Code functionality needs to be verified whether we are building
    a program with optimization disabled or enabled. The most common source of bugs
    when optimization is enabled is undefined behavior. Understanding the undefined
    behavior and preventing it is up to the developer.
  prefs: []
  type: TYPE_NORMAL
- en: Modern C++ is a language that has a lot to offer to the embedded world. The
    mission of this book is to help you discover C++ and what it can do for your embedded
    projects, so let’s embark on the path of discovering C++ and utilizing it to solve
    problems in the embedded domain.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go over challenges in embedded systems with limited
    resources and dynamic memory management in C++.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/embeddedsystems](https://packt.link/embeddedsystems)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_code_Discord.png)'
  prefs: []
  type: TYPE_IMG
