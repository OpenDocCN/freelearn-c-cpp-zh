- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Exploring C++ Concepts from A Low-Latency Application’s Perspective
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从低延迟应用程序的角度探索C++概念
- en: In this chapter, we assume that the reader has an intermediate level of understanding
    of C++ programming concepts, features, and so on. We will discuss how to approach
    low-latency application development in C++. We will move on to discussing what
    C++ features to avoid specifically when it comes to low-latency applications.
    We will then discuss the key C++ features that make it perfect for low-latency
    applications and how we will use them in the rest of the book. We will conclude
    by discussing how to maximize compiler optimizations and which C++ compiler flags
    are important for low-latency applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们假设读者对C++编程概念、特性和等内容有中级理解。我们将讨论如何接近C++中的低延迟应用程序开发。我们将继续讨论在低延迟应用程序中应避免的特定C++特性。然后，我们将讨论使C++成为低延迟应用程序完美选择的键特性，以及我们将在本书的其余部分如何使用它们。最后，我们将讨论如何最大化编译器优化，以及哪些C++编译器标志对低延迟应用程序很重要。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Approaching low-latency application development in C++
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接近C++中的低延迟应用程序开发
- en: Avoiding pitfalls and leveraging C++ features to minimize application latency
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免陷阱并利用C++特性以最小化应用程序延迟
- en: Maximizing C++ compiler optimization parameters
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大化C++编译器优化参数
- en: Let us start by discussing the higher-level ideas when it comes to approaching
    low-latency application development in C++ in the next section.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将首先讨论在C++中开发低延迟应用程序时需要考虑的高级思想。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code for this book can be found in the GitHub repository for this book
    at [https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP](https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP).
    The source code for this chapter is in the Chapter3 directory in the repository.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有代码都可以在本书的GitHub仓库中找到，该仓库地址为[https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP](https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP)。本章的源代码位于仓库中的Chapter3目录下。
- en: Approaching low-latency application development in C++
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接近C++中的低延迟应用程序开发
- en: In this section, we will discuss the higher-level ideas to keep in mind when
    trying to build low-latency applications in C++. Overall, the ideas are to understand
    the architecture that your application runs on, your application use cases that
    are latency-sensitive, the programming language of your choice (C++ in this case),
    how to work with the development tools (the compiler, linker, etc.) and how to
    measure application performance in practice to understand which parts of the application
    to optimize first.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论在C++中尝试构建低延迟应用程序时需要牢记的高级思想。总的来说，这些思想包括理解应用程序运行的架构、对延迟敏感的应用程序用例、选择的语言（在本例中为C++），如何使用开发工具（编译器、链接器等）以及如何在实践中测量应用程序性能以了解哪些部分的应用程序需要首先优化。
- en: Coding for correctness first, optimizing second
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 首先编写正确的代码，然后进行优化
- en: For low-latency applications, correct behavior of the application under different
    use cases and scenarios and robust handling of edge conditions is still the primary
    focus. A fast application that does not do what we need is useless, so the best
    approach when it comes to developing a low-latency application is to first code
    for correctness, not speed. Once the application works correctly, only then the
    focus should be shifted to optimizing the critical parts of the application while
    maintaining correctness. This ensures that developers spend time focusing on the
    correct parts to optimize because it is common to find that our intuition on which
    pieces are critical to performance does not match what happens in practice. Optimizing
    the code can also take significantly longer than coding for correctness, so it
    is important to optimize the most important things first.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于低延迟应用程序，应用程序在不同用例和场景下的正确行为以及边缘条件的鲁棒处理仍然是首要关注点。一个快速但无法完成我们所需任务的应用程序是无用的，因此，在开发低延迟应用程序时，最佳方法是首先确保代码的正确性，而不是速度。一旦应用程序运行正确，焦点应转移到优化应用程序的关键部分，同时保持正确性。这确保了开发者将时间集中在正确的部分进行优化，因为通常会发现我们对哪些部分对性能至关重要的直觉与实际情况不符。优化代码也可能比编写正确代码花费更长的时间，因此，首先优化最重要的部分非常重要。
- en: Designing optimal data structures and algorithms
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计最优的数据结构和算法
- en: Designing custom data structures that are optimal for the application’s use
    cases is an important part of building low-latency applications. A good amount
    of thought needs to be put into each data structure used in the critical parts
    of the application in terms of scalability, robustness, and performance under
    the use cases and data encountered *in practice*. It is important to understand
    why we mention the term *in practice* here because different data structure choices
    will perform better under different use cases and input data even if the different
    data structures themselves have the same output or behavior. Before we discuss
    an example of different possible data structures and algorithms to solve the same
    problem, let us quickly review Big-O notation. Big-O notation is used to describe
    the asymptotic worst-case time complexity of performing a certain task. The term
    asymptotic here is used to describe the fact that we discuss cases where we measure
    the performance over a theoretically infinite (in practice an exceptionally large)
    number of data points. The asymptotic performance eliminates all the constant
    terms and describes the performance only as a function of the number of input
    data elements.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 设计针对应用程序用例最优化的自定义数据结构是构建低延迟应用程序的重要组成部分。在考虑可扩展性、健壮性和在实际情况和遇到的数据下的性能时，需要仔细考虑应用程序关键部分使用的每个数据结构。重要的是要理解为什么我们在这里提到“实际情况”，因为即使不同的数据结构本身具有相同的输出或行为，不同的数据结构选择在不同用例和输入数据下也会表现更好。在我们讨论不同可能的数据结构和算法来解决相同问题的例子之前，让我们快速回顾一下大O符号。大O符号用于描述执行特定任务时的渐近最坏情况时间复杂度。这里的渐近一词用来描述我们讨论的是在理论上无限（在实际情况中是一个异常大的）数据点上的性能测量。渐近性能消除了所有常数项，仅描述性能作为输入数据元素数量的函数。
- en: A simple example of using different data structures to solve the same problem
    would be searching for an entry in a container by a key value. We can solve this
    either by using a hash map implementation that has an expected *amortized* complexity
    of `O(1)` or using an array that has a complexity of `O(n)`, where `n` is the
    number of elements in the container. While on paper it might appear that the hash
    map is clearly the way to go, other factors such as the number of elements, the
    complexity of applying the hash function to the keys, and so on might change which
    data structure is the way to go. In this case, for a handful of elements, the
    array solution is faster due to better cache performance, while for many elements,
    the hash map solution is better. Here, we chose a suboptimal algorithm because
    the underlying data structure for the suboptimal algorithm performed better in
    practice due to cache performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的数据结构来解决相同问题的简单例子之一是通过键值在容器中搜索条目。我们可以通过使用具有预期平均复杂度为 `O(1)` 的哈希表实现，或者使用具有复杂度为
    `O(n)` 的数组来解决此问题，其中 `n` 是容器中元素的数量。虽然在纸上可能看起来哈希表显然是更好的选择，但其他因素，如元素数量、将哈希函数应用于键的复杂度等，可能会改变选择哪种数据结构。在这种情况下，对于少量元素，由于更好的缓存性能，数组解决方案更快，而对于大量元素，哈希表解决方案更好。在这里，我们选择了一个次优算法，因为该算法的底层数据结构在实际应用中由于缓存性能表现更好。
- en: Another slightly different example would be using lookup tables over recomputing
    values for some mathematical functions, say, trigonometric functions. While it
    makes complete sense that looking up the result in a precomputed lookup table
    *should* always be faster compared to performing some calculations, this might
    not always be true. For instance, if the lookup table is very large, then the
    cost of evaluating a floating-point expression might be less than the cost of
    getting a cache miss and reading the lookup table value from the main memory.
    The overall application performance might also be better if accessing the lookup
    table from the main memory leads to a lot of cache pollution, leading to performance
    degradation in other parts of the application code.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个略有不同的例子是使用查找表而不是重新计算某些数学函数的值，例如三角函数。虽然从预计算的查找表中查找结果应该总是比执行一些计算更快，但这并不总是正确的。例如，如果查找表非常大，那么评估浮点表达式的成本可能低于从主内存中获取缓存未命中并读取查找表值的成本。如果从主内存访问查找表导致大量缓存污染，从而降低应用程序代码其他部分的性能，那么整体应用程序性能也可能更好。
- en: Being mindful of the processor
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注意处理器
- en: Modern processors have a lot of architectural and functional details that a
    low-latency application developer should understand, especially a C++ developer
    since it allows very low-level control. Modern processors have multiple cores,
    larger and specialized register banks, pipelined instruction processing where
    instructions needed next are prefetched while executing the current one, instruction
    level parallelism, branch predictions, extended instruction sets to facilitate
    faster and specialized processing, and so on. The better the application developer
    understands these aspects of the processor on which their applications will run,
    the better they can avoid sub-optimal code and/or compilation choices and make
    sure that the compiled machine code is optimal for their target architecture.
    At the very least, the developer should instruct the compiler to output code for
    their specific target architecture using compiler optimization flags, but we will
    discuss that topic later in this chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现代处理器具有许多架构和功能细节，低延迟应用程序开发者应该了解这些细节，尤其是C++开发者，因为它允许非常低级别的控制。现代处理器拥有多个核心、更大的专用寄存器组、流水线指令处理（在执行当前指令的同时预取下一个所需的指令）、指令级并行性、分支预测、扩展指令集以促进更快和专门的处理器，等等。应用程序开发者对其应用程序将运行的处理器这些方面的理解越好，他们就能更好地避免次优代码和/或编译选择，并确保编译的机器代码针对其目标架构是最佳的。至少，开发者应该指导编译器使用编译器优化标志输出针对其特定目标架构的代码，但我们将在此章节的后面讨论这个话题。
- en: Understanding the cache and memory access costs
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解缓存和内存访问成本
- en: Typically, a lot of effort is put into the design and development of data structures
    and algorithms when it comes to low-latency application development from the perspective
    of reducing the amount of work done or the number of instructions executed. While
    this is the correct approach, in this section, we would like to point out that
    thinking about cache and memory accesses is equally important.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在低延迟应用程序开发中，为了减少完成的工作量或执行的指令数量，人们会在数据结构和算法的设计和开发上投入大量精力。虽然这是正确的方法，但在本节中，我们想指出，考虑缓存和内存访问同样重要。
- en: We saw in the previous sub-section, *Designing optimal data structures and algorithms*,
    that it is common for data structures and algorithms that are sub-optimal on paper
    to outperform ones that are optimal on paper. A large reason behind that can be
    the higher cache and memory access costs for the optimal solution outweighing
    the time saved because of the reduced number of instructions the processor needs
    to execute. Another way to think about this is that even though the amount of
    work from the perspective of the number of algorithmic steps is less, in practice,
    it takes longer to finish with the modern processor, cache, and memory access
    architectures today.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一小节“设计最优的数据结构和算法”中，我们看到了一个常见现象，即那些在纸上表现不佳的数据结构和算法往往能超越那些在纸上表现最优的。这背后的一个重要原因是，最优解决方案的更高缓存和内存访问成本可能会超过由于指令数量减少而节省的时间。另一种思考方式是，尽管从算法步骤数量的角度来看工作量较少，但在实际操作中，使用现代处理器、缓存和内存访问架构，完成这些工作需要更长的时间。
- en: Let us quickly review the memory hierarchy in a modern computer architecture.
    Note that details of what we will recap here can be found in our other book, *Developing
    High-Frequency Trading Systems*. The key points here are that the memory hierarchy
    works in such a way that if the CPU cannot find the data or instruction it needs
    next in the register, it goes to the L0 cache, and if it cannot find it there,
    goes to the L1 cache, L2, other caches, and so on, then goes to the main memory
    in that order. Note that the storage is accessed from fastest to slowest, which
    also happens to be least amount of space to most amount of space. The art of effective
    low-latency and cache-friendly application development relies on writing code
    that is cognizant of code and data access patterns to maximize the likelihood
    of finding data in the fastest form of storage possible. This relies on maximizing
    the concepts of **temporal locality** and **spatial locality**. These terms mean
    that data accessed recently is likely to be in the cache and data next to what
    we just accessed is likely to be in the cache, respectively. The following diagram
    visually lays out the register, cache, and memory banks and provides some data
    on access times from the CPU. Note that there is a good amount of variability
    in the access times depending on the hardware and the constant improvements being
    made to technologies. The key takeaway here should be that there is a significant
    increase in access times as we go from CPU registers to cache banks to the main
    memory.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下现代计算机架构中的内存层次结构。请注意，我们在这里回顾的细节可以在我们另一本书《开发高频交易系统》中找到。这里的关键点是内存层次结构以这种方式工作：如果
    CPU 在寄存器中找不到它需要的下一个数据或指令，它会去 L0 缓存，如果在那里也找不到，它会去 L1 缓存、L2、其他缓存，然后按此顺序去主内存。请注意，存储的访问是从最快到最慢的，这也恰好是从空间最少到空间最多的顺序。有效低延迟和缓存友好型应用程序开发的技巧在于编写能够意识到代码和数据访问模式的代码，以最大化在最快形式的存储中找到数据的可能性。这依赖于最大化**时间局部性**和**空间局部性**的概念。这些术语意味着最近访问的数据很可能在缓存中，而我们刚刚访问的数据旁边的数据很可能也在缓存中，分别。以下图表直观地展示了寄存器、缓存和内存银行，并提供了一些从
    CPU 访问的时间数据。请注意，根据硬件的不同以及技术不断进行的改进，访问时间有很大的变化。这里的关键教训应该是，当我们从 CPU 寄存器到缓存银行再到主内存时，访问时间有显著的增加。
- en: '![Figure 3.1 – The hierarchy of memory in modern computer architectures. ](img/Figure_3.1_B19434.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – 现代计算机架构中内存的层次结构](img/Figure_3.1_B19434.jpg)'
- en: Figure 3.1 – The hierarchy of memory in modern computer architectures.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 现代计算机架构中内存的层次结构。
- en: I would advise you to think carefully about the cache and memory access patterns
    for the algorithm locally, as well as the entire application globally, to make
    sure that your source code optimizes cache and memory access patterns, which will
    boost overall application performance. If you have a function that executes very
    quickly when it is called but causes a lot of cache pollution, that will degrade
    the complete application’s performance because other components will incur additional
    cache miss penalties. In such a case, we have failed in our objective of having
    an application that performs optimally even though we might have managed to make
    this function perform optimally locally.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您仔细思考算法在局部以及整个应用程序全局的缓存和内存访问模式，以确保您的源代码优化了缓存和内存访问模式，这将提升整体应用程序的性能。如果您有一个函数在调用时执行非常快，但会造成大量的缓存污染，这将降低整个应用程序的性能，因为其他组件将承担额外的缓存未命中惩罚。在这种情况下，我们未能实现我们的目标，即使我们可能已经成功使这个函数在局部上表现最优。
- en: Understanding how C++ features work under the hood
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 C++ 功能在底层是如何工作的
- en: When developing low-latency applications, it is very important that the developers
    have an extremely good understanding of how the high-level language abstractions
    work at a lower level or “under the hood.” For applications that are not latency-sensitive,
    this is perhaps not as important since if the application behaves the way the
    developer intends it to, the extremely low-level details of how their source code
    achieves that is not relevant.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发低延迟应用程序时，开发者对高级语言抽象在较低级别或“底层”是如何工作的有极其深入的理解是非常重要的。对于非延迟敏感的应用程序，这可能并不那么重要，因为如果应用程序的行为符合开发者的意图，那么他们的源代码如何以极低级别的细节实现这一点并不相关。
- en: For low-latency applications in C++, the more knowledge the developer has of
    how their program gets compiled into machine code, the better they can use the
    programming language to achieve low-latency performance. A lot of high-level abstractions
    available in C++ improve the ease and speed of development, robustness and safety,
    maintainability, software design elegance, and so on, but not all of them might
    be optimal when it comes to low-latency applications.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于C++中的低延迟应用程序，开发者对其程序如何编译成机器代码的了解越多，他们就越能有效地使用编程语言来实现低延迟性能。C++中可用的许多高级抽象提高了开发的速度和便捷性、健壮性和安全性、可维护性、软件设计的优雅性等，但并非所有这些在低延迟应用程序中都是最优的。
- en: Many C++ features, such as dynamic polymorphism, dynamic memory allocation,
    and exception handling, are great additions to the language for most applications.
    However, these are best avoided or used sparingly or used in a specific manner
    when it comes to low-latency applications since they have larger overheads.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 许多C++特性，如动态多态、动态内存分配和异常处理，对于大多数应用程序来说都是很好的补充。然而，当涉及到低延迟应用程序时，最好避免或少量使用，或者以特定方式使用，因为它们具有更大的开销。
- en: Conversely, traditional programming practices suggest the developer break everything
    down into numerous very small functions for reusability; use recursive functions
    when applicable; use **Object-Oriented Programming** (**OOP**) principles, such
    as inheritance and virtual functions; always use smart pointers instead of raw
    pointers; and so on. These principles are sensible for most applications, but
    for low-latency applications, these need to be evaluated and used carefully because
    they might add non-trivial amounts of overhead and latency.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，传统的编程实践建议开发者将一切分解成许多非常小的函数以提高可重用性；在适用的情况下使用递归函数；使用**面向对象编程**（**OOP**）原则，如继承和虚函数；始终使用智能指针而不是原始指针；等等。这些原则对于大多数应用程序来说是合理的，但对于低延迟应用程序，这些原则需要仔细评估和谨慎使用，因为它们可能会增加非平凡的额外开销和延迟。
- en: The key takeaway here is that it is important for low-latency application developers
    to understand each one of these C++ features very well to understand how they
    are implemented in machine code and what impact they have on the hardware resources
    and how they perform in practice.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键要点是，对于低延迟应用程序的开发者来说，了解每个C++特性非常重要，以了解它们如何在机器代码中实现，它们对硬件资源有什么影响，以及它们在实际中的表现。
- en: Leveraging the C++ compiler
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用C++编译器
- en: The modern C++ compiler is truly a fascinating piece of software. There is an
    immense amount of effort invested into building these compilers to be robust and
    correct. A lot of effort is also made to make them very intelligent in terms of
    the transformations and optimizations they apply to the developer’s high-level
    source code. Understanding how the compiler translates the developer’s code into
    machine instructions, how it tries to optimize the code, and when it fails is
    important for low-latency application developers looking to squeeze as much performance
    out of their applications as possible. We will discuss the workings of the compiler
    and optimization opportunities extensively in this chapter so that we can learn
    to work with the compiler instead of against it when it comes to optimizing our
    final application’s representation (machine code executable).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现代的C++编译器确实是一件令人着迷的软件。为了构建这些编译器以使其健壮和正确，投入了巨大的努力。还投入了大量努力，使它们在将开发者的高级源代码转换为机器指令以及它们如何尝试优化代码方面非常智能。对于希望尽可能从其应用程序中提取性能的低延迟应用程序开发者来说，了解编译器如何将开发者的代码转换为机器指令，它如何尝试优化代码以及何时失败是很重要的。我们将在本章中广泛讨论编译器的工作原理和优化机会，以便我们能够学会在优化最终应用程序表示（机器代码可执行文件）时与编译器合作，而不是对抗它。
- en: Measuring and improving performance
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量和提高性能
- en: We mentioned that the ideal application development journey involves first building
    the application for correctness and then worrying about optimizing it after that.
    We also mentioned that it is not uncommon for a developer’s intuition to be incorrect
    when it comes to identifying performance bottlenecks.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到，理想的应用程序开发之旅首先是为了确保正确性而构建应用程序，然后才考虑优化它。我们也提到，当涉及到识别性能瓶颈时，开发者的直觉往往是不正确的。
- en: Finally, we also mentioned that the task of optimizing an application can take
    significantly longer than the task of developing it to perform correctly. For
    that reason, it is advisable that before embarking on an optimization journey,
    the developer try to run the application under practical constraints and inputs
    to check performance. It is important to add instrumentation to the application
    in different forms to measure the performance and find bottlenecks to understand
    and prioritize the optimization opportunities. This is also an important step
    since as the application evolves, measuring and improving performance continues
    to be part of the workflow, that is, measuring and improving performance is a
    part of the application’s evolution. In the last section of this book, *Analyzing
    and improving performance*, we will discuss this idea with a real case study to
    understand this better.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们也提到，优化应用程序的任务可能比正确执行它的任务花费的时间长得多。因此，在开始优化之旅之前，建议开发者尝试在实际约束和输入下运行应用程序，以检查性能。在应用程序中添加不同形式的仪器来测量性能和找到瓶颈，以了解和优先考虑优化机会是很重要的。这也是一个重要的步骤，因为随着应用程序的发展，测量和改进性能继续是工作流程的一部分，也就是说，测量和改进性能是应用程序演变的一部分。在本书的最后一节“分析和改进性能”中，我们将通过一个实际案例研究来讨论这个想法，以更好地理解这一点。
- en: Avoiding pitfalls and leveraging C++ features to minimize application latency
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免陷阱并利用C++特性以最小化应用程序延迟
- en: In this section, we will look at different C++ features that, if used correctly,
    can minimize application latency. We will also discuss the details of using these
    features in a manner that optimizes application performance throughout this sub-section.
    Now, let us start learning about how to use these features correctly to maximize
    application performance and avoid the pitfalls to minimize latency. Note that
    all the code snippets for this chapter are in the `Chapter3` directory in the
    GitHub repository for this book.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨不同的C++特性，如果使用得当，可以最小化应用程序延迟。我们还将讨论如何使用这些特性来优化应用程序性能的细节。现在，让我们开始学习如何正确使用这些特性以最大化应用程序性能并避免陷阱以最小化延迟。请注意，本章的所有代码片段都存储在本书的GitHub仓库的`Chapter3`目录中。
- en: Choosing storage
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择存储
- en: Local variables created within a function are stored on the stack by default
    and the stack memory is also used to store function return values. Assuming no
    large objects are created, the same range of stack storage space is reused a lot,
    resulting in great cache performance due to locality of reference.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数内部创建的局部变量默认存储在栈上，栈内存也用于存储函数的返回值。假设没有创建大对象，相同的栈存储空间会被大量重用，由于引用的局部性，这导致了出色的缓存性能。
- en: Register variables are closest to the processor and are the fastest possible
    form of storage available. They are extremely limited, and the compiler will try
    to use them for the local variables that are used the most, another reason to
    prefer *local variables*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 寄存器变量最接近处理器，是可用的最快存储形式。它们极其有限，编译器会尝试将它们用于使用最频繁的局部变量，这也是更喜欢*局部变量*的另一个原因。
- en: Static variables are inefficient from the perspective of cache performance since
    that memory cannot be re-used for other variables and accessing static variables
    is likely a small fraction of all memory accesses. So, it is best to avoid static
    variables as well as global variables, which have similarly inefficient cache
    performance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 静态变量从缓存性能的角度来看效率低下，因为这种内存不能被其他变量重用，访问静态变量的操作可能只占所有内存访问的一小部分。因此，最好避免使用静态变量以及具有类似低效缓存性能的全局变量。
- en: The `volatile` keyword instructs the compiler to disable a lot of optimizations
    that rely on the assumption that the variable value does not change without the
    compiler’s knowledge. This should only ever be used carefully in multi-threaded
    use cases since it prevents optimizations such as storing the variables in registers
    and force-flushing them to the main memory from the cache every time the value
    changes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`volatile`关键字指示编译器禁用许多依赖于变量值在没有编译器知识的情况下不改变假设的优化。这应该只在多线程用例中谨慎使用，因为它阻止了将变量存储在寄存器中并将它们从缓存强制刷新到主内存的优化，每次值改变时都会这样做。'
- en: Dynamically allocated memory is inefficient to allocate and deallocate and,
    depending on how it is used, can suffer from poor cache performance. More on dynamically
    allocated memory inefficiencies will be discussed later in this section in the
    *Dynamically allocating* *memory* sub-section.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 动态分配的内存分配和释放效率低下，并且根据其使用方式，可能会遭受较差的缓存性能。关于动态分配内存的低效率将在本节后面的*动态分配* *内存*子节中进一步讨论。
- en: An example of C++ optimization technique that leverages storage choice optimization
    is **Small String Optimization** (**SSO**). SSO attempts to use local storage
    for short strings if they are smaller than a certain size (typically 32 characters)
    instead of the default of dynamically allocated memory for string content storage.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: C++优化技术的一个例子是利用存储选择优化的小字符串优化（**SSO**）。SSO尝试在字符串小于一定大小（通常是32个字符）时使用局部存储，而不是默认的动态分配内存来存储字符串内容。
- en: In summary, you should think carefully about where the data gets stored during
    the execution of your program, especially in the critical sections. We should
    try to use registers and local variables as much as possible and optimize cache
    performance. Use volatile, static, global, and dynamic memory only when necessary
    or when it does not affect performance on the critical path.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，你应该仔细考虑在程序执行过程中数据存储的位置，尤其是在关键部分。我们应该尽可能使用寄存器和局部变量，并优化缓存性能。仅在必要时或当它不影响关键路径上的性能时，才使用易失性、静态、全局和动态内存。
- en: Choosing data types
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择数据类型
- en: C++ integer operations are typically super-fast as long as the size of the largest
    register is larger than the integer size. Integers smaller or larger than the
    register size are sometimes slightly slower than regular integers. This is because
    the processor must use multiple registers for a single variable and apply some
    carry-over logic for large integers. Conversely, handling integers smaller than
    a register size is usually handled by using a regular register, zeroing out the
    upper bits, using only the lower bits, and possibly invoking a type conversion
    operation. Note that the extra overhead is very small and generally not something
    to worry about. Signed and unsigned integers are equally fast, but in some cases
    unsigned integers are faster than signed integers. The only cases where signed
    integer operations are a tiny bit slower is where the processor needs to check
    and adjust for the sign bit. Again, the extra overhead is extremely small when
    present and not necessarily something we need to worry about in most cases. We
    will look at the cost of different operations – addition, subtraction, comparison,
    bit operations, and so on typically take a single clock cycle. Multiplication
    operations take longer, and division operations take longest.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 只要最大的寄存器大小大于整数大小，C++的整数操作通常非常快。小于或大于寄存器大小的整数有时会比常规整数稍微慢一些。这是因为处理器必须使用多个寄存器来存储单个变量，并对大整数应用一些进位逻辑。相反，处理小于寄存器大小的整数通常是通过使用常规寄存器、清零高位、仅使用低位和可能调用类型转换操作来完成的。请注意，额外的开销非常小，通常不是需要担心的事情。有符号和无符号整数速度相同，但在某些情况下，无符号整数比有符号整数更快。唯一有符号整数操作稍微慢一些的情况是处理器需要检查和调整符号位。同样，当存在时，额外的开销非常小，在大多数情况下我们不需要担心。我们将查看不同操作的成本——加法、减法、比较、位操作等通常只需要一个时钟周期。乘法操作需要更长的时间，而除法操作需要最长时间。
- en: Using casting and conversion operations
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用类型转换和转换操作
- en: Converting between signed and unsigned integers is free. Converting integers
    from a smaller size into a larger one can take a single clock cycle but sometimes
    can be optimized to be free. Converting integer sizes down from a larger size
    into a smaller one has no additional cost.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在有符号和无符号整数之间进行转换是无成本的。将较小大小的整数转换为较大大小的整数可能只需要一个时钟周期，但有时可以优化为无成本。将整数大小从较大大小转换为较小大小没有额外的成本。
- en: Conversion between floats, doubles, and long doubles is typically free except
    under very few conditions. Conversion of signed and unsigned integers into floats
    or doubles takes a few clock cycles. Conversion from unsigned integers can take
    longer than signed integers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点数、双精度浮点数和长双精度浮点数之间的转换通常是无成本的，除非在极少数情况下。将有符号和无符号整数转换为浮点数或双精度浮点数需要几个时钟周期。从无符号整数到浮点数或双精度浮点数的转换可能比有符号整数需要更长的时间。
- en: Conversion from floating-point values into integers can be extremely expensive
    – 50 to 100 clock cycles or more. If these conversions are on the critical path,
    it is common for low-latency application developers to try and make these more
    efficient by enabling special instruction sets, avoiding or refactoring these
    conversions, if possible, using special assembly language rounding implementations,
    and so on.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将浮点值转换为整数的操作可能非常昂贵——50 到 100 个时钟周期或更多。如果这些转换位于关键路径上，低延迟应用程序的开发者通常会尝试通过启用特殊指令集、避免或重构这些转换（如果可能的话）、使用特殊的汇编语言舍入实现等方式来使这些转换更高效。
- en: Converting pointers from one type into another type is completely free; whether
    the conversions are safe or not is the developer’s responsibility. Type-casting
    a pointer to an object to a pointer to a different object violates the strict
    aliasing rule stating that *two pointers of different types cannot point to the
    same memory location*, which really means that it is possible the compiler might
    not use the same register to store the two different pointers, even though they
    point to the same address. Remember that the CPU registers are the fastest form
    of storage available to the processor but are extremely limited in storage capacity.
    So, when an extra register gets used to store the same variable, it is an inefficient
    use of the registers and negatively impacts performance overall.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 将指针从一个类型转换为另一个类型是完全免费的；转换是否安全是开发者的责任。将对象的指针类型转换成指向不同对象的指针类型违反了严格的别名规则，该规则指出
    *不同类型的两个指针不能指向相同的内存位置*，这实际上意味着编译器可能不会使用相同的寄存器来存储这两个不同的指针，即使它们指向相同的地址。记住，CPU 寄存器是处理器可用的最快存储形式，但存储容量极其有限。因此，当额外的寄存器被用来存储相同的变量时，这是对寄存器的不高效使用，并会对整体性能产生负面影响。
- en: 'An example of type-casting a pointer to be a different object is presented
    here. This example uses a conversion from `double *` into `uint64_t *` and modifies
    the sign bit using the `uint64_t` pointer. This is nothing more than a convoluted
    and more efficient method of achieving `x = -std::abs(x)` but demonstrates how
    this violates the strict aliasing rule (`strict_alias.cpp` in `Chapter3` on GitHub):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供了一个将指针类型转换成不同对象的示例。此示例使用从 `double *` 到 `uint64_t *` 的转换，并使用 `uint64_t` 指针修改符号位。这不过是一种复杂且更有效的方法来实现
    `x = -std::abs(x)`，但展示了这是如何违反严格的别名规则（在 GitHub 的 `Chapter3` 中的 `strict_alias.cpp`）：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It yields something like this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 它会产生类似以下内容：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using modern C++ casting operations, `const_cast`, `static_cast`, and `reinterpret_cast`
    do not incur any additional overhead when used. However, when it comes to `dynamic_cast`,
    which converts an object of a certain class into an object of a different class,
    this can be expensive at runtime. `dynamic_cast` checks whether the conversion
    is valid using **Run-Time Type Information** (**RTTI**), which is slow and possibly
    throws an exception if the conversion is invalid – this makes it safer but increases
    latency.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用现代 C++ 的类型转换操作，`const_cast`、`static_cast` 和 `reinterpret_cast` 在使用时不会产生任何额外的开销。然而，当涉及到
    `dynamic_cast`，它将某个类的对象转换为不同类的对象时，这可能在运行时变得昂贵。`dynamic_cast` 通过使用 **运行时类型信息**
    (**RTTI**) 来检查转换是否有效，这很慢，并且如果转换无效可能会抛出异常——这使得它更安全，但增加了延迟。
- en: Optimizing numerical operations
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化数值运算
- en: Typically, double-precision calculations take about the same time as single-precision
    operations. In general, for integers and floating values, additions are fast,
    multiplications are slightly more expensive than additions, and division is quite
    a bit more expensive than multiplication. Integer multiplications take around
    5 clock cycles and floating-point multiplications take around 8 clock cycles.
    Integer additions take a single clock cycle on most processors and floating-point
    additions take around 2-5 clock cycles. Floating-point divisions and integer divisions
    both take about the same amount of time around 20-80 clock cycles, depending on
    the processor and depending on whether it has special floating-point operations
    or not.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，双精度计算所需的时间与单精度操作大致相同。一般来说，对于整数和浮点数，加法运算很快，乘法运算比加法运算略贵，而除法运算比乘法运算贵得多。整数乘法大约需要
    5 个时钟周期，浮点数乘法大约需要 8 个时钟周期。大多数处理器上整数加法只需要一个时钟周期，而浮点数加法大约需要 2-5 个时钟周期。浮点数除法和整数除法在处理器和是否有特殊浮点操作的情况下，大约需要相同的时间，大约是
    20-80 个时钟周期。
- en: Compilers will try to rewrite and reduce expressions wherever possible to prefer
    faster operations such as rewriting divisions to be multiplications by reciprocals.
    Multiplication and division by values that are powers of 2 are significantly faster
    because the compiler rewrites them to be bit-shift operations, which are much
    faster. There is additional overhead when the compiler uses this optimization
    since it must handle signs and rounding errors. Obviously, this only applies when
    the expressions involve values that can be determined to be powers of 2 at compile
    time. When dealing with multi-dimensional arrays, for instance, the compiler converts
    multiplications into bitwise shift operations wherever possible.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器会尽可能重写和简化表达式，以优先考虑更快的操作，例如将除法重写为倒数乘法。乘以2的幂次的值和除以2的幂次的值要快得多，因为编译器将它们重写为位移操作，这要快得多。当编译器使用这种优化时，会有额外的开销，因为它必须处理符号和舍入误差。显然，这仅适用于在编译时可以确定是2的幂次的值。例如，在处理多维数组时，编译器尽可能将乘法转换为位移操作。
- en: Mixing single- and double-precision operations in the same expression and expressions
    involving floating and integer values should be avoided because they implicitly
    force type conversions. We saw before that type conversions are not always free,
    so these expressions can take longer to compute than we would guess. For instance,
    when mixing single- and double-precision values in an expression, the single-precision
    values must first be converted into double-precision values, which can consume
    a few clock cycles before the expression is computed. Similarly, when mixing integers
    and floating-point values in an expression, either the floating-point value has
    to be converted into an integer or the integer must be converted into a floating-point
    value, which adds a few clock cycles to the final calculation time.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一表达式中混合单精度和双精度操作，以及涉及浮点数和整数的表达式应避免，因为它们隐式地强制类型转换。我们之前看到类型转换并不总是免费的，所以这些表达式可能需要比我们预期的更长的时间来计算。例如，当在表达式中混合单精度和双精度值时，单精度值必须首先转换为双精度值，这可能在计算表达式之前消耗几个时钟周期。同样，当在表达式中混合整数和浮点值时，要么浮点值必须转换为整数，要么整数必须转换为浮点值，这会在最终的计算时间上增加几个时钟周期。
- en: Optimizing boolean and bitwise operations
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化布尔和位运算
- en: Boolean operations such as `&&`) and `||`) are evaluated such that for `&&`,
    if the first operand is false, then the second one is not evaluated, and, for
    `||`, if the first operand is true, then the second one is not evaluated. A simple
    optimization technique is to order the operands of `&&` in order from lowest to
    highest probability of being evaluated to true.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔操作（如`&&`和`||`）的评估方式是，对于`&&`，如果第一个操作数为假，则不评估第二个操作数；对于`||`，如果第一个操作数为真，则不评估第二个操作数。一种简单的优化技术是将`&&`的操作数按从低到高的概率排序为真。
- en: Similarly, for `||`, ordering the operands from highest to lowest probability
    of being true is best. This technique is referred to as `&&` boolean operation,
    the second operand should not be evaluated if the first one is false. Or for an
    `||` boolean operation, the second operand should not be evaluated if the first
    one is true, and so on.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于`||`，将操作数从最高到最低的概率排序为真是最优的。这种技术被称为`&&`布尔操作，如果第一个操作数为假，则不应评估第二个操作数。或者对于`||`布尔操作，如果第一个操作数为真，则不应评估第二个操作数，依此类推。
- en: 'Another aspect of using boolean variables is understanding the way they are
    stored. Boolean variables are stored as 8 bits and not a single bit, as might
    match our intuition from the way they are used. What this means is that operations
    involving boolean values have to be implemented such that any 8-bit values other
    than 0 are treated as 1, which leads to implementations with branches in them
    with comparisons against 0\. For example, the `c = a && b;` expression is implemented
    as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用布尔变量的另一个方面是理解它们是如何存储的。布尔变量是以8位存储的，而不是单个位，这与我们从它们的使用方式中获得的直觉可能不符。这意味着涉及布尔值的操作必须以这种方式实现，即除了0以外的任何8位值都被视为1，这导致在实现中包含与0的比较的分支。例如，`c
    = a && b;` 表达式是这样实现的：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If there was a guarantee that `a` and `b` could not have values other than 0
    or 1, then `c = a && b;` would simply be `c = a & b;`, which is super-fast and
    avoids branching and branching-related overheads.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可以保证`a`和`b`的值只能是0或1，那么`c = a && b;`将简单地是`c = a & b;`，这将非常快，避免了分支和与分支相关的开销。
- en: 'Bitwise operations can also help speed up other cases of boolean expressions
    by treating each bit of an integer as a single boolean variable and then rewriting
    expressions involving comparisons of multiple booleans with bit-masking operations.
    For instance, take an expression such as this, where `market_state` is `uint64_t`
    and `PreOpen`, `Opening`, and `Trading` are enum values that reflect different
    market states:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 位运算也可以通过将整数的每一位视为一个单独的布尔变量，然后使用位掩码操作重写涉及多个布尔比较的表达式来加速其他布尔表达式的处理。例如，考虑以下表达式，其中`market_state`是`uint64_t`类型，而`PreOpen`、`Opening`和`Trading`是表示不同市场状态的枚举值：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It can be rewritten as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 可以重写为以下形式：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If the enum values are chosen such that each bit in the `market_state` variable
    represents a state of true or false, one choice would be for the `PreOpen`, `Opening`,
    and `Trading` enums to be set to `0x001`, `0x010`, and `0x100`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果枚举值被选择，使得`market_state`变量中的每一位代表一个真或假的状态，那么`PreOpen`、`Opening`和`Trading`枚举可以设置为`0x001`、`0x010`和`0x100`。
- en: Initializing, destroying, copying, and moving objects
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化、销毁、复制和移动对象
- en: Constructors and destructors for developer-defined classes should be kept as
    light and efficient as possible since they can be called without the developer
    expecting it. Keeping these methods super-simple and small also allows the compiler
    to *inline* these methods to improve performance. The same applies to copy and
    move constructors, which should be kept simple, with using move constructors preferred
    over using copy constructors wherever possible. In many cases where high levels
    of optimization are required, the developer can delete the default constructor
    and the copy constructor to make sure unnecessary or unexpected copies of their
    objects are not being made.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者定义的类的构造函数和析构函数应尽可能轻量级和高效，因为它们可以在开发者没有预期的情况下被调用。保持这些方法非常简单和紧凑也允许编译器将这些方法*内联*以提高性能。同样适用于复制和移动构造函数，应保持简单，尽可能使用移动构造函数而不是复制构造函数。在需要高度优化的许多情况下，开发者可以删除默认构造函数和复制构造函数，以确保不会创建不必要的或意外的对象副本。
- en: Using references and pointers
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用引用和指针
- en: A lot of C++ features are built around implicitly accessing class members through
    the `this` pointer, so access through references and pointers occurs very frequently
    regardless of whether the developer explicitly does so or not. Accessing objects
    through pointers and references is mostly as efficient as directly accessing the
    objects. This is because most modern processors have support to efficiently fetch
    the pointer values and dereference them. The big disadvantage of using references
    and pointers is that they take up an extra register for the pointer themselves
    and the other one consists of the extra dereference instructions to access the
    variable pointed to by the pointer value.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 许多C++特性都是围绕通过`this`指针隐式访问类成员构建的，因此无论开发者是否明确这样做，通过引用和指针访问都非常频繁。通过指针和引用访问对象与直接访问对象一样高效。这是因为大多数现代处理器都支持高效地获取指针值并解引用它们。使用引用和指针的缺点是它们需要额外的寄存器来存储指针本身，另一个寄存器则用于执行解引用指令以访问指针值所指向的变量。
- en: Pointer arithmetic is just as fast as integer arithmetic except computing the
    differences between pointers requires a division by the size of the object, which
    can potentially be very slow. This is not necessarily a problem if the size of
    the type of object is a multiple of 2, which is quite often the case with primitive
    types and optimized structures.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 指针算术与整数算术一样快，除了计算指针之间的差异需要除以对象的大小，这可能会非常慢。如果对象类型的大小是2的倍数，这通常是原始类型和优化结构的情况，这并不一定是问题。
- en: Smart pointers are an important feature of modern C++ that offers safety, life
    cycle management, automatic memory management, and clear ownership control for
    dynamically allocated objects. Smart pointers such as `std::unique_ptr`, `std::shared_ptr`,
    and `std::weak_ptr` use the `std::shared_ptr` due to the reference counting overhead
    but generally, smart pointers are expected to add very little overhead to the
    entire program unless there are a lot of them.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 智能指针是现代C++的一个重要特性，它提供了安全性、生命周期管理、自动内存管理和对动态分配对象的清晰所有权控制。由于引用计数开销，智能指针如`std::unique_ptr`、`std::shared_ptr`和`std::weak_ptr`使用`std::shared_ptr`，但通常，智能指针预计只会给整个程序带来很少的开销，除非有很多这样的指针。
- en: 'Another important aspect of using pointers is that it can prevent compiler
    optimizations due to `a[0]` to `a[n-1]` and `b`. That means that this optimization
    is valid because `*b` is a constant for the entire loop and can be computed once:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指针的另一个重要方面是它可以防止由于 `a[0]` 到 `a[n-1]` 和 `b` 而产生的编译器优化。这意味着这种优化是有效的，因为 `*b`
    对于整个循环来说是常数，可以一次性计算：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There are really two options for instructing the compiler to assume no pointer
    aliasing in cases where the developer is confident that there is no behavior that
    is dependent on the side effects of pointer aliasing. Use `__restrict__`, or `__restrict`,
    a similar specifier keyword, for your compiler on the function arguments or functions
    to specify no aliasing on the pointers. However, this is a hint, and the compiler
    does not guarantee that this will make a difference. The other option is to specify
    the `-fstrict-aliasing` compiler option to assume no pointer aliasing globally.
    The following code block demonstrates the use of the `restrict` specifier for
    the preceding `func()` function (`pointer_alias.cpp` in `Chapter3` on GitHub):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发者确信没有依赖于指针别名副作用的行为时，有真正两种选项可以指导编译器假设没有指针别名。对于编译器，在函数参数或函数上使用 `__restrict__`
    或类似的指定关键字 `__restrict` 来指定指针上没有别名。然而，这只是一个提示，编译器不保证这会有所不同。另一种选项是指定 `-fstrict-aliasing`
    编译器选项，以全局假设没有指针别名。以下代码块演示了为前面的 `func()` 函数（GitHub上`Chapter3`的`pointer_alias.cpp`）使用
    `restrict` 指定符：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Optimizing jumping and branching
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化跳转和分支
- en: In modern processor pipelines, instructions and data are fetched and decoded
    in stages. When there is a branch instruction, the processor tries to predict
    which of the branches will be taken and fetches and decodes instructions from
    that branch. However, when the processor has mispredicted the branch taken, it
    takes 10 or more clock cycles before it detects the misprediction. After that,
    it must spend a bunch of clock cycles fetching the instructions and data from
    the correct branch and evaluate it. The key takeaway here is that a branch misprediction
    wastes many clock cycles every time it happens.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代处理器流水线中，指令和数据以阶段性地被获取和解析。当存在分支指令时，处理器会尝试预测哪个分支会被采取，并从该分支获取和解析指令。然而，当处理器错误地预测了采取的分支时，它需要
    10 个或更多的时钟周期来检测到错误预测。之后，它必须花费大量的时钟周期从正确的分支获取指令和数据，并对其进行评估。关键点是每次分支预测错误都会浪费很多时钟周期。
- en: 'Let us discuss some of the most used forms of jumps and branches in C++:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下 C++ 中最常用的跳转和分支形式：
- en: '`if-else` branching is the most common thing that comes to mind when discussing
    branching. Long chains of `if-else` conditionals are best avoided, if possible,
    because it is difficult to predict these correctly as they grow. Keeping the number
    of conditions small and trying to structure them so they are more predictable
    is the way to optimize them.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if-else` 分支是讨论分支时最常想到的事情。如果可能的话，最好避免长链的 `if-else` 条件，因为随着它们的增长，正确预测它们变得困难。保持条件数量小，并尝试使它们结构化以便更可预测，这是优化它们的方法。'
- en: '`for` and `while` loops are also types of branching that are typically predicted
    well if the loop count is relatively small. This, of course, gets complicated
    with nested loops and loops containing hard-to-predict exit conditions.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`for` 和 `while` 循环也是分支类型，如果循环计数相对较小，通常可以很好地预测。当然，嵌套循环和包含难以预测的退出条件的循环会使情况变得复杂。'
- en: '`switch` statements are branches with multiple jump targets, so they can be
    very difficult to predict. When label values are widely spread out, the compiler
    must use `switch` statements as a long sequence of `if-else` branching trees.
    An optimization technique that works well with `switch` statements is to assign
    case label values that increment by one and are arranged in ascending order because
    there is a very good chance they will get implemented as jump tables, which is
    significantly more efficient.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch` 语句是具有多个跳转目标的分支，因此它们可能很难预测。当标签值分布广泛时，编译器必须将 `switch` 语句用作一系列的 `if-else`
    分支树。与 `switch` 语句一起工作的优化技术是分配按顺序递增的案例标签值，因为它们有很大机会被实现为跳转表，这要高效得多。'
- en: Replacing branching with table lookups containing different output values in
    the source code is a good optimization wherever possible. We can also create a
    table of function pointers indexed by jump conditions but beware that function
    pointers are not necessarily much more efficient than the branching itself.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，用包含不同输出值的表查找替换源代码中的分支是一种很好的优化。我们还可以创建一个以跳转条件为索引的函数指针表，但请注意，函数指针不一定比分支本身更高效。
- en: '`loop_unroll.cpp` in `Chapter3` on GitHub):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub上`Chapter3`的`loop_unroll.cpp`）：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The compiler can unroll the loop into the following code shown here. Note that
    it is more than likely that for such a simple example, the compiler will use additional
    optimizations and reduce this loop even further. But for now, we limit ourselves
    to only present the impact of loop unrolling:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器可以将循环展开成以下这里显示的代码。请注意，对于这样一个简单的例子，编译器很可能还会使用额外的优化并将这个循环进一步缩减。但到目前为止，我们只限制自己展示循环展开的影响：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Compile-time branching using an `if constexpr (condition-expression) {}` format
    can obviously help a lot by moving the overhead of branching to compile time,
    but this requires that `condition-expression` be something that can be evaluated
    at compile time. This is technically part of the **Compile time Polymorphism**
    or **Template Metaprogramming** paradigm, which we will discuss more in the *Using
    compile-time polymorphism* sub-section in this section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`if constexpr (condition-expression) {}`格式进行编译时分支可以显然帮助很多，因为它将分支的开销移到了编译时，但这要求`condition-expression`是可以在编译时评估的。这实际上是**编译时多态**或**模板元编程**范式的技术部分，我们将在本节中的*使用编译时多态*子节中进一步讨论。
- en: 'It is possible to provide the compiler with branch prediction hints in the
    source code since the developer has a better idea of the expected use cases. These
    do not make a significant difference overall since modern processors are good
    at learning which branches are most likely to be taken after a few iterations
    through the branches. For GNU C++, these are traditionally implemented as follows
    using `__builtin_expect`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于开发者对预期的用例有更好的了解，因此可以在源代码中为编译器提供分支预测提示。这些提示在整体上并没有显著差异，因为现代处理器擅长在经过几次迭代后学习哪些分支最有可能被采取。对于GNU
    C++，这些提示传统上是通过`__builtin_expect`实现的：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For C++ 20, these are standardized as the `[[likely]]` and `[[``unlikely]]`
    attributes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于C++ 20，这些被标准化为`[[likely]]`和`[[unlikely]]`属性。
- en: Calling functions efficiently
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高效地调用函数
- en: There are numerous overheads associated with calling functions – the overhead
    of fetching the function address and jumping to it, passing the parameters to
    it and returning the results, setting up the stack frame, saving and restoring
    registers, exception handling, possible latency in the code cache misses, and
    so on.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 调用函数有许多相关的开销——获取函数地址和跳转到它的开销，向其传递参数并返回结果，设置栈帧，保存和恢复寄存器，异常处理，代码缓存缺失的可能延迟，等等。
- en: When breaking up the code base into functions, some general things to consider
    to maximize the performance would be the following.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在将代码库拆分为函数时，为了最大化性能，以下是一些需要考虑的一般事项。
- en: Thinking before creating an excessive number of functions
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在创建过多的函数之前先思考
- en: Functions should only be created if there is enough re-usability to justify
    them. The criteria for creating functions should be logical program flow and re-usability
    and not the length of code because, as we saw, calling functions is not free,
    and creating excessive functions is not a good idea.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在存在足够的可重用性以证明其合理性时，才应创建函数。创建函数的标准应该是逻辑程序流程和可重用性，而不是代码长度，因为，正如我们所看到的，调用函数不是免费的，创建过多的函数不是一个好主意。
- en: Grouping related functions together
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将相关函数分组
- en: Class member and non-class member functions typically get assigned memory addresses
    in the order in which they are created, so it is generally a good idea to group
    together performance-critical functions that call each other frequently or operate
    on the same datasets. This facilitates better code and data cache performance.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 类成员函数和非类成员函数通常按它们创建的顺序分配内存地址，因此将频繁调用彼此或操作相同数据集的性能关键函数分组在一起通常是一个好主意。这有助于提高代码和数据缓存性能。
- en: Link Time Optimization (LTO) or Whole Program Optimization (WPO)
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 链接时间优化（LTO）或整个程序优化（WPO）
- en: When writing performance-critical functions, it is important to place them in
    the same module where they are used if possible. Doing so unlocks a lot of compiler
    optimizations, the most important of which is the ability to inline the function
    call.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当编写性能关键函数时，如果可能的话，将它们放在它们被使用的同一模块中是很重要的。这样做可以解锁大量的编译器优化，其中最重要的是能够内联函数调用。
- en: Using the `static` keyword to declare a function does the equivalent of putting
    it in an `inline` keyword achieves this as well, but we will explore that in the
    next section.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`static`关键字声明一个函数相当于将其放在`inline`关键字中，这也同样可以达到目的，但我们将这在下一节中探讨。
- en: Specifying WPO and LTO parameters for the compiler instructs it to treat the
    entire code base as a single module and enable compiler optimizations across modules.
    Without enabling these compiler options, optimizations occur across functions
    in the same module but not between modules which can be quite sub-optimal for
    large code bases which typically have a lot of source files and modules.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为编译器指定WPO和LTO参数指示它将整个代码库视为一个单一模块，并启用跨模块的编译器优化。如果不启用这些编译器选项，优化将发生在同一模块内的函数之间，但不会在模块之间发生，这对于通常具有大量源文件和模块的大型代码库来说可能相当不理想。
- en: Macros, inline functions, and template metaprogramming
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 宏、内联函数和模板元编程
- en: '**Macro expressions** are a pre-processor directive and are expanded even before
    compilation begins. This eliminates the overhead associated with calling and returning
    from functions at runtime. Macros have several disadvantages though, such as namespace
    collision, cryptic compilation errors, unnecessary evaluation of conditions and
    expressions, and so on.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**宏表达式**是一个预处理器指令，甚至在编译开始之前就会展开。这消除了与运行时调用和返回函数相关的开销。然而，宏也有一些缺点，例如命名空间冲突、神秘的编译错误、不必要的条件表达式评估等。'
- en: Inlined functions, whether they are part of a class or not, are similar to macros
    but solve a lot of the problems associated with macros. Inlined functions are
    expanded at their usage during compilation and link times and eliminate the overhead
    associated with function calls.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 内联函数，无论它们是否是类的一部分，都类似于宏，但解决了与宏相关的大量问题。内联函数在编译和链接时展开其使用，并消除了与函数调用相关的开销。
- en: Using template metaprogramming, it is possible to move a lot of the computation
    load from runtime to compile time. This involves using partial and full template
    specialization and recursive loop templates. However, template metaprogramming
    can be clumsy and difficult to use, compile, and debug and should only really
    be used where the performance improvements justify the increased development discomfort.
    We will explore templates and template metaprogramming shortly.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模板元编程，可以将大量的计算负载从运行时移动到编译时。这涉及到使用部分和完全模板特化和递归循环模板。然而，模板元编程可能比较笨拙且难以使用、编译和调试，并且只有在性能改进足以证明增加的开发不适时才真正应该使用。我们将在不久的将来探讨模板和模板元编程。
- en: Avoiding function pointers
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 避免使用函数指针
- en: Calling a function through a function pointer has a larger overhead than directly
    calling the function. For one, if the pointer changes, then the compiler cannot
    predict which function will be called and cannot pre-fetch the instructions and
    data. Additionally, this also prevents a lot of compiler optimizations since these
    cannot be inlined at compile time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过函数指针调用函数比直接调用函数有更大的开销。一方面，如果指针发生变化，编译器就无法预测将被调用哪个函数，也无法预取指令和数据。此外，这也阻止了许多编译器优化，因为这些优化不能在编译时内联。
- en: The `std::function` is a much more powerful construct available in modern C++
    but should be used only if necessary since there is potential for misuse and extra
    overhead of a few clock cycles compared to direct inlined functions. `std::bind`
    is another construct to be very careful about when using and should also only
    be used if absolutely necessary. If `std::function` must be used, try to see whether
    you can use a lambda expression instead of `std::bind` since that is typically
    a few clock cycles faster to invoke. Overall, be careful when using `std::function`
    and/or `std::bind` since a lot of developers are surprised that these constructs
    can perform virtual function calls and invoke dynamic memory allocations under
    the hood.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::function`是现代C++中一个更强大的构造，但应该仅在必要时使用，因为存在误用的可能性，并且与直接内联函数相比，会有几个时钟周期的额外开销。`std::bind`也是在使用时需要非常小心的另一个构造，也应该仅在绝对必要时使用。如果必须使用`std::function`，尝试看看是否可以使用lambda表达式而不是`std::bind`，因为通常调用lambda表达式要快几个时钟周期。总的来说，使用`std::function`和/或`std::bind`时要小心，因为许多开发者惊讶地发现这些构造可以执行虚函数调用并在底层调用动态内存分配。'
- en: Passing function parameters by reference or pointers
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过引用或指针传递函数参数
- en: For primitive types, passing parameters by value is super-efficient. For composite
    types that are function parameters, the preferred way of passing them would be
    const references. The **constness** means that the object cannot be modified and
    allows the compiler to apply optimizations based on that and the reference allows
    the compiler to possibly inline the object itself. If the function needs to modify
    the object passed to it, then obviously a non-const reference or pointer is the
    way to go.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于原始类型，按值传递参数非常高效。对于作为函数参数的复合类型，首选的传递方式是const引用。**const性**意味着对象不能被修改，并允许编译器基于此进行优化，而引用允许编译器可能内联对象本身。如果函数需要修改传递给它的对象，那么显然应该使用非const引用或指针。
- en: Returning simple types from functions
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从函数返回简单类型
- en: Functions that return primitive types are very efficient. Returning composite
    types is much more inefficient and can lead to a couple of copies being created
    in some cases, which is quite sub-optimal especially if these are large and/or
    have slow copy constructors and assignment operators. When the compiler can apply
    **Return Value Optimization** (**RVO**), it can eliminate the temporary copy created
    and just write the result to the caller’s object directly. The optimal way to
    return a composite type is to have the caller create an object of that type and
    pass it to the function using a reference or a pointer for the function to modify.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 返回原始类型的函数非常高效。返回复合类型则效率低得多，在某些情况下甚至可能创建几个副本，这在某些情况下尤其不理想，尤其是如果这些类型很大且/或具有缓慢的复制构造函数和赋值运算符。当编译器可以应用**返回值优化**（**RVO**）时，它可以消除创建的临时副本，并直接将结果写入调用者的对象。返回复合类型的最佳方式是让调用者创建该类型的对象，并使用引用或指针将其传递给函数以供修改。
- en: 'Let us look at an example to explain what happens with RVO; let us say we have
    the following function definition and call to the function (`rvo.cpp` in `Chapter3`
    on GitHub):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来解释RVO会发生什么；假设我们有以下函数定义和函数调用（位于GitHub上`Chapter3`的`rvo.cpp`）：
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With RVO, instead of creating a temporary `LargeClass` object inside `rvoExample()`
    and then copying it into the `LargeClass lc_obj` object in `main()`, the `rvoExample()`
    function can directly update `lc_obj` and avoid the temporary object and copy.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RVO时，`rvoExample()`函数中不再创建一个临时的`LargeClass`对象，然后将其复制到`main()`中的`LargeClass
    lc_obj`对象，而是`rvoExample()`函数可以直接更新`lc_obj`，避免临时对象和复制。
- en: Avoiding recursive functions or replacing them with a loop
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 避免递归函数或用循环替换它们
- en: Recursive functions are inefficient because of the overhead of calling themselves
    repeatedly. Additionally, recursive functions can go very deep in the stack and
    take up a lot of stack space, and, in worst-case scenarios, even cause a stack
    overflow. This causes a lot of cache misses due to the new memory areas and makes
    predicting the return address difficult and inefficient. In such cases, replacing
    recursive functions with a loop is significantly more efficient since it avoids
    a lot of the cache performance issues that recursive functions encounter.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 递归函数由于反复调用自身的开销而不太高效。此外，递归函数可以在堆栈中非常深入，占用大量堆栈空间，在最坏的情况下甚至会导致堆栈溢出。这会导致由于新的内存区域而出现大量的缓存未命中，使得预测返回地址变得困难且效率低下。在这种情况下，用循环代替递归函数会显著提高效率，因为它避免了递归函数遇到的大量缓存性能问题。
- en: Using bitfields
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用位字段
- en: '**Bitfields** are just structs where the developer controls the number of bits
    assigned to each member. This makes the data as compact as possible and greatly
    improves cache performance for many objects. Bitfield members are also usually
    modified using bitmask operations, which are very efficient, as we have seen before.
    Accessing the members of bitfields is less efficient than accessing the members
    of a regular structure, so it is important to carefully assess whether using bitfields
    and improving the cache **performance** is worthwhile.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**位字段**只是开发者控制分配给每个成员的位数的结构。这使得数据尽可能紧凑，并且大大提高了许多对象的缓存性能。位字段成员通常也使用位掩码操作来修改，这些操作非常高效，正如我们之前所看到的。访问位字段成员的效率低于访问常规结构成员，因此仔细评估使用位字段并提高缓存**性能**是否值得是很重要的。'
- en: Using runtime polymorphism
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用运行时多态
- en: '`Virtual` functions are the key to implementing runtime polymorphism, but they
    have an additional overhead compared to non-virtual function calls.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`虚`函数是实现运行时多态的关键，但与非虚函数调用相比，它们有额外的开销。'
- en: Usually, the compiler cannot determine at compile time which implementation
    of a virtual function will be called. At runtime, this causes many branch mispredictions
    unless the same version of the virtual function gets called most of the time.
    It is possible for the compiler to determine the virtual function implementation
    called at compile time using `virtual` functions is that the compiler cannot apply
    many of the compile-time optimizations in the presence of `virtual` functions,
    the most important one being inlining.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，编译器无法在编译时确定将调用哪个虚拟函数的实现。在运行时，除非大多数时候调用相同的虚拟函数版本，否则这会导致许多分支预测错误。编译器可以通过使用`虚`函数确定在编译时调用的虚拟函数实现，但由于在存在`虚`函数的情况下，编译器无法应用许多编译时优化，其中最重要的是内联优化。
- en: Inheritance in C++ is another important OOP concept but be careful when the
    inheritance structure gets too complicated since there are many subtle inefficiencies
    that can be introduced. Child classes inherit every single data member from their
    parent class, so the size of the child classes can become quite large and lead
    to poor cache performance.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: C++中的继承是另一个重要的面向对象编程概念，但要注意当继承结构变得过于复杂时，可能会引入许多细微的低效。子类从其父类继承每个数据成员，因此子类的尺寸可能会变得相当大，导致缓存性能不佳。
- en: 'In general, instead of inheriting from multiple parent classes, we can consider
    using the `composition.cpp` in `Chapter3` on GitHub) builds `OrderBook`, which
    basically holds a vector of `Order` objects, in two different ways. The benefit
    (if used properly) of the inheritance model is that it now inherits all the methods
    that `std::vector` provides while the composition model would need to implement
    them. In this example, we demonstrate this by implementing a `size()` method in
    `CompositionOrderBook`, which calls the `size()` method on the `std::vector` object,
    while `InheritanceOrderBook` inherits it directly from `std::vector`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们可以在多个父类中继承，而不是考虑使用GitHub上`Chapter3`中的`composition.cpp`构建`OrderBook`，它基本上持有`Order`对象的向量，以两种不同的方式。如果正确使用，继承模型的好处是它现在继承了`std::vector`提供的所有方法，而组合模型则需要实现它们。在这个例子中，我们通过在`CompositionOrderBook`中实现一个`size()`方法来演示这一点，它调用`std::vector`对象的`size()`方法，而`InheritanceOrderBook`则直接从`std::vector`继承它：
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: C++ `dynamic_cast`, as we discussed before, usually uses the RTTI information
    to perform the cast and should also be avoided.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: C++的`dynamic_cast`，正如我们之前讨论的，通常使用RTTI信息来执行转换，并且也应该避免使用。
- en: Using compile-time polymorphism
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用编译时多态
- en: Let us discuss an alternative to using runtime polymorphism, which is to use
    templates to achieve compile-time polymorphism. Templates are similar to macros,
    meaning they are expanded before compilation, and because of this, not only is
    the runtime overhead eliminated but it also unlocks additional compiler optimization
    opportunities. Templates make the compiler machine code super-efficient but they
    come at the cost of additional source code complexity, as well as larger executable
    sizes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论使用运行时多态的替代方案，即使用模板来实现编译时多态。模板类似于宏，意味着它们在编译前被展开，因此不仅消除了运行时开销，还解锁了额外的编译器优化机会。模板使编译器生成的机器代码超级高效，但它们以增加源代码复杂性和更大的可执行文件大小为代价。
- en: The `virtual` functions and the base class and derived class relationships are
    similar but slightly different using the *CRTP*. A simple example of converting
    runtime polymorphism into compile-time polymorphism is shown here. In both cases,
    the derived classes, `SpecificRuntimeExample` and `SpecificCRTPExample`, override
    the `placeOrder()` method. The code discussed in this sub-section is in the `crtp.cpp`
    file in the GitHub repo for this book under the `Chapter3` directory.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 *CRTP* 的 `virtual` 函数和基类与派生类的关系相似，但略有不同。这里展示了将运行时多态转换为编译时多态的一个简单例子。在两种情况下，派生类
    `SpecificRuntimeExample` 和 `SpecificCRTPExample` 都重写了 `placeOrder()` 方法。本小节讨论的代码位于
    GitHub 仓库中本书的 `Chapter3` 目录下的 `crtp.cpp` 文件中。
- en: Runtime polymorphism using virtual functions
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用虚函数实现的运行时多态
- en: 'Here, we have an example of implementing runtime polymorphism where `SpecificRuntimeExample`
    derives `RuntimeExample` and overrides the `placeOrder()` method:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有一个实现运行时多态的例子，其中 `SpecificRuntimeExample` 继承自 `RuntimeExample` 并重写了 `placeOrder()`
    方法：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Compile-time polymorphism using the CRTP
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 CRTP 实现的编译时多态
- en: 'Now we implement similar functionality as discussed in the previous section,
    but instead of using runtime polymorphism, we use compile-time polymorphism. Here,
    we use the CRTP pattern and `SpecificCRTPExample` specializes/implements the `CRTPExample`
    interface and has a different implementation of `placeOrder()` via `actualPlaceOrder()`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们实现与上一节讨论的类似的功能，但不是使用运行时多态，而是使用编译时多态。在这里，我们使用 CRTP 模式，`SpecificCRTPExample`
    特化/实现了 `CRTPExample` 接口，并通过 `actualPlaceOrder()` 方法提供了 `placeOrder()` 的不同实现：
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Invoking polymorphic methods in the two cases
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在两种情况下调用多态方法
- en: 'Finally, in the following snippet presented, we show how we would create `SpecificRuntimeExample`
    and `SpecificCRTPExample` objects. We then invoke runtime and compile-time polymorphism
    respectively using the `placeOrder()` method:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在以下代码片段中，我们展示了如何创建 `SpecificRuntimeExample` 和 `SpecificCRTPExample` 对象。然后我们分别使用
    `placeOrder()` 方法调用运行时和编译时多态：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Running this yields the following output, the first line using runtime polymorphism
    and the second line using compile time polymorphism:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码将产生以下输出，第一行使用运行时多态，第二行使用编译时多态：
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using additional compile-time processing
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用额外的编译时处理
- en: '**Template metaprogramming** is a more general term that means writing code
    that itself yields more code. The benefit here is also to move computations from
    runtime to compile time and maximize compiler optimization opportunities and runtime
    performance. It is possible to write almost anything with template metaprogramming,
    but it can get extremely complicated and difficult to understand, maintain, and
    debug, lead to very long compilation times, and increase the binary size to a
    very large size.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**模板元编程**是一个更通用的术语，意味着编写能够生成更多代码的代码。这里的优势也是将计算从运行时移动到编译时，并最大化编译器优化机会和运行时性能。使用模板元编程可以编写几乎任何东西，但它可能变得极其复杂和难以理解、维护和调试，导致编译时间非常长，并将二进制文件大小增加到非常大的程度。'
- en: Handling exceptions
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理异常
- en: The C++ exception handling system is designed to detect unexpected error conditions
    at runtime and either gracefully recover or shut down from that point. When it
    comes to low-latency applications, it is important to evaluate the use of exception
    handling since while it is true that exception handling incurs the largest latencies
    during these rare error cases, there can still be some overhead even when exceptions
    are not raised. There is some bookkeeping overhead related to the logic used to
    recover gracefully when exceptions are raised under various scenarios. With nested
    functions, exceptions need to be propagated all the way up to the top-most caller
    function and each stack frame needs to be cleaned up. This is known as **stack
    unwinding** and requires the exception handler to track all the information it
    needs to walk backward during an exception.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: C++异常处理系统旨在在运行时检测意外的错误条件，并从该点优雅地恢复或关闭。当涉及到低延迟应用时，评估异常处理的使用非常重要，因为虽然确实在罕见错误情况下，异常处理会带来最大的延迟，但在不抛出异常的情况下仍然可能有一些开销。与在各种情况下优雅地处理异常时使用的逻辑相关的某些账务开销。在嵌套函数中，异常需要传播到最顶层的调用函数，并且每个堆栈帧都需要清理。这被称为**堆栈回溯**，需要异常处理程序跟踪它在异常期间需要向后遍历的所有信息。
- en: For low-latency applications, exceptions are either disabled per function using
    the `throw()` or `noexcept` specifications or disabled across the entire program
    using compiler flags. This allows the compiler to assume that some or all methods
    will not throw an exception and hence the processor does not have to worry about
    saving and tracking recovery information. Note that using `noexcept` or disabling
    the C++ exception handling system is not without some disadvantages. For one,
    usually, the C++ exception handling system does not typically add a lot of extra
    overhead unless an exception is thrown, so this decision must be made with careful
    consideration. Another point is that if a method marked as `noexcept` throws an
    exception for some reason, the exception can no longer be propagated up the stack
    and instead the program is terminated right there. What this means is that disabling
    the C++ exception handling system either partially or fully makes handling failures
    and exceptions harder and completely the developer’s responsibility. Usually,
    what this means is that the developer will still need to make sure that exceptional
    error conditions are not encountered or handled elsewhere, but the point is that
    now the developer has explicit control over this and can move it out of the critical
    hot path. For this reason, it is common that during the development and testing
    phases, the C++ exception handling system is not disabled, but only during the
    very last optimization steps do we consider removing exception handling.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于低延迟应用，异常可以通过使用`throw()`或`noexcept`指定来逐函数禁用，或者通过编译器标志在整个程序中禁用。这允许编译器假设某些或所有方法不会抛出异常，因此处理器不必担心保存和跟踪恢复信息。请注意，使用`noexcept`或禁用C++异常处理系统并非没有缺点。一方面，通常，除非抛出异常，否则C++异常处理系统不会增加很多额外的开销，因此这个决定必须经过仔细考虑。另一个观点是，如果标记为`noexcept`的方法由于某种原因抛出异常，则异常将无法再向上传播到堆栈，程序将立即终止。这意味着禁用C++异常处理系统（部分或全部）会使处理失败和异常变得更加困难，并且完全由开发者负责。通常，这意味着开发者仍然需要确保不会遇到或处理其他地方的异常错误条件，但关键是现在开发者可以明确控制这一点，并将其移出关键的热点路径。因此，在开发和测试阶段，通常不会禁用C++异常处理系统，但在最后的优化步骤中，我们才考虑移除异常处理。
- en: Accessing cache and memory
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问缓存和内存
- en: We have frequently referred to cache performance while discussing different
    uses of C++ features since accessing the main memory is significantly slower than
    the clock cycles used to execute CPU instructions or access registers or cache
    storage. Here are some general points to keep in mind when trying to optimize
    cache and memory access.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 自从讨论C++特性的不同用途时，我们经常提到缓存性能，因为访问主内存比执行CPU指令或访问寄存器或缓存存储所使用的时钟周期要慢得多。在尝试优化缓存和内存访问时，以下是一些需要记住的一般要点。
- en: Aligning data
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据对齐
- en: Variables that are aligned, in that they are placed at memory locations that
    are multiples of the size of the variable, are accessed most efficiently. The
    term **word size** for processors describes the number of bits read by and processed
    by processors, which for modern processors is either 32-bits or 64-bits. This
    is because the processor can read a variable from memory up to the word size in
    a single read operation. If the variable is aligned in memory, then the processor
    does not have to do any extra work to get it into the required register to be
    processed.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐的变量，即它们放置在变量大小的倍数内存位置上的变量，访问效率最高。处理器中的“字大小”术语描述了处理器读取和处理的数据位数，对于现代处理器来说，要么是32位，要么是64位。这是因为处理器可以在单次读取操作中从内存中读取一个变量，直到字大小。如果变量在内存中对齐，那么处理器不需要做任何额外的工作来将其放入所需的寄存器进行处理。
- en: For these reasons, aligned variables are more efficient to handle, and the compiler
    will take care of automatically aligning variables. This includes adding padding
    in between member variables in a class or a struct to keep those variables aligned.
    When adding member variables to structures where we expect to have a lot of objects,
    it is important to consider the extra padding added carefully because the size
    of the struct will be larger than expected. The extra space in each instance of
    this struct’s or class’s objects means that they can have worse cache performance
    if there are a lot of them. The recommended approach here would be to reorder
    the members of the struct so that minimal extra padding is added to keep the members
    aligned.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，对齐变量更易于处理，编译器将自动处理变量的对齐。这包括在类或结构体中的成员变量之间添加填充，以保持这些变量的对齐。当我们向结构体添加成员变量，并预期会有很多对象时，仔细考虑额外添加的填充非常重要，因为结构体的大小将大于预期。这个结构体或类的对象实例中的额外空间意味着，如果有很多这样的对象，它们的缓存性能可能会更差。这里推荐的方法是对结构体的成员进行重新排序，以使额外填充最小化，从而保持成员对齐。
- en: 'We will see an example that orders the same members inside a structure in three
    different ways – one where there is a lot of additional padding added to keep
    each variable aligned, another where the developer reorders the member variables
    to minimize space waste due to compiler-added padding, and, finally, where we
    use the `pack()` pragma to eliminate all padding. This code is available in the
    `Chapter3/alignment.cpp` file in the GitHub repository for this book:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到一个示例，它以三种不同的方式对结构体内部的相同成员进行排序——一种是在保持每个变量对齐的同时添加了大量额外的填充，另一种是开发人员重新排序成员变量以最小化由于编译器添加的填充造成的空间浪费，最后，我们使用`pack()`指令来消除所有填充。此代码可在GitHub存储库中本书的`Chapter3/alignment.cpp`文件中找到：
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This code outputs the following on my system, displaying the offsets of the
    different data members in each of the three designs of the same structure. Note
    that the first version has an extra 11 bytes of padding, the second one only has
    an extra 3 bytes of padding due to the reordering, and the last version has no
    extra padding:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在我的系统上输出以下内容，显示了同一结构体三种不同设计中不同数据成员的偏移量。请注意，第一个版本有额外的11字节填充，第二个版本由于重新排序，只有额外的3字节填充，而最后一个版本没有额外的填充：
- en: '[PRE17]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Accessing data
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 访问数据
- en: Cache-friendly data access (read and/or write) is when the data is accessed
    sequentially or somewhat sequentially. If the data is accessed backward, it is
    less efficient than this, and cache performance is worse if the data is accessed
    randomly. This is something to consider, especially when accessing multi-dimensional
    arrays of objects and/or objects residing in a container with a non-trivial underlying
    storage of the objects.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存友好的数据访问（读取和/或写入）是指数据按顺序或部分顺序访问。如果数据是反向访问的，那么它的效率低于这种访问方式，如果数据是随机访问的，那么缓存性能会更差。这是需要考虑的一点，尤其是在访问多维数组对象和/或对象驻留在具有非平凡底层存储的对象容器时。
- en: For instance, accessing elements in an array is significantly more efficient
    than accessing elements in a linked list, tree, or hash-map container because
    of the contiguous memory storage versus random memory storage locations. From
    the perspective of algorithmic complexity, searching linearly in an array is less
    efficient than using a hash map since the array search has `O(n)` and the hash
    map has `O(1)` theoretical algorithmic complexity. However, if the number of elements
    is small enough, then using the array still yields better performance, a large
    reason being due to cache performance and algorithm overhead.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，访问数组中的元素比访问链表、树或哈希表容器中的元素要高效得多，这是因为连续的内存存储与随机的内存存储位置相比。从算法复杂性的角度来看，线性搜索数组比使用哈希表效率低，因为数组搜索有`O(n)`的理论算法复杂度，而哈希表有`O(1)`。然而，如果元素数量足够少，那么使用数组仍然可以获得更好的性能，一个很大的原因是由于缓存性能和算法开销。
- en: Using large data structures
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用大型数据结构
- en: When dealing with large multi-dimensional matrix datasets, for instance, with
    linear algebra operations, cache access performance dominates the performance
    of the operation. Often, the actual algorithm implementation for matrix operations
    is different from that used in classic texts to reorder the matrix access operations
    for cache performance. The best approach here is to measure the performance of
    different algorithms and access patterns and find the one that performs best under
    different matrix dimensions, cache contention conditions, and so on.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理大型多维矩阵数据集时，例如进行线性代数运算，缓存访问性能主导了运算的性能。通常，矩阵运算的实际算法实现与经典文本中用于优化缓存性能的矩阵访问操作顺序不同。最佳方法是对不同算法和访问模式进行性能测量，并找到在不同矩阵维度、缓存竞争条件等情况下表现最佳的方案。
- en: Grouping variables together
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将变量分组在一起
- en: When designing classes and method or non-method functions, grouping variables
    that are accessed together greatly improves cache performance by reducing the
    number of cache misses. We discussed that preferring local variables over global,
    static, and dynamically allocated memory leads to better cache performance.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计类和方法或非方法函数时，将一起访问的变量分组可以显著提高缓存性能，通过减少缓存未命中次数来实现。我们讨论了，相比于全局、静态和动态分配的内存，优先使用局部变量可以带来更好的缓存性能。
- en: Grouping functions together
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将函数分组在一起
- en: Grouping class member functions and non-member functions together so that functions
    that are used together are close together in memory also leads to better cache
    performance. This is because functions are placed in memory addresses depending
    on where they are in the developer’s source code and functions next to each other
    get assigned addresses close to each other.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 将类成员函数和非成员函数分组在一起，使得一起使用的函数在内存中靠近，这也导致了更好的缓存性能。这是因为函数在内存地址中的位置取决于它们在开发者的源代码中的位置，相邻的函数会被分配到彼此接近的地址。
- en: Dynamically allocating memory
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动态分配内存
- en: Dynamically allocated memory has several good use cases, specifically when the
    size of containers is not known at compile time and when they can grow or shrink
    in size during the application instance’s life cycle. Dynamically allocated memory
    is also important for objects that are very large and take up a lot of stack space.
    Dynamically allocated memory can have a place in low-latency applications if allocation
    and deallocation are not done on the critical path and an allocated block of memory
    is used so that the cache performance is not hurt.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 动态分配的内存有几种良好的使用场景，特别是当容器的大小在编译时未知，并且它们可以在应用程序实例的生命周期中增长或缩小时。对于非常大且占用大量栈空间的对象，动态分配的内存也非常重要。如果分配和释放操作不在关键路径上执行，并且使用分配的内存块，那么动态分配的内存可以在低延迟应用中发挥作用，这样不会损害缓存性能。
- en: A disadvantage of dynamically allocated memory is that the process of allocating
    and deallocating memory blocks is awfully slow. The repeated allocation and deallocation
    of memory blocks of varied sizes fragments the heap, that is, it creates free
    memory blocks of different sizes interspersed with allocated memory blocks.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 动态分配内存的一个缺点是分配和释放内存块的过程非常缓慢。不同大小的内存块的重复分配和释放会导致堆碎片化，也就是说，它会在分配的内存块之间创建不同大小的空闲内存块。
- en: A fragmented heap makes the allocation and deallocation process even slower.
    Allocated memory blocks might not be optimally aligned unless the developer is
    careful about it. Dynamically allocated memory accessed through pointers causes
    pointer aliasing and prevents compiler optimizations, as we have seen before.
    There are other disadvantages of dynamically allocated memory, but these are the
    biggest ones for low-latency applications. Hence, it is best to avoid dynamically
    allocated memory completely when it comes to low-latency applications, or at the
    very least use it carefully and sparingly.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 分散的堆使得分配和释放过程变得更加缓慢。除非开发者对此非常小心，否则分配的内存块可能无法最优地对齐。通过指针访问的动态分配内存会导致指针别名，并阻止编译器优化，正如我们之前所看到的。动态分配内存还有其他缺点，但对于低延迟应用来说，这些是最大的缺点。因此，在低延迟应用中，最好完全避免使用动态分配的内存，或者至少要谨慎且少量地使用。
- en: Multi-threading
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多线程
- en: If low-latency applications use multi-threading, the threads and the interactions
    between these threads should be designed carefully. Starting and stopping threads
    takes time, so it is best to avoid launching new threads when they are needed
    and instead use a thread pool of worker threads. Task switching or context switching
    is when one thread is paused or blocked, and another thread starts executing in
    its place. Context switching is very expensive since it requires the OS to save
    the state of the current thread, load the state of the next thread, start the
    processing, and so on, and is usually accompanied by memory reads and writes,
    cache misses, instruction pipeline stalls, and so on.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果低延迟应用使用多线程，那么线程以及这些线程之间的交互应该被仔细设计。启动和停止线程需要时间，因此最好在需要时避免启动新线程，而是使用工作线程的线程池。任务切换或上下文切换是指一个线程被暂停或阻塞，另一个线程开始在其位置上执行。上下文切换非常昂贵，因为它需要操作系统保存当前线程的状态，加载下一个线程的状态，开始处理，等等，通常伴随着内存读写、缓存未命中、指令流水线停滞等等。
- en: Synchronization using locks and mutexes between threads is also expensive and
    involves additional checks around concurrent access and context-switching overhead.
    When multiple threads access shared resources, they need to use the `volatile`
    keyword and that also prevents several compiler optimizations. Additionally, different
    threads can compete for the same cache lines and invalidate each other’s caches
    and this contention leads to terrible cache performance. Each thread gets its
    own stack, so it’s best to keep the shared data to a minimum and allocate variables
    locally on the thread’s stack.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用锁和互斥量在线程之间进行同步也是昂贵的，并且涉及到对并发访问和上下文切换开销的额外检查。当多个线程访问共享资源时，它们需要使用 `volatile`
    关键字，这也阻止了编译器进行一些优化。此外，不同的线程可能争夺相同的缓存行，并使彼此的缓存失效，这种竞争导致糟糕的缓存性能。每个线程都有自己的堆栈，因此最好将共享数据保持在最小，并在线程的堆栈上本地分配变量。
- en: Maximizing C++ compiler optimization parameters
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大化 C++ 编译器优化参数
- en: In this last section, we will understand how advanced and amazing modern C++
    compilers are at optimizing the C++ code that the developers write. We will understand
    how compilers optimize the C++ code during the compilation, linking, and optimization
    stages to generate the most efficient machine code possible. We will understand
    how compilers optimize high-level C++ code and when they fail to do the best job.
    We will follow that up with a discussion on what the application developer can
    do to aid the compilers in their optimization task. Finally, we will look at different
    options available in modern C++ compilers by looking specifically at the **GNU
    compiler** (**GCC**). Let us start by understanding how compilers optimize our
    C++ program.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的最后，我们将了解现代 C++ 编译器在优化开发者编写的 C++ 代码方面的先进性和神奇之处。我们将了解编译器如何在编译、链接和优化阶段优化 C++
    代码，以生成尽可能高效的机器代码。我们将了解编译器如何优化高级 C++ 代码，以及它们何时未能做到最好。我们将接着讨论应用开发者可以做什么来帮助编译器完成优化任务。最后，我们将通过具体查看
    **GNU 编译器**（**GCC**）来探讨现代 C++ 编译器中可用的不同选项。让我们首先了解编译器是如何优化我们的 C++ 程序的。
- en: Understanding how compilers optimize
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解编译器优化
- en: In this sub-section, we will understand the different compiler optimization
    techniques that the compiler employs during its many passes over the high-level
    C++ code. The compiler typically first performs local optimizations and then tries
    to globally optimize these smaller code sections. It does so over several passes
    through the translated machine code during the pre-processing, compilation, linking,
    and optimization stages. Broadly, most compiler optimization techniques have some
    common themes, some of which overlap and some of which conflict with each other,
    which we will look at next.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将了解编译器在多次遍历高级C++代码时采用的不同的编译优化技术。编译器通常首先执行局部优化，然后尝试全局优化这些较小的代码段。它在预处理、编译、链接和优化阶段通过翻译的机器代码进行多次遍历来实现这一点。总的来说，大多数编译器优化技术都有一些共同的主题，其中一些相互重叠，一些则相互冲突，我们将在下一节中探讨。
- en: Optimizing the common cases
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化常见情况
- en: This concept applies to software development too and helps the compiler optimize
    the code better. If the compiler can understand which code paths the program execution
    will spend most of its time in, it can optimize the common path to be faster even
    if it slows down the paths that are rarely taken. This results in better performance
    overall, but typically this is harder for the compiler to achieve at compilation
    time since it is not obvious which code paths are expected to be more likely unless
    the developer adds directives to specify this. We will discuss the hints that
    a developer can provide to the compiler to help specify which code paths are expected
    to be more likely during runtime.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念也适用于软件开发，并有助于编译器更好地优化代码。如果编译器能够理解程序执行将花费大部分时间在哪些代码路径上，它就可以优化常见路径以使其更快，即使这会减慢很少走的路径。这总体上会带来更好的性能，但通常在编译时对编译器来说更难实现，因为除非开发者添加指令来指定这一点，否则并不明显哪些代码路径更有可能。我们将讨论开发者可以向编译器提供的提示，以帮助在运行时指定哪些代码路径更有可能。
- en: Minimizing branching
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最小化分支
- en: Modern processors typically prefetch data and instructions before they are required
    so that the processors can execute instructions as quickly as possible. However,
    when there are jumps and branches (conditional and unconditional), the processor
    cannot know which instructions and data will be needed ahead of time with 100%
    certainty. What this means is that sometimes the processor incorrectly predicts
    the branch taken and thus the instructions and data prefetched are incorrect.
    When this happens, there is an extra penalty incurred since now the processor
    must remove the instructions and data that were fetched incorrectly and replace
    them with the correct instructions and data and then execute them after that.
    Techniques such as loop unrolling, inlining, and branch prediction hints help
    reduce branching and the misprediction of branching and improve performance. We
    will explore these concepts in more detail later in this section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现代处理器通常在需要之前预取数据和指令，以便处理器可以尽可能快地执行指令。然而，当存在跳转和分支（条件和非条件）时，处理器无法提前以100%的确定性知道哪些指令和数据将被需要。这意味着有时处理器错误地预测了分支的执行，因此预取的指令和数据是不正确的。当这种情况发生时，会额外产生惩罚，因为现在处理器必须移除错误预取的指令和数据，并用正确的指令和数据替换它们，然后执行它们。诸如循环展开、内联和分支预测提示等技术有助于减少分支和分支预测错误，从而提高性能。我们将在本节稍后更详细地探讨这些概念。
- en: 'There are several cases in which a developer can refactor code in such a way
    that they avoid branching and achieve the same behavior. Sometimes, these optimization
    opportunities are only available to the developer, who understands the code and
    behavior at a deeper level than the compiler. A very simple example of how to
    convert a code block that uses branching and transform it to avoid branching is
    presented next. Here we have an enumeration to track side for an execution and
    we track the last bought/sold quantity, as well as updating the position in two
    different ways. The first way uses a branch on the `fill_side` variable and the
    second method avoids that branching by assuming that the `fill_side` variable
    can only have `BUY`/`SELL` values and can be cast to integers to be indexed into
    an array. This code can be found in the `Chapter3/branch.cpp` file:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，开发者可以通过重构代码来避免分支并实现相同的行为。有时，这些优化机会只有开发者可以利用，因为他们比编译器更深入地理解代码和行为。下面将展示如何将使用分支的代码块转换为避免分支的示例。这里有一个枚举来跟踪执行时的侧面，以及跟踪最后买入/卖出的数量，以及以两种不同的方式更新位置。第一种方式使用`fill_side`变量的分支，第二种方法通过假设`fill_side`变量只能有`BUY`/`SELL`值并且可以转换为整数以索引到数组来避免这种分支。此代码可在`Chapter3/branch.cpp`文件中找到：
- en: '[PRE18]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And both the branching and branchless implementations compute the same values:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 并且分支和分支无实现都计算相同的值：
- en: '[PRE19]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Reordering and scheduling instructions
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重新排序和调度指令
- en: The compiler can take advantage of advanced processors by re-ordering instructions
    in such a way that parallel processing can happen at the instruction, memory,
    and thread levels. The compiler can detect dependencies between code blocks and
    re-order them so that the program still works correctly but executes faster by
    executing instructions and processing data in parallel at the processor level.
    Modern processors can reorder instructions even without the compiler doing so,
    but it helps if the compiler can make it easier for the processors to do so as
    well. The main objective here is to prevent stalls and bubbles in modern processors,
    which have multiple pipelined processors, by choosing and ordering instructions
    in such a way as to preserve the original logical flow.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器可以通过重新排序指令来利用高级处理器，以便在指令、内存和线程级别上发生并行处理。编译器可以检测代码块之间的依赖关系，并重新排序它们，以便程序仍然正确运行但执行速度更快，通过在处理器级别并行执行指令和处理数据。现代处理器甚至在没有编译器的情况下也可以重新排序指令，但如果编译器能使其更容易，那就更好了。这里的主要目标是防止现代处理器（具有多个流水线处理器）中的停顿和气泡，通过选择和排序指令以保持原始逻辑流程。
- en: 'A simple example of how an expression can be reordered to take advantage of
    parallelism is shown here. Note that this is somewhat hypothetical since the actual
    implementation of this will vary greatly depending on the processor and the compiler:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了如何通过重新排序表达式来利用并行性的一个简单示例。请注意，这有点假设性质，因为实际实现将根据处理器和编译器的不同而有很大差异：
- en: '[PRE20]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As it is written, this expression has a data dependency and would be executed
    sequentially, roughly as follows, and cost 5 clock cycles:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 按照目前的写法，这个表达式有一个数据依赖性，将按顺序执行，大致如下，并花费5个时钟周期：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It can be re-ordered into the following instructions, and assuming the advanced
    processor can perform two additions at a time, can be reduced to three clock cycles.
    This is because two operations such as `x = a + b;` and `p = c +d;` can be performed
    in parallel since they are independent of each other:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以被重新排序成以下指令，并且假设高级处理器可以一次执行两个加法操作，可以减少到三个时钟周期。这是因为像`x = a + b;`和`p = c + d;`这样的两个操作可以并行执行，因为它们彼此独立：
- en: '[PRE22]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Using special instructions depending on the architecture
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用根据架构的特殊指令
- en: During the compilation process, the compiler can choose which CPU instructions
    to use to implement the high-level program logic. When the compiler generates
    an executable for a specific architecture, it can use special instructions that
    the architecture supports. This means there is an opportunity to generate even
    more efficient instruction sequences, which leverage the special instructions
    that the architecture provides. We will look at how to specify this in the *Learning
    about compiler optimization* *flags* section.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在编译过程中，编译器可以选择使用哪些CPU指令来实现高级程序逻辑。当编译器为特定架构生成可执行文件时，它可以使用该架构支持的特定指令。这意味着有机会生成更高效的指令序列，这些序列利用了架构提供的特殊指令。我们将在*了解编译器优化*标志部分中查看如何指定这一点。
- en: Vectorization
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量化
- en: Modern processors can use vector registers to perform multiple calculations
    on multiple pieces of data in parallel. For instance, the SSE2 instruction set
    has 128-bit vector registers, which can be used to perform multiple operations
    on multiple integers or floating values depending on the size of these types.
    Extending this further, the AVX2 instruction set, for example, has 256-bit vector
    registers and can support a higher degree of vectorized operations. This optimization
    can be technically considered as part of the discussion in the *Using special
    instructions depending on the architecture* section from before.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现代处理器可以使用向量寄存器并行地对多个数据执行多个计算。例如，SSE2指令集具有128位向量寄存器，可以根据这些类型的大小用于对多个整数或浮点值执行多个操作。进一步扩展，例如AVX2指令集具有256位向量寄存器，可以支持更高程度的向量化操作。这种优化可以从技术上被视为之前*根据架构使用特殊指令*部分讨论的一部分。
- en: 'To understand vectorization even better, let us present the following very
    simple example of a loop that operates on two arrays and stores the result in
    another array (`vector.cpp` in `Chapter3` in GitHub):'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解向量化，让我们来看一个非常简单的例子，这个例子中有一个循环操作两个数组，并将结果存储在另一个数组中（GitHub中`Chapter3`的`vector.cpp`文件）：
- en: '[PRE23]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'For architectures that support special vector registers such as the SSE2 instruction
    set we discussed before, it can hold 4 4-byte float values simultaneously and
    perform 4 additions at a time. In this case, the compiler can leverage the vectorization
    optimization technique and re-write this as the following with loop unrolling
    to use the SSE2 instruction set:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于支持特殊向量寄存器的架构，例如我们之前讨论的SSE2指令集，它可以同时存储4个4字节的浮点值并一次执行4次加法。在这种情况下，编译器可以利用向量化优化技术，并通过循环展开将其重写为以下代码，以使用SSE2指令集：
- en: '[PRE24]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Strength reduction
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强度降低
- en: '**Strength reduction** is a term used to describe compiler optimizations where
    complex operations that are quite expensive are replaced by instructions that
    are simpler and cheaper to improve performance. A classic example is one in which
    the compiler replaces operations involving division by some value with multiplication
    by the reciprocal of that value. Another example would be replacing multiplication
    by a loop index with an addition operation.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**强度降低**是一个术语，用来描述编译器优化过程，其中复杂的且成本较高的操作被替换为更简单且成本更低的指令，以提高性能。一个经典的例子是编译器将涉及除以某个值的操作替换为乘以该值的倒数。另一个例子是将通过循环索引的乘法操作替换为加法操作。'
- en: 'The simplest example we could think of is presented here, where we try to convert
    a price from its double notation into its integer notation by dividing the floating
    value by its minimum valid price increment. The variant that demonstrates the
    strength reduction that a compiler would perform is a simple multiplication instead
    of a division. Note that `inv_min_price_increment = 1 / min_price_increment;`
    is a `constexpr` expression, so it is not evaluated at runtime. This code is available
    in the `Chapter3/strength.cpp` file:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里展示的最简单的例子是尝试通过将浮点值除以其最小有效价格增量来将价格从双精度表示转换为整数表示。演示编译器如何执行强度降低的变体是一个简单的乘法而不是除法。请注意，`inv_min_price_increment
    = 1 / min_price_increment;`是一个`constexpr`表达式，因此它不会在运行时评估。此代码位于`Chapter3/strength.cpp`文件中：
- en: '[PRE25]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Inlining
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内联
- en: 'Calling functions is expensive, as we have already seen before. There are several
    steps:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 调用函数的成本很高，正如我们之前所见。这包括几个步骤：
- en: Saving the current state of variables and execution
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存变量的当前状态和执行状态
- en: Loading the variables and instructions from the function being called
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载被调用函数中的变量和指令
- en: Executing them and possibly returning back values and resuming execution after
    the function call
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行它们，并可能在函数调用后返回值并继续执行
- en: The compiler tries to replace a call to a function with the body of the function
    where possible to remove this overhead associated with calling functions and optimize
    performance. Not only that but now that it has replaced a call to a function with
    the actual body of the function, that opens room for more optimizations since
    the compiler can inspect this new larger code block.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器会尝试在可能的情况下用函数体替换对函数的调用，以移除与调用函数相关的开销并优化性能。不仅如此，一旦它用函数的实际体替换了对函数的调用，这就为更多的优化打开了空间，因为编译器可以检查这个新的更大的代码块。
- en: Constant folding and constant propagation
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常量折叠和常量传播
- en: '**Constant folding** is a no-brainer optimization technique and applies when
    there are expressions whose output can be computed entirely at compile time that
    do not depend on runtime branches or variables. Then, the compiler computes these
    expressions at compile time and replaces the evaluation of these expressions with
    the compile-time constant output value.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**常量折叠**是一种不言而喻的优化技术，适用于存在输出可以在编译时完全计算的表达式，这些表达式不依赖于运行时分支或变量。然后，编译器在编译时计算这些表达式，并用编译时常量输出值替换这些表达式的评估。'
- en: A similar and closely related compiler optimization tracks values in the code
    that are known to be compile-time constants and tries to propagate those constant
    values and unlock additional optimization opportunities. This optimization technique
    is known as **constant propagation**. An example would be loop unrolling if the
    compiler can determine the starting value, incremental value, or stopping value
    of the loop iterator.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一种类似且紧密相关的编译器优化会跟踪代码中已知为编译时常量的值，并试图传播这些常量值并解锁额外的优化机会。这种优化技术被称为**常量传播**。一个例子是，如果编译器可以确定循环迭代器的起始值、增量值或停止值，则可以执行循环展开。
- en: Dead Code Elimination (DCE)
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 死代码消除 (DCE)
- en: '**DCE** applies when the compiler can detect code blocks that have no impact
    on the program behavior. This can be due to code blocks that are never needed
    or code blocks where the calculations do not end up being used or affect the outcome.
    Once the compiler detects such *dead* code blocks, it can remove them and boost
    program performance. Modern compilers emit warnings when the outcome of running
    some code ends up not being used to help developers find such cases, but the compiler
    cannot detect all of these cases at compile time and there are still opportunities
    for DOE once it is translated into machine code instructions.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**DCE**（删除未引用代码）适用于编译器可以检测到对程序行为没有影响的代码块。这可能是由于从未被需要的代码块，或者计算最终没有使用或影响结果的情况。一旦编译器检测到这样的**死代码**块，它就可以移除它们并提高程序性能。现代编译器在运行某些代码的结果最终未被使用时发出警告，以帮助开发者找到此类情况，但编译器无法在编译时检测到所有这些情况，并且一旦翻译成机器代码指令，仍然有机会进行DCE。'
- en: Common Subexpression Elimination (CSE)
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 公共子表达式消除 (CSE)
- en: '**CSE** is a specific optimization technique where the compiler finds duplicated
    sets of instructions or calculations. Here, the compiler restructures the code
    to remove this redundancy by computing the result only once and then using the
    value where it is required.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**CSE**是一种特定的优化技术，其中编译器查找重复的指令集或计算。在这里，编译器重构代码，通过只计算一次结果并在需要的地方使用该值来消除这种冗余。'
- en: Peephole optimizations
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 窥孔优化
- en: '**Peephole optimization** is a relatively generic compiler optimization term
    that refers to a compiler optimization technique where the compiler tries to search
    for local optimizations in short sequences of instructions. We use the term local
    because the compiler does not necessarily try to understand the entire program
    and optimize it globally. Of course, however, by repeatedly and iteratively performing
    peephole optimizations, the compiler can achieve a decent degree of optimization
    at a global scale.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**窥孔优化**是一个相对通用的编译器优化术语，指的是编译器试图在指令的短序列中搜索局部优化的技术。我们使用“局部”这个术语，因为编译器并不一定试图理解整个程序并全局优化它。然而，当然，通过反复和迭代地执行窥孔优化，编译器可以在全局范围内达到相当程度的优化。'
- en: Tail call optimization
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尾调用优化
- en: 'We know that function calls are not cheap because they have overhead associated
    with passing parameters and results and affect the cache performance and processor
    pipeline. `__attribute__ ((noinline))` attribute, which is there to explicitly
    prevent the compiler from inlining the `factorial()` function directly into `main()`.
    You can find this example in the `Chapter3/tail_call.cpp` source file on GitHub:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道函数调用并不便宜，因为它们与传递参数和结果有关的开销，并影响缓存性能和处理器流水线。`__attribute__ ((noinline))` 属性存在是为了显式阻止编译器将
    `factorial()` 函数直接内联到 `main()` 中。你可以在 GitHub 上的 `Chapter3/tail_call.cpp` 源文件中找到这个示例：
- en: '[PRE26]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'For this implementation, we would expect that in the machine code for the `factorial()`
    function, we would find a call to itself, but when compiled with optimization
    turned on, the compiler performs tail call optimization and implements the `factorial()`
    function as a loop and not a recursion. To observe that machine code, you can
    compile this code with something like this:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个实现，我们预计在 `factorial()` 函数的机器代码中会找到一个对自身的调用，但是当开启优化编译时，编译器执行尾调用优化，并将 `factorial()`
    函数实现为一个循环而不是递归。要观察这个机器代码，你可以使用类似以下的方式编译此代码：
- en: '[PRE27]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: And in that `tail_call.s` file, you will see the call to `factorial()` in `main()`
    to be something like the following example. If this is your first time looking
    at assembly code, then let us quickly describe the instructions you will encounter.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在那个 `tail_call.s` 文件中，你会看到 `main()` 中对 `factorial()` 的调用类似于以下示例。如果你是第一次查看汇编代码，那么让我们快速描述你将遇到的指令。
- en: The `movl` instruction moves a value into a register (100 in the following block)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movl` 指令将一个值移动到寄存器中（以下代码块中的 100）'
- en: The `call` instruction calls a function (`factorial()` with name mangling (step
    where the C++ compiler changes the function names in intermediate code) and the
    parameter is passed in the `edi` register)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call` 指令调用一个函数（带有名称修饰的 `factorial()`，这是 C++ 编译器在中间代码中更改函数名称的步骤，参数通过 `edi`
    寄存器传递）'
- en: The `testl` instruction compares two registers and sets the zero flag if they’re
    equal
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`testl` 指令比较两个寄存器，如果它们相等则设置零标志'
- en: '`je` and `jne` check whether the zero flag is set and jump to the specified
    memory address if it is (`je`) or jump to the specified memory address if it is
    not (`jne`)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`je` 和 `jne` 检查零标志是否被设置，如果设置了则跳转到指定的内存地址（`je`），如果没有设置则跳转到指定的内存地址（`jne`）'
- en: 'The `ret` instruction returns from the function and the return value is in
    the `eax` register:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ret` 指令从函数返回，返回值位于 `eax` 寄存器中：'
- en: '[PRE28]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'When you look at the `factorial()` function itself, you will find a loop (the
    `je` and `jne` instructions) instead of an additional `call` instruction to itself:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当你查看 `factorial()` 函数本身时，你会找到一个循环（`je` 和 `jne` 指令），而不是对自身的额外 `call` 指令：
- en: '[PRE32]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Loop unrolling
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环展开
- en: '**Loop unrolling** duplicates the body of the loop multiple times. Sometimes,
    it is not possible for the compiler to know at compile time how many times the
    loop will be executed – in which case, it will partially unroll the loop. For
    loops where the loop body is small and/or where it can be determined that the
    number of times that the loop will execute is low, the compiler can completely
    unroll the loop. This avoids the need for checking the loop counters and the overhead
    associated with conditional branching or looping. This is like function inlining
    where the call to the function is replaced by the body of the function. For loop
    unrolling, the entire loop is rolled out and replaces the conditional loop body.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环展开** 多次复制循环体。有时编译器在编译时无法知道循环将执行多少次 – 在这种情况下，它将部分展开循环。对于循环体小且/或可以确定循环将执行的次数较少的循环，编译器可以完全展开循环。这避免了检查循环计数器和与条件分支或循环相关的开销。这就像函数内联一样，将函数的调用替换为函数体。对于循环展开，整个循环被展开并替换了条件循环体。'
- en: Additional loop optimizations
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 额外的循环优化
- en: '**Loop unrolling** is the primary loop-related optimization technique employed
    by compilers but there are additional loop optimizations:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环展开** 是编译器使用的主要的循环相关优化技术，但还有额外的循环优化：'
- en: '**Loop fission** breaks a loop down into multiple loops operating on smaller
    sets of data to improve cache reference locality.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环分裂** 将循环分解为多个循环，这些循环操作更小的数据集以提高缓存引用局部性。'
- en: '**Loop fusion** does the opposite, where if two adjacent loops are executed
    the same number of times, they can be merged into one to reduce the loop overhead.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环融合**做的是相反的事情，即如果两个相邻的循环执行相同的次数，它们可以被合并成一个以减少循环开销。'
- en: '`while` loop is transformed into a `do-while` loop inside a conditional `if`
    statement. This reduces the total number of jumps by two when the loop is executed
    and is typically applied to loops that are expected to execute at least once.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`while`循环在条件`if`语句内部被转换成`do-while`循环。当循环执行时，这减少了两次跳转的总数，并且通常应用于预期至少执行一次的循环。'
- en: '**Loop interchange** exchanges inner loops and outer loops especially when
    doing so leads to better cache reference locality – for example, in the cases
    of iterating over an array where accessing memory contiguously makes a huge performance
    difference.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环交换**交换内部循环和外部循环，尤其是在这样做可以导致更好的缓存引用局部性时——例如，在迭代数组的情况下，连续访问内存会产生巨大的性能差异。'
- en: Register variables
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 寄存器变量
- en: '**Registers** are internal processor memory and are the fastest form of storage
    available for the processor on account of being the closest to them. Because of
    this, the compiler tries to store variables that have the highest number of accesses
    in the registers. Registers, however, are limited, so the compiler needs to choose
    the variables to store effectively, and the effectiveness of this choice can make
    a significant difference to performance. The compiler typically picks variables
    such as local variables, loop counter and iterator variables, function parameters,
    commonly used expressions, or **induction variables** (variables that change by
    fixed amounts on each loop iteration). There are some limitations to what the
    compiler can place in registers such as variables whose address needs to be taken
    via pointers or references that need to reside in the main memory.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**寄存器**是内部处理器内存，并且由于它们是最接近处理器的，因此是处理器上可用的最快存储形式。正因为如此，编译器试图将访问次数最多的变量存储在寄存器中。然而，寄存器是有限的，因此编译器需要有效地选择要存储的变量，这种选择的有效性可以对性能产生重大影响。编译器通常选择诸如局部变量、循环计数器和迭代变量、函数参数、常用表达式或**归纳变量**（每次循环迭代通过固定量变化的变量）等变量。编译器可以放置在寄存器中的变量有一些限制，例如需要通过指针或引用获取地址的变量或需要驻留在主内存中的变量。'
- en: 'Now, we present a very simple example of how a compiler will transform a loop
    expression using induction variables. See the following code (`Chapter3/induction.cpp`
    on GitHub):'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们通过一个非常简单的例子来说明编译器如何使用归纳变量转换循环表达式。请参阅以下代码（GitHub上的`Chapter3/induction.cpp`）：
- en: '[PRE33]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Live range analysis
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生存范围分析
- en: The term **live range** describes the code block within which a variable is
    active or used. If there are multiple variables in the same code block with overlapping
    live ranges, then each variable needs a different storage location. However, if
    there are variables with live ranges that do not overlap, then the compiler can
    use the same register for multiple variables in each live range.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 术语**生存范围**描述了变量活跃或被使用的代码块。如果同一个代码块中有多个变量具有重叠的生存范围，那么每个变量都需要不同的存储位置。然而，如果有生存范围不重叠的变量，则编译器可以在每个生存范围内为多个变量使用相同的寄存器。
- en: Rematerialization
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重载材料化
- en: '**Rematerialization** is a compiler technique where the compiler chooses to
    re-calculate a value (assuming the calculation is trivial) instead of accessing
    the memory location that contains the value of this calculation already. The output
    value of this recalculation must be stored in registers, so this technique works
    in tandem with *register allocation techniques*. The main objective here is to
    avoid accessing the caches and main memory, which are slower to access than accessing
    the register storage. This, of course, depends on making sure that the recalculation
    takes less time than a cache or memory access.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**重载材料化**是一种编译器技术，其中编译器选择重新计算一个值（假设计算是微不足道的）而不是访问包含该计算值的内存位置。这个重新计算的输出值必须存储在寄存器中，因此这项技术与*寄存器分配技术*协同工作。这里的主要目标是避免访问缓存和主内存，因为它们比访问寄存器存储要慢。当然，这取决于确保重新计算的时间比缓存或内存访问要少。'
- en: Algebraic reductions
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代数简化
- en: The compiler can find expressions that can be further reduced and simplified
    using algebraic laws. While software developers do not unnecessarily complicate
    expressions, there are cases where simpler forms of expressions exist compared
    to what the developer originally wrote in C++. Opportunities for algebraic reductions
    also show up as the compiler optimizes code iteratively due to inlining, macro
    expansions, constant folding, and so on.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器可以找到可以使用代数法则进一步简化和简化的表达式。虽然软件开发者不会不必要地复杂化表达式，但与开发者最初在C++中编写的相比，存在更简单的表达式形式。代数简化的机会也出现在编译器由于内联、宏展开、常量折叠等迭代优化代码时。
- en: Something to note here is that compilers do not typically apply algebraic reductions
    to floating-point operations because, in C++, floating-point operations are not
    safe to reduce due to precision issues. Flags need to be turned on to force the
    compiler to perform unsafe floating-point algebraic reductions, but it would be
    preferable for developers to reduce them explicitly and correctly.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，编译器通常不会对浮点运算应用代数简化，因为在C++中，由于精度问题，浮点运算不安全进行简化。需要打开标志来强制编译器执行不安全的浮点代数简化，但开发者显式且正确地简化它们会更好。
- en: 'The simplest example we can think of here is where a compiler might rewrite
    this expression:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以想到的最简单的例子是编译器可能会重写这个表达式：
- en: '[PRE34]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here, it uses two operations instead of three previously like so:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，它使用两个操作而不是之前的三种操作：
- en: '[PRE35]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Induction variable analysis
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 归纳变量分析
- en: The idea behind **induction variable**-related compiler optimization techniques
    is that an expression that is a linear function of the loop counter variable can
    be reduced into an expression that is a simple addition to a previous value. The
    simplest possible example would be calculating the address of elements in an array
    where the next element is at a memory location equal to the current element’s
    location plus the size of the object type. This is just a simple example since
    in modern compilers and processors, there are special instructions to calculate
    addresses of array elements and induction is not really used there, but induction
    variable-based optimizations are still performed for other loop expressions.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**归纳变量**相关的编译器优化技术的理念是，一个关于循环计数变量的线性函数表达式可以被简化为一个对前一个值的简单加法表达式。最简单的例子可能是计算数组中元素地址，其中下一个元素位于当前元素位置加上对象类型大小的内存位置。这只是一个简单的例子，因为在现代编译器和处理器中，有专门的指令来计算数组元素的地址，并且归纳实际上并没有在那里使用，但基于归纳变量的优化仍然会对其他循环表达式进行。'
- en: Loop invariant code movement
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环不变式代码移动
- en: 'When the compiler can ascertain that some code and instructions within a loop
    are constant for the entire duration of the loop, that expression can be moved
    out of the loop. If there are expressions within the loop that conditionally yield
    one value or the other depending on branching conditions, those can also be moved
    out of the loop. Also, if there are expressions executed on each branch within
    a loop, these can be moved out of the branches and possibly the loop. There are
    many such optimization possibilities, but the fundamental idea is that code that
    does not need to be executed on each loop iteration or can be evaluated once before
    the loop falls under the umbrella of loop invariant code refactoring. Here is
    a hypothetical example of how loop invariant code movement implemented by the
    compiler would work. The first block is what the developer originally wrote, but
    the compiler can understand that the call to `doSomething()` and the expression
    involving the `b` variable are loop invariants and only need to be computed once.
    You will find this code in the `Chapter3/loop_invariant.cpp` file:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 当编译器可以确定某些代码和指令在整个循环过程中都是常数时，该表达式可以被移出循环。如果循环中有表达式根据分支条件条件性地产生一个值或另一个值，这些也可以被移出循环。此外，如果循环中每个分支上都要执行表达式，这些也可以移出分支，甚至可能移出循环。存在许多这样的优化可能性，但基本思想是，不需要在每次循环迭代上执行或可以在循环开始之前评估一次的代码属于循环不变式代码重构的范畴。以下是一个假设的例子，说明编译器如何实现循环不变式代码移动。第一个块是开发者最初编写的，但编译器可以理解对`doSomething()`的调用和涉及`b`变量的表达式是循环不变式，并且只需要计算一次。你将在`Chapter3/loop_invariant.cpp`文件中找到此代码：
- en: '[PRE36]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Static Single Assignment (SSA)-based optimizations
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于静态单赋值（SSA）的优化
- en: SSA is a transformed form of the original program where instructions are re-ordered
    such that every variable is assigned in a single place. After this transformation,
    the compiler can apply many additional optimizations, leveraging the property
    that every variable is assigned in only a single place.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: SSA（单赋值）是原始程序的一种转换形式，其中指令被重新排序，以便每个变量只在一个地方被赋值。在此转换之后，编译器可以应用许多额外的优化，利用每个变量只在一个地方被赋值的属性。
- en: Devirtualization
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚拟化
- en: '**Devirtualization** is a compiler optimization technique, especially for C++,
    that tries to avoid **Virtual Table** (**vtable**) lookups when calling virtual
    functions. This optimization technique boils down to the compiler figuring out
    the correct method to call at compile time. This can happen even when using virtual
    functions because in some cases, the object type is known at compile time, such
    as when there is only a single implementation of pure virtual functions.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**虚拟化**是一种编译器优化技术，特别是针对C++，它试图在调用虚拟函数时避免**虚表**（**vtable**）查找。这种优化技术归结为编译器在编译时确定正确的调用方法。即使在使用虚拟函数的情况下，这也可能发生，因为在某些情况下，对象类型在编译时是已知的，例如当只有一个纯虚拟函数的实现时。'
- en: Another case is where the compiler can determine that only a single derived
    class is created and used in some contexts or code branches, and it can replace
    the indirect functional call using vtable to be a direct call to the correct derived
    type’s method.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，编译器可以确定在某些上下文或代码分支中只创建和使用了一个派生类，并且它可以替换使用虚表进行的间接功能调用，以直接调用正确的派生类型的方法。
- en: Understanding when compilers fail to optimize
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解编译器何时无法优化
- en: In this section, we will discuss the different scenarios under which a compiler
    cannot apply some of the optimization techniques we discussed in the previous
    section. Understanding when compilers fail to optimize will help us develop C++
    code that avoids these failures so that the code can be highly optimized by the
    compiler to yield highly efficient machine code.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论在哪些不同的情况下，编译器无法应用我们在上一节中讨论的一些优化技术。了解编译器何时无法优化将帮助我们开发避免这些失败的C++代码，从而使代码能够被编译器高度优化，生成高效的机器代码。
- en: Failure to optimize across modules
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模块间优化失败
- en: When the compiler compiles the entire program, it compiles modules independently
    of each other on a file-by-file basis. So, the compiler does not have information
    about functions in a module other than the one it is currently compiling. This
    prevents it from being able to optimize functions across modules and a lot of
    the techniques we saw cannot be applied since the compiler does not understand
    the whole program. Modern compilers solve such issues by using **LTO**, where,
    after the individual modules are compiled, the linker treats the different modules
    as if they were part of the same translation unit at compile time. This activates
    all the optimizations we have discussed so far, so it is important to enable LTO
    when trying to optimize the entire application.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 当编译器编译整个程序时，它会根据文件逐个独立编译模块。因此，编译器除了它当前正在编译的模块之外，没有关于模块中函数的信息。这阻止了它能够优化跨模块的函数，我们看到的许多技术都无法应用，因为编译器不理解整个程序。现代编译器通过使用**LTO**（链接时优化）来解决此类问题，在单独的模块编译完成后，链接器在编译时将不同的模块视为同一翻译单元的一部分。这激活了我们之前讨论的所有优化，因此当尝试优化整个应用程序时，启用LTO非常重要。
- en: Dynamic memory allocation
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动态内存分配
- en: We already know that dynamic memory allocation is slow at runtime and introduces
    non-deterministic latency into your applications. They also have another side
    effect and that is **pointer aliasing** in the pointers that point to these dynamically
    allocated memory blocks. We will look at pointer aliasing in more detail next,
    but with dynamically allocated memory blocks, the compiler cannot ascertain that
    the pointers will necessarily point to different and non-overlapping memory areas,
    even though for the programmer it might seem obvious. This prevents various compiler
    optimizations that depend on aligning data or assuming alignment, as well as pointer
    aliasing-related inefficiencies, which we will see next. Local storage and declarations
    are also more cache-efficient because the memory space gets reused frequently
    as new functions are called and local objects are created. Dynamically allocated
    memory blocks can be randomly scattered in memory and yield poor cache performance.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道动态内存分配在运行时速度较慢，并给应用程序引入了非确定性的延迟。它们还有另一个副作用，那就是指向这些动态分配内存块的指针中的**指针别名**。我们将在下一节更详细地探讨指针别名，但对于动态分配的内存块，编译器无法确定指针一定会指向不同且不重叠的内存区域，尽管对于程序员来说这可能是显而易见的。这阻止了依赖于对齐数据或假设对齐的各种编译器优化，以及我们将在下一节看到的与指针别名相关的低效性。局部存储和声明也更缓存高效，因为当新函数被调用和局部对象被创建时，内存空间会频繁地被重用。动态分配的内存块可以在内存中随机分布，导致较差的缓存性能。
- en: Pointer aliasing
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指针别名
- en: When accessing variables through pointers or references, while it might be obvious
    to the developer which pointers point to different and non-overlapping memory
    locations, the compiler cannot be 100% sure. To put it another way, the compiler
    cannot guarantee that a pointer is not pointing to another variable in the code
    block or different pointers are not pointing to overlapping memory locations.
    Since the compiler must assume this possibility, this prevents a lot of the compiler
    optimizations we discussed before since they can no longer be applied safely.
    There are ways to specify which pointers the compiler can safely assume are not
    aliases in C++ code. Another way would be to instruct the compiler to assume no
    pointer aliasing across the entire code, but that would require the developer
    to analyze all pointers and references and make sure there is never any aliasing,
    which is not trivial to do. Finally, the last option is to optimize the code explicitly
    keeping these hindrances to compiler optimizations in mind, which is not trivial
    either.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过指针或引用访问变量时，虽然对于开发者来说可能很明显哪些指针指向不同且不重叠的内存位置，但编译器不能100%确定。换句话说，编译器不能保证一个指针没有指向代码块中的另一个变量，或者不同的指针没有指向重叠的内存位置。由于编译器必须假设这种可能性，这阻止了我们之前讨论的许多编译器优化，因为它们不能再安全地应用。在C++代码中，有方法可以指定编译器可以安全假设不是别名的指针。另一种方法是指示编译器在整个代码中假设没有指针别名，但这需要开发者分析所有指针和引用，并确保永远不会发生别名，这并不简单。最后，最后一个选项是显式优化代码，同时考虑到这些阻碍编译器优化的因素，这也不简单。
- en: 'Our advice on dealing with pointer aliasing would be to do the following:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关于处理指针别名的建议是执行以下操作：
- en: Use the `__restrict` keyword in the function declarations when passing pointers
    to functions to instruct the compiler to assume no pointer aliasing for the pointers
    marked with that specifier
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在函数声明中传递指针到函数时，使用`__restrict`关键字来指示编译器假设带有该指定符的指针没有指针别名。
- en: If additional optimization is required, we recommend explicitly optimizing code
    paths, being aware of pointer aliasing considerations
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要额外的优化，我们建议显式优化代码路径，并意识到指针别名的考虑因素。
- en: Finally, if additional optimizations are still required, we can instruct the
    compiler to assume no pointer aliasing across the entire code base, but this is
    a dangerous option and should only be used as a last resort
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，如果仍然需要额外的优化，我们可以指示编译器在整个代码库中假设没有指针别名，但这是一个危险的选择，并且只能作为最后的手段使用。
- en: Floating-point induction variables
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 浮点归纳变量
- en: Compilers typically do not use induction variable optimizations for floating-point
    expressions and variables. This is because of the rounding errors and issues with
    precision that we have discussed before. This prevents compiler optimizations
    when dealing with floating-point expressions and values. There are compiler options
    that can enable unsafe floating-point optimizations, but the developer must make
    sure to check each expression and formulate them in such a way that these precision
    issues due to compiler optimizations do not have unintended side effects. This
    is not a trivial task; hence, developers should be careful to either optimize
    floating-point expressions explicitly or analyze side effects from unsafe compiler
    optimizations.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器通常不使用归纳变量优化来处理浮点表达式和变量。这是因为我们之前讨论过的舍入误差和精度问题。这阻止了编译器在处理浮点表达式和值时的优化。有一些编译器选项可以启用不安全的浮点优化，但开发者必须确保检查每个表达式并以这种方式构建它们，即这些由于编译器优化引起的精度问题不会产生意外的副作用。这不是一个简单任务；因此，开发者应该小心地显式优化浮点表达式或分析不安全编译器优化带来的副作用。
- en: Virtual functions and function pointers
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚函数和函数指针
- en: We have already discussed that when it comes to virtual functions and function
    pointers, the compiler cannot perform optimizations at compile time since in many
    cases it is not possible for the compiler to determine which method will be called
    at runtime.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过，当涉及到虚函数和函数指针时，由于在许多情况下编译器无法确定在运行时将调用哪个方法，因此编译器无法在编译时进行优化。
- en: Learning about compiler optimization flags
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解编译器优化标志
- en: So far, we have discussed the different optimization techniques that the compiler
    uses, as well as the different cases where the compiler fails to optimize our
    C++ code. There are two fundamental keys to generating optimized low-latency code.
    The first is to write efficient C++ code and optimize manually in cases where
    the compiler might not be able to do so. Secondly, you can provide the compiler
    with as much visibility and information as possible so it can make the correct
    and best optimization decisions. We can convey our intent to the compiler through
    the compiler flags we use to configure it.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了编译器使用的不同优化技术，以及编译器未能优化我们的 C++ 代码的不同情况。生成优化低延迟代码有两个基本关键点。第一个是编写高效的
    C++ 代码，并在编译器可能无法做到的情况下手动优化。其次，你可以尽可能地向编译器提供可见性和信息，以便它能够做出正确和最佳的优化决策。我们可以通过配置编译器的编译器标志来传达我们的意图。
- en: In this section, we will learn about the compiler flags for the GCC since that
    is the compiler we will use in this book. However, most modern compilers have
    flags to configure optimizations like the ones we will discuss in this section.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解 GCC 的编译器标志，因为这是我们将在本书中使用的编译器。然而，大多数现代编译器都有配置优化标志的选项，就像我们将在本节中讨论的那样。
- en: Approaching compiler optimization flags
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 接近编译器优化标志
- en: 'At a high level, the general approach toward GCC compiler optimization flags
    is the following:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，对 GCC 编译器优化标志的一般方法是以下内容：
- en: The highest optimization level is typically preferred so `–O3` is a good starting
    point and enables a lot of optimizations, which we will see shortly.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常首选最高优化级别，因此 `–O3` 是一个很好的起点，并启用了许多优化，我们将在稍后看到。
- en: Measuring the performance of the application in practice is the best way to
    measure and optimize the most critical code paths. GCC itself can perform `-fprofile-generate`
    option is enabled. The compiler determines the flow of the program and counts
    how many times each function and code branch is executed to find optimizations
    for the critical code paths.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实践中测量应用程序的性能是衡量和优化最关键代码路径的最佳方式。GCC 本身可以执行 `-fprofile-generate` 选项。编译器确定程序的流程并计算每个函数和代码分支被执行的次数，以找到关键代码路径的优化。
- en: Enabling `–flto` parameter enables LTO for our applications. The `-fwhole-program`
    option enables **WPO** to enable inter-procedural optimizations, treating the
    entire code base as a whole program.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用 `–flto` 参数为我们的应用程序启用 LTO。`-fwhole-program` 选项启用 **WPO** 以启用过程间优化，将整个代码库视为一个整体程序。
- en: Allowing the compiler to generate a build for a specific architecture where
    the application will run is a good idea. This lets the compiler use special instruction
    sets specific to that architecture and maximize optimization opportunities. For
    GCC, this is enabled using the `–``march` parameter.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许编译器为应用程序运行的具体架构生成构建是一个好主意。这可以让编译器使用特定于该架构的特殊指令集，并最大化优化机会。对于 GCC，这可以通过使用 `–march`
    参数来实现。
- en: It is recommended to disable `-``no-rtti` parameter.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议禁用 `-no-rtti` 参数。
- en: It is possible to instruct the GCC compiler to enable fast floating-point value
    optimizations and even enable unsafe floating-point optimizations. GCC has the
    `-ffp-model=fast`, `-funsafe-math-optimizations` and `-ffinite-math-only` options
    to enable these unsafe floating-point optimizations. When using these flags, it
    is important that the developer carefully thinks about the order of operations
    and the precision resulting from these operations. When using a parameter such
    as `-ffinite-math-only`, make sure that all floating-point variables and expressions
    are finite because this optimization depends on that property. `-fno-trapping-math`
    and `-fno-math-errno` allow the compiler to vectorize loops containing floating-point
    operations by assuming that there will be no reliance on exception handling or
    the `errno` global variable for error signaling.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以指导 GCC 编译器启用快速浮点数值优化，甚至启用不安全的浮点优化。GCC 提供了 `-ffp-model=fast`、`-funsafe-math-optimizations`
    和 `-ffinite-math-only` 选项来启用这些不安全的浮点优化。当使用这些标志时，开发者必须仔细考虑操作顺序和由此产生的精度。当使用如 `-ffinite-math-only`
    这样的参数时，请确保所有浮点变量和表达式都是有限的，因为这种优化依赖于这个属性。`-fno-trapping-math` 和 `-fno-math-errno`
    允许编译器通过假设不会依赖异常处理或 `errno` 全局变量来错误信号，将包含浮点操作的循环向量化。
- en: Understanding the details of GCC optimization flags
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解 GCC 优化标志的细节
- en: In this section, we will provide additional details on the GCC optimization
    flags available. The complete list of optimization flags available is exceptionally
    large and out of the scope of this book. First, we will describe what turning
    on the higher-level optimization directives, `–O1`, `–O2`, and `–O3`, enables
    in GCC, and we encourage interested readers to learn about each one of these in
    greater detail from the GCC manual.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提供有关 GCC 优化标志的更多详细信息。可用的优化标志列表非常大，超出了本书的范围。首先，我们将描述在 GCC 中启用高级优化指令 `–O1`、`–O2`
    和 `–O3` 可以启用什么，并鼓励感兴趣的读者从 GCC 手册中详细了解每个指令。
- en: Optimization level -O1
  id: totrans-306
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优化级别 -O1
- en: '`–O1` is the first level of optimization and enables the following flags presented
    in the following table. At this level, the compiler tries to reduce the code size
    and execution time without incurring a very large increase in compilation, linking,
    and optimization times. These are the most important levels of optimization and
    provide tremendous optimization opportunities based on the ones we discussed in
    this chapter. We will discuss a few of the flags next.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`–O1` 是第一个优化级别，并启用以下表格中展示的以下标志。在这个级别，编译器试图在不大幅增加编译、链接和优化时间的情况下，减少代码大小和执行时间。这些是最重要的优化级别，基于本章讨论的内容提供了巨大的优化机会。我们将在下面讨论一些标志。'
- en: '`-fdce` and `–fdse` perform DCE and **Dead Store** **Elimination** (**DSE**).'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fdce` 和 `–fdse` 执行 DCE 和 **死存储** **消除** （**DSE**）。'
- en: '`-fdelayed-branch` is supported on many architectures and tries to reorder
    instructions to try and maximize the throughput of the pipeline after delayed
    branch instructions.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fdelayed-branch` 在许多架构上受支持，并试图重新排序指令，以尝试在延迟分支指令之后最大化流水线的吞吐量。'
- en: '`-fguess-branch-probability` tries to guess branch probabilities based on heuristics
    for branches that the developer has not provided any hints.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fguess-branch-probability` 尝试根据开发者未提供的启发式方法猜测分支概率。'
- en: '`-fif-conversion` and `-fif-conversion2` try to eliminate branching by changing
    them into branchless equivalents using tricks similar to what we discussed in
    this chapter.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fif-conversion` 和 `-fif-conversion2` 尝试通过使用类似于本章讨论的技巧将它们转换为无分支等价物来消除分支。'
- en: '`-fmove-loop-invariants` enables loop invariant code movement optimization.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fmove-loop-invariants` 启用循环不变代码移动优化。'
- en: If you are interested, you should investigate the details of these flags since
    discussing every parameter is outside the scope of this book.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些标志感兴趣，你应该调查它们的细节，因为讨论每个参数超出了本书的范围。
- en: '| `-``fauto-inc-dec` | `-``fshrink-wrap` |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '`-fauto-inc-dec` 和 `-fshrink-wrap`'
- en: '| `-``fbranch-count-reg` | `-``fshrink-wrap-separate` |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '`-fbranch-count-reg` 和 `-fshrink-wrap-separate`'
- en: '| `-``fcombine-stack-adjustments` | `-``fsplit-wide-types` |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '`-fcombine-stack-adjustments` 和 `-fsplit-wide-types`'
- en: '| `-``fcompare-elim` | `-``fssa-backprop` |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '`-fcompare-elim` 和 `-fssa-backprop`'
- en: '| `-``fcprop-registers` | `-``fssa-phiopt` |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '`-fcprop-registers` 和 `-fssa-phiopt`'
- en: '| `-``fdce` | `-``ftree-bit-ccp` |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '`-fdce` 和 `-ftree-bit-ccp`'
- en: '| `-``fdefer-pop` | `-``ftree-ccp` |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '`-fdefer-pop` 和 `-ftree-ccp`'
- en: '| `-``fdelayed-branch` | `-``ftree-ch` |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '`-fdelayed-branch` 和 `-ftree-ch`'
- en: '| `-``fdse` | `-``ftree-coalesce-vars` |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '`-fdse` 和 `-ftree-coalesce-vars`'
- en: '| `-``fforward-propagate` | `-``ftree-copy-prop` |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '`-fforward-propagate` 和 `-ftree-copy-prop`'
- en: '| `-``fguess-branch-probability` | `-``ftree-dce` |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '`-fguess-branch-probability` 和 `-ftree-dce`'
- en: '| `-``fif-conversion` | `-``ftree-dominator-opts` |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '`-fif-conversion` 和 `-ftree-dominator-opts`'
- en: '| `-``fif-conversion2` | `-``ftree-dse` |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '`-fif-conversion2` 和 `-ftree-dse`'
- en: '| `-``finline-functions-called-once` | `-``ftree-forwprop` |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '`-finline-functions-called-once` 和 `-ftree-forwprop`'
- en: '| `-``fipa-modref` | `-``ftree-fre` |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-modref` 和 `-ftree-fre`'
- en: '| `-``fipa-profile` | `-``ftree-phiprop` |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-profile` 和 `-ftree-phiprop`'
- en: '| `-``fipa-pure-const` | `-``ftree-pta` |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-pure-const` 和 `-ftree-pta`'
- en: '| `-``fipa-reference` | `-``ftree-scev-cprop` |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-reference` 和 `-ftree-scev-cprop`'
- en: '| `-``fipa-reference-addressable` | `-``ftree-sink` |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-reference-addressable` 和 `-ftree-sink`'
- en: '| `-``fmerge-constants162` | `-``ftree-slsr` |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '`-fmerge-constants162` 和 `-ftree-slsr`'
- en: '| `-``fmove-loop-invariants` | `-``ftree-sra` |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '`-fmove-loop-invariants` 和 `-ftree-sra`'
- en: '| `-``fmove-loop-stores` | `-``ftree-ter` |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '`-fmove-loop-stores` 和 `-ftree-ter`'
- en: '| `-``fomit-frame-pointer` | `-``funit-at-a-time` |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '`-fomit-frame-pointer` 和 `-funit-at-a-time`'
- en: '| `-``freorder-blocks` |  |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '`-freorder-blocks`'
- en: Table 3.1 – GCC optimization flags enabled when -O1 is enabled
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1 – 当启用 -O1 时，GCC 优化的标志
- en: Optimization level -O2
  id: totrans-339
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优化级别 -O2
- en: '`-O2` is the next optimization level and at this level, GCC will perform a
    lot more optimizations and will lead to longer compilation and linking times.
    `-O2` adds the flags in the following table in addition to the flags enabled by
    `–O1`. We will quickly discuss a few of these flags and leave a detailed discussion
    of each flag up to interested readers to pursue.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '`-O2` 是下一个优化级别，在这个级别上，GCC 将执行更多的优化，并导致编译和链接时间更长。`-O2` 除了启用 `–O1` 的标志外，还添加了以下表格中的标志。我们将简要讨论其中的一些标志，并将每个标志的详细讨论留给感兴趣的读者去探索。'
- en: '`-falign-functions`, `-falign-labels`, and `-falign-loops` align the starting
    address of functions, jump targets, and loop locations so that the processor can
    access them as efficiently as possible. The principles we discussed on optimal
    data alignment in this chapter apply to the instruction addresses as well.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`-falign-functions`、`-falign-labels` 和 `-falign-loops` 将函数、跳转目标和循环位置的起始地址对齐，以便处理器尽可能高效地访问它们。本章讨论的关于最佳数据对齐的原则也适用于指令地址。'
- en: '`-fdelete-null-pointer-checks` lets the program assume that dereferencing null
    pointers is not safe and leverages that assumption to perform constant folding,
    eliminate null pointer checks, and so on.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fdelete-null-pointer-checks` 允许程序假设解引用空指针是不安全的，并利用这个假设来进行常量折叠、消除空指针检查等操作。'
- en: '`-fdevirtualize` and `-fdevirtualize-speculatively` attempt to convert virtual
    function calls into direct function calls wherever possible. This, in turn, can
    lead to even more optimization due to inlining.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fdevirtualize` 和 `-fdevirtualize-speculatively` 尽可能地将虚函数调用转换为直接函数调用。这反过来又可能导致更多的优化，因为内联。'
- en: '`-fgcse` enables **Global Common Subexpression Elimination** (**GCSE**) and
    constant propagation.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fgcse` 启用 **全局公共子表达式消除**（**GCSE**）和常量传播。'
- en: '`-finline-functions`, `-finline-functions-called-once`, and `-findirect-inlining`
    increase the aggressiveness of the compiler in its attempts to inline functions
    and look for indirect inline opportunities due to previous optimization passes.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`-finline-functions`、`-finline-functions-called-once` 和 `-findirect-inlining`
    增强了编译器在尝试内联函数和寻找由于先前优化传递而产生的间接内联机会时的积极性。'
- en: '| `-``falign-functions -falign-jumps` | `-``foptimize-sibling-calls` |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '`-falign-functions -falign-jumps` 和 `-foptimize-sibling-calls`'
- en: '| `-``falign-labels -falign-loops` | `-``foptimize-strlen` |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '`-falign-labels -falign-loops` 和 `-foptimize-strlen`'
- en: '| `-``fcaller-saves` | `-``fpartial-inlining` |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '`-fcaller-saves` 和 `-fpartial-inlining`'
- en: '| `-``fcode-hoisting` | `-``fpeephole2` |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '`-fcode-hoisting` 和 `-fpeephole2`'
- en: '| `-``fcrossjumping` | `-``freorder-blocks-algorithm=stc` |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '`-fcrossjumping` 和 `-freorder-blocks-algorithm=stc`'
- en: '| `-``fcse-follow-jumps -fcse-skip-blocks` | `-``freorder-blocks-and-partition
    -freorder-functions` |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '`-fcse-follow-jumps -fcse-skip-blocks` 和 `-freorder-blocks-and-partition -freorder-functions`'
- en: '| `-``fdelete-null-pointer-checks` | `-``frerun-cse-after-loop` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '`-fdelete-null-pointer-checks` 和 `-frerun-cse-after-loop`'
- en: '| `-``fdevirtualize -fdevirtualize-speculatively` | `-``fschedule-insns -fschedule-insns2`
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '`-fdevirtualize -fdevirtualize-speculatively` 和 `-fschedule-insns -fschedule-insns2`'
- en: '| `-``fexpensive-optimizations` | `-``fsched-interblock -fsched-spec` |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '`-fexpensive-optimizations` 和 `-fsched-interblock -fsched-spec`'
- en: '| `-``ffinite-loops` | `-``fstore-merging` |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '`-ffinite-loops` 和 `-fstore-merging`'
- en: '| `-``fgcse -fgcse-lm` | `-``fstrict-aliasing` |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '`-fgcse -fgcse-lm` 和 `-fstrict-aliasing`'
- en: '| `-``fhoist-adjacent-loads` | `-``fthread-jumps` |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '`-fhoist-adjacent-loads` 和 `-fthread-jumps`'
- en: '| `-``finline-functions` | `-``ftree-builtin-call-dce` |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '`-finline-functions` 和 `-ftree-builtin-call-dce`'
- en: '| `-``finline-small-functions` | `-``ftree-loop-vectorize` |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '`-finline-small-functions` 和 `-ftree-loop-vectorize`'
- en: '| `-``findirect-inlining` | `-``ftree-pre` |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '`-findirect-inlining` 和 `-ftree-pre`'
- en: '| `-fipa-bit-cp -``fipa-cp -fipa-icf` | `-``ftree-slp-vectorize` |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-bit-cp -fipa-cp -fipa-icf` 和 `-ftree-slp-vectorize`'
- en: '| `-fipa-ra -``fipa-sra -fipa-vrp` | `-``ftree-switch-conversion -ftree-tail-merge`
    |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-ra -fipa-sra -fipa-vrp` 和 `-ftree-switch-conversion -ftree-tail-merge`'
- en: '| `-``fisolate-erroneous-paths-dereference` | `-``ftree-vrp` |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '`-fisolate-erroneous-paths-dereference` 和 `-ftree-vrp`'
- en: '| `-``flra-remat` | `-``fvect-cost-model=very-cheap` |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '`-flra-remat` 和 `-fvect-cost-model=very-cheap`'
- en: Table 3.2 – GCC optimization flags enabled in addition to the ones from -O1
    when -O2 is enabled
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.2 – 当启用 -O2 时，除了来自 -O1 的标志之外，GCC 启用的优化标志
- en: Optimization level –O3
  id: totrans-366
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优化级别 –O3
- en: '`–O3` is the most aggressive optimization option in GCC and it will optimize
    even when it leads to larger executable sizes as long as the program performs
    better. `-O3` enables the following flags presented in the next table beyond `–O2`.
    We quickly discuss a few important ones first and then provide the complete list.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '`–O3` 是 GCC 中最激进的优化选项，它会在程序性能更好的情况下进行优化，即使这会导致可执行文件大小增加。`-O3` 启用了下一表中列出的以下标志，除了
    `–O2`。我们首先简要讨论几个重要标志，然后提供完整的列表。'
- en: '`-fipa-cp-clone` creates function clones to make interprocedural constant propagation
    and other forms of optimization stronger by trading execution speed at the cost
    of higher executable sizes.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fipa-cp-clone` 通过以更高的可执行文件大小为代价换取执行速度，创建函数克隆以增强跨程序常量传播和其他形式的优化。'
- en: '`-fsplit-loops` attempts to split a loop if it can avoid branching within the
    loop by having the loop for one side and then the other side – for instance, in
    a case where we check the side of execution in a trading algorithm within a loop
    and execute two different code blocks within the loop.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '`-fsplit-loops` 尝试将循环拆分，如果可以通过将循环的一侧和另一侧分开来避免循环内的分支，例如，在一个循环中检查交易算法的执行方向，并在循环内执行两个不同的代码块的情况下。'
- en: '`-funswitch-loops` moves loop invariant branches out of the loop to minimize
    branching.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '`-funswitch-loops` 将循环不变分支移出循环以最小化分支。'
- en: '| `-``fgcse-after-reload` | `-``fsplit-paths` |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '`-fgcse-after-reload` 和 `-fsplit-paths`'
- en: '| `-``fipa-cp-clone -floop-interchange` | `-``ftree-loop-distribution` |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '`-fipa-cp-clone -floop-interchange` 和 `-ftree-loop-distribution`'
- en: '| `-``floop-unroll-and-jam` | `-``ftree-partial-pre` |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '`-floop-unroll-and-jam` 和 `-ftree-partial-pre`'
- en: '| `-``fpeel-loops` | `-``funswitch-loops` |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '`-fpeel-loops` 和 `-funswitch-loops`'
- en: '| `-``fpredictive-commoning` | `-``fvect-cost-model=dynamic` |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '`-fpredictive-commoning` 和 `-fvect-cost-model=dynamic`'
- en: '| `-``fsplit-loops` | `-``fversion-loops-for-strides` |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '`-fsplit-loops` 和 `-fversion-loops-for-strides`'
- en: Table 3.3 – GCC optimization flags enabled in addition to the ones from -O2
    when -O3 is enabled
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.3 – 当启用 -O3 时，除了来自 -O2 的标志之外，GCC 启用的优化标志
- en: We will discuss some additional compiler optimization flags we have found useful
    when it comes to optimizing low-latency applications.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论一些额外的编译器优化标志，我们在优化低延迟应用程序时发现它们很有用。
- en: Static linkage
  id: totrans-379
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 静态链接
- en: The `–l library` option is passed to the linker to specify which library to
    link the executables with. However, if the linker finds a static library that
    has a name such as `liblibrary.a` and a shared library that has a name such as
    `liblibrary.so`, then we must specify the `–static` parameter to prevent linking
    with shared libraries and opt for the static library instead. We have discussed
    before why static linkage is preferred over shared library linkage for low-latency
    applications.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`–l library` 选项传递给链接器以指定要链接的可执行文件与哪个库。然而，如果链接器找到一个名为 `liblibrary.a` 的静态库和一个名为
    `liblibrary.so` 的共享库，那么我们必须指定 `–static` 参数以防止与共享库链接并选择静态库。我们之前已经讨论过为什么对于低延迟应用程序，静态链接比共享库链接更受欢迎。'
- en: Target architecture
  id: totrans-381
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 目标架构
- en: The `–march` parameter is used to specify the target architecture for which
    the compiler should build the final executable binary. For example, `–march=native`
    specifies that the compiler should build the executable for the architecture that
    it is being built on. We reiterate here that when the compiler knows the target
    architecture that the application is being built to run on, it can leverage information
    about that architecture, such as extended instruction sets and so on, to improve
    optimization.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '`–march`参数用于指定编译器应构建的最终可执行二进制文件的目标架构。例如，`–march=native`指定编译器应为其正在构建的架构构建可执行文件。我们在此重申，当编译器知道应用程序将被构建以在哪个架构上运行时，它可以利用有关该架构的信息，例如扩展指令集等，以改进优化。'
- en: Warnings
  id: totrans-383
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 警告
- en: The`–Wall`, `–Wextra`, and `–Wpendantic` parameters control the number of warnings
    that are generated by the compiler when it detects a variety of different cases
    that are not technically errors but could be unsafe. It is advisable to turn these
    on for most applications because they detect potential bugs and typos in developers’
    code. While these do not directly affect the compiler’s ability to optimize the
    application, sometimes, the warnings force developers to inspect cases of ambiguity
    or sub-optimal code, such as unexpected or implicit type conversions, which can
    be inefficient. The `–Werror` parameter turns these warnings into errors and will
    force the developer to inspect and fix each case that generates a compiler warning
    before compilation can succeed.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '`–Wall`、`–Wextra`和`–Wpendantic`参数控制编译器在检测到各种不同情况时生成的警告数量，这些情况在技术上不是错误，但可能是危险的。对于大多数应用程序来说，建议启用这些参数，因为它们可以检测开发者代码中的潜在错误和打字错误。虽然这些参数不会直接影响编译器优化应用程序的能力，但有时，警告会迫使开发者检查模糊或次优代码的情况，例如意外的或隐式的类型转换，这可能是低效的。`–Werror`参数将这些警告转换为错误，并将迫使开发者在编译成功之前检查并修复每个生成编译器警告的情况。'
- en: Unsafe fast math
  id: totrans-385
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不安全快速数学
- en: 'This category of compiler optimization flags should not be enabled without
    a lot of consideration and due diligence. In C++, the compiler cannot apply a
    lot of floating-point optimizations that depend on properties such as floating-point
    operations yielding valid values, floating-point expressions being associative,
    and so on. To recap, this is because of the way floating-point values are represented
    in hardware, and a lot of these optimizations can lead to precision loss and different
    (and possibly incorrect) results. Enabling the `–ffast-math` parameter in turn
    enables the following parameters:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有充分考虑和尽职调查的情况下，不应启用这类编译器优化标志。在C++中，编译器无法应用许多依赖于诸如浮点运算产生有效值、浮点表达式具有结合性等属性的浮点优化。概括来说，这是因为浮点值在硬件中的表示方式，而且许多这些优化可能导致精度损失和不同的（甚至可能是错误的）结果。启用`–ffast-math`参数反过来会启用以下参数：
- en: '`–``fno-math-errno`'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–fno-math-errno`'
- en: '`–``funsafe-math-optimizations`'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–funsafe-math-optimizations`'
- en: '`–``ffinite-math-only`'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–ffinite-math-only`'
- en: '`–``fno-rounding-math`'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–fno-rounding-math`'
- en: '`–``fno-signaling-nans`'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–fno-signaling-nans`'
- en: '`–``fcx-limited-range`'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–fcx-limited-range`'
- en: '`–``fexcess-precision=fast`'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`–fexcess-precision=fast`'
- en: These parameters will allow the compiler to apply optimizations to floating-point
    expressions even if they are unsafe. These are not automatically enabled in any
    of the three optimization levels because they are unsafe and should only be enabled
    if the developer is confident that there are no errors or side effects that show
    up because of these.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数将允许编译器对浮点表达式应用优化，即使它们是不安全的。这些参数在三个优化级别中都不会自动启用，因为它们是不安全的，并且只有在开发者确信没有因为这些问题出现错误或副作用时才应该启用。
- en: Summary
  id: totrans-395
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, first, we discussed general advice that applies to developing
    low-latency applications in any programming language. We discussed the ideal software
    engineering approach when it comes to these applications and how to think about,
    design, develop, and evaluate building blocks such as the data structures and
    algorithms to use.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，首先，我们讨论了适用于任何编程语言开发低延迟应用程序的一般建议。我们讨论了这些应用程序的理想软件工程方法，以及如何考虑、设计、开发和评估使用的数据结构和算法等构建块。
- en: We emphasized that when it comes to low-latency application development specifically,
    the depth of knowledge on topics such as processor architecture, cache and memory
    layout and access, how the C++ programming language works under the hood, and
    how the compiler works to optimize your code will dictate your success. Measuring
    and improving performance is also a critical component for low-latency applications
    but we will dive into those details at the end of this book.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调，在低延迟应用开发方面，对处理器架构、缓存和内存布局及访问、C++编程语言在底层的工作原理以及编译器如何优化你的代码等主题的深入了解将决定你的成功。对于低延迟应用来说，测量和提升性能也是一个关键组成部分，但我们将在这本书的末尾深入探讨这些细节。
- en: We spent a lot of time discussing different C++ principles, constructs, and
    features with the objective of understanding how they are implemented at a lower
    level. The goal here was to unlearn sub-optimal practices and emphasize some of
    the ideal aspects of using C++ for low-latency application development.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花费了大量时间讨论不同的C++原则、构造和特性，目的是理解它们在较低层面的实现方式。这里的目的是摆脱次优实践，并强调使用C++进行低延迟应用开发的某些理想方面。
- en: In the remainder of this book, as we build our low-latency electronic trading
    exchange ecosystem (collection of applications that interact with each other),
    we will reinforce and build on these ideas we discussed here as we avoid certain
    C++ features and use others instead.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，当我们构建我们的低延迟电子交易交换生态系统（相互交互的应用集合）时，我们将加强并基于这里讨论的这些想法，避免某些C++特性并使用其他特性。
- en: In the last section of this chapter, we discussed many aspects of the C++ compiler
    in detail. We tried to build an understanding of how compilers optimize developers’
    high-level code, as in, what techniques they have at their disposal. We also investigated
    scenarios in which the compiler fails to optimize a developer’s code. The goal
    there was for you to understand how to use a compiler to your advantage when trying
    to output the most optimal machine code possible and help the compiler help you
    avoid conditions where the compiler fails to optimize. Finally, we looked at the
    different compiler optimization flags available for the GNU GCC compiler, which
    is what we will use in the rest of this book.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们详细讨论了C++编译器的许多方面。我们试图理解编译器如何优化开发者的高级代码，即他们有哪些技术可用。我们还调查了编译器未能优化开发者代码的场景。那里的目标是让你了解如何在尝试输出尽可能优化的机器代码时利用编译器，并帮助编译器避免编译器无法优化的条件。最后，我们查看GNU
    GCC编译器可用的不同编译器优化标志，这是我们将在本书的其余部分使用的编译器。
- en: We will put our theoretical knowledge into practice in the next chapter where
    we jump into implementing some common building blocks of low-latency applications
    in C++. We will keep our goal of building these components to be low-latency and
    highly performant. We will carefully use the principles and techniques we discussed
    in this chapter to build these high-performance components. In later chapters,
    we will use these components to build an electronic trading ecosystem.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把我们的理论知识付诸实践，我们将跳入用C++实现低延迟应用的一些常见构建块。我们将保持构建这些组件以实现低延迟和高性能的目标。我们将仔细使用本章讨论的原则和技术来构建这些高性能组件。在后面的章节中，我们将使用这些组件来构建一个电子交易生态系统。
