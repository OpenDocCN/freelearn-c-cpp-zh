<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-88"><a id="_idTextAnchor093"/>4</h1>
<h1 id="_idParaDest-89"><a id="_idTextAnchor094"/>Building the C++ Building Blocks for Low Latency Applications</h1>
<p>In the previous chapter, we had a detailed and highly technical discussion of how to approach developing low latency applications in C++. We also investigated the technical details of the C++ programming language as well as the GCC compiler. Now, we will move from a theoretical discussion to building some practical low latency C++ components ourselves.</p>
<p>We will build some relatively general components that can be used in a variety of different low latency applications, such as the ones we discussed in the previous chapters. As we build these basic building blocks in this chapter, we will learn about using C++ effectively to write highly performant C++ code. We will use these components in the rest of the book to demonstrate where these components fit into the electronic trading ecosystem that we will design and build.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>C++ threading for multi-threaded low latency applications</li>
<li>Designing C++ memory pools to avoid dynamic memory allocations</li>
<li>Transferring data using lock-free queues</li>
<li>Building a low latency logging framework</li>
<li>C++ network programming using sockets</li>
</ul>
<h1 id="_idParaDest-90"><a id="_idTextAnchor095"/>Technical requirements</h1>
<p>All the code for this book can be found in the GitHub repository for this book at <a href="https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP">https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP</a>. The source for this chapter is in the <code>Chapter4</code> directory in the repository.</p>
<p>We expect you to have at least intermediate C++ programming experience, since we will assume you understand the widely used C++ programming features well. We also assume that you have some experience with network programming in C++, since network programming is a huge topic and cannot be covered in this book. For this book, starting with this chapter, we will use the CMake and Ninja build systems, so we expect you to either understand CMake, g++, Ninja, Make, or some such build system to be able to build the code samples for this book.</p>
<p>The specifications of the environment in which the source code for this book was developed are shown here. We present the details of this environment since all the C++ code presented in this book is not necessarily portable and might require some minor changes to work in your environment:</p>
<ul>
<li><code>Linux 5.19.0-41-generic #42~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 18 17:40:00 UTC 2 x86_64 x86_64 </code><code>x86_64 GNU/Linux</code></li>
<li><code>g++ (Ubuntu </code><code>11.3.0-1ubuntu1~22.04.1) 11.3.0</code></li>
<li><code>cmake </code><code>version 3.23.2</code></li>
<li><code>1.10.2</code></li>
</ul>
<h1 id="_idParaDest-91"><a id="_idTextAnchor096"/>C++ threading for multi-threaded low latency applications</h1>
<p>The first component <a id="_idIndexMarker558"/>we will build <a id="_idIndexMarker559"/>is a very small one but still quite fundamental. This section will design and implement a method of creating and running threads of execution. These will be used in many different parts of a full low-latency system, depending on the design of the different sub-components in the system. Depending on the design of the system, different components might work together as a pipeline to facilitate parallel processing. We will use the multi-threading framework in exactly such a way in our electronic trading systems. Another use case is to pass off non-critical tasks such as logging onto disk, computing statistics, and so on to a background thread.</p>
<p>Before we move on to the source code that creates and manipulates threads, let us first quickly <a id="_idIndexMarker560"/>define a few useful macros. We <a id="_idIndexMarker561"/>will use these functions in many places in the source code that we will be writing in this book, starting with this chapter.</p>
<h2 id="_idParaDest-92"><a id="_idTextAnchor097"/>Defining some useful macros and functions</h2>
<p>Most low latency <a id="_idIndexMarker562"/>applications run on modern pipelined processors that <a id="_idIndexMarker563"/>pre-fetch instructions and data before they need to be executed. We discussed in the previous chapter that branch mispredictions are extremely expensive and stall the pipeline, introducing bubbles into it. Therefore, an important development practice for low latency applications is to have fewer branches. Since branches are unavoidable, it is also important to try and make them as predictable as possible.</p>
<p>We have two simple macros that we will use to provide branching hints to the compiler. These use the <code>__builtin_expect</code> GCC built-in function that reorders the machine instructions generated by the compiler. Effectively, the compiler uses the branch prediction hints provided by the developer to generate machine code that is optimized under the assumption that a branch is more or less likely to be taken.</p>
<p>Note that instruction reordering is only part of the full picture when it comes to branch prediction, since there is a hardware branch predictor that the processor uses when running instructions. Note that modern hardware branch predictors are extremely good at predicting branches and jumps, especially in cases where the same branch gets taken many times and even when there are at least easily predictable branching patterns.</p>
<p>The two macros are the following:</p>
<pre class="source-code">
#define LIKELY(x) __builtin_expect(!!(x), 1)
#define UNLIKELY(x) __builtin_expect(!!(x), 0)</pre>
<p>The <code>LIKELY(x)</code> macro specifies that the condition specified by <code>x</code> is likely to be true, and the <code>UNLIKELY(x)</code> macro does the opposite. As an example of the usage, we will use the <code>UNLIKELY</code> macro shortly in the next set of functions. In C++20, this is standardized like the <code>[[likely]]</code> and <code>[[unlikely]]</code> attributes to perform the same function in a standard and portable manner.</p>
<p>We will define two additional functions next, but these are simply used for assertions in our code base. These should be pretty self-explanatory; <code>ASSERT</code> logs a message and exits if the condition it is provided evaluates to <code>false</code>, and <code>FATAL</code> simply logs a message and exits. Note the use of <code>UNLIKELY</code> here to specify that we do not expect the <code>!cond</code> condition to evaluate to <code>true</code>. Also note that using the <code>ASSERT</code> method on critical code paths is not free, mostly because of the if check. This is something that we will eventually change <a id="_idIndexMarker564"/>to be optimized out of our code for release <a id="_idIndexMarker565"/>builds, but for now, we will keep it, since it should be extremely cheap to use:</p>
<pre class="source-code">
inline auto ASSERT(bool cond, const std::string&amp; msg)
  noexcept {
  if(UNLIKELY(!cond)) {
    std::cerr &lt;&lt; msg &lt;&lt; std::endl;
    exit(EXIT_FAILURE);
  }
}
inline auto FATAL(const std::string&amp; msg) noexcept {
  std::cerr &lt;&lt; msg &lt;&lt; std::endl;
  exit(EXIT_FAILURE);
}</pre>
<p>The code discussed in this section can be found in the <code>Chapter4/macros.h</code> source file in the GitHub repository for this book. Note that the <code>macros.h</code> header file includes the following two header files:</p>
<pre class="source-code">
#include &lt;cstring&gt;
#include &lt;iostream&gt;</pre>
<p>Now, let us jump into thread creation and manipulation functionality in the next section.</p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor098"/>Creating and launching a new thread</h2>
<p>The method <a id="_idIndexMarker566"/>defined in the following code block creates a new thread object, sets <a id="_idIndexMarker567"/>the thread affinity on the thread (more on this later), and forwards <a id="_idIndexMarker568"/>the function and related arguments <a id="_idIndexMarker569"/>that the thread will run during its execution. This is achieved in the <code>thread_body</code> lambda, which is passed to the constructor of <code>std::thread</code>. Note the use of <em class="italic">variadic template arguments</em> and <em class="italic">perfect forwarding</em> to allow this method to be used, running all kinds of functions, arbitrary types, and any number of arguments. After creating the thread, the method waits till the thread either starts running successfully or fails because it failed to set thread affinity, which is what the call to <code>t-&gt;join()</code> does. Ignore the call to <code>setThreadCore(core_id)</code> for now; we will discuss that in the next section:</p>
<pre class="source-code">
#pragma once
#include &lt;iostream&gt;
#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/syscall.h&gt;
template&lt;typename T, typename... A&gt;
inline auto createAndStartThread(int core_id, const
  std::string &amp;name, T &amp;&amp;func, A &amp;&amp;... args) noexcept {
  std::atomic&lt;bool&gt; running(false), failed(false);
  auto thread_body = [&amp;] {
    if (core_id &gt;= 0 &amp;&amp; !setThreadCore(core_id)) {
      std::cerr &lt;&lt; "Failed to set core affinity for " &lt;&lt;
        name &lt;&lt; " " &lt;&lt; pthread_self() &lt;&lt; " to " &lt;&lt; core_id
          &lt;&lt; std::endl;
      failed = true;
      return;
    }
    std::cout &lt;&lt; "Set core affinity for " &lt;&lt; name &lt;&lt; " " &lt;&lt;
      pthread_self() &lt;&lt; " to " &lt;&lt; core_id &lt;&lt; std::endl;
    running = true;
    std::forward&lt;T&gt;(func)((std::forward&lt;A&gt;(args))...);
  };
  auto t = new std::thread(thread_body);
  while (!running &amp;&amp; !failed) {
    using namespace std::literals::chrono_literals;
    std::this_thread::sleep_for(1s);
  }
  if (failed) {
    t-&gt;join();
    delete t;
    t = nullptr;
  }
  return t;
}</pre>
<p>The code discussed in <a id="_idIndexMarker570"/>this section can be found in the <code>Chapter4/thread_utils.h</code> source <a id="_idIndexMarker571"/>file in the GitHub repository for this <a id="_idIndexMarker572"/>book. Now, let us jump into the final <a id="_idIndexMarker573"/>section to set thread affinity in the <code>setThreadCore(core_id)</code> function.</p>
<h2 id="_idParaDest-94"><a id="_idTextAnchor099"/>Setting thread affinity</h2>
<p>Here, we will discuss the source code to set the thread affinity for the thread creation lambda we saw in <a id="_idIndexMarker574"/>the previous section. Before we discuss the source code, remember <a id="_idIndexMarker575"/>that if there is a lot of context-switching between threads, it adds a lot of overhead to thread performance. Threads jumping between CPU cores also hurts performance for similar reasons. Setting thread affinity for performance-critical threads is very important for low latency applications to avoid these issues.</p>
<p>Now, let us look at how to set thread affinity in the <code>setThreadCore()</code> method. First, we use the <code>CPU_ZERO()</code> method to clear the <code>cpu_set_t</code> variable, which is just an array of flags. Then, we use the <code>CPU_SET()</code> method to enable entry for the <code>core_id</code> we are trying to pin the core to. Finally, we use the <code>pthread_setaffinity_np()</code> function to set the thread affinity and return <code>false</code> if that fails. Note the use of <code>pthread_self()</code> here to get the thread ID to use, which makes sense because this is called from within the <code>std::thread</code> instance we create in <code>createAndStartThread()</code>:</p>
<pre class="source-code">
inline auto setThreadCore(int core_id) noexcept {
  cpu_set_t cpuset;
  CPU_ZERO(&amp;cpuset);
  CPU_SET(core_id, &amp;cpuset);
  return (pthread_setaffinity_np(pthread_self(), sizeof
    (cpu_set_t), &amp;cpuset) == 0);
}</pre>
<p>The code discussed in this section can be found in the <code>Chapter4/thread_utils.h</code> source file in the <a id="_idIndexMarker576"/>GitHub repository for this <a id="_idIndexMarker577"/>book. These code blocks belong in the <code>Common</code> namespace, as you will see when you look at the <code>thread_utils.h</code> source file in the GitHub repository.</p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor100"/>Building an example</h2>
<p>Before we conclude <a id="_idIndexMarker578"/>this section, let us quickly look at a simple example that uses the thread utilities we just created. This example can be found in the <code>Chapter4/thread_example.cpp</code> source file in the GitHub repository for this book. Note that the library and all the examples for this chapter can be built using the <code>CMakeLists.txt</code> included in the <code>Chapter4</code> directory. We also provided two simple scripts, <code>build.sh</code> and <code>run_examples.sh</code>, to build and run these examples after setting the correct paths to the <code>cmake</code> and <code>ninja</code> binaries. Note that <code>cmake</code> and <code>ninja</code> are arbitrary build system choices here, and you can change the build system to be anything else if needed.</p>
<p>The example should be quite self-explanatory – we create and launch two threads with a dummy task of adding the two arguments (<code>a</code> and <code>b</code>) passed to it. Then, we wait for the threads to finish execution before exiting the program:</p>
<pre class="source-code">
#include "thread_utils.h"
auto dummyFunction(int a, int b, bool sleep) {
  std::cout &lt;&lt; "dummyFunction(" &lt;&lt; a &lt;&lt; "," &lt;&lt; b &lt;&lt; ")" &lt;&lt;
    std::endl;
  std::cout &lt;&lt; "dummyFunction output=" &lt;&lt; a + b &lt;&lt;
    std::endl;
  if(sleep) {
    std::cout &lt;&lt; "dummyFunction sleeping..." &lt;&lt; std::endl;
    using namespace std::literals::chrono_literals;
    std::this_thread::sleep_for(5s);
  }
  std::cout &lt;&lt; "dummyFunction done." &lt;&lt; std::endl;
}
int main(int, char **) {
  using namespace Common;
  auto t1 = createAndStartThread(-1, "dummyFunction1",
    dummyFunction, 12, 21, false);
  auto t2 = createAndStartThread(1, "dummyFunction2",
    dummyFunction, 15, 51, true);
  std::cout &lt;&lt; "main waiting for threads to be done." &lt;&lt;
    std::endl;
  t1-&gt;join();
  t2-&gt;join();
  std::cout &lt;&lt; "main exiting." &lt;&lt; std::endl;
  return 0;
}</pre>
<p>Running this example will output something like this as the program executes:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter4$ ./cmake-build-release/thread_example
Set core affinity for dummyFunction1 140124979386112 to -1
dummyFunction(12,21)
dummyFunction output=33
dummyFunction done.
Set core affinity for dummyFunction2 140124970993408 to 1
dummyFunction(15,51)
dummyFunction output=66
dummyFunction sleeping...
main waiting for threads to be done.
dummyFunction done.
main exiting.</pre>
<p>Let us move on to the <a id="_idIndexMarker579"/>next section, where we will discuss how to avoid dynamic memory allocations when objects need to be created and discarded during runtime.</p>
<h1 id="_idParaDest-96"><a id="_idTextAnchor101"/>Designing C++ memory pools to avoid dynamic memory allocations</h1>
<p>We have had <a id="_idIndexMarker580"/>several discussions <a id="_idIndexMarker581"/>on dynamic memory allocation, the steps the OS needs to perform, and why dynamic memory allocation is slow. Dynamic memory allocation is so slow in fact that low latency applications actively try to avoid it as much as possible on the critical path. We cannot build useful applications without creating and deleting many objects at runtime, and dynamic memory allocation is too slow for low latency applications.</p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor102"/>Understanding the definition of a memory pool</h2>
<p>First, let us formally <a id="_idIndexMarker582"/>define what a memory pool is and why we need one. Many applications (including low latency applications) need to be able to handle many objects and an unknown number of objects. By an unknown number of objects, we mean that the expected count of objects cannot be determined ahead of time, and it cannot be ascertained what the maximum number of objects will be. Obviously, the maximum number of objects possible is what can fit inside the system’s memory. The traditional approach to handling these objects is to use dynamic memory allocations as needed. In such a case, the heap memory is considered the memory pool – that is, the pool of memory to allocate from and deallocate to. Unfortunately, these are slow, and we will control how the allocation and deallocation of memory happen in our system using our own custom memory pool. We define a memory pool as anything from which we can request additional memory or objects and return free memory or objects to. By building our own custom memory pool, we can leverage the usage patterns and control the allocation and deallocation mechanisms for optimal performance.</p>
<h2 id="_idParaDest-98"><a id="_idTextAnchor103"/>Understanding the use cases of a memory pool</h2>
<p>When the exact number of objects of a certain type that will be required is known ahead of time, you <a id="_idIndexMarker583"/>can decide to create exactly that number when needed. In practice, there are many cases where the exact number of objects is not known ahead of time. This means we need to create objects on the fly using dynamic memory allocation. As mentioned previously, dynamic memory allocation is a very slow process and a problem for low latency applications. We use the term <em class="italic">memory pool</em> to describe a pool of objects of a certain type, and that is what we will build in this section. We will use the memory pool in this book to allocate and deallocate objects that we cannot predict.</p>
<p>The solution we will use is to pre-allocate large blocks of memory at startup and serve out required amounts at runtime – that is, do the memory allocation and deallocation steps ourselves from this storage pool. This ends up performing significantly better for a lot of different reasons, such as being able to limit the memory pool usage to certain components in our system instead of all processes running on the server. We can also control the memory storage and allocation and deallocation algorithms, tuning them to perform optimally for our specific application.</p>
<p>Let us start by first <a id="_idIndexMarker584"/>making some design decisions for our memory pool. All the source code for our memory pool is in the <code>Chapter4/mem_pool.h</code> source file in the GitHub repository for this book.</p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor104"/>Designing the memory pool storage</h2>
<p>First, we need to decide <a id="_idIndexMarker585"/>how to store the elements inside the memory pool. We have really two major choices here – store them on the stack using something like an old-style array (<code>T[N]</code>) or <code>std::array</code>, or store it on the heap using something like an old-style pointer (<code>T*</code>) or something like <code>std::vector</code>. Depending on the size of the memory pool, the usage frequency, usage patterns, and the application itself, one choice might be better than the other. For instance, it is possible that we expect to need a huge amount of memory in the memory pool, either because the objects it stores are large or there are many of them. For such a case, heap allocation would be the preferred choice to accommodate the large memory requirements without impacting the stack memory. If we expect very few objects or small objects, we should consider using the stack implementation instead. If we expect to access the objects rarely, putting them on the stack might encounter better cache performance, but for frequent access, either implementation should work equally well. As with a lot of other choices, these decisions are always made by measuring performance in practice. For our memory pool, we will use <code>std::vector</code> and heap allocation while noting that it is not thread-safe.</p>
<p>We also need a variable to track which blocks are free or in use. Finally, we will need one last variable to track the location of the next free block to quickly serve allocation requests. One important thing to note here is that we have two choices:</p>
<ul>
<li>We use two vectors – one to track the objects and one to track the free or empty markers. This solution is presented in the following diagram; note that in this example, we assume that these two vectors are in very different memory locations. The point we are trying to make here is that accessing the free or empty marker and the object itself might cause cache misses because they are far away from each other.</li>
</ul>
<div><div><img alt="Figure 4.1 – A memory pool implementation that uses two vectors to track objects and show which indices are free or in use" src="img/Figure_4.1_B19434.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – A memory pool implementation that uses two vectors to track objects and show which indices are free or in use</p>
<ul>
<li>We maintain a <a id="_idIndexMarker586"/>single vector of structures (a struct, a class, or primitive objects), and each structure stores both the object and variable to represent the free or empty flag.</li>
</ul>
<div><div><img alt="Figure 4.2 – A memory pool implementation that uses a single vector to track the object and see whether it is free or in use" src="img/Figure_4.2_B19434.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – A memory pool implementation that uses a single vector to track the object and see whether it is free or in use</p>
<p>The second choice is better from a cache performance perspective, because accessing the object <a id="_idIndexMarker587"/>and free marker placed right after the object is better than accessing two different locations in two different vectors that might be potentially far away from each other in memory. This is also because, in almost all usage patterns, if we access the object, we access the free marker and vice versa:</p>
<pre class="source-code">
#pragma once
#include &lt;cstdint&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include "macros.h"
namespace Common {
  template&lt;typename T&gt;
  class MemPool final {
private:
  struct ObjectBlock {
    T object_;
    bool is_free_ = true;
  };
  std::vector&lt;ObjectBlock&gt; store_;
  size_t next_free_index_ = 0;
};</pre>
<p>Next, we need to <a id="_idIndexMarker588"/>look at how we initialize this memory pool in the constructor and some boilerplate code for the construction and assignment tasks.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor105"/>Initializing the memory pool</h2>
<p>Initializing our memory pool is quite straightforward – we simply accept a parameter that specifies <a id="_idIndexMarker589"/>the initial size of our memory pool and initialize the vector to be large enough to accommodate that many concurrently allocated objects. In our design, we will not add functionality to resize the memory pool past its initial size, but that is a relatively straightforward extension to add if needed. Note that this initial vector initialization is the only time the memory pool allocates memory dynamically, so the memory pool should be created before the execution of the critical path starts. One thing to note here is that we add an assertion to make sure that the actual object of type <code>T</code> is the first one in the <code>ObjectBlock</code> struct; we will see the reason for this requirement in the <em class="italic">Handling </em><em class="italic">deallocations</em> section:</p>
<pre class="source-code">
public:
  explicit MemPool(std::size_t num_elems) :
      store_(num_elems, {T(), true}) /* pre-allocation of
        vector storage. */ {
    ASSERT(reinterpret_cast&lt;const ObjectBlock *&gt;
      (&amp;(store_[0].object_)) == &amp;(store_[0]), "T object
        should be first member of ObjectBlock.");
  }</pre>
<p>Now for some boilerplate code – we will delete the default constructor, the copy constructor, and the move constructor methods. We will do the same with the copy assignment operator and the move assignment operator. We do this so that these methods are not accidentally called without our knowledge. This is also the reason we made our constructor explicit – to prohibit implicit conversions where we do not expect them:</p>
<pre class="source-code">
  MemPool() = delete;
  MemPool(const MemPool&amp;) = delete;
  MemPool(const MemPool&amp;&amp;) = delete;
  MemPool&amp; operator=(const MemPool&amp;) = delete;
  MemPool&amp; operator=(const MemPool&amp;&amp;) = delete;</pre>
<p>Now, let us move <a id="_idIndexMarker590"/>on to the code to serve allocation requests by providing a free object of the <code>T</code>-type template parameter.</p>
<h2 id="_idParaDest-101"><a id="_idTextAnchor106"/>Serving new allocation requests</h2>
<p>Serving allocation requests is a <a id="_idIndexMarker591"/>simple task of finding a block that is free in our memory pool storage, which we can do easily using the <code>next_free_index_</code> tracker. Then, we update the <code>is_free_</code> marker for that block, initialize the object block of type <code>T</code> using <code>placement new</code>, and then update <code>next_free_index_</code> to point to the next available free block.</p>
<p>Note two things – the first is that we use <code>placement new</code> to return an object of type <code>T</code> instead of a memory block that is the same size as <code>T</code>. This is not strictly necessary and can be removed if the user of the memory pool wants to take responsibility for constructing the object from the memory block we return. <code>placement new</code> in most compiler implementations might add an extra <code>if</code> check to confirm that the memory block provided to it is not null.</p>
<p>The second thing, which is more of a design choice for us to make depending on the application, is that we call <code>updateNextFreeIndex()</code> to update <code>next_free_index_</code> to point to the next available free block, which can be implemented in different ways other than the provided here. To answer the question of which implementation is optimal is that it <em class="italic">depends</em> and needs to be measured in practice. Now, let us first look at the <code>allocate()</code> method where, again, we use variadic template <a id="_idIndexMarker592"/>arguments to allow arbitrary arguments to be forwarded to the constructor of <code>T</code>. Note that here we use the <code>placement new</code> operator to construct an object of type <code>T</code> with the given arguments from the memory block. Remember that <code>new</code> is an operator that can also be overridden if needed, and the <code>placement new</code> operator skips the step that allocates memory and uses the provided memory block instead:</p>
<pre class="source-code">
    template&lt;typename... Args&gt;
    T *allocate(Args... args) noexcept {
      auto obj_block = &amp;(store_[next_free_index_]);
      ASSERT(obj_block-&gt;is_free_, "Expected free
        ObjectBlock at index:" + std::to_string
          (next_free_index_));
      T *ret = &amp;(obj_block-&gt;object_);
      ret = new(ret) T(args...); // placement new.
      obj_block-&gt;is_free_ = false;
      updateNextFreeIndex();
      return ret;
    }</pre>
<p>Let us look at the <code>updateNextFreeIndex()</code> method next. There are two things to note here – first, we have a branch for a case where the index wraps around the end. While this adds an <code>if</code> condition here, with the <code>UNLIKELY()</code> specification and the expectation of our hardware branch predictor to always predict that the branch isn’t taken, this should not hurt our performance in a meaningful way. We can, of course, break up the loop into two loops and remove that <code>if</code> condition if we really want to – that is, the first loop loops till <code>next_free_index_ == store_.size()</code>, and the second loop loops from 0 onwards.</p>
<p>Secondly, we added a check to detect and fail if there is ever a case where the memory pool is completely <a id="_idIndexMarker593"/>full. There are obviously better ways to handle this in practice that do not involve failures, but for the sake of brevity and to stay within the scope of this book, we will just fail when this happens for now:</p>
<pre class="source-code">
  private:
    auto updateNextFreeIndex() noexcept {
      const auto initial_free_index = next_free_index_;
      while (!store_[next_free_index_].is_free_) {
        ++next_free_index_;
        if (UNLIKELY(next_free_index_ == store_.size())) {
          // hardware branch predictor should almost always
              predict this to be false any ways.
          next_free_index_ = 0;
        }
        if (UNLIKELY(initial_free_index ==
          next_free_index_)) {
          ASSERT(initial_free_index != next_free_index_,
            "Memory Pool out of space.");
        }
      }
    }</pre>
<p>The next section <a id="_idIndexMarker594"/>deals with handling deallocations or returning objects of type <code>T</code> back to the memory pool to reclaim them as free.</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor107"/>Handling deallocations</h2>
<p>Deallocations are <a id="_idIndexMarker595"/>a simple matter of finding the correct <code>ObjectBlock</code> in our internal <code>store_</code> that corresponds to the <code>T</code> object being deallocated and marking the <code>is_free_</code> marker for that block to be <code>true</code>. Here, we use <code>reinterpret_cast</code> to convert <code>T*</code> to <code>ObjectBlock*</code>, which is OK to do, since object <code>T</code> is the first member in <code>ObjectBlock</code>. This should now explain the assertion we added to the constructor in the <em class="italic">Initializing the memory pool</em> section. We also add an assertion here to make sure that the element that the user tries to deallocate belongs to this memory pool. Again, there can be more graceful handling of such error cases, but we will leave that up to you for the sake of brevity and to keep the discussion within the scope of this book:</p>
<pre class="source-code">
    auto deallocate(const T *elem) noexcept {
      const auto elem_index = (reinterpret_cast&lt;const
        ObjectBlock *&gt;(elem) - &amp;store_[0]);
      ASSERT(elem_index &gt;= 0 &amp;&amp; static_cast&lt;size_t&gt;
        (elem_index) &lt; store_.size(), "Element being
          deallocated does not belong to this Memory
            pool.");
      ASSERT(!store_[elem_index].is_free_, "Expected in-use
        ObjectBlock at index:" + std::to_string
          (elem_index));
      store_[elem_index].is_free_ = true;
    }</pre>
<p>That concludes our design and implementation of memory pools. Let us look at a simple example.</p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor108"/>Using the memory pool with an example</h2>
<p>Let us look at <a id="_idIndexMarker596"/>a simple and self-explanatory example of the memory pool we just created. This code is in the <code>Chapter4/mem_pool_example.cpp</code> file and can be built using the <code>CMake</code> file, as previously mentioned. It creates a memory pool of a primitive <code>double</code> type and another of a <a id="_idIndexMarker597"/>custom <code>MyStruct</code> type. Then, it allocates and deallocates some elements from this memory pool and prints out the values and memory locations:</p>
<pre class="source-code">
#include "mem_pool.h"
struct MyStruct {
  int d_[3];
};
int main(int, char **) {
  using namespace Common;
  MemPool&lt;double&gt; prim_pool(50);
  MemPool&lt;MyStruct&gt; struct_pool(50);
  for(auto i = 0; i &lt; 50; ++i) {
    auto p_ret = prim_pool.allocate(i);
    auto s_ret = struct_pool.allocate(MyStruct{i, i+1,
      i+2});
    std::cout &lt;&lt; "prim elem:" &lt;&lt; *p_ret &lt;&lt; " allocated at:"
      &lt;&lt; p_ret &lt;&lt; std::endl;
    std::cout &lt;&lt; "struct elem:" &lt;&lt; s_ret-&gt;d_[0] &lt;&lt; "," &lt;&lt;
      s_ret-&gt;d_[1] &lt;&lt; "," &lt;&lt; s_ret-&gt;d_[2] &lt;&lt; " allocated
        at:" &lt;&lt; s_ret &lt;&lt; std::endl;
    if(i % 5 == 0) {
      std::cout &lt;&lt; "deallocating prim elem:" &lt;&lt; *p_ret &lt;&lt; "
        from:" &lt;&lt; p_ret &lt;&lt; std::endl;
      std::cout &lt;&lt; "deallocating struct elem:" &lt;&lt; s_ret
        -&gt;d_[0] &lt;&lt; "," &lt;&lt; s_ret-&gt;d_[1] &lt;&lt; "," &lt;&lt; s_ret-&gt;
           d_[2] &lt;&lt; " from:" &lt;&lt; s_ret &lt;&lt; std::endl;
      prim_pool.deallocate(p_ret);
      struct_pool.deallocate(s_ret);
    }
  }
  return 0;
}</pre>
<p>Running this <a id="_idIndexMarker598"/>example using the following command should produce output similar to what is shown here:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter4$ ./cmake-build-release/mem_pool_example
prim elem:0 allocated at:0x5641b4d1beb0
struct elem:0,1,2 allocated at:0x5641b4d1c220
deallocating prim elem:0 from:0x5641b4d1beb0
deallocating struct elem:0,1,2 from:0x5641b4d1c220
prim elem:1 allocated at:0x5641b4d1bec0
struct elem:1,2,3 allocated at:0x5641b4d1c230
prim elem:2 allocated at:0x5641b4d1bed0
...</pre>
<p>In the next section, we <a id="_idIndexMarker599"/>will build a very similar component – lock-free queues.</p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor109"/>Transferring data using lock-free queues</h1>
<p>In the <em class="italic">C++ threading for multi-threaded low latency applications</em> section, we hinted that one possible <a id="_idIndexMarker600"/>application of having multiple threads is to set up a pipelined system. Here, one component thread performs part of the processing and forwards the results to the next stage of the pipeline for further processing. We will be using such a design in our electronic trading system, but there’ll be more on that later.</p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor110"/>Communicating between threads and processes</h2>
<p>There are a lot of options when it comes to transferring data between processes and/or threads. <strong class="bold">Inter-Process Communication</strong> (<strong class="bold">IPC</strong>), such as mutexes, semaphores, signals, memory-mapped files, and <a id="_idIndexMarker601"/>shared memory, can <a id="_idIndexMarker602"/>be used for these purposes. It also gets <a id="_idIndexMarker603"/>tricky when there is concurrent access to shared data and the important requirement is to avoid data corruption. Another important requirement is to make sure that the reader and writer have consistent views of the shared data. To transfer information from one thread to another (or from one process to another), the optimal way to do so is through a data queue that both threads have access to. Building a queue of data and using locks to synchronize in a concurrent access environment is an option here. Due to the concurrent access nature of this design, locks or mutexes or something similar has to be used to prevent errors. However, locks and mutexes are extremely inefficient and lead to context switches, which degrade performance tremendously for critical threads. So, what we need is a lock-free queue to facilitate communication <a id="_idIndexMarker604"/>between threads without the overhead of locks and context switches. Note that the lock-free queue we will build here is only to be used for <strong class="bold">Single Producer Single Consumer</strong> (<strong class="bold">SPSC</strong>) – that is, only one thread writes to the queue and only one thread consumes from the queue. More complex use cases for lock-free queues will require additional complexity, which is out of the scope of this book.</p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor111"/>Designing lock-free queue storage</h2>
<p>For lock-free queues, we again have the option of either having the storage allocated on the stack or the <a id="_idIndexMarker605"/>heap. Here, we will again choose <code>std::vector</code> and allocate memory on the heap. Additionally, we create two <code>std::atomic</code> variables – one called <code>next_write_index_</code> – to track what index the next write to the queue will go to.</p>
<p>The second variable, called <code>next_read_index_</code>, is used to track what index the next unread element in the queue is located in. The implementation is relatively straightforward because of our assumption that a single thread writes to the queue and a single thread reads from it. Now, let us first design and implement the internal storage of the lock-free queue data structure. The source code discussed in this section can be found in the <code>Chapter4/lf_queue.h</code> source file in the GitHub repository for this book.</p>
<p>A quick word on <code>std::atomic</code> – it is a modern C++ construct that allows thread-safe operations. It lets us <a id="_idIndexMarker606"/>read, update, and write variables on a shared variable without using locks or mutexes, and it does so while preserving the order of operations. A detailed discussion of <code>std::atomic</code> and memory ordering is outside the scope of this book, but you can find a reference in our other book <em class="italic">Developing High-Frequency </em><em class="italic">Trading Systems</em>.</p>
<p>First, let us define the data members for this class in the following code snippet:</p>
<pre class="source-code">
#pragma once
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;atomic&gt;
namespace Common {
  template&lt;typename T&gt;
  class LFQueue final {
  private:
    std::vector&lt;T&gt; store_;
    std::atomic&lt;size_t&gt; next_write_index_ = {0};
    std::atomic&lt;size_t&gt; next_read_index_ = {0};
    std::atomic&lt;size_t&gt; num_elements_ = {0};
  };
}</pre>
<p>This class holds a <code>std::vector</code> object <code>store_</code> of a <code>T</code> template object type, which is the actual queue of data. A <code>std::atomic&lt;size_t&gt; next_write_index_</code> variable <a id="_idIndexMarker607"/>tracks the index in this vector, where the next element will be written to. Similarly, a <code>std::atomic&lt;size_t&gt; next_read_index_</code> variable tracks the index in this vector, where the next element to be read or consumed is available. These need to be the <code>std::atomic&lt;&gt;</code> type, since the reading and writing operations are performed from different threads.</p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor112"/>Initializing the lock-free queue</h2>
<p>The constructor <a id="_idIndexMarker608"/>for our lock-free queue is very similar to the constructor of the memory pool we saw earlier. We dynamically allocate the memory for the entire vector in the constructor. We can extend this design to allow the lock-free queue to be resized at runtime, but for now, we will stick to a fixed-size queue:</p>
<pre class="source-code">
template&lt;typename T&gt;
class LFQueue final {
public:
  LFQueue(std::size_t num_elems) :
      store_(num_elems, T()) /* pre-allocation of vector
        storage. */ {
  }</pre>
<p>We have similar boilerplate code here with regards to the default constructor, copy and move constructors, and <a id="_idIndexMarker609"/>assignment operators. These are deleted for the reasons we discussed before:</p>
<pre class="source-code">
  LFQueue() = delete;
  LFQueue(const LFQueue&amp;) = delete;
  LFQueue(const LFQueue&amp;&amp;) = delete;
  LFQueue&amp; operator=(const LFQueue&amp;) = delete;
  LFQueue&amp; operator=(const LFQueue&amp;&amp;) = delete;</pre>
<p>Next, we will look at the code to add new elements to the queue.</p>
<h2 id="_idParaDest-108"><a id="_idTextAnchor113"/>Adding elements to the queue</h2>
<p>The code to add <a id="_idIndexMarker610"/>new elements to the queue is implemented in two parts; the first part, <code>getNextToWriteTo()</code>, returns a pointer to the next element to write new data to. The second part, <code>updateWriteIndex()</code>, increments the write index, <code>next_write_index_</code>, once the element has been written to the slot provided. We designed it in such a way that, instead of having a single <code>write()</code> function, we provide the user with a pointer to the element and if the objects are quite large then not all of it needs to be updated or overwritten. Additionally, this design makes it much easier to deal with race conditions:</p>
<pre class="source-code">
  auto getNextToWriteTo() noexcept {
    return &amp;store_[next_write_index_];
  }
  auto updateWriteIndex() noexcept {
      next_write_index_ = (next_write_index_ + 1) %
        store_.size();
      num_elements_++;
  }</pre>
<p>In the next section, we <a id="_idIndexMarker611"/>will use a very similar design to consume elements from the queue.</p>
<h2 id="_idParaDest-109"><a id="_idTextAnchor114"/>Consuming elements from the queue</h2>
<p>To consume elements <a id="_idIndexMarker612"/>from the queue, we do the opposite of what we did to add elements to the queue. Like the design we have where we split <code>write()</code> into two parts, we will have two parts to consume an element from the queue. We have a <code>getNextToRead()</code> method that returns a pointer to the next element to be consumed but does not update the read index. This method will return <code>nullptr</code> if there is no element to be consumed. The second part, <code>updateReadIndex()</code>, just updates the read index after the element is consumed:</p>
<pre class="source-code">
  auto getNextToRead() const noexcept -&gt; const T * {
    return (next_read_index_ == next_write_index_) ?
      nullptr : &amp;store_[next_read_index_];
  }
  auto updateReadIndex() noexcept {
      next_read_index_ = (next_read_index_ + 1) %
        store_.size();
      ASSERT(num_elements_ != 0, "Read an invalid element
        in:" + std::to_string(pthread_self()));
      num_elements_--;
  }</pre>
<p>We also define another simple method to return the number of elements in the queue:</p>
<pre class="source-code">
    auto size() const noexcept {
      return num_elements_.load();
    }</pre>
<p>wThis finishes our <a id="_idIndexMarker613"/>design and implementation of lock-free queues for the SPSC use case. Let us look at an example that uses this component in the next sub-section.</p>
<h2 id="_idParaDest-110"><a id="_idTextAnchor115"/>Using the lock-free queue</h2>
<p>This example of <a id="_idIndexMarker614"/>how to use the lock-free data queue can be found in the <code>Chapter4/lf_queue_example.cpp</code> file and built as previously mentioned. This example creates a consumer thread and provides it with a lock-free queue instance. The producer then generates and adds some elements to that queue, and the consumer thread checks the queue and consumes the queue elements till the queue is empty. Both threads of execution – producer and consumer – wait for short periods of time between generating an element and consuming it:</p>
<pre class="source-code">
#include "thread_utils.h"
#include "lf_queue.h"
struct MyStruct {
  int d_[3];
};
using namespace Common;
auto consumeFunction(LFQueue&lt;MyStruct&gt;* lfq) {
  using namespace std::literals::chrono_literals;
  std::this_thread::sleep_for(5s);
  while(lfq-&gt;size()) {
    const auto d = lfq-&gt;getNextToRead();
    lfq-&gt;updateReadIndex();
    std::cout &lt;&lt; "consumeFunction read elem:" &lt;&lt; d-&gt;d_[0]
      &lt;&lt; "," &lt;&lt; d-&gt;d_[1] &lt;&lt; "," &lt;&lt; d-&gt;d_[2] &lt;&lt; " lfq-size:"
        &lt;&lt;lfq-&gt;size() &lt;&lt; std::endl;
    std::this_thread::sleep_for(1s);
  }
  std::cout &lt;&lt; "consumeFunction exiting." &lt;&lt; std::endl;
}
int main(int, char **) {
  LFQueue&lt;MyStruct&gt; lfq(20);
  auto ct = createAndStartThread(-1, "", consumeFunction,
    &amp;lfq);
  for(auto i = 0; i &lt; 50; ++i) {
    const MyStruct d{i, i * 10, i * 100};
    *(lfq.getNextToWriteTo()) = d;
    lfq.updateWriteIndex();
    std::cout &lt;&lt; "main constructed elem:" &lt;&lt; d.d_[0] &lt;&lt; ","
      &lt;&lt; d.d_[1] &lt;&lt; "," &lt;&lt; d.d_[2] &lt;&lt; " lfq-size:" &lt;&lt;
        lfq.size() &lt;&lt; std::endl;
    using namespace std::literals::chrono_literals;
    std::this_thread::sleep_for(1s);
  }
  ct-&gt;join();
  std::cout &lt;&lt; "main exiting." &lt;&lt; std::endl;
  return 0;
}</pre>
<p>The output of <a id="_idIndexMarker615"/>running this example program is provided as follows, which is just the producer and the consumer writing to and reading from the lock-free queue:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter4$ ./cmake-build-release/lf_queue_example
Set core affinity for  139710770276096 to -1
main constructed elem:0,0,0 lfq-size:1
main constructed elem:1,10,100 lfq-size:2
main constructed elem:2,20,200 lfq-size:3
main constructed elem:3,30,300 lfq-size:4
consumeFunction read elem:0,0,0 lfq-size:3
main constructed elem:4,40,400 lfq-size:4
consumeFunction read elem:1,10,100 lfq-size:3
main constructed elem:5,50,500 lfq-size:4
consumeFunction read elem:2,20,200 lfq-size:3
main constructed elem:6,60,600 lfq-size:4
consumeFunction read elem:3,30,300 lfq-size:3
main constructed elem:7,70,700 lfq-size:4
consumeFunction read elem:4,40,400 lfq-size:3
...</pre>
<p>Next, we will build a <a id="_idIndexMarker616"/>low latency logging framework using some of the components we just built – threads and lock-free queues.</p>
<h1 id="_idParaDest-111"><a id="_idTextAnchor116"/>Building a low latency logging framework</h1>
<p>Now, we will build a low latency logging framework using some of the components we just built in the <a id="_idIndexMarker617"/>previous sections. Logging is an important part of any application, whether it is logging general application behavior, warnings, errors, or even performance statistics. However, a lot of important logging output is actually from performance-critical components that are on a critical path.</p>
<p>A naïve logging approach would be to output to the screen, while<a id="_idTextAnchor117"/> a slightly better approach would be for logs to be saved to one or more log files. However, here we have a few problems – disk I/O is extremely slow and unpredictable, and string operations and formatting themselves are slow. For these reasons, performing these operations on a performance-critical thread is a terrible idea, so we will build a solution in this section to alleviate the downsides while preserving the ability to output logs as needed.</p>
<p>Before we jump into the logger class, we will define a few utility methods to fetch the current system time as well as convert them to strings for logging purposes.</p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor118"/>Designing utility methods for time</h2>
<p>We will define <a id="_idIndexMarker618"/>a simple utility function to fetch the current system time and some constants to make conversions from different units easier. The code for the time utilities can be found in <code>Chapter4/time_utils.h</code> in the GitHub repository for this book:</p>
<pre class="source-code">
#pragma once
#include &lt;chrono&gt;
#include &lt;ctime&gt;
namespace Common {
  typedef int64_t Nanos;
  constexpr Nanos NANOS_TO_MICROS = 1000;
  constexpr Nanos MICROS_TO_MILLIS = 1000;
  constexpr Nanos MILLIS_TO_SECS = 1000;
  constexpr Nanos NANOS_TO_MILLIS = NANO_TO_MICROS *
    MICROS_TO_MILLIS;
  constexpr Nanos NANOS_TO_SECS = NANOS_TO_MILLIS *
    MILLIS_TO_SECS;
  inline auto getCurrentNanos() noexcept {
    return std::chrono::duration_cast
      &lt;std::chrono::nanoseconds&gt;(std::chrono::
        system_clock::now().time_since_epoch()).count();
  }
  inline auto&amp; getCurrentTimeStr(std::string* time_str) {
    const auto time = std::chrono::system_clock::
      to_time_t(std::chrono::system_clock::now());
    time_str-&gt;assign(ctime(&amp;time));
    if(!time_str-&gt;empty())
      time_str-&gt;at(time_str-&gt;length()-1) = '\0';
    return *time_str;
  }
}</pre>
<p>Now, let us <a id="_idIndexMarker619"/>design the logger class itself, starting with the next section.</p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor119"/>Designing the low latency logger</h2>
<p>To build this low latency logging framework, we will create a background logging thread whose only task is to <a id="_idIndexMarker620"/>write log lines to a log file on disk. The idea here is to offload the slow disk I/O operations as well as the string formatting operations away from the main performance-critical thread onto this background thread. One thing to understand is that logging to disk does not have to be instantaneous – that is, most systems can tolerate some delay between an event happening and information pertinent to that event being logged to disk. We will use the multi-threading function we created in the first section of this chapter to create this logger thread and assign it the task of writing to the log file.</p>
<p>To publish data that needs to be logged from the main performance-critical thread to this logging thread, we will use the lock-free data queue we created in the previous section. The way the logger will work is that instead of writing information directly to the disk, the performance-sensitive threads will simply push the information to this lock-free queue. As we discussed before, a logger thread will consume from the other end of this queue and write to the disk. The source code for this component is available in the <code>logging.h</code> and <code>logging.cpp</code> files in the <code>Chapter4</code> directory in the GitHub repository for this book.</p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor120"/>Defining some logger structures</h2>
<p>Before we start designing the logger itself, we will first define the basic block of information that <a id="_idIndexMarker621"/>will be transferred across the lock-free queue from the performance-sensitive thread to the logger thread. In this design, we simply create a structure capable of holding the different types that we will log. First, let us define an enumeration that specifies the type of value the structure it is pointing to; we will call this enumeration <code>LogType</code>:</p>
<pre class="source-code">
#pragma once
#include &lt;string&gt;
#include &lt;fstream&gt;
#include &lt;cstdio&gt;
#include "types.h"
#include "macros.h"
#include "lf_queue.h"
#include "thread_utils.h"
#include "time_utils.h"
namespace Common {
constexpr size_t LOG_QUEUE_SIZE = 8 * 1024 * 1024;
enum class LogType : int8_t {
  CHAR = 0,
  INTEGER = 1, LONG_INTEGER = 2, LONG_LONG_INTEGER = 3,
  UNSIGNED_INTEGER = 4, UNSIGNED_LONG_INTEGER = 5,
  UNSIGNED_LONG_LONG_INTEGER = 6,
  FLOAT = 7, DOUBLE = 8
};
}</pre>
<p>Now, we can define the <code>LogElement</code> structure that will hold the next value to push to the queue and, eventually, <a id="_idIndexMarker622"/>write logs to the file from the logger thread. This structure contains a member of type <code>LogType</code> to specify the type of value it holds. The other member in this structure is a union of the different possible primitive types. This would have been a good place to use <code>std::variant</code>, since it is a type-safe union in modern C++ with the <code>LogType type_</code>, which specifies what the union contains) built into it. However, <code>std::variant</code> has worse runtime performance; hence, we choose to move forward with the old-style union here:</p>
<pre class="source-code">
struct LogElement {
  LogType type_ = LogType::CHAR;
  union {
    char c;
    int i; long l; long long ll;
    unsigned u; unsigned long ul; unsigned long long ull;
    float f; double d;
  } u_;
};</pre>
<p>With the definition <a id="_idIndexMarker623"/>of the <code>LogElement</code> structure out of the way, let us move on to defining data in the logger class.</p>
<h2 id="_idParaDest-115"><a id="_idTextAnchor121"/>Initializing the logger data structures</h2>
<p>Our logger will <a id="_idIndexMarker624"/>contain a few important objects. Firstly, a <code>std::ofstream</code> file object is the log file that data is written to. Secondly, an <code>LFQueue&lt;LogElement&gt;</code> object is the lock-free queue to transfer data from the main thread to the logger thread. Next, <code>std::atomic&lt;bool&gt;</code> stops the logger thread’s processing when needed, and a <code>std::thread</code> object which is the logger thread. Finally, <code>std::string</code> is the filename, which we provide purely for informational purposes:</p>
<pre class="source-code">
class Logger final {
private:
  const std::string file_name_;
  std::ofstream file_;
  LFQueue&lt;LogElement&gt; queue_;
  std::atomic&lt;bool&gt; running_ = {true};
  std::thread *logger_thread_ = nullptr;
};</pre>
<p>Now, let us move <a id="_idIndexMarker625"/>on to constructing our logger, the logger queue, and the logger thread.</p>
<h2 id="_idParaDest-116"><a id="_idTextAnchor122"/>Creating the logger and launching the logger thread</h2>
<p>In the logger constructor, we will initialize the logger queue with an appropriate size, save <code>file_name_</code> for <a id="_idIndexMarker626"/>informational purposes, open the output log file object, and create and <a id="_idIndexMarker627"/>launch the logger thread. Note that here <a id="_idIndexMarker628"/>we will exit if we are unable to open the output log file or unable to <a id="_idIndexMarker629"/>create and launch the logger thread. As we’ve mentioned before, there are obviously more forgiving and more graceful ways to handle these failures, but we will not explore those in this book. Note here that we set the <code>core_id</code> parameter in <code>createAndStartThread()</code> to –1, to not set affinity on the thread right now. We will revisit the design of how to assign each thread to a CPU core later in the book once we understand the design of the full ecosystem, and we will tune it for performance:</p>
<pre class="source-code">
  explicit Logger(const std::string &amp;file_name)
      : file_name_(file_name), queue_(LOG_QUEUE_SIZE) {
    file_.open(file_name);
    ASSERT(file_.is_open(), "Could not open log file:" +
      file_name);
    logger_thread_ = createAndStartThread(-1,
      "Common/Logger", [this]() { flushQueue(); });
    ASSERT(logger_thread_ != nullptr, "Failed to start
      Logger thread.");
  }</pre>
<p>We pass a method called <code>flushQueue()</code> that this logger thread will run. As the name suggests, and in line with what we discussed, this thread will empty the queue of log data and write the data to the file; we will look at that next. The implementation of <code>flushQueue()</code> is simple. If the atomic <code>running_</code> Boolean is <code>true</code>, it runs in a loop, performing the following steps: it consumes any new elements pushed to the lock-free queue, <code>queue_</code>, and writes them to the <code>file_</code> object we created. It unpacks the <code>LogElement</code> objects in <a id="_idIndexMarker630"/>the queue and writes the correct member of the union to <a id="_idIndexMarker631"/>the file, depending on the type. The thread sleeps for <a id="_idIndexMarker632"/>a millisecond when the lock-free queue is empty and then <a id="_idIndexMarker633"/>checks again to see whether there are new elements to be written to disk:</p>
<pre class="source-code">
  auto flushQueue() noexcept {
    while (running_) {
      for (auto next = queue_.getNextToRead();
        queue_.size() &amp;&amp; next; next = queue_
          .getNextToRead()) {
        switch (next-&gt;type_) {
          case LogType::CHAR: file_ &lt;&lt; next-&gt;u_.c; break;
          case LogType::INTEGER: file_ &lt;&lt; next-&gt;u_.i; break;
          case LogType::LONG_INTEGER: file_ &lt;&lt; next-&gt;u_.l; break;
          case LogType::LONG_LONG_INTEGER: file_ &lt;&lt; next-&gt;
             u_.ll; break;
          case LogType::UNSIGNED_INTEGER: file_ &lt;&lt; next-&gt;
             u_.u; break;
          case LogType::UNSIGNED_LONG_INTEGER: file_ &lt;&lt;
             next-&gt;u_.ul; break;
          case LogType::UNSIGNED_LONG_LONG_INTEGER: file_
              &lt;&lt; next-&gt;u_.ull; break;
          case LogType::FLOAT: file_ &lt;&lt; next-&gt;u_.f; break;
          case LogType::DOUBLE: file_ &lt;&lt; next-&gt;u_.d; break;
        }
        queue_.updateReadIndex();
        next = queue_.getNextToRead();
      }
      using namespace std::literals::chrono_literals;
      std::this_thread::sleep_for(1ms);
    }
  }</pre>
<p>The destructor for our logger class is important, so let us look at what cleanup tasks it needs to perform. First, the <a id="_idIndexMarker634"/>destructor waits for the lock-free queue to be consumed by <a id="_idIndexMarker635"/>the logger thread, so it waits till it is empty. Once it is <a id="_idIndexMarker636"/>empty, it sets the <code>running_</code> flag to be <code>false</code> so that <a id="_idIndexMarker637"/>the logger thread can finish its execution. To wait for the logger thread to finish execution – that is, return from the <code>flushQueue()</code> method, it calls the <code>std::thread::join()</code> method on the logger thread. Finally, it closes the <code>file_</code> object, which writes any buffered data onto the disk, and then we are done:</p>
<pre class="source-code">
  ~Logger() {
    std::cerr &lt;&lt; "Flushing and closing Logger for " &lt;&lt;
      file_name_ &lt;&lt; std::endl;
    while (queue_.size()) {
      using namespace std::literals::chrono_literals;
      std::this_thread::sleep_for(1s);
    }
    running_ = false;
    logger_thread_-&gt;join();
    file_.close();
  }</pre>
<p>Finally, we will add the usual boilerplate code we discussed multiple times before regarding the constructors and assignment operators:</p>
<pre class="source-code">
  Logger() = delete;
  Logger(const Logger &amp;) = delete;
  Logger(const Logger &amp;&amp;) = delete;
  Logger &amp;operator=(const Logger &amp;) = delete;
  Logger &amp;operator=(const Logger &amp;&amp;) = delete;</pre>
<p>In this section, we <a id="_idIndexMarker638"/>saw the portion of the component that consumes from the <a id="_idIndexMarker639"/>queue and writes it to disk. In the next section, we will see <a id="_idIndexMarker640"/>how data gets added to the lock-free queue as part of the <a id="_idIndexMarker641"/>logging process from the performance-critical thread.</p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor123"/>Pushing data to the logger queue</h2>
<p>To push data to the lo<a id="_idTextAnchor124"/>gger queue, we will define a couple of overloaded <code>pushValue()</code> methods that <a id="_idIndexMarker642"/>handle different types of arguments. Each method does the same thing, which is to push values one by one onto the queue. One thing worthy of note here is that there are more efficient implementations for what we are about to discuss; however, they involve additional complexity, and we left them out for the sake of brevity and to limit the scope of what we can cover in this book. We will point out the areas of potential improvement when we discuss them.</p>
<p>First, we create a variant of <code>pushValue()</code> to push objects of type <code>LogElement</code>, which will get called from the other <code>pushValue()</code> functions we will define shortly. It basically writes to the next location in the lock-free queue and increments the write index:</p>
<pre class="source-code">
  auto pushValue(const LogElement &amp;log_element) noexcept {
    *(queue_.getNextToWriteTo()) = log_element;
    queue_.updateWriteIndex();
  }</pre>
<p>The next simple variant of <code>pushValue()</code> is for a single char value, which basically just creates an object of type <code>LogElement</code>, calls the <code>pushValue()</code> method we just discussed, and passes the <code>LogElement</code> object:</p>
<pre class="source-code">
  auto pushValue(const char value) noexcept {
    pushValue(LogElement{LogType::CHAR, {.c = value}});
  }</pre>
<p>Now, we create a variant of <code>pushValue()</code> for <code>const char*</code> – that is, a collection of chars. This implementation <a id="_idIndexMarker643"/>loops through the characters one at a time and calls the <code>pushValue()</code> we implemented previously. This is an area of potential improvement, where we could use a single <code>memcpy()</code> to copy over all the characters in the array instead of looping through them. There are some edge cases we would need to handle around the wrapping of the indices at the end of the queue, but we will leave it up to you to explore further:</p>
<pre class="source-code">
  auto pushValue(const char *value) noexcept {
    while (*value) {
      pushValue(*value);
      ++value;
    }
  }</pre>
<p>Next, we create another variant of <code>pushValue()</code> for <code>const std::string&amp;</code>, which is quite straightforward and uses <code>pushValue()</code>, which we created previously:</p>
<pre class="source-code">
  auto pushValue(const std::string &amp;value) noexcept {
    pushValue(value.c_str());
  }</pre>
<p>Finally, we need to add variants of <code>pushValue()</code> for the different primitive types. They are very similar to the one we built for a single char value and are shown here:</p>
<pre class="source-code">
  auto pushValue(const int value) noexcept {
    pushValue(LogElement{LogType::INTEGER, {.i = value}});
  }
  auto pushValue(const long value) noexcept {
    pushValue(LogElement{LogType::LONG_INTEGER, {.l =
      value}});
  }
  auto pushValue(const long long value) noexcept {
    pushValue(LogElement{LogType::LONG_LONG_INTEGER, {.ll =
      value}});
  }
  auto pushValue(const unsigned value) noexcept {
    pushValue(LogElement{LogType::UNSIGNED_INTEGER, {.u =
      value}});
  }
  auto pushValue(const unsigned long value) noexcept {
    pushValue(LogElement{LogType::UNSIGNED_LONG_INTEGER,
      {.ul = value}});
  }
  auto pushValue(const unsigned long long value) noexcept {
    pushValue(LogElement{LogType::UNSIGNED_LONG_LONG_INTEGER,
  {.ull = value}});
  }
  auto pushValue(const float value) noexcept {
    pushValue(LogElement{LogType::FLOAT, {.f = value}});
  }
  auto pushValue(const double value) noexcept {
    pushValue(LogElement{LogType::DOUBLE, {.d = value}});
  }</pre>
<p>At this point, we have <a id="_idIndexMarker644"/>achieved two goals – moved the disk output operation to the background logger thread and moved the task of formatting the primitive values into string format to the background thread. Next, we will add functionality for the performance-sensitive thread to use to push data to the lock-free queue, using the <code>pushValue()</code> methods we just built.</p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor125"/>Adding a useful and generic log function</h2>
<p>We will define a <code>log()</code> method, which is very similar to the <code>printf()</code> function but slightly simpler. It is simpler <a id="_idIndexMarker645"/>in the sense that the format specifier is just a <code>%</code> character that is used to substitute all the different primitive types. This method uses variadic template arguments to support an arbitrary number and types of arguments. It looks for the <code>%</code> character and then substitutes the next value in its place, calling one of the overloaded <code>pushValue()</code> methods we defined in the last section. After that, it calls itself recursively, except this time, the value points to the first argument in the template parameter pack:</p>
<pre class="source-code">
  template&lt;typename T, typename... A&gt;
  auto log(const char *s, const T &amp;value, A... args)
  noexcept {
    while (*s) {
      if (*s == '%') {
        if (UNLIKELY(*(s + 1) == '%')) {
          ++s;
        } else {
          pushValue(value);
          log(s + 1, args...);
          return;
        }
      }
      pushValue(*s++);
    }
    FATAL("extra arguments provided to log()");
  }</pre>
<p>This method is meant to be called using something like this example:</p>
<pre class="source-code">
int int_val = 10;
std::string str_val = "hello";
double dbl_val = 10.10;
log("Integer:% String:% Double:%",
  int_val, str_val, dbl_val);</pre>
<p>The <code>log()</code> method we <a id="_idIndexMarker646"/>built here cannot handle a case where there are no arguments passed to it. Therefore, we need an extra overloaded <code>log()</code> method to handle the case, where a simple <code>const char *</code> is passed to it. We add an extra check here to make sure that extra arguments were not passed to this method or the aforementioned <code>log()</code> method:</p>
<pre class="source-code">
  auto log(const char *s) noexcept {
    while (*s) {
      if (*s == '%') {
        if (UNLIKELY(*(s + 1) == '%')) {
          ++s;
        } else {
          FATAL("missing arguments to log()");
        }
      }
      pushValue(*s++);
    }
  }</pre>
<p>This finishes the design and implementation of our low latency logging framework. Using our multi-threading <a id="_idIndexMarker647"/>routine and our lock-free queue, we created a framework where the performance-critical thread offloads the string formatting and disk file write tasks to the background logger thread. Now, let us look at a good example of how to create, configure, and use the logger we just created.</p>
<h2 id="_idParaDest-119"><a id="_idTextAnchor126"/>Learning how to use the logger with an example</h2>
<p>We will present a basic example <a id="_idIndexMarker648"/>that creates a <code>Logger</code> object and configures it to write the logs to <code>logging_example.log</code>. Then, it logs a few different data types to the file through the logger. This source for this can be found in the <code>Chapter4/logging_example.cpp</code> file:</p>
<pre class="source-code">
#include "logging.h"
int main(int, char **) {
  using namespace Common;
  char c = 'd';
  int i = 3;
  unsigned long ul = 65;
  float f = 3.4;
  double d = 34.56;
  const char* s = "test C-string";
  std::string ss = "test string";
  Logger logger("logging_example.log");
  logger.log("Logging a char:% an int:% and an
    unsigned:%\n", c, i, ul);
  logger.log("Logging a float:% and a double:%\n", f, d);
  logger.log("Logging a C-string:'%'\n", s);
  logger.log("Logging a string:'%'\n", ss);
  return 0;
}</pre>
<p>The output of running this can be viewed by outputting the contents of the <code>logging_example.log</code> file in the current directory, as shown here:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter4$ cat logging_example.log
Logging a char:d an int:3 and an unsigned:65
Logging a float:3.4 and a double:34.56
Logging a C-string:'test C-string'
Logging a string:'test string'</pre>
<p>In this framework, the only overhead that a call to <code>log()</code> invokes is the overhead of iterating through the <a id="_idIndexMarker649"/>characters in the string and pushing the characters and values onto the lock-free queue. Now, we will move our discussion to network programming and the use of sockets, which we will be using later on to facilitate communication between different processes.</p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor127"/>C++ network programming using sockets</h1>
<p>In this final section, we will build the last of our basic building blocks – a framework to handle network <a id="_idIndexMarker650"/>programming using Unix sockets. We <a id="_idIndexMarker651"/>will use this framework to build a server that listens for incoming TCP connections and a client that is capable of establishing a TCP connection to such a server. We will also use this framework to publish UDP traffic and consume from a stream of multicast traffic. Note that to limit the <a id="_idIndexMarker652"/>scope of this discussion, we will only <a id="_idIndexMarker653"/>discuss Unix sockets without any kernel bypass capabilities. Using kernel <a id="_idIndexMarker654"/>bypass and leveraging the kernel bypass API provided by the <strong class="bold">Network Interface Cards</strong> (<strong class="bold">NICs</strong>) that support it is outside the scope of this book. Note also that we expect you to have some basic knowledge or experience with network sockets and, ideally, programming network sockets in C++.</p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor128"/>Building a basic socket API</h2>
<p>Our goal here is to create a mechanism to create a network socket and initialize it with the correct <a id="_idIndexMarker655"/>parameters. This method will be used to create listener, receiver, and sender sockets to communicate over UDP and TCP protocols. Before we jump into the routine that creates the socket itself, let us first define a bunch of utility methods that we will use in our final method. All the code for the basic socket API is in <code>Chapter4/socket_utils.cpp</code> in the GitHub repository for this book. Note that before we investigate the implementation of the functionality, we will present the <code>Chapter4/socket_utils.h</code> header file, which contains all the <code>include</code> files and function signatures we will implement:</p>
<pre class="source-code">
#pragma once
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;unordered_set&gt;
#include &lt;sys/epoll.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netdb.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;netinet/tcp.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;ifaddrs.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;fcntl.h&gt;
#include "macros.h"
#include "logging.h"
namespace Common {
  constexpr int MaxTCPServerBacklog = 1024;
  auto getIfaceIP(const std::string &amp;iface) -&gt; std::string;
  auto setNonBlocking(int fd) -&gt; bool;
  auto setNoDelay(int fd) -&gt; bool;
  auto setSOTimestamp(int fd) -&gt; bool;
  auto wouldBlock() -&gt; bool;
  auto setMcastTTL(int fd, int ttl) -&gt; bool;
  auto setTTL(int fd, int ttl) -&gt; bool;
  auto join(int fd, const std::string &amp;ip, const
    std::string &amp;iface, int port) -&gt; bool;
  auto createSocket(Logger &amp;logger, const std::string
    &amp;t_ip, const std::string &amp;iface, int port, bool is_udp,
       bool is_blocking, bool is_listening, int ttl, bool
         needs_so_timestamp) -&gt; int;
}</pre>
<p>Now, let us start <a id="_idIndexMarker656"/>with the implementation of these methods, starting with the next section.</p>
<h3>Getting interface information</h3>
<p>The first utility <a id="_idIndexMarker657"/>method we need to build is to convert network interfaces represented in string form to a form that can be used by the lower-level socket routines we will use. We call this <code>getIfaceIP()</code>, and we will need this when we specify what network interfaces to listen to, connect from, or send through. We use the <code>getifaddrs()</code> method to fetch information about all the interfaces, which returns a linked list structure, <code>ifaddrs</code>, containing this information. Finally, it uses the <code>getnameinfo()</code> information to get the final name to be used with the rest of the methods:</p>
<pre class="source-code">
#include "socket_utils.h"
namespace Common {
  auto getIfaceIP(const std::string &amp;iface) -&gt; std::string {
    char buf[NI_MAXHOST] = {'\0'};
    ifaddrs *ifaddr = nullptr;
    if (getifaddrs(&amp;ifaddr) != -1) {
      for (ifaddrs *ifa = ifaddr; ifa; ifa = ifa-&gt;ifa_next) {
        if (ifa-&gt;ifa_addr &amp;&amp; ifa-&gt;ifa_addr-&gt;sa_family ==
          AF_INET &amp;&amp; iface == ifa-&gt;ifa_name) {
          getnameinfo(ifa-&gt;ifa_addr, sizeof(sockaddr_in),
            buf, sizeof(buf), NULL, 0, NI_NUMERICHOST);
          break;
        }
      }
      freeifaddrs(ifaddr);
    }
    return buf;
  }
}</pre>
<p>For instance, on my system with the following network interfaces, we have the following:</p>
<pre class="source-code">
lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
wlp4s0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.10.104  netmask 255.255.255.0  broadcast 192.168.10.255</pre>
<p><code>getIfaceIP</code> (<code>"lo"</code>) returns <code>127.0.0.1</code>, and <code>getIfaceIP</code> (<code>"wlp4s0"</code>) returns <code>192.168.10.104</code>.</p>
<p>Next, we will move on to <a id="_idIndexMarker658"/>the next important utility function we need, and this one affects the performance of applications that need network sockets.</p>
<h3>Setting sockets to be non-blocking</h3>
<p>The next utility function we will build is one that sets sockets as non-blocking. A blocking socket is one <a id="_idIndexMarker659"/>where a call that is read on it will block indefinitely till data is available. This is generally not a good design for extremely low latency applications for many reasons. One of the main reasons is that blocking sockets are implemented using switches between the user space and the kernel space, and that is highly inefficient. When the socket needs to be <em class="italic">woken up</em> or unblocked, there needs to be an interrupt, an interrupt handler, and so on from the kernel space to the user space to handle the event. Additionally, the performance-critical thread that gets blocked would incur context-switching costs, which, as already discussed, are detrimental to performance.</p>
<p>The following <code>setNonBlocking()</code> method uses the <code>fcntl()</code> routine with <code>F_GETFL</code> to first check a socket file descriptor, seeing whether it is already non-blocking. If it is not already non-blocking, then it uses the <code>fcntl()</code> routine again but this time with <code>F_SETFL</code> to add the non-blocking bit, which is set on the file descriptor. It returns <code>true</code> if the socket file descriptor was already non-blocking or the method was able to successfully make it non-blocking:</p>
<pre class="source-code">
auto setNonBlocking(int fd) -&gt; bool {
  const auto flags = fcntl(fd, F_GETFL, 0);
  if (flags == -1)
    return false;
  if (flags &amp; O_NONBLOCK)
    return true;
  return (fcntl(fd, F_SETFL, flags | O_NONBLOCK) != -1);
}</pre>
<p>Next, we will enable another <a id="_idIndexMarker660"/>important optimization for TCP sockets by disabling <strong class="bold">Nagle’s algorithm</strong>.</p>
<h3>Disabling Nagle’s algorithm</h3>
<p>Without diving into <a id="_idIndexMarker661"/>too many details, Nagle’s algorithm is used to improve <a id="_idIndexMarker662"/>buffering in TCP sockets and prevent overhead associated with guaranteeing reliability on the TCP socket. This is achieved by delaying some packets instead of sending them out immediately. For many applications, it is a good feature to have, but for low latency applications, disabling the latency associated with sending packets out is imperative.</p>
<p>Fortunately, disabling Nagle’s algorithm is a simple matter of setting a socket option, <code>TCP_NODELAY</code>, using the <code>setsockopt()</code> routine, as shown here:</p>
<pre class="source-code">
auto setNoDelay(int fd) -&gt; bool {
  int one = 1;
  return (setsockopt(fd, IPPROTO_TCP, TCP_NODELAY,
    reinterpret_cast&lt;void *&gt;(&amp;one), sizeof(one)) != -1);
}</pre>
<p>We will define <a id="_idIndexMarker663"/>a few more routines to set optional and/or additional functionality in the next section, before we finally implement the functionality to create a socket.</p>
<h3>Setting up additional parameters</h3>
<p>First, we will <a id="_idIndexMarker664"/>define a simple method to check whether a socket operation would block or not. This is a simple check of the global <code>errno</code> error variable against two possible values, <code>EWOULDBLOCK</code> and <code>EINPROGRESS</code>:</p>
<pre class="source-code">
auto wouldBlock() -&gt; bool {
  return (errno == EWOULDBLOCK || errno == EINPROGRESS);
}</pre>
<p>Next, we define a method <a id="_idIndexMarker665"/>to set the <code>IP_TTL</code> socket options for non-multicast sockets and <code>IP_MULTICAST_TTL</code> for multicast sockets, using the <code>setsockopt()</code> routine, as shown here:</p>
<pre class="source-code">
auto setTTL(int fd, int ttl) -&gt; bool {
  return (setsockopt(fd, IPPROTO_IP, IP_TTL,
    reinterpret_cast&lt;void *&gt;(&amp;ttl), sizeof(ttl)) != -1);
}
auto setMcastTTL(int fd, int mcast_ttl) noexcept -&gt; bool {
  return (setsockopt(fd, IPPROTO_IP, IP_MULTICAST_TTL,
    reinterpret_cast&lt;void *&gt;(&amp;mcast_ttl), sizeof
      (mcast_ttl)) != -1);
}</pre>
<p>Finally, we define one last method that will allow us to generate software timestamps when network packets hit the network socket. Note that if we had specialized hardware (NICs) that support hardware timestamping, we would enable and use those here. However, to limit the scope of this book, we will assume that you do not have any special hardware and can only set the <code>SO_TIMESTAMP</code> option, using the <code>setsockopt()</code> method, to enable software timestamping:</p>
<pre class="source-code">
  auto setSOTimestamp(int fd) -&gt; bool {
    int one = 1;
    return (setsockopt(fd, SOL_SOCKET, SO_TIMESTAMP,
      reinterpret_cast&lt;void *&gt;(&amp;one), sizeof(one)) != -1);
  }</pre>
<p>This completes our discussion of socket-related utility <a id="_idIndexMarker666"/>functions, and now, we can move on to finally implementing the functionality to create generic Unix sockets.</p>
<h3>Creating the socket</h3>
<p>In the first section of the <code>createSocket()</code> method, we first check whether a non-empty <code>t_ip</code> has been <a id="_idIndexMarker667"/>provided, which represents the interface IP, such as <code>192.168.10.104</code>, and if not, we fetch one from the interface name provided using the <code>getIfaceIP()</code> method we built previously. We also need to populate the <code>addrinfo</code> struct, based on the arguments passed in, because we will need to pass it to the <code>getaddrinfo()</code> routine, which will return a linked list that will finally be used to build the actual socket. Note that in the <code>createSocket()</code> method, anytime we fail to create the socket or initialize it with the correct parameters, we return –1 to signify the failure:</p>
<pre class="source-code">
  auto createSocket(Logger &amp;logger, const std::string
    &amp;t_ip, const std::string &amp;iface, int port,
                    bool is_udp, bool is_blocking, bool
                      is_listening, int ttl, bool
                        needs_so_timestamp) -&gt; int {
    std::string time_str;
    const auto ip = t_ip.empty() ? getIfaceIP(iface) :
      t_ip;
    logger.log("%:% %() % ip:% iface:% port:% is_udp:%
      is_blocking:% is_listening:% ttl:% SO_time:%\n",
        __FILE__, __LINE__, __FUNCTION__,
               Common::getCurrentTimeStr(&amp;time_str), ip,
                 iface, port, is_udp, is_blocking,
                   is_listening, ttl, needs_so_timestamp);
    addrinfo hints{};
    hints.ai_family = AF_INET;
    hints.ai_socktype = is_udp ? SOCK_DGRAM : SOCK_STREAM;
    hints.ai_protocol = is_udp ? IPPROTO_UDP : IPPROTO_TCP;
    hints.ai_flags = is_listening ? AI_PASSIVE : 0;
    if (std::isdigit(ip.c_str()[0]))
      hints.ai_flags |= AI_NUMERICHOST;
    hints.ai_flags |= AI_NUMERICSERV;
    addrinfo *result = nullptr;
    const auto rc = getaddrinfo(ip.c_str(), std::
      to_string(port).c_str(), &amp;hints, &amp;result);
    if (rc) {
      logger.log("getaddrinfo() failed. error:% errno:%\n",
        gai_strerror(rc), strerror(errno));
      return -1;
    }</pre>
<p>The next section then checks the parameters passed to the <code>createSocket()</code> method and uses <a id="_idIndexMarker668"/>all the methods we built previously to set the correct socket parameters as needed. Note that we use the <code>addrinfo *</code> result object returned from <code>getaddrinfo()</code> to create the socket through the <code>socket()</code> routine.</p>
<p>First, we make the actual function call to create the socket:</p>
<pre class="source-code">
  int fd = -1;
  int one = 1;
  for (addrinfo *rp = result; rp; rp = rp-&gt;ai_next) {
    fd = socket(rp-&gt;ai_family, rp-&gt;ai_socktype, rp
      -&gt;ai_protocol);
    if (fd == -1) {
      logger.log("socket() failed. errno:%\n",
         strerror(errno));
      return -1;
    }</pre>
<p>Next, we set it to be non-blocking and disable Nagle’s algorithm using the methods we defined previously:</p>
<pre class="source-code">
    if (!is_blocking) {
      if (!setNonBlocking(fd)) {
        logger.log("setNonBlocking() failed. errno:%\n",
          strerror(errno));
        return -1;
      }
      if (!is_udp &amp;&amp; !setNoDelay(fd)) {
        logger.log("setNoDelay() failed. errno:%\n",
          strerror(errno));
        return -1;
      }
    }</pre>
<p>Next, we connect the socket <a id="_idIndexMarker669"/>to the target address if it is not a listening socket:</p>
<pre class="source-code">
    if (!is_listening &amp;&amp; connect(fd, rp-&gt;ai_addr, rp
      -&gt;ai_addrlen) == 1 &amp;&amp; !wouldBlock()) {
      logger.log("connect() failed. errno:%\n",
        strerror(errno));
      return -1;
    }</pre>
<p>Then, if we want to create a socket that listens for incoming connections, we set the correct parameters and bind the socket to a specific address that the client will try to connect to. We also need to call the <code>listen()</code> routine for such a socket configuration. Note that we reference a <code>MaxTCPServerBacklog</code> parameter here, which is defined as follows:</p>
<pre class="source-code">
constexpr int MaxTCPServerBacklog = 1024;</pre>
<p>Now, let us look at <a id="_idIndexMarker670"/>the code to make the socket a listening socket:</p>
<pre class="source-code">
    if (is_listening &amp;&amp; setsockopt(fd, SOL_SOCKET,
      SO_REUSEADDR, reinterpret_cast&lt;const char *&gt;(&amp;one),
        sizeof(one)) == -1) {
      logger.log("setsockopt() SO_REUSEADDR failed.
        errno:%\n", strerror(errno));
      return -1;
    }
    if (is_listening &amp;&amp; bind(fd, rp-&gt;ai_addr, rp-&gt;
      ai_addrlen) == -1) {
      logger.log("bind() failed. errno:%\n",
        strerror(errno));
      return -1;
    }
    if (!is_udp &amp;&amp; is_listening &amp;&amp; listen(fd,
      MaxTCPServerBacklog) == -1) {
      logger.log("listen() failed. errno:%\n",
        strerror(errno));
      return -1;
    }</pre>
<p>Finally, we set the TTL value for the socket we just created and return the socket. We will also set the ability to fetch <a id="_idIndexMarker671"/>the data receipt timestamps from incoming packets using the <code>setSOTimestamp()</code> method we created before:</p>
<pre class="source-code">
    if (is_udp &amp;&amp; ttl) {
      const bool is_multicast = atoi(ip.c_str()) &amp; 0xe0;
      if (is_multicast &amp;&amp; !setMcastTTL(fd, ttl)) {
        logger.log("setMcastTTL() failed. errno:%\n",
          strerror(errno));
        return -1;
      }
      if (!is_multicast &amp;&amp; !setTTL(fd, ttl)) {
        logger.log("setTTL() failed. errno:%\n",
          strerror(errno));
        return -1;
      }
    }
      if (needs_so_timestamp &amp;&amp; !setSOTimestamp(fd)) {
        logger.log("setSOTimestamp() failed. errno:%\n",
          strerror(errno));
        return -1;
      }
  }
  if (result)
    freeaddrinfo(result);
  return fd;
}</pre>
<p>Now that we have discussed and implemented the details of our lower-level socket method, we can <a id="_idIndexMarker672"/>move on to the next section and build a slightly higher-level abstraction that builds on top of this method.</p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor129"/>Implementing a sender/receiver TCP socket</h2>
<p>Now that we <a id="_idIndexMarker673"/>have finished our design and implementation of basic methods to create sockets and set different parameters on them, we can start using them. First, we will implement a <code>TCPSocket</code> structure that builds on top of the socket utilities we created in the previous section. <code>TCPSocket</code> can be used to both send and receive data, so it will be used both within TCP socket servers and clients.</p>
<h3>Defining the data members of the TCP socket</h3>
<p>Let us jump into our implementation of the <code>TCPSocket</code> structure, starting with the data members we need. Since <a id="_idIndexMarker674"/>this socket will be used to send and receive data, we will create two buffers – one to store data to be sent out and one to store data that was just read in. We will also store the file descriptor corresponding to our TCP socket in the <code>fd_</code> variable. We also create two flags: one to track if the send socket is connected and another to check whether the receive socket is connected. We will also save a reference to a <code>Logger</code> object, purely for logging purposes. Finally, we will store a <code>std::function</code> object, which we will use to dispatch callbacks to components that want to read data from this socket when there is new data available to be consumed. The code for this section is in <code>Chapter4/tcp_socket.h</code> and <code>Chapter4/tcp_socket.cpp</code> in the GitHub repository for this book:</p>
<pre class="source-code">
#pragma once
#include &lt;functional&gt;
#include "socket_utils.h"
#include "logging.h"
namespace Common {
  constexpr size_t TCPBufferSize = 64 * 1024 * 1024;
  struct TCPSocket {
    int fd_ = -1;
    char *send_buffer_ = nullptr;
    size_t next_send_valid_index_ = 0;
    char *rcv_buffer_ = nullptr;
    size_t next_rcv_valid_index_ = 0;
    bool send_disconnected_ = false;
    bool recv_disconnected_ = false;
    struct sockaddr_in inInAddr;
    std::function&lt;void(TCPSocket *s, Nanos rx_time)&gt;
      recv_callback_;
    std::string time_str_;
    Logger &amp;logger_;
  };
}</pre>
<p>We define a default r<a id="_idIndexMarker675"/>eceive callback we will use to initialize the <code>recv_callback_</code> data member. This method simply logs information that confirms that the callback was invoked:</p>
<pre class="source-code">
    auto defaultRecvCallback(TCPSocket *socket, Nanos
      rx_time) noexcept {
      logger_.log("%:% %() %
        TCPSocket::defaultRecvCallback() socket:% len:%
          rx:%\n", __FILE__, __LINE__, __FUNCTION__,
                  Common::getCurrentTimeStr(&amp;time_str_),
                    socket-&gt;fd_, socket-&gt;
                      next_rcv_valid_index_, rx_time);
    }</pre>
<p>Next, let us look at the constructor for the <code>TCPSocket</code> structure.</p>
<h3>Constructing and destroying the TCP socket</h3>
<p>For the constructor, we <a id="_idIndexMarker676"/>will create the <code>send_buffer_</code> and <code>rcv_buffer_</code> <code>char *</code> storage on the heap and assign the <code>defaultRecvCallback()</code> method <a id="_idIndexMarker677"/>to the <code>recv_callback_</code> member variable through a lambda method. Note that we set the socket’s receive and send buffers to be of size <code>TCPBufferSize</code>, as defined here:</p>
<pre class="source-code">
constexpr size_t TCPBufferSize = 64 * 1024 * 1024;
    explicit TCPSocket(Logger &amp;logger)
        : logger_(logger) {
      send_buffer_ = new char[TCPBufferSize];
      rcv_buffer_ = new char[TCPBufferSize];
      recv_callback_ = [this](auto socket, auto rx_time) {
        defaultRecvCallback(socket, rx_time); };
    }</pre>
<p>We then create <code>destroy()</code> and a destructor to perform straightforward cleanup tasks. We will <a id="_idIndexMarker678"/>close the socket file descriptor and <a id="_idIndexMarker679"/>destroy the receive and send buffers we created in the constructor:</p>
<pre class="source-code">
  auto TCPSocket::destroy() noexcept -&gt; void {
    close(fd_);
    fd_ = -1;
  }
  ~TCPSocket() {
    destroy();
    delete[] send_buffer_; send_buffer_ = nullptr;
    delete[] rcv_buffer_; rcv_buffer_ = nullptr;
  }</pre>
<p>We define the boilerplate code we saw previously to prevent accidental or unintentional constructions, copies, or assignments:</p>
<pre class="source-code">
  // Deleted default, copy &amp; move constructors and
    assignment-operators.
  TCPSocket() = delete;
  TCPSocket(const TCPSocket &amp;) = delete;
  TCPSocket(const TCPSocket &amp;&amp;) = delete;
  TCPSocket &amp;operator=(const TCPSocket &amp;) = delete;
  TCPSocket &amp;operator=(const TCPSocket &amp;&amp;) = delete;</pre>
<p>Next, let us try to <a id="_idIndexMarker680"/>perform one key operation on this <a id="_idIndexMarker681"/>socket – establishing TCP connections.</p>
<h3>Establishing TCP connections</h3>
<p>For this structure, we <a id="_idIndexMarker682"/>will define a <code>connect()</code> method, which is basically what creates, initializes, and connects <code>TCPSocket</code>. We will use the <code>createSocket()</code> method we created in the previous section with the correct parameters to achieve this:</p>
<pre class="source-code">
  auto TCPSocket::connect(const std::string &amp;ip, const
    std::string &amp;iface, int port, bool is_listening) -&gt;
      int {
    destroy();
    fd_ = createSocket(logger_, ip, iface, port, false,
      false, is_listening, 0, true);
    inInAddr.sin_addr.s_addr = INADDR_ANY;
    inInAddr.sin_port = htons(port);
    inInAddr.sin_family = AF_INET;
    return fd_;
  }</pre>
<p>Next, we will move on to the next critical functionality in our socket – sending and receiving data.</p>
<h3>Sending and receiving data</h3>
<p>We mentioned in our <a id="_idIndexMarker683"/>discussion that when new data is available, the interested listener will be notified <a id="_idIndexMarker684"/>through the <code>recv_callback_</code> <code>std::function</code> mechanism. Therefore, we just need to provide a <code>send()</code> method for the users of this structure to send data out. Note that this <code>send()</code> method simply copies the provided data into the outgoing buffer, and the actual write to the wire will be done in the <code>sendAndRecv()</code> method we will see shortly:</p>
<pre class="source-code">
  auto TCPSocket::send(const void *data, size_t len)
    noexcept -&gt; void {
    if (len &gt; 0) {
      memcpy(send_buffer_ + next_send_valid_index_, data,
        len);
      next_send_valid_index_ += len;
    }
  }</pre>
<p>Finally, we have the <a id="_idIndexMarker685"/>most important method for the <code>TCPSocket</code> structure, <code>sendAndRecv()</code>, which reads available data into <code>rcv_buffer_</code>, increments <a id="_idIndexMarker686"/>the counters, and dispatches <code>recv_callback_</code> if there is some amount of data that was read. The second half of this method does the opposite – it tries to write out data in <code>send_buffer_</code> using the <code>send()</code> routine and updates the index tracker variables:</p>
<pre class="source-code">
  auto TCPSocket::sendAndRecv() noexcept -&gt; bool {
    char ctrl[CMSG_SPACE(sizeof(struct timeval))];
    struct cmsghdr *cmsg = (struct cmsghdr *) &amp;ctrl;
    struct iovec iov;
    iov.iov_base = rcv_buffer_ + next_rcv_valid_index_;
    iov.iov_len = TCPBufferSize - next_rcv_valid_index_;
    msghdr msg;
    msg.msg_control = ctrl;
    msg.msg_controllen = sizeof(ctrl);
    msg.msg_name = &amp;inInAddr;
    msg.msg_namelen = sizeof(inInAddr);
    msg.msg_iov = &amp;iov;
    msg.msg_iovlen = 1;
    const auto n_rcv = recvmsg(fd_, &amp;msg, MSG_DONTWAIT);
    if (n_rcv &gt; 0) {
      next_rcv_valid_index_ += n_rcv;
      Nanos kernel_time = 0;
      struct timeval time_kernel;
      if (cmsg-&gt;cmsg_level == SOL_SOCKET &amp;&amp;
          cmsg-&gt;cmsg_type == SCM_TIMESTAMP &amp;&amp;
          cmsg-&gt;cmsg_len == CMSG_LEN(sizeof(time_kernel))) {
        memcpy(&amp;time_kernel, CMSG_DATA(cmsg),
          sizeof(time_kernel));
        kernel_time = time_kernel.tv_sec * NANOS_TO_SECS +
          time_kernel.tv_usec * NANOS_TO_MICROS;
      }
      const auto user_time = getCurrentNanos();
      logger_.log("%:% %() % read socket:% len:% utime:%
        ktime:% diff:%\n", __FILE__, __LINE__,
          __FUNCTION__,
                  Common::getCurrentTimeStr(&amp;time_str_),
                    fd_, next_rcv_valid_index_, user_time,
                      kernel_time, (user_time -
                        kernel_time));
      recv_callback_(this, kernel_time);
    }
    ssize_t n_send = std::min(TCPBufferSize,
      next_send_valid_index_);
    while (n_send &gt; 0) {
      auto n_send_this_msg = std::min(static_cast&lt;ssize_t&gt;
        (next_send_valid_index_), n_send);
      const int flags = MSG_DONTWAIT | MSG_NOSIGNAL |
         (n_send_this_msg &lt; n_send ? MSG_MORE : 0);
      auto n = ::send(fd_, send_buffer_, n_send_this_msg,
        flags);
      if (UNLIKELY(n &lt; 0)) {
        if (!wouldBlock())
          send_disconnected_ = true;
        break;
      }
      logger_.log("%:% %() % send socket:% len:%\n",
        __FILE__, __LINE__, __FUNCTION__,
          Common::getCurrentTimeStr(&amp;time_str_), fd_, n);
      n_send -= n;
      ASSERT(n == n_send_this_msg, "Don't support partial
        send lengths yet.");
    }
    next_send_valid_index_ = 0;
    return (n_rcv &gt; 0);
  }</pre>
<p>This concludes <a id="_idIndexMarker687"/>our discussion of the <code>TCPSocket</code> class. Next, we <a id="_idIndexMarker688"/>will build a class that encapsulates and manages <code>TCPSocket</code> objects. It will be used to implement functionality for TCP servers in components that act as servers.</p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor130"/>Building a TCP server component</h2>
<p>We built a <code>TCPSocket</code> class in the previous section that can be used by components that need to <a id="_idIndexMarker689"/>connect to TCP connections and send as well as receive data. In this section, we will build a <code>TCPServer</code> component that manages several such <code>TCPSocket</code> objects internally. It also manages tasks, such as listening for, accepting, and tracking new incoming connections and sending and receiving data on this collection of sockets. All the source code for the <code>TCPServer</code> component is in the <code>Chapter4/tcp_server.h</code> and <code>Chapter4/tcp_server.cpp</code> files in the GitHub repository for this book.</p>
<h3>Defining the data members of the TCP server</h3>
<p>First, we will <a id="_idIndexMarker690"/>define and describe the data members that the <code>TCPServer</code> class will contain. It needs a file descriptor, <code>efd_</code>, and a corresponding <code>TCPSocket listener_socket_</code> to represent the socket on which it will be listening for new incoming connections from clients. It maintains an array of <code>epoll_event events_</code>, which will be used to monitor the listening socket file descriptor, along with socket descriptors for connected clients. It will have a few <code>std::vectors</code> of socket objects – sockets that we expect to receive data from, sockets we expect to send data on, and sockets that are disconnected. We will see how these are used shortly.</p>
<p>This class has two <code>std::function</code> objects – one used to dispatch callbacks when new data is received and another one that is dispatched after all callbacks in the current round of polling the sockets are completed. To explain this better, we will first use the <code>epoll</code> call to find all the sockets that have data to read, dispatch <code>recv_callback_</code> for each socket that has data, and finally, when all sockets have been notified, dispatch <code>recv_finished_callback_</code>. One more thing to note here is that the <code>recv_callback_</code> provides <code>TCPSocket</code> on which the data was received, as well as <code>Nanos rx_time</code> to specify the software receive time of the data on that socket. The receive timestamps <a id="_idIndexMarker691"/>are used to process the TCP packets in the exact order in which they were received, since the TCP server monitors and reads from many different client TCP sockets:</p>
<pre class="source-code">
#pragma once
#include "tcp_socket.h"
namespace Common {
  struct TCPServer {
  public:
    int efd_ = -1;
    TCPSocket listener_socket_;
    epoll_event events_[1024];
    std::vector&lt;TCPSocket *&gt; sockets_, receive_sockets_,
      send_sockets_, disconnected_sockets_;
    std::function&lt;void(TCPSocket *s, Nanos rx_time)&gt;
      recv_callback_;
    std::function&lt;void()&gt; recv_finished_callback_;
    std::string time_str_;
    Logger &amp;logger_;
  };
}</pre>
<p>In the next section, we <a id="_idIndexMarker692"/>will look at the code to initialize these fields and de-initialize the TCP server.</p>
<h3>Initializing and destroying the TCP server</h3>
<p>The constructor <a id="_idIndexMarker693"/>for <code>TCPServer</code> is straightforward – it initializes <code>listener_socket_</code> and <code>logger_</code> and sets the default callback <a id="_idIndexMarker694"/>receivers, as we did with <code>TCPSocket</code>:</p>
<pre class="source-code">
    explicit TCPServer(Logger &amp;logger)
        : listener_socket_(logger), logger_(logger) {
      recv_callback_ = [this](auto socket, auto rx_time) {
        defaultRecvCallback(socket, rx_time); };
      recv_finished_callback_ = [this]() {
        defaultRecvFinishedCallback(); };
    }</pre>
<p>We define the default receive callback methods here, which do not do anything except log that the callback was received. These are placeholders anyway, since we will set different ones in real applications:</p>
<pre class="source-code">
    auto defaultRecvCallback(TCPSocket *socket, Nanos
      rx_time) noexcept {
      logger_.log("%:% %() %
        TCPServer::defaultRecvCallback() socket:% len:%
          rx:%\n", __FILE__, __LINE__, __FUNCTION__,
            Common::getCurrentTimeStr(&amp;time_str_), socket-&gt;
              fd_, socket-&gt;next_rcv_valid_index_, rx_time);
    }
    auto defaultRecvFinishedCallback() noexcept {
      logger_.log("%:% %() % TCPServer::
       defaultRecvFinishedCallback()\n", __FILE__,
       __LINE__, __FUNCTION__,
        Common::getCurrentTimeStr(&amp;time_str_));
    }</pre>
<p>The code to destroy the sockets is quite simple as well – we close the file descriptor and destroy <code>TCPSocket listener_socket_</code>:</p>
<pre class="source-code">
  auto TCPServer::destroy() {
    close(efd_);
    efd_ = -1;
    listener_socket_.destroy();
  }</pre>
<p>Finally, we present the boilerplate code that we saw previously for this class:</p>
<pre class="source-code">
    TCPServer() = delete;
    TCPServer(const TCPServer &amp;) = delete;
    TCPServer(const TCPServer &amp;&amp;) = delete;
    TCPServer &amp;operator=(const TCPServer &amp;) = delete;
    TCPServer &amp;operator=(const TCPServer &amp;&amp;) = delete;</pre>
<p>Next, let us <a id="_idIndexMarker695"/>understand the code that initializes the listener <a id="_idIndexMarker696"/>socket.</p>
<h3>Starting up and listening for new connections</h3>
<p>The method <code>TCPServer::listen()</code>, first creates a new <code>epoll</code> instance, using the <code>epoll_create()</code> Linux <a id="_idIndexMarker697"/>system call, and then <a id="_idIndexMarker698"/>saves it in the <code>efd_</code> variable. It uses the <code>TCPSocket::connect()</code> method we built earlier to initialize <code>listener_socket_</code>, but here, the important part is that we set the <code>listening</code> argument to be <code>true</code>. Finally, we add <code>listener_socket_</code> to the list of sockets to be monitored using the <code>epoll_add()</code> method, since initially, this is the only socket to monitor. We will look at this <code>epoll_add()</code> method in the next section:</p>
<pre class="source-code">
  auto TCPServer::listen(const std::string &amp;iface, int
    port) -&gt; void {
    destroy();
    efd_ = epoll_create(1);
    ASSERT(efd_ &gt;= 0, "epoll_create() failed error:" +
      std::string(std::strerror(errno)));
    ASSERT(listener_socket_.connect("", iface, port, true)
      &gt;= 0,
           "Listener socket failed to connect. iface:" +
             iface + " port:" + std::to_string(port) + "
               error:" + std::string
                 (std::strerror(errno)));
    ASSERT(epoll_add(&amp;listener_socket_), "epoll_ctl()
      failed. error:" + std::string(std::strerror(errno)));
  }</pre>
<p>Now, let us <a id="_idIndexMarker699"/>look at how the <code>epoll_add()</code> and the <a id="_idIndexMarker700"/>complementary <code>epoll_del()</code> methods are built in the next subsection.</p>
<h3>Adding and removing monitored sockets</h3>
<p>The <code>epoll_add()</code> method is used to add <code>TCPSocket</code> to the list of sockets to be monitored. It uses the <code>epoll_ctl()</code> system call with the <code>EPOLL_CTL_ADD</code> parameter to add the <a id="_idIndexMarker701"/>provided file <a id="_idIndexMarker702"/>descriptor of the socket to the <code>efd_</code> epoll class member. <code>EPOLLET</code> enabled the <em class="italic">edge-triggered epoll</em> option, which in simple terms means you are notified only once when data needs to be read instead of constant reminders. In this mode, it is up to the application developer to read the data when they want. <code>EPOLLIN</code> is used for notification once data is available to be read:</p>
<pre class="source-code">
  auto TCPServer::epoll_add(TCPSocket *socket) {
    epoll_event ev{};
    ev.events = EPOLLET | EPOLLIN;
    ev.data.ptr = reinterpret_cast&lt;void *&gt;(socket);
    return (epoll_ctl(efd_, EPOLL_CTL_ADD, socket-&gt;fd_,
      &amp;ev) != -1);
  }</pre>
<p>The <code>epoll_del()</code> does the opposite of <code>epoll_add()</code> – <code>epoll_ctl()</code> is still used, but this time, the <code>EPOLL_CTL_DEL</code> parameter removes <code>TCPSocket</code> from the list of sockets being monitored:</p>
<pre class="source-code">
  auto TCPServer::epoll_del(TCPSocket *socket) {
    return (epoll_ctl(efd_, EPOLL_CTL_DEL, socket-&gt;fd_,
      nullptr) != -1);
  }</pre>
<p>The <code>del()</code> method we will build here removes <code>TCPSocket</code> from the list of sockets being monitored, as <a id="_idIndexMarker703"/>well as the different data <a id="_idIndexMarker704"/>member containers of the sockets:</p>
<pre class="source-code">
  auto TCPServer::del(TCPSocket *socket) {
    epoll_del(socket);
    sockets_.erase(std::remove(sockets_.begin(),
      sockets_.end(), socket), sockets_.end());
    receive_sockets_.erase(std::remove
      (receive_sockets_.begin(), receive_sockets_.end(),
        socket), receive_sockets_.end());
    send_sockets_.erase(std::remove(send_sockets_.begin(),
      send_sockets_.end(), socket), send_sockets_.end());
  }</pre>
<p>Now, we can look at the most important method in this subsection – <code>TCPServer::poll()</code>, which will be used to perform a few tasks, as listed here:</p>
<ul>
<li>Call <code>epoll_wait()</code>, detect whether there are any new incoming connections, and if so, add them to our containers</li>
<li>From the call to <code>epoll_wait()</code>, detect sockets that have disconnected from the client’s side and remove them from our containers</li>
<li>From the call to <code>epoll_wait()</code>, check to see whether there are sockets with data ready to be read or with outgoing data</li>
</ul>
<p>Let us break down the entire method into a few blocks – first, the block that calls the <code>epoll_wait()</code> method, with the <code>epoll</code> instance and the maximum number of events being the total number of sockets in our containers, with no timeout:</p>
<pre class="source-code">
  auto TCPServer::poll() noexcept -&gt; void {
    const int max_events = 1 + sockets_.size();
    for (auto socket: disconnected_sockets_) {
      del(socket);
    }
    const int n = epoll_wait(efd_, events_, max_events, 0);</pre>
<p>Next, we iterate <a id="_idIndexMarker705"/>through the <code>events_</code> array <a id="_idIndexMarker706"/>populated by the call to <code>epoll_wait()</code> if it returns a value of <code>n</code> greater than 0. For each <code>epoll_event</code> in the <code>events_</code> array, we use the <code>event.data.ptr</code> object and cast it to <code>TCPSocket*</code>, since that is how we set up the <code>events_</code> array in the <code>epoll_add()</code> method:</p>
<pre class="source-code">
    bool have_new_connection = false;
    for (int i = 0; i &lt; n; ++i) {
      epoll_event &amp;event = events_[i];
      auto socket = reinterpret_cast&lt;TCPSocket
        *&gt;(event.data.ptr);</pre>
<p>For each <code>epoll_event</code> entry, we check whether the <code>EPOLLIN</code> flag is set on the events flag, which would signify that there is a new socket with data to read from. If this socket happens to be <code>listener_socket_</code>, which is <code>TCPServer</code>’s primary socket that we configured to listen for connections on, we can see that we have a new connection to add. If this is a socket different from <code>listener_socket_</code>, then we add it to the list of <code>receive_sockets_</code> vectors if it does not already exist in the list:</p>
<pre class="source-code">
      if (event.events &amp; EPOLLIN) {
        if (socket == &amp;listener_socket_) {
          logger_.log("%:% %() % EPOLLIN
            listener_socket:%\n", __FILE__, __LINE__,
              __FUNCTION__,
               Common::getCurrentTimeStr(&amp;time_str_),
                 socket-&gt;fd_);
          have_new_connection = true;
          continue;
        }
        logger_.log("%:% %() % EPOLLIN socket:%\n",
          __FILE__, __LINE__, __FUNCTION__,
            Common::getCurrentTimeStr(&amp;time_str_), socket-
              &gt;fd_);
        if(std::find(receive_sockets_.begin(),
          receive_sockets_.end(), socket) ==
            receive_sockets_.end())
          receive_sockets_.push_back(socket);
      }</pre>
<p>Similarly, we check <a id="_idIndexMarker707"/>for the <code>EPOLLOUT</code> flag, which <a id="_idIndexMarker708"/>signifies there is a socket that we can send data to, and add it to the <code>send_sockets_</code> vector if it does not already exist:</p>
<pre class="source-code">
      if (event.events &amp; EPOLLOUT) {
        logger_.log("%:% %() % EPOLLOUT socket:%\n",
          __FILE__, __LINE__, __FUNCTION__,
            Common::getCurrentTimeStr(&amp;time_str_), socket-
             &gt;fd_);
        if(std::find(send_sockets_.begin(),
          send_sockets_.end(), socket) ==
            send_sockets_.end())
          send_sockets_.push_back(socket);
      }</pre>
<p>Finally, we check whether the <code>EPOLLERR</code> or <code>EPOLLHUP</code> flags are set, which indicate an error or indicate that the socket was closed (signal <code>hang up</code>) from the other end. In this case, we add this socket to the <code>disconnected_sockets_</code> vector to be removed:</p>
<pre class="source-code">
      if (event.events &amp; (EPOLLERR | EPOLLHUP)) {
        logger_.log("%:% %() % EPOLLERR socket:%\n",
          __FILE__, __LINE__, __FUNCTION__,
            Common::getCurrentTimeStr(&amp;time_str_), socket-
              &gt;fd_);
        if(std::find(disconnected_sockets_.begin(),
          disconnected_sockets_.end(), socket) ==
            disconnected_sockets_.end())
          disconnected_sockets_.push_back(socket);
      }
    }</pre>
<p>Finally, in this method, we need to accept the new connection if we detected one in the previous code block. We <a id="_idIndexMarker709"/>use the <code>accept()</code> system call <a id="_idIndexMarker710"/>with the <code>listener_socket_</code> file descriptor to achieve this and fetch the file descriptor for this new socket. We also set the socket to be non-blocking and disable Nagle’s algorithm, using the <code>setNonBlocking()</code> and <code>setNoDelay()</code> methods we built before:</p>
<pre class="source-code">
    while (have_new_connection) {
      logger_.log("%:% %() % have_new_connection\n",
        __FILE__, __LINE__, __FUNCTION__,
         Common::getCurrentTimeStr(&amp;time_str_));
      sockaddr_storage addr;
      socklen_t addr_len = sizeof(addr);
      int fd = accept(listener_socket_.fd_,
        reinterpret_cast&lt;sockaddr *&gt;(&amp;addr), &amp;addr_len);
      if (fd == -1)
        break;
      ASSERT(setNonBlocking(fd) &amp;&amp; setNoDelay(fd), "Failed
        to set non-blocking or no-delay on socket:" + std::
          to_string(fd));
      logger_.log("%:% %() % accepted socket:%\n",
        __FILE__, __LINE__, __FUNCTION__,
          Common::getCurrentTimeStr(&amp;time_str_), fd);</pre>
<p>Finally, we <a id="_idIndexMarker711"/>create a new <code>TCPSocket</code> object <a id="_idIndexMarker712"/>using this file descriptor and add the <code>TCPSocket</code> object to the <code>sockets_</code> and <code>receive_sockets_</code> containers:</p>
<pre class="source-code">
      TCPSocket *socket = new TCPSocket(logger_);
      socket-&gt;fd_ = fd;
      socket-&gt;recv_callback_ = recv_callback_;
      ASSERT(epoll_add(socket), "Unable to add socket.
        error:" + std::string(std::strerror(errno)));
      if(std::find(sockets_.begin(), sockets_.end(),
        socket) == sockets_.end())
        sockets_.push_back(socket);
      if(std::find(receive_sockets_.begin(),
        receive_sockets_.end(), socket) ==
          receive_sockets_.end())
        receive_sockets_.push_back(socket);
    }
  }</pre>
<p>This concludes all the functionality we need to look for new connections and dead connections, as <a id="_idIndexMarker713"/>well as monitor existing <a id="_idIndexMarker714"/>connections to see whether there is data to be read. The next sub-section concludes our <code>TCPServer</code> class by demonstrating how to send and receive data from a list of sockets that have data to be read or sent out.</p>
<h3>Sending and receiving data</h3>
<p>The code to send <a id="_idIndexMarker715"/>and receive data on a list of sockets with incoming <a id="_idIndexMarker716"/>or outgoing data is shown here. The implementation is very straightforward – it simply calls the <code>TCPSocket::sendAndRecv()</code> method on each of the sockets in <code>receive_sockets_</code> and <code>send_sockets_</code>. For incoming data, the call to <code>TCPSocket::sendAndRecv()</code> dispatches the <code>recv_callback_</code> method. One thing we need to do here is to check whether there was any data that was read this time around, and if so, we dispatch <code>recv_finished_callback_</code> after all the <code>recv_callback_</code> calls are dispatched:</p>
<pre class="source-code">
  auto TCPServer::sendAndRecv() noexcept -&gt; void {
    auto recv = false;
    for (auto socket: receive_sockets_) {
      if(socket-&gt;sendAndRecv())
        recv = true;
    }
    if(recv)
      recv_finished_callback_();
    for (auto socket: send_sockets_) {
      socket-&gt;sendAndRecv();
    }
  }</pre>
<p>This concludes <a id="_idIndexMarker717"/>our implementation of the <code>TCPServer</code> class, let <a id="_idIndexMarker718"/>us wrap up our network programming discussion with a simple example of everything we built in this section.</p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor131"/>Building an example of the TCP server and clients</h2>
<p>In this section, we <a id="_idIndexMarker719"/>will build an example and use the <code>TCPSocket</code> and <code>TCPServer</code> classes we implemented in this section. This example can be found in the <code>Chapter4/socket_example.cpp</code> source file. This simple example creates <code>TCPServer</code>, which listens for incoming connections on the <code>lo</code> interface, the loopback <code>127.0.0.1</code> IP, and the listening port, <code>12345</code>. The <code>TCPServer</code> class receives data from the clients, which connect to it using the <code>tcpServerRecvCallback()</code> lambda method, and the <code>TCPServer</code> responds back to the clients with a simple response. We then create five clients using the <code>TCPSocket</code> class, each of which connects to this <code>TCPServer</code>. Finally, they each send some data to the server, which sends responses back, each of the clients repeatedly calling <code>sendAndRecv()</code> to send and receive data. <code>TCPServer</code> calls <code>poll()</code> and <code>sendAndRecv()</code> to look for connections and data and reads it.</p>
<p>First, the code that sets up the callback lambdas is presented here:</p>
<pre class="source-code">
#include "time_utils.h"
#include "logging.h"
#include "tcp_server.h"
int main(int, char **) {
  using namespace Common;
  std::string time_str_;
  Logger logger_("socket_example.log");
  auto tcpServerRecvCallback = [&amp;](TCPSocket *socket, Nanos
    rx_time)
  noexcept{
      logger_.log("TCPServer::defaultRecvCallback()
        socket:% len:% rx:%\n",
                  socket-&gt;fd_, socket-&gt;
                    next_rcv_valid_index_, rx_time);
      const std::string reply = "TCPServer received msg:" +
        std::string(socket-&gt;rcv_buffer_, socket-&gt;
          next_rcv_valid_index_);
      socket-&gt;next_rcv_valid_index_ = 0;
      socket-&gt;send(reply.data(), reply.length());
  };
  auto tcpServerRecvFinishedCallback = [&amp;]()
  noexcept{
      logger_.log("TCPServer::defaultRecvFinishedCallback()\n");
  };
  auto tcpClientRecvCallback = [&amp;](TCPSocket *socket, Nanos
    rx_time)
  noexcept{
      const std::string recv_msg = std::string(socket-&gt;
        rcv_buffer_, socket-&gt;next_rcv_valid_index_);
      socket-&gt;next_rcv_valid_index_ = 0;
      logger_.log("TCPSocket::defaultRecvCallback()
        socket:% len:% rx:% msg:%\n",
      socket-&gt;fd_, socket-&gt;next_rcv_valid_index_, rx_time,
        recv_msg);
  };</pre>
<p>Then, we <a id="_idIndexMarker720"/>create, initialize, and connect the server and the clients, as shown here:</p>
<pre class="source-code">
  const std::string iface = "lo";
  const std::string ip = "127.0.0.1";
  const int port = 12345;
  logger_.log("Creating TCPServer on iface:% port:%\n",
    iface, port);
  TCPServer server(logger_);
  server.recv_callback_ = tcpServerRecvCallback;
  server.recv_finished_callback_ =
    tcpServerRecvFinishedCallback;
  server.listen(iface, port);
  std::vector &lt; TCPSocket * &gt; clients(5);
  for (size_t i = 0; i &lt; clients.size(); ++i) {
    clients[i] = new TCPSocket(logger_);
    clients[i]-&gt;recv_callback_ = tcpClientRecvCallback;
    logger_.log("Connecting TCPClient-[%] on ip:% iface:%
      port:%\n", i, ip, iface, port);
    clients[i]-&gt;connect(ip, iface, port, false);
    server.poll();
  }</pre>
<p>Finally, we have the <a id="_idIndexMarker721"/>clients send data and call the appropriate polling and sending/receiving methods on the clients and the server, as shown here:</p>
<pre class="source-code">
  using namespace std::literals::chrono_literals;
  for (auto itr = 0; itr &lt; 5; ++itr) {
    for (size_t i = 0; i &lt; clients.size(); ++i) {
      const std::string client_msg = "CLIENT-[" +
        std::to_string(i) + "] : Sending " +
          std::to_string(itr * 100 + i);
      logger_.log("Sending TCPClient-[%] %\n", i,
        client_msg);
      clients[i]-&gt;send(client_msg.data(),
        client_msg.length());
      clients[i]-&gt;sendAndRecv();
      std::this_thread::sleep_for(500ms);
      server.poll();
      server.sendAndRecv();
    }
  }
  for (auto itr = 0; itr &lt; 5; ++itr) {
    for (auto &amp;client: clients)
      client-&gt;sendAndRecv();
    server.poll();
    server.sendAndRecv();
    std::this_thread::sleep_for(500ms);
  }
  return 0;
}</pre>
<p>Running this example, as <a id="_idIndexMarker722"/>shown here, will output something similar to what is shown here in the log file:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter4$ ./cmake-build-release/socket_example ; cat socket_example.log
Creating TCPServer on iface:lo port:12345
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/socket_utils.cpp:68 createSocket() Sat Mar 25 11:32:55 2023 ip:127.0.0.1 iface:lo port:12345 is_udp:0 is_blocking:0 is_listening:1 ttl:0 SO_time:1
Connecting TCPClient-[0] on ip:127.0.0.1 iface:lo port:12345
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_server.cpp:74 poll() Sat Mar 25 11:32:55 2023 EPOLLIN listener_socket:5
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_server.cpp:97 poll() Sat Mar 25 11:32:55 2023 have_new_connection
…
Sending TCPClient-[0] CLIENT-[0] : Sending 0
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_socket.cpp:67 sendAndRecv() Sat Mar 25 11:32:55 2023 send socket:6 len:22
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_server.cpp:78 poll() Sat Mar 25 11:32:55 2023 EPOLLIN socket:7
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_socket.cpp:51 sendAndRecv() Sat Mar 25 11:32:55 2023 read socket:7 len:22 utime:1679761975918407366 ktime:0 diff:1679761975918407366
TCPServer::defaultRecvCallback() socket:7 len:22 rx:0
…
TCPSocket::defaultRecvCallback() socket:12 len:0 rx:1679761987425505000 msg:TCPServer received msg:CLIENT-[3] : Sending 403
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter4/tcp_socket.cpp:51 sendAndRecv() Sat Mar 25 11:33:07 2023 read socket:14 len:47 utime:1679761987925931213 ktime:1679761987925816000 diff:115213
TCPSocket::defaultRecvCallback() socket:14 len:0 rx:1679761987925816000 msg:TCPServer received msg:CLIENT-[4] : Sending 404</pre>
<p>This concludes our <a id="_idIndexMarker723"/>discussion of C++ network programming with sockets. We covered a lot regarding the basic low-level details of socket programming. We also designed and implemented slightly higher-level abstractions for TCP and UDP communication, both from a server’s and a client’s perspective.</p>
<h1 id="_idParaDest-125"><a id="_idTextAnchor132"/>Summary</h1>
<p>In this chapter, we jumped into the world of low latency application C++ development. We built some relatively fundamental but extremely useful building blocks that can be used for a variety of low latency application purposes. We put into practice a lot of the theoretical discussions related to using C++ and computer architecture features effectively to build low latency and highly performant applications.</p>
<p>The first component was used to create new threads of execution and run the functions that different components might require. One important functionality here is being able to control the CPU core that the newly created thread gets pinned to by setting the thread affinity.</p>
<p>The second component we built was meant to avoid dynamic memory allocation on the critical code path. We reiterated the inefficiencies associated with dynamic memory allocation and designed a memory pool to be used to pre-allocate memory from the heap when constructed. Then, we added utility to the component to allow the allocation and deallocation of objects at runtime without relying on dynamic memory allocation.</p>
<p>Next, we built a lock-free, <strong class="bold">First In First Out</strong> (<strong class="bold">FIFO</strong>)-style queue to communicate between threads in an SPSC setup. The important requirement here was that a single reader and a single writer are able to access the shared data in the queue without using any locks or mutexes. The absence of locks and mutexes means the absence of context switches, which, as discussed, are a major source of inefficiencies and latencies in multi-threaded applications.</p>
<p>The fourth component on our list was a framework to facilitate efficient logging for latency-sensitive applications. Logging is a very important if not mandatory component of all applications, including low latency applications. However, due to issues such as disk I/O, slow string formatting, and so on, traditional logging mechanisms such as writing to a log file on disk is impractical for use with low latency applications. To build this component, we used the multi-threading mechanism we built, as well as the lock-free FIFO queue.</p>
<p>Finally, we had an in-depth discussion about designing our network stack – how to create network sockets, how to use them to create TCP servers and clients, and how to use them to publish and consume multicast traffic. We have not used this last component yet, but we will use this component in subsequent chapters to facilitate communication between our electronic trading exchange and different market participants.</p>
<p>Now, we will move on to a case study project, which we will build in the rest of this book – our electronic trading ecosystem. In the next chapter, we will first focus on designing and understanding the higher-level design of the various components in our system. We will understand the purpose of these components, the motivation behind their design choices, and how the flow of information occurs in the system. The next chapter will also see us designing the higher-level C++ interfaces that we will implement in the rest of this book.</p>
</div>


<div><h1 id="_idParaDest-126"><a id="_idTextAnchor133"/>Part 2:Building a Live Trading Exchange in C++</h1>
<p>In this part, we will describe and design the trading applications that make up our ecosystem, which we will be building from scratch in this book – electronic trading exchanges, exchange market data dissemination, order gateways, client market data decoders, and client trading algorithm frameworks. We will implement the matching engine that tracks client orders and performs matching between them. We will also build the components that publish market data for all participants and how it handles client connections and order requests. The focus will be on very low-latency reaction times and high throughput since modern electronic exchanges have thousands of participants and a huge amount of order flow flowing through it.</p>
<p>This part contains the following chapters:</p>
<ul>
<li><a href="B19434_05.xhtml#_idTextAnchor134"><em class="italic">Chapter 5</em></a><em class="italic">, Designing Our Trading Ecosystem</em></li>
<li><a href="B19434_06.xhtml#_idTextAnchor166"><em class="italic">Chapter 6</em></a><em class="italic">, Building the C++ Matching Engine</em></li>
<li><a href="B19434_07.xhtml#_idTextAnchor186"><em class="italic">Chapter 7</em></a><em class="italic">, Communicating with Market Participants</em></li>
</ul>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
</body></html>