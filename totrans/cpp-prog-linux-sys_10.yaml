- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Coroutines in C++ for System Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are almost at the end of our book. The final chapter is dedicated to a feature
    that is very useful for the purposes of system programming but is fairly new to
    the C++ standard. **Coroutine** objects found their application fast, becoming
    first-class state machine objects. Their power is in hiding logic behind the **coroutine
    frame**. Be advised that this is an advanced topic, and the coroutine interface
    of C++ is neither simple nor comfortable to use. It is well thought out but definitely
    not the most user-friendly in comparison to other programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn the basics of using this facility. If you are
    new to it, then you’ll spend some time understanding its requirements. You’ll
    have an easier time with coroutines if you have previous experience with them
    in other programming languages. Still, we will use this chapter to propose their
    application in system programming.
  prefs: []
  type: TYPE_NORMAL
- en: We will present two practical solutions of previous examples related to **networking**
    and **shared memory**. You will immediately see the predictability and the clear
    execution path of the routines. We hope that you are impressed by the concurrent
    manner of execution without the use of synchronization primitives. Direct reuse
    in a real-world environment is possible; just make sure you have the required
    compilers, as the feature is still new. Without further ado, let’s get to our
    final topic.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing coroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network programming and coroutines in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revisiting the shared memory problem through coroutines in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Final thoughts on coroutines and their implementations in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to run the code examples, you must prepare the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A Linux-based system capable of compiling and executing C++20 (for example,
    **Linux** **Mint 21**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The GCC12.2 compiler – [https://gcc.gnu.org/git/gcc.git gcc-source](https://gcc.gnu.org/git/gcc.gitgcc-source):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the `-fcoroutines`, `-std=c++2a`, `-lpthread`, and `-``lrt` flags
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For some of the examples, you can alternatively use [https://godbolt.org/](https://godbolt.org/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All code examples in this chapter are available for download from [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the end of your journey, we’d like to remind you about the knowledge you
    received in [*Chapter 1*](B20833_01.xhtml#_idTextAnchor014) and [*Chapter 2*](B20833_02.xhtml#_idTextAnchor029)
    about **processes** and **threads**. If you remember well, a process is simply
    a running instance of a program. It has its respective address space, which is
    not shared with others, except through shared memory. Threads reside in a process,
    and they cannot exist outside of them, although both processes and threads are
    treated as **tasks** in Linux. They are scheduled in the same manner and have
    the same controlling structures on the **kernel** level. Still, threads are considered
    lightweight because the bigger overhead for the initial load of a program is taken
    by the parent process.
  prefs: []
  type: TYPE_NORMAL
- en: But this is not the full picture. There are **fibers** and coroutines as well.
    If the processes and threads are truly **concurrent** and working in parallel
    over shared resources, fibers are just like threads but are not **concurrency**-compliant.
    While threads often depend on **preemptive** time-slicing because of the task
    scheduler, fibers use **cooperative multitasking**. That is, they yield themselves
    to run another fiber while executing. They are also known as **stackful coroutines**.
    Meanwhile, coroutines in C++ are known as **stackless coroutines** and are not
    OS-managed. In other words, stackful coroutines could be suspended in a nested
    stack frame, while stackless coroutines can only be nested by the top-level routine.
  prefs: []
  type: TYPE_NORMAL
- en: Both facilities are considered implicitly synchronized, so all of the synchronization
    primitives and the **atomic** constructs from the previous chapters are needless.
    But you could picture the early example with reading from the file system – where
    the OS waits for the file to be opened, and the process-caller is signaled to
    continue its work. Imagine that the fibers and the coroutines are useful exactly
    for that reactive access, which does not need additional CPU processing. Actually,
    the networking and the file systems are the areas where the fibers and coroutines
    are considered most valuable. When a request is made, a fiber gives control to
    the main thread, and when the I/O operation is finished, the fiber continues where
    it yielded.
  prefs: []
  type: TYPE_NORMAL
- en: The coroutines technique is rather old. C++ introduced it recently, and it is
    very useful for network programming, I/O operations, event management, and so
    on. Coroutines are also considered executions with the ability to pause. Still,
    they provide multitasking in a cooperative fashion and do not work in parallel.
    This means that tasks cannot be executed simultaneously. At the same time, they
    are real-timw-friendly, allowing switching context between coroutines to be fast,
    and not requiring system calls. In fact, they are **hard-RTOS**-friendly because
    the order of execution and scheduling is controlled by the system programmer,
    as you will see later in the chapter. The coroutines in C++ are very useful for
    implementing task graphs and state machines, too.
  prefs: []
  type: TYPE_NORMAL
- en: Some of you are probably wondering what the difference between coroutines and
    standard single-threaded functional programming is. Well, the latter is considered
    a synchronous approach, while the former is an asynchronous approach with synchronous
    readability. But coroutines are really about reducing the needless (busy) waiting
    and doing something useful while a required resource or a call is being prepared.
    The following diagram is simple but reminds us of the respective differences between
    sync and async executions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Synchronous versus asynchronous application execution](img/Figure_10.01_B20833.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Synchronous versus asynchronous application execution
  prefs: []
  type: TYPE_NORMAL
- en: A regular single-threaded execution is also limited in some ways. First of all,
    calling, suspending, or resuming a function is not traceable inside a program,
    or at least not through a reference. In other words, the control flow happens
    in the background and is implicit. In addition, the control flow has a strict
    direction – a function could either return to its caller or proceed inward toward
    calling another function. Each function call creates a new record on the stack
    and happens immediately, and once invoked, a method cannot be delayed. As soon
    as that function returns, its portion of the stack is cleared and cannot be restored.
    In other words, the activation is not traceable.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, coroutines have their own lifetime. A coroutine is an object
    and can be referenced explicitly. If the coroutine should outlive its caller or
    should be transferred to another, then it could be stored in the `int func(int
    arg)` prototype would mean a function with the name `func`, receiving an argument,
    `arg`, of an integer type, returning an integer. A similar coroutine may never
    return to its caller and the value that the caller expects may be produced by
    another coroutine. Let see how this happens in C++.
  prefs: []
  type: TYPE_NORMAL
- en: The coroutine facility in C++
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Initially, you can think about them like `Task exCoroutine()` task (a task
    is different from the Linux definition of task) – it is interpreted as a coroutine
    if it uses one of the following three operators: `co_await`, `co_yield`, or `co_return`.
    Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The wrapper type is currently `Task`. It is known on the caller level. The coroutine
    object is identified as the `exCoroutine()` function through the `co_return` operator.
    It’s the job of the system programmer to create the `Task` class. It is not a
    part of the Standard library. What’s the `Task` class then?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This is a very generic pattern that is used in almost every coroutine example.
    You should initially refer to it at [https://en.cppreference.com/w/cpp/language/coroutines](https://en.cppreference.com/w/cpp/language/coroutines).
  prefs: []
  type: TYPE_NORMAL
- en: 'We call a task a coroutine that executes a given routine but doesn’t return
    a value. In addition, the coroutine is associated with a `promise` object – we
    spoke about that in [*Chapter 6*](B20833_06.xhtml#_idTextAnchor086). The `promise`
    object is manipulated on a coroutine level. The coroutine returns the operation
    result or raises an exception through this object. This facility also requires
    the `promise`. It also consists of the passed parameters – copied by value, a
    representation of the current invocation reference; the suspension point, so that
    the coroutine is resumed accordingly; and the local variables outside the scope
    of that point. So, what does our code do? Well, from a user standpoint, it does
    nothing, but there’s a lot happening in the background. Let’s observe the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Simple demonstration of a coroutine startup](img/Figure_10.02_B20833.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Simple demonstration of a coroutine startup
  prefs: []
  type: TYPE_NORMAL
- en: Remember, by-value parameters are copied or moved in the scope of the coroutine,
    and the by-reference parameters remain as references. This means that the programmer
    should consider their lifetime in the task-caller, so no dangling pointers appear.
    Afterward, the `promise` is constructed and `get_return_object()` is called. The
    result will be returned to the task-caller when the coroutine first suspends.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.2* demonstrates a case where the `promise` returns `suspend_always`
    and we have lazily started a coroutine. The `initial_suspend()` operation resumes
    and, without the knowledge or the context of how to continue, the coroutine will
    never be resumed and will leak. In order to handle this, we need... a `handle`
    object. You can think of the `handle` object as a view. Similar to the relationships
    between the `string_view` object and a `string` object, or a `vector` object and
    a `range` object with a `range view` object, the `handle` object is used to provide
    indirect access to `*this`. Through the `handle` object, we can call `resume()`
    to continue the coroutine’s work. It must be suspended first, or the behavior
    will be undefined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Graph demonstrating a coroutine’s creation and resumption](img/Figure_10.03_B20833.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Graph demonstrating a coroutine’s creation and resumption
  prefs: []
  type: TYPE_NORMAL
- en: The `initial_suspend()` operation is called and the result is handled through
    `co_await`. This is done through the compiler generating additional code in the
    background around the `suspend_never` awaitable – the coroutine is not created
    in a lazy manner as with `suspend_always`, but is immediately started. Both are
    defined in the C++ Standard Library.
  prefs: []
  type: TYPE_NORMAL
- en: The current coroutine does a `co_return` keyword (in `exCoroutine()`). But that
    way, the coroutine body is exited. If we want to use it to produce constantly
    new or the next generated values, then we require the `co_yield` operator. We
    call such a coroutine a `co_yield` operator as `co_await promise.yield_value(<some
    expression>)`. Otherwise, if it simply calls `co_await`, it is a task, as mentioned
    earlier. Now, if we look at *Figure 10**.3* again, using the `co_yield` operator
    will redirect the arrow from *thread-caller in control* to *coroutine execution*,
    thus providing the opportunity to coroutine to continue work. In other words,
    the `co_return` keyword will lead to execution completion, while the `co_yield`
    keyword will just suspend the coroutine temporarily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go a step back and take a look at `co_await` call. Their work is presented
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Graph representing generated invocations after a co_await call](img/Figure_10.04_B20833.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Graph representing generated invocations after a co_await call
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, a private variable of the `Handle` type is used to call the true `resume()`
    function. Let’s check the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `explicit` specifier. In C++ 20, it allows you to be more restrictive
    on constructor calls. That is, it cannot be used for copy tnitialization or implicit
    conversions. Additionally, we keep our `handle` object private. Now, let’s see
    how this might come in handy (markers {1} and {2}, while a wrapper is provided
    to the caller – markers {1} and {3}):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use this code structure to build a fully functional example. We will
    rename the `Task` struct `Generator`, and implement a coroutine with a generator
    functionality. The full code can be found here: [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will increment a variable N number of times through the coroutine. That’s
    why it needs to be able to yield, and we add the following to `Generator`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, getting the next element happens as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceeding with the coroutine body and its creation in the main thread. The
    increment will happen 100,000 times. This example allows the programmer to generate
    data lazily and not use a big portion of the RAM. At the same time, no separate
    thread is used, so the execution remains in the user space without extensive context
    switching:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The shortened version of the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, you probably already understand why it is not that trivial to
    create a simple coroutine application in C++. As a new feature, this facility
    continues to improve and there are new interfaces expected in upcoming C++ versions,
    which should simplify coroutine usage. But this shouldn’t discourage you from
    continuing to use them. This example could be easily extended to other functionalities,
    and you could build up your knowledge step by step. In the next sections, we will
    do exactly this and get the discussion back in the area of system programming.
  prefs: []
  type: TYPE_NORMAL
- en: Network programming and coroutines in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [*Chapter 7*](B20833_07.xhtml#_idTextAnchor101), you learned about the `Generator`
    definition to match the type of the **coroutine**, as discussed earlier. Traditionally,
    that object is made move-only – this allows us to restrict the usage of the coroutine
    wrapper, but in general cases, coroutine objects are non-copyable and non-moveable,
    because the **coroutine frame** is a part of them, and some local variables can
    be references or pointers to other local variables. Thus, let’s extend the structure
    accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This, again, is a very generic pattern that is used in almost every coroutine
    example. You should initially refer to it at [https://en.cppreference.com/w/cpp/language/coroutines](https://en.cppreference.com/w/cpp/language/coroutines).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll notice that the `struct` object is defined as a `template` in order
    to be generic. We overload the `()` operator in order to be able to appropriately
    give the control back to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We also add a behavior during an exception – the application will be terminated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main thread, we create and join two threads – a server and a client.
    Each of them will execute the coroutines for the respective domains. We provide
    a `socket` (marker {9} in the following code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the `sendto()` method. We use a `string_view` object, the same way we
    did in [*Chapter 3*](B20833_03.xhtml#_idTextAnchor047) – the reasoning is primarily
    the safety of the code and the compactness of the data and its size. At the end
    of the loop, we use `co_yield value`, thus providing the number of bytes sent
    to the main thread. The endless loop allows the coroutine to run until truly canceled
    by outer logic – in this, it’s called 10 times, because of the `for` loop in the
    main thread (marker {10} in the following code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The client thread is implemented in a similar fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The server-side coroutine has the following body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The client-side coroutines are implemented in a similar fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The coroutine function calls the `recvfrom()` system call. At the end, instead
    of the bytes received, the message coming from the socket is stored in the `currValue`
    member variable. It’s then printed out in the main thread. We also use the `MSG_DONTWAIT`
    flag. The respective output will be printed out in different ways every time as
    the code is asynchronous. The last part is as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The merging or misplacing of text is to be expected, but it proves the useability
    of coroutines. The shortened version of the output is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The full example can be found at https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we also had the issue of synchronizing parallel threads,
    but the code was not truly parallel every time. For example, waiting for an event
    such as “the resource is accessible” is a matter of concurrency, not parallel
    execution. That said, coroutines are a powerful tool in the shared memory problem,
    too – let’s check it out in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the shared memory problem through coroutines in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the issues we had with **condition variables** was synchronization during
    process startup. In other words, for the producer-consumer example, we didn’t
    know which threads were going to be first. We synchronized the code through a
    condition variable – its **mutex**, together with a predicate in order to handle
    the correct sequence of events. Otherwise, we would’ve risked losing information
    or ending in a **deadlock**. For a good portion of this book’s example preparations,
    we got to this situation, which made the writing experience even better. But coroutines
    provide another way of doing it, which could be more efficient at times and simpler
    to use (after you get used to the interface of coroutines as it is not the easiest
    to grasp).
  prefs: []
  type: TYPE_NORMAL
- en: 'The next example is motivated by the **awaitable-awaiter** pattern. It is similar
    to the condition variable, but it doesn’t use such synchronization primitives.
    Still, the notification signaling is dependent on an atomic variable. We’ll get
    back to the Task coroutine. It will used for handling the receiver end. The full
    example can be found here: [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010).'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The example is inspired by [https://www.modernescpp.com/index.php/c-20-thread-synchronization-with-coroutines/](https://www.modernescpp.com/index.php/c-20-thread-synchronization-with-coroutines/).
  prefs: []
  type: TYPE_NORMAL
- en: 'We reuse the code from the **shared memory** example from [*Chapter 9*](B20833_09.xhtml#_idTextAnchor129):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We align the shared memory and set its size first, then we continue mapping
    the pointer to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'It is really important that the address of `res` is accessible for dereferencing
    inside the coroutine. Otherwise, the code will crash with `Segmentation fault`,
    which is preferable to a dangling pointer. Another remark is that different compilers
    (or environments) will give you different behavior for this code. Before we get
    to the `Event` struct, let’s see what the sender does – again, we step on our
    previous code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we make sure the shared memory is of the correct size and we map the
    pointer to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Initially, the notification flag is set to `false`, meaning that the coroutine
    will not behave as a regular function but is going to be suspended. Then, the
    `waiter` object is loaded, which is `nullptr`, because it’s not previously set.
    Its respective `resume()` operation is not called. The subsequentially performed
    `await_suspend()` function gets the `waiter` state is stored in the `suspended`
    member variable. Later, `notify()` is triggered and it’s executed fully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main thread, an `Event` object is required to synchronize the workflow.
    A shared memory region is defined as well. If `shm_open()` is called inside each
    coroutine, it will not really be shared virtual memory, as the file descriptor
    will access private regions for each of the coroutines. Thus, we will end up with
    `Segmentation fault`. There are two threads, representing the sender and the receiver
    ends. The aforementioned coroutines are called respectively after the threads
    are joined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The receiver’s code is similar, but the `event` object is passed as an argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This example gives you the flexibility to manage your shared resources in a
    concurrent manner. The notification mechanism of awaiter-awaitable will do the
    job without the need for synchronization primitives. We encourage you to try it
    out yourself. In the meantime, we’ll proceed with some final notes on coroutines
    usage in system programming.
  prefs: []
  type: TYPE_NORMAL
- en: Final thoughts on coroutines and their implementations in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The examples earlier were practical, although not so simple. They were useful
    in understanding the sequence that a coroutine’s execution might take. It is good
    to visualize the state graph of coroutines, although we still believe it would
    be confusing for inexperienced developers.
  prefs: []
  type: TYPE_NORMAL
- en: As presented earlier, *Figure 10**.2*, *Figure 10**.3*, and *Figure 10**.4*
    pretty much cover what we’ve already explained through the code examples. It is
    useful to understand how much additional logic is generated around the coroutine
    and its members. Most of it happens in the background, and the system programmer
    only arranges the scheduling. In this chapter’s examples, we did this through
    the `promise` object and awaitables. The fact that the aforementioned figures
    partially represent a coroutine’s execution as a finite state machine should hint
    to you that this is another application where coroutines are useful. They transform
    state machines into first-class objects. Once the coroutine frame is defined,
    much of the logic remains there and it’s hidden from callers. This provides the
    opportunity for system programmers to put aside the concurrent logic for a moment
    and just focus on calling the coroutines through short code snippets, as we did.
    The system behavior code and task scheduling will be simpler and more obvious.
    Thus, much of the power of managing algorithms, parsers, data structure traversals,
    polling, and so on could be interpreted by this technique. Unfortunately, we cannot
    cover everything here, but we believe it’s worthwhile checking these things out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, we’d like to emphasize that coroutines are fairly new to
    the language. As the coroutine interface in C++ is still lacking comfort and simplicity,
    you can find many custom-made coroutine libraries on the internet. We advise you
    to rely only on the trustworthy ones or wait for the next Standard features of
    this facility. It makes more sense to apply those than to implement them anew
    yourself. As you can see, it’s quite a complex concept, and there’s a lot of research
    being done on the matter. For curious readers, we encourage you to spend some
    time learning about the evolution of coroutines in C++, especially in recent years.
    There are three techniques discussed in the C++ Standard – Coroutines TS, Core
    Coroutines, and Resumable expressions. Although just one is currently used in
    the Standard, the three of them deserve attention. A great summary and analysis
    has been done by Geoffrey Romer, Gor Nishanov, Lewis Baker, and Mihail Mihailov
    here: [https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1493r0.pdf](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1493r0.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to check it out. Many of the clarifications we gave in this chapter
    are presented in the document as a great visual comparison of the regular functions
    and coroutines. Meanwhile, we continue to the finish.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this, we’ve covered all the topics of this book. With the upcoming improvements
    of C++23, coroutines and their evolution will be analyzed more and more, especially
    in the system programming domain – and applied there, of course. Although complex
    to understand at first, coroutines allow you to continue sharpening the usage
    of C++ and give you one more instrument to enhance code.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned how to apply them in your concurrent applications,
    but their usefulness is far greater. We are excited about what comes next. We
    expect the `modules` language feature, which we didn’t cover in this book – intentionally
    – to be fully covered by the compilers and be broadly applied. Another interesting
    feature is `std::generator` – a view for the synchronous creation of coroutines
    in C++23\. `std::stacktrace` from a thrown exception, which will help you in code
    debugging. And for easier printing, you’ll be able to use `std::print` as well.
    The monadic interface of `std::expected` will allow you to store either of two
    values. In addition to all this, files will be loaded at compile time as arrays
    through `#embed`.
  prefs: []
  type: TYPE_NORMAL
- en: We’d like to use this opportunity to express our gratitude to you – the reader!
    We hope you found this book useful and will apply parts of it in your daily job.
    We also hope you enjoyed the experience the way we enjoyed writing the book. It
    was a tremendous journey for us, and we’d be glad to share future journeys with
    you. With this, we wish you good fortune in all your projects!
  prefs: []
  type: TYPE_NORMAL
