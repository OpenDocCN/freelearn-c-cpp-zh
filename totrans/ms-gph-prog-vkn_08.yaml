- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding Shadows Using Mesh Shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we added support for multiple lights using clustered
    deferred techniques with the latest innovations.
  prefs: []
  type: TYPE_NORMAL
- en: We added a hard limit of 256 maximum lights, with the possibility for each one
    to be dynamic and unique in its properties.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will add the possibility for each of these lights to cast
    shadows to further enhance the visuals of any asset displayed in Raptor Engine,
    and we will exploit the possibilities given by mesh shaders of having many of
    these lights cast shadows and still be in a reasonable frame time.
  prefs: []
  type: TYPE_NORMAL
- en: We will also have a look at using sparse resources to improve shadow map memory
    usage, moving the possibility of having many shadow-casting lights from something
    almost impossible to something possible and performant with current hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of shadow techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing shadow mapping using mesh shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving shadow memory with Vulkan’s sparse resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter8](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter8)'
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of shadow techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shadows are one of the biggest additions to any rendering framework as they
    really enhance the perception of depth and volume across a scene. Being a phenomenon
    linked to lights, they have been studied in graphics literature for decades, but
    the problem is still far from being solved.
  prefs: []
  type: TYPE_NORMAL
- en: The most used shadow technique right now is shadow mapping, but recently, thanks
    to hardware-enabled ray tracing, ray traced shadows are becoming popular as a
    more realistic solution.
  prefs: []
  type: TYPE_NORMAL
- en: There were some games—especially *Doom 3*—that also used shadow volumes as a
    solution to make lights cast shadows, but they are not used anymore.
  prefs: []
  type: TYPE_NORMAL
- en: Shadow volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Shadow volumes are an old concept, already proposed by Frank Crow in 1977\.
    They are defined as the projection of each vertex of a triangle along the light
    direction and toward infinity, thus creating a volume.
  prefs: []
  type: TYPE_NORMAL
- en: The shadows are sharp, and they require each triangle and each light to process
    accordingly. The most recent implementation uses the stencil buffer, and this
    change enabled it to be used in real time.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with shadow volumes is that they require a lot of geometry work
    and become fill-rate intensive, and in this case, shadow maps are a clear winner.
  prefs: []
  type: TYPE_NORMAL
- en: Shadow mapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most used technique of all, first appearing around 1978, shadow mapping
    is the industry standard in both real-time and offline rendering. The idea behind
    shadow mapping is to render the scene from the perspective of the light and save
    the depth of each pixel.
  prefs: []
  type: TYPE_NORMAL
- en: After that, when rendering the scene from the camera point of view, the pixel
    position can be converted to the shadow coordinate system and tested against the
    corresponding pixel in the shadow map to see whether the current pixel is in shadow
    or not.
  prefs: []
  type: TYPE_NORMAL
- en: The resolution of a shadow map is very important, as well as what type of information
    is saved inside it. With time, filters started to appear, using mathematical tools
    to add the possibility to soften the shadows, or adding calculations to harden
    the shadows the closer they are to the blocker geometry.
  prefs: []
  type: TYPE_NORMAL
- en: Shadow mapping suffers from a lot of issues as well, but being the de facto
    standard, many techniques are used to alleviate them. Some problems that can be
    encountered are aliasing, shadow acne, and Peter Panning.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a robust shadow solution is one of the most intricate steps of a rendering
    engine and normally requires a lot of trial and error and custom solutions tailored
    to different scenes and situations.
  prefs: []
  type: TYPE_NORMAL
- en: Raytraced shadows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the last few years, raytracing—a technique that uses rays to trace any kind
    of rendering information—got hardware support on customer GPUs, enabling rendering
    programmers to use a different scene representation to trace rays and enhance
    the look of different rendering phenomena.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at raytracing toward the end of the book, but for now, it is sufficient
    to say that using this special representation of the scene (different from mesh
    and meshlets we already use), it is possible to trace, for each pixel on the screen,
    one ray toward each light affecting the pixel and calculate the final shadow contribution
    to that pixel.
  prefs: []
  type: TYPE_NORMAL
- en: It is the most advanced and realistic form of a shadow, but still, performance-wise—despite
    the hardware support—it can be slow, and the diffusion of GPUs supporting it is
    not as elevated as needed to make it the new standard.
  prefs: []
  type: TYPE_NORMAL
- en: That is why shadow mapping is still the standard—any hardware, including mobile
    phones, can render shadow maps, and they can still achieve a convincing look.
    Based on this consideration, we chose to implement shadow mapping as the main
    shadow technique for Raptor Engine.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing shadow mapping using mesh shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have looked at the different ways to render a shadow, we will describe
    the algorithm and the implementation’s detail used to render many shadow maps
    at once leveraging the mesh shader power.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will give an overview of the algorithm. What we are trying
    to achieve is to render shadows using meshlets and mesh shaders, but this will
    require some compute work to generate commands to actually draw the meshlets.
  prefs: []
  type: TYPE_NORMAL
- en: We will draw shadows coming from point lights, and we will use cubemaps as textures
    to store the necessary information. We will talk about cubemaps in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Back to the algorithm, the first step will be to cull mesh instances against
    lights. This is done in a compute shader and will save a per-light list of visible
    mesh instances. Mesh instances are used to retrieve associated meshes later on,
    and per-meshlet culling will be performed using task shaders later on.
  prefs: []
  type: TYPE_NORMAL
- en: The second step is to write indirect draw meshlet arguments to perform the actual
    rendering of meshlets into shadow maps, again in a compute shader. There is a
    caveat here that will be explained in the *A note about multiview* *rendering*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: The third step is to draw meshlets using indirect mesh shaders, drawing into
    the actual shadow maps.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a layered cubemap shadow texture as we are drawing, with each layer
    corresponding to each light.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth and final step is to sample the shadow texture when lighting the
    scene.
  prefs: []
  type: TYPE_NORMAL
- en: We will render shadows with almost no filtering, as the focus of this chapter
    is on mesh shader-driven shadows, but we will give links to filtering options
    at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a visual overview of the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Algorithm overview](img/B18395_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Algorithm overview
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will talk about cubemap shadows, used to store shadows
    from point lights.
  prefs: []
  type: TYPE_NORMAL
- en: Cubemap shadows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Cubemaps** are a general way of mapping a 3D direction (*x*, *y*, *z*) with
    six faces containing image information.'
  prefs: []
  type: TYPE_NORMAL
- en: They are used not only for shadow rendering but in general to draw environments
    as well (such as sky boxes, or far distant landscapes), and they are so standardized
    that even hardware contains support for cubemap sampling and filtering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each direction of the cubemap has normally a name and an orientation and a
    single texture associated with it:'
  prefs: []
  type: TYPE_NORMAL
- en: Positive *x*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative *x*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Positive *y*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative *y*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Positive *z*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative *z*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When rendering to a face, we need to provide matrices that will look in the
    correct direction.
  prefs: []
  type: TYPE_NORMAL
- en: When reading, a single vector will be translated (behind the scenes) to the
    corresponding image. For shadows, the process will be manual, as we will provide
    for each face a view projection matrix that will be read by the meshlets to direct
    the rendering to the correct face.
  prefs: []
  type: TYPE_NORMAL
- en: A caveat for that also is that we will need to duplicate the drawing commands
    for each face, as one vertex can be rendered only to one image view associated
    with each face.
  prefs: []
  type: TYPE_NORMAL
- en: There are some extensions that can associate a vertex with more than one image,
    as we will see in the next section, but their support in mesh shaders at the time
    of writing is still limited.
  prefs: []
  type: TYPE_NORMAL
- en: Another important aspect of the proposed shadow rendering is that we will use
    an array of cubemaps so that we can both read and write every shadow using layered
    rendering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the unrolled cubemap shadow rendering for one point light, with a texture
    for each cubemap face:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – The six cubemap faces rendered from the light point of view](img/B18395_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – The six cubemap faces rendered from the light point of view
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, only the positive *Z* is rendering something. We will provide
    some culling mechanisms to avoid rendering meshlets in empty cubemap faces.
  prefs: []
  type: TYPE_NORMAL
- en: A note about multiview rendering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As written in the previous section, there is an extension that helps with rendering
    a vertex on more than a cubemap face: Multiview Rendering. This extension is widely
    used in virtual reality applications to render a vertex in both the views of a
    stereographic projection and can be used as well with cubemaps.'
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, mesh shaders don’t have a proper extension supported,
    so we are using the NVIDIA Vulkan extension, and this is not supporting Multiview
    Rendering properly, thus we are manually generating commands for each face and
    drawing using those commands.
  prefs: []
  type: TYPE_NORMAL
- en: We are aware that a multi-vendor extension is on the way, so we will update
    the code accordingly, but the core algorithm does not change, as multiview rendering
    is more of an optimization.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to see the algorithm steps.
  prefs: []
  type: TYPE_NORMAL
- en: Per-light mesh instance culling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step in preparing for shadow rendering is a coarse grain culling done
    in a compute shader. In Raptor, we have both mesh and meshlet representations,
    thus we can use meshes and their bounding volumes as a *higher hierarchy* linked
    to meshlets.
  prefs: []
  type: TYPE_NORMAL
- en: We will perform a very simple light sphere to mesh sphere intersection, and
    if intersecting, we will add the corresponding meshlets. The first thing to know
    is that we will dispatch this compute shader using mesh instances and light together,
    so we will calculate for each light and for each mesh instance if the light influences
    the mesh instance.
  prefs: []
  type: TYPE_NORMAL
- en: We will then output a list of per-light meshlet instances, defined as both a
    mesh instance and global meshlet index combined. We will also write the per-light
    meshlet instances count, to skip empty lights and to correctly read the indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is thus to reset the per-light counts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will then skip threads that will work on out-of-bounds lights. When we dispatch,
    we round up the numbers after dividing by 32, so some threads can be working on
    empty lights.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dispatch of this compute will be done by linking each mesh instance with
    each light, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Organization of the command buffer to render the cubemaps for
    multiple lights using a single draw call](img/B18395_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Organization of the command buffer to render the cubemaps for multiple
    lights using a single draw call
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the early out and light index calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In a similar way, we calculate the mesh instance index, and *early out* again
    if the dispatch rounding up is too much:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can finally gather the bounding sphere of the mesh instance and the model
    and simply calculate the world space bounding sphere:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we know that the mesh instance is influenced by the light, so
    increase the per-light meshlet count and add all the indices necessary to draw
    the meshlets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We will end up writing both the mesh instance index—to retrieve the world matrix—and
    the global meshlet index—to retrieve meshlet data in the following task shader.
    But before that, we need to generate an indirect draw commands list, and we will
    see that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Also, based on the scene, we have a maximum number of meshlet instances, and
    we allocate them upfront for each light.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect draw commands generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This compute shader will generate a list of indirect commands for each light.
    We will use the last element of the per-light meshlet instances’ **Shader Storage
    Buffer Object** (**SSBO**) to atomically count the number of indirect commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, reset `atomic int` used for the indirect commands count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will early out execution for rounded-up light indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can finally write the indirect data and the packed light index, only if the
    light contains visible meshes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we write six commands, one for each cubemap face:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We now have a list of indirect drawing commands, six for each light. We will
    perform further culling in the task shader, shown in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Shadow cubemap face culling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the indirect drawing task shader, we will add a mechanism to cull a meshlet
    against a cubemap to optimize the rendering. To do that, we have a utility method
    that will calculate, given a cubemap and an axis-aligned bounding box, which face
    will be visible in the cubemap. It is using cubemap face normals to calculate
    whether the center and extents are enclosed in the four planes used to define
    one of the six cubemap faces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These methods return a bitmask with each of the six bits set as `1` when the
    current axis-aligned bounding box is visible in that face.
  prefs: []
  type: TYPE_NORMAL
- en: Meshlet shadow rendering – task shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have this utility method in place, we can look at the task shader.
    We changed some things with the other task shaders to accommodate the indirect
    drawing and to use layered rendering to write on different cubemaps.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will pass `uint` to the mesh shader that packs a light and a face index
    to retrieve the corresponding cubemap view projection matrix and write to the
    correct layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The meshlet calculation is tricky, as indices need to be calculated globally.
    We first calculate the meshlet index global to the indirect draw:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We then extrapolate the light index and the read offset in the meshlet instances
    written in the culling compute shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can finally read the correct meshlet and mesh instance indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we calculate the face index, and we can start the culling phase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Culling is performed similarly to previous task shaders, but we added also
    per-face culling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point of the shader we write each visible meshlet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, we write the packed light and face index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will see the mesh shader.
  prefs: []
  type: TYPE_NORMAL
- en: Meshlet shadow rendering – mesh shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this mesh shader, we will need to retrieve the layer index in the cubemap
    array to write to, and the light index to read the correct view-projection transform.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that each face has its own transform, as we effectively
    render to each face separately.
  prefs: []
  type: TYPE_NORMAL
- en: Note that each face of the cubemap is considered a layer, thus the first cubemap
    will be rendered in layers 0-5, the second in layers 6-11, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we write the layer index for each primitive. The usage of these offsets
    is to avoid bank conflict when writing, as seen on previous shaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: After this mesh shader rendering of shadows is complete, as there is no fragment
    shader associated. We can now read the generated shadow texture in the lighting
    shader, as explained in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Shadow map sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given that we are just using hard shadow maps without filtering, the code to
    sample it is standard cubemap code. We calculate the world-to-light vector and
    use it to sample the cubemap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Being a layered cubemap, we need both the 3D direction vector and the layer
    index, which we saved in the light itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We then convert the depth to raw depth values with the `vector_to_depth_value`
    utility method, which takes the major axis from the light vector and converts
    it to raw depth so that we can compare the value read from the cubemap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The `vector_to_depth_value` method is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: It takes the major axis from the direction vector and converts it to the raw
    depth using the formula coming from the projection matrix. This value is now usable
    with any depth value stored in a shadow map.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of shadow coming from a point light:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Shadows produced by a single point light in the scene](img/B18395_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Shadows produced by a single point light in the scene
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, shadows are a great improvement in rendering, giving the viewer
    a fundamental visual cue of an object’s relationship with its environment.
  prefs: []
  type: TYPE_NORMAL
- en: Until here, we saw how to implement mesh shader-based shadows, but there is
    still room for improvement, especially in memory usage. Right now, this solution
    allocates upfront a single cubemap for each light, and the memory can become big
    quickly if we consider that we have six textures for each light.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at a solution to lower the shadow map memory using sparse resources
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Improving shadow memory with Vulkan’s sparse resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned at the end of the last section, we currently allocate the full
    memory for each cubemap for all the lights. Depending on the screen size of the
    light, we might be wasting memory as distant and small lights won’t be able to
    take advantage of the high resolution of the shadow map.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, we have implemented a technique that allows us to dynamically
    determine the resolution of each cubemap based on the camera position. With this
    information, we can then manage a sparse texture and re-assign its memory at runtime
    depending on the requirements for a given frame.
  prefs: []
  type: TYPE_NORMAL
- en: Sparse textures (sometimes also referred to as **virtual textures**) can be
    implemented manually, but luckily, they are supported natively in Vulkan. We are
    now going to describe how to use the Vulkan API to implement them.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and allocating sparse textures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regular resources in Vulkan must be bound to a single memory allocation, and
    it’s not possible to bind a given resource to a different allocation. This works
    well for resources that are known at runtime and that we don’t expect to change.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, when using cubemaps with a dynamic resolution, we need to be able
    to bind different portions of memory to a given resource. Vulkan exposes two methods
    to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: Sparse resources allow us to bind a resource to non-contiguous memory allocations,
    but the full resource needs to be bound.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sparse residency allows us to partially bind a resource to different memory
    allocations. This is what we need for our implementation, as we are likely to
    use only a subsection of each layer of a cubemap.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both methods allow users to re-bind a resource to different allocations at
    runtime. The first step needed to start using sparse resources is to pass the
    right flag when creating resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are requesting a resource that supports sparse residency. Once an image
    is created, we don’t need to immediately allocate memory for it. Instead, we are
    going to allocate a region of memory from which we will sub-allocate individual
    pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to note that Vulkan has strict requirements for the size of
    individual pages. These are the required sizes taken from the Vulkan specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.1 – Sparse block sizes for images](img/B18395_08_Table_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.1 – Sparse block sizes for images
  prefs: []
  type: TYPE_NORMAL
- en: 'We will need this information to determine how many pages to allocate for a
    cubemap of a given size. We can retrieve the details for a given image with the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The information for this structure is already available in our texture data
    structure. Next, we retrieve the block size for the given image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'With this information, we can now allocate a pool of pages. First, we retrieve
    the memory requirements for the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This is the same code we would use for a regular texture; however, `memory_requirements.alignment`
    will contain the block size for the given image format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we compute the number of blocks we need to allocate for the given pool
    size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The final step is to allocate the pages that we will use later to write into
    our cubemaps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `vmaAllocateMemoryPages`, to allocate multiple pages at once.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have allocated the memory for our shadow maps, we need to determine
    the resolution for each cubemap.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing per-light shadow memory usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To determine the resolution of the cubemap for a given light, we need to find
    how much influence it has on the scene. Intuitively, a more distant light will
    have less influence, depending on its radius (at least for point lights), but
    we need to quantify its amount of influence. We have implemented a solution similar
    to the one proposed in the *More Efficient Virtual Shadow Maps for Many* *Lights*
    paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to reuse the concept introduced in the previous chapter: clusters.
    We subdivide the screen into tiles and *slice* the frustum on the *z* axis. This
    will give us smaller frustums (approximated by axis-aligned bounding boxes) that
    we will use to determine which regions are covered by a given light.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the code to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by computing the bounding box for each light in camera space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we iterate over the tiles and each depth slice to compute each cluster
    position and size. We start by computing the camera space position of each tile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then need to determine the minimum and maximum depth for each slice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we combine both values to retrieve the position and size of the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have obtained the cluster, we iterate over each light to determine
    whether it covers the cluster and the projection of the cluster onto the light;
    we’ll clarify what this means in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is a box intersection test between the light and the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If they do intersect, we compute an approximation of the projected area of
    the light onto the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: The idea is to take the distance between the light and cluster center in screen
    space, compute the solid angle subtended by the cluster onto the light position,
    and compute the resolution of the cubemap using the size in pixels of the cluster.
    We refer you to the paper for more details.
  prefs: []
  type: TYPE_NORMAL
- en: We keep the maximum resolution, and we will use the computed value to bind the
    memory for each cubemap.
  prefs: []
  type: TYPE_NORMAL
- en: Rendering into a sparse shadow map
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have determined the resolution of the cubemaps for a given frame,
    we need to assign the pre-allocated pages to our textures:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to record which pages are assigned to each image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We start by getting the details for the allocation that we are going to use
    for a given block, as we need to access the `VkDeviceMemory` handle and the offset
    into the pool it was allocated from.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we compute the texture offset for each block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we record this information into a `VkSparseImageMemoryBind` data structure
    that will be used later to update the memory bound to the cubemap texture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It’s important to note that, as we mentioned previously, we only use one image
    with many layers. The layer variable determines which layer each allocation will
    belong to. Please refer to the full code for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we record which image these pages will be bound to:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`array_offset` is an offset into the `pending_sparse_queue_binds` array so
    that we can store all pending allocations in a single array.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have recorded the list of allocation updates, we need to submit
    them to a queue for them to be executed by the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we populate a `VkSparseImageMemoryBindInfo` structure for each layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we submit all pending binding operations to the main queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It’s important to note that it’s the responsibility of the user to make sure
    this operation is completed before accessing the resources whose allocations we
    just updated. We achieve this by signaling a semaphore, `vulkan_bind_semaphore`,
    which will then be waited on by the main rendering work submission.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the queue we call `vkQueueBindSparse` on must have
    the `VK_QUEUE_SPARSE_BINDING_BIT` flag.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have covered the steps necessary to allocate and use sparse
    textures. We first explained how sparse textures work and why they are useful
    for our cubemap use case.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we illustrated the algorithm we used to dynamically determine the resolution
    of each cubemap based on each light contribution to the scene. Finally, we demonstrated
    how to use the Vulkan API to bind memory to sparse resources.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we extended our lighting system to support many point lights
    with an efficient implementation. We started with a brief history of shadow algorithms,
    and their benefits and shortcomings, up until some of the most recent techniques
    that take advantage of raytracing hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we covered our implementation of shadows for many point lights. We explained
    how cubemaps are generated for each light and the optimizations we implemented
    to make the algorithm scale to many lights. In particular, we highlighted the
    culling method we reused from the main geometry pass and the use of a single indirect
    draw call for each light.
  prefs: []
  type: TYPE_NORMAL
- en: In the last section, we introduced sparse textures, a technique that allows
    us to dynamically bind memory to a given resource. We highlighted the algorithm
    we used to determine the contribution of each point light to the scene and how
    we use that information to determine the resolution of each cubemap. Finally,
    we demonstrated how to use sparse resources with the Vulkan API.
  prefs: []
  type: TYPE_NORMAL
- en: 'While we only covered point lights in this chapter, some of the techniques
    can be reused with other types of lights. Some steps could also be optimized further:
    for instance, it’s possible to further reduce the cubemap resolution to account
    only for the area where geometry is visible.'
  prefs: []
  type: TYPE_NORMAL
- en: The cluster computation is currently done on the CPU for clarity and to avoid
    having to read back the cluster data from the GPU, which could be a slow operation,
    but it might be worth moving the implementation to the GPU. We encourage you to
    experiment with the code and add more features!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The book *Real-Time Shadows* provides a good overview of many techniques to
    implement shadows, many of which are still in use today.
  prefs: []
  type: TYPE_NORMAL
- en: '*GPU Pro 360 Guide to Shadows* collects articles from the *GPU Pro* series
    that are focused on shadows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'An interesting technique described in the book is called tetrahedron shadow
    mapping: the idea is to project the shadow map to a tetrahedron and then unwrap
    it to a single texture.'
  prefs: []
  type: TYPE_NORMAL
- en: The original concept was introduced in the *Shadow Mapping for Omnidirectional
    Light Using Tetrahedron Mapping* chapter (originally published in *GPU Pro*) and
    later expanded in *Tile-based Omnidirectional Shadows* (originally published in
    *GPU* *Pro 6*).
  prefs: []
  type: TYPE_NORMAL
- en: 'For more details, we refer you to the code provided by the author: [http://www.hd-prg.com/tileBasedShadows.xhtml](http://www.hd-prg.com/tileBasedShadows.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our sparse texture implementation is based on this SIGGRAPH presentation: [https://efficientshading.com/wp-content/uploads/s2015_shadows.pdf](https://efficientshading.com/wp-content/uploads/s2015_shadows.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This expands on their original paper, found here: [http://newq.net/dl/pub/MoreEfficientClusteredShadowsPreprint.pdf.](http://newq.net/dl/pub/MoreEfficientClusteredShadowsPreprint.pdf%0D)'
  prefs: []
  type: TYPE_NORMAL
- en: While we haven’t implemented it in this chapter, shadow map caching is an important
    technique to reduce the cost of computing shadow maps and amortize the shadow
    map updates over several frames.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good starting point is this presentation: [https://www.activision.com/cdn/research/2017_DD_Rendering_of_COD_IW.pdf](https://www.activision.com/cdn/research/2017_DD_Rendering_of_COD_IW.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our cluster computation closely follows the one presented in this article:
    [http://www.aortiz.me/2018/12/21/CG.xhtml#part-2.](http://www.aortiz.me/2018/12/21/CG.xhtml#part-2%0D)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Vulkan specification provides many more details on how to use the API for
    sparse resources: [https://registry.khronos.org/vulkan/specs/1.2-extensions/html/vkspec.xhtml#sparsememory](https://registry.khronos.org/vulkan/specs/1.2-extensions/html/vkspec.xhtml#sparsememory).'
  prefs: []
  type: TYPE_NORMAL
