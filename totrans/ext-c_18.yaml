- en: Chapter 18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Process Synchronization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter continues our discussion in the previous chapter, *Process Execution*,
    and our main focus will be on process synchronization. Control mechanisms in multi-process
    programs are different from the control techniques we met in multi-threaded programs.
    It is not just the memory which differs; there are other factors that you cannot
    find in a multi-threaded program, and they exist in a multi-process environment.
  prefs: []
  type: TYPE_NORMAL
- en: Despite threads that are bound to a process, processes can live freely on any
    machine, with any operating system, located anywhere within a network as big as
    the internet. As you might imagine, things become complicated. It will not be
    easy to synchronize a number of processes in such a distributed system.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is dedicated to process synchronization happening in just one machine.
    In other words, it mainly talks about single-host synchronization and the techniques
    around it. We discuss briefly the process synchronization in distributed systems,
    but we won't go into extensive detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we describe multi-process software where all processes are being run
    on the same machine. We introduce the techniques that are available in single-host
    environments. We use the knowledge from the previous chapter in order to give
    some examples that demonstrate these techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our first attempt to synchronize a number of processes, we use named POSIX
    semaphores. We explain how they should be used and then we give an example that
    resolves a race condition issue we encountered in the previous chapters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, we talk about named POSIX mutexes and we show how we can use shared
    memory regions to have named mutexes up and working. As an example, we solve the
    same race condition resolved by semaphores, this time using named mutexes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the last technique to synchronize a number of processes, we discuss named
    POSIX condition variables. Like named mutexes, they need to be put in a shared
    memory region to become accessible to a number of processes. We give a thorough
    example regarding this technique which shows how named POSIX condition variables
    can be used to synchronize a multi-process system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As our final discussion in this chapter, we briefly talk about the multi-process
    systems which have their own processes distributed around a network. We discuss
    their features and the problematic differences that they have in comparison to
    a single-host multi-process system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us start the chapter with talking a bit more about single-host concurrency
    control and what techniques are available as part of it.
  prefs: []
  type: TYPE_NORMAL
- en: Single-host concurrency control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is pretty common to be in situations where there are a number of processes
    running on a single machine that, at the same time, need to have simultaneous
    access to a shared resource. Since all of the processes are running within the
    same operating system, they have access to all the facilities which their operating
    system provides.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we show how to use some of these facilities to create a control
    mechanism that synchronizes the processes. Shared memory plays a key role in most
    of these control mechanisms; therefore, we heavily rely on what we explained about
    shared memory in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of POSIX-provided control mechanisms that can be employed
    while all processes are running on the same POSIX-compliant machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Named POSIX semaphores**: The same POSIX semaphores that we explained in
    *Chapter 16*, *Thread Synchronization*, but with one difference: they have a name
    now and can be used globally throughout the system. In other words, they are not
    *anonymous* or *private* semaphores anymore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Named mutexes**: Again, the same POSIX mutexes with the same properties which
    were explained in *Chapter 16*, *Thread Synchronization*, but now named and can
    be used throughout the system. These mutexes should be placed inside a shared
    memory in order to be available to multiple processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Named condition variables**: The same POSIX condition variables which we
    explained in *Chapter 16*, *Thread Synchronization*, but like mutexes, they should
    be placed inside a shared memory object in order to be available to a number of
    processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the upcoming sections, we discuss all the above techniques and give examples
    to demonstrate how they work. In the following section, we are going to discuss
    named POSIX semaphores.
  prefs: []
  type: TYPE_NORMAL
- en: Named POSIX semaphores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you saw in *Chapter 16*, *Thread Synchronization*, semaphores are the main
    tool to synchronize a number of concurrent tasks. We saw them in multi-threaded
    programs and saw how they help to overcome the concurrency issues.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to show how they can be used among some processes.
    *Example 18.1* shows how to use a POSIX semaphore to solve the data races we encountered
    in *examples 17.6* and *17.7* given in the previous chapter, *Process Execution*.
    The example is remarkably similar to *example 17.6*, and it again uses a shared
    memory region for storing the shared counter variable. But it uses named semaphores
    to synchronize the access to the shared counter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code boxes show the way that we use a named semaphore to synchronize
    two processes while accessing a shared variable. The following code box shows
    the global declarations of *example 18.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-1 [ExtremeC_examples_chapter18_1.c]: The global declarations of
    example 18.1'
  prefs: []
  type: TYPE_NORMAL
- en: In *Code Box 18-1*, we have declared a global counter and a global pointer to
    a semaphore object which will be set later. This pointer will be used by both
    parent and child processes to have synchronized access to the shared counter,
    addressed by the counter pointer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the function definitions supposed to do the actual
    process synchronization. Some of the definitions are the same as we had in *example
    17.6* and those lines are removed from the following code box:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-2 [ExtremeC_examples_chapter18_1.c]: The definition of synchronization
    functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have added two new functions compared to *example 17.6*: `init_control_mechanism`
    and `shutdown_control_mechanism`. We also made some changes to the `inc_counter`
    function (shown in *Code Box 18-3*) to use the semaphore and form a critical section
    inside.'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the `init_control_mechanism` and `shutdown_control_mechanism` functions,
    we are using a similar API to the shared memory API to open, close, and unlink
    a named semaphore.
  prefs: []
  type: TYPE_NORMAL
- en: The functions `sem_open`, `sem_close`, and `sem_unlink` can be seen as similar
    to `shm_open`, `shm_close`, and `shm_unlink`. There is one difference and that
    is that the function `sem_open` returns a semaphore pointer instead of a file
    descriptor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the API used for working with the semaphore in this example is the
    same as we have seen before, so the rest of the code can remain unchanged as with
    *example 17.6*. In this example, the semaphore is initialized with value `1`,
    which makes it a mutex. The following code box shows the critical section and
    how the semaphore is used to synchronize the read and write operations performed
    on the shared counter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-3 [ExtremeC_examples_chapter18_1.c]: The critical section where
    the shared counter is being incremented'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing to *example 17.6*, in the function `inc_counter`, the functions `sem_wait`
    and `sem_post` are used to enter and exit the critical sections, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code box, you can see the function `main`. It is almost the
    same as *example 17.6* and we only see some changes in the initial and final parts,
    and that is in accordance with the addition of two new functions seen in *Code
    Box 18-2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-4 [ExtremeC_examples_chapter18_1.c]: The main function of example
    18.1'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following shell box, you can see the output for two successive runs
    of *example 18.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-1: Building in Linux and two successive runs of example 18.1'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we need to link the above code with the `pthread` library because
    we are using POSIX semaphores. We need also to link it with the `rt` library in
    Linux in order to use the shared memories.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding output is clear. Sometimes the child process gets the CPU first
    and increments the counter, and sometimes the parent process does so. There is
    no time when both enter the critical section, and therefore they satisfy the data
    integrity of the shared counter.
  prefs: []
  type: TYPE_NORMAL
- en: Note that it is not required to use the fork API in order to use named semaphores.
    Completely separated processes, which are not parent and child, can still open
    and use the same semaphores if they are run on the same machine and inside the
    same operating system. In *example 18.3*, we show how this is possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the final note in this section, you should know that we have two types of
    named semaphores in Unix-like operating systems. One is *System V Semaphores*,
    and the other is *POSIX semaphores*. In this section, we explained the POSIX semaphores
    because they have a better reputation for their nice API and performance. The
    following link is a Stack Overflow question which nicely explains the differences
    between System V semaphores and POSI[X semaphores: https://stackoverflow.com/questions/368322/differences-between-system-v-and-po](https://stackoverflow.com/questions/368322/differences-between-system-v-and-posix-semaphores)six-semaphores.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:**'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Windows is not POSIX-compliant in terms of using semaphores, and it
    has its own API to create and manage semaphores.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we discuss named mutexes. In short, named mutexes are ordinary
    mutex objects that are put into a shared memory region.
  prefs: []
  type: TYPE_NORMAL
- en: Named mutexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: POSIX mutexes work simply in multi-threaded programs; we demonstrated this in
    *Chapter 16*, *Thread Synchronization*. This would not be the case with regard
    to multiple process environments, however. To have a mutex work among a number
    of processes, it would need to be defined within a place that is accessible to
    all of them.
  prefs: []
  type: TYPE_NORMAL
- en: The best choice for a shared place such as this is a shared memory region. Therefore,
    to have a mutex that works in a multi-process environment, it should be distributed
    in a shared memory region.
  prefs: []
  type: TYPE_NORMAL
- en: The first example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following example, *example 18.2*, is a clone of *example 18.1*, but it
    solves the potential race condition using named mutexes instead of named semaphores.
    It also shows how to make a shared memory region and use it to store a shared
    mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Since each shared memory object has a global name, a mutex stored in a shared
    memory region can be considered *named* and can be accessed by other processes
    throughout the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code box shows the declarations required for *example 18.2*.
    It shows what is needed for having a shared mutex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-5 [ExtremeC_examples_chapter18_2.c]: The global declarations of
    example 18.2'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, we have declared:'
  prefs: []
  type: TYPE_NORMAL
- en: A global file descriptor for pointing to a shared memory region that is meant
    to store the shared counter variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A global file descriptor for the shared memory region storing the shared mutex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pointer to the shared counter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pointer to the shared mutex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These variables will be populated accordingly by the upcoming logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code boxes show all the functions we had in *example 18.1*, but
    as you see, the definitions are updated to work with a named mutex instead of
    a named semaphore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-6 [ExtremeC_examples_chapter18_2.c]: The function init_control_mechanism
    in example 18.2'
  prefs: []
  type: TYPE_NORMAL
- en: As part of the function `init_control_mechanism`, we have created a new shared
    memory object named `/mutex0`. The size of the shared memory region is initialized
    to `sizeof(pthread_mutex_t)` which shows our intention to share a POSIX mutex
    object there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following that, we get a pointer to the shared memory region. Now we have a
    mutex which is allocated from the shared memory, but it still needs to be initialized.
    The next step is therefore to initialize the mutex object using the function `pthread_mutex_init`,
    with attributes that indicate that the mutex object should be shared and accessible
    by other processes. This is especially important; otherwise, the mutex does not
    work in a multi-process environment, even though it is placed inside a shared
    memory region. As you have seen in the preceding code box and as part of the function
    `init_control_mechanism`, we have set the attribute `PTHREAD_PROCESS_SHARED` to
    mark the mutex as shared. Let''s look at the next function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-7 [ExtremeC_examples_chapter18_2.c]: The function destroy_control_mechanism
    in example 18.2'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the function `destroy_control_mechanism` we destroy the mutex object, and
    after that we close and unlink its underlying shared memory region. This is the
    same way that we destroy an ordinary shared memory object. Let''s continue with
    other codes in the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-8 [ExtremeC_examples_chapter18_2.c]: These functions are the same
    as we have seen in example 18.1'
  prefs: []
  type: TYPE_NORMAL
- en: As you see, the preceding functions are not changed at all and they are the
    same as we had in *example 18.1*. Let's look at the critical section inside the
    function `inc_counter` which now uses a named mutex instead of a named semaphore.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-9 [ExtremeC_examples_chapter18_2.c]: The critical section now uses
    a named mutex to protect the shared counter'
  prefs: []
  type: TYPE_NORMAL
- en: Generally, as you see in the preceding code boxes, a few places are different
    from *example 18.1*, and we have had to change only three functions greatly. For
    instance, the function `main` has not changed at all, and it is the same as in
    *example 18.1*. This is simply because we have used a different control mechanism
    in comparison to *example 18.1*, and the remaining logic is the same.
  prefs: []
  type: TYPE_NORMAL
- en: As the final note about *Code Box 18-9*, in the function `inc_counter`, we have
    used the mutex object exactly as we did in a multi-threaded program. The API is
    the same, and it is designed in a way that mutexes can be used both in multi-threaded
    and multi-process environments using the same API. This is a great feature of
    POSIX mutexes because it enables us to use the same written code in both multi-threaded
    and multi-process environments when consuming these objects – while of course,
    the initialization and destruction can be different.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the preceding code is very similar to what we observed for *example
    18.1*. While the shared counter is protected by a mutex in this example, it was
    being protected by a semaphore in the previous example. The semaphore used in
    the previous example was actually a binary semaphore, and as we have explained
    in *Chapter 16*, *Thread Synchronization*, a binary semaphore can mimic a mutex.
    Therefore, not much is new in *example 18.2*, apart from replacing the binary
    semaphore with a mutex.
  prefs: []
  type: TYPE_NORMAL
- en: The second example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The named shared memories and mutexes can be used throughout the system by any
    process. It is not mandatory to have a forked process to be able to use these
    objects. The following example, *example 18.3*, tries to show how we can use a
    shared mutex and a shared memory to simultaneously terminate a number of processes
    that are all running at the same time. We expect to have all processes terminated
    after pressing the key combination `Ctrl` + `C` in only one of them.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the code is going to be provided in multiple steps. The comments related
    to each step are provided right after it. Let's present the first step.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Global declarations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example, we write a single source file that can be compiled and executed
    multiple times to create multiple processes. The processes use some shared memory
    regions to synchronize their execution. One of the processes is elected to be
    the owner of the shared memory regions and manages their creation and destruction.
    Other processes just use the created shared memories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is going to declare some global objects that we need throughout
    the code. We will initialize them later on in the code. Note that the global variables
    defined in the following code box, such as `mutex`, are not actually shared between
    the processes. They have these variables in their own memory space but each of
    the processes maps their own global variable to the objects or variables located
    in the various shared memory regions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-10 [ExtremeC_examples_chapter18_3.c]: The global declaration in
    example 18.3'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, we can see the global declarations used in the code.
    We are going to use a shared flag to let the processes know about the cancellation
    signal. Note that, in this example, we are going to take the busy-wait approach
    to wait for the cancellation flag to become `true`.
  prefs: []
  type: TYPE_NORMAL
- en: We have a dedicated shared memory object for the cancellation flag and another
    shared memory object for the mutex protecting the flag as we did in *example 18.2*.
    Note that we could construct a single structure and define both the cancellation
    flag and the mutex object as its fields, and then use a single shared memory region
    to store them. But we have chosen to use separate shared memory regions to fulfill
    our purpose.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, one important note about the shared memory objects is that
    the cleanup should be performed by the process which has created and initialized
    them in the first place. Since all processes are using the same code, somehow,
    we need to know which process has created a certain shared memory object and make
    that process the owner of that object. Then, while cleaning up the objects, only
    the owner process can proceed and do the actual cleanup. Therefore, we had to
    declare two Boolean variables for this purpose: `mutex_owner` and `cancel_flag_shm_owner`.'
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Cancellation flag's shared memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following code box shows the initialization of the shared memory region
    dedicated to the cancellation flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-11 [ExtremeC_examples_chapter18_3.c]: Initialization of the cancellation
    flag''s shared memory'
  prefs: []
  type: TYPE_NORMAL
- en: The approach we took is different from what we did in *example 18.2*. That's
    because whenever a new process is run, it should check whether the shared memory
    object has already been created by another process. Note that we are not using
    the fork API to create new processes as part of this example and the user can
    use their shell and start a new process at will.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, a new process first tries to open the shared memory region
    by only providing the flag `O_RDWR`. If it succeeds, then it's a sign that the
    current process is not the owner of that region, and it proceeds with mapping
    the shared memory region. If it fails, it means that the shared memory region
    does not exist, and it is an indication that the current process should create
    the region and becomes its owner. So, it proceeds and tries to open the region
    with different flags; `O_CREAT` and `O_EXCL`. These flags create a shared memory
    object if it does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: If the creation succeeds, the current process is the owner, and it continues
    by truncating and mapping the shared memory region.
  prefs: []
  type: TYPE_NORMAL
- en: There is a small chance that between the two successive calls of the `shm_open`
    function in the previous scenario, another process creates the same shared memory
    region, and therefore the second `shm_open` fails. The flag `O_EXCL` prevents
    the current process from creating an object which already exists, and then it
    quits by showing a proper error message. If this happens, which should be very
    rare, we can always try to run the process again and it won't face the same issue
    in the second run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is the reverse operation for destructing the cancellation
    flag and its shared memory region:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-12 [ExtremeC_examples_chapter18_3.c]: Closing the resources allocated
    for the cancellation flag''s shared memory'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Code Box 18-12*, the written logic is very similar to what
    we've seen so far, as part of previous examples, about releasing a shared memory
    object. But there is a difference here and it is the fact that only the owner
    process can unlink the shared memory object. Note that the owner process waits
    for 1 second before unlinking the shared memory object, in order to let other
    processes finalize their resources. This wait is not usually necessary due to
    the fact that, in most POSIX-compliant systems, the shared memory object remains
    in place until all depending processes quit.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Named mutex's shared memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following code box shows how to initialize the shared mutex and its associated
    shared memory object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-13 [ExtremeC_examples_chapter18_3.c]: Initializing the shared mutex
    and its underlying shared memory region'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly to what we did while trying to create the shared memory region associated
    with the cancellation flag, we have done the same thing to create and initialize
    the shared memory region beneath the shared mutex. Note that, just like in *example
    18.2*, the mutex has been marked as `PTHREAD_PROCESS_SHARED`, which allows it
    to be used by multiple processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code box shows how to finalize the shared mutex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-14 [ExtremeC_examples_chapter18_3.c]: Closing the shared mutex
    and its associated shared memory region'
  prefs: []
  type: TYPE_NORMAL
- en: Again, the owner process can only unlink the shared memory object of the shared
    mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Setting the cancellation flag
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following code box shows the functions which allow the processes to read
    or set the cancellation flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-15 [ExtremeC_examples_chapter18_3.c]: The synchronized functions
    that read and set the cancellation flag protected by the shared mutex'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding two functions allow us to have synchronized access to the shared
    cancellation flag. The function `is_canceled` is used to check the value of the
    flag, and the function `cancel` is used to set the flag. As you see, both are
    protected by the same shared mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – The main function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'And finally, the following code box shows the `main` function and a *signal
    handler* which we explain shortly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-16 [ExtremeC_examples_chapter18_3.c]: The function main and the
    signal handler function as part of example 18.3'
  prefs: []
  type: TYPE_NORMAL
- en: As you see, the logic inside the `main` function is clear and straightforward.
    It initializes the shared flag and mutex and then goes into a busy-wait until
    the cancellation flag becomes `true`. Finally, it shuts down all shared resources
    and terminates.
  prefs: []
  type: TYPE_NORMAL
- en: One thing which is new here is the usage of the `signal` function which assigns
    a signal handler to a specific set of *signals*. Signals are one of the facilities
    provided by all POSIX-compliant operating systems and using it, the processes
    within the system can send signals to each other. The *terminal* is just one normal
    process that the user interacts with and it can be used to send signals to other
    processes. Pressing `Ctrl` + `C` is one convenient way to send `SIGINT` to the
    foreground process running in a terminal.
  prefs: []
  type: TYPE_NORMAL
- en: '`SIGINT` is the *interrupt signal* which can be received by a process. In the
    preceding code, we assign the function `sigint_handler` to be the handler of the
    `SIGINT` signal. In other words, whenever the signal `SIGINT` is received by the
    process, the function `sigint_handler` will be called. If the signal `SIGINT`
    is not handled, the default routine is to terminate the process, but this can
    be overridden using signal handlers like above.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to send a `SIGINT` signal to a process, but one of the easiest
    is to press the `Ctrl` + `C` keys on the keyboard. The process will immediately
    receive the `SIGINT` signal. As you see, within the signal handler, we set the
    shared cancellation flag to `true`, and after this point, all the processes start
    to exit their busy-wait loops.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is a demonstration of how the preceding code compiles and works.
    Let''s build the preceding code and run the first process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-2: Compilation of example 18.3 and running the first process'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see, the preceding process is the first to be run, and therefore, it
    is the owner of the mutex and cancellation flag. The following is the run of the
    second process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-3: Running the second process'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see, the second process only opens the shared memory objects, and it
    is not the owner. The following output is showing when `Ctrl` + `C` has been pressed
    on the first process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-4: The output of the first process when Ctrl + C has been pressed'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see, the first process prints that it is handling a signal with the
    number `2` which is the standard signal number of the `SIGINT`. It sets the cancellation
    flag, and it exits immediately. And following it, the second process exits. The
    following is the output of the second process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-5: The output of the second process when it sees that the cancellation
    flag is set'
  prefs: []
  type: TYPE_NORMAL
- en: Also, you can send `SIGINT` to the second process and the result will be the
    same; both processes will get the signal and will quit. Also, you can create more
    than two processes and all of them will synchronously quit using the same shared
    memory and mutex.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we demonstrate how to use condition variables. Like named
    mutexes, if you place a condition variable inside a shared memory region, it can
    be accessed and used by multiple processes using the shared memory's name.
  prefs: []
  type: TYPE_NORMAL
- en: Named condition variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we explained before, similar to named POSIX mutexes, we need to allocate
    a POSIX condition variable from a shared memory region in order to use it in a
    multi-processing system. The following example, *example 18.4*, shows how to do
    so in order to make a number of processes count in a specific order. As you know
    from *Chapter 16*, *Thread Synchronization*, every condition variable should be
    used together with a companion mutex object which protects it. Therefore, we will
    have three shared memory regions in *example 18.4*; one for the shared counter,
    one for the shared *named condition variable*, and one for the shared *named mutex*
    protecting the shared condition variable.
  prefs: []
  type: TYPE_NORMAL
- en: Note that instead of having three different shared memories, we could also use
    a single shared memory. This is possible by defining a structure that encompasses
    all the required objects. In this example, we are not going to take this approach
    and we will define a separate shared memory region for each object.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example 18.4* is about a number of processes which should count in an ascending
    order. Each process is given a number, starting from 1 and up to the number of
    processes, and the given number indicates the process''s rank within the other
    processes. The process must wait for the other processes with smaller numbers
    (ranks) to count first and then it can count its turn and exit. Of course, the
    process assigned the number 1 counts first, even if it is the latest spawned process.'
  prefs: []
  type: TYPE_NORMAL
- en: Since we are going to have three different shared memory regions, each of which
    requiring its own steps to get initialized and finalized, we would have a lot
    of code duplication if we wanted to take the same approach as we have so far in
    the previous examples. For reducing the amount of code that we write, and factoring
    out the duplications into some functions, and having a better-organized code,
    we are going to make it object-oriented according to the topics and procedures
    discussed in *Chapter 6*, *OOP and Encapsulation*, *Chapter 7*, *Composition and
    Aggregation*, and *Chapter 8*, *Inheritance and Polymorphism*. We are going to
    write *example 18.4* in an object-oriented manner and use inheritance to reduce
    the amount of duplicated code.
  prefs: []
  type: TYPE_NORMAL
- en: We will define a parent class for all classes which need to be built upon a
    shared memory region. Therefore, while having the parent shared memory class,
    there will be one child class defined for the shared counter, one child class
    for the shared named mutex, and another child class for the shared named condition
    variable. Each class will have its own pair of header and source files, and all
    of them will be used finally in the main function of the example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sections go through the mentioned classes one by one. First of
    all, let''s being with the parent class: shared memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Class of shared memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code box shows the declarations of the shared memory class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-17 [ExtremeC_examples_chapter18_4_shared_mem.h]: The public interface
    of the shared memory class'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding code contains the declarations (public API) needed to use a shared
    memory object. The functions `shared_mem_getptr`, `shared_mem_isowner`, and `shared_mem_setowner`
    are the behaviors of this class.
  prefs: []
  type: TYPE_NORMAL
- en: If this syntax is not familiar to you, please have a read of *Chapter 6*, *OOP
    and Encapsulation*, *Chapter 7*, *Composition and Aggregation*, and *Chapter 8*,
    *Inheritance and Polymorphism*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code box shows the definitions of the functions declared as part
    of the public interface of the class, as seen in *Code Box 18-17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-18 [ExtremeC_examples_chapter18_4_shared_mem.c]: The definitions
    of all functions found in the shared memory class'
  prefs: []
  type: TYPE_NORMAL
- en: As you see, we have just copied the code we wrote for shared memories as part
    of the previous examples. The structure `shared_mem_t` encapsulates all we need
    to address a POSIX shared memory object. Note the global Boolean variable `process_owner`.
    It indicates whether the current process is the owner of all shared memory regions.
    It is set only once.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Class of shared 32-bit integer counter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code box contains the declaration of the shared counter class
    which is a 32-bit integer counter. This class inherits from the shared memory
    class. As you might have noticed, we are using the second approach we described
    as part of *Chapter 8*, *Inheritance and Polymorphism*, to implement the inheritance
    relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-19 [ExtremeC_examples_chapter18_4_shared_int32.h]: The public interface
    of the shared counter class'
  prefs: []
  type: TYPE_NORMAL
- en: 'And the following code box shows the implementations of the preceding declared
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-20 [ExtremeC_examples_chapter18_4_shared_int32.c]: The definitions
    of all functions found in the shared counter class'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have written a lot less code thanks to inheritance. All the
    necessary code for managing the associated shared memory object has been brought
    in by the field `shm` in the structure `shared_int32_t`.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Class of shared mutex
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code box contains the declaration of the shared mutex class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-21 [ExtremeC_examples_chapter18_4_shared_mutex.h]: The public interface
    of the shared mutex class'
  prefs: []
  type: TYPE_NORMAL
- en: As you see, the above class has three exposed behaviors as expected; `shared_mutex_lock`,
    `shared_mutex_unlock`, and `shared_mutex_make_consistent`. But there is one exception,
    which is that the behavior `shared_mutex_make_consistent` is only available in
    POSIX systems which are not macOS (Apple) based. That's because *robust mutexes*
    are not supported by Apple systems. We will discuss what a robust mutex is in
    the upcoming paragraphs. Note that we have used the macro `__APPLE__` to detect
    whether we are compiling on an Apple system or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code box shows the implementation of the preceding class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-22 [ExtremeC_examples_chapter18_4_shared_mutex.c]: The definitions
    of all functions found in the shared named mutex class'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, we do only the POSIX mutex initialization, finalization,
    and exposing some of the trivial behaviors such as locking and unlocking. Everything
    else regarding the shared memory object is being handled in the shared memory
    class. That's a benefit of using inheritance.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the constructor function `shared_mutex_ctor`, we set the mutex
    as a *shared process* mutex to be accessible to all processes. This is absolutely
    necessary to multi-process software. Note that in systems which are not Apple-based,
    we go further and configure the mutex as a *robust mutex*.
  prefs: []
  type: TYPE_NORMAL
- en: For an ordinary mutex that is locked by a process, if the process should suddenly
    die then the mutex goes into a non-consistent state. For a robust mutex, if this
    happens, the mutex can be put back in a consistent state. The next process, which
    is usually waiting for the mutex, can lock the mutex only by making it consistent.
    You can see how it can be done in the function `shared_mutex_lock`. Note that
    this functionality is not present in Apple systems.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Class of shared condition variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code box shows the declaration of the shared condition variable
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-23 [ExtremeC_examples_chapter18_4_shared_cond.h]: The public interface
    of the shared condition variable class'
  prefs: []
  type: TYPE_NORMAL
- en: Three behaviors are exposed; `shared_cond_wait`, `shared_cond_timedwait`, and
    `shared_cond_broadcast`. If you remember from *Chapter 16*, *Thread Synchronization*,
    the behavior `shared_cond_wait` waits for a signal on a condition variable.
  prefs: []
  type: TYPE_NORMAL
- en: Above, we have added a new version of waiting behavior; `shared_cond_timedwait`.
    It waits for the signal for a specified amount of time and then it gets timed
    out if the condition variable doesn't receive a signal. On the other hand, the
    `shared_cond_wait` never exists until it receives some sort of signal. We will
    use the timed version of waiting in *example 18.4*. Note that both waiting behavior
    functions receive a pointer to the companion shared mutex just like what we saw
    in multi-threaded environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code box contains the actual implementation of the shared condition
    variable class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-24 [ExtremeC_examples_chapter18_4_shared_cond.c]: The definitions
    of all functions found in the shared condition variable class'
  prefs: []
  type: TYPE_NORMAL
- en: In our shared condition variable class, we have only exposed the *broadcasting*
    behavior. We could also expose the *signaling* behavior. As you might remember
    from *Chapter 16*, *Thread Synchronization*, signaling a condition variable wakes
    up only one of the many waiting processes, without the ability to specify or predict
    which one. Broadcasting in contrast will wake all the waiting processes. In *example
    18.4* we'll only use broadcasting, and that's why we have only exposed that function.
  prefs: []
  type: TYPE_NORMAL
- en: Note that since every condition variable has a companion mutex, the shared mutex
    class should be able to use an instance of the shared mutex class, and that's
    why we have declared `shared_mutex_t` as a forward declaration.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – The main logic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code box contains the main logic implemented for our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 18-25 [ExtremeC_examples_chapter18_4_main.c]: The main function of
    example 18.4'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the program accepts an argument indicating its number. As soon
    as the process finds out about its number, it starts to initialize the shared
    counter, the shared mutex, and the shared condition variable. It then enters a
    critical section being protected by the shared mutex.
  prefs: []
  type: TYPE_NORMAL
- en: Inside a loop, it waits for the counter to become equal to its number. Since
    it waits for 5 seconds, there could be a timeout and we may leave the `shared_cond_timedwait`
    function after 5 seconds. This basically means that the condition variable has
    not been notified during that 5 seconds. The process then checks the condition
    again and it goes to sleep for another 5 seconds. This continues until the process
    gets the turn.
  prefs: []
  type: TYPE_NORMAL
- en: When this happens, the process prints its number, increments the shared counter,
    and by broadcasting a signal on the shared condition variable object, it notifies
    the rest of the waiting processes about the modification which it has made to
    the shared counter. Only then does it prepare to quit.
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, if the user presses `Ctrl` + `C`, the signal handler defined
    as part of the main logic sets the local flag `int_received` and as soon as the
    process leaves the function `shared_mutex_timedwait` when it is inside the main
    loop, it notices the interrupt signal and exits the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following shell box shows how to compile *example 18.4*. We are going to
    compile it in Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-6: Compiling the sources of example 18.4 and producing the final
    executable file'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have got the final executable file `ex18_4.out`, we can run three
    processes and see how they count in sequence, no matter how you assign them the
    numbers and in what order they are run. Let''s run the first process. We assign
    to this process the the number 3, by passing the number as an option to the executable
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-7: Running the first process which takes the number 3'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see in the preceding output, the first process creates all the required
    shared objects and becomes the owner of the shared resources. Now, let''s run
    the second process in a separate Terminal. It takes the number 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-8: Running the second process which takes the number 2'
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, the last process takes the number 1\. Since this process has been
    assigned the number 1, it prints its number immediately, increments the shared
    counter, and notifies the rest of the processes about it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-9: Running the third process which takes the number 1\. This process
    will exit immediately since it has the number 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if you go back to the second process, it prints out its number, increments
    the shared counter, and notifies the third process about that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-10: The second process prints its number and exits'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, going back to the first process, it gets notified by the second process,
    then it prints out its number and exits.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 18-11: The first process prints its number and exits. It also deletes
    all shared memory entries.'
  prefs: []
  type: TYPE_NORMAL
- en: Since the first process is the owner of all shared memories, it should delete
    them upon exiting. Releasing the allocated resources in a multi-processing environment
    can be quite tricky and complex because a simple mistake is enough to cause all
    the processes to crash. Further synchronization is required when a shared resource
    is going to be removed from the system.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that, in the preceding example, we'd run the first process with the
    number 2 and the second process with the number 3\. Therefore, the first process
    should print its number before the second process. When the first process exits
    since it's the creator of all shared resources, it deletes the shared objects
    and the second process crashes as soon as it wants to access them.
  prefs: []
  type: TYPE_NORMAL
- en: This is just a simple example of how finalization can be tricky and problematic
    in multi-process systems. In order to mitigate the risk of such crashes, one needs
    to introduce further synchronization among processes.
  prefs: []
  type: TYPE_NORMAL
- en: During the previous sections, we covered the mechanisms which can be employed
    to synchronize a number of processes while all of them are running on the same
    host. In the following section, we are going to briefly talk about distributed
    concurrency control mechanisms and their features.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed concurrency control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter we have assumed that all processes exist within the same
    operating system, and hence the same machine. In other words, we were constantly
    talking about a single-host software system.
  prefs: []
  type: TYPE_NORMAL
- en: But real software systems usually go beyond that. Conversely to the single-host
    software system, we have distributed software systems. These systems have processes
    distributed throughout a network, and they function through communicating over
    the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding a distributed system of processes, we can see more challenges in
    some aspects that are not present in a centralized or single-host system in that
    degree. Next, we discuss some of them briefly:'
  prefs: []
  type: TYPE_NORMAL
- en: '**In a distributed software system, you are probably experiencing parallelism
    instead of concurrency**. Since each process runs on a separate machine, and each
    process has its own specific processor, we will be observing parallelism instead
    of concurrency. Concurrency is usually limited to the borders of a single machine.
    Note that interleavings still exist and we might experience the same non-determinism
    as we saw in concurrent systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Not all processes within a distributed software system are written using
    a single programming language**. It is pretty common to see various programming
    languages being used in a distributed software system. It is also common to see
    the same diversity in the processes of a single-host software system. Despite
    our implicit assumption about the processes within a system, which is that all
    of them have been written using C, we can have processes written using any other
    language. Different languages provide different ways of having concurrency and
    control mechanisms. Therefore, for example, in some languages, you may not be
    able to use a named mutex very easily. Diverse technologies and programming languages
    used in a software system, single-host or distributed, force us to use concurrency
    control mechanisms that are abstract enough to be available in all of them. This
    might limit us to using a specific synchronization technique which is available
    in a certain technology or a programming language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**In a distributed system, you always have a network as the communication channel
    between two processes not residing on the same machine**. This is converse to
    our implicit assumption about the single-host system where all processes are running
    within the same operating system and using the available messaging infrastructures
    to communicate with each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Having a network in the middle means that you have latency**. There is a
    slight latency in single-host systems as well, but it is determined and manageable.
    It is also much lower than the latency you might experience in a network. Latency
    simply means that a process may not receive a message immediately because of many
    reasons having roots in the networking infrastructure. Nothing should be considered
    immediate in these systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Having a network in the middle also results in security issues**. When you
    have all the processes in one system, and all of them are communicating within
    the same boundary using mechanisms with extremely low latency, the security issues
    are greatly different. One has to firstly access the system itself in order to
    attack the system, but in a distributed system, all message passing is being done
    through the network. You might get an *eavesdropper* in the middle to sniff or,
    even worse, alter the messages. Regarding our discussion about synchronization
    in distributed systems, this is also applicable to messages meant to synchronize
    the processes within a distributed system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Other than latency and security issues, you might have delivery issues that
    happen far less frequently in single-host multi-process systems**. Messages should
    be delivered to be processed. When a process sends a message to another process
    within the system, somehow the sender process should make sure that its message
    is received by the other end. *Delivery guarantee* mechanisms are possible, but
    they''re costly and, in some scenarios, it is just not possible to use them at
    all. In those situations, a special kind of messaging problem is seen, which is
    usually modeled by the famous *Two Generals Problem*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preceding differences and possible issues are enough to force us to invent
    new ways of synchronization among processes and various components of giant distributed
    systems. Generally, there are two ways to make a distributed system transactional
    and synchronized:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Centralized process synchronization**: These techniques need a central process
    (or node) that manages the processes. All the other processes within the system
    should be in constant communication with this central node, and they need its
    approval in order to enter their critical sections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed (or peer-to-peer) process synchronization**: Having a process
    synchronization infrastructure that does not have a central node is not an easy
    task. This is actually an active field of research, and there are some ad hoc
    algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we tried to shine a little light over the complexity of concurrency
    control in a distributed multi-process system. Further discussions about distributed
    concurrency control would be out of the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we completed our discussion regarding multi-processing environments.
    As part of this chapter, we discussed the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What a named semaphore is and how it can be created and used by multiple processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What a named mutex is and how it should be used using a shared memory region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We gave an example which was about termination orchestration in which a number
    of processes were waiting for a sign to get terminated and the signal was received
    and handled by one of the processes and propagated to others. We implemented this
    example using shared mutexes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What a named condition variable is and how it can become shared and named using
    a shared memory region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We demonstrated another example of counting processes. As part of this example,
    we used inheritance to reduce the amount of code duplication for mutex and condition
    variable objects having an associated shared memory region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We briefly explored the differences and challenges found in a distributed system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We briefly discussed the methods which can be employed to bring concurrency
    control into distributed software.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the upcoming chapter, we start our discussions regarding **Inter-Process
    Communication** (**IPC**) techniques. Our discussions will span two chapters and
    we will cover many topics such as computer networks, transport protocols, socket
    programming, and many more useful topics.
  prefs: []
  type: TYPE_NORMAL
