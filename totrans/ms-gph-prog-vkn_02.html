<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-31"><a id="_idTextAnchor030"/>2</h1>
<h1 id="_idParaDest-32"><a id="_idTextAnchor031"/>Improving Resources Management</h1>
<p>In this chapter, we are going to improve resource management to make it easier to deal with materials that might have a varying number of textures. This technique<a id="_idIndexMarker076"/> is usually referred to as bindless, even though it’s not entirely accurate. We are still going to bind a list of resources; however, we can access them by using an index rather than having to specify exactly which resources are going to be used during a particular draw.</p>
<p>The second improvement we are going to make is automating the generation of pipeline layouts. Large projects have hundreds or thousands of shaders, compiled with many different variations depending on the combinations of materials used by a particular application. If developers had to manually update their pipeline layout definitions every time a change is made, very few applications would make it to market. The implementation presented in this chapter relies on the information provided by the SPIR-V binary format.</p>
<p>Finally, we are going to add pipeline caching to our GPU device implementation. This solution improves the creation time of pipeline objects after the first run, and can significantly improve an application’s loading times.</p>
<p>In summary, in this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>Unlocking and implementing bindless resources</li>
<li>Automating pipeline layout generation</li>
<li>Improving load times with a pipeline cache</li>
</ul>
<p>By the end of this chapter, you will understand how to enable and use bindless resources in Vulkan. You will also be able to parse SPIR-V binary data to automatically generate pipeline layouts. Finally, you will be able to speed up the loading time of your application by using pipeline caching.</p>
<h1 id="_idParaDest-33"><a id="_idTextAnchor032"/>Technical requirements</h1>
<p>The code for this chapter can be found at the following URL: <a href="https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter2">https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter2</a>.</p>
<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>Unlocking and implementing bindless rendering</h1>
<p>In the previous chapter, we had to manually<a id="_idIndexMarker077"/> bind the textures<a id="_idIndexMarker078"/> for each material. This also meant that if we wanted to support different types of materials requiring a different number of textures, we would have needed separate shaders and pipelines.</p>
<p>Vulkan provides a mechanism to bind an array of textures that can be used across multiple shaders. Each texture can then be accessed through an index. In the following sections, we are going to highlight the changes we have made to the GPU device implementation to enable this feature and describe how to use it.</p>
<p>In the following sections, we will first check that the extensions required to enable bindless resources are available on a given GPU. Then we will show the changes required to the descriptor pool creation and descriptor set update to make use of bindless resources. The last step will be to update our shaders to use indices in our texture array for rendering.</p>
<h2 id="_idParaDest-35"><a id="_idTextAnchor034"/>Checking for support</h2>
<p>Most desktop GPUs, even<a id="_idIndexMarker079"/> if relatively old, should support the <code>VK_EXT_descriptor_indexing</code> extension, provided you have up-to-date drivers. It’s still good practice to verify that the extension is available and, for a production implementation, provide an alternative code path that uses the standard binding model if the extension is not available.</p>
<p>To verify that your device supports this extension, you can use the following code, or you can run the <code>vulkaninfo</code> application provided by the Vulkan SDK. See <a href="B18395_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Introducing the Raptor Engine and Hydra</em>, for how to install the SDK.</p>
<p>The first step then is to query the physical device to determine whether the GPU supports this extension. The following code section accomplishes this:</p>
<pre class="source-code">
VkPhysicalDeviceDescriptorIndexingFeatures indexing
_features{ VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR
           _INDEXING_FEATURES, nullptr };
    VkPhysicalDeviceFeatures2 device_features{
        VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2,
            &amp;indexing_features };
    vkGetPhysicalDeviceFeatures2( vulkan_physical_device,
                                  &amp;device_features );
    bindless_supported = indexing_features.
                         descriptorBindingPartiallyBound &amp;&amp;
                         indexing_features.
                         runtimeDescriptorArray;</pre>
<p>We have to populate the <code>VkPhysicalDeviceDescriptorIndexingFeatures</code> structure and chain it to the <code>VkPhysicalDeviceFeatures2</code> structure. The driver will then populate the <code>indexing_features</code> variable<a id="_idIndexMarker080"/> members when calling <code>vkGetPhysicalDeviceFeatures2</code>. To check that the descriptor indexing extension is supported, we verify that the <code>descriptorBindingPartiallyBound</code> and <code>runtimeDescriptorArray</code> values are <code>true</code>.</p>
<p>Once we have confirmed that the extension is supported, we can enable it when creating the device:</p>
<pre class="source-code">
VkPhysicalDeviceFeatures2 physical_features2 = {
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2 };
vkGetPhysicalDeviceFeatures2( vulkan_physical_device,
                              &amp;physical_features2 );
VkDeviceCreateInfo device_create_info = {};
// same code as chapter 1
device_create_info.pNext = &amp;physical_features2;
if ( bindless_supported ) {
    physical_features2.pNext = &amp;indexing_features;
}
vkCreateDevice( vulkan_physical_device,
                &amp;device_create_info,
                vulkan_allocation_callbacks,
                &amp;vulkan_device );</pre>
<p>We have to chain the <code>indexing_features</code> variable to the <code>physical_features2</code> variable used when creating<a id="_idIndexMarker081"/> our device. The rest of the code is unchanged from <a href="B18395_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Introducing the Raptor Engine </em><em class="italic">and Hydra</em>.</p>
<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>Creating the descriptor pool</h2>
<p>The next step is to create a descriptor pool<a id="_idIndexMarker082"/> from which we can allocate<a id="_idIndexMarker083"/> descriptor sets that support updating the content of a texture after it is bound:</p>
<pre class="source-code">
VkDescriptorPoolSize pool_sizes_bindless[] =
{
    { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
      k_max_bindless_resources },
      { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
      k_max_bindless_resources },
};
pool_info.flags = VK_DESCRIPTOR_POOL_CREATE_UPDATE
                  _AFTER_BIND_BIT_EXT;
pool_info.maxSets = k_max_bindless_resources * ArraySize(
                    pool_sizes_bindless );
pool_info.poolSizeCount = ( u32 )ArraySize(
                            pool_sizes_bindless );
pool_info.pPoolSizes = pool_sizes_bindless;
vkCreateDescriptorPool( vulkan_device, &amp;pool_info,
                        vulkan_allocation_callbacks,
                        &amp;vulkan_bindless_descriptor_pool);</pre>
<p>The main difference<a id="_idIndexMarker084"/> with the code from <a href="B18395_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Introducing the Raptor Engine and Hydra</em>, is the addition of the <code>VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT_EXT</code> flag. This flag is needed to allow the<a id="_idIndexMarker085"/> creation of descriptor sets that can be updated after they have been bound.</p>
<p>Next, we have to define the descriptor set layout bindings:</p>
<pre class="source-code">
const u32 pool_count = ( u32 )ArraySize(
                         pool_sizes_bindless );
VkDescriptorSetLayoutBinding vk_binding[ 4 ];
VkDescriptorSetLayoutBinding&amp; image_sampler_binding =
    vk_binding[ 0 ];
image_sampler_binding.descriptorType = VK_DESCRIPTOR
                                       _TYPE_COMBINED
                                       _IMAGE_SAMPLER;
image_sampler_binding.descriptorCount =
    k_max_bindless_resources;
image_sampler_binding.binding = k_bindless_texture_binding;
VkDescriptorSetLayoutBinding&amp; storage_image_binding =
    vk_binding[ 1 ];
storage_image_binding.descriptorType = VK_DESCRIPTOR
                                       _TYPE_STORAGE_IMAGE;
storage_image_binding.descriptorCount =
    k_max_bindless_resources;
storage_image_binding.binding = k_bindless_texture_binding
                                + 1;</pre>
<p>Notice that <code>descriptorCount</code> no longer<a id="_idIndexMarker086"/> has a value of <code>1</code> but has to accommodate the maximum number of textures<a id="_idIndexMarker087"/> we can use. We can now use this data to create a descriptor set layout:</p>
<pre class="source-code">
VkDescriptorSetLayoutCreateInfo layout_info = {
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO };
layout_info.bindingCount = pool_count;
layout_info.pBindings = vk_binding;
layout_info.flags = VK_DESCRIPTOR_SET_LAYOUT_CREATE
                    _UPDATE_AFTER_BIND_POOL_BIT_EXT;
VkDescriptorBindingFlags bindless_flags =
    VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT_EXT |
        VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT_EXT;
VkDescriptorBindingFlags binding_flags[ 4 ];
binding_flags[ 0 ] = bindless_flags;
binding_flags[ 1 ] = bindless_flags;
VkDescriptorSetLayoutBindingFlagsCreateInfoEXT
extended_info{
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT
        _BINDING_FLAGS_CREATE_INFO_EXT, nullptr };
extended_info.bindingCount = pool_count;
extended_info.pBindingFlags = binding_flags;
layout_info.pNext = &amp;extended_info;
vkCreateDescriptorSetLayout( vulkan_device, &amp;layout_info,
                             vulkan_allocation_callbacks,
                             &amp;vulkan_bindless
                             _descriptor_layout );</pre>
<p>The code is very similar to the version<a id="_idIndexMarker088"/> seen in the previous chapter; however, we<a id="_idIndexMarker089"/> have added the <code>bindless_flags</code> values to enable partial updates to the descriptor set. We also have to chain a <code>VkDescriptorSetLayoutBindingFlagsCreateInfoEXT</code> structure to the <code>layout_info</code> variable. Finally, we can create the descriptor set we are going to use for the lifetime of the application:</p>
<pre class="source-code">
VkDescriptorSetAllocateInfo alloc_info{
    VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO };
alloc_info.descriptorPool = vulkan_bindless
                            _descriptor_pool;
alloc_info.descriptorSetCount = 1;
alloc_info.pSetLayouts = &amp;vulkan_bindless_descriptor
                         _layout;
vkAllocateDescriptorSets( vulkan_device, &amp;alloc_info,
                          &amp;vulkan_bindless_descriptor_set
                         );</pre>
<p>We simply populate the <code>VkDescriptorSetAllocateInfo</code> structure<a id="_idIndexMarker090"/> with the values we have<a id="_idIndexMarker091"/> defined so far and call <code>vkAllocateDescriptorSets</code>.</p>
<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>Updating the descriptor set</h2>
<p>We have done most<a id="_idIndexMarker092"/> of the heavy lifting<a id="_idIndexMarker093"/> at this point. When we call <code>GpuDevice::create_texture</code>, the newly created resource gets added to the <code>texture_to_update_bindless</code> array:</p>
<pre class="source-code">
if ( gpu.bindless_supported ) {
    ResourceUpdate resource_update{
        ResourceDeletionType::Texture,
            texture-&gt;handle.index, gpu.current_frame };
    gpu.texture_to_update_bindless.push( resource_update );
}</pre>
<p>It’s also possible to associate a specific sampler to a given texture. For instance, when we load a texture for a given material, we add the following code:</p>
<pre class="source-code">
gpu.link_texture_sampler( diffuse_texture_gpu.handle,
                          diffuse_sampler_gpu.handle );</pre>
<p>This links the diffuse texture with its sampler. This information will be used in the next code section to determine whether we use a default sampler or the one we have just assigned to the texture.</p>
<p>Before the next frame<a id="_idIndexMarker094"/> is processed, we update<a id="_idIndexMarker095"/> the descriptor set we have created in the previous section with any new textures that have been uploaded:</p>
<pre class="source-code">
for ( i32 it = texture_to_update_bindless.size - 1;
  it &gt;= 0; it-- ) {
    ResourceUpdate&amp; texture_to_update =
        texture_to_update_bindless[ it ];
   Texture* texture = access_texture( {
                      texture_to_update.handle } );
    VkWriteDescriptorSet&amp; descriptor_write =
        bindless_descriptor_writes[ current_write_index ];
    descriptor_write = {
        VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET };
    descriptor_write.descriptorCount = 1;
    descriptor_write.dstArrayElement =
        texture_to_update.handle;
    descriptor_write.descriptorType =
        VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
    descriptor_write.dstSet =
        vulkan_bindless_descriptor_set;
    descriptor_write.dstBinding =
        k_bindless_texture_binding;
    Sampler* vk_default_sampler = access_sampler(
                                  default_sampler );
    VkDescriptorImageInfo&amp; descriptor_image_info =
        bindless_image_info[ current_write_index ];
    <strong class="bold">if ( texture-&gt;sampler != nullptr ) {</strong>
<strong class="bold">        descriptor_image_info.sampler =</strong>
<strong class="bold">        texture-&gt;sampler-&gt;</strong><strong class="bold">vk_sampler;</strong>
<strong class="bold">    }</strong>
<strong class="bold">    else {</strong>
<strong class="bold">        descriptor_image_info.sampler =</strong>
<strong class="bold">        vk_default_sampler-&gt;vk_sampler;</strong>
<strong class="bold">    }</strong>
<strong class="bold">    descriptor_image_info.imageView = </strong>
        <strong class="bold">texture-&gt;vk_format != VK_FORMAT_UNDEFINED ? </strong>
        <strong class="bold">texture-&gt;vk_image_view : vk_dummy_texture-&gt; </strong>
        <strong class="bold">vk_image_view;</strong>
    descriptor_image_info.imageLayout =
        VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
    descriptor_write.pImageInfo = &amp;descriptor_image_info;
    texture_to_update.current_frame = u32_max;
    texture_to_update_bindless.delete_swap( it );
    ++current_write_index;
}</pre>
<p>The preceding code is quite similar to the previous version. We have highlighted the main differences: the sampler selection, as we mentioned in the previous paragraph, and the use of a dummy texture if a slot is empty. We still have to assign a texture to each slot, hence the use of a dummy texture if one is not specified. This is also useful for spotting any missing textures in your scene.</p>
<p>If you prefer to have a tightly packed array of textures, another option is to enable the <code>VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT_EXT</code> flag and chain a <code>VkDescriptorSetVariableDescriptorCountAllocateInfoEXT</code> structure when creating<a id="_idIndexMarker096"/> the descriptor set. We already have<a id="_idIndexMarker097"/> some preliminary code to enable this feature, and we encourage you to complete the implementation!</p>
<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>Update to shader code</h2>
<p>The final piece of the puzzle<a id="_idIndexMarker098"/> to use bindless rendering<a id="_idIndexMarker099"/> is in the shader code, as it needs to be written in a different way.</p>
<p>The steps are similar for all shaders making use of bindless resources, and it would be beneficial to have them defined<a id="_idIndexMarker100"/> in a common header. Unfortunately, this is not fully supported by the <strong class="bold">OpenGL Shading Language</strong>, or <strong class="bold">GLSL</strong>.</p>
<p>We recommend automating this step as it can be easily added when compiling the shader in the engine code.</p>
<p>The first thing to do is to enable the nonuniform qualifier in the GLSL code:</p>
<pre class="source-code">
#extension GL_EXT_nonuniform_qualifier : enable</pre>
<p>This will enable the extension in the current shader, not globally; thus, it must be written in every shader.</p>
<p>The following code is the declaration of the proper bindless textures, with a catch:</p>
<pre class="source-code">
layout ( set = 1, binding = 10 ) uniform sampler2D global_textures[];
layout ( set = 1, binding = 10 ) uniform sampler3D global_textures_3d[];</pre>
<p>This is a known trick to alias the texture declarations to the same binding point. This allows us to have just one global bindless texture array, but all kinds of textures (one-dimensional, two-dimensional, three-dimensional, and their array counterparts) are supported in one go!</p>
<p>This simplifies the usage of bindless textures<a id="_idIndexMarker101"/> across the engine<a id="_idIndexMarker102"/> and the shaders.</p>
<p>Finally, to read the texture, the code in the shader has to be modified as follows:</p>
<pre class="source-code">
texture(global_textures[nonuniformEXT(texture_index)],
        vTexcoord0)</pre>
<p>Let’s go in the following order:</p>
<ol>
<li>First of all, we need the integer index coming from a constant. In this case, <code>texture_index</code> will contain the same number as the texture position in the bindless array.</li>
<li>Second, and this is the crucial change, we need to wrap the index with the <code>nonuniformEXT</code> qualifier (<a href="https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GL_EXT_nonuniform_qualifier.txt">https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GL_EXT_nonuniform_qualifier.txt</a>); this will basically synchronize the programs between the different executions to properly read the texture index, in case the index is different across different threads of the same shader invocation.</li>
</ol>
<p>This might sound complicated at first but think about it as a multithreading issue that needs synchronization to make sure the proper texture index is read in each thread and, as a result, the correct texture is used.</p>
<ol>
<li value="3">Lastly, using the synchronized index we read from the <code>global_textures</code> array, we finally have the texture sample we wanted!</li>
</ol>
<p>We have now added bindless textures support to the Raptor Engine! We started by checking whether the GPU supports this feature. Then we detailed the changes we made to the creation of the descriptor pool and descriptor set.</p>
<p>Finally, we have shown how the descriptor set is updated as new textures are uploaded to the GPU and the necessary shader modifications to make use of bindless textures. All the rendering from now<a id="_idIndexMarker103"/> on will use this feature; thus, this concept<a id="_idIndexMarker104"/> will become familiar.</p>
<p>Next, we are going to improve our engine capabilities by adding automatic pipeline generation by parsing shaders’ binary data.</p>
<h1 id="_idParaDest-39"><a id="_idTextAnchor038"/>Automating pipeline layout generation</h1>
<p>In this section, we are going<a id="_idIndexMarker105"/> to take advantage of the data provided by the SPIR-V binary format to extract the information needed to create a pipeline layout. SPIR-V is the <strong class="bold">intermediate representation</strong> (<strong class="bold">IR</strong>) that shader sources are compiled<a id="_idIndexMarker106"/> to before being passed to the GPU.</p>
<p>Compared to standard GLSL shader sources, which are plain text, SPIR-V is a binary format. This means it’s a more compact format to use when distributing an application. More importantly, developers don’t have to worry about their shaders getting compiled into a different set of high-level instructions depending on the GPU and driver their code is running on.</p>
<p>However, a SPIR-V binary does not contain the final instructions that will be executed by the GPU. Every GPU will take a SPIR-V blob and do a final compilation into GPU instructions. This step is still required because different GPUs and driver versions can produce different assemblies for the same SPIR-V binary.</p>
<p>Having SPIR-V as an intermediate step is still a great improvement. Shader code validation and parsing are done offline, and developers can compile their shaders together with their application code. This allows us to spot any syntax mistakes before trying to run the shader code.</p>
<p>Another benefit of having an intermediate representation is being able to compile shaders written in different languages to SPIR-V so that they can be used with Vulkan. It’s possible, for instance, to compile a shader written in HLSL into SPIR-V and reuse it in a Vulkan renderer.</p>
<p>Before this option was available, developers either had to port the code manually or had to rely on tools that rewrote the shader from one language to another.</p>
<p>By now, you should be convinced of the advantages the introduction of SPIR-V has brought to developers and the Vulkan API.</p>
<p>In the following sections, we are going to use one of our shaders to show you how to compile it to SPIR-V and explain<a id="_idIndexMarker107"/> how to use the information in the binary data to automatically generate a pipeline layout.</p>
<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>Compiling GLSL to SPIR-V</h2>
<p>We are going to use the vertex <a id="_idIndexMarker108"/>shader code that <a id="_idIndexMarker109"/>we developed in <a href="B18395_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Introducing the Raptor Engine and Hydra</em>. Previously, we stored the shader code string in the <code>main.cpp</code> file and we didn’t compile it to SPIR-V before passing it to the Vulkan API to create a pipeline.</p>
<p>Starting from this chapter, we are storing all shader code in the <code>shaders</code> folder of each chapter. For <a href="B18395_02.xhtml#_idTextAnchor030"><em class="italic">Chapter 2</em></a>, <em class="italic">Improving Resources Management</em>, you will find two files: <code>main.vert</code> for the vertex shader and <code>main.frag</code> for the fragment shader. Here is the content of <code>main.vert</code>:</p>
<pre class="source-code">
#version 450
layout ( std140, binding = 0 ) uniform LocalConstants {
    mat4        model;
    mat4        view_projection;
    mat4        model_inverse;
    vec4        eye;
    vec4        light;
};
layout(location=0) in vec3 position;
layout(location=1) in vec4 tangent;
layout(location=2) in vec3 normal;
layout(location=3) in vec2 texCoord0;
layout (location = 0) out vec2 vTexcoord0;
layout (location = 1) out vec3 vNormal;
layout (location = 2) out vec4 vTangent;
layout (location = 3) out vec4 vPosition;
void main() {
    gl_Position = view_projection * model * vec4(position,
                                                 1);
    vPosition = model * vec4(position, 1.0);
    vTexcoord0 = texCoord0;
    vNormal = mat3(model_inverse) * normal;
    vTangent = tangent;
}</pre>
<p>This code is quite standard for a vertex shader. We have four streams of data for position, tangent, normal, and texture coordinates. We have also defined a <code>LocalConstants</code> uniform buffer that stores the data common for all vertices. Finally, we have defined the <code>out</code> variables that are going to be passed to the fragment shader.</p>
<p>The Vulkan SDK provides<a id="_idIndexMarker110"/> the tools to compile<a id="_idIndexMarker111"/> GLSL to SPIR-V and to disassemble the generated SPIR-V into human-readable form. This can be useful to debug a shader that is not behaving as expected.</p>
<p>To compile our vertex shader, we run the following command:</p>
<pre class="console">
glslangValidator -V main.vert -o main.vert.spv</pre>
<p>This will produce a <code>main.vert.spv</code> file that contains the binary data. To view the contents of this file in a human-readable format, we run the following command:</p>
<pre class="console">
spirv-dis main.vert.spv</pre>
<p>This command will print<a id="_idIndexMarker112"/> the disassembled SPIR-V on<a id="_idIndexMarker113"/> the Terminal. We are now going to examine the relevant sections of the output.</p>
<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>Understanding the SPIR-V output</h2>
<p>Starting from the top<a id="_idIndexMarker114"/> of the output, the following<a id="_idIndexMarker115"/> is the first set of information we are provided with:</p>
<pre class="source-code">
      OpCapability Shader
%1 = OpExtInstImport "GLSL.std.450"
      OpMemoryModel Logical GLSL450
      OpEntryPoint Vertex %main "main" %_ %position
      %vPosition %vTexcoord0 %texCoord0 %vNormal %normal
      %vTangent %tangent
      OpSource GLSL 450
      OpName %main "main"</pre>
<p>This preamble defines the version of GLSL that was used to write the shader. The <code>OpEntryPoint</code> directive references the main function and lists the inputs and outputs for the shader. The convention is for variables to be prefixed by <code>%</code>, and it’s possible to forward declare a variable that is defined later.</p>
<p>The next section defines the output variables that are available in this shader:</p>
<pre class="source-code">
OpName %gl_PerVertex "gl_PerVertex"
OpMemberName %gl_PerVertex 0 "gl_Position"
OpMemberName %gl_PerVertex 1 "gl_PointSize"
OpMemberName %gl_PerVertex 2 "gl_ClipDistance"
OpMemberName %gl_PerVertex 3 "gl_CullDistance"
OpName %_ ""</pre>
<p>These are variables that are automatically injected by the compiler and are defined by the GLSL specification. We can see we have a <code>gl_PerVertex</code> structure, which in turn has four members: <code>gl_Position</code>, <code>gl_PointSize</code>, <code>gl_ClipDistance,</code> and <code>gl_CullDistance</code>. There is also an unnamed variable defined as <code>%_</code>. We’re going to discover soon what it refers to.</p>
<p>We now move<a id="_idIndexMarker116"/> on to the structures<a id="_idIndexMarker117"/> we have defined:</p>
<pre class="source-code">
OpName %LocalConstants "LocalConstants"
OpMemberName %LocalConstants 0 "model"
OpMemberName %LocalConstants 1 "view_projection"
OpMemberName %LocalConstants 2 "model_inverse"
OpMemberName %LocalConstants 3 "eye"
OpMemberName %LocalConstants 4 "light"
OpName %__0 ""</pre>
<p>Here, we have the entries for our <code>LocalConstants</code> uniform buffer, its members, and their position within the struct. We see again an unnamed <code>%__0</code> variable. We’ll get to it shortly. SPIR-V allows you to define member decorations to provide additional information that is useful to determine the data layout and location within the struct:</p>
<pre class="source-code">
OpMemberDecorate %LocalConstants 0 ColMajor
OpMemberDecorate %LocalConstants 0 Offset 0
OpMemberDecorate %LocalConstants 0 MatrixStride 16
OpMemberDecorate %LocalConstants 1 ColMajor
OpMemberDecorate %LocalConstants 1 Offset 64
OpMemberDecorate %LocalConstants 1 MatrixStride 16
OpMemberDecorate %LocalConstants 2 ColMajor
OpMemberDecorate %LocalConstants 2 Offset 128
OpMemberDecorate %LocalConstants 2 MatrixStride 16
OpMemberDecorate %LocalConstants 3 Offset 192
OpMemberDecorate %LocalConstants 4 Offset 208
OpDecorate %LocalConstants Block</pre>
<p>From these entries, we can start to have some insights as to the type of each member of the struct. For instance, we can identify the first three entries as being matrices. The last one only has an offset.</p>
<p>The offset value<a id="_idIndexMarker118"/> is the most relevant value for our purposes<a id="_idIndexMarker119"/> as it allows us to know where exactly each member starts. This is crucial when transferring data from the CPU to the GPU, as the alignment rules for each member could be different.</p>
<p>The next two lines define the descriptor set and binding for our struct:</p>
<pre class="source-code">
OpDecorate %__0 DescriptorSet 0
OpDecorate %__0 Binding 0</pre>
<p>As you can see, these decorations refer to the unnamed <code>%__0</code> variable. We have now reached the section where the variable types are defined:</p>
<pre class="source-code">
%float = OpTypeFloat 32
%v4float = OpTypeVector %float 4
%uint = OpTypeInt 32 0
%uint_1 = OpConstant %uint 1
%_arr_float_uint_1 = OpTypeArray %float %uint_1
%gl_PerVertex = OpTypeStruct %v4float %float
                %_arr_float_uint_1 %_arr_float_uint_1
%_ptr_Output_gl_PerVertex = OpTypePointer Output
                            %gl_PerVertex
%_ = OpVariable %_ptr_Output_gl_PerVertex Output</pre>
<p>For each variable, we have<a id="_idIndexMarker120"/> its type and, depending on the type, additional information that is relevant to it. For instance, the <code>%float</code> variable is of type 32-bit <code>float</code>; the <code>%v4float</code> variable is of type <code>vector</code>, and it contains 4 <code>%</code><code>float</code> values.</p>
<p>This corresponds to <code>vec4</code> in GLSL. We then have a constant definition for an unsigned value of <code>1</code> and a fixed-sized array of the <code>float</code> type and length of <code>1</code>.</p>
<p>The definition of the <code>%gl_PerVertex</code> variable follows. It is of the <code>struct</code> type and, as we have seen previously, it has four members. Their types are <code>vec4</code> for <code>gl_Position</code>, <code>float</code> for <code>gl_PointSize</code>, and <code>float[1]</code> for <code>gl_ClipDistance</code> and <code>gl_CullDistance</code>.</p>
<p>The SPIR-V specs require that each variable that can be read or written to is referred to by a pointer. And that’s exactly what we see with <code>%_ptr_Output_gl_PerVertex</code>: it’s a pointer to the <code>gl_PerVertex</code> struct. Finally, we can see the type for the unnamed <code>%_</code> variable is a pointer to the <code>gl_PerVertex</code> struct.</p>
<p>Finally, we have the type definitions for our own uniform data:</p>
<pre class="source-code">
%LocalConstants = OpTypeStruct %mat4v4float %mat4v4float
                  %mat4v4float %v4float %v4float
%_ptr_Uniform_LocalConstants = OpTypePointer Uniform
                               %LocalConstants
%__0 = OpVariable %_ptr_Uniform_LocalConstants
       Uniform</pre>
<p>As before, we can see that <code>%LocalConstants</code> is a struct with five members, three of the <code>mat4</code> type and two of the <code>vec4</code> type. We then have the type definition of the pointer to our uniform struct and finally, the <code>%__0</code> variable of this type. Notice that this variable has the <code>Uniform</code> attribute. This means it is read-only and we will make use of this information later to determine the type of descriptor to add to the pipeline layout.</p>
<p>The rest of the disassembly contains the input and output variable definitions. Their definition follows the same structure as the variables we have seen so far, so we are not going to analyze them all here.</p>
<p>The disassembly also contains the instructions for the body of the shader. While it is interesting to see how the GLSL code is translated into SPIR-V instructions, this detail is not relevant to the pipeline creation, and we are not going to cover it here.</p>
<p>Next, we are going to show how we can leverage all of this data to automate pipeline creation.</p>
<h2 id="_idParaDest-42"><a id="_idTextAnchor041"/>From SPIR-V to pipeline layout</h2>
<p>Khronos already provides functionality to parse SPIR-V data to create a pipeline layout. You can find the implementation at <a href="https://github.com/KhronosGroup/SPIRV-Reflect">https://github.com/KhronosGroup/SPIRV-Reflect</a>. For this book, we decided to write a simplified version of the parser that we believe is easier to follow as we are interested only in a small subset of entries.</p>
<p>You can find the implementation in <code>source\chapter2\graphics\spirv_parser.cpp</code>. Let’s see how to use this API and how it works under the hood:</p>
<pre class="source-code">
spirv::ParseResult parse_result{ };
spirv::parse_binary( ( u32* )spv_vert_data,
                       spv_vert_data_size, name_buffer,
                       &amp;parse_result );
spirv::parse_binary( ( u32* )spv_frag_data,
                       spv_frag_data_size, name_buffer,
                       &amp;parse_result );</pre>
<p>Here, we assume that the binary data for the vertex and fragment shader has already been read into the <code>spv_vert_data</code> and <code>spv_frag_data</code> variables. We have to define an empty <code>spirv::ParseResult</code> structure that will contain the result of the parsing. Its definition is quite simple:</p>
<pre class="source-code">
struct ParseResult {
    u32 set_count;
    DescriptorSetLayoutCreation sets[MAX_SET_COUNT];
};</pre>
<p>It contains the number of sets that we identified from the binary data and the list of entries for each set.</p>
<p>The first step of the parsing is to make sure that we are reading valid SPIR-V data:</p>
<pre class="source-code">
u32 spv_word_count = safe_cast&lt;u32&gt;( data_size / 4 );
u32 magic_number = data[ 0 ];
RASSERT( magic_number == 0x07230203 );
u32 id_bound = data[3];</pre>
<p>We first compute the number of 32-bit words that are included in the binary. Then we verify that the first four bytes match the magic number that identifies a SPIR-V binary. Finally, we retrieve the number of IDs that are defined in the binary.</p>
<p>Next, we loop over all the words in the binary to retrieve the information we need. Each ID definition starts with the <code>Op</code> type and the number of words that it is composed of:</p>
<pre class="source-code">
SpvOp op = ( SpvOp )( data[ word_index ] &amp; 0xFF );
u16 word_count = ( u16 )( data[ word_index ] &gt;&gt; 16 );</pre>
<p>The <code>Op</code> type is stored in the bottom 16 bits of the word, and the word count is in the top 16 bits. Next, we parse the data for the <code>Op</code> types we are interested in. We are not going to cover all <code>Op</code> types in this section, as the structure is the same for all types. We suggest you refer to the SPIR-V specification (linked in the <em class="italic">Further reading</em> section) for more details on each <code>Op</code> type.</p>
<p>We start with the type of shader we are currently parsing:</p>
<pre class="source-code">
case ( SpvOpEntryPoint ):
{
    SpvExecutionModel model = ( SpvExecutionModel )data[
                                word_index + 1 ];
    stage = parse_execution_model( model );
    break;
}</pre>
<p>We extract the execution model, translate it into a <code>VkShaderStageFlags</code> value, and store it in the <code>stage</code> variable.</p>
<p>Next, we parse the descriptor set index and binding:</p>
<pre class="source-code">
case ( SpvOpDecorate ):
{
    u32 id_index = data[ word_index + 1 ];
    Id&amp; id= ids[ id_index ];
    SpvDecoration decoration = ( SpvDecoration )data[
                                 word_index + 2 ];
    switch ( decoration )
    {
        case ( SpvDecorationBinding ):
        {
            id.binding = data[ word_index + 3 ];
            break;
        }
        case ( SpvDecorationDescriptorSet ):
        {
            id.set = data[ word_index + 3 ];
            break;
        }
    }
    break;
}</pre>
<p>First, we retrieve the index of the ID. As we mentioned previously, variables can be forward declared, and we might have to update the values for the same ID multiple times. Next, we retrieve the value of the decoration. We are only interested in the descriptor set index (<code>SpvDecorationDescriptorSet</code>) and binding (<code>SpvDecorationBinding</code>) and we store their values in the entry for this ID.</p>
<p>We follow with an example of a variable type:</p>
<pre class="source-code">
case ( SpvOpTypeVector ):
{
    u32 id_index = data[ word_index + 1 ];
    Id&amp; id= ids[ id_index ];
    id.op = op;
    id.type_index = data[ word_index + 2 ];
    id.count = data[ word_index + 3 ];
    break;
}</pre>
<p>As we saw in the disassembly, a vector is defined by its entry type and count. We store them in the <code>type_index</code> and <code>count</code> members of the ID struct. Here, we also see how an ID can refer to another one if needed. The <code>type_index</code> member stores the index to another entry in the <code>ids</code> array and can be used later to retrieve additional type information.</p>
<p>Next, we have a sampler definition:</p>
<pre class="source-code">
case ( SpvOpTypeSampler ):
{
    u32 id_index = data[ word_index + 1 ];
    RASSERT( id_index &lt; id_bound );
    Id&amp; id= ids[ id_index ];
    id.op = op;
    break;
}</pre>
<p>We only need to store the <code>Op</code> type for this entry. Finally, we have the entry for a variable type:</p>
<pre class="source-code">
case ( SpvOpVariable ):
{
    u32 id_index = data[ word_index + 2 ];
    Id&amp; id= ids[ id_index ];
    id.op = op;
    id.type_index = data[ word_index + 1 ];
    id.storage_class = ( SpvStorageClass )data[
                         word_index + 3 ];
    break;
}</pre>
<p>The relevant information for this entry is <code>type_index</code>, which will always refer to an entry of <code>pointer</code> type and the storage class. The storage class tells us which entries are variables that we are interested in and which ones we can skip.</p>
<p>And that is exactly what the next part of the code is doing. Once we finish parsing all IDs, we loop over each ID entry and identify the ones we are interested in. We first identify all variables:</p>
<pre class="source-code">
for ( u32 id_index = 0; id_index &lt; ids.size; ++id_index ) {
    Id&amp; id= ids[ id_index ];
    if ( id.op == SpvOpVariable ) {</pre>
<p>Next, we use the variable storage class to determine whether it is a uniform variable:</p>
<pre class="source-code">
switch ( id.storage_class ) {
    case ( SpvStorageClassUniform ):
    case ( SpvStorageClassUniformConstant ):
    {</pre>
<p>We are only interested in the <code>Uniform</code> and <code>UniformConstant</code> variables. We then retrieve the <code>uniform</code> type. Remember, there is a double indirection to retrieve the actual type of a variable: first, we get the <code>pointer</code> type, and from the <code>pointer</code> type, we get to the real type of the variable. We have highlighted the code that does this:</p>
<pre class="source-code">
Id&amp; uniform_type = ids[ ids[ id.type_index ].type_index ];
DescriptorSetLayoutCreation&amp; setLayout =
parse_result-&gt;sets[ id.set ];
setLayout.set_set_index( id.set );
DescriptorSetLayoutCreation::Binding binding{ };
binding.start = id.binding;
binding.count = 1;</pre>
<p>After retrieving the type, we get the <code>DescriptorSetLayoutCreation</code> entry for the set this variable is part of. We then create a new <code>binding</code> entry and store the <code>binding</code> value. We always assume a count of <code>1</code> for each resource.</p>
<p>In this last step, we determine the resource type for this binding and add its entry to the set layout:</p>
<pre class="source-code">
switch ( uniform_type.op ) {
    case (SpvOpTypeStruct):
    {
        binding.type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
        binding.name = uniform_type.name.text;
        break;
    }
    case (SpvOpTypeSampledImage):
    {
        binding.type = VK_DESCRIPTOR_TYPE_COMBINED
        _IMAGE_SAMPLER;
        binding.name = id.name.text;
        break;
    }
}
setLayout.add_binding_at_index( binding, id.binding );</pre>
<p>We use the <code>Op</code> type to determine the type of resource we have found. So far, we are only interested in <code>Struct</code> for uniform buffers and <code>SampledImage</code> for textures. We are going to add support for more types when needed for the remainder of the book.</p>
<p>While it’s possible to distinguish between uniform buffers and storage buffers, the binary data cannot determine whether a buffer is dynamic or not. In our implementation, the application code needs to specify this detail.</p>
<p>An alternative would be to use a naming convention (prefixing dynamic buffers with <code>dyn_</code>, for instance) so that dynamic buffers can be automatically identified.</p>
<p>This concludes our introduction to the SPIR-V binary format. It might take a couple of readings to fully understand how it works, but don’t worry, it certainly took us a few iterations to fully understand it!</p>
<p>Knowing how to parse SPIR-V data is an important tool to automate other aspects of graphics development. It can be used, for instance, to automate the generation of C++ headers to keep CPU and GPU structs in sync. We encourage you to expand our implementation to add support for the features you might need!</p>
<p>In this section, we have explained how to compile a shader source into SPIR-V. We have shown how the SPIR-V binary format is organized and how to parse this data to help us automatically create a pipeline layout.</p>
<p>In the next and final section of this chapter, we are going to add pipeline caching to our GPU device implementation.</p>
<h1 id="_idParaDest-43"><a id="_idTextAnchor042"/>Improving load times with a pipeline cache</h1>
<p>Each time we create a graphics pipeline and, to a lesser extent, a compute pipeline, the driver has to analyze and compile the shaders we have provided. It also has to inspect the state we have defined in the creation structure and translate it into instructions to program the different units of the GPU. This process is quite expensive, and it’s one of the reasons why, in Vulkan we have to define most of the pipeline state upfront.</p>
<p>In this section, we are going to add pipeline caching to our GPU device implementation to improve loading times. If your application has to create thousands of pipelines, it can incur a significant startup time or, for a game, long loading times between levels.</p>
<p>The technique described in this section will help to reduce the time spent creating pipelines. The first change you will notice is that the <code>GpuDevice::create_pipeline</code> method accepts a new optional parameter that defines the path of a pipeline cache file:</p>
<pre class="source-code">
GpuDevice::create_pipeline( const PipelineCreation&amp;
                            creation, const char*
                            cache_path )</pre>
<p>We then need to define the <code>VkPipelineCache</code> structure:</p>
<pre class="source-code">
VkPipelineCache pipeline_cache = VK_NULL_HANDLE;
VkPipelineCacheCreateInfo pipeline_cache_create_info {
    VK_STRUCTURE_TYPE_PIPELINE_CACHE_CREATE_INFO };</pre>
<p>The next step is to check whether the pipeline cache file already exists. If it does, we load the file data and add it to the pipeline cache creation:</p>
<pre class="source-code">
FileReadResult read_result = file_read_binary( cache_path,
                                               allocator );
pipeline_cache_create_info.initialDataSize =
  read_result.size;
pipeline_cache_create_info.pInitialData = read_result.data;</pre>
<p>If the file doesn’t exist, we don’t have to make any further changes to the creation structure. We can now call <code>vkCreatePipelineCache</code>:</p>
<pre class="source-code">
vkCreatePipelineCache( vulkan_device,
                       &amp;pipeline_cache_create_info,
                       vulkan_allocation_callbacks,
                       &amp;pipeline_cache );</pre>
<p>This will return a handle to a <code>VkPipelineCache</code> object that we are going to use when creating the pipeline object:</p>
<pre class="source-code">
vkCreateGraphicsPipelines( vulkan_device, pipeline_cache,
                           1, &amp;pipeline_info,
                           vulkan_allocation_callbacks,
                           &amp;pipeline-&gt;vk_pipeline );</pre>
<p>We can do the same for compute pipelines:</p>
<pre class="source-code">
vkCreateComputePipelines( vulkan_device, pipeline_cache, 1,
                          &amp;pipeline_info,
                          vulkan_allocation_callbacks,
                          &amp;pipeline-&gt;vk_pipeline );</pre>
<p>If we have loaded a pipeline cache file, the driver will use the data to accelerate the pipeline creation. If, on the other hand, this is the first time we are creating the given pipeline, we can now query and store the pipeline cache data for later reuse:</p>
<pre class="source-code">
sizet cache_data_size = 0;
vkGetPipelineCacheData( vulkan_device, pipeline_cache,
                        &amp;cache_data_size, nullptr );
void* cache_data = allocator-&gt;allocate( cache_data_size, 64 );
vkGetPipelineCacheData( vulkan_device, pipeline_cache,
                        &amp;cache_data_size, cache_data );
file_write_binary( cache_path, cache_data, cache_data_size );</pre>
<p>We first call <code>vkGetPipelineCacheData</code> with <code>nullptr</code> for the data member to retrieve the cache data size. We then allocate the memory that is needed to store the cache data and call <code>vkGetPipelineCacheData</code> again, this time with a pointer to the memory where the cache data will be stored. Finally, we write this data to the file specified when <code>GpuDevice::create_pipeline</code> was called.</p>
<p>We are now done with the pipeline cache data structure, and it can be destroyed:</p>
<pre class="source-code">
vkDestroyPipelineCache( vulkan_device, pipeline_cache,
                        vulkan_allocation_callbacks );</pre>
<p>Before we conclude, we want to mention a shortcoming of pipeline caching. The data in the cache is controlled by each vendor driver implementation. When a new driver version is released, the data format of the cache might change and become incompatible with the data previously stored in the cache file. Having a cache file, in this case, might provide no benefit as the driver cannot make use of it.</p>
<p>For this reason, each driver has to prefix the cache data with the following header:</p>
<pre class="source-code">
struct VkPipelineCacheHeaderVersionOne {
    uint32_t                       headerSize;
    VkPipelineCacheHeaderVersion   headerVersion;
    uint32_t                       vendorID;
    uint32_t                       deviceID;
    uint8_t                        pipeline
                                   CacheUUID[VK_UUID_SIZE];
}</pre>
<p>When we load the cache data from disk, we can compare the values in the header against the values returned by the driver and GPU we are running on:</p>
<pre class="source-code">
VkPipelineCacheHeaderVersionOne* cache_header =
    (VkPipelineCacheHeaderVersionOne*)read_result.data;
if ( cache_header-&gt;deviceID == vulkan_physical
     _properties.deviceID &amp;&amp; cache_header-&gt;vendorID ==
     vulkan_physical_properties.vendorID &amp;&amp;
     memcmp( cache_header-&gt;pipelineCacheUUID,
     vulkan_physical_properties.pipelineCacheUUID,
     VK_UUID_SIZE ) == 0 ) {
    pipeline_cache_create_info.initialDataSize =
    read_result.size;
    pipeline_cache_create_info.pInitialData =
    read_result.data;
}
else
{
    cache_exists = false;
}</pre>
<p>If the values in the header match the ones of the device we are running on, we use the cache data as before. If they don’t, we act as if the cache didn’t exist and store a new version after the pipeline has been created.</p>
<p>In this section, we have demonstrated how to leverage pipeline caching to speed up pipeline creation at runtime. We have highlighted the changes made to our GPU device implementation to make use of this feature and how it has been used in this chapter’s code.</p>
<h1 id="_idParaDest-44"><a id="_idTextAnchor043"/>Summary</h1>
<p>In this chapter, we improved our GPU device implementation to make it easier to manage a large number of textures with bindless resources. We explained which extensions are needed and detailed which changes are required when creating a descriptor set layout to allow the use of bindless resources. We then showed the changes needed when creating a descriptor set to update the array of textures in use.</p>
<p>We then added automatic pipeline layout generation by parsing the SPIR-V binaries generated by the <code>glslang</code> compiler for our shaders. We provided an overview of the SPIR-V binary data format and explained how to parse it to extract the resources bound to a shader, and how to use this information to create a pipeline layout.</p>
<p>Finally, we enhanced our pipeline creation API by adding pipeline caching to improve the load times of our applications after the first run. We presented the Vulkan APIs that are needed to either generate or load the pipeline cache data. We also explained some of the limitations of pipeline caching and how to deal with them.</p>
<p>All the techniques presented in this chapter have the common goal of making it easier to deal with large projects and reduce manual code changes to a minimum when making changes to our shaders or materials.</p>
<p>We will continue to scale our engine in the next chapter by adding multithreading to record multiple command buffers or to submit multiple workloads in parallel to the GPU.</p>
<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/>Further reading</h1>
<p>We have covered only a small subset of the SPIR-V specification. If you would like to expand our parser implementation for your needs, we highly recommend consulting the official specification: <a href="https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.xhtml">https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.xhtml</a>.</p>
<p>We wrote a custom SPIR-V parser for this chapter, primarily for educational purposes. For your own project, we recommend using the existing reflection library from Khronos: <a href="https://github.com/KhronosGroup/SPIRV-Reflect">https://github.com/KhronosGroup/SPIRV-Reflect</a>.</p>
<p>It provides the functionality described in this chapter to deduce the pipeline layout for a shader binary and many other features.</p>
</div>
</div></body></html>