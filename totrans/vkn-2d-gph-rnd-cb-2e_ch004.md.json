["```cpp\n const aiScene* scene = aiImportFile(\n    “data/rubber_duck/scene.gltf”, aiProcess_Triangulate);\n  const aiMesh* mesh = scene->mMeshes[0];\n  std::vector<vec3> positions;\n  std::vector<uint32_t> indices;\n  positions.reserve(mesh->mNumVertices);\n  indices.reserve(3 * mesh->mNumFaces);\n  for (unsigned int i = 0; i != mesh->mNumVertices; i++) {\n    const aiVector3D v = mesh->mVertices[i];\n    positions.push_back(vec3(v.x, v.y, v.z));\n  }\n  for (unsigned int i = 0; i != mesh->mNumFaces; i++) {\n    for (int j = 0; j != 3; j++)\n      indices.push_back(mesh->mFaces[i].mIndices[j]);\n  }\n  aiReleaseImport(scene);\n```", "```cpp\n Holder<lvk::BufferHandle> vertexBuffer = ctx->createBuffer(\n      { .usage     = lvk::BufferUsageBits_Vertex,\n        .storage   = lvk::StorageType_Device,\n        .size      = sizeof(vec3) * positions.size(),\n        .data      = positions.data(),\n        .debugName = “Buffer: vertex” }, nullptr);\n  Holder<lvk::BufferHandle> indexBuffer = ctx->createBuffer(\n      { .usage     = lvk::BufferUsageBits_Index,\n        .storage   = lvk::StorageType_Device,\n        .size      = sizeof(uint32_t) * indices.size(),\n        .data      = indices.data(),\n        .debugName = “Buffer: index” }, nullptr);\n```", "```cpp\n Holder<lvk::TextureHandle> depthTexture = ctx->createTexture({\n        .type       = lvk::TextureType_2D,\n        .format     = lvk::Format_Z_F32,\n        .dimensions = {(uint32_t)width, (uint32_t)height},\n        .usage      = lvk::TextureUsageBits_Attachment,\n        .debugName  = “Depth buffer”,\n    });\n```", "```cpp\n const lvk::VertexInput vdesc = {\n    .attributes    = { { .location = 0, \n                         .format = lvk::VertexFormat::Float3 } },\n    .inputBindings = { { .stride = sizeof(vec3) } },\n  };\n```", "```cpp\n Holder<lvk::ShaderModuleHandle> vert =\n    loadShaderModule(ctx, “Chapter03/01_Assimp/src/main.vert”);\n  Holder<lvk::ShaderModuleHandle> frag =\n    loadShaderModule(ctx, “Chapter03/01_Assimp/src/main.frag”);\n  Holder<lvk::RenderPipelineHandle> pipelineSolid =\n    ctx->createRenderPipeline({\n      .vertexInput = vdesc,\n      .smVert      = vert,\n      .smFrag      = frag,\n      .color       = { { .format = ctx->getSwapchainFormat() } },\n      .depthFormat = ctx->getFormat(depthTexture),\n      .cullMode    = lvk::CullMode_Back,\n  });\n```", "```cpp\n const uint32_t isWireframe = 1;\n  Holder<lvk::RenderPipelineHandle> pipelineWireframe =\n    ctx->createRenderPipeline({\n      .vertexInput = vdesc,\n      .smVert      = vert,\n      .smFrag      = frag,\n      .specInfo = { .entries = { { .constantId = 0,\n                                   .size = sizeof(uint32_t) } },\n        .data = &isWireframe, .dataSize = sizeof(isWireframe) },\n      .color       = { { .format = ctx->getSwapchainFormat() } },\n      .depthFormat = ctx->getFormat(depthTexture),\n      .cullMode    = lvk::CullMode_Back,\n      .polygonMode = lvk::PolygonMode_Line,\n  });\n```", "```cpp\n const lvk::DepthState dState = {\n    .compareOp = lvk::CompareOp_Less, .isDepthWriteEnabled = true   };\n```", "```cpp\n while (!glfwWindowShouldClose(window)) {\n    …\n    const float ratio = width / height;\n    const mat4 p = glm::perspective(45.0f, ratio, 0.1f, 1000.0f);\n```", "```cpp\n const mat4 m = glm::rotate(\n      mat4(1.0f), glm::radians(-90.0f), vec3(1, 0, 0));\n    const mat4 v = glm::rotate(glm::translate(mat4(1.0f),\n      vec3(0.0f, -0.5f, -1.5f)), (float)glfwGetTime(),\n      vec3(0.0f, 1.0f, 0.0f));\n```", "```cpp\n const lvk::RenderPass renderPass = {\n      .color = {\n        { .loadOp = LoadOp_Clear, .clearColor = { 1., 1., 1., 1\\. }}\n      },\n      .depth = { .loadOp = LoadOp_Clear, .clearDepth = 1\\. }\n    };\n    const lvk::Framebuffer framebuffer = {\n      .color = { { .texture = ctx->getCurrentSwapchainTexture() } },\n      .depthStencil = { .texture = depthTexture },\n    };\n```", "```cpp\n lvk::ICommandBuffer& buf = ctx->acquireCommandBuffer();\n    buf.cmdBeginRendering(renderPass, framebuffer);\n```", "```cpp\n buf.cmdBindVertexBuffer(0, vertexBuffer);\n    buf.cmdBindIndexBuffer(indexBuffer, lvk::IndexFormat_UI32);\n```", "```cpp\n buf.cmdBindRenderPipeline(pipelineSolid);\n    buf.cmdBindDepthState(dState);\n    buf.cmdPushConstants(p * v * m);\n    buf.cmdDrawIndexed(lvk::Primitive_Triangle, indices.size());\n```", "```cpp\n buf.cmdBindRenderPipeline(pipelineWireframe);\n    buf.cmdSetDepthBias(0.0f, -1.0f, 0.0f);\n    buf.cmdDrawIndexed(lvk::Primitive_Triangle, indices.size());\n```", "```cpp\n buf.cmdEndRendering();\n    ctx->submit(buf, ctx->getCurrentSwapchainTexture());\n```", "```cpp\nstruct BufferDesc final {\n  uint8_t usage = 0;\n  StorageType storage = StorageType_HostVisible;\n  size_t size = 0;\n  const void* data = nullptr;\n  const char* debugName = ““;\n};\n```", "```cpp\nenum BufferUsageBits : uint8_t {\n  BufferUsageBits_Index = 1 << 0,\n  BufferUsageBits_Vertex = 1 << 1,\n  BufferUsageBits_Uniform = 1 << 2,\n  BufferUsageBits_Storage = 1 << 3,\n  BufferUsageBits_Indirect = 1 << 4,\n};\n```", "```cpp\nHolder<BufferHandle> VulkanContext::createBuffer(\n  const BufferDesc& requestedDesc, Result* outResult) {\n  BufferDesc desc = requestedDesc;\n  if (!useStaging_ && (desc.storage == StorageType_Device))\n    desc.storage = StorageType_HostVisible;\n```", "```cpp\n VkBufferUsageFlags usageFlags = desc.storage == StorageType_Device ?\n    VK_BUFFER_USAGE_TRANSFER_DST_BIT |\n    VK_BUFFER_USAGE_TRANSFER_SRC_BIT : 0;\n```", "```cpp\n if (desc.usage & BufferUsageBits_Index)\n    usageFlags |= VK_BUFFER_USAGE_INDEX_BUFFER_BIT;\n  if (desc.usage & BufferUsageBits_Vertex)\n    usageFlags |= VK_BUFFER_USAGE_VERTEX_BUFFER_BIT;\n  if (desc.usage & BufferUsageBits_Uniform)\n    usageFlags |= VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT |\n                  VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT;\n  if (desc.usage & BufferUsageBits_Storage)\n    usageFlags |= VK_BUFFER_USAGE_STORAGE_BUFFER_BIT |\n                  VK_BUFFER_USAGE_TRANSFER_DST_BIT |\n                  VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT;\n  if (desc.usage & BufferUsageBits_Indirect)\n    usageFlags |= VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT |\n                  VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT;\n```", "```cpp\n const VkMemoryPropertyFlags memFlags =\n    storageTypeToVkMemoryPropertyFlags(desc.storage);\n  Result result;\n  BufferHandle handle = createBuffer(\n    desc.size, usageFlags, memFlags, &result, desc.debugName);\n```", "```cpp\n if (desc.data) {\n    upload(handle, desc.data, desc.size, 0);\n  }\n  Result::setResult(outResult, Result());\n  return {this, handle};\n}\n```", "```cpp\nclass VulkanBuffer final {\n public:\n  VulkanBuffer() = default;\n  VulkanBuffer(lvk::VulkanContext* ctx,\n               VkDevice device,\n               VkDeviceSize bufferSize,\n               VkBufferUsageFlags usageFlags,\n               VkMemoryPropertyFlags memFlags,\n               const char* debugName = nullptr);\n  ~VulkanBuffer();\n```", "```cpp\n void bufferSubData(size_t offset, size_t size, const void* data);\n  void getBufferSubData(size_t offset, size_t size, void* data);\n  [[nodiscard]] uint8_t* getMappedPtr() const {\n    return static_cast<uint8_t*>(mappedPtr_);\n  }\n  bool isMapped() const { return mappedPtr_ != nullptr; }\n  void flushMappedMemory(VkDeviceSize offset, VkDeviceSize size);\n```", "```cpp\n lvk::VulkanContext* ctx_ = nullptr;\n  VkDevice device_ = VK_NULL_HANDLE;\n  VkBuffer vkBuffer_ = VK_NULL_HANDLE;\n  VkDeviceMemory vkMemory_ = VK_NULL_HANDLE;\n  VmaAllocationCreateInfo vmaAllocInfo_ = {};\n  VmaAllocation vmaAllocation_ = VK_NULL_HANDLE;\n  VkDeviceAddress vkDeviceAddress_ = 0;\n  VkDeviceSize bufferSize_ = 0;\n  VkBufferUsageFlags vkUsageFlags_ = 0;\n  VkMemoryPropertyFlags vkMemFlags_ = 0;\n  void* mappedPtr_ = nullptr;\n};\n```", "```cpp\nlvk::VulkanBuffer::VulkanBuffer(lvk::VulkanContext* ctx,\n                                VkDevice device,\n                                VkDeviceSize bufferSize,\n                                VkBufferUsageFlags usageFlags,\n                                VkMemoryPropertyFlags memFlags,\n                                const char* debugName) :\n  ctx_(ctx), device_(device), bufferSize_(bufferSize),\n  vkUsageFlags_(usageFlags), vkMemFlags_(memFlags)\n{\n  const VkBufferCreateInfo ci = {\n      .sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO,\n      .pNext = nullptr,\n      .flags = 0,\n      .size = bufferSize,\n      .usage = usageFlags,\n      .sharingMode = VK_SHARING_MODE_EXCLUSIVE,\n      .queueFamilyIndexCount = 0,\n      .pQueueFamilyIndices = nullptr,\n  };\n```", "```cpp\n if (LVK_VULKAN_USE_VMA) {\n    if (memFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) {\n      vmaAllocInfo_.requiredFlags =\n        VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;\n      vmaAllocInfo_.preferredFlags =\n        VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |\n        VK_MEMORY_PROPERTY_HOST_CACHED_BIT;\n      vmaAllocInfo_.flags = VMA_ALLOCATION_CREATE_MAPPED_BIT |\n        VMA_ALLOCATION_CREATE_HOST_ACCESS_RANDOM_BIT;\n    }\n    if (memFlags & VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)\n      vmaAllocInfo_.requiredFlags |=\n        VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;\n    vmaAllocInfo_.usage = VMA_MEMORY_USAGE_AUTO;\n    vmaCreateBuffer((VmaAllocator)ctx_->getVmaAllocator(), &ci,\n      &vmaAllocInfo_, &vkBuffer_, &vmaAllocation_, nullptr);\n```", "```cpp\n if (memFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) {\n      vmaMapMemory((VmaAllocator)ctx_->getVmaAllocator(),\n        vmaAllocation_, &mappedPtr_);\n    }\n  } else {\n```", "```cpp\n vkCreateBuffer(device_, &ci, nullptr, &vkBuffer_);\n    VkMemoryRequirements requirements = {};\n    vkGetBufferMemoryRequirements(device_, vkBuffer_, &requirements);\n    lvk::allocateMemory(ctx_->getVkPhysicalDevice(), device_,\n      &requirements, memFlags, &vkMemory_));\n    vkBindBufferMemory(device_, vkBuffer_, vkMemory_, 0);\n```", "```cpp\n if (memFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) {\n      vkMapMemory(device_, vkMemory_, 0, bufferSize_, 0, &mappedPtr_);\n    }\n  }\n```", "```cpp\n lvk::setDebugObjectName(\n    device_, VK_OBJECT_TYPE_BUFFER, (uint64_t)vkBuffer_, debugName);\n```", "```cpp\n if (usageFlags & VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT) {\n    const VkBufferDeviceAddressInfo ai = {\n      .sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO,\n      .buffer = vkBuffer_,     };\n    vkDeviceAddress_ = vkGetBufferDeviceAddress(device_, &ai);\n  }\n}\n```", "```cpp\nlvk::VulkanBuffer::~VulkanBuffer() {\n  if (!ctx_) return;\n  if (LVK_VULKAN_USE_VMA) {\n    if (mappedPtr_)\n      vmaUnmapMemory(\n        (VmaAllocator)ctx_->getVmaAllocator(), vmaAllocation_);\n    ctx_->deferredTask(std::packaged_task<void()>(\n      [vma = ctx_->getVmaAllocator(),\n       buffer = vkBuffer_,\n       allocation = vmaAllocation_]() {\n      vmaDestroyBuffer((VmaAllocator)vma, buffer, allocation);\n    }));\n  } else {\n```", "```cpp\n if (mappedPtr_)\n      vkUnmapMemory(device_, vkMemory_);\n    ctx_->deferredTask(std::packaged_task<void()>(\n      [device = device_, buffer = vkBuffer_, memory = vkMemory_]() {\n      vkDestroyBuffer(device, buffer, nullptr);\n      vkFreeMemory(device, memory, nullptr);\n    }));\n  }\n}\n```", "```cpp\nvoid lvk::VulkanBuffer::flushMappedMemory(\n  VkDeviceSize offset, VkDeviceSize size) const\n{\n  if (!LVK_VERIFY(isMapped()))return;\n  if (LVK_VULKAN_USE_VMA) {\n    vmaFlushAllocation((VmaAllocator)ctx_->getVmaAllocator(),\n      vmaAllocation_, offset, size);\n  } else {\n    const VkMappedMemoryRange memoryRange = {\n      .sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,\n      .memory = vkMemory_,\n      .offset = offset,\n      .size = size,\n    };\n    vkFlushMappedMemoryRanges(device_, 1, &memoryRange);\n  }\n}\n```", "```cpp\nvoid lvk::VulkanBuffer::getBufferSubData(\n  size_t offset, size_t size, void* data) {\n  LVK_ASSERT(mappedPtr_);\n  if (!mappedPtr_) return;\n  LVK_ASSERT(offset + size <= bufferSize_);\n  const uint8_t* src = static_cast<uint8_t*>(mappedPtr_) + offset;\n  memcpy(data, src, size);\n}\n```", "```cpp\nvoid lvk::VulkanBuffer::bufferSubData(\n  size_t offset, size_t size, const void* data) {\n  if (!mappedPtr_) return;\n  LVK_ASSERT(offset + size <= bufferSize_);\n  if (data) {\n    memcpy((uint8_t*)mappedPtr_ + offset, data, size);\n  } else {\n    memset((uint8_t*)mappedPtr_ + offset, 0, size);\n  }\n}\n```", "```cpp\nvoid lvk::CommandBuffer::cmdBindVertexBuffer(uint32_t index,\n  BufferHandle buffer, size_t bufferOffset)\n{\n  if (!LVK_VERIFY(!buffer.empty()))return;\n  lvk::VulkanBuffer* buf = ctx_->buffersPool_.get(buffer);\n  VkBuffer vkBuf = buf->vkBuffer_;\n  LVK_ASSERT(buf->vkUsageFlags_ & VK_BUFFER_USAGE_VERTEX_BUFFER_BIT);\n  const VkDeviceSize offset = bufferOffset;\n  vkCmdBindVertexBuffers(\n    wrapper_->cmdBuf_, index, 1, &vkBuf, &offset);\n}\n```", "```cpp\nvoid lvk::CommandBuffer::cmdBindIndexBuffer(BufferHandle indexBuffer,\n  IndexFormat indexFormat, size_t indexBufferOffset)\n{\n  lvk::VulkanBuffer* buf = ctx_->buffersPool_.get(indexBuffer);\n  LVK_ASSERT(buf->vkUsageFlags_ & VK_BUFFER_USAGE_INDEX_BUFFER_BIT);\n  const VkIndexType type = indexFormatToVkIndexType(indexFormat);\n  vkCmdBindIndexBuffer(\n    wrapper_->cmdBuf_, buf->vkBuffer_, indexBufferOffset, type);\n}\n```", "```cpp\nResult upload(BufferHandle handle,\n  const void* data, size_t size, size_t offset = 0) = 0;\nuint8_t* getMappedPtr(BufferHandle handle) const = 0;\nuint64_t gpuAddress(BufferHandle handle, size_t offset = 0) const = 0;\nvoid flushMappedMemory(BufferHandle handle,\n  size_t offset, size_t size) const = 0;\n```", "```cpp\nResult VulkanContext::upload(lvk::BufferHandle handle,\n  const void* data, size_t size, size_t offset) {\n  if (!LVK_VERIFY(data)) return lvk::Result();\n  lvk::VulkanBuffer* buf = buffersPool_.get(handle);\n```", "```cpp\n if (!LVK_VERIFY(offset + size <= buf->bufferSize_))\n    return Result(Result::Code::ArgumentOutOfRange, “Out of range”);\n  stagingDevice_->bufferSubData(*buf, offset, size, data);\n  return lvk::Result();\n}\n```", "```cpp\nclass VulkanStagingDevice final {\n public:\n  explicit VulkanStagingDevice(VulkanContext& ctx);\n  ~VulkanStagingDevice();\n  void bufferSubData(VulkanBuffer& buffer,\n    size_t dstOffset, size_t size, const void* data);\n  void imageData2D(VulkanImage& image,\n                   const VkRect2D& imageRegion,\n                   uint32_t baseMipLevel,\n                   uint32_t numMipLevels,\n                   uint32_t layer,\n                   uint32_t numLayers,\n                   VkFormat format,\n                   const void* data[]);\n  // … imageData3D() is skipped\n```", "```cpp\n private:\n  struct MemoryRegionDesc {\n    uint32_t srcOffset_ = 0;\n    uint32_t alignedSize_ = 0;\n    SubmitHandle handle_ = {};\n  };\n```", "```cpp\n MemoryRegionDesc getNextFreeOffset(uint32_t size);\n  void waitAndReset();\n private:\n  VulkanContext& ctx_;\n  BufferHandle stagingBuffer_;\n  std::unique_ptr<lvk::VulkanImmediateCommands> immediate_;\n  uint32_t stagingBufferFrontOffset_ = 0;\n  uint32_t stagingBufferSize_ = 0;\n  uint32_t bufferCapacity_ = 0;\n  std::vector<MemoryRegionDesc> regions_;\n};\n```", "```cpp\nMemoryRegionDesc VulkanStagingDevice::getNextFreeOffset(uint32_t size) {\n  constexpr uint32_t kStagingBufferAlignment_ = 16;\n  uint32_t alignedSize = (size + kStagingBufferAlignment_ - 1) &\n     ~(kStagingBufferAlignment_ - 1);\n```", "```cpp\n auto bestIt = regions_.begin();\n  for (auto it = regions_.begin(); it != regions_.end(); it++) {\n    if (immediate_->isReady(SubmitHandle(it->handle_))) {\n      if (it->alignedSize_ >= alignedSize) {\n        SCOPE_EXIT { regions_.erase(it); };\n        return *it;\n      }\n      if (bestIt->alignedSize_ < it->alignedSize_) bestIt = it;\n    }\n  }\n```", "```cpp\n if (bestIt != regions_.end() && \n      bufferCapacity_ < bestIt->alignedSize_) {\n    regions_.erase(bestIt);\n    return *bestIt;\n  }\n  if (bufferCapacity_ == 0) waitAndReset();\n```", "```cpp\n alignedSize =\n    (alignedSize <= bufferCapacity_) ? alignedSize : bufferCapacity_;\n  const uint32_t srcOffset = stagingBufferFrontOffset_;\n  stagingBufferFrontOffset_ =\n    (stagingBufferFrontOffset_ + alignedSize) % stagingBufferSize_;\n  bufferCapacity_ -= alignedSize;\n  return {srcOffset, alignedSize};\n}\n```", "```cpp\nvoid VulkanStagingDevice::bufferSubData(VulkanBuffer& buffer,\n  size_t dstOffset, size_t size, const void* data)\n{\n  if (buffer.isMapped()) {\n    buffer.bufferSubData(dstOffset, size, data);\n    return;\n  }\n  lvk::VulkanBuffer* stagingBuffer =\n    ctx_.buffersPool_.get(stagingBuffer_);\n```", "```cpp\n while (size) {\n    MemoryRegionDesc desc = getNextFreeOffset((uint32_t)size);\n    const uint32_t chunkSize =\n      std::min((uint32_t)size, desc.alignedSize_);\n```", "```cpp\n stagingBuffer->bufferSubData(desc.srcOffset_, chunkSize, data);\n```", "```cpp\n const VkBufferCopy copy = {desc.srcOffset_, dstOffset, chunkSize};\n    auto& wrapper = immediate_->acquire();\n    vkCmdCopyBuffer(wrapper.cmdBuf_,\n      stagingBuffer->vkBuffer_, buffer.vkBuffer_, 1, &copy);\n    desc.handle_ = immediate_->submit(wrapper);\n```", "```cpp\n regions_.push_back(desc);\n    size -= chunkSize;\n    data = (uint8_t*)data + chunkSize;\n    dstOffset += chunkSize;\n  }\n}\n```", "```cpp\nvoid VulkanStagingDevice::imageData2D(VulkanImage& image,\n                                      const VkRect2D& imageRegion,\n                                      uint32_t baseMipLevel,\n                                      uint32_t numMipLevels,\n                                      uint32_t layer,\n                                      uint32_t numLayers,\n                                      VkFormat format,\n                                      const void* data[])\n{\n  uint32_t mipSizes[LVK_MAX_MIP_LEVELS];\n```", "```cpp\n uint32_t width = image.vkExtent_.width >> baseMipLevel;\n  uint32_t height = image.vkExtent_.height >> baseMipLevel;\n  const Format texFormat(vkFormatToFormat(format));\n```", "```cpp\n uint32_t layerStorageSize = 0;\n  for (uint32_t i = 0; i < numMipLevels; ++i) {\n    const uint32_t mipSize = lvk::getTextureBytesPerLayer(\n      image.vkExtent_.width, image.vkExtent_.height, texFormat, i);\n    layerStorageSize += mipSize;\n    mipSizes[i] = mipSize;\n    width = width <= 1 ? 1 : width >> 1;\n    height = height <= 1 ? 1 : height >> 1;\n  }\n```", "```cpp\n const uint32_t storageSize = layerStorageSize * numLayers;\n  MemoryRegionDesc desc = getNextFreeOffset(layerStorageSize);\n  if (desc.alignedSize_ < storageSize) {\n    waitAndReset();\n    desc = getNextFreeOffset(storageSize);\n  }\n  LVK_ASSERT(desc.alignedSize_ >= storageSize);\n```", "```cpp\n lvk::VulkanBuffer* stagingBuffer =\n    ctx_.buffersPool_.get(stagingBuffer_);\n  auto& wrapper = immediate_->acquire();\n  for (uint32_t layer = 0; layer != numLayers; layer++) {\n    stagingBuffer->bufferSubData(\n      desc.srcOffset_ + layer * layerStorageSize,\n      layerStorageSize,\n      data[layer]);\n    uint32_t mipLevelOffset = 0;\n    for (uint32_t mipLevel = 0; mipLevel < numMipLevels; ++mipLevel) {\n      const auto currentMipLevel = baseMipLevel + mipLevel;\n```", "```cpp\n lvk::imageMemoryBarrier(wrapper.cmdBuf_,\n                              image.vkImage_,\n                              0,\n                              VK_ACCESS_TRANSFER_WRITE_BIT,\n                              VK_IMAGE_LAYOUT_UNDEFINED,\n                              VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,\n                              VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT,\n                              VK_PIPELINE_STAGE_TRANSFER_BIT,\n                              VkImageSubresourceRange{\n                                VK_IMAGE_ASPECT_COLOR_BIT,\n                                currentMipLevel, 1, layer, 1});\n```", "```cpp\n const VkRect2D region = {\n        .offset = {.x = imageRegion.offset.x >> mipLevel,\n                   .y = imageRegion.offset.y >> mipLevel},\n        .extent = {.width =\n                     max(1u, imageRegion.extent.width >> mipLevel),\n                   .height=\n                     max(1u, imageRegion.extent.height >> mipLevel)},\n      };\n      const VkBufferImageCopy copy = {\n          .bufferOffset =\n            desc.srcOffset_ + layer*layerStorageSize + mipLevelOffset,\n          .bufferRowLength = 0,\n          .bufferImageHeight = 0,\n          .imageSubresource = VkImageSubresourceLayers{\n            VK_IMAGE_ASPECT_COLOR_BIT, currentMipLevel, layer, 1},\n          .imageOffset = {.x = region.offset.x,\n                          .y = region.offset.y,\n                          .z = 0},\n          .imageExtent = {.width = region.extent.width,\n                          .height = region.extent.height,\n                          .depth = 1u},\n      };\n      vkCmdCopyBufferToImage(wrapper.cmdBuf_,\n        stagingBuffer->vkBuffer_, image.vkImage_,\n        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &copy);\n```", "```cpp\n lvk::imageMemoryBarrier(\n        wrapper.cmdBuf_,\n        image.vkImage_,\n        VK_ACCESS_TRANSFER_READ_BIT | VK_ACCESS_TRANSFER_WRITE_BIT,\n        VK_ACCESS_SHADER_READ_BIT,\n        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,\n        VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,\n        VK_PIPELINE_STAGE_TRANSFER_BIT,\n        VK_PIPELINE_STAGE_ALL_COMMANDS_BIT,\n        VkImageSubresourceRange{\n          VK_IMAGE_ASPECT_COLOR_BIT, currentMipLevel, 1, layer, 1});\n```", "```cpp\n mipLevelOffset += mipSizes[mipLevel];\n    }\n  }\n```", "```cpp\n desc.handle_ = immediate_->submit(wrapper);\n  image.vkImageLayout_ = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;\n  regions_.push_back(desc);\n}\n```", "```cpp\n int w, h, comp;\n  const uint8_t* img = stbi_load(“data/wood.jpg”, &w, &h, &comp, 4);\n```", "```cpp\n lvk::Holder<lvk::TextureHandle> texture = ctx->createTexture({\n      .type       = lvk::TextureType_2D,\n      .format     = lvk::Format_RGBA_UN8,\n      .dimensions = {(uint32_t)w, (uint32_t)h},\n      .usage      = lvk::TextureUsageBits_Sampled,\n      .data       = img,\n      .debugName  = “03_STB.jpg”,\n  });\n```", "```cpp\n stbi_image_free((void*)img);\n```", "```cpp\n const struct PerFrameData {\n      mat4 mvp;\n      uint32_t textureId;\n    } pc = {\n      .mvp       = p * m,\n      .textureId = texture.index(),\n    };\n    …\n    buf.cmdPushConstants(pc);\n    buf.cmdDraw(lvk::Primitive_TriangleStrip, 0, 4);\n    …\n```", "```cpp\n#version 460 core\nlayout(push_constant) uniform PerFrameData {\n  uniform mat4 MVP;\n  uint textureId;\n};\nlayout (location=0) out vec2 uv;\nconst vec2 pos[4] = vec2[4](\n  vec2(1.0, -1.0), vec2(1.0,  1.0), vec2(-1.0, -1.0), vec2(-1.0, 1.0)\n);\nvoid main() {\n  gl_Position = MVP * vec4(0.5 * pos[gl_VertexIndex], 0.0, 1.0);\n  uv = (pos[gl_VertexIndex]+vec2(0.5)) * 0.5;\n}\n```", "```cpp\n#version 460 core\n#extension GL_EXT_nonuniform_qualifier : require\nlayout (set = 0, binding = 0) uniform texture2D kTextures2D[];\nlayout (set = 0, binding = 1) uniform sampler kSamplers[];\nlayout (location=0) in vec2 uv;\nlayout (location=0) out vec4 out_FragColor;\nlayout(push_constant) uniform PerFrameData {\n  uniform mat4 MVP;\n  uint textureId;\n};\n```", "```cpp\nvec4 textureBindless2D(uint textureid, uint samplerid, vec2 uv) {\n  return texture(sampler2D(kTextures2D[textureid],\n                           kSamplers[samplerid]), uv);\n}\nvoid main() {\n  out_FragColor = textureBindless2D(textureId, 0, uv);\n}\n```", "```cpp\nHolder< TextureHandle> VulkanContext::createTexture(\n  const TextureDesc& requestedDesc,\n  const char* debugName,\n  Result* outResult)\n{\n  TextureDesc desc(requestedDesc);\n  if (debugName && *debugName) desc.debugName = debugName;\n```", "```cpp\n const VkFormat vkFormat = lvk::isDepthOrStencilFormat(desc.format) ?\n    getClosestDepthStencilFormat(desc.format) :\n    formatToVkFormat(desc.format);\n  const lvk::TextureType type = desc.type;\n```", "```cpp\n VkImageUsageFlags usageFlags = desc.storage == StorageType_Device ?\n    VK_IMAGE_USAGE_TRANSFER_DST_BIT : 0;\n  if (desc.usage & lvk::TextureUsageBits_Sampled)\n    usageFlags |= VK_IMAGE_USAGE_SAMPLED_BIT;\n  if (desc.usage & lvk::TextureUsageBits_Storage)\n    usageFlags |= VK_IMAGE_USAGE_STORAGE_BIT;\n  if (desc.usage & lvk::TextureUsageBits_Attachment)\n    usageFlags |= lvk::isDepthOrStencilFormat(desc.format) ?\n      VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT :\n      VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT;\n```", "```cpp\n usageFlags |= VK_IMAGE_USAGE_TRANSFER_SRC_BIT;\n  const VkMemoryPropertyFlags memFlags =\n    storageTypeToVkMemoryPropertyFlags(desc.storage);\n```", "```cpp\n const bool hasDebugName = desc.debugName && *desc.debugName;\n  char debugNameImage[256] = {0};\n  char debugNameImageView[256] = {0};\n  if (hasDebugName) {\n    snprintf(debugNameImage, sizeof(debugNameImage)-1,\n      “Image: %s”, desc.debugName);\n    snprintf(debugNameImageView, sizeof(debugNameImageView) - 1,\n      “Image View: %s”, desc.debugName);\n  }\n```", "```cpp\n VkImageCreateFlags createFlags = 0;\n  uint32_t arrayLayerCount = static_cast<uint32_t>(desc.numLayers);\n  VkImageViewType imageViewType;\n  VkImageType imageType;\n  VkSampleCountFlagBits samples = VK_SAMPLE_COUNT_1_BIT;\n  switch (desc.type) {\n```", "```cpp\n case TextureType_2D:\n      imageViewType = VK_IMAGE_VIEW_TYPE_2D;\n      imageType = VK_IMAGE_TYPE_2D;\n      samples = lvk::getVulkanSampleCountFlags(desc.numSamples);\n      break;\n    case TextureType_3D:\n      imageViewType = VK_IMAGE_VIEW_TYPE_3D;\n      imageType = VK_IMAGE_TYPE_3D;\n      break;\n```", "```cpp\n case TextureType_Cube:\n      imageViewType = VK_IMAGE_VIEW_TYPE_CUBE;\n      arrayLayerCount *= 6;\n      imageType = VK_IMAGE_TYPE_2D;\n      createFlags = VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT;\n      break;\n  }\n```", "```cpp\n Result result;\n  std::shared_ptr<VulkanImage> image = createImage(imageType,\n    VkExtent3D{ desc.dimensions.width,\n                desc.dimensions.height,\n                desc.dimensions.depth},\n    vkFormat,\n    desc.numMipLevels,\n    arrayLayerCount,\n    VK_IMAGE_TILING_OPTIMAL,\n    usageFlags,\n    memFlags,\n    createFlags,\n    samples,\n    &result,\n    debugNameImage);\n```", "```cpp\n VkImageAspectFlags aspect = 0;\n  if (image->isDepthFormat_ || image->isStencilFormat_) {\n    if (image->isDepthFormat_) {\n      aspect |= VK_IMAGE_ASPECT_DEPTH_BIT;\n    } else if (image->isStencilFormat_) {\n      aspect |= VK_IMAGE_ASPECT_STENCIL_BIT;\n    }\n  } else {\n    aspect = VK_IMAGE_ASPECT_COLOR_BIT;\n  }\n```", "```cpp\n VkImageView view = image->createImageView(\n    imageViewType, vkFormat, aspect, 0, VK_REMAINING_MIP_LEVELS, 0,\n    arrayLayerCount, debugNameImageView);\n```", "```cpp\n TextureHandle handle = texturesPool_.create(\n    lvk::VulkanTexture(std::move(image), view));\n  awaitingCreation_ = true;\n```", "```cpp\n if (desc.data) {\n    const void* mipMaps[] = {desc.data};\n    upload(handle,\n      {.dimensions = desc.dimensions, .numMipLevels = 1}, mipMaps);\n  }\n  return {this, handle};\n}\n```", "```cpp\nstd::shared_ptr<VulkanImage> VulkanContext::createImage(\n  VkImageType imageType, VkExtent3D extent,  VkFormat format,\n  uint32_t numLevels,   uint32_t numLayers, VkImageTiling tiling,\n  VkImageUsageFlags usageFlags, VkMemoryPropertyFlags memFlags,\n  VkImageCreateFlags flags, VkSampleCountFlagBits samples,\n  lvk::Result* outResult, const char* debugName)\n{\n  return std::make_shared<VulkanImage>(*this, vkDevice_, extent,\n    imageType, format, numLevels, numLayers, tiling, usageFlags,\n    memFlags, flags, samples, debugName);\n}\n```", "```cpp\nVulkanImage::VulkanImage(VulkanContext& ctx, VkDevice device,\n  VkExtent3D extent, VkImageType type, VkFormat format,\n  uint32_t numLevels, uint32_t numLayers, VkImageTiling tiling,\n  VkImageUsageFlags usageFlags, VkMemoryPropertyFlags memFlags,\n  VkImageCreateFlags createFlags, VkSampleCountFlagBits samples,\n  const char* debugName) :\n  ctx_(ctx), vkDevice_(device), vkUsageFlags_(usageFlags),\n  vkExtent_(extent), vkType_(type), vkImageFormat_(format),\n  numLevels_(numLevels), numLayers_(numLayers), vkSamples_(samples),\n  isDepthFormat_(isDepthFormat(format)),\n  isStencilFormat_(isStencilFormat(format))\n {\n```", "```cpp\n const VkImageCreateInfo ci = {\n      .sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO,\n      .flags = createFlags,\n      .imageType = type,\n      .format = vkImageFormat_,\n      .extent = vkExtent_,\n      .mipLevels = numLevels_,\n      .arrayLayers = numLayers_,\n      .samples = samples,\n      .tiling = tiling,\n      .usage = usageFlags,\n      .sharingMode = VK_SHARING_MODE_EXCLUSIVE,\n      .initialLayout = VK_IMAGE_LAYOUT_UNDEFINED,\n  };\n```", "```cpp\n if (LVK_VULKAN_USE_VMA) {\n    vmaAllocInfo_.usage = memFlags &\n      VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT ?\n        VMA_MEMORY_USAGE_CPU_TO_GPU : VMA_MEMORY_USAGE_AUTO;\n    VkResult result = vmaCreateImage(\n      (VmaAllocator)ctx_.getVmaAllocator(), &ci, &vmaAllocInfo_,\n      &vkImage_, &vmaAllocation_, nullptr);\n```", "```cpp\n if (memFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) {\n      vmaMapMemory((VmaAllocator)ctx_.getVmaAllocator(),\n        vmaAllocation_, &mappedPtr_);\n    }\n  } else {\n```", "```cpp\n VK_ASSERT(vkCreateImage(vkDevice_, &ci, nullptr, &vkImage_));\n    VkMemoryRequirements memRequirements;\n    vkGetImageMemoryRequirements(device, vkImage_, &memRequirements);\n    VK_ASSERT(lvk::allocateMemory(ctx.getVkPhysicalDevice(),\n      vkDevice_, &memRequirements, memFlags, &vkMemory_));\n    VK_ASSERT(vkBindImageMemory(vkDevice_, vkImage_, vkMemory_, 0));\n    if (memFlags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) {\n      VK_ASSERT(vkMapMemory(\n        vkDevice_, vkMemory_, 0, VK_WHOLE_SIZE, 0, &mappedPtr_));\n    }\n  }\n```", "```cpp\n VK_ASSERT(lvk::setDebugObjectName(vkDevice_, VK_OBJECT_TYPE_IMAGE,\n    (uint64_t)vkImage_, debugName));\n  vkGetPhysicalDeviceFormatProperties(ctx.getVkPhysicalDevice(),\n    vkImageFormat_, &vkFormatProperties_);\n}\n```", "```cpp\nVkImageView VulkanImage::createImageView(VkImageViewType type,\n  VkFormat format, VkImageAspectFlags aspectMask,\n  uint32_t baseLevel, uint32_t numLevels,\n  uint32_t baseLayer, uint32_t numLayers,\n  const char* debugName) const\n {\n  const VkImageViewCreateInfo ci = {\n    .sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,\n    .image = vkImage_,\n    .viewType = type,\n    .format = format,\n    .components = {.r = VK_COMPONENT_SWIZZLE_IDENTITY,\n                   .g = VK_COMPONENT_SWIZZLE_IDENTITY,\n                   .b = VK_COMPONENT_SWIZZLE_IDENTITY,\n                   .a = VK_COMPONENT_SWIZZLE_IDENTITY},\n```", "```cpp\n .subresourceRange = { \n      aspectMask, baseLevel,\n      numLevels ? numLevels : numLevels_,\n      baseLayer, numLayers},\n  };\n  VkImageView vkView = VK_NULL_HANDLE;\n  VK_ASSERT(vkCreateImageView(vkDevice_, &ci, nullptr, &vkView));\n  VK_ASSERT(lvk::setDebugObjectName(vkDevice_,\n    VK_OBJECT_TYPE_IMAGE_VIEW, (uint64_t)vkView, debugName));\n  return vkView;\n}\n```", "```cpp\nstruct VulkanTexture final {\n  VulkanTexture() = default;\n  VulkanTexture(std::shared_ptr<lvk::VulkanImage> image,\n                VkImageView imageView);\n  ~VulkanTexture();\n  VkExtent3D getExtent() const { return image_->vkExtent_;  }\n  VkImageView getOrCreateVkImageViewForFramebuffer(\n    uint8_t level, uint16_t layer);\n  std::shared_ptr<lvk::VulkanImage> image_;\n  VkImageView imageView_ = VK_NULL_HANDLE; // all mip-levels\n  VkImageView imageViewForFramebuffer_[LVK_MAX_MIP_LEVELS][6] = {}; // max 6 faces for cubemap rendering\n};\n```", "```cpp\ntemplate<typename ObjectType> class Handle final {\n  uint32_t index_ = 0;\n  uint32_t gen_ = 0;\n```", "```cpp\n Handle(uint32_t index, uint32_t gen) : index_(index), gen_(gen){};\n  template<typename ObjectType,\n           typename ImplObjectType> friend class Pool;\n public:\n  Handle() = default;\n```", "```cpp\n bool empty() const { return gen_ == 0; }\n  bool valid() const { return gen_ != 0; }\n  uint32_t index() const { return index_; }\n  uint32_t gen() const { return gen_; }\n```", "```cpp\n void* indexAsVoid() const \n  { return reinterpret_cast<void*>(static_cast<ptrdiff_t>(index_)); }\n  bool operator==(const Handle<ObjectType>& other) const\n  { return index_ == other.index_ && gen_ == other.gen_;  }\n  bool operator!=(const Handle<ObjectType>& other) const\n  { return index_ != other.index_ || gen_ != other.gen_; }\n```", "```cpp\n explicit operator bool() const { return gen_ != 0; }\n};\nstatic_assert(sizeof(Handle<class Foo>) == sizeof(uint64_t));\n```", "```cpp\nusing ComputePipelineHandle = lvk::Handle<struct ComputePipeline>;\nusing RenderPipelineHandle = lvk::Handle<struct RenderPipeline>;\nusing ShaderModuleHandle = lvk::Handle<struct ShaderModule>;\nusing SamplerHandle = lvk::Handle<struct Sampler>;\nusing BufferHandle = lvk::Handle<struct Buffer>;\nusing TextureHandle = lvk::Handle<struct Texture>;\n```", "```cpp\ntemplate<typename HandleType> class Holder final {\n public:\n  Holder() = default;\n  Holder(lvk::IContext* ctx, HandleType handle)\n    : ctx_(ctx), handle_(handle) {}\n```", "```cpp\n ~Holder() { lvk::destroy(ctx_, handle_); }\n  Holder(const Holder&) = delete;\n  Holder(Holder&& other):ctx_(other.ctx_), handle_(other.handle_) {…}\n  Holder& operator=(const Holder&) = delete;\n  Holder& operator=(Holder&& other) { … }\n```", "```cpp\n Holder& operator=(std::nullptr_t) { this->reset(); return *this; }\n  inline operator HandleType() const { return handle_; }\n  bool valid() const { return handle_.valid(); }\n  bool empty() const { return handle_.empty(); }\n```", "```cpp\n void reset() {\n    lvk::destroy(ctx_, handle_);\n    ctx_ = nullptr;\n    handle_ = HandleType{};\n  }\n  HandleType release() {\n    ctx_ = nullptr;\n    return std::exchange(handle_, HandleType{});\n  }\n  uint32_t index() const { return handle_.index(); }\n  void* indexAsVoid() const { return handle_.indexAsVoid(); }\n private:\n  lvk::IContext* ctx_ = nullptr;\n  HandleType handle_;\n};\n```", "```cpp\nvoid destroy(lvk::IContext* ctx, lvk::ComputePipelineHandle handle);\nvoid destroy(lvk::IContext* ctx, lvk::RenderPipelineHandle handle);\nvoid destroy(lvk::IContext* ctx, lvk::ShaderModuleHandle handle);\nvoid destroy(lvk::IContext* ctx, lvk::SamplerHandle handle);\nvoid destroy(lvk::IContext* ctx, lvk::BufferHandle handle);\nvoid destroy(lvk::IContext* ctx, lvk::TextureHandle handle);\n```", "```cpp\nvoid destroy(lvk::IContext* ctx, lvk::ComputePipelineHandle handle) {\n  if (ctx) ctx->destroy(handle);\n}\n```", "```cpp\ntemplate<typename ObjectType, typename ImplObjectType>\nclass Pool {\n  static constexpr uint32_t kListEndSentinel = 0xffffffff;\n  struct PoolEntry {\n    explicit PoolEntry(ImplObjectType& obj) : obj_(std::move(obj)) {}\n    ImplObjectType obj_ = {};\n    uint32_t gen_ = 1;\n    uint32_t nextFree_ = kListEndSentinel;\n  };\n  uint32_t freeListHead_ = kListEndSentinel;\npublic:\n  std::vector<PoolEntry> objects_;\n```", "```cpp\n Handle<ObjectType> create(ImplObjectType&& obj) {\n    uint32_t idx = 0;\n    if (freeListHead_ != kListEndSentinel) {\n      idx = freeListHead_;\n      freeListHead_ = objects_[idx].nextFree_;\n      objects_[idx].obj_ = std::move(obj);\n    } else {\n```", "```cpp\n idx = (uint32_t)objects_.size();\n      objects_.emplace_back(obj);\n    }\n    numObjects_++;\n    return Handle<ObjectType>(idx, objects_[idx].gen_);\n  }\n```", "```cpp\n void destroy(Handle<ObjectType> handle) {\n    if (handle.empty()) return;\n    assert(numObjects_ > 0);\n    const uint32_t index = handle.index();\n    assert(index < objects_.size());\n    assert(handle.gen() == objects_[index].gen_); // double deletion\n```", "```cpp\n objects_[index].obj_ = ImplObjectType{};\n    objects_[index].gen_++;\n    objects_[index].nextFree_ = freeListHead_;\n    freeListHead_ = index;\n    numObjects_--;\n  }\n```", "```cpp\n ImplObjectType* get(Handle<ObjectType> handle) {\n    if (handle.empty()) return nullptr;\n    const uint32_t index = handle.index();\n    assert(index < objects_.size());\n    assert(handle.gen() == objects_[index].gen_); // deleted object\n    return &objects_[index].obj_;\n  }\n```", "```cpp\n void clear() {\n    objects_.clear();\n    freeListHead_ = kListEndSentinel;\n    numObjects_ = 0;\n  }\n```", "```cpp\n uint32_t numObjects() const {\n    return numObjects_;\n  }\n  uint32_t numObjects_ = 0;\n};\n```", "```cpp\nPool<lvk::ShaderModule, VkShaderModule> shaderModulesPool_;\nPool<lvk::RenderPipeline, RenderPipelineState> renderPipelinesPool_;\nPool<lvk::ComputePipeline, ComputePipelineState>\n  computePipelinesPool_;\nPool<lvk::Sampler, VkSampler> samplersPool_;\nPool<lvk::Buffer, VulkanBuffer> buffersPool_;\nPool<lvk::Texture, VulkanTexture> texturesPool_;\n```", "```cpp\n uint32_t currentMaxTextures_ = 16;\n  uint32_t currentMaxSamplers_ = 16;\n  VkPipelineLayout vkPipelineLayout_ = VK_NULL_HANDLE;\n  VkDescriptorSetLayout vkDSL_ = VK_NULL_HANDLE;\n  VkDescriptorPool vkDPool_ = VK_NULL_HANDLE;\n  VkDescriptorSet vkDSet_ = VK_NULL_HANDLE;\n  SubmitHandle lastSubmitHandle = SubmitHandle();\n```", "```cpp\nResult lvk::VulkanContext::growDescriptorPool(\n  uint32_t maxTextures, uint32_t maxSamplers)\n{\n  currentMaxTextures_ = maxTextures;\n  currentMaxSamplers_ = maxSamplers;\n  if (!LVK_VERIFY(maxTextures <= vkPhysicalDeviceVulkan12Properties_.\n        maxDescriptorSetUpdateAfterBindSampledImages))\n    LLOGW(“Max Textures exceeded: %u (max %u)”, maxTextures,\n        vkPhysicalDeviceVulkan12Properties_.\n          maxDescriptorSetUpdateAfterBindSampledImages);\n  if (!LVK_VERIFY(maxSamplers <= vkPhysicalDeviceVulkan12Properties_.\n        maxDescriptorSetUpdateAfterBindSamplers))\n    LLOGW(“Max Samplers exceeded %u (max %u)”, maxSamplers,\n        vkPhysicalDeviceVulkan12Properties_.\n          maxDescriptorSetUpdateAfterBindSamplers);\n```", "```cpp\n if (vkDSL_ != VK_NULL_HANDLE) {\n    deferredTask(std::packaged_task<void()>(\n      [device = vkDevice_, dsl = vkDSL_]() {\n        vkDestroyDescriptorSetLayout(device, dsl, nullptr); })); }\n  if (vkDPool_ != VK_NULL_HANDLE) {\n    deferredTask(std::packaged_task<void()>(\n      [device = vkDevice_, dp = vkDPool_]() {\n        vkDestroyDescriptorPool(device, dp, nullptr); })); }\n  if (vkPipelineLayout_ != VK_NULL_HANDLE) {\n    deferredTask(std::packaged_task<void()>(\n      [device = vkDevice_, layout = vkPipelineLayout_]() {\n        vkDestroyPipelineLayout(device, layout, nullptr); })); }\n```", "```cpp\n const VkDescriptorSetLayoutBinding bindings[kBinding_NumBindings] ={\n    getDSLBinding(kBinding_Textures,\n      VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE, maxTextures),\n    getDSLBinding(kBinding_Samplers,\n      VK_DESCRIPTOR_TYPE_SAMPLER, maxSamplers),\n    getDSLBinding(kBinding_StorageImages,\n      VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, maxTextures),\n  };\n```", "```cpp\n const uint32_t flags = VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT |\n               VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT |\n                           VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT;\n  VkDescriptorBindingFlags bindingFlags[kBinding_NumBindings];\n  for (int i = 0; i < kBinding_NumBindings; ++i)\n    bindingFlags[i] = flags;\n```", "```cpp\n const VkDescriptorSetLayoutBindingFlagsCreateInfo bindingFlagsci = {\n      .sType =  VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO_EXT,\n      .bindingCount = kBinding_NumBindings,\n      .pBindingFlags = bindingFlags,\n  };\n  const VkDescriptorSetLayoutCreateInfo dslci = {\n      .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,\n      .pNext = &bindingFlagsci,\n      .flags =\n       VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT_EXT,\n      .bindingCount = kBinding_NumBindings,\n      .pBindings = bindings,\n  };\n  vkCreateDescriptorSetLayout(vkDevice_, &dslci, nullptr, &vkDSL_);\n```", "```cpp\n const VkDescriptorPoolSize poolSizes[kBinding_NumBindings] = {\n    VkDescriptorPoolSize{\n      VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE, maxTextures},\n    VkDescriptorPoolSize{\n      VK_DESCRIPTOR_TYPE_SAMPLER, maxSamplers},\n    VkDescriptorPoolSize{\n      VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, maxTextures},\n  };\n  const VkDescriptorPoolCreateInfo ci = {\n    .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,\n    .flags = VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT,\n    .maxSets = 1,\n    .poolSizeCount = kBinding_NumBindings,\n    .pPoolSizes = poolSizes,\n  };\n  vkCreateDescriptorPool(vkDevice_, &ci, nullptr, &vkDPool_);\n```", "```cpp\n const VkDescriptorSetAllocateInfo ai = {\n    .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,\n    .descriptorPool = vkDPool_,\n    .descriptorSetCount = 1,\n    .pSetLayouts = &vkDSL_,\n  };\n  vkAllocateDescriptorSets(vkDevice_, &ai, &vkDSet_);\n```", "```cpp\n const VkDescriptorSetLayout dsls[] = {vkDSL_, vkDSL_, vkDSL_};\n  const VkPushConstantRange range = {\n    .stageFlags = VK_SHADER_STAGE_VERTEX_BIT |\n                  VK_SHADER_STAGE_FRAGMENT_BIT |\n                  VK_SHADER_STAGE_COMPUTE_BIT,\n    .offset = 0,\n    .size = 128,\n  };\n  const VkPipelineLayoutCreateInfo ci = {\n    .sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO,\n    .setLayoutCount = (uint32_t)LVK_ARRAY_NUM_ELEMENTS(dsls),\n    .pSetLayouts = dsls,\n    .pushConstantRangeCount = 1,\n    .pPushConstantRanges = &range,\n  };\n  vkCreatePipelineLayout(\n    vkDevice_, &ci, nullptr, &vkPipelineLayout_);\n  return Result();\n}\n```", "```cpp\nvoid VulkanContext::checkAndUpdateDescriptorSets() {\n  if (!awaitingCreation_) return;\n```", "```cpp\n uint32_t newMaxTextures = currentMaxTextures_;\n  uint32_t newMaxSamplers = currentMaxSamplers_;\n  while (texturesPool_.objects_.size() > newMaxTextures)\n    newMaxTextures *= 2;\n  while (samplersPool_.objects_.size() > newMaxSamplers)\n    newMaxSamplers *= 2;\n  if (newMaxTextures != currentMaxTextures_ ||\n      newMaxSamplers != currentMaxSamplers_) {\n    growDescriptorPool(newMaxTextures, newMaxSamplers);\n  }\n```", "```cpp\n std::vector<VkDescriptorImageInfo> infoSampledImages;\n  std::vector<VkDescriptorImageInfo> infoStorageImages;\n  infoSampledImages.reserve(texturesPool_.numObjects());\n  infoStorageImages.reserve(texturesPool_.numObjects());\n  VkImageView dummyImageView =\n    texturesPool_.objects_[0].obj_.imageView_;\n```", "```cpp\n for (const auto& obj : texturesPool_.objects_) {\n    const VulkanTexture& texture = obj.obj_;\n    const bool isTextureAvailable = texture.image_ &&\n      ((texture.image_->vkSamples_ & VK_SAMPLE_COUNT_1_BIT) ==\n        VK_SAMPLE_COUNT_1_BIT);\n    const bool isSampledImage = isTextureAvailable &&\n      texture.image_->isSampledImage();\n    const bool isStorageImage = isTextureAvailable && \n      texture.image_->isStorageImage();\n```", "```cpp\n infoSampledImages.push_back({\n      VK_NULL_HANDLE,\n      isSampledImage ? texture.imageView_ : dummyImageView,\n      VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL});\n    infoStorageImages.push_back({\n      VK_NULL_HANDLE,\n      isStorageImage ? texture.imageView_ : dummyImageView,\n      VK_IMAGE_LAYOUT_GENERAL});\n  }\n```", "```cpp\n std::vector<VkDescriptorImageInfo> infoSamplers;\n  infoSamplers.reserve(samplersPool_.objects_.size());\n  for (const auto& sampler : samplersPool_.objects_) {\n    infoSamplers.push_back({\n      sampler.obj_ ? sampler.obj_ : samplersPool_.objects_[0].obj_,\n      VK_NULL_HANDLE,\n      VK_IMAGE_LAYOUT_UNDEFINED});\n  }\n```", "```cpp\n VkWriteDescriptorSet write[kBinding_NumBindings] = {};\n  uint32_t numWrites = 0;\n  if (!infoSampledImages.empty())\n    write[numWrites++] = VkWriteDescriptorSet{\n      .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,\n      .dstSet = vkDSet_,\n      .dstBinding = kBinding_Textures,\n      .dstArrayElement = 0,\n      .descriptorCount = (uint32_t)infoSampledImages.size(),\n      .descriptorType = VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE,\n      .pImageInfo = infoSampledImages.data(),\n    };\n  if (!infoSamplers.empty())\n    write[numWrites++] = VkWriteDescriptorSet{\n      .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,\n      .dstSet = vkDSet_,\n      .dstBinding = kBinding_Samplers,\n      .dstArrayElement = 0,\n      .descriptorCount = (uint32_t)infoSamplers.size(),\n      .descriptorType = VK_DESCRIPTOR_TYPE_SAMPLER,\n      .pImageInfo = infoSamplers.data(),\n    };\n  if (!infoStorageImages.empty())\n    write[numWrites++] = VkWriteDescriptorSet{\n      .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,\n      .dstSet = vkDSet_,\n      .dstBinding = kBinding_StorageImages,\n      .dstArrayElement = 0,\n      .descriptorCount = (uint32_t)infoStorageImages.size(),\n      .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,\n      .pImageInfo = infoStorageImages.data(),\n    };\n```", "```cpp\n if (numWrites) {\n    immediate_->wait(std::exchange(\n      lastSubmitHandle, immediate_->getLastSubmitHandle()));\n    vkUpdateDescriptorSets(vkDevice_, numWrites, write, 0, nullptr);\n  }\n  awaitingCreation_ = false;\n}\n```", "```cpp\nlayout (set = 0, binding = 0) uniform texture2D kTextures2D[];\nlayout (set = 1, binding = 0) uniform texture3D kTextures3D[];\nlayout (set = 2, binding = 0) uniform textureCube kTexturesCube[];\nlayout (set = 0, binding = 1) uniform sampler kSamplers[];\nlayout (set = 1, binding = 1) uniform samplerShadow kSamplersShadow[];\n```", "```cpp\nvec4 textureBindless2D(uint textureid, uint samplerid, vec2 uv) {\n  return texture(sampler2D(kTextures2D[textureid],\n                           kSamplers[samplerid]), uv);\n}\nvec4 textureBindless2DLod(\n  uint textureid, uint samplerid, vec2 uv, float lod) {\n  return textureLod(sampler2D(kTextures2D[textureid],\n                              kSamplers[samplerid]), uv, lod);\n}\nfloat textureBindless2DShadow(\n  uint textureid, uint samplerid, vec3 uvw) {\n  return texture(sampler2DShadow(kTextures2D[textureid],\n                                 kSamplersShadow[samplerid]), uvw);\n}\nivec2 textureBindlessSize2D(uint textureid) {\n  return textureSize(kTextures2D[textureid], 0);\n}\n```", "```cpp\nlayout (location=0) in vec2 uv;\nlayout (location=0) out vec4 out_FragColor;\nlayout(push_constant) uniform PerFrameData {\n  uniform mat4 MVP;\n  uint textureId;\n};\nvoid main() {\n  out_FragColor = textureBindless2D(textureId, 0, uv);\n};\n```"]