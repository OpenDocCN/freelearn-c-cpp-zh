["```cpp\nvoid GameCamera::apply_jittering( f32 x, f32 y ) {\n    // Reset camera projection\n    camera.calculate_projection_matrix();\n    // Calculate jittering translation matrix and modify\n       projection matrix\n    mat4s jittering_matrix = glms_translate_make( { x, y,\n                                                  0.0f } );\n    camera.projection = glms_mat4_mul( jittering_matrix,\n                                       camera.projection );\n    camera.calculate_view_projection();\n}\n```", "```cpp\nvoid GameCamera::apply_jittering( f32 x, f32 y ) {\n   camera.calculate_projection_matrix();\n   // Perform the same calculations as before, with the\n      observation that\n   // we modify only 2 elements in the projection matrix:\n   camera.projection.m20 += x;\n   camera.projection.m21 += y;\n   camera.calculate_view_projection();\n}\n```", "```cpp\n   f32 jitter_x = halton( jitter_index, 2 );\n   f32 jitter_y = halton( jitter_index, 3 );\n```", "```cpp\n    f32 jitter_offset_x = jitter_x * 2 - 1.0f;\n    f32 jitter_offset_y = jitter_y * 2 - 1.0f;\n```", "```cpp\ngame_camera.apply_jittering( jitter_offset_x / gpu.swapchain_width, jitter_offset_y / gpu.swapchain_height );\n```", "```cpp\njitter_index = ( jitter_index + 1 ) % jitter_period;\n```", "```cpp\nlayout (local_size_x = 8, local_size_y = 8, local_size_z =\n        1) in;\nvoid main() {\n    ivec3 pos = ivec3(gl_GlobalInvocationID.xyz);\n    // Read the raw depth and reconstruct NDC coordinates.\n    const float raw_depth = texelFetch(global_textures[\n        nonuniformEXT(depth_texture_index)], pos.xy, 0).r;\n    const vec2 screen_uv = uv_nearest(pos.xy, resolution);\n    vec4 current_position_ndc = vec4(\n        ndc_from_uv_raw_depth( screen_uv, raw_depth ), 1.0f\n        );\n    // Reconstruct world position and previous NDC position\n    const vec3 pixel_world_position =\n        world_position_from_depth\n           (screen_uv, raw_depth, inverse_view_projection);\n    vec4 previous_position_ndc = previous_view_projection *\n        vec4(pixel_world_position, 1.0f);\n    previous_position_ndc.xyz /= previous_position_ndc.w;\n    // Calculate the jittering difference.\n    vec2 jitter_difference = (jitter_xy –\n                              previous_jitter_xy)* 0.5f;\n    // Pixel velocity is given by the NDC [-1,1] difference\n       in X and Y axis\n    vec2 velocity = current_position_ndc.xy –\n                    previous_position_ndc.xy;\n    // Take in account jittering\n    velocity -= jitter_difference;\n    imageStore( motion_vectors, pos.xy, vec4(velocity, 0,\n                                             0) );\n```", "```cpp\n// Mesh shader version\ngl_MeshVerticesNV[ i ].gl_Position = view_projection *\n    (model * vec4(position, 1));\nvec4 world_position = model * vec4(position, 1.0);\nvec4 previous_position_ndc = previous_view_projection *\n    vec4(world_position, 1.0f);\nprevious_position_ndc.xyz /= previous_position_ndc.w;\nvec2 jitter_difference = (jitter_xy - previous_jitter_xy) *\n                          0.5f;\nvec2 velocity = gl_MeshVerticesNV[ i ].gl_Position.xy –\n    previous_position_ndc.xy - jitter_difference;\nvTexcoord_Velocity[i] = velocity;\n```", "```cpp\nvec3 taa_simplest( ivec2 pos ) {\n    const vec2 velocity = sample_motion_vector( pos );\n    const vec2 screen_uv = uv_nearest(pos, resolution);\n    const vec2 reprojected_uv = screen_uv - velocity;\n    vec3 current_color = sample_color(screen_uv.xy).rgb;\n    vec3 history_color =\n        sample_history_color(reprojected_uv).rgb;\n    // source_weight is normally around 0.9.\n    return mix(current_color, previous_color,\n               source_weight);\n}\n```", "```cpp\nvoid find_closest_fragment_3x3(ivec2 pixel, out ivec2\n                               closest_position, out\n                               float closest_depth) {\n    closest_depth = 1.0f;\n    closest_position = ivec2(0,0);\n    for (int x = -1; x <= 1; ++x ) {\n        for (int y = -1; y <= 1; ++y ) {\n            ivec2 pixel_position = pixel + ivec2(x, y);\n                pixel_position = clamp(pixel_position,\n                    ivec2(0), ivec2(resolution.x - 1,\n                        resolution.y - 1));\n            float current_depth =\n                texelFetch(global_textures[\n                    nonuniformEXT(depth_texture_index)],\n                        pixel_position, 0).r;\n            if ( current_depth < closest_depth ) {\n                closest_depth = current_depth;\n                closest_position = pixel_position;\n            }\n        }\n    }\n}\n```", "```cpp\n        float closest_depth = 1.0f;\n        ivec2 closest_position = ivec2(0,0);\n        find_closest_fragment_3x3( pos.xy,\n                                   closest_position,\n                                   closest_depth );\n        const vec2 velocity = sample_motion_vector\n            (closest_position.xy);\n        // rest of the TAA shader\n```", "```cpp\n   // Sample motion vectors.\n    const vec2 velocity = sample_motion_vector_point(\n                          closest_position );\n    const vec2 screen_uv = uv_nearest(pos.xy, resolution);\n    const vec2 reprojected_uv = screen_uv - velocity;\n    // History sampling: read previous frame samples and\n       optionally apply a filter to it.\n    vec3 history_color = vec3(0);\n    history_color = sample_history_color(\n                    reprojected_uv ).rgb;\n    switch (history_sampling_filter) {\n        case HistorySamplingFilterSingle:\n            history_color = sample_history_color(\n                            reprojected_uv ).rgb;\n            break;\n        case HistorySamplingFilterCatmullRom:\n            history_color = sample_texture_catmull_rom(\n                            reprojected_uv,\n                            history_color_texture_index );\n            break;\n    }\n```", "```cpp\n// Current sampling: read a 3x3 neighborhood and cache\n   color and other data to process history and final\n   resolve.\n    // Accumulate current sample and weights.\n    vec3 current_sample_total = vec3(0);\n    float current_sample_weight = 0.0f;\n    // Min and Max used for history clipping\n    vec3 neighborhood_min = vec3(10000);\n    vec3 neighborhood_max = vec3(-10000);\n    // Cache of moments used in the constraint phase\n    vec3 m1 = vec3(0);\n    vec3 m2 = vec3(0);\n    for (int x = -1; x <= 1; ++x ) {\n        for (int y = -1; y <= 1; ++y ) {\n            ivec2 pixel_position = pos + ivec2(x, y);\n            pixel_position = clamp(pixel_position,\n                ivec2(0), ivec2(resolution.x - 1,\n                    resolution.y - 1));\n            vec3 current_sample =\n            sample_current_color_point(pixel_position).rgb;\n            vec2 subsample_position = vec2(x * 1.f, y *\n                                           1.f);\n            float subsample_distance = length(\n                                       subsample_position\n                                       );\n            float subsample_weight = subsample_filter(\n                                     subsample_distance );\n            current_sample_total += current_sample *\n                                    subsample_weight;\n            current_sample_weight += subsample_weight;\n            neighborhood_min = min( neighborhood_min,\n                                    current_sample );\n            neighborhood_max = max( neighborhood_max,\n                                     current_sample );\n            m1 += current_sample;\n            m2 += current_sample * current_sample;\n        }\n    }\nvec3 current_sample = current_sample_total /\n                      current_sample_weight;\n```", "```cpp\n    switch (history_clipping_mode) {\n        // This is the most complete and robust history\n           clipping mode:\n        case HistoryClippingModeVarianceClipClamp:\n        default: {\n            // Calculate color AABB using color moments m1\n               and m2\n            float rcp_sample_count = 1.0f / 9.0f;\n            float gamma = 1.0f;\n            vec3 mu = m1 * rcp_sample_count;\n            vec3 sigma = sqrt(abs((m2 * rcp_sample_count) –\n                         (mu * mu)));\n            vec3 minc = mu - gamma * sigma;\n            vec3 maxc = mu + gamma * sigma;\n            // Clamp to new AABB\n            vec3 clamped_history_color = clamp(\n                                         history_color.rgb,\n                                         neighborhood_min,\n                                         neighborhood_max\n                                         );\n            history_color.rgb = clip_aabb(minc, maxc,\n                                vec4(clamped_history_color,\n                                1), 1.0f).rgb;\n            break;\n        }\n    }\n```", "```cpp\n// Resolve: combine history and current colors for final\n   pixel color\n    vec3 current_weight = vec3(0.1f);\n    vec3 history_weight = vec3(1.0 - current_weight);\n```", "```cpp\n    // Temporal filtering\n    if (use_temporal_filtering() ) {\n        vec3 temporal_weight = clamp(abs(neighborhood_max –\n                                      neighborhood_min) /\n                                      current_sample,\n                                      vec3(0), vec3(1));\n        history_weight = clamp(mix(vec3(0.25), vec3(0.85),\n                               temporal_weight), vec3(0),\n                               vec3(1));\n        current_weight = 1.0f - history_weight;\n    }\n```", "```cpp\n    // Inverse luminance filtering\n    if (use_inverse_luminance_filtering() ||\n        use_luminance_difference_filtering() ) {\n        // Calculate compressed colors and luminances\n        vec3 compressed_source = current_sample /\n            (max(max(current_sample.r, current_sample.g),\n                current_sample.b) + 1.0f);\n        vec3 compressed_history = history_color /\n            (max(max(history_color.r, history_color.g),\n                history_color.b) + 1.0f);\n        float luminance_source = use_ycocg() ?\n            compressed_source.r :\n                luminance(compressed_source);\n        float luminance_history = use_ycocg() ?\n            compressed_history.r :\n                luminance(compressed_history);\n        if ( use_luminance_difference_filtering() ) {\n            float unbiased_diff = abs(luminance_source –\n            luminance_history) / max(luminance_source,\n            max(luminance_history, 0.2));\n            float unbiased_weight = 1.0 - unbiased_diff;\n            float unbiased_weight_sqr = unbiased_weight *\n                                        unbiased_weight;\n            float k_feedback = mix(0.0f, 1.0f,\n                                   unbiased_weight_sqr);\n            history_weight = vec3(1.0 - k_feedback);\n            current_weight = vec3(k_feedback);\n        }\n        current_weight *= 1.0 / (1.0 + luminance_source);\n        history_weight *= 1.0 / (1.0 + luminance_history);\n    }\n```", "```cpp\n    vec3 result = ( current_sample * current_weight +\n                    history_color * history_weight ) /\n                    max( current_weight + history_weight,\n                    0.00001 );\n    return result;\n```", "```cpp\n    vec4 color = texture(global_textures[\n                 nonuniformEXT(texture_id)], vTexCoord.xy);\n    float input_luminance = luminance(color.rgb);\n    float average_luminance = 0.f;\n    // Sharpen\n    for (int x = -1; x <= 1; ++x ) {\n        for (int y = -1; y <= 1; ++y ) {\n            vec3 sampled_color = texture(global_textures[\n                nonuniformEXT(texture_id)], vTexCoord.xy +\n                    vec2( x / resolution.x, y /\n                        resolution.y )).rgb;\n            average_luminance += luminance( sampled_color\n                                          );\n        }\n    }\n    average_luminance /= 9.0f;\n    float sharpened_luminance = input_luminance –\n                                average_luminance;\n    float final_luminance = input_luminance +\n                            sharpened_luminance *\n                            sharpening_amount;\n    color.rgb = color.rgb * (final_luminance /\n                input_luminance);\n```", "```cpp\nvec2 unjitter_uv(float uv, vec2 jitter) {\n    return uv - dFdxFine(uv) * jitter.x + dFdyFine(uv) *\n        jitter.y;\n}\n```"]