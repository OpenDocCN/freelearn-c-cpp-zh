- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deciphering Order-Independent Transparency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rendering transparent objects isn’t always easy. While opaque objects can be
    rendered in any order, transparent objects need to be rendered from farthest to
    nearest relative to the camera, which implies an extra sorting step before performing
    the actual rendering. This depth sorting ensures that more distant objects are
    blended into the frame buffer first, followed by nearer objects, allowing for
    accurate composition of transparent layers.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting can become computationally expensive and error-prone, especially when
    dealing with complex scenes, intersecting objects, or real-time rendering scenarios.
    Additionally, sorting fails to solve the problem of cyclic overlaps, where multiple
    objects interpenetrate in such a way that no single depth-sorting order can accurately
    represent their visual appearance.
  prefs: []
  type: TYPE_NORMAL
- en: Order-independent transparency techniques try to solve these problems by accumulating
    transparency information in a way that doesn’t depend on the order in which objects
    are processed. This chapter delves into the complexities and challenges of rendering
    transparent objects, a task that requires precision and careful execution. In
    contrast to opaque objects, which can be rendered in any order, transparent objects
    necessitate rendering based on their depth in relation to the camera, from the
    farthest to the nearest. This involves an additional sorting step, which, while
    ensuring accurate composition of transparent layers, can prove to be computationally
    intensive and prone to errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Depth-Peeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Dual Depth-Peeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Linked-List Order-Independent Transparency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Weighted Order-Independent Transparency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you will need to make sure you have VS 2022 installed along
    with the Vulkan SDK. Basic familiarity with the C++ programming language and an
    understanding of OpenGL or any other graphics API will be useful. Please revisit
    [*Chapter 1*](B18491_01.xhtml#_idTextAnchor019)*, Vulkan Core Concepts*, under
    the *Technical requirements* section for details on setting up and building executables
    for this chapter. All recipes for this chapter are encapsulated in a single executable
    and can be launched using `Chapter05_Transparency.exe` executable.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Depth-Peeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Depth Peeling** was introduced in 2001 by Cass Everitt as a solution to render
    semi-transparent geometry without the need to sort the geometry from back-to-front.
    The technique consists of rendering the scene multiple times (passes). At each
    pass, only the nearest fragments to the camera are rendered and their depth is
    collected to be used on the next pass. On each pass, except for the first pass,
    fragments closer than the ones in the depth pass collected in the previous iteration
    are discarded. This process *peels* the scene into consecutive layers, from front
    to back. At the end of the process, all layers are blended into one final image,
    which is then blended once more with the background.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository mentioned in *Technical requirements*, the Depth Peeling algorithm
    is implemented by the `DepthPeeling` class, located in `source/enginecore/passes/DepthPeeling.hpp`
    and `cpp` files. In this recipe, you will learn how to peel away or progressively
    remove layers of transparent objects in your rendering process. This technique
    ensures accurate rendering by handling each layer individually from the farthest
    to the nearest, thus improving the overall visual quality of scenes with complex
    overlapping transparencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm consists of rendering the scene repeatedly, storing the depth
    map at the end of each pass. The fragments nearest to the camera are blended with
    the previous pass (or an empty framebuffer for the first pass). The current pass
    fragment depth is discarded if it is smaller than the depth from the last pass,
    as summarized in *Figure 5**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 –Depth Peeling algorithm with 3 planes](img/B18491_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 –Depth Peeling algorithm with 3 planes
  prefs: []
  type: TYPE_NORMAL
- en: We’ve provided a foundational understanding of this technique in the preceding
    section. Moving forward, we will delve deeper, guiding you through a detailed,
    step-by-step process on how to practically implement this technique using Vulkan.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The algorithm uses two sets of depth maps and two sets of color attachments
    to perform a ping-pong operation between passes. The depth map obtained during
    one pass is used as a reference depth map on the next, while a second depth map
    is then used as a depth attachment. The same thing is done with two color attachments:
    one is used to store the blending of the current pass, while the other is used
    as the reference, generated in the previous pass. The subsequent steps will guide
    you through the actual execution of these operations. With the help of a detailed
    diagram provided below, you will be able to visualize and better understand the
    intricate workings of this algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.2* effectively illustrates the described process, aiding in your
    comprehension and application of this intricate technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Depth peeling algorithm](img/B18491_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Depth peeling algorithm
  prefs: []
  type: TYPE_NORMAL
- en: Now we will go through steps on how to perform this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm is performed by the `DepthPeeling::draw` method, which starts
    by clearing the depth map 1 and both color attachments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Both the color and depth attachments start with the color and depth attachments
    with index equal to 0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The algorithm repeats a number of times, equal to the number of passes. Care
    must be taken to transition each attachment to the correct layout, obeying the
    ping-ponging mechanism: a texture used as a color attachment before needs to be
    transitioned to a texture that will be read by a shader and vice-versa:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we begin the render pass, issue the draw call, and end the pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The images are transitioned to the correct layout by the render pass, so all
    we need to do is copy the result of the current pass into the other texture that
    will be used as the color attachment during the next pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The vertex fragment is not special for depth peeling, but the fragment shader
    must discard fragments that are closer to the camera than the fragments collected
    in the previous pass. The fragment shader also performs the blending into the
    current attachment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The blending equation is a special one, used for front-to-back compositing,
    as described by Louis Bavoil and Kevin Myers in 2008 in their *Order Independent
    Transparency with Dual Depth Peeling* paper. The blending equation is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C dst = A dst(A src C src)+ C dst
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A dst = (1 − A src) A dst
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the following recipe, we will explore how to enhance the depth-peeling technique,
    making it more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Dual Depth-Peeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main drawbacks of the Depth Peeling algorithm is that it requires
    multiple passes, each of which may consist of rasterizing the entire scene. The
    **Dual Depth-Peeling** algorithm extends the original Depth Peeling algorithm
    by peeling two layers at the same time, almost effectively cutting the number
    of passes by half. In this recipe, we will focus on implementing the Dual Depth-Peeling
    algorithm. We will address one of the key limitations of the Depth Peeling algorithm,
    namely its requirement for multiple passes which may involve rasterizing the entire
    scene. You’ll learn how the Dual Depth-Peeling algorithm improves upon the original
    by peeling two layers concurrently, thus potentially reducing the number of passes
    by nearly half. This insight will empower you to handle complex scenes with greater
    efficiency and speed.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository, the Depth Peeling algorithm is implemented by the `DualDepthPeeling`
    class, located in `source/enginecore/passes/DualDepthPeeling.hpp` and `cpp` files.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin, we need to set the `VkPhysicalDeviceFeatures::independentBlend`
    property to true. This property allows us to use different blending equations
    for each attachment associated with a graphics pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: On each pass, a depth map with two components, R and G (in the code we use the
    `VK_FORMAT_R32G32_SFLOAT` format), is used to store both the front and the back
    peels simultaneously. The blend equation used with the map is `VK_BLEND_OP_MAX`.
    When storing the current fragment’s depth, we encode it as `vec2(-depth, depth)`.
    The R component stores the negative depth of the front peel, while the G component
    stores the actual depth of the back peel, The `Max` blending equation ensures
    that we only store the nearest front peel by negating it. The back peels are guaranteed
    to always be the farthest because they are stored as positive depths.
  prefs: []
  type: TYPE_NORMAL
- en: 'The front peel is blended with the modified blend equation:'
  prefs: []
  type: TYPE_NORMAL
- en: C dst = A dst(A src C src)+ C dst
  prefs: []
  type: TYPE_NORMAL
- en: A dst = (1 − A src) A dst
  prefs: []
  type: TYPE_NORMAL
- en: While the back peel is blended with the regular back-to-front blend equation
  prefs: []
  type: TYPE_NORMAL
- en: C dst = A src C src + (1 − A src) C dst
  prefs: []
  type: TYPE_NORMAL
- en: With the preparatory steps outlined, you are now ready to delve into the implementation
    of the Dual Depth-Peeling algorithm. In the next section, we will guide you through
    the step-by-step process of executing this algorithm, using the insights and techniques
    discussed above.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The algorithm in Vulkan consists of using 2 color attachments, one for the front
    peel and one for the back peel. It also uses 2 depth buffers with the same format.
    One is used for the even numbered passes, while the other for the odd even passes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by specifying the blend operations for each attachment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These instances of the `VkPipelineColorBlendAttachmentState` structure are added
    to the `VkPipelineColorBlendStateCreateInfo` structure when creating a graphics
    pipeline and are provided in the order the attachments will be set in the framebuffers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The algorithm, implemented by `DualDepthPeeling::draw` method, starts by clearing
    the depth buffers and the color attachments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The depth textures are then transitioned for the first pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Both the front and back textures are bound as attachments and are loaded and
    stored for each pass. One of the depth textures is also bound as an attachment
    and is cleared to `(-99,999; 99,999)` and stored after each pass. The other depth
    texture is bound as a texture for read by the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each pass we start by transitioning the color and depth attachments to
    the correct layouts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The attachments are provided for the render pass using dynamic rendering, the
    scene is rendered, and the pass is completed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once all the passes are completed, one last step remains which is consists of
    blending the last front and back peels. The front peel is provided as a color
    attachment and as a texture for the shader, while the back color is only provided
    as a texture for reading by the shader.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This last pass consists of drawing a rectangle the size of the viewport and
    used solely for blending the two peels
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The main dual depth peeling fragment shader reads the depth value of the fragment
    output from the previous pass, decodes it, and decided whether the fragment should
    be discarded or not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final pass, where the front and back peels are blended, uses a simple fragment
    shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Having delved into the intricacies of the Dual Depth-Peeling algorithm, we will
    now shift our focus to another advanced technique in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Linked-List Order-Independent Transparency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Order Independent Transparency** uses a per pixel linked list to handle transparency,
    it makes use of data structures, specifically linked lists, to store fragments
    for each pixel. Each node of the list contains information about a fragment’s
    color and depth value, and the nodes are connected in a way that follows the order
    of fragments arrival, thus making sorting unnecessary.'
  prefs: []
  type: TYPE_NORMAL
- en: This approach effectively eliminates overdrawing, and artifacts associated with
    depth sorting. By focusing on the depth value of each fragment, the approach provides
    a more accurate, visually pleasing representation of transparent objects. In this
    recipe, we will delve into the detailed process of implementing the Linked-List
    **Order-Independent Transparency** (**OIT**) technique. You’ll learn how this
    technique leverages per pixel linked lists to efficiently manage transparency,
    eliminating the issues of overdrawing and depth sorting artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository, the Linked list algorithm is implemented by the `OitLinkedListPass`
    class, located in `source/enginecore/passes/` `OitLinkedListPass.hpp` and `cpp`
    files. The corresponding shaders are `source/enginecore/resources/shaders/OitLinkedListBuildPass.frag`
    and `source/enginecore/resources/shaders/ OITLinkedListCompositePass.frag`
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm begins by initializing an empty list for each pixel, and as the
    scene is rendered, it adds nodes to the list in the order in which they are processed.
    This is done in a two-pass rendering stage. In the first pass, also known as the
    build pass, each fragment’s depth, color, and next-node pointer are written into
    a buffer. The second pass, also known as resolve or composite pass, goes through
    the list from back-to-front for each pixel and blends the colors based on depth
    values, resulting in the final pixel color.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To implement a per pixel linked list, we need to maintain various buffers.
  prefs: []
  type: TYPE_NORMAL
- en: The `OitLinkedListPass::init` method is tasked with initializing a variety of
    resources. It establishes both the Build pass and the Composite pass pipelines.
    Furthermore, it arranges the necessary resources for the Build pass pipeline.
    The code snippet below highlights some key resources configured during the initialization
    phase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`atomicCounterBuffer_`: This buffer is created to hold an atomic counter. The
    counter is used to allocate slots in the linked list buffer for storing new fragments.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`linkedListBuffer_`: This is the main buffer that holds the linked lists of
    fragments for each pixel. Each pixel can have multiple fragments, and each fragment
    is represented as a `Node` in the linked list. The size of this buffer is determined
    by the number of pixels in the swapchain’s extent (its width and height), the
    number of slots per pixel, and the size of the Node structure.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`linkedListHeadPtrTexture_`: This buffer stores the head pointers for the linked
    lists of each pixel. A head pointer points to the first Node of a linked list.
    This buffer is created as a 2D texture (image) because it needs to store a pointer
    for each pixel in the swapchain’s extents. The format `VK_FORMAT_R32_UINT` indicates
    that each element in the texture is a 32-bit unsigned integer, which is suitable
    for representing a pointer.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The actual magic of the algorithm happens during the `draw` function. As a first
    step, we are setting the pixels in `linkedListHeadPtrTexture_` to zero with `vkCmdClearColorImage`
    function, and filling the `linkedListBuffer_` and `atomicCounterBuffer_` with
    zeros using `vkCmdFillBuffer`, just to reset everything to null state before we
    begin writing to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to set up correct memory barriers. These barriers ensure that
    all clear operations finish before the shader starts reading from or writing to
    the buffers. The first barrier is a memory barrier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The other two barriers are buffer barriers, one for the linked list buffer
    and one for the atomic counter buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next step descriptor sets are bound, updated, and the vertex and index
    buffers are bound to the pipeline. Then the indexed draw command is issued for
    each mesh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The vertex fragment is not special, but the fragment shader must maintain a
    linked list along with head pointer. Below we present the code breakdown for `OitLinkedListBuildPass.frag`
    which is responsible for the build pass of the linked list OIT algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We start by defining a Node struct, which represents a node in a linked list
    for handling transparency. It contains the color and the index of the previous
    node. Afterwards, we declare several uniform and buffer variables, used for object
    properties, an atomic counter, a linked list of nodes, and an image for head pointers.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The main function performs an atomic add operation on the atomic counter to
    get a unique index for each fragment. After calculating the size of the image
    and ensuring the new node index doesn’t exceed the maximum size of the linked
    list, it performs an atomic exchange operation to insert the new node at the beginning
    of the linked list. Finally, it sets the properties of the new node in the linked
    list.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The next and final step is to draw a full screen quad. Before performing the
    full screen quad pass, we set up memory and buffer barriers to ensure synchronization
    for the `linkedListBuffer_` and the `linkedListHeadPtrTexture_` since these resources
    are used during the composite pass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Lastly, the composite pass fragment shader starts by first getting the head
    of the linked list for the current pixel. The list is stored in a buffer, and
    each pixel corresponds to the first node of a linked list of all fragments that
    affect that pixel. An array to temporarily store the nodes for sorting is created.
    We then iterate over the linked list, retrieving each node and storing it in the
    temporary array. It continues until it reaches the end of the list (denoted by
    `nodeIndex` being 0) or when it has retrieved 20 nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The nodes in the array are sorted in descending order based on their depth
    values using a simple bubble sort algorithm. This ensures that the nodes closest
    to the camera are blended last:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, the colors of each node are blended from back to front using the mix
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This algorithm gives a very good result and is an excellent option if you value
    correctness. It’s a bit slower than the one presented in the next recipe, but
    it is by far the most intuitive algorithm amongst all the different algorithms
    we discussed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We would like to note an additional technique, known as **Tail Blending**, that
    can be effectively combined with the technique discussed above. One of the limitations
    of our approach is the maximum number of fragments that can be accommodated for
    each pixel, which is typically dictated by the anticipated depth complexity of
    the scene and the memory available. In more intricate scenes with numerous overlapping
    transparent objects, the fragment count for a pixel may surpass this limit. That’s
    when Tail Blending becomes handy. When a linked list reaches its capacity, any
    extra fragments are directly blended with the color of the last node in the list,
    also known as the *tail*, hence the term *Tail Blending*. The benefit of tail
    blending is its ability to process scenes with extremely high depth complexity
    without the need to expand the maximum length of the linked list, thereby conserving
    memory. However, a potential drawback is that it might yield less precise results
    since blending is order-dependent and the fragments blended with the tail aren’t
    arranged in relation to the other fragments in the list.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Please see the following link on:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploring and Expanding the Continuum of OIT Algorithms: [http://cwyman.org/papers/hpg16_oitContinuum.pdf](http://cwyman.org/papers/hpg16_oitContinuum.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Weighted Order-Independent Transparency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Weighted Order-Independent Transparency** (**WOIT**) uses a different idea
    to tackle transparency, by using the concept of weighted averages rather than
    using data structures like linked lists or layers like depth peeling.'
  prefs: []
  type: TYPE_NORMAL
- en: This method doesn’t require sorting or linked lists or multiple passes, reducing
    the overhead associated with those operations. The final color is calculated by
    normalizing the color buffer with the weight buffer, which provides an aggregate
    view of the colors and their weights. Although it may not be as accurate as per-pixel
    linked lists in complex scenarios, WOIT offers a performance-efficient solution
    for handling transparency in scenes with lower depth complexity. In this recipe,
    you will gain an understanding of the WOIT technique. We will explore how this
    method employs weighted averages to handle transparency, eschewing the need for
    data structures like linked lists or multiple passes, thereby reducing associated
    overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository, the WOIT algorithm is implemented by the `OitWeightedPass`
    class, located in source `/enginecore/passes/` `OitWeightedPass.hpp` and `cpp`
    files. The corresponding shaders are `source/enginecore/resources/shaders/OitWeighted.frag`
    and `source/enginecore/resources/shaders/ OITWeightedComposite.frag`
  prefs: []
  type: TYPE_NORMAL
- en: The WOIT algorithm begins by initializing two empty buffers for each pixel,
    one for accumulating color and the other for accumulating weights. As the scene
    is rendered, the algorithm processes each transparent fragment and updates these
    buffers in a single rendering pass. During this pass, each fragment’s color is
    multiplied by its alpha value (the weight) and added to the color buffer, while
    the alpha value itself is added to the weight buffer. This process continues for
    all fragments, accumulating and blending their contributions based on their opacity.
    Once all fragments are processed, a final composite step is performed where the
    accumulated color in the color buffer is divided by the total weight in the weight
    buffer. This results in the final pixel color, providing a composite view of all
    transparent fragments based on their weights.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following steps provides a guide on implementing the WOIT technique using
    the Vulkan API.
  prefs: []
  type: TYPE_NORMAL
- en: The `OitWeightedPass::init` method is tasked with initializing a variety of
    resources. It establishes both the Accumulation pass and the Composite pass pipelines.
    Furthermore, it arranges the necessary resources for the accumulation pass pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `colorTexture_` uses the `VK_FORMAT_R16G16B16A16_SFLOAT` format. This format
    represents 4 channels (R, G, B, A) of 16-bit floating point numbers, providing
    high precision for color representation. It’s important for the color buffer to
    have a high precision format because during the accumulation pass, colors from
    various fragments are added together:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `alphaTexture`_ uses the `VK_FORMAT_R16_SFLOAT` format, which is a single
    16-bit floating point number. This is adequate because we’re only storing the
    alpha (opacity) value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since WOIT depends upon blending, it’s important to set up blending attachments
    correctly. The pipeline descriptor `gpDesc` below is created with two `VkPipelineColorBlendAttachmentState`
    structures, one for each attachment. For the first blend attachment (corresponding
    to the color texture), the blend factors are set to `VK_BLEND_FACTOR_ONE` for
    both the source and destination, and the blend operation is `VK_BLEND_OP_ADD`.
    This effectively implements additive blending, where the new fragment’s color
    is added to the existing color in the color buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the second blend attachment (corresponding to the alpha texture), the source
    alpha blend factor is `VK_BLEND_FACTOR_ZERO`, and the destination alpha blend
    factor is `VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR`. This configuration ensures that
    the new fragment’s alpha (or weight) is accumulated in the alpha buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we need to initialize the composite pipeline. This could be implemented
    as a Vulkan subpass, but for simplicity we have kept it as a separate pass. The
    composite pipeline is created with `VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA` as `srcColorBlendFactor`
    and `VK_BLEND_FACTOR_SRC_ALPHA` as `dstColorBlendFactor`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This configuration causes the incoming fragment’s color and alpha values to
    be blended with the current color and alpha in the frame buffer, with the incoming
    fragment’s alpha value controlling how much of the incoming color overwrites the
    existing color.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The draw function is where the actual rendering occurs, the implementation is
    straightforward and uses `vkCmdDrawIndexed` to draw multiple meshes. Below we
    present the fragment shader used during this step. In this fragment shader, the
    view-space depth is scaled to provide depth weight; closer fragments are assigned
    larger weights. Then, the maximum color component multiplied by alpha is calculated
    to weigh vibrant pixels more. The calculated color weight is ensured to be no
    more than 1.0 and compared with the alpha to take the maximum value. The depth
    weight is then calculated and clamped within a specific range. The final weight
    is the product of color and depth weights. The color is then premultiplied by
    its alpha value to prevent over-saturation during blending. This shader outputs
    the weighted color and the original alpha of the fragment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The final step is drawing a full screen quad using composite pipeline, it reads
    the accumulated color and alpha from two textures (`colorData` and `alphaData`)
    for the current fragment. The accumulated color (`accumulateColor`) is the sum
    of the product of color, alpha, and weight for each fragment from the previous
    step. The alpha value (alpha) is the original alpha value of the fragment. In
    the output color (`outColor`), the RGB components of the accumulated color are
    divided by the accumulated alpha value to normalize them, with a minimum limit
    of 0.0001 to prevent division by zero. This is because the accumulated color was
    premultiplied by the alpha value (and weight) in the previous steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This technique is faster than the linked-list one presented in recipe *Implementing
    Linked-List Order-Independent Transparency*, but it has its drawbacks, such as
    the weighting function which is prone to add artifacts to the result if not well
    designed and tested.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we have explored various techniques for handling transparency.
    The following table highlights the advantages and disadvantages of each method:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Technique** | **Memory** | **Performance** | **Physically correct** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Linked list OIT | High, depends upon scene complexity as well as maintained
    LinkedList size | Moderate speed, only requires two passes | Highly accurate,
    handles complex overlapping geometry very well |'
  prefs: []
  type: TYPE_TB
- en: '| Dual Depth Peeling OIT | Moderate, requires storage of two depth buffer |
    Slower, since it requires multiple passes | Moderate accuracy, struggles with
    highly complex scene. |'
  prefs: []
  type: TYPE_TB
- en: '| WOIT | Low, only needs to store weights & colors for each fragment. | Fast,
    since only single pass is required | Low accuracy, requires careful weight management
    that can depend upon scene. |'
  prefs: []
  type: TYPE_TB
- en: Table 5.1 – Comparison of various techniques
  prefs: []
  type: TYPE_NORMAL
- en: We hope *Table 5.1* will help you decide which technique to use based upon your
    use case.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Please see following link for more details on WOIT:'
  prefs: []
  type: TYPE_NORMAL
- en: 'WOIT: https://jcgt.org/published/0002/02/09/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
