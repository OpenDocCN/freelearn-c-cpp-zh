<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-173"><a id="_idTextAnchor186"/>7</h1>
<h1 id="_idParaDest-174"><a id="_idTextAnchor187"/>Communicating with Market Participants</h1>
<p>In this chapter, we will build the order gateway component at the electronic trading exchange that is responsible for accepting client connections, handling requests, and publishing responses to clients about their orders when there are updates. Fairness, low latency, and low jitter (latency variance) are important requirements here to facilitate high-frequency trading participants. We will also build the component that publishes market data from the trading exchange. These market data updates are designed to allow clients to construct the order book of all client orders that the electronic trading exchange holds. These market updates need to be sent out as soon as possible when there are order updates and when matches occur, so the focus will be on super-low-latency performance. Additionally, the exchange needs to periodically provide snapshots of the order book for participants that drop packets or start after the market is already open.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Defining the market data protocol and order data protocol</li>
<li>Building the order gateway server</li>
<li>Building the market data publisher</li>
<li>Building the main exchange application</li>
</ul>
<h1 id="_idParaDest-175"><a id="_idTextAnchor188"/>Technical requirements</h1>
<p>All the code for this book can be found in the GitHub repository for this book at <a href="https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP">https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP</a>. The source code for this chapter can be found in the <code>Chapter7</code> directory in the repository.</p>
<p>It is important that you have read and understood the design of the electronic trading ecosystem presented in the <em class="italic">Designing Our Trading Ecosystem</em> chapter. The components we build in this chapter will interact with the matching engine we built in the <em class="italic">Building the C++ Matching Engine</em> chapter, so we assume you are familiar with that. As before, we will use the building blocks we built in the <em class="italic">Building the C++ Building Blocks for Low-Latency </em><em class="italic">Applications</em> chapter.</p>
<h1 id="_idParaDest-176"><a id="_idTextAnchor189"/>Defining the market data protocol and order data protocol</h1>
<p>Before we<a id="_idIndexMarker1036"/> build the components inside the trading exchange that publish market data updates and receive and respond to client requests, we need to finalize the protocol. The <a id="_idIndexMarker1037"/>protocol needs to be publicly available so that market participants who want to connect to the exchange, process updates, and send order requests can build their software. The protocol is the <em class="italic">language</em> that the exchange and market participants will use to communicate. We will have two protocols – one for the format of the market data updates and one for the format to send order requests and receive order responses in.</p>
<h2 id="_idParaDest-177"><a id="_idTextAnchor190"/>Designing the market data protocol</h2>
<p>For the <a id="_idIndexMarker1038"/>market data protocol, we will define an internal format that the matching engine uses, and a public format meant for the market participants. We saw the internal matching format, that is, the <code>MEMarketUpdate</code> struct, in the <em class="italic">Building the Matching Engine</em> chapter, in the <em class="italic">Defining the operations and interactions in our matching engine</em> section. In this section, we will define the public market data format, which will be encapsulated in the <code>MDPMarketUpdate</code> struct. Remember that we mentioned that market data formats can be of several types and different complexity, for example, the FAST protocol or the SBE protocol. For our market data format, we will use the <code>Chapter7/exchange/market_data/market_update.h</code> source file.</p>
<p>Before we look at the market data protocol, a reminder that we first explained what a snapshot of market data is, why it is needed, and how it is synthesized using incremental market data updates in the <em class="italic">Designing Our Trading Ecosystem</em> chapter in the <em class="italic">Understanding how an exchange publishes information to participants</em> section, in the <em class="italic">Designing the market data publisher</em> subsection. Additionally, we discussed additional details about the snapshot data stream in the same chapter, in the <em class="italic">Building a market participant’s interface to the exchange</em> section. So, it would be worthwhile to revisit those sections if a refresher of those concepts is required. But just to re-introduce snapshot messages, these are messages that contain full information about the state of the limit order book at any given time and can be used by market participants if they need to re-construct the full limit order book.</p>
<p>Before we look at the <code>MDPMarketUpdate</code> struct, let us first revisit the <code>MarketUpdateType</code> enumeration we created in the previous chapter. In this chapter, we will add a few new enumeration types here – <code>CLEAR</code>, <code>SNAPSHOT_START</code>, and <code>SNAPSHOT_END</code> – which will be needed later. The <code>CLEAR</code> message is used to notify clients that they should clear/empty the order book on their end, <code>SNAPSHOT_START</code> signifies that a snapshot message is starting, and <code>SNAPSHOT_END</code> signifies that all updates in the snapshot update have been delivered.</p>
<p>The updated<a id="_idIndexMarker1040"/> enumeration list is shown as follows:</p>
<pre class="source-code">
#pragma once
#include &lt;sstream&gt;
#include "common/types.h"
using namespace Common;
namespace Exchange {
  enum class MarketUpdateType : uint8_t {
    INVALID = 0,
    CLEAR = 1,
    ADD = 2,
    MODIFY = 3,
    CANCEL = 4,
    TRADE = 5,
    SNAPSHOT_START = 6,
    SNAPSHOT_END = 7
  };
}</pre>
<p>Our <code>MDPMarketUpdate</code> structure<a id="_idIndexMarker1041"/> contains an important addition over the <code>MEMarketUpdate</code> structure, which is a sequence number field. This <code>size_t seq_num_</code> field is an increasing sequence number value for every market update published by the exchange. For every new market update, the sequence number is exactly 1 greater than the previous market update. This sequence number field will be used by the market data consumers in the market participants’ trading systems to detect gaps in market updates. Remember that for our market data publisher, we will publish the market data in UDP format, which is an unreliable protocol. So, when there are drops in packets at the network level, or if a participant’s system drops a packet, they can use the sequence number field to detect that. We present the internal <code>MEMarketUpdate</code> format again, and the new public <code>MDPMarketUpdate</code> format as follows:</p>
<pre class="source-code">
#pragma pack(push, 1)
  struct MEMarketUpdate {
    MarketUpdateType type_ = MarketUpdateType::INVALID;
    OrderId order_id_ = OrderId_INVALID;
    TickerId ticker_id_ = TickerId_INVALID;
    Side side_ = Side::INVALID;
    Price price_ = Price_INVALID;
    Qty qty_ = Qty_INVALID;
    Priority priority_ = Priority_INVALID;
    auto toString() const {
      std::stringstream ss;
      ss &lt;&lt; "MEMarketUpdate"
         &lt;&lt; " ["
         &lt;&lt; " type:" &lt;&lt; marketUpdateTypeToString(type_)
         &lt;&lt; " ticker:" &lt;&lt; tickerIdToString(ticker_id_)
         &lt;&lt; " oid:" &lt;&lt; orderIdToString(order_id_)
         &lt;&lt; " side:" &lt;&lt; sideToString(side_)
         &lt;&lt; " qty:" &lt;&lt; qtyToString(qty_)
         &lt;&lt; " price:" &lt;&lt; priceToString(price_)
         &lt;&lt; " priority:" &lt;&lt; priorityToString(priority_)
         &lt;&lt; "]";
      return ss.str();
    }
  };
  struct MDPMarketUpdate {
    size_t seq_num_ = 0;
    MEMarketUpdate me_market_update_;
    auto toString() const {
      std::stringstream ss;
      ss &lt;&lt; "MDPMarketUpdate"
         &lt;&lt; " ["
         &lt;&lt; " seq:" &lt;&lt; seq_num_
         &lt;&lt; " " &lt;&lt; me_market_update_.toString()
         &lt;&lt; "]";
      return ss.str();
    }
  };
#pragma pack(pop)</pre>
<p>Hence, <code>MDPMarketUpdate</code> is simply <code>MEMarketUpdate</code> with a leading <code>seq_num_</code> field. Before we finish this subsection, we will define two simple typedefs that we will need later in this chapter. We saw the first one, <code>MEMarketUpdateLFQueue</code>, in the previous chapter; the new <code>MDPMarketUpdateLFQueue</code> is similar and represents a lock-free<a id="_idIndexMarker1042"/> queue of <code>MDPMarketUpdate</code> structures:</p>
<pre class="source-code">
  typedef Common::LFQueue&lt;Exchange::MEMarketUpdate&gt;
    MEMarketUpdateLFQueue;
  typedef Common::LFQueue&lt;Exchange::MDPMarketUpdate&gt;
    MDPMarketUpdateLFQueue;</pre>
<p>That concludes our design of the market data protocol. We will see the design of the order data protocol next.</p>
<h2 id="_idParaDest-178"><a id="_idTextAnchor191"/>Designing the order data protocol</h2>
<p>In this subsection, we will design the <a id="_idIndexMarker1043"/>public order data protocol the clients will use to send order requests to the exchange and receive order responses from it, specifically the order gateway server.</p>
<p>First, we will see the format of messages sent from the market participant’s order gateway to the exchange’s order gateway server. We already discussed the <code>ClientRequestType</code> enumeration, the <code>MEClientRequest</code> struct, and the <code>ClientRequestLFQueue</code> typedef used by the matching engine in the <em class="italic">Building the C++ Matching Engine</em> chapter, in the <em class="italic">Defining the operations and interactions in our matching engine</em> section. <code>MEClientRequest</code> is the internal format used by the matching engine, but <code>OMClientRequest</code> is the format that the market participants need to use when sending order requests to the exchange order gateway server. Like the market data format, <code>OMClientRequest</code> has a sequence number field, <code>seq_num_</code>, and then the <code>MEClientRequest</code> struct after that. The sequence number field here serves a similar purpose as before, to make sure that the exchange and client’s order gateway components are in sync with each other. The code for this structure is in <a id="_idIndexMarker1044"/>the <code>Chapter7/exchange/order_server/client_request.h</code> file:</p>
<pre class="source-code">
#pragma once
#include &lt;sstream&gt;
#include "common/types.h"
#include "common/lf_queue.h"
using namespace Common;
namespace Exchange {
#pragma pack(push, 1)
  struct OMClientRequest {
    size_t seq_num_ = 0;
    MEClientRequest me_client_request_;
    auto toString() const {
      std::stringstream ss;
      ss &lt;&lt; "OMClientRequest"
         &lt;&lt; " ["
         &lt;&lt; "seq:" &lt;&lt; seq_num_
         &lt;&lt; " " &lt;&lt; me_client_request_.toString()
         &lt;&lt; "]";
      return ss.str();
    }
  };
#pragma pack(pop)
}</pre>
<p>We have a <a id="_idIndexMarker1045"/>symmetrical design of the responses sent from the exchange’s order gateway server to the client’s order gateway component. We saw the <code>MEClientResponse</code> structure in the previous chapter, which is used internally between the matching engine and the order gateway server component inside the trading exchange infrastructure. The <code>OMClientResponse</code> structure is the public format that the market participants will use to receive and process order responses in. Like the other structures we saw before, there is a sequence number field for synchronization purposes and the remaining payload for this structure is the <code>MEClientResponse</code> structure. This structure can be found in the <code>Chapter7/exchange/order_server/client_response.h</code> file:</p>
<pre class="source-code">
#pragma once
#include &lt;sstream&gt;
#include "common/types.h"
#include "common/lf_queue.h"
using namespace Common;
namespace Exchange {
#pragma pack(push, 1)
  struct OMClientResponse {
    size_t seq_num_ = 0;
    MEClientResponse me_client_response_;
    auto toString() const {
      std::stringstream ss;
      ss &lt;&lt; "OMClientResponse"
         &lt;&lt; " ["
         &lt;&lt; "seq:" &lt;&lt; seq_num_
         &lt;&lt; " " &lt;&lt; me_client_response_.toString()
         &lt;&lt; "]";
      return ss.str();
    }
  };
#pragma pack(pop)
}</pre>
<p>This concludes the design of<a id="_idIndexMarker1046"/> the new structures we will need in this chapter. Next, we will start discussing the implementation of the order gateway server, starting with how it handles incoming client requests from market participants.</p>
<h1 id="_idParaDest-179"><a id="_idTextAnchor192"/>Building the order gateway server</h1>
<p>In this section, we will start<a id="_idIndexMarker1047"/> building the order gateway server infrastructure, which is responsible for setting up a TCP server for clients to connect to. The order gateway server also needs to process incoming client requests from different clients in the order in which they arrive and forward those to the matching engine. Finally, it also needs to receive the order responses from the matching engine and forward them to the correct TCP connection for the corresponding market participant. We will revisit the design of the order gateway server and how it interacts with the matching engine and the market participants, as follows.</p>
<div><div><img alt="Figure 7.1 – Order gateway server and its subcomponents" src="img/B19434_07_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Order gateway server and its subcomponents</p>
<p>To refresh your memory, the order gateway server receives new TCP connections or client requests on established TCP connections. Then, those requests go through a FIFO sequencer stage to make sure that requests are processed in the exact order in which they arrived at the exchange’s infrastructure. There is a transformation between the internal matching engine format and the public order data format we described in the previous section. In the previous chapter on <em class="italic">Building the Matching Engine</em>, we already built the communication path to and from the matching engine, which is through lock-free queues. All the details behind the design of this component as well as what purpose it serves in our electronic trading ecosystem were discussed in the <em class="italic">Designing Our Trading Ecosystem</em> chapter, specifically in the <em class="italic">Understanding the layout of the electronic trading ecosystem</em> and <em class="italic">Understanding how an exchange publishes information to participants</em> sections. So, we would strongly recommend revisiting that chapter as you build the order gateway server at the exchange.</p>
<p>First, we will build the <code>OrderServer</code> class, which <a id="_idIndexMarker1048"/>represents the order gateway server component in the preceding diagram. The code for <code>OrderServer</code> resides in the <code>Chapter7/exchange/order_server/order_server.h</code> and <code>Chapter7/exchange/order_server/order_server.cpp</code> files.</p>
<h2 id="_idParaDest-180"><a id="_idTextAnchor193"/>Defining the data members in the order gateway server</h2>
<p>The <code>OrderServer</code> class has a<a id="_idIndexMarker1049"/> few important data<a id="_idIndexMarker1050"/> members:</p>
<ul>
<li>A <code>tcp_server_</code> variable, which is an instance of the <code>Common::TCPServer</code> class, which will be used to host a TCP server to poll for, accept incoming connections from market participants, and poll the established TCP connections to see whether there is data to be read from any of the connections.</li>
<li>A <code>fifo_sequencer_</code> variable, which is an instance of the <code>FIFOSequencer</code> class and is responsible for making sure that client requests that come in on different TCP connections are processed in the correct order in which they came.</li>
<li>A lock-free queue variable, <code>outgoing_responses_</code>, of the <code>ClientResponseLFQueue</code> type, using which it receives <code>MEClientResponse</code> messages from the matching engine, which need to be sent out to the correct market participant.</li>
<li>A <code>std::array</code> <code>cid_tcp_socket_</code> of <code>TCPSocket</code> objects of size <code>ME_MAX_NUM_CLIENTS</code>, which will be used as a hash map from client-id to the <code>TCPSocket</code> connection for that client.</li>
<li>Two <code>std::array</code>s also of size <code>ME_MAX_NUM_CLIENTS</code> to track the exchange-to-client and client-to-exchange sequence numbers on the <code>OMClientResponse</code> and <code>OMClientRequest</code> messages. These are the <code>cid_next_outgoing_seq_num_</code> and <code>cid_next_exp_seq_num_</code> variables.</li>
<li>A Boolean <code>run_</code> variable, which will be used to start and stop the <code>OrderServer</code> thread. Note that it is marked <code>volatile</code> since it will be accessed from different threads, and we want to prevent compiler optimizations here for correct<a id="_idIndexMarker1051"/> functionality in a <a id="_idIndexMarker1052"/>multi-threaded environment:<pre class="source-code">
#pragma once</pre><pre class="source-code">
#include &lt;functional&gt;</pre><pre class="source-code">
#include "common/thread_utils.h"</pre><pre class="source-code">
#include "common/macros.h"</pre><pre class="source-code">
#include "common/tcp_server.h"</pre><pre class="source-code">
#include "order_server/client_request.h"</pre><pre class="source-code">
#include "order_server/client_response.h"</pre><pre class="source-code">
#include "order_server/fifo_sequencer.h"</pre><pre class="source-code">
namespace Exchange {</pre><pre class="source-code">
  class OrderServer {</pre><pre class="source-code">
  private:</pre><pre class="source-code">
    const std::string iface_;</pre><pre class="source-code">
    const int port_ = 0;</pre><pre class="source-code">
    ClientResponseLFQueue *outgoing_responses_ = nullptr;</pre><pre class="source-code">
    volatile bool run_ = false;</pre><pre class="source-code">
    std::string time_str_;</pre><pre class="source-code">
    Logger logger_;</pre><pre class="source-code">
    std::array&lt;size_t, ME_MAX_NUM_CLIENTS&gt; cid_next_outgoing_</pre><pre class="source-code">
    seq_num_;</pre><pre class="source-code">
    std::array&lt;size_t, ME_MAX_NUM_CLIENTS&gt; cid_next_exp_seq_</pre><pre class="source-code">
    num_;</pre><pre class="source-code">
    std::array&lt;Common::TCPSocket *, ME_MAX_NUM_CLIENTS&gt; cid_tcp_</pre><pre class="source-code">
    socket_;</pre><pre class="source-code">
    Common::TCPServer tcp_server_;</pre><pre class="source-code">
    FIFOSequencer fifo_sequencer_;</pre><pre class="source-code">
  };</pre><pre class="source-code">
}</pre></li>
</ul>
<p>One more minor <a id="_idIndexMarker1053"/>declaration before we move on to <a id="_idIndexMarker1054"/>the next subsection is that the <code>OrderServer</code> class has the following method declarations, which we will define in the subsequent subsections. These are methods corresponding to the constructor, the destructor, a <code>start()</code> method, and a <code>stop()</code> method, but for now, do not worry about the details of these; we will be defining them very soon:</p>
<pre class="source-code">
    OrderServer(ClientRequestLFQueue *client_requests,
    ClientResponseLFQueue *client_responses, const std::string &amp;iface,
    int port);
    ~OrderServer();
    auto start() -&gt; void;
    auto stop() -&gt; void;</pre>
<p>In the next subsection, we will initialize and de-initialize the <code>OrderServer</code> class and its member variables.</p>
<h2 id="_idParaDest-181"><a id="_idTextAnchor194"/>Initializing the order gateway server</h2>
<p>The constructor for<a id="_idIndexMarker1055"/> this class is straightforward. We initialize the three arrays with some basic values: sequence numbers set to 1 and <code>TCPSocket</code>s set to <code>nullptr</code>. We will also set the two callback members, <code>recv_callback_</code> and <code>recv_finished_callback_</code>, to point to the <code>recvCallback()</code> and <code>recvFinishedCallback()</code> member functions. We will discuss these callback handling methods in the next few subsections. The constructor for <code>OrderServer</code> accepts pointers to two lock-free queue objects: one to forward <code>MEClientRequest</code>s to the matching engine and one to receive <code>MEClientResponse</code>s from the matching engine. It also accepts a network interface and port to use that the order gateway server will listen to and accept client connections on:</p>
<pre class="source-code">
#include "order_server.h"
namespace Exchange {
  OrderServer::OrderServer(ClientRequestLFQueue *client_requests,
    ClientResponseLFQueue *client_responses, const std::string &amp;iface,
    int port)
      : iface_(iface), port_(port), outgoing_responses_(client_
    responses), logger_("exchange_order_server.log"),
        tcp_server_(logger_), fifo_sequencer_(client_requests, 
    &amp;logger_) {
    cid_next_outgoing_seq_num_.fill(1);
    cid_next_exp_seq_num_.fill(1);
    cid_tcp_socket_.fill(nullptr);
    tcp_server_.recv_callback_ = [this](auto socket, auto rx_time) { 
    recvCallback(socket, rx_time); };
    tcp_server_.recv_finished_callback_ = [this]() {
    recvFinishedCallback(); };
  }
}</pre>
<p>We will also<a id="_idIndexMarker1056"/> define a <code>start()</code> method, which will set the bool run_ to be true. This is the flag that controls how long the main thread will run. We also initialize the <code>TCPServer</code> member object to start listening on the interface and port that <code>OrderServer</code> was provided in the constructor. Finally, it creates and launches a thread that will execute the <code>run()</code> method, which we will also see in the next few subsections. For now, we will not set affinity on any threads we create in this application, but we will discuss optimization possibilities at the end of this book:</p>
<pre class="source-code">
  auto OrderServer::start() -&gt; void {
    run_ = true;
    tcp_server_.listen(iface_, port_);
    ASSERT(Common::createAndStartThread(-1, "Exchange/OrderServer",
    [this]() { run(); }) != nullptr, "Failed to start OrderServer
    thread.");
  }</pre>
<p>We define a complementary <code>stop()</code> method, which simply sets the <code>run_</code> flag to false, which will cause the <code>run()</code> method to finish execution (more on this shortly):</p>
<pre class="source-code">
  auto OrderServer::stop() -&gt; void {
    run_ = false;
  }</pre>
<p>The destructor for the <code>OrderServer</code> class is also quite simple. It calls the <code>stop()</code> method to instruct the main thread to stop execution and then waits a brief period of time for the thread to finish any pending tasks:</p>
<pre class="source-code">
  OrderServer::~OrderServer() {
    stop();
    using namespace std::literals::chrono_literals;
    std::this_thread::sleep_for(1s);
  }</pre>
<p>This concludes the <a id="_idIndexMarker1057"/>subsection on the initialization of this class. Next, we will investigate the functionality needed for <code>OrderServer</code> to handle incoming client requests over TCP connections.</p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor195"/>Handling incoming client requests</h2>
<p>In this subsection, we <a id="_idIndexMarker1058"/>will discuss the code we need to handle incoming client requests. These client requests are received over TCP connections, and these are dispatched to the <code>recvCallback()</code> and <code>recvFinishedCallback()</code> methods through the <code>TCPServer</code> like we set up in the constructor. We will break down the implementation of this method into different blocks so we can understand it better here.</p>
<p>The first code block in this method checks whether the size of the available data is at least as large as a complete <code>OMClientRequest</code> struct. Then it breaks up the available data into blocks of size equal to the size of an <code>OMClientRequest</code> object, and iterates through the available data. It reinterprets <code>rcv_buffer_</code> in <code>TCPSocket</code> as an <code>OMClientRequest</code> struct and saves it in the request variable, which is of the <code>OMClientRequest</code> pointer type:</p>
<pre class="source-code">
    auto recvCallback(TCPSocket *socket, Nanos rx_time) noexcept {
      logger_.log("%:% %() % Received socket:% len:% rx:%\n", __FILE__,
    __LINE__, __FUNCTION__, Common::getCurrentTimeStr(&amp;time_str_),
                  socket-&gt;fd_, socket-&gt;next_rcv_valid_index_, rx_
    time);
      if (socket-&gt;next_rcv_valid_index_ &gt;= sizeof(OMClientRequest)) {
        size_t i = 0;
        for (; i + sizeof(OMClientRequest) &lt;= socket-&gt;next_rcv_valid_
        index_; i += sizeof(OMClientRequest)) {
        auto request = reinterpret_cast&lt;const OMClientRequest         *&gt;(socket-&gt;rcv_buffer_ + i);
          logger_.log("%:% %() % Received %\n", __FILE__, __LINE__,
          __FUNCTION__, Common::getCurrentTimeStr(&amp;time_str_),
          request-&gt;toString());</pre>
<p>Once it has the <code>OMClientRequest</code> it needs to process, it checks whether this is the first request from this client. If that is the case, then it tracks the <code>TCPSocket</code> instance for this client by<a id="_idIndexMarker1059"/> adding it to the <code>cid_tcp_socket_</code> <code>std::array</code>, which we are using as a hash map:</p>
<pre class="source-code">
          if (UNLIKELY(cid_tcp_socket_[request-&gt;me_client_request_.
          client_id_] == nullptr)) {
            cid_tcp_socket_[request-&gt;me_client_request_.client_id_] =
            socket;
          }</pre>
<p>If a <code>TCPSocket</code> entry for this client-id already existed in the <code>cid_tcp_socket_</code> container, then we would make sure that the previously tracked <code>TCPSocket</code> for this client-id matches the <code>TCPSocket</code> for the current request. If they do not match, we log an error and skip processing this request:</p>
<pre class="source-code">
          if (cid_tcp_socket_[request-&gt;me_client_request_.client_id_]
          != socket) {
            logger_.log("%:% %() % Received ClientRequest from
            ClientId:% on different socket:% expected:%\n", __FILE__,
            __LINE__, __FUNCTION__,
                        Common::getCurrentTimeStr(&amp;time_str_),
                        request-&gt;me_client_request_.client_id_,
                        socket-&gt;fd_,
                        cid_tcp_socket_[request-&gt;me_client_request_.
                        client_id_]-&gt;fd_);
            continue;
          }</pre>
<p>Next, we will perform a sequence number check to make sure that the sequence number on this <code>OMClientRequest</code> is exactly what we expect it to be based on the last message we have seen. If there is a mismatch between the expected and received sequence numbers, then <a id="_idIndexMarker1060"/>we log an error and ignore this request:</p>
<pre class="source-code">
          auto &amp;next_exp_seq_num = cid_next_exp_seq_num_[request-&gt;me_
          client_request_.client_id_];
          if (request-&gt;seq_num_ != next_exp_seq_num) {
            logger_.log("%:% %() % Incorrect sequence number.
            ClientId:% SeqNum expected:% received:%\n", __FILE__,
            __LINE__, __FUNCTION__,
                        Common::getCurrentTimeStr(&amp;time_str_),
                        request-&gt;me_client_request_.client_id_, next_
                        exp_seq_num, request-&gt;seq_num_);
            continue;
          }</pre>
<p>One note here is that in a realistic setup, the exchange will send a reject back to the client if it receives a request on an incorrect socket or if there is a sequence number mismatch, to notify them of the error. We have omitted that here for simplicity’s sake, but it is not difficult to add if needed. If we have made it this far in the execution of this loop, then we increment the next expected sequence number on the next <code>OMClientRequest</code> for this client and forward this request to the FIFO sequencer data member. One important thing to note here is that we also forward <code>rx_time</code>, which is the software receive time of this TCP packet, to the FIFO sequencer since it will need that information to sequence the requests correctly. We will discuss the details of how the FIFO sequencer achieves this in the next subsection:</p>
<pre class="source-code">
          ++next_exp_seq_num;
          fifo_sequencer_.addClientRequest(rx_time, request-&gt;me_
          client_request_);
        }
        memcpy(socket-&gt;rcv_buffer_, socket-&gt;rcv_buffer_ + i, socket-
        &gt;next_rcv_valid_index_ - i);
        socket-&gt;next_rcv_valid_index_ -= i;
      }
    }</pre>
<p>Remember that<a id="_idIndexMarker1061"/> the <code>recvFinishedCallback()</code> method is called when all the <code>recvCallback()</code> methods have been dispatched from the current call to <code>TCPServer::sendAndRecv()</code>. The <code>recvFinishedCallback()</code> method instructs <code>FIFOSequencer</code> to correctly order the <code>MEClientRequests</code> that it has queued up and push them to the matching engine. This mechanism will become clear when we discuss the design and implementation of the <code>FIFOSequencer</code> in the next subsection:</p>
<pre class="source-code">
    auto recvFinishedCallback() noexcept {
      fifo_sequencer_.sequenceAndPublish();
    }</pre>
<p>Next, we will discuss the FIFO sequencer component, which is responsible for maintaining fairness from the perspective of processing client requests. It does this by making sure that requests received across different TCP connections are processed in the exact order in which they were received in the order gateway server.</p>
<h2 id="_idParaDest-183"><a id="_idTextAnchor196"/>Processing requests fairly using the FIFO sequencer</h2>
<p>The<a id="_idIndexMarker1062"/> FIFO sequencer<a id="_idIndexMarker1063"/> subcomponent in the order gateway server is responsible for making sure that client requests are processed in the order of their arrival time. This is necessary because the order gateway server reads and dispatches client requests from different TCP connections, which arrive at different times. Let us get started by first defining the data members inside this class. The code for the FIFO sequencer is in the <code>Chapter7/exchange/order_server/fifo_sequencer.h</code> source file.</p>
<h3>Defining the data members in the FIFO sequencer</h3>
<p>First, we define a<a id="_idIndexMarker1064"/> constant, <code>ME_MAX_PENDING_REQUESTS</code>, which<a id="_idIndexMarker1065"/> represents the maximum number of simultaneously pending requests available at the network socket across all TCP connections. If the order gateway server is busy with other tasks and has not polled the TCP connections for a very short period of time, it is possible client requests arrived during that time and are queued at the network socket level.</p>
<p>The FIFO sequencer uses this constant to create a <code>std::array</code> of that size of <code>RecvTimeClientRequest</code> structures. This member variable is named <code>pending_client_requests_</code> in this <code>FIFOSequencer</code> class. To count the number of actual pending request entries in this <code>pending_client_requests_</code> array, we will maintain a <code>pending_size_</code> variable of the <code>size_t</code> type.</p>
<p>The <code>RecvTimeClientRequest</code> struct has two members – <code>recv_time_</code>, of the <code>Nanos</code> type, and a <code>request_</code> variable of the <code>MEClientRequest</code> type. This structure captures the client request as well as the time of its arrival at the order gateway server. We will sort these by time and then process them in order of arrival. To make sorting easy, we will define a <code>&lt;</code> operator, which returns <code>true</code> if the client request on the <strong class="bold">left-hand side</strong> (<strong class="bold">LHS</strong>) was received before the client request on the <strong class="bold">right-hand side</strong> (<strong class="bold">RHS</strong>) of that operator.</p>
<p>Finally, the last<a id="_idIndexMarker1066"/> important member of this class is the <code>incoming_requests_</code> variable, which<a id="_idIndexMarker1067"/> is of the <code>ClientRequestLFQueue</code> type, which is the lock-free queue that the FIFO sequencer uses to send <code>MEClientRequest</code>s to the matching engine:</p>
<pre class="source-code">
#pragma once
#include "common/thread_utils.h"
#include "common/macros.h"
#include "order_server/client_request.h"
namespace Exchange {
  constexpr size_t ME_MAX_PENDING_REQUESTS = 1024;
  class FIFOSequencer {
  private:
    ClientRequestLFQueue *incoming_requests_ = nullptr;
    std::string time_str_;
    Logger *logger_ = nullptr;
    struct RecvTimeClientRequest {
      Nanos recv_time_ = 0;
      MEClientRequest request_;
      auto operator&lt;(const RecvTimeClientRequest &amp;rhs) const {
        return (recv_time_ &lt; rhs.recv_time_);
      }
    };
    std::array&lt;RecvTimeClientRequest, ME_MAX_PENDING_REQUESTS&gt;
    pending_client_requests_;
    size_t pending_size_ = 0;
  };
}</pre>
<p>Now, let us look at the source code to initialize the FIFO sequencer.</p>
<h3>Initializing the FIFO sequencer</h3>
<p>The <a id="_idIndexMarker1068"/>constructor for the <code>FIFOSequencer</code> class is straightforward and self-explanatory. It is presented as follows and initializes <code>incoming_requests_</code> <code>ClientRequestLFQueue</code> and <code>logger_</code>, which are both passed to it in the constructor for this class:</p>
<pre class="source-code">
  class FIFOSequencer {
  public:
    FIFOSequencer(ClientRequestLFQueue *client_requests, Logger 
    *logger)
        : incoming_requests_(client_requests), logger_(logger) {
    }</pre>
<p>Now, we will look at the most important functionality inside the FIFO sequencer – queueing up client requests and publishing them in order of their receive time.</p>
<h3>Publishing client requests in order</h3>
<p>We<a id="_idIndexMarker1069"/> used the <code>FIFOSequencer::addClientRequest()</code> method in a previous subsection, <em class="italic">Handling incoming client requests</em>. Here, we present the implementation, which is quite simple and involves simply adding it to the end of <code>pending_client_requests_</code> and incrementing the <code>pending_size_</code> variable to signify that there is an additional entry that was added. Note here that we only ever expect a maximum of <code>ME_MAX_PENDING_REQUESTS</code> at a time since we set it to a high value. If this limit is not enough, we have the option of increasing the array size and possibly switching to using a <code>MemPool</code> of <code>RecvTimeClientRequest</code> objects:</p>
<pre class="source-code">
    auto addClientRequest(Nanos rx_time, const MEClientRequest
    &amp;request) {
      if (pending_size_ &gt;= pending_client_requests_.size()) {
        FATAL("Too many pending requests");
      }
      pending_client_requests_.at(pending_size_++) =
      std::move(RecvTimeClientRequest{rx_time, request});
    }</pre>
<p>We also <a id="_idIndexMarker1070"/>used the <code>FIFOSequencer::sequenceAndPublish()</code> method in a previous subsection, <em class="italic">Handling incoming client requests</em>. This is the most important method in the <code>FIFOSequencer</code> class and performs the following tasks:</p>
<ul>
<li>First, it sorts all the <code>RecvTimeClientRequest</code> entries in the <code>pending_client_requests_</code> container in ascending order of their arrival times. It achieves this by using the <code>std::sort()</code> algorithm, which in turn uses the <code>&lt;</code> operator we built for <code>RecvTimeClientRequest</code> objects to sort the container. One word here: sorting can become time consuming if the number of elements is very large, but we rarely expect that to be the case here, since the number of simultaneously pending requests is expected to be quite low. This would be another optimization area, but we need to measure the load and performance of our system in practice before deciding how to improve this.</li>
<li>After the sorting step, it writes each of the <code>MEClientRequest</code> entries to the <code>incoming_requests_</code> <code>LFQueue</code>, which goes to the matching engine.</li>
<li>Finally, it<a id="_idIndexMarker1071"/> resets the <code>pending_size_</code> variable to mark the end of processing and returns  from the method:<pre class="source-code">
    auto sequenceAndPublish() {</pre><pre class="source-code">
      if (UNLIKELY(!pending_size_))</pre><pre class="source-code">
        return;</pre><pre class="source-code">
      logger_-&gt;log("%:% %() % Processing % requests.\n", __</pre><pre class="source-code">
      FILE__, __LINE__, __FUNCTION__, Common::getCurrentTimeStr</pre><pre class="source-code">
      (&amp;time_str_), pending_size_);</pre><pre class="source-code">
      std::sort(pending_client_requests_.begin(), pending_</pre><pre class="source-code">
      client_requests_.begin() + pending_size_);</pre><pre class="source-code">
      for (size_t i = 0; i &lt; pending_size_; ++i) {</pre><pre class="source-code">
        const auto &amp;client_request = pending_client_requests_.</pre><pre class="source-code">
        at(i);</pre><pre class="source-code">
        logger_-&gt;log("%:% %() % Writing RX:% Req:%</pre><pre class="source-code">
        to FIFO.\n", __FILE__, __LINE__, __FUNCTION__,</pre><pre class="source-code">
        Common::getCurrentTimeStr(&amp;time_str_),</pre><pre class="source-code">
                     client_request.recv_time_, client_request.</pre><pre class="source-code">
                     request_.toString());</pre><pre class="source-code">
        auto next_write = incoming_requests_-&gt;getNextToWriteTo();</pre><pre class="source-code">
        *next_write = std::move(client_request.request_);</pre><pre class="source-code">
        incoming_requests_-&gt;updateWriteIndex();</pre><pre class="source-code">
      }</pre><pre class="source-code">
      pending_size_ = 0;</pre><pre class="source-code">
    }</pre></li>
</ul>
<p>This concludes the<a id="_idIndexMarker1072"/> design and implementation of the <code>FIFOSequencer</code> subcomponent inside our order gateway server. Now, we can go back to our design of the <code>OrderServer</code> class by adding functionality to send client responses back out to the clients over TCP.</p>
<h2 id="_idParaDest-184"><a id="_idTextAnchor197"/>Sending client responses</h2>
<p>In this subsection, we will look<a id="_idIndexMarker1073"/> at how <code>OrderServer</code> performs two important tasks in the <code>run()</code> method. Remember that this <code>run()</code> method is the main loop for this class, which is run on the thread we created and launched in the <em class="italic">Initializing the order gateway server</em> subsection, specifically in the <code>start()</code> method. The <code>run()</code> method performs the following two main tasks:</p>
<ul>
<li>It calls the <code>poll()</code> method on the <code>TCPServer</code> object it holds. Remember that the <code>poll()</code> method checks for and accepts new connections, removes dead connections, and checks whether there is data available on any of the established TCP connections, that is, client requests.</li>
<li>It also calls the <code>sendAndRecv()</code> method on the <code>TCPServer</code> object it holds. The <code>sendAndRecv()</code> method reads the data from each of the TCP connections and dispatches the callbacks for them. The <code>sendAndRecv()</code> call also sends out any outgoing data on the TCP connections, that is, client responses. This code block is shown as follows and should be quite easy to understand:<pre class="source-code">
    auto run() noexcept {</pre><pre class="source-code">
      logger_.log("%:% %() %\n", __FILE__, __LINE__, __</pre><pre class="source-code">
      FUNCTION__, Common::getCurrentTimeStr(&amp;time_str_));</pre><pre class="source-code">
      while (run_) {</pre><pre class="source-code">
        tcp_server_.poll();</pre><pre class="source-code">
        tcp_server_.sendAndRecv();</pre></li>
<li>The <code>run()</code> loop also drains the <code>outgoing_responses_</code> lock-free queue, which the matching engine uses to send out <code>MEClientResponse</code> messages that need to be dispatched to the correct clients.</li>
<li>It iterates through the available data in the <code>outgoing_responses_</code> queue and then for each <code>MEClientResponse</code> it reads, it first finds out what the correct outgoing sequence number is. This is the sequence number on the <code>OMClientResponse</code> message to be sent to that client ID. It does this by looking up that answer in the <code>cid_next_outgoing_seq_num_</code> array, which we are <a id="_idIndexMarker1074"/>really using as a hash map from the client ID to the sequence number:<pre class="source-code">
        for (auto client_response = outgoing_responses_-</pre><pre class="source-code">
        &gt;getNextToRead(); outgoing_responses_-&gt;size() &amp;&amp;</pre><pre class="source-code">
        client_response; client_response = outgoing_responses_-</pre><pre class="source-code">
        &gt;getNextToRead()) {</pre><pre class="source-code">
          auto &amp;next_outgoing_seq_num = cid_next_outgoing_seq_</pre><pre class="source-code">
          num_[client_response-&gt;client_id_];</pre><pre class="source-code">
          logger_.log("%:% %() % Processing cid:% seq:% %\n", __</pre><pre class="source-code">
          FILE__, __LINE__, __FUNCTION__,</pre><pre class="source-code">
          Common::getCurrentTimeStr(&amp;time_str_),</pre><pre class="source-code">
          client_response-&gt;client_id_, next_</pre><pre class="source-code">
          outgoing_seq_num, client_response-</pre><pre class="source-code">
          &gt;toString());</pre></li>
<li>It also checks that it has a valid <code>TCPSocket</code> for the client ID that this response is meant for. It looks up that information in the <code>cid_tcp_socket_</code> array, which is a hash map from the client ID to <code>TCPSocket</code> objects.</li>
<li>It then sends an <code>OMClientResponse</code> message on <code>TCPSocket</code> for this client ID by calling the <code>TCPSocket::send()</code> method. It achieves this by first sending the <code>next_outgoing_seq_num_</code> value and then the <code>MEClientResponse</code> message that the matching engine generated. It might not be immediately clear, but this is actually sending an <code>OMClientResponse</code> message because the <code>OMClientResponse</code> message is actually just a sequence number field followed by a <code>MEClientResponse</code> message, which is what we just did.</li>
<li>Finally, it <a id="_idIndexMarker1075"/>updates the read index and the sequence number of the next outgoing message and continues with the loop:<pre class="source-code">
          ASSERT(cid_tcp_socket_[client_response-&gt;client_id_] !=</pre><pre class="source-code">
          nullptr,</pre><pre class="source-code">
                 "Dont have a TCPSocket for ClientId:" + </pre><pre class="source-code">
                 std::to_string(client_response-&gt;client_id_));</pre><pre class="source-code">
          cid_tcp_socket_[client_response-&gt;client_id_]-</pre><pre class="source-code">
          &gt;send(&amp;next_outgoing_seq_num, sizeof(next_outgoing_</pre><pre class="source-code">
          seq_num));</pre><pre class="source-code">
          cid_tcp_socket_[client_response-&gt;client_id_]-</pre><pre class="source-code">
          &gt;send(client_response, sizeof(MEClientResponse));</pre><pre class="source-code">
          outgoing_responses_-&gt;updateReadIndex();</pre><pre class="source-code">
          ++next_outgoing_seq_num;</pre><pre class="source-code">
        }</pre><pre class="source-code">
      }</pre><pre class="source-code">
    }</pre></li>
</ul>
<p>This concludes the<a id="_idIndexMarker1076"/> full design and implementation of the order gateway server component in our electronic trading infrastructure. Next, we will look at the component that publishes the public market data to the participants.</p>
<h1 id="_idParaDest-185"><a id="_idTextAnchor198"/>Building the market data publisher</h1>
<p>The last component in the<a id="_idIndexMarker1077"/> electronic trading exchange we need to build is the market data publisher, which is how the exchange publishes public market data updates to any market participants that need it. Revisiting the design of the market data publisher, we present a diagram of how this component communicates with the matching engine and publishes to the market data participants over UDP, as follows.</p>
<div><div><img alt="Figure 7.2 – Market data publisher and its subcomponents" src="img/B19434_07_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Market data publisher and its subcomponents</p>
<p>We would like to remind you that the purpose and design of the market data publisher were discussed in detail in the <em class="italic">Designing Our Trading Ecosystem</em> chapter, specifically in the <em class="italic">Understanding the layout of the electronic trading ecosystem</em> and <em class="italic">Understanding how an exchange publishes information to participants</em> sections. We would strongly encourage you to revisit those sections to follow along as we build our market data publisher component.</p>
<p>Let us get started by first understanding how updates are consumed from the matching engine and published by jumping into the <code>MarketDataPublisher</code> class. All the source code <a id="_idIndexMarker1078"/>for the <code>MarketDataPublisher</code> class is in the <code>Chapter7/exchange/market_data/market_data_publisher.h</code> and <code>Chapter7/exchange/market_data/market_data_publisher.cpp</code> source files.</p>
<h2 id="_idParaDest-186"><a id="_idTextAnchor199"/>Defining the data members in the market data publisher</h2>
<p>The <code>MarketDataPublisher</code> class<a id="_idIndexMarker1079"/> has the following<a id="_idIndexMarker1080"/> important members:</p>
<ul>
<li>A <code>next_inc_seq_num_</code> variable of the <code>size_t</code> type, which represents the sequence number to set on the next outgoing incremental market data message. We discussed the concepts of incremental and snapshot market data updates in the <em class="italic">Designing Our Trading Ecosystem</em> chapter, in the <em class="italic">Understanding how an exchange publishes information to participants</em> and <em class="italic">Building a market participant’s interface to the </em><em class="italic">exchange</em> sections.</li>
<li>An <code>outgoing_md_updates_</code> variable of the <code>MEMarketUpdateLFQueue</code> type, which is a lock-free queue of <code>MEMarketUpdate</code> messages. We discussed the <code>MEMarketUpdate</code> structure in the <em class="italic">Building the C++ Matching Engine</em> chapter, in the <em class="italic">Defining the operations and interactions in our matching engine</em> section. This <code>LFQueue</code> is how the matching engine sends the <code>MEMarketUpdate</code> messages that the market data publisher then publishes over UDP.</li>
<li>An <code>incremental_socket_</code> member, which is an <code>McastSocket</code> to be used to publish UDP messages on the incremental multicast stream.</li>
<li>A <code>snapshot_synthesizer_</code> variable of the <code>SnapshotSynthesizer</code> type, which we will discuss in the next subsection. This object will be responsible for generating a snapshot of the limit order book from the updates that the matching engine provides and periodically publishing a snapshot of the full order book on the snapshot multicast stream. This was discussed in the <em class="italic">Designing Our Trading Ecosystem</em> chapter, in the <em class="italic">Understanding how an exchange publishes information to participants</em> section, specifically in the <em class="italic">Designing the market data </em><em class="italic">publisher</em> subsection.</li>
<li>A lock-free queue instance called <code>snapshot_md_updates_</code>, which will be of the <code>MDPMarketUpdateLFQueue</code> type, which is a lock-free queue containing <code>MDPMarketUpdate</code> messages. This queue is used by the market data publisher thread to publish <code>MDPMarketUpdate</code> messages that it sends on the incremental stream to the <code>SnapshotSynthesizer</code> component. This <code>LFQueue</code> is necessary since <code>SnapshotSynthesizer</code> runs on a different thread than <code>MarketDataPublisher</code>, which is primarily so that the snapshot synthesis and publishing process do not slow down the latency-sensitive <code>MarketDataPublisher</code> component.</li>
<li>The last <a id="_idIndexMarker1081"/>important member of the <code>MarketDataPublisher</code> class is the <code>run_</code> Boolean variable, which is just used to control when the <code>MarketDataPublisher</code> thread is started and<a id="_idIndexMarker1082"/> stopped. Since it is accessed from different threads, like the <code>run_</code> variable in the <code>OrderServer</code> class, it is also marked as <code>volatile</code>:<pre class="source-code">
#pragma once</pre><pre class="source-code">
#include &lt;functional&gt;</pre><pre class="source-code">
#include "market_data/snapshot_synthesizer.h"</pre><pre class="source-code">
namespace Exchange {</pre><pre class="source-code">
  class MarketDataPublisher {</pre><pre class="source-code">
  private:</pre><pre class="source-code">
    size_t next_inc_seq_num_ = 1;</pre><pre class="source-code">
    MEMarketUpdateLFQueue *outgoing_md_updates_ = nullptr;</pre><pre class="source-code">
    MDPMarketUpdateLFQueue snapshot_md_updates_;</pre><pre class="source-code">
    volatile bool run_ = false;</pre><pre class="source-code">
    std::string time_str_;</pre><pre class="source-code">
    Logger logger_;</pre><pre class="source-code">
    Common::McastSocket incremental_socket_;</pre><pre class="source-code">
    SnapshotSynthesizer *snapshot_synthesizer_ = nullptr;</pre><pre class="source-code">
  };</pre><pre class="source-code">
}</pre></li>
</ul>
<p>In the next section, we will see how these data members are initialized.</p>
<h2 id="_idParaDest-187"><a id="_idTextAnchor200"/>Initializing the market data publisher</h2>
<p>In this subsection, we will <a id="_idIndexMarker1083"/>look at how to initialize <code>MarketDataPublisher</code>, and how to start and stop the <code>MarketDataPublisher</code> component. First, we will look at the constructor, which is presented as follows. The <code>market_updates</code> argument passed to it is the <code>MEMarketUpdateLFQueue</code> object, which the matching engine will publish market updates on. The constructor also receives the network interface and two sets of IPs and ports – one for the incremental market data stream and one for the snapshot market data stream. In the constructor, it initializes the <code>outgoing_md_updates_</code> member with the argument passed in the constructor and the <code>snapshot_md_updates_</code> <code>LFQueue</code> to be of the size <code>ME_MAX_MARKET_UPDATES</code>, which we first defined back in the <em class="italic">Designing the C++ matching engine</em> chapter, in the <em class="italic">Defining the operations and interactions in our matching engine</em> <em class="italic">section</em>, and is available in the <code>common/types.h</code> source file. It also initializes the <code>logger_</code> object with a log file for this class and initializes the <code>incremental_socket_</code> variable with the incremental IP and port provided in the constructor. Finally, it creates a <code>SnapshotSynthesizer</code> object and passes the <code>snapshot_md_updates_</code> <code>LFQueue</code> and the snapshot multicast stream information:</p>
<pre class="source-code">
#include "market_data_publisher.h"
namespace Exchange {  MarketDataPublisher::MarketDataPublisher(MEMarketUpdateLFQueue
   *market_updates, const std::string &amp;iface,
                                           const std::string 
                                           &amp;snapshot_ip, int snapshot_
                                           port,
                                           const std::string
                                           &amp;incremental_ip, int 
                                           incremental_port)
      : outgoing_md_updates_(market_updates), snapshot_md_updates_(ME_
      MAX_MARKET_UPDATES),
        run_(false), logger_("exchange_market_data_publisher.log"),
        incremental_socket_(logger_) {
    ASSERT(incremental_socket_.init(incremental_ip, iface,
    incremental_port, /*is_listening*/ false) &gt;= 0,
           "Unable to create incremental mcast socket. error:" +
           std::string(std::strerror(errno)));
    snapshot_synthesizer_ = new SnapshotSynthesizer(&amp;snapshot_md_
    updates_, iface, snapshot_ip, snapshot_port);
  }</pre>
<p>We also present a <code>start()</code> method, shown <a id="_idIndexMarker1084"/>as follows, which is similar in functionality to the <code>start()</code> method we saw for the <code>OrderServer</code> class. First, it sets the <code>run_</code> flag to <code>true</code>, then creates and launches a new thread and assigns the <code>run()</code> method to that thread, which will be our main <code>run</code> loop for the <code>MarketDataPublisher</code> component. It also calls the <code>start()</code> method on the <code>SnapshotSynthesizer</code> object so that the <code>SnapshotSynthesizer</code> thread can also be launched:</p>
<pre class="source-code">
    auto start() {
      run_ = true;
      ASSERT(Common::createAndStartThread(-1, "Exchange/
      MarketDataPublisher", [this]() { run(); }) != nullptr, "Failed
      to start MarketData thread.");
      snapshot_synthesizer_-&gt;start();
    }</pre>
<p>The destructor is quite self-explanatory; it calls the <code>stop()</code> method to stop the running <code>MarketDataPublisher</code> thread, then waits a short amount of time to let the thread finish any pending tasks and deletes the <code>SnapshotSynthesizer</code> object. We will see the implementation of the <code>stop()</code> method right after the destructor, but it should not be too difficult to <a id="_idIndexMarker1085"/>guess what that method looks like:</p>
<pre class="source-code">
    ~MarketDataPublisher() {
      stop();
      using namespace std::literals::chrono_literals;
      std::this_thread::sleep_for(5s);
      delete snapshot_synthesizer_;
      snapshot_synthesizer_ = nullptr;
    }</pre>
<p>Finally, as mentioned before, we present the <code>stop()</code> method. This method simply sets the <code>run_</code> flag to <code>false</code> and instructs the <code>SnapshotSynthesizer</code> thread to stop as well:</p>
<pre class="source-code">
    auto stop() -&gt; void {
      run_ = false;
      snapshot_synthesizer_-&gt;stop();
    }</pre>
<p>Now that we have seen how to initialize this class, we will look at how <code>MarketDataPublisher</code> will publish order book updates, first the updates on the incremental updatesmarket data channel first and then the market updates on the snapshot updates secondmarket data channel.</p>
<h2 id="_idParaDest-188"><a id="_idTextAnchor201"/>Publishing order book updates</h2>
<p>The main <code>run()</code> loop in <code>MarketDataPublisher</code> does a couple of important things, which we will discuss <a id="_idIndexMarker1086"/>here. First, it drains the <code>outgoing_md_updates_</code> queue by reading any new <code>MEMarketDataUpdates</code> published by the matching engine. This part of the code block is shown as follows:</p>
<pre class="source-code">
  auto MarketDataPublisher::run() noexcept -&gt; void {
    logger_.log("%:% %() %\n", __FILE__, __LINE__, __FUNCTION__,
    Common::getCurrentTimeStr(&amp;time_str_));
    while (run_) {
      for (auto market_update = outgoing_md_updates_-&gt;getNextToRead();
           outgoing_md_updates_-&gt;size() &amp;&amp; market_update; market_
           update = outgoing_md_updates_-&gt;getNextToRead()) {
        logger_.log("%:% %() % Sending seq:% %\n", __FILE__, __LINE__,
        __FUNCTION__, Common::getCurrentTimeStr(&amp;time_str_), next_inc_
        seq_num_,
                    market_update-&gt;toString().c_str());</pre>
<p>Once it has a <code>MEMarketUpdate</code> message from the matching engine, it will proceed to write it to the <code>incremental_socket_</code> UDP socket. But it needs to write out the message in the <code>MDPMarketUpdate</code> format, which is just a sequence number followed by a <code>MEMarketUpdate</code> message. As we saw with <code>OrderServer</code>, it will achieve this here by first writing <code>next_inc_seq_num_</code>, which is the next incremental sequence number to be sent out on the incremental stream, and then write <code>MEMarketUpdate</code>, which it received from the matching engine. This logic is shown in the following code block, along with the line to increment the read index in the <code>LFQueue</code> that it just read from:</p>
<pre class="source-code">
        incremental_socket_.send(&amp;next_inc_seq_num_, sizeof(next_inc_
        seq_num_));
        incremental_socket_.send(market_update,
        sizeof(MEMarketUpdate));
        outgoing_md_updates_-&gt;updateReadIndex();</pre>
<p>It needs to <a id="_idIndexMarker1087"/>do one additional step here, which is to write the same incremental update it wrote to the socket to the <code>snapshot_md_updates_</code> <code>LFQueue</code> to inform the <code>SnapshotSynthesizer</code> component about the new incremental update from the matching engine that was sent to the clients. That code block is shown as follows:</p>
<pre class="source-code">
        auto next_write = snapshot_md_updates_.getNextToWriteTo();
        next_write-&gt;seq_num_ = next_inc_seq_num_;
        next_write-&gt;me_market_update_ = *market_update;
        snapshot_md_updates_.updateWriteIndex();</pre>
<p>Finally, it increments the incremental stream sequence number tracker for the next message that will be sent out and calls <code>sendAndRecv()</code> on <code>incremental_socket_</code> so that the messages get put on the wire:</p>
<pre class="source-code">
        ++next_inc_seq_num_;
      }
      incremental_socket_.sendAndRecv();
    }
  }
}</pre>
<p>That concludes all the tasks we need to perform to consume updates from the matching engine and generate the incremental market update multicast stream. In the next subsection, we will take care of the final key step in the market data publisher, which is synthesizing <a id="_idIndexMarker1088"/>order book snapshots and publishing them periodically on the snapshot multicast stream.</p>
<h2 id="_idParaDest-189"><a id="_idTextAnchor202"/>Synthesizing and publishing snapshots</h2>
<p>This section <a id="_idIndexMarker1089"/>will be dedicated to the design and implementation of the <code>SnapshotSynthesizer</code> class, which consumes incremental <code>MDPMarketDataUpdates</code> from the <code>MarketDataPublisher</code> thread, synthesizes<a id="_idIndexMarker1090"/> a full snapshot of the order book, and periodically publishes the full book snapshot on the snapshot multicast stream. All the source code for <code>SnapshotSynthesizer</code> can be found in the <code>Chapter7/exchange/market_data/snapshot_synthesizer.h</code> and <code>Chapter7/exchange/market_data/snapshot_synthesizer.cpp</code> source files.</p>
<h3>Defining the data members in the snapshot synthesizer</h3>
<p>Let us first define the data <a id="_idIndexMarker1091"/>members in the <code>SnapshotSynthesizer</code> class. The <a id="_idIndexMarker1092"/>important ones are described as follows:</p>
<ul>
<li>First, <code>snapshot_md_updates_</code> of the <code>MDPMarketUpdateLFQueue</code> type, which is what <code>MarketDataPublisher</code> uses to publish incremental <code>MDPMarketUpdates</code> to this component, which we saw in the previous section.</li>
<li>It also has a <code>snapshot_socket_</code> variable, which is an <code>McastSocket</code> to be used to publish snapshot market data updates to the snapshot multicast stream.</li>
<li>One of the most important data members is the <code>ticker_orders_</code> variable, which is a <code>std::array</code> of size <code>ME_MAX_TICKERS</code> to represent the snapshot of the book for each trading instrument. Each element of this array is a <code>std::array</code> of <code>MEMarketUpdate</code> pointers and a maximum size of <code>ME_MAX_ORDER_IDS</code> to represent a hash map from <code>OrderId</code> to the order corresponding to that <code>OrderId</code>. As we have done before, we use the first <code>std::array</code> as a hash map from <code>TickerId</code> to the snapshot of the limit order book. The second <code>std::array</code> is also a hash map from <code>OrderId</code> to the order information. We will also have an <code>order_pool_</code> data member of the <code>MemPool</code> type of <code>MEMarketUpdate</code> objects. This memory pool is what we will use to allocate and deallocate <code>MEMarketUpdate</code> objects from as we update the order book snapshot in the <code>ticker_orders_</code> container.</li>
<li>We have two variables to track information about the last incremental market data update that <code>SnapshotSynthesizer</code> has processed. The first one is the <code>last_inc_seq_num_</code> variable to track the sequence number on the last incremental <code>MDPMarketUpdate</code> it has received. The second one is the <code>last_snapshot_time_</code> variable used to track when the last snapshot was published over UDP since this component will only periodically publish the full snapshot of all the books.</li>
<li>There is also a <a id="_idIndexMarker1093"/>Boolean <code>run_</code> variable, which <a id="_idIndexMarker1094"/>serves a similar purpose as the <code>run_</code> variables in the <code>OrderServer</code> and <code>MarketDataPublisher</code> components we built before. This will be used to start and stop the <code>SnapshotSynthesizer</code> thread and will be marked <code>volatile</code> since it will be accessed from multiple threads:<pre class="source-code">
#pragma once</pre><pre class="source-code">
#include "common/types.h"</pre><pre class="source-code">
#include "common/thread_utils.h"</pre><pre class="source-code">
#include "common/lf_queue.h"</pre><pre class="source-code">
#include "common/macros.h"</pre><pre class="source-code">
#include "common/mcast_socket.h"</pre><pre class="source-code">
#include "common/mem_pool.h"</pre><pre class="source-code">
#include "common/logging.h"</pre><pre class="source-code">
#include "market_data/market_update.h"</pre><pre class="source-code">
#include "matcher/me_order.h"</pre><pre class="source-code">
using namespace Common;</pre><pre class="source-code">
namespace Exchange {</pre><pre class="source-code">
  class SnapshotSynthesizer {</pre><pre class="source-code">
  private:</pre><pre class="source-code">
    MDPMarketUpdateLFQueue *snapshot_md_updates_ = nullptr;</pre><pre class="source-code">
    Logger logger_;</pre><pre class="source-code">
    volatile bool run_ = false;</pre><pre class="source-code">
    std::string time_str_;</pre><pre class="source-code">
    McastSocket snapshot_socket_;</pre><pre class="source-code">
    std::array&lt;std::array&lt;MEMarketUpdate *, ME_MAX_ORDER_IDS&gt;,</pre><pre class="source-code">
    ME_MAX_TICKERS&gt; ticker_orders_;</pre><pre class="source-code">
    size_t last_inc_seq_num_ = 0;</pre><pre class="source-code">
    Nanos last_snapshot_time_ = 0;</pre><pre class="source-code">
    MemPool&lt;MEMarketUpdate&gt; order_pool_;</pre><pre class="source-code">
  };</pre><pre class="source-code">
}</pre></li>
</ul>
<p>In the next subsection, we will see how these variables are initialized as we look at the initialization of the <code>SnapshotSynthesizer</code> class.</p>
<h3>Initializing the snapshot synthesizer</h3>
<p>The <code>SnapshotSynthesizer</code> constructor<a id="_idIndexMarker1095"/> takes an argument of the <code>MDPMarketUpdateLFQueue</code> type passed to it from the <code>MarketDataPublisher</code> component. It also receives the network interface name and the snapshot IP and port to represent the multicast stream. The constructor initializes the <code>snapshot_md_updates_</code> data member from the argument passed to it and initializes <code>logger_</code> with a new filename. It initializes <code>MEMarketUpdate</code> <code>MemPool</code> to be of the size <code>ME_MAX_ORDER_IDS</code>. It also initializes <code>snapshot_socket_</code> and configures it to publish messages on the snapshot multicast IP and port on the provided network interface:</p>
<pre class="source-code">
#include "snapshot_synthesizer.h"
namespace Exchange {
  SnapshotSynthesizer::SnapshotSynthesizer(MDPMarketUpdateLFQueue
  *market_updates, const std::string &amp;iface,
                                           const std::string &amp;snapshot_
                                           ip, int snapshot_port)
      : snapshot_md_updates_(market_updates), logger_("exchange_
      snapshot_synthesizer.log"), snapshot_socket_(logger_), order_
      pool_(ME_MAX_ORDER_IDS) {
    ASSERT(snapshot_socket_.init(snapshot_ip, iface, snapshot_port,
    /*is_listening*/ false) &gt;= 0,
           "Unable to create snapshot mcast socket. error:" +
           std::string(std::strerror(errno)));
  }</pre>
<p>We also <a id="_idIndexMarker1096"/>add a <code>start()</code> method here in the same way as we did with our other classes before. This <code>start()</code> method sets the <code>run_</code> flag to true, creates and launches a thread, and assigns the <code>run()</code> method to the thread:</p>
<pre class="source-code">
  void SnapshotSynthesizer::start() {
    run_ = true;
    ASSERT(Common::createAndStartThread(-1, "Exchange/
    SnapshotSynthesizer", [this]() { run(); }) != nullptr,
           "Failed to start SnapshotSynthesizer thread.");
  }</pre>
<p>The destructor for this class is extremely simple; it just calls the <code>stop()</code> method. The <code>stop()</code> method is also extremely simple and just sets the <code>run_</code> flag to false so that the <code>run()</code> method exits:</p>
<pre class="source-code">
  SnapshotSynthesizer::~SnapshotSynthesizer() {
    stop();
  }
  void SnapshotSynthesizer::stop() {
    run_ = false;
  }</pre>
<p>Next, we will look at the important pieces of <code>SnapshotSynthesizer</code>, which will synthesize the order book snapshots and publish the snapshots periodically.</p>
<h3>Synthesizing the snapshot of the order book</h3>
<p>The process of <a id="_idIndexMarker1097"/>synthesizing the snapshot of the order books for the different trading instruments is like building <code>OrderBook</code>. However, the difference here is that the snapshot synthesis process only needs to maintain the last state of the live orders, so it is a simpler container. The <code>addToSnapshot()</code> method we will build next receives an <code>MDPMarketUpdate</code> message every time there is a new incremental market data update provided to <code>SnapshotSynthesizer</code>. We will break this method up into several code blocks so that it is easier to follow.</p>
<p>In the first code block, we extract the <code>MEMarketUpdate</code> piece of the <code>MDPMarketUpdate</code> message and store it in the <code>me_market_update</code> variable. It also finds the <code>std::array</code> of <code>MEMarketUpdate</code> messages for the correct <code>TickerId</code> for this instrument from the <code>ticker_orders_ std::array</code> hash map. We then have a switch case on the type of <code>MarketUpdateType</code> and then handle each of those cases individually. Before we look at each of the cases under the switch case, let us present<a id="_idIndexMarker1098"/> the initial code block in the <code>addToSnapshot()</code> method we described:</p>
<pre class="source-code">
  auto SnapshotSynthesizer::addToSnapshot(const MDPMarketUpdate
  *market_update) {
    const auto &amp;me_market_update = market_update-&gt;me_market_update_;
    auto *orders = &amp;ticker_orders_.at(me_market_update.ticker_id_);
    switch (me_market_update.type_) {</pre>
<p>Now, we will show the implementation of the <code>MarketUpdateType::ADD</code> case in the switch case. To handle a <code>MarketUpdateType::ADD</code> message, we simply insert it into the <code>MEMarketUpdate</code> <code>std::array</code> at the correct <code>OrderId</code> location. We create a <code>MEMarketUpdate</code> message by allocating it from the <code>order_pool_</code> memory pool using the <code>allocate()</code> call and passing it the <code>MEMarketUpdate</code> object to copy the fields from:</p>
<pre class="source-code">
      case MarketUpdateType::ADD: {
        auto order = orders-&gt;at(me_market_update.order_id_);
        ASSERT(order == nullptr, "Received:" + me_market_update.
        toString() + " but order already exists:" + (order ? order-
        &gt;toString() : ""));
        orders-&gt;at(me_market_update.order_id_) = order_pool_.
        allocate(me_market_update);
      }
        break;</pre>
<p><code>MarketUpdateType::MODIFY</code> is handled<a id="_idIndexMarker1099"/> similarly to <code>MarketUpdateType::ADD</code>. The minor difference here is that we just update the <code>qty_</code> and <code>price_</code> fields and leave the <code>type_</code> field on the entry as is:</p>
<pre class="source-code">
      case MarketUpdateType::MODIFY: {
        auto order = orders-&gt;at(me_market_update.order_id_);
        ASSERT(order != nullptr, "Received:" + me_market_update.
        toString() + " but order does not exist.");
        ASSERT(order-&gt;order_id_ == me_market_update.order_id_,
        "Expecting existing order to match new one.");
        ASSERT(order-&gt;side_ == me_market_update.side_, "Expecting
        existing order to match new one.");
        order-&gt;qty_ = me_market_update.qty_;
        order-&gt;price_ = me_market_update.price_;
      }
        break;</pre>
<p>The <code>MarketUpdateType::CANCEL</code> type does the opposite of what <code>MarketUpdateType::ADD</code> did. Here, we find <code>MEMarketUpdate</code> in the hash map and call <code>deallocate()</code> on it. We also set the entry in the hash map style <code>std::array</code> to <code>nullptr</code> to mark it as canceled or a dead order:</p>
<pre class="source-code">
      case MarketUpdateType::CANCEL: {
        auto order = orders-&gt;at(me_market_update.order_id_);
        ASSERT(order != nullptr, "Received:" + me_market_update.
        toString() + " but order does not exist.");
        ASSERT(order-&gt;order_id_ == me_market_update.order_id_,
        "Expecting existing order to match new one.");
        ASSERT(order-&gt;side_ == me_market_update.side_, "Expecting
        existing order to match new one.");
        order_pool_.deallocate(order);
        orders-&gt;at(me_market_update.order_id_) = nullptr;
      }
        break;</pre>
<p>We do not need to do<a id="_idIndexMarker1100"/> anything with the other enumeration values, so we ignore them. We just update the last sequence number we have seen on the incremental market data stream, which is stored in the <code>last_inc_seq_num_</code> data members:</p>
<pre class="source-code">
      case MarketUpdateType::SNAPSHOT_START:
      case MarketUpdateType::CLEAR:
      case MarketUpdateType::SNAPSHOT_END:
      case MarketUpdateType::TRADE:
      case MarketUpdateType::INVALID:
        break;
    }
    ASSERT(market_update-&gt;seq_num_ == last_inc_seq_num_ + 1, "Expected
    incremental seq_nums to increase.");
    last_inc_seq_num_ = market_update-&gt;seq_num_;
  }</pre>
<p>This concludes the <a id="_idIndexMarker1101"/>code to synthesize and update the order book snapshot from the incremental <code>MEMarketUpdate</code> messages. Next, we will look at how the full snapshot stream is generated and published.</p>
<h3>Publishing the snapshots</h3>
<p>The next method – <code>publishSnapshot()</code> – is called whenever we want to publish a complete snapshot of the<a id="_idIndexMarker1102"/> current state of the order book. Before we look at the code to publish the snapshot messages, let us first try to understand the format and content of a snapshot message containing the full state of the book for multiple instruments. The format of a full snapshot message looks like the following:</p>
<ol>
<li>The first <code>MDPMarketUpdate</code> message is of the <code>MarketUpdateType::SNAPSHOT_START</code> type with <code>seq_num_ = 0</code> to mark the beginning of the snapshot messages.</li>
<li>Then, for each instrument, we publish the following:<ol><li>A <code>MDPMarketUpdate</code> message of the <code>MarketUpdateType::CLEAR</code> type to instruct the client to clear their order book before applying the messages that follow</li><li>For each order that exists in the snapshot for this instrument, we publish a <code>MDPMarketUpdate</code> message with <code>MarketUpdateType::ADD</code> till we have published the information for all the orders</li></ol></li>
<li>Finally, we publish a <code>MDPMarketUpdate</code> message of the <code>MarketUpdateType::SNAPSHOT_END</code> type to mark the end of the snapshot messages. One thing to note is that for the <code>SNAPSHOT_START</code> and <code>SNAPSHOT_END</code> messages, we set the <code>OrderId</code> value to be the last incremental sequence number that was used to construct this snapshot. The market participants will use this sequence number to synchronize the snapshot market data stream with the incremental market data stream.</li>
</ol>
<p>This design is <a id="_idIndexMarker1103"/>represented in the following diagram, with a snapshot containing data for three instruments.</p>
<div><div><img alt="Figure 7.3 – Diagram describing the layout of our market data snapshot messages" src="img/B19434_07_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Diagram describing the layout of our market data snapshot messages</p>
<p>With that format in mind, let us look at the code to synthesize and publish the snapshot message format we described previously. First, we publish the <code>MarketUpdateType::SNAPSHOT_START</code> message, as follows:</p>
<pre class="source-code">
  auto SnapshotSynthesizer::publishSnapshot() {
    size_t snapshot_size = 0;
    const MDPMarketUpdate start_market_update{snapshot_size++,
    {MarketUpdateType::SNAPSHOT_START, last_inc_seq_num_}};
    logger_.log("%:% %() % %\n", __FILE__, __LINE__, __FUNCTION__,
    getCurrentTimeStr(&amp;time_str_), start_market_update.toString());
    snapshot_socket_.send(&amp;start_market_update,
    sizeof(MDPMarketUpdate));</pre>
<p>Then, we iterate through all the<a id="_idIndexMarker1104"/> instruments that we will publish the snapshots for. The first thing we do is publish the <code>MDPMarketUpdate</code> message of the <code>MarketUpdateType::CLEAR</code> type for that instrument:</p>
<pre class="source-code">
    for (size_t ticker_id = 0; ticker_id &lt; ticker_orders_.size();
    ++ticker_id) {
      const auto &amp;orders = ticker_orders_.at(ticker_id);
      MEMarketUpdate me_market_update;
      me_market_update.type_ = MarketUpdateType::CLEAR;
      me_market_update.ticker_id_ = ticker_id;
      const MDPMarketUpdate clear_market_update{snapshot_size++, me_
      market_update};
      logger_.log("%:% %() % %\n", __FILE__, __LINE__, __FUNCTION__,
      getCurrentTimeStr(&amp;time_str_), clear_market_update.toString());
      snapshot_socket_.send(&amp;clear_market_update,
      sizeof(MDPMarketUpdate));</pre>
<p>Then, we iterate through all the orders for this trading instrument and check for live orders – entries that do not have <code>nullptr</code> values. For each valid order, we publish the <code>MDPMarketUpdate</code> message for that <code>OrderId</code> with <code>MarketUpdateType::ADD</code>:</p>
<pre class="source-code">
      for (const auto order: orders) {
        if (order) {
          const MDPMarketUpdate market_update{snapshot_size++, *order};
          logger_.log("%:% %() % %\n", __FILE__, __LINE__, __
          FUNCTION__, getCurrentTimeStr(&amp;time_str_), market_update.
          toString());
          snapshot_socket_.send(&amp;market_update, sizeof(MDPMarketUpdate));
          snapshot_socket_.sendAndRecv();
        }
      }
    }</pre>
<p>Finally, we publish<a id="_idIndexMarker1105"/> the <code>MDPMarketUpdate</code> message with the <code>MarketUpdateType::SNAPSHOT_END</code> type to signify the end of the snapshot messages this round:</p>
<pre class="source-code">
    const MDPMarketUpdate end_market_update{snapshot_size++, {MarketUpdateType::SNAPSHOT_END, last_inc_seq_num_}};
    logger_.log("%:% %() % %\n", __FILE__, __LINE__, __FUNCTION__,
    getCurrentTimeStr(&amp;time_str_), end_market_update.toString());
    snapshot_socket_.send(&amp;end_market_update,
    sizeof(MDPMarketUpdate));
    snapshot_socket_.sendAndRecv();
    logger_.log("%:% %() % Published snapshot of % orders.\n",
    __FILE__, __LINE__, __FUNCTION__, getCurrentTimeStr(&amp;time_str_),
    snapshot_size - 1);
  }</pre>
<p>That concludes the design of the snapshot stream and the code to publish it in the <code>publishSnapshot()</code> method. In the next subsection, we will finish our discussion of the <code>SnapshotSynthesizer</code> component in the market data publisher infrastructure by implementing the main <code>run()</code> loop that ties everything together.</p>
<h3>Running the main loop</h3>
<p>Remember <a id="_idIndexMarker1106"/>that <code>SnapshotSynthesizer</code> runs on its own thread separate from the <code>MarketDataPublisher</code> thread to not cause latencies on the component that publishes the incremental market data stream. The <code>run()</code> method is the method assigned to the <code>SnapshotSynthesizer</code> thread. The only task it performs is checking the <code>snapshot_md_updates_</code> lock-free queue for new entries, which the <code>MarketDataPublisher</code> sends incremental <code>MDPMarketUpdate</code> messages on. For each incremental <code>MDPMarketUpdate</code> message it reads, it calls the <code>addToSnapshot()</code> method we built earlier. Additionally, it checks the <code>last_snapshot_time_</code> variable against the current time obtained from <code>getCurrentTime()</code> to see whether a minute has elapsed. If at least a minute has elapsed since the last time a snapshot was published, it calls the <code>publishSnapshot()</code> method to publish a new snapshot. It also remembers the current time as the last time a full snapshot was published:</p>
<pre class="source-code">
  void SnapshotSynthesizer::run() {
    logger_.log("%:% %() %\n", __FILE__, __LINE__, __FUNCTION__,
    getCurrentTimeStr(&amp;time_str_));
    while (run_) {
      for (auto market_update = snapshot_md_updates_-&gt;getNextToRead();
      snapshot_md_updates_-&gt;size() &amp;&amp; market_update; market_update =
      snapshot_md_updates_-&gt;getNextToRead()) {
        logger_.log("%:% %() % Processing %\n", __FILE__, __LINE__,
        __FUNCTION__, getCurrentTimeStr(&amp;time_str_),
                    market_update-&gt;toString().c_str());
        addToSnapshot(market_update);
        snapshot_md_updates_-&gt;updateReadIndex();
      }
      if (getCurrentNanos() - last_snapshot_time_ &gt; 60 * NANOS_TO_
      SECS) {
        last_snapshot_time_ = getCurrentNanos();
        publishSnapshot();
      }
    }
  }
}</pre>
<p>This concludes the<a id="_idIndexMarker1107"/> design and implementation of <code>SnapshotSynthesizer</code> as well as the <code>MarketDataPublisher</code> component and our complete electronic trading exchange infrastructure. In the next section, we will build the main electronic exchange application, which will tie together all the components we have built so far on the side of the electronic exchange.</p>
<h1 id="_idParaDest-190"><a id="_idTextAnchor203"/>Building the main exchange application</h1>
<p>In this final section of the chapter, as <a id="_idIndexMarker1108"/>well as the final section of the electronic trading exchange discussion, we will build the main exchange application. This will be a standalone binary application that will run an order gateway server, the matching engine, and the market data publisher and perform the following tasks:</p>
<ul>
<li>The order gateway server accepts client connections and client requests.</li>
<li>The matching engine builds the limit order book.</li>
<li>The matching engine also performs matching between client orders.</li>
<li>The matching engine and the order gateway server publish client responses.</li>
<li>The matching engine and the market data publisher publish incremental market data updates in response to client requests.</li>
<li>The market data publisher also synthesizes and periodically publishes a full snapshot of the order book.</li>
</ul>
<p>The complete <a id="_idIndexMarker1109"/>design is presented in the following diagram.</p>
<div><div><img alt="Figure 7.4 – The final trading exchange application and all its components" src="img/B19434_07_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – The final trading exchange application and all its components</p>
<p>The code for this exchange application is available in the <code>Chapter7/exchange/exchange_main.cpp</code> source file.</p>
<p>We will create a <code>Logger</code>, <code>MatchingEngine</code>, <code>MarketDataPublisher</code>, and <code>OrderServer</code> instance in the global scope. We will also create a signal handling function since this application will be killed when a UNIX signal is sent to it. The signal handler cleans up the components and exits:</p>
<pre class="source-code">
#include &lt;csignal&gt;
#include "matcher/matching_engine.h"
#include "market_data/market_data_publisher.h"
#include "order_server/order_server.h"
Common::Logger *logger = nullptr;
Exchange::MatchingEngine *matching_engine = nullptr;
Exchange::MarketDataPublisher *market_data_publisher = nullptr;
Exchange::OrderServer *order_server = nullptr;
void signal_handler(int) {
  using namespace std::literals::chrono_literals;
  std::this_thread::sleep_for(10s);
  delete logger;
  logger = nullptr;
  delete matching_engine;
  matching_engine = nullptr;
  delete market_data_publisher;
  market_data_publisher = nullptr;
  delete order_server;
  order_server = nullptr;
  std::this_thread::sleep_for(10s);
  exit(EXIT_SUCCESS);
}</pre>
<p>The <code>main()</code> function<a id="_idIndexMarker1110"/> initializes the logger object, installs the signal handler, and sets up three lock-free queues – <code>client_requests</code>, of the <code>ClientRequestLFQueue</code> type, <code>client_responses</code>, of the <code>ClientResponseLFQueue</code> type, and <code>market_updates</code>, of the <code>MEMarketUpdateLFQueue</code> type – to facilitate communication between the three major components:</p>
<pre class="source-code">
int main(int, char **) {
  logger = new Common::Logger("exchange_main.log");
  std::signal(SIGINT, signal_handler);
  const int sleep_time = 100 * 1000;
  Exchange::ClientRequestLFQueue client_requests(ME_MAX_CLIENT_
  UPDATES);
  Exchange::ClientResponseLFQueue client_responses(ME_MAX_CLIENT_
  UPDATES);
  Exchange::MEMarketUpdateLFQueue market_updates(ME_MAX_MARKET_
  UPDATES);</pre>
<p>Then, we create and<a id="_idIndexMarker1111"/> start the instance of the <code>MatchingEngine</code> component and pass the three <code>LFQueue</code> objects:</p>
<pre class="source-code">
  std::string time_str;
  logger-&gt;log("%:% %() % Starting Matching Engine...\n", __FILE__, __
  LINE__, __FUNCTION__, Common::getCurrentTimeStr(&amp;time_str));
  matching_engine = new Exchange::MatchingEngine(&amp;client_requests,
  &amp;client_responses, &amp;market_updates);
  matching_engine-&gt;start();</pre>
<p>We will also create and start the instance of <code>MarketDataPublisher</code> and provide it with the snapshot and incremental stream information and the <code>market_updates</code> <code>LFQueue</code> object.</p>
<p>One note about the interfaces and the IPs and ports specified in this chapter as well as the subsequent ones is that we chose these arbitrarily; feel free to change them if needed. The important thing here is that the market data stream IP:port information used by the electronic exchange and trading clients should match, and similarly, the order server IP:port <a id="_idIndexMarker1112"/>information used by the electronic exchange and trading clients match:</p>
<pre class="source-code">
  const std::string mkt_pub_iface = "lo";
  const std::string snap_pub_ip = "233.252.14.1", inc_pub_ip =
  "233.252.14.3";
  const int snap_pub_port = 20000, inc_pub_port = 20001;
  logger-&gt;log("%:% %() % Starting Market Data Publisher...\n", __
  FILE__, __LINE__, __FUNCTION__, Common::getCurrentTimeStr(&amp;time_
  str));
  market_data_publisher = new Exchange::MarketDataPublisher(&amp;market_
  updates, mkt_pub_iface, snap_pub_ip, snap_pub_port, inc_pub_ip, inc_
  pub_port);
  market_data_publisher-&gt;start();</pre>
<p>We perform similar tasks with the <code>order_server</code> object – create <code>OrderServer</code> and start it after providing it with the order gateway server configuration information:</p>
<pre class="source-code">
  const std::string order_gw_iface = "lo";
  const int order_gw_port = 12345;
  logger-&gt;log("%:% %() % Starting Order Server...\n", __FILE__, __
  LINE__, __FUNCTION__, Common::getCurrentTimeStr(&amp;time_str));
  order_server = new Exchange::OrderServer(&amp;client_requests, &amp;client_
  responses, order_gw_iface, order_gw_port);
  order_server-&gt;start();</pre>
<p>Finally, the <code>main()</code> thread just sleeps infinitely since the threads within the three components will run the exchange from this point on:</p>
<pre class="source-code">
  while (true) {
    logger-&gt;log("%:% %() % Sleeping for a few milliseconds..\n", __
    FILE__, __LINE__, __FUNCTION__, Common::getCurrentTimeStr(&amp;time_
    str));
    usleep(sleep_time * 1000);
  }
}</pre>
<p>Running the application<a id="_idIndexMarker1113"/> as follows will produce some minimal output to the screen, but most of the output goes to the log files we create from the three components and their subcomponents:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter7$ ./cmake-build-release/exchange_main
Set core affinity for Common/Logger exchange_main.log 140329423955712 to -1
Set core affinity for Common/Logger exchange_matching_engine.log 140329253541632 to -1
Set core affinity for Exchange/MatchingEngine 140329245148928 to –1
...
Sun Mar 26 13:58:04 2023 Flushing and closing Logger for exchange_order_server.log
Sun Mar 26 13:58:04 2023 Logger for exchange_order_server.log exiting.</pre>
<p>The <code>exchange_main</code> application was killed by sending it the <code>SIGINT</code> signal using the <code>kill –2 PID</code> command. We can inspect the log files to see what the different components did. Note, however, that the output right now is not super interesting. It simply logs that the components were created and started. This output will have a lot more information once we add clients for this trading exchange that connect and send client requests to it:</p>
<pre class="source-code">
(base) sghosh@sghosh-ThinkPad-X1-Carbon-3rd:~/Building-Low-Latency-Applications-with-CPP/Chapter7$ tail -n 10 *.log</pre>
<p>The <code>exchange_main.log</code> file<a id="_idIndexMarker1114"/> contains information about the creation of the different components, as shown:</p>
<pre class="source-code">
==&gt; exchange_main.log &lt;==
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/exchange_main.cpp:43 main() Sun Mar 26 09:13:49 2023 Starting Matching Engine...
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/exchange_main.cpp:51 main() Sun Mar 26 09:13:51 2023 Starting Market Data Publisher...
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/exchange_main.cpp:58 main() Sun Mar 26 09:13:56 2023 Starting Order Server...
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/exchange_main.cpp:63 main() Sun Mar 26 09:13:58 2023 Sleeping for a few milliseconds..</pre>
<p>The <code>exchange_market_data_publisher.log</code> file creates the UDP sockets and calls the <code>run()</code> method as shown:</p>
<pre class="source-code">
==&gt; exchange_market_data_publisher.log &lt;==
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/common/socket_utils.cpp:68 createSocket() Sun Mar 26 09:13:52 2023 ip:233.252.14.3 iface:lo port:20001 is_udp:1 is_blocking:0 is_listening:0 ttl:32 SO_time:0
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/market_data/market_data_publisher.cpp:15 run() Sun Mar 26 09:13:54 2023</pre>
<p>The <code>exchange_matching_engine.log</code> file does not have much meaningful output yet since no matching was performed and no order book was built:</p>
<pre class="source-code">
==&gt; exchange_matching_engine.log &lt;==
                          X
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/matcher/me_order_book.cpp:12 ~MEOrderBook() Sun Mar 26 09:15:00 2023 OrderBook
Ticker:7
                          X</pre>
<p>The <code>exchange_order_server.log</code> file also <a id="_idIndexMarker1115"/>contains some information about the creation of <code>TCPServer</code> and the <code>run()</code> method for the main thread:</p>
<pre class="source-code">
==&gt; exchange_order_server.log &lt;==
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/common/socket_utils.cpp:68 createSocket() Sun Mar 26 09:13:57 2023 ip:127.0.0.1 iface:lo port:12345 is_udp:0 is_blocking:0 is_listening:1 ttl:0 SO_time:1
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/order_server/order_server.h:25 run() Sun Mar 26 09:13:57 2023</pre>
<p>Finally, the <code>exchange_snapshot_synthesizer.log</code> file outputs the messages in an empty snapshot for the different trading instruments, since there are no orders in the order book yet:</p>
<pre class="source-code">
==&gt; exchange_snapshot_synthesizer.log &lt;==
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/market_data/snapshot_synthesizer.cpp:82 publishSnapshot() Sun Mar 26 09:14:55 2023 MDPMarketUpdate [ seq:2 MEMarketUpdate [ type:CLEAR ticker:1 oid:INVALID side:INVALID qty:INVALID price:INVALID priority:INVALID]]
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/market_data/snapshot_synthesizer.cpp:82 publishSnapshot() Sun Mar 26 09:14:55 2023 MDPMarketUpdate [ seq:3 MEMarketUpdate [ type:CLEAR ticker:2 oid:INVALID side:INVALID qty:INVALID price:INVALID priority:INVALID]]
...
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/market_data/snapshot_synthesizer.cpp:96 publishSnapshot() Sun Mar 26 09:14:55 2023 MDPMarketUpdate [ seq:9 MEMarketUpdate [ type:SNAPSHOT_END ticker:INVALID oid:0 side:INVALID qty:INVALID price:INVALID priority:INVALID]]
/home/sghosh/Building-Low-Latency-Applications-with-CPP/Chapter7/exchange/market_data/snapshot_synthesizer.cpp:100 publishSnapshot() Sun Mar 26 09:14:55 2023 Published snapshot of 9 orders.</pre>
<p>This concludes our discussion, design, and implementation of the electronic trading exchange. In the next chapter, we will build the trading system on the client’s end.</p>
<h1 id="_idParaDest-191"><a id="_idTextAnchor204"/>Summary</h1>
<p>This chapter was dedicated to building the order gateway server and the market data publisher components. We also combined the matching engine component we built in the previous chapter with the order gateway server and market data publisher components we built in this chapter to build the final trading exchange main application.</p>
<p>First, we defined the public market data protocol that will be used by the exchange to publish data on the wire and used by the clients to write market data consumer applications. We performed a similar task with the order gateway protocol so that client applications can understand the format of the client requests that they send to the exchange’s order gateway server and receive responses from.</p>
<p>We built the order gateway server, whose design we established in the <em class="italic">Designing Our Trading Ecosystem</em> chapter. We built the <code>OrderServer</code> class, which builds and runs <code>TCPServer</code>, to accept and manage TCP client connections. We added functionality to handle incoming client requests and send client responses. We also built the <code>FIFOSequencer</code> component, which is responsible for sequencing/ordering the incoming TCP client requests in the order in which they were received to maintain fairness in the market.</p>
<p>The next component we built was designed in the same chapter, <em class="italic">Designing Our Trading Ecosystem</em>, which is the market data publisher. We built <code>MarketDataPublisher</code>, which consumes market data updates from the matching engine and generates a multicast stream of incremental market data updates. We also added the <code>SnapshotSynthesizer</code> component, which runs on a different thread and is responsible for consuming market data updates from <code>MarketDataPublisher</code> and synthesizing the snapshot of the full order book. This full snapshot is periodically published by <code>SnapshotSynthesizer</code> on the snapshot multicast stream.</p>
<p>Finally, we built the main electronic trading exchange application, which ties together all the exchange side components we have built so far. This will serve as the central electronic trading exchange that supports multiple clients and different trading instruments for clients to connect and trade as well as receive market data updates for.</p>
<p>In the next chapter, we switch our focus from the exchange-side infrastructure to the market participants’ infrastructure. The next chapter will focus on the functionality to connect to the order gateway server and communicate with it, as well as receiving and processing the market data updates published by the electronic exchange.</p>
</div>


<div><h1 id="_idParaDest-192"><a id="_idTextAnchor205"/>Part 3:Building Real-Time C++ Algorithmic Trading Systems</h1>
<p>In this part, we will start building the trading client-side C++ algorithmic trading system. We will be building components that interface with the trading exchange to process market data and connect to and communicate with the exchange order gateway. We will also build the C++ framework on which we will build market-making and liquidity-taking trading algorithms. In the HFT space, this is where participants spend a lot of time and effort trying to reduce latencies and maximize performance (and profits). Finally, we will implement the market-making and liquidity-taking trading algorithms in this framework, run the entire trading ecosystem, and understand the interactions between all the components.</p>
<p>This part contains the following chapters:</p>
<ul>
<li><a href="B19434_08.xhtml#_idTextAnchor206"><em class="italic">Chapter 8</em></a><em class="italic">, Processing Market Data and Sending Orders to the Exchange in C++</em></li>
<li><a href="B19434_09.xhtml#_idTextAnchor227"><em class="italic">Chapter 9</em></a><em class="italic">, Building the C++ Trading Algorithm Building Blocks</em></li>
<li><a href="B19434_10.xhtml#_idTextAnchor262"><em class="italic">Chapter 10</em></a><em class="italic">, Building the C++ Market-Making and Liquidity-Taking Algorithms</em></li>
</ul>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
</body></html>