- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing and Optimizing the Performance of Our C++ System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will analyze the performance of our electronic trading ecosystem
    based on the measurements we added in the previous chapter, *Adding instrumentation
    and measuring performance*. Using the insights we develop about the performance
    of our trading systems based on this analysis, we will learn what areas to focus
    on in terms of potential performance bottlenecks and what areas we can improve.
    We will discuss tips and techniques for optimizing our C++ trading ecosystem.
    Finally, we will think about the future of our electronic trading ecosystem and
    what enhancements can be made in the future.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the performance of our trading ecosystem
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussing tips and techniques for optimizing our C++ trading system
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking about the future of our trading ecosystem
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the book’s code can be found in the GitHub repository for this book at [https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP](https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP).
    The source code for this chapter is in the `Chapter12` directory in the repository.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Since this is the concluding chapter of this book and we will discuss tips for
    improving the performance of the full electronic trading ecosystem as well as
    future enhancements, we expect you to have gone through all the preceding chapters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'The specifications of the environment in which the source code for this book
    was developed are listed as follows. We have presented the details of this environment
    since all the C++ code presented in this book is not necessarily portable and
    might require some minor changes to work in your environment:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'OS: `Linux 5.19.0-41-generic #42~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr
    18 17:40:00 UTC 2 x86_64 x86_64` `x86_64 GNU/Linux`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GCC: `g++ (Ubuntu` `11.3.0-1ubuntu1~22.04.1) 11.3.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CMake: `cmake` `version 3.23.2`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ninja: `1.10.2`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, for those who are interested in running the *optional* Python
    Jupyter notebook included with this chapter, the following environment was used.
    We will not discuss the installation process for Python, Jupyter, and these libraries
    and assume that you will figure it out on your own:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Analyzing the performance of our trading ecosystem
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we analyze the performance of our electronic trading ecosystem, let us
    quickly recap the measurements we added in the previous chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the latencies we measure
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We added two forms of measurement. The first one measures the performance of
    internal components and the second one generates timestamps at key points in our
    entire system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'The first form, which measures the latencies of internal components, generates
    differences in `RDTSC` values before and after calls to different functions, and
    generates log entries such as the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The second form, which measures the latencies at key points in the trading
    ecosystem, generates absolute timestamp values and generates log entries such
    as the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种形式，它测量交易生态系统中关键点的延迟，生成绝对时间戳值，并生成如下日志条目：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, let us move forward and analyze these latency measurements.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续分析这些延迟测量值。
- en: Analyzing the performance
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析性能
- en: 'To analyze these performance metrics, we have built a Python Jupyter notebook,
    which is available at `Chapter12/notebooks/perf_analysis.ipynb`. Note that since
    this is a book about C++ and low-latency applications, we will not discuss the
    source code in this notebook, but instead describe the analysis. Running the notebook
    is optional, so we also included an HTML file with the results of this analysis,
    which is available at `Chapter12/notebooks/perf_analysis.html`. To run this notebook,
    you will first have to launch the `jupyter notebook` server from the `Chapter12`
    root directory (where the log files exist) using the following command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析这些性能指标，我们构建了一个Python Jupyter笔记本，它位于`Chapter12/notebooks/perf_analysis.ipynb`。请注意，由于这是一本关于C++和低延迟应用的书籍，我们不会讨论这个笔记本中的源代码，而是描述分析过程。运行笔记本是可选的，所以我们还包含了一个包含此分析结果的HTML文件，它位于`Chapter12/notebooks/perf_analysis.html`。要运行这个笔记本，你首先必须从`Chapter12`根目录（其中存在日志文件）使用以下命令启动`jupyter
    notebook`服务器：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If your browser does not already launch the web page for this notebook, you
    can copy and paste the URL you receive and navigate to and open the `notebooks/perf_analysis.ipynb`
    notebook. Note that the preceding addresses are just examples for this specific
    run; you will receive a different address, which you should use. Once you open
    the notebook, you can run it using **Cell** | **Run All**, or the closest equivalent
    in your notebook instance, as shown in the following screenshot.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的浏览器还没有打开这个笔记本的网页，你可以复制并粘贴你收到的URL，导航到并打开`notebooks/perf_analysis.ipynb`笔记本。请注意，前面的地址只是这个特定运行的示例；你将收到一个不同的地址，你应该使用。一旦打开笔记本，你可以使用**Cell**
    | **Run All**，或者在你的笔记本实例中显示的最近似等效方式来运行它，如下面的截图所示。
- en: '![Figure 12.1 – Screenshot of the perf_analysis.ipynb notebook](img/B19434_12_001.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – perf_analysis.ipynb笔记本的截图](img/B19434_12_001.jpg)'
- en: Figure 12.1 – Screenshot of the perf_analysis.ipynb notebook
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – perf_analysis.ipynb笔记本的截图
- en: 'Since we will not discuss the details of this notebook, we will briefly describe
    the analysis performed in it. This notebook performs the following steps in the
    order presented here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不会讨论这个笔记本的细节，我们将简要描述其中执行的分析。这个笔记本按照以下顺序执行以下步骤：
- en: First, it looks for the log files generated by running the electronic trading
    ecosystem in the current working directory. Specifically, it looks for log files
    from the trading exchange; in the case of this notebook, we look for log files
    from the trading client with `ClientId=1`.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，它在当前工作目录中查找运行电子交易生态系统的日志文件。具体来说，它查找来自交易交易所的日志文件；在这个笔记本的情况下，我们查找`ClientId=1`的交易客户端的日志文件。
- en: It opens each log file and looks for log entries that contain the `RDTSC` and
    `TTT` tokens in them to find the log entries corresponding to the measurements
    we discussed in the previous chapter and revisited in the preceding sub-section.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它打开每个日志文件，并查找包含`RDTSC`和`TTT`标记的日志条目，以找到与我们在上一章中讨论并在前一小节中回顾的测量值相对应的日志条目。
- en: It then creates two `pandas` `DataFrame` instances containing each of the measurements
    it extracts from the log files.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它创建了两个`pandas` `DataFrame`实例，包含从日志文件中提取的每个测量值。
- en: For the measurement entries corresponding to the measurement of internal functions,
    which are tagged with the `RDTSC` token, we generate a scatter plot of those measurements
    as well as a rolling mean of those plots (to smooth the overall latency measurements).
    One crucial point here is that the measurement values in the log files represent
    the difference in `RDTSC` values, that is, the number of CPU cycles elapsed for
    a function call. In this notebook, we convert the CPU cycles into nanoseconds
    using a constant factor of 2.6 GHz, which is specific to our system and will differ
    based on your hardware; it will need to be adjusted. We will look at a few examples
    of these plots in the next sub-section.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the measurement entries corresponding to the timestamps at key spots in
    our electronic trading ecosystem, which are tagged with the `TTT` token, we also
    generate a scatter plot and a plot of the rolling mean values. The difference
    here is that we display the transit times from one hop to the other. For instance,
    we will plot the time it takes from the hop at `T1_OrderServer_TCP_read` to the
    hop at `T2_OrderServer_LFQueue_write`, from `T2_OrderServer_LFQueue_write` to
    `T3_MatchingEngine_LFQueue_read`, from `T3_MatchingEngine_LFQueue_read` to `T4_MatchingEngine_LFQueue_write`,
    and so forth.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of these inter-hop transits on the side of the exchange is shown in the
    following diagram.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Flow of data between different hops at the electronic exchange](img/B19434_12_002.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Flow of data between different hops at the electronic exchange
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Each of these inter-hop transits on the side of the trading client is shown
    in the following diagram.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Flow of data between different hops on the electronic trading
    client](img/B19434_12_003.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Flow of data between different hops on the electronic trading
    client
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: In the next sub-section, we will observe the distribution of a few of these
    different latency metrics from both groups (`RDTSC` and `TTT`) and see what we
    can learn from them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the output of our analysis
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will present the distribution of the latencies for a subset
    of the measurements we added in the previous chapter and analyzed using the notebook
    presented in the previous sub-section. Our objective here is to gain some insight
    into the performance of different components and sub-components in our ecosystem.
    First, we will start with a few examples of latencies for internal function calls
    in the next sub-section. One thing to note is that for the sake of brevity, we
    will present and discuss a subset of all the performance plots available in the
    Python notebook in this chapter. Also, note that these are not arranged in any
    particular order; we simply picked some of the more interesting ones and left
    all possible plots in the notebook for you to inspect further.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Observing the latencies for internal function calls
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first performance plot we present in this chapter is the distribution of
    the latency of calling the `Exchange::MEOrderBook::removeOrder()` method in the
    matching engine inside the trading exchange. That is presented as follows, but
    our key takeaway here is that this is a very well-behaved function; that is, the
    minimum and maximum latencies are within a tight range between 0.4 and 3.5 microseconds
    and the mean is relatively stable around the 1-to-1.5-microsecond range. There
    might be the possibility to make this faster, of course, but this seems quite
    well behaved for now and has low-performance latencies; we should evaluate whether
    this method is a bottleneck before trying to optimize it any further.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Latency distribution for the removeOrder() method in MEOrderBook
    for the matching engine](img/B19434_12_004.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Latency distribution for the removeOrder() method in MEOrderBook
    for the matching engine
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The next plot presents the distribution of latencies for the `Exchange::FIFOSequencer::``     sequenceAndPublish()` method. This instance is more interesting because here we
    see that while this method has low average latencies in the 90 microseconds range,
    it experiences many spikes in latencies spiking up to values in the 500 to 1,200
    microseconds range. This behavior will result in jitter in the `OrderServer` component’s
    performance when it comes to processing client order requests and is something
    we might need to investigate.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Latency distribution of the sequenceAndPublish() method in
    FIFOSequencer for the matching engine](img/B19434_12_005.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Latency distribution of the sequenceAndPublish() method in FIFOSequencer
    for the matching engine
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The next plot shows another interesting distribution of latency values for the
    `Trading::PositionKeeper::addFill()` method. In this case, the average performance
    latency remains stable around the 50 microseconds range. However, between **15:28:00**
    and **15:29:00**, there are a few spikes in latency that warrant a closer look.
    The difference here compared to *Figure 12**.4* is that there the spikes were
    distributed evenly, but in this case, there appears to be a small patch of spikes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Latency distribution of the addFill() method in PositionKeeper
    for the trade engine](img/B19434_12_006.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Latency distribution of the addFill() method in PositionKeeper
    for the trade engine
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'We conclude this sub-section by presenting one more plot, this time of the
    `Trading::``     PositionKeeper::updateBBO()` method, which updates the PnL for open positions.
    This is another well-behaved method with an average performance latency of 10
    microseconds, and there seem to be many measurements close to 0 microseconds,
    which is slightly different from *Figure 12**.3*, where the minimum latency value
    was never remarkably close to 0.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Latency distribution of the updateBBO() method in PositionKeeper
    for the trade engine](img/B19434_12_007.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7 – 交易引擎PositionKeeper中updateBBO()方法的延迟分布](img/B19434_12_007.jpg)'
- en: Figure 12.7 – Latency distribution of the updateBBO() method in PositionKeeper
    for the trade engine
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 – 交易引擎PositionKeeper中updateBBO()方法的延迟分布
- en: In the next sub-section, we will look at a few similar examples, but this time
    pertaining to the latencies between the different hops in our ecosystem.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将查看一些类似的例子，但这次是关于我们生态系统中不同跳之间的延迟。
- en: Observing the latencies between hops in the ecosystem
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 观察生态系统中跳之间的延迟
- en: The first plot we will look at is the time difference between when a trading
    client’s `OrderGateway` component writes a client request to the TCP socket (`T12`)
    up to the point when the exchange’s `OrderServer` component reads that client
    request from the TCP socket (`T1`). This represents the network transit time from
    the trading client to the trading exchange on the TCP connection. The average
    latency in this case is around 15 to 20 microseconds and the distribution is evenly
    distributed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的第一个图表是交易客户端的`OrderGateway`组件将客户端请求写入TCP套接字（`T12`）到交易所的`OrderServer`组件从TCP套接字读取该客户端请求（`T1`）的时间差。这代表了TCP连接上从交易客户端到交易交易所的网络传输时间。在这种情况下，平均延迟大约在15到20微秒之间，分布是均匀的。
- en: '![Figure 12.8 – Latency distribution between the T12_OrderGateway_TCP_write
    and T1_OrderServer_TCP_read hops](img/B19434_12_008.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图12.8 – T12_OrderGateway_TCP_write和T1_OrderServer_TCP_read跳之间的延迟分布](img/B19434_12_008.jpg)'
- en: Figure 12.8 – Latency distribution between the T12_OrderGateway_TCP_write and
    T1_OrderServer_TCP_read hops
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 – T12_OrderGateway_TCP_write和T1_OrderServer_TCP_read跳之间的延迟分布
- en: The next plot displays the distribution of the network transit time for the
    market data updates, from when the market data updates are written to the UDP
    socket by `MarketDataPublisher` (`T6`) to when they are read from the UDP socket
    by `MarketDataConsumer` (`T7`). There seems to be a great amount of variance in
    the latencies for this measurement, as the plot shows; however, this has lower
    overall latencies than the TCP path.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了市场数据更新的网络传输时间分布，从市场数据更新由`MarketDataPublisher`（`T6`）写入UDP套接字到由`MarketDataConsumer`（`T7`）从UDP套接字读取它们的时间。如图所示，这个测量的延迟似乎有很大的变化；然而，这个路径的整体延迟比TCP路径要低。
- en: '![Figure 12.9 – Latency distribution between the T6_MarketDataPublisher_UDP_write
    and T7_MarketDataConsumer_UDP_read hops](img/B19434_12_009.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图12.9 – T6_MarketDataPublisher_UDP_write和T7_MarketDataConsumer_UDP_read跳之间的延迟分布](img/B19434_12_009.jpg)'
- en: Figure 12.9 – Latency distribution between the T6_MarketDataPublisher_UDP_write
    and T7_MarketDataConsumer_UDP_read hops
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – T6_MarketDataPublisher_UDP_write和T7_MarketDataConsumer_UDP_read跳之间的延迟分布
- en: The next diagram shows the distribution of latencies measured from `MarketDataConsumer`
    reading a market update from the UDP socket (`T7`) to the time when the market
    update is written to `LFQueue` connected to `TradeEngine` (`T8`). This path experiences
    huge spikes in latencies (up to 2,000 microseconds) compared to its average performance
    of around 100 microseconds, so this is something we need to investigate.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了从`MarketDataConsumer`从UDP套接字（`T7`）读取市场更新到市场更新写入连接到`TradeEngine`的`LFQueue`（`T8`）的时间的延迟分布。与平均性能大约为100微秒相比，这个路径的延迟出现了巨大的峰值（高达2,000微秒），因此这是我们需要调查的。
- en: '![Figure 12.10 – Latency distribution between the T7_MarketDataConsumer_UDP_read
    and T8_MarketDataConsumer_LFQueue_write hops](img/B19434_12_010.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图12.10 – T7_MarketDataConsumer_UDP_read和T8_MarketDataConsumer_LFQueue_write跳之间的延迟分布](img/B19434_12_010.jpg)'
- en: Figure 12.10 – Latency distribution between the T7_MarketDataConsumer_UDP_read
    and T8_MarketDataConsumer_LFQueue_write hops
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 – T7_MarketDataConsumer_UDP_read和T8_MarketDataConsumer_LFQueue_write跳之间的延迟分布
- en: The next plot displays the distribution of the latencies between `MatchingEngine`
    reading a client request from `LFQueue` attached to `OrderServer` (`T3`) and the
    time `MatchingEngine` processes it and writes the client response to `LFQueue`
    back to `OrderServer` (`T4t`). This path also appears to be experiencing large
    latency spikes and should be investigated.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了`MatchingEngine`从连接到`OrderServer`的`LFQueue`（`T3`）读取客户端请求到`MatchingEngine`处理它并将客户端响应写回`LFQueue`到`OrderServer`（`T4t`）之间的延迟分布。这个路径似乎也经历了大的延迟峰值，应该进行调查。
- en: '![Figure 12.11 – Latency distribution between the T3_MatchingEngine_LFQueue_read
    and T4t_MatchingEngine_LFQueue_write hops](img/B19434_12_011.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Latency distribution between the T3_MatchingEngine_LFQueue_read
    and T4t_MatchingEngine_LFQueue_write hops
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: This section was dedicated to the analysis of the different latency measurements
    in our ecosystem. In the next section, we will discuss some tips and techniques
    that we can use to optimize the design and implementation of the different components
    in our electronic trading ecosystem.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Discussing tips and techniques for optimizing our C++ trading system
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will present a few possible areas where we can optimize
    our C++ trading ecosystem. Note that these are only some examples and a lot more
    is possible, but we will leave you to measure and discover those inefficiencies,
    as well as improve on them. To reiterate what we have mentioned a few times before,
    you should measure the performance of various parts of your system with everything
    we learned in the previous chapter, *Adding instrumentation and measuring performance*.
    You should analyze them using the approach we discussed in this chapter and use
    the C++ discussions we had in the chapter *Exploring C++ Concepts from a Low-Latency
    Application’s Perspective* to improve on them further. Now, let us discuss some
    areas of improvement next. We have tried to arrange these loosely in order from
    least to most effort.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the release build
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first suggestion would be to try and optimize the release build we run for
    our system. Some simple things we can do in the code itself is remove the calls
    to `ASSERT()` from the release binaries. The motivation behind this is to remove
    the extra `if` condition this macro introduces in our code base wherever it gets
    used. However, this can be dangerous since we might allow exceptional conditions
    through. The optimal middle ground is to remove the use of this macro only from
    the critical code path wherever it is safe to do so.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Another suggestion would be to reduce logging in the release build. We have
    made a decent amount of effort to make logging efficient and low-latency. Additionally,
    it is not wise to eliminate all logging since it makes troubleshooting difficult,
    if not impossible. However, logging is not free, so we should try to reduce logging
    on the critical path for release builds as much as possible.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: The most common method to perform optimizations, as we suggested here, that
    only apply to release builds is to define the NDEBUG (No Debug) preprocessor flag
    and check for its existence in our code base. If the flag is defined, we build
    a release build and skip non-essential code such as asserts and logging.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of this for the `MemoryPool::deallocate()` method is shown here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Another example for the `FIFOSequencer::sequenceAndPublish()` method is shown
    here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Another thing to think about is whether the actual entries being logged can
    be output in a more optimal method. For instance, `Common:: getCurrentTimeStr()`,
    which gets called in each of our log lines in the current code base state itself,
    is quite expensive. This is because it performs string formatting operations using
    `sprintf()`, which is quite expensive, like most string formatting operations.
    Here, we have another optimization where in release builds, we can output a simple
    integer value representing time, instead of a formatted string, which, while more
    readable, is less efficient.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Let us move on to the next possible optimization area – managing thread affinity.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Setting thread affinity correctly
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, in all the instances of creating and launching threads, we have passed
    the `core_id` parameter to be `-1` in the call to the `Common::createAndStartThread()`
    method; that is, the threads were not pinned to any specific core. This was done
    intentionally since, as we mentioned before, the `exchange_main` application instance
    creates and runs 10 threads and each `trading_main` application instance creates
    and runs 8 threads. Unless you are executing the source code for this book on
    a production-grade trading server, it is unlikely to have too many CPU cores.
    Our system, for example, has only four cores. In practice, however, each of the
    following performance-critical threads would be assigned a CPU core all to themselves.
    We present a sample core assignment next; however, this will change from server
    to server and might also depend on the NUMA architecture – but that is beyond
    the scope of this book. Note that these names refer to the names we passed to
    the method in the `name` string parameter:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '`core_id`=0 : `Exchange/MarketDataPublisher`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=1 : `Exchange/MatchingEngine`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=2 : `Exchange/OrderServer`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=3 : `Trading/MarketDataConsumer`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=4 : `Trading/OrderGateway`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=5 : `Trading/TradeEngine`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any additional performance critical threads get assigned the remaining core
    ids in a similar fashion
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The remaining non-critical threads, as well as any Linux processes running
    on the server, would be given a block of CPU cores to be run on without any affinity
    settings. Specifically, in our system, they would be the following non-critical
    threads:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Exchange/SnapshotSynthesizer`'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger exchange_main.log`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger exchange_matching_engine.log`'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger exchange_market_data_publisher.log`'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger exchange_snapshot_synthesizer.log`'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger exchange_order_server.log`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger trading_main_1.log`'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger trading_engine_1.log`'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger trading_order_gateway_1.log`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`core_id`=-1 : `Common/Logger trading_market_data_con``sumer_1.log`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any other non-critical threads would also be assigned core id -1 i.e. these
    threads will not be pinned to any specific CPU code
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note one additional detail: for this setup to be as optimized as possible,
    we need to make sure that the Linux process scheduler does not assign any OS processes
    to the CPU cores being used by the critical threads. This is achieved on Linux
    using the `isolcpus` kernel parameter, which we will not discuss in detail here.
    The `isolcpus` parameter tells the process scheduler which cores to ignore when
    deciding where to schedule a process.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Logger for strings
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is an opportunity to optimize our `Logger` class to handle parameters
    of the `char*` type better. Remember that our implementation for logging `char*`
    parameters consists of calling the `Logger::pushValue(const char value)` method
    on each of the characters iteratively, as shown:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'One option here is to introduce a new enumeration value to the `LogType` enumeration.
    Let’s call it `STRING`, like so:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We’ll update the `LogElement` type to have a fixed-size `char*` array of *some*
    size, as shown. We are vague on the size of this array on purpose since this is
    pseudo-code and we want to focus more on the design and the idea and less on the
    implementation details:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then, finally, update `Logger::pushValue(const char *value)` and `Logger::flushQueue()`
    to copy and write the strings in blocks of characters rather than a single character
    at a time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Eliminating the use of std::function instances
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our code base, we used the `std::function<>` function wrapper in a couple
    of places, as listed here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '`Common::McastSocket`:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`Common::TCPServer`:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`Common::TCPSocket`:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Trading::TradeEngine`:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Calling functions through these objects is slower than directly calling functions,
    and these incur similar costs as `virtual` functions. This mechanism of calling
    methods using the `std::function<>` objects can be replaced with templates. To
    refresh your memory on the drawbacks of calling functions indirectly, please revisit
    the chapter *Exploring C++ Concepts from a Low-Latency Application’s Perspective*,
    specifically the *Avoiding function pointers* sub-section of the *Calling functions
    efficiently* section. Additionally, revisit the *Using compile-time polymorphism*
    section in the same chapter, reviewing the discussion on the `std::function<>`
    instances in our code base, but we encourage those who are interested to attempt
    that improvement.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting the impact of these optimizations
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will not be able to investigate every optimization opportunity in detail,
    but before we finish this section, we will discuss the details of two optimizations
    that we discussed in this section. First, let us discuss the implementation and
    impact of the optimization on our `Logger` class for logging strings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking Logger string optimization
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To implement the Logger string optimization, we will change the `pushValue()`
    method for `char*` arguments as discussed before. For the sake of brevity, we
    will not look at the full class, which we implement in an alternate `OptLogger`
    class available in the `Chapter12/common/opt_logging.h` source file. The most
    important change is shown here, but please refer to the full source file to see
    the other minor changes:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To benchmark this and compare it against the original `Logger` implementation,
    we will create a simple standalone binary called `logger_benchmark`. We do this
    so that we can check the performance impact in a controlled environment. Remember
    that running the full trading ecosystem introduces a lot of variance due to the
    number of processes and threads, the network activity, the trading activity, and
    so on, and it can be difficult to properly assess the impact of the `Logger` optimization.
    The source code for this benchmark application can be found in the `Chapter12/benchmarks/logger_benchmark.cpp`
    source file. Let us look at the implementation of this source file quickly before
    looking at the results.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will include the header files corresponding to the original `Logger`
    and the new `OptLogger` classes:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we will define a `random_string()` method, which simply generates random
    strings of a specified length. We will use this to generate random strings for
    the two loggers to log to compare the performance difference when it comes to
    strings. This uses a `charset()` lambda method, which returns a random alphanumeric
    (0-9, a-z, or A-z) character. It then uses the `std::generate_n()` method to generate
    a `std::string` with a length specified in the length argument by calling the
    `charset()` lambda method repeatedly:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we will define a `benchmarkLogging()` method, which accepts a template
    parameter, `T`, which it expects to be an instance of one of the two loggers we
    are comparing here. It runs a loop 100,000 times and uses the `random_string()`
    method we built previously and the logger’s `log()` method to log 100,000 random
    strings. For each call to the `log()` method, it records and sums up the difference
    in clock cycles, using the `Common::rdtsc()` method we built in the previous chapter.
    Finally, it returns the average clock cycles by dividing the sum of each RDTSC
    difference by the loop count:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we can finally build the `main()` method, which is quite simple. It creates
    an instance of the old logger – `Common::Logger()` – calls the `benchmarkLogging()`
    method on it, and outputs the average clock cycle count to the screen. Then, it
    does exactly the same thing again, except this time it uses the new logger – `OptCommon::OptLogger()`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This binary can be built using the same script as before, that is, by running
    `scripts/build.sh` from the `Chapter12` root directory. To run the binary, you
    can call it directly from the command line, as shown here, and, among other output,
    you will see the following two lines displaying the results of the benchmarking:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that there will be some variance in the output for each run, and the results
    you get will likely be different due to system-dependent reasons, but amount the
    optimization has sped things up, should be somewhat similar to what we have shown.
    In this case, it seems like our optimization efforts have sped up the `log()`
    method for strings to be roughly 50 times faster. Next, let us look at another
    example of the optimization tips we discussed before, which is optimizing the
    binary for release builds.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking release build optimization
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To benchmark an example of leaving out non-essential code from the release
    build, we picked the `MemPool` class. Note that this principle applies to all
    the components we built, but we arbitrarily picked a single one to limit the scope
    of our discussion. Similar to what we did for the `Logger` class, we create a
    new class called `OptMemPool`, which you will find in the `Chapter12/common/opt_mem_pool.h`
    source file. The primary change in this file compared to the `MemPool` class is
    that the calls to `ASSERT()` are only built for non-release builds. This is achieved
    by checking for the `NDEBUG` preprocessor flag, as shown in the following two
    examples. You can check out the full source code in the file we mentioned previously:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To benchmark this optimization, we will build a `release_benchmark` binary,
    and the code for that is available in the `Chapter12/benchmarks/release_benchmark.cpp`
    source file. First, let us look at the header files we need to include, most importantly
    the `mem_pool.h` and `opt_mem_pool.h` files. Since memory pools store structures,
    we will use `Exchange::MDPMarketUpdate` as an example, so we include the `market_update.h`
    header file for that as well:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Similar to what we did with the `logger_benchmark.cpp` file, we will create
    a `benchmarkMemPool()` method, which accepts a template parameter, `T`, and expects
    it to be one of the two memory pools we are comparing. In this method, we will
    first allocate and save 256 `MDPMarketUpdate` objects from the memory pool, using
    the `allocate()` method. Then, we will deallocate each of these objects and return
    them to the memory pool, using the `deallocate()` method. We will run this loop
    100,000 times to find a reliable average over many iterations. We will measure
    and sum up the clock cycles elapsed for each call to `allocate()` and `deallocate()`
    as we did before with the logger benchmark. Finally, we return the average clock
    cycles by dividing the sum of elapsed clock cycles by the loop count:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, we build the `main()` method, which again is quite simple. It calls
    the `benchmarkMemPool()` method twice, once with an object of the `Common::MemPool`
    type and next with an object of the `OptCommon::OptMemPool` type, and outputs
    the average clock cycles elapsed for the `allocate()` and `deallocate()` methods:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The process to build this benchmark binary remains the same, so we will not
    repeat it. Running the binary will yield something that resembles the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this case, our optimization efforts yielded a speed up of around 7 to 8 times
    for the `allocate()` and `deallocate()` methods.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we presented and explained a subset of optimization areas/ideas
    in our electronic trading ecosystem. The goal here is to get you to understand
    what these optimization areas can look like and how to approach them with the
    goal of optimizing performance. In the next section, we’ll discuss some more future
    improvements and enhancements that can be made to our electronic trading ecosystem.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about the future of our trading ecosystem
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we conclude this chapter and this book, we will discuss a few possible
    enhancements to our electronic trading ecosystem. In the previous section, we
    discussed some examples of things that can be optimized for those interested in
    maximizing the performance of the electronic trading system we built in this book.
    In this section, we will discuss some examples of how this ecosystem can be enhanced,
    not necessarily to reduce latency but to make the system more feature-rich and
    add functionality.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Growing containers dynamically
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We built and used a few containers in this book, as listed here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The lock-free queue – `LFQueue` – which is used in multiple components for various
    object types, such as `MEMarketUpdate`, `MDPMarketUpdate`, `MEClientRequest`,
    and `MEClientResponse`
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The memory pool – `MemPool` – which was used for multiple object types, such
    as instances of `MEMarketUpdate`, `MEOrder`, `MEOrdersAtPrice`, `MarketOrder`,
    and `MarketOrdersAtPrice`
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all these cases, we assumed a safe maximum size value. In practice, that
    still leaves us open to the possibility that under some circumstances, we might
    exceed these limits and get in trouble. One enhancement we can make to this system
    is to improve our handling of this unlikely edge case.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: One option would be to fail/exit if we encounter a scenario where `LFQueue`
    is full or `MemPool` is out of memory. Another option would be to fall back to
    dynamic memory allocation or a secondary inefficient container for this unlikely
    event; that is, we will be inefficient and slow in this extremely rare case that
    we run out of memory or space in our containers, but we will continue to function
    until it is resolved. Yet another option is to make these containers flexible
    where they can be grown if needed even though the task of growing these containers
    when needed will be extremely slow, since in practice we do not expect to encounter
    that condition.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Growing and enhancing the hash maps
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this book, we used `std::array` in many contexts as a hash map by assuming
    a safe upper bound. For instance, by assuming that valid `TickerId` values fall
    in the range of 0 and `ME_MAX_TICKERS`, we used `std::array` instances of size
    `ME_MAX_TICKERS` as hash maps with `TickerId` keys. A similar design was used
    for containers such as `TradeEngineCfgHashMap`, `OrderHashMap`, `ClientOrderHashMap`,
    `OrdersAtPriceHashMap`, `OrderBookHashMap`, `MarketOrderBookHashMap`, and `OMOrderTickerSideHashMap`.
    While in practice, some of these can continue to exist, that is, valid and reasonable
    upper bounds can be decided and used, for some of these, this design will not
    scale up elegantly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: There are several different hash map implementations available – `std::unordered_map`,
    `absl::flat_hash_map`, `boost::` hash maps, `emhash7::HashMap`, `folly::AtomicHashmap`,
    `robin_hood::unordered_map`, `tsl::hopscotch_map`, and many more. Additionally,
    it is common to optimize and tweak these containers so that they perform best
    under our specific use cases. We’ll leave those of you who are interested with
    the task of exploring these and deciding which ones can replace the `std::array`-based
    hash maps in our system.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of demonstrating an example, we will replace the `std::array`-based
    hash maps in the limit order book that the matching engine builds and maintains
    (`MEOrderBook`) with `std::unordered_map` hash maps. We will then benchmark the
    two implementations to see how much of a difference it makes. Following the same
    pattern as we used in the benchmarking we performed earlier in this chapter, we
    will introduce a new `MEOrderBook` class, `UnorderedMapMEOrderBook`, where the
    only difference is the use of the `std::unordered_map` containers instead of the
    `std::array` containers. All the source code for this new class is available in
    the `Chapter12/exchange/matcher/unordered_map_me_order_book.h` and `Chapter12/exchange/matcher/unordered_map_me_order_book.cpp`
    source files. For the sake of brevity, we will not repeat the entire class implementation
    here, but we will discuss the important changes. The first important and obvious
    change is the inclusion of the `unordered_map` header file in the `unordered_map_me_order_book.h`
    header file:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We change the `cid_oid_to_order_` data member to be `std::unordered_map<ClientId,
    std::unordered_map<OrderId, MEOrder *>>` instead of `ClientOrderHashMap`, which
    is a `typedef` for `std::array<OrderHashMap, ME_MAX_NUM_CLIENTS>`. This data member
    is a hash map from `ClientId` to `OrderId` to `MEOrder` objects. Remember that
    `ClientOrderHashMap` is actually a hash map of hash maps, that is, a `std::array`
    whose elements are also `std::array` objects. The other data member we change
    is the `price_orders_at_price_` member, which we change to `std::unordered_map<Price,
    MEOrdersAtPrice *>` instead of the `OrdersAtPriceHashMap` type. This data member
    is a hash map from `Price` to `MEOrdersAtPrice` objects. If you have forgotten
    what `MEOrder` and `MEOrdersAtPrice` are, please revisit the *Designing the exchange
    order book* sub-section in the *Defining the operations and interactions in our
    matching engine* section of the chapter *Building the C++ Matching Engine*. These
    changes are shown here:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We will need to remove the following lines from the destructor since the `fill()`
    method does not apply to `std::unordered_map` objects:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In terms of accessing these modified containers, we replace the calls to the
    `std::array::at()` method for `cid_oid_to_order_` and `price_orders_at_price_`
    with the `std::unordered_map::operator[]` method. These changes for `cid_oid_to_order_`
    are shown here:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We need to make similar changes in spots where we access the `price_orders_at_price_`
    container, which is shown here:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, we present the `hash_benchmark` binary to measure the performance
    differences because of these changes. The source code for this binary can be found
    in the `Chapter12/benchmarks/hash_benchmark.cpp` source file. First, we include
    the header files shown as follows and also define a global `loop_count` variable
    as we have done in our previous benchmarks:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As we have done before, we will define a `benchmarkHashMap()` method, which
    accepts a template parameter, `T`, to represent either `MEOrderBook` or `UnorderedMapMEOrderBook`.
    It also accepts a vector of `Exchange::MEClientRequest` messages, which will be
    processed in the benchmark. The actual processing is quite simple. It checks the
    type of `MEClientRequest` and then calls the `add()` method for `ClientRequestType::NEW`
    and the `cancel()` method for `ClientRequestType::CANCEL`. We use `Common::rdtsc()`
    to measure and sum up the clock cycles elapsed for each of these calls and then
    return the average at the end of this method:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now we can look at the `main()` method. We need `Logger` and a `MatchingEngine`
    object to create the `MEOrderBook` or `UnorderedMapMEOrderBook` object, but to
    create the `MatchingEngine` object, we need three lock-free queues as we have
    seen in the implementation of the `exchange_main` binary. So, we create these
    objects as shown here, even though we are not measuring the performance of any
    of these components:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we will create a vector of 100,000 (`loop_count`) `MEClientRequest` objects,
    which will be composed of new order requests as well as requests to cancel these
    orders. We have seen similar code in the `trading_main` application for the random
    trading algorithm:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we end the `main()` method by calling the `benchmarkHashMap()` method
    twice – once with an instance of `MEOrderBook` and once with an instance of `UnorderedMapMEOrderBook`,
    as shown:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The process to build this application remains the same, which is by calling
    the `scripts/build.sh` script from the `Chapter12` root directory. Running the
    application by calling the `hash_benchmark` binary will yield output like what
    is shown here, with some variance between independent runs and depending on the
    system:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Based on the output of this run, it appears that switching from a `std::array`
    hash map implementation to a `std::unordered_map` hash map implementation adds
    an approximate 6 to 7% extra overhead to the `MEOrderBook` `add()` and `cancel()`
    performance.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing snapshot messages
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our design of the snapshot messages in the `MarketDataPublisher` component
    at the trading exchange, a full cycle of snapshot messages between the `START_SNAPSHOT`
    and `END_SNAPSHOT` messages contains the snapshot for all trading instruments,
    as shown in the following diagram (which we have seen before). In our `SnapshotSynthesizer`,
    this full snapshot for all trading instruments is published once every 60 seconds.
    What this means is that if the order books for each of these trading instruments
    have a lot of orders, then every 60 seconds, there is a huge spike in network
    traffic on the snapshot multicast channels followed by silence in the remaining
    60 seconds.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Current composition of snapshot messages](img/B19434_12_012.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Current composition of snapshot messages
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: It would be an enhancement to this design if we changed this such that these
    snapshots are spaced out more evenly and each snapshot cycle contained the snapshot
    messages corresponding to only one `TickerId`. As a simple example, instead of
    sending a snapshot message cycle for 6 instruments every 60 seconds, we can send
    6 snapshots each containing information for a single instrument, and each of these
    snapshots is spaced out with 10 seconds in between them. This hypothetical proposal
    is represented in the following diagram.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.13 – A proposal for an optimized snapshot messaging format](img/B19434_12_013.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – A proposal for an optimized snapshot messaging format
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: In this new proposal, as we mentioned, there are fewer spikes in network traffic
    since the full snapshot is distributed over time. This leads to a lower chance
    of dropping packets on the snapshot multicast stream for the `MarketDataConsumer`
    components in the trading client’s systems. This also leads to the client’s system
    synchronizing or catching up with the snapshot stream for each trading instrument
    faster, since it does not need to wait for the full snapshot across all trading
    instruments before it can mark some of the instruments as *recovered*.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Adding authentication and rejection messages to the Order protocol
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our electronic trading exchange right now has no concept of user authentication
    and is missing a lot of error checking and handling. By this, we mean that it
    does not check whether clients log in with the correct credentials and are authorized
    to trade the instruments they try to trade. Additionally, if the `ClientId` and
    `TCPSocket` instances do not match or there is a sequence number gap in the `ClientRequest`
    messages that a client sends, we quietly ignore it in `Exchange::OrderServer`.
    This is shown in the following code block from the `exchange/order_server/order_server.h`
    source file, which we have already discussed in detail:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Silently ignoring errors like these is not ideal since the clients are not notified
    about these errors. An enhancement to this workflow would be to add a rejection
    message to the `ClientResponse` message protocol, which the `OrderServer` component
    can use to notify the clients about these errors. This enhancement is in addition
    to the enhancements we suggested to the order protocol to facilitate the authentication
    of the trading clients.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Supporting modify messages in the Order protocol
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our current order protocol for `ClientRequest` messages only supports `ClientRequestType::NEW`
    and `ClientRequestType::CANCEL` requests. An enhancement to this protocol would
    be to add a `ClientRequestType::MODIFY` message type so that client trading systems
    can modify their order’s price or quantity attributes. We would need to update
    the `OrderServer`, `MatchingEngine`, `MEOrderBook`, and other components on the
    exchange’s side and update the `OrderGateway`, `OrderManager`, `MarketMaker`,
    `TradeEngine`, and other components on the trading client’s side.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing trade engine components
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The trade engine has several components that can be improved and/or enhanced.
    In this section, we provide brief descriptions of these improvements for each
    of the components with potential future enhancements.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Adding risk metrics to RiskManager
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the chapter *Designing Our Trading Ecosystem*, in the *Understanding the
    risk management systems* section, we described a couple of different risk metrics.
    `RiskManager` was built only with a small subset of those risk metrics and can
    be enhanced by adding additional risk measures, as described in that section.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing OrderManager
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`OrderManager` was built extremely simply – it supports a maximum of one active
    order on each side, that is, at most one buy order and one sell order. Obviously,
    this is an extremely simplified version and `OrderManager` can be enhanced to
    support much more complex order management.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`OrderManager` 极其简单构建——它支持每侧最多一个活跃订单，也就是说，最多一个买入订单和一个卖出订单。显然，这是一个极其简化的版本，`OrderManager`
    可以增强以支持更复杂的订单管理。'
- en: Enriching FeatureEngine
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 丰富 FeatureEngine
- en: '`FeatureEngine` was set up with two hardcoded features built into it. It can
    be enriched a lot to support complex configurations of features, a library of
    diverse types of features, complex interactions between these features, and so
    on.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`FeatureEngine` 配置了两个硬编码的特征。它可以大量丰富以支持复杂特征配置、多种类型特征的库、这些特征之间的复杂交互等。'
- en: Enhancing the trading algorithms
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升交易算法
- en: '`LiquidityTaker` and `MarketMaker` in this book were also extremely simple
    representations of realistic trading strategies. These can be enhanced/improved
    in many ways – improvements in terms of feature compositions, order management,
    efficient execution, and so on.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的 `LiquidityTaker` 和 `MarketMaker` 也是对现实交易策略的极其简单表示。这些可以在许多方面进行增强/改进——包括特征组合、订单管理、高效执行等方面的改进。
- en: This concludes our discussion of future enhancement possibilities for our electronic
    trading ecosystem.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对电子交易生态系统未来增强可能性的讨论。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The first section of this chapter focused on analyzing the latency metrics we
    added to our electronic trading systems in the previous chapter. We discussed
    a few examples of latency measurements for internal functions, as well as a few
    examples of latency measurements between critical hops in our system. The goal
    was to understand the distribution of latencies in different cases so that you
    understand how to identify and investigate areas of potential problems or optimization
    opportunities.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分专注于分析我们在上一章中添加到电子交易系统中的延迟指标。我们讨论了内部函数的几个延迟测量示例，以及系统关键跳转之间的几个延迟测量示例。目标是了解不同情况下延迟的分布，以便您了解如何识别和调查潜在问题或优化机会的区域。
- en: In the second section of this chapter, we discussed a few tips and techniques
    regarding how to approach potential performance optimization possibilities. We
    presented a few examples of what could be improved and discussed the performance
    problems that exist in the current design and solutions to those problems.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第二部分，我们讨论了一些关于如何接近潜在性能优化可能性的技巧和技术。我们提供了一些可以改进的示例，并讨论了当前设计中的性能问题及其解决方案。
- en: In the concluding section, we described a roadmap for the future of the electronic
    trading ecosystem we built in this book. We discussed several different components,
    sub-components, and workflows that can be enriched to build a more mature electronic
    trading ecosystem.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在结论部分，我们描述了本书中构建的电子交易生态系统的未来路线图。我们讨论了几个可以丰富以构建更成熟电子交易生态系统的不同组件、子组件和工作流程。
- en: The approach and principles we discussed in this book pertaining to latency-sensitive
    applications developed in C++ should guide you on your journey. The full end-to-end
    electronic trading ecosystem we built is a prime example of a low-latency application
    and hopefully provided a good practical example of how to build a low-latency
    application from scratch. Hopefully, this chapter added to the experience by providing
    you with tools to analyze the performance and iteratively improve the system.
    We wish you all the best as you continue your low-latency application development
    journey!
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 本书讨论的关于在 C++ 中开发的对延迟敏感的应用程序的方法和原则应指导您的旅程。我们构建的完整端到端电子交易生态系统是一个低延迟应用的典范，并希望提供了一个从零开始构建低延迟应用的优秀实践示例。希望这一章通过为您提供分析性能和迭代改进系统的工具，增加了您的经验。我们祝愿您在继续您的低延迟应用开发旅程中一切顺利！
