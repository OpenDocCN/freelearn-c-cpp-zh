<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-117"><a id="_idTextAnchor116"/>8</h1>
<h1 id="_idParaDest-118"><a id="_idTextAnchor117"/>Adding Shadows Using Mesh Shaders</h1>
<p>In the previous chapter, we added support for multiple lights using clustered deferred techniques with the latest innovations.</p>
<p>We added a hard limit of 256 maximum lights, with the possibility for each one to be dynamic and unique in its properties.</p>
<p>In this chapter, we will add the possibility for each of these lights to cast shadows to further enhance the visuals of any asset displayed in Raptor Engine, and we will exploit the possibilities given by mesh shaders of having many of these lights cast shadows and still be in a reasonable frame time.</p>
<p>We will also have a look at using sparse resources to improve shadow map memory usage, moving the possibility of having many shadow-casting lights from something almost impossible to something possible and performant with current hardware.</p>
<p>In this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>A brief history of shadow techniques</li>
<li>Implementing shadow mapping using mesh shaders</li>
<li>Improving shadow memory with Vulkan’s sparse resources</li>
</ul>
<h1 id="_idParaDest-119"><a id="_idTextAnchor118"/>Technical requirements</h1>
<p>The code for this chapter can be found at the following URL: <a href="https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter8">https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter8</a></p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor119"/>A brief history of shadow techniques</h1>
<p>Shadows are<a id="_idIndexMarker388"/> one of the biggest additions to any rendering framework as they really enhance the perception of depth and volume across a scene. Being a phenomenon linked to lights, they have been studied in graphics literature for decades, but the problem is still far from being solved.</p>
<p>The most used shadow technique right now is shadow mapping, but recently, thanks to hardware-enabled ray tracing, ray traced shadows are becoming popular as a more realistic solution.</p>
<p>There were some games—especially <em class="italic">Doom 3</em>—that also used shadow volumes as a solution to make lights cast shadows, but they are not used anymore.</p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor120"/>Shadow volumes</h2>
<p>Shadow volumes are <a id="_idIndexMarker389"/>an old concept, already proposed by Frank Crow in 1977. They are defined as the projection of each vertex of a triangle along the light direction and toward infinity, thus creating a volume<a id="_idTextAnchor121"/>.</p>
<p>The shadows are sharp, and they require each triangle and each light to process accordingly. The most recent implementation uses the stencil buffer, and this change enabled it to be used in real time.</p>
<p>The problem with shadow volumes is that they require a lot of geometry work and become fill-rate intensive, and in this case, shadow maps are a clear winner.</p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor122"/>Shadow mapping</h2>
<p>The most used <a id="_idIndexMarker390"/>technique of all, first appearing around 1978, shadow mapping is the industry standard in both real-time and offline rendering. The idea behind shadow mapping is to render the scene from the perspective of the light and save the depth of each pixel.</p>
<p>After that, when rendering the scene from the camera point of view, the pixel position can be converted to the shadow coordinate system and tested against the corresponding pixel in the shadow map to see whether the current pixel is in shadow or not.</p>
<p>The resolution of a shadow map is very important, as well as what type of information is saved inside it. With time, filters started to appear, using mathematical tools to add the possibility to soften the shadows, or adding calculations to harden the shadows the closer they are to the blocker geometry.</p>
<p>Shadow mapping suffers from a lot of issues as well, but being the de facto standard, many techniques are used to alleviate them. Some problems that can be encountered are aliasing, shadow acne, and Peter Panning.</p>
<p>Finding a robust<a id="_idIndexMarker391"/> shadow solution is one of the most intricate steps of a rendering engine and normally requires a lot of trial and error and custom solutions tailored to different scenes and situations.</p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor123"/>Raytraced shadows</h2>
<p>In the last<a id="_idIndexMarker392"/> few years, raytracing—a technique that uses rays to trace any kind of rendering information—got hardware support on customer GPUs, enabling rendering programmers to use a different scene representation to trace rays and enhance the look of different rendering phenomena.</p>
<p>We will look at raytracing toward the end of the book, but for now, it is sufficient to say that using this special representation of the scene (different from mesh and meshlets we already use), it is possible to trace, for each pixel on the screen, one ray toward each light affecting the pixel and calculate the final shadow contribution to that pixel.</p>
<p>It is the most advanced and realistic form of a shadow, but still, performance-wise—despite the hardware support—it can be slow, and the diffusion of GPUs supporting it is not as elevated as needed to make it the new standard.</p>
<p>That is why shadow mapping is still the standard—any hardware, including mobile phones, can render shadow maps, and they can still achieve a convincing look. Based on this consideration, we <a id="_idIndexMarker393"/>chose to implement shadow mapping as the main shadow technique for Raptor Engine.</p>
<h1 id="_idParaDest-124"><a id="_idTextAnchor124"/>Implementing shadow mapping using mesh shaders</h1>
<p>Now that we <a id="_idIndexMarker394"/>have looked at the different ways to render a shadow, we will describe the algorithm and the implementation’s detail used to render many shadow maps at once leveraging the mesh shader power.</p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor125"/>Overview</h2>
<p>In this section, we<a id="_idIndexMarker395"/> will give an overview of the algorithm. What we are trying to achieve is to render shadows using meshlets and mesh shaders, but this will require some compute work to generate commands to actually draw the meshlets.</p>
<p>We will draw shadows coming from point lights, and we will use cubemaps as textures to store the necessary information. We will talk about cubemaps in the following section.</p>
<p>Back to the algorithm, the first step will be to cull mesh instances against lights. This is done in a compute shader and will save a per-light list of visible mesh instances. Mesh instances are used to retrieve associated meshes later on, and per-meshlet culling will be performed using task shaders later on.</p>
<p>The second step is to write indirect draw meshlet arguments to perform the actual rendering of meshlets into shadow maps, again in a compute shader. There is a caveat here that will be explained in the <em class="italic">A note about multiview </em><em class="italic">rendering</em> section.</p>
<p>The third step is to draw meshlets using indirect mesh shaders, drawing into the actual shadow maps.</p>
<p>We will use a layered cubemap shadow texture as we are drawing, with each layer corresponding to each light.</p>
<p>The fourth and final step is to sample the shadow texture when lighting the scene.</p>
<p>We will render shadows with almost no filtering, as the focus of this chapter is on mesh shader-driven shadows, but we will give links to filtering options at the end of the chapter.</p>
<p>Here is a visual <a id="_idIndexMarker396"/><a id="_idIndexMarker397"/>overview of the algorithm:</p>
<div><div><img alt="Figure 8.1 – Algorithm overview" height="750" src="img/B18395_08_01.jpg" width="1384"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Algorithm overview</p>
<p>In the next section, we will talk about cubemap shadows, used to store shadows from point lights.</p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor126"/>Cubemap shadows</h2>
<p><strong class="bold">Cubemaps</strong> are <a id="_idIndexMarker398"/>a general way <a id="_idIndexMarker399"/>of mapping a 3D direction (<em class="italic">x</em>, <em class="italic">y</em>, <em class="italic">z</em>) with six faces containing image information.</p>
<p>They are used not only for shadow rendering but in general to draw environments as well (such as sky boxes, or far distant landscapes), and they are so standardized that even hardware contains support for cubemap sampling and filtering.</p>
<p>Each direction of the cubemap has normally a name and an orientation and a single texture associated with it:</p>
<ul>
<li>Positive <em class="italic">x</em></li>
<li>Negative <em class="italic">x</em></li>
<li>Positive <em class="italic">y</em></li>
<li>Negative <em class="italic">y</em></li>
<li>Positive <em class="italic">z</em></li>
<li>Negative <em class="italic">z</em></li>
</ul>
<p>When rendering to a face, we need to provide matrices that will look in the correct direction.</p>
<p>When <a id="_idIndexMarker400"/>reading, a single vector will be <a id="_idIndexMarker401"/>translated (behind the scenes) to the correspondin<a id="_idTextAnchor127"/>g image. For shadows, the process will be manual, as we will provide for each face a view projection matrix that will be read by the meshlets to direct the rendering to the correct face.</p>
<p>A caveat for that also is that we will need to duplicate the drawing commands for each face, as one vertex can be rendered only to one image view associated with each face.</p>
<p>There are some extensions that can associate a vertex with more than one image, as we will see in the next section, but their support in mesh shaders at the time of writing is still limited.</p>
<p>Another important aspect of the proposed shadow rendering is that we will use an array of cubemaps so that we can both read and write every shadow using layered rendering.</p>
<p>Here is the unrolled cubemap shadow rendering for one point light, with a texture for each cubemap face:</p>
<div><div><img alt="Figure 8.2 – The six cubemap faces rendered from the light point of view" height="646" src="img/B18395_08_02.jpg" width="968"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – The six cubemap faces rendered from the light point of view</p>
<p>As we can<a id="_idIndexMarker402"/> see, only the positive <em class="italic">Z</em> is rendering<a id="_idIndexMarker403"/> something. We will provide some culling mechanisms to avoid rendering meshlets in empty cubemap faces.</p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor128"/>A note about multiview rendering</h2>
<p>As written in <a id="_idIndexMarker404"/>the previous <a id="_idIndexMarker405"/>section, there is an extension that helps with rendering a vertex on more than a cubemap face: Multiview Rendering. This extension is widely used in virtual reality applications to render a vertex in both the views of a stereographic projection and can be used as well with cubemaps.</p>
<p>At the time of writing, mesh shaders don’t have a proper extension supported, so we are using the NVIDIA Vulkan extension, and this is not supporting Multiview Rendering properly, thus we are manually generating commands for each face and drawing using those commands.</p>
<p>We are aware that a multi-vendor extension is on the way, so we will update the code accordingly, but the core <a id="_idIndexMarker406"/>algorithm does not change, as multiview rendering is more of an <a id="_idIndexMarker407"/>optimization.</p>
<p>We are now ready to see the algorithm steps.</p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor129"/>Per-light mesh instance culling</h2>
<p>The first step in<a id="_idIndexMarker408"/> preparing for shadow rendering is a coarse grain culling done in a compute shader. In Raptor, we have both mesh and meshlet representations, thus we can use meshes and their bounding volumes as a <em class="italic">higher hierarchy</em> linked to meshlets.</p>
<p>We will perform a very simple light sphere to mesh sphere intersection, and if intersecting, we will add the corresponding meshlets. The first thing to know is that we will dispatch this compute shader using mesh instances and light together, so we will calculate for each light and for each mesh instance if the light influences the mesh instance.</p>
<p>We will then output a list of per-light meshlet instances, defined as both a mesh instance and global meshlet index combined. We will also write the per-light meshlet instances count, to skip empty lights and to correctly read the indices.</p>
<p>The first step is thus to reset the per-light counts:</p>
<pre class="source-code">
layout (local_size_x = 32, local_size_y = 1, local_size_z =
        1) in;
void main() {
    if (gl_GlobalInvocationID.x == 0 ) {
        for ( uint i = 0; i &lt; NUM_LIGHTS; ++i ) {
            per_light_meshlet_instances[i * 2] = 0;
            per_light_meshlet_instances[i * 2 + 1] = 0;
        }
    }
    global_shader_barrier();</pre>
<p>We will then skip threads that will work on out-of-bounds lights. When we dispatch, we round up the numbers after dividing by 32, so some threads can be working on empty lights.</p>
<p>The dispatch of this compute will be done by linking each mesh instance with each light, like so:</p>
<div><div><img alt="Figure 8.3 – Organization of the command buffer to render the cubemaps for multiple lights using a single draw call" height="295" src="img/B18395_08_03.jpg" width="924"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Organization of the command buffer to render the cubemaps for multiple lights using a single draw call</p>
<p>Here is the<a id="_idIndexMarker409"/> early out and light index calculation:</p>
<pre class="source-code">
    uint light_index = gl_GlobalInvocationID.x %
                       active_lights;
    if (light_index &gt;= active_lights) {
        return;
    }
    const Light = lights[light_index];</pre>
<p>In a similar way, we calculate the mesh instance index, and <em class="italic">early out</em> again if the dispatch rounding up is too much:</p>
<pre class="source-code">
    uint mesh_instance_index = gl_GlobalInvocationID.x /
                               active_lights;
    if (mesh_instance_index &gt;= num_mesh_instances) {
        return;
    }
    uint mesh_draw_index = mesh_instance_draws
                           [mesh_instance_index].
                           mesh_draw_index;
    // Skip transparent meshes
    MeshDraw mesh_draw = mesh_draws[mesh_draw_index];
    if ( ((mesh_draw.flags &amp; (DrawFlags_AlphaMask |
           DrawFlags_Transparent)) != 0 ) ){
        return;
    }</pre>
<p>We can finally<a id="_idIndexMarker410"/> gather the bounding sphere of the mesh instance and the model and simply calculate the world space bounding sphere:</p>
<pre class="source-code">
    vec4 bounding_sphere = mesh_bounds[mesh_draw_index];
    mat4 model = mesh_instance_draws
                 [mesh_instance_index].model;
    // Calculate mesh instance bounding sphere
    vec4 mesh_world_bounding_center = model * vec4
        (bounding_sphere.xyz, 1);
    float scale = length( model[0] );
    float mesh_radius = bounding_sphere.w * scale * 1.1;
    // Artificially inflate bounding sphere
    // Check if mesh is inside light
    const bool mesh_intersects_sphere =
    sphere_intersect(mesh_world_bounding_center.xyz,
        mesh_radius, light.world_position, light.radius )
            || disable_shadow_meshes_sphere_cull();
    if (!mesh_intersects_sphere) {
        return;
    }</pre>
<p>At this point, we <a id="_idIndexMarker411"/>know that the mesh instance is influenced by the light, so increase the per-light meshlet count and add all the indices necessary to draw the meshlets:</p>
<pre class="source-code">
    uint per_light_offset =
        atomicAdd(per_light_meshlet_instances[light_index],
            mesh_draw.meshlet_count);
    // Mesh inside light, add meshlets
    for ( uint m = 0; m &lt; mesh_draw.meshlet_count; ++m ) {
        uint meshlet_index = mesh_draw.meshlet_offset + m;
         meshlet_instances[light_index *
             per_light_max_instances + per_light_offset
                 + m] = uvec2( mesh_instance_index,
                     meshlet_index );
    }
}</pre>
<p>We will end up writing both the mesh instance index—to retrieve the world matrix—and the global meshlet index—to retrieve meshlet data in the following task shader. But before that, we need to generate an indirect draw commands list, and we will see that in the next section.</p>
<p>Also, based<a id="_idIndexMarker412"/> on the scene, we have a maximum number of meshlet instances, and we allocate them upfront for each light.</p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor130"/>Indirect draw commands generation</h2>
<p>This compute<a id="_idIndexMarker413"/> shader will generate a list of indirect commands for each light. We will use the last element of the per-light meshlet instances’ <strong class="bold">Shader Storage Buffer Object</strong> (<strong class="bold">SSBO</strong>) to <a id="_idIndexMarker414"/>atomically count the number of indirect commands.</p>
<p>As before, reset <code>atomic int</code> used for the indirect commands count:</p>
<pre class="source-code">
layout (local_size_x = 32, local_size_y = 1, local_size_z =
        1) in;
void main() {
    if (gl_GlobalInvocationID.x == 0 ) {
        // Use this as atomic int
        per_light_meshlet_instances[NUM_LIGHTS] = 0;
    }
    global_shader_barrier();</pre>
<p>We will early out execution for rounded-up light indices:</p>
<pre class="source-code">
    // Each thread writes the command of a light.
    uint light_index = gl_GlobalInvocationID.x;
    if ( light_index &gt;= active_lights ) {
        return;
    }</pre>
<p>We can finally write the indirect data and the packed light index, only if the light contains visible meshes.</p>
<p>Note that we<a id="_idIndexMarker415"/> write six commands, one for each cubemap face:</p>
<pre class="source-code">
    // Write per light shadow data
    const uint visible_meshlets =
        per_light_meshlet_instances[light_index];
    if (visible_meshlets &gt; 0) {
        const uint command_offset =
            atomicAdd(per_light_meshlet_instances[
                NUM_LIGHTS], 6);
        uint packed_light_index = (light_index &amp; 0xffff)
                                   &lt;&lt; 16;
        meshlet_draw_commands[command_offset] =
            uvec4( ((visible_meshlets + 31) / 32), 1, 1,
                packed_light_index | 0 );
        meshlet_draw_commands[command_offset + 1] =
            uvec4( ((visible_meshlets + 31) / 32), 1, 1,
                packed_light_index | 1 );
   ... same for faces 2 to 5.
    }
}</pre>
<p>We now have<a id="_idIndexMarker416"/> a list of indirect drawing commands, six for each light. We will perform further culling in the task shader, shown in the next section.</p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor131"/>Shadow cubemap face culling</h2>
<p>In the indirect <a id="_idIndexMarker417"/>drawing task <a id="_idIndexMarker418"/>shader, we will add a mechanism to cull a meshlet against a cubemap to optimize the rendering. To do that, we have a utility method that will calculate, given a cubemap and an axis-aligned bounding box, which face will be visible in the cubemap. It is using cubemap face normals to calculate whether the center and extents are enclosed in the four planes used to define one of the six cubemap faces:</p>
<pre class="source-code">
uint get_cube_face_mask( vec3 cube_map_pos, vec3 aabb_min,
                         vec3 aabb_max ) {
    vec3 plane_normals[] = {
        vec3(-1, 1, 0), vec3(1, 1, 0), vec3(1, 0, 1),
            vec3(1, 0, -1), vec3(0, 1, 1), vec3(0, -1, 1)
    };
    vec3 abs_plane_normals[] = {
        vec3(1, 1, 0), vec3(1, 1, 0), vec3(1, 0, 1),
            vec3(1, 0, 1), vec3(0, 1, 1), vec3(0, 1, 1) };
    vec3 aabb_center = (aabb_min + aabb_max) * 0.5f;
    vec3 center = aabb_center - cube_map_pos;
    vec3 extents = (aabb_max - aabb_min) * 0.5f;
    bool rp[ 6 ];
    bool rn[ 6 ];
    for ( uint  i = 0; i &lt; 6; ++i ) {
        float dist = dot( center, plane_normals[ i ] );
        float radius = dot( extents, abs_plane_normals[ i ]
        );
        rp[ i ] = dist &gt; -radius;
        rn[ i ] = dist &lt; radius;
    }
    uint fpx = (rn[ 0 ] &amp;&amp; rp[ 1 ] &amp;&amp; rp[ 2 ] &amp;&amp; rp[ 3 ] &amp;&amp;
                aabb_max.x &gt; cube_map_pos.x) ? 1 : 0;
    uint fnx = (rp[ 0 ] &amp;&amp; rn[ 1 ] &amp;&amp; rn[ 2 ] &amp;&amp; rn[ 3 ] &amp;&amp;
                aabb_min.x &lt; cube_map_pos.x) ? 1 : 0;
    uint fpy = (rp[ 0 ] &amp;&amp; rp[ 1 ] &amp;&amp; rp[ 4 ] &amp;&amp; rn[ 5 ] &amp;&amp;
                aabb_max.y &gt; cube_map_pos.y) ? 1 : 0;
    uint fny = (rn[ 0 ] &amp;&amp; rn[ 1 ] &amp;&amp; rn[ 4 ] &amp;&amp; rp[ 5 ] &amp;&amp;
                aabb_min.y &lt; cube_map_pos.y) ? 1 : 0;
    uint fpz = (rp[ 2 ] &amp;&amp; rn[ 3 ] &amp;&amp; rp[ 4 ] &amp;&amp; rp[ 5 ] &amp;&amp;
                aabb_max.z &gt; cube_map_pos.z) ? 1 : 0;
    uint fnz = (rn[ 2 ] &amp;&amp; rp[ 3 ] &amp;&amp; rn[ 4 ] &amp;&amp; rn[ 5 ] &amp;&amp;
                aabb_min.z &lt; cube_map_pos.z) ? 1 : 0;
    return fpx | ( fnx &lt;&lt; 1 ) | ( fpy &lt;&lt; 2 ) | ( fny &lt;&lt; 3 )
    | ( fpz &lt;&lt; 4 ) | ( fnz &lt;&lt; 5 );
}</pre>
<p>These methods<a id="_idIndexMarker419"/> return a<a id="_idIndexMarker420"/> bitmask with each of the six bits set as <code>1</code> when the current axis-aligned bounding box is visible in that face.</p>
<h2 id="_idParaDest-131"><a id="_idTextAnchor132"/>Meshlet shadow rendering – task shader</h2>
<p>Now that we<a id="_idIndexMarker421"/> have this u<a id="_idTextAnchor133"/>tility method in <a id="_idIndexMarker422"/>place, we can look at the task shader. We changed some things with the other task shaders to accommodate the indirect drawing and to use layered rendering to write on different cubemaps.</p>
<p>We will pass <code>uint</code> to the mesh shader that packs a light and a face index to retrieve the corresponding cubemap view projection matrix and write to the correct layer:</p>
<pre class="source-code">
out taskNV block {
    uint meshlet_indices[32];
     uint light_index_face_index;
};
void main() {
    uint task_index = gl_LocalInvocationID.x;
     uint meshlet_group_index = gl_WorkGroupID.x;</pre>
<p>The meshlet calculation is tricky, as indices need to be calculated globally. We first calculate the meshlet index global to the indirect draw:</p>
<pre class="source-code">
    // Calculate meshlet and light indices
    const uint meshlet_index = meshlet_group_index * 32 +
                               task_index;</pre>
<p>We then extrapolate the light index and the read offset in the meshlet instances written in the culling compute shader:</p>
<pre class="source-code">
    uint packed_light_index_face_index =
        meshlet_draw_commands[gl_DrawIDARB].w;
    const uint light_index =
        packed_light_index_face_index &gt;&gt; 16;
    const uint meshlet_index_read_offset =
        light_index * per_light_max_instances;</pre>
<p>We can <a id="_idIndexMarker423"/>finally read the correct meshlet and <a id="_idIndexMarker424"/>mesh instance indices:</p>
<pre class="source-code">
uint global_meshlet_index = 
   meshlet_instances[meshlet_index_read_offset + 
   meshlet_index].y; 
   uint mesh_instance_index =
        meshlet_instances[meshlet_index_read_offset +
            meshlet_index].x;</pre>
<p>Now, we calculate the face index, and we can start the culling phase:</p>
<pre class="source-code">
    const uint face_index = (packed_light_index_face_index
                             &amp; 0xf);
    mat4 model = mesh_instance_draws[mesh_instance_index]
                 .model;</pre>
<p>Culling is <a id="_idIndexMarker425"/>performed similarly to previous task<a id="_idIndexMarker426"/> shaders, but we added also per-face culling:</p>
<pre class="source-code">
    vec4 world_center = model * vec4(meshlets
                        [global_meshlet_index].center, 1);
    float scale = length( model[0] );
    float radius = meshlets[global_meshlet_index].radius *
                   scale * 1.1;   // Artificially inflate
                                     bounding sphere
vec3 cone_axis = 
   mat3( model ) * vec3(int(meshlets 
   [global_meshlet_index].cone_axis[0]) / 127.0, 
   int(meshlets[global_meshlet_index]. 
   cone_axis[1]) / 127.0, 
   int(meshlets[global_meshlet_index]. 
   cone_axis[2]) / 127.0); 
   float cone_cutoff = int(meshlets[global_meshlet_index].
                           cone_cutoff) / 127.0;
    bool accept = false;
    const vec4 camera_sphere = camera_spheres[light_index];
    // Cone cull
    accept = !coneCull(world_center.xyz, radius, cone_axis,
             cone_cutoff, camera_sphere.xyz) ||
             disable_shadow_meshlets_cone_cull();
    // Sphere culling
    if ( accept ) {
        accept = sphere_intersect( world_center.xyz,
                 radius, camera_sphere.xyz,
                 camera_sphere.w) ||
                 disable_shadow_meshlets_sphere_cull();
    }
    // Cubemap face culling
    if ( accept ) {
        uint visible_faces =
        get_cube_face_mask( camera_sphere.xyz,
            world_center.xyz - vec3(radius),
                world_center.xyz + vec3(radius));
        switch (face_index) {
            case 0:
                accept = (visible_faces &amp; 1) != 0;
                break;
            case 1:
                accept = (visible_faces &amp; 2) != 0;
                break;
...same for faces 2 to 5.
                    }
        accept = accept || disable_shadow_meshlets_cubemap
                 _face_cull();
    }</pre>
<p>At this point<a id="_idIndexMarker427"/> of the shader we write each <a id="_idIndexMarker428"/>visible meshlet:</p>
<pre class="source-code">
         uvec4 ballot = subgroupBallot(accept);
    uint index = subgroupBallotExclusiveBitCount(ballot);
    if (accept)
        meshlet_indices[index] = global_meshlet_index;
    uint count = subgroupBallotBitCount(ballot);
    if (task_index == 0)
        gl_TaskCountNV = count;</pre>
<p>And finally, we write the packed light and face index:</p>
<pre class="source-code">
        light_index_face_index =
            packed_light_index_face_index;
}</pre>
<p>Next, we will see the mesh shader.</p>
<h2 id="_idParaDest-132"><a id="_idTextAnchor134"/>Meshlet shadow rendering – mesh shader</h2>
<p>In this mesh<a id="_idIndexMarker429"/> shader, we will need to retrieve<a id="_idIndexMarker430"/> the layer index in the cubemap array to write to, and the light index to read the correct view-projection transform.</p>
<p>It’s important to note that each face has its own transform, as we effectively render to each face separately.</p>
<p>Note that each face of the cubemap is considered a layer, thus the first cubemap will be rendered in layers 0-5, the second in layers 6-11, and so on.</p>
<p>Here is the code:</p>
<pre class="source-code">
void main() {
   ...
    const uint light_index = light_index_face_index &gt;&gt; 16;
    const uint face_index = (light_index_face_index &amp; 0xf);
    const int layer_index = int(CUBE_MAP_COUNT *
                                light_index + face_index);
    for (uint i = task_index; i &lt; vertex_count; i +=
       32)    {
        uint vi = meshletData[vertexOffset + i];
        vec3 position = vec3(vertex_positions[vi].v.x,
                        vertex_positions[vi].v.y,
                        vertex_positions[vi].v.z);
        gl_MeshVerticesNV[ i ].gl_Position =
        view_projections[layer_index] *
           (model * vec4(position, 1));
    }
    uint indexGroupCount = (indexCount + 3) / 4;
    for (uint i = task_index; i &lt; indexGroupCount; i += 32) {
        writePackedPrimitiveIndices4x8NV(i * 4,
            meshletData[indexOffset + i]);
    }</pre>
<p>Here, we write the layer index for each primitive. The usage of these offsets is to avoid bank conflict when <a id="_idIndexMarker431"/>writing, as seen on <a id="_idIndexMarker432"/>previous shaders:</p>
<pre class="source-code">
     gl_MeshPrimitivesNV[task_index].gl_Layer =
         layer_index;
    gl_MeshPrimitivesNV[task_index + 32].gl_Layer =
        layer_index;
    gl_MeshPrimitivesNV[task_index + 64].gl_Layer =
        layer_index;
    gl_MeshPrimitivesNV[task_index + 96].gl_Layer =
        layer_index;
    if (task_index == 0) {
        gl_PrimitiveCountNV =
            uint(meshlets[global_meshlet_index]
                .triangle_count);
    }
}</pre>
<p>After this mesh shader rendering of shadows is complete, as there is no fragment shader<a id="_idIndexMarker433"/> associated. We can now read the<a id="_idIndexMarker434"/> generated shadow texture in the lighting shader, as explained in the next section.</p>
<h2 id="_idParaDest-133"><a id="_idTextAnchor135"/>Shadow map sampling</h2>
<p>Given that <a id="_idIndexMarker435"/>we are just using hard shadow maps without filtering, the code to sample it is standard cubemap code. We calculate the world-to-light vector and use it to sample the cubemap.</p>
<p>Being a layered cubemap, we need both the 3D direction vector and the layer index, which we saved in the light itself:</p>
<pre class="source-code">
    vec3 shadow_position_to_light = world_position –
                                    light.world_position;
const float closest_depth =
    texture(global_textures_cubemaps_array
    [nonuniformEXT(cubemap_shadows_index)],
    vec4(shadow_position_to_light,
    shadow_light_index)).r;</pre>
<p>We then convert the depth to raw depth values with the <code>vector_to_depth_value</code> utility method, which takes the major axis from the light vector and converts it to raw depth so that we can compare the value read from the cubemap:</p>
<pre class="source-code">
    const float current_depth = vector_to_depth_value
                                (shadow_position_to_light,
                                 light.radius);
    float shadow = current_depth - bias &lt; closest_depth ?
                   1 : 0;</pre>
<p>The <code>vector_to_depth_value</code> method is shown here:</p>
<pre class="source-code">
float vector_to_depth_value( inout vec3 Vec, float radius) {
    vec3 AbsVec = abs(Vec);
    float LocalZcomp = max(AbsVec.x, max(AbsVec.y,
                           AbsVec.z));
    const float f = radius;
    const float n = 0.01f;
    float NormZComp = -(f / (n - f) - (n * f) / (n - f) /
                        LocalZcomp);
    return NormZComp;
}</pre>
<p>It takes the major<a id="_idIndexMarker436"/> axis from the direction vector and converts it to the raw depth using the formula coming from the projection matrix. This value is now usable with any depth value stored in a shadow map.</p>
<p>Here is an example of shadow coming from a point light:</p>
<div><div><img alt="Figure 8.4 – Shadows produced by a single point light in the scene" height="795" src="img/B18395_08_04.jpg" width="838"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Shadows produced by a single point light in the scene</p>
<p>As we can <a id="_idIndexMarker437"/>see, shadows are a great improvement in rendering, giving the viewer a fundamental visual cue of an object’s relationship with its environment.</p>
<p>Until here, we saw how to implement mesh shader-based shadows, but there is still room for improvement, especially in memory usage. Right now, this solution allocates upfront a single cubemap <a id="_idTextAnchor136"/>for each light, and the memory can become big quickly if we consider that we have six textures for each light.</p>
<p>We will look at a solution to lower the shadow map memory using sparse resources in the next section.</p>
<h1 id="_idParaDest-134"><a id="_idTextAnchor137"/>Improving shadow memory with Vulkan’s sparse resources</h1>
<p>As we<a id="_idIndexMarker438"/> mentioned <a id="_idIndexMarker439"/>at the end of the last section, we currently allocate the full memory for each cubemap for all the lights. Depending on the screen size of the light, we might be wasting memory as distant and small lights won’t be able to take advantage of the high resolution of the shadow map.</p>
<p>For this reason, we have implemented a technique that allows us to dynamically determine the resolution of each cubemap based on the camera position. With this information, we can then manage a sparse texture and re-assign its memory at runtime depending on the requirements for a given frame.</p>
<p>Sparse textures (sometimes also referred<a id="_idIndexMarker440"/> to as <strong class="bold">virtual textures</strong>) can be implemented manually, but luckily, they are supported natively in Vulkan. We are now going to describe how to use the Vulkan API to implement them.</p>
<h2 id="_idParaDest-135"><a id="_idTextAnchor138"/>Creating and allocating sparse textures</h2>
<p>Regular<a id="_idIndexMarker441"/> resources<a id="_idIndexMarker442"/> in Vulkan <a id="_idIndexMarker443"/>must<a id="_idIndexMarker444"/> be bound to a single memory allocation, and it’s not possible to bind a given resource to a different allocation. This works well for resources that are known at runtime and that we don’t expect to change.</p>
<p>However, when using cubemaps with a dynamic resolution, we need to be able to bind different portions of memory to a given resource. Vulkan exposes two methods to achieve this:</p>
<ul>
<li>Sparse resources allow us to bind a resource to non-contiguous memory allocations, but the full resource needs to be bound.</li>
<li>Sparse residency allows us to partially bind a resource to different memory allocations. This is what we need for our implementation, as we are likely to use only a subsection of each layer of a cubemap.</li>
</ul>
<p>Both methods allow users to re-bind a resource to different allocations at runtime. The first step needed to start using sparse resources is to pass the right flag when creating resources:</p>
<pre class="source-code">
VkImageCreateInfo image_info = {
    VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO };
image_info.flags = VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT |
                   VK_IMAGE_CREATE_SPARSE_BINDING_BIT;</pre>
<p>Here, we are requesting a resource that supports sparse residency. Once an image is created, we don’t need to immediately allocate memory for it. Instead, we are going to allocate<a id="_idIndexMarker445"/> a<a id="_idIndexMarker446"/> region<a id="_idIndexMarker447"/> of<a id="_idIndexMarker448"/> memory from which we will sub-allocate individual pages.</p>
<p>It’s important to note that Vulkan has strict requirements for the size of individual pages. These are the required sizes taken from the Vulkan specification:</p>
<div><div><img alt="Table 8.1 – Sparse block sizes for images" height="387" src="img/B18395_08_Table_01.jpg" width="1237"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 8.1 – Sparse block sizes for images</p>
<p>We will need this information to determine how many pages to allocate for a cubemap of a given size. We can retrieve the details for a given image with the following code:</p>
<pre class="source-code">
VkPhysicalDeviceSparseImageFormatInfo2 format_info{
    VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT
        _INFO_2 };
format_info.format = texture-&gt;vk_format;
format_info.type = to_vk_image_type( texture-&gt;type );
format_info.samples = VK_SAMPLE_COUNT_1_BIT;
format_info.usage = texture-&gt;vk_usage;
format_info.tiling = VK_IMAGE_TILING_OPTIMAL;</pre>
<p>The <a id="_idIndexMarker449"/>information<a id="_idIndexMarker450"/> for <a id="_idIndexMarker451"/>this structure is already<a id="_idIndexMarker452"/> available in our texture data structure. Next, we retrieve the block size for the given image:</p>
<pre class="source-code">
Array&lt;VkSparseImageFormatProperties2&gt; properties;
vkGetPhysicalDeviceSparseImageFormatProperties2(
    vulkan_physical_device, &amp;format_info, &amp;property_count,
        properties.data );
u32 block_width = properties[ 0 ].properties.
                  imageGranularity.width;
u32 block_height = properties[ 0 ].properties.
                   imageGranularity.height;</pre>
<p>With this information, we can now allocate a pool of pages. First, we retrieve the memory requirements for the image:</p>
<pre class="source-code">
VkMemoryRequirements memory_requirements{ };
vkGetImageMemoryRequirements( vulkan_device, texture-&gt;
                              vk_image,
                              &amp;memory_requirements );</pre>
<p>This is the same code we would use for a regular texture; however, <code>memory_requirements.alignment</code> will contain the block size for the given image format.</p>
<p>Next, we compute the number of blocks we need to allocate for the given pool size:</p>
<pre class="source-code">
u32 block_count = pool_size / ( block_width * block_height );</pre>
<p>The final step<a id="_idIndexMarker453"/> is <a id="_idIndexMarker454"/>to <a id="_idIndexMarker455"/>allocate <a id="_idIndexMarker456"/>the pages that we will use later to write into our cubemaps:</p>
<pre class="source-code">
VmaAllocationCreateInfo allocation_create_info{ };
allocation_create_info.usage = VMA_MEMORY_USAGE_GPU_ONLY;
VkMemoryRequirements page_memory_requirements;
page_memory_requirements.memoryTypeBits =
    memory_requirements.memoryTypeBits;
page_memory_requirements.alignment =
    memory_requirements.alignment;
page_memory_requirements.size =
    memory_requirements.alignment;
vmaAllocateMemoryPages( vma_allocator,
                        &amp;page_memory_requirements,
                        &amp;allocation_create_info,
                        block_count, page_pool-&gt;
                        vma_allocations.data, nullptr );</pre>
<p>The <code>vmaAllocateMemoryPages</code>, to allocate multiple pages at once.</p>
<p>Now that <a id="_idIndexMarker458"/>we <a id="_idIndexMarker459"/>have<a id="_idIndexMarker460"/> allocated<a id="_idIndexMarker461"/> the memory for our shadow maps, we need to determine the resolution for each cubemap.</p>
<h2 id="_idParaDest-136"><a id="_idTextAnchor139"/>Choosing per-light shadow memory usage</h2>
<p>To determine<a id="_idIndexMarker462"/> the<a id="_idIndexMarker463"/> resolution of the cubemap for a given light, we need to find how much influence it has on the scene. Intuitively, a more distant light will have less influence, depending on its radius (at least for point lights), but we need to quantify its amount of influence. We have implemented a solution similar to the one proposed in the <em class="italic">More Efficient Virtual Shadow Maps for Many </em><em class="italic">Lights</em> paper.</p>
<p>We are going to reuse the concept introduced in the previous chapter: clusters. We subdivide the screen into tiles and <em class="italic">slice</em> the frustum on the <em class="italic">z</em> axis. This will give us smaller frustums (approximated by axis-aligned bounding boxes) that we will use to determine which regions are covered by a given light.</p>
<p>Let’s look at the code to achieve this:</p>
<ol>
<li>We start by computing the bounding box for each light in camera space:<pre class="source-code">
for ( u32 l = 0; l &lt; light_count; ++l ) {</pre><pre class="source-code">
    Light&amp; light = scene-&gt;lights[ l ];</pre><pre class="source-code">
    vec4s aabb_min_view = glms_mat4_mulv(</pre><pre class="source-code">
                          last_camera.view,</pre><pre class="source-code">
                          light.aabb_min );</pre><pre class="source-code">
    vec4s aabb_max_view = glms_mat4_mulv(</pre><pre class="source-code">
                          last_camera.view,</pre><pre class="source-code">
                          light.aabb_max );</pre><pre class="source-code">
    lights_aabb_view[ l * 2 ] = vec3s{</pre><pre class="source-code">
        aabb_min_view.x, aabb_min_view.y,</pre><pre class="source-code">
            aabb_min_view.z };</pre><pre class="source-code">
    lights_aabb_view[ l * 2 + 1 ] = vec3s{</pre><pre class="source-code">
        aabb_max_view.x, aabb_max_view.y,</pre><pre class="source-code">
            aabb_max_view.z };</pre><pre class="source-code">
}</pre></li>
<li>Next, we <a id="_idIndexMarker464"/>iterate<a id="_idIndexMarker465"/> over the tiles and each depth slice to compute each cluster position and size. We start by computing the camera space position of each tile:<pre class="source-code">
vec4s max_point_screen = vec4s{ f32( ( x + 1 ) *</pre><pre class="source-code">
                         tile_size ), f32( ( y + 1 ) *</pre><pre class="source-code">
                         tile_size ), 0.0f, 1.0f };</pre><pre class="source-code">
                         // Top Right</pre><pre class="source-code">
vec4s min_point_screen = vec4s{ f32( x * tile_size ),</pre><pre class="source-code">
                         f32( y * tile_size ),</pre><pre class="source-code">
                         0.0f, 1.0f }; // Top Right</pre><pre class="source-code">
vec3s max_point_view = screen_to_view(</pre><pre class="source-code">
                       max_point_screen );</pre><pre class="source-code">
vec3s min_point_view = screen_to_view(</pre><pre class="source-code">
                       min_point_screen );</pre></li>
<li>We then need to determine the minimum and maximum depth for each slice:<pre class="source-code">
f32 tile_near = z_near * pow( z_ratio, f32( z ) *</pre><pre class="source-code">
                              z_bin_range );</pre><pre class="source-code">
f32 tile_far  = z_near * pow( z_ratio, f32( z + 1 ) *</pre><pre class="source-code">
                              z_bin_range );</pre></li>
<li>Finally, we <a id="_idIndexMarker466"/>combine<a id="_idIndexMarker467"/> both values to retrieve the position and size of the cluster:<pre class="source-code">
vec3s min_point_near = line_intersection_to_z_plane(</pre><pre class="source-code">
                       eye_pos, min_point_view,</pre><pre class="source-code">
                       tile_near );</pre><pre class="source-code">
vec3s min_point_far  = line_intersection_to_z_plane(</pre><pre class="source-code">
                       eye_pos, min_point_view,</pre><pre class="source-code">
                       tile_far );</pre><pre class="source-code">
vec3s max_point_near = line_intersection_to_z_plane(</pre><pre class="source-code">
                       eye_pos, max_point_view,</pre><pre class="source-code">
                       tile_near );</pre><pre class="source-code">
vec3s max_point_far  = line_intersection_to_z_plane(</pre><pre class="source-code">
                       eye_pos, max_point_view,</pre><pre class="source-code">
                       tile_far );</pre><pre class="source-code">
vec3s min_point_aabb_view = glms_vec3_minv( glms_vec3_minv( min_point_near, min_point_far ), glms_vec3_minv( max_point_near, max_point_far ) );</pre><pre class="source-code">
vec3s max_point_aabb_view = glms_vec3_maxv( glms_vec3_maxv( min_point_near, min_point_far ), glms_vec3_maxv( max_point_near, max_point_far ) );</pre></li>
</ol>
<p>Now that we have obtained the cluster, we iterate over each light to determine whether it covers the cluster and the projection of the cluster onto the light; we’ll clarify what this means in a moment.</p>
<ol>
<li value="5">The next <a id="_idIndexMarker468"/>step<a id="_idIndexMarker469"/> is a box intersection test between the light and the cluster:<pre class="source-code">
f32 minx = min( min( light_aabb_min.x,</pre><pre class="source-code">
                light_aabb_max.x ), min(</pre><pre class="source-code">
                min_point_aabb_view.x,</pre><pre class="source-code">
                max_point_aabb_view.x ) );</pre><pre class="source-code">
f32 miny = min( min( light_aabb_min.y,</pre><pre class="source-code">
                light_aabb_max.y ), min(</pre><pre class="source-code">
                min_point_aabb_view.y,</pre><pre class="source-code">
                max_point_aabb_view.y ) );</pre><pre class="source-code">
f32 minz = min( min( light_aabb_min.z,</pre><pre class="source-code">
                light_aabb_max.z ), min(</pre><pre class="source-code">
                min_point_aabb_view.z,</pre><pre class="source-code">
                max_point_aabb_view.z ) );</pre><pre class="source-code">
f32 maxx = max( max( light_aabb_min.x,</pre><pre class="source-code">
                light_aabb_max.x ), max(</pre><pre class="source-code">
                min_point_aabb_view.x,</pre><pre class="source-code">
                max_point_aabb_view.x ) );</pre><pre class="source-code">
f32 maxy = max( max( light_aabb_min.y,</pre><pre class="source-code">
                light_aabb_max.y ), max(</pre><pre class="source-code">
                min_point_aabb_view.y,</pre><pre class="source-code">
                max_point_aabb_view.y ) );</pre><pre class="source-code">
f32 maxz = max( max( light_aabb_min.z,</pre><pre class="source-code">
                light_aabb_max.z ), max(</pre><pre class="source-code">
                min_point_aabb_view.z,</pre><pre class="source-code">
                max_point_aabb_view.z ) );</pre><pre class="source-code">
f32 dx = abs( maxx - minx );</pre><pre class="source-code">
f32 dy = abs( maxy - miny );</pre><pre class="source-code">
f32 dz = abs( maxz - minz );</pre><pre class="source-code">
f32 allx = abs( light_aabb_max.x - light_aabb_min.x )</pre><pre class="source-code">
           + abs( max_point_aabb_view.x –</pre><pre class="source-code">
           min_point_aabb_view.x );</pre><pre class="source-code">
f32 ally = abs( light_aabb_max.y - light_aabb_min.y )</pre><pre class="source-code">
           + abs( max_point_aabb_view.y –</pre><pre class="source-code">
           min_point_aabb_view.y );</pre><pre class="source-code">
f32 allz = abs( light_aabb_max.z - light_aabb_min.z )</pre><pre class="source-code">
           + abs( max_point_aabb_view.z –</pre><pre class="source-code">
           min_point_aabb_view.z );</pre><pre class="source-code">
 bool intersects = ( dx &lt;= allx ) &amp;&amp; ( dy &lt; ally ) &amp;&amp;</pre><pre class="source-code">
                   ( dz &lt;= allz );</pre></li>
</ol>
<p>If they do<a id="_idIndexMarker470"/> intersect, we <a id="_idIndexMarker471"/>compute an approximation of the projected area of the light onto the cluster:</p>
<pre class="source-code">
f32 d = glms_vec2_distance( sphere_screen, tile_center );
f32 diff = d * d - tile_radius_sq;
if ( diff &lt; 1.0e-4 ) {
    continue;
}
f32 solid_angle = ( 2.0f * rpi ) * ( 1.0f - ( sqrtf(
                    diff ) / d ) );
f32 resolution = sqrtf( ( 4.0f * rpi * tile_pixels ) /
                        ( 6 * solid_angle ) );</pre>
<p>The idea is to take the distance between the light and cluster center in screen space, compute the solid angle subtended by the cluster onto the light position, and compute the resolution of the cubemap using the size in pixels of the cluster. We refer you to the paper for more details.</p>
<p>We keep the<a id="_idIndexMarker472"/> maximum <a id="_idIndexMarker473"/>resolution, and we will use the computed value to bind the memory for each cubemap.</p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor140"/>Rendering into a sparse shadow map</h2>
<p>Now that we<a id="_idIndexMarker474"/> have<a id="_idIndexMarker475"/> determined the resolution of the cubemaps for a given frame, we need to assign the pre-allocated pages to our textures:</p>
<ol>
<li value="1">The first step is to record which pages are assigned to each image:<pre class="source-code">
VkImageAspectFlags aspect = TextureFormat::has_depth(</pre><pre class="source-code">
texture-&gt;vk_format ) ? VK_IMAGE_ASPECT_DEPTH_BIT : VK_IMAGE_ASPECT_COLOR_BIT;</pre><pre class="source-code">
for ( u32 block_y = 0; block_y &lt; num_blocks_y;</pre><pre class="source-code">
      ++block_y ) {</pre><pre class="source-code">
      for ( u32 block_x = 0; block_x &lt; num_blocks_x;</pre><pre class="source-code">
            ++block_x ) {</pre><pre class="source-code">
                VkSparseImageMemoryBind sparse_bind{ };</pre><pre class="source-code">
                VmaAllocation allocation = </pre><pre class="source-code">
                   page_pool-&gt; vma_allocations</pre><pre class="source-code">
                      [ page_pool-&gt;used_pages++ ];</pre><pre class="source-code">
                VmaAllocationInfo allocation_info{ };</pre><pre class="source-code">
                vmaGetAllocationInfo( vma_allocator,</pre><pre class="source-code">
                                      allocation,</pre><pre class="source-code">
                                      &amp;allocation_info );</pre></li>
</ol>
<p>We start by getting the details for the allocation that we are going to use for a given block, as we need to access the <code>VkDeviceMemory</code> handle and the offset into the pool it was allocated from.</p>
<ol>
<li value="2">Next, we compute the texture offset for each block:<pre class="source-code">
        i32 dest_x = ( i32 )( block_x * block_width +</pre><pre class="source-code">
                              x );</pre><pre class="source-code">
        i32 dest_y = ( i32 )( block_y * block_height +</pre><pre class="source-code">
                              y );</pre></li>
<li>Then, we <a id="_idIndexMarker476"/>record <a id="_idIndexMarker477"/>this information into a <code>VkSparseImageMemoryBind</code> data structure that will be used later to update the memory bound to the cubemap texture:<pre class="source-code">
        sparse_bind.subresource.aspectMask = aspect;</pre><pre class="source-code">
        sparse_bind.subresource.arrayLayer = layer;</pre><pre class="source-code">
        sparse_bind.offset = { dest_x, dest_y, 0 };</pre><pre class="source-code">
        sparse_bind.extent = { block_width,</pre><pre class="source-code">
                               block_height, 1 };</pre><pre class="source-code">
        sparse_bind.memory =</pre><pre class="source-code">
            allocation_info.deviceMemory;</pre><pre class="source-code">
        sparse_bind.memoryOffset =</pre><pre class="source-code">
            allocation_info.offset;</pre><pre class="source-code">
        pending_sparse_queue_binds.push( sparse_bind</pre><pre class="source-code">
                                       );</pre><pre class="source-code">
    }</pre><pre class="source-code">
}</pre></li>
</ol>
<p>It’s important to note that, as we mentioned previously, we only use one image with many layers. The layer variable determines which layer each allocation will belong to. Please refer to the full code for more details.</p>
<ol>
<li value="4">Finally, we<a id="_idIndexMarker478"/> record <a id="_idIndexMarker479"/>which image these pages will be bound to:<pre class="source-code">
SparseMemoryBindInfo bind_info{ };</pre><pre class="source-code">
bind_info.image = texture-&gt;vk_image;</pre><pre class="source-code">
bind_info.binding_array_offset = array_offset;</pre><pre class="source-code">
bind_info.count = num_blocks;</pre><pre class="source-code">
pending_sparse_memory_info.push( bind_info );</pre></li>
</ol>
<p><code>array_offset</code> is an offset into the <code>pending_sparse_queue_binds</code> array so that we can store all pending allocations in a single array.</p>
<p>Now that we have recorded the list of allocation updates, we need to submit them to a queue for them to be executed by the GPU.</p>
<ol>
<li value="5">First, we<a id="_idIndexMarker480"/> populate a <code>VkSparseImageMemoryBindInfo</code> structure for each layer:<pre class="source-code">
for ( u32 b = 0; b &lt; pending_sparse_memory_info.size;</pre><pre class="source-code">
      ++b ) {</pre><pre class="source-code">
    SparseMemoryBindInfo&amp; internal_info =</pre><pre class="source-code">
        pending_sparse_memory_info[ b ];</pre><pre class="source-code">
    VkSparseImageMemoryBindInfo&amp; info =</pre><pre class="source-code">
        sparse_binding_infos[ b ];</pre><pre class="source-code">
    info.image = internal_info.image;</pre><pre class="source-code">
    info.bindCount = internal_info.count;</pre><pre class="source-code">
    info.pBinds = pending_sparse_queue_binds.data +</pre><pre class="source-code">
                  internal_info.binding_array_offset;</pre><pre class="source-code">
}</pre></li>
<li>Next, we<a id="_idIndexMarker481"/> submit <a id="_idIndexMarker482"/>all pending binding operations to the main queue:<pre class="source-code">
VkBindSparseInfo sparse_info{</pre><pre class="source-code">
    VK_STRUCTURE_TYPE_BIND_SPARSE_INFO };</pre><pre class="source-code">
sparse_info.imageBindCount =</pre><pre class="source-code">
    sparse_binding_infos.size;</pre><pre class="source-code">
sparse_info.pImageBinds = sparse_binding_infos.data;</pre><pre class="source-code">
sparse_info.signalSemaphoreCount = 1;</pre><pre class="source-code">
sparse_info.pSignalSemaphores =</pre><pre class="source-code">
    &amp;vulkan_bind_semaphore;</pre><pre class="source-code">
vkQueueBindSparse( vulkan_main_queue, 1, &amp;sparse_info,</pre><pre class="source-code">
                   VK_NULL_HANDLE );</pre></li>
</ol>
<p>It’s important to note that it’s the responsibility of the user to make sure this operation is completed before accessing the resources whose allocations we just updated. We achieve this by signaling a semaphore, <code>vulkan_bind_semaphore</code>, which will then be waited on by the main rendering work submission.</p>
<p>It’s important to note that the queue we call <code>vkQueueBindSparse</code> on must have the <code>VK_QUEUE_SPARSE_BINDING_BIT</code> flag.</p>
<p>In this section, we have covered the steps necessary to allocate and use sparse textures. We first explained how sparse textures work and why they are useful for our cubemap use case.</p>
<p>Next, we illustrated the algorithm we used to dynamically determine the resolution of each cubemap <a id="_idIndexMarker483"/>based on <a id="_idIndexMarker484"/>each light contribution to the scene. Finally, we demonstrated how to use the Vulkan API to bind memory to sparse resources.</p>
<h1 id="_idParaDest-138"><a id="_idTextAnchor141"/>Summary</h1>
<p>In this chapter, we extended our lighting system to support many point lights with an efficient implementation. We started with a brief history of shadow algorithms, and their benefits and shortcomings, up until some of the most recent techniques that take advantage of raytracing hardware.</p>
<p>Next, we covered our implementation of shadows for many point lights. We explained how cubemaps are generated for each light and the optimizations we implemented to make the algorithm scale to many lights. In particular, we highlighted the culling method we reused from the main geometry pass and the use of a single indirect draw call for each light.</p>
<p>In the last section, we introduced sparse textures, a technique that allows us to dynamically bind memory to a given resource. We highlighted the algorithm we used to determine the contribution of each point light to the scene and how we use that information to determine the resolution of each cubemap. Finally, we demonstrated how to use sparse resources with the Vulkan API.</p>
<p>While we only covered point lights in this chapter, some of the techniques can be reused with other types of lights. Some steps could also be optimized further: for instance, it’s possible to further reduce the cubemap resolution to account only for the area where geometry is visible.</p>
<p>The cluster computation is currently done on the CPU for clarity and to avoid having to read back the cluster data from the GPU, which could be a slow operation, but it might be worth moving the implementation to the GPU. We encourage you to experiment with the code and add more features!</p>
<h1 id="_idParaDest-139"><a id="_idTextAnchor142"/>Further reading</h1>
<p>The book <em class="italic">Real-Time Shadows</em> provides a good overview of many techniques to implement shadows, many of which are still in use today.</p>
<p><em class="italic">GPU Pro 360 Guide to Shadows</em> collects articles from the <em class="italic">GPU Pro</em> series that are focused on shadows.</p>
<p>An interesting technique described in the book is called tetrahedron shadow mapping: the idea is to project the shadow map to a tetrahedron and then unwrap it to a single texture.</p>
<p>The original concept was introduced in the <em class="italic">Shadow Mapping for Omnidirectional Light Using Tetrahedron Mapping</em> chapter (originally published in <em class="italic">GPU Pro</em>) and later expanded in <em class="italic">Tile-based Omnidirectional Shadows</em> (originally published in <em class="italic">GPU </em><em class="italic">Pro 6</em>).</p>
<p>For more details, we refer you to the code provided by the author: <a href="http://www.hd-prg.com/tileBasedShadows.xhtml">http://www.hd-prg.com/tileBasedShadows.xhtml</a>.</p>
<p>Our sparse texture implementation is based on this SIGGRAPH presentation: <a href="https://efficientshading.com/wp-content/uploads/s2015_shadows.pdf">https://efficientshading.com/wp-content/uploads/s2015_shadows.pdf</a>.</p>
<p>This expands on their original paper, found here: <a href="http://newq.net/dl/pub/MoreEfficientClusteredShadowsPreprint.pdf%0D">http://newq.net/dl/pub/MoreEfficientClusteredShadowsPreprint.pdf.</a></p>
<p>While we haven’t implemented it in this chapter, shadow map caching is an important technique to reduce the cost of computing shadow maps and amortize the shadow map updates over several frames.</p>
<p>A good starting point is this presentation: <a href="https://www.activision.com/cdn/research/2017_DD_Rendering_of_COD_IW.pdf">https://www.activision.com/cdn/research/2017_DD_Rendering_of_COD_IW.pdf</a>.</p>
<p>Our cluster computation closely follows the one presented in this article: <a href="http://www.aortiz.me/2018/12/21/CG.xhtml#part-2%0D">http://www.aortiz.me/2018/12/21/CG.xhtml#part-2.</a></p>
<p>The Vulkan specification provides many more details on how to use the API for sparse resources: <a href="https://registry.khronos.org/vulkan/specs/1.2-extensions/html/vkspec.xhtml#sparsememory">https://registry.khronos.org/vulkan/specs/1.2-extensions/html/vkspec.xhtml#sparsememory</a>.</p>
</div>
</div></body></html>