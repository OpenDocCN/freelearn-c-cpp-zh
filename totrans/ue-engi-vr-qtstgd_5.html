<html><head></head><body><div><h1 class="header-title">Creating Optimized Game Art for VR in UE4</h1>
                
            
            
                
<p><em>Server 17</em> has come a long way. We have brought the game from a simple puzzle idea to a working game prototype. At this stage, we have a sample level, custom gameplay, and custom interfaces. We have built interaction systems that can be expanded to add even more game mechanics. However, the game is not much to look at, is it? Our lighting is basic. We are still using the default textures for many things. There is nothing wrong with it, since this is still a game prototype, but if we want to be able to present this to anyone beyond family and friends, it is going to need a bit of sprucing up. </p>
<p>Creating 3D game art for VR is not like creating game art for other titles. Though we use many of the same programs, VR requires us to be conservative with our art. The performance requirements of VR demand that we keep polygon counts low, use tricks to eliminate the use of advanced lighting techniques, and rethink our approach to art. Fake everything you can, and treat your game art as if it is the late, 90s.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Performance is key</li>
<li>Artistic limitations in VR</li>
<li>Performance-boosting techniques</li>
<li>Measuring ingame performance</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Performance is key</h1>
                
            
            
                
<p>Again and again, we have touched on the theme of performance in VR. We talked about it first when we discussed VR sickness in <a href="926e8e71-f556-43b2-b4f8-47dc017c7a38.xhtml">Chapter 1</a>, <em>Introducing VR Technology in Unreal Engine 4</em>. We touched on it again in <a href="ec4818ac-6582-4488-ba15-e48ef829466f.xhtml">Chapter 3</a>, <em>Exploring Riveting Gameplay in Virtual Reality</em>, when we programmed the interaction systems that make our game work. So, why do we keep talking about it? Performance is central to enjoying a VR experience. Having high-end visuals helps our players become immersed in our digital environments, while keeping steady frame rates is the best way to maximize player comfort and reduce VR sickness. So, how do we balance both of these needs?</p>
<p>In this chapter, we are going to talk about performance regarding to 3D game art, lighting, and visual effects. In VR, managing your assets and detail level becomes a balancing act. How do we provide the visuals required to engage our players while keeping framerates at 90 FPS or above to keep them comfortable? The simple answer is understanding and careful planning. With the right planning and a few tricks, we can keep our FPS high, and deliver the experience our players demand.</p>
<p>To start us off, let's discuss the important points of how VR renders the elements we place on the screen. Each object we create and add to our environment needs to go through the process of being drawn to the screen. The more detailed the object (as measured by the polygon count or the triangle count), the more processing it takes. Processing takes time. We also have to be aware of draw calls. Each time we update the screen, the object needs to be drawn again along with each material that it uses. We could describe this as follows:</p>
<p class="CDPAlignLeft CDPAlign"><em>Draw Calls = Number of Meshes on screen * Number of Materials per Mesh</em></p>
<p>We also have to remember that VR headsets render to two screens (one per eye). So the number of draw calls is actually doubled! This is where planning can help. Here are some helpful do's and don'ts:</p>
<ul>
<li><strong>Do's</strong>:</li>
<li style="padding-left: 30px">Plan our environment so we can minimize the number of meshes on the screen. Make sure that each mesh has a purpose and adds something to the level by being there. </li>
<li style="padding-left: 30px">Minimize the number of materials that are on each object. It is possible to create one large material that can be used with several different meshes. However, keeping the number of materials per object as low as possible works as well.</li>
<li><strong>Don'ts</strong>:</li>
<li style="padding-left: 30px">Place meshes just to fill space. This makes the level feel cluttered and busy. This also increases the number of draw calls per frame.</li>
<li style="padding-left: 30px">Depend on advanced rendering techniques to display meshes and effects. Features such as transparency, screen-space reflections, and normal maps do not work well in VR. Either they are too resource intensive or do not display correctly.</li>
</ul>
<p>These are just a couple of the ways knowledge and planning can help with performance. By understanding the demands of VR and planning our approach to the art, we can do our best to minimize draw calls. </p>


            

            
        
    </div>



  
<div><h1 class="header-title">Artistic limitations in VR</h1>
                
            
            
                
<p>Now that we have a basic understanding, it's time to get specific. How do the limitations we face in VR affect each of the following categories of game art?:</p>
<ul>
<li>Static and skeletal meshes</li>
<li>Materials</li>
<li>Lighting</li>
<li>Visual effects</li>
</ul>
<p>Each category represents different limitations that need to be considered when creating the visuals for our game.</p>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">Static and skeletal mesh limitations</h1>
                
            
            
                
<p>Let's start by taking a look at static and skeletal meshes:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a5a44b03-4c2d-4305-9cbc-8a2823bd12cd.png" style="width:43.67em;height:23.67em;" width="1500" height="812"/></p>
<p>The static mesh editor in Unreal 4</p>
<p>Static and skeletal meshes represent the majority of the art that goes into creating a game in Unreal Engine 4. These are your 3D models and tend to be sorted into groups such as environment, character, weapon, vehicle, and so on. Back in the late '90s when computer resources were more limited, artists had to work within strict limits when it came to polygon or triangle counts, but those limits are a thing of the past. Modern game hardware can push millions of triangles to the screen with no problems. However, with the performance needs of VR being so high, it is time to create our models like it's 1999!</p>
<p>For some of us older folks, we are able to remember what those limitations were like. For others of us (younger readers), we need a bit of a refresher on what that means. Today's standards for triangle counts are quite high. A first-person weapon can be 30,000 triangles or more. It is not uncommon for characters to have a triangle count of up to 120,000 triangles. However, every bit of extra detail can impact performance. Without normal maps to help us fake detail and decrease these numbers, how can we maintain the level of detail that we need for a high-end environment? A common practice is to delete the polygons on objects in places that the player won't see. How can we do that when the player can see all around our objects?</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Material limitations</h1>
                
            
            
                
<p>Next, let's discuss materials:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f601798a-ccfc-4bb2-88fe-8827484bc665.png" width="1950" height="1058"/></p>
<p>A glimpse of the material editor</p>
<p>The complexity and number of a scene's materials is often the major reason for poor performance in VR. Each material that we apply to a mesh adds a draw call to our game, forcing the computer to work harder each frame. This can result in slower performance and not being able to hit our 90 FPS target. There is also the issue of transparency and reflections. Transparent and translucent materials are a fantastic effect. However, they are costly in VR, as the material has to be reevaluated and redrawn every frame. Reflections are another great effect that helps a world feel more realistic and immersive. Yet, these are also very resource intensive and require complex calculations. </p>


            

            
        
    </div>



  
<div><h1 class="header-title">Lighting limitations</h1>
                
            
            
                
<p>It's now time to look at lighting:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/30f3667d-19fc-41f6-a60e-bae31151b78f.png" width="1926" height="960"/></p>
<p>An example of lighting in UE4</p>
<p>Many modern games make use of dynamic light sources to provide players with a living world. Shadows move as the sun marches across the sky. NPCs cast shadows as they move under street lamps. This type of lighting and shadow help us feel grounded in the world and are an essential part of any game. However, dynamic lighting is very expensive to calculate for every frame. So, how can we use shadows to keep the realism in our virtual worlds?</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Visual Effects (VFX) limitations</h1>
                
            
            
                
<p>Lastly, we come to visual effects:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/2497210e-43fc-4798-a5e0-20fde43adcda.png" width="1950" height="1053"/></p>
<p>Unreal Engine 4 Cascade VFX editor</p>
<p>The right visual effects bring a punch and excitement to many different kinds of games. They are essential in action games. They bring a sense of impact to sports games. They even add to the realism and feel of simulations. Yet, much like dynamic lighting, they are costly when it comes to performance. The limitations on translucent and transparent materials apply here. Making some techniques such as the use of SubUV textures (laying out the frames of an animated particle in a grid) ineffective. Many particles also contain dynamic light sources. </p>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">Performance-boosting techniques</h1>
                
            
            
                
<p>With the player's comfort to consider and all of these limitations, how are designers creating amazing 3D worlds for VR users to step into? The answer can be summed up in the phase <em>fake it till you make it</em>. The technology behind VR is rapidly evolving. New techniques for dealing with the issues we've mentioned are being built into the next generation of game engines. However, for now, there are some best practices currently being used by artists in the industry today to deliver amazing visuals, such as the showdown demo from Epic Games:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7b29d208-bebe-4a58-b174-372d85025d83.png" width="1400" height="746"/></p>
<p>The showdown demo from Epic Games</p>
<p>These guys were able to render this amazing scene at 90 FPS. There is transparency, lighting, and visual effects. The models used are from various other UE4 demos and are not reduced in quality. Here is just some of how they did it.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Static and skeletal mesh techniques</h1>
                
            
            
                
<p>The best way to maximize the success of your VR environment in terms of performance is to approach the scene with a plan and be as conservative as possible. Since the player has the opportunity to scrutinize and interact with the environment more than in a traditional game, VR-ready assets need to be scaled for users of an average height. Meshes must also be manifold. This means ensuring that the object is complete and there are no missing polygons in the mesh, since the player can usually view the object from any angle. Here is an example of a DJ deck that was created for <em>Tribe XR</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/72096641-4865-40cc-9d57-e1786f96f1af.png" style="width:47.67em;height:31.00em;" width="1773" height="1154"/></p>
<p>Pioneer CDJ used in Tribe XR open in Autodesk Maya. This mesh is only 2,001 triangles</p>
<p>In their game <em>Tribe XR</em>, the team planned and focused their VR DJing experience to fit in one room so that they could maximize the ability to create an immersive Sci-Fi environment. Inspired by games such as <em>Overwatch</em> and <em>Team Fortress 2</em>, the lounge they have created has just enough meshes in it to give it that lived-in feel. Each one is placed with purpose to create a relaxed and believable atmosphere. The meshes they used have low polygon/triangle counts, and UV maps are optimized to reduce redundant draw calls. The result is a smooth VR experience that keeps framerates high and players absorbed in the music.</p>
<p>Standard methods of game optimization, such as the use of <strong>Level of Detail</strong> (<strong>LOD</strong>) meshes, is still viable in VR and should still be considered.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Material techniques</h1>
                
            
            
                
<p>As mentioned previously, materials for VR should be planned and designed to minimize the number of draw calls that are required in every frame. Each mesh should incorporate the minimum number of materials to reduce these draw calls. In the showdown demo, Epic Games created many purpose-built props, though some were taken from previous demos, such as the Samaritan demo. The meshes constructed for VR all follow a similar pattern. All are optimized with low triangle counts, and most utilize only one material.</p>
<p>The translucency/transparency is kept to a minimum and only used in a handful of locations, such as the glass in vehicles. The glass in the surrounding buildings has been faked through the texture images that are used. In places where translucency is needed, the DitherTemporalAA material node can be used to make opacity-masked objects look like translucent ones. Here is one example using a rocket smoke trail:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/735777df-dc38-4795-a1d7-644117502651.png" width="1950" height="1269"/></p>
<p>The RocketTrail material from the showdown demo</p>
<p>Specifically, using the DitherTemporalAA node helps eliminate pixel overdraw, and this improves performance.</p>
<p>Finally, we have a powerful tool in helping us fine-tune the materials in our scenes: the Shader Complexity view. Accessed through the View Mode drop-down menu in the viewport, this view shades the scene in greens and reds, with green being less complex and red being more complex. Let's look at this screenshot from the showdown demo:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/25782631-9279-43b8-9f99-62362e425c13.png" width="1932" height="1028"/></p>
<p>The showdown demo with Shader Complexity enabled</p>
<p>Most of the scene is overlayed in green, showing us that there is a minimum number of shader instructions for most objects in the level. Where we see red is the transparent windshield glass and the shaders used on the characters that were taken from the infiltrator demo (these are not optimized for VR).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Lighting techniques</h1>
                
            
            
                
<p>Lighting a level is one of the most resource intensive processes that happens every frame update. When dynamic lights move, it changes shadows, reflections, and scattered light, which all have to be recalculated and redrawn. To compensate for this, Unreal Engine 4 gives the option to bake lightmaps for each object. This creates static lighting by baking the lighting data into a lightmap on each object. Lightmaps can't be as realistic as dynamic lighting, but the performance difference is very dramatic. That isn't to say that dynamic lighting doesn't have a place in VR projects. Dynamic lights may still be used in limited numbers, and they should never touch one another. If the scene you are creating is an outdoor scene, try setting your directional light (sun or moon) to dynamic, and then use cascading shadow maps with the simplest settings you can.</p>
<p>However, the problem with using static lighting is the loss of shadows for your dynamic objects. Things such as the player, enemies, and interactive objects just seem to float within your virtual space, without a shadow to ground them. This gives the space a somewhat-unnatural look. To fix this, we can use a technique that can create a fake blob shadow. We can see it here in the showdown demo:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/1eea53e5-378b-44e2-8486-404ef0da696c.png" width="1944" height="963"/></p>
<p>A static mesh with a fake blob shadow</p>
<p>Finally, reflections can go a long way to giving an area a feeling of complexity and realism. However, real-time reflections use a significant amount of resources and are not well-suited to VR games. In the spirit of <em>fake it till you make it</em>, the designers at Epic Games created the reflection-capture actor. These actors grab reflections from within their areas of influence and encode them into static cube maps. These cube maps can then be used by materials to create and fine-tune reflections in the level. Since these cube maps are created before the game begins, they have very little impact on the level of performance.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Visual effects techniques</h1>
                
            
            
                
<p>If you've done much game development work, whether it is two or three dimensional, then you are aware of the traditional SubUV technique for creating particle effects. This technique involves creating a sprite sheet that represents a particle, such as fire or smoke, and having the game engine animate through the cells. This creates an animated particle that looks three dimensional but is actually a 2D texture. Here is an example of smoke:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5bf52efb-b5f4-4a65-9b10-6ad912934437.png" style="width:36.42em;height:29.17em;" width="1775" height="1422"/></p>
<p>Smoke particle created with the SubUV technique</p>
<p>Your first thought might be that this type of particle would be ideal for VR since we are projecting a smoke particle with a 2D texture. However, since the technique depends on transparency, creating this particle in VR would be tough on our performance. We would also need to consider that players in VR can view the particles from many different angles. Because of this, particles created using the SubUV technique end up looking flat and uninteresting. Designers can work around these issues by focusing on using small meshes as particles and creating effects that are close to the camera:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/93d9392a-24c2-4e7d-b154-d44759f89199.png" width="1940" height="672"/></p>
<p>A VR-friendly particle open in Cascade</p>
<p>In the showdown demo, smoke is used at several points in the level, such as part of the vehicle explosion that flips the car. To minimize the impact on performance, the designers created an animated smoke material that they were able to place on to a 3D ribbon mesh, which is then emitted along with several different types of concrete chunks as part of the effect. When the demo is viewed with the Shader Complexity view enabled, these smoke effects are shown with a green tint, meaning that they are optimized and have little impact on the framerate. This also allowed the designers to deploy these effects near or directly in front of the camera—something that can be done well with SubUV particles.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Measuring ingame performance</h1>
                
            
            
                
<p>Over and over again, I have mentioned-performance as the most important consideration for a VR game. Yet, we have not talked about how to measure performance inside Unreal Engine 4 so that we can know whether we are optimizing well or not. Let's take a look at the tools we have available.</p>
<p>UE4 has an amazing number of performance profiling tools available as part of the game engine, more than I could discuss in this one-quick-start guide. However, I do want to discuss a couple that are relevant to our discussion: the Stat commands and the GPU Visualizer:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/cffc171d-ccae-4367-b1e5-e05d05dcd02e.png" style="width:46.00em;height:29.08em;" width="993" height="628"/></p>
<p>Stat command statistics </p>
<p>There are several Stat commands that can be useful for us to determine our performance. They are accessed by  opening Accessing the console with the tilde key and typing in the following commands (they are not case-sensitive):</p>
<ul>
<li><strong>Stat FPS</strong>: This command brings up the current framerate and the time it takes to render a frame in milliseconds. Remember that our target goal for HTC Vive and Oculus Rift is 90 FPS.</li>
<li><strong>Stat Unit</strong>: Displays in milliseconds the time per frame spent on rendering the frame, game calculations, draw calls, and GPU calculation time.</li>
<li><strong>Stat SceneRendering</strong>: Displays general render time statistics. When performance starts to drop, this panel can show us the culprit.</li>
</ul>
<p>These statistics can help us understand whether our game is CPU bound or GPU bound. Being CPU bound means that our game has too many complex calculations and performance is currently being bottlenecked by the CPU. When our game is GPU bound, it means that we have too many draw calls, lights, or complex visuals, and our performance is being constrained by the graphics processor.</p>
<p>Another simple method of determining whether we are CPU or GPU bound is to lower the graphics quality of the game and take a look at the effects on our framerate. If there is no change to the current FPS, then we are bound to the CPU.</p>
<p>The other tool we have is the GPU Visualizer:</p>
<div><img src="img/59bf5795-5d0c-4c6f-8d87-7c766568b987.png" style="width:27.00em;height:23.92em;" width="1033" height="916"/></div>
<p>The GPU Visualizer</p>
<p>This is a visual interface that allows us to see the GPU cost of the render passes used to draw each frame. Though it may look complicated at first, this interface can show us which visual element or feature is causing the largest drop in performance, as indicated by the feature taking the largest number of milliseconds to render. With that knowledge, we can optimize the specific feature or remove it entirely. For more information on this subject, please refer to the <em>Performance and Profiling</em> section of the Unreal Engine 4 documentation located at <a href="https://docs.unrealengine.com/en-us/Engine/Performance">https://docs.unrealengine.com/en-us/Engine/Performance.</a></p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we learned several of the known causes of performance issues in VR games related to static and skeletal meshes, materials, lighting, and visual effects. After discussing the causes, we explored several different solutions using some examples from the DJ simulation <em>Tribe XR</em> and Epic Games own the cinematic VR demo showdown. Lastly, we discussed methods for profiling our own game performance to determine whether our game is being limited by the CPU or GPU, and how we can use that data to adjust and optimize our application for maximum player comfort.</p>
<p>In the final chapter, we will discuss the importance of game testing in the user experience design process and how to collect that data to make further design decisions. We will also learn how to finalize our game through the cooking process and prepare it for distribution. Finally, we will discuss the importance of everything we learned, how to proceed with the game prototype that we created, and look at further resources for continuing to develop VR applications.</p>


            

            
        
    </div>



  </body></html>