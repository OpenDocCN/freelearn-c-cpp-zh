<html><head></head><body><div><p>&#13;
			<h1 id="_idParaDest-53" class="chapter-number"><a id="_idTextAnchor055"/>3</h1>&#13;
			<h1 id="_idParaDest-54"><a id="_idTextAnchor056"/>Turning the Source File into an Abstract Syntax Tree</h1>&#13;
			<p>As we learned in the previous chapter, a compiler is typically divided into two parts – the frontend and the backend. In this chapter, we will implement the frontend of a programming language – that is, the part that mainly deals with the source language. We will learn about the techniques that real-world compilers use and apply them to our programming languages.</p>&#13;
			<p>Our journey <a id="_idIndexMarker142"/>will begin with us defining our programming language’s grammar and end with an <strong class="bold">abstract syntax tree</strong> (<strong class="bold">AST</strong>), which will become the base for code generation. You can use this approach for every programming language for which you would like to implement a compiler.</p>&#13;
			<p>In this chapter, you will learn about the following:</p>&#13;
			<ul>&#13;
				<li>Defining a real programming language, where you will learn about the <code>tinylang</code> language, which is a subset of a real programming language, and for which you will implement a compiler frontend</li>&#13;
				<li>Organizing the directory structure of a compiler project</li>&#13;
				<li>Knowing how to handle multiple input files for the compiler</li>&#13;
				<li>The skill of handling user messages and informing them of issues in a pleasant manner</li>&#13;
				<li>Building the lexer using modular pieces</li>&#13;
				<li>Constructing a recursive descent parser from the rules derived from a grammar to perform syntax analysis</li>&#13;
				<li>Performing semantic analysis by creating an AST and analyzing its characteristics</li>&#13;
			</ul>&#13;
			<p>With the skills you’ll acquire in this chapter, you’ll be able to build a compiler frontend for any programming language.</p>&#13;
			<h1 id="_idParaDest-55"><a id="_idTextAnchor057"/>Defining a real programming language</h1>&#13;
			<p>Real programming brings up more challenges than the simple calc language from the previous chapter. To have <a id="_idIndexMarker143"/>a look at the details, we will be using a tiny subset of <em class="italic">Modula-2</em> in this and the following chapters. Modula-2 is well-designed and <a id="_idIndexMarker144"/>optionally supports <code>tinylang</code>.</p>&#13;
			<p>Let’s begin with an example of what a program in <code>tinylang</code> looks like. The following function computes the greatest common divisor using the <em class="italic">Euclidean algorithm</em>:</p>&#13;
			<pre class="source-code">&#13;
MODULE Gcd;&#13;
PROCEDURE GCD(a, b: INTEGER) : INTEGER;&#13;
VAR t: INTEGER;&#13;
BEGIN&#13;
  IF b = 0 THEN&#13;
    RETURN a;&#13;
  END;&#13;
  WHILE b # 0 DO&#13;
    t := a MOD b;&#13;
    a := b;&#13;
    b := t;&#13;
  END;&#13;
  RETURN a;&#13;
END GCD;&#13;
END Gcd.</pre>			<p>Now that we have a feeling for how a program in the language looks, let’s take a quick tour of the <code>tinylang</code> subset’s grammar as used in this chapter. In the next few sections, we’ll use this grammar to derive the lexer and the parser from it:</p>&#13;
			<pre class="source-code">&#13;
compilationUnit&#13;
  : "MODULE" identifier ";" ( import )* block identifier "." ;&#13;
Import : ( "FROM" identifier )? "IMPORT" identList ";" ;&#13;
Block&#13;
  : ( declaration )* ( "BEGIN" statementSequence )? "END" ;</pre>			<p>A compilation unit in Modula-2 begins with the <code>MODULE</code> keyword, followed by the name of <a id="_idIndexMarker146"/>the module. The content of a module can have a list of imported modules, declarations, and a block containing statements that run at initialization time:</p>&#13;
			<pre class="source-code">&#13;
declaration&#13;
  : "CONST" ( constantDeclaration ";" )*&#13;
  | "VAR" ( variableDeclaration ";" )*&#13;
  | procedureDeclaration ";" ;</pre>			<p>A declaration introduces constants, variables, and procedures. The declaration of constants is prefixed with the <code>CONST</code> keyword. Similarly, variable declarations begin with the <code>VAR</code> keyword. The declaration of a constant is very simple:</p>&#13;
			<pre class="source-code">&#13;
constantDeclaration : identifier "=" expression ;</pre>			<p>The identifier is the name of the constant. The value is derived from an expression, which must be computable at compile time. The declaration of variables is a bit more complex:</p>&#13;
			<pre class="source-code">&#13;
variableDeclaration : identList ":" qualident ;&#13;
qualident : identifier ( "." identifier )* ;&#13;
identList : identifier ( "," identifier)* ;</pre>			<p>To be able to declare more than one variable in one go, a list of identifiers is used. The type name can potentially come from another module and is prefixed by the module name in this case. This <a id="_idIndexMarker147"/>is called a <strong class="bold">qualified identifier</strong>. A procedure requires the most details:</p>&#13;
			<pre class="source-code">&#13;
procedureDeclaration&#13;
  : "PROCEDURE" identifier ( formalParameters )? ";"&#13;
    block identifier ;&#13;
formalParameters&#13;
  : "(" ( formalParameterList )? ")" ( ":" qualident )? ;&#13;
formalParameterList&#13;
  : formalParameter (";" formalParameter )* ;&#13;
formalParameter : ( "VAR" )? identList ":" qualident ;</pre>			<p>The preceding code shows how constants, variables, and procedures are declared. Procedures <a id="_idIndexMarker148"/>can have parameters and a return type. Normal parameters are passed as values, and <code>VAR</code> parameters are passed by reference. The other part missing from the <code>block</code> rule is <code>statementSequence</code>, which is a list of single statements:</p>&#13;
			<pre class="source-code">&#13;
statementSequence&#13;
  : statement ( ";" statement )* ;</pre>			<p>A statement is delimited by a semicolon if it is followed by another statement. Again, only a subset of the <em class="italic">Modula-2</em> statements is supported:</p>&#13;
			<pre class="source-code">&#13;
statement&#13;
  : qualident ( ":=" expression | ( "(" ( expList )? ")" )? )&#13;
  | ifStatement | whileStatement | "RETURN" ( expression )? ;</pre>			<p>The first part of this rule describes an assignment or a procedure call. A qualified identifier followed by <code>:=</code> is an assignment. If it is followed by <code>(</code>, then it is a procedure call. The other statements are the usual control statements:</p>&#13;
			<pre class="source-code">&#13;
ifStatement&#13;
  : "IF" expression "THEN" statementSequence&#13;
    ( "ELSE" statementSequence )? "END" ;</pre>			<p>The <code>IF</code> statement also has a simplified syntax as it can only have a single <code>ELSE</code> block. With that statement, we can conditionally guard a statement:</p>&#13;
			<pre class="source-code">&#13;
whileStatement&#13;
  : "WHILE" expression "DO" statementSequence "END" ;</pre>			<p>The <code>WHILE</code> statement <a id="_idIndexMarker149"/>describes a loop that’s guarded by a condition. Together with the <code>IF</code> statement, this enables us to write simple algorithms in <code>tinylang</code>. Finally, the definition of an expression is missing:</p>&#13;
			<pre class="source-code">&#13;
expList&#13;
  : expression ( "," expression )* ;&#13;
expression&#13;
  : simpleExpression ( relation simpleExpression )? ;&#13;
relation&#13;
  : "=" | "#" | "&lt;" | "&lt;=" | "&gt;" | "&gt;=" ;&#13;
simpleExpression&#13;
  : ( "+" | "-" )? term ( addOperator term )* ;&#13;
addOperator&#13;
  : "+" | "-" | "OR" ;&#13;
term&#13;
  : factor ( mulOperator factor )* ;&#13;
mulOperator&#13;
  : "*" | "/" | "DIV" | "MOD" | "AND" ;&#13;
factor&#13;
  : integer_literal | "(" expression ")" | "NOT" factor&#13;
  | qualident ( "(" ( expList )? ")" )? ;</pre>			<p>The expression syntax is very similar to that of calc in the previous chapter. Only the <code>INTEGER</code> and <code>BOOLEAN</code> data types are supported.</p>&#13;
			<p>Additionally, the <code>identifier</code> and <code>integer_literal</code> tokens are used. An <code>H</code>.</p>&#13;
			<p>These are already a lot of rules, and we’re only covering a part of Modula-2! Nevertheless, it is possible to write small applications in this subset. Let’s implement a compiler for <code>tinylang</code>!</p>&#13;
			<h1 id="_idParaDest-56"><a id="_idTextAnchor058"/>Creating the project layout</h1>&#13;
			<p>The project layout for <code>tinylang</code> follows the approach we laid out in <a href="B19561_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Installing LLVM</em>. The source code for each component is in a subdirectory of the <code>lib</code> directory, and the <a id="_idIndexMarker152"/>header files are in a subdirectory of <code>include/tinylang</code>. The subdirectory is named after the component. In <a href="B19561_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Installing LLVM</em>, we only created the <code>Basic</code> component.</p>&#13;
			<p>From the previous chapter, we know that we need to implement a lexer, a parser, an AST, and a semantic analyzer. Each is a component of its own, called <code>Lexer</code>, <code>Parser</code>, <code>AST</code>, and <code>Sema</code>, respectively. The directory layout that will be used in this chapter looks like this:</p>&#13;
			<div>&#13;
				<div>&#13;
					<img src="img/B19561_03_1.jpg" alt="Figure 3.1 – The directory layout of the tinylang project" width="205" height="377"/>&#13;
				</p>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – The directory layout of the tinylang project</p>&#13;
			<p>The components <a id="_idIndexMarker153"/>have clearly defined dependencies. <code>Lexer</code> depends only on <code>Basic</code>. <code>Parser</code> depends on <code>Basic</code>, <code>Lexer</code>, <code>AST</code>, and <code>Sema</code>. <code>Sema</code> only depends on <code>Basic</code> and <code>AST</code>. The well-defined dependencies help us reuse the components.</p>&#13;
			<p>Let’s have a closer look at the implementation!</p>&#13;
			<h1 id="_idParaDest-57"><a id="_idTextAnchor059"/>Managing the input files for the compiler</h1>&#13;
			<p>A real compiler has to deal with many files. Usually, the developer calls the compiler with the name <a id="_idIndexMarker154"/>of the main compilation unit. This compilation unit can refer to other files – for example, via <code>#include</code> directives in C or <code>import</code> statements in Python or Modula-2. An imported module can import other modules, and so on. All these files must be loaded into memory and run through the analysis stages of the compiler. During development, a developer may make syntactical or semantical errors. When detected, an error message, including the source line and a marker, should be printed. This essential component is not trivial.</p>&#13;
			<p>Luckily, LLVM comes with a solution: the <code>llvm::SourceMgr</code> class. A new source file is added to <code>SourceMgr</code> with a call to the <code>AddNewSourceBuffer()</code> method. Alternatively, a file can be loaded with a call to the <code>AddIncludeFile()</code> method. Both methods <a id="_idIndexMarker155"/>return an ID to identify the buffer. You can use this ID to retrieve a pointer to the memory buffer of the associated file. To define a location in the file, you can use the <code>llvm::SMLoc</code> class. This class encapsulates a pointer to the buffer. Various <code>PrintMessage()</code> methods allow you to emit errors and other informational messages to the user.</p>&#13;
			<h1 id="_idParaDest-58"><a id="_idTextAnchor060"/>Handling messages for the user</h1>&#13;
			<p>Only a centralized definition of messages is missing. In a large piece of software (such as a compiler), you do not want to sprinkle message strings all over the place. If there is a request to <a id="_idIndexMarker156"/>change messages or translate them into another language, then you better have them in a central place!</p>&#13;
			<p>A simple approach is that each message has an ID (an <code>enum</code> member), a severity level such as <code>Error</code> or <code>Warning</code>, and a string containing the messages. In your code, you only refer to the message ID. The severity level and message string are only used when the message is printed. These three items (the ID, the security level, and the message) must be managed consistently. The LLVM libraries use the preprocessor to solve this. The data is stored in a file with the <code>.def</code> suffix and is wrapped in a macro name. That file is usually included several times, with different definitions for the macro. The definition is in the <code>include/tinylang/Basic/Diagnostic.def</code> file path and looks as follows:</p>&#13;
			<pre class="source-code">&#13;
#ifndef DIAG&#13;
#define DIAG(ID, Level, Msg)&#13;
#endif&#13;
DIAG(err_sym_declared, Error, "symbol {0} already declared")&#13;
#undef DIAG</pre>			<p>The first macro parameter, <code>ID</code>, is the enumeration label, the second parameter, <code>Level</code>, is the severity, and the third parameter, <code>Msg</code>, is the message text. With this definition at hand, we can <a id="_idIndexMarker157"/>define a <code>DiagnosticsEngine</code> class to emit error messages. The interface is in the <code>include/tinylang/Basic/Diagnostic.h</code> file:</p>&#13;
			<pre class="source-code">&#13;
#ifndef TINYLANG_BASIC_DIAGNOSTIC_H&#13;
#define TINYLANG_BASIC_DIAGNOSTIC_H&#13;
#include "tinylang/Basic/LLVM.h"&#13;
#include "llvm/ADT/StringRef.h"&#13;
#include "llvm/Support/FormatVariadic.h"&#13;
#include "llvm/Support/SMLoc.h"&#13;
#include "llvm/Support/SourceMgr.h"&#13;
#include "llvm/Support/raw_ostream.h"&#13;
#include &lt;utility&gt;&#13;
namespace tinylang {</pre>			<p>After including the necessary header files, <code>Diagnostic.def</code> can be used to define the enumeration. To not pollute the global namespace, a nested namespace called <code>diag</code> is used:</p>&#13;
			<pre class="source-code">&#13;
namespace diag {&#13;
enum {&#13;
#define DIAG(ID, Level, Msg) ID,&#13;
#include "tinylang/Basic/Diagnostic.def"&#13;
};&#13;
} // namespace diag</pre>			<p>The <code>DiagnosticsEngine</code> class uses a <code>SourceMgr</code> instance to emit the messages via the <code>report()</code> method. Messages can have parameters. To implement this facility, the variadic-format support provided by LLVM is used. The message text and the severity level are retrieved with the help of the <code>static</code> method. As a bonus, the number of emitted error messages is also counted:</p>&#13;
			<pre class="source-code">&#13;
class DiagnosticsEngine {&#13;
  static const char *getDiagnosticText(unsigned DiagID);&#13;
  static SourceMgr::DiagKind&#13;
  getDiagnosticKind(unsigned DiagID);</pre>			<p>The message <a id="_idIndexMarker158"/>string is returned by <code>getDiagnosticText()</code>, while the level is returned by <code>getDiagnosticKind()</code>. Both methods are later implemented in the <code>.</code><code>cpp</code> file:</p>&#13;
			<pre class="source-code">&#13;
  SourceMgr &amp;SrcMgr;&#13;
  unsigned NumErrors;&#13;
public:&#13;
  DiagnosticsEngine(SourceMgr &amp;SrcMgr)&#13;
      : SrcMgr(SrcMgr), NumErrors(0) {}&#13;
  unsigned nunErrors() { return NumErrors; }</pre>			<p>As messages can have a variable number of parameters, the solution in C++ is to use a variadic template. Of course, this is also used by the <code>formatv()</code> function provided by LLVM. To get the formatted message, we just need to forward the template parameters:</p>&#13;
			<pre class="source-code">&#13;
  template &lt;typename... Args&gt;&#13;
  void report(SMLoc Loc, unsigned DiagID,&#13;
              Args &amp;&amp;... Arguments) {&#13;
    std::string Msg =&#13;
        llvm::formatv(getDiagnosticText(DiagID),&#13;
                      std::forward&lt;Args&gt;(Arguments)...)&#13;
            .str();&#13;
    SourceMgr::DiagKind Kind = getDiagnosticKind(DiagID);&#13;
    SrcMgr.PrintMessage(Loc, Kind, Msg);&#13;
    NumErrors += (Kind == SourceMgr::DK_Error);&#13;
  }&#13;
};&#13;
} // namespace tinylang&#13;
#endif</pre>			<p>With that, we have <a id="_idIndexMarker159"/>implemented most of the class. Only <code>getDiagnosticText()</code> and <code>getDiagnosticKind()</code>are missing. They are defined in the <code>lib/Basic/Diagnostic.cpp</code> file and also make use of the <code>Diagnostic.def</code> file:</p>&#13;
			<pre class="source-code">&#13;
#include "tinylang/Basic/Diagnostic.h"&#13;
using namespace tinylang;&#13;
namespace {&#13;
const char *DiagnosticText[] = {&#13;
#define DIAG(ID, Level, Msg) Msg,&#13;
#include "tinylang/Basic/Diagnostic.def"&#13;
};</pre>			<p>As in the header file, the <code>DIAG</code> macro is defined to retrieve the desired part. Here, we define an array that holds the text messages. Therefore, the <code>DIAG</code> macro only returns the <code>Msg</code> part. We use the same approach for the level:</p>&#13;
			<pre class="source-code">&#13;
SourceMgr::DiagKind DiagnosticKind[] = {&#13;
#define DIAG(ID, Level, Msg) SourceMgr::DK_##Level,&#13;
include "tinylang/Basic/Diagnostic.def"&#13;
};&#13;
} // namespace</pre>			<p>Not surprisingly, both <a id="_idIndexMarker160"/>functions simply index the array to return the desired data:</p>&#13;
			<pre class="source-code">&#13;
const char *&#13;
DiagnosticsEngine::getDiagnosticText(unsigned DiagID) {&#13;
  return DiagnosticText[DiagID];&#13;
}&#13;
SourceMgr::DiagKind&#13;
DiagnosticsEngine::getDiagnosticKind(unsigned DiagID) {&#13;
  return DiagnosticKind[DiagID];&#13;
}</pre>			<p>The combination of the <code>SourceMgr</code> and <code>DiagnosticsEngine</code> classes provides a good basis for the other components. We’ll use them in the lexer first!</p>&#13;
			<h1 id="_idParaDest-59"><a id="_idTextAnchor061"/>Structuring the lexer</h1>&#13;
			<p>As we know <a id="_idIndexMarker161"/>from the previous chapter, we need a <code>Token</code> class and a <code>Lexer</code> class. Additionally, a <code>TokenKind</code> enumeration is required to give each token class a unique number. Having an all-in-one header and implementation file does not scale, so let’s move the items. <code>TokenKind</code> can be used universally and is placed in the <code>Basic</code> component. The <code>Token</code> and <code>Lexer</code> classes belong to the <code>Lexer</code> component but are placed in different headers and implementation files.</p>&#13;
			<p>There are <a id="_idIndexMarker162"/>three <a id="_idIndexMarker163"/>different <a id="_idIndexMarker164"/>classes of tokens: <code>CONST</code> keyword, the<code>;</code> delimiter, and the <code>ident</code> token, respectively, each of which represents identifiers in the source. Each token needs a member name for the enumeration. Keywords and punctuators have natural display names that can be used for messages.</p>&#13;
			<p>Like in many programming languages, the keywords are a subset of the identifiers. To classify a token as a keyword, we need a keyword filter, which checks if the found identifier is indeed a keyword. This is the same behavior as in C or C++, where keywords are also a subset <a id="_idIndexMarker165"/>of identifiers. Programming languages evolve and new keywords may be introduced. As an example, the original K&amp;R C language had no enumerations defined with the <code>enum</code> keyword. Due to this, a flag indicating the language level of a keyword should be present.</p>&#13;
			<p>We collected several pieces of information, all of which belong to a member of the <code>TokenKind</code> enumeration: the label for the enumeration member, the spelling of punctuators, and a flag for keywords. For the diagnostic messages, we centrally store the information in a <code>.def</code> file called <code>include/tinylang/Basic/TokenKinds.def</code>, which looks like this. One thing to note is that keywords are prefixed with <code>kw_</code>:</p>&#13;
			<pre class="source-code">&#13;
#ifndef TOK&#13;
#define TOK(ID)&#13;
#endif&#13;
#ifndef PUNCTUATOR&#13;
#define PUNCTUATOR(ID, SP) TOK(ID)&#13;
#endif&#13;
#ifndef KEYWORD&#13;
#define KEYWORD(ID, FLAG) TOK(kw_ ## ID)&#13;
#endif&#13;
TOK(unknown)&#13;
TOK(eof)&#13;
TOK(identifier)&#13;
TOK(integer_literal)&#13;
PUNCTUATOR(plus,                "+")&#13;
PUNCTUATOR(minus,               "-")&#13;
// …&#13;
KEYWORD(BEGIN                       , KEYALL)&#13;
KEYWORD(CONST                       , KEYALL)&#13;
// …&#13;
#undef KEYWORD&#13;
#undef PUNCTUATOR&#13;
#undef TOK</pre>			<p>With these <a id="_idIndexMarker166"/>centralized definitions, it’s easy to create the <code>TokenKind</code> enumeration in the <code>include/tinylang/Basic/TokenKinds.h</code> file. Again, the enumeration is put into its own namespace, <code>tok</code>:</p>&#13;
			<pre class="source-code">&#13;
#ifndef TINYLANG_BASIC_TOKENKINDS_H&#13;
#define TINYLANG_BASIC_TOKENKINDS_H&#13;
namespace tinylang {&#13;
  namespace tok {&#13;
    enum TokenKind : unsigned short {&#13;
#define TOK(ID) ID,&#13;
#include "TokenKinds.def"&#13;
      NUM_TOKENS&#13;
    };</pre>			<p>The pattern to fill the array should be familiar by now. The <code>TOK</code> macro is defined to only return <code>ID</code>. As a useful addition, we also define <code>NUM_TOKENS</code> as the last member of the enumeration, which denotes the number of defined tokens:</p>&#13;
			<pre class="source-code">&#13;
    const char *getTokenName(TokenKind Kind);&#13;
    const char *getPunctuatorSpelling(TokenKind Kind);&#13;
    const char *getKeywordSpelling(TokenKind Kind);&#13;
  }&#13;
}&#13;
#endif</pre>			<p>The <a id="_idIndexMarker167"/>implementation file, <code>lib/Basic/TokenKinds.cpp</code>, also uses the <code>.def</code> file to retrieve the names:</p>&#13;
			<pre class="source-code">&#13;
#include "tinylang/Basic/TokenKinds.h"&#13;
#include "llvm/Support/ErrorHandling.h"&#13;
using namespace tinylang;&#13;
static const char * const TokNames[] = {&#13;
#define TOK(ID) #ID,&#13;
#define KEYWORD(ID, FLAG) #ID,&#13;
#include "tinylang/Basic/TokenKinds.def"&#13;
  nullptr&#13;
};</pre>			<p>The textual name of a token is derived from its enumeration label, <code>ID</code>. There are two particularities:</p>&#13;
			<ul>&#13;
				<li>First, we need to define the <code>TOK</code> and <code>KEYWORD</code> macros since the default definition of <code>KEYWORD</code> does not use the <code>TOK</code> macro</li>&#13;
				<li>Second, a <code>nullptr</code> value is added at the end of the array, accounting for the added <code>NUM_TOKENS</code> enumeration member:<pre class="source-code">&#13;
const char *tok::getTokenName(TokenKind Kind) {&#13;
  return TokNames[Kind];&#13;
}</pre></li>			</ul>&#13;
			<p>We take a slightly <a id="_idIndexMarker168"/>different approach in the <code>getPunctuatorSpelling()</code> and <code>getKeywordSpelling()</code> functions. These functions only return a meaningful value for a subset of the enumeration. This can be realized with a <code>switch</code> statement, returning a <code>nullptr</code> value by default:</p>&#13;
			<pre class="source-code">&#13;
const char *tok::getPunctuatorSpelling(TokenKind Kind) {&#13;
  switch (Kind) {&#13;
#define PUNCTUATOR(ID, SP) case ID: return SP;&#13;
#include "tinylang/Basic/TokenKinds.def"&#13;
    default: break;&#13;
  }&#13;
  return nullptr;&#13;
}&#13;
const char *tok::getKeywordSpelling(TokenKind Kind) {&#13;
  switch (Kind) {&#13;
#define KEYWORD(ID, FLAG) case kw_ ## ID: return #ID;&#13;
#include "tinylang/Basic/TokenKinds.def"&#13;
    default: break;&#13;
  }&#13;
  return nullptr;&#13;
}</pre>			<p class="callout-heading">Tip</p>&#13;
			<p class="callout">Note how the macros are defined to retrieve the necessary piece of information from the file.</p>&#13;
			<p>In the previous chapter, the <code>Token</code> class was declared in the same header file as the <code>Lexer</code> class. To make <a id="_idIndexMarker169"/>this more versatile, we will put the <code>Token</code> class into its own header file in <code>include/Lexer/Token.h</code>. As before, <code>Token</code> stores a pointer to the start of the token, its length, and the token kind, as defined previously:</p>&#13;
			<pre class="source-code">&#13;
class Token {&#13;
  friend class Lexer;&#13;
  const char *Ptr;&#13;
  size_t Length;&#13;
  tok::TokenKind Kind;&#13;
public:&#13;
  tok::TokenKind getKind() const { return Kind; }&#13;
  size_t getLength() const { return Length; }</pre>			<p>The <code>SMLoc</code> instance, which denotes the source position in messages, is created from the pointer to the token:</p>&#13;
			<pre class="source-code">&#13;
  SMLoc getLocation() const {&#13;
    return SMLoc::getFromPointer(Ptr);&#13;
  }</pre>			<p>The <code>getIdentifier()</code> and <code>getLiteralData()</code> methods allow access to the text of the token for identifiers and literal data. It is not necessary to access the text for any other token type as this is implied by the token type:</p>&#13;
			<pre class="source-code">&#13;
  StringRef getIdentifier() {&#13;
    assert(is(tok::identifier) &amp;&amp;&#13;
           "Cannot get identfier of non-identifier");&#13;
    return StringRef(Ptr, Length);&#13;
  }&#13;
  StringRef getLiteralData() {&#13;
    assert(isOneOf(tok::integer_literal,&#13;
                   tok::string_literal) &amp;&amp;&#13;
           "Cannot get literal data of non-literal");&#13;
    return StringRef(Ptr, Length);&#13;
  }&#13;
};</pre>			<p>We declare the <code>Lexer</code> class in the <code>include/Lexer/Lexer.h</code> header file and put the implementation in the <code>lib/Lexer/lexer.cpp</code> file. The structure is the same as for the calc <a id="_idIndexMarker170"/>language from the previous chapter. We need to take a closer look at two details here:</p>&#13;
			<ul>&#13;
				<li>First, some operators share the same prefix – for example, <code>&lt;</code> and <code>&lt;=</code>. When the current character we look at is <code>&lt;</code>, then we must check the next character before deciding which token we found. Remember that the input needs to end with a null byte. Therefore, the next character can always be used if the current character is valid:<pre class="source-code">&#13;
    case '&lt;':&#13;
      if (*(CurPtr + 1) == '=')&#13;
        formTokenWithChars(token, CurPtr + 2,&#13;
                           tok::lessequal);&#13;
      else&#13;
        formTokenWithChars(token, CurPtr + 1, tok::less);&#13;
      break;</pre></li>				<li>The other detail is that there are far more keywords now. How can we handle this? A simple and fast solution is to populate a hash table with the keywords, which are all stored in the <code>TokenKinds.def</code> file. This can be done during the instantiation of the <code>Lexer</code> class. With this approach, it is also possible to support different <a id="_idIndexMarker171"/>levels of the language as the keywords can be filtered with the attached flag. Here, this flexibility is not needed yet. In the header file, the keyword filter is defined as follows, using an instance of <code>llvm::StringMap</code> for the hash table:<pre class="source-code">&#13;
class KeywordFilter {&#13;
  llvm::StringMap&lt;tok::TokenKind&gt; HashTable;&#13;
  void addKeyword(StringRef Keyword,&#13;
                  tok::TokenKind TokenCode);&#13;
public:&#13;
  void addKeywords();</pre><p class="list-inset">The <code>getKeyword()</code> method returns the token kind of the given string, or a default value if the string does not represent a keyword:</p><pre class="source-code">  tok::TokenKind getKeyword(&#13;
      StringRef Name,&#13;
      tok::TokenKind DefaultTokenCode = tok::unknown) {&#13;
    auto Result = HashTable.find(Name);&#13;
    if (Result != HashTable.end())&#13;
      return Result-&gt;second;&#13;
    return DefaultTokenCode;&#13;
  }&#13;
};</pre><p class="list-inset">In the implementation file, the keyword table is filled:</p><pre class="source-code">void KeywordFilter::addKeyword(StringRef Keyword,&#13;
                               tok::TokenKind TokenCode) {&#13;
  HashTable.insert(std::make_pair(Keyword, TokenCode));&#13;
}&#13;
void KeywordFilter::addKeywords() {&#13;
#define KEYWORD(NAME, FLAGS)                               \&#13;
  addKeyword(StringRef(#NAME), tok::kw_##NAME);&#13;
#include "tinylang/Basic/TokenKinds.def"&#13;
}</pre></li>			</ul>&#13;
			<p>With the <a id="_idIndexMarker172"/>techniques you’ve just learned about, it’s not difficult to write an efficient lexer class. As compilation speed matters, many compilers use a handwritten lexer, with one example being clang.</p>&#13;
			<h1 id="_idParaDest-60"><a id="_idTextAnchor062"/>Constructing a recursive descent parser</h1>&#13;
			<p>As shown <a id="_idIndexMarker173"/>in the previous chapter, the parser is derived from the grammar. Let’s recall all the <em class="italic">construction rules</em>. For each rule of the grammar, you create a method named after the non-terminal on the left-hand side of the rule to parse the right-hand side of the rule. Following the definition of the right-hand side, you do the following:</p>&#13;
			<ul>&#13;
				<li>For each non-terminal, the corresponding method is called</li>&#13;
				<li>Each token is consumed</li>&#13;
				<li>For alternatives and optional or repeating groups, the look-ahead token (the next unconsumed token) is examined to decide where to continue</li>&#13;
			</ul>&#13;
			<p>Let’s apply these construction rules to the following rule of grammar:</p>&#13;
			<pre class="source-code">&#13;
ifStatement&#13;
  : "IF" expression "THEN" statementSequence&#13;
    ( "ELSE" statementSequence )? "END" ;</pre>			<p>We can <a id="_idIndexMarker174"/>easily translate this into the following C++ method:</p>&#13;
			<pre class="source-code">&#13;
void Parser::parseIfStatement() {&#13;
  consume(tok::kw_IF);&#13;
  parseExpression();&#13;
  consume(tok::kw_THEN);&#13;
  parseStatementSequence();&#13;
  if (Tok.is(tok::kw_ELSE)) {&#13;
    advance();&#13;
    parseStatementSequence();&#13;
  }&#13;
  consume(tok::kw_END);&#13;
}</pre>			<p>The whole grammar of <code>tinylang</code> can be turned into C++ in this way. In general, you have to be careful to avoid some pitfalls since most grammars that you will find on the internet are not suitable for this kind of construction.</p>&#13;
			<p class="callout-heading">Grammars and parsers</p>&#13;
			<p class="callout">There are two different types of parsers: top-down parsers and bottom-up parsers. Their names are derived from the order in which a rule is handled during parsing. The input for a parser is the sequence of tokens generated by the lexer.</p>&#13;
			<p class="callout">A top-down <a id="_idIndexMarker175"/>parser expands the leftmost symbol in a rule <a id="_idIndexMarker176"/>until a token is matched. Parsing is successful if all tokens are consumed and all symbols are expanded. This is exactly how the parser for tinylang works.</p>&#13;
			<p class="callout">A bottom-up parser <a id="_idIndexMarker177"/>does the opposite: it looks at the sequence <a id="_idIndexMarker178"/>of tokens and tries to replace the tokens with a symbol of the grammar. For example, if the next tokens are <code>IF</code>, <code>3</code>, <code>+</code>, and <code>4</code>, then a bottom-up parser replaces the <code>3 + 4</code> token with the <code>expression</code> symbol, resulting in the <code>IF</code> <code>expression</code> sequence. When all tokens that belong to the <code>IF</code> statement are seen, then this sequence of tokens and symbols is replaced by the <code>ifStatement</code> symbol.</p>&#13;
			<p class="callout">The parsing is successful if all tokens are consumed and the only symbol left is the start symbol. While top-down parsers can easily be constructed by hand, this is not the case for bottom-up parsers.</p>&#13;
			<p class="callout">A different way to characterize both types of parsers is by which symbols are expanded first. Both read the input from left to right, but a top-down parser expands the leftmost symbol first while a bottom-up parser expands the rightmost symbol. Because of this, a top-down parser is also called an LL parser, while a bottom-up parser is called an LR parser.</p>&#13;
			<p class="callout">A grammar must have certain properties so that either an LL or an LR parser can be derived from it. The grammars are named accordingly: you need an LL grammar to construct an LL parser.</p>&#13;
			<p class="callout">You can find more details in university textbooks about compiler construction, such as Wilhelm, Seidl, and Hack: <em class="italic">Compiler Design. Syntactic and Semantic Analysis</em>, Springer 2013, and Grune and Jacobs: <em class="italic">Parsing Techniques, A practical guide</em>, Springer 2008.</p>&#13;
			<p>One issue to look for is left-recursive rules. A rule is called <strong class="bold">left-recursive</strong> if the right-hand side <a id="_idIndexMarker179"/>begins with the same terminal that’s on the left-hand side. A typical example can be found in grammars for expressions:</p>&#13;
			<pre class="source-code">&#13;
expression : expression "+" term ;</pre>			<p>If it’s not already clear from the grammar, then the translation to C++ makes it obvious that this results in infinite recursion:</p>&#13;
			<pre class="source-code">&#13;
Void Parser::parseExpression() {&#13;
  parseExpression();&#13;
  consume(tok::plus);&#13;
  parseTerm();&#13;
}</pre>			<p>Left recursion <a id="_idIndexMarker180"/>can also occur indirectly and involve more rules, which is much more difficult to spot. That’s why an algorithm exists that can detect and eliminate left recursion.</p>&#13;
			<p class="callout-heading">Note</p>&#13;
			<p class="callout">Left-recursive rules are only a problem for LL parsers, such as the recursive-descent parser for <code>tinylang</code>. The reason is that these parsers expand the leftmost symbol first. In contrast, if you use a parser generator to generate an LR parser, which expands the rightmost symbol first, then you should avoid right-recursive rules.</p>&#13;
			<p>At each step, the parser decides how to continue by just using the look-ahead token. The grammar is said to have conflicts if this decision cannot be made deterministically. To illustrate this, have a look at the <code>using</code> statement in C#. Like in C++, the <code>using</code> statement can be used to make a symbol visible in a namespace, such as in <code>using Math;</code>. It is also possible to define an alias name for the imported symbol with <code>using M = Math;</code>. In a grammar, this can be expressed as follows:</p>&#13;
			<pre class="source-code">&#13;
usingStmt : "using" (ident "=")? ident ";"</pre>			<p>There’s a problem here: after the parser consumes the <code>using</code> keyword, the look-ahead token is <code>ident</code>. However, this information is not enough for us to decide if the optional group must be skipped or parsed. This situation always arises if the set of tokens, with which the optional group can begin, overlaps with the set of tokens that follow the optional group.</p>&#13;
			<p>Let’s rewrite the rule with an alternative instead of an optional group:</p>&#13;
			<pre class="source-code">&#13;
usingStmt : "using" ( ident "=" ident | ident ) ";" ;</pre>			<p>Now, there is a different conflict: both alternatives begin with the same token. Looking only at the look-ahead token, the parser can’t decide which of the alternatives is the right one.</p>&#13;
			<p>These conflicts are very common. Therefore, it’s good to know how to handle them. One approach <a id="_idIndexMarker181"/>is to rewrite the grammar in such a way that the conflict disappears. In the previous example, both alternatives begin with the same token. This can be factored out, resulting in the following rule:</p>&#13;
			<pre class="source-code">&#13;
usingStmt : "using" ident ("=" ident)? ";" ;</pre>			<p>This formulation has no conflict, but it should also be noted that it is less expressive. In the two other formulations, it is obvious which <code>ident</code> is the alias name and which <code>ident</code> is the namespace name. In the conflict-free rule, the leftmost <code>ident</code> changes its role. First, it is the namespace name, but if an equals sign follows, then it turns into the alias name.</p>&#13;
			<p>The second approach is to add a predicate to distinguish between both cases. This predicate, often <a id="_idIndexMarker182"/>called a <code>Token &amp;peek(int n)</code> that returns the <em class="italic">n</em>th token after the current look-ahead token. Here, the existence of an equals sign can be used as an additional predicate in the decision:</p>&#13;
			<pre class="source-code">&#13;
if (Tok.is(tok::ident) &amp;&amp; Lex.peek(0).is(tok::equal)) {&#13;
  advance();&#13;
  consume(tok::equal);&#13;
}&#13;
consume(tok::ident);</pre>			<p>A third approach is to use backtracking. For this, you need to save the current state. Then, you must try to parse the conflicting group. If this does not succeed, then you need to go back to the saved state and try the other path. Here, you are searching for the correct rule to apply, which is not as efficient as the other methods. Therefore, you should only use this approach as a last resort.</p>&#13;
			<p>Now, let’s incorporate error recovery. In the previous chapter, I introduced the so-called <em class="italic">panic mode</em> as a technique for error recovery. The basic idea is to skip tokens until one is found that is suitable for continuing parsing. For example, in <code>tinylang</code>, a statement is followed by a semicolon (<code>:</code>).</p>&#13;
			<p>If there is <a id="_idIndexMarker183"/>a syntax problem in an <code>IF</code> statement, then you skip all tokens until you find a semicolon. Then, you continue with the next statement. Instead of using an ad hoc definition for the token set, it’s better to use a systematic approach.</p>&#13;
			<p>For each non-terminal, you compute the set of tokens that can follow the non-terminal anywhere (called the <code>;</code>, <code>ELSE</code>, and <code>END</code> tokens can follow. So, you must use this set in the error recovery part of <code>parseStatement()</code>. This method assumes that a syntax error can be handled locally. In general, this is not possible. Because the parser skips tokens, so many could be skipped that the end of input is reached. At this point, local recovery is not possible.</p>&#13;
			<p>To prevent meaningless error messages, the calling method needs to be informed that an error recovery is still not finished. This can be done with <code>bool</code>. If it returns <code>true</code>, this means that error recovery hasn’t finished yet, while <code>false</code> means that parsing (including a possible error recovery) was successful.</p>&#13;
			<p>There are numerous ways to extend this error recovery scheme. Using the <code>FOLLOW</code> sets of active callers is a popular approach. As a simple example, assume that <code>parseStatement()</code> was called by <code>parseStatementSequence()</code>, which was itself called by <code>parseBlock()</code> and that from <code>parseModule()</code>.</p>&#13;
			<p>Here, each of the corresponding non-terminals has a <code>FOLLOW</code> set. If the parser detects a syntax error in <code>parseStatement()</code>, then tokens are skipped until the token is in at least one of the <code>FOLLOW</code> sets of the active callers. If the token is in the <code>FOLLOW</code> set of the statement, then the error was recovered locally and a <code>false</code> value is returned to the caller. Otherwise, a <code>true</code> value is returned, meaning that error recovery must continue. A possible implementation strategy for this extension is passing <code>std::bitset</code> or <code>std::tuple</code> to represent the union of the current <code>FOLLOW</code> sets to the callee.</p>&#13;
			<p>One last question is still open: how can we call the error recovery? In the previous chapter, <code>goto</code> was used to jump to the error recovery block. This works but is not a pleasing solution. Given what we discussed earlier, we can skip tokens in a separate method. Clang has a method has <code>skipUntil()</code> for this purpose; we also use this for <code>tinylang</code>.</p>&#13;
			<p>Because the next step is to add semantic actions to the parser, it would also be nice to have a central <a id="_idIndexMarker184"/>place to put cleanup code if necessary. A nested function would be ideal for this. C++ does not have a nested function. Instead, a Lambda function can serve a similar purpose. The <code>parseIfStatement()</code> method, which we looked at initially, looks as follows when the complete error recovery code is added:</p>&#13;
			<pre class="source-code">&#13;
bool Parser::parseIfStatement() {&#13;
  auto _errorhandler = [this] {&#13;
    return skipUntil(tok::semi, tok::kw_ELSE, tok::kw_END);&#13;
  };&#13;
  if (consume(tok::kw_IF))&#13;
    return _errorhandler();&#13;
  if (parseExpression(E))&#13;
    return _errorhandler();&#13;
  if (consume(tok::kw_THEN))&#13;
    return _errorhandler();&#13;
  if (parseStatementSequence(IfStmts))&#13;
    return _errorhandler();&#13;
  if (Tok.is(tok::kw_ELSE)) {&#13;
    advance();&#13;
    if (parseStatementSequence(ElseStmts))&#13;
      return _errorhandler();&#13;
  }&#13;
  if (expect(tok::kw_END))&#13;
    return _errorhandler();&#13;
  return false;&#13;
}</pre>			<p class="callout-heading">Parser and lexer generators</p>&#13;
			<p class="callout">Manually constructing a parser and a lexer can be a tedious task, especially if you try to invent a <a id="_idIndexMarker185"/>new programming <a id="_idIndexMarker186"/>language and change the grammar very often. Luckily, some tools automate this task.</p>&#13;
			<p class="callout">The classic <a id="_idIndexMarker187"/>Linux tools are <strong class="bold">flex</strong> (<a href="https://github.com/westes/flex">https://github.com/westes/flex</a>) and <strong class="bold">bison</strong> (<a href="https://www.gnu.org/software/bison/">https://www.gnu.org/software/bison/</a>). flex generates <a id="_idIndexMarker188"/>a lexer from a set of regular expressions, while bison generates an <strong class="bold">LALR(1)</strong> parser from a grammar description. Both tools generate C/C+ source code and can be used together.</p>&#13;
			<p class="callout">Another popular <a id="_idIndexMarker189"/>tool is <strong class="bold">AntLR</strong> (https://www.antlr.org/). AntLR can generate a lexer, a parser, and an AST from a grammar description. The generated parser belongs to the <strong class="bold">LL(*)</strong> class, which means it is a top-down parser that uses a variable number of lookaheads to solve conflicts. The tool is written in Java but can generate source code for many popular languages, including C/C++.</p>&#13;
			<p class="callout">All these tools require some library support. If you are looking for a tool that generates a self-contained <a id="_idIndexMarker190"/>lexer and parser, then <strong class="bold">Coco/R</strong> (<a href="https://ssw.jku.at/Research/Projects/Coco/">https://ssw.jku.at/Research/Projects/Coco/</a>) may be the tool for you. Coco/R generates a lexer and a recursive-descent parser from an <strong class="bold">LL(1)</strong> grammar description, similar to the one used in this book. The generated files are based on a template file that you can change if needed. The tool is written in C# but ports to C++, Java, and other languages.</p>&#13;
			<p class="callout">There are many other tools available, and they vary a lot in terms of the features and output languages they support. Of course, when choosing a tool, there are also trade-offs to consider. An LALR(1) parser generator such as bison can consume a wide range of grammars, and free grammars you can find on the internet are often LALR(1) grammars.</p>&#13;
			<p class="callout">As a downside, these generators generate a state machine that needs to be interpreted at runtime, which can <a id="_idIndexMarker191"/>be slower than a recursive descent parser. Error handling is also more complicated. bison has basic support for handling syntax errors, but the correct use requires a deep understanding of how the parser works. Compared to this, AntLR consumes a slightly smaller grammar class but automatically generates error handling, and can also generate an AST. So, rewriting grammar so that it can be used with AntLR may speed up development later.</p>&#13;
			<h1 id="_idParaDest-61"><a id="_idTextAnchor063"/>Performing semantic analysis</h1>&#13;
			<p>The parser we constructed in the previous section only checks the syntax of the input. The next step <a id="_idIndexMarker192"/>is to add the ability to perform semantic analysis. In the calc example in the previous chapter, the parser constructed an AST. In a separate phase, the semantic analyzer worked on this tree. This approach can always be used. In this section, we will use a slightly different approach and intertwine the parser and the semantic analyzer more.</p>&#13;
			<p>What does the semantic analyzer need to do? Let’s take a look:</p>&#13;
			<ul>&#13;
				<li>For each declaration, the names of variables, objects, and more must be checked to ensure they have not been declared elsewhere.</li>&#13;
				<li>For each occurrence of a name in an expression or statement, it must be checked that the name is declared and that the desired use fits the declaration.</li>&#13;
				<li>For each expression, the resulting type must be computed. It is also necessary to compute if the expression is constant and if so, which value it has.</li>&#13;
				<li>For assignment and parameter passing, we must check that the types are compatible. Further, we must check that the conditions in <code>IF</code> and <code>WHILE</code> statements are of the <code>BOOLEAN</code> type.</li>&#13;
			</ul>&#13;
			<p>That’s already a lot to check for such a small subset of a programming language!</p>&#13;
			<h2 id="_idParaDest-62"><a id="_idTextAnchor064"/>Handling the scope of names</h2>&#13;
			<p>Let’s have a look at the scope of names first. The scope of a name is the range where the name <a id="_idIndexMarker193"/>is visible. Like C, <code>tinylang</code> uses a declare-before-use model. For example, the <code>B</code> and <code>X</code> variables are declared at the module level to be of the <code>INTEGER</code> type:</p>&#13;
			<pre class="source-code">&#13;
VAR B, X: INTEGER;</pre>			<p>Before the declaration, the variables are not known and cannot be used. That’s only possible after the declaration. Inside a procedure, more variables can be declared:</p>&#13;
			<pre class="source-code">&#13;
PROCEDURE Proc;&#13;
VAR B: BOOLEAN;&#13;
BEGIN&#13;
  (* Statements *)&#13;
END Proc;</pre>			<p>Inside the procedure, at the point where the comment is, a use of <code>B</code> refers to the <code>B</code> local variable while a use of <code>X</code> refers to the <code>X</code> global variable. The scope of the local variable, <code>B</code>, is <code>Proc</code>. If a name cannot be found in the current scope, then the search continues in the enclosing scope. Therefore, the <code>X</code> variable can be used inside the procedure. In <code>tinylang</code>, only modules and procedures open a new scope. Other language constructs, such as structs and classes, usually also open a scope. Predefined entities such as the <code>INTEGER</code> type and the <code>TRUE</code> literal are declared in a global scope, enclosing the scope of the module.</p>&#13;
			<p>In <code>tinylang</code>, only the name is crucial. Therefore, a scope can be implemented as a mapping from a name to its declaration. A new name can only be inserted if it is not already present. For the lookup, the enclosing or parent scope must also be known. The interface (in the <code>include/tinylang/Sema/Scope.h</code> file) looks as follows:</p>&#13;
			<pre class="source-code">&#13;
#ifndef TINYLANG_SEMA_SCOPE_H&#13;
#define TINYLANG_SEMA_SCOPE_H&#13;
#include "tinylang/Basic/LLVM.h"&#13;
#include "llvm/ADT/StringMap.h"&#13;
#include "llvm/ADT/StringRef.h"&#13;
namespace tinylang {&#13;
class Decl;&#13;
class Scope {&#13;
  Scope *Parent;&#13;
  StringMap&lt;Decl *&gt; Symbols;&#13;
public:&#13;
  Scope(Scope *Parent = nullptr) : Parent(Parent) {}&#13;
  bool insert(Decl *Declaration);&#13;
  Decl *lookup(StringRef Name);&#13;
  Scope *getParent() { return Parent; }&#13;
};&#13;
} // namespace tinylang&#13;
#endif</pre>			<p>The implementation <a id="_idIndexMarker194"/>in the <code>lib/Sema/Scope.cpp</code> file looks as follows:</p>&#13;
			<pre class="source-code">&#13;
#include "tinylang/Sema/Scope.h"&#13;
#include "tinylang/AST/AST.h"&#13;
using namespace tinylang;&#13;
bool Scope::insert(Decl *Declaration) {&#13;
  return Symbols&#13;
      .insert(std::pair&lt;StringRef, Decl *&gt;(&#13;
          Declaration-&gt;getName(), Declaration))&#13;
      .second;&#13;
}</pre>			<p>Please note that the <code>StringMap::insert()</code> method does not override an existing entry. The <code>second</code> member of the resulting <code>std::pair</code> indicates if the table was updated. This information is returned to the caller.</p>&#13;
			<p>To implement <a id="_idIndexMarker195"/>the search for the declaration of a symbol, the <code>lookup()</code> method searches in the current scope and, if nothing is found, searches the scopes linked by the <code>parent</code> member:</p>&#13;
			<pre class="source-code">&#13;
Decl *Scope::lookup(StringRef Name) {&#13;
  Scope *S = this;&#13;
  while (S) {&#13;
    StringMap&lt;Decl *&gt;::const_iterator I =&#13;
        S-&gt;Symbols.find(Name);&#13;
    if (I != S-&gt;Symbols.end())&#13;
      return I-&gt;second;&#13;
    S = S-&gt;getParent();&#13;
  }&#13;
  return nullptr;&#13;
}</pre>			<p>The variable declaration is then processed as follows:</p>&#13;
			<ul>&#13;
				<li>The current scope is the module scope.</li>&#13;
				<li>The <code>INTEGER</code> type declaration is looked up. It’s an error if no declaration is found or if it is not a type declaration.</li>&#13;
				<li>A new AST node called <code>VariableDeclaration</code> is instantiated, with the important attributes being the name, <code>B</code>, and the type.</li>&#13;
				<li>The name, <code>B</code>, is inserted into the current scope, mapping to the declaration instance. If the name is already present in the scope, then this is an error. The content of the current scope is not changed in this case.</li>&#13;
				<li>The same is done for the <code>X</code> variable.</li>&#13;
			</ul>&#13;
			<p>Two tasks <a id="_idIndexMarker196"/>are performed here. As in the calc example, AST nodes are constructed. At the same time, attributes of the node, such as the type, are computed. Why is this possible?</p>&#13;
			<p>The semantic analyzer can fall back on two different sets of attributes. The scope is inherited from the caller. The type declaration can be computed (or synthesized) by evaluating the name of the type declaration. The language is designed in such a way that these two sets of attributes are sufficient to compute all attributes of the AST node.</p>&#13;
			<p>An important aspect is the <em class="italic">declare-before-use</em> model. If a language allows the use of names before declaration, such as members inside a class in C++, then it is not possible to compute all attributes of an AST node at once. In such a case, the AST node must be constructed with only partially computed attributes or just with plain information (such as in the calc example).</p>&#13;
			<p>The AST must then be visited one or more times to determine the missing information. In the case of <code>tinylang</code> (and Modula-2), it would be possible to dispense with the AST construction – the AST is indirectly represented through the call hierarchy of the <code>parseXXX()</code> methods. Code generation from an AST is much more common, so we construct an AST here, too.</p>&#13;
			<p>Before we <a id="_idIndexMarker197"/>put the pieces together, we need to understand the LLVM style of using <strong class="bold">runtime type </strong><strong class="bold">information</strong> (<strong class="bold">RTTI</strong>).</p>&#13;
			<h2 id="_idParaDest-63"><a id="_idTextAnchor065"/>Using an LLVM-style RTTI for the AST</h2>&#13;
			<p>Naturally, the AST nodes are a part of a class hierarchy. A declaration always has a name. Other <a id="_idIndexMarker198"/>attributes depend on what is being declared. If a variable is declared, then a type is required. A constant declaration needs a type, a value, and so on. Of course, at runtime, you need to find out which kind of declaration you are working with. The <code>dynamic_cast&lt;&gt;</code> C++ operator could be used for this. The problem is that the required RTTI is only available if the C++ class has a virtual table attached – that is, it uses virtual functions. Another disadvantage is that C++ RTTI is bloated. To avoid these disadvantages, the LLVM developers introduced a self-made RTTI style, which is used throughout the LLVM libraries.</p>&#13;
			<p>The (abstract) base class of our hierarchy is <code>Decl</code>. To implement the LLVM-style RTTI, a public enumeration containing a label for each subclass must be added. Also, a private member of this type and a public getter are required. The private member is usually called <code>Kind</code>. In our case, this looks as follows:</p>&#13;
			<pre class="source-code">&#13;
class Decl {&#13;
public:&#13;
  enum DeclKind { DK_Module, DK_Const, DK_Type,&#13;
                  DK_Var, DK_Param, DK_Proc };&#13;
private:&#13;
  const DeclKind Kind;&#13;
public:&#13;
  DeclKind getKind() const { return Kind; }&#13;
};</pre>			<p>Each subclass now needs a special function member called <code>classof</code>. The purpose of this function is to determine if a given instance is of the requested type. For <code>VariableDeclaration</code>, it is implemented as follows:</p>&#13;
			<pre class="source-code">&#13;
static bool classof(const Decl *D) {&#13;
  return D-&gt;getKind() == DK_Var;&#13;
}</pre>			<p>Now, you can use the special templates, <code>llvm::isa&lt;&gt;</code>, to check if an object is of the requested <a id="_idIndexMarker199"/>type and <code>llvm::dyn_cast&lt;&gt;</code> to dynamically cast the object. More templates exist, but these two are the most commonly used ones. For the other templates, see <a href="https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates">https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates</a> and for more information about the LLVM style, including more advanced uses, see <a href="https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html">https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html</a>.</p>&#13;
			<h2 id="_idParaDest-64"><a id="_idTextAnchor066"/>Creating the semantic analyzer</h2>&#13;
			<p>Equipped <a id="_idIndexMarker200"/>with this knowledge, we can now implement all the parts. First, we must create the definition of the AST node for a variable that’s stored in the <code>include/llvm/tinylang/AST/AST.h</code> file. Besides support for the LLVM-style RTTI, the base class stores the name of the declaration, the location of the name, and a pointer to the enclosing declaration. The latter is required during code generation of nested procedures. The <code>Decl</code> base class is declared as follows:</p>&#13;
			<pre class="source-code">&#13;
class Decl {&#13;
public:&#13;
  enum DeclKind { DK_Module, DK_Const, DK_Type,&#13;
                  DK_Var, DK_Param, DK_Proc };&#13;
private:&#13;
  const DeclKind Kind;&#13;
protected:&#13;
  Decl *EnclosingDecL;&#13;
  SMLoc Loc;&#13;
  StringRef Name;&#13;
public:&#13;
  Decl(DeclKind Kind, Decl *EnclosingDecL, SMLoc Loc,&#13;
       StringRef Name)&#13;
      : Kind(Kind), EnclosingDecL(EnclosingDecL), Loc(Loc),&#13;
        Name(Name) {}&#13;
  DeclKind getKind() const { return Kind; }&#13;
  SMLoc getLocation() { return Loc; }&#13;
  StringRef getName() { return Name; }&#13;
  Decl *getEnclosingDecl() { return EnclosingDecL; }&#13;
};</pre>			<p>The declaration <a id="_idIndexMarker201"/>for a variable only adds a pointer to the type declaration:</p>&#13;
			<pre class="source-code">&#13;
class TypeDeclaration;&#13;
class VariableDeclaration : public Decl {&#13;
  TypeDeclaration *Ty;&#13;
public:&#13;
  VariableDeclaration(Decl *EnclosingDecL, SMLoc Loc,&#13;
                      StringRef Name, TypeDeclaration *Ty)&#13;
      : Decl(DK_Var, EnclosingDecL, Loc, Name), Ty(Ty) {}&#13;
  TypeDeclaration *getType() { return Ty; }&#13;
  static bool classof(const Decl *D) {&#13;
    return D-&gt;getKind() == DK_Var;&#13;
  }&#13;
};</pre>			<p>The method <a id="_idIndexMarker202"/>in the parser needs to be extended with a semantic action and variables for collected information:</p>&#13;
			<pre class="source-code">&#13;
bool Parser::parseVariableDeclaration(DeclList &amp;Decls) {&#13;
  auto _errorhandler = [this] {&#13;
    while (!Tok.is(tok::semi)) {&#13;
      advance();&#13;
      if (Tok.is(tok::eof)) return true;&#13;
    }&#13;
    return false;&#13;
  };&#13;
  Decl *D = nullptr; IdentList Ids;&#13;
  if (parseIdentList(Ids)) return _errorhandler();&#13;
  if (consume(tok::colon)) return _errorhandler();&#13;
  if (parseQualident(D)) return _errorhandler();&#13;
  Actions.actOnVariableDeclaration(Decls, Ids, D);&#13;
  return false;&#13;
}</pre>			<p><code>DeclList</code> is a list of declarations, <code>std::vector&lt;Decl*&gt;</code>, and <code>IdentList</code> is a list of locations and identifiers, <code>std::vector&lt;std::pair&lt;SMLoc, StringRef&gt;&gt;</code>.</p>&#13;
			<p>The <code>parseQualident()</code> method returns a declaration, which in this case is expected to be a type declaration.</p>&#13;
			<p>The parser class knows an instance of the semantic analyzer class, <code>Sema</code>, that’s stored in the <code>Actions</code> member. A call to <code>actOnVariableDeclaration()</code> runs the semantic analyzer <a id="_idIndexMarker203"/>and the AST construction. The implementation is in the <code>lib/Sema/Sema.cpp</code> file:</p>&#13;
			<pre class="source-code">&#13;
void Sema::actOnVariableDeclaration(DeclList &amp;Decls,&#13;
                                    IdentList &amp;Ids,&#13;
                                    Decl *D) {&#13;
  if (TypeDeclaration *Ty = dyn_cast&lt;TypeDeclaration&gt;(D)) {&#13;
    for (auto &amp;[Loc, Name] : Ids) {&#13;
      auto *Decl = new VariableDeclaration(CurrentDecl, Loc,&#13;
                                           Name, Ty);&#13;
      if (CurrentScope-&gt;insert(Decl))&#13;
        Decls.push_back(Decl);&#13;
      else&#13;
        Diags.report(Loc, diag::err_symbold_declared, Name);&#13;
    }&#13;
  } else if (!Ids.empty()) {&#13;
    SMLoc Loc = Ids.front().first;&#13;
    Diags.report(Loc, diag::err_vardecl_requires_type);&#13;
  }&#13;
}</pre>			<p>The type declaration is checked with <code>llvm::dyn_cast&lt;TypeDeclaration&gt;</code>. If it is not a type declaration, then an error message is printed. Otherwise, for each name in the <code>Ids</code> list, <code>VariableDeclaration</code> is instantiated and added to the list of declarations. If adding the variable to the current scope fails because the name is already declared, then an error message is printed as well.</p>&#13;
			<p>Most of the other entities are constructed in the same way – the complexity of the semantic analysis is the only difference. More work is required for modules and procedures because they open a new scope. Opening a new scope is easy: only a new <code>Scope</code> object must be instantiated. As soon as the module or procedure has been parsed, the scope must be removed.</p>&#13;
			<p>This must be <a id="_idIndexMarker204"/>done reliably because we do not want to add names to the wrong scope in case of a syntax error. This is a classic use of the <strong class="bold">Resource Acquisition Is Initialization</strong> (<strong class="bold">RAII</strong>) idiom in C++. Another complication comes from <a id="_idIndexMarker205"/>the fact that a procedure can recursively call itself. Therefore, the name of the procedure must be added to the current scope before it can be used. The semantic analyzer has two methods to enter and leave a scope. The scope is associated with a declaration:</p>&#13;
			<pre class="source-code">&#13;
void Sema::enterScope(Decl *D) {&#13;
  CurrentScope = new Scope(CurrentScope);&#13;
  CurrentDecl = D;&#13;
}&#13;
void Sema::leaveScope() {&#13;
  Scope *Parent = CurrentScope-&gt;getParent();&#13;
  delete CurrentScope;&#13;
  CurrentScope = Parent;&#13;
  CurrentDecl = CurrentDecl-&gt;getEnclosingDecl();&#13;
}</pre>			<p>A simple helper class is used to implement the RAII idiom:</p>&#13;
			<pre class="source-code">&#13;
class EnterDeclScope {&#13;
  Sema &amp;Semantics;&#13;
public:&#13;
  EnterDeclScope(Sema &amp;Semantics, Decl *D)&#13;
      : Semantics(Semantics) {&#13;
    Semantics.enterScope(D);&#13;
  }&#13;
  ~EnterDeclScope() { Semantics.leaveScope(); }&#13;
};</pre>			<p>When parsing <a id="_idIndexMarker206"/>a module or procedure, two interactions occur with the semantic analyzer. The first is after the name is parsed. Here, the (almost empty) AST node is constructed and a new scope is established:</p>&#13;
			<pre class="source-code">&#13;
bool Parser::parseProcedureDeclaration(/* … */) {&#13;
  /* … */&#13;
  if (consume(tok::kw_PROCEDURE)) return _errorhandler();&#13;
  if (expect(tok::identifier)) return _errorhandler();&#13;
  ProcedureDeclaration *D =&#13;
      Actions.actOnProcedureDeclaration(&#13;
          Tok.getLocation(), Tok.getIdentifier());&#13;
  EnterDeclScope S(Actions, D);&#13;
  /* … */&#13;
}</pre>			<p>The semantic analyzer checks the name in the current scope and returns the AST node:</p>&#13;
			<pre class="source-code">&#13;
ProcedureDeclaration *&#13;
Sema::actOnProcedureDeclaration(SMLoc Loc, StringRef Name) {&#13;
  ProcedureDeclaration *P =&#13;
      new ProcedureDeclaration(CurrentDecl, Loc, Name);&#13;
  if (!CurrentScope-&gt;insert(P))&#13;
    Diags.report(Loc, diag::err_symbold_declared, Name);&#13;
  return P;&#13;
}</pre>			<p>The real work is done after all the declarations and the procedure body have been parsed. You only need to check if the name at the end of the procedure declaration is equal to the <a id="_idIndexMarker207"/>name of the procedure and if the declaration used for the return type is a type declaration:</p>&#13;
			<pre class="source-code">&#13;
void Sema::actOnProcedureDeclaration(&#13;
    ProcedureDeclaration *ProcDecl, SMLoc Loc,&#13;
    StringRef Name, FormalParamList &amp;Params, Decl *RetType,&#13;
    DeclList &amp;Decls, StmtList &amp;Stmts) {&#13;
  if (Name != ProcDecl-&gt;getName()) {&#13;
    Diags.report(Loc, diag::err_proc_identifier_not_equal);&#13;
    Diags.report(ProcDecl-&gt;getLocation(),&#13;
                 diag::note_proc_identifier_declaration);&#13;
  }&#13;
  ProcDecl-&gt;setDecls(Decls);&#13;
  ProcDecl-&gt;setStmts(Stmts);&#13;
  auto *RetTypeDecl =&#13;
      dyn_cast_or_null&lt;TypeDeclaration&gt;(RetType);&#13;
  if (!RetTypeDecl &amp;&amp; RetType)&#13;
    Diags.report(Loc, diag::err_returntype_must_be_type,&#13;
                 Name);&#13;
  else&#13;
    ProcDecl-&gt;setRetType(RetTypeDecl);&#13;
}</pre>			<p>Some declarations are inherently present and cannot be defined by the developer. This includes the <code>BOOLEAN</code> and <code>INTEGER</code> types and the <code>TRUE</code> and <code>FALSE</code> literals. These declarations exist in the global scope and must be added programmatically. Modula-2 also predefines <a id="_idIndexMarker208"/>some procedures, such as <code>INC</code> or <code>DEC</code>, that can be added to the global scope. Given our classes, initializing the global scope is simple:</p>&#13;
			<pre class="source-code">&#13;
void Sema::initialize() {&#13;
  CurrentScope = new Scope();&#13;
  CurrentDecl = nullptr;&#13;
  IntegerType =&#13;
      new TypeDeclaration(CurrentDecl, SMLoc(), "INTEGER");&#13;
  BooleanType =&#13;
      new TypeDeclaration(CurrentDecl, SMLoc(), "BOOLEAN");&#13;
  TrueLiteral = new BooleanLiteral(true, BooleanType);&#13;
  FalseLiteral = new BooleanLiteral(false, BooleanType);&#13;
  TrueConst = new ConstantDeclaration(CurrentDecl, SMLoc(),&#13;
                                      "TRUE", TrueLiteral);&#13;
  FalseConst = new ConstantDeclaration(&#13;
      CurrentDecl, SMLoc(), "FALSE", FalseLiteral);&#13;
  CurrentScope-&gt;insert(IntegerType);&#13;
  CurrentScope-&gt;insert(BooleanType);&#13;
  CurrentScope-&gt;insert(TrueConst);&#13;
  CurrentScope-&gt;insert(FalseConst);&#13;
}</pre>			<p>With this scheme, all required calculations for <code>tinylang</code> can be done. For example, let’s look at how to compute if an expression results in a constant value:</p>&#13;
			<ul>&#13;
				<li>We must ensure literal or a reference to a constant declaration is a constant</li>&#13;
				<li>If both sides of an expression are constant, then applying the operator also yields a constant</li>&#13;
			</ul>&#13;
			<p>These rules are embedded into the semantic analyzer while creating the AST nodes for an expression. Likewise, the type and the constant value can be computed.</p>&#13;
			<p>It should be <a id="_idIndexMarker209"/>noted that not all kinds are computation can be done in this way. For example, to detect the use of uninitialized variables, a method called <em class="italic">symbolic interpretation</em> can be used. In its general form, the method requires a special walk order through the AST, which is not possible during construction time. The good news is that the presented approach creates a fully decorated AST that is ready for code generation. This AST can be used for further analysis, given that costly analysis can be turned on or off on demand.</p>&#13;
			<p>To play around with the frontend, you also need to update the driver. Since the code generation is missing, a correct <code>tinylang</code> program produces no output. Still, it can be used to explore error recovery and provoke semantic errors:</p>&#13;
			<pre class="source-code">&#13;
#include "tinylang/Basic/Diagnostic.h"&#13;
#include "tinylang/Basic/Version.h"&#13;
#include "tinylang/Parser/Parser.h"&#13;
#include "llvm/Support/InitLLVM.h"&#13;
#include "llvm/Support/raw_ostream.h"&#13;
using namespace tinylang;&#13;
int main(int argc_, const char **argv_) {&#13;
  llvm::InitLLVM X(argc_, argv_);&#13;
  llvm::SmallVector&lt;const char *, 256&gt; argv(argv_ + 1,&#13;
                                            argv_ + argc_);&#13;
  llvm::outs() &lt;&lt; "Tinylang "&#13;
               &lt;&lt; tinylang::getTinylangVersion() &lt;&lt; "\n";&#13;
  for (const char *F : argv) {&#13;
    llvm::ErrorOr&lt;std::unique_ptr&lt;llvm::MemoryBuffer&gt;&gt;&#13;
        FileOrErr = llvm::MemoryBuffer::getFile(F);&#13;
    if (std::error_code BufferError =&#13;
            FileOrErr.getError()) {&#13;
      llvm::errs() &lt;&lt; "Error reading " &lt;&lt; F &lt;&lt; ": "&#13;
                   &lt;&lt; BufferError.message() &lt;&lt; "\n";&#13;
      continue;&#13;
    }&#13;
    llvm::SourceMgr SrcMgr;&#13;
    DiagnosticsEngine Diags(SrcMgr);&#13;
    SrcMgr.AddNewSourceBuffer(std::move(*FileOrErr),&#13;
                              llvm::SMLoc());&#13;
    auto TheLexer = Lexer(SrcMgr, Diags);&#13;
    auto TheSema = Sema(Diags);&#13;
    auto TheParser = Parser(TheLexer, TheSema);&#13;
    TheParser.parse();&#13;
  }&#13;
}</pre>			<p>Congratulations! You’ve finished implementing the frontend for <code>tinylang</code>! You can use the example program, <code>Gcd.mod</code>, provided in the <em class="italic">Defining a real programming language</em> section to run the frontend:</p>&#13;
			<pre class="console">&#13;
$ tinylang Gcd.mod</pre>			<p>Of course, this is <a id="_idIndexMarker210"/>a valid program, and it looks like nothing happens. Be sure to modify the file and provoke some error messages. We’ll continue with the fun in the next chapter by adding code generation.</p>&#13;
			<h1 id="_idParaDest-65"><a id="_idTextAnchor067"/>Summary</h1>&#13;
			<p>In this chapter, you learned about the techniques that a real-world compiler uses in the frontend. Starting with the project layout, you created separate libraries for the lexer, the parser, and the semantic analyzer. To output messages to the user, you extended an existing LLVM class, allowing the messages to be stored centrally. The lexer is now separated into several interfaces.</p>&#13;
			<p>Then, you learned how to construct a recursive descent parser from a grammar description, looked at what pitfalls to avoid, and learned how to use generators to do the job. The semantic analyzer you constructed performs all the semantic checks required by the language while being intertwined with the parser and AST construction.</p>&#13;
			<p>The result of your coding effort is a fully decorated AST. You’ll use this in the next chapter to generate IR code and, finally, object code.s</p>&#13;
		</div>&#13;
	</div></body></html>