- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Moving Animation Calculations from CPU to GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to *Chapter 2*! In the previous chapter, we explored the steps to load
    and animate a 3D model by using Open Assimp Import Library, or Assimp for short.
    The resulting application can render a large number of model instances. But, depending
    on your processor type and speed, the computational part for the model matrices
    becomes dominant quite fast. As a consequence, we are no longer able to reach
    60 frames per second in the application.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we move the matrix calculations to compute shaders, running
    entirely on the GPU. We start with a short history of methods to do computations
    that are independent of the main code of the application, and the growth of parallelism
    in CPUs and GPUs. Next, we examine the current state of the matrix calculations.
    Then, we create a plan for what we should move to a compute shader, and how this
    relocation could be accomplished. As the last step, we check the results of the
    relocation and take a short look at which other parts of the application could
    possibly take advantage of offloading compute-intense work.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What are compute shaders and why should we love them?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling animation performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving the node computations to the GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the implementation by scaling up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to debug a compute shader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use compute shaders, a GPU supporting at least OpenGL 4.3 and/or Vulkan 1.0
    is required. Since the source code for the book is written for OpenGL 4.6 and
    Vulkan 1.1, we are safe here.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the example code in the folder `chapter02`, subfolders `01_opengl_computeshader`
    for OpenGL, and `02_vulkan_computeshader` for Vulkan.
  prefs: []
  type: TYPE_NORMAL
- en: What are compute shaders and why should we love them?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s take a short look at the history of home computers to see how concurrency
    was handled. On servers, concurrent programs have been the norm since the mid-1960s
    but for home computers and game consoles, the evolution is a bit different.
  prefs: []
  type: TYPE_NORMAL
- en: The famous raster interrupt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the general idea of interrupts has existed in computer systems since
    the beginning of computers, interrupts in home computers were normally used by
    the operating system to react to external events (though the first machines with
    interrupts were introduced in the 1950s). One of these interrupts signaled the
    beginning of a new picture to output to old “cathode-ray tube” TV sets: the raster
    interrupt.'
  prefs: []
  type: TYPE_NORMAL
- en: The raster interrupt fired after the cathode ray was reset to the top left of
    the TV set. This steady event, occurring 50 times per second (in the EU; 60 times
    per second in the US), became a point of interest for programmers really quickly.
    By redirecting the interrupt handler to their own code, the machine could do work
    that needed to be done to a fixed time schedule, like playing music or graphic
    changes that should happen at a specific location on the screen. These programs
    embraced the capabilities of home computers even more than the architects of the
    machines could have imagined, like adding more sprites to the screen than the
    machine had available, drawing sprites inside of screen borders, raster bars,
    or even a simple form of multitasking on 8-bit CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Up to this day, retro coders do even more magic with old home computers. See
    the *Additional resources* section for links to demos plus tutorials on how the
    limitations of hardware were embraced over time.
  prefs: []
  type: TYPE_NORMAL
- en: Then, for a long time, nothing special happened. The era of 8- and 16-bit home
    computers ended, and x86 machines took over. However, the general system layout
    stayed the same – one processor core using time-sharing via interrupts to present
    the illusion of having multiple programs running at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: The rise of multi-core machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the start of the year 2000, common desktop machines became capable of working
    with multiple CPU cores: Windows 2000 was introduced (Linux was able to utilize
    more than one CPU for a long time, but it was a niche system on desktops in 2000).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Five years later, the first processors with more than one computational core
    were available for desktop users: Pentium D and AMD 64 X2\. These new CPUs were
    seen as the start of a new era in programming, since more than one process could
    run at the same time. That was also the start of an era of headaches for programmers
    – two threads could really run in parallel, requiring new thinking about synchronization.'
  prefs: []
  type: TYPE_NORMAL
- en: Right now, the average CPU core count of a desktop machine is between 4 and
    8\. Taking into account the simultaneous multithreading of modern CPUs, many desktop
    machines can even handle between 28 and 32 threads in parallel. Sadly, the headaches
    for programmers are the same as 20 years ago – utilizing a large number of cores
    is still a complex and error-prone process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Behind the scenes, another technology with an even more massive number of cores
    evolved: graphics processors.'
  prefs: []
  type: TYPE_NORMAL
- en: Hidden multi-core champions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the shadows of processor core upgrades, graphics cards also raised the number
    of parallel cores. They did this on even larger scales. Starting with only a couple
    of shader cores in 2009 and 2010, the growth in numbers is insane:'
  prefs: []
  type: TYPE_NORMAL
- en: A NVIDIA GeForce RTX 4090 has a whopping 16,384 shader cores, and an AMD Radeon
    RX 7900 XTX has 6,144 shader cores.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two numbers can’t be compared directly due to internal differences between
    these two GPUs, but the raw numbers show one thing: If we were able to use some
    of the shader cores to calculate our model matrices for the animation frames,
    the computation would be a lot faster. At the same time, our CPU would have less
    work to do, enabling us to do other tasks while the GPU calculates the model matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to graphics API designers and GPU vendors, using these shader cores
    is as easy as writing a small, C-like program: a compute shader.'
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the wonderful world of compute shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Up to OpenGL 4.2, doing computations on the GPU was already possible by utilizing
    the other shader types, like vertex and fragment shaders. Similar to uploading
    arbitrary data to the GPU via texture buffer objects, shaders could be used to
    do massive parallel computations, saving the results into a texture buffer. The
    final texture could be read back to the CPU-accessible memory – et voila: the
    GPU helped us do some expensive calculations.'
  prefs: []
  type: TYPE_NORMAL
- en: With the introduction of OpenGL 4.3, this process was simplified by officially
    adding compute shaders and **shader storage buffer objects** (**SSBOs**). In Vulkan
    1.0, the support for compute shaders and SSBOs was already mandatory, bringing
    the new graphics API to par with OpenGL 4.3+.
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of SSBOs are great: shaders can read and write to an SSBO, unlike
    read-only uniform buffers. The general access to an SSBO is simplified too, as
    it has no hard-limited maximum size. Combined with slightly different padding
    for `float` and `vec2` data types, getting or setting a value in an SSBO is simple,
    like using a C-style array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: On the other hand, with compute shaders, you get full control of the number
    of shader instances you want to start. The overall number of shader invocations
    depends on the setting in the compute shader and the dispatch call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we use the following compute shader settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, run this OpenGL dispatch call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It means we will send a request to start 51,200 instances of the shader to
    the GPU driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: For more details about compute shaders, links to tutorials for OpenGL and Vulkan
    are available in the *Additional resources* section.
  prefs: []
  type: TYPE_NORMAL
- en: While there are some additional limitations, like the number of shader cores
    used together for the sake of simplified internal management (called a wave on
    AMD GPUs, and a warp on NVIDIA GPUs), the number of invocations shows the user-friendly
    usage of compute shaders.
  prefs: []
  type: TYPE_NORMAL
- en: You, the programmer, don’t need to care about spawning a massive number of threads
    in the code or joining them at the end of the program. Also, there is no need
    to create mutexes, or atomic variables, to control access to the data. All these
    steps are firmly hidden from your eyes in the depths of the graphics driver.
  prefs: []
  type: TYPE_NORMAL
- en: Though you are not free of obligations – you still have to make sure only a
    single shader invocation reads or writes a single buffer address. But, with the
    help of the control variables set by the GPU, like the global and local invocation
    IDs, this part is also easy – a lot easier compared to the efforts needed for
    manual multi-threading on the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we use the magic of the compute shaders in our program? The first
    step here is to analyze the hotspots in the code and to create a plan for how
    the same data could be computed on the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling animation performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To test the performance of the application on your system, you can import the
    test model named `Woman.gltf` in the `woman` subfolder of the `assets` folder,
    move the slider next to the **Create Multiple Instances** button to 100, and click
    the button **Create Multiple Instances** several times. Every click will add another
    100 instances of the model, distributed randomly across the virtual world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Or, you can change the code for the instance slider in the `createFrame()`
    method of the `UserInterface` class in the `opengl` folder. Adjust the fourth
    parameter of the call, controlling the maximum value of the slider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After you add a couple of hundreds of instances, you should see a picture similar
    to *Figure 2.1*. The **Timers** section of the user interface has been zoomed
    into to show the values for the time it takes to generate the model matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Model matrix generation time with 1,601 instances on the screen'
  prefs: []
  type: TYPE_NORMAL
- en: Here, the 1,601 instances require more than 20 milliseconds to create the model
    matrices – which is still a small value, if we calculate the raw numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each model has 41 animated bones. For each of the bones, two values for each
    of the **translation, rotation, and scale** (**TRS**) are read in every frame.
    These values are mixed together by linear interpolation for translation and scale,
    and **spherical linear interpolation** (**SLERP**) for rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'On top of these nearly 400,000 vector multiplications, every bone needs the
    resulting TRS matrix created, multiplied by the parent matrix. Every matrix multiplication
    consists of 16 float multiplications, so we have another ~100,000 multiplications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: That’s quite a large amount of work to be done for the CPU in every single frame.
    These numbers are also reflected in the profiling outputs for Windows and Linux.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s verify the assumption about the workload of the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Locating the hotspots in the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By using the built-in profiler of Visual Studio 2022, we see the function calls
    for the animations and the matrix multiplications among the functions with the
    most execution time spent inside a single function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Animation calls in Visual Studio 2022 profiling'
  prefs: []
  type: TYPE_NORMAL
- en: 'After compiling the executable on Linux with the extra flag `-pg`, running
    the application, and starting `gprof`, the result is similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Animation calls in Linux profiling'
  prefs: []
  type: TYPE_NORMAL
- en: The vast amount of CPU time is needed to calculate the new translation, rotation,
    scaling, and model matrices for every node. So, let’s check how to change the
    data representation to allow a simple upload to a compute shader.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the current data representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the current implementation, the matrix work is done in the `updateAnimation()`
    method of the `AssimpInstance` class. For every frame the renderer draws to the
    screen, the following steps must be done:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we loop over all animation channels, getting the corresponding node
    of the model and updating the translation, scaling, and rotation of every node
    with the bone-local transforms from the animation data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we iterate over all bones, and update the TRS matrix of every node, calculating
    the node-local transforms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The TRS matrix update of a node includes the multiplication by the parent node
    TRS matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can collect the final TRS matrix for the nodes, and multiply
    it by the corresponding bone offset node, generating the `mBoneMatrices` vector
    containing the world position for every node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The extra `.count()` check for the bone offset matrices is done to avoid accessing
    an invalid matrix. The bone offset matrix should be valid for every node that
    is part of the animation, but it’s better to be safe than sorry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, in the `draw()` call of our renderer, i.e., in the `OGLRenderer` class,
    the animation is updated for every instance. After the animation update, the `mBoneMatrices`
    vector is retrieved and added to a local `mBoneMatrices` vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the next step, the local `mBoneMatrices` vector will be uploaded into the
    SSBO buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `assimp_skinning.vert` vertex shader in the `shader` folder, the bone
    matrices are visible as the `readonly` buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the values from the bone number of every vertex as an index into the
    bone matrices SSBO to calculate the final vertex skinning matrix named `skinMat`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the last step, we use the `skinMat` matrix to move the vertex to the correct
    position for the specific animation frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, there are a lot of calculations needed for every single frame
    of the animation we render. Let’s transfer the computational load to the graphics
    card.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the data model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To move the calculations to the GPU, we create a new struct called `NodeTransformData`
    in the file `OGLRenderData.h` in the `opengl` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: For the Vulkan renderer, the struct needs to be created in the file `VkRenderData.h`
    in the `vulkan` folder.
  prefs: []
  type: TYPE_NORMAL
- en: In this new `struct`, we will save the transformation values on a per-node basis.
    We are using a `glm::vec4`, that’s a vector type with four `float` elements for
    translation and scaling to avoid additional padding values for proper alignment
    and simply ignoring the last element in the shader.
  prefs: []
  type: TYPE_NORMAL
- en: GPU/CPU memory alignment may differ
  prefs: []
  type: TYPE_NORMAL
- en: Since GPUs are optimized for fast memory access, data in the buffers must be
    aligned in memory, in most cases to multiples of 16 bytes. This alignment will
    be automatically created when uploading data to the GPU. On the CPU side, a different
    alignment may be used, for instance for 3-element vector types like a `glm::vec3`,
    which is 12 bytes long. To use a `glm::vec3` vector, an additional `float` is
    needed as padding to match the 16-byte alignment because uploading misaligned
    data will end up in distorted images and incorrect results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also use a `glm::vec4` vector for the rotation, which is a `glm::quat` quaternion
    in the `AssimpChannel` class. The reason for this decision is simple: **GLSL**,
    the **OpenGL Shading Language**, does not know what a quaternion is, or how to
    handle a quaternion. We will have to implement the quaternion functions by ourselves
    in the compute shader. So, we utilize the normal 4-element vector to transport
    the four elements of the rotation quaternion to the shader.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can simplify the animation update. First, we add a local `std::vector`
    of our new type `NodeTransformData` to the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We iterate again over all channels, but instead of modifying the nodes of the
    model, we fill a local `NodeTransformData` variable with the transformation data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And, after a check to avoid accessing an invalid bone, we set the node transform
    of the corresponding bone with the collected transformation data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'During the `draw()` call of our renderer, we still need to update the animations
    in the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we get the node transformation from the instance, and collect them in
    a local array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As the last step, we must upload the node transforms to an SSBO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The elements of the `NodeTransformData` struct are not 4x4 matrices, but only
    the three `glm::vec4` elements per node. So, we need to upload 25% less data to
    the SSBO in this step.
  prefs: []
  type: TYPE_NORMAL
- en: Having the node transformations available on the GPU is a cool first step. But,
    if we further analyze the data flow, we will find out we need much more data in
    our compute shaders to calculate the final model matrices. Let’s see what else
    is required to calculate the world space positions from the bone-local transform
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Adding missing data for the compute shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first, and most obvious missing data part is the array of bone offset matrices.
    In the CPU implementation, we multiply the final TRS matrix per node with the
    bone offset matrix for the same node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the bone offset matrices are on a per-model base, we can add an SSBO
    to our `AssimpModel` class and upload the data during the model loading. We can
    simply add an SSBO to the `AssimpModel.h` header file in the `model` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in the `loadModel()` method, we fill a local vector with the offset matrices
    and upload the data to the SSBO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After we prepare the data for our compute shader, we bind the SSBO containing
    the bone offset matrices to the same binding point we configured in the matrix
    multiplication compute shader (`binding = 2`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'A bit more hidden at first glance is the need for parent matrices. In the method
    `updateTRSMatrix()` of `AssimpNode`, we retrieve the TRS matrix from the parent
    node (if we have a parent node). Then, we use the parent node to calculate the
    TRS matrix of the node itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In the `updateAnimation()` method of the `AssimpInstance` class, we start with
    the update of the TRS matrix of the root node and descend into the child nodes,
    collecting the parent matrix node, which contains all transformation matrices
    up to the model root node.
  prefs: []
  type: TYPE_NORMAL
- en: For the compute shader, we need a different approach. Since all shader invocations
    run in parallel, we would need to cut down the number of invocations to one per
    model, allowing the known linear progression on the model matrices. To use a larger
    amount of shader invocations, we will create an `int` vector that contains the
    number of the parent node at each position. This “parent node vector” enables
    us to “walk” backward on the model skeleton in the shader, collecting all parent
    node matrices on the way.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create the parent node vector in the loop with the bone offset matrices.
    First, we get the parent node of our current bone, then use a small lambda to
    get the position of the parent bone in the same bone list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If we don’t find a parent node in the bone list, we have found the root node
    of the model. In this case, we add a `-1` to identify the root node. In all other
    cases, we add the index number of the parent bone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `boneParentIndexList` now contains a flat list of the parent nodes for all
    the nodes in the model, with the special parent `-1` for the root node. By a repeated
    lookup of the parent node, we can ascend the skeleton tree from every node, until
    we reach the root node with the special number `-1` as parent.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make the parent bone list available in the compute shader, we create another
    SSBO in the `AssimpModel` class, and upload the `boneParentIndexList` to the GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Back in the renderer, the parent bone buffer will be bound to a binding point
    of our compute shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We haven’t finished the workload transformation to the GPU yet. Some data needs
    to be handled in a different way when using a compute shader.
  prefs: []
  type: TYPE_NORMAL
- en: Relocating data to another shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Also missing from the calculations now is the instance world position. The
    `updateAnimation()` method contains the following line to set the transformation
    matrix for the root node of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The root transformation matrix of the model contains general transformations
    that will be applied to the entire model, like a global scaling of the model.
    The other matrix, `mLocalTransformMatrix`, is used to set the user-controlled
    parameters of the model instance. The local transformation matrix allows us to
    rotate and move the model instance in the virtual world.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the bone offset matrices, the root node transformation will be
    moved to the `assimp_skinning.vert` vertex shader, not to a compute shader. It
    does not matter which of the two shaders does the matrix multiplication, but moving
    the root node transformation to the vertex shader may lower the load of the computer
    shaders a bit. Also, the vertex shader only runs for objects that are drawn to
    the screen, not for instances that are culled before the rendering itself, or
    invisible instances, potentially lowering the overall computational load of the
    GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Doing the last preparations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'And, at last, we can also decide how many distinct computer shaders we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '*We need – at least – two compute shaders*.'
  prefs: []
  type: TYPE_NORMAL
- en: To calculate the final TRS matrix for a node, we need to have all parent TRS
    matrices completed, with all matrices multiplied from the current node up to the
    model root. Since we can only control the amount of shader invocations we start,
    but not when or how long such a shader invocation runs, we need to set some sort
    of barrier between the calculation of the node TRS matrices, and the process of
    collecting the matrices along the skeleton.
  prefs: []
  type: TYPE_NORMAL
- en: The only way to create such a barrier is on the CPU side. A barrier will be
    added while submitting the compute shader to the graphics API, telling the GPU
    to wait for the first shaders to finish, before it starts the second batch.
  prefs: []
  type: TYPE_NORMAL
- en: So, we will have to start with the node transforms, wait until all node transform
    matrices are finished, and then start the calculation of the final node matrices.
  prefs: []
  type: TYPE_NORMAL
- en: After the theoretical part is done, we can start the shader-related implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Moving the node computations to the GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The process of loading a compute shader differs only slightly from a vertex
    or fragment shader. For OpenGL, we have to set the shader type in the `glCreateShader()`
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'For Vulkan, we must set the correct shader stage during the creation of the
    `VkShaderModule`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'All the other steps of loading the shader code, linking, or creating the shader
    module, stay the same. Because we have only a single shader file, additional methods
    have been added to the `Shader` class. Loading a compute shader in OpenGL can
    now be achieved by calling the `loadComputeShader()` method of the `Shader` class
    with the relative file name of the shader source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Vulkan uses the **Standard Portable Intermediate Representation** (**SPIR-V**)
    format for shaders. Instead of the shader source, the precompiled shader code
    must be loaded into the `Shader` class for the Vulkan renderer.
  prefs: []
  type: TYPE_NORMAL
- en: As we compute new matrices in the compute shaders, and we have to move these
    matrices between different shaders, two additional SSBOs are required.
  prefs: []
  type: TYPE_NORMAL
- en: Adding more shader storage buffers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first SSBO will store the TRS matrices that we create from the node transforms.
    This SSBO is a simple buffer, defined in the header file for the renderer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The second SSBO will contain the final bone matrices that will be used in the
    skinning vertex shader. The bone matrix buffer is also added as a normal SSBO
    declaration in the header file of the renderer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'One important step to use the SSBO in the shaders is the have a correct size
    set. If the SSBO is too small, not all data will be stored in the compute shader,
    and instances or body parts of instances may be missing. A wrong buffer size may
    be hard to debug – you may not even get a warning that the shader writes beyond
    the end of the buffer. We must calculate the buffer size according to the number
    of bones, the number of instances, and the size of the 4x4 matrix, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we resize the two SSBOs to the final matrix size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: When drawing multiple models, both buffers will end up with the maximum size
    of all models. But this does not do any harm, as the buffers will be reused for
    the next model and filled only up to the real amount of data used in the new model.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the node transforms in a shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the first compute shader, we must upload the node transform data to the
    first compute shader. We bind the SSBO storing the new TRS matrices created from
    the node transform to the proper binding point of the compute shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The compute shader itself is named `assimp_instance_transform.comp`, located
    in the `shader` folder. The first line of the compute shader is the usual version
    definition; the second line defines the local invocation sizes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create 32 invocations of the shader by default. You may need to experiment
    with the local sizes to achieve maximum performance. Shaders are started in groups
    of fixed sizes to simplify the GPU-internal management. Common values are 32 (called
    “warps,” for NVIDIA GPUs) or 64 (called “waves,” for AMD GPUs). It’s kind of useless
    to set all the local sizes to 1 for NVIDIA or AMD GPUs, since the remaining 31
    warps or respective 63 waves will be unused.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we must add the `NodeTransformData` with the same data types as we used
    while declaring the type in the `OGLRenderData.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'As a reminder: The `rotation` element is a quaternion, disguised as `vec4`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we define the two SSBOs, using the same binding points as in the renderer
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We mark the node transform data as `readonly`, and the TRS matrices as `writeonly`.
    The two modifiers could help the shader compiler to optimize the access of the
    buffers, since some operations could be left out. The other modifier, `restrict`,
    also helps the shader compiler to optimize the shader code. By adding `restrict`,
    we tell the shader compiler that we will never read a value with a variable that
    we wrote before from another variable. Eliminating read-after-write dependencies
    will make the life of the shader compiler much easier.
  prefs: []
  type: TYPE_NORMAL
- en: To read the data from the `TransformData` buffer, three methods have been added.
    Within these three methods, called `getTranslationMatrix()`, `getScaleMatrix()`,
    and `getRotationMatrix()`, we read the data elements of the buffer and create
    4x4 matrices for the corresponding transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, see the implementation of the `getTranslationMatrix()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The resulting 4x4 matrix is an identity matrix, enriched by the translation
    data for the specific `index` in the `TransformData` buffer. The `getScaleMatrix()`
    method creates a scaling matrix, having the first three elements of the main diagonal
    set to the scaling values. Finally, the `getRotationMatrix()` method resembles
    the spirit of the `mat3_cast` algorithm from GLM, converting a quaternion into
    a 4x4 rotation matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `main()` method of the first compute shader, we get the `x` and `y`
    dimensions of the shader invocations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the number of bones in the model as `x` dimension, simplifying
    the remaining part of the shader code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Locating the correct index in the buffer is done by combining the number of
    bones, the shader instance (invocation), and the node we will work on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The main logic for the compute shader multiplies the translation, rotation,
    and scaling matrix in the TRS order, and saves the result in the buffer for the
    TRS matrices, at the same `index` of the node transforms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'In GLM, matrices are multiplied from right to left, a fact that may be confusing
    at first. So, despite the name of the matrix being “TRS,” the multiplications
    are performed in reverse order of the name: The model scaling is applied first,
    then the rotation, and then the translation comes last. Other math libraries or
    different matrix packings may use a different order of multiplication. Two extensive
    matrix tutorials are listed in the *Additional resources* section.'
  prefs: []
  type: TYPE_NORMAL
- en: Saving the TRS matrix on the same spot as the node transforms retains the order
    of nodes in a model and the order of nodes in all model instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'To trigger the shader execution, we call `glDispatchCompute()` for the OpenGL
    renderer, adding a memory barrier that waits for the SSBO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The memory barrier makes sure the CPU waits for a specific state of the GPU.
    In this case, we must wait until all SSBO writes have finished, so we set the
    bit for the shader storage buffers. The call to `glMemoryBarrier()` simply blocks
    execution, returning only after the GPU has reached the desired state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go on, let’s take a look at what happens inside the compute shader
    when `glDispatchCompute()` or `vkCmdDispatch()` is called. *Figure 2.4* shows
    the internal elements of the compute shader invocations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Global work groups and local invocation structure of a compute
    shader'
  prefs: []
  type: TYPE_NORMAL
- en: When we call the dispatch command with the parameters `4,4,2`, a total of number
    of `4*4*2 = 32` workgroups will be started, as shown on the left side of *Figure
    2.4*. The total number of workgroups is simply the product of the three dimensions
    `X`, `Y`, and `Z` of the global compute space.
  prefs: []
  type: TYPE_NORMAL
- en: 'In each of the 32 workgroups, a total of four shader invocations are running,
    as seen for the workgroup `[3,0,0]` in the middle of *Figure 2.4*. The so-called
    local size is defined by the three shader layout values `local_size_x`, `local_size_y`,
    and `local_size_z`. The local size of a workgroup is calculated like the number
    of workgroups, by multiplying the three values for `X`, `Y`, and `Z` dimensions:
    `2*2*1 = 4`.'
  prefs: []
  type: TYPE_NORMAL
- en: A separation into workgroups is important if the shader instances need to communicate
    between each other since communication is only possible inside the same workgroup.
    Shader invocations from different workgroups are effectively isolated and unable
    to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the total number of shader invocations can become huge quite
    quickly, since the local size of a single workgroup and the total number of workgroups
    are multiplied. This massive parallelism is the secret behind the raw power of
    a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: So, for the `x` dimension, we use the `numberOfBones`, as stated before. By
    calculating the `std::ceil` of the `numberOfInstances` divided by 32 as the `y`
    dimension, we make sure to start groups of 32 shader invocations to calculate
    the matrices for up to 32 instances at once, as configured as the local `y` dimension
    in the shader code. If we have an instance count of less than a multiple of 32,
    the additional waves or warps are still running, but the results are ignored.
    Technically, we are reading and writing outside the buffer bounds, but the GPU
    driver should handle the situation, i.e., by discarding the writes.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Vulkan, we must call `VkCmdDispatch()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The size of the Shader Storage Buffer Object for the compute shaders in Vulkan
    should also be rounded to hold a multiple of 32 times the number of bones to avoid
    accidental overwrites of buffer data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Barriers to synchronizing the shaders in Vulkan must be set to wait for the
    results of the queues. For synchronization between the compute shader and the
    vertex shader, we need to set the barrier between the writes of the compute shader
    and the first read operation of the vertex shader like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Now, Vulkan waits for the compute shader to finish all calculations before starting
    the draw calls in the vertex shader.
  prefs: []
  type: TYPE_NORMAL
- en: The TRS matrix buffer now contains the matrices for every node, but without
    the parent nodes, the root node transform matrix, or any offset matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the final node matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can start the next compute shader, we must bind all buffers that
    will be used during the shader run. We have a total of four SSBOs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Since all data already resides on the GPU, we don’t need any kind of upload
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second compute shader itself is called `assimp_instance_matrix_mult.comp`
    and can be found in the `shader` folder. The shader code starts – again – with
    a version and the local size definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: A local size of 32 is used since the code was developed on a machine with an
    NVIDIA GPU. For an AMD GPU, you should use a local size of 64, as explained in
    the section *Calculating the node transforms in a shader*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the first compute shader, the SSBOs follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The first buffer, `TRSMatrix`, contains the TRS matrices from the first compute
    shader. In the `ParentMatrixIndices` buffer, the shader can find the list containing
    the parent node for each of the nodes. The bone matrix offsets for every node
    are made available in the third buffer, `BoneOffsets`, and the final node matrices
    will be stored in the last buffer, `BoneMatrices`. The `readonly` and `writeonly`
    modifiers are set according to the usage of the buffers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we use the same settings as the first compute shader, having virtually
    the same first lines in the `main()` method of the second compute shader should
    be no surprise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we get the TRS matrix for the bone we will be working on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we introduce a variable called `parent`, storing the `index` of the parent
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: We will need the `parent` node index to get the correct parent matrix while
    we walk the node skeleton up to the root node.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the first step of the skeleton walk, we get the parent node of the node
    that we are working on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following `while` loop, we get the parent matrix of the node and multiply
    both matrices. Then we look up the parent of the parent node, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding lines of code may make you raise your eyebrows, since we apparently
    break one of the basic rules of GLSL shader code: the size of a loop must be known
    at compile time. Luckily, this rule does not apply to a `while` loop. We are free
    to alter the loop control variable inside the body of the loop, creating loops
    of various lengths.'
  prefs: []
  type: TYPE_NORMAL
- en: However, this code could impact shader performance as GPUs are optimized to
    execute the same instructions on every thread. You may have to check the shader
    code on different GPUs to make sure you see the expected speedup.
  prefs: []
  type: TYPE_NORMAL
- en: Also be aware that the accidental creation of an infinite loop may end in a
    locked-up system since the shader code never returns the wave or warp to the pool.
    It’s a good idea to ensure a valid exit condition for a while loop on the CPU
    side since a GPU lockup may only be resolved by a forced restart of your computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'As long as we don’t have errors or cycles in the parent node list, we will
    end at the last block for every node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Here, we multiply the resulting node matrix, containing all matrices up to the
    root node, by the bone offset matrix for the node, and store the result in the
    writable `NodeMatrices` buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting the computation is done in exactly the same way as for the first shader.
    Run `glDispatchCompute()` for OpenGL, followed by a `glMemoryBarrier()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'And, for Vulkan, use `VkCmdDispatch()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the `NodeMatrices` buffer contains the TRS matrices for all nodes,
    close to the result we had after the `updateAnimation()` call in the CPU-based
    version of the code in [*Chapter 1*](Chapter_1.xhtml) – with the exception of
    the model root matrix for the instance.
  prefs: []
  type: TYPE_NORMAL
- en: Finalizing the compute relocation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let’s add the missing matrix calculation to the vertex skinning shader.
    First, we collect the matrices containing the world positions during the loop
    over all instances of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the world position matrices are uploaded into an SSBO, and bound to the
    vertex skinning shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'In the vertex skinning shader itself, the new buffer is introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create a combined matrix from the world position and the vertex
    skin matrix, and use the new matrix to calculate the position of the vertex and
    the normal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Compiling and running the example from *Chapter 2* should result in the same
    functionality as the example from [*Chapter 1*](Chapter_1.xhtml). We can load
    models and create a large number of instances, but we are still able to control
    the parameters of every single instance of every model. The main difference should
    be the amount of time it takes to create the transform matrices – we should see
    a large drop, compared to the CPU-based version, and end up most probably below
    10 milliseconds. Depending on your CPU and GPU types, the speed gain will differ.
    But in all cases, the GPU shader should be notably faster than pure CPU calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the speedup we achieved by using compute shaders.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the implementation by scaling up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All features and the user interface are identical to [*Chapter 1*](Chapter_1.xhtml).
    But our changes can be made visible by adding more and more instances. If you
    add the same 1,600 instances as in *Figure 2.1*, you will see much smaller matrix
    generation times. The values may be similar to *Figure 2.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: The compute shader version with 1,600 instances'
  prefs: []
  type: TYPE_NORMAL
- en: The time for virtually the same matrix operations went down from ~24 milliseconds
    on the CPU to less than 6 milliseconds by using compute shaders. We won around
    18 milliseconds of CPU time in every single frame!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let us add more models – many models. Let’s say we add a total of 4,000
    instances of the example model. The resulting matrix generation times on your
    machine may be similar to the number in *Figure 2.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/figure_2_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: The compute shader version with 4,000 instances'
  prefs: []
  type: TYPE_NORMAL
- en: Even with 2.5 times the number of instances, the average matrix generation time
    of the compute shader code is still at about half the time of the CPU version.
    You may even see a much larger, non-linear performance gain with more powerful
    GPUs. Recent GPUs not only have several thousands of cores that are working in
    parallel on the matrix multiplications, but the next biggest model also nearly
    doubles the number of cores, leading to more parallelization.
  prefs: []
  type: TYPE_NORMAL
- en: We can scale up the number of instances a lot more or process more complex models
    while still having a lower matrix generation time. At some arbitrary number of
    instances, the frame rate of the application will still drop below 60 FPS. Depending
    on your system, this may happen before reaching the 4,000 instances of *Figure
    2.6*, or much later.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you attach a profiler to the application, you will spot the new bottleneck
    of our calculation: The quaternion SLERP at the end of the method `getRotation()`
    in the `AssimpAnimChannel` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Also, the two `mix()` calls of `getTranslation()` and `getScale()` in the `AssimpAnimChannel`
    class will be among the top findings of the profiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you could try to move even more operations to the compute shaders.
    But be aware that your mileage may vary. Some changes could raise the computational
    load of the GPU more than the CPU load will be lowered. That’s the moment when
    you should grab a good book about shader programming, or watch some conference
    talks, if you want to continue your journey into the world of compute shaders.
    The best way to get into GPU computation is still “learning by doing” and not
    giving up if the shader does not give the expected results. But be warned: Here
    will be dragons around, eating your time...'
  prefs: []
  type: TYPE_NORMAL
- en: Before we close this chapter, let’s talk briefly about compute shader debugging.
  prefs: []
  type: TYPE_NORMAL
- en: How to debug a compute shader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compute shaders are cool – at least, until you run into some kind of trouble.
  prefs: []
  type: TYPE_NORMAL
- en: While you can easily attach a debugger to the CPU code to see what’s going on,
    the GPU side is harder to check. A mistake in a fragment shader may cause distorted
    graphics, providing some hint for where the bug lies, but in other cases, you
    might see just nothing. In addition to undoing the latest changes, you can always
    attach a debugging tool like **RenderDoc** and check out what’s going wrong with
    the usual shader types.
  prefs: []
  type: TYPE_NORMAL
- en: But, while RenderDoc has experimental support for compute shader debugging,
    this support is still limited. So, in contrast to other shader types, a compute
    shader is mostly a “black box” for us with RenderDoc – a program receiving and
    outputting opaque data.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your GPU, you might want to try out NVIDIA Nsight (for NVIDIA GPUs)
    or the AMD Radeon GPU Profiler (for AMD GPUs). Links to all three tools are available
    in the *Additional resources* section.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases though, the problems in a compute shader come from simple mistakes.
    Uploading wrong or incomplete data to an SSBO, stride or padding problems, getting
    the order of elements wrong, swapping the order of a (non-commutative) matrix
    multiplication by accident... simple, but annoying errors that can take ages to
    find.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quite easy way to see what a compute shader stage does is by reading back
    the contents of the SSBOs. As an example for OpenGL, these lines read the data
    inside the SSBO `buffer` into the `std::vector` named `bufferVector`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The contents of the SSBO could be compared to the results of the same calculations
    done on the CPU. Step by step and buffer by buffer, the problem may be narrowed
    down until the error has been found.
  prefs: []
  type: TYPE_NORMAL
- en: Reading back an SSBO may not be an obvious solution to do compute shader debugging,
    but every little bit of help is welcome here. But, depending on the complexity
    of the shader, you may be thrown back to a manual walk-through of the code. Also,
    try to use a simple dataset to simplify debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we moved a large part of the computations from the CPU to compute
    shaders on the GPU. After a brief history of concurrent code execution, we created
    a plan on how to move the node transform calculation to the GPU, and we finally
    executed that plan. At the end of the chapter, we checked the resulting application
    for the speedup we achieved.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a look at solutions to add a visual selection
    to the model view application. Being able to create thousands of model instances
    is nice, but locating one special instance among all the others is nearly impossible
    right now. We will discuss two different approaches and implement one of them.
  prefs: []
  type: TYPE_NORMAL
- en: Practical sessions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are some additions you could make to the code:'
  prefs: []
  type: TYPE_NORMAL
- en: Add “Programmable Vertex Pulling” to the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Programmable Vertex Pulling, the vertex data will no longer be pushed by
    using a vertex buffer. Instead, the vertex data will be uploaded to a UBO or SSBO
    to the GPU, and the vertex shader is used to extract all the data for every vertex
    from that buffer.
  prefs: []
  type: TYPE_NORMAL
- en: Move `mix()` and `slerp()` from `AssimpAnimChannel` to the GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the two data values for the timings of translation, rotation, and scaling
    have been extracted from the channel vector, a linear interpolation for translation
    and scaling and a SLERP for rotation are required. Both interpolation types are
    called thousands of items per frame – maybe the GPU is faster.
  prefs: []
  type: TYPE_NORMAL
- en: Blend between two animations in a compute shader.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This task is similar to the previous practical session. But, instead of doing
    the interpolation between the animation keys of a single animation clip on the
    GPU, do the interpolation between the transformations at the same time for two
    different animation clips.
  prefs: []
  type: TYPE_NORMAL
- en: 'For extra difficulty: Combine both tasks and do interpolations between the
    4 values for the node transformations of two animation clips in a compute shader.'
  prefs: []
  type: TYPE_NORMAL
- en: Use RenderDoc to view the buffer contents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the buffer data type is shown as RGB values in RenderDoc, you may see
    some interesting and recurring patterns in the buffers.
  prefs: []
  type: TYPE_NORMAL
- en: Additional resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C64 demo coding: [https://codebase64.org/doku.php?id=base:start](https://codebase64.org/doku.php?id=base:start)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Atari ST demo scene: [https://democyclopedia.wordpress.com](https://democyclopedia.wordpress.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'pouët.net demo scene archive: [https://www.pouet.net](https://www.pouet.net)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LearnOpenGL on compute shaders: [https://learnopengl.com/Guest-Articles/2022/Compute-Shaders/Introduction](https://learnopengl.com/Guest-Articles/2022/Compute-Shaders/Introduction)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vulkan Tutorial on compute shaders: [https://vulkan-tutorial.com/Compute_Shader](https://vulkan-tutorial.com/Compute_Shader)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Vulkan Compute: High-Performance Compute Programming with Vulkan and Compute
    Shaders* by *Kenwright*, published by the author himself, ISBN: 979-8345148280'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GLSL Interface block restrictions: [https://www.khronos.org/opengl/wiki/Interface_Block_(GLSL)](https://www.khronos.org/opengl/wiki/Interface_Block_(GLSL))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Matrix multiplication guide: [https://blog.mecheye.net/2024/10/the-ultimate-guide-to-matrix-multiplication-and-ordering/](https://blog.mecheye.net/2024/10/the-ultimate-guide-to-matrix-multiplication-and-ordering/%0D%0A)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tutorial on different matrix multiplications: [https://tomhultonharrop.com/mathematics/matrix/2022/12/26/column-row-major.html](https://tomhultonharrop.com/mathematics/matrix/2022/12/26/column-row-major.html%0D%0A)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenGL memory barriers: [https://registry.khronos.org/OpenGL-Refpages/gl4/html/glMemoryBarrier.xhtml](https://registry.khronos.org/OpenGL-Refpages/gl4/html/glMemoryBarrier.xhtml%0D%0A)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RenderDoc homepage: [https://renderdoc.org](https://renderdoc.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NVIDIA Nsight: [https://developer.nvidia.com/tools-overview](https://developer.nvidia.com/tools-overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AMD Radeon GPU Profiler: [https://gpuopen.com/rgp/](https://gpuopen.com/rgp/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
