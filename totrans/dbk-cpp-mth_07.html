<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-80">
    <a id="_idTextAnchor079">
    </a>
    
     7
    
   </h1>
   <h1 id="_idParaDest-81">
    <a id="_idTextAnchor080">
    </a>
    
     There’s No Simple Way to Do Parallelism and Concurrency in C++
    
   </h1>
   <p class="italic-heading">
    <em class="italic">
     
      Unless we rethink OOP
     
    </em>
    
     <em class="italic">
      
       and FP
      
     </em>
    
   </p>
   <p>
    
     To do parallelism and concurrency in C++, we used to require either separate libraries (for example, Boost) or OS primitives.
    
    
     With the introduction of functional programming constructs, parallelism and concurrency have become easier, within
    
    
     
      certain constraints.
     
    
   </p>
   <p>
    
     In this chapter, we’re going to cover the following
    
    
     
      main topics:
     
    
   </p>
   <ul>
    <li>
     
      Defining parallelism
     
     
      
       and concurrency
      
     
    </li>
    <li>
     
      Common issues with parallelism
     
     
      
       and concurrency
      
     
    </li>
    <li>
     
      Functional programming to
     
     
      
       the rescue!
      
     
    </li>
    <li>
     
      The
     
     
      
       Actor Model
      
     
    </li>
    <li>
     
      What we can’t
     
     
      
       do yet
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-82">
    <a id="_idTextAnchor081">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     The code for this chapter is available on GitHub at
    
    <a href="https://github.com/PacktPublishing/Debunking-CPP-Myths">
     
      https://github.com/PacktPublishing/Debunking-CPP-Myths
     
    </a>
    
     , in the
    
    <strong class="source-inline">
     
      ch7
     
    </strong>
    
     folder.
    
    
     The code has been compiled with Makefiles using g++ and C++ 20.
    
    
     The example regarding the Actor Model uses
    
    <strong class="bold">
     
      C++ Actor Framework
     
    </strong>
    
     (
    
    <strong class="bold">
     
      CAF
     
    </strong>
    
     ) (
    
    <a href="https://www.actor-framework.org/">
     
      https://www.actor-framework.org/
     
    </a>
    
     ) so you’ll need to install it
    
    <a id="_idIndexMarker271">
    </a>
    
     before working on it.
    
    
     On Ubuntu, it can be installed by running
    
    <strong class="source-inline">
     
      apt install libcaf-dev
     
    </strong>
    
     .
    
    
     The CAF version that’s used in the examples is the stable Ubuntu version of the
    
    
     
      library:
     
    
    
     <strong class="source-inline">
      
       0.17
      
     </strong>
    
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-83">
    <a id="_idTextAnchor082">
    </a>
    
     Defining parallelism and concurrency
    
   </h1>
   <p>
    
     My first computer was an
    
    <a id="_idIndexMarker272">
    </a>
    
     HC-90, a ZX-80 clone built in Romania.
    
    
     I owned two versions: the first required a cassette player to load programs.
    
    
     Despite this inconvenience, it had a big advantage over its main competitor at the time, the CHIP computer, yet another ZX-80 clone
    
    <a id="_idIndexMarker273">
    </a>
    
     built in Romania.
    
    
     You see, the CHIP computer required a cassette to load into its OS, while the HC-90 had enough EPROM memory to boot directly into a BASIC interpreter.
    
    
     The second version I owned was much better: it had a 5-inch floppy disk reader, which meant that you could load programs
    
    
     
      much faster.
     
    
   </p>
   <p>
    
     In both versions, the BASIC interpreter
    
    <a id="_idIndexMarker274">
    </a>
    
     was your interface with the computer, and since not many programs were available other than games, I spent some of my time in high school writing BASIC programs and playing games.
    
    
     Eventually, I realized that I wanted more than BASIC.
    
    
     I played a bit with graphics and sound, but the problem was that everything was very slow.
    
    
     This made me learn ZX 80 assembler, which was an adventure.
    
    
     It was very easy to make mistakes in assembler, which resulted in a reboot and the loss of all work.
    
    
     It wasn’t a sustainable way to program, but it made me appreciate the programming luxuries of today much more.
    
    
     Imagine this: I can compile and run tests on my programs on my computer and save my changes to a source
    
    
     
      control system.
     
    
   </p>
   <p>
    
     I knew back then that I wanted the graphics and sounds to feel faster.
    
    
     What I didn’t realize was that I had a fundamental limitation: there was only one CPU (or one core, as we would say today), which meant that the graphics, sound, and logic code had to run sequentially.
    
    
     The CPU could receive a command to play a sound, then go to display some graphics, and then make some computations, and since there was a very short lag between the instruction and the actual sound playing or the image showing, it seemed as if these tasks were running in parallel.
    
    
     But they weren’t: they were concurrent.
    
    
     You could observe this if you loaded the system to the maximum since the image and sound were no
    
    
     
      longer synchronized.
     
    
   </p>
   <p>
    
     What would have happened if I had more processors or more cores to work with?
    
    
     Well, I could have defined various tasks that can be run on separate processors.
    
    
     A capable scheduler could take these tasks and run them in parallel to fill the capacity of the idle CPUs.
    
    
     If the tasks are well-defined, we can squeeze a lot of the power from the available cores and get the answer
    
    <a id="_idIndexMarker275">
    </a>
    
     faster.
    
    
     This
    
    
     
      is
     
    
    
     <strong class="bold">
      
       parallelism
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     A nuance to this definition, which will become useful in this chapter, comes from the Haskell community (see
    
    <a href="https://wiki.haskell.org/Parallelism_vs._Concurrency">
     
      https://wiki.haskell.org/Parallelism_vs._Concurrency
     
    </a>
    
     ).
    
    
     They make a big distinction between a parallel functional program and a concurrent functional program, therefore presuming both programs use immutability.
    
    
     Parallel functional programs use cores to execute faster, but they’re deterministic, and the meaning of the program is unchanged whether we execute it sequentially or in parallel.
    
    
     Contrast this with functional concurrent programs that run concurrent threads, each doing I/O operations, and that are non-deterministic since we don’t know the order
    
    
     
      of operations.
     
    
   </p>
   <p>
    
     Unfortunately, as is common in software development, these terms have a life of their own.
    
    
     You might encounter people who believe concurrency and parallelism are completely different things.
    
    
     In researching this matter, I came upon a conversation on StackOverflow stating the argument that concurrency is a superset of parallelism since concurrency refers to a set of methods that are used for managing multiple threads.
    
    
     And this may well be how some computer science books treat
    
    
     
      the topic.
     
    
   </p>
   <p>
    
     The need for clarity constrains us to pick one definition.
    
    
     I’ll pick the definition that closely matches my formative years of
    
    <a id="_idIndexMarker276">
    </a>
    
     programming:
    
    <strong class="bold">
     
      concurrency
     
    </strong>
    
     is when multiple operations seem to run at the same time, while parallelism is when they do.
    
    
     This difference, while seemingly simple, leads to a difference in intent when designing the program.
    
    
     When we design a program expecting it to run in parallel, we define operations that can run in parallel and figure out their order.
    
    
     We try to squeeze time from the CPU by splitting a larger task into parts that can run independently, without them affecting each other much.
    
    
     The intent is different when we design a program expecting it to run concurrently: we optimize the response time by pushing the longer tasks into the dead times of
    
    
     
      the CPU.
     
    
   </p>
   <p>
    
     Both these programming models are challenging, albeit in different ways.
    
    
     Let’s remind ourselves of the common issues we face when
    
    
     
      using them.
     
    
   </p>
   <h1 id="_idParaDest-84">
    <a id="_idTextAnchor083">
    </a>
    
     Common issues with parallelism and concurrency
    
   </h1>
   <p>
    
     I’m convinced that the fundamental problem of software development is to mentally translate the static view of a system – the code – into its dynamic behavior, or what the program does when it runs.
    
    
     Programmers run code in their heads every time they’re considering a change, often automatically but always at the expense of mental energy.
    
    
     This is one of the reasons why I believe practices such as
    
    <strong class="bold">
     
      test-driven development
     
    </strong>
    
     (
    
    <strong class="bold">
     
      TDD
     
    </strong>
    
     ) and
    
    <a id="_idIndexMarker277">
    </a>
    
     incremental design are useful; they allow us to move part of this mental energy spending from our brains to running the
    
    
     
      tests repeatedly.
     
    
   </p>
   <p>
    
     This
    
    <a id="_idIndexMarker278">
    </a>
    
     fundamental problem is already difficult for single threads, but for parallel or concurrent designs, it adds a new level of challenge.
    
    
     We not only need to imagine what the code will do but also how the code will interact with the other parts of the code that run at the same time.
    
    
     So, imagination and the brain energy required to make sense of
    
    <a id="_idIndexMarker279">
    </a>
    
     parallel execution is the
    
    
     
      first challenge.
     
    
   </p>
   <p>
    
     Then, there are the purely
    
    
     
      technical challenges.
     
    
   </p>
   <p>
    
     When resources are shared, resource management becomes much harder, particularly when multiple threads can modify values.
    
    
     One thread might be using a value that was already changed by another thread, thus leading to wrong results.
    
    
     A memory address might be freed by one thread and then another thread attempts to read or write
    
    
     
      to it.
     
    
   </p>
   <p>
    
     Sharing the same infrastructure isn’t easy either.
    
    
     One thread might take all the resources due to a bug, thus blocking other threads for long periods.
    
    
     This is less of an issue when the program is formed of separate tasks using multiple cores, but it still leads to reduced performance since the separate tasks need to converge at some point.
    
    
     Threads could wait for one another indefinitely or until a
    
    
     
      timeout occurs.
     
    
   </p>
   <p>
    
     Implementing programs that work with parallel or concurrent tasks from scratch is one of the most difficult things you might need to do as a programmer.
    
    
     I remember when I once debugged a synchronization issue between threads for a week, and I knew my technical lead and my project manager were starting to doubt my abilities.
    
    
     I didn’t doubt myself, but I didn’t like how long it took me to finally figure
    
    
     
      it out.
     
    
   </p>
   <p>
    
     For this reason, libraries and patterns have appeared that help us implement concurrent and parallel programs.
    
    
     Most of them invite us to pass a function that represents a thread to a method that sorts out some of the complexities of thread synchronization.
    
    
     This is possible by separating the tasks that we might need into types of tasks.
    
    
     Additionally, architecture models such as MapReduce that are implemented by Hadoop and inspired by functional programming help us deal with
    
    
     
      large-scale parallelization.
     
    
   </p>
   <p>
    
     As we can see, we can’t discuss modern approaches to parallel programming without discussing the functional programming approach
    
    
     
      to it.
     
    
   </p>
   <h1 id="_idParaDest-85">
    <a id="_idTextAnchor084">
    </a>
    
     Functional programming to the rescue!
    
   </h1>
   <p>
    
     As we’ve seen, one of the problems with parallel and concurrent tasks is the shared access to resources.
    
    
     Functional programming, in its pure form, solves this out of the box through immutability.
    
    
     Since
    
    <a id="_idIndexMarker280">
    </a>
    
     everything is immutable by default, and since any change to a value is made by pointing to a changed value instead of modifying the initial one, threads are never at risk of modifying data used by other threads.
    
    
     We discussed how to achieve this when we discussed the different paradigms available
    
    
     
      in C++.
     
    
   </p>
   <p>
    
     But there’s more: functional programming offers us parallelizable algorithms out of the box.
    
    
     The C++ standardization committee recognized this when introducing functional algorithms along with an execution policy that allows you to run operations on collections
    
    
     
      in parallel.
     
    
   </p>
   <p>
    
     Let’s look at a simple example: we want to compute the sum of squares of the values in a collection.
    
    
     The functional version of this type of algorithm is a typical map-reduce one: first, we pass in the initial collection and map it to a collection that contains the squares of the values, after which we reduce it by adding all the elements.
    
    
     In STL, these operations are implemented in
    
    <strong class="source-inline">
     
      std::transform
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      std::reduce
     
    </strong>
    
     , respectively.
    
    
     A version that combines them is available in
    
    <strong class="source-inline">
     
      std::transform_reduce
     
    </strong>
    
     , but we’ll ignore it for now to make the example
    
    
     
      more relevant.
     
    
   </p>
   <p>
    
     Here’s what the function
    
    
     
      looks like:
     
    
   </p>
   <pre class="source-code">
long long sumOfSquares(const vector&lt;int&gt; numbers){
     vector&lt;long long&gt; squaredNumbers(numbers.size());
     auto squareNumber = [](const long it ){ return it * it; };
     transform(numbers.begin(), numbers.end(), squaredNumbers.begin(), squareNumber);
     return reduce(squaredNumbers.begin(), squaredNumbers.end(), 0);
}
TEST_CASE("sum of squares in parallel") {
        vector&lt;int&gt; numbers{234, 423, 345, 212, 112, 2412};
        CHECK_EQ(6227942, sumOfSquares(numbers));
}</pre>
   <p>
    
     The only thing we need to do to
    
    <a id="_idIndexMarker281">
    </a>
    
     run these operations in parallel is to add a parameter to both functional algorithms that specifies the execution policy.
    
    
     The execution policy we’ll use is
    
    <strong class="source-inline">
     
      std::execution::par
     
    </strong>
    
     , an instance of
    
    <strong class="source-inline">
     
      std::execution_parallel
     
    </strong>
    
     provided by the standard library that specifies that the algorithms need to run
    
    
     
      in parallel:
     
    
   </p>
   <pre class="source-code">
long long sumOfSquares(const vector&lt;int&gt; numbers){
     vector&lt;long long&gt; squaredNumbers(numbers.size());
     auto squareNumber = [](const long it ){ return it * it; };
     transform(<strong class="bold">std::execution::par</strong>, numbers.begin(), numbers.end(), squaredNumbers.begin(), squareNumber);
     return reduce(<strong class="bold">std::execution::par</strong>, squaredNumbers.begin(), squaredNumbers.end(), 0);
}</pre>
   <p>
    
     From this example, we can notice a
    
    
     
      few things.
     
    
   </p>
   <p>
    
     First, it’s very easy to switch between the different execution policies when you use functional programming.
    
    
     This enables us to fix issues related to parallelization more easily and to optimize code.
    
    
     Running the algorithms in parallel isn’t necessarily better than sequential execution in all cases.
    
    
     It’s likely that for small numbers or short collections, the resources that are used to start threads and manage them are larger than the
    
    
     
      time saved.
     
    
   </p>
   <p>
    
     Second, we can use the execution policy as a parameter or as a general configuration.
    
    
     This would allow us to test that algorithms work sequentially in isolation from thread synchronization.
    
    
     It also allows us to decide what policy to use at runtime, depending on a few factors related to the
    
    
     
      input data.
     
    
   </p>
   <p>
    
     Third, each of these
    
    <a id="_idIndexMarker282">
    </a>
    
     execution policies imposes limitations on your code.
    
    
     For example, the parallel policy we’ve used here requires that the iterators aren’t invalidated in the process, thus disallowing write access and the usage of
    
    <strong class="source-inline">
     
      std::back_inserter
     
    </strong>
    
     .
    
    
     Other execution policies are available in STL besides
    
    <strong class="source-inline">
     
      std::execution::parallel_policy
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::execution::sequenced_policy:
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::execution::parallel_unsequenced_policy
     
    </strong>
    
     , and
    
    <strong class="source-inline">
     
      std::execution::unsequenced_policy
     
    </strong>
    
     , with the remark that the standardization committee might add built-in policies for
    
    <strong class="source-inline">
     
      std::parallel::cuda
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      std::parallel::opencl
     
    </strong>
    
     .
    
    
     Each of these policies has its limitations and constraints, so the most portable code is what’s used for maximum immutability and
    
    
     
      functional algorithms.
     
    
   </p>
   <p>
    
     Fourth, the algorithms run in sequence, but each of them is parallelized.
    
    
     If we need to squeeze more from our computing resources, we either use the combined
    
    <strong class="source-inline">
     
      std::transform_reduce
     
    </strong>
    
     algorithm or write our own algorithm combining the two.
    
    
     Once again, it’s important to realize that running code in parallel is a trade-off: some of the computing resources will be spent on starting and synchronizing threads, which for some configurations might not add a
    
    
     
      big benefit.
     
    
   </p>
   <p>
    
     Finally, the fifth point is that the map-reduce pattern is very powerful.
    
    
     Any unary function can be used for
    
    <strong class="source-inline">
     
      map
     
    </strong>
    
     and any binary function can be used for
    
    <strong class="source-inline">
     
      reduce
     
    </strong>
    
     , and we can bind the parameters of functions that require more values until we get unary or binary functions.
    
    
     Maps and reduces can be chained in many ways.
    
    
     If you start looking at your programs as data in/data out, you’ll notice that all our programs can be written as data in/functional transformations/data out, with many of the functional transformations being
    
    <strong class="source-inline">
     
      map
     
    </strong>
    
     /
    
    <strong class="source-inline">
     
      reduce
     
    </strong>
    
     operations.
    
    
     This realization leads to a very powerful programming model since we can turn parallelization on or off for all or parts of the algorithms.
    
    
     Occasionally, we may want to write our own algorithms that optimize parallelization for important parts of the code, but we get most of it
    
    
     
      for free.
     
    
   </p>
   <p>
    
     The only catch is that we need to use immutable data and
    
    
     
      functional algorithms.
     
    
   </p>
   <p>
    
     The design style we’ve discussed so far is data-centric since it focuses on the data structures and their transformations.
    
    
     As always when it comes to software design and architecture, we have the alternative to focus on behavior.
    
    
     Surely enough, a design style that splits the program into behaviors and allows for parallel programming has emerged in the form of the
    
    
     
      Actor Model.
     
    
   </p>
   <h1 id="_idParaDest-86">
    <a id="_idTextAnchor085">
    </a>
    
     The Actor Model
    
   </h1>
   <p>
    
     The world around us moves in parallel
    
    <a id="_idIndexMarker283">
    </a>
    
     very naturally.
    
    
     Each tree, plant, or person does their own thing, and occasionally they interact, and things change for the parties involved.
    
    
     So, we already have a mental model of how parallel programs could work: separate entities that encapsulate their behavior and communicate somehow, on an infrastructure that ensures
    
    
     
      proper synchronization.
     
    
   </p>
   <p>
    
     This idea led to the creation of the Actor Model in 1973 by Carl Hewitt.
    
    
     This model splits a program into actors that can do
    
    
     
      three things:
     
    
   </p>
   <ul>
    <li>
     
      Send messages to
     
     
      
       other actors
      
     
    </li>
    <li>
     
      Create
     
     
      
       new actors
      
     
    </li>
    <li>
     
      Define the behavior for the next message the
     
     
      
       actor receives
      
     
    </li>
   </ul>
   <p>
    
     Each actor has an address that’s conceptually similar to an email address, and actors can only communicate with the actors whose addresses they have.
    
    
     This address can be received in a message or obtained by creating a
    
    
     
      new actor.
     
    
   </p>
   <p>
    
     The actor model separates the communication mechanism from the functionality of each actor.
    
    
     This has resulted in implementations that allow us to write highly parallelizable code without having to deal with
    
    
     
      thread primitives.
     
    
   </p>
   <p>
    
     The oldest and most stable implementation for C++ is
    
    <a id="_idIndexMarker284">
    </a>
    
     CAF (
    
    <a href="https://www.actor-framework.org/">
     
      https://www.actor-framework.org/
     
    </a>
    
     ).
    
    
     A newer
    
    <a id="_idIndexMarker285">
    </a>
    
     alternative is
    
    <strong class="bold">
     
      Hiactor
     
    </strong>
    
     from Alibaba (
    
    <a href="https://github.com/alibaba/hiactor">
     
      https://github.com/alibaba/hiactor
     
    </a>
    
     ).
    
    
     However, the best-known implementation comes from the Java
    
    <a id="_idIndexMarker286">
    </a>
    
     world: the
    
    <strong class="bold">
     
      Akka
     
    </strong>
    
     <strong class="bold">
      
       toolkit
      
     </strong>
    
    
     
      (
     
    
    <a href="https://akka.io/">
     
      
       https://akka.io/
      
     
    </a>
    
     
      ).
     
    
   </p>
   <p>
    
     Let’s look at a simple example of implementing a chat between two actors using CAF.
    
    
     The following code defines the behavior of an actor as a Lambda, instantiates two chatting actors, and sends
    
    <a id="_idIndexMarker287">
    </a>
    
     messages between them.
    
    
     Each actor writes their message to
    
    
     
      the console:
     
    
   </p>
   <pre class="console">
behavior chatter(event_based_actor* self, const string&amp; name) {
return {
[=] (const string&amp; msg) {
cout &lt;&lt; name &lt;&lt; " received: " &lt;&lt; msg &lt;&lt; endl;
}
};
}
void caf_main(actor_system&amp; system) {
          auto alice = system.spawn(chatter, "Alice");
          auto bob = system.spawn(chatter, "Bob");
          scoped_actor self{system};
          self-&gt;send(alice, "Hello Alice!");
          self-&gt;send(bob, "Hello Bob!");
          self-&gt;send(alice, "How are you?");
          self-&gt;send(bob, "I'm good, thanks!");
          sleep_for(seconds(1));
}
CAF_MAIN()</pre>
   <p>
    
     Running this code
    
    <a id="_idIndexMarker288">
    </a>
    
     leads to different outputs.
    
    
     The best one is the one
    
    
     
      we expect:
     
    
   </p>
   <pre class="source-code">
Bob received: Hello Bob!
Alice received: Hello Alice!
Alice received: How are you?
Bob received: I'm good, thanks!</pre>
   <p>
    
     However, running the code repeatedly leads to various results, as
    
    
     
      shown here:
     
    
   </p>
   <pre class="source-code">
Bob received: Hello Bob!
Bob received: I'm good, thanks!
Alice received: Hello Alice!
Alice received: How are you?</pre>
   <p>
    
     We can also receive even
    
    
     
      worse outputs:
     
    
   </p>
   <pre class="source-code">
Alice received: Hello Alice!
BobAlice received: How are you? received: Hello Bob!
Bob received: I'm good, thanks!</pre>
   <p>
    
     These results make it obvious that actors run in parallel.
    
    
     It also shows that parallel programming can only mask its complexity so much underneath the magic of
    
    
     
      these frameworks.
     
    
   </p>
   <p>
    
     However, the actor model offers us a way to think about parallel programming in terms of objects that respond to requests and allows us to pick the type of actors we need and the type of communication that’s most fit for our system.
    
    
     The preceding example shows an event-based actor that receives asynchronous messages, but the framework supports blocking messages and various types of actors, depending on their
    
    
     
      life cycle.
     
    
   </p>
   <p>
    
     An advantage of the actor model is that we can distribute the actors on separate computers, thus allowing us to scale a model relatively easily.
    
    
     Of course, this means that we hit the challenges of distributed systems head-on from the very first line of code that uses
    
    
     
      this model.
     
    
   </p>
   <p>
    
     With that, we’ve seen what’s possible today within the standard library and by using the venerable actor model.
    
    
     But what still
    
    
     
      isn’t possible?
     
    
   </p>
   <h1 id="_idParaDest-87">
    <a id="_idTextAnchor086">
    </a>
    
     What we can’t do yet
    
   </h1>
   <p>
    
     As you can see, using parallel and concurrent code isn’t as easy as “
    
    <em class="italic">
     
      Write the code you want and let the tools and compiler make sense of it.
     
    </em>
    
     ” Perhaps we’ll be able to do this in the future with the intervention of AI, although based on my current experience using coding assistants, I have to say this seems very
    
    
     
      far away.
     
    
   </p>
   <p>
    
     Instead, you must structure your code for the programming model you choose.
    
    
     And if you start by writing the code base as a single-threaded application and without using functional constructs, changing it will prove difficult.
    
    
     I see parallels between objects and actors and, in theory, it might be possible to turn each object into an actor and each method into an event, but this seems idealistic.
    
    
     The reality is that there are still a lot of things that can go wrong when we switch from a synchronous to an event-based system, and a lot of them are very difficult to debug and require a deep understanding not only of the actor model but also of the framework you’re using for
    
    
     
      the actors.
     
    
   </p>
   <p>
    
     Your best bet is to redesign applications within the paradigm you choose: either the data-centric functional one or the behavior-centric
    
    
     
      actor model.
     
    
   </p>
   <p>
    
     With a data-centric paradigm, you look at the data in and at the set of transformations required to get to the desired output.
    
    
     Each of these transformations is immutable, therefore taking data as input and returning another data structure as output.
    
    
     As we’ve seen, each of these transformations is parallelizable.
    
    
     Occasionally, we’ll need our own algorithms or to optimize some of the existing ones, after which we can write our own implementations that follow the same pattern.
    
    
     We can fine-tune the system using the execution policy and end up with a system that’s highly customizable and relatively easy
    
    
     
      to optimize.
     
    
   </p>
   <p>
    
     With a behavior-centric paradigm, you look at your objects as actors that receive messages.
    
    
     This is closer to the original view of Alan Kay on object-oriented programming.
    
    
     As documented in the email exchange at
    
    <a href="https://www.purl.org/stefan_ram/pub/doc_kay_oop_en">
     
      https://www.purl.org/stefan_ram/pub/doc_kay_oop_en
     
    </a>
    
     , a vision focused not on classes but on messaging, and most closely implemented in Smalltalk.
    
    
     You build your application from the ground up using actors and their messaging mechanics and test that the output is what you expect.
    
    
     You need to know about the types of actors and the types of messaging available in detail so that you can pick the ones that fit your problem.
    
    
     As shown in this example, actors don’t necessarily guarantee the order of execution, which may or may not be a concern for your system.
    
    
     This leads to a highly scalable system, but one that’s more difficult to understand
    
    
     
      and debug.
     
    
   </p>
   <p>
    
     This means we can’t automatically translate applications that are written to be synchronous and single-threaded into parallel or concurrent systems.
    
    
     Most of the time, a redesign
    
    
     
      is required.
     
    
   </p>
   <h1 id="_idParaDest-88">
    <a id="_idTextAnchor087">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     Is there a simple way to do parallelism and concurrency in C++?
    
    
     It’s easier than it used to be, in that we rarely need to create our own threads and deal with their synchronization unless we’re building infrastructure code.
    
    
     We don’t necessarily need external libraries or tools since STL supports parallel execution for
    
    
     
      many algorithms.
     
    
   </p>
   <p>
    
     However, we can’t avoid the essential complexity of parallel and concurrent programming.
    
    
     Programs that take advantage of it need to be structured differently, have additional constraints, and require a different mindset and a different design paradigm.
    
    
     This isn’t a C++ problem – it’s a problem for any attempt
    
    
     
      at parallelism.
     
    
   </p>
   <p>
    
     Therefore, the conclusion is that it can be simpler than it used to be if we make the right choices, but it’s still
    
    
     
      very complicated.
     
    
   </p>
   <p>
    
     In the next chapter, we’ll ask the question of whether the fastest form of C++ is
    
    
     
      inline assembly.
     
    
   </p>
  </div>
 </body></html>