<html><head></head><body>
  <div id="_idContainer031">
   <h1 class="chapter-number" id="_idParaDest-80">
    <a id="_idTextAnchor079">
    </a>
    <span class="koboSpan" id="kobo.1.1">
     7
    </span>
   </h1>
   <h1 id="_idParaDest-81">
    <a id="_idTextAnchor080">
    </a>
    <span class="koboSpan" id="kobo.2.1">
     There’s No Simple Way to Do Parallelism and Concurrency in C++
    </span>
   </h1>
   <p class="italic-heading">
    <em class="italic">
     <span class="koboSpan" id="kobo.3.1">
      Unless we rethink OOP
     </span>
    </em>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.4.1">
       and FP
      </span>
     </em>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.5.1">
     To do parallelism and concurrency in C++, we used to require either separate libraries (for example, Boost) or OS primitives.
    </span>
    <span class="koboSpan" id="kobo.5.2">
     With the introduction of functional programming constructs, parallelism and concurrency have become easier, within
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.6.1">
      certain constraints.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.7.1">
     In this chapter, we’re going to cover the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.8.1">
      main topics:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.9.1">
      Defining parallelism
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.10.1">
       and concurrency
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.11.1">
      Common issues with parallelism
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.12.1">
       and concurrency
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.13.1">
      Functional programming to
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.14.1">
       the rescue!
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.15.1">
      The
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.16.1">
       Actor Model
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.17.1">
      What we can’t
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.18.1">
       do yet
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-82">
    <a id="_idTextAnchor081">
    </a>
    <span class="koboSpan" id="kobo.19.1">
     Technical requirements
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.20.1">
     The code for this chapter is available on GitHub at
    </span>
    <a href="https://github.com/PacktPublishing/Debunking-CPP-Myths">
     <span class="koboSpan" id="kobo.21.1">
      https://github.com/PacktPublishing/Debunking-CPP-Myths
     </span>
    </a>
    <span class="koboSpan" id="kobo.22.1">
     , in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.23.1">
      ch7
     </span>
    </strong>
    <span class="koboSpan" id="kobo.24.1">
     folder.
    </span>
    <span class="koboSpan" id="kobo.24.2">
     The code has been compiled with Makefiles using g++ and C++ 20.
    </span>
    <span class="koboSpan" id="kobo.24.3">
     The example regarding the Actor Model uses
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.25.1">
      C++ Actor Framework
     </span>
    </strong>
    <span class="koboSpan" id="kobo.26.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.27.1">
      CAF
     </span>
    </strong>
    <span class="koboSpan" id="kobo.28.1">
     ) (
    </span>
    <a href="https://www.actor-framework.org/">
     <span class="koboSpan" id="kobo.29.1">
      https://www.actor-framework.org/
     </span>
    </a>
    <span class="koboSpan" id="kobo.30.1">
     ) so you’ll need to install it
    </span>
    <a id="_idIndexMarker271">
    </a>
    <span class="koboSpan" id="kobo.31.1">
     before working on it.
    </span>
    <span class="koboSpan" id="kobo.31.2">
     On Ubuntu, it can be installed by running
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.32.1">
      apt install libcaf-dev
     </span>
    </strong>
    <span class="koboSpan" id="kobo.33.1">
     .
    </span>
    <span class="koboSpan" id="kobo.33.2">
     The CAF version that’s used in the examples is the stable Ubuntu version of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.34.1">
      library:
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.35.1">
       0.17
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.36.1">
      .
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-83">
    <a id="_idTextAnchor082">
    </a>
    <span class="koboSpan" id="kobo.37.1">
     Defining parallelism and concurrency
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.38.1">
     My first computer was an
    </span>
    <a id="_idIndexMarker272">
    </a>
    <span class="koboSpan" id="kobo.39.1">
     HC-90, a ZX-80 clone built in Romania.
    </span>
    <span class="koboSpan" id="kobo.39.2">
     I owned two versions: the first required a cassette player to load programs.
    </span>
    <span class="koboSpan" id="kobo.39.3">
     Despite this inconvenience, it had a big advantage over its main competitor at the time, the CHIP computer, yet another ZX-80 clone
    </span>
    <a id="_idIndexMarker273">
    </a>
    <span class="koboSpan" id="kobo.40.1">
     built in Romania.
    </span>
    <span class="koboSpan" id="kobo.40.2">
     You see, the CHIP computer required a cassette to load into its OS, while the HC-90 had enough EPROM memory to boot directly into a BASIC interpreter.
    </span>
    <span class="koboSpan" id="kobo.40.3">
     The second version I owned was much better: it had a 5-inch floppy disk reader, which meant that you could load programs
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.41.1">
      much faster.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.42.1">
     In both versions, the BASIC interpreter
    </span>
    <a id="_idIndexMarker274">
    </a>
    <span class="koboSpan" id="kobo.43.1">
     was your interface with the computer, and since not many programs were available other than games, I spent some of my time in high school writing BASIC programs and playing games.
    </span>
    <span class="koboSpan" id="kobo.43.2">
     Eventually, I realized that I wanted more than BASIC.
    </span>
    <span class="koboSpan" id="kobo.43.3">
     I played a bit with graphics and sound, but the problem was that everything was very slow.
    </span>
    <span class="koboSpan" id="kobo.43.4">
     This made me learn ZX 80 assembler, which was an adventure.
    </span>
    <span class="koboSpan" id="kobo.43.5">
     It was very easy to make mistakes in assembler, which resulted in a reboot and the loss of all work.
    </span>
    <span class="koboSpan" id="kobo.43.6">
     It wasn’t a sustainable way to program, but it made me appreciate the programming luxuries of today much more.
    </span>
    <span class="koboSpan" id="kobo.43.7">
     Imagine this: I can compile and run tests on my programs on my computer and save my changes to a source
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.44.1">
      control system.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.45.1">
     I knew back then that I wanted the graphics and sounds to feel faster.
    </span>
    <span class="koboSpan" id="kobo.45.2">
     What I didn’t realize was that I had a fundamental limitation: there was only one CPU (or one core, as we would say today), which meant that the graphics, sound, and logic code had to run sequentially.
    </span>
    <span class="koboSpan" id="kobo.45.3">
     The CPU could receive a command to play a sound, then go to display some graphics, and then make some computations, and since there was a very short lag between the instruction and the actual sound playing or the image showing, it seemed as if these tasks were running in parallel.
    </span>
    <span class="koboSpan" id="kobo.45.4">
     But they weren’t: they were concurrent.
    </span>
    <span class="koboSpan" id="kobo.45.5">
     You could observe this if you loaded the system to the maximum since the image and sound were no
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.46.1">
      longer synchronized.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.47.1">
     What would have happened if I had more processors or more cores to work with?
    </span>
    <span class="koboSpan" id="kobo.47.2">
     Well, I could have defined various tasks that can be run on separate processors.
    </span>
    <span class="koboSpan" id="kobo.47.3">
     A capable scheduler could take these tasks and run them in parallel to fill the capacity of the idle CPUs.
    </span>
    <span class="koboSpan" id="kobo.47.4">
     If the tasks are well-defined, we can squeeze a lot of the power from the available cores and get the answer
    </span>
    <a id="_idIndexMarker275">
    </a>
    <span class="koboSpan" id="kobo.48.1">
     faster.
    </span>
    <span class="koboSpan" id="kobo.48.2">
     This
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.49.1">
      is
     </span>
    </span>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.50.1">
       parallelism
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.51.1">
      .
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.52.1">
     A nuance to this definition, which will become useful in this chapter, comes from the Haskell community (see
    </span>
    <a href="https://wiki.haskell.org/Parallelism_vs._Concurrency">
     <span class="koboSpan" id="kobo.53.1">
      https://wiki.haskell.org/Parallelism_vs._Concurrency
     </span>
    </a>
    <span class="koboSpan" id="kobo.54.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.54.2">
     They make a big distinction between a parallel functional program and a concurrent functional program, therefore presuming both programs use immutability.
    </span>
    <span class="koboSpan" id="kobo.54.3">
     Parallel functional programs use cores to execute faster, but they’re deterministic, and the meaning of the program is unchanged whether we execute it sequentially or in parallel.
    </span>
    <span class="koboSpan" id="kobo.54.4">
     Contrast this with functional concurrent programs that run concurrent threads, each doing I/O operations, and that are non-deterministic since we don’t know the order
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.55.1">
      of operations.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.56.1">
     Unfortunately, as is common in software development, these terms have a life of their own.
    </span>
    <span class="koboSpan" id="kobo.56.2">
     You might encounter people who believe concurrency and parallelism are completely different things.
    </span>
    <span class="koboSpan" id="kobo.56.3">
     In researching this matter, I came upon a conversation on StackOverflow stating the argument that concurrency is a superset of parallelism since concurrency refers to a set of methods that are used for managing multiple threads.
    </span>
    <span class="koboSpan" id="kobo.56.4">
     And this may well be how some computer science books treat
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.57.1">
      the topic.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.58.1">
     The need for clarity constrains us to pick one definition.
    </span>
    <span class="koboSpan" id="kobo.58.2">
     I’ll pick the definition that closely matches my formative years of
    </span>
    <a id="_idIndexMarker276">
    </a>
    <span class="koboSpan" id="kobo.59.1">
     programming:
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.60.1">
      concurrency
     </span>
    </strong>
    <span class="koboSpan" id="kobo.61.1">
     is when multiple operations seem to run at the same time, while parallelism is when they do.
    </span>
    <span class="koboSpan" id="kobo.61.2">
     This difference, while seemingly simple, leads to a difference in intent when designing the program.
    </span>
    <span class="koboSpan" id="kobo.61.3">
     When we design a program expecting it to run in parallel, we define operations that can run in parallel and figure out their order.
    </span>
    <span class="koboSpan" id="kobo.61.4">
     We try to squeeze time from the CPU by splitting a larger task into parts that can run independently, without them affecting each other much.
    </span>
    <span class="koboSpan" id="kobo.61.5">
     The intent is different when we design a program expecting it to run concurrently: we optimize the response time by pushing the longer tasks into the dead times of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.62.1">
      the CPU.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.63.1">
     Both these programming models are challenging, albeit in different ways.
    </span>
    <span class="koboSpan" id="kobo.63.2">
     Let’s remind ourselves of the common issues we face when
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.64.1">
      using them.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-84">
    <a id="_idTextAnchor083">
    </a>
    <span class="koboSpan" id="kobo.65.1">
     Common issues with parallelism and concurrency
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.66.1">
     I’m convinced that the fundamental problem of software development is to mentally translate the static view of a system – the code – into its dynamic behavior, or what the program does when it runs.
    </span>
    <span class="koboSpan" id="kobo.66.2">
     Programmers run code in their heads every time they’re considering a change, often automatically but always at the expense of mental energy.
    </span>
    <span class="koboSpan" id="kobo.66.3">
     This is one of the reasons why I believe practices such as
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.67.1">
      test-driven development
     </span>
    </strong>
    <span class="koboSpan" id="kobo.68.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.69.1">
      TDD
     </span>
    </strong>
    <span class="koboSpan" id="kobo.70.1">
     ) and
    </span>
    <a id="_idIndexMarker277">
    </a>
    <span class="koboSpan" id="kobo.71.1">
     incremental design are useful; they allow us to move part of this mental energy spending from our brains to running the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.72.1">
      tests repeatedly.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.73.1">
     This
    </span>
    <a id="_idIndexMarker278">
    </a>
    <span class="koboSpan" id="kobo.74.1">
     fundamental problem is already difficult for single threads, but for parallel or concurrent designs, it adds a new level of challenge.
    </span>
    <span class="koboSpan" id="kobo.74.2">
     We not only need to imagine what the code will do but also how the code will interact with the other parts of the code that run at the same time.
    </span>
    <span class="koboSpan" id="kobo.74.3">
     So, imagination and the brain energy required to make sense of
    </span>
    <a id="_idIndexMarker279">
    </a>
    <span class="koboSpan" id="kobo.75.1">
     parallel execution is the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.76.1">
      first challenge.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.77.1">
     Then, there are the purely
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.78.1">
      technical challenges.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.79.1">
     When resources are shared, resource management becomes much harder, particularly when multiple threads can modify values.
    </span>
    <span class="koboSpan" id="kobo.79.2">
     One thread might be using a value that was already changed by another thread, thus leading to wrong results.
    </span>
    <span class="koboSpan" id="kobo.79.3">
     A memory address might be freed by one thread and then another thread attempts to read or write
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.80.1">
      to it.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.81.1">
     Sharing the same infrastructure isn’t easy either.
    </span>
    <span class="koboSpan" id="kobo.81.2">
     One thread might take all the resources due to a bug, thus blocking other threads for long periods.
    </span>
    <span class="koboSpan" id="kobo.81.3">
     This is less of an issue when the program is formed of separate tasks using multiple cores, but it still leads to reduced performance since the separate tasks need to converge at some point.
    </span>
    <span class="koboSpan" id="kobo.81.4">
     Threads could wait for one another indefinitely or until a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.82.1">
      timeout occurs.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.83.1">
     Implementing programs that work with parallel or concurrent tasks from scratch is one of the most difficult things you might need to do as a programmer.
    </span>
    <span class="koboSpan" id="kobo.83.2">
     I remember when I once debugged a synchronization issue between threads for a week, and I knew my technical lead and my project manager were starting to doubt my abilities.
    </span>
    <span class="koboSpan" id="kobo.83.3">
     I didn’t doubt myself, but I didn’t like how long it took me to finally figure
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.84.1">
      it out.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.85.1">
     For this reason, libraries and patterns have appeared that help us implement concurrent and parallel programs.
    </span>
    <span class="koboSpan" id="kobo.85.2">
     Most of them invite us to pass a function that represents a thread to a method that sorts out some of the complexities of thread synchronization.
    </span>
    <span class="koboSpan" id="kobo.85.3">
     This is possible by separating the tasks that we might need into types of tasks.
    </span>
    <span class="koboSpan" id="kobo.85.4">
     Additionally, architecture models such as MapReduce that are implemented by Hadoop and inspired by functional programming help us deal with
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.86.1">
      large-scale parallelization.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.87.1">
     As we can see, we can’t discuss modern approaches to parallel programming without discussing the functional programming approach
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.88.1">
      to it.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-85">
    <a id="_idTextAnchor084">
    </a>
    <span class="koboSpan" id="kobo.89.1">
     Functional programming to the rescue!
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.90.1">
     As we’ve seen, one of the problems with parallel and concurrent tasks is the shared access to resources.
    </span>
    <span class="koboSpan" id="kobo.90.2">
     Functional programming, in its pure form, solves this out of the box through immutability.
    </span>
    <span class="koboSpan" id="kobo.90.3">
     Since
    </span>
    <a id="_idIndexMarker280">
    </a>
    <span class="koboSpan" id="kobo.91.1">
     everything is immutable by default, and since any change to a value is made by pointing to a changed value instead of modifying the initial one, threads are never at risk of modifying data used by other threads.
    </span>
    <span class="koboSpan" id="kobo.91.2">
     We discussed how to achieve this when we discussed the different paradigms available
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.92.1">
      in C++.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.93.1">
     But there’s more: functional programming offers us parallelizable algorithms out of the box.
    </span>
    <span class="koboSpan" id="kobo.93.2">
     The C++ standardization committee recognized this when introducing functional algorithms along with an execution policy that allows you to run operations on collections
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.94.1">
      in parallel.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.95.1">
     Let’s look at a simple example: we want to compute the sum of squares of the values in a collection.
    </span>
    <span class="koboSpan" id="kobo.95.2">
     The functional version of this type of algorithm is a typical map-reduce one: first, we pass in the initial collection and map it to a collection that contains the squares of the values, after which we reduce it by adding all the elements.
    </span>
    <span class="koboSpan" id="kobo.95.3">
     In STL, these operations are implemented in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.96.1">
      std::transform
     </span>
    </strong>
    <span class="koboSpan" id="kobo.97.1">
     and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.98.1">
      std::reduce
     </span>
    </strong>
    <span class="koboSpan" id="kobo.99.1">
     , respectively.
    </span>
    <span class="koboSpan" id="kobo.99.2">
     A version that combines them is available in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.100.1">
      std::transform_reduce
     </span>
    </strong>
    <span class="koboSpan" id="kobo.101.1">
     , but we’ll ignore it for now to make the example
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.102.1">
      more relevant.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.103.1">
     Here’s what the function
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.104.1">
      looks like:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.105.1">
long long sumOfSquares(const vector&lt;int&gt; numbers){
     vector&lt;long long&gt; squaredNumbers(numbers.size());
     auto squareNumber = [](const long it ){ return it * it; };
     transform(numbers.begin(), numbers.end(), squaredNumbers.begin(), squareNumber);
     return reduce(squaredNumbers.begin(), squaredNumbers.end(), 0);
}
TEST_CASE("sum of squares in parallel") {
        vector&lt;int&gt; numbers{234, 423, 345, 212, 112, 2412};
        CHECK_EQ(6227942, sumOfSquares(numbers));
}</span></pre>
   <p>
    <span class="koboSpan" id="kobo.106.1">
     The only thing we need to do to
    </span>
    <a id="_idIndexMarker281">
    </a>
    <span class="koboSpan" id="kobo.107.1">
     run these operations in parallel is to add a parameter to both functional algorithms that specifies the execution policy.
    </span>
    <span class="koboSpan" id="kobo.107.2">
     The execution policy we’ll use is
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.108.1">
      std::execution::par
     </span>
    </strong>
    <span class="koboSpan" id="kobo.109.1">
     , an instance of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.110.1">
      std::execution_parallel
     </span>
    </strong>
    <span class="koboSpan" id="kobo.111.1">
     provided by the standard library that specifies that the algorithms need to run
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.112.1">
      in parallel:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.113.1">
long long sumOfSquares(const vector&lt;int&gt; numbers){
     vector&lt;long long&gt; squaredNumbers(numbers.size());
     auto squareNumber = [](const long it ){ return it * it; };
     transform(</span><strong class="bold"><span class="koboSpan" id="kobo.114.1">std::execution::par</span></strong><span class="koboSpan" id="kobo.115.1">, numbers.begin(), numbers.end(), squaredNumbers.begin(), squareNumber);
     return reduce(</span><strong class="bold"><span class="koboSpan" id="kobo.116.1">std::execution::par</span></strong><span class="koboSpan" id="kobo.117.1">, squaredNumbers.begin(), squaredNumbers.end(), 0);
}</span></pre>
   <p>
    <span class="koboSpan" id="kobo.118.1">
     From this example, we can notice a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.119.1">
      few things.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.120.1">
     First, it’s very easy to switch between the different execution policies when you use functional programming.
    </span>
    <span class="koboSpan" id="kobo.120.2">
     This enables us to fix issues related to parallelization more easily and to optimize code.
    </span>
    <span class="koboSpan" id="kobo.120.3">
     Running the algorithms in parallel isn’t necessarily better than sequential execution in all cases.
    </span>
    <span class="koboSpan" id="kobo.120.4">
     It’s likely that for small numbers or short collections, the resources that are used to start threads and manage them are larger than the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.121.1">
      time saved.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.122.1">
     Second, we can use the execution policy as a parameter or as a general configuration.
    </span>
    <span class="koboSpan" id="kobo.122.2">
     This would allow us to test that algorithms work sequentially in isolation from thread synchronization.
    </span>
    <span class="koboSpan" id="kobo.122.3">
     It also allows us to decide what policy to use at runtime, depending on a few factors related to the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.123.1">
      input data.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.124.1">
     Third, each of these
    </span>
    <a id="_idIndexMarker282">
    </a>
    <span class="koboSpan" id="kobo.125.1">
     execution policies imposes limitations on your code.
    </span>
    <span class="koboSpan" id="kobo.125.2">
     For example, the parallel policy we’ve used here requires that the iterators aren’t invalidated in the process, thus disallowing write access and the usage of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.126.1">
      std::back_inserter
     </span>
    </strong>
    <span class="koboSpan" id="kobo.127.1">
     .
    </span>
    <span class="koboSpan" id="kobo.127.2">
     Other execution policies are available in STL besides
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.128.1">
      std::execution::parallel_policy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.129.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.130.1">
      std::execution::sequenced_policy:
     </span>
    </strong>
    <span class="koboSpan" id="kobo.131.1">
     ,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.132.1">
      std::execution::parallel_unsequenced_policy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.133.1">
     , and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.134.1">
      std::execution::unsequenced_policy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.135.1">
     , with the remark that the standardization committee might add built-in policies for
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.136.1">
      std::parallel::cuda
     </span>
    </strong>
    <span class="koboSpan" id="kobo.137.1">
     and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.138.1">
      std::parallel::opencl
     </span>
    </strong>
    <span class="koboSpan" id="kobo.139.1">
     .
    </span>
    <span class="koboSpan" id="kobo.139.2">
     Each of these policies has its limitations and constraints, so the most portable code is what’s used for maximum immutability and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.140.1">
      functional algorithms.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.141.1">
     Fourth, the algorithms run in sequence, but each of them is parallelized.
    </span>
    <span class="koboSpan" id="kobo.141.2">
     If we need to squeeze more from our computing resources, we either use the combined
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.142.1">
      std::transform_reduce
     </span>
    </strong>
    <span class="koboSpan" id="kobo.143.1">
     algorithm or write our own algorithm combining the two.
    </span>
    <span class="koboSpan" id="kobo.143.2">
     Once again, it’s important to realize that running code in parallel is a trade-off: some of the computing resources will be spent on starting and synchronizing threads, which for some configurations might not add a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.144.1">
      big benefit.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.145.1">
     Finally, the fifth point is that the map-reduce pattern is very powerful.
    </span>
    <span class="koboSpan" id="kobo.145.2">
     Any unary function can be used for
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.146.1">
      map
     </span>
    </strong>
    <span class="koboSpan" id="kobo.147.1">
     and any binary function can be used for
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.148.1">
      reduce
     </span>
    </strong>
    <span class="koboSpan" id="kobo.149.1">
     , and we can bind the parameters of functions that require more values until we get unary or binary functions.
    </span>
    <span class="koboSpan" id="kobo.149.2">
     Maps and reduces can be chained in many ways.
    </span>
    <span class="koboSpan" id="kobo.149.3">
     If you start looking at your programs as data in/data out, you’ll notice that all our programs can be written as data in/functional transformations/data out, with many of the functional transformations being
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.150.1">
      map
     </span>
    </strong>
    <span class="koboSpan" id="kobo.151.1">
     /
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.152.1">
      reduce
     </span>
    </strong>
    <span class="koboSpan" id="kobo.153.1">
     operations.
    </span>
    <span class="koboSpan" id="kobo.153.2">
     This realization leads to a very powerful programming model since we can turn parallelization on or off for all or parts of the algorithms.
    </span>
    <span class="koboSpan" id="kobo.153.3">
     Occasionally, we may want to write our own algorithms that optimize parallelization for important parts of the code, but we get most of it
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.154.1">
      for free.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.155.1">
     The only catch is that we need to use immutable data and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.156.1">
      functional algorithms.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.157.1">
     The design style we’ve discussed so far is data-centric since it focuses on the data structures and their transformations.
    </span>
    <span class="koboSpan" id="kobo.157.2">
     As always when it comes to software design and architecture, we have the alternative to focus on behavior.
    </span>
    <span class="koboSpan" id="kobo.157.3">
     Surely enough, a design style that splits the program into behaviors and allows for parallel programming has emerged in the form of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.158.1">
      Actor Model.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-86">
    <a id="_idTextAnchor085">
    </a>
    <span class="koboSpan" id="kobo.159.1">
     The Actor Model
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.160.1">
     The world around us moves in parallel
    </span>
    <a id="_idIndexMarker283">
    </a>
    <span class="koboSpan" id="kobo.161.1">
     very naturally.
    </span>
    <span class="koboSpan" id="kobo.161.2">
     Each tree, plant, or person does their own thing, and occasionally they interact, and things change for the parties involved.
    </span>
    <span class="koboSpan" id="kobo.161.3">
     So, we already have a mental model of how parallel programs could work: separate entities that encapsulate their behavior and communicate somehow, on an infrastructure that ensures
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.162.1">
      proper synchronization.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.163.1">
     This idea led to the creation of the Actor Model in 1973 by Carl Hewitt.
    </span>
    <span class="koboSpan" id="kobo.163.2">
     This model splits a program into actors that can do
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.164.1">
      three things:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.165.1">
      Send messages to
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.166.1">
       other actors
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.167.1">
      Create
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.168.1">
       new actors
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.169.1">
      Define the behavior for the next message the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.170.1">
       actor receives
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.171.1">
     Each actor has an address that’s conceptually similar to an email address, and actors can only communicate with the actors whose addresses they have.
    </span>
    <span class="koboSpan" id="kobo.171.2">
     This address can be received in a message or obtained by creating a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.172.1">
      new actor.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.173.1">
     The actor model separates the communication mechanism from the functionality of each actor.
    </span>
    <span class="koboSpan" id="kobo.173.2">
     This has resulted in implementations that allow us to write highly parallelizable code without having to deal with
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.174.1">
      thread primitives.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.175.1">
     The oldest and most stable implementation for C++ is
    </span>
    <a id="_idIndexMarker284">
    </a>
    <span class="koboSpan" id="kobo.176.1">
     CAF (
    </span>
    <a href="https://www.actor-framework.org/">
     <span class="koboSpan" id="kobo.177.1">
      https://www.actor-framework.org/
     </span>
    </a>
    <span class="koboSpan" id="kobo.178.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.178.2">
     A newer
    </span>
    <a id="_idIndexMarker285">
    </a>
    <span class="koboSpan" id="kobo.179.1">
     alternative is
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.180.1">
      Hiactor
     </span>
    </strong>
    <span class="koboSpan" id="kobo.181.1">
     from Alibaba (
    </span>
    <a href="https://github.com/alibaba/hiactor">
     <span class="koboSpan" id="kobo.182.1">
      https://github.com/alibaba/hiactor
     </span>
    </a>
    <span class="koboSpan" id="kobo.183.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.183.2">
     However, the best-known implementation comes from the Java
    </span>
    <a id="_idIndexMarker286">
    </a>
    <span class="koboSpan" id="kobo.184.1">
     world: the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.185.1">
      Akka
     </span>
    </strong>
    <span class="No-Break">
     <strong class="bold">
      <span class="koboSpan" id="kobo.186.1">
       toolkit
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.187.1">
      (
     </span>
    </span>
    <a href="https://akka.io/">
     <span class="No-Break">
      <span class="koboSpan" id="kobo.188.1">
       https://akka.io/
      </span>
     </span>
    </a>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.189.1">
      ).
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.190.1">
     Let’s look at a simple example of implementing a chat between two actors using CAF.
    </span>
    <span class="koboSpan" id="kobo.190.2">
     The following code defines the behavior of an actor as a Lambda, instantiates two chatting actors, and sends
    </span>
    <a id="_idIndexMarker287">
    </a>
    <span class="koboSpan" id="kobo.191.1">
     messages between them.
    </span>
    <span class="koboSpan" id="kobo.191.2">
     Each actor writes their message to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.192.1">
      the console:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.193.1">
behavior chatter(event_based_actor* self, const string&amp; name) {
return {
[=] (const string&amp; msg) {
cout &lt;&lt; name &lt;&lt; " received: " &lt;&lt; msg &lt;&lt; endl;
}
};
}
void caf_main(actor_system&amp; system) {
          auto alice = system.spawn(chatter, "Alice");
          auto bob = system.spawn(chatter, "Bob");
          scoped_actor self{system};
          self-&gt;send(alice, "Hello Alice!");
          self-&gt;send(bob, "Hello Bob!");
          self-&gt;send(alice, "How are you?");
          self-&gt;send(bob, "I'm good, thanks!");
          sleep_for(seconds(1));
}
CAF_MAIN()</span></pre>
   <p>
    <span class="koboSpan" id="kobo.194.1">
     Running this code
    </span>
    <a id="_idIndexMarker288">
    </a>
    <span class="koboSpan" id="kobo.195.1">
     leads to different outputs.
    </span>
    <span class="koboSpan" id="kobo.195.2">
     The best one is the one
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.196.1">
      we expect:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.197.1">
Bob received: Hello Bob!
</span><span class="koboSpan" id="kobo.197.2">Alice received: Hello Alice!
</span><span class="koboSpan" id="kobo.197.3">Alice received: How are you?
</span><span class="koboSpan" id="kobo.197.4">Bob received: I'm good, thanks!</span></pre>
   <p>
    <span class="koboSpan" id="kobo.198.1">
     However, running the code repeatedly leads to various results, as
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.199.1">
      shown here:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.200.1">
Bob received: Hello Bob!
</span><span class="koboSpan" id="kobo.200.2">Bob received: I'm good, thanks!
</span><span class="koboSpan" id="kobo.200.3">Alice received: Hello Alice!
</span><span class="koboSpan" id="kobo.200.4">Alice received: How are you?</span></pre>
   <p>
    <span class="koboSpan" id="kobo.201.1">
     We can also receive even
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.202.1">
      worse outputs:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.203.1">
Alice received: Hello Alice!
</span><span class="koboSpan" id="kobo.203.2">BobAlice received: How are you? </span><span class="koboSpan" id="kobo.203.3">received: Hello Bob!
</span><span class="koboSpan" id="kobo.203.4">Bob received: I'm good, thanks!</span></pre>
   <p>
    <span class="koboSpan" id="kobo.204.1">
     These results make it obvious that actors run in parallel.
    </span>
    <span class="koboSpan" id="kobo.204.2">
     It also shows that parallel programming can only mask its complexity so much underneath the magic of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.205.1">
      these frameworks.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.206.1">
     However, the actor model offers us a way to think about parallel programming in terms of objects that respond to requests and allows us to pick the type of actors we need and the type of communication that’s most fit for our system.
    </span>
    <span class="koboSpan" id="kobo.206.2">
     The preceding example shows an event-based actor that receives asynchronous messages, but the framework supports blocking messages and various types of actors, depending on their
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.207.1">
      life cycle.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.208.1">
     An advantage of the actor model is that we can distribute the actors on separate computers, thus allowing us to scale a model relatively easily.
    </span>
    <span class="koboSpan" id="kobo.208.2">
     Of course, this means that we hit the challenges of distributed systems head-on from the very first line of code that uses
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.209.1">
      this model.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.210.1">
     With that, we’ve seen what’s possible today within the standard library and by using the venerable actor model.
    </span>
    <span class="koboSpan" id="kobo.210.2">
     But what still
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.211.1">
      isn’t possible?
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-87">
    <a id="_idTextAnchor086">
    </a>
    <span class="koboSpan" id="kobo.212.1">
     What we can’t do yet
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.213.1">
     As you can see, using parallel and concurrent code isn’t as easy as “
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.214.1">
      Write the code you want and let the tools and compiler make sense of it.
     </span>
    </em>
    <span class="koboSpan" id="kobo.215.1">
     ” Perhaps we’ll be able to do this in the future with the intervention of AI, although based on my current experience using coding assistants, I have to say this seems very
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.216.1">
      far away.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.217.1">
     Instead, you must structure your code for the programming model you choose.
    </span>
    <span class="koboSpan" id="kobo.217.2">
     And if you start by writing the code base as a single-threaded application and without using functional constructs, changing it will prove difficult.
    </span>
    <span class="koboSpan" id="kobo.217.3">
     I see parallels between objects and actors and, in theory, it might be possible to turn each object into an actor and each method into an event, but this seems idealistic.
    </span>
    <span class="koboSpan" id="kobo.217.4">
     The reality is that there are still a lot of things that can go wrong when we switch from a synchronous to an event-based system, and a lot of them are very difficult to debug and require a deep understanding not only of the actor model but also of the framework you’re using for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.218.1">
      the actors.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.219.1">
     Your best bet is to redesign applications within the paradigm you choose: either the data-centric functional one or the behavior-centric
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.220.1">
      actor model.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.221.1">
     With a data-centric paradigm, you look at the data in and at the set of transformations required to get to the desired output.
    </span>
    <span class="koboSpan" id="kobo.221.2">
     Each of these transformations is immutable, therefore taking data as input and returning another data structure as output.
    </span>
    <span class="koboSpan" id="kobo.221.3">
     As we’ve seen, each of these transformations is parallelizable.
    </span>
    <span class="koboSpan" id="kobo.221.4">
     Occasionally, we’ll need our own algorithms or to optimize some of the existing ones, after which we can write our own implementations that follow the same pattern.
    </span>
    <span class="koboSpan" id="kobo.221.5">
     We can fine-tune the system using the execution policy and end up with a system that’s highly customizable and relatively easy
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.222.1">
      to optimize.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.223.1">
     With a behavior-centric paradigm, you look at your objects as actors that receive messages.
    </span>
    <span class="koboSpan" id="kobo.223.2">
     This is closer to the original view of Alan Kay on object-oriented programming.
    </span>
    <span class="koboSpan" id="kobo.223.3">
     As documented in the email exchange at
    </span>
    <a href="https://www.purl.org/stefan_ram/pub/doc_kay_oop_en">
     <span class="koboSpan" id="kobo.224.1">
      https://www.purl.org/stefan_ram/pub/doc_kay_oop_en
     </span>
    </a>
    <span class="koboSpan" id="kobo.225.1">
     , a vision focused not on classes but on messaging, and most closely implemented in Smalltalk.
    </span>
    <span class="koboSpan" id="kobo.225.2">
     You build your application from the ground up using actors and their messaging mechanics and test that the output is what you expect.
    </span>
    <span class="koboSpan" id="kobo.225.3">
     You need to know about the types of actors and the types of messaging available in detail so that you can pick the ones that fit your problem.
    </span>
    <span class="koboSpan" id="kobo.225.4">
     As shown in this example, actors don’t necessarily guarantee the order of execution, which may or may not be a concern for your system.
    </span>
    <span class="koboSpan" id="kobo.225.5">
     This leads to a highly scalable system, but one that’s more difficult to understand
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.226.1">
      and debug.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.227.1">
     This means we can’t automatically translate applications that are written to be synchronous and single-threaded into parallel or concurrent systems.
    </span>
    <span class="koboSpan" id="kobo.227.2">
     Most of the time, a redesign
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.228.1">
      is required.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-88">
    <a id="_idTextAnchor087">
    </a>
    <span class="koboSpan" id="kobo.229.1">
     Summary
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.230.1">
     Is there a simple way to do parallelism and concurrency in C++?
    </span>
    <span class="koboSpan" id="kobo.230.2">
     It’s easier than it used to be, in that we rarely need to create our own threads and deal with their synchronization unless we’re building infrastructure code.
    </span>
    <span class="koboSpan" id="kobo.230.3">
     We don’t necessarily need external libraries or tools since STL supports parallel execution for
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.231.1">
      many algorithms.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.232.1">
     However, we can’t avoid the essential complexity of parallel and concurrent programming.
    </span>
    <span class="koboSpan" id="kobo.232.2">
     Programs that take advantage of it need to be structured differently, have additional constraints, and require a different mindset and a different design paradigm.
    </span>
    <span class="koboSpan" id="kobo.232.3">
     This isn’t a C++ problem – it’s a problem for any attempt
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.233.1">
      at parallelism.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.234.1">
     Therefore, the conclusion is that it can be simpler than it used to be if we make the right choices, but it’s still
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.235.1">
      very complicated.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.236.1">
     In the next chapter, we’ll ask the question of whether the fastest form of C++ is
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.237.1">
      inline assembly.
     </span>
    </span>
   </p>
  </div>
 </body></html>