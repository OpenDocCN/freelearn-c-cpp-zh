- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Promises and Futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we learned the foundations of managing and synchronizing
    thread execution using C++. We also mentioned in [*Chapter 3*](B22219_03.xhtml#_idTextAnchor051)
    that to return values from a thread, we could use promises and futures. Now it’s
    time to learn how to do that and much more using these features in C++.
  prefs: []
  type: TYPE_NORMAL
- en: '**Futures** and **promises** are essential blocks for achieving asynchronous
    programming. They define a way to manage the result of a task that will be completed
    in the future, usually in a separate thread.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What are promises and futures?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are shared futures and how are they different from regular futures?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are packaged tasks and when do we use them?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we check future statuses and errors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the benefits and drawbacks of using promises and futures?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of real-life scenarios and solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Promises and futures have been available since C++11, but some examples implemented
    in this chapter use features from C++20, such as **std::jthread** , so the code
    shown in this chapter can be compiled by compilers supporting C++20.
  prefs: []
  type: TYPE_NORMAL
- en: Please check the *Technical requirements* section in [*Chapter 3*](B22219_03.xhtml#_idTextAnchor051)
    for guidance on how to install GCC 13 and Clang 8 compilers.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find all the complete code in the following GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The examples for this chapter are located under the **Chapter_06** folder.
    All source code files can be compiled using CMake as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Executable binaries will be generated under the **bin** directory.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring promises and futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **future** is an object that represents some undetermined result that will
    be completed sometime in the future. A **promise** is the provider of that result.
  prefs: []
  type: TYPE_NORMAL
- en: Promises and futures have been part of the C++ standard since version C++11
    and are available by including the **<future>** header file, promises via the
    class **std::promise** and futures via the class **std::future** .
  prefs: []
  type: TYPE_NORMAL
- en: The **std::promise** and **std::future** pair implements a one-shot producer-consumer
    channel with the promise as the producer and the future as the consumer. The consumer
    ( **std::future** ) can block until the result of the producer ( **std::promise**
    ) is available.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Promise-future communication channel](img/B22219_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Promise-future communication channel
  prefs: []
  type: TYPE_NORMAL
- en: Many modern programming languages provide similar asynchronous approaches, such
    as Python (with the **asyncio** library), Scala (in the **scala.concurrent** library),
    JavaScript (in its core library), Rust (in its **Standard Library** ( **std**
    ) or crates such as **promising_future** ), Swift (in the Combine framework),
    and Kotlin, among others.
  prefs: []
  type: TYPE_NORMAL
- en: The basic principle behind achieving asynchronous execution using promises and
    futures is that a function we want to run to generate a result is executed in
    the background, using a new thread or the current one, and a future object is
    used by the initial thread to retrieve the result computed by the function. This
    result value will be stored when the function finishes, so meanwhile, the future
    will be used as a placeholder. The asynchronous function will use a promise object
    to store the result in the future with no need for explicit synchronization mechanisms
    between the initial thread and the background one. When the value is needed by
    the initial thread, it will be retrieved from the future object. If the value
    is still not ready, the initial thread execution will be blocked until the future
    becomes ready.
  prefs: []
  type: TYPE_NORMAL
- en: With this idea, making a function run asynchronously becomes easy. We only need
    to be aware that the function can run on a separate thread, so we need to avoid
    data races, but result communication and synchronization between threads is managed
    by the promise-future pair.
  prefs: []
  type: TYPE_NORMAL
- en: Using promises and futures improves responsiveness by offloading computations
    and provides a structured approach to handling asynchronous operations compared
    to threads and callbacks, as we will explore in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now learn about these two objects.
  prefs: []
  type: TYPE_NORMAL
- en: Promises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Promises are defined in the **<future>** header as **std::promise** .
  prefs: []
  type: TYPE_NORMAL
- en: With a promise, we get an agreement that the result will be available at some
    time in the future. This way, we can let the background task do its work and compute
    the result. Meanwhile the main thread will also proceed with its task and, when
    the result is needed, request it. At that time, the result might already be ready.
  prefs: []
  type: TYPE_NORMAL
- en: Also, promises can communicate if an exception was raised instead of returning
    a valid value and, they will make sure that its lifetime persists until the thread
    finishes and writes the result to it.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a promise is a facility to store a result (a value or an exception)
    that is later acquired asynchronously via a future. A promise object is only intended
    to be used once and cannot be modified afterward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from a result, each promise also holds a shared state. The shared state
    is a memory area that stores the completion status, synchronization mechanisms,
    and a pointer to the result. It ensures proper communication and synchronization
    between a promise and a future by enabling the promise to store either a result
    or an exception, signal when it’s complete, and allowing the future to access
    the result, blocking if the promise is not yet ready. The promise can update its
    shared state using the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Make ready** : The promise stores the result in the shared state and makes
    the state of the promise to become ready unblocking any thread waiting on a future
    associated with the promise. Remember that the result can be a value (or even
    void) or an exception.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release** : The promise releases its reference to the shared state, which
    will be destroyed if this is the last reference. This memory release mechanism
    is like the one used by shared pointers and their control blocks. This operation
    does not block unless the shared state was created by **std::async** and is not
    yet in the ready status (we will learn about this in the next chapter).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abandon** : The promise stores an exception of type **std::future_error**
    with error code **std::future_errc::broken_promise** , making the shared state
    ready and then releasing it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **std::promise** object can be constructed using its default constructor or
    using a custom allocator. In both cases, a new promise will be created with an
    empty shared state. Promises can also be constructed using the move constructor;
    thus, the new promise will have the shared state owned by the other promise. The
    initial promise will remain with no shared state.
  prefs: []
  type: TYPE_NORMAL
- en: Moving a promise is useful in scenarios related to resource management, optimization
    by avoiding extra copies, and keeping correct ownership semantics; for example,
    it’s useful when a promise needs to be completed in another thread, stored in
    a container, returned to the caller of an API call, or sent to a callback handler.
  prefs: []
  type: TYPE_NORMAL
- en: Promises cannot be copied (their copy-constructor or copy-assignment operator
    is deleted), avoiding two promise objects sharing the same shared state and in
    risk of data races when results are stored in the shared state.
  prefs: []
  type: TYPE_NORMAL
- en: As promises can be moved, they can also be swapped. The **std::swap** function
    from the **Standard Template Library** ( **STL** ) has a template specialization
    for promises.
  prefs: []
  type: TYPE_NORMAL
- en: When a promise object is deleted, the associated future will still have access
    to the shared state. If deletion happens after the promise sets the value, the
    shared state will be in release mode, thus the future can access the result and
    use it. However, if the promise was deleted before setting the result value, the
    shared state will be moved to abandoned, and the future will obtain **std::future_errc::broken_promise**
    when trying to get the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'A value can be set by using the **std::promise** function **set_value()** and
    an exception by using the **set_exception()** function. The result is stored atomically
    in the promise’s shared state, making its state ready. Let’s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the previous example, the **prom** promise is created and moved into the
    **threadFunc** lambda function as a parameter. As the promise is non-copyable,
    we need to use pass-by-value together with moving the promise into the parameter
    to avoid copies.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the lambda function, the **func()** function is called, and its result
    is stored in the promise using **set_value()** . If **func()** throws an exception,
    it’s captured and stored into the promise using **set_exception()** . As we will
    learn later, this result (value or exception) can be extracted in the calling
    thread by using a future.
  prefs: []
  type: TYPE_NORMAL
- en: 'In C++14, we can also use generalized lambda capture to pass the promise into
    the lambda capture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, **prm = std::move(prom)** is moving the external promise, **prom**
    , into the lambda’s internal promise, **prm** . By default, parameters are captured
    as constants, so we need to specify the lambda as mutable to allow **prm** to
    be modified.
  prefs: []
  type: TYPE_NORMAL
- en: '**set_value()** can throw a **std::future_error** exception if the promise
    has no shared state (error code set to **no_state** ) or the shared state has
    already a stored result (error code set to **promise_already_satisfied** ).'
  prefs: []
  type: TYPE_NORMAL
- en: '**set_value()** can also be used without specifying a value. In that case,
    it simply makes the state ready. That can be used as a barrier, as we will see
    later in this chapter after introducing futures.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6* *.2* shows a diagram representing the different shared state transitions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Promise shared state transitions diagram](img/B22219_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Promise shared state transitions diagram
  prefs: []
  type: TYPE_NORMAL
- en: There are two other functions to set the value of a promise, **set_value_at_thread_exit**
    and **set_exception_at_thread_exit** . As before, the result is stored immediately,
    but using these new functions, the state is not made ready yet. The state becomes
    ready when the thread exits after all thread-local variables have been destroyed.
    This is useful when we want threads to manage resources that need to be cleaned
    up before exiting, even if an exception happens, or if we want to provide accurate
    log activity or monitor when threads exit.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of exceptions thrown or synchronization mechanisms to avoid data races,
    both functions behave as **set_value()** and **set_exception()** .
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to store a result in a promise, let’s learn about the other
    member of the duo, the future.
  prefs: []
  type: TYPE_NORMAL
- en: Futures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Futures are defined in the **<future>** header file as **std::future** .
  prefs: []
  type: TYPE_NORMAL
- en: As we saw earlier, a future is the consumer side of the communication channel.
    It provides access to the result stored by the promise.
  prefs: []
  type: TYPE_NORMAL
- en: 'A **std::future** object must be created from a **std::promise** object by
    calling **get_future()** , or through a **std::packaged_task** object (more details
    later in this chapter) or a call to the **std::async** function (in [*Chapter
    7*](B22219_07.xhtml#_idTextAnchor143) ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Like promises, futures can be moved but not copied for the same reasons. To
    reference the same shared state from multiple futures, we need to use shared futures
    (explained in the next section, *Shared futures* ).
  prefs: []
  type: TYPE_NORMAL
- en: 'The **get()** method can be used to retrieve the result. If the shared state
    is still not ready, this call will block by internally calling **wait()** . When
    the shared state becomes ready, the result value is returned. If an exception
    was stored in the shared state, that exception will be rethrown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the result is retrieved from the **fut** future by
    using the **get()** function. If the result is a value, it will be printed with
    a line starting with **Result from thread** . On the other hand, if an exception
    were thrown and stored into the promise, it would be rethrown and captured in
    the caller thread, and a line starting with **Exception** would be printed out.
  prefs: []
  type: TYPE_NORMAL
- en: After calling the **get()** method, **valid()** will return **false** . If for
    some reason **get()** is called when **valid()** is **false** , the behavior is
    undefined, but the C++ standard recommends that a **std::future_error** exception
    is thrown with the **std::future_errc::no_state** error code. Futures in which
    the **valid()** function returns **false** can still be moved.
  prefs: []
  type: TYPE_NORMAL
- en: When a future is destroyed, it releases its shared state reference. If that
    were the last reference, the shared state would be destroyed. These actions will
    not block unless in a specific case when using **std::async** , which we will
    learn about in [*Chapter 7*](B22219_07.xhtml#_idTextAnchor143) .
  prefs: []
  type: TYPE_NORMAL
- en: Future errors and error codes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have seen in the preceding examples, some functions that deal with asynchronous
    execution and shared states can throw **std::future_error** exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: This exception class is inherited from **std::logic_error** , which in turn
    is inherited from **std::exception** , defined in the **<stdexcept>** and **<exception>**
    header files, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: As with any other exception defined in the STL, the error code can be checked
    by using its **code()** function or an explanatory string by using its **what()**
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Error codes reported by futures are defined by **std::future_errorc** , a scoped
    enumeration ( **enum** class). The C++ standard defines the following error codes,
    but the implementation may define additional ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '**broken_promise** : Reported when a promise is deleted before setting the
    result, so the shared state is released before being valid.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**future_already_retrieved** : Occurring when **std::promise::get_future()**
    is called more than once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**promise_already_satisfied** : Reported by **std::promise:: set_value()**
    if the shared state already has a stored result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**no_state** : Reported when some methods are used but there is no shared state
    as the promise was created by using the default constructor or moved from. As
    we will see later in this chapter, this happens when calling some packaged tasks
    ( **std::packaged_task** ) methods, such as **get_future()** , **make_ready_at_thread_exit()**
    , or **reset()** , when their shared state has not been created, or when using
    **std::future::get()** with a not-yet-ready future ( **std::future::valid()**
    returns **false** ).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Waiting for results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**std::future** also provides functions to block the thread and wait for a
    result to be available. These functions are **wait()** , **wait_for()** , and
    **wait_until()** . The **wait()** function will block indefinitely until the result
    is ready, **wait_for()** for a period, and **wait_until()** until a specific time
    has been reached. All will return as soon as the result is available within those
    waiting periods.'
  prefs: []
  type: TYPE_NORMAL
- en: These functions must be called only when **valid()** is **true** . Otherwise,
    the behavior is undefined but encouraged by the C++ standard to throw a **std::future_error**
    exception with the **std::future_errc::no_state** error code.
  prefs: []
  type: TYPE_NORMAL
- en: As commented previously, using **std::promise::set_value()** without specifying
    a value sets the shared state as ready. This together with **std::future::wait()**
    can be used to implement a barrier and stop a thread from progressing until it
    is signaled. The following example shows this mechanism in action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by adding the required header files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the **main()** function, the program will start by creating two promises,
    **numbers_promise** and **letters_promise** , and their corresponding futures,
    **numbers_ready** and **letters_ready** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the **input_data_thread** emulates two I/O thread operations running
    in sequence, one copying numbers into a vector and another inserting letters into
    a set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: While this is happening, the main thread stops its execution by using **numbers_ready.wait()**
    , waiting for the counterpart promise, **numbers_promise** , to be ready. Once
    all numbers are read, **input_data_thread** will call **numbers_promise.set_value()**
    , waking up the main thread and continuing its execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Numbers will then be sorted and printed if letters have not already been read
    by using the **wait_for()** function from the **letters_ready** future and checking
    whether it timed out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This section of the code shows how the main thread can do some work. Meanwhile,
    **input_data_thread** continues processing incoming data. Then, the main thread
    will wait again by calling **letters_ready.wait()** .
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, when all letters are added to the set, the main thread will wake up
    by being signaled again by using **letters_promise.set_value()** , and numbers
    (if not yet printed) and letters will be printed in order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we have seen in the previous example, a future status object is returned
    by the wait functions. Next, let’s learn what these objects are.
  prefs: []
  type: TYPE_NORMAL
- en: Future status
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**wait_for()** and **wait_until()** return a **std::future_status** object.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A future can be in any of the following statuses:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ready** : The shared state is **ready** , indicating that the result can
    be retrieved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deferred** : The shared state contains a **deferred** function, meaning that
    the result will only be computed when explicitly requested. We will learn more
    about deferred functions in the next chapter when introducing **std::async** .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timeout** : The specified **timeout period** passed before the shared state
    could become ready.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will learn how to share a promise result among multiple futures by
    using shared futures.
  prefs: []
  type: TYPE_NORMAL
- en: Shared futures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw earlier, **std::future** is only moveable, thus only one future object
    can refer to a particular asynchronous result. On the other hand, **std::shared_future**
    is copyable, so several shared future objects can refer to the same shared state.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, **std::shared_future** allows thread-safe access from different threads
    to the same shared state. Shared futures can be useful for sharing the result
    of a computationally intensive task among multiple consumers or interested parties,
    reducing redundant computation. Also, they can be used to notify events or as
    a synchronization mechanism where multiple threads must wait for the completion
    of a single task. Later in this chapter, we will learn how to chain asynchronous
    operations by using shared futures.
  prefs: []
  type: TYPE_NORMAL
- en: The interface of **std:;shared_object** is the same as the one for **std::future**
    , so everything explained about waiting and getter functions applies here.
  prefs: []
  type: TYPE_NORMAL
- en: 'A shared object can be created by using the **std::future::share()** function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: That invalidates the original future (its **valid()** function will return **false**
    ).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how to send the same result to many threads at
    the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We start by creating a promise, **prom** , getting the future, **fut** , from
    it, and finally, getting a shared future, **shared_fut** , by calling **share()**
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, five threads are created and added to a vector, each one having a shared
    future instance and an index. All these threads will be waiting for the promise,
    **prom** , to be ready by calling **shared_future.get()** . When a value is set
    in the promise shared state, the value will be accessible by all the threads.
    The output of running the previous program is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, shared futures can also be used to signal multiple threads at the
    same time.
  prefs: []
  type: TYPE_NORMAL
- en: Packaged tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A **packaged task** , or **std::packaged_task** , also defined in the **<future>**
    header file, is a class template that wraps a callable object to be invoked asynchronously.
    Its result is stored in a shared state, which is accessible through a **std::future**
    object. To create a **std::packaged_task** object, we need to define as the template
    parameter the function signature that represents the task that will be called
    and pass the desired function as its constructor argument. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, **task1** is created by using a function and executed
    by using a thread. On the other hand, **task2** is created by using a lambda function
    and executed by invoking its method **operator()** . Finally, **task3** is created
    by using a forwarding call wrapper by using **std::bind** .
  prefs: []
  type: TYPE_NORMAL
- en: 'To retrieve the future associated with a task, just call **get_future()** from
    its **packaged_task** object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As with promises and futures, packaged tasks can be constructed with no shared
    state by using the default constructor, the move constructor, or allocators. Packaged
    tasks are thus move-only and non-copyable. Also, assignment operators and the
    swap function have similar behaviors as promises and futures.
  prefs: []
  type: TYPE_NORMAL
- en: The destructor of packaged tasks behaves like the promise destructors; if the
    shared state is released before being valid, a **std::future_error** exception
    will be thrown with the **std::future_errc::broken_promise** error code. As with
    futures, packaged tasks define a **valid()** that function returns **true** if
    a **std::packaged_task** object has a shared state.
  prefs: []
  type: TYPE_NORMAL
- en: As with promises, **get_future()** can only be called once. If this function
    is called more than once, a **std::future_error** exception with the **future_already_retrieved**
    code will be thrown. If the packaged tasks were created from the default constructor,
    thus with no shared state, the error code will be **no_state** .
  prefs: []
  type: TYPE_NORMAL
- en: 'As seen in the previous example, the stored callable object can be invoked
    by using **operator()** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes, it’s interesting to make the result ready only when the thread that
    runs the packaged task exits and all its **thread-local** objects are destroyed.
    This is achieved by using the **make_ready_at_thread_exit()** function. Even if
    the result is not ready until the thread exits, it is computed right away as usual.
    Therefore, its computation is not deferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s define the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This function creates a packaged task called **task** that sets its Boolean
    argument to **true** . A future called **result** is also created from this task.
    When the task is executed by calling **make_ready_at_thread_exit()** , its **done**
    argument is set to **true** but the future result is still not marked as ready.
    When the **task_func** function exits, the **result** future is moved to the passed-by
    reference. At this point, the thread exits, and the **result** future will be
    set as ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, say we call this task from the main thread by using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The program will show the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**make_ready_at_thread_exit()** will throw **std::future_error** exceptions
    if there is no shared state (the **no_state** error code) or the task has already
    been invoked (the **promise_already_satisfied** error code).'
  prefs: []
  type: TYPE_NORMAL
- en: A packaged task state can also be reset by calling **reset()** . This function
    will abandon the current state and construct a new shared state. Obviously, if
    there is no state when calling **reset()** , an exception with the **no_state**
    error code will be thrown. After resetting, a new future must be acquired by calling
    **get_future()** .
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example prints the first 10 power-of-two numbers. Each number
    is computed by calling the same **packaged_task** object. In each loop iteration,
    **packaged_task** is reset, and a new future object is retrieved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output when executing the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As we will learn in the next chapter, **std::async** provides a simpler way
    to achieve the same result. The only advantage of **std::packaged_task** is the
    ability to specify in exactly which thread the task will run.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to use promises, futures, and packaged tasks, it’s time
    to understand not only the upsides of this approach but also what downsides can
    arise.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits and drawbacks of promises and futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are advantages as well as some disadvantages of using promises and futures.
    Here are the main points.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As high-level abstractions for managing asynchronous operations, writing and
    reasoning about concurrent code by using promises and futures is simplified and
    less error-prone.
  prefs: []
  type: TYPE_NORMAL
- en: Futures and promises enable concurrent execution of tasks, allowing the program
    to use multiple CPU cores efficiently. This can lead to improved performance and
    reduced execution time for computationally intensive tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Also, they facilitate asynchronous programming by decoupling the initiation
    of an operation from its completion. As we will see later, this is particularly
    useful for I/O-bound tasks, such as network requests or file operations, where
    the program can continue executing other tasks while waiting for the asynchronous
    operation to complete. As a result, they can return a value but also an exception,
    allowing exception propagation from the asynchronous tasks to the caller code
    section that waits for their completion, which allows for a cleaner way for error
    handling and recovery.
  prefs: []
  type: TYPE_NORMAL
- en: As we have also mentioned, they also provide a mechanism for synchronizing the
    completion of tasks and retrieving their results. This helps in coordinating parallel
    tasks and managing dependencies between them.
  prefs: []
  type: TYPE_NORMAL
- en: Drawbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unfortunately, not everything is positive news; there are also some areas that
    are impacted.
  prefs: []
  type: TYPE_NORMAL
- en: For example, asynchronous programming with futures and promises can introduce
    complexity when dealing with dependencies between tasks or managing the life cycle
    of asynchronous operations. Also, potential deadlocks can happen if there are
    circular dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, using futures and promises may introduce some performance overhead
    due to the synchronization mechanisms happening under the hood, involved in coordinating
    asynchronous tasks and managing shared states.
  prefs: []
  type: TYPE_NORMAL
- en: As with other concurrent or asynchronous solutions, debugging code that uses
    futures and promises can be more challenging compared to synchronous code, as
    the flow of execution may be non-linear and involve multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: Now it’s time to tackle real-life scenarios by implementing some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of real-life scenarios and solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we’ve learned about some new building blocks of creating asynchronous
    programs, let’s build solutions for some real-life scenarios. In this section,
    we will learn how to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Cancel asynchronous operation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return combined results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chain asynchronous operations and create a pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a thread-safe **single-producer-single-consumer** ( **SPSC** ) task queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canceling asynchronous operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw earlier, futures offer the ability to check for completion or timeout
    before waiting for the result. That can be done by checking the **std::future_status**
    object returned by the **std::future** , **wait_for()** , or **wait_until()**
    function.
  prefs: []
  type: TYPE_NORMAL
- en: By combining futures with mechanisms such as cancellation flags (by means of
    **std::atomic_bool** ) or timeouts, we can gracefully terminate long-running tasks
    if necessary. Timeout cancellation can be implemented by simply using the **wait_for()**
    and **wait_until()** functions.
  prefs: []
  type: TYPE_NORMAL
- en: Canceling a task by using a cancellation flag or token can be implemented by
    passing a reference to a cancellation flag defined as **std::atomic_bool** , where
    the caller thread sets its value to **true** to request the task cancellation,
    and the worker thread periodically checks this flag and whether it’s set. If it
    is set, it exits gracefully and performs any cleanup work to be done.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first define a long-running task function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The **long_running_task** function accepts as arguments a period in milliseconds
    ( **ms** ) to run the task and a reference to an atomic Boolean value ( **cancellation_token**
    ) representing the cancellation token. The function will periodically check whether
    the cancellation token is set to **true** . When the running period passes or
    the cancellation token is set to **true** , the thread will exit.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main thread, we can use two **packaged task objects** to execute this
    function, that is, **task1** lasting for 500 ms and running in thread **t1** ,
    and **task2** running for one second in thread **t2** . Both share the same cancellation
    token:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: After both tasks have started, the main thread sleeps for 600 ms. When it wakes
    up, it sets the cancellation token to **true** . At that time, **task1** was already
    finished, but **task2** was still running. Thus, **task2** is being cancelled.
  prefs: []
  type: TYPE_NORMAL
- en: 'This explanation aligns with the obtained output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s see how to combine several asynchronous computation results into
    a single future.
  prefs: []
  type: TYPE_NORMAL
- en: Returning combined results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another common approach in asynchronous programming is to decompose complex
    tasks into smaller independent subtasks using multiple promises and futures. Each
    subtask can be launched in a separate thread and its result stored in a corresponding
    promise. The main thread can then use the futures to wait for all subtasks to
    finish and combine their results to obtain the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is useful to achieve parallel processing of multiple independent
    tasks, allowing the efficient utilization of multiple cores for faster computations.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see an example of a task that emulates a value computation and an I/O
    operation. We want that task to return a tuple with both results, the computed
    value as an **int** value, and the information read from the file as a **string**
    object. So, we define the **combineFunc** function that accepts as an argument
    a **combineProm** promise holding a tuple with the result types.
  prefs: []
  type: TYPE_NORMAL
- en: 'This function will create two threads, **computeThread** and **fetchData**
    , with their respective promises, **computeProm** and **fetchProm** , and futures,
    **computeFut** and **fetchFut** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, both threads will execute asynchronously and independently, generating
    a result and storing it in their respective promises.
  prefs: []
  type: TYPE_NORMAL
- en: 'The combined promise is set by calling the **get()** function on each future
    and combining their result into a tuple that is used to set the value of the combined
    promise by calling its **set_value()** function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The **combineFunc** task can be called as usual by using a thread and setting
    up the **combineProm** promise and its **combineFut** future. Calling the **get()**
    function on this future will return a tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this example will show the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s continue by learning how to create a pipeline using promises and
    futures.
  prefs: []
  type: TYPE_NORMAL
- en: Chaining asynchronous operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Promises and futures can be chained together to perform multiple asynchronous
    operations sequentially. We can create a pipeline where one future’s result becomes
    the input for the next operation’s promise. This allows for composing complex
    asynchronous workflows where the output of one task feeds into the next.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we can allow branching in the pipeline and keep some tasks switched off
    until needed. This can be done by using futures with deferred execution, which
    is useful in scenarios where the computation cost is high, but the result may
    not always be needed. Thus, we can use futures to initiate the computation asynchronously
    and retrieve the result only when required. As futures with deferred status can
    only be created by using **std::async** , we will leave that for the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will focus on creating the following task graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – A pipeline example](img/B22219_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – A pipeline example
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining a template class called **Task** that accepts a callable
    as a template argument, defining the function to execute. This class will also
    allow us to create tasks that share a future with dependent ones. These will use
    the shared futures to wait for the predecessor tasks to signal them about their
    completion by calling **set_value()** in the associated promise before running
    their own task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Let’s describe step by step how this **Task** class is implemented.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two constructors: one to initialize an object of type **Task** that
    has no dependencies with other tasks and another templated constructor to initialize
    a task with a variable number of dependent tasks. Both initialize an identifier
    ( **id_** ), the function to call to perform the task ( **func_** ), a Boolean
    variable indicating whether the task has dependencies or not ( **has_dependency_**
    ), and a shared future, **fut_** , to share with tasks that will depend on this
    one. This **fut_** future is retrieved from the **prom_** promise used to signal
    the task completion. The templated constructor also calls the **add_dependencies**
    function forwarding the futures passed as arguments, which will be stored in the
    **deps_** vector.'
  prefs: []
  type: TYPE_NORMAL
- en: The **get_dependency()** function just returns the shared future used by dependent
    tasks to wait for the completion of the current task.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, **operator()** waits for the completion of previous tasks by calling
    **wait_completion()** , which checks whether each shared future stored in the
    **deps_** vector is valid and waiting until the result is ready by calling **get()**
    . Once all shared futures are ready, meaning that all previous tasks are complete,
    the **func_** function is invoked, running the task, and the **prom_** promise
    is then set to ready by calling **set_value()** , triggering the dependent tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main thread, we define the pipeline as follows, creating a graph like
    the one shown in *Figure 6* *.3* :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to start the pipeline by triggering all tasks and calling their
    **operator()** . As **task1** has no dependencies, it will start running straight
    away. All other tasks will be waiting for their predecessor tasks to complete
    their work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to wait for the pipeline to finish the execution of all tasks.
    We can achieve that by simply waiting for the shared future returned by the last
    task, **task5** , to be ready:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of running this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: There are some issues that can occur with this approach that we must be aware
    of. First, the dependency graph must be a **directed acyclic graph** ( **DAG**
    ), therefore without cycles or loops between dependent tasks. Otherwise, a deadlock
    will occur, as a task might be waiting for a task happening in the future and
    not yet started. Also, we need enough threads to run all the tasks concurrently
    or launch the tasks orderly; otherwise, it can also lead to a deadlock with threads
    waiting on the completion of tasks that have still not launched.
  prefs: []
  type: TYPE_NORMAL
- en: One common use case of this approach can be found in **MapReduce** algorithms
    where large datasets are processed in parallel across multiple nodes, and futures
    and threads can be used to execute map and reduce tasks concurrently, allowing
    efficient distributed data processing.
  prefs: []
  type: TYPE_NORMAL
- en: Thread-safe SPSC task queue
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this last example, we will show how to use promises and futures to create
    an SPSC queue.
  prefs: []
  type: TYPE_NORMAL
- en: The producer thread creates a promise for each item it wants to add to the queue.
    The consumer thread waits for a future obtained from an empty queue slot. Once
    the producer finishes adding an item, it sets the value on the corresponding promise,
    notifying the waiting consumer. This allows for efficient data exchange between
    threads while maintaining thread safety.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first define the thread-safe queue class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we simply use a mutex to have mutual exclusion over all the
    queue data structures when pushing or popping elements. We want to keep this example
    simple and focus on the promise and future interactions. A better approach could
    be to use a vector or circular array and control the access to individual elements
    within the queue with mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: The queue also uses a condition variable, **cond_var_** , to wait if the queue
    is empty when trying to pop an element and to notify one waiting thread when an
    element is pushed. Elements are moved in and out of the queue by moving them.
    This is needed as the queue will store futures, and as we learned earlier, futures
    are movable but non-copiable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The thread-safe queue will be used to define a task queue that will store futures,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define a function, **producer** , that accepts a reference to the
    queue, and a value, **val** , that will be produced. This function just creates
    a promise, retrieves a future from the promise, and pushes that future into the
    queue. Then, we simulate a task running and producing the value, **val** , by
    making the thread wait for a random number of milliseconds. Finally, the value
    is stored in the promise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'At the other end of the communication channel, the **consumer** function accepts
    a reference to the same queue. Again, we simulate a task running on the consumer
    side by waiting for a random number of milliseconds. Then, a future is popped
    out of the queue and its result is retrieved, being the value, **val** , or an
    exception if something went wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'For this example, we will use these constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main thread, two threads are started; the first runs the producer function
    **producerFunc** , which pushes some futures into the queue, while the second
    thread runs the consumer function **consumerFunc** , which consumes elements from
    the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is sample output of executing this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: With a producer-consumer queue like this one, the consumer and producer are
    decoupled, and their threads communicate asynchronously, allowing both the producer
    and consumer to do extra work while the other side generates or processes the
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about promises and futures, how to use them to execute
    asynchronous code in separate threads, and also how to run callables using packaged
    tasks. These objects and mechanisms constitute and implement the key concepts
    of asynchronous programming used by many programming languages, including C++.
  prefs: []
  type: TYPE_NORMAL
- en: We also now understand why promises, futures, and packaged tasks cannot be copied,
    and thus how to share futures by using shared future objects.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have shown how to use futures, promises, and packaged tasks to tackle
    real-life problems.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to explore promises and futures deeper, it is worth mentioning some
    third-party open source libraries, especially **Boost.Thread** and **Facebook
    Folly** . These libraries include additional functionality, including callbacks,
    executors, and combinators.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn a simpler way to asynchronously invoke callables
    by using **std::async** .
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Boost futures and promises: [https://theboostcpplibraries.com/boost.thread-futures-and-promises](https://theboostcpplibraries.com/boost.thread-futures-and-promises)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Facebook Folly open source library: [https://github.com/facebook/folly](https://github.com/facebook/folly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Futures for C++11 at Facebook: [https://engineering.fb.com/2015/06/19/developer-tools/futures-for-c-11-at-facebook](https://engineering.fb.com/2015/06/19/developer-tools/futures-for-c-11-at-facebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*‘Futures and Promises’ – How Instagram leverages it for better resource* *utilization*
    : [https://scaleyourapp.com/futures-and-promises-and-how-instagram-leverages-it/](https://scaleyourapp.com/futures-and-promises-and-how-instagram-leverages-it/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SeaStar: Open source C++ framework for high-performance server applications:
    [https://seastar.io](https://seastar.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
