- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Challenges in Embedded Systems with Limited Resources
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are reading this book, chances are you have a good grasp of embedded
    systems. There are many definitions of embedded systems, and while the following
    may not be the most common, it captures the essence shared by others. **Embedded
    systems** are specialized computing systems for specific use with a limited set
    of responsibilities, in contrast to general-purpose computing systems. Embedded
    systems can be embedded in a larger electronic or mechanical system, or act as
    a standalone device.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The line between embedded systems and general-purpose computing devices is sometimes
    blurred. We can all agree that the system that controls a toaster or a pump in
    an airplane is an embedded system. Cellphones and early smartphones were also
    considered embedded systems. Nowadays, smartphones are closer to the definition
    of a general-purpose computing device. In this book, we will focus on firmware
    development using modern C++ on small embedded systems or resource-constrained
    embedded systems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Resource-constrained embedded systems are often employed in safety-critical
    applications. They have a responsibility to control a process in a timely manner
    and they cannot fail, as failure can mean the loss of human lives. In this chapter,
    we will cover limitations imposed by regulations on software development for safety-critical
    devices and implications for the usage of C++. We will learn how to mitigate these
    concerns.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Safety-critical and hard real-time embedded systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic memory management
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disabling unwanted C++ features
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get the most out of this chapter, I strongly recommend using Compiler Explorer
    ([https://godbolt.org/](https://godbolt.org/)) as you read through the examples.
    Select GCC as your compiler and target x86 architecture. This will allow you to
    see standard output (stdio) results and better observe the code’s behavior. As
    we are using a lot of modern C++ features, make sure to select C++23 standard,
    by adding `-std=c++23` in compiler options box.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The examples from this chapter are available on GitHub ([https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter02](https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter02)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Safety-critical and hard real-time embedded systems
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Safety-critical embedded systems** are systems whose failure may result in
    damage to property or environment, injury to people, or even a loss of life. Failure
    of these systems is not acceptable. Brakes, steering systems, and airbags in cars
    are good examples of safety-critical systems. The correct functioning of these
    systems is essential for the safe operation of a vehicle.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will analyze the real-time requirements of an airbag control unit in
    a car.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Airbag control unit and real-time requirements
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Safety-critical embedded systems often impose hard real-time requirements, meaning
    that any missed deadline results in system failure. An **A****irbag Control Unit**
    (**ACU**) collects data from accelerometers and pressure sensors, runs an algorithm
    that processes the collected data, and detects side, front, and rear-end crashes.
    Upon the crash detection, the ACU controls the deployment of different restraint
    systems, including airbags and seat belt tensioners.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: ACU implementations must be resilient to different scenarios, such as malfunctioning
    sensors and electronics. These are mitigated by redundant sensors, comparing data
    from sensors, comparing data against thresholds, and self-tests. Most importantly,
    ACUs need to meet timing requirements, as they have only a couple of milliseconds
    to collect data, make decisions, and initiate deployment of restraint systems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: The ACU fails if it doesn’t detect a crash on time, but it also fails if it
    deploys restraint systems just a bit too late, as this can do more harm to a driver
    and passengers than if the ACU hadn’t initiated a deployment at all. This is why
    an ACU must meet hard real-time requirements, and when it comes to firmware, this
    means all the worst-case execution times must be predictable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'The effect of delayed airbag deployment is the subject of many studies concerned
    with injuries caused to occupants. The following extract is part of the conclusion
    from the paper *Study regarding the influence of airbag deployment time on the
    occupant injury level during a frontal vehicle collision*, published at MATEC
    Web of Conferences 184(1):01007, by authors Alexandru Ionut Radu, Corneliu Cofaru,
    Bogdan Tolea, and Dragoș Sorin Dima, outlining results of simulations of delayed
    airbag deployment:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '*“It has been found that by increasing the delay of the airbag deployment time
    in the event of a frontal impact, the probability of injury to the occupant’s
    head increases by up to 46%. Reducing the distance between the occupant’s head
    and the dashboard / steering wheel when the airbag ignites would result in a force
    expansion of the gas that is transmitted to the occupant’s head generating an
    extra acceleration and also throws back the occupant increasing the injury potential
    due to the impact between the head and headrest. Thus, an increase in injury probability
    of 8% was observed in the 0 ms delay of the airbag deployment, while a 100 ms
    delay resulted in a 54% increase in the head acceleration value. So, the role
    of the airbag is reversed, it no longer has the role of cushioning the collision,
    but to generate injuries.”*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A graphic illustration of collision and delayed airbag deployment is shown
    in the following figure (source: [https://www.researchgate.net/publication/326715516_Study_regarding_the_influence_of_airbag_deployment_time_on_the_occupant_injury_level_during_a_frontal_vehicle_collision](https://www.researchgate.net/publication/326715516_Study_regarding_the_influence_of_airbag_deployment_time_on_the_occupant_injury_level_during_a_frontal_vehicle_collision)):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Crash simulation with delayed restraint system deployment](img/B22402_2_1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Crash simulation with delayed restraint system deployment
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.1* effectively illustrates what happens if an ACU doesn’t meet
    hard real-time requirements and produces delayed results. The figure is taken
    from the paper *Study regarding the influence of airbag deployment time on the
    occupant injury level during a frontal vehicle collision*.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple reasons why an ACU may fail and cause no or a delayed deployment:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Sensor malfunctioning
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Electronics malfunctioning
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crash detection algorithm failure
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firmware failure to meet a deadline
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensors and electronics malfunctioning are mitigated by redundancy, data sanity
    checks, cross-comparison, and startup and runtime self-tests. This puts additional
    stress on firmware and its correct functioning. A crash detection algorithm may
    fail due to a bad model that was built upon, or other factors that are out of
    firmware responsibilities. The firmware’s job is to feed the algorithm with sensors’
    data on time, execute it in a timely manner within a set time window, and act
    based on the output of the algorithm.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Measuring firmware performance and non-determinism
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do we ensure that the firmware will run all functions within imposed real-time
    requirements? We measure it. We can measure different metrics, such as performance
    profiling, response to external events, and A-B timing. Performance profiling
    will tell us in which functions the program spends the most time. Response to
    external events will indicate how much time it takes for a system to respond to
    an external event, such as an interrupt or a message on a communication bus.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: A-B timing and real-time execution
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most important metric when dealing with real-time requirements is **A-B
    timing**. We measure how long it takes for firmware to execute a program from
    point A to point B. A-B timing can measure a function’s duration, but not necessarily.
    We can use it to measure different things. Going from A to B can take different
    times, based on the state of the system and inputs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: A simple way to make an A-B measurement is toggling a **General Purpose Input
    Output** (**GPIO**) and using an oscilloscope to measure the time between changes
    of a GPIO. It’s a simple solution that works well but doesn’t scale, as we would
    need a GPIO for every function we want to measure or we’d need to measure one
    function at a time. We could also use the internal timer of a **Microcontroller
    Unit (MCU)**to make precise measurements and output that information over a UART
    port. This would require us to utilize a general-purpose timer just for the sake
    of measuring. Most microcontrollers have specialized units for instrumentation
    and profiling.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Some ARM-based microcontrollers have a **Data Watchpoint and Trace** (**DWT**)
    unit. DWT is used for data tracing and system profiling, including the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Program Counter** (**PC**) sampling'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cycle counting
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DWT generates events and outputs them using an **Instrumentation Trace Macrocell**
    (**ITM**) unit. The ITM unit can also be used to output data generated from the
    firmware itself, in the `printf` style. ITM buffers data and sends it over to
    an ITM sink. **Single Wire Output** (**SWO**) can be used as an ITM sink.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'We can utilize DWT and ITM for profiling as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: DWT can generate periodic sampling of the PC and use ITM to send them over SWO.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On a host machine, we capture and analyze the received data.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By using a linker map file for our firmware, we can generate the distribution
    of time spent in each of the functions in our program.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This can help us to see which function takes the most time. It’s not particularly
    useful for A-B timing measurements, but it allows us to see where the program
    spends most of the time without any direct software instrumentation except setting
    up DWT and ITM units.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Sotware instrumentation with GCC
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**GNU Compiler Collection** (**GCC**) supports software instrumentation by
    using the `-finstrument-functions` flag to instrument functions’ entries and exists.
    This inserts `entry` and `exit` calls to each function with the following signature:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can utilize DWT and ITM in the `__cyg_profile_func_enter` and `__cyg_profile_func_exit`
    functions to send the clock cycle count and analyze it on the host machine to
    make A-B timing measurements. The following is an example of a simplified implementation
    of `entry` and `exit` functions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding implementation uses `extern` `"C"` as a linkage language specifier
    for `entry` and `exit` instrumentation functions as they are linked with C libraries
    by the compiler. The example also assumes that `printf` is redirected to use ITM
    as output and that the cycle counter register in DWT is started.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to use ITM’s timestamping and send both timestamps and function
    addresses from `entry` and `exit` instrumentation functions. With the help of
    a linker map file, we can then reconstruct the sequence of function calls and
    returns. There are specialized formats for sending traces, such as **Common Trace
    Format** (**CTF**), and desktop tools called **trace viewers** that can allow
    us to streamline software instrumentation. CTF is an open format used to serialize
    an event in a packet with one or more fields. Specialized tools, such as **barectf**
    ([https://barectf.org/docs/barectf/3.1/index.html](https://barectf.org/docs/barectf/3.1/index.html))
    are used to facilitate CTF packet generation.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Events are described using a **YAML Ain’t Markup Language** (**YAML**) configuration
    file. A simple C library containing trace functions is generated by `barectf`
    using the configuration file. These functions are used in source code in places
    where we want to emit traces.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: CTF traces can be sent over different transport layers such as ITM or serial.
    Traces can be analyzed using tools such as Babeltrace ([https://babeltrace.org](https://babeltrace.org))
    and TraceCompass ([https://eclipse.dev/tracecompass](https://eclipse.dev/tracecompass)).
    There are other tools that facilitate trace generation, transfer, and viewing
    such as SEGGER SystemView. On the target side, a small software module provided
    by SEGGER is included to make calls to tracing functions. Traces are sent over
    SEGGER’s **Real Time Transfer** (**RTT**) protocol using SWD and analyzed in SystemView.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: We covered some basic approaches to A-B timing. There are more advanced techniques,
    and they often depend on the target capabilities, as there are some more advanced
    tracing units that can be utilized for A-B measurements.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Determinism vs. Non-Determinism in Firmware
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we measure the duration of a function using the A-B timing approach and have
    the same duration and function output for the same inputs, we say that the function
    is **deterministic**. If a function depends on a global state and the measured
    duration is different for the same inputs, we say it is **non-deterministic**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Default dynamic memory allocators in C++ tend to be non-deterministic. The duration
    of allocation depends on the current global state of the allocator and the complexity
    of the allocating algorithm. We can measure duration for the same inputs with
    different global states, but it is hard to evaluate all possible global states
    and to guarantee the **Worst-Case Execution Time** (**WCET**) with default allocators.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: The non-deterministic behavior of dynamic memory allocation is just one problem
    for safety-critical systems. The other problem is that it can fail. If there is
    no more available memory or if the memory is fragmented, then the allocation can
    fail. This is why many safety coding standards such as **Motor Industry Software
    Reliability Association** (**MISRA**) and **Automotive Open System Architecture**
    (**AUTOSAR**) discourage dynamic memory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: We will explore dynamic memory management implications and safety-critical concerns
    next.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic memory management
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The C++ standard defines the following storage durations for objects:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**Automatic storage duration**: Objects with automatic storage duration are
    automatically created and destroyed as the program enters and exits the block
    in which they are defined. These are typically local variables within functions,
    except those declared `static`, `extern`, or `thread_local`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static storage duration**: Objects with static storage duration are allocated
    when the program starts and deallocated when the program ends. All objects declared
    at the namespace scope (including the global namespace) have this static duration,
    plus those declared with `static` or `extern`.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Thread storage duration**: Introduced in C++11, objects with thread storage
    duration are created and destroyed with the thread in which they are defined,
    allowing each thread to have its own instance of a variable. They are declared
    with the `thread_local` specifier.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic storage duration**: Objects with dynamic storage duration are explicitly
    created and destroyed using dynamic memory allocation functions (`new` and `delete`
    in C++), giving the software developer control over the lifetime of these objects.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dynamic storage gives great flexibility to a software developer, providing
    full control over an object’s lifetime. With great power comes great responsibility.
    Objects are dynamically allocated using the `new` operator and freed using `delete`.
    Every object that is allocated dynamically must be freed exactly once and should
    never be accessed after it has been freed. This is a straightforward rule but
    failing to follow it causes a range of problems, such as the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Memory leaks occur when dynamically allocated memory is not freed properly.
    Over time, this unused memory accumulates potentially exhausting system resources.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dangling pointers happen when a pointer still references a memory location that
    has been freed. Accessing such a pointer leads to undefined behavior.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Double free errors occur when memory that has already been freed is deleted
    again, leading to undefined behavior.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another problem with dynamic memory management is memory fragmentation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Memory fragmentation
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Memory fragmentation** occurs when free memory is divided into small, non-contiguous
    blocks over time, making it difficult or impossible to allocate large blocks of
    memory even when there is enough free memory available in total. There are two
    main types:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '**External fragmentation**: This happens when there is enough total memory
    available to satisfy an allocation request but no single continuous block is large
    enough due to fragmentation. It’s common in systems where memory allocation and
    deallocation occur frequently, and sizes vary significantly.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal fragmentation**: This occurs when allocated memory blocks are larger
    than the requested memory, leading to wasted space within allocated blocks. It
    happens when using allocators that have fixed-size memory blocks or memory pools
    and with allocators designed to give WCET.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Memory fragmentation leads to inefficient memory use, reducing the performance
    or preventing further allocations resulting in out-of-memory scenarios, even when
    it appears that sufficient memory is available. Let’s visualize the memory region
    reserved for dynamic memory allocation in the following figure:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Memory region used for dynamic allocation](img/B22402_2_2.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Memory region used for dynamic allocation
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 2**.2*, each block represents a memory unit allocated during the
    allocation process. Empty regions were not allocated, or they were freed using
    the `delete` operator. Even though there is plenty of memory available, if there
    were a request for the allocation of four memory units, the allocation would fail,
    as there are not four continuous memory blocks available due to memory fragmentation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Non-deterministic behavior of default memory allocators and out-of-memory scenarios
    are major concerns for safety-critical systems. MISRA and AUTOSAR provide coding
    guidelines for the use of C++ in safety-critical systems.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: MISRA is an organization that provides guidelines for the software developed
    for electronic components used in the automotive industry. It is a collaboration
    between vehicle manufacturers, component suppliers, and engineering consultancies.
    Standards produced by MISRA are also used in aerospace, defense, space, medical,
    and other industries.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: AUTOSAR is a global development partnership by automotive manufacturers, suppliers,
    and other companies from the electronics, semiconductor, and software industries.
    AUTOSAR also produces guidelines for the use of C++ in critical and safety-related
    systems.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Safety-critical guidelines for dynamic memory management in C++
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MISRA C++ 2008, which covers the C++03 standard, prohibits the usage of dynamic
    memory allocation, while AUTOSAR’s *Guidelines for the use of the C++14 language
    in critical and safety-related systems* specifies, among others, the following
    rules:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Rule A18-5-5 (required, toolchain, partially automated)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“Memory management functions shall ensure the following: (a) deterministic
    behavior resulting with the existence of worst-case execution time, (b) avoiding
    memory fragmentation, (c) avoid running out of memory, (d) avoiding mismatched
    allocations or deallocations, (e) no dependence on non-deterministic calls to
    kernel.”'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Rule A18-5-6 (required, verification / toolchain, non-automated)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“An analysis shall be performed to analyze the failure modes of dynamic memory
    management. In particular, the following failure modes shall be analyzed: (a)
    non-deterministic behavior resulting with nonexistence of worst-case execution
    time, (b) memory fragmentation, (c) running out of memory, (d) mismatched allocations
    and deallocations, (e) dependence on non-deterministic calls to kernel.”'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now, following these two rules to the letter is an extremely hard task. We can
    write a custom allocator that has deterministic WCET and minimizes fragmentation,
    but how do we write an allocator that avoids running out of memory? Or, in case
    it happens, how do we ensure the non-failure of the system? Every call to the
    allocator would need to verify the success of the operation and, in case of failure,
    somehow mitigate it. Or we would need to be able to estimate the amount of memory
    needed for an allocator accurately, so it doesn’t run out of memory in runtime
    under any circumstances. This adds a whole new layer of complexity to our software
    design and adds more complexity than we would add value by allowing dynamic memory
    allocation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: An in-between approach to dynamic memory allocation policy is to allow it on
    startup, but not when the system is running. This is the policy used by **Joint
    Strike Fighter Air Vehicle C++ Coding Standards**. MISRA C++ 2023 also advises
    against the usage of dynamic memory allocation when the system is running, and
    as a mitigation policy, recommends using it at startup.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: The C++ standard library uses dynamic memory allocation heavily. Exception handling
    mechanism implementations also often use dynamic allocation. Before dismissing
    the idea of using the standard library in embedded projects, let’s discover the
    internal workings of the `std::vector` container and see what C++ offers to mitigate
    our concerns.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic memory management in the C++ standard library
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We introduced `std::vector` as a container from the standard library that uses
    dynamic memory allocation. `vector` is a template class, and we can specify the
    underlying type. It stores the elements contiguously, and we can get direct access
    to the underlying contiguous storage using the `data` method.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code example demonstrates the usage of a vector:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We created a vector with the underlying `uint8_t` type and added values from
    `0` to `8` using the `push_back` method. The example also demonstrates access
    to a pointer to the underlying contiguous storage, which we provided as an argument
    to the `print_array` lambda.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'The usual allocation strategy of `vector` is to allocate one element on the
    first insertion, then double it each time it reaches its capacity. Storing values
    for `0` to `8` would result in 4 allocation requests, as shown in the following
    figure:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Vector allocation requests](img/B22402_2_3.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Vector allocation requests
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.3* depicts the vector’s allocation requests. In order to inspect
    vector implementation on any platform, we can overload the `new` and `delete`
    operators and monitor the allocation requests:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `new` overloaded operator passes allocation calls to `malloc`, and it prints
    out the size requested by the caller. The `delete` overloaded operator just prints
    out the function signature so we can see when it is called. Some standard library
    implementations using GCC implement the `new` operator using `malloc`. Our vector
    allocation calls will result in the following output:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding results are obtained using the GCC compiler, and they are the
    same both for x86_64 and Arm Cortex-M4 platforms. When the vector fills the available
    memory, it requests allocation of the doubled amount of currently used memory.
    It then copies data from the original storage to newly acquired memory. Afterward,
    it deletes previously used storage, as we can see from the preceding generated
    output.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Overloading the `new` and `delete` operators would allow us to change the allocation
    mechanism globally, in order to meet the safety-critical guidelines requesting
    for deterministic WTEC and avoiding out-of-memory scenarios, which is quite challenging.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'The allocation requests from the vector can be optimized by using the `reserve`
    method if the number of elements is known beforehand:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Using the `reserve` method will make the vector request eight elements, and
    it will ask for more memory only if we go beyond eight elements. This makes it
    useful for projects that allow dynamic allocation at startup if we can guarantee
    that the number of elements at any point will stay within reserved memory. If
    we add a ninth element to the vector, it will make another allocation request,
    requesting the memory to fit 16 elements.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'The C++ standard library also makes possible usage of local allocators for
    containers. Let’s take a look at the vector’s declaration:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see that the second template parameter is `Allocator`, and the default
    argument is `std::allocator`, which uses the `new` and `delete` operators. C++17
    introduced `std::pmr::polymorphic_allocator`, an allocator that exhibits different
    allocation behavior depending upon the `std::pmr::memory_resource` type from which
    it is constructed.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a memory resource that can be constructed by providing it with an
    initial, statically allocated buffer, and it’s called `std::pmr::monotonic_buffer_resource`.
    The monotonic buffer is built for performance, and it releases memory only when
    it is destroyed. Initializing it with a statically allocated buffer makes it suitable
    for embedded applications. Let’s see how we can use it for a vector:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the preceding example, we do the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Create a `std::array` container, with an underlying type of `uint8_t`.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Construct a monotonic buffer and provide it with the array we just created as
    the initial buffer.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the monotonic buffer to create a polymorphic allocator, which we use to
    create a vector.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Please note that the vector is from the `std::pmr` namespace, and it’s just
    a partial specialization of `std::vector`, as shown here:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'A vector created by utilizing a monotonic buffer will allocate memory in the
    space provided by the buffer. Let’s examine the behavior of such a vector in the
    following example built from the previously explained code:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding program will provide the following output:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We see that even though we used the monotonic buffer, the program called the
    `new` operator. You can notice that the call to the `reserve` method is commented.
    This will result in a vector-expanding strategy, as described previously. When
    the monotonic buffer initial memory is used, it will fall to the upstream memory
    resource pointer. The default upstream memory resource will use the `new` and
    `delete` operators.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'If we print the buffer used as initial storage for `monotonic_buffer_resource`,
    we can see that the vector is allocating the first element and storing `0` to
    it, then it doubles it and stores `0` and `1`, and then doubles it again, storing
    `0`, `1`, `2`, and `3`. When it tries to double it again, the monotonic buffer
    will not be able to meet the allocation request and will fall to using the default
    allocator, which relies on the `new` and `delete` operators. We can visualize
    this in the following figure:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – State of the buffer used by the monotonic buffer resource](img/B22402_2_4.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – State of the buffer used by the monotonic buffer resource
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.4* depicts the internal state of the used by the monotonic buffer
    resource. We can see that the monotonic buffer resource is not deallocating memory
    in any way. On an allocation buffer request, it returns a pointer to the last
    available element in the initial buffer if there is enough space in the buffer
    to fit the requested number of elements.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that the `new` operator used in this example has a different
    signature from the one previously used. Actually, the standard library defines
    different versions of `new` and matching `delete` operators, and it’s hard to
    tell which version is used by a container from the standard library without inspection.
    This makes overloading them globally and replacing implementation with a custom
    one even more challenging, making a local allocator usually a better choice.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The polymorphic allocator utilizing a monotonic buffer initialized with a buffer
    on the stack may be a good option to mitigate some of the issues imposed by the
    dynamic memory management when working with containers from the standard C++ library.
    The approach we demonstrated on the vector can be used on other containers from
    standard libraries, such as `list` and `map`, but also other types from the library,
    such as `basic_string`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Mitigating concerns of dynamic memory allocation is possible but it still poses
    some challenges. If you want to be absolutely sure that your C++ program is not
    calling a `new` operator, there are means to ensure it. Let us explore how we
    can disable unwanted C++ features.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Disabling unwanted C++ features
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may have noticed that we used `printf` from the C standard library for printing
    debug information on standard output instead of `std::cout` from the C++ standard
    library. The reason is twofold – the implementation of the `std::cout` global
    object from `ostream` has a large memory footprint and it uses dynamic memory
    allocation. C++ works well with the C standard library, and using `printf` is
    a good alternative for resource-constrained systems.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed the exception handling mechanism, which often relies on
    dynamic memory allocation. Disabling exceptions in C++ is as easy as passing the
    appropriate flag to the compiler. In the case of GCC, that flag is `–fno-exceptions`.
    The same goes for **Run-Time Type Information** (**RTTI**). We can disable it
    with the `–fno-rtti` flag.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Disabling exceptions will result in calling `std::terminate` when an exception
    is thrown. We can replace the default terminate handler with our own implementation
    and handle it appropriately, as shown in the following example:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding example demonstrates setting the terminate handler using `std::set_terminate`
    by our own implementation. This allows us to handle cases that shouldn’t happen
    in runtime and try to recover from them or gracefully terminate them. Some features
    or behaviors in C++ can’t be disabled by compiler flags, but there are other means
    to handle them,
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'As we saw previously, we can redefine global `new` and `delete` operators.
    We can also delete them, which will make the compilation fail if we use a software
    component that calls `new`, effectively allowing us to prevent any attempts of
    dynamic memory allocation if needed:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding example will fail with the following compiler message (among
    others):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: By deleting `new` operators, we can make the compilation of a C++ program that
    is trying to use dynamic memory management fail. This is useful if we want to
    be sure our program is not using dynamic memory management.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C++ allows a great degree of flexibility. Resource-constrained embedded systems
    and safety-critical guidelines can impose some limitations on the usage of certain
    C++ features, such as exception handling, RTTI, and the usage of dynamic memory
    allocation by containers and other modules from the standard C++ library. C++
    acknowledges those concerns and provides mechanisms for disabling unwanted features.
    In this chapter, we learned about different strategies for mitigating concerns
    of dynamic memory allocation by means of local allocators and overloading global
    `new` and `delete` operators.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The learning curve is steep but worth the effort, so let’s continue our journey
    of discovering C++ in embedded systems.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the C++ ecosystem for embedded development.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨嵌入式开发中的 C++ 生态系统。
