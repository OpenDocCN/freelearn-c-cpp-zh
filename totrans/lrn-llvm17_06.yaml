- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Basics of IR Code Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having created a decorated **abstract syntax tree** (**AST**) for your programming
    language, the next task is to generate the LLVM IR code from it. LLVM IR code
    resembles a three-address code with a human-readable representation. Therefore,
    we need a systematic approach to translate language concepts such as control structures
    into the lower level of LLVM IR.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the basics of LLVM IR and how to generate
    IR for control flow structures from the AST. You will also learn how to generate
    LLVM IR for expressions in **static single assignment** (**SSA**) form using a
    modern algorithm. Finally, you will learn how to emit assembler text and object
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating IR from the AST
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using AST numbering to generate IR code in SSA form
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up the module and the driver
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know how to create a code generator for
    your programming language and how to integrate it into your compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Generating IR from the AST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The LLVM code generator takes a module in LLVM IR as input and turns it into
    object code or assembly text. We need to transform the AST representation into
    IR. To implement an IR code generator, we will look at a simple example first
    and then develop the classes needed for the code generator. The complete implementation
    will be divided into three classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeGenerator`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CGModule`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CGProcedure`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `CodeGenerator` class is the general interface used by the compiler driver.
    The `CGModule` and `CGProcedure` classes hold the state required for generating
    the IR code for a compilation unit and a single function.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll begin by looking at the Clang-generated IR.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the IR code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before generating the IR code, it’s good to know the main elements of the IR
    language. In [*Chapter 2*](B19561_02.xhtml#_idTextAnchor037), *The Structure of
    a Compiler*, we had a brief look at IR. An easy way to get more knowledge of IR
    is to study the output from `clang`. For example, save this C source code, which
    implements the Euclidean algorithm for calculating the greatest common divisor
    of two numbers, as `gcd.c`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can create the `gcd.ll` IR file by using `clang` and the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The IR code is not target-independent, even if it often looks like it is. The
    preceding command compiles the source file for an ARM 64-bit CPU on Linux. The
    `-S` option instructs `clang` to output an assembly file, and with the additional
    specification of `-emit-llvm`, an IR file is created. The optimization level,
    `-O1`, is used to get an easily readable IR code. Clang has many more options,
    all of which are documented in the command-line argument reference at [https://clang.llvm.org/docs/ClangCommandLineReference.html](https://clang.llvm.org/docs/ClangCommandLineReference.html).
    Let’s have a look at the generated file and understand how the C source maps to
    the LLVM IR.
  prefs: []
  type: TYPE_NORMAL
- en: A C file is translated into a `i`, followed by the number of bits. For example,
    the 64-bit integer type is written as `i64`. The most basic float types are `float`
    and `double`, denoting the 32-bit and 64-bit IEEE floating-point types. It is
    also possible to create aggregate types such as vectors, arrays, and structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the LLVM IR looks like. At the top of the file, some basic properties
    are established:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first line is a comment informing you about which module identifier was
    used. In the following line, the filename of the source file is named. With `clang`,
    both are the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `target datalayout` string establishes some basic properties. The different
    parts are separated by `-`. The following information is included:'
  prefs: []
  type: TYPE_NORMAL
- en: A small `e` means that bytes in memory are stored using the little-endian schema.
    To specify a big endian, you must use a big `E`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`M:` specifies the name mangling that’s applied to symbols. Here, `m:e` means
    that ELF name mangling is used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entries in `iN:A:P` form, such as`i8:8:32`, specify the alignment of data,
    given in bits. The first number is the alignment required by the ABI, and the
    second number is the preferred alignment. For bytes (`i8`), the ABI alignment
    is 1 byte (`8`) and the preferred alignment is 4 bytes (`32`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n` specifies which native register sizes are available. `n32:64` means that
    32-bit and 64-bit wide integers are natively supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`S` specifies the alignment of the stack, again in bits. `S128` means that
    the stack maintains a 16-byte alignment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The provided target data layout must match what the backend expects. Its purpose
    is to communicate the captured information to the target-independent optimization
    passes. For example, an optimization pass can query the data layout to get the
    size and alignment of a pointer. However, changing the size of a pointer in the
    data layout does not change the code generation in the backend.
  prefs: []
  type: TYPE_NORMAL
- en: A lot more information is provided with the target data layout. You can find
    more information in the reference manual at [https://llvm.org/docs/LangRef.html#data-layout](https://llvm.org/docs/LangRef.html#data-layout).
  prefs: []
  type: TYPE_NORMAL
- en: 'Last, the `target triple` string specifies the architecture we are compiling
    for. This reflects the information we gave on the command line. The triple is
    a configuration string that usually consists of the CPU architecture, the vendor,
    and the operating system. More information about the environment is often added.
    For example, the `x86_64-pc-win32` triple is used for a Windows system running
    on a 64-bit X86 CPU. `x86_64` is the CPU architecture, `pc` is a generic vendor,
    and `win32` is the operating system. The parts are connected by a hyphen. A Linux
    system running on an ARMv8 CPU uses `aarch64-unknown-linux-gnu` as its triple.
    `aarch64` is the CPU architecture, while the operating system is `linux` running
    a `gnu` environment. There is no real vendor for a Linux-based system, so this
    part is `unknown`. Parts that are not known or unimportant for a specific purpose
    are often omitted: the `aarch64-linux-gnu` triple describes the same Linux system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the `gcd` function is defined in the IR file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This resembles the function signature in the C file. The `unsigned` data type
    is translated into the 32-bit integer type, `i32`. The function name is prefixed
    with `@`, and the parameter names are prefixed with `%`. The body of the function
    is enclosed in curly braces. The code of the body follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The IR code is organized into so-called `entry`. The code in the block is simple:
    the first instruction compares the `%b` parameter against `0`. The second instruction
    branches to the `return` label if the condition is `true` and to the `while.body`
    label if the condition is `false`.'
  prefs: []
  type: TYPE_NORMAL
- en: Another characteristic of the IR code is that it is in a `%cmp`. This register
    is then used, but it is never written again. Optimizations such as constant propagation
    and common-sub-expression elimination work very well with the SSA form and all
    modern compilers are using it.
  prefs: []
  type: TYPE_NORMAL
- en: SSA
  prefs: []
  type: TYPE_NORMAL
- en: 'The SSA form was developed in the late 1980s. Since then, it has been widely
    used in compilers because it simplifies data flow analysis and optimizations.
    For example, the identification of common sub-expressions inside a loop becomes
    much easier if the IR is in SSA form. A basic property of SSA is that it establishes
    `def-use` and `use-def` chains: for a single definition, you know of all uses
    (`def-use`), and for each use, you know the unique definition (`use-def`). This
    knowledge is used a lot, such as in constant propagation: if a definition is determined
    to be a constant, then all uses of this value can be easily replaced with that
    constant value.'
  prefs: []
  type: TYPE_NORMAL
- en: To construct the SSA form, the algorithm from Cytron et al. (1989) is very popular,
    and it is also used in the LLVM implementation. Other algorithms have been developed
    too. An early observation is that these algorithms become simpler if the source
    language does not have a `goto` statement.
  prefs: []
  type: TYPE_NORMAL
- en: An in-depth treatment of SSA can be found in the book *SSA-based Compiler Design*,
    by F. Rastello and F. B. Tichadou, Springer 2022.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next basic block is the body of the `while` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Inside the loop of `gcd`, the `a` and `b` parameters are assigned new values.
    If a register can be only written once, then this is not possible. The solution
    is to use the special `phi` instruction. The `phi` instruction has a list of basic
    blocks and values as parameters. A basic block presents the incoming edge from
    that basic block, and the value is the value from that basic block. At runtime,
    the `phi` instruction compares the label of the previously executed basic block
    with the labels in the parameter list.
  prefs: []
  type: TYPE_NORMAL
- en: The value of the instruction is the value that’s associated with the label.
    For the first `phi` instruction, the value is the `%rem` register if the previously
    executed basic block was `while.body`. The value is `%b` if `entry` was the previously
    executed basic block. The values are the ones at the start of the basic block.
    The `%b.loop` register gets a value from the first `phi` instruction. The same
    register is used in the parameter list of the second `phi` instruction, but the
    value is assumed to be the one before it is changed through the first `phi` instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the loop’s body, the return value must be chosen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Again, a `phi` instruction is used to select the desired value. The `ret` instruction
    not only ends this basic block but also denotes the end of this function at runtime.
    It has the return value as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some restrictions on the use of `phi` instructions. They must be
    the first instructions of a basic block. The first basic block is special: it
    has no previously executed block. Therefore, it cannot begin with a `phi` instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: LLVM IR reference
  prefs: []
  type: TYPE_NORMAL
- en: We’ve only touched the very basics of the LLVM IR. Please visit the LLVM Language
    Reference Manual at [https://llvm.org/docs/LangRef.html](https://llvm.org/docs/LangRef.html)
    to look up all the details.
  prefs: []
  type: TYPE_NORMAL
- en: The IR code itself looks a lot like a mix of C and assembly language. Despite
    this familiar style, it is not clear how we can easily generate the IR code from
    an AST. The `phi` instruction in particular looks difficult to generate. But don’t
    be scared – in the next section, we’ll implement a simple algorithm to just do
    that!
  prefs: []
  type: TYPE_NORMAL
- en: Learning about the load-and-store approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All local optimizations in LLVM are based on the SSA form shown here. For global
    variables, memory references are used. The IR language knows load and store instructions,
    which are used to fetch and store those values. You can use this for local variables
    too. These instructions do not belong to the SSA form, and LLVM knows how to convert
    them into the required SSA form. Therefore, you can allocate memory slots for
    each local variable and use load and store instructions to change their value.
    All you need to remember is the pointer to the memory slot where a variable is
    stored. The `clang` compiler uses this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the IR code for load and store. Compile `gcd.c` again, but this
    time without enabling optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `gcd` function now looks different. This is the first basic block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The IR code now relies on the automatic numbering of registers and labels. The
    names of the parameters are not specified. Implicitly, they are `%0` and `%1`.
    The basic block has no label, so `2` is assigned. The first few instructions allocate
    memory for the four 32-bit values. After that, the `%0` and `%1` parameters are
    stored in the memory slots pointed to by registers `%4` and `%5`. To compare `%1`
    to `0`, the value is explicitly loaded from the memory slot. With this approach,
    you do not need to use the `phi` instruction! Instead, you load a value from a
    memory slot, perform a calculation on it, and store the new value back in the
    memory slot. The next time you read the memory slot, you get the last computed
    value. All the other basic blocks for the `gcd` function follow this pattern.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using load and store instructions in this way is that it is
    fairly easy to generate the IR code. The disadvantage is that you generate a lot
    of IR instructions that LLVM will remove with the `mem2reg` pass in the very first
    optimization step, after converting the basic block into SSA form. Therefore,
    we generate the IR code in SSA form directly.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start developing IR code generation by mapping the control flow to basic
    blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping the control flow to basic blocks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The conceptual idea of a basic block is that it is a *linear sequence of instructions*
    that are executed in that order. A basic block has exactly one entry at the beginning,
    and it ends with a terminator instruction, which is an instruction that transfers
    the control flow to another basic block, such as a branch instruction, a switch
    instruction, or a return instruction. See [https://llvm.org/docs/LangRef.html#terminator-instructions](https://llvm.org/docs/LangRef.html#terminator-instructions)
    for a complete list of terminator instructions. A basic block can begin with `phi`
    instructions, but inside a basic block, neither `phi` nor branch instructions
    are allowed. In other words, you can only enter a basic block at the first instruction,
    and you can only leave a basic block at the last instruction, which is the terminator
    instruction. It is not possible to branch to an instruction inside a basic block
    or to branch to another basic block from the middle of a basic block. Please note
    that a simple function call with the `call` instruction can occur inside a basic
    block. Each basic block has exactly one label, marking the first instruction of
    the basic block. Labels are the targets of branch instructions. You can view branches
    as directed edges between two basic blocks, resulting in the **control flow graph**
    (**CFG**). A basic block can have **predecessors** and **successors**. The first
    basic block of a function is special in the sense that no predecessors are allowed.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a consequence of these restrictions, control statements of the source language,
    such as `WHILE` and `IF`, produce several basic blocks. Let’s look at the `WHILE`
    statement. The condition of the `WHILE` statement controls if the loop body or
    the next statement is executed. The condition must be generated in a basic block
    of its own because there are two predecessors:'
  prefs: []
  type: TYPE_NORMAL
- en: The basic block resulting from the statement before `WHILE`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The branch from the end of the loop body back to the condition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also two successors:'
  prefs: []
  type: TYPE_NORMAL
- en: The beginning of the loop body
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic block resulting from the statement following `WHILE`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The loop body itself has at least one basic block:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – The basic blocks of a WHILE statement](img/B19561_04_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – The basic blocks of a WHILE statement
  prefs: []
  type: TYPE_NORMAL
- en: 'The IR code generation follows this structure. We store a pointer to the current
    basic block in the `CGProcedure` class and use an instance of `llvm::IRBuilder<>`
    to insert instructions into the basic block. First, we create the basic blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Fn` variable denotes the current function and `getLLVMCtx()` returns the
    LLVM context. Both are set later. We end the current basic block with a branch
    to the basic block, which will hold the condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The basic block for the condition becomes the new current basic block. We generate
    the condition and end the block with a conditional branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we generate the loop body. Finally, we add a branch back to the basic
    block of the condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'With that, we have generated the `WHILE` statement. Now that we’ve generated
    the `WhileCondBB` and `Curr` blocks, we can seal them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The empty basic block for statements following `WHILE` becomes the new current
    basic block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Following this schema, you can create an `emit()` method for each statement
    of the source language.
  prefs: []
  type: TYPE_NORMAL
- en: Using AST numbering to generate IR code in SSA form
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To generate IR code in SSA form from the AST, we can use an approach called
    **AST numbering**. The basic idea is that for each basic block, we store the current
    value of local variables written in this basic block.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The implementation is based on the paper *Simple and Efficient Construction
    of Static Single Assignment Form*, by Braun et al., International Conference on
    CompilerConstruction 2013 (CC 2013), Springer (see http://individual.utoronto.ca/dfr/ece467/braun13.pdf).
    In its presented form, it only works for IR code that has a structured controlled
    flow. The paper also describes the necessary extensions if you need to support
    arbitrary control flow – for example, a `goto` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is simple, we will still need several steps. We will introduce the
    required data structure first, and after that, we will learn how to read and write
    values local to a basic block. Then, we will handle values that are used in several
    basic blocks and conclude by optimizing the created `phi` instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the data structure to hold values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We use the `BasicBlockDef` struct to hold the information for a single block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `llvm::Value` LLVN class represents a value in SSA form. The `Value` class
    acts like a label on the result of a computation. It is created once, usually
    through an IR instruction, and then used. Various changes can occur during optimizations.
    For example, if the optimizer detects that the `%1` and `%2` values are always
    the same, then it can replace the use of `%2` with `%1`. This changes the label
    but not the computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be aware of such changes, we cannot use the `Value` class directly. Instead,
    we need a value handle. There are value handles with different functionality.
    To track replacement, we can use the `llvm::TrackingVH<>` class. As a result,
    the `Defs` member maps a declaration of the AST (a variable or a formal parameter)
    to its current value. Now, we need to store this information for each basic block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: With this data structure, we are now able to handle local values.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing values local to a basic block
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To store the current value of a local variable in a basic block, we will create
    an entry in the maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The lookup of a variable’s value is a bit more complicated because the value
    might not be in the basic block. In this case, we need to extend the search to
    the predecessors using a possible recursive search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The real work is searching the predecessors, which we’ll implement in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Searching the predecessor blocks for a value
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the current basic block we are looking at has only one predecessor, then
    we search there for the value of the variable. If the basic block has several
    predecessors, then we need to search for the value in all these blocks and combine
    the results. To illustrate this situation, you can look at the basic block with
    the condition of a `WHILE` statement from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: This basic block has two predecessors – the one resulting from the statement
    before the `WHILE` statement and the one resulting from the branch for the end
    of the body of the `WHILE` loop. A variable that’s used in the condition should
    have some initial value and will most likely be changed in the body of the loop.
    So, we need to collect these definitions and create a `phi` instruction from it.
    The basic blocks that are created from the `WHILE` statement contain a cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we recursively search the predecessor blocks, we must break this cycle.
    To do so, we can use a simple trick: we can insert an empty `phi` instruction
    and record this as the current value of the variable. If we see this basic block
    again in our search, then we’ll see that the variable has a value that we can
    use. The search stops at this point. Once we’ve collected all the values, we must
    update the `phi` instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: However, we will still face a problem. At the time of the lookup, not all predecessors
    of a basic block may be known. How can this happen? Look at the creation of the
    basic blocks for the `WHILE` statement. The IR for the condition of the loop is
    generated first. However, the branch from the end of the body that goes back to
    the basic block, which contains the condition, can only be added after the IR
    for the body is generated. This is because this basic block is not known earlier.
    If we need to read the value of a variable in the condition, then we are stuck,
    because not all predecessors are known.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this situation, we must do a little more:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we must attach a `Sealed` flag to the basic block.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we must define a basic block as sealed if we know all the predecessors
    of the basic block. If the basic block is not sealed and we need to look up the
    value of the variable not yet defined in this basic block, then we must insert
    an empty `phi` instruction and use it as the value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We also need to remember this instruction. If the block is later sealed, then
    we need to update the instruction with the real values. To implement this, we
    must add two more members to `struct BasicBlockDef`: the `IncompletePhis` map,
    which records the `phi` instructions we need later to update, and the `Sealed`
    flag, which indicates if the basic block is sealed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, the method can be implemented, as discussed at the beginning of this
    section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `addEmptyPhi()` method inserts an empty `phi` instruction at the beginning
    of the basic block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To add the missing operands to the `phi` instruction, first, we must search
    all the predecessors of the basic block and add the operand pair value and basic
    block to the `phi` instruction. Then, we must try to optimize the instruction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This algorithm can generate unneeded `phi` instructions. One approach to optimize
    these will be implemented in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the generated phi instructions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How can we optimize a `phi` instruction and why should we do it? Although the
    SSA form is advantageous for many optimizations, the `phi` instruction is often
    not interpreted by the algorithms and thus hinders the optimization in general.
    Therefore, the fewer `phi` instructions we generate, the better. Let’s take a
    closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the instruction has only one operand or all operands have the same value,
    then we replace the instruction with this value. If the instruction has no operand,
    then we replace the instruction with the special `Undef` value. Only if the instruction
    has two or more distinct operands do we have to keep the instruction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Removing a `phi` instruction may lead to optimization opportunities in other
    `phi` instructions. Fortunately, LLVM keeps track of the users and the use of
    values (which is the `use-def` chain mentioned in the definition of SSA). We must
    search for all uses of the value in other `phi` instructions and try to optimize
    these instructions too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If we want, we can improve this algorithm even further. Instead of always iterating
    the list of values for each `phi` instruction, we can pick and remember two distinct
    values. Then, in the `optimizePhi` function, we can check if these two values
    are still in the list of the `phi` instruction. If that is the case, then we know
    that there is nothing to optimize. But even without this optimization, this algorithm
    runs very fast, so we are not going to implement this now.
  prefs: []
  type: TYPE_NORMAL
- en: We are almost done. The only thing we haven’t done is implement the operation
    to seal a basic block. We will do this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Sealing a block
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As soon as we know that all the predecessors of a block are known, we can seal
    the block. If the source language contains only structured statements such as
    `tinylang`, then it is easy to determine where a block can be sealed. Take another
    look at the basic blocks that are generated for the `WHILE` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic block that contains the condition can be sealed after the branch
    from the end of the body is added because this was the last missing predecessor.
    To seal a block, we can simply add the missing operands to the incomplete `phi`
    instructions and set the flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With these methods, we are now ready to generate the IR code for expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the IR code for expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In general, you translate expressions, as shown in [*Chapter 2*](B19561_02.xhtml#_idTextAnchor037),
    *The Structure of a Compiler*. The only interesting part is how to access variables.
    The previous section treated local variables, but there are other kinds of variables
    we can consider. Let’s discuss what we need to do:'
  prefs: []
  type: TYPE_NORMAL
- en: For a local variable of the procedure, we use the `readLocalVariable()` and
    `writeLocalVariable()` methods from the previous section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a local variable in an enclosing procedure, we need a pointer to the frame
    of the enclosing procedure. This will be handled later in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a global variable, we generate load and store instructions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a formal parameter, we have to differentiate between passing by value and
    passing by reference (the `VAR` parameter in `tinylang`). A parameter that’s passed
    by value is treated as a local variable, and a parameter passed by reference is
    treated as a global variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Putting it all together, we get the following code for reading a variable or
    formal parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Writing to a variable or formal parameter is symmetrical – we just need to exchange
    the method to read with the one to write and use a `store` instruction instead
    of a `load` instruction.
  prefs: []
  type: TYPE_NORMAL
- en: Next, these functions are applied while generating the IR code for the functions.
  prefs: []
  type: TYPE_NORMAL
- en: Emitting the IR code for a function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of the IR code will live in a function. A function in IR code resembles
    a function in C. It specifies in the name, the types of parameters, the return
    value, and other attributes. To call a function in a different compilation unit,
    you need to declare the function. This is similar to a prototype in C. If you
    add basic blocks to the function, then you define the function. We will do all
    this in the next few sections, but first, we will discuss the visibility of symbol
    names.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling visibility with linkage and name mangling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Functions (and also global variables) have a linkage style attached. With the
    linkage style, we define the visibility of a symbol name and what should happen
    if more than one symbol has the same name. The most basic linkage styles are `private`
    and `external`. A symbol with `private` linkage is only visible in the current
    compilation unit, while a symbol with `external` linkage is globally available.
  prefs: []
  type: TYPE_NORMAL
- en: For a language without a proper module concept, such as C, this is adequate.
    With modules, we need to do more. Let’s assume that we have a module called `Square`
    that provides a `Root()` function and a `Cube` module, which also provides a `Root()`
    function. If the functions are private, then there is no problem. The function
    gets the name `Root` and private linkage. The situation is different if the function
    is exported so that it can be called from other modules. Using the function name
    alone is not enough, because this name is not unique.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is to tweak the name to make it globally unique. This is called
    name `Square.Root` as the name looks like an obvious solution, but it may lead
    to problems with assemblers as the dot may have a special meaning. Instead of
    using a delimiter between the name components, we can get a similar effect by
    prefixing the name components with their length: `6Square4Root`. This is no legal
    identifier for LLVM, but we can fix this by prefixing the whole name with `_t`
    (with `t` for `tinylang`): `_t6Square4Root`. In this way, we can create unique
    names for exported symbols:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If your source language supports type overloading, then you need to extend this
    scheme with type names. For example, to distinguish between the `int root(int)`
    and `double root(double)` C++ functions, the type of the parameter and the return
    value must be added to the function name.
  prefs: []
  type: TYPE_NORMAL
- en: You also need to think about the length of the generated name since some linkers
    place restrictions on the length. With nested namespaces and classes in C++, the
    mangled names can be rather long. There, C++ defines a compression scheme to avoid
    repeating name components over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at how to treat parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Converting a type from an AST description into LLVM types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The parameters of a function also need some consideration. First, we need to
    map the types of the source language to an LLVM type. As `tinylang` currently
    has only two types, this is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '`Int64Ty`, `Int1Ty`, and `VoidTy` are class members that hold the type representation
    of the `i64`, `i1`, and `void` LLVM types.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a formal parameter passed by reference, this is not enough. The LLVM type
    of this parameter is a pointer. However, when we want to use the value of the
    formal parameter, we need to know the underlying type. This is controlled by the
    `HonorReference` flag, which has a default value of `true`. We generalize the
    function and take the formal parameter into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: With these helpers at hand, we can create the LLVM IR function.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the LLVM IR function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To emit a function in LLVM IR, a function type is needed, which is similar
    to a prototype in C. Creating the function type involves mapping the types and
    then calling the factory method to create the function type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the function type, we also create the LLVM function. This associates
    the function type with the linkage and the mangled name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `getModule()` method returns the current LLVM module, which we’ll set up
    a bit later.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the function created, we can add some more information about it:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we can give the parameter’s names. This makes the IR more readable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, we can add attributes to the function and to the parameters to specify
    some characteristics. As an example, we will do this for parameters passed by
    reference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the LLVM level, these parameters are pointers. But from the source language
    design, these are very restricted pointers. Analogous to references in C++, we
    always need to specify a variable for a `VAR` parameter. So, by design, we know
    that this pointer will never be null and that it is always dereferenceable, meaning
    that we can read the value that’s being pointed to without risking a general protection
    fault. Also, by design, this pointer cannot be passed around – in particular,
    there are no copies of the pointer that outlive the call to the function. Therefore,
    the pointer is said to not be captured.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `llvm::AttributeBuilder` class is used to build the set of attributes for
    a formal parameter. To get the storage size of a parameter type, we can simply
    query the data layout object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have created the IR function. In the next section, we’ll add the
    basic blocks of the function body to the function.
  prefs: []
  type: TYPE_NORMAL
- en: Emitting the function body
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are almost done with emitting the IR code for a function! We only need to
    put the pieces together to emit a function, including its body:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a procedure declaration from `tinylang`, first, we will create the function
    type and the function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will create the first basic block of the function and make it the
    current one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must step through all formal parameters. To handle VAR parameters
    correctly, we need to initialize the `FormalParams` member (used in `readVariable()`).
    In contrast to local variables, formal parameters have a value in the first basic
    block, so we must make these values known:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After this setup, we can call the `emit()` method to start generating the IR
    code for statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last block after generating the IR code may not be sealed yet, so we must
    call `sealBlock()` now. A procedure in `tinylang` may have an implicit return,
    so we must also check if the last basic block has a proper terminator, and add
    one if not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With that, we’ve finished generating IR code for functions. However, we still
    need to create the LLVM module, which holds all the IR code together. We’ll do
    this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the module and the driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We collect all the functions and global variables of a compilation unit in an
    LLVM module. To ease the IR generation process, we can wrap all the functions
    from the previous sections into a code generator class. To get a working compiler,
    we also need to define the target architecture for which we want to generate code,
    and also add the passes that emit the code. We will implement this in this and
    the next few chapters, starting with the code generator.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping all in the code generator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The IR module is the brace around all elements we generate for a compilation
    unit. At the global level, we iterate through the declarations at the module level,
    create global variables, and call the code generation for procedures. A global
    variable in `tinylang` is mapped to an instance of the `llvm::GobalValue` class.
    This mapping is saved in `Globals` and made available to the code generation for
    procedures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The module also holds the `LLVMContext` class and caches the most commonly
    used LLVM types. The latter ones need to be initialized, for example, for the
    64-bit integer type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The `CodeGenerator` class initializes the LLVM IR module and calls the code
    generation for the module. Most importantly, this class must know for which target
    architecture we’d like to generate code. This information is passed in the `llvm::TargetMachine`
    class, which is set up in the driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'For ease of use, we must also introduce a factory method for the code generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The `CodeGenerator` class provides a small interface to create IR code, which
    is ideal for use in the compiler driver. Before we integrate it, we need to implement
    the support for machine code generation.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the target machine class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, only the target machine is missing. With the target machine, we define
    the CPU architecture we’d like to generate code for. For each CPU, there are features
    available that can be used to influence the code generation process. For example,
    a newer CPU of a CPU architecture family can support vector instructions. With
    features, we can toggle the use of vector instructions on or off. To support setting
    all these options from the command line, LLVM provides some supporting code. In
    the `Driver` class, we can add the following `include` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This `include` variable adds common command-line options to our compiler driver.
    Many LLVM tools also use these command-line options, which have the benefit of
    providing a common interface to the user. Only the option to specify a target
    triple is missing. As this is very useful, we’ll add this ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create the target machine:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To display error messages, the name of the application must be passed to the
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'First, we must collect all the information provided by the command line. These
    are options for the code generator – that is, the name of the CPU and possible
    features that should be activated or deactivated, and the triple of the target:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must look up the target in the target registry. If an error occurs,
    then we will display the error message and bail out. A possible error would be
    an unsupported triple specified by the user:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the help of the `Target` class, we can configure the target machine using
    all the known options requested by the user:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With the target machine instance, we can generate IR code that targets a CPU
    architecture of our choice. What is missing is the translation to assembly text
    or the generation of object code files. We’ll add this support in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Emitting assembler text and object code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In LLVM, the IR code is run through a pipeline of passes. Each pass performs
    a single task, such as removing dead code. We’ll learn more about passes in [*Chapter
    7*](B19561_07.xhtml#_idTextAnchor117), *Optimizing IR*. Outputting assembler code
    or an object file is implemented as a pass too. Let’s add basic support for it!
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to include even more LLVM header files. First, we need the `llvm::legacy::PassManager`
    class to hold the passes to emit code to a file. We also want to be able to output
    LLVM IR code, so we also need a pass to emit this. Finally, we’ll use the `llvm::
    ToolOutputFile` class for the file operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Another command-line option for outputting LLVM IR is also needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we want to be able to give the output file a name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The first task in the new `emit()` method is to deal with the name of the output
    file if it’s not given by the user on the command line. If the input is read from
    `stdin`, indicated by the use of the minus symbol, `-`, then we output the result
    to `stdout`. The `ToolOutputFile` class knows how to handle the special filename,
    `-`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, we drop a possible extension of the input filename and append `.ll`,
    `.s`, or `.o` as an extension, depending on the command-line options given by
    the user. The `FileType` option is defined in the `llvm/CodeGen/CommandFlags.inc`
    header file, which we included earlier. This option doesn’t support emitting IR
    code, so we’ve added the new`–emit-llvm` option, which only takes effect if it’s
    used together with the assembly file type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Some platforms distinguish between text and binary files, so we have to provide
    the right open flags when opening the output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can add the required passes to `PassManager`. The `TargetMachine` class
    has a utility method that adds the requested classes. Therefore, we only need
    to check if the user requests to output the LLVM IR code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'With all this preparation done, emitting the file boils down to a single function
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ToolOutputFile` class automatically deletes the file if we do not explicitly
    request that we want to keep it. This makes error handling easier as there are
    potentially many places where we need to handle errors and only one place is reached
    if everything goes well. We successfully emitted the code, so we want to keep
    the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must report success to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Calling the `emit()` method with `llvm::Module`, which we created with a call
    to the `CodeGenerator` class, emits the code as requested.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you have the greatest common divisor algorithm in `tinylang` stored
    in the `Gcd.mod` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'To translate this to the `Gcd.o` object file, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'If you’d like to inspect the generated IR code directly on the screen, type
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'With the current state of the implementation, it is not possible to create
    a complete program in `tinylang`. However, you can use a small C program called
    `callgcd.c` to test the generated object file. Note the use of the mangled name
    to call the `GCD` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'To compile and run the whole application with `clang`, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Let’s celebrate! At this point, we have created a complete compiler by reading
    the source language up and emitting assembler code or an object file.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to implement a code generator for LLVM IR code.
    Basic blocks are important data structures that hold all the instructions and
    express branches. You learned how to create basic blocks for the control statements
    of the source language and how to add instructions to a basic block. You applied
    a modern algorithm to handle local variables in functions, leading to less IR
    code. The goal of a compiler is to generate assembler text or an object file for
    the input, so you also added a simple compilation pipeline. With this knowledge,
    you will be able to generate LLVM IR code and assembler text or object code for
    your language compiler.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you’ll learn how to deal with aggregate data structures
    and how to ensure that function calls comply with the rules of your platform.
  prefs: []
  type: TYPE_NORMAL
