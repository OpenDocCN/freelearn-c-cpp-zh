- en: '*Chapter 9*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Requirements Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There may have been roughly an equivalent amount of thought over the last few
    decades into how to know you're building the right software as there has been
    into how to build software better. The software engineering techniques of the
    period 1960s-1980s explained how to construct requirements specifications, how
    to verify that the software delivered satisfied the specifications, and how to
    allow discoveries made while building and testing the software to feed back into
    the specification.
  prefs: []
  type: TYPE_NORMAL
- en: In the 1990s, methodologies arose that favored closer interaction between the
    users of the software and its builders. **Rapid Application Development** dropped
    "big upfront" planning in favor of quickly iterated prototypes that customers
    could explore and give feedback on. **Extreme Programming** took this idea further
    and involves the customer or a representative of the customer not only in appraising
    the product during development but in prioritizing and planning the project as
    it proceeds. (It's a bit of a simplification to call these 1990s ideas. Many of
    the concepts behind RAD and other methodologies had been around since at least
    the 1970s, and a systematic literature review could pin the ideas more precisely
    onto the calendar.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, it was the 1990s in which the ideas were synthesized into proposed
    systems for building software, and it was also the 1990s in which development
    teams started to use the systems and vendors created products to exploit their
    needs.)
  prefs: []
  type: TYPE_NORMAL
- en: In parallel with that story, the history of how software applications are presented
    to their users has also been evolving. The success of this presentation is evident
    in the way that successive generations of practitioners have distanced themselves
    from the terminology used by the previous generation. If attempts to make software
    usable had been seen to work, then people would be happy to associate themselves
    with the field. Instead, **Human-Computer Interaction** has fallen out of favor,
    as have **Human Interface Design**, **Computer-Supported Collaborative Working**,
    **Interaction Design**, **User Interface Design**, and so on. It'll soon be the
    turn of **User Experience** to become one of history's résumé keywords.
  prefs: []
  type: TYPE_NORMAL
- en: If the whole point of building software is to make it easier for people to do
    things, we should investigate what it is that people are trying to do and how
    to support that. Along the way, we can find out how to understand what *we* do,
    which can help us improve our own work (maybe even by writing software to do so).
  prefs: []
  type: TYPE_NORMAL
- en: Study People
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software applications do not exist in a vacuum. They are used by people; a system
    of people with existing goals, ideas, values, and interactions with each other
    (and yes, programmers, existing technology). The introduction of a new software
    product into this system will undoubtedly change the system. Will it support the
    existing goals and values or replace them with new ones? Will it simplify existing
    interactions, or introduce friction?
  prefs: []
  type: TYPE_NORMAL
- en: To answer these questions, we must have a way to measure that system of people.
    To do *that*, we must understand what questions we should ask about that system
    in order to support the things we want to learn and discover what it is we should
    measure.
  prefs: []
  type: TYPE_NORMAL
- en: Decide The Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In *Chapter 6, Testing*, I had to start by deciding that the requirements of
    a software system did not arise as some fundamental truth about the universe but
    were based on the way the people who used the system worked with the world and
    with each other. Now imagine that you're trying to understand the requirements
    of an application such as Excel. Will you consider the needs of each of the millions
    of users individually? While this could lead to a higher-quality product (or products,
    if you resolve conflicting needs by producing different solutions), there are
    few, if any, companies that could afford to undertake the research involved, and
    even if they could, it would be difficult to profit from the resulting software.
  prefs: []
  type: TYPE_NORMAL
- en: It's much cheaper to pick a small number of representative users and design
    the software for them. Some teams pick actual customers, while others create "personas"
    based on hypothetical customers, or on market research. Whichever way it's done,
    the product will come to represent the real or imagined needs of those real or
    imagined people
  prefs: []
  type: TYPE_NORMAL
- en: User personas give the impression of designing for users, when in fact the product
    team has merely externalized their impression of what they want the software to
    be. It's easy to go from "I want this feature" to "Bob would want this feature"
    when Bob is a stock photo pinned to a whiteboard; Bob won't join in with the discussion,
    so he won't tell you otherwise. The key thing is to get inside the fictitious
    Bob's head and ask "why" he'd want that feature. Sometimes, teams that I've been
    on where personas were used nominated someone to be their advocate during discussions.
    This gave that person license to challenge attempts to put words in the persona's
    mouth; not quite the same as having a real customer involved but still useful.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, the situation seems much better for builders of in-house or
    "enterprise" software; find the people who are going to use the software and build
    it for them. There are still some important questions about this model of the
    software's environment. One clear problem is where you're going to stop. Does
    the team you're building for represent an isolated unit in the company with clear
    inputs and outputs, or do you treat the interactions between members of this and
    other teams as part of the system? How about the interactions with customers,
    partners, and other external parties? The article **Three Schools of Thought on
    Enterprise Architecture**—[http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6109219](http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6109219)
    explores the effects of these boundaries on considering the systems involved.
  prefs: []
  type: TYPE_NORMAL
- en: Having decided on the scope of the system, are you designing for the specific
    people who currently comprise it or for more abstract concepts such as the roles
    that are occupied by those people? In either case, be aware of political biases
    entering into your model. Software designed according to a collaborative model
    of the interaction between a manager and their reports will differ from that modelled
    on the struggle between the oppressed workers and the exploitative bourgeoisie.
    Because the software will end up changing the system it's deployed into, such
    decisions will affect the way people work with each other.
  prefs: []
  type: TYPE_NORMAL
- en: You Shouldn't Necessarily Build What The Client Asks For
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Discovering the requirements for any software application is hard, even if the
    people building it are going to be the people using it. In *Chapter 6, Testing*,
    I explored the notion that everybody has their own idea of what the software should
    do, and in *Chapter 7, Architecture*, the fact that some requirements are not
    made explicit. So, if you just asked everyone for a list of things the software
    should do and built that, it'd be rife with conflicts and probably wouldn't do
    everything that any one person wanted from it.
  prefs: []
  type: TYPE_NORMAL
- en: While it's an inaccurate way of finding out what software should do, asking
    people is one of the easiest and most accessible methods. You can interview people
    with either a directed questionnaire or an open-ended discussion, finding out
    what they think of the system of interest and hopefully teasing out some of those
    tacit requirements. You can also get a group of people together, as a round-table
    discussion or a focus group, to collectively discuss their needs and problems.
    Even when people are being helpful and answering your questions to the best of
    their abilities, there will be problems that come up with interpreting their answers.
    The thing they do is likely a specialist activity, and so is making software.
    Each of these disciplines will have its jargon and its accepted "common sense"
    knowledge; translating between those will be difficult. Everyone has their own
    version of what "everybody" who does their job knows and will probably not think
    to tell you about those things.
  prefs: []
  type: TYPE_NORMAL
- en: So, there's an art (or maybe a science; I don't think the industry has made
    its mind up yet) to looking past the direct answers to your direct questions,
    to find out both what questions you *should* have asked and what answers you would
    *never* have been given. This is where bespoke software (particularly so called
    "enterprise" software) has a chance to provide a much better experience than off-the-shelf
    software; you have the opportunity to observe what your users *really* do and
    to provide software that supports that, rather than offering something that supports
    their stated needs.
  prefs: []
  type: TYPE_NORMAL
- en: You need to remember too that *you* are the software expert, and your client
    is the expert at solving whatever problem it is that they solve. When they talk
    about the *problem* they are having, there is more information about how it should
    be solved than when they tell you about the *solution* they envisage. That's not
    to say that you shouldn't accept their suggestions; but you *should* remember
    that their expertise lies elsewhere and that your team probably has more experience
    of designing software. Obviously, if you're a start-up working on a developer
    tool, your team probably has *less* experience than your customers.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid Asking What You Want To Hear
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you've got a pet feature, it's all too easy to drop it into a discussion
    of the proposed system when conducting interviews and focus groups with prospective
    users. The problem you then face is that it's easy for people to agree that said
    feature would be a good idea, even if it really wouldn't.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, you have to separate things that people think they would use from things
    that people *do* use. Consider whatever word processing software you use and think
    about all the features it has that you've never touched. When you bought the software,
    were you swayed by any of the discussions of those features in the marketing material?
    (The idea that word processors have more features than people use has been investigated
    by human-computer interaction researchers—[https://www.cs.ubc.ca/~joanna/papers/GI2000_McGrenere_Bloat.pdf](https://www.cs.ubc.ca/~joanna/papers/GI2000_McGrenere_Bloat.pdf)
    and while they found that some features go unused by some users, the users still
    know that those features are there and have some familiarity with their function.
    So, saying that these extra features are entirely without value is clearly a stretch;
    nonetheless, the default choice on whether we "should" incorporate a feature into
    a product is usually "yes" due to the feature matrix marketing described here.)
    Do you think the majority of other users do make use of those features? Would
    the software be worth as much if it didn't have those features? Given the choice
    between an application that does a thing and one that doesn't, people will often
    choose the one that does it even if they don't see a need for that right now.
    Particularly as, when you're gathering requirements, there's no other information
    to go on; without being able to see the two (currently hypothetical) applications,
    prospective users can't compare their usability, speed, quality, or other features,
    so the options really do boil down to "with" or "without."
  prefs: []
  type: TYPE_NORMAL
- en: 'Bear in mind, too, the tendency for people without a strong view on a statement
    to agree with it. This is known in psychological circles as the *acquiescence
    response bias* and needs to be taken into account when evaluating the results
    of questionnaires. An example is in order. Imagine that you wanted to build a
    "clean coder" IDE, but you want to find out whether anyone would use it first.
    You create a questionnaire asking respondents to rate how strongly they agree
    or disagree with these statements:'
  prefs: []
  type: TYPE_NORMAL
- en: A professional programmer writes unit tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good method has minimal loops and branches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long, descriptive variable names are better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Someone else wants to write a "stripped-down" IDE, harking back to the times
    when "real programmers didn''t eat quiche" and just got their jobs done. (This
    is a tongue-in-cheek reference to the article **Real Programmers Don''t Use Pascal**—[http://www.ee.ryerson.ca/~elf/hack/realmen.html](http://www.ee.ryerson.ca/~elf/hack/realmen.html),
    which was itself a tongue-in-cheek reference to the book **Real Men Don''t Eat
    Quiche**—[https://bit.ly/2XjLjxw](https://bit.ly/2XjLjxw). That was itself satirical,
    but I''ve run out of cheeks into which I am willing to insert my tongue.) They
    create a questionnaire in which respondents rate their agreement with these statements:'
  prefs: []
  type: TYPE_NORMAL
- en: Time spent writing tests is time spent not adding value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good method has as many loops and branches as necessary to provide a simple
    interface onto complex work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typing is not the focus of programming; terseness is a virtue.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These questionnaires will yield different results; not necessarily entirely
    in opposition to one another but certainly each revealing a bias in favor of the
    higher end of their respective scales. This is the acquiescence response bias;
    each has asked what they wanted to hear and the respondents in each case have
    tended to agree with it. The two researchers should have each chosen a mix of
    questions from both lists to get a more representative survey.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, bear in mind that telling your client "I think we should do it like
    *this*" will predispose them to that approach, due to a cognitive bias called
    **anchoring**—[https://www.sciencedaily.com/terms/anchoring.htm](https://www.sciencedaily.com/terms/anchoring.htm)).
    Having *anchored* a particular feature or workflow in their mind, they'll prefer
    options that contain that feature or workflow even if it rationally appears worse
    than an unrelated alternative. You could end up privileging a suboptimal or costly
    design just because it was the first thing you thought of and blurted it out to
    your clients. It's best to leave options open early on so that you don't pit your
    own customers against better designs you create later on.
  prefs: []
  type: TYPE_NORMAL
- en: Understand The Problem Domain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier, you and your team are the experts in making software,
    and the customers are the experts in the thing that the software will do. I've
    cautioned against using that distinction to build the software you want rather
    than the software that the customers need; should this be taken to mean that the
    software people stick to software and the customers stick to their problem domain?
  prefs: []
  type: TYPE_NORMAL
- en: No.
  prefs: []
  type: TYPE_NORMAL
- en: You need to know what you're building *for*, so you need to have some understanding
    of the problem domain. Yes, this is asymmetric. That's because the situation is
    asymmetric – you're building the software to solve a problem; the problem hasn't
    been created so that you can write some software. That's just the way it is, and
    compromises must come more from the software makers than from the people we're
    working for. The better you understand the problem you're trying to solve, the
    more you can synthesize ideas from that domain and the software domain to create
    interesting solutions. In other words, you can write better software if you understand
    what it is that software will do. That's hopefully not a controversial idea.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different levels on which this understanding can be implemented,
    relevant to different amounts of interaction with customers. *Chapter 5, Coding
    Practices*, described **Domain-Driven Design** and the ubiquitous language: the
    glossary of terms that defines concepts in the problem domain and should be used
    to name parts in the software domain, too. Needless to say, everyone working on
    the software should be familiar with the ubiquitous language and using it in the
    same way – it''s not ubiquitous otherwise! The point of the ubiquitous language
    is to ensure that everyone—customers and software makers—means the same thing
    when they use technical or jargon terms. Therefore, it prefers jargon to be from
    the problem domain, so that non-software people don''t have to learn software
    terminology, and it''s expected that the terms pervade the software design and
    implementation and are not just used in customer meetings.'
  prefs: []
  type: TYPE_NORMAL
- en: The ubiquitous language should be considered a starting point. Some methodologies,
    including Extreme Programming, require that the development team have a customer
    representative on hand to ensure that the development work is always adding value.
    These discussions need to be had at the level of the business, that is, at the
    level of the problem domain. (This is one of the reasons that programmers often
    get frustrated that the business doesn't schedule time for refactoring, development
    infrastructure, or "paying off" technical debt. The problem is that bringing these
    things up in the context of a business discussion is a mistake; these are internal
    details of what we do and how we work with each other and have nothing to do with
    business value or how we work with customers. If some refactoring work is going
    to make it easier to work on the software, then just do it and let the business
    see the results in terms of reduced costs.) This in turn means that at least one
    person is going to need to be capable of having a peer discussion about the problem
    at hand with the customer representative.
  prefs: []
  type: TYPE_NORMAL
- en: Uncover Tacit Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter has already covered the idea that you need to find out what customers
    need from their software that they're not talking about. But it's worth bringing
    up again, because the ubiquitous language may have ubiquitous holes.
  prefs: []
  type: TYPE_NORMAL
- en: Think of all the times you've been surprised at a question someone from outside
    the software field has asked about an application you're writing. Well, no, of
    *course* the app we made for the seven-inch tablet won't work on the three-inch
    phone. It's such a basic thing, it's not even worth mentioning, so why would someone
    ask it?
  prefs: []
  type: TYPE_NORMAL
- en: Now think about flipping that situation. What are the things that people in
    your problem domain think so basic that they'd never mention them? The things
    that a professor told them were "obvious" in a first-year lecture and they haven't
    questioned since? How are you going to get anyone to tell you about them?
  prefs: []
  type: TYPE_NORMAL
- en: As with pair coaching, this is a situation where acting like a petulant toddler
    can be to your advantage. Domain experts are likely to have particular ways of
    doing things; finding out *why* is what's going to uncover the stuff they didn't
    think to tell you. It'll be frustrating. Some things we don't have real reasons
    for doing; they're just "best" practice or the way it gets done. Probing those
    things will set up a cognitive dissonance, which can lead people to get defensive;
    it's important to let them know that you're asking because you're aware how much
    of an expert they are at this stuff and that you just need to understand the basics
    in order to do a good job by them.
  prefs: []
  type: TYPE_NORMAL
- en: Why the cognitive dissonance? Well, sometimes we just do things because "that's
    how they're done," rather than because there's any known value to that technique.
    We can find examples of this in the field of making software. Many developers
    (though, far from all) use version control. What are the benefits of doing so?
    Surprisingly, *no study can be found*—[http://www.neverworkintheory.org/?p=451](http://www.neverworkintheory.org/?p=451)
    that investigates that. However, many developers, myself included, will tell you
    that version control is important, you should be doing it, and can come up with
    benefits. Tell us "but there's no evidence for those benefits, so why not just
    stop?" and we'll get confused and angry, trying more vociferously to defend our
    position despite the problems with the argument.
  prefs: []
  type: TYPE_NORMAL
- en: You Shouldn't Build What Your Client Wants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At least, you probably shouldn''t, anyway. Most of the time, they won''t represent
    the majority of users, or even *any* of the users. This happens in pretty much
    every field of software:'
  prefs: []
  type: TYPE_NORMAL
- en: In-house software is usually commissioned by the IT department, but will be
    used by sales, engineers, finance, and other departments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commercial software is usually driven by a product manager but will be sold
    to thousands (or more) of people. Even where you have a dedicated customer representative,
    they represent only one of many users. And, as with in-house software, the "representative"
    may still not be the ultimate user of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even in a case where you're building bespoke software for a small team of people
    who are involved in the decision-making, a disproportionate number of suggestions
    will come from the more senior or more vocal users; with the worst case being
    that specific requests get filtered through the understanding of a senior manager
    before being summarized and presented to the development team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What this means is that, in almost all situations, what your client wants is
    at best only a rough approximation to what would be in the best interests of the
    product (and therefore its user base, and presumably your bottom line). The trick
    to managing this is, of course, political rather than technical; you probably
    don't want to offend the people who *are* giving you input into the software requirements,
    especially if they're paying the bills. That means flipping the **Bozo Bit**—[http://c2.com/cgi/wiki?SetTheBozoBit](http://c2.com/cgi/wiki?SetTheBozoBit)
    is out of the question. But if something's a bad idea, you probably don't want
    it in your app.
  prefs: []
  type: TYPE_NORMAL
- en: But what makes *you* sure it's a bad idea? Even if you are the user of the software
    you're writing, it's still one not-quite-representative user versus another. Yes,
    you may have more of an idea about platform norms and expected behavior, but that
    could also mean that you're conservative about brand new ideas because no other
    app works this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Resolving this conflict can be achieved with data. I discussed A/B testing
    and user acceptance testing in *Chapter 6, Testing*; those tools can be put to
    use here in discovering whether any given suggestion improves the software. It
    doesn''t have to be expensive; in that, you don''t have to build the whole feature
    before you can find out whether anyone wants it. You could try out a prototype
    on a whiteboard to see how people get on with it or build a very basic version
    of the feature to see how popular it is. Be cautious about trying to poll users
    to find out how popular a feature would be though: answering "yes" or "no" takes
    the same effort, but in one case they get a higher chance of getting a new shiny
    thing, whether they''d use it or not. The risk/reward calculation in responding
    to a feature poll is biased toward affirming the request, and we''ve already seen
    acquiescence bias means people tend to agree with whatever statement is presented
    to them.'
  prefs: []
  type: TYPE_NORMAL
- en: When you've got the data, the conversation can start "that was a nice idea,
    but it looks like the customers aren't ready for it" rather than "I'm not building
    your bad feature." That's a much easier way to have an ongoing relationship with
    your clients. Unfortunately, it's not always an option; plenty of software is
    still built in secrecy, with no user engagement until 1.0 is nearly ready (or
    even later). In these cases, your imperfect customer proxies are all you've got
    and, like it or not, you have only their suggestions and your opinions to work
    with. You can still frame discussion around hypothetical other users (often called
    personae) to defuse any emotional feelings about challenging "personal" feature
    requests, but that's an imperfect rhetorical tool rather than an imperfect requirements
    tool. Application telemetry in the 1.0 release can tell you how people really
    use the features and help you prioritize future development, but that's too late
    for discussions about the initial release; and remember that it's the initial
    release that costs money while it's not paying for itself.
  prefs: []
  type: TYPE_NORMAL
- en: Human Factors In Software Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The thing about software requirements is that they don't exist. Or at least,
    they don't exist in isolation. The standard model of particle physics is based
    on the idea that there are fundamental particles called quarks, and that these
    combine into systems called *hadrons* (heavyweight particles including protons
    and neutrons) and *mesons* (middleweight particles important in high-energy interactions).
    Quarks are bound into these systems by *gluons*, the particles that carry the
    strong force. This model is generally accepted, even though no one has ever seen
    a quark or a gluon in isolation; they're always part of a hadron or meson.
  prefs: []
  type: TYPE_NORMAL
- en: Just as quarks and gluons have no existence on their own, so software on its
    own without users is meaningless, and software users without software have nothing
    to do. The whole represents a *socio-technical system* and it is *this* system
    that we are constructing and modifying with our software-building efforts. So,
    no view on software requirements is complete without a view of the effect the
    software will have on the politics, economics, social structure, and psychology
    of the people who will interact with it, and of how those people will affect the
    software.
  prefs: []
  type: TYPE_NORMAL
- en: '*I''ve had a theoretical grasp on this point for years. It was finally emotionally
    reified for me by* **Robert Annett**—[https://twitter.com/robert_annett](https://twitter.com/robert_annett)
    *during a talk he gave on legacy software systems. The anecdote he told involved
    him walking through an office at the company he was deploying a new system at,
    talking with one of the people he''d be working with. As they left a room where
    around 20 data entry clerks were working, his new colleague said quietly "it''s
    a shame really – when your new system comes online, we''ll have to fire them."*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Sometimes, the pattern of sigils and words you feed to the compiler can have
    a real impact on real people, good or bad.*'
  prefs: []
  type: TYPE_NORMAL
- en: Economics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The economic side of this interaction is covered well by Barry Boehm in his
    1981 book **Software Engineering Economics**—[http://books.google.co.uk/books/about/Software_engineering_economics.html?id=VphQAAAAMAAJ&redir_esc=y](http://books.google.co.uk/books/about/Software_engineering_economics.html?id=VphQAAAAMAAJ&redir_esc=y).
    His model for estimating the costs of software projects has not been generally
    adopted in the industry, but it does include what he calls "human relations factors,"
    which can affect the cost of a software system and the benefits derived. It includes
    the "modified golden rule" for working with other people:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Do unto others as you would have others do unto you – if you were like them*.'
  prefs: []
  type: TYPE_NORMAL
- en: The point of the conditional clause is to remind programmers that not everyone
    wants to be treated like they enjoy solving software problems and can understand
    computer science concepts. Boehm argues that the costs and benefits of usability,
    of satisfying human needs, and of allowing users to fulfil their potential need
    to be considered in economic terms for a software project.
  prefs: []
  type: TYPE_NORMAL
- en: 'While surely better (or at least, more complete) than not reasoning at all
    about these factors, trying to find a dollar value for them is an early stage
    in their consideration. What I infer from it, and from similar arguments in information
    security and other fields (remember the discussion on the economic value of accessibility,
    in the *Chapter 6, Testing*) is that we either can''t *see* or can''t *justify*
    an intrinsic benefit of those properties, but would still like to include them
    in our decision-making. The fact that we''re not willing to ignore them leads
    me toward the second explanation: we know that these things are valuable but don''t
    have an argument to support that.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s not to say that these defenses for human factors aren''t useful; just
    that they aren''t the apotheosis of debate. You can see how usability might be
    economically justified in terms of cost; more effort in designing usable software
    can pay off in making its users more efficient, and more satisfied. Satisfaction
    (linked to another of the factors – fulfilment of human potential) can lead to
    greater engagement with their work and higher levels of staff retention, reducing
    the HR costs of the organization. Satisfying human needs is what **Herzberg**—[http://www.businessballs.com/herzberg.htm](http://www.businessballs.com/herzberg.htm)
    deems a *hygiene factor*: people must have their basic needs met before they can
    be motivated to pursue other goals.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes the trade-off in goals cannot reasonably be cast in economic terms.
    A good example is a game: if it had great usability, it''d be really simple so
    people would complete it quickly and then get back to work – an economic win.
    But people don''t play games that are straightforward; they play games that offer
    them a challenge, whether that challenge be mental, dexterous, or something else.
    Therefore, the player''s desire to be challenged, or to lose themselves in the
    game world, takes precedence, although it is difficult to see how to assign a
    monetary value to that desire.'
  prefs: []
  type: TYPE_NORMAL
- en: Politics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The political side of software development can have an impact on how people
    think they are recognized, supported, empowered, and valued by the system in which
    the software is used and the wider system of interacting systems. Let''s start
    this section by looking at a case study: a shared calendar application used in
    a business. On one team, everyone can schedule events on their own calendar, and
    the manager can see everyone''s calendars. Additionally, the manager has a personal
    assistant who can schedule events for the manager in the manager''s calendar.'
  prefs: []
  type: TYPE_NORMAL
- en: The manager feels in a position of power, because they can see where everyone
    is and can strategically walk past their desks to see what they're up to at times
    when their reports should be there, because they don't have any meetings recorded.
    Additionally, the manager feels empowered because the mechanical work of updating
    the calendar software has been delegated to someone else, and delegation is a
    key activity for managers.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the other members of the team feel empowered because they
    can control the manager through the calendar software. If they do not want to
    be disturbed, they can create themselves a "meeting" and find somewhere quiet
    to work. They can work with the personal assistant to arrange for the manager
    to be in a meeting at a time when they want to have a team discussion without
    the manager's involvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'This discussion about calendar software depends on an underlying model of the
    politics in the group using the calendar: I wrote it to rely on a *Marxist* model,
    exposing the struggle between the manager (playing the part of the capitalist)
    and the workers. Each group is represented by their own goals, which are, according
    to the model, inevitably in conflict. Stability is achieved by ensuring that conflicting
    goals do not come into direct opposition over a single issue.'
  prefs: []
  type: TYPE_NORMAL
- en: Whether the people participating in this system are really engaged in the conflict
    presented in this model of the system – and whether individual participants would
    recognize that conflict or have a different perception of the system, is not captured
    within this model. It's an internally consistent story that has nothing to tell
    us about its own accuracy or applicability.
  prefs: []
  type: TYPE_NORMAL
- en: In designing software to be used by multiple people, the real politics of the
    system of people and our model of those politics will both shape the interactions
    facilitated by the software. Will the software support an existing distribution
    of power or will it empower one group at the expense of others? Is the political
    structure modeled on a coarse level (as in the managers/workers case above) or
    are the different needs and expectations of every individual in the system captured?
    Will the software enable any new relationships or break some existing relationships?
    Will it even out inequalities, reinforce existing inequalities, or introduce new
    ones?
  prefs: []
  type: TYPE_NORMAL
- en: 'These are complex questions to address but it is necessary to answer them for
    the impact of collaborative software on its users to be fully understood. As the
    anecdote earlier in this section shows, software systems can have a real impact
    on real people: the management of a large business may be pleased to reduce their
    headcount after deploying new software, to recoup development costs, and see it
    as the responsibility of those who are made redundant to find alternative employment.
    A charity with a remit to support local people by providing work may prefer to
    retain the workers and reject the software. Only by understanding the political
    environment can you be sure that your software is a good social fit for its potential
    users and customers.'
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section really reiterates what came before: you should be building software
    that your users *need* in preference to what they *want*. That''s the ideology,
    anyway. Reality has this annoying habit of chipping in with a "well, *actually*"
    at this point.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s much easier to *sell* the thing the buyer wants than the thing they really
    need. Selling things is a good opportunity to take, as it allows you to fund other
    activities: perhaps including the development of the thing that the customers
    still needs. But, well, *actually*...'
  prefs: []
  type: TYPE_NORMAL
- en: '...good marketing efforts can convince the customer that the thing they actually
    need is something they do in fact want. You can then shortcut all of the above
    discussion by making the thing people *should* be buying and convincing them to
    buy it. This is one of those high-risk, high-reward situations: yes, *selling
    people a faster horse*—[http://blogs.hbr.org/cs/2011/08/henry_ford_never_said_the_fast.html](http://blogs.hbr.org/cs/2011/08/henry_ford_never_said_the_fast.html)
    is easier but the margins will not be as high and the success not as long-lived
    as if you invent the motorcar industry. As they say, profit is a prize for taking
    a risk.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how you prioritize building the software really depends on your comfortable
    risk level. You could get incremental low-margin gains by finding the things that
    people are definitely willing to buy and building those. This is the **Lean Start-up**
    approach, where you start with nothing and rapidly iterate towards what the data
    is telling you people want to buy. Or you could take the risk: build the thing
    you know people need, then convince them that it''s worth the money. This is the
    approach that bears most resemblance to Steve Jobs'' famous position: *It''s not
    up to customers to know what they want*.'
  prefs: []
  type: TYPE_NORMAL
- en: Is It Really "Engineering"?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There''s an old quote that says anything where people feel the need to include
    the word "science" isn''t a science. And, yes, the original author was talking
    about computer science. But perhaps we should be wary of the attribution of "engineering"
    to requirements engineering. Engineering is, after all, the application of science
    to the manufacture of artifacts, while requirements engineering is the application
    of social science (the warning is firing again!) to the business of improving
    a social system. Really, it''s a transformation of some fields of social science
    (politics, economics, anthropology, ethnography, and geography) to other fields
    of social science (sociology and business studies) with some software created
    to effect the transformation. (Shortly after I finished writing this section,
    Paul Ralph submitted a paper to ArXiv describing **the rational and alternative
    paradigms**—[http://arxiv.org/abs/1303.5938v1](http://arxiv.org/abs/1303.5938v1)
    of software design. The rational paradigm is basically the intuition-based version
    of requirements engineering: the software requirements exist as a fundamental
    truth to the universe and can be derived from careful thought. The alternative
    paradigm is the empirical one: the requirements arise as a result of the interactions
    between people and can only be understood through observation. Ralph''s paper
    does a good job of explaining these two paradigms and putting them in context
    in the history of software design.)'
  prefs: []
  type: TYPE_NORMAL
- en: This isn't to say that the phrase "requirements engineering" needs to be retired,
    because people know what it means and use it as a placeholder for the real meaning
    of the discipline. But maybe we need to think of this as a generational thing;
    that while to *us* it's called "requirements engineering," we remember to give
    it a different term with the people we teach; something like "social software".
  prefs: []
  type: TYPE_NORMAL
