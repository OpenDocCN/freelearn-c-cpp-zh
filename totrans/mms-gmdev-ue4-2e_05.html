<html><head></head><body>
        

                            
                    <h1 class="header-title">Adding Enemies!</h1>
                
            
            
                


            

            
        
    

        

                            
                    <h1 class="header-title"> Introduction</h1>
                
            
            
                
<p>For most games involving combat, there are typically <strong>non-player characters</strong> (<strong>NPCs</strong>) in one form or another. NPCs give a feeling of realism and interaction to games, and the AI that controls them makes them believable (or not!), so it is very important to get it right. Making the most of UE4s BehaviorTree is a very important step to making games efficiently with compelling enemies and friends. In this chapter, we will make a basic melee enemy that will use bits of information from the world to update its choices in its BehaviorTree and react to the player appropriately. We'll also delve into a bit of debugging the tree and its data.  Our main goals here will be:</p>
<ul>
<li>Importing a new character and skeletal mesh to the game</li>
<li>Creating a new AIController class</li>
<li>Building a basic Behavior Tree brain</li>
<li>Add sensing via C++</li>
<li>Hook up behavior to the Animation Blueprint</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>As always, it's recommended to follow the progress in all the preceding chapters; however, the bulk of this chapter will work as a standalone project as well, with a few exceptions.  </p>
<p>The chapter's GitHub branch is, as usual, here:</p>
<p><a href="https://github.com/PacktPublishing/Mastering-Game-Development-with-Unreal-Engine-4-Second-Edition/tree/Chapter-5">https://github.com/PacktPublishing/Mastering-Game-Development-with-Unreal-Engine-4-Second-Edition/tree/Chapter-5</a></p>
<p>Engine version used: 4.19.2.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating an AI controller and a basic brain</h1>
                
            
            
                
<p>Much like adding new weapons in the last chapter, we're going to want some interesting new visuals for our AI enemies, so let's head back to the marketplace and see what is freely available. The Paragon project (which was canceled) yielded a huge amount of assets released for free by Epic, so let's import one or more of their characters that we can use for our enemies. Then we give them a controller, spawn them in our level, and see how their brain makes decisions and ultimately becomes a challenging opponent for our player to fight!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Proving out the basics</h1>
                
            
            
                
<p>In the marketplace, to prove out our concept, the GitHub project will begin by importing the Paragon: Countess assets the same way we did at the beginning of <a href="eadb37a8-4ecb-4fc9-b391-e65671c99fc0.xhtml" target="_blank"/><a href="eadb37a8-4ecb-4fc9-b391-e65671c99fc0.xhtml" target="_blank">Chapter 4</a>, <em>UI Necessities – Menus, HUD, and Load/Save</em>. Note that to save approximately 200 MB of the approximately 2 GB download of such a high-detail character, the Tier 2 skins were removed from GitHub, but of course you're welcome to use any of the many amazingly detailed characters that were released from the Paragon project. Once the character is added to the project, there are three main steps to getting it doing anything meaningful in the game:</p>
<ol>
<li>Create a new <kbd>AIController</kbd> class and make a blueprint instance of it (here, it's called <kbd>MeleeAIController</kbd>).</li>
<li>Add an AnimationBlueprint for and hook it to a new Character.</li>
<li>Add a BehaviorTree to the controller with some nodes to get it to start, well, behaving.</li>
</ol>
<p>Getting some basic functionality from the behavior tree takes a little bit of additional basics, but let's go through these quickly one step at a time to get a basic functioning pawn in the game.</p>
<p>Upon creating the AI controller, for now just add one variable:</p>
<pre>public:
        
        UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "Targeting")
        float HearingRadius = 300.0f;</pre>
<p>Make a blueprint instance of this in FirstPersonCPP/AI and name it CountessController.</p>
<p>In ParagonCountess | Characters | Global, make a new Animation | Animation Blueprint class. When you do this, it will ask for a parent class and a skeleton: use AnimInstance and S_Countess_Skeleton respectively. Once created, name it <kbd>ABP_Countess</kbd> and double-click that to bring up its editor. If you click the AnimGraph tab, you can see one simple node, drag from its input and filter to StateMachine, and add a new one and double-click it. Drag from Entry and add a state. Name it Idle and double-click it and we will be done with a very temporary animation blueprint with one quick node, like so:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/be6ad5bd-23a2-4fec-a4be-d3cabefc7444.png"/></p>
<p class="mce-root"/>
<p>To use and test our character at all, first make a new Blueprint Class in FirstPersonCPP/AI based on Character, and name it <kbd>BP_Countess</kbd>. We will set it up to look like so:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d851f969-da3e-4581-8f2b-4bdc4ea07f84.png"/></p>
<p>Note the capsule root component for collision purposes, and the mesh's position and rotation offsets to get things looking right on the ground in game. Also, click the (self) component at the top and set AIController to CountessController.</p>
<p>Now for the most relevant part, but note that this is also going to be in a very bare-bones state for the moment as we simply get all our classes and requirements blocked out. As noted previously, whenever it's possible to get things working at a basic level and checked in to source control as a checkpoint, this is a great idea even if the overall work changes (or classes are even deleted) as the task progresses. This gives a safe fallback point if anything goes wrong, and when you're working in a team it allows for easy sharing of the state of your work, so we'll do that once our basic tree is in. In our AI folder, right-click and under Artificial Intelligence and add a Behavior Tree and a Blackboard. Name them MeleeTree and MeleeBoard respectively. Opening the blackboard, we will add two keys by using the add button in the top left. Make one an object type and the other a vector, and we'll name them Target and TargetLocation respectively on the right side of the editor in their properties. Opening the behavior tree next, we first click the button near the top to add a new service. This will create it for you at the same folder level in the content browser. Rename it <kbd>BTService_FindTarget</kbd> and double-click it. This service works as a piece of blueprint scripting you can use in various places in a behavior tree. It's the only complicated portion of what we'll currently check-in, and building its graph looks like so:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5643f1ab-a62e-431e-b3ff-7c5d845d06ea.png"/></p>
<p>Hopefully, by now this is fairly straightforward: the owning actor of any behavior tree service is the AI controller. We then get our hearing radius from that and do a sphere sweep for any MasteringCharacter pawns and, assuming we find one, we set the target and target location variables (by name!) to update to our player location. Blackboards, as the name implies, are a place to post data from various outside locations that can then be directly accessed internally by a behavior tree. Just think of them as variable holders using key/value pairs.</p>
<p>Now that we have that done, we can make a super-simple behavior tree. First, confirm its blackboard in the root's details is set to MeleeBoard. Next, in its main editing area, drag down on the behavior tree's root and add a selector node. The quickest way to think about selectors and sequencers is that both do a set of tasks (which can, of course, have child selectors and sequencers), but selectors run from left to right through their children until one succeeds (and then it returns control back up the tree). A selector runs left to right until one of its children fails. On this selector, right-click its node and click Add Service. Of course, we'll select our find target service and click it so that in its properties in its details window, we can just remove the random time interval (set to <kbd>0.0</kbd>) so it runs every half second. And lastly, dragging from the selector, pick a task and use MoveTo, and set its blackboard key to TargetLocation in its details window, and set its Acceptable Radius to 100.0 so she doesn't get too close for comfort:</p>
<p>Note on navigation: to generate a nav-mesh used by the behavior here, we need to add a NavMesh volume to the level and have it encompass everywhere you want AI to be able to traverse. Going forward, adding one of these volumes (or many in finer detailed areas) should be standard practice. A quick link about NavMesh volumes will be added to the <em>Further reading</em> section at the end.</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/4766233f-8636-4da4-a61f-0a4221bb4371.png"/></p>
<p>That's it! Place a <kbd>BP_Countess</kbd> directly into your level by dragging it in and without properly animating or smoothly turning, she should follow you around the map! We've reached a major checkpoint in this work, and this will be reflected in the GitHub project.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding C++ decision making to the behavior tree</h1>
                
            
            
                
<p>The next process involves taking some of the logic and sensing out of blueprints and into C++. This can be valuable for a number of reasons. While the blackboard concept works just fine, it can be difficult to manage and even more difficult at times to debug than even typical blueprint debugging. If a variable is suddenly not what you expected it to be, there isn't always an obvious way to track down why. So, having as much logic as is reasonable and possible in C++ is always a help. In this instance, we're effectively removing the hearing detection and target setting from the preceding task into C++.</p>
<p>There are always advantages and disadvantages to this. For example, we won't really get new functionality out of this work here, but we gain a more scalable performance and easier debugging as complexity later increases. If no further complexity is needed, it's probably best to stop where we did in the last section and call it a day. One major issue arises in synchronizing the two layers, which you must. For an example of iterative development, my first instinct was to use the <kbd>OnTargetChange</kbd> blueprint event to simply set our blackboard variable and then let the blackboard decorator pull the actor's location from the target object. I remember once encountering a problem when I did this: as the time play begins, the blackboard is told to start and, in the same tick, the sphere now added to the player will do its initial collision query. When trying to use the edge-driven event to set the target, it fails on the first frame as there is no blackboard to set a variable on, and it will never correct itself until the player leaves the hearing sphere radius and re-enters. So a more pull-driven mixed solution was ultimately implemented here as seen here:</p>
<pre>public:
        
        AMeleeAIController(const FObjectInitializer&amp; ObjectInitializer = FObjectInitializer::Get());
 
        UFUNCTION(BlueprintImplementableEvent)
        void OnTargetChange(class AMasteringCharacter* Target);
 
        UFUNCTION(BlueprintCallable)
        class AMasteringCharacter* GetTarget();
 
        virtual void BeginPlay() override;
 
        UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "Targeting")
        class USphereComponent* HearingSphere;
 
        UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "Targeting")
        float HearingRadius = 1000.0f;<br/><br/>protected:<br/>    UFUNCTION()
    void OnHearingOverlap(UPrimitiveComponent* OverlappedComp, AActor* Other, UPrimitiveComponent* OtherComp, int32 OtherBodyIndex, bool bFromSweep, const FHitResult&amp; SweepResult);
 
    UPROPERTY()
    AMasteringCharacter* CurrentTarget = nullptr;
AMeleeAIController::AMeleeAIController(const FObjectInitializer&amp; ObjectInitializer)
        : Super(ObjectInitializer)
{
        HearingSphere = CreateDefaultSubobject&lt;USphereComponent&gt;(TEXT("HearingSphere"));
        HearingSphere-&gt;InitSphereRadius(HearingRadius);
        HearingSphere-&gt;SetCollisionObjectType(ECC_Pawn);
        HearingSphere-&gt;SetCollisionProfileName("Trigger");
 
        HearingSphere-&gt;OnComponentBeginOverlap.AddDynamic(this, &amp;AMeleeAIController::OnHearingOverlap);
 
        bAttachToPawn = true;
}
class AMasteringCharacter* AMeleeAIController::GetTarget()
{
        return CurrentTarget;
}
 
void AMeleeAIController::BeginPlay()
{
        Super::BeginPlay();
 
        HearingSphere-&gt;AttachComponentTo(GetRootComponent(), FAttachmentTransformRules::SnapToTargetNotIncludingScale);
}
 
void AMeleeAIController::OnHearingOverlap(UPrimitiveComponent* OverlappedComp, AActor* Other, UPrimitiveComponent* OtherComp, int32 OtherBodyIndex, bool bFromSweep, const FHitResult&amp; SweepResult)
{
        AMasteringCharacter *Target = Cast&lt;AMasteringCharacter&gt;(Other);
        if (Target != nullptr &amp;&amp; CurrentTarget != Target)
        {
                CurrentTarget = Target;
                OnTargetChange(CurrentTarget);
        }
}</pre>
<p>Now the other advantage to this work is that our blueprint FindTarget service simplifies significantly, so we can call it every <kbd>0.1</kbd> seconds (or every frame, if desired):</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/889dbe94-d5c7-4c69-9ecf-e8b9452ea589.png"/></p>
<p>Now you can see this service is just a pass-through, taking the controller's target, and note that it uses the Nav Agent Location now too as this is much more accurate for navigating too (it typically puts the target location on the same plane as the agent trying to navigate there, so <em>close enough</em> distances are now in 2D rather than a 3D measurement, which is much more intuitive).</p>
<p>While this was all a relatively simple change, setting such a precedent early can be a huge time saver later. Also, note that changing the Hearing Radius value in the CountessController blueprint won't immediately change the value of the hearing sphere in the blueprint, but when a new one is spawned, the constructor will indeed use that new value for the new instance and have the right radius for you. For a quick test in the default level, the one existing countess was moved to the far right and is now only alerted to the player when she's 6 m away.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Attacking the player</h1>
                
            
            
                
<p>This section sounds deceptively simple, but you'll need several missing pieces when you step through the design process:</p>
<ul>
<li>A fleshed out animation blueprint that can switch the enemy's state while moving and attacking</li>
<li>The enemy's ability to be damaged and killed</li>
<li>A decision on how and where attack success is resolved (weapon bounding, a one-frame cone-test in front of the enemy, that is, how realistic does hitting the player need to be?)</li>
</ul>
<p>The second step typically involves a bit more of our UI section's work, and the player should similarly be able to be killed and respawned, but these should be do-able after all the other lessons to this point and won't be covered in depth here. For things such as healthbars to display over the enemy's heads, see the link on 3D widgets in the <em>Further reading</em> section at the end of the chapter. The third step is fairly subjective to game complexity: will this be a player taking on many enemies at once, or NPCs that fight each other, or is it more of a 1-3 enemies at a time versus the player scenario and giving the player the absolute feeling of realism is key?</p>
<p>So, as an incremental check-in for this overall work as the next submission to GitHub, there are several points to notice here to set the stage for our final version: the countess' animation blueprint is now set to have her run while moving, she moves up to an attack radius and will tether back to her start location now if she's dragged away too long without reaching her target, and new modes of sensing have been added for vision and a much-reduced hearing radius for stealth characters:</p>
<pre>void AMeleeAIController::OnHearingOverlap(UPrimitiveComponent* OverlappedComp, AActor* Other, UPrimitiveComponent* OtherComp, int32 OtherBodyIndex, bool bFromSweep, const FHitResult&amp; SweepResult)
{
        AStealthCharacter* StealthChar = Cast&lt;AStealthCharacter&gt;(Other);
        if (StealthChar != nullptr)
        {
                if (StealthChar-&gt;IsStealthed())
                {
                        return; // we let the stealthed sphere deal with these
                }
        }
 
        SetPotentialTarget(Other);
}
 
void AMeleeAIController::OnStealthHearingOverlap(UPrimitiveComponent* OverlappedComp, AActor* Other, UPrimitiveComponent* OtherComp, int32 OtherBodyIndex, bool bFromSweep, const FHitResult&amp; SweepResult)
{
        SetPotentialTarget(Other);
}
 
void AMeleeAIController::OnSightOverlap(UPrimitiveComponent* OverlappedComp, AActor* Other, UPrimitiveComponent* OtherComp, int32 OtherBodyIndex, bool bFromSweep, const FHitResult&amp; SweepResult)
{
        APawn* Owner = GetPawn();
 
        if (Owner == Other)
        {
                return;
        }
 
        FVector ToTarget = Other-&gt;GetActorLocation() - Owner-&gt;GetActorLocation();
        FVector Facing = GetPawn()-&gt;GetActorForwardVector();
 
        if (SightAngle &gt; 90.0f)
        {
                UE_LOG(LogTemp, Error, TEXT("Sight Angles of 90+ degrees not supported, please use hearing for this detection!"));
                SightAngle = 90.0f;
        }
 
        if (FVector::DotProduct(ToTarget, Facing) &lt; 0.0f)
        {
                return;
        }
 
        float DotToTarget = FVector::DotProduct(ToTarget.GetSafeNormal(), Facing.GetSafeNormal());
        float RadiansToTarget = FMath::Acos(DotToTarget);
        float AngToTarget = RadiansToTarget * 180.0f / PI;
 
        if (AngToTarget &lt; SightAngle)
        {
                SetPotentialTarget(Other);
        }
}
 
void AMeleeAIController::SetPotentialTarget(AActor* Other)
{
        AMasteringCharacter* Target = Cast&lt;AMasteringCharacter&gt;(Other);
        if (Target != nullptr &amp;&amp; CurrentTarget != Target)
        {
                CurrentTarget = Target;
                OnTargetChange(CurrentTarget);
        }
}</pre>
<p>One potential improvement could be doing a line-of-sight test to the player too. This is not a hard task, but one that players would expect or might notice as a bug if we didn't add it down the road. Note also this change:</p>
<pre>void AMeleeAIController::BeginPlay()
{
        Super::BeginPlay();
 
        HomeLocation = GetPawn()-&gt;GetNavAgentLocation();
 
    HearingSphere-&gt;AttachToComponent(GetRootComponent(), FAttachmentTransformRules::SnapToTargetNotIncludingScale);
    StealthHearingSphere-&gt;AttachToComponent(GetRootComponent(), FAttachmentTransformRules::SnapToTargetNotIncludingScale);
    SightSphere-&gt;AttachToComponent(GetRootComponent(), FAttachmentTransformRules::SnapToTargetNotIncludingScale);
 
        OnReturnedHome();
}</pre>
<p class="mce-root"/>
<p><kbd>OnReturnedHome</kbd> sets all the radii of the spheres to their set variable lengths, and in the constructor, <kbd>SetReturningHome</kbd> is called, which reduces them all to zero. I noticed during testing that on the first frame of the game, you got a collision with the spheres still at the world origin if you let them perform collision before the <kbd>Attach</kbd> calls in <kbd>BeginPlay</kbd> are made. Those two functions are also used in a new behavior tree task:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b9b7e002-374a-4b24-b6eb-fb10605d21ae.png"/></p>
<p>And there is a very similar new task added for moving to the target so we no longer need to worry about the blueprint or updating it (and can remove the old find task service entirely at this point), as seen in our new tree with the 5-second kiting flow built in:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6404039b-0307-4f74-925e-39635f48b2c3.png" style="width:59.75em;height:50.33em;"/></p>
<p>The easiest way in the default map to test the kiting-timeout is to go get the countless enemy's attention, run to the moving platform previously added, and stay on top of the box after that. Once 5 seconds without reaching the player pass (you can do this too by running from one side of the map to the other if you're careful), you'll see the flow kick over to move to home!</p>
<p>The last pieces needed now are a means of switching the countess into an attack state and dealing damage to the player, even if the results of that damage aren't yet handled. To accomplish this, we need to add a variable to our animation instance and set that variable from a task in the behavior tree. We also need a way to say the countess can attack, which we will make a wait node in the behavior tree. The last thing needed is a quick means of dealing that damage, so we'll add an event to the attack animation she uses and when that fires off, we check whether the player is in front of her, and she'll hit the player if so. </p>
<p>The most straightforward way of synchronizing a C++ class with our desired state is to put an enum in the controller class and have it have a reference to the animation instance and set variables on it. There are drawbacks to this, namely, these update on separate threads. And those updates aren't even deterministic, so you might have a C++ controller update, the animation instance update, the animation instance update again, then the C++ controller again, and vice versa. So if you choose to have C++ logic dictating the animation blueprint's state, beware that there can be up to a 2-frame delay between one desiring a change, and the other recognizing it. If you have logic directly from your animation blueprint updating that state too, make sure to always have one point of update, typically the controller, and it is highly recommended to make this a queue that synchronizes between frames and then proceeds to the next queue entry.</p>
<p>So since our AI is fairly simple, we'll add an Attack boolean variable in its blueprint, then we need a new behavior tree task as before, which looks like this:</p>
<div><img src="img/03da14fa-c381-4127-bd0a-e17c8e1888f2.png"/></div>
<p class="mce-root"/>
<p>Note that it simply sets us into the attack state of our animation blueprint, waits for a short time, and then clears that (so we don't immediately re-enter again when it finishes). And there's an update to the tree that is quite simple, like so:</p>
<div><img src="img/e62e098c-7964-4275-912f-9b755ebb39fb.png"/></div>
<p>The wait after the attack is our cooldown, and so you'll see our countess waits for that time between attacking the player when in range or defers to moving after the player if she's not in range from the move-to-target node.</p>
<p>And, of course, the animation blueprint must reflect these, so again, add an Attack boolean blueprint variable, and make the transitions look like this (we wait for the attack animation to be near the end to go back to idle, and from idle or moving, we enter attack if the behavior tree sets our Attack variable):</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/503ddba8-bed8-4551-a513-641533d2b267.png" style="width:38.25em;height:32.75em;"/></p>
<p>So, the remaining piece to AI attacking is just seeing whether we hit the character. And once again, player death and UI for this are not covered here for brevity but should be fairly trivial after the rest of this work. All we need now is an animation notify event on the attack animation, an event in the animation blueprint that handles this, and a little logic on the controller, all in blueprint here. So, first go to the controller and add this blueprint function:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7d091f61-2df1-4c05-9166-250d88e12d58.png"/></p>
<p>As you can see, this will display to the screen when the player was 1.5 m or closer in front of the countess, was therefore hit, and for how much damage. Again, translating this into gameplay to kill and then respawn the player should be fairly trivial at this point. Next, head to the animation (<kbd>Primary_Attack_A_Normal</kbd> is what is set in the attack node in the animation blueprint) and add this notification by right-clicking in the timeline, clicking Add New Notify at the bottom, and naming it:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e2a9bfcf-c443-43b0-9cc6-5d163ca49256.png"/></p>
<p>Then go to the animation blueprint's event graph and right-click to add an event for that notify:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/be650199-76c4-46ff-a38f-a70e86cca6ba.png" style="width:67.67em;height:46.83em;"/></p>
<p>And thus having our AI chase the player, attack on an interval, run home when kited, and transmit damage has been taken when hit is completed. Congratulations, we have a fully functional AI enemy (with some improvements to add in the next section)! And as usual, these latest changes are all in GitHub, so feel free to examine all of them in detail in the submissions there.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">More polished combat – spawn points, hit reactions, and dying</h1>
                
            
            
                
<p>So now we have an AI that likes to chase down our player and try to hurt them, great. But at this stage, our player can do almost no interaction with that enemy. We'll want to make things a bit more professional by spawning the enemies from a spawn point actor rather than placing them directly in the level (so we can spawn multiple enemies, wait until they are triggered, and so on), have them react when they're shot (which should not interrupt their other activities, but simply layer on top of them with a blended animation), and of course, be able to kill them (and have all of this reflected when loading/saving).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Spawn points for enemy placement</h1>
                
            
            
                
<p>Spawn points are a valuable tool when working with most shooter games. Players in multiplayer games use them when respawning, and AI often rush forth from them in waves or in a fixed number as a challenge for the player. Here, we will make a quick and simple spawn point, drop an instance in the default level, and test that all is well. First, in the AI folder, right-click and make a new blueprint class of the Trigger Box type, here named Countess Spawner.</p>
<p>The logic here is that when the player overlaps the box, an instance of our countess is spawned where we want by using a simple scene component with a billboard attached (which is set to editor only and hidden in game). Then we have a bit of logic to spawn BP_Countess types and keep an array of those that have been spawned, which is updated when they die, and they will only spawn if the array is below a concurrent count variable:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ad8850ea-bd10-485e-adc9-efe1e7f6cadc.png"/></p>
<p>As can be seen in the map, a scaled version of this was placed between some boxes, and its spawn location moved to the corner of the map so that when the player crosses those boxes a countess appears in the corner, but only up to three until one is killed, and then another is allowed. Note that to do this, there are some critical changes to our controller that must be made. First, remove the <kbd>BeginPlay</kbd> function and replace it with <kbd>Possess(APawn* InPawn)</kbd> (keeping the contents the same).</p>
<p>This is because <kbd>BeginPlay</kbd> can (and will) be called potentially before the process of possessing a spawned pawn has occurred. There's also a null check added in <kbd>OnSightOverlap</kbd> for the same reason (the component may be testing hits before the owner pawn is set). Next, in BP_Countess itself, set its AutoPossess property to Placed in World or Spawned so the AI controller actually runs. Note also that there is a specific Spawn AI From Class blueprint node like spawn actor, but it does things slightly differently and since most of our work is done by our controller already, autoprocessing was the best option here.</p>
<p>This should be it for our spawn points. Of course, they can always be made more complex with wave spawning, or random spawn locations, or timers, or whatever logic makes sense and is fun for the game. But the important part is that this can now be reused anywhere to theoretically generate tons of interesting encounters with various AI down the road.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Hit reactions and dying</h1>
                
            
            
                
<p>So far you can shoot our countess as much as you want and nothing interesting happens. We'll fix this with a few code changes to our projectile, and some significant logic we can bundle up in the melee controller. Quickly going through this, we'll add a health parameter to the melee controller like so:</p>
<pre>UPROPERTY(EditAnywhere, BlueprintReadWrite, SaveGame, Category = "Health")
float Health = 100.0f;</pre>
<p>Then modify the projectile's on hit to look like so:</p>
<pre>void AMasteringProjectile::OnHit(UPrimitiveComponent* HitComp, AActor* OtherActor, UPrimitiveComponent* OtherComp, FVector NormalImpulse, const FHitResult&amp; Hit)
{
        // Only add impulse and destroy projectile if we hit a physics
        if ((OtherActor != NULL) &amp;&amp; (OtherActor != this) &amp;&amp; (OtherComp != NULL))
        {
                AController* controller = GetInstigatorController();
                AActor* damager = GetInstigator();
                FDamageEvent DamEvt;
 
                OtherActor-&gt;TakeDamage(DamageAmount, DamEvt, controller, damager != nullptr ? damager : this);
 
                if (OtherComp-&gt;IsSimulatingPhysics())
                {
                        OtherComp-&gt;AddImpulseAtLocation(GetVelocity() * 100.0f, GetActorLocation());
                }
                else if (Cast&lt;APawn&gt;(OtherActor) != nullptr)
                {
                        Destroy();
                }
        }
}</pre>
<p>And in the weapon when we spawn the projectile, add this line:</p>
<pre>ActorSpawnParams.Instigator = Cast&lt;APawn&gt;(GetOwner());</pre>
<p>Then to get our countess to react to the hit and die, we'll need a couple of things in the controller blueprint and animation blueprint. First, let's do the controller:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/baa079bf-42dd-488f-bd59-9b91ea653053.png" style="width:34.75em;height:32.08em;"/></p>
<p>This way, when the pawn is hit and takes damage, the controller is notified, the take damage function (which was created by making the logic, then right-clicking all those logic nodes and selecting Collapse to Function) looks like so:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7d9cf507-346f-4489-8f60-2f0a27db7049.png"/></p>
<p>The Get ABP function just gets our controlled pawn, casts to a BP_Countess, gets its animation instance, and casts that to an ABP_Countess in an Output (return) node. The Hit Reacting (float) and Dying (bool) variables were also simply added directly to the ABP_Countess and used in two ways, as seen here:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c1509ee6-0072-4fd9-b405-35541db728ab.png"/></p>
<p>The HitReact state machine only has one state, and all it does is play the countess' Hit React (fwd) animation. Inserting the APply Additive blend in our root graph with this variable as the weight blends it in. This was built as an additive animation, so you can see at this stage when she takes damage, her head jerks back, but her other animations continue as normal, perfect. Near the end of the animation, a new notification is added, and an event in the event graph for this clears the blend to <kbd>0.0</kbd>.</p>
<p>And dying:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/77b0743a-d045-45c1-9c5d-e5990eedc60f.png"/></p>
<p>Note the one-way transition – there's no coming back from dying. This node in the main graph only plays the countess' Death animation, and near its end has another notify added. In the event graph when that event is triggered, the Try Get Owner Pawn is destroyed. Now, the countess takes damage, reacts, and dies, most of what we hope for out of an AI!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Notes on load/save</h1>
                
            
            
                
<p>Loading and saving the AI, in this case, is not a trivial choice. In this instance, I've moved all of the logic for the most part to the spawner, so saving damaged AI (for example) won't work if they're placed directly in the level anymore. You can reverse this by setting the actor save interface in the BP_Countess, but then, there's no way to properly fix up the spawners to have links to the AI they've spawned.</p>
<p>As a general rule, as done here, if you can have your AI regenerate its state from where it is spawned in the world, you're far better off than trying to save every aspect of exactly where it was at save time. Granted, this can lead to exploits (for example, an AI about to hit with a very powerful attack when saved, then when loaded, is back to idle and starts a normal attack), but as AI complexity grows, load/save complexity can become a nightmare. If at all possible, spawn the AI into the world and let it figure out what it should be doing from there, as is done here with our spawner class.</p>
<p>Our countess spawner adds two new variables, an array of locations, and an array of health values. These are stored on save, and set to SaveGame variables in the spawner's blueprint the way we did for the state of the moving platform earlier, and respawned and restored on load. This does require adding the actor save interface to the spawner (again, like we did for the platform), and marking up those two variables, but also adding a new native event to the saved actor interface:</p>
<pre>UFUNCTION(BlueprintNativeEvent, BlueprintCallable, Category = "Load-Save")
void ActorSaved();</pre>
<p>Then we'd call it when we save, like we do for the load version, currently in the <kbd>MainMenuWidget.cpp's SaveGame</kbd> function around line 82:</p>
<pre>ISavedActorInterface::Execute_ActorSaved(Actor);</pre>
<p>Now in the countess spawner, triggered from these events (after the interface is added in class settings as before), we can add two new functions, one for loading its countesses and one for saving. First, let's look at saving:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f72618f4-9ad5-443c-b3bf-46c89b2b0d76.png"/></p>
<p class="mce-root"/>
<p>And then we have the load event:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d5b9d0e7-db93-42ff-acb0-d343e798200e.png"/></p>
<p>Voila! Our countesses are in the right place, with the right health, but they may not be in the exact step of their AI we saved them at, but they will quickly adjust. One known issue here is that if an AI is saved while it's dying, it will need to be damaged again to start dying again, but with some special work this could be fixed too. But overall, we now have a fully functional AI that chases down the player, hurts the player, can be hurt and react to hits, dies, and be loaded and saved reasonably professionally.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>So this was another whirlwind chapter packed full of many, many changes and a lot of new content. From where we were before, we now have a full functioning enemy who looks great, performs as we might expect in a polished game, and saves with our progress to boot. This is another quantum leap in making a serious game. One last point some may be asking after all of this: doesn't Epic have a built-in senses system for AI? And yes, they do, which you're more than welcome to explore; but in most instances, a custom and debuggable version is typically needed, which we've now made here in solid detail. If the built-in senses and their events are perfect for your project, though, definitely do consider them. But in the overall work-effort of making an AI, making your own sensing code is probably one of the less demanding (and honestly more fun!) portions to write. So, now that we have the core of a solid game going, how do we strategize progressing from level to level or through a large world with a much more significant amount of content than these test levels? Well, that's next!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>What are the three major classes needed to make a proper AI in UE4?</li>
<li>What purpose does the blackboard serve in AI logic?</li>
<li>How was target selection brought from C++ into our behavior tree?</li>
<li>What is the difference between a sequencer and selector in a behavior tree?</li>
<li>How was the behavior tree informed it should attack and stop moving towards the player?</li>
<li>As blueprint logic complexity grows, what's a good trick to compartmentalize sections of logic?</li>
<li>What advantages do AI spawners bring to a game's design?</li>
<li>What are the trade-offs of perfect AI state load/save versus a simple load/save and logic recovering state?</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>Nav-mesh information:</p>
<p><a href="https://docs.unrealengine.com/en-us/Resources/ContentExamples/NavMesh">https://docs.unrealengine.com/en-us/Resources/ContentExamples/NavMesh</a></p>
<p>3D widgets:</p>
<p><a href="https://docs.unrealengine.com/en-us/Engine/UMG/HowTo/InWorldWidgetInteraction">https://docs.unrealengine.com/en-us/Engine/UMG/HowTo/InWorldWidgetInteraction</a></p>


            

            
        
    </body></html>