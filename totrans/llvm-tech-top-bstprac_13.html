<html><head></head><body>
		<div><h1 id="_idParaDest-135"><em class="italic"><a id="_idTextAnchor141"/>Chapter 10</em>: Processing LLVM IR</h1>
			<p>In the previous chapter, we learned about PassManager and AnalysisManager in LLVM. We went through some tutorials for developing an LLVM pass and how to retrieve program analysis data via AnalysisManager. The knowledge and skills we acquired help to build the foundation for developers to create composable building blocks for code transformation and program analysis.</p>
			<p>In this chapter, we are going to focus on the methodology of processing <strong class="bold">LLVM IR</strong>. LLVM IR is a target-independent <strong class="bold">intermediate representation</strong> for program analysis and compiler transformation. You can think of LLVM IR as an <em class="italic">alternative</em> form of the code you want to optimize and compile. However, different from the C/C++ code you're familiar with, LLVM IR describes the program in a different way – we will give you a more concrete idea later. The majority of the <em class="italic">magic</em> that's done by LLVM that makes the input program faster or smaller after the compilation process is performed on LLVM IR. Recall that in the previous chapter, <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager</em>, we described how different passes are organized in a pipeline fashion – that was the high-level structure of how LLVM transforms the input code. In this chapter, we are going to show you the fine-grained details of how to modify LLVM IR in an efficient way.</p>
			<p>Although the most straightforward and visual way to view LLVM IR is by its textual representation, LLVM provides libraries that contain a set of powerful modern C++ APIs to interface with the IR. These APIs can inspect the in-memory representation of LLVM IR and help us manipulate it, which effectively changes the target program we are compiling. These LLVM IR libraries can be embedded in a wide variety of applications, allowing developers to transform and analyze their target source code with ease.</p>
			<p class="callout-heading">LLVM APIs for different programming languages</p>
			<p class="callout">Officially, LLVM only supports APIs for two languages: C and C++. Between them, C++ is the most feature-complete and update to date, but it also has the most <em class="italic">unstable</em> interface – it might be changed at any time without backward compatibility. On the other hand, C APIs have stable interfaces but come at the cost of lagging behind new feature updates, or even keeping certain features absent. The API bindings for OCaml, Go, and Python are in the source tree as community-driven projects.</p>
			<p>We will try to guide you with generally applicable learning blocks driven by commonly seen topics and tasks that are supported by many realistic examples. Here is the list of topics we'll cover in this chapter:</p>
			<ul>
				<li>Learning LLVM IR basics</li>
				<li>Working with values and instructions</li>
				<li>Working with loops</li>
			</ul>
			<p>We will start by introducing LLVM IR. Then, we will learn about two of the most essential elements in LLVM IR – values and instructions. Finally, we'll end this chapter by looking at loops in LLVM – a more advanced topic that is crucial for working on performance-sensitive applications.</p>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor142"/>Technical requirements</h1>
			<p>The tools we'll need in this chapter are the <code>opt</code> command-line utility and <code>clang</code>. Please build them using the following command:</p>
			<pre>$ ninja opt clang</pre>
			<p>Most of the code in this chapter can be implemented inside LLVM pass – and the pass plugin – as introduced in <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager</em>. </p>
			<p>In addition, please install the <strong class="bold">Graphviz</strong> tool. You can consult the following page for an installation guide for your system: <a href="https://graphviz.org/download">https://graphviz.org/download</a>. On Ubuntu, for instance, you can install that package via the following command:</p>
			<pre>$ sudo apt install graphviz</pre>
			<p>We will use a command-line tool – the <code>dot</code> command – provided by Graphviz to visualize the control flow of a function.</p>
			<p>The code example mentioned in this chapter can be implemented inside LLVM pass, if not specified otherwise.</p>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor143"/>Learning LLVM IR basics</h1>
			<p>LLVM IR<a id="_idIndexMarker476"/> is an alternative form of the program you want to optimize and compile. It is, however, structured differently from normal programming languages such as C/C++. LLVM IR is organized in a hierarchical fashion. The levels in this hierarchy – counting from the top – are <strong class="bold">Module</strong>, <strong class="bold">function</strong>, <strong class="bold">basic block</strong>, and <strong class="bold">instruction</strong>. The following diagram shows their structure:</p>
			<div><div><img src="img/B14590_Figure_10.1.jpg" alt="Figure 10.1 – Hierarchy structure of LLVM IR&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Hierarchy structure of LLVM IR</p>
			<p>A <strong class="bold">module</strong> represents <a id="_idIndexMarker477"/>a translation unit – usually a source file. Each module can contain<a id="_idIndexMarker478"/> multiple <strong class="bold">functions</strong> (or global variables). Each contains a <a id="_idIndexMarker479"/>list of <strong class="bold">basic blocks</strong> where each of the basic blocks contains a <a id="_idIndexMarker480"/>list of <strong class="bold">instructions</strong>.</p>
			<p class="callout-heading">Quick refresher – basic block</p>
			<p class="callout">A <a id="_idIndexMarker481"/>basic block represents a list of instructions with only one entry and one exit point. In other words, if a basic block is executed, the control flow is guaranteed to walk through every instruction in the block.</p>
			<p>Knowing the high-level structure of LLVM IR, let's look at one of the LLVM IR examples. Let's say we have the following C code, <code>foo.c</code>:</p>
			<pre>int foo(int a, int b) {
  return a &gt; 0? a – b : a + b;
}</pre>
			<p>We can <a id="_idIndexMarker482"/>use the following <code>clang</code> command to generate its <em class="italic">textual</em> LLVM IR counterpart:</p>
			<pre>$ clang -emit-llvm -S foo.c</pre>
			<p>The result will be put in the <code>foo.ll</code> file. The following diagram shows part of its content, with annotations for the corresponding IR unit:</p>
			<div><div><img src="img/B14590_Figure_10.2.jpg" alt="Figure 10.2 – Part of the content in foo.ll, annotated with the corresponding IR unit&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Part of the content in foo.ll, annotated with the corresponding IR unit</p>
			<p>In textual form, an instruction is usually presented in the following format:</p>
			<pre>&lt;result&gt; = &lt;operator / op-code&gt; &lt;type&gt;, [operand1, operand2, …]</pre>
			<p>For instance, let's assume we have the following instruction:</p>
			<pre>%12 = load i32, i32* %3</pre>
			<p>Here, <code>%12</code> is the result value, <code>load</code> is the op-code, <code>i32</code> is the data type of this instruction, and <code>%3</code> is the only operand.</p>
			<p>In <a id="_idIndexMarker483"/>addition to the textual representation, nearly every component in LLVM IR has a C++ class counterpart with the same name. For instance, a function and a basic block are simply represented by <code>Function</code> and the <code>BasicBlock</code> C++ class, respectively. </p>
			<p>Different kinds of instructions are represented by classes that are all derived from the <code>Instruction</code> class. For example, the <code>BinaryOperator</code> class represents a binary operation instruction, while <code>ReturnInst</code> class represents a return statement. We will look at <code>Instruction</code> and its child classes in more detail later.</p>
			<p>The hierarchy<a id="_idIndexMarker484"/> depicted in <em class="italic">Figure 10.1</em> is the <strong class="bold">concrete</strong> structure of LLVM IR. That is, this is how they are stored in memory. On top of that, LLVM also provides other <em class="italic">logical</em> structures to view the relationships of different IR units. They are usually evaluated from the concrete structures and stored as auxiliary data structures or treated as analysis results. Here are some of the most important ones in LLVM:</p>
			<ul>
				<li><strong class="bold">Control Flow Graph</strong> (<strong class="bold">CFG</strong>): This<a id="_idIndexMarker485"/> is a graph structure that's organized into basic blocks to show their control flow relations. The vertices in this graph represent basic blocks, while the edges represent a single control flow transfer.</li>
				<li><strong class="bold">Loop</strong>: This represents the loop<a id="_idIndexMarker486"/> we are familiar with, which consists of multiple basic blocks that have at least one back edge – a control flow edge that goes back to its parent or ancestor vertices. We will look at this in more detail in the last section of this chapter, the <em class="italic">Working with loops</em> section.</li>
				<li><strong class="bold">Call graph</strong>: Similar to CFG, the call graph<a id="_idIndexMarker487"/> also shows control flow transfers, but the vertices become individual functions and the edges become function call relations.</li>
			</ul>
			<p>In the next section, we are going to learn how to iterate through different IR units in both concrete and logical structures.</p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor144"/>Iterating different IR units</h2>
			<p>Iterating <a id="_idIndexMarker488"/>IR units – such as basic blocks or instructions – are <em class="italic">essential</em> to LLVM IR development. It is usually one of the first steps we must complete in many transformation or analysis algorithms – scanning through the whole code and finding an interesting area in order to apply certain measurements. In this section, we are going to learn about the practical aspects of iterating different IR units. We will cover the following topics:</p>
			<ul>
				<li>Iterating instructions</li>
				<li>Iterating basic blocks</li>
				<li>Iterating the call graph</li>
				<li>Learning the GraphTraits</li>
			</ul>
			<p>Let's start by discussing how to iterate instructions.</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor145"/>Iterating instructions</h2>
			<p>An instruction is <a id="_idIndexMarker489"/>one of the most basic elements in LLVM IR. It usually represents a single action in the program, such as an arithmetic operation or a function call. Walking through all the instructions in a single basic block or function is the cornerstone of most program analyses and compiler optimizations. </p>
			<p>To iterate through all the instructions in a basic block, you just need to use a simple for-each loop over the block:</p>
			<pre>// `BB` has the type of `BasicBlock&amp;`
<strong class="bold">for (Instruction &amp;I : BB)</strong> {
  // Work on `I`
}</pre>
			<p>We can iterate through all the instructions in a function in two ways. First, we can iterate over all the basic blocks in the function before visiting the instructions. Here is an example:</p>
			<pre>// `F` has the type of `Function&amp;`
<strong class="bold">for (BasicBlock &amp;BB : F) {</strong>
  <strong class="bold">for (Instruction &amp;I : BB) {</strong>
    // Work on `I`
  }
}</pre>
			<p>Second, you can leverage a utility called <code>inst_iterator</code>. Here is an example:</p>
			<pre><strong class="bold">#include "llvm/IR/InstIterator.h"</strong>
…
// `F` has the type of `Function&amp;`
<strong class="bold">for (Instruction &amp;I : instructions(F))</strong> {
  // Work on `I`
}</pre>
			<p>Using the <a id="_idIndexMarker490"/>preceding code, you can retrieve all the instructions in this function.</p>
			<h3>Instruction visitor</h3>
			<p>There are many cases where<a id="_idIndexMarker491"/> we want to apply different treatments to different types of instructions in a basic block or function. For example, let's assume we have the following code:</p>
			<pre>for (Instruction &amp;I : instructions(F)) {
  switch (<strong class="bold">I.getOpcode()</strong>) {
  <strong class="bold">case Instruction::BinaryOperator</strong>:
  // this instruction is a binary operator like `add` or `sub`
    break;
  <strong class="bold">case Instruction::Return</strong>:
    // this is a return instruction
    break;
  …
  }
}</pre>
			<p>Recall that different <a id="_idIndexMarker492"/>kinds of instructions are modeled by (different) classes derived from <code>Instruction</code>. Therefore, an <code>Instruction</code> instance can represent any of them. The <code>getOpcode</code> method shown in the preceding snippet can give you a unique token – namely, <code>Instruction::BinaryOperator</code> and <code>Instruction::Return</code> in the given code – that tells you about the underlying class. However, if we want to work on the derived class ( <code>ReturnInst</code>, in this case) instance rather than the "raw" <code>Instruction</code>, we need to do some type casting.</p>
			<p>LLVM provides a <a id="_idIndexMarker493"/>better way to implement this kind of visiting pattern –<code>InstVisitor</code>. <code>InstVisitor</code> is a class where each of its member methods is a callback function for a specific instruction type. You can define your own callbacks after inheriting from the <code>InstVisitor</code> class. For instance, check out the following code snippet:</p>
			<pre>#include "llvm/IR/InstVisitor.h"
class MyInstVisitor : public <strong class="bold">InstVisitor&lt;MyInstVisitor&gt;</strong> {
  <strong class="bold">void visitBinaryOperator(BinaryOperator &amp;BOp)</strong> {
    // Work on binary operator instruction
    …
  }
  <strong class="bold">void visitReturnInst(ReturnInst &amp;RI)</strong> {
    // Work on return instruction
    …
  }
};</pre>
			<p>Each <code>visitXXX</code> method shown here is a callback function for a specific instruction type. Note that we are <em class="italic">not</em> overriding each of these methods (there was no <code>override</code> keyword attached to the method). Also, instead of defining callbacks for all the instruction types, <code>InstVisitor</code> allows you to only define those that we are interested in.</p>
			<p>Once <code>MyInstVisitor</code> has been<a id="_idIndexMarker494"/> defined, we can simply create an instance of it and invoke the <code>visit</code> method to launch the visiting process. Let's take the following code as an example:</p>
			<pre>// `F` has the type of `Function&amp;`
MyInstVisitor Visitor;
Visitor.<strong class="bold">visit(F)</strong>;</pre>
			<p>There<a id="_idIndexMarker495"/> are also <code>visit</code> methods for <code>Instruction</code>, <code>BasicBlock</code>, and <code>Module</code>.</p>
			<p class="callout-heading">Ordering basic blocks and instructions</p>
			<p class="callout">All the skills we've introduced in this section assume<a id="_idIndexMarker496"/> that the <code>Function</code> doesn't store or iterate its enclosing <code>BasicBlock</code> instances in a particular <em class="italic">linear</em> order. We will show you how to iterate through all the basic blocks in various meaningful orders shortly.</p>
			<p>With that, you've learned several ways to iterate instructions from a basic block or a function. Now, let's learn how to iterate basic blocks in a function.</p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor146"/>Iterating basic blocks</h2>
			<p>In the <a id="_idIndexMarker497"/>previous section, we learned how to iterate basic blocks of a function using a simple for loop. However, developers can only receive basic blocks in an <em class="italic">arbitrary</em> order in this way – that ordering gave you neither the execution order nor the control flow information among the blocks. In this section, we will show you how to iterate basic blocks in a more meaningful way.</p>
			<p>Basic blocks are important elements for expressing the control flow of a function, which can be represented by a directed graph – namely, the <code>opt</code> tool. Assuming you have an LLVM IR file, <code>foo.ll</code>, you can use the following command to print out the CFG of each function in Graphviz format:</p>
			<pre>$ opt <strong class="bold">-dot-cfg</strong> -disable-output foo.ll</pre>
			<p>This command will generate one <code>.dot</code> file for each function in <code>foo.ll</code>. </p>
			<p class="callout-heading">The .dot File might be hidden</p>
			<p class="callout">The filename of the CFG <code>.dot</code> file for each function usually starts with a dot character (<code>'.'</code>). On Linux/Unix systems, this effectively <em class="italic">hides</em> the file from the normal <code>ls</code> command. So, use the <code>ls -a</code> command to show those files instead.</p>
			<p>Each <code>.dot</code> file contains the Graphviz representation of that function's CFG. Graphviz is a general and<a id="_idIndexMarker499"/> textual format for expressing graphs. People usually convert a <code>.dot</code> file into other (image) formats before studying it. For instance, using the following command, you can convert a <code>.dot</code> file into a PNG image file that visually shows the graph:</p>
			<pre>$ dot -Tpng foo.cfg.dot &gt; foo.cfg.png</pre>
			<p>The following diagram shows two examples:</p>
			<div><div><img src="img/B14590_Figure_10.3.jpg" alt="Figure 10.3 – Left: CFG for a function containing branches; right: CFG for a function containing a loop&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Left: CFG for a function containing branches; right: CFG for a function containing a loop</p>
			<p>The left-hand side of the preceding diagram shows a CFG for a function containing several branches; the right-hand side shows a CFG for a function containing a single loop.</p>
			<p>Now, we <a id="_idIndexMarker500"/>know that basic blocks are organized as a directed graph – namely, the CFG. Can we iterate this CFG so that it follows the edges and nodes? LLVM answers this question by providing utilities for iterating a graph in four different ways: topological order, depth first (essentially doing <strong class="bold">DFS</strong>), breadth first (essentially doing <strong class="bold">BFS</strong>), and <strong class="bold">Strongly Connected Components</strong> (<strong class="bold">SCCs</strong>). We are going to learn how to use each of<a id="_idIndexMarker501"/> these utilities in the following subsections.</p>
			<p>Let's start with topological order traversal.</p>
			<h3>Topological order traversal</h3>
			<p>Topological ordering is <a id="_idIndexMarker502"/>a simple linear ordering that guarantees that for each node in the graph, it will only be visited after we've visited all of its parent (predecessor) nodes. LLVM provides <code>po_iterator</code> and some other utility functions to implement <em class="italic">reversed</em> topological ordering (reversed topological ordering is easier to implement) on the CFG. The following snippet gives an example of using <code>po_iterator</code>:</p>
			<pre>#include "llvm/ADT/PostOrderIterator.h"
#include "llvm/IR/CFG.h"
// `F` has the type of `<strong class="bold">Function*</strong>`
for (<strong class="bold">BasicBlock</strong> *BB : <strong class="bold">post_order(F)</strong>) {
  BB-&gt;printAsOperand(errs());
  errs() &lt;&lt; "\n";
}</pre>
			<p>The <code>post_order</code> function is just a helper function to create an iteration range of <code>po_iterator</code>. Note that the <code>llvm/IR/CFG.h</code> header is necessary to make <code>po_iterator</code> work on <code>Function</code> and <code>BasicBlock</code>.</p>
			<p>If we apply the preceding code to the function containing branches in the preceding diagram, we'll get the following command-line output:</p>
			<pre>label %12
label %9
label %5
label %7
label %3
label %10
label %1</pre>
			<p>Alternatively, you can traverse from a specific basic block using nearly the same syntax; for instance:</p>
			<pre>// `F` has the type of `<strong class="bold">Function*</strong>`
<strong class="bold">BasicBlock &amp;EntryBB</strong> = F-&gt;getEntryBlock();
for (<strong class="bold">BasicBlock</strong> *BB : <strong class="bold">post_order(&amp;EntryBB)</strong>) {
  BB-&gt;printAsOperand(errs());
  errs() &lt;&lt; "\n";
}</pre>
			<p>The preceding<a id="_idIndexMarker503"/> snippet will give you the same result as the previous one since it's traveling from the entry block. You're free to traverse from the arbitrary block, though.</p>
			<h3>Depth-first and breadth-first traversal</h3>
			<p><strong class="bold">DFS</strong> and <strong class="bold">BFS</strong> are two of the <a id="_idIndexMarker504"/>most famous and iconic algorithms for visiting <a id="_idIndexMarker505"/>topological structures such as a graph or a tree. For each node in a tree or a graph, DFS will always try to visit its child nodes before visiting other nodes that share the same parents (that is, the <em class="italic">sibling</em> nodes). On the other hand, BFS will traverse all the sibling nodes before moving to its child nodes.</p>
			<p>LLVM provides <code>df_iterator</code> and <code>bf_iterator</code> (and some other utility functions) to implement depth-first and breadth-first ordering, respectively. Since their usages are nearly identical, we are only going to demonstrate <code>df_iterator</code> here:</p>
			<pre>#include "llvm/ADT/DepthFirstIterator.h"
#include "llvm/IR/CFG.h"
// `F` has the type of `<strong class="bold">Function*</strong>`
for (<strong class="bold">BasicBlock</strong> *BB : <strong class="bold">depth_first(F)</strong>) {
  BB-&gt;printAsOperand(errs());
  errs() &lt;&lt; "\n";
}</pre>
			<p>Similar to <code>po_iterator</code> and <code>post_order</code>, <code>depth_first</code> is just a utility function for creating an iteration range of <code>df_iterator</code>. To use <code>bf_iterator</code>, simply replace <code>depth_first</code> with <code>breadth_first</code>. If you apply the preceding code to the containing branches in the preceding diagram, it will give you the following command-line output:</p>
			<pre>label %1
label %3
label %5
label %9
label %12
label %7
label %10</pre>
			<p>When <a id="_idIndexMarker506"/>using <code>bf_iterator</code>/<code>breadth_first</code>, we will get the following command-line output for the same example:</p>
			<pre>label %1
label %3
label %10
label %5
label %7
label %12
label %9</pre>
			<p><code>df_iterator</code> and <code>bf_iterator</code> can also<a id="_idIndexMarker507"/> be used with <code>BasicBlock</code>, in the same way as <code>po_iterator</code> shown previously.</p>
			<h3>SSC traversal</h3>
			<p>An <strong class="bold">SCC</strong> represents a subgraph where every enclosing node can be reached <a id="_idIndexMarker508"/>from every other node. In the context of CFG, it is useful to traverse CFG with loops.</p>
			<p>The basic block traversal methods we introduced earlier are useful tools to reason about the control flow in a function. For a loop-free function, these methods give you a linear view that closely reflects the execution orders of enclosing basic blocks. However, for a function that contains loops, these (linear) traversal methods cannot show the cyclic execution flow that's created by the loops.</p>
			<p class="callout-heading">Recurring control flow</p>
			<p class="callout">Loops are not the only programming constructs that create recurring control flows within a function. A few other directives – the <code>goto</code> syntax in C/C++, for example – will also introduce a recurring control flow. However, those corner cases will make analyzing the control flow more difficult (which is one of the reasons you shouldn't use <code>goto</code> in your code), so when we are talking about recurring control flows, we are only referring to loops.</p>
			<p>Using <code>scc_iterator</code> in LLVM, we can traverse strongly connected basic blocks in a CFG. With this information, we can quickly spot a recurring control flow, which is crucial for some analysis and program transformation tasks. For example, we need to know the back edges and recurring basic blocks in order to accurately propagate the branch probability data along the control flow edges. </p>
			<p>Here is an example of using <code>scc_iterator</code>:</p>
			<pre>#include "<strong class="bold">llvm/ADT/SCCIterator.h</strong>"
#include "llvm/IR/CFG.h"
// `F` has the type of `Function*`
for (auto SCCI = <strong class="bold">scc_begin</strong>(&amp;F); !SCCI.<strong class="bold">isAtEnd</strong>(); ++SCCI) {
  <strong class="bold">const std::vector&lt;BasicBlock*&gt; &amp;SCC</strong> = *SCCI;
  for (auto *BB : SCC) {
    BB-&gt;printAsOperand(errs());
    errs() &lt;&lt; "\n";
  }
  errs() &lt;&lt; "====\n";
}</pre>
			<p>Different from the previous traversal methods, <code>scc_iterator</code> doesn't provide a handy range-style iteration. Instead, you need to create a <code>scc_iterator</code> instance using <code>scc_begin</code> and do manual increments. More importantly, you should use the <code>isAtEnd</code> method to check the exit condition, rather than doing a comparison with the "end" iterator like we usually do with C++ STL containers. A vector of <code>BasicBlock</code> can be dereferenced from a single <code>scc_iterator</code>. These <code>BasicBlock</code> instances are the basic blocks within a<a id="_idIndexMarker509"/> SCC. The ordering among these SCC instances is roughly the same as in the reversed topological order – namely, the post ordering we saw earlier.</p>
			<p>If you run the preceding code over the function that contains a loop in the preceding diagram, it gives you the following command-line output:</p>
			<pre>label %6
====
label %4
label %2
====
label %1
====</pre>
			<p>This shows that basic blocks <code>%4</code> and <code>%2</code> are in the same SCC.</p>
			<p>With that, you've learned how to iterate basic blocks within a function in different ways. In the next section, we are going to learn how to iterate functions within a module by following the call graph.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor147"/>Iterating the call graph</h2>
			<p>A call<a id="_idIndexMarker510"/> graph is a direct graph that represents the function call relationships in a module. It plays an important role in <strong class="bold">inter-procedural</strong> code transformation and analysis, namely, analyzing or optimizing code across multiple functions. A famous optimization <a id="_idIndexMarker511"/>called <strong class="bold">function inlining</strong> is an example of this.</p>
			<p>Before we dive<a id="_idIndexMarker512"/> into the details of iterating nodes in the call graph, let's take a look at how to build a call graph. LLVM uses the <code>CallGraph</code> class to represent the call graph of a single <code>Module</code>. The following sample code uses a pass module to build a <code>CallGraph</code>:</p>
			<pre>#include "llvm/Analysis/CallGraph.h"
struct SimpleIPO : public PassInfoMixin&lt;SimpleIPO&gt; {
  PreservedAnalyses run(Module &amp;M, ModuleAnalysisManager &amp;MAM) {
    <strong class="bold">CallGraph CG(M);</strong>
    for (auto &amp;Node : CG) {
      // Print function name
      if (Node.first)
        errs() &lt;&lt; Node.first-&gt;getName() &lt;&lt; "\n";
    }
    return PreservedAnalysis::all();
  }
};</pre>
			<p>This snippet built a <code>CallGraph</code> instance before iterating through all the enclosing functions and printing their names.</p>
			<p>Just like <code>Module</code> and <code>Function</code>, <code>CallGraph</code> only provides the most basic way to enumerate all its enclosing components. So, how do we traverse <code>CallGraph</code> in different ways – for instance, by using SCC – as we saw in the previous section? The answer to this is surprisingly simple: in the exact <em class="italic">same</em> way – using the same set of APIs and the same usages.</p>
			<p>The secret behind this is a thing called <code>GraphTraits</code>.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor148"/>Learning about GraphTraits</h2>
			<p><code>GraphTraits</code> is a<a id="_idIndexMarker513"/> class designed to provide an abstract interface over various different graphs in LLVM – CFG and call graph, to name a few. It allows other LLVM components – analyses, transformations, or iterator utilities, as we saw in the previous section – to build their works <em class="italic">independently</em> of the underlying graphs. Instead of asking every graph in LLVM to inherit from <code>GraphTraits</code> and implement the required <a id="_idIndexMarker514"/>functions, <code>GraphTraits</code> takes quite a different approach by using <strong class="bold">template specialization</strong>.</p>
			<p>Let's say that you have written a simple C++ class that has a template argument that accepts arbitrary types, as shown here:</p>
			<pre>template &lt;typename T&gt;
struct Distance {
  static T compute(T &amp;PointA, T &amp;PointB) {
    return PointA – PointB;
  }
};</pre>
			<p>This C++ class will compute the distance between two points upon calling the <code>Distance::compute</code> method. The types of those points are parameterized by the <code>T</code> template argument.</p>
			<p>If <code>T</code> is a numeric type such as <code>int</code> or <code>float</code>, everything will be fine. However, if <code>T</code> is a struct of a class, like the one here, then the default <code>compute</code> method implementation will not be able to compile:</p>
			<pre>Distance&lt;<strong class="bold">int</strong>&gt;::compute(94, 87); // Success
…
struct SimplePoint {
  float X, Y;
};
SimplePoint A, B;
Distance&lt;<strong class="bold">SimplePoint</strong>&gt;::compute(A, B); // Compilation Error</pre>
			<p>To solve this issue, you can either implement a subtract operator for <code>SimplePoint</code>, or you can use template specialization, as shown here:</p>
			<pre>// After the original declaration of struct Distance…
template&lt;&gt;
struct <strong class="bold">Distance&lt;SimplePoint&gt;</strong> {
  <strong class="bold">SimplePoint compute(SimplePoint &amp;A, SimplePoint &amp;B)</strong> {
    return std::sqrt(std::pow(A.X – B.X, 2),…);
  }
};
…
SimplePoint A, B;
<strong class="bold">Distance&lt;SimplePoint&gt;</strong>::compute(A, B); // Success</pre>
			<p><code>Distance&lt;SimplePoint&gt;</code> in the<a id="_idIndexMarker515"/> previous code describes what <code>Distance&lt;T&gt;</code> looks like when <code>T</code> is equal to <code>SimplePoint</code>. You can think of the original <code>Distance&lt;T&gt;</code> as some kind of <code>Distance&lt;SimplePoint&gt;</code> being one of its <code>compute</code> method in <code>Distance&lt;SimplePoint&gt;</code> is <em class="italic">not</em> an override method of the original <code>compute</code> in <code>Distance&lt;T&gt;</code>. This is different from normal class inheritance (and virtual methods).</p>
			<p><code>GraphTraits</code> in LLVM is a template class that provides an interface for various graph algorithms, such as <code>df_iterator</code> and <code>scc_iterator</code>, as we saw previously. Every graph in LLVM will <em class="italic">implement</em> this interface via template specialization. For instance, the following <code>GraphTraits</code> specialization is used for modeling the <strong class="bold">CFG</strong> of a function:</p>
			<pre>template&lt;&gt;
struct <strong class="bold">GraphTraits&lt;Function*&gt;</strong> {…}</pre>
			<p>Inside the body of <code>GraphTraits&lt;Function*&gt;</code>, there are several (static) methods and <code>typedef</code> statements that implement the required interface. For example, <code>nodes_iterator</code> is the type that's used for iterating over all the vertices in CFG, while <code>nodes_begin</code> provides you with the entry/starting node of this CFG:</p>
			<pre>template&lt;&gt;
struct GraphTraits&lt;Function*&gt; {
  typedef pointer_iterator&lt;Function::iterator&gt; <strong class="bold">nodes_iterator</strong>;
  static node_iterator <strong class="bold">nodes_begin</strong>(Function *F) {
    return nodes_iterator(F-&gt;begin());
  }
  …
};</pre>
			<p>In this case, <code>nodes_iterator</code> is basically <code>Function::iterator</code>. <code>nodes_begin</code> simply returns the first basic block in the function (via an iterator). If we look at <code>GraphTraits</code> for <code>CallGraph</code>, it has completely different implementations of <code>nodes_iterator</code> and <code>nodes_begin</code>:</p>
			<pre>template&lt;&gt;
struct GraphTraits&lt;CallGraph*&gt; {
  typedef <strong class="bold">mapped_iterator&lt;CallGraph::iterator,</strong> 
  <strong class="bold">decltype(&amp;CGGetValuePtr)&gt;</strong> nodes_iterator;
  static node_iterator nodes_begin(CallGraph *CG) {
    <strong class="bold">return nodes_iterator(CG-&gt;begin(), &amp;CGGetValuePtr);</strong>
  }
};</pre>
			<p>When developers are<a id="_idIndexMarker516"/> implementing a new graph algorithm, instead of hardcoding it for each kind of graph in LLVM, they can build their algorithms by using <code>GraphTraits</code> as an interface to access the key properties of arbitrary graphs.</p>
			<p>For example, let's say we want to create a new graph algorithm, <code>find_tail</code>, which finds the first node in the graph that has no child nodes. Here is the skeleton of <code>find_tail</code>:</p>
			<pre>template&lt;class GraphTy,
         <strong class="bold">typename GT = GraphTraits&lt;GraphTy&gt;</strong>&gt;
  auto find_tail(GraphTy G) {
  for(auto NI = <strong class="bold">GT::nodes_begin</strong>(G); NI != <strong class="bold">GT::nodes_end</strong>(G);    ++NI) {
    // A node in this graph
    auto Node = *NI;
    // Child iterator for this particular node
    auto ChildIt = <strong class="bold">GT::child_begin</strong>(Node);
    auto ChildItEnd = <strong class="bold">GT::child_end</strong>(Node);
    if (ChildIt == ChildItEnd)
      // No child nodes
      return Node;
  }
  …
}</pre>
			<p>With the help of this<a id="_idIndexMarker517"/> template and <code>GraphTraits</code>, we can <em class="italic">reuse</em> this function on <code>Function</code>, <code>CallGraph</code>, or any kind of graph in LLVM; for instance:</p>
			<pre>// `F` has the type of `<strong class="bold">Function</strong>*`
<strong class="bold">BasicBlock</strong> *TailBB = find_tail(F);
// `CG` has the type of `<strong class="bold">CallGraph</strong>*`
<strong class="bold">CallGraphNode</strong> *TailCGN = find_tail(CG);</pre>
			<p>In short, <code>GraphTraits</code> generalizes algorithms – such as <code>df_iterator</code> and <code>scc_iterator</code>, as we saw previously – in LLVM to <em class="italic">arbitrary</em> graphs using the template specialization technique. This is a clean and efficient way to define interfaces for reusable components.</p>
			<p>In this section, we learned the hierarchy structure of LLVM IR and how to iterate different IR units – either concrete or logical units, such as CFGs. We also learned the important role of <code>GraphTraits</code> for encapsulating different graphs – CFGs and call graphs, to name a few – and exposed a common interface to various algorithms in LLVM, thus making those algorithms more concise and reusable.</p>
			<p>In the next section, we will learn about how values are represented in LLVM, which describes a picture of how different LLVM IR components are associated with each other. In addition, we will learn about the correct and efficient way to manipulate and update values in LLVM.</p>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor149"/>Working with values and instructions</h1>
			<p>In LLVM, a <strong class="bold">value</strong> is a<a id="_idIndexMarker518"/> unique construct – not only does it represent values stored in variables, but it also models a wide range of concepts from constants, global variables, individual instructions, and even basic blocks. In other words, it is one of the <em class="italic">foundations</em> of LLVM IR. </p>
			<p>The concept of value is<a id="_idIndexMarker519"/> especially important for instructions as it directly interacts with values in the IR. Therefore, in this section, we will put them into the same discussion. We are going to see how values work in LLVM IR and how values are associated with instructions. On top of that, we are going to learn how to create and insert new instructions, as well as how to update them. </p>
			<p>To learn how to use values in LLVM IR, we must understand the important theory behind this system, which dictates the behavior and the format of LLVM instructions – the <strong class="bold">Single Static Assignment</strong> (<strong class="bold">SSA</strong>) form.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor150"/>Understanding SSA</h2>
			<p>SSA is a way of <a id="_idIndexMarker520"/>structuring and designing IR to make program analysis and compiler transformation easier to perform. In SSA, a variable (in the IR) will only be assigned a value exactly <em class="italic">once</em>. This means that we cannot manipulate a variable like this:</p>
			<pre>// the following code is NOT in SSA form
x = 94;
x = 87; // `x` is assigned the second time, not SSA!</pre>
			<p>Although a variable can only be assigned once, it can be <em class="italic">used</em> multiple times in arbitrary instructions. For instance, check out the following code:</p>
			<pre>x = 94;
y = x + 4; // first time `x` is used
z = x + 2; // second time `x` is used</pre>
			<p>You might be wondering how normal C/C++ code – which is clearly not in SSA form – gets transformed into an SSA form of IR, such as LLVM. While there is a whole class of different <a id="_idIndexMarker521"/>algorithms and research papers that answer this question, which we are not going to cover here, most of the simple C/C++ code can be transformed using trivial techniques such as renaming. For instance, let's say we have the following (non-SSA) C code:</p>
			<pre>x = 94;
x = x * y; // `x` is assigned more than once, not SSA!
x = x + 5;</pre>
			<p>Here, we can rename <code>x</code> in the first assignment with something like <code>x0</code> and <code>x</code> on the left-hand side of the second and third assignments with alternative names such as <code>x1</code> and <code>x2</code>, respectively:</p>
			<pre>x0 = 94;
x1 = x0 * y;
x2 = x1 + 5;</pre>
			<p>With these simple measurements, we can obtain the SSA form of our original code with the same behavior.</p>
			<p>To have a more comprehensive understanding of SSA, we must change our way of thinking about what <a id="_idIndexMarker522"/>instructions <em class="italic">look like</em> in a program. In <code>x</code>" where the second line means "do some multiplication using <code>x</code> and <code>y</code> before storing the result in the <code>x</code> variable":</p>
			<div><div><img src="img/B14590_Figure_10.4.jpg" alt="Figure 10.4 – Thinking instructions as &quot;actions&quot;&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Thinking instructions as "actions"</p>
			<p>These interpretations <a id="_idIndexMarker523"/>sound intuitive. However, things get tricky when we make some <em class="italic">transformations</em> – which is, of course, a common thing in a compiler – on these instructions. In the preceding diagram, on the right-hand side, when the first instruction becomes <code>x = 87</code>, we don't know if this modification <code>x</code> variable on the right-hand side of <code>x</code>. Here, we have no choice but to list all the instructions that have <code>x</code> on their left-hand side (that is, using <code>x</code> as the destination), which is pretty inefficient.</p>
			<p>Instead of looking at the <em class="italic">action</em> aspect of an instruction, we can focus on the <em class="italic">data</em> that's generated by an instruction and get a clear picture of the provenance of each instruction – that is, the region that can be reached by its resulting value. Furthermore, we can easily find out the origins of arbitrary variables/values. The following diagram illustrates this advantage:</p>
			<div><div><img src="img/B14590_Figure_10.5.jpg" alt="Figure 10.5 – SSA highlighting the dataflow among instructions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – SSA highlighting the dataflow among instructions</p>
			<p>In other words, SSA <a id="_idIndexMarker524"/>highlights the <strong class="bold">dataflow</strong> in a program so that the compiler will have an easier time tracking, analyzing, and modify the instructions.</p>
			<p>Instructions in LLVM are organized in SSA form. This means we are more interested in the value, or the data flow generated by an instruction, rather than which variable it stores the result in. Since each instruction in LLVM IR can only produce a single result value, an <code>Instruction</code> object – recall that <code>Instruction</code> is the C++ class that represents an instruction in LLVM IR – also represents its <code>Value</code>. <code>Instruction</code> is one of its child classes. This means that given an <code>Instruction</code> object, we can, of course, cast it to a <code>Value</code> object. That particular <code>Value</code> object is effectively the result of that <code>Instruction</code>:</p>
			<pre>// let's say `I` represents an instruction `<strong class="bold">x = a + b</strong>`
Instruction *I = …;
Value *V = I; // `V` effectively represents the value `<strong class="bold">x</strong>`</pre>
			<p>This is one of the most important things to know in order to work with LLVM IR, especially to use most of its APIs.</p>
			<p>While the <code>Instruction</code> object represents its own result value, it also has <em class="italic">operands</em> that are served as inputs to the instruction. Guess what? We are also using <code>Value</code> objects as operands. For example, let's assume we have the following code:</p>
			<pre>Instruction *<strong class="bold">BinI</strong> = BinaryOperator::Create(Instruction::Add,…);
Instruction *RetI = ReturnInst::Create(…, <strong class="bold">BinI</strong>, …);</pre>
			<p>The preceding snippet is basically creating an arithmetic addition instruction (represented by <code>BinaryOperator</code>), whose <em class="italic">result</em> value will be the <em class="italic">operand</em> of another return instruction. The resulting IR is equivalent to the following C/C++ code:</p>
			<pre><strong class="bold">x</strong> = a + b;
return <strong class="bold">x</strong>;</pre>
			<p>In addition to <code>Instruction</code>, <code>Constant</code> (the C++ class for different kinds of constant values), <code>GlobalVariable</code> (the C++ class for global variables), and <code>BasicBlock</code> are all subclasses of <code>Value</code>. This means that they're also organized in SSA form and that you can use them as the operands for an <code>Instruction</code>.</p>
			<p>Now, you know what SSA is and learned what impact it has on the design of LLVM IR. In the next section, we are going to discuss how to modify and update values in LLVM IR.</p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor151"/>Working with values</h2>
			<p>SSA makes<a id="_idIndexMarker525"/> us focus on the <em class="italic">data flow</em> among instructions. Since we have a clear view of how values go from one instruction to the other, it's easy to replace the usage of certain values in an instruction. But how is the concept of "value usage" represented in LLVM? The following diagram shows two important C++ classes that answer this question – <code>User</code> and <code>Use</code>:</p>
			<div><div><img src="img/B14590_Figure_10.6.jpg" alt="Figure 10.6 – The relationship between Value, User, and Use&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – The relationship between Value, User, and Use</p>
			<p>As we can see, <code>User</code> represents the concept of an IR instance (for example, an <code>Instruction</code>) that uses a certain <code>Value</code>. Furthermore, LLVM uses another class, <code>Use</code>, to model the edge between <code>Value</code> and <code>User</code>. Recall that <code>Instruction</code> is a child class of <code>Value</code> – which represents the result that's generated by this instruction. In fact, <code>Instruction</code> is also derived from <code>User</code>, since almost all instructions take at least one operand.</p>
			<p>A <code>User</code> might be pointed to by multiple <code>Use</code> instances, which means it uses many <code>Value</code> instances. You can use <code>value_op_iterator</code> provided by <code>User</code> to check out each of these <code>Value</code> instances; for example:</p>
			<pre>// `Usr` has the type of `User*`
for (<strong class="bold">Value *</strong>V : Usr-&gt;<strong class="bold">operand_values</strong>()) {
  // Working with `V`
}</pre>
			<p>Again, <code>operand_values</code> is just a utility function to generate a <code>value_op_iterator</code> range.</p>
			<p>Here is an example of why we want to iterate through all the <code>User</code> instances of a <code>Value</code>: imagine we are analyzing a program where one of its <code>Function</code> instances will return sensitive information – let's say, a <code>get_password</code> function. Our goal is to ensure that whenever <code>get_password</code> is called within a <code>Function</code>, its returned value (sensitive information) won't be leaked via another function call. For example, we want to detect <a id="_idIndexMarker526"/>the following pattern and raise an alarm:</p>
			<pre>void vulnerable() {
  <strong class="bold">v = get_password()</strong>;
  …
  bar(<strong class="bold">v</strong>); // WARNING: sensitive information leak to `bar`!
}</pre>
			<p>One of the most naïve ways to implement this analysis is by inspecting all <code>User</code> instances of the sensitive <code>Value</code>. Here is some example code:</p>
			<pre>User *find_leakage(CallInst *GetPWDCall) {
  for (auto *<strong class="bold">Usr</strong> : GetPWDCall-&gt;<strong class="bold">users</strong>()) {
    if (<strong class="bold">isa&lt;CallInst&gt;(Usr)</strong>) {
      return Usr;
    }
  }
  …
}</pre>
			<p>The <code>find_leackage</code> function takes a <code>CallInst</code> argument – which represents a <code>get_password</code> function call – and returns any <code>User</code> instance that uses the <code>Value</code> instance that's returned from that <code>get_password</code> call.</p>
			<p>A <code>Value</code> instance can be used by multiple different <code>User</code> instances. So, similarly, we can iterate through all of them using the following snippet:</p>
			<pre>// `V` has the type of `Value*`
for (<strong class="bold">User *</strong>Usr : V-&gt;<strong class="bold">users</strong>()) {
  // Working with `Usr`
}</pre>
			<p>With that, you've <a id="_idIndexMarker527"/>learned how to inspect the <code>User</code> instance of a <code>Value</code>, or the <code>Value</code> instance that's used by the current <code>User</code>. In addition, when we're developing a compiler transformation, it is pretty common to change the <code>Value</code> instance that's used by a <code>User</code> to another one. LLVM provides some handy utilities to do this.</p>
			<p>First, the <code>Value::replaceAllUsesWith</code> method can, as its name suggests, tell all of its <code>User</code> instances to use another <code>Value</code> instead of it. The following diagram illustrates its effect:</p>
			<div><div><img src="img/B14590_Figure_10.7.jpg" alt="Figure 10.7 – Effect of Value::replaceAllUsesWith&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – Effect of Value::replaceAllUsesWith</p>
			<p>This method is really useful when you're replacing an <code>Instruction</code> with another <code>Instruction</code>. Using the preceding diagram to explain this, <code>V1</code> is the original <code>Instruction</code> and <code>V2</code> is the new one. </p>
			<p>Another utility function that does a similar thing is <code>User::replaceUsesOfWith(From,To)</code>. This method effectively scans through all of the operands in this <code>User</code> and replaces the usage of a specific <code>Value</code> (the <em class="italic">From</em> argument) with another <code>Value</code> (the <em class="italic">To</em> argument).</p>
			<p>The skills you've learned in this section are some of the most fundamental tools for developing a program transformation in LLVM. In the next section, we will talk about how to create and modify instructions.</p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor152"/>Working with instructions</h2>
			<p>Previously, we<a id="_idIndexMarker528"/> learned the basics of <code>Value</code> – including its relationship with <code>Instruction</code> – and the way to update <code>Value</code> instances under the framework of SSA. In this section, we are going to learn some more basic knowledge and skills that give you a better understanding of <code>Instruction</code> and help you <em class="italic">modify</em> <code>Instruction</code> instances in a correct and efficient way, which is the key to developing a successful compiler optimization.</p>
			<p>Here is the list of topics we are going to cover in this section:</p>
			<ul>
				<li>Casting between different instruction types</li>
				<li>Inserting a new instruction</li>
				<li>Replacing an instruction</li>
				<li>Processing instructions in batches</li>
			</ul>
			<p>Let's start by looking at different instruction types.</p>
			<h3>Casting between different instruction types</h3>
			<p>In the previous section, we <a id="_idIndexMarker529"/>learned about a useful utility called <code>InstVisitor</code>. The <code>InstVisitor</code> class helps you determine the underlying class of an <code>Instruction</code> instance. It also saves you the efforts of casting between different instruction types. However, we cannot always rely on <code>InstVisitor</code> for every task that involves type casting between <code>Instruction</code> and its derived classes. More generally speaking, we want a simpler solution for type casting between parent and child classes.</p>
			<p>Now, you might be wondering, but C++ <em class="italic">already</em> provided this mechanism via the <code>dynamic_cast</code> directive, right? Here is an example of <code>dynamic_cast</code>:</p>
			<pre>class Parent {…};
class Child1 : public Parent {…};
class Child2 : public Parent {…};
void foo() {
  Parent *P = new Child1();
  Child1 *C = <strong class="bold">dynamic_cast&lt;Child1*&gt;(P)</strong>; // OK
  Child2 *O = <strong class="bold">dynamic_cast&lt;Child2*&gt;(P)</strong>; // Error: bails out at                                         // runtime
}</pre>
			<p>In the <code>foo</code> function <a id="_idIndexMarker530"/>used in the preceding code, we can see that in its second line, we can convert <code>P</code> into a <code>Child1</code> instance because that is its underlying type. On the other hand, we cannot convert <code>P</code> into <code>Child2</code> – the program will simply crash during runtime if we do so.</p>
			<p>Indeed, <code>dynamic_cast</code> has the exact functionality we are looking for – more formally speaking, the <strong class="bold">Runtime Type Info</strong> (<strong class="bold">RTTI</strong>) feature – but it also comes with high overhead in terms of runtime <a id="_idIndexMarker531"/>performance. What's worse, the default implementation of RTTI in C++ is quite complex, making the resulting program difficult to optimize. Therefore, LLVM <em class="italic">disables</em> RTTI by default. Due to this, LLVM came up with its own system of runtime type casting that is much simpler and more efficient. In this section, we are going to talk about how to use it.</p>
			<p>LLVM's casting framework provides three functions for dynamic type casting:</p>
			<ul>
				<li><code>isa&lt;T&gt;(val) </code></li>
				<li><code>cast&lt;T&gt;(val)</code></li>
				<li><code>dyn_cast&lt;T&gt;(val)</code></li>
			</ul>
			<p>The first function, <code>isa&lt;T&gt;</code> – pronounced "is-a" – checks if the <code>val</code> pointer type can be cast to a pointer of the <code>T</code> type. Here is an example:</p>
			<pre>// `I` has the type of `Instruction*`
if (<strong class="bold">isa&lt;BinaryOperator&gt;</strong>(I)) {
  // `I` can be casted to `BinaryOperator*`
}</pre>
			<p>Note that differently from <code>dynamic_cast</code>, you don't need to put <code>BinaryOperator*</code> as the template argument in this case – only a type without a pointer qualifier.</p>
			<p>The <code>cast&lt;T&gt;</code> function performs the real type casting from (pointer-type) <code>val</code> to a pointer of the <code>T</code> type. Here is an example:</p>
			<pre>// `I` has the type of `Instruction*`
if (isa&lt;BinaryOperator&gt;(I)) {
  <strong class="bold">BinaryOperator *BinOp = cast&lt;BinaryOperator&gt;(I)</strong>;
}</pre>
			<p>Again, you don't need <a id="_idIndexMarker532"/>to put <code>BinaryOperator*</code> as the template argument. Note that if you don't perform type checking using <code>isa&lt;T&gt;</code> before calling <code>cast&lt;T&gt;</code>, the program will just crash during runtime.</p>
			<p>The last function, <code>dyn_cast&lt;T&gt;</code>, is a combination of <code>isa&lt;T&gt;</code> and <code>cast&lt;T&gt;</code>; that is, you perform type casting if applicable. Otherwise, it returns a null. Here is an example:</p>
			<pre>// `I` has the type of `Instruction*`
<strong class="bold">if (BinaryOperator *BinOp = dyn_cast&lt;BinaryOperator&gt;(I))</strong> {
  // Work with `BinOp`
}</pre>
			<p>Here, we can see some neat syntax that combines the variable declaration (of <code>BinOp</code>) with the <code>if</code> statement.</p>
			<p>Be aware that none of these APIs can take null as the argument. On the contrary, <code>dyn_cast_or_null&lt;T&gt;</code> doesn't have this limitation. It is basically a <code>dyn_cast&lt;T&gt;</code> API that accepts null as input.</p>
			<p>Now, you know how to check and cast from an arbitrary <code>Instruction</code> instance to its underlying instruction type. Starting from the next section, we are finally going to create and modify some instructions.</p>
			<h3>Inserting a new instruction</h3>
			<p>In one of the code examples from the previous <em class="italic">Understanding SSA</em> section, we saw a snippet like this:</p>
			<pre>Instruction *BinI = BinaryOperator::Create(…);
Instruction *RetI = ReturnInst::Create(…, BinI, …);</pre>
			<p>As suggested by the<a id="_idIndexMarker533"/> method's name – <code>Create</code> – we can infer that these two lines created a <code>BinaryOperator</code> and a <code>ReturnInst</code> instruction.</p>
			<p>Most of the instruction classes in LLVM provide factory methods – such as <code>Create</code> here – to build a new instance. People are encouraged to use these factory methods versus allocating instruction objects manually via the <code>new</code> keyword or <code>malloc</code> function. LLVM will manage the instruction object's memory for you – once it's been inserted into a <code>BasicBlock</code>. There are several ways to insert a new instruction into a <code>BasicBlock</code>:</p>
			<ul>
				<li>Factory methods in some instruction classes provide an option to insert the instruction right after it is created. For instance, one of the <code>Create</code> method variants in <code>BinaryOperator</code> allows you to insert it <em class="italic">before</em> another instruction after the creation. Here is an example:<pre>Instruction *<code>BinOp</code> will be placed before the one represented by <code>BeforeI</code>. This method, however, can't be ported across different instruction classes. Not every instruction class has factory methods that provide this feature and even if they do provide them, the API might not be the same.</p></li>
				<li>We can use the <code>insertBefore</code>/<code>insertAfter</code> methods provided by the <code>Instruction</code> class to insert a new instruction. Since all instruction classes are subclasses of <code>Instruction</code>, we can use <code>insertBefore</code> or <code>insertAfter</code> to insert the newly created instruction instance before or after another <code>Instruction</code>.</li>
				<li>We can also use the <code>IRBuilder</code> class. <code>IRBuilder</code> is a powerful tool for automating some of the instruction creation and insertion steps. It implements a builder design pattern that can insert new instructions one after another when developers invoke one of its creation methods. Here is an example:<pre>// `BB` has the type of `BasicBlock*`
<code>IRBuilder</code> instance, we need to designate an <em class="italic">insertion point</em> as one of the constructor arguments. This insertion point argument can be a <code>BasicBlock</code>, which means we want to insert a new instruction at the<a id="_idIndexMarker534"/> end of <code>BasicBlock</code>; it can also be an <code>Instruction</code> instance, which means that new instructions are going to be inserted <em class="italic">before</em> that specific <code>Instruction</code>. </p><p>You are encouraged to use <code>IRBuilder</code> over other mechanisms if possible whenever you need to create and insert new instructions in sequential order.</p></li>
			</ul>
			<p>With that, you've learned how to create and insert new instructions. Now, let's look at how to <em class="italic">replace</em> existing instructions with others.</p>
			<h3>Replacing an instruction</h3>
			<p>There are many<a id="_idIndexMarker535"/> cases where we will want to replace an existing instruction. For instance, a simple optimizer might replace an arithmetic multiplication instruction with a left-shifting instruction when one of the multiplication's operands is a power-of-two integer constant. In this case, it seems straightforward that we can achieve this by simply changing the <em class="italic">operator</em> (the opcode) and one of the operands in the original <code>Instruction</code>. That is <strong class="bold">not</strong> the recommended way to do things, however.</p>
			<p>To replace an <code>Instruction</code> in LLVM, you need to create a new <code>Instruction</code> (as the replacement) and <em class="italic">reroute</em> all the SSA definitions and usages from the original <code>Instruction</code> to the replacement one. Let's use the power-of-two-multiplication we just saw as an example:</p>
			<ol>
				<li>The function we are<a id="_idIndexMarker536"/> going to implement is called <code>replacePow2Mul</code>, whose argument is the multiplication instruction to be processed (assuming that we have ensured the multiplication has a constant, power-of-two integer operand). First, we will retrieve the constant integer – represented by the <code>ConstantInt</code> class – operand and convert it into its base-2 logarithm value (via the <code>getLog2</code> utility function; the exact implementation of <code>getLog2</code> is left as an exercise for you):<pre>void replacePow2Mul(BinaryOperator &amp;Mul) {
  // Find the operand that is a power-of-2 integer   // constant
  int ConstIdx = isa&lt;<strong class="bold">ConstantInt</strong>&gt;(Mul.<strong class="bold">getOperand</strong>(0))? 0    : 1;
  ConstantInt *ShiftAmount = getLog2(Mul.   <strong class="bold">getOperand</strong>(ConstIdx));
}</pre></li>
				<li>Next, we will create a new left-shifting instruction – represented by the <code>ShlOperator</code> class:<pre>void replacePow2Mul(BinaryOperator &amp;Mul) {
  …
  // Get the other operand from the original instruction
  auto *Base = Mul.getOperand(ConstIdx? 0 : 1);
  // Create an instruction representing left-shifting
  <strong class="bold">IRBuilder&lt;&gt;</strong> Builder(&amp;Mul);
  auto *Shl = Builder.<strong class="bold">CreateShl</strong>(Base, ShiftAmount);
}</pre></li>
				<li>Finally, before we <a id="_idIndexMarker537"/>remove the <code>Mul</code> instruction, we need to tell all the users of the original <code>Mul</code> to use our newly created <code>Shl</code> instead:<pre>void replacePow2Mul(BinaryOperator &amp;Mul) {
  …
  // Using `replaceAllUsesWith` to update users of `Mul`
  Mul.<code>Mul</code> are using <code>Shl</code> instead. Thus, we can safely remove <code>Mul</code> from the program.</p></li>
			</ol>
			<p>With that, you've learned how to replace an existing <code>Instruction</code> properly. In the final subsection, we are going to talk about some tips for processing multiple instructions in a <code>BasicBlock</code> or a <code>Function</code>.</p>
			<h3>Tips for processing instructions in batches</h3>
			<p>So far, we have been<a id="_idIndexMarker538"/> learning how to insert, delete, and replace a single <code>Instruction</code>. However, in real-world cases, we usually perform such actions on a <em class="italic">sequence</em> of <code>Instruction</code> instances (that are in a <code>BasicBlock</code>, for instance). Let's try to do that by putting what we've learned into a <code>for</code> loop that iterates through all the instructions in a <code>BasicBlock</code>; for instance:</p>
			<pre>// `BB` has the type of `BasicBlock&amp;`
for (Instruction &amp;I : BB) {
  if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I)) {
    if (isMulWithPowerOf2(BinOp))
      <strong class="bold">replacePow2Mul</strong>(BinOp);
  }
}</pre>
			<p>The preceding code used the <code>replacePow2Mul</code> function we just saw in the previous section to replace the multiplications in this <code>BasicBlock</code> with left-shifting instructions if the multiplication fulfills certain criteria. (This is checked by the <code>isMulWithPowerOf2</code> function. Again, the details of this function have been left as an exercise to you.)</p>
			<p>This code looks pretty <a id="_idIndexMarker539"/>straightforward but unfortunately, it will crash while running this transformation. What happened here was that the <code>Instruction</code> instances in <code>BasicBlock</code> became <em class="italic">stale</em> after running our <code>replacePow2Mul</code>. The <code>Instruction</code> iterator is unable to keep updated with the changes that have been applied to the <code>Instruction</code> instances in this <code>BasicBlock</code>. In other words, it's really hard to change the <code>Instruction</code> instances while iterating them at the same time.</p>
			<p>The simplest way to solve this problem is to <strong class="bold">push off</strong> the changes:</p>
			<pre>// `BB` has the type of `BasicBlock&amp;`
<strong class="bold">std::vector&lt;BinaryOperator*&gt; Worklist;</strong>
// Only perform the feasibility check
for (auto &amp;I : BB) {
  if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I)) {
    if (isMulWithPowerOf2(BinOp)) <strong class="bold">Worklist.push_back(BinOp)</strong>;
  }
}
// Replace the target instructions at once
for (auto *BinOp : <strong class="bold">Worklist</strong>) {
  <strong class="bold">replacePow2Mul</strong>(BinOp);
}</pre>
			<p>The preceding code separates<a id="_idIndexMarker540"/> the previous code example into two parts (as two separate <code>for</code> loops). The first <code>for</code> loop is still iterating through all the <code>Instruction</code> instances in <code>BasicBlock</code>. But this time, it only performs the checks (that is, calling <code>isMulWithPowerOf2</code>) without replacing the <code>Instruction</code> instance right away if it passes the checks. Instead, this <code>for</code> loop pushes the candidate <code>Instruction</code> into array storage – a <code>for</code> loop, the second <code>for</code> loop inspects the <a id="_idIndexMarker541"/>worklist and performs the real replacement by calling <code>replacePow2Mul</code> on each worklist item. Since the replacements in the second <code>for</code> loop don't invalidate any iterators, we can finally transform the code without any crashes occurring.</p>
			<p>There are, of course, other ways to circumvent the aforementioned iterator problem, but they are mostly complicated and less readable. Using a worklist is the safest and most expressive way to modify instructions in batches.</p>
			<p><code>Value</code> is a first-class construction in LLVM that outlines the data flow among different entities such as instructions. In this section, we introduced how values are represented in LLVM IR and the model of SSA that makes it easier to analyze and transform it. We also learned how to update values in an efficient way and some useful skills for manipulating instructions. This will help build the foundation for you to build more complex and advanced compiler optimizations using LLVM.</p>
			<p>In the next section, we will look at a slightly more complicated IR unit – a loop. We are going to learn how loops are represented in LLVM IR and how to work with them.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor153"/>Working with loops</h1>
			<p>So far, we <a id="_idIndexMarker542"/>have learned about several IR units such as modules, functions, basic blocks, and instructions. We have also learned about some <em class="italic">logical</em> units such as CFG and call graphs. In this section, we are going to look at a more logical IR unit: a loop.</p>
			<p>Loops are ubiquitous constructions that are heavily used by programmers. Not to mention that nearly every programming language contains this concept, too. A loop repeatedly executes a certain number of instructions multiple times, which, of course, saves programmers lots of effort from repeating that code by themselves. However, if the loop contains any <em class="italic">inefficient</em> code – for example, a time-consuming memory load that always delivers the same value – the performance slowdown will also be <em class="italic">magnified</em> by the number of iterations. </p>
			<p>Therefore, it is the compiler's job to eliminate as many flaws as possible from a loop. In addition to removing suboptimal code from loops, since loops are on the critical path of the runtime's performance, people have always been trying to further optimize them with special hardware-based accelerations; for example, replacing a loop with vector instructions, which can process multiple scalar values in just a few cycles. In short, loop optimization is the key to generating faster, more efficient programs. This is especially important in the high-performance and scientific computing communities.</p>
			<p>In this section, we<a id="_idIndexMarker543"/> are going to learn how to process loops with LLVM. We will try to tackle this topic in two parts:</p>
			<ul>
				<li>Learning about loop representation in LLVM</li>
				<li>Learning about loop infrastructure in LLVM</li>
			</ul>
			<p>In LLVM, loops are slightly more complicated than other (logical) IR units. Therefore, we will learn about the high-level concept of a loop in LLVM and its <em class="italic">terminologies</em> first. Then, in the second part, we are going to get our hands on the infrastructure and tools that are used fo<a id="_idTextAnchor154"/>r processing loops in LLVM.</p>
			<p>Let's start with the first part.</p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor155"/>Learning about loop representation in LLVM</h2>
			<p>A loop is<a id="_idIndexMarker544"/> represented by the <code>Loop</code> class in LLVM. This class captures any control flow structure that has a <em class="italic">back edge</em> from an enclosing basic block in one of its predecessor blocks. Before we dive into its details, let's learn how to retrieve a <code>Loop</code> instance.</p>
			<p>As we mentioned previously, a loop is a logical IR unit in LLVM IR. Namely, it is derived (or calculated) from physical IR units. In this case, we need to retrieve the calculated <code>Loop</code> instances from <code>AnalysisManager</code> – which was first introduced in <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager</em>. Here is an example showing how to retrieve it in a <code>Pass</code> function:</p>
			<pre>#include "llvm/Analysis/LoopInfo.h"
…
PreservedAnalyses run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {
  <strong class="bold">LoopInfo &amp;LI = FAM.getResult&lt;LoopAnalysis&gt;(F);</strong>
  // `LI` contains ALL `Loop` instances in `F`
  for (<strong class="bold">Loop *LP : LI</strong>) {
    // Working with one of the loops, `LP`
  }
  …
}</pre>
			<p><code>LoopAnalysis</code> is an LLVM analysis class that provides us with a <code>LoopInfo</code> instance, which includes <em class="italic">all</em> the <code>Loop</code> instances in a <code>Function</code>. We can iterate through a <code>LoopInfo</code> instance<a id="_idIndexMarker545"/> to get an individual <code>Loop</code> instance, as shown in the preceding code.</p>
			<p>Now, let's look into a <code>Loop</code> instance.</p>
			<h3>Learning about loop terminologies</h3>
			<p>A <code>Loop</code> instance<a id="_idIndexMarker546"/> contains multiple <code>BasicBlock</code> instances for a particular loop. LLVM assigns a special meaning/name to some of these blocks, as well as the (control flow) edges among them. The following diagram shows this terminology:</p>
			<div><div><img src="img/B14590_Figure_10.8.jpg" alt="Figure 10.8 – Structure and terminology used in a loop&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8 – Structure and terminology used in a loop</p>
			<p>Here, every rectangle is a <code>BasicBlock</code> instance. However, only blocks residing within the dash line area are included in a <code>Loop</code> instance. The preceding diagram also shows two important control flow edges. Let's explain each of these terminologies in detail:</p>
			<ul>
				<li><code>Loop</code>, it represents the block that has the header block <a id="_idIndexMarker548"/>as the only successor. In other words, it's the only predecessor of the header block. </p><p>The existence of a pre-header block makes it easier to write some of the loop transformations. For instance, when we want to <em class="italic">hoist</em> an instruction to the outside of the loop so that it is only executed once before entering the loop, the pre-header block can be a good place to put this. If we don't have a pre-header block, we need to duplicate this instruction for <em class="italic">every</em> predecessor of the header block.</p></li>
				<li><strong class="bold">Back Edge</strong>: This is the <a id="_idIndexMarker549"/>control flow edge that goes from one of the blocks in the loop to the header block. A loop might contain several back edges.</li>
				<li><strong class="bold">Latch Block</strong>: This is the <a id="_idIndexMarker550"/>block that sits at the source of a back edge.</li>
				<li><strong class="bold">Exiting Block</strong> and <strong class="bold">Exit Block</strong>: These <a id="_idIndexMarker551"/>two names are slightly confusing: the exiting block is the block<a id="_idIndexMarker552"/> that has a control flow edge – the <strong class="bold">Exit Edge</strong> – that goes <em class="italic">outside</em> the loop. The other end of the exit edge, which is not part of the loop, is the exit block. A loop can contain multiple exit blocks (and exiting blocks).</li>
			</ul>
			<p>These are the important terminologies for blocks in a <code>Loop</code> instance. In addition to the control flow structure, compiler<a id="_idIndexMarker553"/> engineers are also interested in a special value that might exist in a loop: the <code>i</code> variable is the induction variable:</p>
			<pre>for (<strong class="bold">int i</strong> = 0; i &lt; 87; ++i){…}</pre>
			<p>A loop might not contain an induction variable – for example, many <code>while</code> loops in C/C++ don't have one. Also, it's not always easy to find out about an induction variable, nor its <em class="italic">boundary</em> – the start, end, and stopping values. We will show some of the utilities in the next section to help you with this task. But before that, we are going to discuss an interesting topic regarding the <em class="italic">canonical</em> form of a loop.</p>
			<h3>Understanding canonical loops</h3>
			<p>In the previous section, we<a id="_idIndexMarker554"/> learned several pieces of terminology for loops in LLVM, including the pre-header block. Recall that the existence of a pre-header block makes it easier to develop a loop transformation because it creates a simpler loop structure. Following this discussion, there are other properties that make it easier for us to write loop transformations, too. If a <code>Loop</code> instance has these nice properties, we usually call it a <strong class="bold">canonical loop</strong>. The optimization pipeline in LLVM will try to "massage" a loop into this canonical form before sending it to any of the loop transformations.</p>
			<p>Currently, LLVM has two canonical forms for <code>Loop</code>: a <strong class="bold">simplified</strong> form and a <strong class="bold">rotated</strong> form. The simplified form has the following properties:</p>
			<ul>
				<li>A pre-header block.</li>
				<li>A single back edge (and thus a single latch block).</li>
				<li>The predecessors of the exit blocks come from the loop. In other words, the header block dominates all the exit blocks.</li>
			</ul>
			<p>To get a simplified loop, you can run <code>LoopSimplfyPass</code> over the original loop. In addition, you can use the <code>Loop::isLoopSimplifyForm</code> method to check if a <code>Loop</code> is in this form.</p>
			<p>The benefits of having a single back edge include that we can analyze recursive data flow – for instance, the induction variable – more easily. For the last property, if every exit block is dominated by the loop, we can have an easier time "sinking" instructions below the loop without any interference from other control flow paths.</p>
			<p>Let's look at the <a id="_idIndexMarker555"/>rotated canonical form. Originally, the rotated form was not a formal canonical form in LLVM's loop optimization pipeline. But with more and more loop passes depending on it, it has become the "de facto" canonical form. The following diagram shows what this form looks like:</p>
			<div><div><img src="img/B14590_Figure_10.9.jpg" alt="Figure 10.9 – Structure and terminology of a rotated loop&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.9 – Structure and terminology of a rotated loop</p>
			<p>To get a rotated loop, you can run <code>LoopRotationPass</code> over the original loop. To check if a loop is rotated, you can use the <code>Loop::isRotatedForm</code> method.</p>
			<p>This rotated form is basically transforming an arbitrary loop into a <code>do{…}while(…)</code> loop (in C/C++) with some extra checks. More specifically, let's say we have the following <code>for</code> loop:</p>
			<pre>// `N` is not a constant
for (int i = 0; i &lt; N; ++i){…}</pre>
			<p>Loop rotation effectively turns it into the following code:</p>
			<pre><strong class="bold">if (i &lt; N)</strong> {
  do {
    …
    ++i;
  } while(i &lt; N);
}</pre>
			<p>The highlighted boundary <a id="_idIndexMarker556"/>check in the preceding code is used to ensure that the loop won't execute if the <code>i</code> variable is out of bounds at the very beginning. We also call this check the <strong class="bold">loop guard</strong>, as shown in the preceding diagram.</p>
			<p>In addition to the loop guard, we also found that a rotated loop has a combined header, latch, and exiting block. The rationale behind this is to ensure that every instruction in this block has the same <em class="italic">execution count</em>. This is a useful property for compiler optimizations such as loop vectorization.</p>
			<p>With that, we have learned about the various loop terminologies and the definition of canonical loops in LLVM. In the next section, we will learn about some APIs that can help you inspect some of these properties and process loops in an efficient way.</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor156"/>Learning about loop infrastructure in LLVM</h2>
			<p>In the <em class="italic">Learning about loop representation in LLVM</em> section, we learned about the high-level<a id="_idIndexMarker557"/> construction and important properties of a loop in LLVM IR. In this section, we are going to see what APIs are available for us to inspect those properties and further transform the loops. Let's start our discussion from the loop pass – the LLVM pass that applies to <code>Loop</code> instances.</p>
			<p>In <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager</em>, we learned that there are different kinds of LLVM pass that work on different IR units – for instance, we have seen passes for <code>Function</code> and <code>Module</code>. These two kinds of passes have a similar function signature for their <code>run</code> method – the main entry point of an LLVM pass – as shown here:</p>
			<pre>PreservedAnalyses run(<strong class="bold">&lt;IR unit class&gt;</strong> &amp;Unit,
                      <strong class="bold">&lt;IR unit&gt;AnalysisManager</strong> &amp;AM);</pre>
			<p>Both of their <code>run</code> methods take two arguments – a reference to the IR unit instance and an <code>AnalysisManager</code> instance.</p>
			<p>In contrast, a loop<a id="_idIndexMarker558"/> pass has a slightly more complicated <code>run</code> method signature, as shown here:</p>
			<pre>PreservedAnalyses run(Loop &amp;LP, LoopAnalysisManager &amp;LAM,
                      <strong class="bold">LoopStandardAnalysisResults</strong> &amp;LAR,
                      <strong class="bold">LPMUpdater</strong> &amp;U);</pre>
			<p>The <code>run</code> method takes four arguments, but we already know about the first two. Here are the descriptions for the other two:</p>
			<ul>
				<li>The third argument, <code>LoopStandardAnalysisResults</code>, provides you with some analysis data instances, such as <code>AAResults</code> (alias analysis data), <code>DominatorTree</code>, and <code>LoopInfo</code>. These analyses are extensively used by many loop optimizations. However, most of them are managed by either <code>FunctionAnalysisManager</code> or <code>ModuleAnalysisManager</code>. This means that, originally, developers needed to implement more complicated methods – for example, using the <code>OuterAnalysisManagerProxy</code> class – to retrieve them. The <code>LoopStandardAnalysisResults</code> instance basically helps you retrieve this analysis data <em class="italic">ahead of time</em>.</li>
				<li>The last argument is used for notifying <code>PassManager</code> of any newly added loops so that it can put those new loops into the queue before processing them later. It can also tell the PassManager to put the current loop into the queue again.</li>
			</ul>
			<p>When we are writing a pass, we will want to use the analysis data provided by AnalysisManager – in this case, it is the <code>LoopAnalysisManager</code> instance. <code>LoopAnalysisManager</code> has a similar usage to other versions of AnalysisManager (<code>FunctionAnalysisManager</code>, for example) we learned about in the previous chapter. The only difference is that we need to supply an additional argument to the <code>getResult</code> method. Here is an example:</p>
			<pre>PreservedAnalyses run(<strong class="bold">Loop &amp;LP</strong>, LoopAnalysisManager &amp;LAM,
                      <strong class="bold">LoopStandardAnalysisResults &amp;LAR</strong>,
                      LPMUpdater &amp;U) {
  …
  LoopNest &amp;LN = LAM.getResult&lt;LoopNestAnalysis&gt;(<strong class="bold">LP, LAR</strong>);
  …
}</pre>
			<p><code>LoopNest</code> is the<a id="_idIndexMarker559"/> analysis data that's generated by <code>LoopNestAnalysis</code>. (We will talk about both shortly in the <em class="italic">Dealing with nested loops</em> section.)</p>
			<p>As shown in the previous snippet, <code>LoopAnalysisManager::getResult</code> takes another <code>LoopStandarAnalysisResults</code> type argument, in addition to the <code>Loop</code> instance.</p>
			<p>Except for having different a <code>run</code> method signature and a slightly different usage of <code>LoopAnalysisManager</code>, developers can build their loop passes in the same way as other kinds of passes. Now that we've looked at the foundation provided by loop pass and AnalysisManager, it's time to look at some specialized loops. The first one we are going to introduce is the <em class="italic">nested</em> loop. </p>
			<h3>Dealing with nested loops</h3>
			<p>So far, we <a id="_idIndexMarker560"/>have been talking about loops with only one layer. However, nested loops – loops with other loop(s) enclosed in them – are also common in real-world scenarios. For example, most of the matrix multiplication implementations require at least two layers of loops.</p>
			<p>Nested loops are usually depicted as a tree – called a <strong class="bold">loop tree</strong>. In a loop tree, every node represents a loop. If a node has a parent node, this <a id="_idIndexMarker561"/>means that the corresponding loop is <em class="italic">enclosed</em> within the loop<a id="_idIndexMarker562"/> being modeled by the parent. The following diagram shows an example of this:</p>
			<div><div><img src="img/B14590_Figure_10.10.jpg" alt="Figure 10.10 – A loop tree example&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.10 – A loop tree example</p>
			<p>In the preceding diagram, loops <code>j</code> and <code>g</code> are enclosed within loop <code>i</code>, so they are both child nodes of loop <code>i</code> in the loop tree. Similarly, loop <code>k</code> – the innermost loop – is modeled as the child node of loop <code>j</code> in the tree.</p>
			<p>The root of a loop tree also represents a <em class="italic">top-level</em> loop in a <code>Function</code>. Recall that, previously, we learned how to retrieve all <code>Loop</code> instances in a <code>Function</code> by iterating through the <code>LoopInfo</code> object – each of the <code>Loop</code> instances that were retrieved in this way are top-level loops. For a given <code>Loop</code> instance, we can retrieve its subloops at the next layer in a similar way. Here is an example:</p>
			<pre>// `LP` has the type of `Loop&amp;`
for (<strong class="bold">Loop *SubLP : LP</strong>) {
  // `SubLP` is one of the sub-loops at the next layer
}</pre>
			<p>Note that the preceding snippet only traversed the subloops at the next level, rather than all the descendant subloops. To traverse all descendant subloops in a tree, you have two options:</p>
			<ul>
				<li>By using the <code>Loop::getLoopsInPreorder()</code> method, you can traverse all the descendant loops of a <code>Loop</code> instance in a pre-ordered fashion.</li>
				<li>In the <em class="italic">Iterating different IR units</em> section, we have learned what <code>GraphTraits</code> is and how LLVM uses it for graph traversal. It turns out that LLVM also has a default implementation of <code>GraphTraits</code> for the loop tree. Therefore, you can traverse a loop tree with existing graph iterators in LLVM, such as post-ordering and depth-first, to name a few. For example, the following code tries to traverse a<a id="_idIndexMarker563"/> loop tree rooted at <code>RootL</code> in a depth-first fashion:<pre>#include "llvm/Analysis/LoopInfo.h"
#include "llvm/ADT/DepthFirstIterator.h"
…
// `RootL` has the type of `Loop*`
for (<code>GraphTraits</code>, we can have more flexibility when it comes to traversing a loop tree.</p></li>
			</ul>
			<p>In addition to dealing with individual loops in a loop tree, LLVM also provides a wrapper class that represents the whole structure – <code>LoopNest</code>.</p>
			<p><code>LoopNest</code> is analysis data that's generated by <code>LoopNestAnalysis</code>. It encapsulates all the subloops in a given <code>Loop</code> instance and provides several "shortcut" APIs for commonly used functionalities. Here are some of the important ones:</p>
			<ul>
				<li><code>getOutermostLoop()</code>/<code>getInnermostLoop()</code>: These utilities retrieve the outer/innermost <code>Loop</code> instances. These are pretty handy because many loop optimizations only apply to either the inner or outermost loop.</li>
				<li><code>areAllLoopsSimplifyForm()</code>/<code>areAllLoopsRotatedForm()</code>: These useful utilities tell you if all the enclosing loops are in a certain canonical form, as we mentioned in the previous section.</li>
				<li><code>getPerfectLoops(…)</code>: You can use this to get all the <em class="italic">perfect loops</em> in the current loop hierarchy. By perfect loops, we are referring to loops that are nested together without a "gap" between them. Here is an example of perfect loops and non-perfect loops:<pre>// Perfect loops
for(int i=…) {
  for(int j=…){…}
}
// Non-perfect loops
for(int x=…) {
  <code>foo</code> call site is the gap between the upper and lower loops.</p><p>Perfect loops are preferrable in many loop optimizations. For example, it's easier to <em class="italic">unroll</em> perfectly nested loops – ideally, we only need to duplicate the body of the innermost loop.</p></li>
			</ul>
			<p>With that, you've learned how to work with nested loops. In the next section, we are going to learn about another important topic for loop optimization: induction variables.</p>
			<h3>Retrieving induction variables and their range</h3>
			<p>The induction variable<a id="_idIndexMarker565"/> is a variable that progresses by a certain pattern in each loop iteration. It is the key to many loop optimizations. For example, in order to <em class="italic">vectorize</em> a loop, we need to know how the induction variable is used by the array – the data we want to put in a vector – within the loop. The induction variable can also help <a id="_idIndexMarker566"/>us resolve the <strong class="bold">trip count</strong> – the total number of iterations – of a loop. Before we dive into the details, the following diagram shows some terminology related to induction variables and where they're located in the loop:</p>
			<div><div><img src="img/B14590_Figure_10.11.jpg" alt="Figure 10.11 – Terminology for an induction variable&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.11 – Terminology for an induction variable</p>
			<p>Now, let's introduce some APIs that can help you retrieve the components shown in the preceding diagram. </p>
			<p>First, let's talk about the induction variable. The <code>Loop</code> class already provides two convenient methods for retrieving the induction variable: <code>getCanonicalInductionVariable</code> and <code>getInductionVariable</code>. Both methods return a <code>PHINode</code> instance as the induction variable (if there are any). The first method can only be used if the induction variable starts from zero and only increments by one on each iteration. On the other hand, the second method can handle more complicated cases, but requires a <code>ScalarEvolution</code> instance as the argument.</p>
			<p><code>ScalarEvolution</code> is an interesting and powerful framework in LLVM. Simply put, it tries to track how values <em class="italic">change</em> – for example, through arithmetic operation – over the program path. Putting this into the context of loop optimization, it is used to capture recurrence value-changing behaviors in the loop, which has a strong relationship with the induction variable.</p>
			<p>To find out more about the induction variable's behavior in a loop, you can retrieve an <code>InductionDescriptor</code> instance via <code>Loop::getInductionDescriptor</code>. An <code>InductionDescriptor</code> instance provides information such as the initial value, the step value, and the instruction that <em class="italic">updates</em> the induction variable at each iteration. The <code>Loop</code> class also provides another similar data structure for realizing the boundaries of the induction variable: the <code>Loop::LoopBounds</code> class. <code>LoopBounds</code> not only provides the initial and step values of the induction variable, but also the prospective ending value, as well as the predicate that's used for checking the exit condition. You can retrieve a <code>LoopBounds</code> instance via the <code>Loop::getBounds</code> method.</p>
			<p>Loops are<a id="_idIndexMarker567"/> crucial for a program's runtime performance. In this section, we learned how loops are represented in LLVM IR and how to work with them. We also looked at their high-level concepts and various practical APIs for retrieving the desired loop properties. With this knowledge, you are one step closer to creating a more effective, aggressive loop optimization and gaining even higher performance from your target applications.</p>
			<h1 id="_idParaDest-150"><a id="_idTextAnchor157"/>Summary</h1>
			<p>In this section, we learned about LLVM IR – the target-independent intermediate representation that sits at the core of the entire LLVM framework. We provided an introduction to the high-level structure of LLVM IR, followed by practical guidelines on how to walk through different units within its hierarchy. We also focused on instructions, values, and SSA form at, which are crucial for working with LLVM IR efficiently. We also presented several practical skills, tips, and examples on the same topic. Last but not least, we learned how to process loops in LLVM IR – an important technique for optimizing performance-sensitive applications. With these abilities, you can perform a wider range of program analysis and code optimization tasks on LLVM IR.</p>
			<p>In the next chapter, we will learn about a collection of LLVM utilities APIs that can improve your productivity when it comes to developing, diagnosing, and debugging with LLVM.</p>
		</div>
	</body></html>