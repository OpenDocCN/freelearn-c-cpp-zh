<html><head></head><body>
        

                            
                    <h1 class="header-title">Lighting and Shading</h1>
                
            
            
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li class="mce-root">Shading with multiple positional lights</li>
<li class="mce-root">Shading with a directional light source</li>
<li class="mce-root">Using per-fragment shading for improved realism</li>
<li class="mce-root">The Blinn-Phong reflection model</li>
<li class="mce-root">Simulating a spotlight</li>
<li class="mce-root">Creating a cartoon shading effect</li>
<li class="mce-root">Simulating fog</li>
<li>A physically-based reflection model</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction</h1>
                
            
            
                
<p>In <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em>, we covered a number of techniques for implementing some of the shading effects that were produced by the former fixed-function pipeline. We also looked at some basic features of GLSL such as functions and subroutines. In this chapter, we'll move beyond those introductory features, and see how to produce shading effects such as spotlights, fog, and cartoon style shading. We'll cover how to use multiple light sources and how to improve the realism of the results with a technique called per-fragment shading.</p>
<p>We'll also cover the very popular and important Blinn-Phong reflection model and directional light sources.</p>
<p>Finally, we'll cover how to fine-tune the depth test by configuring the early depth test optimization.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Shading with multiple positional lights</h1>
                
            
            
                
<p>When shading with multiple light sources, we need to evaluate the reflection model for each light, and sum the results to determine the total light intensity reflected by a surface location. The natural choice is to create uniform arrays to store the position and intensity of each light. We'll use an array of structures so that we can store the values for multiple lights within a single uniform variable.</p>
<p>The following image shows a "pig" mesh rendered with five light sources of different colors. Note the multiple specular highlights:</p>
<div><img src="img/2498e7c9-3129-45d5-8af1-aa31ff0a0280.png" style="width:19.00em;height:14.25em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Set up your OpenGL program with the vertex position in attribute location zero, and the normal in location one.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>To create a shader program that renders using the Blinn-Phong reflection model with multiple light sources, use the following steps:</p>
<p>In the vertex shader, we'll use a similar structure as in the previous recipes, except we will use an array of structures for the lights. In addition, we just store two intensities for each light. The first is the ambient intensity and the second is used for both diffuse and specular. The <kbd>phongModel</kbd> function is updated to use light information from one of the values in the array:</p>
<pre style="padding-left: 60px">layout (location = 0) in vec3 VertexPosition; 
layout (location = 1) in vec3 VertexNormal; 
 
out vec3 Color; 
 <br/>uniform struct LightInfo {<br/>  vec4 Position; // Light position in eye coords.<br/>  vec3 La;       // Ambient light intesity<br/>  vec3 L;        // Diffuse and specular light intensity<br/>} lights[5];
<br/>// Material and matrix uniforms omitted...
 <br/>vec3 phongModel( int light, vec3 position, vec3 n ) { <br/>  vec3 ambient = lights[light].La * Material.Ka;<br/>  vec3 s = normalize( lights[light].Position.xyz - position );<br/>  float sDotN = max( dot(s,n), 0.0 );<br/>  vec3 diffuse = Material.Kd * sDotN;<br/>  vec3 spec = vec3(0.0);<br/>  if( sDotN &gt; 0.0 ) {<br/>    vec3 v = normalize(-position.xyz);<br/>    vec3 r = reflect( -s, n );<br/>    spec = Material.Ks *<br/>            pow( max( dot(r,v), 0.0 ), Material.Shininess );<br/>  }<br/><br/>  return ambient + lights[light].L * (diffuse + spec);<br/>}<br/>void main() {<br/>  vec3 camNorm = normalize( NormalMatrix * VertexNormal);<br/>  vec3 camPosition = <br/>       ModelViewMatrix * vec4(VertexPosition,1.0)).xyz;<br/><br/>  // Evaluate the lighting equation, for each light<br/>  Color = vec3(0.0);<br/>  for( int i = 0; i &lt; 5; i++ )<br/>      Color += phongModel( i, camPosition, camNorm );<br/><br/>  gl_Position = MVP * vec4(VertexPosition,1.0);<br/>}</pre>
<p>The fragment shader simply applies the color to the fragment, as in previous recipes.</p>
<p>In the OpenGL application, set the values for the <kbd>lights</kbd> array in the vertex shader. For each light, use something similar to the following code. This example uses the C++ shader program class described in <a href="3b817a9a-28a1-4be7-936c-b982b4dfacdf.xhtml"/><a href="3b817a9a-28a1-4be7-936c-b982b4dfacdf.xhtml">Chapter 2</a>, <em>Working with GLSL Programs</em> (<kbd>prog</kbd> is a <kbd>GLSLProgram</kbd> object):</p>
<pre style="padding-left: 60px">prog.setUniform("lights[0].L", glm::vec3(0.0f,0.8f,0.8f) ); 
prog.setUniform("lights[0].La", glm::vec3(0.0f,0.2f,0.2f) );<br/>prog.setUniform("lights[0].Position", position );</pre>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>Within the vertex shader, the lighting parameters are stored in the uniform array <kbd>lights</kbd>. Each element of the array is a struct of type <kbd>LightInfo</kbd>. This example uses five lights. The diffuse/specular light intensity is stored in the <kbd>L</kbd> field, the ambient intensity is stored in the <kbd>La</kbd> field, and the position in camera coordinates is stored in the <kbd>Position</kbd> field.</p>
<p>The rest of the uniform variables are essentially the same as in the Phong model shader presented in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em>.</p>
<p>The <kbd>phongModel</kbd> function is responsible for computing the shading equation for a given light source. The index of the light is provided as the first parameter, <kbd>light</kbd>. The equation is computed based on the values in the <kbd>lights</kbd> array in that index. In this example, we don't use a separate light intensity for the diffuse and specular components.</p>
<p>In the <kbd>main</kbd> function, a <kbd>for</kbd> loop is used to compute the shading equation for each light, and the results are summed into the output variable <kbd>Color</kbd>.</p>
<p>The fragment shader simply applies the interpolated color to the fragment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/scenemultilight.cpp</kbd> file in the example code</li>
<li>The <em>Implementing the Phong reflection model</em> recipe in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a><em>,</em> <em>The Basics of GLSL Shaders</em></li>
<li>The <em>Shading with a directional light source</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Shading with a directional light source</h1>
                
            
            
                
<p>A core component of a shading equation is the vector that points from the surface location toward the light source (<kbd>s</kbd>, in previous examples). For lights that are extremely far away, there is very little variation in this vector over the surface of an object. In fact, for very distant light sources, the vector is essentially the same for all points on a surface (another way of thinking about this is that the light rays are nearly parallel). Such a model would be appropriate for a distant, but powerful, light source such as the sun. Such a light source is commonly called a <strong>directional light source</strong> because it does not have a specific position, only a direction.</p>
<p class="mce-root"/>
<p>Of course, we are ignoring the fact that, in reality, the intensity of the light decreases with the square of the distance from the source. However, it is not uncommon to ignore this aspect for directional light sources.</p>
<p>If we are using a directional light source, the direction toward the source is the same for all points in the scene. Therefore, we can increase the efficiency of our shading calculations because we no longer need to recompute the direction toward the light source for each location on the surface.</p>
<p>Of course, there is a visual difference between a positional light source and a directional one. The following images show a torus rendered with a positional light (left) and a directional light (right). In the left image, the light is located somewhat close to the torus. The directional light covers more of the surface of the torus due to the fact that all of the rays are parallel:</p>
<div><img src="img/5e1837f9-f62c-4ba8-be6b-90bb75362678.png" style="width:24.83em;height:9.42em;"/></div>
<p>In previous versions of OpenGL, the fourth component of the light position was used to determine whether or not a light was considered directional. A zero in the fourth component indicated that the light source was directional and the position was to be treated as a direction toward the source (a vector). Otherwise, the position was treated as the actual location of the light source. In this example, we'll emulate the same functionality.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Set up your OpenGL program with the vertex position in attribute location zero, and the vertex normal in location one.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>To create a shader program that implements the Phong reflection model using a directional light source, we'll use the same vertex shader as in the previous recipe, except with a single light source.  Within the <kbd>phongModel</kbd> function, replace the calculation of the <kbd>s</kbd> vector with the following: </p>
<pre>vec3 s;<br/>if( Light.Position.w == 0.0 )<br/>  s = normalize( Light.Position.xyz );<br/>else<br/>  s = normalize( Light.Position.xyz - position );</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>Within the vertex shader, the fourth coordinate of the uniform variable <kbd>Light.Position</kbd> is used to determine whether or not the light is to be treated as a directional light. Inside the <kbd>phongModel</kbd> function, which is responsible for computing the shading equation, the value of the vector <kbd>s</kbd> is determined based on whether or not the fourth coordinate of <kbd>Light.Position</kbd> is zero. If the value is zero, <kbd>Light.Position</kbd> is normalized and used as the direction toward the light source. Otherwise, <kbd>Light.Position</kbd> is treated as a location in eye coordinates, and we compute the direction toward the light source by subtracting the vertex position from <kbd>Light.Position</kbd> and normalizing the result.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>There is a slight efficiency gain when using directional lights, due to the fact that there is no need to recompute the light direction for each vertex. This saves a subtraction operation, which is a small gain but could accumulate when there are several lights or when the lighting is computed per-fragment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/scenedirectional.cpp</kbd> file in the example code</li>
<li>The <em>Implementing the Phong reflection model</em> recipe in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml"/><a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml"/><a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em></li>
<li>The <em>Using per-fragment shading </em><em>for improved realism</em> recipe in this chapter</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Using per-fragment shading for improved realism</h1>
                
            
            
                
<p>When the shading equation is evaluated within the vertex shader (as we have done in previous recipes), we end up with a color associated with each vertex. That color is then interpolated across the face, and the fragment shader assigns that interpolated color to the output fragment. As mentioned previously, this technique is called <strong>Gouraud shading</strong>. Gouraud shading (like all shading techniques) is an approximation, and can lead to some less than desirable results when, for example, the reflection characteristics at the vertices have little resemblance to those in the center of the polygon. For example, a bright specular highlight may reside in the center of a polygon but not at its vertices. Simply evaluating the shading equation at the vertices would prevent the specular highlight from appearing in the rendered result. Other undesirable artifacts, such as edges of polygons, may also appear when Gouraud shading is used, due to the fact that color interpolation may not match the value of the reflection model across the face.</p>
<p>To improve the accuracy of our results, we can move the computation of the shading equation from the vertex shader to the fragment shader. Instead of interpolating color across the polygon, we interpolate the position and normal vector, and use these values to evaluate the shading equation at each fragment. This technique is called <strong>Phong shading</strong> or <strong>Phong interpolation</strong>. The results from Phong shading are much more accurate and provide more pleasing results, but some undesirable artifacts may still appear.</p>
<p>The following image shows the difference between Gouraud and Phong shading. The scene on the left is rendered with Gouraud (per-vertex) shading, and on the right is the same scene rendered using Phong (per-fragment) shading. Underneath the teapot is a partial plane, drawn with a single quad. Note the difference in the specular highlight on the teapot, as well as the variation in the color of the plane beneath the teapot:</p>
<div><img src="img/9f6158b4-6338-4dc5-9760-02cd47873aeb.png" style="width:34.67em;height:13.17em;"/></div>
<p class="chapter-content">In this example, we'll implement Phong shading by passing the position and normal from the vertex shader to the fragment shader, and then evaluating the Phong reflection model within the fragment shader.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Set up your program with the vertex position in attribute location zero, and the normal in location one. Your OpenGL application must also provide the values for the uniform variables, as in the previous recipes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">To create a shader program that can be used for implementing per-fragment (or Phong) shading using the Phong reflection model, use the following steps:</p>
<ol>
<li>The vertex shader simply converts the position and normal to camera coordinates and passes them to the fragment shader:</li>
</ol>
<pre style="padding-left: 60px">layout (location = 0) in vec3 VertexPosition;<br/>layout (location = 1) in vec3 VertexNormal;<br/><br/>out vec3 Position;<br/>out vec3 Normal;<br/><br/>uniform mat4 ModelViewMatrix, NormalMatrix, ProjectionMatrix, MVP;<br/><br/>void main() {<br/>  Normal = normalize( NormalMatrix * VertexNormal);<br/>  Position = ( ModelViewMatrix * vec4(VertexPosition,1.0) ).xyz;<br/>  gl_Position = MVP * vec4(VertexPosition,1.0);<br/>}</pre>
<ol start="2">
<li>The fragment shader evaluates the Phong reflection model using the values passed from the vertex shader:</li>
</ol>
<pre style="padding-left: 60px">in vec3 Position; 
in vec3 Normal; <br/>// Uniform variables...
<br/>layout( location = 0 ) out vec4 FragColor; 
 
vec3 phongModel( vec3 position, vec3 n ) { 
   // Compute and return Phong reflection model
} 
 
void main() { <br/>  FragColor = vec4(phongModel(Position, normalize(Normal)), 1);
} </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">The vertex shader has two output variables: <kbd>Position</kbd> and <kbd>Normal</kbd>. In the <kbd>main</kbd> function, we convert the vertex normal to camera coordinates by transforming with the normal matrix, and then store the converted value in <kbd>Normal</kbd>. Similarly, the vertex position is converted to eye coordinates by transforming it by the model-view matrix, and the converted value is stored in <kbd>Position</kbd>. The values of <kbd>Position</kbd> and <kbd>Normal</kbd> are automatically interpolated and provided to the fragment shader via the corresponding input variables. The fragment shader then computes the Phong reflection model using the values provided. Here, we re-normalize the <kbd>Normal</kbd> vector because the interpolation process can create vectors that are not of unit length. </p>
<p class="mce-root">Finally, the result is then stored in the output variable <kbd>FragColor</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">Evaluating the shading equation within the fragment shader produces more accurate renderings. However, the price we pay is in the evaluation of the shading model for each pixel of the polygon, rather than at each vertex. The good news is that with modern graphics cards, there may be enough processing power to evaluate all of the fragments for a polygon in parallel. This can essentially provide nearly equivalent performance for either per-fragment or per-vertex shading.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/sceneperfragment.cpp</kbd> recipe in the example code</li>
<li>The <em>Implementing the Phong reflection model</em> recipe in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em></li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">The Blinn-Phong reflection model</h1>
                
            
            
                
<p class="mce-root">As covered in the <em>Implementing the Phong reflection model </em>recipe in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em>, the specular term in the equation involves the dot product of the vector of pure reflection (<em>r</em>), and the direction toward the viewer (<em>v</em>):</p>
<div><p class="mce-root">In order to evaluate the preceding equation, we need to find the vector of pure reflection (<em>r</em>), which is the reflection of the vector toward the light source (<em>s</em>) about the normal vector (<em>n</em>):</p>
<div><img class="fm-editor-equation" src="img/6dce10af-52fa-4818-a702-2e42d3bf27ef.png" style="width:12.42em;height:1.83em;"/></div>
<p>This equation is implemented using the GLSL function <kbd>reflect</kbd>.</p>
<p class="mce-root">We can avoid calculating <em>r</em> by making use of the following observation. When <em>v</em> is aligned with <em>r</em>, the normal vector (<em>n</em>) must be halfway between <em>v</em> and <em>s</em>. Let's define the halfway vector (<em>h</em>) as the vector that is halfway between <em>v</em> and <em>s</em>, where <em>h</em> is normalized after the addition:</p>
<div><img class="fm-editor-equation" src="img/b44c9a59-70f4-489e-86c8-5c6004d39768.png" style="width:6.17em;height:1.33em;"/></div>
<p class="mce-root">The following diagram shows the relative positions of the halfway vector and the others:</p>
<div><img src="img/2615656a-d295-4666-9347-e2a100568868.png" style="width:18.58em;height:10.25em;"/></div>
<p class="mce-root">We can then replace the dot product in the equation for the specular component, with the dot product of <em>h</em> and <em>n</em>:</p>
<div><img class="fm-editor-equation" src="img/4c114917-4c01-4b1f-8f4c-f554155dc7e9.png" style="width:10.25em;height:1.75em;"/></div>
<p class="mce-root">Computing <em>h</em> requires fewer operations than it takes to compute <em>r</em>, so we should expect some efficiency gain by using the halfway vector. The angle between the halfway vector and the normal vector is proportional to the angle between the vector of pure reflection (<em>r</em>) and the vector toward the viewer (<em>v</em>) when all vectors are co-planar. Therefore, we expect that the visual results will be similar, although not exactly the same.</p>
<p>This small modification to the Phong reflection model was proposed by James Blinn, a researcher who worked at NASA's <strong>Jet Propulsion Laboratory</strong> (<strong>JPL</strong>). His modified version, which uses the <em>halfway vector</em> in the specular term is, therefore called the <strong>Blinn-Phong model</strong>.</p>
<p>It is interesting to note that the Blinn-Phong model, despite appearing to be somewhat <em>ad hoc</em>, produces results that match physical measurements more closely than the Phong model.  For details, see this paper:<a href="http://people.csail.mit.edu/wojciech/BRDFValidation/index.html"> http://people.csail.mit.edu/wojciech/BRDFValidation/index.html</a></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Start by utilizing the same shader program that was presented in the recipe <em>Using per-fragment shading for improved realism</em>, and set up your OpenGL program as described there.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">Using the same shader pair as in the recipe <em>Using per-fragment </em><em>shading for improved realism</em>, replace the <kbd>phongModel</kbd> function in the fragment shader with the following:</p>
<pre>vec3 blinnPhong( vec3 position, vec3 n ) { <br/>  vec3 ambient = Light.La * Material.Ka;<br/>  vec3 s = normalize( Light.Position.xyz - position );<br/>  float sDotN = max( dot(s,n), 0.0 );<br/>  vec3 diffuse = Material.Kd * sDotN;<br/>  vec3 spec = vec3(0.0);<br/>  if( sDotN &gt; 0.0 ) {<br/>    vec3 v = normalize(-position.xyz);<br/>    vec3 h = normalize( v + s );<br/>    spec = Material.Ks *<br/>            pow( max( dot(h,n), 0.0 ), Material.Shininess );<br/>  }<br/>  return ambient + Light.L * (diffuse + spec);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">We compute the halfway vector by summing the direction toward the viewer (<kbd>v</kbd>), and the direction toward the light source (<kbd>s</kbd>), and normalizing the result. The value for the halfway vector is then stored in <kbd>h</kbd>. The specular calculation is then modified to use the dot product between <kbd>h</kbd> and the normal vector (<kbd>n</kbd>). The rest of the calculation is unchanged.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">The following screenshot shows the teapot rendered using the Blinn-Phong model (right), versus the same rendering using the equation provided in the <em>Implementing the Phong reflection model</em> recipe in <a href="74703f9d-f69a-4b08-bb38-6e1066371207.xhtml">Chapter 3</a>, <em>The Basics of GLSL Shaders</em> (left). The halfway vector produces a larger specular highlight.  If desired, we could compensate for the difference in the size of the specular highlight by increasing the value of the exponent <kbd>Material.Shininess</kbd>:</p>
<div><img src="img/8b37199d-173d-4fd7-bf5d-bef7ea751b4f.png" style="width:38.50em;height:14.33em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/shader/blinnphong.vert.glsl</kbd> and <kbd>chapter04/shader/blinnphong.frag.glsl</kbd> files in the example code</li>
<li>The <em>Using per-fragment shading for improved realism</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Simulating a spotlight</h1>
                
            
            
                
<p class="mce-root">The fixed function pipeline had the ability to define light sources as spotlights. In such a configuration, the light source was considered to be one that only radiated light within a cone, the apex of which was located at the light source. Additionally, the light was attenuated so that it was maximal along the axis of the cone and decreased toward the outside edges. This allowed us to create light sources that had a similar visual effect to a real spotlight.</p>
<p class="mce-root">The following screenshot shows a teapot and a torus rendered with a single spotlight. Note the slight decrease in the intensity of the spotlight from the center toward the outside edge:</p>
<div><img src="img/1d797f40-5120-4c88-bd9f-4f11214993ed.png" style="width:20.67em;height:14.67em;"/></div>
<p class="mce-root">In this recipe, we'll use a shader to implement a spotlight effect, similar to that produced by the fixed-function pipeline:</p>
<div><img src="img/9c6e823c-5f7f-494a-8ffc-27746d130928.png" style="width:17.00em;height:13.25em;"/></div>
<p class="mce-root">The spotlight's cone is defined by a spotlight direction (<strong>d</strong>, in the preceding image), a cutoff angle (<strong>c</strong>, in the preceding image), and a position (<strong>P</strong>, in the preceding image). The intensity of the spotlight is considered to be the strongest along the axis of the cone, and decreases as you move toward the edges.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Start with the same vertex shader from the recipe, <em>Using per-fragment shading for improved realism</em>. Your OpenGL program must set the values for all uniform variables defined in that vertex shader as well as the fragment shader shown next.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">To create a shader program that uses the ADS shading model with a spotlight, use the following code for the fragment shader:</p>
<pre>in vec3 Position; 
in vec3 Normal; 
 
uniform struct SpotLightInfo {<br/>    vec3 Position;  // Position in cam coords<br/>    vec3 L;         // Diffuse/spec intensity<br/>    vec3 La;        // Amb intensity<br/>    vec3 Direction; // Direction of the spotlight in cam coords.<br/>    float Exponent; // Angular attenuation exponent<br/>    float Cutoff;   // Cutoff angle (between 0 and pi/2)<br/>} Spot;<br/><br/>// Material uniforms...
 
layout( location = 0 ) out vec4 FragColor; 
 
vec3 blinnPhongSpot( vec3 position, vec3 n ) { <br/>  vec3 ambient = Spot.La * Material.Ka, <br/>    diffuse = vec3(0), spec = vec3(0);<br/>  vec3 s = normalize( Spot.Position - position );<br/>  float cosAng = dot(-s, normalize(Spot.Direction));<br/>  float angle = acos( cosAng );<br/>  float spotScale = 0.0;<br/>  if(angle &lt; Spot.Cutoff ) {<br/>    spotScale = pow( cosAng, Spot.Exponent );<br/>    float sDotN = max( dot(s,n), 0.0 );<br/>    diffuse = Material.Kd * sDotN;<br/>    if( sDotN &gt; 0.0 ) {<br/>      vec3 v = normalize(-position.xyz);<br/>      vec3 h = normalize( v + s );<br/>      spec = Material.Ks *<br/>        pow( max( dot(h,n), 0.0 ), Material.Shininess );<br/>    }<br/>  }<br/>  return ambient + spotScale * Spot.L * (diffuse + spec);<br/>}<br/><br/>void main() {<br/>  FragColor = vec4(blinnPhongSpot(Position, normalize(Normal)), 1);<br/>}<br/><br/></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">The <kbd>SpotLightInfo</kbd> structure defines all of the configuration options for the spotlight. We declare a single uniform variable named <kbd>Spot</kbd> to store the data for our spotlight. The <kbd>Position</kbd> field defines the location of the spotlight in eye coordinates. The <kbd>L</kbd> field is the intensity (diffuse and specular) of the spotlight, and <kbd>La</kbd> is the ambient intensity. The <kbd>Direction</kbd> field will contain the direction that the spotlight is pointing, which defines the center axis of the spotlight's cone. This vector should be specified in camera coordinates. Within the OpenGL program, it should be transformed by the normal matrix in the same way that normal vectors would be transformed. We could do so within the shader; however, within the shader, the normal matrix would be specified for the object being rendered. This may not be the appropriate transform for the spotlight's direction.</p>
<p class="mce-root">The <kbd>Exponent</kbd> field defines the exponent that is used when calculating the angular attenuation of the spotlight. The intensity of the spotlight is decreased in proportion to the cosine of the angle between the vector from the light to the surface location (the negation of the variable <kbd>s</kbd>) and the direction of the spotlight. That cosine term is then raised to the power of the variable <kbd>Exponent</kbd>. The larger the value of this variable, the faster the intensity of the spotlight is decreased. This is similar to the exponent in the specular shading term.</p>
<p class="mce-root">The <kbd>Cutoff</kbd> field defines the angle between the central axis and the outer edge of the spotlight's cone of light. We specify this angle in radians.</p>
<p class="mce-root">The <kbd>blinnPhongSpot</kbd> function computes the Blinn-Phong reflection model, using a spotlight as the light source. The first line computes the ambient lighting component and stores it in the <kbd>ambient</kbd> variable.  The second line computes the vector from the surface location to the spotlight's position (<kbd>s</kbd>).  Next, we compute the dot product between the direction from the spotlight to the surface point (<kbd>-s</kbd>) and the direction of the spotlight and store the result in <kbd>cosAng</kbd>. The angle between them is then computed and stored in the variable <kbd>angle</kbd>.   The variable <kbd>spotScale</kbd> will be used to scale the value of the spotlight's diffuse/specular intensity.  It is initially set to zero.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">We then compare the value of the <kbd>angle</kbd> variable with that of the <kbd>Spot.Cutoff</kbd> variable. If <kbd>angle</kbd> is greater than zero and less than <kbd>Spot.Cutoff</kbd>, then the surface point is within the spotlight's cone. Otherwise, the surface point only receives ambient light, so we skip the rest and return only the ambient component.</p>
<p class="mce-root">If <kbd>angle</kbd> is less than <kbd>Spot.Cutoff</kbd>, we compute the <kbd>spotScale</kbd> value by raising the dot product of <kbd>-s</kbd> and <kbd>spotDir</kbd> to the power of <kbd>Spot.Exponent</kbd>. The value of <kbd>spotScale</kbd> is used to scale the intensity of the light so that the light is maximal in the center of the cone, and decreases as you move toward the edges. Finally, the Blinn-Phong reflection model is computed as usual.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>Chapter04/scenespot.cpp</kbd> file in the example code</li>
<li>The <em>Using per-fragment shading for improved realism</em> recipe</li>
<li>The T<em>he Blinn-Phong reflection model </em>recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a cartoon shading effect</h1>
                
            
            
                
<p class="mce-root"><strong>Toon shading</strong> (also called <strong>cel shading</strong>) is a non-photorealistic rendering technique that is intended to mimic the style of shading often used in hand-drawn animation. There are many different techniques that are used to produce this effect. In this recipe, we'll use a very simple technique that involves a slight modification to the ambient and diffuse shading model.</p>
<p class="mce-root">The basic effect is to have large areas of constant color with sharp transitions between them. This simulates the way that an artist might shade an object using strokes of a pen or brush. The following image shows an example of a teapot and torus rendered with toon shading:</p>
<div><img src="img/bb29d75e-b189-4725-a38d-4fe472d02af9.png" style="width:18.58em;height:11.17em;"/></div>
<p class="mce-root">The technique presented here involves computing only the ambient and diffuse components of the typical ADS shading model, and quantizing the cosine term of the diffuse component. In other words, the value of the dot product normally used in the diffuse term is restricted to a fixed number of possible values. The following table illustrates the concept for four levels:</p>
<table border="1" class="table" style="border-collapse: collapse;width: 62.8536%">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 81.25%"><strong>Cosine of the angle between s and n</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 20.5645%"><strong>Value used</strong></td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 81.25%">Between 1 and 0.75</td>
<td class="CDPAlignCenter CDPAlign" style="width: 20.5645%">0.75</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 81.25%">Between 0.75 and 0.5</td>
<td class="CDPAlignCenter CDPAlign" style="width: 20.5645%">0.5</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 81.25%">Between 0.5 and 0.25</td>
<td class="CDPAlignCenter CDPAlign" style="width: 20.5645%">0.25</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 81.25%">Between 0.25 and 0.0</td>
<td class="CDPAlignCenter CDPAlign" style="width: 20.5645%">0.0</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">In the preceding table, <strong>s</strong> is the vector toward the light source and <strong>n</strong> is the normal vector at the surface. By restricting the value of the cosine term in this way, the shading displays strong discontinuities from one level to another (see the preceding image), simulating the pen strokes of hand-drawn cel animation.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Start with the same vertex shader from the <em>Using per-fragment shading for improved realism</em> recipe. Your OpenGL program must set the values for all uniform variables defined in that vertex shader as well as the fragment shader code described here.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">To create a shader program that produces a toon shading effect, use the following fragment shader:</p>
<pre>in vec3 Position;<br/>in vec3 Normal;<br/><br/>uniform struct LightInfo {<br/>  vec4 Position; // Light position in eye coords.<br/>  vec3 La;       // Ambient light intesity<br/>  vec3 L;        // Diffuse and specular light intensity<br/>} Light;<br/><br/>uniform struct MaterialInfo {<br/>  vec3 Ka; // Ambient reflectivity<br/>  vec3 Kd; // Diffuse reflectivity<br/>} Material;<br/><br/>const int levels = 3;<br/>const float scaleFactor = 1.0 / levels;<br/><br/>layout( location = 0 ) out vec4 FragColor;<br/><br/>vec3 toonShade( ) {<br/>    vec3 n = normalize( Normal );<br/>    vec3 s = normalize( Light.Position.xyz - Position );<br/>    vec3 ambient = Light.La * Material.Ka;<br/>    float sDotN = max( dot( s, n ), 0.0 );<br/>    vec3 diffuse = Material.Kd * floor( sDotN * levels ) * scaleFactor;<br/><br/>    return ambient + Light.L * diffuse;<br/>}<br/><br/>void main() {<br/>    FragColor = vec4(toonShade(), 1.0);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">The constant variable, <kbd>levels</kbd>, defines how many distinct values will be used in the diffuse calculation. This could also be defined as a uniform variable to allow for configuration from the main OpenGL application. We will use this variable to quantize the value of the cosine term in the diffuse calculation.</p>
<p class="mce-root">The <kbd>toonShade</kbd> function is the most significant part of this shader. We start by computing <kbd>s</kbd>, the vector toward the light source. Next, we compute the cosine term of the diffuse component by evaluating the dot product of <kbd>s</kbd> and <kbd>Normal</kbd>. The next line quantizes that value in the following way. Since the two vectors are normalized, and we have removed negative values with the <kbd>max</kbd> function, we are sure that the value of cosine is between zero and one. By multiplying this value by <kbd>levels</kbd> and taking the <kbd>floor</kbd>, the result will be an integer between <kbd>0</kbd> and <kbd>levels -1</kbd>. When we divide that value by levels (by multiplying by <kbd>scaleFactor</kbd>), we scale these integral values to be between zero and one again. The result is a value that can be one of <kbd>levels</kbd> possible values spaced between zero and one. This result is then multiplied by <kbd>Material.Kd</kbd>, the diffuse reflectivity term.</p>
<p class="mce-root">Finally, we combine the diffuse and ambient components together to get the final color for the fragment.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">When quantizing the cosine term, we could have used <kbd>ceil</kbd> instead of <kbd>floor</kbd>. Doing so would have simply shifted each of the possible values up by one level. This would make the levels of shading slightly brighter.</p>
<p class="mce-root">The typical cartoon style seen in most cel animation includes black outlines around the silhouettes and along other edges of a shape. The shading model presented here does not produce those black outlines. There are several techniques for producing them, and we'll look at one later on in this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/scenetoon.cpp</kbd> file in the example code</li>
<li>The <em>Using per-fragment shading for improved realism</em> recipe</li>
<li><em>The Blinn-Phong reflection model</em> recipe </li>
<li>The <em>Drawing silhouette lines using the geometry shader</em> recipe in <a href="fab663d4-e210-417c-aa3b-2c4c307ec913.xhtml">Chapter 6</a>, <em>Image Processing and Screen Space Techniques</em></li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Simulating fog</h1>
                
            
            
                
<p class="mce-root">A simple fog effect can be achieved by mixing the color of each fragment with a constant fog color. The amount of influence of the fog color is determined by the distance from the camera. We could use either a linear relationship between the distance and the amount of fog color, or we could use a non-linear relationship such as an exponential one.</p>
<p class="mce-root">The following image shows four teapots rendered with a fog effect produced by mixing the fog color in a linear relationship with distance:</p>
<div><img src="img/6b0c4b37-0dad-4535-857b-89e982167b2c.png" style="width:18.67em;height:11.25em;"/></div>
<p class="mce-root">To define this linear relationship, we can use the following equation:</p>
<div><img class="fm-editor-equation" src="img/07b17663-7f06-4f6b-8202-d51e3b7fff74.png" style="width:10.25em;height:3.50em;"/></div>
<p class="mce-root">In the preceding equation, <em>d<sub>min</sub></em> is the distance from the eye where the fog is minimal (no fog contribution), and <em>d<sub>max</sub></em> is the distance where the fog color obscures all other colors in the scene. The variable <em>z</em> represents the distance from the eye. The value <em>f</em> is the fog factor. A fog factor of zero represents 100% fog, and a factor of one represents no fog. Since fog typically looks thickest at longer distances, the fog factor is minimal when <em>|z|</em> is equal to <em>d<sub>max</sub></em>, and maximal when <em>|z|</em> is equal to <em>d<sub>min</sub></em>.</p>
<p>Since the fog is applied by the fragment shader, the effect will only be visible on the objects that are rendered. It will not appear on any <em>empty</em> space in the scene (the background). To help make the fog effect consistent, you should use a background color that matches the maximum fog color.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Start with the same vertex shader from the <em>Using per-fragment shading for improved realism</em> recipe. Your OpenGL program must set the values for all uniform variables defined in that vertex shader as well as the fragment shader shown in the following section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">To create a shader that produces a fog-like effect, use the following code for the fragment shader:</p>
<pre>in vec3 Position; 
in vec3 Normal; <br/>// Light and material uniforms ...<br/>uniform struct FogInfo {<br/>  float MaxDist;<br/>  float MinDist;<br/>  vec3 Color;<br/>} Fog;<br/><br/>layout( location = 0 ) out vec4 FragColor;<br/><br/>vec3 blinnPhong( vec3 position, vec3 n ) { <br/>  // Blinn-Phong reflection model ...<br/>}<br/><br/>void main() {<br/>    float dist = abs( Position.z );<br/>    float fogFactor = (Fog.MaxDist - dist) /<br/>                      (Fog.MaxDist - Fog.MinDist);<br/>    fogFactor = clamp( fogFactor, 0.0, 1.0 );<br/>    vec3 shadeColor = blinnPhong(Position, normalize(Normal));<br/>    vec3 color = mix( Fog.Color, shadeColor, fogFactor );<br/>    FragColor = vec4(color, 1.0);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">In this shader, the <kbd>blinnPhong</kbd> function is exactly the same as the one used in <em>The Blinn-Phong reflection model</em> recipe<em>.</em> The part of this shader that deals with the fog effect lies within the <kbd>main</kbd> function.</p>
<p class="mce-root">The uniform variable <kbd>Fog</kbd> contains the parameters that define the extent and color of the fog. The <kbd>MinDist</kbd> field is the distance from the eye to the fog's starting point, and <kbd>MaxDist</kbd> is the distance to the point where the fog is maximal. The <kbd>Color</kbd> field is the color of the fog.</p>
<p class="mce-root">The <kbd>dist</kbd> variable is used to store the distance from the surface point to the eye position. The <kbd>z</kbd> coordinate of the position is used as an estimate of the actual distance. The <kbd>fogFactor</kbd> variable is computed using the preceding equation. Since <kbd>dist</kbd> may not be between <kbd>Fog.MinDist</kbd> and <kbd>Fog.MaxDist</kbd>, we clamp the value of <kbd>fogFactor</kbd> to be between zero and one.</p>
<p class="mce-root">We then call the <kbd>blinnPhong</kbd> function to evaluate the reflection model. The result of this is stored in the <kbd>shadeColor</kbd> variable.</p>
<p class="mce-root">Finally, we mix <kbd>shadeColor</kbd> and <kbd>Fog.Color</kbd> together based on the value of <kbd>fogFactor</kbd>, and the result is used as the fragment color.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">In this recipe, we used a linear relationship between the amount of fog color and the distance from the eye. Another choice would be to use an exponential relationship. For example, the following equation could be used:</p>
<div><img class="fm-editor-equation" src="img/1cda3161-457c-4eba-bd09-0bece84dc867.png" style="width:6.33em;height:2.08em;"/></div>
<p class="mce-root">In the above equation, <em>d</em> represents the density of the fog. Larger values would create <em>thicker</em> fog. We could also square the exponent to create a slightly different relationship (a faster increase in the fog with distance).</p>
<div><img class="fm-editor-equation" src="img/279083d8-41b2-498f-8d5d-754c37e4a2db.png" style="width:7.08em;height:2.25em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Computing distance from the eye</h1>
                
            
            
                
<p class="mce-root">In the preceding code, we used the absolute value of the <em>z</em> coordinate as the distance from the camera. This may cause the fog to look a bit unrealistic in certain situations. To compute a more precise distance, we could replace the line:</p>
<pre>float dist = abs( Position.z ); </pre>
<p class="mce-root">With the following:</p>
<pre>float dist = length( Position.xyz ); </pre>
<p class="mce-root">Of course, the latter version requires a square root, and therefore would be a bit slower in practice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/scenefog.cpp</kbd> file in the example code</li>
<li><em>The Blinn-Phong reflection model</em> recipe</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">A physically-based reflection model</h1>
                
            
            
                
<p><strong>Physically-based rendering</strong> or <strong>PBR</strong> is an umbrella term that encompasses tools and techniques that make use of physically-based models of light and reflection. The term itself is somewhat loosely defined, but can generally be described as a shading/reflection model that tries to model the physics of light interacting with matter as accurately as possible. The term may mean slightly different things to different people, but for our purposes, we are interested primarily in how it differs from the Phong and the Blinn-Phong reflection models.</p>
<p>The Blinn-Phong model is an empirical model of reflection based on observation. A PBR model could also be considered an empirical model, but in general, it is more detailed and accurate with regards to the physics of the interaction being represented. The Blinn-Phong model uses a few parameters which are not physically based but produce effective results. For example, separating the light intensity into three (or two) separate values is not physically accurate (there's only one light). However, it provides many "tuneable" parameters to the artist to work with, giving them the flexibility to achieve the desired look.</p>
<p>In recent years, PBR techniques have gained favor due to the fact that they reduce the number of tuneable parameters, and provide more consistent results across a wide variety of materials. Artists have found that previous models (non-PBR) have a tendency to be tricky to "get right." When a scene consists of a wide variety of materials, the parameters may require a significant amount of "tweaking" to make consistent. With PBR-based techniques, the reflection models try to represent the physics more accurately, which tends to make things look more consistent under a wide variety of lighting settings, reducing the amount of fine-tuning required by artists.</p>
<p>In this recipe, we'll implement a basic PBR-based reflection model using point light sources. Before we get started, however, let's go over the math. In the following equations, we'll use the vectors <em>n</em>, <em>l</em>, <em>v</em>, and <em>h</em>, defined as follows:  </p>
<ul>
<li><em>n</em>: The surface normal</li>
<li><em>l</em>: The vector representing the direction of incoming light</li>
<li><em>v</em>: The direction toward the viewer (camera)</li>
<li><em>h</em>: The vector halfway between <em>l</em> and <em>v</em> (as in the Blinn-Phong model)</li>
</ul>
<p>A popular mathematical model for describing how light scatters from a surface is called <strong>the reflectance equation</strong> (a special case of the <strong>rendering equation</strong>), and has the following form:</p>
<div><img class="fm-editor-equation" src="img/d20ce6f4-de33-4c14-a99d-21854e83d95a.png" style="width:19.17em;height:3.33em;"/></div>
<p>This integral might look a bit scary, but basically, it means the following. The amount of outgoing radiance from a surface (<em>L<sub>o</sub></em>) toward the viewer (<em>v</em>), is equal to the integral (think weighted-sum) of the BRDF (<em>f</em>) times the amount of incoming radiance (<em>L<sub>i</sub></em>). The integral is over the hemisphere above the surface, for all incoming light directions (<em>l</em>) within that hemisphere weighted by a cosine factor (<em>n · l</em>). This cosine factor is a weight that essentially represents the geometry of the situation. The more directly that the light hits the surface, the higher it is weighted.  A more complete derivation of this equation is available in several texts. In this recipe, we'll simplify this integral to a simple sum, assuming that the only sources of incoming radiance are point light sources. This is of course a huge simplification, we'll consider some techniques to evaluate the integral more accurately later.</p>
<p>The most significant term for us is the BRDF term (<em>f</em>), which stands for bidirectional reflectance distribution function. It represents the fraction of radiance that is reflected from a surface point, given the incoming direction (<em>l</em>) and the outgoing direction (<em>v</em>). Its value is a spectral value (R,G,B), with components ranging from 0 to 1. In this recipe, we'll model the BRDF as a sum of two parts: the diffuse BRDF and the specular BRDF:</p>
<div><img class="fm-editor-equation" src="img/b20db239-6f3d-4e4a-a2d6-316d82f14ce0.png" style="width:9.50em;height:1.58em;"/></div>
<p>The diffuse BRDF represents light that is absorbed into the surface slightly and then is re-radiated. It is common to model this term so that the radiated light has no preferred direction. It is radiated equally in all outgoing directions. This is also called <strong>Lambertian reflectance</strong>. Since it has no dependence on the incoming or outgoing directions, the Lambertian BRDF is simply a constant value:</p>
<div><img class="fm-editor-equation" src="img/a41ab085-7009-407b-88d0-588792e10958.png" style="width:5.08em;height:2.42em;"/></div>
<p>The <em>c</em><sub><em>dif</em>f</sub> term represents the fraction of light that is diffusely radiated. It is commonly considered the diffuse color of the object.</p>
<p>The specular term represents surface reflectance. Light that is reflected directly off the surface of the object without being absorbed. This is also sometimes called <strong>glossy reflectance</strong>. A common way to model this reflectance is based on <strong>microfacet theory</strong>. This theory was developed to describe reflection from general, non-optically flat surfaces. It models the surface as consisting of small facets that are optically flat (mirrors) and are oriented in various directions. Only those that are oriented correctly to reflect toward the viewer can contribute to the BRDF.</p>
<p>We represent this BRDF as a product of three terms and a correction factor (the denominator):</p>
<div><img class="fm-editor-equation" src="img/e0141150-3520-47fe-9f9b-d6fda1f7ef8f.png" style="width:16.08em;height:3.50em;"/></div>
<p>I won't go into the details of each of these terms. For more information, check out the following <em>See also</em> section. Instead, I'll briefly describe each one. The <em>F</em> term represents <strong>Fresnel reflection</strong>, the fraction of light reflected from an optically flat surface. The Fresnel reflectance depends on the angle between the normal and the direction of incoming light (angle of incidence). However, since we are using microfacet theory, the microfacet surfaces that contribute are the ones that have their normal vector parallel to the halfway vector (<em>h</em>). Therefore, we use the angle between <em>l</em> and <em>h</em> instead of the angle between <em>l</em> and <em>n</em>. </p>
<p>The Fresnel reflectance also depends on the index of refraction of the surface. However, we'll use an approximation that instead uses a different parameter. It is known as the <strong>Schlick approximation</strong>:</p>
<div><img class="fm-editor-equation" src="img/0e75a16a-b20c-443e-81a6-36baed8510ca.png" style="width:22.17em;height:1.83em;"/></div>
<p>Rather than using the index of refraction, this approximation uses <em>F<sub>0</sub></em>, the <strong>characteristic specular reflectance</strong> of the material. Or in other words, the reflectance when the angle of incidence is zero degrees. This term is useful in that it can be used as a specular "color", which is somewhat more intuitive and natural for artists.</p>
<p>To further understand this <em>F<sub>0</sub></em> term, let's consider values for common materials. It turns out that a material's optical properties are closely tied to its electrical properties. It is therefore helpful to divide materials into three categories: dielectrics (insulators), metals (conductors), and semiconductors. Our model will ignore the third category and focus on the first two. Metals generally do not exhibit any diffuse reflection, because any light that is refracted into the surface is completely absorbed by the free electrons. The value for <em>F<sub>0</sub></em> is much larger for metals than for dielectrics. In fact, dielectrics have very low values for <em>F<sub>0</sub></em>, usually in the range of 0.05 (for all RGB components). This leads us to the following technique.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We'll associate a color with a material.  If the material is a metal, there's no diffuse reflection, so we set <em>c<sub>diff</sub></em> to (0,0,0), and use the color as the value for <em>F<sub>0</sub></em> in the Fresnel term. If the material is a dielectric, we set <em>F<sub>0</sub></em> to some small value (we'll use (0.04, 0.04, 0.04)), and use the color as the value for <em>c</em><sub><em>dif</em>f</sub>.  Essentially, we use two slightly different models for metals and dielectrics, switching between the two as needed. Rather than using the same model for both metals and non-metals and tweaking parameters to represent each, we separate them into two different categories each with a slightly different BRDF model. The popular term for this is <strong>metalness workflow</strong>.</p>
<p>Next, let's consider the <em>D</em> term in the specular BRDF. This is the <strong>microgeometry normal distribution function</strong> (or <strong>microfacet distribution function</strong>). It describes the statistical distribution of microsurface orientations. It has a scalar value, and gives the relative concentration of microfacet normals in the direction <em>h</em>. This term has a strong effect on the size and shape of the specular highlight. There are many choices for this function, and several have been developed in recent years based on physical measurements. We'll use a popular one from graphics researchers Trowbridge and Reitz, which was also given the name <strong>GGX</strong> by a separate research team:</p>
<div><img class="fm-editor-equation" src="img/dddc6f0b-994a-47a0-a13d-f9a2c0911f0d.png" style="width:16.25em;height:3.00em;"/></div>
<p>In this equation, <em>α</em> is a term that represents the roughness of the surface. Following the lead of others, we'll use a roughness parameter <em>r</em>, and set <em>α</em> to <em>r<sup>2</sup></em>.</p>
<p>Finally, we'll consider the <em>G</em> term in the specular BRDF. This is the geometry function and describes the probability that microsurfaces with a given normal will be visible from both the light direction (<em>l</em>) and the view direction (<em>v</em>). Its value is a scalar between 0 and 1. It is essential for energy conservation. We'll use the following model for <em>G</em>:</p>
<div><img class="fm-editor-equation" src="img/76ffd085-ba46-4971-bf52-cd85f7efd28e.png" style="width:11.67em;height:1.33em;"/></div>
<p>Where:</p>
<div><img class="fm-editor-equation" src="img/d9f23ea1-19c9-4a9a-b121-25a9f51278da.png" style="width:14.75em;height:2.75em;"/></div>
<p>The constant <em>k</em> is a value that is proportional to the roughness. Again, following the lead of others (see the following <em>See also</em>), we'll use the following for <em>k</em>:</p>
<div><img class="fm-editor-equation" src="img/683b8189-6ac5-4a4d-8b40-adceb0dcd1aa.png" style="width:6.17em;height:2.67em;"/></div>
<p>Putting all of this together, we now have a complete representation for our BRDF. Before jumping into the code, let's revisit the reflectance equation. This is the first equation we discussed, containing an integral over all directions over the hemisphere above the surface. It would be too costly to try to evaluate this integral in an interactive application, so we'll simplify it by making the assumption that all incoming light comes directly from point light sources. If we do so, the integral reduces to the following sum:</p>
<div><img class="fm-editor-equation" src="img/80aec644-d2b9-416d-a8d4-78cad56e4ed8.png" style="width:16.33em;height:3.92em;"/></div>
<p>Where <em>N</em> is the number of point light sources, <em>L<sub>i</sub></em> is the illumination received at the surface due to <em>i</em><sup>th</sup> light source and <em>l<sub>i</sub></em> is the direction toward the <em>i</em><sup>th</sup> light source. Since the intensity of light decreases with distance, we'll use an inverse-square relationship. However, other models could be used here:</p>
<div><img class="fm-editor-equation" src="img/dbb3e979-8b22-408e-b048-292c48471ad0.png" style="width:5.25em;height:3.67em;"/></div>
<p><em>I<sub>i</sub></em> is the intensity of the source and <em>d<sub>i</sub></em> is the distance from the surface point to the light source.</p>
<p>We now have a complete microfacet-based model that can be applied for metallic surfaces and dielectrics. As we covered earlier, we'll modify the BRDF slightly depending on whether we are working with a metal or a dielectric. The number of parameters to this BRDF is relatively small. The following parameters will define a material:</p>
<ul>
<li>The surface roughness (<em>r</em>), a value between 0 and 1</li>
<li>Whether or not the material is metallic (Boolean)</li>
<li>A color which is interpreted as the diffuse color for dielectrics, or the characteristic specular reflectance (<em>F<sub>0</sub></em>) for metals</li>
</ul>
<p>These parameters are quite intuitive and understandable, as opposed to the many parameters in the Blinn-Phong model from the previous recipe. There's just one color, and roughness is a more intuitive concept than the specular exponent.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>We'll set up our shader by starting with the shader pair from the Blinn-Phong recipe, but we'll change the fragment shader. Let's set up some uniforms for the light and material information.</p>
<p>For the light sources, we just need a position and an intensity:</p>
<pre>uniform struct LightInfo {<br/>  vec4 Position; // Light position in cam. coords.<br/>  vec3 L;        // Intensity<br/>} Light[3];</pre>
<p>For materials, we need the three values mentioned previously:</p>
<pre>uniform struct MaterialInfo {<br/>  float Rough;  // Roughness<br/>  bool Metal;   // Metallic (true) or dielectric (false)<br/>  vec3 Color;   // Diffuse color for dielectrics, f0 for metallic<br/>} Material;</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>We'll define a function for each of the three terms in the specular BRDF. Use the following steps:</p>
<ol>
<li>Define a function for the Fresnel term using the Schlick approximation:</li>
</ol>
<pre style="padding-left: 60px">vec3 schlickFresnel( float lDotH ) {<br/>  vec3 f0 = vec3(0.04);  // Dielectrics<br/>  if( Material.Metal ) {<br/>    f0 = Material.Color;<br/>  }<br/>  return f0 + (1 - f0) * pow(1.0 - lDotH, 5);<br/>}</pre>
<ol start="2">
<li>Define a function for the geometry term <em>G</em>:  </li>
</ol>
<pre style="padding-left: 60px">float geomSmith( float dotProd ) {<br/>  float k = (Material.Rough + 1.0) * (Material.Rough + 1.0) / 8.0;<br/>  float denom = dotProd * (1 - k) + k;<br/>  return 1.0 / denom;<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="3">
<li>The normal distribution function <em>D</em>, based on GGX/Trowbridge-Reitz:</li>
</ol>
<pre style="padding-left: 60px">float ggxDistribution( float nDotH ) {<br/>  float alpha2 = Material.Rough * Material.Rough * Material.Rough * Material.Rough;<br/>  float d = (nDotH * nDotH) * (alpha2 - 1) + 1;<br/>  return alpha2 / (PI * d * d);<br/>}</pre>
<ol start="4">
<li>We'll now define a function that computes the entire model for a single light source:</li>
</ol>
<pre style="padding-left: 60px">vec3 microfacetModel( int lightIdx, vec3 position, vec3 n ) { <br/>  vec3 diffuseBrdf = vec3(0.0); // Metallic<br/>  if( !Material.Metal ) {<br/>    diffuseBrdf = Material.Color;<br/>  }<br/><br/>  vec3 l = vec3(0.0), <br/>    lightI = Light[lightIdx].L;<br/>  if( Light[lightIdx].Position.w == 0.0 ) {  // Directional light<br/>    l = normalize(Light[lightIdx].Position.xyz);<br/>  } else {            // Positional light<br/>    l = Light[lightIdx].Position.xyz - position;<br/>    float dist = length(l);<br/>    l = normalize(l);<br/>    lightI /= (dist * dist);<br/>  }<br/><br/>  vec3 v = normalize( -position );<br/>  vec3 h = normalize( v + l );<br/>  float nDotH = dot( n, h );<br/>  float lDotH = dot( l, h );<br/>  float nDotL = max( dot( n, l ), 0.0 );<br/>  float nDotV = dot( n, v );<br/>  vec3 specBrdf = 0.25 * ggxDistribution(nDotH) * <br/>        schlickFresnel(lDotH) * geomSmith(nDotL) * geomSmith(nDotV);<br/><br/>  return (diffuseBrdf + PI * specBrdf) * lightI * nDotL;<br/>}</pre>
<ol start="5">
<li>We put this all together by summing over the light sources, applying Gamma correction, and writing out the result:</li>
</ol>
<pre style="padding-left: 60px">void main() {<br/>  vec3 sum = vec3(0), n = normalize(Normal);<br/>  for( int i = 0; i &lt; 3; i++ ) {<br/>    sum += microfacetModel(i, Position, n);<br/>  }<br/><br/>  // Gamma <br/>  sum = pow( sum, vec3(1.0/2.2) );<br/><br/>  FragColor = vec4(sum, 1);<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The <kbd>schlickFresnel</kbd> function computes the value of <em>F</em>.  If the material is a metal, the value for <em>F<sub>0</sub></em> is taken from the value of <kbd>Material.Color</kbd>. Otherwise, we simply use (0.04, 0.04, 0.04). Since most dielectrics have similar small values for <em>F<sub>0</sub></em>, this is a relatively good approximation for common dielectrics.</p>
<p>The <kbd>geomSmith</kbd> and <kbd>ggxDistribution</kbd> functions are straightforward implementations of the equations described previously. However, in <kbd>geomSmith</kbd>, we omit the numerator. This is due to the fact that it will cancel with the denominator of the overall specular BRDF.</p>
<p>The <kbd>microfacetModel</kbd> function computes the BRDF. The <kbd>diffuse</kbd> term is set to <kbd>0</kbd> if the material is metallic, otherwise, it is set to the value of the material's color. Note that we omit the factor of <em>π</em> here. This is due to the fact that it will cancel with the <em>π</em> term in the overall sum (the last summation equation), so no need to include it here.</p>
<p>Next, we determine the <em>L<sub>i</sub></em> term (<kbd>lightI</kbd>) and the vector <em>l</em>, depending on whether it is a directional light or a positional one. If it is directional, <kbd>lightI</kbd> is just the value of <kbd>Light[lightIdx].L</kbd>, otherwise, it is scaled by the inverse square of the distance to the light source.</p>
<p>Then, we calculate the specular BRDF (<kbd>specBrdf</kbd>), using the functions we defined previously. Note that (as mentioned previously) we omit the denominator of the BRDF (except for the factor of 0.25) due to the fact that those two dot products cancel with the numerators of the <em>G<sub>1</sub></em> functions.</p>
<p>The final result of this function is the total BRDF times the light intensity, times the dot product of <em>n</em> and <em>l</em>. We only multiply the specular BRDF times <em>π</em> due to the fact that we omitted the <em>π</em> term from the diffuse BRDF.   </p>
<p>Results for some simple materials are shown in the following image:</p>
<div><img src="img/9e6a3e0a-0c24-4a2a-b78c-6cc4214bcede.png" style="width:28.00em;height:11.50em;"/></div>
<p>The back row shows dielectric (non-metal) materials with increasing roughness from left to right.   The front row shows five metallic materials with various values for <em>F<sub>0</sub></em>.  </p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>Rather than making <kbd>Material.Metal</kbd> a Boolean value, one could choose to make it a continuous value between 0 and 1.  Indeed, this is exactly what some implementations do. The value would then be used to interpolate between the two models (metallic and dielectric). However, that makes the parameter somewhat less intuitive for artists and you may find that the extra configurability may not be all that useful.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter04/scenepbr.cpp</kbd> file in the example code</li>
<li>An excellent explanation of the mathematics behind PBR models and other information from the SIGGRAPH 2013 conference at <a href="http://blog.selfshadow.com/publications/s2013-shading-course/">http://blog.selfshadow.com/publications/s2013-shading-course/</a></li>
<li>The <em>wonderful</em> book: <em>Physically Based Rendering</em> by Pharr, Jakob, and Humphreys, currently in its third edition</li>
</ul>


            

            
        
    </body></html>