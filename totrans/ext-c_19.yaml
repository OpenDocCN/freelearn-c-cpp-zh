- en: Chapter 19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Single-Host IPC and Sockets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed the techniques by which two processes
    could operate on the same shared resource concurrently and in a synchronized fashion.
    In this chapter, we are going to expand these techniques and introduce a new category
    of methods that allow two processes to transmit data. These techniques, both those
    introduced in the previous chapter and the ones we are going to discuss in this
    chapter, are together referred to as **Inter-Process Communication** (**IPC**)
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In this and the following chapter, we are going to talk about the IPC techniques
    that, despite the methods we discussed in the previous chapter, involve a kind
    of *message passing* or *signaling* between two processes. The transmitting messages
    are not stored in any shared place like a file or a shared memory, rather they
    are emitted and received by the processes.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we cover two major topics. Firstly, we underpin the IPC techniques
    and we discuss single-host IPC and the POSIX API. Secondly, we begin to introduce
    socket programming and the surrounding topics. These topics include computer networks,
    the listener-connector model, and the sequences that exist for two processes to
    establish a connection.
  prefs: []
  type: TYPE_NORMAL
- en: 'As part of this chapter, we are going to discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Various IPC techniques. We introduce push-based and pull-based IPC techniques
    and as part of this section, we define the techniques discussed in the previous
    chapter to be pull-based IPC techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication protocols and the characteristics that a protocol usually has.
    We introduce what serialization and deserialization mean and how they contribute
    to a fully operational IPC.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File descriptors and how they play a key role in establishing an IPC channel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The exposed API for POSIX signals, POSIX pipes, and POSIX message queues are
    discussed as part of this chapter. For each technique, an example is provided
    to demonstrate the basic usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer networks and how two processes can communicate over an existing network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The listener-connector model and how two processes can establish a transport
    connection over a number of networks. This is the basis for our future discussions
    regarding socket programming.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What socket programming is and what socket objects are.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequences that exist for each of the processes participating in a listener-connector
    connection, and the API that they have to use from the POSIX socket library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first section, we are going to revisit IPC techniques.
  prefs: []
  type: TYPE_NORMAL
- en: IPC techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An IPC technique generally refers to any means that is used by processes to
    communicate and transmit data. In the previous chapter, we discussed filesystems
    and shared memory as our beginning approach to share data between two processes.
    We didn''t use the term ''IPC'' for these techniques at that point, but this is
    in fact what they are! In this chapter, we will add a few more IPC techniques
    to the ones that we have encountered already, but we should remember that they
    are different in a number of ways. Before jumping to the differences and trying
    to categorize them, let''s list some IPC techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Shared memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filesystem (both on disk and in memory)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX signals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX pipes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX message queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unix domain sockets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internet (or network) sockets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the programming point of view, the shared memory and filesystem techniques
    are similar in certain ways and because of that they can be put into the same
    group, known as *pull-based* IPC techniques. The rest of the techniques stand
    out and they have their own category. We refer to them as *push-based* IPC techniques.
    This chapter together with the next chapter are dedicated to push-based IPC, and
    various techniques are discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the IPC techniques all are responsible for transmitting a number of
    messages between two processes. Since we are going to use the term *message* heavily
    in the upcoming paragraphs, it is worth defining it first.
  prefs: []
  type: TYPE_NORMAL
- en: Every message contains a series of bytes that are put together according to
    a well-defined interface, protocol, or standard. The structure of a message should
    be known by both processes dealing with that message, and it is usually covered
    as part of a communication protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'A list of differences between pull-based and push-based techniques can be seen
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In pull-based techniques, we have a shared resource or *medium* external to
    both processes and available in the user space. Files, shared memories, and even
    a network service like an **Network Filesystem** (**NFS**) server can be the shared
    resource. These mediums are the main place holders for the messages created and
    consumed by the processes. While in push-based techniques, there is no such a
    shared resource or medium and instead, there is a *channel*. Processes send and
    receive messages through this channel, and these messages are not stored in any
    intermediate medium.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In pull-based techniques, each process must *pull* the available messages from
    the medium. In push-based techniques, the incoming messages are *pushed* (*delivered*)
    to the receiver end.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In pull-based techniques, because of having a shared resource or medium, concurrent
    access to the medium must be synchronized. That's why we explored the various
    synchronization techniques for such IPC techniques in the previous chapter. Note
    that this is not the case regarding push-based techniques and there is no synchronization
    needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In pull-based techniques, the processes can operate independently. That's because
    the messages can be stored in a shared resource and it can be fetched later. In
    other words, the processes can operate in an *async* fashion. Conversely, in a
    push-based IPC technique, both processes should be up and running at the same
    time, and because the messages are pushed instantly, the receiver process may
    lose some of the incoming messages if it's down. In other words, the processes
    operate in a *sync* fashion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In push-based techniques, we have a temporary message buffer for each process
    that holds the incoming pushed messages. This message buffer resides in the kernel
    and lives as long as the process is running. This message buffer might be accessed
    concurrently, but the synchronization must be guaranteed by the kernel itself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Messages being either transmitted in an IPC channel when using a push-based
    technique, or stored in an IPC medium when using a pull-based technique, should
    have a content that is understandable by the receiving process. This means that
    both processes – the sender end and the receiver end – must know how to create
    and parse the messages. Since messages are made up of bytes, this implies that
    both processes must know how to translate an object (a text or video) into a series
    of bytes, and how to resurrect the same object from the received bytes. We'll
    see shortly that the inter-operability of the processes is covered by a common
    *communication protocol* adapted by both of them.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we'll discuss communication protocols in greater depth.
  prefs: []
  type: TYPE_NORMAL
- en: Communication protocols
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having just a communication channel or medium is not enough. Two parties willing
    to communicate over a shared channel need to understand one another, too! A very
    simple example is when two people want to talk to each other using the same language,
    such as English or Japanese. Here, the language can be considered as the protocol
    used by two parties in order to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of IPC, processes are no exception; they need a common language
    so they can communicate. Technically, we use the term *protocol* to refer to this
    common language between any two parties. As part of this section, we are going
    to discuss communication protocols and their various characteristics such as the
    *message length* and the *message content*. Before being able to talk about these
    characteristics, we need to describe a communication protocol in a deeper sense.
    Note that our main focus in this chapter is IPC techniques; therefore, we only
    talk about communication protocols between two processes. Any kind of communication
    happening between parties other than processes cannot be covered as part of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Processes can only transmit bytes. This effectively means that every piece of
    information must be translated into a series of bytes before being transmitted
    by one of the IPC techniques. This is called *serialization* or *marshalling*.
    A paragraph of text, a piece of audio, a music track, or any other kind of object
    must be serialized before being sent over an IPC channel, or being stored in an
    IPC medium. Hence, regarding the IPC communication protocols, this means that
    the messages transmitted between processes are a series of bytes in a very specific
    and well-defined order.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, when a process receives a series of bytes from an IPC channel, it should
    be able to reconstruct the original object out of the incoming bytes. This is
    called *deserialization* or *unmarshaling*.
  prefs: []
  type: TYPE_NORMAL
- en: To explain serialization and deserialization in the same flow, when a process
    wants to send an object to another process over any already established IPC channel,
    the sender process first serializes the object into a byte array. Then it transmits
    the byte array to the other party. On the receiver side, the process deserializes
    the incoming bytes and it resurrects the sent object. As you can see, these operations
    are the inverse of each other, and they are used by both ends in order to use
    a byte-oriented IPC channel to transmit information. This is something you can't
    escape from, and every IPC-based technology (RPC, RMI, and so on) relies heavily
    on the serialization and deserialization of various objects. From now on, we use
    the term serialization to refer to both serialization and deserialization operations.
  prefs: []
  type: TYPE_NORMAL
- en: Note that serialization is not limited to push-based IPC techniques that we
    have discussed so far. In pull-based IPC techniques such as filesystem or shared
    memory, we still need serialization. That's because the underlying mediums in these
    techniques can store a series of bytes and if a process wants to store an object
    in a shared file, for instance, it has to serialize it before being able to store
    it there. Therefore, serialization is universal to all IPC techniques; no matter
    which IPC method you are using, you have to deal with a great amount of serialization
    and deserialization while using the underlying channel or medium.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a communication protocol implicitly dictates the serialization because,
    as part of a protocol, we define the order of bytes very carefully. This is crucial
    because a serialized object must be deserialized back to the same object on the
    receiver side. Therefore, both the serializer and deserializer must obey the same
    rules dictated by the protocol. Having an incompatible serializer and deserializer
    at both ends effectively means no communication at all, simply because the receiver
    end cannot reconstruct the transmitted object.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we use the term *parsing* as a synonym for *deserialization*, but
    they are in fact fundamentally different.
  prefs: []
  type: TYPE_NORMAL
- en: To make the discussion more tangible, let's talk about some real examples. A
    web server and a web client communicate using **Hyper Text Transfer Protocol**
    (**HTTP**). Therefore, both sides are required to use compatible HTTP serializers
    and deserializers to speak to each other. As another example, let's talk about
    the **Domain Name Service** (**DNS**) protocol. Both the DNS client and server
    must use compatible serializers and deserializers so that they can communicate.
    Note that unlike HTTP, which has textual content, DNS is a binary protocol. We
    discuss this shortly in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Since serialization operations can be used in various components in a software
    project, they are usually provided as some libraries that can be added to any
    component wishing to use them. For famous protocol such as HTTP, DNS, and FTP,
    there are well-known third-party libraries that can be used without hassle. But
    for custom protocols specially designed for a project, the serialization libraries
    must be written by the team itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:**'
  prefs: []
  type: TYPE_NORMAL
- en: Well-known protocols such as HTTP, FTP, and DNS are standards and they are described
    in some official open documents called **request for comments** (**RFC**). For
    example, the HTTP/1.1 protocol is described in RFC-2616\. A simple Google search
    will take you to the RFC page.
  prefs: []
  type: TYPE_NORMAL
- en: As a further note regarding *serialization libraries*, they can be provided
    in various programming languages. Note that a specific serialization itself is
    not dependent on any programming language because it only talks about the order
    of bytes and how they should be interpreted. Therefore, the serialization and
    deserialization algorithms can be developed using any programming language. That's
    a crucial requirement. In a big software project, we can have multiple components
    written in various programming languages, and there are situations in which these
    components must transmit information. Hence, we need the same serialization algorithms
    written in various languages. For instance, we have HTTP serializers written in
    C, C++, Java, Python, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: To sum up the main point of this section, we need a well-defined protocol between
    two parties in order for them to talk to each other. An IPC protocol is a standard
    that dictates how the overall communication must take place and what details must
    be obeyed regarding the byte order and their meaning in various messages. We have
    to use some serialization algorithms in order to consume a byte-oriented IPC channel
    to transmit objects.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we describe the characteristics of IPC protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol characteristics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IPC protocols have various characteristics. Briefly, every protocol can specify
    a different content type for the messages transmitted over an IPC channel. In
    another protocol, the messages can have a fixed length or a variable length. Some
    protocols dictate that the provided operations must be consumed in a synchronous
    fashion, while there are protocols that allow asynchronous usage. In the following
    sections, we will be covering these distinguishing factors. Note that the existing
    protocols can be categorized based on these characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Content type
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Messages sent over IPC channels can have *textual* content or *binary* content
    or a combination of both of them. Binary content has bytes with values ranging
    over all possible numerical values between 0 to 255\. But textual content has
    only characters that are used in text. In other words, only alphanumerical characters
    together with some symbols are allowed in textual content.
  prefs: []
  type: TYPE_NORMAL
- en: While textual content can be considered as a special case of binary content,
    we try to keep them separate and treat them differently. For instance, textual
    messages are good candidates to be compressed before sending, while binary messages
    suffer from a poor *compression ratio* (the actual size divided by the compressed
    size). It is good to know that some protocols are purely textual, such as JSON,
    and some others are fully binary, such as DNS. There are also protocols such as
    BSON and HTTP that allow message contents to be a combination of both textual
    and binary data. In these protocols, raw bytes can be mixed with text to form
    the final message.
  prefs: []
  type: TYPE_NORMAL
- en: Note that binary content can be sent as text. There are various encodings that
    allow you to represent binary content using textual characters. *Base64* is one
    of the most famous *binary-to-text encoding* algorithms that allows such a transformation.
    These encoding algorithms are widely used in purely textual protocols such as
    JSON to send binary data.
  prefs: []
  type: TYPE_NORMAL
- en: Length of messages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The messages produced according to an IPC protocol can be either *fixed-length*
    or *variable-length*. By fixed-length, we mean that all messages have the same
    length. Conversely, by variable-length, we mean that the produced messages can
    have different lengths. Receiving either fixed-length messages or variable-length
    messages have an immediate impact on the receiver side while deserializing the
    content of a message. Using a protocol that always produces fixed-length messages
    can reduce the burden of parsing receiving messages because the receiver already
    knows the number of bytes that it should read from the channel, and messages with
    the same size usually (not always) have the same structure. When reading fixed-length
    messages from an IPC channel, if all of them follow the same structure, we have
    a nice opportunity to use C structures to refer to those bytes through some already-defined
    fields, similar to what we did for objects placed in shared memories in the previous
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: With protocols that produce variable-length messages, finding where an individual
    message ends is not that easy, and the receiver side somehow (which we explain
    shortly) should decide whether it has read a complete message or more bytes must
    be read from the channel. Note that the receiver might read multiple chunks from
    the channel before reading a complete message, and a single chunk may contain
    data from two adjacent messages. We will see an example of this in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since most protocols are variable-length and you usually don''t have the luxury
    of dealing with fixed-length messages, it is worth discussing the methods that
    various protocols adopt to make their variable-length messages distinguishable
    or separable. In other words, these protocols use a mechanism to mark the end
    of a message and, this way, the receiver can use those marks to indicate that
    it has read a complete message. Next, you can see some of these methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using a delimiter or a separator**: A delimiter or separator is a series
    of bytes (in binary messages) or characters (in textual messages) that indicates
    the end of a message. The delimiter should be chosen depending on the content
    of the messages, because it should be easily distinguishable from the actual content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Length-prefix framing**: In these protocols, each message has a fixed-length
    prefix (usually 4 bytes or even more) that carries the number of bytes that should
    be read by the receiver in order to have a complete message. Various protocols
    such as all **Tag-Value-Length** (**TLV**) protocols, with **Abstract Syntax Notation**
    (**ASN**) as an example, use this technique.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using a finite-state machine**: These protocols follow a *regular grammar*
    that can be modeled by a *finite-state machine*. The receiver side should be aware
    of the grammar of the protocol, and it should use a proper deserializer that works
    based on a finite-state machine to read a complete message from the IPC channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequentiality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most protocols, we have a *conversation* happening between two processes
    that follows a *request-response* scheme. One of the parties sends a request and
    the other side replies. This scheme is usually used in client-server scenarios.
    The listener process, often the server process, waits for a message, and when
    the message is received, it replies accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: If the protocol is synchronous or sequential, the sender (client) will wait
    until the listener (server) completes the request and sends back the reply. In
    other words, the sender stays in a *blocking* state until the listener replies.
    In an asynchronous protocol, the sender process isn't blocked, and it can continue
    with another task while the request is being processed by the listener. That is,
    the sender won't get blocked while the reply is being prepared.
  prefs: []
  type: TYPE_NORMAL
- en: In an asynchronous protocol, there should be a *pulling* or *pushing* mechanism
    in place, which allows the sender to check for the reply. In a pulling scenario,
    the sender will regularly ask the listener about the result. In a pushing scenario,
    the listener will push back the reply to the sender via the same or a different
    communication channel.
  prefs: []
  type: TYPE_NORMAL
- en: The sequentiality of a protocol is not limited to request-response scenarios.
    Messaging applications usually use this technique to have the maximum responsiveness
    both on the server-side and on the client-side.
  prefs: []
  type: TYPE_NORMAL
- en: Single-host communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to talk about single-host IPC. Multiple-host
    IPC will be the subject of our discussion in the next chapter. There are four
    main techniques that can be used by processes to communicate when they reside
    on the same machine:'
  prefs: []
  type: TYPE_NORMAL
- en: POSIX signals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX pipes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX message queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unix domain sockets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POSIX signals, unlike the other preceding techniques, don't create a communication
    channel between the processes, but can be used as a way to notify a process about
    an event. In certain scenarios, such signals can be used by processes to notify
    each other about specific events in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Before jumping to the first IPC technique, POSIX signals, let's discuss file
    descriptors. Other than POSIX signals, no matter which IPC technique you use,
    you will be dealing with file descriptors of some sort. Therefore, we'll now dedicate
    a separate section to them and discuss them further.
  prefs: []
  type: TYPE_NORMAL
- en: File descriptors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two communicating processes can be running either on the same machine or on
    two different machines connected by a computer network. In this section and much
    of this chapter, our focus is on the first case, in which processes reside on
    the same machine. That's where file descriptors become immensely important. Note
    that in multiple-host IPC we will still be dealing with file descriptors, but
    they are called *sockets* there. We will discuss them thoroughly in the upcoming chapter.
  prefs: []
  type: TYPE_NORMAL
- en: A file descriptor is an abstract handle to an object within the system that
    can be used to read and write data. As you can see, despite the name, file descriptors
    can refer to a wide range of available mechanisms that deal with reading and modifying
    byte streams.
  prefs: []
  type: TYPE_NORMAL
- en: Regular files are certainly among the objects that can be referred to by file
    descriptors. Such files are located on filesystems, either on a hard disk or in
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: Other things that can be referred to and accessed via file descriptors are devices.
    As we saw in *Chapter 10*, *Unix - History and Architecture*, each device can
    be accessed using a device file, which is usually found in the `/dev` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding push-based IPC techniques, a file descriptor can represent an IPC
    channel. In this case, the file descriptor can be used to read and write data
    from and to the represented channel. That's why the first step in setting up an
    IPC channel is to define a number of file descriptors.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know more about file descriptors and what they represent, we can
    move on and discuss the first IPC technique that can be used in single-host multi-process
    system; however, POSIX signals don't use file descriptors. You are going to hear
    more about file descriptors in the future sections dedicated to POSIX pipes and
    POSIX message queues. Let's begin with POSIX signals.
  prefs: []
  type: TYPE_NORMAL
- en: POSIX signals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In POSIX systems, processes and threads can send and receive a number of predefined
    signals. A signal can be sent either by a process, or a thread, or by the kernel
    itself. Signals are actually meant to notify a process or a thread about an event
    or error. For example, when the system is going to be rebooted, the system sends
    a `SIGTERM` signal to all processes to let them know that a rebooting is in progress
    and they must immediately quit. Once a process receives this signal, it should
    react accordingly. In some cases, nothing should be done, but in some cases, the
    current state of the process should be persisted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the available signals in a Linux system. The table
    is extracted from the Linux signals [manual page that can be found at http://www.man7.org/](http://www.man7.org/linux/man-pages/man7/signal.7.html)linux/man-pages/man7/signal.7.html:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Table 19-1: List of all available signals in a Linux system'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the preceding table, not all of the signals are POSIX, and
    Linux has got its own signals. While most of the signals correspond to well-known
    events, there are two POSIX signals that can be defined by the user. This is mostly
    used in scenarios when you want to invoke a certain functionality in your program
    while the process is running. *Example 19.1* demonstrates how to use signals and
    how they can be handled in a C program. Next, you can find the code for *example
    19.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 19-1 [ExtremeC_examples_chapter19_1.c]: Handling POSIX signals'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we have used the `signal` function to assign various
    signal handlers to some specific signals. As you can see, we have one signal handler
    for the user-defined signals, one handler for the `SIGINT` signal, and one for
    the `SIGKILL` signal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The program is merely a never-ending loop, and all we want to do is to handle
    some signals. The following commands show how to compile and run the example in
    the background:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-1: Compiling and running example 19.1'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know the PID of the program, we can send it some signals. The PID
    is 4598 and the program is running in the background. Note that the PID will be
    different for you. You can use the `kill` command to send a signal to a process.
    The following command is used to examine the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-2: Sending different signals to the background process'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the program handles all signals except the `SIGKILL` signal.
    `SIGKILL` cannot be handled by any process and, usually, a parent process that
    has spawned the process can be notified about its child being killed.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `SIGINT` signal, or the interrupt signal, can be sent to a foreground
    program by pressing `Ctrl` + `C`. Therefore, whenever you press this combination
    of keys, you are actually sending an interrupt signal to the running program.
    The default handler just stops the program, but as you can see in the preceding
    example, we can handle the `SIGINT` signal and ignore it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the ability to send a signal to a process using shell commands,
    a process also can send a signal to another process if it knows the target process''s
    PID. You can use the `kill` function (declared in `signal.h`), which does exactly
    the same as its command-line version. It accepts two parameters: the first is
    the target PID and the second is the signal number. It is also possible for a
    process or a thread to use the `kill` or `raise` functions to send a signal to
    itself. Note that the `raise` function sends the signal to the current thread.
    These functions can be quite useful in scenarios in which you want to notify another
    part of your program about an event.'
  prefs: []
  type: TYPE_NORMAL
- en: The last note about the preceding example is that, as you saw in *Shell Box
    19-2*, it doesn't matter that the main thread is busy with the never-ending loop,
    the signals are delivered asynchronously. Therefore, you can be sure that you
    always receive the incoming signals.
  prefs: []
  type: TYPE_NORMAL
- en: Now it's time to talk about POSIX pipes as another single-host IPC technique
    that can be useful in certain circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: POSIX pipes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'POSIX Pipes in Unix are unidirectional channels that can be used between two
    processes that need to exchange messages. Upon creating a POSIX pipe, you will
    get two file descriptors. One file descriptor is used to write to the pipe, and
    the other one is used to read from the pipe. The following example shows the basic
    usage of a POSIX pipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 19-2 [ExtremeC_examples_chapter19_2.c]: Example 19.2 on using a POSIX
    pipe'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, in the second line of the `main` function, we have used the
    `pipe` function. As we've already said, it accepts an array of two file descriptors
    and opens two file descriptors, one for reading from the pipe and the other one
    for writing to it. The first file descriptor, found at index 0, should be used
    for reading; and the second file descriptor, located at index 1, should be used
    for writing to the pipe.
  prefs: []
  type: TYPE_NORMAL
- en: In order to have two processes, we have used the fork API. As we've explained
    in *Chapter 17*, *Process Execution*, the fork API clones the parent process and
    creates a new child process. Therefore, the opened file descriptors are available
    to the child process after calling the `fork` function.
  prefs: []
  type: TYPE_NORMAL
- en: When the child process is spawned, the parent process enters the `else` block
    and the child process enters the `if` block. Firstly, each process should close
    the file descriptor that it is not going to use. In this example, the parent wants
    to read from the pipe and the child wants to write to the pipe. That's why the
    parent process closes the second file descriptor (the write file descriptor) and
    the child process closes the first file descriptor (the read file descriptor).
    Note that a pipe is unidirectional and reverse communication is not possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following shell box shows the output of the preceding example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-3: Output of running example 19.2'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Code Box 19-2*, for reading and writing operations we use
    the `read` and `write` functions. As we mentioned before, in push-based IPC, a
    file descriptor refers to a byte channel, and when you have a file descriptor
    pointing to a channel, you can use the file descriptor's related functions. The
    `read` and `write` functions accept a file descriptor and no matter what kind
    of IPC channel is behind, they operate on the underlying channel the same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous example, we used the fork API to spawn a new process. If a
    situation arises in which we have two different processes spawned separately,
    the question is, how can they communicate through a shared pipe? If a process
    demands access to a pipe object within the system, it should have the corresponding
    file descriptor. There are two options available:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the processes should set up the pipe and transfer the corresponding file
    descriptors to the other process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The processes should use a named pipe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first scenario, the processes must use a Unix domain socket channel in
    order to exchange file descriptors. The problem is that if such a channel exists
    between the two processes, they could use it for further communication and there
    would be no need to set up another channel (POSIX pipe) that has a less friendly
    API than Unix domain sockets.
  prefs: []
  type: TYPE_NORMAL
- en: The second scenario seems to be more promising. One of the processes could use
    the `mkfifo` function and create a queue file by providing a path. Then, the second
    process could use the path to the already created file and open it for further
    communication. Note that the channel is still unidirectional and, depending on
    the scenario, one of the processes should open the file in read-only mode and
    the other should open it in write-only mode.
  prefs: []
  type: TYPE_NORMAL
- en: One more point should be discussed about the previous example. As you can see,
    the child process waits for 2 seconds before writing to the pipe. In the meantime,
    the parent process is blocked on the `read` function. So, while there is no message
    written to the pipe, the process reading from the pipe becomes blocked.
  prefs: []
  type: TYPE_NORMAL
- en: As the final note in this section, we know that POSIX pipes are push-based.
    As we've explained this before, push-based IPC techniques have a corresponding
    temporary kernel buffer for holding the incoming pushed messages. POSIX pipes
    are no exception and the kernel holds the written messages until they are read.
    Note that if the owner process quits, the pipe object and its corresponding kernel
    buffer are destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will discuss POSIX message queues.
  prefs: []
  type: TYPE_NORMAL
- en: POSIX message queues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kernel-hosted message queues are part of the POSIX standard. They differ significantly
    from POSIX pipes in a number of ways. Here, we examine the fundamental differences:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The elements inside a pipe are bytes. Instead, message queues hold messages.
    Pipes are not aware of any existing structure in the written bytes, while message
    queues keep actual messages and each call to the `write` function results in a
    new message being added to the queue. Message queues preserve the boundaries between
    written messages. To elaborate more on this, suppose that we have three messages:
    the first one has 10 bytes, the second one has 20 bytes, and the third one has
    30 bytes. We write these messages both to a POSIX pipe and to a POSIX message
    queue. The pipe only knows that it has 60 bytes inside, and it allows a program
    to read 15 bytes. But the message queue only knows that it has 3 messages and
    it doesn''t allow a program to read 15 bytes because we don''t have any messages
    with 15 bytes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pipes have a maximum size, the unit of which is the number of bytes. Message
    queues instead have a maximum number of messages. In message queues, every message
    has a maximum size in terms of bytes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every message queue, like a named shared memory or a named semaphore, opens
    a file. While these files are not regular files, they can be used by future processes
    to access the same message queue instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Message queues can be prioritized, while pipes don't care about the priority
    of bytes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And they have the following properties in common:'
  prefs: []
  type: TYPE_NORMAL
- en: Both are unidirectional. In order to have bidirectional communication, you need
    to create two instances of pipes or queues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both have limited capacity; you cannot write any number of bytes or messages
    that you want.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both are represented using file descriptors in most POSIX systems; therefore,
    I/O functions such as `read` and `write` can be used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both techniques are *connection-less*. In other words, if two different processes
    write two different messages, it is possible for one of them to read the other
    process's message. In other words, there is no ownership defined for the messages
    and any process can read them. This would be a problem, especially when there
    is more than one process operating on the same pipe or message queue concurrently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: POSIX message queues explained in this chapter should not be confused with message
    queue brokers being used in the **Message Queue Middleware** (**MQM**) architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various resources on the internet that explain POSIX message queues.
    The following link explains POSIX message queues specifically for the QNX operating
    system, but most of the content is still applicable to other POSIX systems: https://users.pja.edu.pl/~jms/qnx/help/watcom/clibref/mq_overview.html.'
  prefs: []
  type: TYPE_NORMAL
- en: Now it is time to have an example. *Example 16.3* has the same scenario as we
    had in *example 16.2*, but it uses a POSIX message queue instead of a POSIX pipe.
    All the functions related to POSIX message queues are declared in the `mqueue.h`
    header file. We will explain some of them shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the following code doesn''t compile on macOS because OS/X doesn''t
    support POSIX message queues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Code Box 19-3 [ExtremeC_examples_chapter19_3.c]: Example 19.3 on using a POSIX
    message queues'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to compile the preceding code, run the following commands. Note that
    the preceding code should be linked with the `rt` library on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-4: Building example 19.3 on Linux'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following shell box demonstrates the output of *example 19.3*. As you can
    see, the output is exactly the same as we had for *example 19.2* but it uses POSIX
    message queues to perform the same logic that we wrote in *example 19.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-5: Running example 19.3 on Linux'
  prefs: []
  type: TYPE_NORMAL
- en: Note that both POSIX pipes and message queues have a limited buffer in the kernel.
    Therefore, writing to pipes and message queues without having a consumer that
    reads their content can lead to all write operations being blocked. In other words,
    any `write` function call would remain blocked until a consumer reads a message
    from the message queue or some bytes from the pipe.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will briefly explain Unix domain sockets. They
    are usually the first choice when connecting two local processes in a single-host
    setup.
  prefs: []
  type: TYPE_NORMAL
- en: Unix domain sockets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another technique that can be used by a number of processes to communicate in
    a single-host deployment is using Unix domain sockets. They are special kind of
    sockets that only operate within the same machine. Therefore, they are different
    from network sockets, which allow two processes from two different machines to
    talk to each other over an existing network. Unix domain sockets have various
    characteristics that make them important and sophisticated in comparison to POSIX
    pipes and POSIX message queues. The most important characteristic is the fact
    that Unix domain sockets are bidirectional. Therefore, a single socket object
    is enough to read from and write to the underlying channel. In other words, the
    channels operated by Unix domain sockets are full-duplex. In addition, Unix domain
    sockets can be both *session-aware* and *message-aware*. This makes them even
    more flexible. We will discuss session-awareness and message-awareness in the
    following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Since Unix domain sockets cannot be discussed without knowing the basics of
    socket programming, we won't go any further than this in this chapter. Instead,
    in the following sections, we introduce socket programming and the concepts around
    it. A full discussion regarding Unix domain sockets will be given in the following
    chapter. Let's begin with socket programming.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to socket programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As part of this chapter, we decided to discuss socket programming before going
    through the real C code examples as part of the next chapter. That's because there
    are some fundamental concepts that you need to know before jumping to the code.
  prefs: []
  type: TYPE_NORMAL
- en: Socket programming can be done both on single-host and multi-host deployments.
    As you might have guessed, the socket programming in a single-host system is done
    through Unix domain sockets. In a multi-host setup, socket programming is about
    creating and using network sockets. Both Unix sockets and network sockets more
    or less use the same API and share the same concepts, so it would make sense to
    cover them together in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key concepts before using network sockets is how computer networks
    work. In the following section, we are going to talk about this and introduce
    you to computer networks. There are many terms and concepts that you should know
    before being able to write your first socket programming example.
  prefs: []
  type: TYPE_NORMAL
- en: Computer networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The approach we take to explain the networking concepts in this section is different
    from the usual texts you might find about this topic. Our goal is to create a
    basic understanding of how things work in a computer network, especially between
    two processes. We want to look at this concept from a programmer's point of view.
    And the main actors in our discussion are processes, not computers. Therefore,
    you might find the order of sections a bit odd at first, but it will help you
    to get the idea of how IPC works over a computer network.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this section shouldn't be considered a complete description of computer
    networks and, of course, it cannot be done in a few pages and in just one section.
  prefs: []
  type: TYPE_NORMAL
- en: Physical layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, let's forget about processes and just consider the computers, or simply
    the machines. Before moving forward, note that we use various terms to refer to
    a computer in a network. We can call it a computer, machine, host, node, or even
    a system. Of course, the context helps you to find out the true meaning behind
    a given term.
  prefs: []
  type: TYPE_NORMAL
- en: The first step toward having multi-host software is a number of computers that
    are connected together through a network or, more precisely, a computer network.
    For now, let's focus on two computers that we want to connect. In order to connect
    these two physical machines to one other, we certainly need some sort of physical
    medium such as a piece of wire or a wireless setup.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, without such a physical medium (which doesn't need to be visible,
    like in a wireless network), the connection would not be possible. These physical
    connections are analogous to roads between cities. We will stick to this analogy
    because it can explain what is happening inside a computer network very closely.
  prefs: []
  type: TYPE_NORMAL
- en: All the hardware equipment required to connect two machines physically are considered
    to be part of the *physical layer*. This is the first and the most basic layer
    that we explore. Without having this layer, it is impossible to transmit data
    between two computers and assume them to be connected. Everything above this layer
    is not physical and all you find is a set of various standards regarding how the
    data should be transmitted.
  prefs: []
  type: TYPE_NORMAL
- en: Let's talk about the next layer, the link layer.
  prefs: []
  type: TYPE_NORMAL
- en: Link layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While merely having roads is not sufficient for traffic to move along them,
    the same is true for the physical connections between computers. In order to use
    roads, we need laws and regulations about the vehicles, signs, materials, borders,
    speed, lanes, directions, and so on, and without them, traveling along the roads
    would be chaotic and problematic. Similar rules are needed for direct physical
    connections between two computers.
  prefs: []
  type: TYPE_NORMAL
- en: While the physical components and devices required to connect a number of computers
    all belong to the physical layer, the mandatory regulations and protocols that
    govern the way data is transmitted along the physical layer all belong to an upper
    layer called the *link layer*.
  prefs: []
  type: TYPE_NORMAL
- en: As part of the regulations enforced by the link protocols, messages should be
    broken into pieces called *frames*. This is analogous to the regulations in a
    road system that defines a maximum length of the vehicles traveling on a certain
    road. You cannot drive a 1 km-long trailer (presuming that it is physically possible)
    on a road. You have to break it down into smaller segments, or into smaller vehicles.
    Similarly, a long piece of data should be broken into multiple frames, and each
    frame must be traveling along the network freely, independent of the other frames.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth mentioning that networks can exist between any two computational
    devices. They don't necessarily need to be computers. There are many devices and
    machines in industry that can be connected to each other to form a network. Industrial
    networks have their own standards for their physical wiring, connectors, terminators,
    and so on, and they have their own link protocols and standards.
  prefs: []
  type: TYPE_NORMAL
- en: Many standards describe such link connections, for instance, how a desktop computer
    can get connected to an industrial machine. One of the most prominent link protocols
    that is designed to connect a number of computers via a wire is *Ethernet*. Ethernet
    describes all the rules and regulations governing data transmission over computer
    networks. We have another widely used link protocol called IEEE 802.11, which
    governs wireless networks.
  prefs: []
  type: TYPE_NORMAL
- en: A network consisting of computers (or any other groups of homogenous computing
    machines or devices) connected by a physical connection via a specific link protocol
    is called a **Local Area Network** (**LAN**). Note that any device willing to
    join a LAN must use a physical component called a *network adapter* or a **Network
    Interface Controller** (**NIC**) attached to it. For instance, the computers wanting
    to join an Ethernet network must have an *Ethernet NIC*.
  prefs: []
  type: TYPE_NORMAL
- en: A computer can have multiple NICs attached. Each NIC can connect to a specific
    LAN, therefore a computer with three NICs is able to connect to three different
    LANs simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible that it uses all its three NICs to connect to the same LAN.
    The way that you configure NICs and how you connect computers to various LANs
    should be designed beforehand and a precise plan should be in place.
  prefs: []
  type: TYPE_NORMAL
- en: Every NIC has a specific and unique address defined by the governing link protocol.
    This address will be used for data transmission between the nodes inside a LAN.
    The Ethernet and IEEE 802.11 protocols define a **media access control** (**MAC**)
    address for every compatible NIC. Therefore, any Ethernet NIC or IEEE 802.11 Wi-Fi
    adapter should have a unique MAC address in order to join a compatible LAN. Inside
    a LAN, the assigned MAC addresses should be unique. Note that ideally, any MAC
    address should be unique universally and unchangeable. However, this is not the
    case, and you can even set the MAC address of a NIC.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize what we have explained so far, we have a stack of two layers, the
    physical layer beneath and the link layer above. This is enough to connect a number
    of computers on a single LAN. But it doesn't end here. We need another layer on
    top of these two layers to be able to connect computers from various LANs with
    or without any intermediate LANs in between.
  prefs: []
  type: TYPE_NORMAL
- en: Network layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we've seen that MAC addresses are used in Ethernet LANs in order to
    connect a number of nodes. But what happens if two computers from two different
    LANs need to connect to each other? Note that these LAN networks are not necessarily
    compatible.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, one of the LANs could be a wired Ethernet network, while the other
    one could be a **fiber distributed data interface** (**FDDI**) network mainly
    using fiber optic as the physical layer. Another example is industrial machines
    connected to an **Industrial Ethernet** (**IE**) LAN that need to connect to operators'
    computers, which are on an ordinary Ethernet LAN. These examples and many more
    show that we need another layer on top of the aforementioned protocols in order
    to connect various nodes from different LANs. Note that we even need this third
    layer in order to connect compatible LANs. This would be even more crucial if
    we are going to transmit data from one LAN to another (compatible or heterogeneous)
    through a number of intermediate LANs. We explain this further in the upcoming
    paragraphs.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the frames in the link layer, we have *packets* in the *network layer*.
    Long messages are broken into smaller pieces called packets. While frames and
    packets are referring to two different concepts in two different layers, for simplicity,
    we consider them the same and we stick to the term *packet* for the rest of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: As a key difference, you should know that frames encapsulate packets, in other
    words, a frame contains a packet. We won't go any deeper regarding frames and
    packets, but you can find numerous sources on the internet that describe various
    aspects of these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *network protocol* fills the gap between various LANs in order to connect
    them to each other. While each LAN can have its own specific physical layer and
    its own specific link layer standards and protocols, the governing network protocol
    should be the same for all of them. Otherwise, heterogeneous (not compatible)
    LANs cannot connect to each other. The most famous network protocol at the moment
    is the **Internet Protocol** (**IP**). It is extensively used in large computer
    networks that usually consist of smaller Ethernet or Wi-Fi LANs. IP has two versions
    based on the length of its addresses: IPv4 and IPv6.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But how can two computers from two different LANs be connected? The answer
    lies in the *routing* mechanism. In order to receive data from an external LAN,
    there should be a *router* node. Suppose that we are going to connect two different
    LANs: LAN1 and LAN2\. A router is simply another node that resides in both networks
    by having two NICs. One NIC is in LAN1 and the other one is in LAN2\. Then, a
    special routing algorithm decides which packets to transfer and how they should
    be transferred between networks.'
  prefs: []
  type: TYPE_NORMAL
- en: With the routing mechanism, multiple networks can have a bidirectional flow
    of data through the router nodes. For this to happen, within every LAN there should
    be a router node. Therefore, when you want to send data to a computer located
    in a different geographical zone, it could be that your data is being transmitted
    through tens of routers before hitting its target. I'm not going to go any further
    than this into the routing concept, but there are tons of great information about
    this mechanism on the web.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a utility program called *traceroute* that allows you to see the routers
    between your computer and the target computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, two hosts from two different LANs can be connected to each other,
    with or without having intermediate LANs in between. Any further effort to make
    more specific connections should be done on top of this layer. Therefore, any
    communication happening between two programs, residing on two different nodes,
    must take place on top of a stack of three layers of protocols: the physical layer,
    the link layer, and finally the network layer. But what does it exactly mean when
    we say that two computers are connected to each other?'
  prefs: []
  type: TYPE_NORMAL
- en: It is a bit vague to say that two nodes are connected, at least for programmers.
    To be more precise, the operating systems of these nodes are connected to each
    other, and they are the actors who transmit data. The ability to join a network
    and talk to other nodes in the same LAN or in a different LAN is intrinsically
    encoded in most current operating systems. Unix-based operating systems, which
    are our main focus in this book, are all operating systems that support networking,
    and they can be installed on the nodes participating in a network.
  prefs: []
  type: TYPE_NORMAL
- en: Linux, Microsoft Windows, and almost any modern operating system supports networking.
    Indeed, it is unlikely that an operating system could survive if it could not
    operate in a network. Note that it is the kernel, or to be precise a unit within
    the kernel, that manages network connections and, therefore, it is more exact
    to say that the actual networking functionality is provided by the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Since the networking functionality is provided by the kernel, any process in
    the user space can benefit from that, and it can get connected to another process
    residing on a different node within the network. As a programmer, you don't need
    to worry about the layers (physical, link, and network layers) operated by the
    kernel, and you can focus on the layers above them, those that relate to your
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every node in an IP network has an IP address. Like we said before, we have
    two versions of IP addresses: **IP version 4** (**IPv4**) and **IP version 6**
    (**IPv6**). An IPv4 address consists of four segments, each of which can hold
    a numerical value between 0 and 255\. Therefore, IPv4 addresses start from `0.0.0.0`
    and go up to `255.255.255.255`. As you can see, we only need 4 bytes (or 32 bits)
    in order to store an IPv4 address. For IPv6 addresses, this goes up to 16 bytes
    (or 128 bits). Also, we have private and public IP addresses, but the details
    are way beyond the subject of this chapter. It''s sufficient for us to know that
    every node in an IP network has a unique IP address.'
  prefs: []
  type: TYPE_NORMAL
- en: Building on the previous section, in a single LAN, every node has a link layer
    address together with an IP address, but we will use the IP address to make connections
    to that node and not the link layer address. As an example, in an Ethernet LAN,
    every node has two addresses; one is a MAC address and the other one is an IP
    address. The MAC address is used by the link layer protocols to transmit data
    within the LAN, and the IP address is used by the programs residing on various
    nodes to make network connections either within the same LAN or over a number
    of LANs.
  prefs: []
  type: TYPE_NORMAL
- en: The main functionality of the network layer is to connect two or more LANs.
    This will eventually lead to a big mesh of networks that are connected to each
    other, and they form a giant network with many individual LAN networks within
    it. In fact, such a network exists, and we know it as the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Like any other network, every node that is accessible on the internet must have
    an IP address. But the main difference between a node that is accessible on the
    internet and a node that is not is that an internet node must have a public IP
    address, while a node that is not accessible through the internet usually has
    a private address.
  prefs: []
  type: TYPE_NORMAL
- en: To give an example, your home network might be connected to the internet, but
    an external node on the internet cannot get connected to your laptop because your
    laptop has a private IP address and not a public IP address. While your laptop
    is still accessible inside your home network, it is not available on the internet.
    Therefore, if your software is going to be available on the internet, it should
    be run on a machine that has a public IP address.
  prefs: []
  type: TYPE_NORMAL
- en: There is a tremendous amount of information about IP networking, and we are not
    going to cover all of it, but as a programmer it is important to know the difference
    between private and public addresses.
  prefs: []
  type: TYPE_NORMAL
- en: While in a network, ensuring the connectivity between the nodes is not the programmer's
    responsibility; it is considered part of your skillset to be able to detect network
    defects. This is very important because it can let you know whether a bug or misbehavior
    has roots in your code, or it is an infrastructure (or network) issue. That's
    why we have to touch on some more concepts and tools here.
  prefs: []
  type: TYPE_NORMAL
- en: The basic tool that guarantees that two hosts (nodes), either in the same LAN
    or located on different LANs, are capable of transmitting data, or that they can
    "see" each other, is the *ping* tool. You may already know of it. It sends a number
    of **Internet Control Message Protocol** (**ICMP**) packets that, if a reply is
    sent back, means that the other host is up, connected, and responding.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: ICMP is another network layer protocol that is mainly used for monitoring and
    management of IP-based networks in case of connectivity or quality of service
    issues and failures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you are going to check whether your computer can see the public IP
    address `8.8.8.8` (which it should if it is connected to the internet). The following
    commands will help you to check the connectivity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Shell Box 19-6: Using the ping utility to check the connectivity to the internet'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the output, it says that it has sent 7 ICMP ping packets and
    none of them have been lost during transmission. This means that the operating
    system behind the IP address `8.8.8.8` is up and responsive.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The public IP address `8.8.8.8` refers to the Google Public DNS service. More
    can be read here: https://en.wikipedia.org/wiki/Google_Public_DNS.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we explained how two computers can get connected via a network.
    Now, we are getting close to the point where two processes can actually get connected
    to each other and transmit data over a number of LANs. For this purpose, we need
    another layer on top of the network layer. That's where network programming begins.
  prefs: []
  type: TYPE_NORMAL
- en: Transport layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, we have seen that two computers can get connected to each other via
    a stack of three layers: the physical layer, the link layer, and the network layer.
    For inter-process communication, we actually need two processes to be connected
    and talking to each other. But with two computers connected through these three
    layers, we can have many processes running on each of them, and any process running
    on the first machine might want to establish a connection with another process
    located on the second machine. Therefore, having a connection just based on the
    network layer is too general to support several distinct connections initiated
    by various processes.'
  prefs: []
  type: TYPE_NORMAL
- en: That's why we need another layer on top of the network layer. The *transport
    layer* is there to address this need. While hosts are connected through the network
    layer, the processes running on those hosts can get connected through the transport
    layer established on top of the network layer. Like any other layer that has its
    own unique identifiers or unique addresses, this layer has a new concept as its
    unique identifier, usually known as a *port*. We will elaborate more on this in
    the upcoming sections, but before that, we have to explain the *listener-connector*
    model, which allows two parties to communicate over a channel. In the next section,
    we start to explain this model by giving an analogy between computer networks
    and telephone networks.
  prefs: []
  type: TYPE_NORMAL
- en: Analogy of telephone networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The best example to start with is the **Public Switched Telephone Network**
    (or **PSTN**). While the similarity between computer networks and telephone networks
    might not seem very promising, there are strong similarities that allow us to
    explain the transport layer in a sensible fashion.
  prefs: []
  type: TYPE_NORMAL
- en: In our analogy, the people using the telephone network are like processes in
    a computer network. Therefore, a telephone call is equivalent to a *transport
    connection*. The people are able to make calls only if the necessary infrastructure
    has been installed. This is analogous to the networking infrastructure that should
    be in place in order to enable processes to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: We suppose that the required underlying infrastructure is in place and it works
    perfectly and, based on that, we want to have two entities residing in these systems
    to make a channel and transmit data. This is analogous to two people in the PSTN
    and two processes residing on two different hosts in a computer network.
  prefs: []
  type: TYPE_NORMAL
- en: Anyone who wants to use PSTN needs to have a telephone device. This is analogous
    to the requirement of having a NIC for a computer node. On top of these devices,
    there are multiple layers consisting of various protocols. These layers building
    up the underlying infrastructure make the creation of a transport channel possible.
  prefs: []
  type: TYPE_NORMAL
- en: Now, in PSTN, one of the telephone devices that is connected to the PSTN waits
    until it receives a call. We call this the *listener* side. Note that a telephone
    device plugged into the PSTN always waits for a call signal from the network and,
    as soon as it receives the signal, it rings.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's talk about the other side, which makes the call. Note that making
    a call is equivalent to creating a transport channel. The other side also has
    a telephone device that is used to make a call. The listener is accessible through
    a telephone number, which can be thought of as the address of the listener. The
    *connector* side must know this telephone number in order to make the call. Therefore,
    the connector dials the listener's telephone number and the underlying infrastructure
    lets the listener know that there is an incoming call.
  prefs: []
  type: TYPE_NORMAL
- en: When the listener side answers the telephone, it accepts the incoming connection
    and a channel is established between the listener and the connector. From now
    on, it is up to the people sitting at each end to talk and continue the discussion
    over the created PSTN channel. Note that if one of the parties cannot understand
    the language of the other party, the communication cannot continue and one of
    the parties hangs up the phone, and the channel would be destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: Connection-less versus connection-oriented transport communication
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The preceding analogy tries to explain the transport communication in a computer
    network but, in fact, it describes *connection-oriented communication*. Here,
    we are going to introduce and describe another type of communication: *connection-less
    communication*. But before that, let''s have a deeper look at connection-oriented
    communication.'
  prefs: []
  type: TYPE_NORMAL
- en: In connection-oriented communication, a specific and dedicated channel is created
    for a connector. Therefore, if we have one listener communicating with three connectors,
    we have three dedicated channels. It doesn't matter how big the transmitting message
    is, the message will reach the other party in the correct form without any loss
    inside the channel. If multiple messages are sent to the same location, the order
    of the sent messages is preserved, and the receiving process won't notice any
    disturbances in the underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: As we've explained in the previous sections, any message is always broken into
    smaller chunks called packets while being transmitted over a computer network.
    In a connection-oriented scheme however, none of the parties, neither the listener
    nor the connector, will notice anything about the underlying *packet switching*.
    Even if the sent packets are received in a different order, the receiver's operating
    system will rearrange the packets in order to reconstruct the message in its true
    form, and the receiver process won't notice anything.
  prefs: []
  type: TYPE_NORMAL
- en: More than that, if one of the packets gets lost while being transmitted, the
    receiver's operating system will request it again in order to revive the full
    message. As an example, **Transport Control Protocol** (**TCP**) is a transport
    layer protocol that behaves exactly as we have explained above. Therefore, TCP channels
    are connection-oriented.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with connection-oriented channels, we also have connection-less communication.
    In connection-oriented communication, we guarantee two factors: the *delivery*
    of the individual packets, and the *sequence* of the packets. A connection-oriented
    transport protocol such as TCP preserves these factors at the same time. Conversely,
    a connection-less transport protocol doesn''t guarantee them.'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, you might have no guarantee for the delivery of the individual
    packets that the message is broken into, or you might not have a guarantee that
    all the packets will be in the correct order. Or you might not have both! For
    instance, the **User Datagram Protocol** (**UDP**) doesn't guarantee packet delivery
    or the order of the packets. Note that the guarantee of the correctness of contents
    of an individual packet is provided by the protocol in the network layer and the
    link layer.
  prefs: []
  type: TYPE_NORMAL
- en: Now it's time to explain two terms that are commonly used in network programming.
    The *stream* is the sequence of bytes that is transmitted over a connection-oriented
    channel. This means that connection-less transmission effectively doesn't offer
    a stream of data. We have a specific term for a unit of data being transmitted
    over a connection-less channel. We call it a *datagram*. A datagram is a piece
    of data that can be delivered as a whole in a connection-less channel. Any piece
    of data bigger than the maximum datagram size cannot be surely delivered or the
    final sequence might be wrong. Datagram is a concept defined in the transport
    layer, and it is the counterpart concept to packet in the network layer.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, regarding UDP packets, it is guaranteed that every individual
    UDP datagram (packet) is transmitted correctly, but nothing more can be said about
    the correlation between two adjacent datagrams (packets). It is accepted that
    no integrity should exist beyond a UDP datagram, but this is not true of TCP.
    In TCP, because of the guarantee of delivery and preserving the sequence of the
    sent packets, we can put individual packets aside and look at it as a stream of
    bytes being transmitted between two processes.
  prefs: []
  type: TYPE_NORMAL
- en: Transport initialization sequences
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this subsection, we are going to talk about the steps that each process takes
    in order to establish a transport communication. We have different sequences for
    connection-oriented and connection-less schemes, so we are going to talk about
    them in two following subsections separately. Note that the difference appears
    only in the initialization of the channel, and after that, both sides will use
    more or less the same API in order to read from and write to the created channel.
  prefs: []
  type: TYPE_NORMAL
- en: The listener process always *binds* an endpoint (usually an IP address together
    with a port) and the connector process always *connects* to that endpoint. This
    is regardless of being a connection-oriented or a connection-less channel.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the following sequences, we have assumed that there is an IP network
    established between the computers hosting the listener and connector processes.
  prefs: []
  type: TYPE_NORMAL
- en: Connection-less initialization sequences
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to establish a connection-less communication channel, the listener
    process will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The listener process binds a port on one of existing NICs, or even all of them.
    This means that the listener process asks its host operating system to redirect
    the incoming data to that port and, hence, to the listener process. The port is
    simply a number between 0 and 65535 (2 bytes) and must not be already bound by
    another listener process. Trying to bind a port that's already in use results
    in an error. Note that in the case of binding a port on a specific NIC, the operating
    system will redirect all incoming packets that are targeted at that bound port
    and received on that specific NIC to the listener process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The process waits and reads the messages that become available on the created
    channel and responds to them by writing back to the channel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'And the connector process will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It must know the IP address and the port number of the listener process. Therefore,
    it tries to connect to the listener side by providing the IP address and the port
    number to its host operating system. If the target process is not listening on
    the specified port, or the IP address points to an invalid or the wrong host,
    the connection will fail.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the connection is successfully established, the connector process can write
    to the channel and read from it in almost the same way, meaning the same API that
    the listener process uses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that beside taking the preceding steps, the listener and connector processes
    should both be using the same transport protocol, otherwise the messages cannot
    be read and understood by their host operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: Connection-oriented initialization sequences
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In a connection-oriented scenario, the listener process will follow the following
    sequence in order to get initialized:'
  prefs: []
  type: TYPE_NORMAL
- en: Bind a port, just like the connection-less scenario explained previously. The
    port is exactly the same as explained in the previous section and it follows the
    same constraints.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The listener process continues by configuring the size of its *backlog*. The
    backlog is a queue of pending connections that are not accepted yet by the listener
    process. In connection-oriented communication, the listener side should accept
    incoming connections before being able to transmit any data. After configuring
    the backlog, the listener process enters *listening mode*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, the listener process begins to *accept* incoming connections. This is an
    essential step in establishing a transport channel. Only after accepting an incoming
    connection can they transmit data. Note that if the connector process sends a
    connection to the listener process, but the listener process cannot accept that
    connection, it will remain in the backlog until it gets either accepted or *timed
    out*. This can happen when the listener process is too busy with other connections
    and it cannot accept any further new connection. Then, the incoming connections
    will pile up in the backlog and when the backlog becomes full, new connections
    will be rejected immediately by the host operating system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sequence of the connector process is very similar to what we explained for
    the connection-less communication in the previous section. The connector connects
    to a certain endpoint by providing the IP address and the port, and after being
    accepted by the listener process, it can use the same API to read from and write
    to the connection-oriented channel.
  prefs: []
  type: TYPE_NORMAL
- en: Since the established channel is connection-oriented, the listener process has
    a dedicated channel to the connector side; therefore, they can exchange a stream
    of bytes that doesn't have an upper limit in terms of the number of bytes. Therefore,
    the two processes can transmit a huge amount of data, and its correctness is guaranteed
    by the governing transport and network protocols.
  prefs: []
  type: TYPE_NORMAL
- en: As the last note about the transport layer, we mentioned that the listener processes
    (regardless of the underlying channel being connection-oriented and connection-less)
    are required to bind an endpoint. Regarding UDP and TCP specifically, this endpoint
    is made up of an IP address and a port number.
  prefs: []
  type: TYPE_NORMAL
- en: Application layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a transport channel is established between two processes residing on two
    different ends, they should be able to talk to each other. By talking, we mean
    transmitting a series of bytes that can be understood by both ends. As we explained
    in the earlier sections in this chapter, a communication protocol is required
    here. Since this protocol resides in the *application layer* and it is used by
    the processes (or the applications running as processes), it is called an *application
    protocol*.
  prefs: []
  type: TYPE_NORMAL
- en: While there aren't many protocols used in link, network, and transport layers
    and they are mostly well-known, we have numerous application protocols that are
    used in the application layer. This is again analogous to telecommunication networks.
    While there aren't many standards for telephone networks, the number of languages
    that people use to communicate is large, and they differ greatly. In computer
    networks, every application run as a process needs to use an application protocol
    in order to communicate with another process.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the programmers either use a well-known application protocol such
    as HTTP or FTP or they have to use a custom application protocol that is designed
    and built locally within a team.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have discussed five layers; physical, link, network, transport, and
    application. Now it's time to put all of them into a single body and use it as
    a reference to design and deploy computer networks. In the following section,
    we talk about the internet protocol suite.
  prefs: []
  type: TYPE_NORMAL
- en: Internet protocol suite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The network model that we see every day and that is widely applied is the **Internet
    Protocol Suite** (**IPS**). IPS is mainly used on the internet, and since pretty
    much all computers want to have access to the internet, they have universally
    adapted to use IPS, which is not officially the standard approved by ISO. The
    standard model for computer networks is **Open System Interconnections** (**OSI**)
    model, which is more a theoretical model and is almost never publicly deployed
    and used. IPS has the following layers. Note that the prominent protocols in each
    layer are mentioned in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: Physical layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Link layer: Ethernet, IEEE 802.11 Wi-Fi'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Internet layer: IPv4, IPv6, and ICMP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Transport layer: TCP, UDP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application layer: Numerous protocols such as HTTP, FTP, DNS, and DHCP, and
    so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the layers have a nice correspondence to the layers that we
    discussed in this chapter, but with only one exception; the network layer is renamed
    the internet layer. This is because as part of IPS, the network protocols that
    are prominent in this layer are only IPv4 and IPv6\. The rest of the explanations
    can be applied to IPS layers. IPS is the main model that we will be dealing with
    throughout this book and in the actual work environment.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how computer networks work, we are in a good position to proceed
    and see what *socket programming* is. As part of the rest of this chapter and
    the upcoming chapter, you will see that there is a deep correspondence between
    the concepts discussed in the transport layer and the concepts we have in socket
    programming.
  prefs: []
  type: TYPE_NORMAL
- en: What is socket programming?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we know about the IPS model and the various network layers, it is much
    easier to explain what socket programming is. Before delving into the technical
    discussions regarding the socket programming, we should define it as an IPC technique
    that allows us to connect two processes residing on either the same node or two
    different nodes having a network connectivity between them. If we put the single-host
    socket programming aside, the other form requires us to have an operational network
    between the two nodes. This very fact ties socket programming with computer networks
    and all we have explained so far.
  prefs: []
  type: TYPE_NORMAL
- en: To make it more technical, we should say that socket programming mainly happens
    in the transport layer. As we have already said, the transport layer is responsible
    for connecting two processes over an existing internet layer (network layer).
    Therefore, the transport layer is the key layer for establishing a socket programming
    context. Basically, that's why you as a programmer should know more about the
    transport layer and its various protocols. Some socket programming-related bugs
    have their origins in the underlying transport channel.
  prefs: []
  type: TYPE_NORMAL
- en: In socket programming, sockets are the main tools for establishing a transport
    channel. Note that despite what we have discussed so far, socket programming can
    go beyond transport layer or *process-to-process communications* and it can include
    internet layer (network layer) or *host-to-host communications* as well. This
    means that we can have internet-layer-specific sockets as well as transport layer
    sockets. With this in mind, most of the sockets that we see and work with are
    transport sockets and for the rest of this chapter and the next chapter, we will
    mainly be talking about transport sockets.
  prefs: []
  type: TYPE_NORMAL
- en: What is a socket?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have explained in the previous section, the transport layer is where the
    actual socket programming is taking place. Everything above it just makes the
    socket programming more specific; however, the actual underlying channel has been
    established in the transport layer.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed that the internet connection (network connection) on which
    the transport channel has been established is actually the connection between
    the operating systems, or more specifically the kernels of those operating systems.
    Therefore, there should be a concept in the kernel that resembles a connection.
    More than that, there could be many established connections initiated or accepted
    by the same kernel simply because there can be several processes running and hosted
    in that operating system and willing to have network connections.
  prefs: []
  type: TYPE_NORMAL
- en: The concept that we are looking for is the *socket*. For any established or
    soon-to-be-established connection in a system, there is a dedicated socket that
    identifies that connection. For a single connection made between two processes,
    there is exactly one socket on each side that addresses the same connection. As
    we explained before, one of these sockets belongs to the connector side and the
    other one belongs to the listener side. The API that allows us to define and manage
    a socket object is described by the *socket library* exposed by the operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are mainly talking about POSIX systems, we expect to have such a socket
    library as part of the POSIX API and, in fact, we do have such a library. In the
    rest of this chapter, we discuss the *POSIX socket library* and we explain how
    it can be used to establish a connection between two processes.
  prefs: []
  type: TYPE_NORMAL
- en: POSIX socket library
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Every socket object has three attributes: *domain*, *type*, and *protocol*.
    While the manual pages of an operating system explain these attributes very well,
    we want to talk about some of the values that are commonly used for these attributes.
    We start with the domain attribute, which is also known as **address family**
    (**AF**) or **protocol family** (**PF**). Some of the values that are widely used
    can be seen in the following list. Note that these address families support both
    connection-oriented and connection-less transport connections.'
  prefs: []
  type: TYPE_NORMAL
- en: '`AF_LOCAL` or `AF_UNIX`: These are local sockets, which work only when both
    connector and listener processes are located on the same host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AF_INET`: These sockets allow two processes to connect to each other over
    an IPv4 connection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AF_INET6`: These sockets allow two processes to connect to each other over
    an IPv6 connection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note**:'
  prefs: []
  type: TYPE_NORMAL
- en: In some POSIX systems, in the constants used for the domain attribute, you might
    find the prefix `PF_` instead of `AF_`. It is often the case that `AF_` constants
    have the same values as `PF_` constants, so they can be used interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will demonstrate the usage of the `AF_UNIX` and `AF_INET`
    domains, but it should be easy to find examples that use the `AF_INET6` domain.
    Also, there could be address families that are specific to a certain operating
    system and cannot be found on other systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most well-known values for the type attribute of a socket object are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SOCK_STREAM`: This means that the socket will represent a connection-oriented
    transport communication that guarantees delivery, correctness, and the order of
    the sent content. As we''ve explained streams in the previous sections, the term
    `STREAM` also suggests this. Note that, at this point, you cannot predict that
    the actual underlying transport protocol is TCP because this is not true regarding
    local sockets that belong to the `AF_UNIX` address family.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SOCK_DGRAM`: This means that the socket will represent a connection-less transport
    communication. Note that the term datagram, abbreviated as `DGRAM`, like we explained
    in the previous sections, refers to a series of bytes that cannot be seen as a
    stream. Instead, they can be seen as some individual chunks of data that are called
    datagrams. In a more technical context, a datagram represents a packet of data
    transmitted over a network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SOCK_RAW`: A raw socket can represent both connection-oriented and connection-less
    channels. The main difference between `SOCK_RAW` and `SOCK_DGRAM` or `SOCK_STREAM`
    is that the kernel actually knows about the underlying used transport protocol
    (UDP or TCP) and it can parse a packet and extract the header and the content.
    But with a raw socket, it doesn''t do so, and it is up to the program that has
    opened the socket to read and extract various sections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, when using `SOCK_RAW`, the packets are delivered directly to
    the program and it should extract and understand the packet structure itself.
    Note that if the underlying channel is a stream channel (connection-oriented),
    the recovery of lost packets and packet reordering are not done by the kernel,
    and the program should do them itself. This implies that recovery and packet reordering
    are actually done by the kernel when you select TCP as your transport protocol.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The third attribute, protocol, identifies the protocol that should be used for
    the socket object. Since most address families, together with the type, determine
    a certain protocol, this attribute can be chosen by the operating system upon
    the socket creation. In circumstances when we have multiple possible protocols,
    this attribute should be defined.
  prefs: []
  type: TYPE_NORMAL
- en: Socket programming offers solutions for both single-host and multiple-host IPC.
    In other words, while it is quite possible to connect two processes located on
    two different hosts and in two different LANs using internet (network) sockets,
    it is totally possible to connect two processes residing on the same host using
    Unix domain sockets.
  prefs: []
  type: TYPE_NORMAL
- en: As the last note in this section, we should add that socket connections are
    bidirectional and full-duplex. This means that both parties can read from and
    write to the underlying channel without interfering with the other end. This is
    a desired feature because it is usually a requirement in most IPC-related scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have been introduced to the concept of sockets, we have to revisit
    the sequences that we explained in the previous sections regarding listener and
    connector processes. But this time, we dive into more detail and describe how
    sockets can be used to perform these sequences.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting listener-connector sequences
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we mentioned before, as part of computer networks, in almost every connection
    one of the ends is always listening for incoming connections, and the other end
    tries to connect to the listener side. We also discussed an example regarding
    a telephone network, explaining how a telephone is used to listen to an incoming
    call, and how it can be used to make calls and connect to other listening devices.
    A similar situation exists in socket programming. Here, we want to explore the
    sequences that should be followed by the processes at two different ends in order
    to establish a successful transport connection.
  prefs: []
  type: TYPE_NORMAL
- en: In the following subsections, we will go deeper into the details of socket creation
    and the various operations that should be performed by both processes that want
    to engage in a connection. The sequences explained in the following subsections
    for the listener and connector processes are infrastructure agnostic and benefit
    from the generalization that socket programming provides over the various underlying
    transport connections.
  prefs: []
  type: TYPE_NORMAL
- en: As you should remember, we discussed the listener and connector sequences regarding
    connection-oriented and connection-less communications separately. We take the
    same approach here, and we firstly start with the stream (connection-oriented)
    listener sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Stream listener sequence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The following steps should be followed by a process that wants to listen for
    new stream connections. You have been introduced to the binding, listening, and
    accepting phases in the previous sections, but here we will talk about them from
    a socket programming perspective. Note that most of the actual functionality is
    provided by the kernel and the process only needs to call the right functions
    from the socket library in order to put itself into listening mode:'
  prefs: []
  type: TYPE_NORMAL
- en: The process should create a socket object using the `socket` function. This
    socket object is usually called a *listener socket*. The socket object represents
    the whole listener process, and it will be used to accept new connections. Depending
    on the underlying channel, the arguments sent to the `socket` function can vary.
    We could pass either `AF_UNIX` or `AF_INET` as the address family of the socket,
    but we have to use `SOCK_STREAM` as the type of the socket because we are going
    to have a stream channel. The protocol attribute of the socket object can be determined
    by the operating system. For example, if you choose `AF_INET` and `SOCK_STREAM`
    for a socket object, TCP will be selected by default for the protocol attribute.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, the socket must be bound to an *endpoint* that is reachable by the connector
    processes using the `bind` function. The details of the chosen endpoint heavily
    depend on the chosen address family. For example, for an internet channel, the
    endpoint should be a combination of an IP address and a port. For a Unix domain
    socket, the endpoint should be the path to a *socket file* located on the filesystem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The socket must be configured for listening. Here, we use the `listen` function.
    As we have explained before, it simply creates a backlog for the listener socket.
    The backlog is a list of awaiting connections that have not yet been accepted
    by the listener process. While the listener process cannot accept new incoming
    connections, the kernel will keep the incoming connections in the corresponding
    backlog until the listener process becomes free and starts to accept them. Once
    the backlog is full, any further incoming connections will be rejected by the
    kernel. Choosing a low size for the backlog can lead to many connections being
    rejected when the listener process is congested and choosing a large size can
    lead to a pile of awaiting connections that will eventually get timed out and
    disconnected. The backlog size should be chosen according to the dynamics of the
    listener program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After configuring the backlog, it is time to accept the incoming connections.
    For every incoming connection, the `accept` function should be called. Therefore,
    it is a widely used pattern to have the `accept` called in a never-ending loop.
    Whenever the listener process stops accepting new connections, the connector processes
    are put into the backlog and once the backlog is full, they get rejected. Note
    that every call to the `accept` function simply picks up the next connection waiting
    in the socket's backlog. If the backlog is empty and if the listener socket is
    configured to be blocking, then any call to the `accept` function will be blocked
    until a new connection comes in.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that the `accept` function returns a new socket object. This means that
    the kernel dedicates a new unique socket object to every accepted connection.
    In other words, a listener process that has accepted 100 clients is using at least
    101 sockets: 1 for the listener socket and 100 sockets for its incoming connections.
    The returned socket from the `accept` function should be used for further communication
    with the client sitting at the other end of the channel.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that this sequence of function calls remains the same for all types of
    the stream (connection-oriented) socket-based IPC. In the next chapter, we show
    real examples of how these steps should be programmed using C. In the next subsection,
    we deal with the stream connector sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Stream connector sequence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'When the connector process wants to connect to a listener process that is already
    in listening mode, it should follow the following sequence. Note that the listener
    process should be in listening mode, otherwise the connection will get refused
    by the kernel of the target host:'
  prefs: []
  type: TYPE_NORMAL
- en: The connector process should create a socket by calling the `socket` function.
    This socket will be used to connect to the target process. The characteristics
    of this socket should be similar or at least compatible with those we set for
    the listener socket, otherwise, we cannot establish a connection. Therefore, we
    need to set the same address family that we set for the listener socket. And the
    type should remain `SOCK_STREAM`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then it should use the `connect` function by passing the arguments that uniquely
    identify the listener endpoint. The listener endpoint should be reachable by the
    connector process and it should have been made available by the target process.
    If the `connect` function succeeds, it means that the connection has been accepted
    by the target process. Before this point, the connection might be waiting in the
    backlog of the target process. If the specified target endpoint is not available
    for any reason, the connection will fail, and the connector process will receive
    an error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Just like `accept` function call in the listener process, the `connect` function
    returns a socket object. This socket identifies the connection and should be used
    for further communication with the listener process. In the upcoming chapter,
    we will give a demonstration of the preceding sequences in the calculator example.
  prefs: []
  type: TYPE_NORMAL
- en: Datagram listener sequence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A datagram listener process will do the following in order to get initialized:'
  prefs: []
  type: TYPE_NORMAL
- en: Like the stream listener, the datagram listener process creates a socket object
    by calling the `socket` function. But this time, it must set the socket's type
    attribute as `SOCK_DGRAM`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that the listener socket has been created, the listener process should bind
    it to an endpoint. The endpoint and its constraints are very similar to the stream
    listener end. Note that there won't be a listening mode or an accepting phase
    for a datagram listener socket because the underlying channel is connection-less,
    and we can't have a dedicated session for each incoming connection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As explained, there is no listening mode or accepting phase with a datagram
    server socket. Also, the datagram listeners should use the `recvfrom` and `sendto`
    functions in order to read from and write back to a connector process. Reads can
    still be done using the `read` function, but writing the responses cannot be done
    just using a simple `write` function call. You will see why when we look at the
    datagram listener example as part of the upcoming chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Datagram connector sequence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A datagram connector has almost the same sequence as a stream connector. The
    only difference is the socket type, which must be `SOCK_DGRAM` for the datagram
    connector. One special case for datagram Unix domain connector sockets is that
    they have to bind to a Unix domain socket file in order to receive the responses
    from the server. We will elaborate on this in the upcoming chapter as part of
    the datagram calculator example when using Unix domain sockets.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have gone through all the possible sequences, it's time to explain
    how sockets and *socket descriptors* are related. This is last section in this
    chapter, and by starting the next chapter, we will be giving real C examples that
    cover all the sequences.
  prefs: []
  type: TYPE_NORMAL
- en: Sockets have their own descriptors!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike other push-based IPC techniques that work with file descriptors, socket-based
    techniques deal with socket objects. Every socket object is referred to by an
    integer value, which is a socket descriptor inside the kernel. This socket descriptor
    can be used to refer to the underlying channel.
  prefs: []
  type: TYPE_NORMAL
- en: Note that file descriptors and socket descriptors are different. File descriptors
    refer to a regular file or a device file while socket descriptors refer to socket
    objects created by `socket`, `accept`, and `connect` function calls.
  prefs: []
  type: TYPE_NORMAL
- en: While the file descriptors and socket descriptors are different, we still can
    use the same API or set of functions to read from and write to them. Therefore,
    it is possible to use `read` and `write` functions to work with sockets just like
    files.
  prefs: []
  type: TYPE_NORMAL
- en: These descriptors have another similarity; both of them can be configured to
    be non-blocking via the same API. Non-blocking descriptors can be used to work
    with the behind file or socket in a non-blocking fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we started to talk about IPC techniques that allow two processes
    to communicate and transmit data. Our discussion in this chapter will be complete
    in the upcoming chapter where we talk specifically about socket programming, and
    we will give various real C examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'As part of this chapter, we covered the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Pull-based and push-based IPC techniques and how they are different and similar.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We compared single-host IPC techniques versus multiple-host IPC techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You learned about communication protocols and their various characteristics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We went over the serialization and deserialization concepts and how they operate
    to fulfill a certain communication protocol.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explained how the content, length, and the sequentiality features of protocols
    can affect receiver processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explained POSIX pipes and demonstrated how to use them with an example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You saw what a POSIX message queue is and how it can be used to enable two processes
    to communicate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We briefly explained Unix domain sockets and their basic properties.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explained what computer networks are and how the stack of various network
    layers can lead to a transport connection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explained what socket programming is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explained the initialization sequences of listener and connector processes
    and the steps they take to become initialized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We compared file descriptors and socket descriptors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we continue our discussion about socket programming with
    a focus on providing real C examples. We will define an example of a calculator
    client and a calculator server. After that, we will use both Unix domain sockets
    and internet sockets to establish a fully functional client-server communication
    between the calculator client and its server.
  prefs: []
  type: TYPE_NORMAL
