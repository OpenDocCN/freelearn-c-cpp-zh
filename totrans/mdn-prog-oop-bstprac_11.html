<html><head></head><body>
		<div class="Content" id="_idContainer042">
			<h1 id="_idParaDest-137"><em class="italics"><a id="_idTextAnchor146"/>Chapter 9</em></h1>
		</div>
		<div class="Content" id="_idContainer043">
			<h1 id="_idParaDest-138"><a id="_idTextAnchor147"/>Requirements Engineering</h1>
		</div>
		<div class="Content" id="_idContainer044">
			<p>There may have been roughly an equivalent amount of thought over the last few decades into how to know you're building the right software as there has been into how to build software better. The software engineering techniques of the period 1960s-1980s explained how to construct requirements specifications, how to verify that the software delivered satisfied the specifications, and how to allow discoveries made while building and testing the software to feed back into the specification.</p>
			<p>In the 1990s, methodologies arose that favored closer interaction between the users of the software and its builders. <strong class="bold">Rapid Application Development</strong> dropped "big upfront" planning in favor of quickly iterated prototypes that customers could explore and give feedback on. <strong class="bold">Extreme Programming</strong> took this idea further and involves the customer or a representative of the customer not only in appraising the product during development but in prioritizing and planning the project as it proceeds. (It's a bit of a simplification to call these 1990s ideas. Many of the concepts behind RAD and other methodologies had been around since at least the 1970s, and a systematic literature review could pin the ideas more precisely onto the calendar. </p>
			<p>Nonetheless, it was the 1990s in which the ideas were synthesized into proposed systems for building software, and it was also the 1990s in which development teams started to use the systems and vendors created products to exploit their needs.)</p>
			<p>In parallel with that story, the history of how software applications are presented to their users has also been evolving. The success of this presentation is evident in the way that successive generations of practitioners have distanced themselves from the terminology used by the previous generation. If attempts to make software usable had been seen to work, then people would be happy to associate themselves with the field. Instead, <strong class="bold">Human-Computer Interaction </strong>has fallen out of favor, as have <strong class="bold">Human Interface Design</strong>, <strong class="bold">Computer-Supported Collaborative Working</strong>, <strong class="bold">Interaction Design</strong>, <strong class="bold">User Interface Design</strong>, and so on. It'll soon be the turn of <strong class="bold">User Experience</strong> to become one of history's résumé keywords.</p>
			<p>If the whole point of building software is to make it easier for people to do things, we should investigate what it is that people are trying to do and how to support that. Along the way, we can find out how to understand what <em class="italics">we</em> do, which can help us improve our own work (maybe even by writing software to do so).</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor148"/>Study People</h2>
			<p>Software applications do not exist in a vacuum. They are used by people; a system of people with existing goals, ideas, values, and interactions with each other (and yes, programmers, existing technology). The introduction of a new software product into this system will undoubtedly change the system. Will it support the existing goals and values or replace them with new ones? Will it simplify existing interactions, or introduce friction?</p>
			<p>To answer these questions, we must have a way to measure that system of people. To do <em class="italics">that</em>, we must understand what questions we should ask about that system in order to support the things we want to learn and discover what it is we should measure.</p>
			<h3 id="_idParaDest-140"><a id="_idTextAnchor149"/>Decide The Model</h3>
			<p>In <em class="italics">Chapter 6, Testing</em>, I had to start by deciding that the requirements of a software system did not arise as some fundamental truth about the universe but were based on the way the people who used the system worked with the world and with each other. Now imagine that you're trying to understand the requirements of an application such as Excel. Will you consider the needs of each of the millions of users individually? While this could lead to a higher-quality product (or products, if you resolve conflicting needs by producing different solutions), there are few, if any, companies that could afford to undertake the research involved, and even if they could, it would be difficult to profit from the resulting software.</p>
			<p>It's much cheaper to pick a small number of representative users and design the software for them. Some teams pick actual customers, while others create "personas" based on hypothetical customers, or on market research. Whichever way it's done, the product will come to represent the real or imagined needs of those real or imagined people</p>
			<p>User personas give the impression of designing for users, when in fact the product team has merely externalized their impression of what they want the software to be. It's easy to go from "I want this feature" to "Bob would want this feature" when Bob is a stock photo pinned to a whiteboard; Bob won't join in with the discussion, so he won't tell you otherwise. The key thing is to get inside the fictitious Bob's head and ask "why" he'd want that feature. Sometimes, teams that I've been on where personas were used nominated someone to be their advocate during discussions. This gave that person license to challenge attempts to put words in the persona's mouth; not quite the same as having a real customer involved but still useful.</p>
			<p>At first glance, the situation seems much better for builders of in-house or "enterprise" software; find the people who are going to use the software and build it for them. There are still some important questions about this model of the software's environment. One clear problem is where you're going to stop. Does the team you're building for represent an isolated unit in the company with clear inputs and outputs, or do you treat the interactions between members of this and other teams as part of the system? How about the interactions with customers, partners, and other external parties? The article <strong class="bold">Three Schools of Thought on Enterprise Architecture</strong>—<a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6109219">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6109219</a> explores the effects of these boundaries on considering the systems involved.</p>
			<p>Having decided on the scope of the system, are you designing for the specific people who currently comprise it or for more abstract concepts such as the roles that are occupied by those people? In either case, be aware of political biases entering into your model. Software designed according to a collaborative model of the interaction between a manager and their reports will differ from that modelled on the struggle between the oppressed workers and the exploitative bourgeoisie. Because the software will end up changing the system it's deployed into, such decisions will affect the way people work with each other.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor150"/>You Shouldn't Necessarily Build What The Client Asks For</h2>
			<p>Discovering the requirements for any software application is hard, even if the people building it are going to be the people using it. In <em class="italics">Chapter 6, Testing</em>, I explored the notion that everybody has their own idea of what the software should do, and in <em class="italics">Chapter 7, Architecture</em>, the fact that some requirements are not made explicit. So, if you just asked everyone for a list of things the software should do and built that, it'd be rife with conflicts and probably wouldn't do everything that any one person wanted from it.</p>
			<p>While it's an inaccurate way of finding out what software should do, asking people is one of the easiest and most accessible methods. You can interview people with either a directed questionnaire or an open-ended discussion, finding out what they think of the system of interest and hopefully teasing out some of those tacit requirements. You can also get a group of people together, as a round-table discussion or a focus group, to collectively discuss their needs and problems. Even when people are being helpful and answering your questions to the best of their abilities, there will be problems that come up with interpreting their answers. The thing they do is likely a specialist activity, and so is making software. Each of these disciplines will have its jargon and its accepted "common sense" knowledge; translating between those will be difficult. Everyone has their own version of what "everybody" who does their job knows and will probably not think to tell you about those things.</p>
			<p>So, there's an art (or maybe a science; I don't think the industry has made its mind up yet) to looking past the direct answers to your direct questions, to find out both what questions you <em class="italics">should</em> have asked and what answers you would <em class="italics">never</em> have been given. This is where bespoke software (particularly so called "enterprise" software) has a chance to provide a much better experience than off-the-shelf software; you have the opportunity to observe what your users <em class="italics">really</em> do and to provide software that supports that, rather than offering something that supports their stated needs.</p>
			<p>You need to remember too that <em class="italics">you</em> are the software expert, and your client is the expert at solving whatever problem it is that they solve. When they talk about the <em class="italics">problem</em> they are having, there is more information about how it should be solved than when they tell you about the <em class="italics">solution</em> they envisage. That's not to say that you shouldn't accept their suggestions; but you <em class="italics">should</em> remember that their expertise lies elsewhere and that your team probably has more experience of designing software. Obviously, if you're a start-up working on a developer tool, your team probably has <em class="italics">less</em> experience than your customers.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor151"/>Avoid Asking What You Want To Hear</h2>
			<p>If you've got a pet feature, it's all too easy to drop it into a discussion of the proposed system when conducting interviews and focus groups with prospective users. The problem you then face is that it's easy for people to agree that said feature would be a good idea, even if it really wouldn't.</p>
			<p>Firstly, you have to separate things that people think they would use from things that people <em class="italics">do</em> use. Consider whatever word processing software you use and think about all the features it has that you've never touched. When you bought the software, were you swayed by any of the discussions of those features in the marketing material? (The idea that word processors have more features than people use has been investigated by human-computer interaction researchers—<a href="https://www.cs.ubc.ca/~joanna/papers/GI2000_McGrenere_Bloat.pdf">https://www.cs.ubc.ca/~joanna/papers/GI2000_McGrenere_Bloat.pdf</a> and while they found that some features go unused by some users, the users still know that those features are there and have some familiarity with their function. So, saying that these extra features are entirely without value is clearly a stretch; nonetheless, the default choice on whether we "should" incorporate a feature into a product is usually "yes" due to the feature matrix marketing described here.) Do you think the majority of other users do make use of those features? Would the software be worth as much if it didn't have those features? Given the choice between an application that does a thing and one that doesn't, people will often choose the one that does it even if they don't see a need for that right now. Particularly as, when you're gathering requirements, there's no other information to go on; without being able to see the two (currently hypothetical) applications, prospective users can't compare their usability, speed, quality, or other features, so the options really do boil down to "with" or "without."</p>
			<p>Bear in mind, too, the tendency for people without a strong view on a statement to agree with it. This is known in psychological circles as the <em class="italics">acquiescence response bias</em> and needs to be taken into account when evaluating the results of questionnaires. An example is in order. Imagine that you wanted to build a "clean coder" IDE, but you want to find out whether anyone would use it first. You create a questionnaire asking respondents to rate how strongly they agree or disagree with these statements:</p>
			<ul>
				<li>A professional programmer writes unit tests.</li>
				<li>A good method has minimal loops and branches.</li>
				<li>Long, descriptive variable names are better.</li>
			</ul>
			<p>Someone else wants to write a "stripped-down" IDE, harking back to the times when "real programmers didn't eat quiche" and just got their jobs done. (This is a tongue-in-cheek reference to the article <strong class="bold">Real Programmers Don't Use Pascal</strong>—<a href="http://www.ee.ryerson.ca/~elf/hack/realmen.html">http://www.ee.ryerson.ca/~elf/hack/realmen.html</a>, which was itself a tongue-in-cheek reference to the book <strong class="bold">Real Men Don't Eat Quiche</strong>—<a href="https://bit.ly/2XjLjxw">https://bit.ly/2XjLjxw</a>. That was itself satirical, but I've run out of cheeks into which I am willing to insert my tongue.) They create a questionnaire in which respondents rate their agreement with these statements:</p>
			<ul>
				<li>Time spent writing tests is time spent not adding value.</li>
				<li>A good method has as many loops and branches as necessary to provide a simple interface onto complex work.</li>
				<li>Typing is not the focus of programming; terseness is a virtue.</li>
			</ul>
			<p>These questionnaires will yield different results; not necessarily entirely in opposition to one another but certainly each revealing a bias in favor of the higher end of their respective scales. This is the acquiescence response bias; each has asked what they wanted to hear and the respondents in each case have tended to agree with it. The two researchers should have each chosen a mix of questions from both lists to get a more representative survey.</p>
			<p>Finally, bear in mind that telling your client "I think we should do it like <em class="italics">this</em>" will predispose them to that approach, due to a cognitive bias called <strong class="bold">anchoring</strong>—<a href="https://www.sciencedaily.com/terms/anchoring.htm">https://www.sciencedaily.com/terms/anchoring.htm</a>). Having <em class="italics">anchored</em> a particular feature or workflow in their mind, they'll prefer options that contain that feature or workflow even if it rationally appears worse than an unrelated alternative. You could end up privileging a suboptimal or costly design just because it was the first thing you thought of and blurted it out to your clients. It's best to leave options open early on so that you don't pit your own customers against better designs you create later on.</p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor152"/>Understand The Problem Domain</h2>
			<p>As mentioned earlier, you and your team are the experts in making software, and the customers are the experts in the thing that the software will do. I've cautioned against using that distinction to build the software you want rather than the software that the customers need; should this be taken to mean that the software people stick to software and the customers stick to their problem domain?</p>
			<p>No.</p>
			<p>You need to know what you're building <em class="italics">for</em>, so you need to have some understanding of the problem domain. Yes, this is asymmetric. That's because the situation is asymmetric – you're building the software to solve a problem; the problem hasn't been created so that you can write some software. That's just the way it is, and compromises must come more from the software makers than from the people we're working for. The better you understand the problem you're trying to solve, the more you can synthesize ideas from that domain and the software domain to create interesting solutions. In other words, you can write better software if you understand what it is that software will do. That's hopefully not a controversial idea.</p>
			<p>There are different levels on which this understanding can be implemented, relevant to different amounts of interaction with customers. <em class="italics">Chapter 5, Coding Practices</em>, described <strong class="bold">Domain-Driven Design </strong>and the ubiquitous language: the glossary of terms that defines concepts in the problem domain and should be used to name parts in the software domain, too. Needless to say, everyone working on the software should be familiar with the ubiquitous language and using it in the same way – it's not ubiquitous otherwise! The point of the ubiquitous language is to ensure that everyone—customers and software makers—means the same thing when they use technical or jargon terms. Therefore, it prefers jargon to be from the problem domain, so that non-software people don't have to learn software terminology, and it's expected that the terms pervade the software design and implementation and are not just used in customer meetings.</p>
			<p>The ubiquitous language should be considered a starting point. Some methodologies, including Extreme Programming, require that the development team have a customer representative on hand to ensure that the development work is always adding value. These discussions need to be had at the level of the business, that is, at the level of the problem domain. (This is one of the reasons that programmers often get frustrated that the business doesn't schedule time for refactoring, development infrastructure, or "paying off" technical debt. The problem is that bringing these things up in the context of a business discussion is a mistake; these are internal details of what we do and how we work with each other and have nothing to do with business value or how we work with customers. If some refactoring work is going to make it easier to work on the software, then just do it and let the business see the results in terms of reduced costs.) This in turn means that at least one person is going to need to be capable of having a peer discussion about the problem at hand with the customer representative.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor153"/>Uncover Tacit Requirements</h2>
			<p>This chapter has already covered the idea that you need to find out what customers need from their software that they're not talking about. But it's worth bringing up again, because the ubiquitous language may have ubiquitous holes.</p>
			<p>Think of all the times you've been surprised at a question someone from outside the software field has asked about an application you're writing. Well, no, of <em class="italics">course</em> the app we made for the seven-inch tablet won't work on the three-inch phone. It's such a basic thing, it's not even worth mentioning, so why would someone ask it?</p>
			<p>Now think about flipping that situation. What are the things that people in your problem domain think so basic that they'd never mention them? The things that a professor told them were "obvious" in a first-year lecture and they haven't questioned since? How are you going to get anyone to tell you about them?</p>
			<p>As with pair coaching, this is a situation where acting like a petulant toddler can be to your advantage. Domain experts are likely to have particular ways of doing things; finding out <em class="italics">why</em> is what's going to uncover the stuff they didn't think to tell you. It'll be frustrating. Some things we don't have real reasons for doing; they're just "best" practice or the way it gets done. Probing those things will set up a cognitive dissonance, which can lead people to get defensive; it's important to let them know that you're asking because you're aware how much of an expert they are at this stuff and that you just need to understand the basics in order to do a good job by them.</p>
			<p>Why the cognitive dissonance? Well, sometimes we just do things because "that's how they're done," rather than because there's any known value to that technique. We can find examples of this in the field of making software. Many developers (though, far from all) use version control. What are the benefits of doing so? Surprisingly, <em class="italics">no study can be found</em>—<a href="http://www.neverworkintheory.org/?p=451">http://www.neverworkintheory.org/?p=451</a> that investigates that. However, many developers, myself included, will tell you that version control is important, you should be doing it, and can come up with benefits. Tell us "but there's no evidence for those benefits, so why not just stop?" and we'll get confused and angry, trying more vociferously to defend our position despite the problems with the argument.</p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor154"/>You Shouldn't Build What Your Client Wants</h2>
			<p>At least, you probably shouldn't, anyway. Most of the time, they won't represent the majority of users, or even <em class="italics">any</em> of the users. This happens in pretty much every field of software:</p>
			<ul>
				<li>In-house software is usually commissioned by the IT department, but will be used by sales, engineers, finance, and other departments.</li>
				<li>Commercial software is usually driven by a product manager but will be sold to thousands (or more) of people. Even where you have a dedicated customer representative, they represent only one of many users. And, as with in-house software, the "representative" may still not be the ultimate user of the application.</li>
				<li>Even in a case where you're building bespoke software for a small team of people who are involved in the decision-making, a disproportionate number of suggestions will come from the more senior or more vocal users; with the worst case being that specific requests get filtered through the understanding of a senior manager before being summarized and presented to the development team.</li>
			</ul>
			<p>What this means is that, in almost all situations, what your client wants is at best only a rough approximation to what would be in the best interests of the product (and therefore its user base, and presumably your bottom line). The trick to managing this is, of course, political rather than technical; you probably don't want to offend the people who <em class="italics">are</em> giving you input into the software requirements, especially if they're paying the bills. That means flipping the <strong class="bold">Bozo Bit</strong>—<a href="http://c2.com/cgi/wiki?SetTheBozoBit">http://c2.com/cgi/wiki?SetTheBozoBit</a> is out of the question. But if something's a bad idea, you probably don't want it in your app.</p>
			<p>But what makes <em class="italics">you</em> sure it's a bad idea? Even if you are the user of the software you're writing, it's still one not-quite-representative user versus another. Yes, you may have more of an idea about platform norms and expected behavior, but that could also mean that you're conservative about brand new ideas because no other app works this way.</p>
			<p>Resolving this conflict can be achieved with data. I discussed A/B testing and user acceptance testing in <em class="italics">Chapter 6, Testing</em>; those tools can be put to use here in discovering whether any given suggestion improves the software. It doesn't have to be expensive; in that, you don't have to build the whole feature before you can find out whether anyone wants it. You could try out a prototype on a whiteboard to see how people get on with it or build a very basic version of the feature to see how popular it is. Be cautious about trying to poll users to find out how popular a feature would be though: answering "yes" or "no" takes the same effort, but in one case they get a higher chance of getting a new shiny thing, whether they'd use it or not. The risk/reward calculation in responding to a feature poll is biased toward affirming the request, and we've already seen acquiescence bias means people tend to agree with whatever statement is presented to them.</p>
			<p>When you've got the data, the conversation can start "that was a nice idea, but it looks like the customers aren't ready for it" rather than "I'm not building your bad feature." That's a much easier way to have an ongoing relationship with your clients. Unfortunately, it's not always an option; plenty of software is still built in secrecy, with no user engagement until 1.0 is nearly ready (or even later). In these cases, your imperfect customer proxies are all you've got and, like it or not, you have only their suggestions and your opinions to work with. You can still frame discussion around hypothetical other users (often called personae) to defuse any emotional feelings about challenging "personal" feature requests, but that's an imperfect rhetorical tool rather than an imperfect requirements tool. Application telemetry in the 1.0 release can tell you how people really use the features and help you prioritize future development, but that's too late for discussions about the initial release; and remember that it's the initial release that costs money while it's not paying for itself.</p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor155"/>Human Factors In Software Systems</h2>
			<p>The thing about software requirements is that they don't exist. Or at least, they don't exist in isolation. The standard model of particle physics is based on the idea that there are fundamental particles called quarks, and that these combine into systems called <em class="italics">hadrons</em> (heavyweight particles including protons and neutrons) and <em class="italics">mesons</em> (middleweight particles important in high-energy interactions). Quarks are bound into these systems by <em class="italics">gluons</em>, the particles that carry the strong force. This model is generally accepted, even though no one has ever seen a quark or a gluon in isolation; they're always part of a hadron or meson.</p>
			<p>Just as quarks and gluons have no existence on their own, so software on its own without users is meaningless, and software users without software have nothing to do. The whole represents a <em class="italics">socio-technical system</em> and it is <em class="italics">this</em> system that we are constructing and modifying with our software-building efforts. So, no view on software requirements is complete without a view of the effect the software will have on the politics, economics, social structure, and psychology of the people who will interact with it, and of how those people will affect the software.</p>
			<p><em class="italics">I've had a theoretical grasp on this point for years. It was finally emotionally reified for me by </em><strong class="bold">Robert Annett</strong>—<a href="https://twitter.com/robert_annett">https://twitter.com/robert_annett</a><em class="italics"> during a talk he gave on legacy software systems. The anecdote he told involved him walking through an office at the company he was deploying a new system at, talking with one of the people he'd be working with. As they left a room where around 20 data entry clerks were working, his new colleague said quietly "it's a shame really – when your new system comes online, we'll have to fire them."</em></p>
			<p><em class="italics">Sometimes, the pattern of sigils and words you feed to the compiler can have a real impact on real people, good or bad.</em></p>
			<h3 id="_idParaDest-147"><a id="_idTextAnchor156"/>Economics</h3>
			<p>The economic side of this interaction is covered well by Barry Boehm in his 1981 book <strong class="bold">Software Engineering Economics</strong>—<a href="http://books.google.co.uk/books/about/Software_engineering_economics.html?id=VphQAAAAMAAJ&amp;redir_esc=y">http://books.google.co.uk/books/about/Software_engineering_economics.html?id=VphQAAAAMAAJ&amp;redir_esc=y</a>. His model for estimating the costs of software projects has not been generally adopted in the industry, but it does include what he calls "human relations factors," which can affect the cost of a software system and the benefits derived. It includes the "modified golden rule" for working with other people:</p>
			<p><em class="italics">Do unto others as you would have others do unto you – if you were like them</em>.</p>
			<p>The point of the conditional clause is to remind programmers that not everyone wants to be treated like they enjoy solving software problems and can understand computer science concepts. Boehm argues that the costs and benefits of usability, of satisfying human needs, and of allowing users to fulfil their potential need to be considered in economic terms for a software project.</p>
			<p>While surely better (or at least, more complete) than not reasoning at all about these factors, trying to find a dollar value for them is an early stage in their consideration. What I infer from it, and from similar arguments in information security and other fields (remember the discussion on the economic value of accessibility, in the <em class="italics">Chapter 6, Testing</em>) is that we either can't <em class="italics">see</em> or can't <em class="italics">justify</em> an intrinsic benefit of those properties, but would still like to include them in our decision-making. The fact that we're not willing to ignore them leads me toward the second explanation: we know that these things are valuable but don't have an argument to support that.</p>
			<p>That's not to say that these defenses for human factors aren't useful; just that they aren't the apotheosis of debate. You can see how usability might be economically justified in terms of cost; more effort in designing usable software can pay off in making its users more efficient, and more satisfied. Satisfaction (linked to another of the factors – fulfilment of human potential) can lead to greater engagement with their work and higher levels of staff retention, reducing the HR costs of the organization. Satisfying human needs is what <strong class="bold">Herzberg</strong>—<a href="http://www.businessballs.com/herzberg.htm">http://www.businessballs.com/herzberg.htm</a> deems a <em class="italics">hygiene factor</em>: people must have their basic needs met before they can be motivated to pursue other goals.</p>
			<p>Sometimes the trade-off in goals cannot reasonably be cast in economic terms. A good example is a game: if it had great usability, it'd be really simple so people would complete it quickly and then get back to work – an economic win. But people don't play games that are straightforward; they play games that offer them a challenge, whether that challenge be mental, dexterous, or something else. Therefore, the player's desire to be challenged, or to lose themselves in the game world, takes precedence, although it is difficult to see how to assign a monetary value to that desire.</p>
			<h3 id="_idParaDest-148"><a id="_idTextAnchor157"/>Politics</h3>
			<p>The political side of software development can have an impact on how people think they are recognized, supported, empowered, and valued by the system in which the software is used and the wider system of interacting systems. Let's start this section by looking at a case study: a shared calendar application used in a business. On one team, everyone can schedule events on their own calendar, and the manager can see everyone's calendars. Additionally, the manager has a personal assistant who can schedule events for the manager in the manager's calendar.</p>
			<p>The manager feels in a position of power, because they can see where everyone is and can strategically walk past their desks to see what they're up to at times when their reports should be there, because they don't have any meetings recorded. Additionally, the manager feels empowered because the mechanical work of updating the calendar software has been delegated to someone else, and delegation is a key activity for managers.</p>
			<p>On the other hand, the other members of the team feel empowered because they can control the manager through the calendar software. If they do not want to be disturbed, they can create themselves a "meeting" and find somewhere quiet to work. They can work with the personal assistant to arrange for the manager to be in a meeting at a time when they want to have a team discussion without the manager's involvement.</p>
			<p>This discussion about calendar software depends on an underlying model of the politics in the group using the calendar: I wrote it to rely on a <em class="italics">Marxist</em> model, exposing the struggle between the manager (playing the part of the capitalist) and the workers. Each group is represented by their own goals, which are, according to the model, inevitably in conflict. Stability is achieved by ensuring that conflicting goals do not come into direct opposition over a single issue.</p>
			<p>Whether the people participating in this system are really engaged in the conflict presented in this model of the system – and whether individual participants would recognize that conflict or have a different perception of the system, is not captured within this model. It's an internally consistent story that has nothing to tell us about its own accuracy or applicability.</p>
			<p>In designing software to be used by multiple people, the real politics of the system of people and our model of those politics will both shape the interactions facilitated by the software. Will the software support an existing distribution of power or will it empower one group at the expense of others? Is the political structure modeled on a coarse level (as in the managers/workers case above) or are the different needs and expectations of every individual in the system captured? Will the software enable any new relationships or break some existing relationships? Will it even out inequalities, reinforce existing inequalities, or introduce new ones?</p>
			<p>These are complex questions to address but it is necessary to answer them for the impact of collaborative software on its users to be fully understood. As the anecdote earlier in this section shows, software systems can have a real impact on real people: the management of a large business may be pleased to reduce their headcount after deploying new software, to recoup development costs, and see it as the responsibility of those who are made redundant to find alternative employment. A charity with a remit to support local people by providing work may prefer to retain the workers and reject the software. Only by understanding the political environment can you be sure that your software is a good social fit for its potential users and customers.</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor158"/>Prioritizing Requirements</h2>
			<p>This section really reiterates what came before: you should be building software that your users <em class="italics">need</em> in preference to what they <em class="italics">want</em>. That's the ideology, anyway. Reality has this annoying habit of chipping in with a "well, <em class="italics">actually</em>" at this point.</p>
			<p>It's much easier to <em class="italics">sell</em> the thing the buyer wants than the thing they really need. Selling things is a good opportunity to take, as it allows you to fund other activities: perhaps including the development of the thing that the customers still needs. But, well, <em class="italics">actually</em>...</p>
			<p>...good marketing efforts can convince the customer that the thing they actually need is something they do in fact want. You can then shortcut all of the above discussion by making the thing people <em class="italics">should</em> be buying and convincing them to buy it. This is one of those high-risk, high-reward situations: yes, <em class="italics">selling people a faster horse</em>—<a href="http://blogs.hbr.org/cs/2011/08/henry_ford_never_said_the_fast.html">http://blogs.hbr.org/cs/2011/08/henry_ford_never_said_the_fast.html</a> is easier but the margins will not be as high and the success not as long-lived as if you invent the motorcar industry. As they say, profit is a prize for taking a risk.</p>
			<p>So, how you prioritize building the software really depends on your comfortable risk level. You could get incremental low-margin gains by finding the things that people are definitely willing to buy and building those. This is the <strong class="bold">Lean Start-up</strong> approach, where you start with nothing and rapidly iterate towards what the data is telling you people want to buy. Or you could take the risk: build the thing you know people need, then convince them that it's worth the money. This is the approach that bears most resemblance to Steve Jobs' famous position: <em class="italics">It's not up to customers to know what they want</em>.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor159"/>Is It Really "Engineering"?</h2>
			<p>There's an old quote that says anything where people feel the need to include the word "science" isn't a science. And, yes, the original author was talking about computer science. But perhaps we should be wary of the attribution of "engineering" to requirements engineering. Engineering is, after all, the application of science to the manufacture of artifacts, while requirements engineering is the application of social science (the warning is firing again!) to the business of improving a social system. Really, it's a transformation of some fields of social science (politics, economics, anthropology, ethnography, and geography) to other fields of social science (sociology and business studies) with some software created to effect the transformation. (Shortly after I finished writing this section, Paul Ralph submitted a paper to Ar<a id="_idTextAnchor160"/>Xiv describing <strong class="bold">the rational and alternative paradigms</strong>—<a href="http://arxiv.org/abs/1303.5938v1">http://arxiv.org/abs/1303.5938v1</a> of software design. The rational paradigm is basically the intuition-based version of requirements engineering: the software requirements exist as a fundamental truth to the universe and can be derived from careful thought. The alternative paradigm is the empirical one: the requirements arise as a result of the interactions between people and can only be understood through observation. Ralph's paper does a good job of explaining these two paradigms and putting them in context in the history of software design.)</p>
			<p>This isn't to say that the phrase "requirements engineering" needs to be retired, because people know what it means and use it as a placeholder for the real meaning of the discipline. But maybe we need to think of this as a generational thing; that while to <em class="italics">us</em> it's called "requirements engineering," we remember to give it a different term with the people we teach; something like "social software".</p>
		</div>
	</body></html>