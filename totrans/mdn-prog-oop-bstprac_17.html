<html><head></head><body>
		<div class="Content" id="_idContainer062">
			<h1 id="_idParaDest-232"><em class="italics"><a id="_idTextAnchor247"/>Chapter 15</em></h1>
		</div>
		<div class="Content" id="_idContainer063">
			<h1 id="_idParaDest-233"><a id="_idTextAnchor248"/>Philosophy</h1>
		</div>
		<div class="Content" id="_idContainer064">
			<h2 id="_idParaDest-234"><a id="_idTextAnchor249"/>Introduction</h2>
			<p>As the manuscript for this book came together, I realized that a lot of the content was based on a limited and naive <em class="italics">philosophy</em> of software creation. I was outlining this philosophy as it applied to each chapter, then explaining what the various relevant tasks were and how they fit into that philosophy. Here it is, written explicitly and separately from other considerations in the book:</p>
			<p><em class="italics">Our role as people who make software is to "solve problems," and only incidentally to make software. Making software for its own sake is at best a benign waste of time and money, or at worst detrimental to those exposed to it. Our leading considerations at all times must be the people whose problems we are solving, and the problems themselves.</em></p>
			<p>If this were the 1970s, you might call that <em class="italics">new age</em> claptrap. These days, you'd probably just think of it as the kind of nonsense you get in those self-help books about becoming a better manager; perhaps I should've left software behind for management consultancy by now. But it's only by agreeing on the philosophy of a discipline that we can decide what work represents a valuable contribution. Consider how the philosophy of science has changed over the millennia (The discussion here is based on a talk given by my first manager, John Ward, at Oxford University's Department of Physics.).</p>
			<p>In ancient Greek civilization, any conclusion that you could construct a logical argument for could be accepted as scientific fact. So, women had fewer teeth than men, and wood could combust because it was made of heavy earth and light fire, and the fire wanted to escape to the heavens. These things were accepted as true because people thought about them and decided that they were true.</p>
			<p>Over the next few centuries, the face of science changed. Richard P. Feynman was likely paraphrasing the French philosopher-priest Buridan when he expressed the belief that "the test of all knowledge is experiment"; a viewpoint that, by Feynman's time, had already spent centuries working its way into society's philosophy of science. At the time of the foundation of the Royal Society, if a respectable person presented evidence for something in the correct circles, then it was true: this is how we knew that sea monsters existed, because gentlemen had sailed to the Americas and reported seeing them. If someone of repute had seen something, then it must be there.</p>
			<p>In the twentieth century, Karl Popper argued for a falsification philosophy of science: rather than looking for evidence that a theory is true, accept it weakly and look for evidence that it is false. This is the approach that scientists take today. All of this is not some grand history presented to show progress toward our current, enlightened state. The accepted philosophy of science could change again at any time. The reason for presenting this anecdote is to show that what's considered good science, or bad science, or worthwhile science, is <em class="italics">situated</em> within the prevailing philosophical view (in addition to other considerations, including ethics). By analogy, if anyone wants to argue that there is such a thing as <em class="italics">good</em> programming practice, or bad practice, or worthwhile practice, they must do it, whether explicitly or implicitly, with reference to a particular philosophy and system of values.</p>
			<p>In this concluding chapter, I want to bring the whole book together by examining the role of and inputs into a holistic philosophy of software construction.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor250"/>Software as A Pursuit</h2>
			<p>Is making software (for money – we'll leave hobby aside) a profession? Is it a craft? Is it a science? An engineering discipline? An art form? A social science?</p>
			<p>It's easy to refute the idea of professional programmers. Professions are marked by an educational barrier to entry: you can't be a self-taught lawyer or architect, for example. The education ensures that (prospective) practitioners are aware of the institutional body of knowledge and code of ethics – things that are absent from the "profession" of programming. Certain organizations, such as the <em class="italics">Chartered Institute for IT</em>—<a href="http://www.bcs.org/">http://www.bcs.org/</a> and the <strong class="bold">Association for Computing Machinery</strong>—<a href="http://www.acm.org">http://www.acm.org</a> are trying to cast it as such but represent a minority of practitioners.</p>
			<p>We have professional-style conferences; these cater to a small minority of practitioners, frequently featuring sales rhetoric and self-promotion alongside (or instead of) problem-solving workshops and technical presentations. There is no professional closure: you cannot be disbarred from writing software if you disregard the ethics of doing so. The ethics of programming were discussed in <em class="italics">Chapter 14, Ethics</em>, and were found to be largely absent.</p>
			<p>A further difficulty with organizing software as a profession: as I described in the <em class="italics">Chapter 10, Learning</em>, the teaching of programming is far too haphazard to represent the transference of a core body of knowledge. In recommending a curriculum for university computing courses back in 1968, the ACM drew a thick line between academic computer science and computing as practiced in the wild. Even in the <em class="italics">latest version of the curriculum</em>—<a href="http://ai.stanford.edu/users/sahami/CS2013/">http://ai.stanford.edu/users/sahami/CS2013/</a>, professional standards and ethical implications are only a small part of the training a <em class="italics">Computer Science</em> course would offer. (At time of writing, curriculum 13 was still in draft status.) People who complete CS degrees undoubtedly have good knowledge of the workings of a computer, but one could argue that this is a necessary, though insufficient, input to be a novice programmer.</p>
			<p>The extent to which software practitioners treat our work as a profession has, then, always been varied. It is also largely à la carte. The practice of writing software is not a profession and would not survive professionalization over a short timescale. Almost everyone who currently calls themselves a programmer would be excluded from the profession until they had taken some appropriate training, unless there were some way to get "grandfathered" in, which would undermine the value of being a member of a recognized profession. The sudden collapse in the availability of "licensed" programmers would either cripple businesses or see them using existing, unlicensed practitioners legally or otherwise. Imagine, for example, that the BCS managed to secure protected nomination for the profession in the UK. Would UK-based companies wait until their programmers were chartered professionals before proceeding with their IT projects, or would they sack the now-underqualified employees and outsource their work abroad?</p>
			<p>Could programming, then, be an art form, or a craft or trade that combines artisanal capability with some technical knowledge? In the book <em class="italics">The Computer Boys Take Over</em>, Nathan Ensmenger makes a compelling argument for this position. He observes that, while there is a significant corpus of technical knowledge and computer science that <em class="italics">can</em> go into programming, many programmers have only a partial understanding of this corpus. They augment their technical knowledge with self-taught patterns – things that experience tells them have worked before and will work again. Any programmer or team of programmers builds up a local domain of craft knowledge, with the result that the craft of programming varies from context to context.</p>
			<p>Ensmenger also notices that the programmer is responsible for mediating "between the technological and social architectures of the organization." He concludes that this combination of artisanal craft with scientific knowledge and social integration makes the programmer not a professional, but a technician. He also observes that the rhetoric of professional programmers is one of fluid boundaries: programmers will talk about their work as science, engineering, <em class="italics">or</em> art, depending on who is listening. Bear this in mind throughout this discussion – both to appraise the various positions that are described and to analyze my own conclusions for signs of Humpty-Dumptyism:</p>
			<p><em class="italics">'When I use a word,' Humpty Dumpty said in rather a scornful tone, 'it means just what I choose it to mean—neither more nor less.' </em></p>
			<p>The <strong class="bold">Software Craftsmanship movement</strong>—<a href="http://manifesto.softwarecraftsmanship.org/">http://manifesto.softwarecraftsmanship.org/</a> uses language that's firmly rooted in mediaeval trade schools. Adherents talk of apprenticeships and journeymen (and, to carry on an earlier reference, of shoes and ships and sealing-wax; of cabbages and kings.), though parallels with the guilds of middle-age Europe (and the exclusivity they practiced, on a par with professional institutes) tend not to be drawn. Focus is on community interaction, on learning from the experiences of others and synthesizing a new approach to the craft by combining those experiences.</p>
			<p>While it appeals to centuries of tradition, software craftsmanship is very clearly a direct response to and retreat from the profession of "software engineering," or maybe from a straw man idea of it. The foreword to Pete McBreen's <em class="italics">Software Craftsmanship</em> asks:</p>
			<p><em class="italics">Is software engineering appropriate for projects of less than 100 developer-years? Is the specialization inherent in software engineering a good idea? Can software development even be expressed in engineering terms?</em></p>
			<p>The answer, as far as McBreen is concerned, of course turns out to be "no"; apprenticeship, practice, and self-organized teams are preferred here. Software engineering may be suitable for building space shuttle software, McBreen tells us, but fails the producer of shrink-wrap commercial software or in-house line of business applications. Such applications need the personal touch, and a good programmer would understand not only the technical details of software construction, but the artistry required to make a bespoke piece.</p>
			<p>What that <em class="italics">doesn't</em> address, though, is whether the software craftsmanship movement actually promotes software making as a <em class="italics">craft</em>, or whether it's as much a straw man as the version of engineering discussed in software engineering. The image of the mediaeval craft is as much one of exclusivity and division as that of the professional trade. Master craftsmen would be members of a guild that controlled the practice of the craft (and the dissemination of its secret techniques) in a given region. Other than the guild members, only the apprentices would be allowed to practice (and then only in the limited fashions enabled by their masters). Anyone who had finished their apprenticeship would be booted out to become a "journeyman," taking odd jobs as they traveled to find a town that wasn't already under guild control, where they could set up shop, or until they could submit a "masterpiece" and become a member of the guild.</p>
			<p>That members of the craftsmanship movement in software see this exclusivity as appealing is evident. The <strong class="bold">Software Craftsmanship Manifesto</strong>—<a href="http://manifesto.softwarecraftsmanship.org">http://manifesto.softwarecraftsmanship.org</a> makes this point in both explicit ways:</p>
			<p><em class="italics">we have come to value […] a community of professionals.</em></p>
			<p>…and implicit ways:</p>
			<p><em class="italics">we have come to value […] well-crafted software.</em></p>
			<p>The second example is quite subtle, but what <em class="italics">is</em> "well-crafted software"? It's such a woolly phrase that the only way to get a definition would be by joining the guild of professionals; that is, by submitting to the masters.</p>
			<p>Robert C. Martin likes to take this divisive approach to the language of software by defining "professionals" as those who exhibit desirable qualities, and "unprofessional" as those who do not:</p>
			<ul>
				<li><em class="italics">Legacy code is not inevitable when programmers behave professionally</em>—<a href="https://twitter.com/unclebobmartin/status/298762801164451840">https://twitter.com/unclebobmartin/status/298762801164451840</a></li>
				<li>Here is a <em class="italics">minimal</em> list of the things that every software professional should be conversant with (from <strong class="bold">The Clean Coder</strong>—<a href="http://www.amazon.com/The-Clean-Coder-Professional-Programmers/dp/0137081073">http://www.amazon.com/The-Clean-Coder-Professional-Programmers/dp/0137081073</a>, <em class="italics">Chapter 1</em>, <em class="italics">emphasis original</em>)</li>
				<li>Professionals know they are arrogant and are not falsely humble. A professional knows their job and takes pride in their work. A professional is confident in their abilities and takes bold and calculated risks based on that confidence. A professional is not timid. (<em class="italics">The Clean Coder</em>, <em class="italics">Chapter 1</em>)</li>
			</ul>
			<p>The language used here automatically creates a division among programmers: those who conform to Martin's ideal are "professional," and everybody else is, well, something else. Unprofessional? Amateurish? Not a programmer? It <em class="italics">also</em> creates a division between professional programmers and those they work with. Managers and customers had best not dare question how we're working – we're working <em class="italics">professionally</em>. (Brad Cox, in his book <em class="italics">Superdistribution: Objects as property on the electronic frontier</em>—<a href="http://virtualschool.edu/mon/Superdistribution/">http://virtualschool.edu/mon/Superdistribution/</a>, makes the same point about the division between programmers and non-programmers, so it already existed when he was writing in 1996. He says, tongue in cheek, "The role of customers, and especially of managers, is to stand out of the way, checkbook in hand, admiring the brilliance of this programmer's skill and devotion to his craft.")</p>
			<p>The craftsmanship movement asks whether software is <em class="italics">really</em> a professional engineering discipline, and in answering "no" promotes many of the same ideals and divisions as the software engineering movement or of any regulated profession.</p>
			<p>I would like to pose a different question: is programming <em class="italics">really</em> a social science? To what extent should a programmer know the social, interpersonal side of software construction? Much of the content of this book has focused on the collaborative nature of programming: documentation, management, teamwork, and requirements engineering are all examples of things programmers do that are for or with other people. I would argue, then, that there are few situations in which a programmer can get away <em class="italics">without</em> those skills. The remaining sections in this chapter look at the practice of making software through the lenses of various branches of the social sciences.</p>
			<h2 id="_idParaDest-236"><a id="_idTextAnchor251"/>An Economic Philosophy of Software</h2>
			<h3 id="_idParaDest-237"><a id="_idTextAnchor252"/>Direct Economic Factors</h3>
			<p>Software products are often created or extended as fixed-duration projects. The estimated cost of the project is compared against the estimated revenue generated, and if the balance is favorable then the project is given the go-ahead. Advanced project funders will consider <em class="italics">protected revenue</em> (how many customers will not jump to a competing product if this feature is added) and <em class="italics">opportunity cost</em> (what work could we be doing if we decline this work), factoring those into the decisions about the project.</p>
			<p>I mentioned Barry W. Boehm and his book, <strong class="bold">Software Engineering Economics</strong>—<a href="http://books.google.co.uk/books/about/Software_engineering_economics.html?id=mpZQAAAAMAAJ&amp;redir_esc=y">http://books.google.co.uk/books/about/Software_engineering_economics.html?id=mpZQAAAAMAAJ&amp;redir_esc=y</a> in <em class="italics">Chapter 9, Requirements Engineering</em>. He introduced the idea of human economic factors; assigning a dollar value to the satisfaction (or otherwise) the software would bring to its users, for example. I'll come back to that in the next section, on <em class="italics">Externalities</em>, but for the moment, bear in mind that the expected human economic factors are considered in the <em class="italics">project</em> cost.</p>
			<p>So, strangely enough, the <em class="italics">maintenance</em> costs are considered a part of the project economics in Boehm's COCOMO model. Remember from Lehman's Laws of E-type software that the deployment environment evolves, and the software system must evolve to keep up with it. In Boehm's model, this evolution is accounted for in an entry in the project's costs.</p>
			<p>This maintenance costs fudge seems to be an indicator that something is wrong with the way we're budgeting for software. Some evolutionary changes (feature additions) must be accounted for as explicit projects, their costs explicitly calculated and balanced against projected income. Other evolutionary changes (maintenance fixes) are just considered a necessary risk of writing software, the costs of which are absorbed into the calculations of writing new features.</p>
			<p>Are new features always bigger and more expensive than bug fixes? No. Do bug fixes always cost us money, and never attract or protect income? No. Are new features sometimes snuck into maintenance? Yes. Are bug fixes sometimes held off until new project releases? Yes. Then why aren't they budgeted together?</p>
			<p>It could be for ethical reasons: perhaps programmers feel that maintenance problems are mistakes they should own up to and correct free of charge. But remember that one of Lehman's Laws says that the satisfaction derived from software will decay as the <em class="italics">social environment</em> involves. Not all bugs <em class="italics">were</em> bugs at the time of writing! You cannot be apologetic for work you did <em class="italics">correctly</em> before a change in the environment.</p>
			<p>To me, this suggests a need for a nimbler economic model; one that treats any change equally regardless of whether it's a bug fix, feature addition, or internal quality cleanup. Forget what we've <em class="italics">already</em> spent and made on this product (for that way lies the sunk-cost fallacy), what will the <em class="italics">proposed</em> change cost? What will it get us? How risky is it? What else could we be doing instead? What alternatives do we have?</p>
			<h3 id="_idParaDest-238"><a id="_idTextAnchor253"/>Externalities</h3>
			<p>The above questions only consider the <em class="italics">direct</em> economic impact of making software. There are other factors; factors that have some form of cost or benefit but that don't have a tangible effect on the price or revenue of the work. In economics, these are called <em class="italics">externalities</em>.</p>
			<p>Externalities can be positive or negative, but they can also be personal rather than relating to a company and its work. Software making as a career has all sorts of externalities, in terms of benefits and costs, to being a programmer that aren't reflected in our salaries. Let's consider externalities that affect both the individual as well as the business.</p>
			<p>Open source software is a positive externality for many businesses. Many companies in the software industry take components or systems that have been published freely and incorporate them into their own products or provide "value-added" services such as support. These companies receive value from the open source software without having to pay for creating that software. As an example of open source software as an externality, the cost of writing OpenSSH doesn't factor into the price of macOS X, although OpenSSH is a component of that system.</p>
			<p>The picture for individual programmers is less clear. Leaving aside micro-ISV developers for a moment, who's personal and business goals are often tightly coupled, a career programmer applying for a job might be asked to produce a portfolio of open source projects that they have created or contributed to. I infer from this that <em class="italics">having created</em> open source software has a positive effect: it improves our reputation and the likelihood that we will be hired. On the other hand, <em class="italics">the act of creating</em> open source software can be negative: if you don't do it as part of your job, then you're effectively increasing the amount of work you do without any direct compensation.</p>
			<p>Bugs are negative externalities. Software companies often either price their work according to market forces if they're selling to consumers or based on a day-rate for the initial project if they're selling to a client business. In neither case is the subsequent cost of maintenance factored into the selling price; it's going to be a reduction in profit compared to the same product requiring no maintenance. Customers themselves do not factor bugs into the (economic or psychological) cost of <em class="italics">using</em> software. As argued by David Rice in <em class="italics">Geekonomics: the real price of insecure software</em>—<a href="http://books.google.co.uk/books/about/Geekonomics.html?id=k6cRhfp2aWgC">http://books.google.co.uk/books/about/Geekonomics.html?id=k6cRhfp2aWgC</a>, customers often only have the feature checklist to go on when evaluating a software product and cannot tell anything about its quality. But the quality costs; you pay testers, you triage bug reports, you monitor support channels for problems, and you work on the fixes.</p>
			<p>Some organizations run hackathons or hack days, in which people usually form teams to produce a software-based solution to some challenge, with the winners getting a prize. These hack days can have a positive career effect in that some employers might value contributing to hack days as evidence of community involvement, and they give the opportunity to "sharpen the saw" and try new skills or tools. On the other hand, spending even more time working (especially the all-nighters required at some hack days) will have a bad effect on your health, which is a negative effect.</p>
			<p>Finally, consider whether all of the work that goes into making a software product is even reflected in the label price. If you double the amount you spend on producing a user guide, does the price go up? Probably not. The same goes for localization: you get a larger pool of potential customers, but for the most part you wouldn't be able to raise the price. That shows that, to your customers, localization is an externality: a benefit of localized software but not one that changes how much they pay.</p>
			<p>Companies can factor the value they place on externalities into their decisions by internally charging for them or even passing the costs or savings onto customers: a simple example is that some agency companies will charge less for a project if they're allowed to co-brand the resulting product. The association of the agency's brand with the product and the possibility of that driving future work is a positive externality. Passing savings onto customers—that is, reducing costs when there are positive externalities—is obviously more palatable to them than passing on charges for negative externalities, but the latter can be done. Think of the price premiums on <strong class="bold">organic foods</strong>—<a href="https://www.mint.com/blog/trends/organic-food-07082010/">https://www.mint.com/blog/trends/organic-food-07082010/</a>, which are greater than the cost differences in production (which can, in some cases, be lower than for non-organic foods, due to subsidies—another way to reify an externality). By convincing purchasers that there are real benefits to organic foods, suppliers can command a premium price.</p>
			<h3 id="_idParaDest-239"><a id="_idTextAnchor254"/>Traditional Supply-And-Demand Economics</h3>
			<p>Many economics textbooks will start with a discussion of supply and demand as the key influences on market price: when demand is high or supply is low, prices go up; they go down when demand is low, or supply is high. The problem with applying this economic structure to software pricing is that supply is infinite: there's no "unit cost," so once the software is made, it can be copied over and over until everybody who wants a copy has one. So how can software be sold <em class="italics">at all</em> without prices instantly plummeting to zero?</p>
			<p>In the face of evidence, some people don't believe it can. That's what <strong class="bold">Digital Rights Management</strong> is about: trying to reinsert the scarcity of physical goods into the economics of software (and other digital goods) distribution. But people <em class="italics">do</em> successfully sell software, music, documents (such as this one), and so on without DRM. Rather than noticing the infinite supply "issue" and trying to limit supply, we need to try to understand the market that <em class="italics">does</em> exist, <em class="italics">is</em> sustainable, but that doesn't match long-standing models.</p>
			<p>I'll start with a hypothesis: that what's being traded is not the software itself, but <em class="italics">capability</em> first, and <em class="italics">time</em> second. Given the desire, but inability, to do something as a problem, <em class="italics">anything</em> that solves the problem by enabling that thing is valued. This is what economist Herbert Simon described as bounded rationality, or <strong class="bold">satisficing</strong>—<a href="http://www.economist.com/node/13350892">http://www.economist.com/node/13350892</a>. So, a first solution discovered, whether ideal or not, is still valued. This already explains why the infinite supply "problem" is not real: on discovering that a product can be purchased that meets their needs, a consumer is likely to settle for making the purchase as a satisficing solution—many will not spend extra time on researching a pirated version of the app. (For some people, using a pirated version of an application <em class="italics">does</em> cost, in terms of anxiety. Any decision, however rational, that runs counter to a person's ethics exerts a mental cost. This is understood by the information security sector as one of the limiting factors of controlling security via policy.)</p>
			<p>Having found that the problem can indeed be solved, the customer is then able to spend a little effort on thinking about how to improve that solution. That's where the time-saving part comes in. Now that they know <em class="italics">what</em> they are capable of, it's possible to improve that capability so that they've got more free time for other things: that's also worth money, as Benjamin Franklin made clear. (This argument applies, in a modified form, to games. Just reverse the two factors. <em class="italics">Given</em> that I have time available, can you supply the <em class="italics">capability</em> for me to enjoy its passage?)</p>
			<p>In this model, software itself has no value, compatible with the infinite supply problem in traditional economics. But the customer's time and abilities <em class="italics">are</em> in limited supply, and software can be used as a tool to unlock these. In this sense, paying for software is similar to paying for education: it is not the <em class="italics">teaching</em> that you want, it is the <em class="italics">having been taught</em>. We can then say of software that it is not <em class="italics">creating the solution to the problem</em> that customers value, but <em class="italics">the problem having been solved</em>. Because of the nature of satisfaction, customers will pay for a solution if the cost and the capability are "good enough."</p>
			<p>Looking back to the second paragraph in this chapter, we see that this economic model is just the same philosophy, expressed in economic terms. Our role as people who make software is to <em class="italics">solve problems</em>—we provide a valuable service to our customers by <em class="italics">solving problems</em>.</p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor255"/>A Management Philosophy of Software</h2>
			<p>Imagine a world in which programmers are valued similar to middle managers. But first, disabuse yourself of the idea that managers are inherently useless and evil, and let me explain what a manager is.</p>
			<p>Managers typically don't get paid for doing work; they typically get paid according to how well their team does work, and how much work their team does. Lots of work done badly isn't very good, but not enough work done well isn't desirable either.</p>
			<p>That usually means that they avoid doing work. Given some work to do, their usual action is to find the person on their team most capable of doing the work, and to get them to do the work. They will make that person responsible for doing the work, and (if they're any good) give them the authority to do it.</p>
			<p>But they're not paid for telling the person how to do the work, or for the task of delegating responsibility or authority. In fact, if the work isn't done, or isn't done well, it's the <em class="italics">manager</em> that the rest of the company will hold responsible. They're paid for the work having been done.</p>
			<p><em class="italics">Now</em>, imagine a world in which programmers are valued similar to middle managers: a world in which the programmer is the manager and the computers report to the programmer. The programmer is not paid for <em class="italics">writing software</em> – for explaining to the computer what work needs to be done. The programmer is paid for the computers <em class="italics">having done the work</em> that was assigned, both in sufficient quantity and to sufficient quality. If the computers don't do the work, it's the <em class="italics">programmer</em> who will be held responsible.</p>
			<p>Again, this is just a restatement of the position taken at the beginning of the chapter. While the restatement in the previous section told us what the people who buy software value, this one tells us what should be considered valuable in someone who makes software. We see that "number of lines of code written," "number of story points completed," "number of features added," and "number of bugs fixed" are not, in themselves, valuable things, but perhaps we can see the extent to which each is a useful <em class="italics">proxy</em> of our work.</p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor256"/>A Social Philosophy of Software</h2>
			<p>In <em class="italics">Chapter 9, Requirements Engineering</em>, you saw that software does not stand on its own but is embedded in the social system in which it's used. Much of the rest of this book has discussed a different social system: the system in which software is <em class="italics">developed</em>. A lot of software is made by more than one person. Even in the rare cases where a single person does all the <em class="italics">production</em> (the coding, the design, the UI text, the marketing, the sales, and so on), there will likely be some customer input, even if that just takes the form of support emails.</p>
			<p>So, how are these two social systems accounted for in the field? The typical image of a programmer is of someone (typically a white male in his 20s), working on his own, staring at a monitor. If the outside world is acknowledged at all, it is through its exclusion: the programmer wears his headphones to avoid distractions as he cuts his code. (At the time of writing, and for my account, the results of <em class="italics">a Google Images search for "programmer"</em>— <a href="https://www.google.co.uk/search?q=programmer&amp;aq=f&amp;um=1&amp;ie=UTF-8&amp;hl=en&amp;tbm=isch&amp;source=og&amp;sa=N&amp;tab=wi&amp;ei=4J2TUbOrOZSV0QWI7YHABQ&amp;biw=2560&amp;bih=1368&amp;sei=452TUcKIFoi40QXmjIDYCQ">https://www.google.co.uk/search?q=programmer&amp;aq=f&amp;um=1&amp;ie=UTF-8&amp;hl=en&amp;tbm=isch&amp;source=og&amp;sa=N&amp;tab=wi&amp;ei=4J2TUbOrOZSV0QWI7YHABQ&amp;biw=2560&amp;bih=1368&amp;sei=452TUcKIFoi40QXmjIDYCQ</a> supported this description of the "typical" image.)</p>
			<p>We automatically see all sorts of problems here. The person making the software is a programmer, not any of the other specialists involved. He is male, not female or trans*. He is white, not of any other ethnicity. He is young, not old. He is alone, not working with others. All of these inequalities exist in the <em class="italics">depiction</em> of software makers. All of which fail to capture the diversity and the complexity of the social systems surrounding software systems. Many of these inequalities exist in the depiction of software makers because they exist in the <em class="italics">reality</em> of software making.</p>
			<p>Social scientists ask two high-level questions of any social system they investigate: How is the society made and repaired? What divisions and inequalities does it support? By examining the "conventional" view of a programmer, we have seen some of the inequalities currently supported by the software industry.</p>
			<p>We could potentially find more. Shanley Kane <em class="italics">examined the language used by Silicon Valley start-ups</em>—<a href="http://blog.prettylittlestatemachine.com/blog/2013/02/20/what-your-culture-really-says">http://blog.prettylittlestatemachine.com/blog/2013/02/20/what-your-culture-really-says</a> looking for the underlying biases, for example:</p>
			<h4>We don't have a vacation policy</h4>
			<p class="callout">What your culture might actually be saying is… We fool ourselves into thinking we have a better work/life balance when really people take even less vacation than they would when they had a vacation policy. Social pressure and addiction to work has replaced policy as a regulator of vacation time.</p>
			<p>If true, this implies that those able to work longer hours and take fewer holidays are in a position of relative power within the system. This is turn privileges certain classes of people: those who are younger and do not have children, for example.</p>
			<p>So, that's the social system where software is <em class="italics">made</em>. What about that in which software is <em class="italics">used</em>? There are inequalities and divisions there, too. Commercial software systems (and even free software systems that run on commercial platforms) are only accessible to those who can afford to buy them.</p>
			<p>In the UK, the Office of National Statistics <em class="italics">estimates that over 7 million people have never used the internet</em>. They identify correlations between ability to access the internet and demographic status, so online services are (for example) less likely to be available to people over 75 and to disabled people (This lack of accessibility is before we even consider whether specific services have "accessibility" features as commonly understood by developers.)</p>
			<p>Other inequalities can be found. Many applications have been created to only support the English language, and where they <em class="italics">can</em> be localized, they don't handle non-Gregorian calendars, right-to-left writing systems, characters with diacritic modifiers, and other "non-English" (or non-American) locale features.</p>
			<p>Knowing that these inequalities exist (others do, too) and reporting them is one thing, but probably isn't novel. What are we to do with that awareness?</p>
			<p>Which inequalities you feel are <em class="italics">unjust</em> probably depends on your political views, though the ethics documents described in the previous chapter give us a handy guide. From <strong class="bold">the ACM code of ethics</strong>— <a href="http://www.acm.org/about/code-of-ethics">http://www.acm.org/about/code-of-ethics</a>:</p>
			<p><em class="italics">Inequities between different groups of people may result from the use or misuse of information and technology. In a fair society, all individuals would have equal opportunity to participate in, or benefit from, the use of computer resources regardless of race, sex, religion, age, disability, national origin or other such similar factors. However, these ideals do not justify unauthorized use of computer resources nor do they provide an adequate basis for violation of any other ethical imperatives of this code.</em></p>
			<p>That's quite explicit. The behavior the ACM expects from its members is that of no discrimination whatsoever <em class="italics">within the limits of the rest of the ethical code</em> – as ever, potential ethical conflicts exist. Stealing computer resources from privileged parties for the use of disadvantaged parties (I hereby dub this "Robin Hood scheduling") would be one example of such a conflict.</p>
			<p>An important factor to be aware of in discrimination is <strong class="bold">othering</strong>. Social psychologists differentiate between <strong class="bold">marked and unmarked identities</strong>—<a href="http://cak400.wordpress.com/2012/10/01/marked-and-unmarked-identities-and-social-hierarchy/">http://cak400.wordpress.com/2012/10/01/marked-and-unmarked-identities-and-social-hierarchy/</a>. An "unmarked" identity is what's accepted to be normal, and other identities are differentiated ("marked") by being different from this benchmark. People who talk about immigrants are <em class="italics">marking</em> some people as immigrants, and by extension implicitly defining natives as normal. People who talk about women are <em class="italics">marking</em> some people as women, and implicitly defining men as normal.</p>
			<p>The important aspect with regard to Othering is the asymmetric nature of this distinction: it is between those who are "normal" and those who are "not like us." It's important to realize that we <em class="italics">do</em> this, that it's how our minds <em class="italics">work</em>, to <em class="italics">identify</em> when we're doing it and to consciously <em class="italics">correct</em> for it. As <em class="italics">Mike Lee put it</em>—<a href="https://twitter.com/bmf/status/333960606837272577">https://twitter.com/bmf/status/333960606837272577</a>:</p>
			<p><em class="italics">We put those qualities into the other that we reject in ourselves. But that blinds us to the reality.</em></p>
			<p>So, next time you think "normal people wouldn't want <em class="italics">that</em> feature," or "no one with an ounce of common sense would use it <em class="italics">that</em> way," ask whether you <em class="italics">really</em> think "people who aren't like me wouldn't want that," then consider whether you're making software for the small number of people who are like you, or for everyone.</p>
			<h2 id="_idParaDest-242"><a id="_idTextAnchor257"/>A Pedagogic Philosophy of Software</h2>
			<p>This is the most technical and low-level part of the philosophy chapter, and the one I'm least qualified to talk about. I've done a couple of years of teaching programming at a university but as one of the most obvious features of university teaching is that no one trains you before you start, I'm not sure whether that counts.</p>
			<p>It's easy to find assertions that <em class="italics">academic computer science bears no relation to practice</em>—<a href="http://shape-of-code.coding-guidelines.com/2013/05/15/wot-apply-academic-work-in-industry/">http://shape-of-code.coding-guidelines.com/2013/05/15/wot-apply-academic-work-in-industry/</a> and that <em class="italics">computer science is not adequate preparation for a career in software</em>. Is this a problem? If it is, what is the cause? What alternatives are there?</p>
			<p>The divergence between commercial and academic software practices began early in the history of computing. The first version of the ACM curriculum described in <em class="italics">Software as a pursuit</em> was <strong class="bold">Curriculum 68</strong>—<a href="http://dl.acm.org/citation.cfm?id=362976">http://dl.acm.org/citation.cfm?id=362976</a>. In the introduction to this curriculum, the authors make it clear that the academic computer science course is not appropriate for training professional IT staff:</p>
			<p><em class="italics">For example, these recommendations are not directed to the training of computer operators, coders, and other service personnel. Training for such positions, as well as for many programming positions, can probably be supplied best by applied technology programs, vocational institutes, or junior colleges. It is also likely that the majority of applications programmers in such areas as business data processing, scientific research, and engineering analysis will continue to be specialists educated in the related subject matter areas, although such students can undoubtedly profit by taking a number of computer science courses.</em></p>
			<p>So, the curriculum was created with the knowledge that it would <em class="italics">not</em> apply directly to those who wish to be professional programmers. While vocational courses do exist, it's very common to meet capable self-taught programmers who had no formal introduction to the field – myself included. There's a <em class="italics">lot</em> of information about how to make software out in the world, which the self-taught must discover somehow: ultimately, much will be learned by trial and error. The <strong class="bold">Software Engineering Body of Knowledge</strong>—<a href="https://www.computer.org/education/bodies-of-knowledge/software-engineering">https://www.computer.org/education/bodies-of-knowledge/software-engineering</a> can be thought of as a guide to what to learn from the published literature on software engineering. When formatted as a book, the guide is longer than this text. Like this book, the guide itself is not at the level of "this is how software is made" but at the level of "these are the things you should bear in mind while making software." So, we have a 200-page guide to 13 "knowledge areas," which comprise lists of things you should know, with <em class="italics">some</em> references to available literature. The knowledge areas, the topics chosen in each, and the currency and validity of the references are all (as you could probably expect from this field) contentious, so the <strong class="bold">SWEBOK</strong> (<strong class="bold">Software Engineering Body of Knowledge</strong>) represents a conservative selection of ideas that have definitely become broadly applied.</p>
			<p>How can the self-taught programmer get up to speed on this huge and evolving body of knowledge? Supporters of "software as a profession" would say that they can't; that it's up to professional bodies to teach and maintain the body of knowledge and to ensure that only those who are up to speed may be considered programmers. Supporters of "software as a craft" would also say that they can't: that they need the expert guidance that comes from apprenticeship, then the period of self-searching that comes from being a journeyman.</p>
			<p>But, reflecting on <em class="italics">Chapter 10, Learning</em>, I have to ask: is the SWEBOK anything other than a <em class="italics">curriculum</em> for learning, whether taught or self-directed? It's presented at quite an abstract level (and in a very dry style), so may work better for instructors to decide what to teach than for beginners trying to find out what to <em class="italics">learn</em>. </p>
			<p>That content – not necessarily the SWEBOK itself, but something akin to it – could easily be adapted into a guide for self-learning. The pattern I find most appropriate for this is the competency matrix: I have evaluated my own knowledge of computer science against <strong class="bold">the Programmer Competency Matrix</strong>—<a href="http://www.starling-software.com/employment/programmer-competency-matrix.html">http://www.starling-software.com/employment/programmer-competency-matrix.html</a> over the last few years, and in the course of writing this text created <strong class="bold">the Programmer Courtesy Matrix</strong>—<a href="http://blog.securemacprogramming.com/2013/04/rebooting-the-programmer-competency-matrix/">http://blog.securemacprogramming.com/2013/04/rebooting-the-programmer-competency-matrix/</a> to summarize the material.</p>
			<p>Where the matrix succeeds is that it gives learners a handy way to evaluate their own progress (whether through reflection, or discussion with evaluators or educators) and to understand what's needed to advance in any particular row of the matrix. The columnar layout provides guidance on what's "next" and what can be left to "later."</p>
			<p><em class="italics">This ordering is something I struggled with early in my career. I was working at a large company that had progression through technical roles: software engineer, senior software engineer, principal software engineer, and software architect. I was hired at the first level but quickly got promoted to senior software engineer. Because I focused on the next level, I tried to learn about the responsibilities of the principal engineer before consolidating and extending my understanding of the senior role. I therefore didn't make a particularly good senior engineer: a prerequisite for moving onward.</em></p>
			<p>Where the matrix <em class="italics">fails</em> is at the part the <strong class="bold">SWEBOK</strong> does well: giving you references to material at each level, so the learner knows <em class="italics">where</em> to find the information to progress. That part of a curriculum is much more contextual: a curriculum for self-learning might point to books, articles, conference presentations, or websites for where to learn; a curriculum for directed learning might suggest particular training or university courses, or a problem set to be assessed by an educator. The point is that there's no reason a self-taught programmer can't, with awareness of the field and their own capabilities, provided by a competency matrix, progress as a career programmer – maybe at a different pace to a taught or master-bound programmer, but progressing, nonetheless.</p>
			<p>Referring this discussion (and <em class="italics">Chapter 10, Learning</em>) back to the position statement at the beginning of this chapter, the teaching of software makers should really be considered the teaching of <em class="italics">problem identification and solution</em> within the context of software systems. From this view, the goals of teaching in the academic and commercial fields are compatible; it's just the choice of problems to solve (and hence the focus on particular areas of the body of knowledge, equivalent to particular rows in the competency matrix) that are different.</p>
			<p>For novice programmers, the self-taught, apprenticed, and educated (Beware of reading a false dichotomy in this sentence; self-taught and apprenticed programmers are not "uneducated," they just did not learn how to make software <em class="italics">from an educator</em>) alike, the course from hobbyist to professional software making – whatever the context in which that software is made, and whatever the specific definition of "professional" we choose – starts with <em class="italics">awareness</em> of software as a means to solve problems, not as an end in itself. The next step is <em class="italics">awareness</em> of the gap between their novice competence and the current state of the art. How they choose to close that gap is less important than awareness of the gap's existence.</p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor258"/>What Does It Mean to Be "Good" At Making Software?</h2>
			<p>Statements abound about the productivity of people who make software. Many people claim <em class="italics">that some programmers are 10x more productive than others</em>—<a href="http://www.johndcook.com/blog/2011/01/10/some-programmers-really-are-10x-more-productive/">http://www.johndcook.com/blog/2011/01/10/some-programmers-really-are-10x-more-productive/</a>. What does that <em class="italics">mean</em>?</p>
			<p>Presumably, to come up with a quantity, even a relative one like "10x," we have some quantitative measure that can be applied to people who make software in different contexts. What is that quantity? The number of significant lines of code written? If so, should we sack programmers <em class="italics">who write -2000 lines of code in a day</em>—<a href="http://folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt">http://folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt</a>?</p>
			<p>How about the time taken to fix a bug, the measure originally applied (to a small number of programmers) to discover the 10x figure? Maybe the programmers aren't more productive, but <em class="italics">we caught them on a good day</em>? What about the programmer who spent more time ensuring the bug wasn't present in the first place? Is that person more diligent or wasting time gold-plating?</p>
			<p>If you accept the view of software making presented here, then the <em class="italics">amount of software one can write</em> is, regardless of the way you measure it, irrelevant to the question of how good the maker is. The relevant question is how many problems the software maker removed from (or introduced into) the system in which their customers are working.</p>
			<p><em class="italics">One of the most effective demonstrations of this measure of productivity came from a friend who was asked by a potential client to design a mobile app to solve a particular issue the client's business had. Having met with the client and discussed their problems, this person observed that a spreadsheet was a better solution than the mobile app. They thus declined the opportunity to waste the client's money creating a suboptimal solution. That person could get their spreadsheet written, and the software maker could turn their attention to more appropriate uses of their skills.</em></p>
			<p>Unfortunately, the question of whether software's net effect in a system has been to solve or to introduce problems is unanswered, and is perhaps unanswerable, as systems get large. For example, until the 1980s, many offices in Western organizations employed a largely female typing pool, albeit on low wages and in noisy environments. After the introduction of the desktop computer, those typists were replaced by people in traditionally higher-status jobs preparing their own documents with word-processing applications. Those applications and the computers they ran on were supported by a predominantly male IT support workforce.</p>
			<p>To the businesses in which those changes occurred, was the IT support department more or less cost-effective than the typing pool? Was typing in a word processor a better use of an executive's time than handwriting a manuscript for a typist? Do desktop computers and office printers cause fewer problems than a few dozen typewriters, or more problems?</p>
			<p>At a social level, have the unemployed typists been freed from the tyranny of the typing pool, or have they been excluded from the workforce? Has the computer been good or bad for gender equality? Has software opened up more opportunities than it has removed?</p>
			<p>These are complicated questions, and I'm going to finish without answering them. Suffice it to say that, while our new metric for productivity is better philosophically than things like lines of code, it's a lot harder to apply.</p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor259"/>Conclusion</h2>
			<p>I wrote this book to reflect on what I knew about making software and to understand what I didn't know about making software. I published it so that you could take advantage of what I've found over the decade I've been doing this for a living, and to trigger your own reflections on your experiences (with the hope that you would share these with us, just as I have).</p>
			<p>I started by looking at the things we do when we're at the coal face: the tools and practices we use to convert ideas into software. Then I looked at how we work with other people: how we document what we've done; how we find out what software needs writing; how we take advantage of opportunities to learn from other people, interpret other people's arguments, and work with them in the context of a team or a business. Finally, I tried to construct a high-level model in which to situate <a id="_idTextAnchor260"/>all of that work, by considering the ethics and philosophy of making software, and how to move our knowledge forward by teaching this generation's novices.</p>
			<p>Through this process, I found that, while computer science may be able to tell us something about the compilers and languages we use on computers, software products can't be isolated from the <em class="italics">social</em> systems in which they're made and used. Psychology, sociology, ethnography, and economics: all of the social sciences have wisdom to impart that can help us use our skills as software makers to solve problems for people.</p>
			<p>Unfortunately, this work closed on a quandary: while different bodies of software makers have identified the ethical imperative to avoid discrimination, we cannot unequivocally say that our industry has not caused <em class="italics">new</em> divisions and inequalities in the societies it has affected. Questions of whether to use web or native technologies, or whether functional or object-oriented programming styles are "better" will either be answered, become irrelevant, or both. The question of whether our work removes or strengthens divisions between people will never go away and will be the measure by which history judges what we do.</p>
		</div>
		<div>
			<div class="Content" id="_idContainer065">
			</div>
		</div>
	</body></html>