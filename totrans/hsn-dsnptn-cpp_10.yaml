- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Local Buffer Optimization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地缓冲区优化
- en: Not all design patterns are concerned with designing class hierarchies. For
    commonly occurring problems, a software design pattern is the most general and
    reusable solution, and, for those programming in C++, one of the most commonly
    occurring problems is inadequate performance. One of the most common causes of
    such poor performance is inefficient memory management. Patterns were developed
    to deal with these problems. In this chapter, we will explore one such pattern
    that addresses, in particular, the overhead of small, frequent memory allocations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有设计模式都关注于设计类层次结构。对于常见问题，软件设计模式是最通用和可重用的解决方案，而对于使用 C++ 的程序员来说，最常见的问题之一是性能不足。这种糟糕性能的最常见原因是不高效的内存管理。模式是为了解决这些问题而开发的。在本章中，我们将探讨一种特别针对小型、频繁内存分配开销的模式。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What is the overhead of small memory allocations, and how can it be measured?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型内存分配的开销是什么，如何进行测量？
- en: What is local buffer optimization, how does it improve performance, and how
    can the improvements be measured?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地缓冲区优化是什么，它如何提高性能，以及如何测量这些改进？
- en: When can the local buffer optimization pattern be used effectively?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在什么情况下可以有效地使用本地缓冲区优化模式？
- en: What are the possible downsides of, and restrictions on, the use of the local
    buffer optimization pattern?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用本地缓冲区优化模式可能有哪些潜在缺点和限制？
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will need the Google Benchmark library installed and configured, details
    for which can be found here: [https://github.com/google/benchmark](https://github.com/google/benchmark)
    (see [*Chapter 4*](B19262_04.xhtml#_idTextAnchor152), *Swap – From Simple to Subtle*,
    for installation instructions).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装和配置 Google Benchmark 库，详细信息可以在以下链接找到：[https://github.com/google/benchmark](https://github.com/google/benchmark)（参见
    [*第 4 章*](B19262_04.xhtml#_idTextAnchor152)，*交换 – 从简单到微妙*，有关安装说明）。
- en: 'Example code can be found at the following link: [https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/main/Chapter10).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 示例代码可以在以下链接找到：[https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/main/Chapter10)。
- en: The overhead of small memory allocations
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小型内存分配的开销
- en: The local buffer optimization is just that - an optimization. It is a performance-oriented
    pattern, and we must, therefore, keep in mind the first rule of performance -
    never guess anything about performance. Performance, and the effect of any optimization,
    must be measured.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本地缓冲区优化仅仅是优化。它是一个面向性能的模式，因此我们必须牢记性能的第一规则——永远不要对性能做出任何猜测。性能，以及任何优化的影响，都必须进行测量。
- en: The cost of memory allocations
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存分配的成本
- en: 'Since we are exploring the overhead of memory allocations and the ways to reduce
    it, the first question we must answer is how expensive a memory allocation is.
    After all, nobody wants to optimize something so fast that it needs no optimization.
    We can use Google Benchmark (or any other microbenchmark, if you prefer) to answer
    this question. The simplest benchmark to measure the cost of memory allocation
    might look like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在探索内存分配的开销及其降低方法，我们必须回答的第一个问题是内存分配有多昂贵。毕竟，没有人想优化一个如此快速以至于不需要优化的东西。我们可以使用
    Google Benchmark（或任何其他微基准测试，如果你更喜欢）来回答这个问题。测量内存分配成本的最简单基准可能看起来像这样：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `benchmark::DoNotOptimize` wrapper prevents the compiler from optimizing
    away the unused variable. Alas, this experiment is probably not going to end well;
    the microbenchmark library needs to run the test many times, often millions of
    times, to accumulate a sufficiently accurate average runtime. It is highly likely
    that the machine will run out of memory before the benchmark is complete. The
    fix is easy enough, we must also free the memory we allocated:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`benchmark::DoNotOptimize` 包装器阻止编译器优化掉未使用的变量。唉，这个实验可能不会有一个好结果；微基准测试库需要多次运行测试，通常是数百万次，以积累足够准确的平均运行时间。在基准测试完成之前，机器很可能耗尽内存。修复方法是足够的简单，我们必须释放我们分配的内存：'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We must note that we now measure the cost of both allocation and deallocation,
    which is reflected in the changed name of the function. This is not an unreasonable
    change; any allocated memory will need to be deallocated sometime later, so the
    cost must be paid at some point. We have also changed the benchmark to be parameterized
    by the allocation size. If you run this benchmark, you should get something like
    this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须注意，我们现在测量的是分配和释放的成本，这反映在函数名称的改变上。这种改变并不不合理；任何分配的内存最终都需要释放，因此成本必须在某个时候支付。我们还改变了基准测试，使其由分配大小参数化。如果你运行这个基准测试，你应该得到类似以下的结果：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This tells us that the allocation and deallocation of `64` bytes of memory
    cost about `19` nanoseconds on this particular machine, which adds up to 52 million
    allocations/deallocations per second. If you’re curious whether the *64 bytes*
    size is special in some way, you can change the size value in the argument of
    the benchmark, or run the benchmark for a whole range of sizes:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，在这个特定的机器上，分配和释放`64`字节内存的成本大约是`19`纳秒，这意味着每秒可以完成5200万次分配/释放。如果你对`64`字节的大小是否以某种方式特别感兴趣，你可以改变基准中参数的尺寸值，或者为一系列尺寸运行基准测试：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You might also note that, so far, we have measured the time it takes to make
    the very first memory allocation in the program since we have not allocated anything
    else. The C++ runtime system probably did some dynamic allocations at the startup
    of the program, but still, this is not a very realistic benchmark. We can make
    the measurement more relevant by reallocating some amount of memory:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还会注意到，到目前为止，我们只测量了程序中第一次内存分配所需的时间，因为我们还没有分配其他任何东西。C++运行时系统可能在程序启动时进行了一些动态分配，但这仍然不是一个非常现实的基准。我们可以通过重新分配一些内存来使测量更加相关：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we make `N` calls to `malloc` before starting the benchmark. Further improvements
    can be achieved by varying the allocation size during the reallocations. We have
    also replicated the body of the benchmark loop `32` times (using the C preprocessor
    macro) to reduce the overhead of the loop itself on the measurement. The time
    reported by the benchmark is now the time it takes to do `32` allocations and
    deallocations, which is not very convenient, but the allocation rate remains valid,
    since we have accounted for the loop unrolling, and multiplied the number of iterations
    by `32` when setting the number of processed items (in Google Benchmark, an item
    is whatever you want it to be, and the number of items per second is reported
    at the end of the benchmark, so we have declared one allocation/deallocation to
    be an item).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在开始基准测试之前调用`malloc` `N`次。通过在重新分配期间改变分配大小，我们可以实现进一步的改进。我们还使用C预处理器宏将基准循环的主体复制了`32`次，以减少循环本身在测量中的开销。基准测试报告的时间现在是进行`32`次分配和释放所需的时间，这不太方便，但分配率仍然是有效的，因为我们已经考虑了循环展开，并在设置处理项目数量时将迭代次数乘以`32`（在Google
    Benchmark中，项目是你想要它成为的任何东西，每秒的项目数量在基准测试结束时报告，因此我们声明一次分配/释放为一个项目）。
- en: Even with all these modifications and improvements, the final result is going
    to be pretty close to our initial measurement of `54` million allocations per
    second. This seems very fast, just `18` nanoseconds. Remember, however, that a
    modern CPU can do dozens of instructions in this time. As we are dealing with
    small allocations, it is highly likely that the processing time spent on each
    allocated memory fragment is also small, and the overhead of allocation is non-trivial.
    This, of course, represents guessing about performance and is something I warned
    you against, and so we will confirm this claim via direct experiments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 即使经过所有这些修改和改进，最终结果也将非常接近我们最初的每秒`54`百万次分配的测量值。这似乎非常快，只有`18`纳秒。然而，请记住，现代CPU可以在这么短的时间内执行数十条指令。由于我们处理的是小分配，因此每个分配的内存片段的处理时间也很小，分配的开销也不可忽视。这当然是对性能的猜测，也是我之前警告过你的，因此我们将通过直接实验来验证这一说法。
- en: 'First, however, I want to show you another reason why small memory allocations
    are particularly inefficient. So far, we have explored the cost of memory allocations
    on only one thread. Today, most programs that have any performance requirements
    at all are concurrent, and C++ supports concurrency and multi-threading. Let’s
    take a look at how the cost of memory allocations changes when we do it on several
    threads at once:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，首先我想向你展示另一个原因，为什么小内存分配特别低效。到目前为止，我们只探索了在单个线程上内存分配的成本。如今，大多数有性能要求的程序都是并发的，C++支持并发和多线程。让我们看看当我们在多个线程上同时进行内存分配时，成本是如何变化的：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The result greatly depends on the hardware and the version of `malloc` used
    by the system. Also, on large machines with many CPUs, you can have many more
    than two threads.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 结果很大程度上取决于硬件和系统使用的`malloc`版本。此外，在拥有许多CPU的大机器上，你可以有超过两个线程。
- en: 'Nonetheless, the overall trend should look something like this:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，整体趋势应该看起来像这样：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is quite dismal; the cost of allocations increased several times when we
    went from one thread to two (on a larger machine, a similar increase is going
    to happen, but probably with more than two threads). The system memory allocator
    appears to be the bane of effective concurrency. There are better allocators that
    can be used to replace the default `malloc()` allocator, but they have their own
    downsides. Plus, it would be better if our C++ program did not depend on a particular,
    non-standard, system library replacement for its performance. We need a better
    way to allocate memory. Let’s have a look at it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当令人沮丧；当我们从单个线程增加到两个线程（在更大的机器上，类似的增加将会发生，但可能涉及超过两个线程）时，分配的成本增加了几倍。系统内存分配器似乎成为了有效并发的祸害。有更好的分配器可以用来替换默认的`malloc()`分配器，但它们也有自己的缺点。此外，如果我们的C++程序不依赖于特定、非标准的系统库替换以获得性能，那就更好了。我们需要一种更好的内存分配方式。让我们来看看。
- en: Introducing local buffer optimization
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入局部缓冲区优化
- en: The least amount of work a program can do to accomplish a certain task is no
    work at all. Free stuff is great. Similarly, the fastest way to allocate and deallocate
    memory is this - don’t. Local buffer optimization is a way to get something for
    nothing; in this case, to get some memory for no additional computing cost.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 程序完成特定任务所需做的最少工作就是什么都不做。免费的东西很棒。同样，分配和释放内存最快的方式就是——不做。局部缓冲区优化是一种不劳而获的方式；在这种情况下，不增加额外的计算成本就能获得一些内存。
- en: The main idea
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要思想
- en: 'To understand local buffer optimization, you have to remember that memory allocations
    do not happen in isolation. Usually, if a small amount of memory is needed, the
    allocated memory is used as a part of some data structure. For example, let’s
    consider a very simple character string:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解局部缓冲区优化，你必须记住内存分配并不是孤立发生的。通常情况下，如果需要少量内存，分配的内存会被用作某些数据结构的一部分。例如，让我们考虑一个非常简单的字符串：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The string allocates its memory from `malloc()` via a `strdup()` call and returns
    it by calling `free()`. To be in any way useful, the string would need many more
    member functions, but these are sufficient for now to explore the overhead of
    memory allocation. Speaking of allocation, every time a string is constructed,
    copied, or assigned, an allocation happens. To be more precise, every time a string
    is constructed, an additional allocation happens; the string object itself has
    to be allocated somewhere, which may be on the stack for a local variable, or
    on the heap if the string is a part of some dynamically allocated data structure.
    In addition to that, an allocation for the string data happens, and the memory
    is always taken from `malloc()`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串通过`strdup()`调用从`malloc()`分配内存，并通过调用`free()`返回它。为了在任何程度上有用，字符串需要更多的成员函数，但就现在而言，这些已经足够探索内存分配的开销了。说到分配，每次字符串被构造、复制或赋值时，都会发生分配。更准确地说，每次字符串被构造时，都会发生额外的分配；字符串对象本身必须被分配到某个地方，这可能是在栈上的局部变量，或者如果字符串是某些动态分配的数据结构的一部分，则是在堆上。此外，还会为字符串数据发生分配，内存总是从`malloc()`中获取。
- en: This, then, is the idea of the local buffer optimization - why don’t we make
    the string object larger so it can contain its own data? That really would be
    getting something for nothing; the memory for the string object has to be allocated
    anyway, but the additional memory for the string data we would get at no extra
    cost. Of course, a string can be arbitrarily long, so we do not know in advance
    how much larger we need to make the string object to store any string the program
    will encounter. Even if we did, it would be a tremendous waste of memory to always
    allocate an object of that large size, even for very short strings.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是局部缓冲区优化的想法——我们为什么不将字符串对象做得更大，以便它可以包含自己的数据呢？这实际上真的是不劳而获；字符串对象的内存无论如何都需要分配，但我们可以得到额外的字符串数据内存，而无需额外成本。当然，字符串可以任意长，所以我们事先不知道需要将字符串对象做得多大才能存储程序可能遇到的任何字符串。即使我们知道，总是分配那么大的对象，即使是对于非常短的字符串，也会造成巨大的内存浪费。
- en: We can, however, make an observation - the longer the string is, the longer
    it takes to process it (copy, search, convert, or whatever we need to do with
    it).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以观察到——字符串越长，处理它所需的时间就越长（复制、搜索、转换或我们需要对其进行的任何操作）。
- en: 'For very long strings, the cost of allocations is going to be small compared
    to the cost of processing. For short strings, on the other hand, the cost of the
    allocation could be significant. Therefore, the most performance benefit can be
    obtained by storing short strings in the object itself, while any string that
    is too long to fit in the object will be stored in allocated memory as before.
    This is, in a nutshell, local buffer optimization, which for strings is also known
    as **short string optimization**; the object (string) contains a local buffer
    of a certain size, and any string that fits into that buffer is stored directly
    inside the object:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常长的字符串，分配的成本与处理成本相比将非常小。另一方面，对于短字符串，分配的成本可能会很大。因此，通过在对象本身存储短字符串，而将任何太长无法放入对象的字符串存储在分配的内存中，我们可以获得最大的性能提升。简而言之，这就是局部缓冲区优化，对于字符串来说也被称为**短字符串优化**；对象（字符串）包含一个特定大小的本地缓冲区，任何适合该缓冲区的字符串都直接存储在对象内部：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the preceding code example, the buffer size is set statically at `16` characters,
    including the null character used to terminate the string. Any string that is
    longer than `16` is allocated from `malloc()`. When assigning or destroying a
    string object, we must check whether the allocation was done or the internal buffer
    was used, in order to appropriately release the memory used by the string.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码示例中，缓冲区大小被静态设置为`16`个字符，包括用于终止字符串的空字符。任何长度超过`16`的字符串都将从`malloc()`分配。在分配或销毁字符串对象时，我们必须检查是否进行了分配或使用了内部缓冲区，以便适当地释放字符串使用的内存。
- en: Effect of local buffer optimization
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局部缓冲区优化的效果
- en: 'How much faster is `small_string` compared to `simple_string`? That depends,
    of course, on what you need to do with it. Let’s start with just creating and
    deleting the strings. To avoid typing the same benchmark code twice, we can use
    the template benchmark, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`small_string`与`simple_string`相比快多少？这当然取决于你需要用它做什么。让我们从仅仅创建和删除字符串开始。为了避免两次输入相同的基准代码，我们可以使用模板基准，如下所示：'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result is quite impressive:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果相当令人印象深刻：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It gets even better when we try the same test on multiple threads:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在多个线程上尝试相同的测试时，情况甚至更好：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Regular string creation is slightly faster on two threads, but creating short
    strings is almost exactly twice as fast (and again twice as fast on four threads).
    Of course, this is pretty much the best-case scenario for small string optimization
    - firstly because all we do is create and delete strings, which is the very part
    we optimized, and secondly because the string is a local variable its memory is
    allocated as a part of the stack frame, so there is no additional allocation cost.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个线程上，常规字符串创建稍微快一些，但创建短字符串几乎正好快两倍（在四个线程上再次快两倍）。当然，这几乎是短字符串优化的最佳情况——首先是因为我们做的只是创建和删除字符串，这正是我们优化的部分，其次是因为字符串是局部变量，其内存作为栈帧的一部分分配，因此没有额外的分配成本。
- en: However, this is not an unreasonable case; after all, local variables are not
    rare at all, and if the string is a part of some larger data structure, the allocation
    cost for that structure has to be paid anyway, so allocating anything else at
    the same time and without additional cost is effectively free.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是一个不合理的情况；毕竟，局部变量并不罕见，如果字符串是某个大型数据结构的一部分，那么该结构的分配成本无论如何都必须支付，因此同时分配其他任何东西而无需额外成本实际上是免费的。
- en: 'Nonetheless, it is unlikely that we only allocate the strings to immediately
    deallocate them, so we should consider the cost of other operations. We can expect
    similar improvements for copying or assigning strings, as long as they stay short,
    of course:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们不太可能只分配字符串然后立即释放它们，因此我们应该考虑其他操作的成本。只要它们保持较短，我们可以期望复制或分配字符串会有类似的改进：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Indeed, a similar dramatic performance gain is observed:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，也观察到了类似的戏剧性的性能提升：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We are also likely to need to read the data in the strings at least once, to
    compare them or search for a specific string or character, or compute some derived
    value. We do not expect improvements of a similar scale for these operations,
    of course, since none of them involves any allocations or deallocations. You might
    ask why, then, should we expect any improvements at all?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能需要至少读取字符串中的数据一次，以比较它们或搜索特定的字符串或字符，或者计算一些派生值。当然，我们并不期望这些操作会有类似的规模改进，因为它们都不涉及任何分配或释放。那么，为什么我们仍然期望有任何改进呢？
- en: 'Indeed, a simple test of string comparison, for example, shows no difference
    between the two versions of the string. In order to see any benefit, we have to
    create many string objects and compare them:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，一个简单的字符串比较测试，例如，显示两个字符串版本之间没有差异。为了看到任何好处，我们必须创建许多字符串对象并将它们进行比较：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For small values of `N` (a small total number of strings), there won’t be any
    significant benefit from the optimization. But when we have to process many strings,
    comparing strings with the small string optimization can be approximately twice
    as fast:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`N`值较小的情况（字符串的总数较少），优化不会带来任何显著的好处。但是，当我们必须处理许多字符串时，使用小字符串优化比较字符串可以大约快两倍：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Why is that happening, if there are no allocations at all? This experiment shows
    the second, very important, benefit of local buffer optimization - improved cache
    locality. The string object itself has to be accessed before the string data can
    be read; it contains the pointer to the data. For the regular string, accessing
    the string characters involves two memory accesses at different, generally unrelated
    addresses. If the total amount of data is large, then the second access, to the
    string data, is likely to miss the cache and wait for the data to be brought from
    the main memory. On the other hand, the optimized string keeps the data close
    to the string object, so that once the string itself is in the cache, so is the
    data. The reason that we need a sufficient amount of different strings to see
    this benefit is that with few strings, all string objects and their data can reside
    in the cache permanently. Only when the total size of the strings exceeds the
    size of the cache will the performance benefits manifest themselves. Now, let’s
    dive deeper into some additional optimizations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有任何分配，为什么会发生这种情况？这个实验显示了局部缓冲区优化的第二个、非常重要的好处——提高了缓存局部性。在读取字符串数据之前，必须访问字符串对象本身；它包含数据的指针。对于常规字符串，访问字符串字符涉及两次不同的、通常无关的地址的内存访问。如果数据总量很大，那么第二次访问，即访问字符串数据，很可能会错过缓存并等待数据从主内存中传输过来。另一方面，优化的字符串将数据保持得靠近字符串对象，因此一旦字符串本身在缓存中，数据也在缓存中。我们需要足够多的不同字符串来看到这种好处的原因是，当字符串很少时，所有字符串对象及其数据可以永久地驻留在缓存中。只有当字符串的总大小超过缓存大小时，性能好处才会显现出来。现在，让我们更深入地探讨一些额外的优化。
- en: Additional optimizations
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的优化
- en: 'The `small_string` class we have implemented has an obvious inefficiency -
    when the string is stored in the local buffer, we do not really need the pointer
    to the data. We know exactly where the data is, in the local buffer. We do need
    to know, somehow, whether the data is in the local buffer or in the externally
    allocated memory, but we don’t need to use 8 bytes (on a 64-bit machine) just
    to store that. Of course, we still need the pointer for storing longer strings,
    but we could reuse that memory for the buffer when the string is short:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的`small_string`类存在一个明显的低效之处——当字符串存储在本地缓冲区时，我们实际上并不需要数据的指针。我们确切地知道数据在哪里，就在本地缓冲区中。我们确实需要以某种方式知道数据是存储在本地缓冲区还是外部分配的内存中，但仅仅为了存储这一点，我们并不需要使用8个字节（在64位机器上）。当然，我们仍然需要指针来存储较长的字符串，但当我们处理短字符串时，我们可以重复使用那段内存：
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, we use the last byte as a `tag` to indicate whether the string is stored
    locally (`tag == 0`) or in a separate allocation (`tag == 1`). Note that the total
    buffer size is still `16` characters, `15` for the string itself and `1` for the
    tag, which also doubles at the trailing zero if the string needs all `16` bytes
    (this is why we have to use `tag == 0` to indicate local storage, as it would
    cost us an extra byte to do otherwise). The pointer is overlaid in memory with
    the first `8` bytes of the character buffer. In this example, we have chosen to
    optimize the total memory occupied by the string; this string still has a 16-character
    local buffer, just like the previous version, but the object itself is now only
    16 bytes, not 24\. If we were willing to keep the object size the same, we could
    have used a larger buffer and stored longer strings locally. The benefit of the
    small string optimization does, generally, diminish as the strings become longer.
    The optimal crossover point from local to remote strings depends on the particular
    application and must of course be determined by benchmark measurements.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用最后一个字节作为`tag`来指示字符串是存储在本地（`tag == 0`）还是单独的分配中（`tag == 1`）。请注意，总缓冲区大小仍然是`16`个字符，`15`个用于字符串本身，`1`个用于tag，如果字符串需要所有`16`个字节，这个tag也会变成尾随的零（这就是为什么我们必须使用`tag
    == 0`来指示本地存储，否则会多浪费一个字节）。指针覆盖在字符缓冲区的第一个`8`个字节上。在这个例子中，我们选择优化字符串占用的总内存；这个字符串仍然有16个字符的本地缓冲区，就像之前的版本一样，但对象本身现在只有16个字节，而不是24个。如果我们愿意保持对象大小不变，我们可以使用更大的缓冲区并本地存储更长的字符串。一般来说，随着字符串变长，小字符串优化的好处会逐渐减少。从本地到远程字符串的最佳转换点取决于特定的应用程序，并且当然必须通过基准测试来确定。
- en: Local buffer optimization beyond strings
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越字符串的本地缓冲区优化
- en: The local buffer optimization can be used effectively for much more than just
    short strings. In fact, any time a small dynamic allocation of a size that is
    determined at runtime is needed, this optimization should be considered. In this
    section, we will consider several such data structures.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本地缓冲区优化可以有效地用于比短字符串更多的情况。实际上，任何需要运行时确定大小的动态小分配时，都应该考虑这种优化。在本节中，我们将考虑几个这样的数据结构。
- en: Small vector
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小向量
- en: 'Another very common data structure that often benefits from local buffer optimization
    is vectors. Vectors are essentially dynamic contiguous arrays of data elements
    of the specified type (in this sense, a string is a vector of bytes, although
    null termination gives strings their own specifics). A basic vector, such as `std::vector`
    found in the C++ standard library, needs two data members, a data pointer and
    the data size:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常常见的、经常从本地缓冲区优化中受益的数据结构是向量。向量本质上是由指定类型的数据元素组成的动态连续数组（在这个意义上，字符串是字节的向量，尽管空终止符赋予了字符串其特定的特性）。一个基本的向量，如C++标准库中找到的`std::vector`，需要两个数据成员，一个数据指针和一个数据大小：
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Vectors are usually templates, like the standard `std::vector`, but we have
    simplified this example to show a vector of integers (converting this vector class
    to a template is left as an exercise for you, and does not in any way alter the
    application of the local buffer optimization pattern). We can apply *small vector
    optimization* and store the vector data in the body of the vector object as long
    as it is small enough:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 向量通常是模板，就像标准`std::vector`一样，但我们将这个例子简化了，以展示一个整数向量（将这个向量类转换为模板留给你作为练习，并且不会以任何方式改变本地缓冲区优化模式的应用）。只要足够小，我们就可以应用*小向量优化*并将向量数据存储在向量对象的主体中：
- en: '[PRE18]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can further optimize the vector in a similar manner to the string and overlay
    the local buffer with the pointer. We cannot use the last byte as a `tag`, as
    we did before, since any element of the vector can have any value, and the value
    of zero is, in general, not special. However, we need to store the size of the
    vector anyway, so we can use it at any time to determine whether the local buffer
    is used or not. We can take further advantage of the fact that if the local buffer
    optimization is used, the size of the vector cannot be very large, so we do not
    need a field of the `size_t` type to store it:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用类似字符串的方法进一步优化向量，并将局部缓冲区与指针叠加。我们不能像之前那样使用最后一个字节作为 `tag`，因为向量的任何元素都可以有任意值，而零值在一般情况下并不特殊。然而，我们无论如何都需要存储向量的大小，因此我们可以随时用它来确定是否使用了局部缓冲区。我们可以进一步利用这样一个事实，即如果使用局部缓冲区优化，向量的大小不可能非常大，所以我们不需要
    `size_t` 类型的字段来存储它：
- en: '[PRE19]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, we store the vector size either in `size_t` `long_.n` or in `unsigned`
    `char` `short_.n`, depending on whether or not the local buffer is used. A remote
    buffer is indicated by storing `UCHAR_MAX` (that is, 255) in the short size. Since
    this value is larger than the size of the local buffer, this `tag` is unambiguous
    (were the local buffer increased to store more than 255 elements, the type of
    `short_.n` would need to be changed to a longer integer).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们根据是否使用局部缓冲区来存储向量大小，要么在 `size_t` `long_.n` 中，要么在 `unsigned` `char` `short_.n`
    中。远程缓冲区通过在短大小中存储 `UCHAR_MAX`（即 255）来表示。由于这个值大于局部缓冲区的大小，这个 `tag` 是明确的（如果局部缓冲区增加到可以存储超过
    255 个元素，那么 `short_.n` 的类型就需要更改为更长的整数）。
- en: We can measure the performance gains from small vector optimization using a
    benchmark similar to the one we used for the strings. Depending on the actual
    size of the vector, gains of about 10x can be expected in creating and copying
    the vectors, and more if the benchmark runs on multiple threads. Of course, other
    data structures can be optimized in a similar manner when they store small amounts
    of dynamically allocated data. The optimizations of these data structures are
    fundamentally similar, but there is one noteworthy variant we should highlight.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与字符串相同的基准测试来衡量小向量优化的性能提升。根据向量的实际大小，在创建和复制向量时可以期望大约 10 倍的性能提升，如果基准测试在多线程上运行，则提升更多。当然，当它们存储少量动态分配的数据时，其他数据结构也可以以类似的方式优化。这些数据结构的优化在本质上相似，但有一个值得注意的变体我们应该强调。
- en: Small queue
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小队列
- en: The small vector we have just seen uses a local buffer to store a small array
    of vector elements. This is the standard way of optimizing data structures that
    store a variable number of elements when this number is often small. A particular
    version of this optimization is used for data structures based on a queue, where
    the buffer grows on one end and is consumed on the other end. If there are only
    a few elements in the queue at any time, the queue can be optimized with a local
    buffer. The technique commonly employed here is a `buffer[N]`, so, as the elements
    are added to the end of the queue, we are going to reach the end of the array.
    By then some elements were taken from the queue, so the first few elements of
    the array are no longer used. When we reach the end of the array, the next enqueued
    value goes into the first element of the array, `buffer[0]`. The array is treated
    like a ring, after the element `buffer[N-1]` comes the element `buffer[0]` (hence
    another name for this technique, a *ring buffer*).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才看到的小向量使用局部缓冲区来存储向量元素的小数组。这是在元素数量经常很少时优化存储可变数量元素的数据结构的标准方式。对于基于队列的数据结构，这种优化有一个特定的版本，其中缓冲区在一端增长，在另一端消耗。如果队列在任何时候只有少数几个元素，则可以使用局部缓冲区来优化队列。这里常用的技术是
    `buffer[N]`，因此，当元素被添加到队列的末尾时，我们将达到数组的末尾。到那时，一些元素已经被从队列中取出，所以数组的前几个元素不再使用。当我们到达数组的末尾时，下一个入队的值将进入数组的第一个元素，`buffer[0]`。数组被当作环形处理，在
    `buffer[N-1]` 元素之后是 `buffer[0]` 元素（因此这种技术的另一个名字是 *环形缓冲区*）。
- en: 'The circular buffer technique is commonly used for queues and other data structures
    where data is added and removed many times while the total volume of data stored
    at any given time is limited. Here is one possible implementation of a circular
    buffer queue:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 环形缓冲区技术通常用于队列和其他数据结构，在这些数据结构中，数据被多次添加和移除，而在任何给定时间存储的数据总量是有限的。下面是环形缓冲区队列的一种可能的实现：
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In this example, we support only the local buffer; if the number of elements
    the queue must hold exceeds the size of the buffer, the call to `push()` returns
    `false`. We could have switched to a heap-allocated array instead, just like we
    did in `Example 07` for `small_vector`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只支持局部缓冲区；如果队列必须保留的元素数量超过了缓冲区的大小，`push()`调用将返回`false`。我们本可以切换到堆分配的数组，就像我们在`Example
    07`中为`small_vector`所做的那样。
- en: 'In this implementation, we increment the indices `front_` and `tail_` without
    bounds, but when these values are used as indices into the local buffer, we take
    the index value modulo buffer size. Of note is the optimization that is very common
    when dealing with circular buffers: the size of the buffer is a power of two (enforced
    by the assert). This allows us to replace the general (and slow) modulo calculation
    such as `front_ % buf_size_` by much faster bitwise arithmetic. We do not have
    to worry about integer overflow either: even if we call `push()` and `pop()` more
    than `2^64` times, the unsigned integer index values will overflow and go back
    to zero and the queue continues to work fine.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实现中，我们无限制地增加`front_`和`tail_`索引，但当这些值用作局部缓冲区的索引时，我们取索引值对缓冲区大小的模。值得注意的是，当处理循环缓冲区时，这种优化非常常见：缓冲区的大小是2的幂（由assert强制）。这允许我们用更快的位运算来替换一般的（并且较慢的）模运算，例如`front_
    % buf_size_`。我们也不必担心整数溢出：即使我们调用`push()`和`pop()`超过`2^64`次，无符号整数索引值将溢出并回到零，队列仍然可以正常工作。
- en: 'As expected, the queue with the local buffer optimization far outperforms a
    general queue such as `std::queue<int>` (as long as the optimization remains valid
    and the number of elements in the queue is small, of course):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，具有局部缓冲区优化的队列远远优于一般的队列，例如`std::queue<int>`（当然，只要优化仍然有效且队列中的元素数量较少，当然是这样）：
- en: '[PRE21]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The circular local buffer can be used very effectively in many situations where
    we need to process large volumes of data but hold only a few elements at a time.
    Possible applications include network and I/O buffers, pipelines for exchanging
    data between threads in concurrent programs, and many more.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 循环局部缓冲区可以非常有效地用于许多需要处理大量数据但一次只保留少量元素的情况。可能的应用包括网络和I/O缓冲区、在并发程序中交换线程间数据的管道等。
- en: Let us now look at applications of local buffer optimizations beyond common
    data structures.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看局部缓冲区优化在常见数据结构之外的用途。
- en: Type-erased and callable objects
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类型擦除和可调用对象
- en: 'There is another, very different, type of application where the local buffer
    optimization can be used very effectively - storing callable objects, which are
    objects that can be invoked as functions. Many template classes provide an option
    to customize some part of their behavior using a callable object. For example,
    `std::shared_ptr`, the standard shared pointer in C++, allows the user to specify
    a custom deleter. This deleter will be called with the address of the object to
    be deleted, so it is a callable with one argument of the `void*` type. It could
    be a function pointer, a member function pointer, or a functor object (an object
    with an `operator()` defined) - any type that can be called on a `p` pointer;
    that is, any type that compiles in the `callable(p)` function call syntax can
    be used. The deleter, however, is more than a type; it is an object and is specified
    at runtime, and so it needs to be stored someplace where the shared pointer can
    get to it. Were the deleter a part of the shared pointer type, we could simply
    declare a data member of that type in the shared pointer object (or, in the case
    of the C++ shared pointer, in its reference object that is shared between all
    copies of the shared pointer). You could consider it a trivial application of
    the local buffer optimization, as in the following smart pointer that automatically
    deletes the object when the pointer goes out of scope (just like `std::unique_ptr`):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一种非常不同的应用类型，其中可以使用局部缓冲优化来非常有效地存储可调用对象，这些对象可以作为函数调用。许多模板类提供了一种使用可调用对象自定义其行为一部分的选项。例如，`std::shared_ptr`是C++中的标准共享指针，允许用户指定一个自定义的`deleter`。这个`deleter`将使用要删除的对象的地址被调用，因此它是一个具有`void*`类型一个参数的可调用对象。它可以是一个函数指针、成员函数指针或函数对象（定义了`operator()`的对象）——任何可以在`p`指针上调用的类型；也就是说，任何可以在`callable(p)`函数调用语法中编译的类型都可以使用。然而，`deleter`不仅仅是一个类型；它是一个对象，并在运行时指定，因此需要存储在一个共享指针可以访问到它的位置。如果`deleter`是共享指针类型的一部分，我们可以在共享指针对象中声明该类型的数据成员（或者在C++共享指针的情况下，在其引用对象中声明，该引用对象在所有共享指针副本之间共享）。你可以将其视为局部缓冲优化的简单应用，如下面的智能指针，当指针超出作用域时自动删除对象（就像`std::unique_ptr`一样）：
- en: '[PRE22]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We are after more interesting things, however, and one such thing can be found
    when we deal with type-erased objects. The details of such objects were considered
    in the chapter dedicated to type erasure, but in a nutshell, they are objects
    where the callable is not a part of the type itself (as in, it is *erased* from
    the type of the containing object). The callable is instead stored in a polymorphic
    object, and a virtual function is used to call the object of the right type at
    runtime. The polymorphic object, in turn, is manipulated through the base class
    pointer.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们追求的是更有趣的事情，当我们处理类型擦除对象时，我们可以找到这样一件事。这类对象的细节在专门讨论类型擦除的章节中已经讨论过，但简而言之，它们是可调用不是类型本身的一部分（也就是说，它被从包含对象的类型中*擦除*）。可调用存储在一个多态对象中，并通过一个虚函数在运行时调用正确类型的对象。多态对象反过来又通过基类指针进行操作。
- en: 'Now, we have a problem that is, in a sense, similar to the preceding small
    vector - we need to store some data, in our case the callable object, whose type,
    and therefore size, is not statically known. The general solution is to dynamically
    allocate such objects and access them through the base class pointer. In the case
    of a smart pointer `deleter`, we could do it like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们面临一个问题，从某种意义上讲，与前面的小向量类似——我们需要存储一些数据，在我们的例子中是可调用对象，其类型和因此的大小不是静态已知的。一般的解决方案是动态分配这样的对象，并通过基类指针访问它们。在智能指针`deleter`的情况下，我们可以这样做：
- en: '[PRE23]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note that the `Deleter` type is no longer a part of the smart pointer type;
    it was *erased*. All smart pointers for the same `T` object type have the same
    type, `smartptr_te<T>` (here, `te` stands for *type-erased*). However, we have
    to pay a steep price for this syntactic convenience - every time a smart pointer
    is created, there is an additional memory allocation. How steep? The first rule
    of performance must again be remembered - *steep* is only a guess until confirmed
    by an experiment, such as the following benchmark:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Deleter`类型不再是智能指针类型的一部分；它已经被*擦除*。对于相同的`T`对象类型，所有智能指针都有相同的类型，`smartptr_te<T>`（在这里，`te`代表*类型擦除*）。然而，我们必须为此语法便利付出高昂的代价——每次创建智能指针时，都会进行额外的内存分配。高昂到什么程度？我们必须再次记住性能的第一规则——*高昂*只是一个猜测，直到通过实验得到证实，如下面的基准测试：
- en: '[PRE24]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For a smart pointer with a statically defined deleter, we can expect the cost
    of each iteration to be very similar to the cost of calling `malloc()` and `free()`,
    which we measured earlier:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有静态定义的删除器的智能指针，我们可以预期每次迭代的成本与之前测量的`malloc()`和`free()`的成本非常相似：
- en: '[PRE25]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For a type-erased smart pointer, there are two allocations instead of one, and
    so the time it takes to create the pointer object is doubled. By the way, we can
    also measure the performance of a raw pointer, and it should be the same as the
    smart pointer within the accuracy of the measurements (this was, in fact, a stated
    design goal for the `std::unique_ptr` standard).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于类型擦除智能指针，有两个分配而不是一个，因此创建指针对象所需的时间加倍。顺便说一下，我们还可以测量原始指针的性能，它应该与智能指针在测量精度内相同（这实际上是一个针对`std::unique_ptr`标准的明确设计目标）。
- en: 'We can apply the same idea of local buffer optimization here, and it is likely
    to be even more effective than it was for strings; after all, most callable objects
    are small. We can’t completely count on that, however, and must handle the case
    of a callable object that is larger than the local buffer:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里应用相同的局部缓冲区优化理念，并且它可能比字符串中的效果还要好；毕竟，大多数可调用对象都很小。然而，我们并不能完全依赖这一点，必须处理大于局部缓冲区的可调用对象的情况：
- en: '[PRE26]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Using the same benchmark as before, we can measure the performance of the type-erased
    smart pointer with local buffer optimization:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前的相同基准测试，我们可以测量具有局部缓冲区优化的类型擦除智能指针的性能：
- en: '[PRE27]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: While the construction and deletion of a smart pointer without type erasure
    took 21 nanoseconds, and 44 nanoseconds with type erasure, the optimized type-erased
    shared pointer test takes 22 nanoseconds on the same machine. The slight overhead
    comes from checking whether the `deleter` is stored locally or remotely.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有类型擦除的智能指针的构建和删除需要21纳秒，而有类型擦除的需要44纳秒，但优化后的类型擦除共享指针测试在同一台机器上只需要22纳秒。轻微的额外开销来自检查`deleter`是存储在本地还是远程。
- en: Local buffer optimization in the standard library
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标准库中的局部缓冲区优化
- en: We should note that the last application of local buffer optimization, storing
    callables for type-erased objects, is widely used in the C++ standard template
    library. For example, `std::shared_ptr` has a type-erased deleter, and most implementations
    use the local buffer optimization; the deleter is stored with the reference object
    and not with each copy of the shared pointer, of course. The `std::unique_pointer`
    standard, on the other hand, is not type-erased at all, to avoid even a small
    overhead, or potentially a much larger overhead should the deleter not fit into
    the local buffer.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该注意，局部缓冲区优化的最后一种应用，为类型擦除对象存储可调用对象，在C++标准模板库中被广泛使用。例如，`std::shared_ptr`有一个类型擦除删除器，并且大多数实现都使用局部缓冲区优化；当然，删除器是与引用对象一起存储，而不是与共享指针的每个副本一起存储。另一方面，`std::unique_pointer`标准根本不进行类型擦除，以避免任何小的开销，或者如果删除器不适合局部缓冲区，可能是一个更大的开销。
- en: The “*ultimate*” type-erased object of the C++ standard library, `std::function`,
    is also typically implemented with a local buffer for storing small callable objects
    without the expense of an additional allocation. The universal container object
    for any type, `std::any` (since C++17), is also typically implemented without
    a dynamic allocation when possible.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: C++标准库中的“*终极*”类型擦除对象`std::function`通常也使用局部缓冲区来存储小型可调用对象，而不需要额外的分配开销。任何类型的通用容器对象`std::any`（自C++17起）在可能的情况下也通常不进行动态分配。
- en: Local buffer optimization in detail
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局部缓冲区优化的详细说明
- en: We have seen the applications of local buffer optimization; for simplicity,
    we stayed with the most basic implementation of it. This simple implementation
    misses several important details, which we will now highlight.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了局部缓冲区优化的应用；为了简单起见，我们坚持最基本实现。这种简单实现遗漏了几个重要细节，我们现在将突出显示。
- en: 'First of all, we completely neglected the alignment of the buffer. The type
    we used to reserve the space inside an object is `char`; therefore, our buffer
    is byte-aligned. Most data types have higher alignment requirements: the exact
    requirements are platform-specific, but most built-in types are aligned on their
    own size (double is 8-byte-aligned on a 64-bit platform such as x86). Higher alignments
    are needed for some machine-specific types such as packed integer or floating-point
    arrays for AVX instructions.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们完全忽略了缓冲区的对齐。我们用来在对象内部预留空间的类型是 `char`；因此，我们的缓冲区是字节对齐的。大多数数据类型有更高的对齐要求：确切的要求是平台特定的，但大多数内置类型都对其自身大小进行对齐（在
    64 位平台如 x86 上，`double` 是 8 字节对齐的）。对于一些特定于机器的类型，如用于 AVX 指令的打包整数或浮点数组，需要更高的对齐。
- en: 'Alignment is important: depending on the processor and the code generated by
    the compiler, accessing memory not aligned as required by the data type can result
    in poor performance or memory access violations (crashes). For example, most AVX
    instructions require 16- or 32-byte alignment, and the unaligned versions of these
    instructions are significantly slower. Another example is atomic operations such
    as the ones used in mutexes and other concurrent data structures: they also don’t
    work if the data type is not properly aligned (for example, an atomic `long` must
    be aligned on an 8-byte boundary).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐很重要：根据处理器和编译器生成的代码，如果访问的数据类型未按要求对齐，可能会导致性能下降或内存访问违规（崩溃）。例如，大多数 AVX 指令需要 16
    或 32 字节的对齐，而这些指令的非对齐版本要慢得多。另一个例子是原子操作，如用于互斥锁和其他并发数据结构的操作：如果数据类型没有正确对齐，它们也无法工作（例如，原子
    `long` 必须对齐在 8 字节边界上）。
- en: 'Specifying the minimum alignment for our buffer is not hard, at least if we
    know the type we want to store in the buffer. For example, if we have a small
    vector for an arbitrary type `T`, we can simply write:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 指定缓冲区的最小对齐要求并不困难，至少如果我们知道我们想在缓冲区中存储的类型。例如，如果我们有一个任意类型 `T` 的小向量，我们可以简单地写出：
- en: '[PRE28]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: If the buffer is used for storing an object of one of several types, we have
    to use the highest alignment of all possible types. Finally, if the type of the
    object to be stored is unknown – the typical case for type-erased implementations
    – we have to select a “*high enough*” alignment and add a compile-time check at
    the point where a specific object is constructed in the buffer.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缓冲区用于存储几种类型之一的对象，我们必须使用所有可能类型中的最高对齐。最后，如果要存储的对象类型未知——这是类型擦除实现的典型情况——我们必须选择一个“*足够高*”的对齐，并在缓冲区中构造特定对象的位置添加编译时检查。
- en: 'The second important subtlety to remember is how the buffer is defined. Usually,
    it is an aligned array of characters (or `std::byte_t`). In the previous section,
    we used an array of `int` for the small vector of integers. Again, there is a
    subtlety here: declaring the buffer as an object or an array of objects of the
    right type will cause these objects to be destroyed automatically when the object
    containing the buffer is destroyed. For trivially destructible types such as integers,
    it makes no difference at all – their destructors do nothing.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的第二个重要细节是如何定义缓冲区。通常，它是一个字符（或 `std::byte_t`）的对齐数组。在前一节中，我们使用 `int` 数组来表示小整数向量。同样，这里也有一个细节：将缓冲区声明为对象或正确类型的对象数组，当包含缓冲区的对象被销毁时，这些对象将自动被销毁。对于像整数这样的简单可销毁类型，这根本无关紧要——它们的析构函数什么也不做。
- en: 'In general, this is not so, and an arbitrary destructor can be invoked only
    if an object was constructed at this location. For our small vector, this is not
    always the case: the vector may be empty or contain fewer objects than the buffer
    can hold. This is the most common case by far: usually, if we employ local buffer
    optimization, we cannot be sure that an object was constructed in the buffer.
    In this case, declaring the buffer as an array of non-trivially-destructible objects
    would be a mistake. However, if you have a guarantee that, in your particular
    case, the buffer always contains an object (or several objects, for an array),
    declaring them with the corresponding type greatly simplifies the implementation
    of the destructor, as well as the copy/move operations.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下并非如此，只有当在此位置构造了对象时，才会调用任意析构函数。对于我们的小型向量，这并不总是成立：向量可能为空或包含的对象少于缓冲区能容纳的数量。这可能是最常见的情况：通常，如果我们采用本地缓冲区优化，我们无法确定对象是否在缓冲区中构造。在这种情况下，将缓冲区声明为具有非平凡析构对象的数组将会是一个错误。然而，如果你有保证，在你的特定情况下，缓冲区总是包含一个对象（或多个对象，对于数组），使用相应的类型声明将大大简化析构函数的实现，以及复制/移动操作。
- en: You should have noticed by now that a typical implementation of a local buffer
    needs a lot of boilerplate code. There are `reinterpret_cast` casts everywhere,
    you have to remember to add the alignment, there are some compile-time checks
    you should always add to make sure only suitable types are stored in the buffer,
    and so on. It is good to combine these details together in a single general reusable
    implementation. Unfortunately, as is often the case, there is a tension between
    reusability and complexity, so we will have to settle for several general reusable
    implementations.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经注意到，一个典型的本地缓冲区的实现需要大量的模板代码。到处都是 `reinterpret_cast` 转换，你必须记得添加对齐，还有一些编译时检查你应该始终添加，以确保只有合适的类型存储在缓冲区中，等等。将这些细节组合成一个单一的可重用实现是很好的。不幸的是，正如通常情况下那样，重用性和复杂性之间存在矛盾，所以我们只能满足于几个可重用的通用实现。
- en: 'If we put together everything we have learned about local buffers, we can come
    up with something like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将关于本地缓冲区所学的所有内容综合起来，我们可以得出如下结论：
- en: '[PRE29]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here we have a buffer of arbitrary size and alignment (both are template parameters).
    Now that we have a space to store objects, we have to make sure the type we want
    to erase fits into this space. To this end, it is convenient to add a `constexpr`
    validator function (it’s used only in compile-time syntax checks):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们有一个任意大小和对齐（两者都是模板参数）的缓冲区。现在我们有了存储对象的空间，我们必须确保我们想要擦除的类型适合这个空间。为此，添加一个 `constexpr`
    验证函数是方便的（它仅在编译时语法检查中使用）：
- en: '[PRE30]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The buffer can be used as if it contained an object of type `T` by calling
    the member function `as<T>()`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区可以通过调用成员函数 `as<T>()` 来使用，仿佛它包含了一个类型为 `T` 的对象：
- en: '[PRE31]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The buffer can be constructed empty (default-constructed) or with an immediately
    constructed object. In the former case, the object can be emplaced later. Either
    way, we validate that the type fits into the buffer and meets the alignment requirements
    (if C++20 and concepts are not available, SFINAE can be used instead). The default
    constructor is trivial, but the emplacing constructor and the `emplace()` method
    have constraints on the type and the constructor arguments:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区可以构造为空（默认构造）或带有立即构造的对象。在前一种情况下，对象可以在稍后放置。无论哪种方式，我们都验证类型是否适合缓冲区并满足对齐要求（如果
    C++20 和概念不可用，可以使用 SFINAE）。默认构造函数是平凡的，但放置构造函数和 `emplace()` 方法对类型和构造函数参数有约束：
- en: '[PRE32]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Note that we do check that the requested type can be stored in the buffer but
    no checking is done at run time to ensure that the buffer does indeed contain
    such an object. Such checking can be added at the cost of additional space and
    run-time computations and might make sense as a debugging instrumentation. We
    do not do anything special for copying, moving, or deleting the buffer. As-is,
    this implementation is suitable for trivially copyable and trivially destructible
    objects. In this case, we will want to assert these restrictions when an object
    is constructed in the buffer (in both the constructor and the `emplace()` method):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们确实检查了请求的类型是否可以存储在缓冲区中，但在运行时没有进行检查以确保缓冲区确实包含这样的对象。这种检查可以通过增加额外的空间和运行时计算来实现，并且可能作为调试工具是有意义的。我们对于复制、移动或删除缓冲区没有做任何特殊处理。目前，这个实现适用于简单可复制的和简单可破坏的对象。在这种情况下，当在缓冲区中构造对象时（在构造函数和
    `emplace()` 方法中），我们希望断言这些限制：
- en: '[PRE33]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In this case, it may also make sense to add a `swap()` method to the class:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，给类添加一个 `swap()` 方法也是有意义的：
- en: '[PRE34]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'On the other hand, if we’re using this buffer for storing objects of a single
    known type and that type is not trivially destructible, we end up writing something
    like this all the time:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们使用这个缓冲区来存储单个已知类型的对象，并且该类型不是简单可破坏的，我们就会一直写类似这样的代码：
- en: '[PRE35]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can simplify the client code by adding another generally usable method:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过添加另一个通用的方法来简化客户端代码：
- en: '[PRE36]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We can add similar methods to copy and move objects stored in the buffer, or
    leave that to the client.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以添加类似的方法来复制和移动存储在缓冲区中的对象，或者让客户端来处理：
- en: 'Our general local buffer implementation works for all trivially copyable and
    destructible types, as well as for all cases where the type is known and the client
    of our code handles copying and destroying the objects stored in the buffer. There
    is one special case that is left out but is nonetheless worth considering: when
    a local buffer is used in type-erased classes, the stored (erased) type may require
    non-trivial copying or deletion but the client cannot do these operations since
    the whole point of type erasure is that the client code does not know the erased
    type after it was emplaced into the buffer. In this special case, we need to capture
    the type at the point when it was stored and generate the corresponding copy,
    move, and deletion operations. In other words, we have to combine our local buffer
    with the techniques we learned earlier, in [*Chapter 6*](B19262_06.xhtml#_idTextAnchor266),
    *Understanding Type Erasure*, about type erasure. The most suitable variant of
    type erasure, in this case, is `vtable` – a table of function pointers we generate
    using templates. The `vtable` itself is an aggregate (`struct`) holding function
    pointers that will do the deletion, copying, or moving:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的一般本地缓冲区实现适用于所有简单可复制的和可破坏的类型，以及所有已知类型的情况，其中客户端处理存储在缓冲区中的对象的复制和销毁。有一个特殊情况被省略了，但仍然值得考虑：当在类型擦除类中使用本地缓冲区时，存储（擦除）的类型可能需要非简单复制或删除，但客户端无法执行这些操作，因为类型擦除的整个目的就是客户端代码在对象放入缓冲区后不知道擦除的类型。在这种情况下，我们需要在存储类型时捕获该类型，并生成相应的复制、移动和删除操作。换句话说，我们必须将我们的本地缓冲区与我们在[*第6章*](B19262_06.xhtml#_idTextAnchor266)中学习的技术结合起来，*理解类型擦除*。在这种情况下，最合适的类型擦除变体是
    `vtable` —— 我们使用模板生成的函数指针表。`vtable` 本身是一个包含将执行删除、复制或移动的函数指针的聚合（`struct`）：
- en: '[PRE37]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We need one class member, `vtable_`, to store a pointer to the `vtable`. The
    object that we will point to needs to be created by the constructor or the `emplace()`
    method, of course – that is the only time we know the real type and how to delete
    or copy it. But we are not going to do dynamic memory allocation for it. Instead,
    we create a static template variable and initialize it with pointers to static
    member functions (also templates). The compiler creates an instance of this static
    variable for every type we store in the buffer. Of course, we also need static
    template functions (a pointer to a static member function is the same as a regular
    function pointer, rather than a member function pointer). These functions are
    instantiated by the compiler with the same type `T` of the object that is stored
    in the buffer:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个类成员 `vtable_` 来存储对 `vtable` 的指针。当然，我们将要指向的对象需要由构造函数或 `emplace()` 方法创建——这是唯一我们知道实际类型以及如何删除或复制它的时候。但是，我们不会为它进行动态内存分配。相反，我们创建一个静态模板变量，并用指向静态成员函数（也是模板）的指针来初始化它。编译器会为我们在缓冲区中存储的每个类型创建这个静态变量的实例。当然，我们还需要静态模板函数（一个指向静态成员函数的指针与一个常规函数指针相同，而不是成员函数指针）。这些函数由编译器使用存储在缓冲区中的对象的相同类型
    `T` 实例化：
- en: '[PRE38]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As shown in [*Chapter 6*](B19262_06.xhtml#_idTextAnchor266), *Understanding
    Type Erasure*, we first use template static functions to generate copy, move,
    and delete operations for any type `T` we need. We store the pointers to these
    functions in an instance of a static template variable `vtable`, and a pointer
    to that instance in a (non-static) data member `vtable_`. The latter is our only
    cost, size-wise (the rest is static variables and functions that are generated
    by the compiler once for each type stored in the buffer).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第6章*](B19262_06.xhtml#_idTextAnchor266) *理解类型擦除*所示，我们首先使用模板静态函数为任何类型 `T`
    生成复制、移动和删除操作。我们将这些函数的指针存储在一个静态模板变量 `vtable` 的实例中，并将该实例的指针存储在一个（非静态）数据成员 `vtable_`
    中。后者是我们唯一的成本，从大小上来说（其余的是编译器为存储在缓冲区中的每个类型生成一次的静态变量和函数）。
- en: 'This `vtable_` has to be initialized at the time the object is emplaced in
    the buffer since this is the last time we explicitly know the type of the stored
    object:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `vtable_` 必须在对象放入缓冲区时初始化，因为这是我们最后一次明确知道存储对象的类型：
- en: '[PRE39]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note the initialization of the `vtable_` member in the constructor. In the `emplace()`
    method, we also have to delete the object previously constructed in the buffer,
    if one exists.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意构造函数中 `vtable_` 成员的初始化。在 `emplace()` 方法中，我们还需要删除缓冲区中先前构造的对象，如果有的话。
- en: 'With the type erasure machinery in place, we can finally implement the destructors
    and the copy/move operations. They all use a similar approach – call the corresponding
    function in the `vtable`. Here are the copy operations:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在类型擦除机制到位后，我们最终可以实现析构函数和复制/移动操作。它们都使用类似的方法——调用 `vtable` 中的相应函数。以下是复制操作：
- en: '[PRE40]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The move operations are similar, only they use the `move_construct_` function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 移动操作类似，只是它们使用 `move_construct_` 函数：
- en: '[PRE41]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note that the move-assignment operator is not required to check for self-assignment,
    but it’s also not wrong to do so. It is highly desirable for the move operations
    to be `noexcept`; unfortunately, we cannot guarantee that because we do not know
    the erased type at compile time. We can make a design choice and declare them
    `noexcept` anyway. If we do, we can also assert, at compile-time, that the object
    we store in the buffer is `noexcept` movable.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意移动赋值运算符不需要检查自赋值，但这样做也没有错。移动操作最好是 `noexcept`；不幸的是，我们无法保证这一点，因为我们不知道擦除类型。我们可以做出设计选择，并声明它们为
    `noexcept`。如果我们这样做，我们还可以在编译时断言我们存储在缓冲区中的对象是 `noexcept` 可移动的。
- en: 'Finally, we have the destruction operations. Since we allow the caller to destroy
    the contained object without destroying the buffer itself (by calling `destroy()`),
    we have to take care to ensure that the object gets destroyed only once:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有销毁操作。由于我们允许调用者销毁包含的对象而不销毁缓冲区本身（通过调用 `destroy()`），我们必须确保对象只被销毁一次：
- en: '[PRE42]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Having the type-erased `vtable` allows us to reconstruct, at run time, the
    type stored in the buffer (it is embedded in the code generated for the static
    functions such as `copy_construct()`). There is, of course, a cost to it; we already
    noted the additional data member `vtable_`, but there is also some run-time cost
    arising from the indirect function calls. We can estimate it by using both implementations
    of the local buffer (with and without type erasure) to store and copy some trivially
    copyable object, for example, a lambda with a captured reference:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The overhead of (well-implemented) type erasure is non-negligible but modest.
    An added advantage is that we could also verify at run-time whether or not our
    calls to `as<T>()` refer to a valid type and that the object is indeed constructed.
    Relatively to the very cheap implementation of an unchecked method, this would
    add significant overhead, so probably should be restricted to debug builds.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: We have seen significant, sometimes dramatic, improvements to the performance
    of many different data structures and classes provided by the local buffer optimization.
    With the easy-to-use general implementations we just learned, why would you not
    use this optimization all the time? As is the case for any design pattern, our
    exploration is not complete without mentioning the trade-offs and the downsides.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Downsides of local buffer optimization
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Local buffer optimization is not without its downsides. The most obvious one
    is that all objects with a local buffer are larger than they would be without
    one. If the typical data stored in the buffer is smaller than the chosen buffer
    size, then every object is wasting some memory, but at least the optimization
    is paying off. Worse, if our choice of buffer size is badly off and most data
    is, in fact, larger than the local buffer, the data is stored remotely but the
    local buffers are still created inside every object, and all that memory is wasted.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: There is an obvious trade-off between the amount of memory we are willing to
    waste and the range of data sizes where the optimization is effective. The size
    of the local buffer should be carefully chosen with the application in mind.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The more subtle complication is this - the data that used to be external to
    the object is now stored inside the object. This has several consequences, in
    addition to the performance benefits we were so focused on. First of all, every
    copy of the object contains its own copy of the data as long as it fits into the
    local buffer. This prevents designs such as the reference counting of data; for
    example, a **Copy-On-Write** (**COW**) string, where the data is not copied as
    long as all string copies remain the same, cannot use the small string optimization.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, the data must be moved if the object itself is moved. Contrast this
    with `std::vector`, which is moved or swapped, essentially like a pointer - the
    pointer to the data is moved but the data remains in place. A similar consideration
    exists for the object contained inside `std::any`. You could dismiss this concern
    as trivial; after all, local buffer optimization is used primarily for small amounts
    of data, and the cost of moving them should be comparable to the cost of copying
    the pointer. However, more than performance is at stake here - moving an instance
    of `std::vector` (or `std::any`, for that matter) is guaranteed not to throw an
    exception. However, no such guarantees are offered when moving an arbitrary object.
    Therefore, `std::any` can be implemented with a local buffer optimization only
    if the object it contains is `std::is_nothrow_move_constructible`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果对象本身被移动，则必须移动数据。这与`std::vector`的情况形成对比，`std::vector`被移动或交换，本质上就像一个指针——数据指针被移动，但数据本身保持不变。对于`std::any`内部包含的对象也存在类似的考虑。你可以认为这种担忧是微不足道的；毕竟，局部缓冲区优化主要用于少量数据，移动它们的成本应该与复制指针的成本相当。然而，这里不仅仅是性能问题——移动`std::vector`（或`std::any`，无论如何）的实例保证不会抛出异常。然而，在移动任意对象时没有这样的保证。因此，只有当`std::any`包含的对象是`std::is_nothrow_move_constructible`时，`std::any`才能使用局部缓冲区优化。
- en: Even such a guarantee does not suffice for the case of `std::vector`, however;
    the standard explicitly states that moving, or swapping, a vector does not invalidate
    iterators pointing to any element of the vector. Obviously, this requirement is
    incompatible with local buffer optimization, since moving a small vector would
    relocate all its elements to a different region of memory. For that reason, many
    high-efficiency libraries offer a custom vector-like container that supports small
    vector optimization, at the expense of the standard iterator invalidation guarantees.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使有这样的保证，对于`std::vector`的情况也不够；标准明确指出，移动或交换向量不会使指向向量任何元素的迭代器失效。显然，这个要求与局部缓冲区优化不相容，因为移动一个小向量会将所有元素重新定位到内存的不同区域。因此，许多高效库提供了一种定制的类似向量的容器，它支持小向量优化，但牺牲了标准迭代器失效的保证。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We have just introduced a design pattern aimed solely at improved performance.
    Efficiency is an important consideration for the C++ language; thus, the C++ community
    developed patterns to address the most common inefficiencies. Repeated or wasteful
    memory allocation is perhaps the most common of all. The design pattern we have
    just seen - local buffer optimization - is a powerful tool that can greatly reduce
    such allocations. We have seen how it can be applied to compact data structures,
    as well as to store small objects, such as callables. We have also reviewed the
    possible downsides of using this pattern.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚介绍了一种旨在提高性能的设计模式。效率是C++语言的一个重要考虑因素；因此，C++社区开发了模式来解决最常见的低效问题。重复或浪费的内存分配可能是所有问题中最常见的。我们刚刚看到的设计模式——局部缓冲区优化——是一种强大的工具，可以大大减少这种分配。我们已经看到它如何应用于紧凑的数据结构，以及存储小对象，如可调用对象。我们还回顾了使用此模式可能存在的缺点。
- en: With the next chapter, [*Chapter 11*](B19262_11.xhtml#_idTextAnchor509), *ScopeGuard*,
    we move on to study more complex patterns that address broader design issues.
    The idioms we have learned so far are often used in the implementation of these
    patterns.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，[*第11章*](B19262_11.xhtml#_idTextAnchor509)，*ScopeGuard*，我们将继续研究更复杂的模式，这些模式解决更广泛的设计问题。我们迄今为止学到的惯用用法通常用于这些模式的实现。
- en: Questions
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How can we measure the performance of a small fragment of code?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何衡量一小段代码的性能？
- en: Why are small and frequent memory allocations particularly bad for performance?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么小而频繁的内存分配对性能尤其不利？
- en: What is local buffer optimization, and how does it work?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 局部缓冲区优化是什么，它是如何工作的？
- en: Why is an allocation of an additional buffer inside an object effectively *free*?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在对象内部分配一个额外的缓冲区实际上是*免费*的？
- en: What is short string optimization?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 短字符串优化是什么？
- en: What is small vector optimization?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小向量优化是什么？
- en: Why is local buffer optimization particularly effective for callable objects?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么局部缓冲区优化对可调用对象特别有效？
- en: What are the trade-offs to consider when using local buffer optimization?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用局部缓冲区优化时需要考虑哪些权衡？
- en: When should an object not be placed in a local buffer?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时不应该将对象放入局部缓冲区？
