<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-93"><a id="_idTextAnchor092"/>6</h1>
<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>GPU-Driven Rendering</h1>
<p>In this chapter, we will upgrade the geometry pipeline to use the latest available technology: <strong class="bold">mesh shaders</strong> and <strong class="bold">meshlets</strong>. The i<a id="_idIndexMarker278"/>dea behind this technique is to move the flow of mesh rendering from the CPU to the GPU, moving culling and draw command generation into different shaders. </p>
<p>We will first work on the mesh structure on the CPU, by separating it into different <em class="italic">meshlets</em> that are <a id="_idIndexMarker279"/>groups of up to 64 triangles, each with an individual bounding sphere. We will then use compute shaders to perform culling and write a list of commands to draw the meshlets in the different passes. Finally, we will use the mesh shaders to render the meshlets. There will also be a compute version provided, as mesh shaders are still available only on Nvidia GPUs for now.</p>
<p>Traditionally, geometry culling has been performed on the CPU. Each mesh on the scene is usually represented by <a id="_idIndexMarker280"/>an <strong class="bold">axis aligned bounding box</strong> (<strong class="bold">AABB</strong>). An AABB can easily be culled against the camera frustum, but with the increase in scene complexity, a large portion of frame time could be spent on the culling step.</p>
<p>This is usually the first step in a rendering pipeline, as we need to determine which meshes to submit for drawing. This means it’s hard to find other work that could be done in parallel. Another pain point of doing frustum culling on the CPU is that it’s hard to determine which objects are occluded and don’t need to be drawn.</p>
<p>At every frame, we need to re-sort all elements based on the camera position. When there are hundreds of thousands of elements in the scene, this is usually unfeasible. Finally, some meshes, terrain, for example, are organized in large areas that end up always being drawn, even if only a small part of them is visible.</p>
<p>Thankfully, we can move some of this computation to the GPU and take advantage of its parallel capabilities. The techniques we are going to present in this chapter will allow us to perform frustum and occlusion culling on the GPU. To make the process as efficient as possible, we are going to generate the list of draw commands directly on the GPU.</p>
<p>In this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>Breaking down large meshes into meshlets</li>
<li>Processing meshlets using task and mesh shaders to perform back-face and frustum culling</li>
<li>Performing efficient occlusion culling using compute shaders</li>
<li>Generating draw commands on the GPU and using indirect drawing functions</li>
</ul>
<h1 id="_idParaDest-95"><a id="_idTextAnchor094"/>Technical requirements</h1>
<p>The code for this chapter can be found at the following URL: <a href="https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter6">https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter6</a>.</p>
<h1 id="_idParaDest-96"><a id="_idTextAnchor095"/>Breaking down large meshes into meshlets</h1>
<p>In this<a id="_idIndexMarker281"/> chapter, we are going to focus primarily on the geometry stage of the pipeline, the one before the shading stage. Adding some complexity to the geometry stage of the pipeline will pay dividends in later stages as we’ll reduce the number of pixels that need to be shaded.</p>
<p class="callout-heading">Note</p>
<p class="callout">When we refer to the geometry stage of the graphics pipeline, we don’t mean geometry shaders. The geometry stage of the pipeline refers<a id="_idIndexMarker282"/> to <strong class="bold">input assembly</strong> (<strong class="bold">IA</strong>), vertex processing, and <strong class="bold">primitive assembly</strong> (<strong class="bold">PA</strong>). Vertex processing can, in turn, run one or <a id="_idIndexMarker283"/>more of the following shaders: vertex, geometry, tessellation, task, and mesh shaders.</p>
<p>Content geometry comes in many shapes, sizes, and complexity. A rendering engine must be able to deal with meshes from small, detailed objects to large terrains. Large meshes (think terrain or buildings) are usually broken down by artists so that the rendering engine can pick out the different levels of details based on the distance from the camera of these objects.</p>
<p>Breaking down meshes into smaller chunks can help cull geometry that is not visible, but some of these meshes are still large enough that we need to process them in full, even if only a small portion is visible.</p>
<p>Meshlets have <a id="_idIndexMarker284"/>been developed to address these problems. Each mesh is subdivided into groups of vertices (usually 64) that can be more easily processed on the GPU.</p>
<p>The following image illustrates how meshes can be broken down into meshlets:</p>
<div><div><img alt="Figure 6.1 – A meshlet subdivision example" height="605" src="img/B18395_06_01.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – A meshlet subdivision example</p>
<p>These vertices can make<a id="_idIndexMarker285"/> up an arbitrary number of triangles, but we usually tune this value according to the hardware we are running on. In Vulkan, the recommended value is <code>126</code> (as written in <a href="https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/">https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/</a>, the number is needed to reserve some memory for writing the primitive count with each meshlet).</p>
<p class="callout-heading">Note</p>
<p class="callout">At the time of writing, mesh and task shaders are only available on Nvidia hardware through its extension. While some of the APIs described in this chapter are specific to this extension, the concepts can be generally applied and implemented using generic compute shaders. A more generic version of this extension is currently being worked on by the Khronos committee so that mesh and task shaders should soon be available from other vendors!</p>
<p>Now that <a id="_idIndexMarker286"/>we have a much smaller number of triangles, we can use them to have much finer-grained control by culling meshlets that are not visible or are being occluded by other objects.</p>
<p>Together with the list of vertices and triangles, we also generate some additional data for each meshlet that will be very useful later on to perform back-face, frustum, and occlusion culling.</p>
<p>One additional possibility (that will be added in the future) is to choose the <strong class="bold">level of detail</strong> (<strong class="bold">LOD</strong>) of a <a id="_idIndexMarker287"/>mesh and, thus, a different subset of meshlets based on any wanted heuristic.</p>
<p>The first of this additional data represents the bounding sphere of a meshlet, as shown in the following screenshot:</p>
<div><div><img alt="Figure 6.2 – A meshlet bounding spheres example; some of the larger spheres have been hidden for clarity" height="605" src="img/B18395_06_02.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – A meshlet bounding spheres example; some of the larger spheres have been hidden for clarity</p>
<p>Some of you<a id="_idIndexMarker288"/> might ask: why not AABBs? AABBs require at least two <code>vec3</code> of data: one for the center and one for the half-size vector. Another encoding could be to store the minimum and maximum corners. Instead, spheres can be encoded with a single <code>vec4</code>: a <code>vec3</code> for the center plus the radius.</p>
<p>Given that we might need to process millions of meshlets, each saved byte counts! Spheres can also be more easily tested for frustum and occlusion culling, as we will describe later in the chapter.</p>
<p>The next<a id="_idIndexMarker289"/> additional piece of data that we’re going to use is the meshlet cone, as shown in the following screenshot:</p>
<div><div><img alt="Figure 6.3 – A meshlet cone example; not all cones are displayed for clarity" height="605" src="img/B18395_06_03.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – A meshlet cone example; not all cones are displayed for clarity</p>
<p>The cone indicates the <a id="_idIndexMarker290"/>direction a meshlet is facing and will be used for back-face culling.</p>
<p>Now we have a better understanding of why meshlets are useful and how we can use them to improve the culling of larger meshes, let’s see how we generate them in code!</p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor096"/>Generating meshlets</h2>
<p>We are<a id="_idIndexMarker291"/> using an open <a id="_idIndexMarker292"/>source library, called <strong class="bold">MeshOptimizer</strong> (<a href="https://github.com/zeux/meshoptimizer">https://github.com/zeux/meshoptimizer</a>) to generate the meshlets. An alternative library<a id="_idIndexMarker293"/> is <strong class="bold">meshlete</strong> (<a href="https://github.com/JarkkoPFC/meshlete">https://github.com/JarkkoPFC/meshlete</a>) and we encourage you to try both to find the one that best suits your needs.</p>
<p>After we have loaded the data (vertices and indices) for a given mesh, we are going to generate the list of meshlets. First, we determine the maximum number of meshlets that could be generated for our mesh and allocate memory for the vertices and indices arrays that <a id="_idIndexMarker294"/>will describe the meshlets:</p>
<pre class="source-code">
const sizet max_meshlets = meshopt_buildMeshletsBound( 
    indices_accessor.count, max_vertices, max_triangles );
 
Array&lt;meshopt_Meshlet&gt; local_meshlets;
local_meshlets.init( temp_allocator, max_meshlets, 
    max_meshlets );
 
Array&lt;u32&gt; meshlet_vertex_indices;
meshlet_vertex_indices.init( temp_allocator, max_meshlets * 
    max_vertices, max_meshlets* max_vertices );
Array&lt;u8&gt; meshlet_triangles;
meshlet_triangles.init( temp_allocator, max_meshlets * 
    max_triangles * 3, max_meshlets* max_triangles * 3 );</pre>
<p>Notice the types for the indices and triangle arrays. We are not modifying the original vertex or index buffer, but only generating a list of indices in the original buffers. Another interesting aspect is that we only need 1 byte to store the triangle indices. Again, saving memory is very important to keep meshlet processing efficient!</p>
<p>The next step is to generate our meshlets:</p>
<pre class="source-code">
const sizet max_vertices = 64;
const sizet max_triangles = 124;
const f32 cone_weight = 0.0f;
 
sizet meshlet_count = meshopt_buildMeshlets( 
    local_meshlets.data, 
    meshlet_vertex_indices.data, 
    meshlet_triangles.data, indices, 
    indices_accessor.count, 
    vertices, 
    position_buffer_accessor.count, 
    sizeof( vec3s ), 
    max_vertices, 
    max_triangles, 
    cone_weight );</pre>
<p>As <a id="_idIndexMarker295"/>mentioned in the preceding step, we need to tell the library the maximum number of vertices and triangles that a meshlet can contain. In our case, we are using the recommended values for the Vulkan API. The other parameters include the original vertex and index buffer, and the arrays we have just created that will contain the data for the meshlets.</p>
<p>Let’s have a better look at the data structure of each meshlet:</p>
<pre class="source-code">
struct meshopt_Meshlet
{
unsigned int vertex_offset;
unsigned int triangle_offset;
 
unsigned int vertex_count;
unsigned int triangle_count;
};</pre>
<p>Each meshlet is described by two offsets and two counts, one for the vertex indices and one for the indices of the triangles. Note that these offsets refer to <code>meshlet_vertex_indices</code> and <code>meshlet_triangles</code> that are populated by the library, not the original vertex and index buffers of the mesh.</p>
<p>Now<a id="_idIndexMarker296"/> that we have the meshlet data, we need to upload it to the GPU. To keep the data size to a minimum, we store the positions at full resolution while we compress the normals to 1 byte for each dimension and UV coordinates to half-float for each dimension. In pseudocode, this is as follows:</p>
<pre class="source-code">
meshlet_vertex_data.normal = ( normal + 1.0 ) * 127.0;
meshlet_vertex_data.uv_coords = quantize_half( uv_coords );</pre>
<p>The next step is to extract the additional data (bounding sphere and cone) for each meshlet:</p>
<pre class="source-code">
for ( u32 m = 0; m &lt; meshlet_count; ++m ) {
    meshopt_Meshlet&amp; local_meshlet = local_meshlets[ m ];
 
    meshopt_Bounds meshlet_bounds = 
    meshopt_computeMeshletBounds( 
    meshlet_vertex_indices.data + 
    local_meshlet.vertex_offset,
    meshlet_triangles.data +
    local_meshlet.triangle_offset,
    local_meshlet.triangle_count,
    vertices, 
    position_buffer_accessor
    .count,
    sizeof( vec3s ) );
 
    ...
}</pre>
<p>We loop over<a id="_idIndexMarker297"/> all the meshlets and we call the MeshOptimizer API that computes the bounds for each meshlet. Let’s see in more detail the structure of the data that is returned:</p>
<pre class="source-code">
struct meshopt_Bounds
{
    float center[3];
    float radius;
 
    float cone_apex[3];
    float cone_axis[3];
    float cone_cutoff;
 
    signed char cone_axis_s8[3];
    signed char cone_cutoff_s8;
};</pre>
<p>The first four floats represent the bounding sphere. Next, we have the cone definition, which is comprised of the cone direction (<code>cone_axis</code>) and the cone angle (<code>cone_cutoff</code>). We are not using the <code>cone_apex</code> value as it makes the back-face culling computation more expensive. However, it can lead to better results.</p>
<p>Once again, notice that quantized values (<code>cone_axis_s8</code> and <code>cone_cutoff_s8</code>) help us reduce the size of the data required for each meshlet.</p>
<p>Finally, meshlet data is copied into GPU buffers and it will be used during the execution of task and mesh shaders.</p>
<p>For each<a id="_idIndexMarker298"/> processed mesh, we will also save an offset and count of meshlets to add a coarse culling based on the parent mesh: if the mesh is visible, then its meshlets will be added.</p>
<p>In this section, we have described what meshlets are and why they are useful to improve the culling of geometry on the GPU. Next, we showed the data structures that are used in our implementation. Now that our data is ready, it’s time for it to be consumed by task and mesh shaders. That’s the topic of the next section!</p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor097"/>Understanding task and mesh shaders</h1>
<p>Before we begin, we should mention that mesh shaders can be used without task shaders. If, for instance, you wanted to perform culling or some other pre-processing step on the meshlets on the CPU, you are free to do so.</p>
<p>Also, note that<a id="_idIndexMarker299"/> task and<a id="_idIndexMarker300"/> mesh shaders replace vertex shaders in the graphics pipeline. The output of mesh shaders is going to be consumed by the fragment shader directly.</p>
<p>The following diagram illustrates the differences between the traditional geometry pipeline and the mesh shader pipeline:</p>
<div><div><img alt="Figure 6.4 – The difference between traditional and mesh pipeline" height="793" src="img/B18395_06_04.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – The difference between traditional and mesh pipeline</p>
<p>In this section, we are going to provide an overview of how task and mesh shaders work and then use this information to implement back-face and frustum culling using task shaders.</p>
<p>Both <a id="_idIndexMarker301"/>task and mesh shaders <a id="_idIndexMarker302"/>use the same execution model of compute shaders, with some minor changes. The output of task shaders is consumed directly by a mesh shader, and for both types, we can specify the thread group size.</p>
<p>Task shaders (sometimes also referred to as amplification shaders) can be thought of as filters. We submit all meshlets for processing when invoking a task shader, and the task shader will output the meshlets that have passed the filter.</p>
<p>The following diagram provides an example of meshlets that are processed by the task shader. The meshlets that are rejected won’t be processed further.</p>
<div><div><img alt="Figure 6.5 – The task shader determines which meshlets to cull. The culled meshlets won’t be processed by the mesh shader" height="170" src="img/B18395_06_05.jpg" width="907"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5 – The task shader determines which meshlets to cull. The culled meshlets won’t be processed by the mesh shader</p>
<p>The mesh shader then takes the active meshlets and performs the final processing as you normally would in a vertex shader.</p>
<p>While this is only a high-level overview of task and mesh shaders, there isn’t much more to it. We will provide more resources in the <em class="italic">Further reading</em> section if you’d like to know more about the inner workings of this feature.</p>
<p>Next, we are going to explain how to implement task and mesh shaders in Vulkan!</p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor098"/>Implementing task shaders</h2>
<p>As we <a id="_idIndexMarker303"/>mentioned previously, task and mesh shaders are available through an extension of the Vulkan API. We have shown how to check for extensions before, so we are not duplicating the code in this chapter. Please refer to the code for more details.</p>
<p>The extension also introduces two new pipeline stages, <code>VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV</code> and <code>VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV</code>, that can be used to place pipeline barriers to ensure data used by these stages is synchronized correctly.</p>
<p>Task shaders <a id="_idIndexMarker304"/>can be treated like any compute shader: we create a pipeline that includes an (optional) task shader module, a mesh shader, and a fragment shader. Invoking a task shader is done with the following API:</p>
<pre class="source-code">
vkCmdDrawMeshTasksNV( vk_command_buffer, task_count, 
    first_task );</pre>
<p>Think of <code>task_count</code> as the workgroup size of a compute shader. There is also an indirect variant that can read the invocation details for multiple draws from a buffer:</p>
<pre class="source-code">
vkCmdDrawMeshTasksIndirectCountNV( vk_command_buffer, 
    mesh_draw_buffer, 0, draw_count, stride );</pre>
<p>We use this variant in our code as it allows us to have only one draw call per scene and give the GPU full control over which meshlets will be drawn.</p>
<p>With indirect rendering, we write the commands in a GPU program as we would do on the CPU, and we additionally read a buffer to know how many commands are there. We will see command writing in the <em class="italic">GPU culling using compute</em> section of this chapter.</p>
<p>We now turn our attention to the shader implementation. Task and mesh shaders require that their GLSL extension be enabled, otherwise, the compiler might treat the code as a regular compute shader:</p>
<pre class="source-code">
#extension GL_NV_mesh_shader: require</pre>
<p>Since we are using an indirect command to invoke our shader, we need to enable another extension that will let us access the <code>draw</code> ID for the current shader invocation:</p>
<pre class="source-code">
#extension GL_ARB_shader_draw_parameters : enable</pre>
<p>Note that this extension is enabled in the <code>platform.h</code> header and not directly in the shader code. As we mentioned, task shaders are akin to compute shaders. In fact, the first directive in our shader is to determine the thread group size:</p>
<pre class="source-code">
layout(local_size_x = 32) in;</pre>
<p>Here, <code>local_size_y</code> and <code>local_size_z</code> will be ignored even if specified. We can now move to the main body of the shader. We start by determining which mesh and meshlet we <a id="_idIndexMarker305"/>need to process:</p>
<pre class="source-code">
uint thread_index = gl_LocalInvocationID.x;
uint group_index = gl_WorkGroupID.x;
uint meshlet_index = group_index * 32 + thread_index;
 
uint mesh_instance_index = draw_commands[ gl_DrawIDARB ]
    .drawId;</pre>
<p>The <code>gl_DrawIDARB</code> draw index comes from the invocation of each <code>vkCmdDrawMeshTasksNV</code> through the commands written in the indirect buffer.</p>
<p>Next, we load the data for the current meshlet. First, we determine the world position and the size of the meshlet bounding sphere:</p>
<pre class="source-code">
vec4 center = model * vec4(meshlets[mi].center, 1);
float scale = length( model[0] );
float radius = meshlets[mi].radius * scale;</pre>
<p>Next, we restore the <code>cone_axis</code> value (remember, they are stored as a single byte) and <code>cone_cutoff</code>:</p>
<pre class="source-code">
vec3 cone_axis = mat3( model ) * 
   vec3(int(meshlets[mi].cone_axis[0]) / 127.0, 
   int(meshlets[mi].cone_axis[1]) / 127.0, 
   int(meshlets[mi].cone_axis[2]) / 127.0); 
float cone_cutoff = int(meshlets[mi].cone_cutoff) / 127.0;</pre>
<p>We now have all of the data we need to perform back-face and frustum culling:</p>
<pre class="source-code">
accept = !coneCull(center.xyz, radius, cone_axis, 
    cone_cutoff, eye.xyz);</pre>
<p>Next, <code>coneCull</code> is implemented as follows:</p>
<pre class="source-code">
bool coneCull(vec3 center, float radius, vec3 cone_axis, 
float cone_cutoff, vec3 camera_position)
{
    return dot(center - camera_position, cone_axis) &gt;= 
        cone_cutoff * length(center - camera_position) + 
        radius;
}</pre>
<p>This code <a id="_idIndexMarker306"/>first computes the cosine of the angle between the cone axis and the vector toward the camera from the center of the bounding sphere. Then it scales the cone cutoff (which is the cosine of the cut-off half angle) by the distance between the camera and the center of the bounding sphere and adds the radius of the bounding sphere.</p>
<p>This determines whether the cone is pointing away from the camera, and should be culled or, if it’s pointing toward the camera, it should be kept. </p>
<p>The next step<a id="_idIndexMarker307"/> is to perform frustum culling. First, we transform the center of the bounding sphere into camera space:</p>
<pre class="source-code">
center = world_to_camera * center;</pre>
<p>Next, we check against the six frustum planes to determine whether the bounding sphere is inside the frustum:</p>
<pre class="source-code">
for ( uint i = 0; i &lt; 6; ++i ) {
    frustum_visible = frustum_visible &amp;&amp; 
        (dot( frustum_planes[i], center) &gt; -radius);
}</pre>
<p>We accept the meshlet if it’s both visible and not considered back facing:</p>
<pre class="source-code">
accept = accept &amp;&amp; frustum_visible;</pre>
<p>The final step is to write out the indices of the visible meshlets and their number. The output data structure is defined as follows:</p>
<pre class="source-code">
out taskNV block
{
    uint meshletIndices[32];
};</pre>
<p>We use the subgroup instructions of GLSL for this step, and it’s worth going through line by line if it’s the first time you have seen this syntax. To access these instructions, the following extension must be enabled:</p>
<pre class="source-code">
#extension GL_KHR_shader_subgroup_ballot: require</pre>
<p>First, we <a id="_idIndexMarker308"/>set a bit for the active shader invocation depending on whether the meshlet is considered visible or not:</p>
<pre class="source-code">
uvec4 ballot = subgroupBallot(accept);</pre>
<p>Next, we determine which bit was set by the previous call and use it to store the active meshlet index:</p>
<pre class="source-code">
uint index = subgroupBallotExclusiveBitCount(ballot);
 
if (accept)
    meshletIndices[index] = meshlet_index;</pre>
<p>Finally, we count all the bits set across this thread group and store them in the <code>gl_TaskCountNV</code> variable: </p>
<pre class="source-code">
uint count = subgroupBallotBitCount(ballot);
 
if (ti == 0)
    gl_TaskCountNV = count;</pre>
<p>The <code>gl_TaskCountNV</code> variable is used by the GPU to determine how many mesh shader invocations are needed to process the meshlets that have not been occluded. The <code>if</code> is needed so that we write <code>TaskCount</code> only once per meshlet.</p>
<p>This concludes our implementation of task shaders. Next, we are going to look at our mesh shader implementation.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor099"/>Implementing mesh shaders</h2>
<p>After <a id="_idIndexMarker309"/>performing meshlet culling in the task shader, we need to process the active meshlets. This is similar to a regular vertex shader, however, there are some important differences that we’d like to point out.</p>
<p>Like task shaders, mesh shaders can be considered compute shaders, and the first directive is to determine the thread group size:</p>
<pre class="source-code">
layout(local_size_x = 32) in;</pre>
<p>We then have to read the data that has been written by the task shader:</p>
<pre class="source-code">
in taskNV block
{
    uint meshletIndices[32];
};</pre>
<p>Next, we define the data we are going to output. We first determine the maximum number of vertices and primitives (triangles in our case) that we could write:</p>
<pre class="source-code">
layout(triangles, max_vertices = 64, max_primitives = 124) out;</pre>
<p>We follow with the same data we might usually output from a vertex shader:</p>
<pre class="source-code">
layout (location = 0) out vec2 vTexcoord0[];
layout (location = 1) out vec4 vNormal_BiTanX[];
layout (location = 2) out vec4 vTangent_BiTanY[];
layout (location = 3) out vec4 vPosition_BiTanZ[];
layout (location = 4) out flat uint mesh_draw_index[];</pre>
<p>Notice, though, that we are using an array of values, as we can output up to 64 vertices per invocation.</p>
<p>Now that we have our input and output values, we can move to the shader implementation. Like before, we first determine our mesh and meshlet index:</p>
<pre class="source-code">
uint ti = gl_LocalInvocationID.x;
uint mi = meshletIndices[gl_WorkGroupID.x];
 
MeshDraw mesh_draw = mesh_draws[ meshlets[mi].mesh_index ];
uint mesh_instance_index = draw_commands[gl_DrawIDARB + 
total_count].drawId;</pre>
<p>Next, we <a id="_idIndexMarker310"/>determine the vertex and index offset and count for the active meshlet:</p>
<pre class="source-code">
uint vertexCount = uint(meshlets[mi].vertexCount);
uint triangleCount = uint(meshlets[mi].triangleCount);
uint indexCount = triangleCount * 3;
 
uint vertexOffset = meshlets[mi].dataOffset;
uint indexOffset = vertexOffset + vertexCount;</pre>
<p>We then process the vertices for the active meshlet:</p>
<pre class="source-code">
for (uint i = ti; i &lt; vertexCount; i += 32)
{
    uint vi = meshletData[vertexOffset + i];
 
vec3 position = vec3(vertex_positions[vi].v.x, 
   vertex_positions[vi].v.y, 
   vertex_positions[vi].v.z); 
 
    // normals, tangents, etc.
 
    gl_MeshVerticesNV[ i ].gl_Position = view_projection * 
        (model * vec4(position, 1));
 
    mesh_draw_index[ i ] = meshlets[mi].mesh_index;
}</pre>
<p>Notice we<a id="_idIndexMarker311"/> are writing to the <code>gl_MeshVerticesNV</code> variable. This variable is used by the GPU to keep track of the vertices we output and their index. This data will then be used by the rasterizer to draw the resulting triangles on the screen.</p>
<p>Next, we write out the indices:</p>
<pre class="source-code">
uint indexGroupCount = (indexCount + 3) / 4;
 
for (uint i = ti; i &lt; indexGroupCount; i += 32)
{
    writePackedPrimitiveIndices4x8NV(i * 4, 
        meshletData[indexOffset + i]);
}</pre>
<p>The <code>writePackedPrimitiveIndices4x8NV</code> instruction has been introduced specifically for mesh shaders and it allows them to write four indices at once. As we mentioned previously, indices require only 1 byte to be stored, as we can’t have values greater than 64. They are packed into <code>meshletData</code>, which is an unsigned <code>int</code> array.</p>
<p>If indices were stored in a different format, we would need to write them out individually to the <code>gl_PrimitiveIndicesNV</code> variable.</p>
<p>Finally, we write the primitive count in the appropriate variable:</p>
<pre class="source-code">
if (ti == 0)
    gl_PrimitiveCountNV = uint(meshlets[mi].triangleCount);</pre>
<p>This concludes our mesh shader implementation.</p>
<p>In this section, we have given an overview of how task and mesh shaders work and how they relate to<a id="_idIndexMarker312"/> compute shaders. Next, we provided a walk-through of our task and mesh shader implementation and highlighted the main differences from regular vertex shaders.</p>
<p>In the next section, we are going to extend our implementation by adding occlusion culling.</p>
<h1 id="_idParaDest-101"><a id="_idTextAnchor100"/>GPU culling using compute</h1>
<p>In the previous <a id="_idIndexMarker313"/>section, we demonstrated<a id="_idIndexMarker314"/> how to perform back-face and frustum culling on meshlets. In this section, we are going to implement frustum and occlusion culling using compute shaders.</p>
<p>Depending on the rendering pipeline, occlusion culling is usually done through a depth pre-pass, where we write only the depth buffer. The depth buffer can then be used during the G-Buffer pass to avoid shading fragments that we already know are occluded.</p>
<p>The downside of this approach is that we have to draw the scene twice and, unless there is other work that can overlap with the depth pre-pass, have to wait for the depth pre-pass to complete before proceeding to the next step.</p>
<p>The algorithm described in this section was first presented at <a href="https://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf">https://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf</a>.</p>
<p>Here’s how it works:</p>
<ol>
<li value="1">Using the depth buffer from the previous frame, we render the visible objects in the scene and perform mesh and meshlet frustum and occlusion culling. This could lead to false negatives, for example, meshes or meshlets that are visible in this frame but were not visible before. We store the list of these objects so that any false positives can be resolved in the next phase.</li>
<li>The previous step generates a list of draw commands directly in a compute shader. This list will be used to draw the visible objects using an indirect draw command.</li>
<li>We now have an updated depth buffer, and we update the depth pyramid as well.</li>
<li>We can<a id="_idIndexMarker315"/> now re-test the objects that have been culled in the first phase and generate a new draw list to remove any false positives.</li>
<li>We draw<a id="_idIndexMarker316"/> the remaining objects and generate our final depth buffer. This will then be used as the starting point for the next frame, and the process will repeat.</li>
</ol>
<p>Now that we have a better understanding of the steps of the occlusion algorithm, let’s see in detail how it is implemented.</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>Depth pyramid generation</h2>
<p>When describing<a id="_idIndexMarker317"/> the<a id="_idIndexMarker318"/> occlusion algorithm, we mentioned the use of the depth buffer. However, we are not using the depth buffer directly. What we use instead is called a <strong class="bold">depth pyramid</strong>. You can think of it as the mipmap of the depth buffer.</p>
<p>The main difference from traditional mipmaps is that we can’t use bi-linear interpolation to compute the lower level. If we were to use regular interpolation, we would compute depth values that don’t exist in the scene.</p>
<p class="callout-heading">Note</p>
<p class="callout">As we’ll see later in the book, this applies in general to sampling depth textures. You should either use nearest neighbor sampling or specific samplers with min/max compare operations. Check out <a href="https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkSamplerReductionMode.xhtml">https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkSamplerReductionMode.xhtml</a> for more info.</p>
<p>Instead, we read the four fragments we want to reduce and pick the maximum value. We pick the maximum because our depth value goes from <code>0</code> to <code>1</code> and we need to make sure we cover the full range of values. If you are using <code>inverted-z</code>, the depth values go from <code>1</code> to <code>0</code> and the minimum value has to be used instead.</p>
<p>We perform this step using a compute shader. We start by transitioning the depth texture to a read state:</p>
<pre class="source-code">
util_add_image_barrier( gpu, gpu_commands-&gt;
    vk_command_buffer, depth_texture, 
        RESOURCE_STATE_SHADER_RESOURCE, 0, 1, true );</pre>
<p>Then, we<a id="_idIndexMarker319"/> loop over the levels of the depth pyramid:</p>
<pre class="source-code">
u32 width = depth_pyramid_texture-&gt;width;
u32 height = depth_pyramid_texture-&gt;
    height for ( u32 mip_index = 0; mip_index &lt; 
    depth_pyramid_texture-&gt;mipmaps; ++mip_index ) {
    util_add_image_barrier( gpu, gpu_commands-&gt;
    vk_command_buffer, depth_pyramid_texture-&gt;
    vk_image, RESOURCE_STATE_UNDEFINED, 
    RESOURCE_STATE_UNORDERED_ACCESS, 
    mip_index, 1, false );</pre>
<p>The barrier in the preceding example is needed to ensure the image we are writing to is correctly set up. Next, we compute the group size for this level and invoke the compute shader:</p>
<pre class="source-code">
    u32 group_x = ( width + 7 ) / 8;
    u32 group_y = ( height + 7 ) / 8;
 
    gpu_commands-&gt;dispatch( group_x, group_y, 1 );</pre>
<p>As we’ll see in a moment, the thread group size of the compute shader is set to 8x8. We have to take this into account to compute the right group size.</p>
<p>Finally, we transition the image of the current level so that we can safely read from it at the next iteration:</p>
<pre class="source-code">
    util_add_image_barrier( gpu, gpu_commands-&gt;
        vk_command_buffer, depth_pyramid_texture-&gt;
        vk_image, RESOURCE_STATE_UNORDERED_ACCESS, 
        RESOURCE_STATE_SHADER_RESOURCE, mip_index, 
        1, false );
 
    width /= 2;
    height /= 2;
}</pre>
<p>We <a id="_idIndexMarker320"/>also update the width and height to match the size of the next level. The compute shader implementation is relatively simple:</p>
<pre class="source-code">
ivec2 texel_position00 = ivec2( gl_GlobalInvocationID.xy )
    * 2;
ivec2 texel_position01 = texel_position00 + ivec2(0, 1);
ivec2 texel_position10 = texel_position00 + ivec2(1, 0);
ivec2 texel_position11 = texel_position00 + ivec2(1, 1);</pre>
<p>We first compute the positions for the texels we want to reduce. Next, we read the depth value for these texels:</p>
<pre class="source-code">
float color00 = texelFetch( src, texel_position00, 0 ).r;
float color01 = texelFetch( src, texel_position01, 0 ).r;
float color10 = texelFetch( src, texel_position10, 0 ).r;
float color11 = texelFetch( src, texel_position11, 0 ).r;</pre>
<p>Finally, we compute the maximum value and store it in the right position of the next level in the pyramid:</p>
<pre class="source-code">
float result = max( max( max( color00, color01 ), 
    color10 ), color11 );
imageStore( dst, ivec2( gl_GlobalInvocationID.xy ), 
    vec4( result, 0, 0, 0 ) );</pre>
<p>The <code>max</code> operation is <a id="_idIndexMarker321"/>needed because the depth goes from <code>0</code> (close to the camera) to <code>1</code> (far from the camera). When using <code>inverse-depth</code>, it should be set to <code>min</code>. When down-sampling, we want the farthest of the four samples to avoid over-occluding.</p>
<p>Now that we have computed the depth pyramid, let’s see how it’s going to be used for occlusion culling.</p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor102"/>Occlusion culling</h2>
<p>The <a id="_idIndexMarker322"/>implementation <a id="_idIndexMarker323"/>of this step is done entirely in a compute shader. We are going to highlight the main sections of the code. We start by loading the current mesh:</p>
<pre class="source-code">
uint mesh_draw_index = 
   mesh_instance_draws[mesh_instance_index] 
   .mesh_draw_index; 
 
MeshDraw mesh_draw = mesh_draws[mesh_draw_index];
 
mat4 model = 
   mesh_instance_draws[mesh_instance_index].model;</pre>
<p>Next, we compute the bounding sphere position and radius in view space:</p>
<pre class="source-code">
vec4 bounding_sphere = mesh_bounds[mesh_draw_index];
 
vec4 world_bounding_center = model * 
    vec4(bounding_sphere.xyz, 1);
vec4 view_bounding_center = world_to_camera * 
    world_bounding_center;
 
float scale = length( model[0] );
float radius = bounding_sphere.w * scale;</pre>
<p>Note that<a id="_idIndexMarker324"/> this is the bounding <a id="_idIndexMarker325"/>sphere for the full mesh, not the meshlet. We are going to process the meshlets in the same way.</p>
<p>The next step is to perform frustum culling on the bounding sphere. This is the same code we presented in the <em class="italic">Implementing task shaders</em> section, and we are not going to replicate it here.</p>
<p>If the mesh passes the frustum culling, we check for occlusion culling next. First, we compute the bounding square of the perspective projected sphere. This step is necessary as the projected sphere shape could be an ellipsoid. Our implementation is based on this paper: <a href="https://jcgt.org/published/0002/02/05/">https://jcgt.org/published/0002/02/05/</a> and the Niagara project (<a href="https://github.com/zeux/niagara/">https://github.com/zeux/niagara/</a>).</p>
<p>We are going to highlight only the final implementation; we suggest reading the full paper for more details about the theory and derivation.</p>
<p>We start by checking whether the sphere is fully behind the near plane. If that’s the case, no further processing is required:</p>
<pre class="source-code">
bool project_sphere(vec3 C, float r, float znear, 
    float P00, float P11, out vec4 aabb) {
        if (-C.z - r &lt; znear)
        return false;</pre>
<p>Why <code>–C.z</code>? Because in our implementation, we look at a negative direction vector, thus the visible pixel’s <code>z</code> is always negative.</p>
<p>Next, we compute the minimum and maximum points on the <em class="italic">x</em> axis. We do so by considering only the <code>xz</code> plane, finding the projection of the sphere onto this plane, and computing<a id="_idIndexMarker326"/> the minimum and maximum <code>x</code> coordinates of this projection:</p>
<pre class="source-code">
vec2 cx = vec2(C.x, -C.z);
vec2 vx = vec2(sqrt(dot(cx, cx) - r * r), r);
vec2 minx = mat2(vx.x, vx.y, -vx.y, vx.x) * cx;
vec2 maxx = mat2(vx.x, -vx.y, vx.y, vx.x) * cx;</pre>
<p>We repeat <a id="_idIndexMarker327"/>the same procedure for the <code>y</code> coordinate (omitted here). The computed points are in world space, but we need their value in perspective-projected space. This is accomplished with the following code:</p>
<pre class="source-code">
aabb = vec4(minx.x / minx.y * P00, miny.x / miny.y * P11, 
       maxx.x / maxx.y * P00, maxy.x / maxy.y * P11);</pre>
<p><code>P00</code> and <code>P11</code> are the first two diagonal values of the view-projection matrix. The final step is to transform these values from screen space to UV space. Operating in UV space will be useful for the next part of the algorithm.</p>
<p>The transformation is performed by the following code:</p>
<pre class="source-code">
aabb = aabb.xwzy * vec4(0.5f, -0.5f, 0.5f, -0.5f) + 
vec4(0.5f);</pre>
<p>Coordinates in screen space are in the <code>[-1, 1]</code> range, while UV coordinates are in the <code>[0, 1]</code> range. This transformation performs the mapping from one range to the other. We use a negative offset for <code>y</code> as screen space has a bottom-left origin, while UV space has a top-left origin.</p>
<p>Now that we have the 2D bounding box for the mesh sphere, we can check whether it’s occluded. First, we determine which level of the depth pyramid we should use:</p>
<pre class="source-code">
ivec2 depth_pyramid_size = 
   textureSize(global_textures[nonuniformEXT 
   (depth_pyramid_texture_index)], 0); 
float width = (aabb.z - aabb.x) * depth_pyramid_size.x ;
float height = (aabb.w - aabb.y) * depth_pyramid_size.y ;
 
float level = floor(log2(max(width, height)));</pre>
<p>We simply<a id="_idIndexMarker328"/> scale the size of the bounding box in UV coordinates, computed in the previous step, by the size of the top level of the <a id="_idIndexMarker329"/>depth pyramid texture. We then take the logarithm of the largest between the width and height to determine which level of the pyramid we should use for the depth value lookup.</p>
<p>With this step, we reduce the bounding box to an individual pixel lookup. Remember, when computing the levels of the pyramid, the reduction step stores the farthest depth value. Thanks to this, we can safely look up an individual fragment to determine whether the bounding box is occluded or not.</p>
<p>This is accomplished with the following code:</p>
<pre class="source-code">
float depth = 
   textureLod(global_textures[nonuniformEXT 
   (depth_pyramid_texture_index)], (aabb.xy + aabb.zw) 
   0.5, level).r;</pre>
<p>First, we look up the depth value in the pyramid for the sphere bounding box. Next, we compute the closest depth of the bounding sphere.</p>
<p>We also compute the closest depth for the bounding sphere: </p>
<pre class="source-code">
float depth_sphere = z_near / (view_bounding_center.z – 
                     radius); </pre>
<p>Finally, we determine whether the sphere is occluded by checking its depth against the depth we read from the pyramid:</p>
<pre class="source-code">
occlusion_visible = (depth_sphere &lt;= depth);</pre>
<p>If the mesh passes both the frustum and occlusion culling, we add the command to draw it in the command list:</p>
<pre class="source-code">
draw_commands[draw_index].drawId = mesh_instance_index;
draw_commands[draw_index].taskCount = 
    (mesh_draw.meshlet_count + 31) / 32;
draw_commands[draw_index].firstTask = 
    mesh_draw.meshlet_offset / 32;</pre>
<p>We will then use this list of commands to draw the meshlets for the visible meshes (as shown in the <em class="italic">Understanding task and mesh shaders</em> section) and update the depth pyramid.</p>
<p>The last step <a id="_idIndexMarker330"/>will be to rerun the culling for <a id="_idIndexMarker331"/>the meshes that were discarded in this first pass. Using the updated depth pyramid, we can generate a new command list to draw any meshes that had been incorrectly culled.</p>
<p>This concludes our implementation of occlusion culling. In this section, we have explained an algorithm for efficient occlusion culling on the GPU. We started by detailing the steps performed by this technique.</p>
<p>We then highlighted the main sections of the code that perform the creation of the depth pyramid, which is used for occlusion culling based on the bounding sphere of each mesh.</p>
<p>Performing culling on the GPU is a powerful technique that has helped developers overcome some of the limitations of the traditional geometry pipeline and allows us to render more complex and detailed scenes.</p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor103"/>Summary</h1>
<p>In this chapter, we have introduced the concept of meshlets, a construct that helps us break down large meshes into more manageable chunks and that can be used to perform occlusion computations on the GPU. We have demonstrated how to use the library of our choice (MeshOptimizer) to generate meshlets, and we also illustrated the extra data structures (cones and bounding spheres) that are useful for occlusion operations.</p>
<p>We introduced mesh and task shaders. Conceptually similar to compute shaders, they allow us to quickly process meshlets on the GPU. We demonstrated how to use task shaders to perform back-face and frustum culling, and how mesh shaders replace vertex shaders by processing and generating multiple primitives in parallel.</p>
<p>Finally, we went through the implementation of occlusion culling. We first listed the steps that compose this technique. Next, we demonstrated how to compute a depth pyramid from our existing depth buffer. Lastly, we analyzed the occlusion culling implementation and highlighted the most relevant part of the compute shader. This step also generates a list of commands that can be used with an indirect draw call.</p>
<p>So far, our scene only uses one light. In the next chapter, we are going to implement clustered-deferred lighting, which will allow us to render hundreds of lights in our scene.</p>
<h1 id="_idParaDest-105"><a id="_idTextAnchor104"/>Further reading</h1>
<p>As we mentioned in a previous section, task and mesh shaders are only available on Nvidia GPUs. This blog post has more details about their inner workings: <a href="https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/">https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/</a>.</p>
<p>Our implementation has been heavily inspired by the algorithms and techniques described in these resources:</p>
<ul>
<li><a href="https://www.gdcvault.com/play/1023463/contactUs">https://www.gdcvault.com/play/1023463/contactUs</a></li>
<li><a href="http://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf">http://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf</a></li>
</ul>
<p>Our go-to reference implementation for a task and mesh shader has been this project: <a href="https://github.com/zeux/niagara">https://github.com/zeux/niagara</a>, which is also accompanied by a series of videos showing its development: <a href="https://www.youtube.com/playlist?list=PL0JVLUVCkk-l7CWCn3-cdftR0oajugYvd">https://www.youtube.com/playlist?list=PL0JVLUVCkk-l7CWCn3-cdftR0oajugYvd</a>.</p>
<p>These libraries can be used to generate meshlets:</p>
<ul>
<li><a href="https://github.com/zeux/meshoptimizer">https://github.com/zeux/meshoptimizer</a> (the one we use)</li>
<li><a href="https://github.com/JarkkoPFC/meshlete">https://github.com/JarkkoPFC/meshlete</a></li>
</ul>
<p>A more recent development in occlusion culling is the concept of a visibility buffer. The technique is described in detail in these resources:</p>
<ul>
<li><a href="http://www.conffx.com/Visibility_Buffer_GDCE.pdf">http://www.conffx.com/Visibility_Buffer_GDCE.pdf</a></li>
<li><a href="http://filmicworlds.com/blog/visibility-buffer-rendering-with-material-graphs/">http://filmicworlds.com/blog/visibility-buffer-rendering-with-material-graphs/</a></li>
<li><a href="https://www.youtube.com/watch?v=eviSykqSUUw">https://www.youtube.com/watch?v=eviSykqSUUw</a></li>
</ul>
</div>
</div></body></html>