<html><head></head><body>
		<div id="_idContainer011">
			<h1 id="_idParaDest-39" class="chapter-number" lang="en-GB"><a id="_idTextAnchor038"/>4</h1>
			<h1 id="_idParaDest-40" lang="en-GB"><a id="_idTextAnchor039"/>Adding Tests to a Project</h1>
			<p lang="en-GB">In this chapter, we’re going to add a major new ability to the test library. The new ability will let you check conditions within a test to make sure everything is going as planned. Sometimes, these checks are called an <em class="italic" lang="">assert</em>, and <a id="_idIndexMarker098"/>sometimes, they are called an <em class="italic" lang="">expect</em>. Whatever they are <a id="_idIndexMarker099"/>called, they let you confirm that the values you get back from the code being tested match expectations.</p>
			<p lang="en-GB">For this book and the test library<a id="_idIndexMarker100"/> that we’re creating, I’m going to call these checks confirmations. Each confirmation will be called a <em class="italic" lang="">confirm</em>. The reason for this is that assert is already being used in C++, and it can be confusing to use the same name. Additionally, expect is a common term within other test libraries, which is not by itself a reason to avoid using the same term. I actually like the term expect. But expect has another common behavior that we don’t want. Many other testing libraries will let a test continue even if an expect fails. I don’t really like this behavior. Once something has gone wrong, I think it’s time to end that test. Other tests can still run. But we shouldn’t continue running a test once something doesn’t match what we expect.</p>
			<p lang="en-GB">So far, you can use the test library to write multiple tests, run them, and see the results. The result of each test is to either pass or fail. You can even expect certain failures and treat them as passing. And there’s a third result that will likely not be needed outside of the test library itself and that is a missed failure. You can read all about these abilities in the first three chapters.</p>
			<p lang="en-GB">In this chapter, we will cover the following main topics:</p>
			<ul>
				<li lang="en-GB">How to detect whether a test passes or fails</li>
				<li lang="en-GB">Enhancing the testing library to support confirmations</li>
				<li lang="en-GB">Should error cases be tested, too?</li>
			</ul>
			<p lang="en-GB">There’s a reason we’ve waited until this chapter to add confirms. We’re following a TDD approach to the design of the test library itself. That means we let the tests drive the design. This is an agile approach to software design. We think about what is the most valuable or necessary feature or capability to add next, what the end use of that feature will be, write the minimum amount of code needed to get it working, and then enhance the design by adding more.</p>
			<p lang="en-GB">Until now, there was no point in adding confirms. We needed to get the essential functionality working first, which would let tests be created and run before we could think about what to do inside the tests. Maybe we could have added confirms before the exception handling. But I choose to work on exception handling before confirms. Exceptions seem more closely related to the essential declaration and running of the tests than confirms and, therefore, are more valuable than confirms.</p>
			<p lang="en-GB">Additionally, you’ll also see that we’ll be using exceptions to enable confirmations. This is another reason why the basic ability to handle exceptions came before confirms.</p>
			<p lang="en-GB">Now we can turn our attention to the tests with confirms. Again, we’re going to do the minimum amount of work needed to get the confirms functional and useful. We’ll continue adding more abilities to confirms in the next chapter.</p>
			<h1 id="_idParaDest-41" lang="en-GB"><a id="_idTextAnchor040"/>Technical requirements</h1>
			<p lang="en-GB">All of the code in this chapter uses standard C++, which builds on any modern C++ 17, or later, compiler and standard library. The code is based on and continues from the previous chapters.</p>
			<p lang="en-GB">You can find all of the code for this chapter at the following GitHub repository:</p>
			<p lang="en-GB"><a href="https://github.com/PacktPublishing/Test-Driven-Development-with-CPP">https://github.com/PacktPublishing/Test-Driven-Development-with-CPP</a></p>
			<h1 id="_idParaDest-42" lang="en-GB"><a id="_idTextAnchor041"/>How to detect whether a test passes or fails</h1>
			<p lang="en-GB">In this chapter, the<a id="_idIndexMarker101"/> tests we’ll be creating are different enough from the creation tests that they should have their own file. When writing your own tests, you’ll want to organize them into multiple files, too.</p>
			<p lang="en-GB">Let’s create a new file called <strong class="source-inline" lang="">Confirm.cpp</strong> and place it inside the <strong class="source-inline" lang="">tests</strong> folder. With the new file, the project structure will look like the following:</p>
			<pre class="source-code" lang="en-GB">
MereTDD project root folder
    Test.h
    tests folder
        main.cpp
        Confirm.cpp
        Creation.cpp</pre>
			<p lang="en-GB">Then, add a single test to the new file so that it looks like this:</p>
			<pre class="source-code" lang="en-GB">
#include "../Test.h"
TEST("Test will pass without any confirms")
{
}</pre>
			<p lang="en-GB">We already have an empty test in <strong class="source-inline" lang="">Creation.cpp</strong>, which looks like this:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test can be created")
{
}</pre>
			<p lang="en-GB">The only real difference between these two tests is the name. Do we really need another test that does the exact same thing but with a different name? I could argue on either side of a debate about adding code that does the same thing but with a different name. Some people<a id="_idIndexMarker102"/> might see this and think it is pure code duplication.</p>
			<p lang="en-GB">To me, the difference comes down to <em class="italic" lang="">intent</em>. Yes, both tests happen to be the same right now. But who knows whether one or both will be modified later? And if that ever happens, will we be able to remember that a test was serving multiple purposes?</p>
			<p lang="en-GB">I strongly urge you to write each test as if it is the only thing standing between your code and the bugs that the test is designed to prevent. Or maybe the test is exercising a specific usage to make sure that nothing breaks later during a design change. Having two identical tests is okay as long as they are testing different things. It’s the goal that should be unique.</p>
			<p lang="en-GB">In this case, the original test just ensures that a test can be created in its most basic form. The new test is specifically making sure that an empty test will pass. These are two different tests that just happen to require the same test method body to accomplish their goals.</p>
			<p lang="en-GB">Now that we have a new file in the project with a new test, let’s build and make sure everything works as expected. And it fails. The reason for the build failure is the following:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">ld: 5 duplicate symbols for architecture x86_64</strong></pre>
			<p lang="en-GB">Everything compiles okay, but the project fails to link into the final runnable executable. We have five linker errors. One of the linker errors says the following:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">duplicate symbol 'Test3::run()'</strong></pre>
			<p lang="en-GB">I have only listed one of the<a id="_idIndexMarker103"/> linker errors because they are all similar. The problem is that we now have two declarations of <strong class="source-inline" lang="">Test3</strong>. One declaration comes from each file, <strong class="source-inline" lang="">Creation.cpp</strong> and <strong class="source-inline" lang="">Confirm.cpp</strong>; that is because the <strong class="source-inline" lang="">TEST</strong> macro declares the <strong class="source-inline" lang="">Test</strong> class with a unique number based on the line number where the <strong class="source-inline" lang="">TEST</strong> macro appears in the source file. Both files happen to use the <strong class="source-inline" lang="">TEST</strong> macro on line 3, so they each declare a class called <strong class="source-inline" lang="">Test3</strong>.</p>
			<p lang="en-GB">The solution for this is to use an <em class="italic" lang="">unnamed namespace</em> in the macros when declaring the class. This will still create two classes such as <strong class="source-inline" lang="">Test3</strong>, but each will be in a namespace that does not extend outside of the <strong class="source-inline" lang="">.cpp</strong> file in which it is declared. This means that the test classes can continue to be based on the line number, which is guaranteed to be unique within each <strong class="source-inline" lang="">.cpp</strong> file and will now no longer conflict with any other tests that happen to be declared on the same line number in a different <strong class="source-inline" lang="">.cpp</strong> file.</p>
			<p lang="en-GB">All we need to do is modify the <strong class="source-inline" lang="">TEST</strong> and <strong class="source-inline" lang="">TEST_EX</strong> macros to add an unnamed namespace around just the class declaration inside of each macro. We don’t need to extend the namespace to the end of the macro because the macros go on to declare the beginning of the <strong class="source-inline" lang="">run</strong> method. Luckily, the <strong class="source-inline" lang="">run</strong> method declaration does not need to be inside the namespace. Otherwise, we would have to figure out how to end the namespace with the closing curly brace after the <strong class="source-inline" lang="">run</strong> method has been fully defined. As it is, we can end the namespace after the class declaration. The <strong class="source-inline" lang="">TEST</strong> macro looks like this:</p>
			<pre class="source-code" lang="en-GB">
#define TEST( testName ) \
namespace { \
class MERETDD_CLASS : public MereTDD::TestBase \
{ \
public: \
    MERETDD_CLASS (std::string_view name) \
    : TestBase(name) \
    { \
        MereTDD::getTests().push_back(this); \
    } \
    void run () override; \
}; \
} /* end of unnamed namespace */ \
MERETDD_CLASS MERETDD_INSTANCE(testName); \
void MERETDD_CLASS::run ()</pre>
			<p lang="en-GB">And the <strong class="source-inline" lang="">TEST_EX</strong> macro <a id="_idIndexMarker104"/>needs a similar unnamed namespace as follows:</p>
			<pre class="source-code" lang="en-GB">
#define TEST_EX( testName, exceptionType ) \
namespace { \
class MERETDD_CLASS : public MereTDD::TestBase \
{ \
public: \
    MERETDD_CLASS (std::string_view name) \
    : TestBase(name) \
    { \
        MereTDD::getTests().push_back(this); \
    } \
    void runEx () override \
    { \
        try \
        { \
            run(); \
        } \
        catch (exceptionType const &amp;) \
        { \
            return; \
        } \
        throw MereTDD::MissingException(#exceptionType); \
    } \
    void run () override; \
}; \
} /* end of unnamed namespace */ \
MERETDD_CLASS MERETDD_INSTANCE(testName); \
void MERETDD_CLASS::run ()</pre>
			<p lang="en-GB">Now that the project builds again, running it will show the new test. Depending on what order your linker built the final executable, you might find the new test runs before or after the previous tests. Here is a portion of the results when I ran the test project:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">Running 7 tests</strong>
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test will pass without any confirms</strong>
<strong class="bold" lang="">Passed</strong>
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test can be created</strong>
<strong class="bold" lang="">Passed</strong>
<strong class="bold" lang="">---------------</strong></pre>
			<p lang="en-GB">The other five tests and the summary are not shown. The previous chapter ended with six tests, and we just added one more bringing the total to seven tests. The important part is that the new test runs and passes. Now we can think about what a confirm will look like. And what does it mean to confirm something?</p>
			<p lang="en-GB">When running a test, you<a id="_idIndexMarker105"/> want to not just verify that the test completes but that it completes correctly. And it also helps to check along the way to make sure everything is running as expected. You can do this by comparing the values you get from the code being tested to make sure they match the expected values.</p>
			<p lang="en-GB">Let’s say that you have a function that adds two numbers and returns a result. You can call this function with known values and compare the returned sum with an expected sum that you calculate yourself. You confirm that the calculated sum matches the expected sum. If the values match, then the confirm passes. But if the values don’t match, then the confirm fails, which should cause the test to fail, too.</p>
			<p lang="en-GB">A test can have multiple confirms and each will be checked to make sure they pass. The moment one confirm fails, there’s no point in continuing the test because it has already failed. Some TDD purists will claim that a test should only have a single confirmation. I think there’s a good compromise between only having a single confirm versus writing epic tests that try to verify everything.</p>
			<p lang="en-GB">A popular style of writing tests with multiple confirmations is to keep track of how many confirms pass by letting a test continue even if a confirm fails. There is a benefit to this style because the developer can sometimes fix multiple problems with a single run of the tests. We’re not taking this approach because I think the benefit is rarely achieved in practice. Some people might argue this, but hear me out. Once something is proven to not meet your expectations, the most likely result is a chain reaction of further failures. I have rarely seen a well-designed test fail one confirmation and then somehow recover to pass unrelated confirmations. If the test behaves like this, then it normally is testing unrelated issues and should be broken into multiple tests. The practice we’re going to be following is this: when a confirm fails, then the test itself has failed. Other tests might proceed just fine. But the test with a failed confirm has already failed, and there is no point in continuing to see whether maybe some part of the test might still be okay.</p>
			<p lang="en-GB">When writing tests, just like when writing regular code, it’s good to avoid duplication. In other words, if you find yourself testing the same things by checking values that have already been checked in other tests, then it’s time to think about the goal of each test. Write one test that covers some basic functionality that will be used many times. Then, in other tests that make use of that same functionality, you can assume it has already been tested and works, so there is no need to verify it again with extra confirms.</p>
			<p lang="en-GB">Some code will probably make all of this clearer. First, let’s think about how to verify an expected result without a confirm. This is a time when we can’t just write the code for what a confirm will look like because we don’t know yet what we want it to do. A little exploration is in order. The next section will turn the exploration we’ll do here into actual confirms.</p>
			<p lang="en-GB">For a moment, let’s pretend <a id="_idIndexMarker106"/>that we have a real TDD project that we’re working on. We’ll keep things simple and say that we need some way to determine whether a school grade is passing or not. Even this simple example could become complicated if there were different guidelines for passing homework versus quizzes or tests. If that were the case, there might be a whole class hierarchy involved. We just have a simple need to determine whether a score from 0 to 100 is a passing grade or not.</p>
			<p lang="en-GB">Now that we have our scenario, what would a simple test look like? We don’t have any code to support the grading requirement. It’s just a general idea of what we want. So, we expect the build to fail if we try running right after creating a test. This is how you can use TDD to come up with a design.</p>
			<p lang="en-GB">For now, we’ll put this code inside <strong class="source-inline" lang="">Confirm.cpp</strong>. If we were really building a test project for a school grading application, then there might be a test file called <strong class="source-inline" lang="">Grades.cpp</strong>. Because we’re just exploring, we’ll use the test file we already have, called <strong class="source-inline" lang="">Confirm.cpp</strong>, and create a test like this:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    if (result)
    {
        throw 1;
    }
}</pre>
			<p lang="en-GB">The first thing is to think about the usage. If you had a function called <strong class="source-inline" lang="">isPassingGrade</strong> that accepted a score and returned a bool result, would that meet your requirements and be easy to use? It seems easy enough. It will do whatever it needs inside to tell us whether the score is passing or not and return true if the grade is passing and false if it’s not.</p>
			<p lang="en-GB">Then, you can think about how to test this function. It’s always good to test boundary conditions, so we can start by asking whether a score of 0 is passing or not. We assign the passing result to a variable that can be tested against an expected value. We expect 0 to be a failing grade, which is why the code throws something if the result is true instead. This will cause<a id="_idIndexMarker107"/> the test case to fail because of an unexpected exception.</p>
			<p lang="en-GB">We’re on the right track. This is what I want you to understand about checking along the way to make sure everything is running okay. We could add another check in the same test like this to make sure that 100 is a passing grade:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    if (result)
    {
        throw 1;
    }
    result = isPassingGrade(100);
    if (not result)
    {
        throw 1;
    }
}</pre>
			<p lang="en-GB">Now, you can see a single test that checks two things. First, it makes sure that a score of 0 is a failing grade and then that a score of 100 is a passing grade. Because these checks are so related, I would put them in the same test as this and confirm that the first case should be a failing grade and the second should be a passing grade.</p>
			<p lang="en-GB">A test confirmation is nothing more than a simple check against an expected value that throws an exception if the expectation is not met.</p>
			<p lang="en-GB">Some TDD purists will recommend that you split the test into two separate tests. My advice is to use your best judgment. I tend to avoid absolute guidance that says you should <em class="italic" lang="">always</em> do something one way or another. I think there’s room to be flexible.</p>
			<p lang="en-GB">Let’s get this building so that we can run it and see the results. All we need to do is add the <strong class="source-inline" lang="">isPassingGrade</strong> function. We’ll add the function to the top of <strong class="source-inline" lang="">Confirm.cpp</strong>. If this was a real project you were working on, then you would have a better place to put this function. It would not be in the test project; instead, it would be included in the project being tested.</p>
			<p lang="en-GB">Inside <strong class="source-inline" lang="">Confirm.cpp</strong>, create<a id="_idIndexMarker108"/> a function called <strong class="source-inline" lang="">isPassingGrade</strong>, as follows:</p>
			<pre class="source-code" lang="en-GB">
bool isPassingGrade (int value)
{
    return true;
}</pre>
			<p lang="en-GB">Now we can build and run the project to see the results. The test result we’re interested in fails like this:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test passing grades</strong>
<strong class="bold" lang="">Failed</strong>
<strong class="bold" lang="">Unexpected exception thrown.</strong>
<strong class="bold" lang="">---------------</strong></pre>
			<p lang="en-GB">The function should obviously fail because it always returns true for a passing grade regardless of the score given. But that’s not the part we’re going to focus on next. It would be if you really were building and testing a grading application. You would enhance the design, get the test to pass, and then enhance the test, and continue until all the tests pass.</p>
			<p lang="en-GB">This is enough to demonstrate what I mean by checking on the progress of a running test to make sure it’s proceeding as expected. Now we have a test that, first, checks to make sure 0 is a failing grade and then checks to make sure 100 is a passing grade. Each of these is a confirm. At each point, we are checking whether the actual result matches what we expect. And we confirm in different ways to fit each condition.</p>
			<p lang="en-GB">In the next section, we’re going to enhance the test library to fix problems with the current solution and make it easier to write confirms. Right now, the code throws an int when it detects a problem, and while the throw definitely causes the test to fail, it leads to a test result that says the failure was caused by an unexpected exception.</p>
			<p lang="en-GB">The next section will wrap the <strong class="source-inline" lang="">if</strong> statement with its criteria and the exception throwing into an easy macro that will handle everything and lead to a better description of what actually failed and where it failed.</p>
			<h1 id="_idParaDest-43" lang="en-GB"><a id="_idTextAnchor042"/>Enhancing the testing library to support assertions</h1>
			<p lang="en-GB">The passing grades test from the <a id="_idIndexMarker109"/>previous section has two confirms that<a id="_idIndexMarker110"/> we’re going to improve in this section. It looks like this:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    if (result)
    {
        throw 1;
    }
    result = isPassingGrade(100);
    if (not result)
    {
        throw 1;
    }
}</pre>
			<p lang="en-GB">In the first confirm, we want to make sure that <strong class="source-inline" lang="">result</strong> is false because we know that a score of 0 should not be a passing grade. And for the second confirm, we want to make sure that, this time, <strong class="source-inline" lang="">result</strong> is true because we know that a score of 100 should lead to a passing grade.</p>
			<p lang="en-GB">Can you see how the <strong class="source-inline" lang="">if</strong> condition needs to be the <em class="italic" lang="">opposite</em> of what we’re trying to confirm? This is because the <strong class="source-inline" lang="">if</strong> block runs when the confirm does <em class="italic" lang="">not</em> meet the expected value. We’ll need to make this easier to use because it will lead to bugs if we always have to write confirms like this. But there are still bigger problems with the test code.</p>
			<p lang="en-GB">Why does it throw an int if the check fails? That’s because we’re still exploring what a real confirm should look like. The code we have now just shows you the need for making checks along the way inside of a test to ensure things are proceeding as expected. This section will change how we’re going to be writing confirms in our tests.</p>
			<p lang="en-GB">Throwing an int when a value does not match what was expected also leads to the wrong test result description. We don’t want the test results to say that an unexpected exception was thrown.</p>
			<p lang="en-GB">However, we do want to throw something. Because once a test deviates from the expected path, we don’t want the test to continue. It’s already shown that it has failed. Throwing whenever an expected condition is not met is a great way to fail the test at that point. We need to figure out a way to change the test result description to better inform us of what went wrong.</p>
			<p lang="en-GB">First, let’s fix the test result by throwing something more meaningful. Note that the following code uses hardcoded numeric values, such as 17 and 23. Numbers such as these are often called <em class="italic" lang="">magic numbers</em> and <a id="_idIndexMarker111"/>should be avoided. We’ll be fixing the problem soon, and the use of <a id="_idIndexMarker112"/>direct numbers whose meaning is unclear is included to show you that there is a better way. In <strong class="source-inline" lang="">Confirm.cpp</strong>, change<a id="_idIndexMarker113"/> the passing grades test to throw <strong class="source-inline" lang="">BoolConfirmException</strong> from both confirms like this:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    if (result)
    {
        throw MereTDD::BoolConfirmException(false, 17);
    }
    result = isPassingGrade(100);
    if (not result)
    {
        throw MereTDD::BoolConfirmException(true, 23);
    }
}</pre>
			<p lang="en-GB">Later, we’ll need to create this class. For now, we want to code it like we intend to use it. It’s called <strong class="source-inline" lang="">BoolConfirmException</strong> because it will let us confirm that a bool value matches what we expect. The constructor parameters will be the expected bool value and the line number. I used line numbers 17 and 23 because they are the line numbers in my editor for the two <strong class="source-inline" lang="">throw</strong> statements. Later in this section, we’ll use a macro so that we can let the macro provide the line number automatically. Normally, you would want to avoid hardcoding any numeric value in the code except for simple values such as 0, 1, and maybe -1. Any other values are called magic numbers because the meaning is confusing.</p>
			<p lang="en-GB">The exception thrown in confirms will be based on the information needed to make a meaningful test result description. For bool values, the expected value and line number are enough. Other exceptions will need more information and will be explained in the next chapter. We’ll have more than one exception type, but they will be related. Inheritance is a good way<a id="_idIndexMarker114"/> to represent the different exception types that we’ll be throwing. The base class<a id="_idIndexMarker115"/> for all the types will be called <strong class="source-inline" lang="">ConfirmException</strong>.</p>
			<p lang="en-GB">In <strong class="source-inline" lang="">Test.h</strong>, create a new class called <strong class="source-inline" lang="">ConfirmException</strong> inside the <strong class="source-inline" lang="">MereTDD</strong> namespace like this:</p>
			<pre class="source-code" lang="en-GB">
namespace MereTDD
{
class ConfirmException
{
public:
    ConfirmException () = default;
    virtual ~ConfirmException () = default;
    std::string_view reason () const
    {
        return mReason;
    }
protected:
    std::string mReason;
};</pre>
			<p lang="en-GB">Then, right after the base exception class, we can declare the derived <strong class="source-inline" lang="">BoolConfirmException</strong> class like this:</p>
			<pre class="source-code" lang="en-GB">
class BoolConfirmException : public ConfirmException
{
public:
    BoolConfirmException (bool expected, int line)
    {
        mReason =  "Confirm failed on line ";
        mReason += std::to_string(line) + "\n";
        mReason += "    Expected: ";
        mReason += expected ? "true" : "false";
    }
};</pre>
			<p lang="en-GB">The purpose of <strong class="source-inline" lang="">BoolConfirmException</strong> is to format a meaningful description that can be read through the <strong class="source-inline" lang="">reason</strong> method in the base class.</p>
			<p lang="en-GB">The next thing we need to do is catch the base class when running the tests and display the confirm reason instead of a message saying that there was an unexpected exception. Modify<a id="_idIndexMarker116"/> the <strong class="source-inline" lang="">runTests</strong> method in <strong class="source-inline" lang="">Test.h</strong> so that it will catch the new exception base class <a id="_idIndexMarker117"/>and set the appropriate failed message like this:</p>
			<pre class="source-code" lang="en-GB">
        try
        {
            test-&gt;runEx();
        }
        catch (ConfirmException const &amp; ex)
        {
            test-&gt;setFailed(ex.reason());
        }</pre>
			<p lang="en-GB">The confirm exception is ready. Building and running shows the following test result:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test passing grades</strong>
<strong class="bold" lang="">Failed</strong>
<strong class="bold" lang="">Confirm failed on line 17</strong>
<strong class="bold" lang="">    Expected: false</strong>
<strong class="bold" lang="">---------------</strong></pre>
			<p lang="en-GB">This is a lot better than saying there was an unexpected exception. Now, we understand there was a confirm failure on line 17 and that the test expected the value to be false. Line 17 is for grade 0, which we expected to be a failing grade.</p>
			<p lang="en-GB">Let’s add a macro for the confirm so that we no longer have to provide the line number manually. And the macro can include the backward logic in the <strong class="source-inline" lang="">if</strong> condition and the throwing of the proper confirm exception. Here’s what the test should look like with the macro. We’ll add the macro but only after we write the code that intends to use the macro. Change the passing grades test in <strong class="source-inline" lang="">Confirm.cpp</strong> to look like this:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    CONFIRM_FALSE(result);
    result = isPassingGrade(100);
    CONFIRM_TRUE(result);
}</pre>
			<p lang="en-GB">Now the test really looks like it’s using confirms. Additionally, the macros make it very clear that the first confirm is <em class="italic" lang="">expecting</em> <strong class="source-inline" lang="">result</strong> to be false, while the second confirm is <em class="italic" lang="">expecting</em> <strong class="source-inline" lang="">result</strong> to be true. The value that gets passed to the macro is called the <em class="italic" lang="">actual</em> value. As long as the actual value matches the expected value, then the confirm passes and lets the test continue.</p>
			<p lang="en-GB">To define these macros, we’ll <a id="_idIndexMarker118"/>put them at the end of <strong class="source-inline" lang="">Test.h</strong>. Note <a id="_idIndexMarker119"/>that each one is almost identical to what the test used to code manually:</p>
			<pre class="source-code" lang="en-GB">
#define CONFIRM_FALSE( actual ) \
if (actual) \
{ \
    throw MereTDD::BoolConfirmException(false, __LINE__); \
}
#define CONFIRM_TRUE( actual ) \
if (not actual) \
{ \
    throw MereTDD::BoolConfirmException(true, __LINE__); \
}</pre>
			<p lang="en-GB">You can see that when confirming a false expected value, the <strong class="source-inline" lang="">if</strong> condition looks for a true actual value. Additionally, when confirming a true expected value, the <strong class="source-inline" lang="">if</strong> condition looks for a false actual value. Both macros throw <strong class="source-inline" lang="">BoolConfirmException</strong> and use <strong class="source-inline" lang="">__LINE__</strong> to get the line number automatically.</p>
			<p lang="en-GB">Now, running the tests shows almost the exact same results. The only difference is the line number that the passing grades test fails at. This is because the confirm macros now use a single line each. The results look like this:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test passing grades</strong>
<strong class="bold" lang="">Failed</strong>
<strong class="bold" lang="">Confirm failed on line 15</strong>
<strong class="bold" lang="">    Expected: false</strong>
<strong class="bold" lang="">---------------</strong></pre>
			<p lang="en-GB">The confirms are much easier to use now, and they make the test clearer to read and understand. Our goal is not to build a school grading application, so we’ll be removing the exploratory code. However, before removing it, the next section will use the passing grades test to explain another important aspect of TDD. And that is the question of what to do about error cases.</p>
			<h1 id="_idParaDest-44" lang="en-GB"><a id="_idTextAnchor043"/>Should error cases be tested, too?</h1>
			<p lang="en-GB">Is it possible to get to 100% testing code <a id="_idIndexMarker120"/>coverage? And what does that mean?</p>
			<p lang="en-GB">Let me explain by continuing to use the passing grades code we were exploring in the previous section. Here is the test again:</p>
			<pre class="source-code" lang="en-GB">
TEST("Test passing grades")
{
    bool result = isPassingGrade(0);
    CONFIRM_FALSE(result);
    result = isPassingGrade(100);
    CONFIRM_TRUE(result);
}</pre>
			<p lang="en-GB">Right now, this test does cover 100% of the function under test. That means that all of the code inside the <strong class="source-inline" lang="">isPassingGrade</strong> function is being run by at least one test. I know, the <strong class="source-inline" lang="">isPassingGrade</strong> function is a simple function with a single line of code that always returns true. It looks like this:</p>
			<pre class="source-code" lang="en-GB">
bool isPassingGrade (int value)
{
    return true;
}</pre>
			<p lang="en-GB">With a function this simple, just calling it from within a test will make sure that all of the code is covered or run. As it is, the function doesn’t work and needs to be enhanced to pass both confirms. We can enhance it to look like this:</p>
			<pre class="source-code" lang="en-GB">
bool isPassingGrade (int value)
{
    if (value &lt; 60)
    {
        return false;
    }
    return true;
}</pre>
			<p lang="en-GB">Building and running the project now passes the test. The results of the passing grades test look like this:</p>
			<pre class="source-code" lang="en-GB">
<strong class="bold" lang="">---------------</strong>
<strong class="bold" lang="">Test passing grades</strong>
<strong class="bold" lang="">Passed</strong>
<strong class="bold" lang="">---------------</strong></pre>
			<p lang="en-GB">And we still have 100% code coverage for this function because the passing grades test calls the function twice with the values of 0 and 100. The first call causes the <strong class="source-inline" lang="">if</strong> condition to be true, which executes the code inside the <strong class="source-inline" lang="">if</strong> block. And the second call causes the <strong class="source-inline" lang="">return</strong> statement after the <strong class="source-inline" lang="">if</strong> block to run. By calling <strong class="source-inline" lang="">isPassingGrade</strong> with both the 0 and 100 values, we cause all of the code inside to be run at least once. That is what it means to<a id="_idIndexMarker121"/> achieve 100% code coverage.</p>
			<p lang="en-GB">Both values of 0 and 100 are valid grades, and it makes sense to test with them. We don’t need to test what will happen if we call <strong class="source-inline" lang="">isPassingGrade</strong> with the values of 1 or 99. That’s because they are not interesting.</p>
			<p lang="en-GB">Edge values are almost always interesting. So, it would make sense to add a couple more calls inside the test for values 59 and 60. While these represent good call values and confirms to add to the test, they won’t do anything for the code coverage.</p>
			<p lang="en-GB">That leads to the first point I want you to understand. Simply achieving 100% code coverage is not enough. You want to ensure that you are testing everything that needs to be tested. Look for edge cases that should be tested even if they don’t do anything to improve your code coverage.</p>
			<p lang="en-GB">And then look for error cases.</p>
			<p lang="en-GB">Error cases will likely drive your code to add extra checking to make sure the error cases are properly handled. TDD is a great way to drive these conditions. Alternatively, you might decide to change your design as a way to make an error case no longer applicable.</p>
			<p lang="en-GB">For example, does it make sense to check whether a negative grade is passing? If so, definitely add a test and then add the code to make the test pass. This is something that I would put into a new test. Remember the balance between having a single confirm per test versus allowing multiple confirms?</p>
			<p lang="en-GB">It makes sense to include all confirms for calling <strong class="source-inline" lang="">isPassingGrade</strong> for the values of 0, 59, 60, and 100 in a single test. At least to me.</p>
			<p lang="en-GB">However, calling <strong class="source-inline" lang="">isPassingGrade</strong> with a value of -1 is different enough that it should have its own test. Or maybe thinking of this test is enough to cause you to change the design so that <strong class="source-inline" lang="">isPassingGrade</strong> no longer accepts an int parameter, and you decide to use an unsigned int parameter instead. For this particular example, I would probably use an unsigned int. That would mean we no longer need a test for -1 or any negative number grade.</p>
			<p lang="en-GB">But what about grades above 100? Maybe they should be allowed for extra credit grades. If so, then add a new test for grades above 100 and make sure to confirm they pass. You might find the values of 101, 110, and 1,000,000 to be interesting.</p>
			<p lang="en-GB">Why the values of 101, 110, and 1,000,000? Well, 101 is an edge value and should be included. The value of 110 seems<a id="_idIndexMarker122"/> like a reasonable extra credit value. And the value of 1,000,000 is a good example of a ridiculous value that should be included just to make sure the code doesn’t fail with some unexpected exception. You might even consider putting the 1,000,000 value in its own test.</p>
			<p lang="en-GB">Error cases should be tested. Ideally, you will think of the error cases while writing the tests, and you can write the test first before adding code to handle the error condition. For example, if you decide that any grade over 1,000 should result in an exception being thrown, then write a test that expects the exception and call <strong class="source-inline" lang="">isPassingGrade</strong> with the value of 1,000 to make sure that it does throw.</p>
			<p lang="en-GB">One final thought about testing error cases is this: I’ve seen a lot of code that was not designed using TDD, and one thing that stands out to me regarding a lot of this code is that error cases are much harder to test. Sometimes, it’s no longer feasible to add tests for certain error cases because they are too difficult to isolate and get them to run so that the test can verify how the code responds.</p>
			<p lang="en-GB">Once you start following TDD, you’ll find that you have much better test coverage. That’s because you designed tests first, including the tests for error cases. This forces you to make your designs <em class="italic" lang="">testable</em> from the very beginning.</p>
			<h1 id="_idParaDest-45" lang="en-GB"><a id="_idTextAnchor044"/>Summary</h1>
			<p lang="en-GB">In this chapter, you learned how to write tests that can detect a failure even before reaching the end of the test. You learned how to use confirms to make sure that the actual values match what you expect them to be. However, this chapter only explained how to check bool values. There are many other types of values you will need to check, such as the following:</p>
			<ul>
				<li lang="en-GB">You might have a number such as a count that needs to be confirmed</li>
				<li lang="en-GB">You might need to check a string value to make sure it contains the text you expect</li>
			</ul>
			<p lang="en-GB">The next chapter will add these additional types and explain a common problem when comparing fractional or floating-point numeric values.</p>
		</div>
	</body></html>