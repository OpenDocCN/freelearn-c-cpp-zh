<html><head></head><body>
		<div><h1 id="_idParaDest-49"><em class="italics"><a id="_idTextAnchor053"/>Chapter 4</em></h1>
		</div>
		<div><h1 id="_idParaDest-50"><a id="_idTextAnchor054"/>Tools That Support Software Development</h1>
		</div>
		<div><h2 id="_idParaDest-51"><a id="_idTextAnchor055"/>Introduction</h2>
			<p>Yes, there are loads of different tools. Yes, everybody has their favorite. No, there's no reason to look down on people who use different tools than yours. Yes, people who like <code>vi</code> are weird. In this chapter, I'm not going to recommend specific tools, but maybe certain classes of tools and ways I've found of working with them that help me.</p>
			<p>If you're new to programming – perhaps you've just taken a few classes or worked through some books – this chapter should tell you something about what programmers do beyond typing <code>public static void</code> into text editors. If you're more experienced, you may still find the odd useful nugget here.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor056"/>Version Control/Source Code Management</h2>
			<p>I imagine many readers are currently thinking that the battle over version control must surely be over by now, and that all developers are using some system. This is, unfortunately, demonstrably untrue. Let me start with an anecdote. It's 2004, and I've just started working as a systems manager in a university computing lab. My job is partly to maintain the computers in the lab, partly to teach programming and numerical computing to physics undergraduates, and partly to write software that will assist in said teaching. As part of this work, I started using version control, both for my source code and for some of the configuration files in <code>/etc</code> on the servers. A more experienced colleague saw me doing this and told me that I was just generating work for myself; that this wasn't necessary for the small things I was maintaining.</p>
			<p>Move on now to 2010, and I'm working in a big scientific facility in the UK. Using software and a <em class="italics">lot</em> of computers, we've got something that used to take an entire PhD to finish down to somewhere between 1 and 8 hours. I'm on the software team and, yes, we're using version control to track changes to the software and to understand what version is released. Well, kind of, anyway. The "core" of the files/source code is in version control, but one of its main features is to provide a scripting environment and DSL in which scientists at the "lab benches," if you will, can write up scripts that automate their experiments. These scripts are not (necessarily) version controlled. Worse, the source code is deployed to experimental stations so someone who discovers a bug <em class="italics">in the core</em> can fix it locally without the change being tracked in version control.</p>
			<p>So, a group does an experiment at this facility, and produces some interesting results. You try to replicate this later, and you get different results. It could be soft<a id="_idTextAnchor057"/>ware-related, right? All you need to do is to use the same software as the original group used… Unfortunately, you can't. It's vanished.</p>
			<p>That's an example of how scientists failing to use the tools from software development could be compromising their science. There's a lot of snake oil in the software field, both from people wanting you to use their tools/methodologies because you'll pay them for it, and from people who have decided that "their" way of working is correct and that any other way is incorrect. You need to be able to cut through all of that nonsense to find out how particular tools and techniques impact the actual work you're trying to do. Philosophy of science currently places a high value on reproducibility and auditing. Version control supports that, so it would be beneficial for programmers working in science to use version control. But they aren't; not consistently, anyway.</p>
			<p>In its simplest guise - the one that I was using in 2004 - version control is a big undo stack. Only, unlike a series of undo and redo commands, you can leave messages explaining who made each change and why. Even if you're working on your own, this is a great facility to have – if you try something that gets confusing or doesn't work out, you can easily roll back to a working version and take things from there.</p>
			<p>Once you're more familiar with the capabilities of a version control system, it can become a powerful tool for configuration management. Work on different features and bugfixes for the same product can proceed in parallel, with work being integrated when it's ready into one or more releases of the product. Discussing this workflow in detail is more than I'm willing to cover here: I recommend the <strong class="bold">Pragmatic Programmer</strong> books on version control such as <strong class="bold">Pragmatic Version Control Using Git</strong>—<a href="http://pragprog.com/book/tsgit/pragmatic-version-control-using-git">http://pragprog.com/book/tsgit/pragmatic-version-control-using-git</a> by Travis Swicegood.</p>
			<h3 id="_idParaDest-53"><a id="_idTextAnchor058"/>On Version Control and Collaboration</h3>
			<p>Version control is <em class="italics">no</em> more of a collaboration tool than other document management systems, such as SharePoint. Integrating (or merging) related work by different people is hard and requires knowledge of the meaning of the code and how changes interact. Version control systems don't have that knowledge, and as a result cannot simplify this merging process in any but the most trivial cases. It <em class="italics">does</em> let you defer the problem until you want to face it, but that's about it.</p>
			<p>Some tools - for example, <strong class="bold">GitHub</strong> — <a href="http://www.github.com">http://www.github.com</a> – provide social features around a core version control system. However, the problems of knowing what to integrate from whom, and when, and resolving conflicts all still exist. The social features give you somewhere to talk about those problems.</p>
			<h3 id="_idParaDest-54"><a id="_idTextAnchor059"/>Distributed Version Control</h3>
			<p>I've used a good few version control systems over the years, from simple tools that work with the local filesystem to hugely expensive commercial products. My favored way of working now is with a <code>darcs</code>, they all work in much the same way).</p>
			<p>With a DVCS, it's very easy to get a local project into version control, so even toy projects and prototypes can be versioned. A feature that makes them great for this, over earlier systems that version local files, such as <strong class="bold">RCS</strong> (<strong class="bold">Reaction Control System)</strong> and <strong class="bold">SCCS</strong> (<strong class="bold">Source Code Control System</strong>), is that the whole repository (that is, all of the files that comprise the versioned project) is treated atomically. In other words, the repository can be at one version or another, but never in an in-between state where some files are at an earlier revision than others.</p>
			<p>Earlier systems, like RCS, do not impose this restriction. With RCS, every file is versioned independently so each can be checked out on a different version. While this is more flexible, it does introduce certain problems. For example, consider the files in the following figure. One of the files contains a function that's used in code in the other file. You need to make a change to the function's signature, to add a new parameter. This means changing all three files.</p>
			<div><div><img alt="Figure 4.1: A dependency that crosses multiple files" src="img/B15099_04_01.jpg"/>
				</div>
			</div>
			<h6>Figure 4.1: A dependency that crosses multiple files</h6>
			<p>In an atomic version control system, the files can either both be checked out at the revision with one parameter or both be checked out at the revision with two parameters. A per-file versioning system will allow any combination of versions to be checked out, despite the fact that half of the possible combinations do not make sense.</p>
			<p>Once you've got a project that's locally versioned in a DVCS repository, sharing it with others is simple and can be done in numerous ways. If you want to back up or share the repository on a hosted service like <strong class="bold">BitBucket</strong>—<a href="http://www.bitbucket.org">http://www.bitbucket.org</a>, you set that up as a remote repository and push your content. A collaborator can then clone the repository from the remote version and start working on the code. If they're on the same network as you, then you can just share the folder containing the repository without setting up a remote service.</p>
			<h4>Personal Experience</h4>
			<p class="callout">In some situations, a combination of these approaches is required. The DVCS tools that I've used all support that. On one recent project, everything was hosted on a remote service but there were hundreds of megabytes of assets stored in the repository. It made sense for the computers in the office to not only clone the remote repository, but also to peer with each other to reduce the time and bandwidth used when the assets changed. The situation looked like the following figure.</p>
			<div><div><img alt="Figure 4.2: A DVCS configuration can break out of the “star” topology required by centralized systems" src="img/B15099_04_02.jpg"/>
				</div>
			</div>
			<h6>Figure 4.2: A DVCS configuration can break out of the "star" topology required by centralized systems</h6>
			<p>Doing this with a centralized version control system would've been possible, but ugly. One of the developers would've needed to fully synchronize their working copy with the server, then fully copy the repository and its metadata to all of the other developer systems. This is less efficient than just copying the differences between the repositories. Some centralized version control systems wouldn't even support that way of working, because they track which files they think you have checked out on the server.</p>
			<p>Another benefit brought by DVCS – as much due to improved algorithms as their distributed nature – is the ease with which you can create and destroy branches. When I mainly worked with centralized version control (primarily Subversion and Perforce), branches were created for particular tasks, such as new releases, and the teams I worked on invented workflows for deciding when code migrated from one branch to another.</p>
			<p>With DVCSes, I often create a branch every hour or so. If I want to start some new work, I create a branch in my local version of the repository. After a while, I'm either done, and the branch gets merged and deleted; convinced that the idea was wrong - in which case, it's just deleted; or I want someone else to have a look, and I push that branch without merging it. All of this was possible with centralized VCS, though much slower – and you needed network access to even create the branch.</p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor060"/>Continuous Integration and Deployment</h2>
			<p>Having just discussed version control, it's time to announce which VCS mistake I see more often than any other - the mistake that's made by everyone (myself included), regardless of their experience or expertise. And the winner is…</p>
			<p><em class="italics">Adding new files to a project but forgetting to add them to the repository.</em></p>
			<p>I don't do this <em class="italics">very</em> often - maybe less than once per month. But whenever I do, when the other developers on the team synchronize their repositories, we're left in a situation where everything works for me, but they can't build.</p>
			<p>If we're lucky, the error will report that the file wasn't found, and we can quickly resolve the problem. If not, there'll be some other error about a missing symbol or something that will take time to track down before discovering the root cause.</p>
			<p>If only we had some form of robot that would see every check-in, grab the source code, and try to build the product. If it couldn't do that, it'd be great if it came over and complained to the person who made the change that broke the build.</p>
			<p>It turns out that we've been living in the future for quite a while now, and that robot already exists. It goes by the name of <strong class="bold">Continuous Integration</strong>, or CI.</p>
			<h3 id="_idParaDest-56"><a id="_idTextAnchor061"/>Why Use CI?</h3>
			<p>Finding those missing files isn't the only thing CI is good for. If you have automated tests (see the <em class="italics">Chapter 5, Coding Practices</em>), a CI system can run the tests on every change and report any problems. My team's CI server is configured to run the analysis tool (discussed in this chapter) and consider a build failed if that tool discovers any problems. Some projects automatically generate API documentation and publish it to a web server.</p>
			<p>It can even make the build available for people to install once it's passed all of the tests. This is related to the idea of <strong class="bold">Continuous Deployment</strong>: if a version of the software seems good enough to use (that is, it doesn't fail any test you put it through), then start using it. You may still find problems that weren't exposed by the automated tests, but you'll do so earlier than if you didn't deploy right away.</p>
			<p>A final benefit to CI - one that's quite subtle but very useful – is that it forces you to set your project up so that it can be checked out of version control and built automatically. This means that even when a human programmer is working with the project, it's easy for them to get set up with the source and start being productive. That person could be you, when you get a new laptop. It could be a contractor or a new employee joining the team. Either way, if there's a single step to fetch the project and build it, then they'll be up to speed quickly, rather than asking you how to fetch some library or configure some plugin.</p>
			<h3 id="_idParaDest-57"><a id="_idTextAnchor062"/>CI On Real Teams</h3>
			<p>Some teams I've worked on have been so heavily invested in using CI that they've employed someone to maintain the CI infrastructure (it's not a full-time occupation, so they usually look after other supporting tools and consult on their use). In other teams, it's been up to the developers to keep it running.</p>
			<p>The difficulty in that second case is in knowing when to look after the CI versus doing project work. As an example, in the month before this section was written, I had to migrate my team's CI system onto different hardware. Despite trying to ensure that the configuration of the system didn't change between the two environments, the tests in one of the projects would no longer run.</p>
			<p>The thing is, the tests worked fine in the IDEs on all of the developer machines. Is it really important to take more time away from adding value to the products our clients are paying for to handhold some confused robot?</p>
			<p>I consider running without CI to be proceeding at risk these days. Yes, I <em class="italics">could</em> avoid all problems without it. Yes, it's <em class="italics">possible</em> that nothing will go wrong. But why take the chance? Why not spend that little extra to ensure I discover problems as early as possible? It's spending a little now to potentially save a lot in the future. I therefore try to find the time to maintain the CI service when it's necessary.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor063"/>Build Management</h2>
			<p>I wrote in the previous section that a benefit of adopting CI is that it forces you to simplify the building of your project (by which I mean compiling sources, translating assets, creating packages, and anything else that takes the inputs created by the project team and converts them into a product that will be used by customers). Indeed, to use CI you will have to condense the build down until an automated process can complete it given any revision of your source code.</p>
			<p>There's no need to write a script or an other program to do this work, because plenty of build management tools already exist. At a high level, they all do the same thing: they take a collection of input files, a collection of output files, and some information about the transformations needed to get from one to the other. How they do that, of course, varies from product to product.</p>
			<h3 id="_idParaDest-59"><a id="_idTextAnchor064"/>Convention or Configuration</h3>
			<p>Some build systems, like <code>make</code> and <code>ant</code>, need the developer to tell them nearly everything about a project before they can do anything. As an example, while <code>make</code> has an implicit rule for converting C source files into object files, it won't actually execute that rule until you tell it that you need the object file for something.</p>
			<p>Conversely, other tools (including Maven) make certain assumptions about a project. Maven assumes that every <code>.java</code> file in a folder called <code>src/main/java</code> must be compiled into a class that will be part of the product.</p>
			<p>The configuration approach has the advantage that it's discoverable even to someone who knows little about the system. Someone armed with a collection of source files, <code>grep</code>, and a little patience could work out from a <code>Makefile</code> or <code>Xcode</code> project which files were built as which targets, and how. Because there's a full (or near full) specification of how everything's built, you can find what you need to change to make it act differently, too.</p>
			<p>The downside to that discoverability is that you <em class="italics">have</em> to specify all that stuff. You can't just tell Xcode that any <code>.m</code> file in a folder called <code>Classes</code> should be passed to the Objective-C compiler; you have to give it a big list of all of them. Add a new file, and you must change the list.</p>
			<p>With a convention-based build system, this situation is exactly reversed. If you follow the conventions, everything's automatic. However, if you don't <em class="italics">know</em> the conventions, they can be hard to discover. I once had a situation on a <em class="italics">Rails</em> project where the folder that static resources (such as images) were saved in changed between two releases. On launching the app, none of my images were being used and it wasn't clear why. Of course, for someone who <em class="italics">does</em> know the conventions, there's no learning curve associated with transferring between different projects.</p>
			<p>On balance, I'd prefer a convention-led approach, provided the conventions are well-documented somewhere so it's easy to find out what's going on and how to override it if you need to. The benefit of reduced effort and increased consistency, for me, outweighs the occasional surprise that's encountered.</p>
			<h3 id="_idParaDest-60"><a id="_idTextAnchor065"/>Build Systems That Generate Other Build Systems</h3>
			<p>Some build procedures get so complicated that they spawn another build system that configures the build environment for the target system before building. An archetypal example is GNU Autotools, –  which actually has a three-level build system. Typically, developers will run <code>autoconf</code>, a tool that examines a project to find out what questions the subsequent step should ask and generates a script called <code>configure</code>. The user downloads the source package and runs <code>configure</code>, which inspects the compilation environment and uses a collection of macros to create a Makefile. The Makefile can then compile the source code to (finally!) create the product.</p>
			<p>As argued by <em class="italics">Poul-Henning Kamp</em>—<a href="http://queue.acm.org/detail.cfm?id=2349257">http://queue.acm.org/detail.cfm?id=2349257</a>), this is a bad architecture that adds layers of cruft to work around code that has not been written to be portable to the environments it will be used in. Software written to be built with tools like these is hard to read, because you must read multiple languages just to understand how one line of code works.</p>
			<p>Consider a bug reported in a particular C function in your project. You open that function to find two different implementations, chosen by a <code>#ifdef/#else/#endif</code> preprocessor block. You search for the macro used by that block and find it in <code>config.h</code>, so you must read the <code>configure</code> script to find out how it's set. To discover whether <em class="italics">that</em> test is doing the right thing, you need to look at the <code>configure.ac</code> file to find out how the test is generated.</p>
			<p>About the only justification for using such a convoluted process is that it's thought of as conventional and expected by your target users, but even then, I'd question whether that expectation is driven by a technical need or by <strong class="bold">Stockholm syndrome</strong> — <a href="http://en.wikipedia.org/wiki/Stockholm_syndrome">http://en.wikipedia.org/wiki/Stockholm_syndrome</a>. If your product doesn't need to be portable, then there's no need to add all that complexity – and even if it does, there may be better ways to solve the problem that'll work for your product. One obvious approach is to target a portable platform such as Mono or Python.</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor066"/>Bug and work tracking</h2>
			<p>For most of their history, computers have excelled at doing things one at a time. Even a single client or customer can parallelize much better than that and will think of (and make) multiple requests while you're still working on one thing.</p>
			<p>It's really useful to write all of these requests down, and keep track of where you and your colleagues are on each of them so that you don't all try to solve the same problem, and can let the client know which of them you've fixed. Bug trackers (sometimes more generally called issue trackers or work trackers) are designed to solve that problem.</p>
			<h3 id="_idParaDest-62"><a id="_idTextAnchor067"/>What Goes in And When?</h3>
			<p>I've worked on projects where the bug tracker gets populated with all of the project's feature requests at the beginning (this discussion overlaps slightly with the treatment of software project management patterns, in <em class="italics">Chapter 13, Teamwork</em>). This introduces a couple of problems. One is that the <strong class="bold">Big List</strong> needs a lot of grooming and editing to stay relevant as features are added and removed, split between multiple developers, or found to be dependent on other work. The second is psychological: for a long time, members of the project team will be looking at a soul-destroying list of things that still haven't been done, like Sisyphus standing with his rock looking up from the base of the hill. The project will seem like a death march from the beginning.</p>
			<p>My preference is to attack the work tracker with an iterative approach. When it's decided what will go into the next build, add those tasks to the work tracker. As they're done, mark them as closed. The only things that stay in the tracker from one iteration to the next are those things that don't get completed in the build when they were scheduled to. Now, the big list of items in the tracker is always the big list of what we've already completed, not the big list of things still remaining. This is something akin to the Kanban system, where a team will have a fixed "capacity" of pending work. As they pull work from the pending bucket to start working on it, they can request that the bucket get topped up—but never past its capacity.</p>
			<p>My approach to reporting bugs is different. Unless it's something trivial in the code I'm working on now, so that I can fix the problem in under a couple of minutes and move on, I'll always report it straight away. This means I won't forget about the problem; the fix is implicitly planned for the next iteration, following the <strong class="bold">Joel Test</strong> rule of fixing bugs before adding new code, and we can see how many bugs are being discovered in each build of the product. (Now that I reflect on the Joel Test, I realize that this chapter covers a lot of points that are included in the test. Perhaps you should just measure your team's performance with respect to the Joel test's 12 points and fix any that you answer "no" to—<a href="http://www.joelonsoftware.com/articles/fog0000000043.html">http://www.joelonsoftware.com/articles/fog0000000043.html</a>.).</p>
			<h3 id="_idParaDest-63"><a id="_idTextAnchor068"/>How Precisely to Track?</h3>
			<p>So, you managed to fix that bug in 2 hours. But, was it <em class="italics">actually</em> 2 hours, or was it 125 minutes? Did you spend those 2 hours solely fixing the bug, or did you answer that email about the engineers-versus-sales whist drive during that time?</p>
			<p>Being able to compare estimated time versus actual time can be useful. I'm not sure that "velocity" – the ratio between the estimated time and the actual time spent on tasks – is particularly helpful, because in my experience estimates are not consistently wrong by a constant factor. It's knowing <em class="italics">what</em> work you're bad at estimating that's helpful. Do you fail to appreciate the risks involved in adding new features, or do you tend to assume all bug fixes are trivially simple?</p>
			<p>So, precise measurements are not particularly helpful, which is useful to know, because the accuracy probably doesn't exist to back up that precision. I usually just look at my watch when I start work and when I end work, and round to the nearest quarter or half hour. That means my time records include all those interruptions and little tasks I did while fixing the bug – which is fine because they slowed me down and that needs recording.</p>
			<p>Estimates aren't even that accurate. The game I play with my team goes like this: every developer on the team (and no one else) independently writes down an estimate of how long the tasks we're planning will take. They're allowed to pick one of these: 1 hour, 2 hours, 4 hours, 8 hours, or don't know. If we think a task will take longer than 8 hours, we break it down and estimate smaller chunks of the task.</p>
			<p>For each task, everyone presents their estimates. If they're roughly the same, then we just pick the highest number and go with that. If there's a spread of opinion – maybe one developer thinks something will take an hour when someone else thinks it'll take a day – we'll discuss that. Probably, one (or more) of the team is relying on tacit knowledge that needs to be brought into the open. It's usually possible to resolve such differences quickly and move on to the next thing.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor069"/>Integrated Development Environment</h2>
			<p>Well, really, I suppose your environment doesn't need to be fully integrated. For a long time, my toolset was a combination of Project Builder, Interface Builder, WebObjects Builder, EOModeler, and Edit. It <em class="italics">does</em> need to make you more efficient than the simple "text editor and <code>make</code>" combo of yore.</p>
			<p>What's the big problem? Why so harsh on the text editor? Any time you have to stop making software to deal with your tools, there's a chance you'll lose concentration, forget what you were doing, and have to spend a few minutes reacquainting yourself with the problem. Losing a couple of minutes doesn't sound like too big a deal, but if you're doing it a couple of times an hour every working day, it quickly adds up to a frustrating drop in productivity.</p>
			<p>You're going to be using your IDE for most of your working day, <em class="italics">every</em> working day, for the next few years. You should invest heavily in it. That means spending a bit of money on a good one that's better than the free alternatives. It means training yourself in the tricks and shortcuts so you can do them without thinking, saving the occasional second and (more importantly) keeping you focused on the work. It can even mean writing plugins, if your environment supports them, so you can do more without context-switching.</p>
			<p>In some plugin-rich environments, you could go a whole day without ever leaving the IDE. For example, Eclipse now includes the <strong class="bold">Mylyn</strong> (<a href="http://eclipse.org/mylyn/start/">http://eclipse.org/mylyn/start/</a>) task-focused plugin, so you can interact with your bug tracker inside the IDE. It'll also let you focus your views on only those files related to the task you're currently working on.</p>
			<p>Not only do you need to go deep on your chosen IDE, you need to go broad on alternatives. A future version of your favorite tool might change things so much that you'd be more efficient switching to a different app. Or you might start working on a project where your preferred IDE isn't available; for example, you can't (easily) write a Mono app in Xcode, or an Eclipse RCP application in Visual Studio.</p>
			<p>This restriction of development environments to particular platforms, whether done for technological or business reasons, is unfortunate. This is where the "just use a text editor" crowd has a point: you can learn <code>emacs</code> just once and whatever language you end up programming in, you don't need to learn how to use the editor again just to write code. As you're going to spend your whole working life in one of these environments, every change to features you already know how to use represents horrendous inefficiency.</p>
			<p>Notice that all of the aforementioned IDEs follow the same common pattern. When people have the "which IDE is best?" argument, what they're actually discussing is "which slightly souped-up monospace text editor with a <strong class="bold">build</strong> button do you like using?" Eclipse, Xcode, IntelliJ, Visual Studio… All of these tools riff on the same design—letting you see the source code and change the source code. As secondary effects, you can also do things like build the source code, run the built product, and debug it.</p>
			<p>The most successful IDE in the world, I would contend (and then wave my hands unconvincingly when anyone asks for data), is one that's not designed like that at all. It's the one that is used by more non-software specialists than any of those already mentioned. The one that doesn't require you to practice being an IDE user for years before you get any good. The one that business analysts, office assistants, accountants, and project managers alike all turn to when they need their computer to run through some custom algorithm. The most successful IDE in the world is Excel.</p>
			<p>In a spreadsheet, it's the inputs and results that are front-and-center in the presentation, not the intermediate stuff that gets you from one to the other. You can test your "code" by typing in a different input and watching the results change in front of you. You can see intermediate results, not by breaking and stepping through, or putting in a log statement then switching to the log view, but by breaking the algorithm up into smaller steps (or functions or procedures, if you want to call them that). You can then visualize how these intermediate results change right alongside the inputs and outputs. That's quicker feedback than even REPLs can offer.</p>
			<p>Many spreadsheet users naturally adopt a "test-first" approach; they create inputs for which they know what the results should be and make successively better attempts to build a formula that achieves those results. And, of course, interesting visualizations such as graphs are available (though the quality does vary between products). Drawing a graph in Xcode is… challenging. Indeed, you can't do it at all, but you can get Xcode to create an application that can itself generate a graph. The results are a significant distance away from the tools.</p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor070"/>Static Analysis</h2>
			<p>In the <em class="italics">Chapter 5, Coding Practices</em>, there's a section on <em class="italics">Code Reviews</em>. Knowing that reviewers will find and fixate upon the simplest problems they can find, wouldn't it be great to remove all the trivial problems so that they're forced to look for something more substantial?</p>
			<p>This is what static analysis does. It finds problems in code that can be automatically discovered without running the product, but that are either off-topic for compiler warnings or take too long to discover for the compiler to be an appropriate tool to search for them.</p>
			<p>What are off-topic problems? Typically, those that require knowledge of the semantics of the functions or methods you're using – knowledge that's beyond the scope of the compiler. For example, consider a C++ <code>destroyObject&lt;T&gt;(T t)</code> function that <em class="italics">deletes</em> its parameter. Calling that function twice with the same argument would be an error – but the compiler doesn't know that if it's just inspecting the function signature. Others are a matter of style. For example, Apple's C APIs have a naming convention related to their memory management rules: a function name contains <code>Create</code> when the caller owns the returned object or <code>Get</code> when the <code>callee</code> does. It's not a mistake to use C language to mix those up, so the compiler won't tell you about it, but an analyzer can.</p>
			<p>There is basically no reason to avoid using a static analyzer (if your reason is that there isn't one for your language/framework/whatever yet, you might have chosen a language/framework/whatever that isn't ready yet. There's a section about that in <em class="italics">Chapter 12, Business</em>). It'll discover easily fixable bugs for you and quickly train you into not making those mistakes in the first place.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor071"/>Code Generation</h2>
			<p>There are, in many applications, plenty of features that are trivial to implement but must be done over and over. Perhaps it's taking an array of model objects and preparing a list view, creating classes from database schemata, or creating a list of compile-time constants from a text file.</p>
			<p>These situations can usually be automated by generating code. The idea is to express the problem in a succinct representation, then translate that into something that can be incorporated into your program. This is pretty much what a compiler does; though many programming languages are far from succinct, they're still much less unwieldy than the machine's native instruction code.</p>
			<h3 id="_idParaDest-67"><a id="_idTextAnchor072"/>Writing Your Own Generator Shouldn't Be A First Resort</h3>
			<p>Just as a code generator makes it easier to create a product, it makes it harder to debug. For a concrete example, consider the <code>autotools</code> build system discussed earlier in this chapter. Imagine that a developer is looking into a reported problem in which one of the tests fails (a problem that I had to deal with today). The log file tells them what the C program was that encapsulated the test, but the developer cannot just modify that program. They must discover where the <code>configure</code> script is generating that program, and what it's trying to achieve by doing so. They must then find out where in <code>configure.ac</code> that section of the shell script is generated and work out a change to the <code>m4</code> macros that will result in the desired change to the C program, two steps later.</p>
			<p>In short, if your target environment offers facilities to solve your problem natively, such a solution will require less reverse engineering when diagnosing later problems. It's only if such a solution is overly expensive or error-prone that code generation is a reasonable alternative.</p>
			<p>Many of the cases given at the beginning of this section were data-driven, like the situation deriving class descriptions from a database schema for some <strong class="bold">Object-Relational Mapping</strong> (<strong class="bold">ORM</strong>) system. This is a case where some programming languages give you the ability to solve this problem without generating code in their language. If you can resolve messages sent to an object at runtime, then you can tell that object which table its object is in and it can decide whether any message corresponds to a column in that table. If you can add classes and methods at runtime, then you can generate all of the ORM classes when the app connects to the database.</p>
			<p>The existence and applicability of such features depends very much on the environment you're targeting but look for and consider them before diving into writing a generator.</p>
			<h3 id="_idParaDest-68"><a id="_idTextAnchor073"/>When the Generator Won't Be Used by A Programmer</h3>
			<p>If the target "customer" for this facility isn't going to be another developer, then a generator can often be a better choice than a full-featured programming language, despite the increase in implementation complexity.</p>
			<p>A solution that's often explored in this context is a <strong class="bold">Domain-Specific Language</strong> (<strong class="bold">DSL</strong>), a very limited programming language that exposes grammar and features much closer to the problem that the customer understands than to computer science concepts. Many projects that I've been involved with have used DSLs, because they offer a nice trade-off between letting the customer modify the system as they see fit and avoiding complex configuration mechanisms.</p>
			<h4>Case study</h4>
			<p class="callout">The "customer" using the application doesn't need to be the end user of the finished product. On one project I worked on, I created a DSL to give to the client so that they could define achievements used in the project's gamification feature. A parser app told them about any inconsistencies in their definitions, such as missing or duplicate properties, and also generated a collection of objects that would implement the rules for those achievements in the app. It could also generate a script that connected to the app store to tell it what the achievements were.</p>
		</div>
	</body></html>