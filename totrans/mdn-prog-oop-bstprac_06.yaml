- en: '*Chapter 4*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tools That Support Software Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Yes, there are loads of different tools. Yes, everybody has their favorite.
    No, there's no reason to look down on people who use different tools than yours.
    Yes, people who like `vi` are weird. In this chapter, I'm not going to recommend
    specific tools, but maybe certain classes of tools and ways I've found of working
    with them that help me.
  prefs: []
  type: TYPE_NORMAL
- en: If you're new to programming – perhaps you've just taken a few classes or worked
    through some books – this chapter should tell you something about what programmers
    do beyond typing `public static void` into text editors. If you're more experienced,
    you may still find the odd useful nugget here.
  prefs: []
  type: TYPE_NORMAL
- en: Version Control/Source Code Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I imagine many readers are currently thinking that the battle over version control
    must surely be over by now, and that all developers are using some system. This
    is, unfortunately, demonstrably untrue. Let me start with an anecdote. It's 2004,
    and I've just started working as a systems manager in a university computing lab.
    My job is partly to maintain the computers in the lab, partly to teach programming
    and numerical computing to physics undergraduates, and partly to write software
    that will assist in said teaching. As part of this work, I started using version
    control, both for my source code and for some of the configuration files in `/etc`
    on the servers. A more experienced colleague saw me doing this and told me that
    I was just generating work for myself; that this wasn't necessary for the small
    things I was maintaining.
  prefs: []
  type: TYPE_NORMAL
- en: Move on now to 2010, and I'm working in a big scientific facility in the UK.
    Using software and a *lot* of computers, we've got something that used to take
    an entire PhD to finish down to somewhere between 1 and 8 hours. I'm on the software
    team and, yes, we're using version control to track changes to the software and
    to understand what version is released. Well, kind of, anyway. The "core" of the
    files/source code is in version control, but one of its main features is to provide
    a scripting environment and DSL in which scientists at the "lab benches," if you
    will, can write up scripts that automate their experiments. These scripts are
    not (necessarily) version controlled. Worse, the source code is deployed to experimental
    stations so someone who discovers a bug *in the core* can fix it locally without
    the change being tracked in version control.
  prefs: []
  type: TYPE_NORMAL
- en: So, a group does an experiment at this facility, and produces some interesting
    results. You try to replicate this later, and you get different results. It could
    be software-related, right? All you need to do is to use the same software as
    the original group used… Unfortunately, you can't. It's vanished.
  prefs: []
  type: TYPE_NORMAL
- en: That's an example of how scientists failing to use the tools from software development
    could be compromising their science. There's a lot of snake oil in the software
    field, both from people wanting you to use their tools/methodologies because you'll
    pay them for it, and from people who have decided that "their" way of working
    is correct and that any other way is incorrect. You need to be able to cut through
    all of that nonsense to find out how particular tools and techniques impact the
    actual work you're trying to do. Philosophy of science currently places a high
    value on reproducibility and auditing. Version control supports that, so it would
    be beneficial for programmers working in science to use version control. But they
    aren't; not consistently, anyway.
  prefs: []
  type: TYPE_NORMAL
- en: In its simplest guise - the one that I was using in 2004 - version control is
    a big undo stack. Only, unlike a series of undo and redo commands, you can leave
    messages explaining who made each change and why. Even if you're working on your
    own, this is a great facility to have – if you try something that gets confusing
    or doesn't work out, you can easily roll back to a working version and take things
    from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you''re more familiar with the capabilities of a version control system,
    it can become a powerful tool for configuration management. Work on different
    features and bugfixes for the same product can proceed in parallel, with work
    being integrated when it''s ready into one or more releases of the product. Discussing
    this workflow in detail is more than I''m willing to cover here: I recommend the
    **Pragmatic Programmer** books on version control such as **Pragmatic Version
    Control Using Git**—[http://pragprog.com/book/tsgit/pragmatic-version-control-using-git](http://pragprog.com/book/tsgit/pragmatic-version-control-using-git)
    by Travis Swicegood.'
  prefs: []
  type: TYPE_NORMAL
- en: On Version Control and Collaboration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Version control is *no* more of a collaboration tool than other document management
    systems, such as SharePoint. Integrating (or merging) related work by different
    people is hard and requires knowledge of the meaning of the code and how changes
    interact. Version control systems don't have that knowledge, and as a result cannot
    simplify this merging process in any but the most trivial cases. It *does* let
    you defer the problem until you want to face it, but that's about it.
  prefs: []
  type: TYPE_NORMAL
- en: Some tools - for example, **GitHub** — [http://www.github.com](http://www.github.com)
    – provide social features around a core version control system. However, the problems
    of knowing what to integrate from whom, and when, and resolving conflicts all
    still exist. The social features give you somewhere to talk about those problems.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed Version Control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I've used a good few version control systems over the years, from simple tools
    that work with the local filesystem to hugely expensive commercial products. My
    favored way of working now is with a `darcs`, they all work in much the same way).
  prefs: []
  type: TYPE_NORMAL
- en: With a DVCS, it's very easy to get a local project into version control, so
    even toy projects and prototypes can be versioned. A feature that makes them great
    for this, over earlier systems that version local files, such as **RCS** (**Reaction
    Control System)** and **SCCS** (**Source Code Control System**), is that the whole
    repository (that is, all of the files that comprise the versioned project) is
    treated atomically. In other words, the repository can be at one version or another,
    but never in an in-between state where some files are at an earlier revision than
    others.
  prefs: []
  type: TYPE_NORMAL
- en: Earlier systems, like RCS, do not impose this restriction. With RCS, every file
    is versioned independently so each can be checked out on a different version.
    While this is more flexible, it does introduce certain problems. For example,
    consider the files in the following figure. One of the files contains a function
    that's used in code in the other file. You need to make a change to the function's
    signature, to add a new parameter. This means changing all three files.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1: A dependency that crosses multiple files](img/B15099_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: A dependency that crosses multiple files'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In an atomic version control system, the files can either both be checked out
    at the revision with one parameter or both be checked out at the revision with
    two parameters. A per-file versioning system will allow any combination of versions
    to be checked out, despite the fact that half of the possible combinations do
    not make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Once you've got a project that's locally versioned in a DVCS repository, sharing
    it with others is simple and can be done in numerous ways. If you want to back
    up or share the repository on a hosted service like **BitBucket**—[http://www.bitbucket.org](http://www.bitbucket.org),
    you set that up as a remote repository and push your content. A collaborator can
    then clone the repository from the remote version and start working on the code.
    If they're on the same network as you, then you can just share the folder containing
    the repository without setting up a remote service.
  prefs: []
  type: TYPE_NORMAL
- en: Personal Experience
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In some situations, a combination of these approaches is required. The DVCS
    tools that I've used all support that. On one recent project, everything was hosted
    on a remote service but there were hundreds of megabytes of assets stored in the
    repository. It made sense for the computers in the office to not only clone the
    remote repository, but also to peer with each other to reduce the time and bandwidth
    used when the assets changed. The situation looked like the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2: A DVCS configuration can break out of the “star” topology required
    by centralized systems](img/B15099_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: A DVCS configuration can break out of the "star" topology required
    by centralized systems'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Doing this with a centralized version control system would've been possible,
    but ugly. One of the developers would've needed to fully synchronize their working
    copy with the server, then fully copy the repository and its metadata to all of
    the other developer systems. This is less efficient than just copying the differences
    between the repositories. Some centralized version control systems wouldn't even
    support that way of working, because they track which files they think you have
    checked out on the server.
  prefs: []
  type: TYPE_NORMAL
- en: Another benefit brought by DVCS – as much due to improved algorithms as their
    distributed nature – is the ease with which you can create and destroy branches.
    When I mainly worked with centralized version control (primarily Subversion and
    Perforce), branches were created for particular tasks, such as new releases, and
    the teams I worked on invented workflows for deciding when code migrated from
    one branch to another.
  prefs: []
  type: TYPE_NORMAL
- en: With DVCSes, I often create a branch every hour or so. If I want to start some
    new work, I create a branch in my local version of the repository. After a while,
    I'm either done, and the branch gets merged and deleted; convinced that the idea
    was wrong - in which case, it's just deleted; or I want someone else to have a
    look, and I push that branch without merging it. All of this was possible with
    centralized VCS, though much slower – and you needed network access to even create
    the branch.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration and Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having just discussed version control, it's time to announce which VCS mistake
    I see more often than any other - the mistake that's made by everyone (myself
    included), regardless of their experience or expertise. And the winner is…
  prefs: []
  type: TYPE_NORMAL
- en: '*Adding new files to a project but forgetting to add them to the repository.*'
  prefs: []
  type: TYPE_NORMAL
- en: I don't do this *very* often - maybe less than once per month. But whenever
    I do, when the other developers on the team synchronize their repositories, we're
    left in a situation where everything works for me, but they can't build.
  prefs: []
  type: TYPE_NORMAL
- en: If we're lucky, the error will report that the file wasn't found, and we can
    quickly resolve the problem. If not, there'll be some other error about a missing
    symbol or something that will take time to track down before discovering the root
    cause.
  prefs: []
  type: TYPE_NORMAL
- en: If only we had some form of robot that would see every check-in, grab the source
    code, and try to build the product. If it couldn't do that, it'd be great if it
    came over and complained to the person who made the change that broke the build.
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that we've been living in the future for quite a while now, and
    that robot already exists. It goes by the name of **Continuous Integration**,
    or CI.
  prefs: []
  type: TYPE_NORMAL
- en: Why Use CI?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finding those missing files isn't the only thing CI is good for. If you have
    automated tests (see the *Chapter 5, Coding Practices*), a CI system can run the
    tests on every change and report any problems. My team's CI server is configured
    to run the analysis tool (discussed in this chapter) and consider a build failed
    if that tool discovers any problems. Some projects automatically generate API
    documentation and publish it to a web server.
  prefs: []
  type: TYPE_NORMAL
- en: 'It can even make the build available for people to install once it''s passed
    all of the tests. This is related to the idea of **Continuous Deployment**: if
    a version of the software seems good enough to use (that is, it doesn''t fail
    any test you put it through), then start using it. You may still find problems
    that weren''t exposed by the automated tests, but you''ll do so earlier than if
    you didn''t deploy right away.'
  prefs: []
  type: TYPE_NORMAL
- en: A final benefit to CI - one that's quite subtle but very useful – is that it
    forces you to set your project up so that it can be checked out of version control
    and built automatically. This means that even when a human programmer is working
    with the project, it's easy for them to get set up with the source and start being
    productive. That person could be you, when you get a new laptop. It could be a
    contractor or a new employee joining the team. Either way, if there's a single
    step to fetch the project and build it, then they'll be up to speed quickly, rather
    than asking you how to fetch some library or configure some plugin.
  prefs: []
  type: TYPE_NORMAL
- en: CI On Real Teams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some teams I've worked on have been so heavily invested in using CI that they've
    employed someone to maintain the CI infrastructure (it's not a full-time occupation,
    so they usually look after other supporting tools and consult on their use). In
    other teams, it's been up to the developers to keep it running.
  prefs: []
  type: TYPE_NORMAL
- en: The difficulty in that second case is in knowing when to look after the CI versus
    doing project work. As an example, in the month before this section was written,
    I had to migrate my team's CI system onto different hardware. Despite trying to
    ensure that the configuration of the system didn't change between the two environments,
    the tests in one of the projects would no longer run.
  prefs: []
  type: TYPE_NORMAL
- en: The thing is, the tests worked fine in the IDEs on all of the developer machines.
    Is it really important to take more time away from adding value to the products
    our clients are paying for to handhold some confused robot?
  prefs: []
  type: TYPE_NORMAL
- en: I consider running without CI to be proceeding at risk these days. Yes, I *could*
    avoid all problems without it. Yes, it's *possible* that nothing will go wrong.
    But why take the chance? Why not spend that little extra to ensure I discover
    problems as early as possible? It's spending a little now to potentially save
    a lot in the future. I therefore try to find the time to maintain the CI service
    when it's necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Build Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I wrote in the previous section that a benefit of adopting CI is that it forces
    you to simplify the building of your project (by which I mean compiling sources,
    translating assets, creating packages, and anything else that takes the inputs
    created by the project team and converts them into a product that will be used
    by customers). Indeed, to use CI you will have to condense the build down until
    an automated process can complete it given any revision of your source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s no need to write a script or an other program to do this work, because
    plenty of build management tools already exist. At a high level, they all do the
    same thing: they take a collection of input files, a collection of output files,
    and some information about the transformations needed to get from one to the other.
    How they do that, of course, varies from product to product.'
  prefs: []
  type: TYPE_NORMAL
- en: Convention or Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some build systems, like `make` and `ant`, need the developer to tell them nearly
    everything about a project before they can do anything. As an example, while `make`
    has an implicit rule for converting C source files into object files, it won't
    actually execute that rule until you tell it that you need the object file for
    something.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, other tools (including Maven) make certain assumptions about a project.
    Maven assumes that every `.java` file in a folder called `src/main/java` must
    be compiled into a class that will be part of the product.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration approach has the advantage that it's discoverable even to
    someone who knows little about the system. Someone armed with a collection of
    source files, `grep`, and a little patience could work out from a `Makefile` or
    `Xcode` project which files were built as which targets, and how. Because there's
    a full (or near full) specification of how everything's built, you can find what
    you need to change to make it act differently, too.
  prefs: []
  type: TYPE_NORMAL
- en: The downside to that discoverability is that you *have* to specify all that
    stuff. You can't just tell Xcode that any `.m` file in a folder called `Classes`
    should be passed to the Objective-C compiler; you have to give it a big list of
    all of them. Add a new file, and you must change the list.
  prefs: []
  type: TYPE_NORMAL
- en: With a convention-based build system, this situation is exactly reversed. If
    you follow the conventions, everything's automatic. However, if you don't *know*
    the conventions, they can be hard to discover. I once had a situation on a *Rails*
    project where the folder that static resources (such as images) were saved in
    changed between two releases. On launching the app, none of my images were being
    used and it wasn't clear why. Of course, for someone who *does* know the conventions,
    there's no learning curve associated with transferring between different projects.
  prefs: []
  type: TYPE_NORMAL
- en: On balance, I'd prefer a convention-led approach, provided the conventions are
    well-documented somewhere so it's easy to find out what's going on and how to
    override it if you need to. The benefit of reduced effort and increased consistency,
    for me, outweighs the occasional surprise that's encountered.
  prefs: []
  type: TYPE_NORMAL
- en: Build Systems That Generate Other Build Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some build procedures get so complicated that they spawn another build system
    that configures the build environment for the target system before building. An
    archetypal example is GNU Autotools, – which actually has a three-level build
    system. Typically, developers will run `autoconf`, a tool that examines a project
    to find out what questions the subsequent step should ask and generates a script
    called `configure`. The user downloads the source package and runs `configure`,
    which inspects the compilation environment and uses a collection of macros to
    create a Makefile. The Makefile can then compile the source code to (finally!)
    create the product.
  prefs: []
  type: TYPE_NORMAL
- en: As argued by *Poul-Henning Kamp*—[http://queue.acm.org/detail.cfm?id=2349257](http://queue.acm.org/detail.cfm?id=2349257)),
    this is a bad architecture that adds layers of cruft to work around code that
    has not been written to be portable to the environments it will be used in. Software
    written to be built with tools like these is hard to read, because you must read
    multiple languages just to understand how one line of code works.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a bug reported in a particular C function in your project. You open
    that function to find two different implementations, chosen by a `#ifdef/#else/#endif`
    preprocessor block. You search for the macro used by that block and find it in
    `config.h`, so you must read the `configure` script to find out how it's set.
    To discover whether *that* test is doing the right thing, you need to look at
    the `configure.ac` file to find out how the test is generated.
  prefs: []
  type: TYPE_NORMAL
- en: About the only justification for using such a convoluted process is that it's
    thought of as conventional and expected by your target users, but even then, I'd
    question whether that expectation is driven by a technical need or by **Stockholm
    syndrome** — [http://en.wikipedia.org/wiki/Stockholm_syndrome](http://en.wikipedia.org/wiki/Stockholm_syndrome).
    If your product doesn't need to be portable, then there's no need to add all that
    complexity – and even if it does, there may be better ways to solve the problem
    that'll work for your product. One obvious approach is to target a portable platform
    such as Mono or Python.
  prefs: []
  type: TYPE_NORMAL
- en: Bug and work tracking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For most of their history, computers have excelled at doing things one at a
    time. Even a single client or customer can parallelize much better than that and
    will think of (and make) multiple requests while you're still working on one thing.
  prefs: []
  type: TYPE_NORMAL
- en: It's really useful to write all of these requests down, and keep track of where
    you and your colleagues are on each of them so that you don't all try to solve
    the same problem, and can let the client know which of them you've fixed. Bug
    trackers (sometimes more generally called issue trackers or work trackers) are
    designed to solve that problem.
  prefs: []
  type: TYPE_NORMAL
- en: What Goes in And When?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I''ve worked on projects where the bug tracker gets populated with all of the
    project''s feature requests at the beginning (this discussion overlaps slightly
    with the treatment of software project management patterns, in *Chapter 13, Teamwork*).
    This introduces a couple of problems. One is that the **Big List** needs a lot
    of grooming and editing to stay relevant as features are added and removed, split
    between multiple developers, or found to be dependent on other work. The second
    is psychological: for a long time, members of the project team will be looking
    at a soul-destroying list of things that still haven''t been done, like Sisyphus
    standing with his rock looking up from the base of the hill. The project will
    seem like a death march from the beginning.'
  prefs: []
  type: TYPE_NORMAL
- en: My preference is to attack the work tracker with an iterative approach. When
    it's decided what will go into the next build, add those tasks to the work tracker.
    As they're done, mark them as closed. The only things that stay in the tracker
    from one iteration to the next are those things that don't get completed in the
    build when they were scheduled to. Now, the big list of items in the tracker is
    always the big list of what we've already completed, not the big list of things
    still remaining. This is something akin to the Kanban system, where a team will
    have a fixed "capacity" of pending work. As they pull work from the pending bucket
    to start working on it, they can request that the bucket get topped up—but never
    past its capacity.
  prefs: []
  type: TYPE_NORMAL
- en: My approach to reporting bugs is different. Unless it's something trivial in
    the code I'm working on now, so that I can fix the problem in under a couple of
    minutes and move on, I'll always report it straight away. This means I won't forget
    about the problem; the fix is implicitly planned for the next iteration, following
    the **Joel Test** rule of fixing bugs before adding new code, and we can see how
    many bugs are being discovered in each build of the product. (Now that I reflect
    on the Joel Test, I realize that this chapter covers a lot of points that are
    included in the test. Perhaps you should just measure your team's performance
    with respect to the Joel test's 12 points and fix any that you answer "no" to—[http://www.joelonsoftware.com/articles/fog0000000043.html](http://www.joelonsoftware.com/articles/fog0000000043.html).).
  prefs: []
  type: TYPE_NORMAL
- en: How Precisely to Track?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So, you managed to fix that bug in 2 hours. But, was it *actually* 2 hours,
    or was it 125 minutes? Did you spend those 2 hours solely fixing the bug, or did
    you answer that email about the engineers-versus-sales whist drive during that
    time?
  prefs: []
  type: TYPE_NORMAL
- en: Being able to compare estimated time versus actual time can be useful. I'm not
    sure that "velocity" – the ratio between the estimated time and the actual time
    spent on tasks – is particularly helpful, because in my experience estimates are
    not consistently wrong by a constant factor. It's knowing *what* work you're bad
    at estimating that's helpful. Do you fail to appreciate the risks involved in
    adding new features, or do you tend to assume all bug fixes are trivially simple?
  prefs: []
  type: TYPE_NORMAL
- en: So, precise measurements are not particularly helpful, which is useful to know,
    because the accuracy probably doesn't exist to back up that precision. I usually
    just look at my watch when I start work and when I end work, and round to the
    nearest quarter or half hour. That means my time records include all those interruptions
    and little tasks I did while fixing the bug – which is fine because they slowed
    me down and that needs recording.
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimates aren''t even that accurate. The game I play with my team goes like
    this: every developer on the team (and no one else) independently writes down
    an estimate of how long the tasks we''re planning will take. They''re allowed
    to pick one of these: 1 hour, 2 hours, 4 hours, 8 hours, or don''t know. If we
    think a task will take longer than 8 hours, we break it down and estimate smaller
    chunks of the task.'
  prefs: []
  type: TYPE_NORMAL
- en: For each task, everyone presents their estimates. If they're roughly the same,
    then we just pick the highest number and go with that. If there's a spread of
    opinion – maybe one developer thinks something will take an hour when someone
    else thinks it'll take a day – we'll discuss that. Probably, one (or more) of
    the team is relying on tacit knowledge that needs to be brought into the open.
    It's usually possible to resolve such differences quickly and move on to the next
    thing.
  prefs: []
  type: TYPE_NORMAL
- en: Integrated Development Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, really, I suppose your environment doesn't need to be fully integrated.
    For a long time, my toolset was a combination of Project Builder, Interface Builder,
    WebObjects Builder, EOModeler, and Edit. It *does* need to make you more efficient
    than the simple "text editor and `make`" combo of yore.
  prefs: []
  type: TYPE_NORMAL
- en: What's the big problem? Why so harsh on the text editor? Any time you have to
    stop making software to deal with your tools, there's a chance you'll lose concentration,
    forget what you were doing, and have to spend a few minutes reacquainting yourself
    with the problem. Losing a couple of minutes doesn't sound like too big a deal,
    but if you're doing it a couple of times an hour every working day, it quickly
    adds up to a frustrating drop in productivity.
  prefs: []
  type: TYPE_NORMAL
- en: You're going to be using your IDE for most of your working day, *every* working
    day, for the next few years. You should invest heavily in it. That means spending
    a bit of money on a good one that's better than the free alternatives. It means
    training yourself in the tricks and shortcuts so you can do them without thinking,
    saving the occasional second and (more importantly) keeping you focused on the
    work. It can even mean writing plugins, if your environment supports them, so
    you can do more without context-switching.
  prefs: []
  type: TYPE_NORMAL
- en: In some plugin-rich environments, you could go a whole day without ever leaving
    the IDE. For example, Eclipse now includes the **Mylyn** ([http://eclipse.org/mylyn/start/](http://eclipse.org/mylyn/start/))
    task-focused plugin, so you can interact with your bug tracker inside the IDE.
    It'll also let you focus your views on only those files related to the task you're
    currently working on.
  prefs: []
  type: TYPE_NORMAL
- en: Not only do you need to go deep on your chosen IDE, you need to go broad on
    alternatives. A future version of your favorite tool might change things so much
    that you'd be more efficient switching to a different app. Or you might start
    working on a project where your preferred IDE isn't available; for example, you
    can't (easily) write a Mono app in Xcode, or an Eclipse RCP application in Visual
    Studio.
  prefs: []
  type: TYPE_NORMAL
- en: 'This restriction of development environments to particular platforms, whether
    done for technological or business reasons, is unfortunate. This is where the
    "just use a text editor" crowd has a point: you can learn `emacs` just once and
    whatever language you end up programming in, you don''t need to learn how to use
    the editor again just to write code. As you''re going to spend your whole working
    life in one of these environments, every change to features you already know how
    to use represents horrendous inefficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that all of the aforementioned IDEs follow the same common pattern. When
    people have the "which IDE is best?" argument, what they're actually discussing
    is "which slightly souped-up monospace text editor with a **build** button do
    you like using?" Eclipse, Xcode, IntelliJ, Visual Studio… All of these tools riff
    on the same design—letting you see the source code and change the source code.
    As secondary effects, you can also do things like build the source code, run the
    built product, and debug it.
  prefs: []
  type: TYPE_NORMAL
- en: The most successful IDE in the world, I would contend (and then wave my hands
    unconvincingly when anyone asks for data), is one that's not designed like that
    at all. It's the one that is used by more non-software specialists than any of
    those already mentioned. The one that doesn't require you to practice being an
    IDE user for years before you get any good. The one that business analysts, office
    assistants, accountants, and project managers alike all turn to when they need
    their computer to run through some custom algorithm. The most successful IDE in
    the world is Excel.
  prefs: []
  type: TYPE_NORMAL
- en: In a spreadsheet, it's the inputs and results that are front-and-center in the
    presentation, not the intermediate stuff that gets you from one to the other.
    You can test your "code" by typing in a different input and watching the results
    change in front of you. You can see intermediate results, not by breaking and
    stepping through, or putting in a log statement then switching to the log view,
    but by breaking the algorithm up into smaller steps (or functions or procedures,
    if you want to call them that). You can then visualize how these intermediate
    results change right alongside the inputs and outputs. That's quicker feedback
    than even REPLs can offer.
  prefs: []
  type: TYPE_NORMAL
- en: Many spreadsheet users naturally adopt a "test-first" approach; they create
    inputs for which they know what the results should be and make successively better
    attempts to build a formula that achieves those results. And, of course, interesting
    visualizations such as graphs are available (though the quality does vary between
    products). Drawing a graph in Xcode is… challenging. Indeed, you can't do it at
    all, but you can get Xcode to create an application that can itself generate a
    graph. The results are a significant distance away from the tools.
  prefs: []
  type: TYPE_NORMAL
- en: Static Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the *Chapter 5, Coding Practices*, there's a section on *Code Reviews*. Knowing
    that reviewers will find and fixate upon the simplest problems they can find,
    wouldn't it be great to remove all the trivial problems so that they're forced
    to look for something more substantial?
  prefs: []
  type: TYPE_NORMAL
- en: This is what static analysis does. It finds problems in code that can be automatically
    discovered without running the product, but that are either off-topic for compiler
    warnings or take too long to discover for the compiler to be an appropriate tool
    to search for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'What are off-topic problems? Typically, those that require knowledge of the
    semantics of the functions or methods you''re using – knowledge that''s beyond
    the scope of the compiler. For example, consider a C++ `destroyObject<T>(T t)`
    function that *deletes* its parameter. Calling that function twice with the same
    argument would be an error – but the compiler doesn''t know that if it''s just
    inspecting the function signature. Others are a matter of style. For example,
    Apple''s C APIs have a naming convention related to their memory management rules:
    a function name contains `Create` when the caller owns the returned object or
    `Get` when the `callee` does. It''s not a mistake to use C language to mix those
    up, so the compiler won''t tell you about it, but an analyzer can.'
  prefs: []
  type: TYPE_NORMAL
- en: There is basically no reason to avoid using a static analyzer (if your reason
    is that there isn't one for your language/framework/whatever yet, you might have
    chosen a language/framework/whatever that isn't ready yet. There's a section about
    that in *Chapter 12, Business*). It'll discover easily fixable bugs for you and
    quickly train you into not making those mistakes in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Code Generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are, in many applications, plenty of features that are trivial to implement
    but must be done over and over. Perhaps it's taking an array of model objects
    and preparing a list view, creating classes from database schemata, or creating
    a list of compile-time constants from a text file.
  prefs: []
  type: TYPE_NORMAL
- en: These situations can usually be automated by generating code. The idea is to
    express the problem in a succinct representation, then translate that into something
    that can be incorporated into your program. This is pretty much what a compiler
    does; though many programming languages are far from succinct, they're still much
    less unwieldy than the machine's native instruction code.
  prefs: []
  type: TYPE_NORMAL
- en: Writing Your Own Generator Shouldn't Be A First Resort
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just as a code generator makes it easier to create a product, it makes it harder
    to debug. For a concrete example, consider the `autotools` build system discussed
    earlier in this chapter. Imagine that a developer is looking into a reported problem
    in which one of the tests fails (a problem that I had to deal with today). The
    log file tells them what the C program was that encapsulated the test, but the
    developer cannot just modify that program. They must discover where the `configure`
    script is generating that program, and what it's trying to achieve by doing so.
    They must then find out where in `configure.ac` that section of the shell script
    is generated and work out a change to the `m4` macros that will result in the
    desired change to the C program, two steps later.
  prefs: []
  type: TYPE_NORMAL
- en: In short, if your target environment offers facilities to solve your problem
    natively, such a solution will require less reverse engineering when diagnosing
    later problems. It's only if such a solution is overly expensive or error-prone
    that code generation is a reasonable alternative.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the cases given at the beginning of this section were data-driven, like
    the situation deriving class descriptions from a database schema for some **Object-Relational
    Mapping** (**ORM**) system. This is a case where some programming languages give
    you the ability to solve this problem without generating code in their language.
    If you can resolve messages sent to an object at runtime, then you can tell that
    object which table its object is in and it can decide whether any message corresponds
    to a column in that table. If you can add classes and methods at runtime, then
    you can generate all of the ORM classes when the app connects to the database.
  prefs: []
  type: TYPE_NORMAL
- en: The existence and applicability of such features depends very much on the environment
    you're targeting but look for and consider them before diving into writing a generator.
  prefs: []
  type: TYPE_NORMAL
- en: When the Generator Won't Be Used by A Programmer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the target "customer" for this facility isn't going to be another developer,
    then a generator can often be a better choice than a full-featured programming
    language, despite the increase in implementation complexity.
  prefs: []
  type: TYPE_NORMAL
- en: A solution that's often explored in this context is a **Domain-Specific Language**
    (**DSL**), a very limited programming language that exposes grammar and features
    much closer to the problem that the customer understands than to computer science
    concepts. Many projects that I've been involved with have used DSLs, because they
    offer a nice trade-off between letting the customer modify the system as they
    see fit and avoiding complex configuration mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The "customer" using the application doesn't need to be the end user of the
    finished product. On one project I worked on, I created a DSL to give to the client
    so that they could define achievements used in the project's gamification feature.
    A parser app told them about any inconsistencies in their definitions, such as
    missing or duplicate properties, and also generated a collection of objects that
    would implement the rules for those achievements in the app. It could also generate
    a script that connected to the app store to tell it what the achievements were.
  prefs: []
  type: TYPE_NORMAL
