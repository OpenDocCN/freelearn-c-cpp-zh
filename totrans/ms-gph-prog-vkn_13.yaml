- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Revisiting Shadows with Ray Tracing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to implement shadows using **ray tracing**. In
    [*Chapter 8*](B18395_08.xhtml#_idTextAnchor116), *Adding Shadows Using Mesh Shaders*,
    we used traditional shadow mapping techniques to get the visibility from each
    light and use that information to compute the shadow term for the final image.
    Using ray tracing for shadows allows us to get more detailed results and to have
    finer-grained control over the quality of results based on the distance and intensity
    of each light.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to implement two techniques: the first one is similar to the one
    used in offline rendering, where we shoot rays to each light to determine visibility.
    While this approach gives us the best results, it can be quite expensive depending
    on the number of lights in the scene.'
  prefs: []
  type: TYPE_NORMAL
- en: The second technique is based on a recent article from **Ray Tracing Gems**.
    We use some heuristics to determine how many rays we need to cast per light, and
    we combine the results with spatial and temporal filters to make the result stable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing simple ray-traced shadows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an advanced technique for ray-traced shadows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By the end of this chapter you will learn how to implement basic ray-traced
    shadows. You will also become familiar with a more advanced technique that is
    capable of rendering multiple lights with soft shadows.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter13](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter13).'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing simple ray-traced shadows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned in the introduction, shadow mapping techniques have been a staple
    of real-time rendering for many years. Before the introduction of ray tracing
    capabilities in GPUs, using other techniques was simply too expensive.
  prefs: []
  type: TYPE_NORMAL
- en: This hasn’t prevented the graphics community from coming up with clever solutions
    to increase the quality of results while maintaining a low cost. The main issue
    with traditional techniques is that they are based on capturing depth buffers
    from the point of view of each light. This works well for objects that are near
    the light and camera, but as we move further away, depth discontinuities lead
    to artefacts in the final result.
  prefs: []
  type: TYPE_NORMAL
- en: Solutions to this problem include filtering the result – for instance, using
    **Percentage Closer Filtering** (**PCF**) or **Cascade Shadow Maps** (**CSM**).
    This technique requires capturing multiple depth *slices* – the cascades to maintain
    enough resolution as we move further away from the light. This is usually employed
    only for sunlight, as it can require a lot of memory and time to re-render the
    scene multiple times. It can also be quite difficult to get good results on the
    boundaries between cascades.
  prefs: []
  type: TYPE_NORMAL
- en: The other main issue with shadow mapping is that it can be difficult to get
    hard shadows because of the resolution of the depth buffer and the discontinuities
    it introduces. We can alleviate these issues with ray tracing. Offline rendering
    has used ray and path tracing for many years to achieve photo-realistic effects,
    including shadows.
  prefs: []
  type: TYPE_NORMAL
- en: They, of course, have the luxury of being able to wait for hours or days for
    a single frame to complete, but we can get similar results in real time. In the
    previous chapter, we used the `vkCmdTraceRaysKHR` command to cast rays into a
    scene.
  prefs: []
  type: TYPE_NORMAL
- en: For this implementation, we are introducing ray queries, which allow us to traverse
    the Acceleration Structures we set up from a fragment and compute shaders.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to modify the `calculate_point_light_contribution` method of our
    lighting pass to determine which lights each fragment can see and determine the
    final shadow term.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to enable the `VK_KHR_ray_query` device extension. We also need
    to enable the related shader extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, instead of computing the cube map from each light point of view, we simply
    cast a ray from the fragment world position to each light.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by initializing a `rayQueryEXT` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Notice the `gl_RayFlagsTerminateOnFirstHitEXT` parameter, as we are only interested
    in the first hit for this ray. `l` is the direction from `world_position` to the
    light and we use a small offset from the ray origin to avoid self-intersection.
  prefs: []
  type: TYPE_NORMAL
- en: The last parameter, `d`, is the distance from `world_position` to the light
    position. It’s important to specify this value, as the ray query could report
    intersections past the light position otherwise, and we could incorrectly mark
    a fragment to be in shadow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have initialized the ray query object, we call the following method
    to start scene traversal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return either when a hit is found or when the ray terminates. When
    using ray queries, we don’t have to specify a shader binding table. To determine
    the result of ray traversal, there are several methods we can use to query the
    outcome. In our case, we only want to know whether the ray hit any geometry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If not, it means we can see the light we are processing from this fragment,
    and we can account for this light contribution in the final computation. We repeat
    this for each light to obtain the overall shadow term.
  prefs: []
  type: TYPE_NORMAL
- en: While this implementation is really simple, it mainly works for point lights.
    For other types of light – area lights, for instance – we would need to cast multiple
    rays to determine the visibility. As the number of lights increases, it can become
    too expensive to use this simple technique.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have demonstrated a simple implementation to get started
    with real-time ray-traced shadows. In the next section, we are going to introduce
    a new technique that scales better and can support multiple types of light.
  prefs: []
  type: TYPE_NORMAL
- en: Improving ray-traced shadows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we described a simple algorithm that can be used to
    compute the visibility term in our scene. As we mentioned, this doesn’t scale
    well for a large number of lights and can require a large number of samples for
    different types of light.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to implement a different algorithm inspired by
    the article *Ray Traced Shadows* in the *Ray Tracing Gems* book. As will be common
    in this chapter and upcoming chapters, the main idea is to spread the computation
    cost over time.
  prefs: []
  type: TYPE_NORMAL
- en: This can still lead to noisy results, as we are still using a low number of
    samples. To achieve the quality we are looking for, we are going to make use of
    spatial and temporal filtering, similar to what we did in [*Chapter 11*](B18395_11.xhtml#_idTextAnchor178),
    *Temporal Anti-Aliasing*.
  prefs: []
  type: TYPE_NORMAL
- en: The technique is implemented over three passes, and we are also going to leverage
    motion vectors. We are now going to explain each pass in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Motion vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in [*Chapter 11*](B18395_11.xhtml#_idTextAnchor178), *Temporal Anti-Aliasing*,
    motion vectors are needed to determine how far an object at a given fragment has
    moved between frames. We need this information to determine which information
    to keep and which to discard for our computation. This helps us avoid ghosting
    artifacts in the final image.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the technique in this chapter, we need to compute motion vectors differently
    compared to **Temporal Anti-Aliasing** (**TAA**). We first compute the proportional
    difference of depth between the two frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we compute an epsilon value that will be used to determine acceptable
    changes in depth:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use these two values to decide whether the reprojection was successful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure shows the result of this computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – The motion vector’s texture](img/B18395_13_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – The motion vector’s texture
  prefs: []
  type: TYPE_NORMAL
- en: We are going to store this value in a texture for later use. The next step is
    to compute the variation in visibility for the past four frames.
  prefs: []
  type: TYPE_NORMAL
- en: Computing visibility variance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This technique uses data from the past four frames to determine how many samples
    are needed for each light for each fragment. We store the `visibility` values
    in a 3D RGBA16 texture, where each channel is the `visibility` value of the previous
    frames. Each layer stores the visibility history for individual lights.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is one of the first compute shaders where we use a 3D dispatch size. It’s
    worth highlighting the `dispatch` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In this pass, we simply compute the difference between the minimum and maximum
    value over the past four frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The historical values are set to `0` during the first frame. We store the delta
    in another 3D texture to be used in the next pass. The following figure shows
    the result of this pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – The visibility variation for the past four frames](img/B18395_13_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – The visibility variation for the past four frames
  prefs: []
  type: TYPE_NORMAL
- en: Computing visibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This pass is responsible for computing how many rays to shoot for each light
    depending on the variance across the past four frames.
  prefs: []
  type: TYPE_NORMAL
- en: 'This pass needs to read a lot of data from different textures. We are going
    to use **local data storage** (**LDS**) to cache the values across all threads
    within a shader invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we explained in [*Chapter 9*](B18395_09.xhtml#_idTextAnchor143), *Implementing
    Variable Rate Shading*, we need to be careful about synchronizing these writes
    by placing a `barrier()` call before accessing the data stored in `local_image_data`.
    Likewise, we need to populate values around the edges of the matrix. The code
    is the same as before and we won’t replicate it here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to filter this data to make it more temporally stable. The
    first step is to compute the maximum value in a 5x5 region and store the result
    in another LDS matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`max_filter` is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After computing the `max` values, we pass them through a 13x13 tent filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This is done to smooth out differences between adjacent fragments while still
    giving more weight to the fragment we are processing. We then combine this value
    with temporal data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Before moving on, we update the variation cache for the next frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We now leverage the data we just obtained to compute the visibility term. First,
    we need to determine the sample count. If the reprojection in the previous pass
    has failed, we simply use the maximum sample count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If the reprojection was successful, we get the sample count for the last frame
    and determine whether the sample count has been stable over the past four frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We then combine this information with the filtered value we computed previously
    to determine the sample count for this frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If the filtered value surpasses a given threshold, we are going to increase
    the sample count. This means we identified a high-variance value across the past
    four frames and we’d need more samples to converge to a better result.
  prefs: []
  type: TYPE_NORMAL
- en: If, on the other hand, the sample count has been stable across the past four
    frames, we decrease the sample count.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this works well in practice, it could reach a sample count of `0` if
    the scene is stable – for instance, when the camera is not moving. This would
    lead to an unlit scene. For this reason, we force the sample count to `1` if the
    past four frames also had a sample count of `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of the sample count cache texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – The sample count cache texture](img/B18395_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – The sample count cache texture
  prefs: []
  type: TYPE_NORMAL
- en: Notice that fragments that *see* the light tend to require more samples, as
    expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know how many samples we need, we can move on to computing the
    `visibility` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`get_light_visibility` is the method that traces rays through the scene. It’s
    implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We first compute a few parameters as we have done before for our lighting implementation.
    In addition, we compute `d`, the distance between the world position of this fragment
    and the light we are processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we trace rays through the scene only if this light is close enough and
    it’s not behind geometry at this fragment. This is achieved using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We then trace one ray per sample. To make sure the results converge over time,
    we compute the ray direction by using a pre-computed Poisson disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have computed our ray direction, we can start ray traversal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is very similar to the code we presented in the first section, but
    in this case, we accumulate the `visibility` value for each direction the light
    is visible from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we return the average of the computed `visibility` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the `visibility` value for this frame, we need to update our
    visibility history cache. If the reprojection was successful, we simply add the
    new value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If, on the other hand, the reprojection failed, we overwrite all `history`
    entries with the new `visibility` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The last step is to also update the sample count cache:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have updated the visibility term for this frame and updated all
    the caches, we can move to the last pass and compute the filtered visibility that
    will be used in our lighting computation.
  prefs: []
  type: TYPE_NORMAL
- en: Computing filtered visibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we were to use the `visibility` value as computed in the previous section,
    the output would be very noisy. For each frame, we might have a different sample
    count and sample positions, especially if the camera or objects are moving.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, we need to *clean up* the result before we can use it. One
    common approach is to use a denoiser. A denoiser is usually implemented as a series
    of compute passes that, as the name implies, will reduce the noise as much as
    possible. Denoisers can take a significant amount of time, especially as the resolution
    increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we are going to use a simple temporal and spatial filter to reduce
    the amount of time this technique takes. As with the previous pass, we need to
    read data into LDS first. This is accomplished by following two lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '`visibility_temporal_filter` is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We first read the historical visibility data at this fragment for the given
    light and simply compute the average. This is our temporal filter. Depending on
    your use case, you might use a different weighting function, giving more emphasis
    to more recent values.
  prefs: []
  type: TYPE_NORMAL
- en: For spatial filtering, we are going to use a Gaussian kernel. The original article
    uses variable-sized kernels according to visibility variance. In our implementation,
    we decided to use a fixed 5x5 Gaussian kernel, as it provides good enough results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loop to compute the filtered value is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we store the normal in our fragment location. We then iterate over the
    kernel size to compute the final term:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As described in the article, if the normals of adjacent fragments diverge, we
    ignore this data point. This is done to prevent shadow leaking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we combine the value that has already gone through the temporal filter
    with the kernel value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure illustrates the content of the filtered visibility texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – The filtered visibility texture](img/B18395_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – The filtered visibility texture
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the computation of the `visibility` value for each light. We
    can now use this information during our lighting pass, as described in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Using the filtered visibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using our `visibility` term is really simple. In the `calculate_point_light_contribution`
    method, we simply have to read the visibility we have computed in the previous
    passes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: It could be possible to combine traditional shadow maps with a ray tracing implementation
    similar to the one we described here. It all depends on the frame budget for the
    technique, the type of lights in the scene, and the desired quality.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have presented a different implementation for ray-traced
    shadows. The first step is to compute and store the visibility variance across
    the past four frames. Next, we computed the sample count for each fragment and
    each light using a `max` filter followed by a tent filter.
  prefs: []
  type: TYPE_NORMAL
- en: We then used this sample count to trace rays into the scene to determine a raw
    `visibility` value. In the last pass, we passed this `visibility` value through
    a temporal and spatial filter to reduce noise. Finally, we used this filtered
    value in our lighting computation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have presented two implementations for ray-traced shadows.
    In the first section, we provided a simple implementation similar to what you
    might find in an offline renderer. We simply shoot one ray per fragment to each
    light to determine whether it’s visible or not from that position.
  prefs: []
  type: TYPE_NORMAL
- en: While this works well for point lights, it would require many rays to support
    other light types and render soft shadows. For this reason, we also provided an
    alternative that makes use of spatial and temporal information to determine how
    many samples to use per light.
  prefs: []
  type: TYPE_NORMAL
- en: We start by computing the visibility variance of the past four frames. We then
    filter this value to determine how many rays to shoot for each fragment for each
    light. We use this count to traverse the scene and determine the `visibility`
    value for each fragment. Finally, we filter the visibility we obtained to reduce
    the noise. The filtered visibility is then used in the lighting computation to
    determine the final shadow term.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we continue our ray tracing journey by implementing global
    illumination!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The technique we have implemented in this chapter is detailed in [*Chapter
    13*](B18395_13.xhtml#_idTextAnchor213), *Revisiting Shadows with Ray Tracing,*
    of the book *Ray Tracing Gems*. It is freely available here: [http://www.realtimerendering.com/raytracinggems/rtg/index.xhtml](http://www.realtimerendering.com/raytracinggems/rtg/index.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have only used a limited set of the GLSL APIs available for ray tracing.
    We recommend reading the GLSL extension specification to see all the options available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GLSL_EXT_ray_tracing.txt](https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GLSL_EXT_ray_tracing.txt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GLSL_EXT_ray_query.txt](https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GLSL_EXT_ray_query.txt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We used a few filters in this chapter. Signal processing is a vast and wonderful
    field that has more implications in graphics programming than people realize.
    To get you started, we recommend this article by Bart Wronski: [https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/](https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/).'
  prefs: []
  type: TYPE_NORMAL
