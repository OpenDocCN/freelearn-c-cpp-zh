<html><head></head><body>
		<div id="_idContainer047">
			<h1 id="_idParaDest-151"><em class="italic"><a id="_idTextAnchor158"/>Chapter 11</em>: Gearing Up with Support Utilities</h1>
			<p>In the previous chapter, we learned the basics of <strong class="bold">Low-Level Virtual Machine</strong> (<strong class="bold">LLVM</strong>) <strong class="bold">intermediate representation</strong> (<strong class="bold">IR</strong>)—the target-independent intermediate representations in LLVM—and how to inspect and manipulate this with C++ <strong class="bold">application programming interfaces</strong> (<strong class="bold">APIs</strong>). These are the core techniques for doing program analysis and transformation in LLVM. In addition to those skill sets, LLVM also provides many support utilities to improve compiler developers' productivity when working with LLVM IR. We are going to cover those topics in this chapter.</p>
			<p>A compiler is a complex piece of software. It not only needs to handle thousands of different cases— including input programs with different shapes and a wide variety of target architectures—but the <strong class="bold">correctness</strong> of a compiler is also an important topic: namely, the compiled code needs to have the same behavior as the original one. LLVM, a large-scale compiler framework (and probably one of the biggest), is not an exception. </p>
			<p>To tackle these complexities, LLVM has provided a crate of gadgets to improve the development experience. In this chapter, we are going to show you how to gear up to use those tools. The utilities covered here can assist you in diagnosing problems that occur from the LLVM code you are developing. This includes more efficient debugging, error handling, and profiling abilities; for instance, one of the tools can collect statistical numbers on key components—such as the number of basic blocks being processed by a specific Pass—and automatically generate a summary report. Another example is LLVM's own error-handling framework, which prevents as many unhandled errors (a common programming mistake) as possible.</p>
			<p>Here is a list of the topics we are going to cover in this chapter:</p>
			<ul>
				<li>Printing diagnostic messages</li>
				<li>Collecting statistics</li>
				<li>Adding time measurements</li>
				<li>Error-handling utilities in LLVM</li>
				<li>Learning about the <strong class="source-inline">Expected</strong> and <strong class="source-inline">ErrorOr</strong> classes</li>
			</ul>
			<p>With the help of these utilities, you will have a better time debugging and diagnosing the LLVM code, letting you focus on the core logic you want to implement with LLVM.</p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor159"/>Technical requirements</h1>
			<p>In this section, we are also going to use LLVM Pass as the platform to show different API usages. Therefore, please make sure you have built the <strong class="source-inline">opt</strong> command-line tool, as follows:</p>
			<p class="source-code">$ ninja opt</p>
			<p>Note that some of the content in this chapter only works with a <strong class="bold">debug build</strong> version of LLVM. Please check the first chapter, <a href="B14590_01_Final_JC_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Saving Resources When Building LLVM,</em> for a recap on how to build LLVM in debug mode.</p>
			<p>You can also go back to <a href="B14590_09_Final_JC_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 9</em></a>, <em class="italic">Working with PassManager and AnalysisManager,</em> if you are not sure how to create a new LLVM Pass.</p>
			<p>The sample code for this chapter can be found here: </p>
			<p><a href="https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter11">https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter11</a></p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor160"/>Printing diagnostic messages</h1>
			<p>In software development, there are many ways to diagnose a bug—for instance, using a debugger, inserting a sanitizer <a id="_idIndexMarker568"/>into your program (to catch invalid memory access, for example), or simply using one of the simplest yet most effective ways: adding <em class="italic">print statements</em>. While the last option doesn't sound really smart, it is actually pretty useful in many cases where other options cannot unleash their full potential (for example, release mode binaries with poor debug information quality or multithread programs).</p>
			<p>LLVM provides a small utility that not only helps you to print out debug messages but also <em class="italic">filters</em> which messages to show. Let's say we have an LLVM Pass, <strong class="source-inline">SimpleMulOpt</strong>, which replaces multiplication by power-of-two constants with left-shifting operations (which is what we did in the last section of the previous chapter, <em class="italic">Processing LLVM IR</em>). Here is part of its <strong class="source-inline">run</strong> method:</p>
			<p class="source-code">PreservedAnalyses</p>
			<p class="source-code">SimpleMulOpt::run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p>
			<p class="source-code">  for (auto &amp;I : <strong class="bold">instructions</strong>(F)) {</p>
			<p class="source-code">    if (auto *BinOp = dyn_cast&lt;<strong class="bold">BinaryOperator</strong>&gt;(&amp;I) &amp;&amp;</p>
			<p class="source-code">        BinOp-&gt;getOpcode() == Instruction::Mul) {</p>
			<p class="source-code">      auto *<strong class="bold">LHS</strong> = BinOp-&gt;getOperand(0),</p>
			<p class="source-code">           *<strong class="bold">RHS</strong> = BinOp-&gt;getOperand(1);</p>
			<p class="source-code">      // `BinOp` is a multiplication, `LHS` and `RHS` are its</p>
			<p class="source-code">      // operands, now trying to optimize this instruction…</p>
			<p class="source-code">      …</p>
			<p class="source-code">    }</p>
			<p class="source-code">  }</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The preceding code iterates <a id="_idIndexMarker569"/>through all instructions in the given function before looking for instructions that represent arithmetic multiplication. If there are any, the Pass will then work with the <strong class="source-inline">LHS</strong> and <strong class="source-inline">RHS</strong> operands (which appear in the rest of the code—these are not shown here).</p>
			<p>Let's assume that we want to print out the operand variables during our development. The most naïve way will be by using our old friend <strong class="source-inline">errs()</strong>, which streams arbitrary messages to <strong class="source-inline">stderr</strong>, as shown in the following code snippet:</p>
			<p class="source-code">// (extracted from the previous snippet)</p>
			<p class="source-code">…</p>
			<p class="source-code">auto *LHS = BinOp-&gt;getOperand(0),</p>
			<p class="source-code">     *RHS = BinOp-&gt;getOperand(1);</p>
			<p class="source-code"><strong class="bold">errs()</strong> &lt;&lt; "Found a multiplication with operands ";</p>
			<p class="source-code">LHS-&gt;<strong class="bold">printAsOperand(errs())</strong>;</p>
			<p class="source-code"><strong class="bold">errs()</strong> &lt;&lt; " and ";</p>
			<p class="source-code">RHS-&gt;<strong class="bold">printAsOperand(errs())</strong>;</p>
			<p class="source-code">…</p>
			<p>The <strong class="source-inline">printAsOperand</strong> used in the preceding code snippet prints the textual representation of a <strong class="source-inline">Value</strong> to the given stream (<strong class="source-inline">errs()</strong>, in this case).</p>
			<p>Everything looks normal, except the <a id="_idIndexMarker570"/>fact that these messages will be printed out anyway even in a production environment, which is not what we want. Either we need to remove these codes before we ship our products, adding some macro guard around these codes (for example, <strong class="source-inline">#ifndef NDEBUG</strong>), or we can use the debug utility provided by LLVM. Here is an example of this:</p>
			<p class="source-code">#include "<strong class="bold">llvm/Support/Debug.h</strong>"</p>
			<p class="source-code">#define <strong class="bold">DEBUG_TYPE "simple-mul-opt"</strong></p>
			<p class="source-code">…</p>
			<p class="source-code">auto *LHS = BinOp-&gt;getOperand(0),</p>
			<p class="source-code">     *RHS = BinOp-&gt;getOperand(1);</p>
			<p class="source-code"><strong class="bold">LLVM_DEBUG</strong>(<strong class="bold">dbgs()</strong> &lt;&lt; "Found a multiplication with operands ");</p>
			<p class="source-code">LLVM_DEBUG(LHS-&gt;printAsOperand(<strong class="bold">dbgs()</strong>));</p>
			<p class="source-code">LLVM_DEBUG(dbgs() &lt;&lt; " and ");</p>
			<p class="source-code">LLVM_DEBUG(RHS-&gt;printAsOperand(dbgs()));</p>
			<p class="source-code">…</p>
			<p>The preceding code is basically doing the following three things:</p>
			<ul>
				<li>Replacing any usage of <strong class="source-inline">errs()</strong> with <strong class="source-inline">dbgs()</strong>. These two streams are basically doing the same thing, but the latter one will add a nice banner (<strong class="source-inline">Debug Log Output</strong>) to the output message.</li>
				<li>Wrapping all lines related to debug printing with the <strong class="source-inline">LLVM_DEBUG(…)</strong> macro function. The use of this macro ensures that the enclosing line is only compiled in development mode. It also encodes the debug message category, which we will introduce shortly.</li>
				<li>Before using any <strong class="source-inline">LLVM_DEBUG(…)</strong> macro functions, please make sure you define <strong class="source-inline">DEBUG_TYPE</strong> to the desired debug category string (<strong class="source-inline">simple-mul-opt</strong>, in this case).</li>
			</ul>
			<p>In addition to the aforementioned code modification, we also need to use an additional command-line flag, <strong class="source-inline">-debug</strong>, with <strong class="source-inline">opt</strong> to print those debug messages. Here is an example of this:</p>
			<p class="source-code">$ opt -O3 <strong class="bold">-debug</strong> -load-pass-plugin=… …</p>
			<p>But then, you'll find the <a id="_idIndexMarker571"/>output to be pretty noisy. There are tons of debug messages from <em class="italic">other</em> LLVM Passes. In this case, we're only interested in the messages from our Pass.</p>
			<p>To filter out unrelated messages, we can use the <strong class="source-inline">-debug-only</strong> command-line flag. Here is an example of this:</p>
			<p class="source-code">$ opt -O3 <strong class="bold">-debug-only=simple-mul-opt</strong> -load-pass-plugin=… …</p>
			<p>The value after <strong class="source-inline">-debug-only</strong> is the <strong class="source-inline">DEBUG_TYPE</strong> value we defined in the previous code snippet. In other words, we can use <strong class="source-inline">DEBUG_TYPE</strong> defined by each Pass to filter the desired debug messages. We can also select <em class="italic">multiple</em> debug categories to print. For instance, check out the following command:</p>
			<p class="source-code">$ opt -O3 <strong class="bold">-debug-only=sroa,simple-mul-opt</strong> -load-pass-plugin=… …</p>
			<p>This command not only prints debug messages from our <strong class="source-inline">SimpleMulOpt</strong> Pass, but also those coming from the <strong class="source-inline">SROA</strong> Pass—an LLVM Pass included in the <strong class="source-inline">O3</strong> optimization pipeline.</p>
			<p>In addition to defining a single debug category (<strong class="source-inline">DEBUG_TYPE</strong>) for an LLVM Pass, you are in fact free to use as many categories as you like inside a Pass. This is useful, for instance, when you want to use separate debug categories for different parts of a Pass. For example, we can use separate categories for each of the operands in our <strong class="source-inline">SimpleMulOpt</strong> Pass. Here is how we can do this:</p>
			<p class="source-code">…</p>
			<p class="source-code"><strong class="bold">#define DEBUG_TYPE "simple-mul-opt"</strong></p>
			<p class="source-code">auto *LHS = BinOp-&gt;getOperand(0),</p>
			<p class="source-code">     *RHS = BinOp-&gt;getOperand(1);</p>
			<p class="source-code">LLVM_DEBUG(dbgs() &lt;&lt; "Found a multiplication instruction");</p>
			<p class="source-code"><strong class="bold">DEBUG_WITH_TYPE</strong>("<strong class="bold">simple-mul-opt-lhs</strong>",</p>
			<p class="source-code">               LHS-&gt;printAsOperand(dbgs() &lt;&lt; "LHS operand: "));</p>
			<p class="source-code"><strong class="bold">DEBUG_WITH_TYPE</strong>("<strong class="bold">simple-mul-opt-rhs</strong>",</p>
			<p class="source-code">               RHS-&gt;printAsOperand(dbgs() &lt;&lt; "RHS operand: "));</p>
			<p class="source-code">…</p>
			<p><strong class="source-inline">DEBUG_WITH_TYPE</strong> is a <a id="_idIndexMarker572"/>special version of <strong class="source-inline">LLVM_DEBUG</strong>. It executes code at the second argument, with the first argument as the debug category, which can be different from the currently defined <strong class="source-inline">DEBUG_TYPE</strong> value. In the preceding code snippet, in addition to printing <strong class="source-inline">Found a multiplication instruction</strong> using the original <strong class="source-inline">simple-mul-opt</strong> category, we are using <strong class="source-inline">simple-mul-opt-lhs</strong> to print messages <a id="_idIndexMarker573"/>related to the <strong class="bold">left-hand-side</strong> (<strong class="bold">LHS</strong>) operand and use <strong class="source-inline">simple-mul-opt-rhs</strong> to print messages for the other operand. With this feature, we can have a finer granularity to select debug message categories via the <strong class="source-inline">opt</strong> command.</p>
			<p>You have now learned how to use the utility provided by LLVM to print out debug messages in the development environment only, and how to filter them if needed. In the next section, we are going to learn how to collect key statistics while running an LLVM Pass.</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor161"/>Collecting statistics</h1>
			<p>As mentioned in the previous section, a compiler <a id="_idIndexMarker574"/>is a complex piece of <a id="_idIndexMarker575"/>software. Collecting <strong class="bold">statistical numbers</strong>—for example, the number of basic blocks processed by a specific optimization—is one of the easiest and most efficient ways to get a quick portrait on the runtime behaviors of a compiler.</p>
			<p>There are several ways to collect statistics in LLVM. In this section, we are going to learn three of the most common and useful options for doing this, and these methods are outlined here:</p>
			<ul>
				<li>Using the <strong class="source-inline">Statistic</strong> class</li>
				<li>Using an optimization remark</li>
				<li>Adding time measurements</li>
			</ul>
			<p>The first option is a general <a id="_idIndexMarker576"/>utility that collects statistics via simple counters; the second option is specifically designed to profile <em class="italic">compiler optimizations</em>; and the last option is used for collecting timing information in the compiler.</p>
			<p>Let's start with the first one.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor162"/>Using the Statistic class</h2>
			<p>In this section, we are going to demonstrate <a id="_idIndexMarker577"/>new features by amending them to the <strong class="source-inline">SimpleMulOpt</strong> LLVM Pass from the previous section. First, let's assume that we don't only want to print out the operand <strong class="source-inline">Value</strong> from multiplication instructions but <a id="_idIndexMarker578"/>that we also want to <em class="italic">count</em> how many multiplication instructions have been processed by our Pass. First, let's try to implement this feature using the <strong class="source-inline">LLVM_DEBUG</strong> infrastructure we just learned about, as follows:</p>
			<p class="source-code">#define DEBUG_TYPE "simple-mul-opt"</p>
			<p class="source-code">PreservedAnalyses</p>
			<p class="source-code">SimpleMulOpt::run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p>
			<p class="source-code">  <strong class="bold">unsigned NumMul = 0</strong>;</p>
			<p class="source-code">  for (auto &amp;I : instructions(F)) {</p>
			<p class="source-code">    if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I) &amp;&amp;</p>
			<p class="source-code">        BinOp-&gt;getOpcode() == Instruction::Mul) {</p>
			<p class="source-code">      <strong class="bold">++NumMul;</strong></p>
			<p class="source-code">      …</p>
			<p class="source-code">    }</p>
			<p class="source-code">  }</p>
			<p class="source-code">  <strong class="bold">LLVM_DEBUG(dbgs() &lt;&lt; "Number of multiplication: " &lt;&lt; NumMul);</strong></p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>This approach seems <a id="_idIndexMarker579"/>pretty straightforward. But it comes with a drawback—the statistical numbers we are interested in are mixed with other debug messages. We need to take additional actions to parse or filter the value we want because although you might argue that these problems could be <a id="_idIndexMarker580"/>tackled by using a separate <strong class="source-inline">DEBUG_TYPE</strong> tag for each counter variable, when the number of counter variables increases, you might find yourself creating lots of redundant code.</p>
			<p>One elegant solution is to use the <strong class="source-inline">Statistic</strong> class (and related utilities) provided by LLVM. Here is a version rewritten using this solution:</p>
			<p class="source-code">#include "llvm/ADT/Statistic.h"</p>
			<p class="source-code">#define <strong class="bold">DEBUG_TYPE</strong> "simple-mul-opt"</p>
			<p class="source-code"><strong class="bold">STATISTIC(NumMul, "Number of multiplications processed");</strong></p>
			<p class="source-code">PreservedAnalyses</p>
			<p class="source-code">SimpleMulOpt::run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p>
			<p class="source-code">  for (auto &amp;I : instructions(F)) {</p>
			<p class="source-code">    if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I) &amp;&amp;</p>
			<p class="source-code">        BinOp-&gt;getOpcode() == Instruction::Mul) {</p>
			<p class="source-code">      <strong class="bold">++NumMul;</strong></p>
			<p class="source-code">      …</p>
			<p class="source-code">    }</p>
			<p class="source-code">  }</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The preceding code snippet shows the usage of <strong class="source-inline">Statistic</strong>, calling the <strong class="source-inline">STATISTIC</strong> macro function to create a <strong class="source-inline">Statistic</strong> type variable (with a textual description) and simply using it like a normal integer counter variable.</p>
			<p>This solution only <a id="_idIndexMarker581"/>needs to modify a few lines in the original code, plus it collects all counter values and prints them in a table view at the end of the optimization. For example, if you run the <strong class="source-inline">SimpleMulOpt</strong> Pass using the <strong class="source-inline">-stats</strong> flag with <strong class="source-inline">opt</strong>, you will get the following output:</p>
			<p class="source-code">$ opt <strong class="bold">-stats</strong> –load-pass-plugin=… …</p>
			<p class="source-code">===-------------------------------===</p>
			<p class="source-code">      … Statistics Collected …</p>
			<p class="source-code">===-------------------------------===</p>
			<p class="source-code"><strong class="bold">87</strong> simple-mul-opt - Number of multiplications processed</p>
			<p class="source-code">$</p>
			<p><strong class="source-inline">87</strong> is the number of <a id="_idIndexMarker582"/>multiplication instructions processed in <strong class="source-inline">SimpleMulOpt</strong>. Of course, you are free to add as many <strong class="source-inline">Statistic</strong> counters as you want in order to collect different statistics. If you run more than one Pass in the pipeline, all of the statistical numbers will be presented in the same table. For instance, if we add another <strong class="source-inline">Statistic</strong> counter into <strong class="source-inline">SimpleMulOpt</strong> to collect a number of <strong class="source-inline">none-power-of-two constant operands</strong> from the multiplication instructions and run <a id="_idIndexMarker583"/>the Pass with <strong class="bold">Scalar Replacement of Aggregates</strong> (<strong class="bold">SROA</strong>), we can get an output similar to the one shown next:</p>
			<p class="source-code">$ opt -stats –load-pass-plugin=… <strong class="bold">--passes="sroa,simple-mult-opt"</strong> …</p>
			<p class="source-code">===-------------------------------===</p>
			<p class="source-code">      … Statistics Collected …</p>
			<p class="source-code">===-------------------------------===</p>
			<p class="source-code">94  simple-mul-opt - Number of multiplications processed</p>
			<p class="source-code">87  simple-mul-opt - Number of none-power-of-two constant operands</p>
			<p class="source-code">100 sroa           - Number of alloca partition uses rewritten</p>
			<p class="source-code">34  sroa           - Number of instructions deleted</p>
			<p class="source-code">…</p>
			<p class="source-code">$</p>
			<p>The second <a id="_idIndexMarker584"/>column in the preceding code snippet is the name of the origin Pass, which is designated by the <strong class="source-inline">DEBUG_TYPE</strong> value defined prior to any calls to <strong class="source-inline">STATISTIC</strong>.</p>
			<p>Alternatively, you can <a id="_idIndexMarker585"/>output the result in <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) format by adding the <strong class="source-inline">-stats-json</strong> flag to <strong class="source-inline">opt</strong>. For example, look at the following code snippet:</p>
			<p class="source-code">$ opt -stats <strong class="bold">-stats-json</strong> –load-pass-plu<a id="_idTextAnchor163"/>gin=… …</p>
			<p class="source-code">{</p>
			<p class="source-code">        <strong class="bold">"simple-mul-opt.NumMul": 87</strong></p>
			<p class="source-code">}</p>
			<p class="source-code">$</p>
			<p>In this JSON format, instead of <a id="_idIndexMarker586"/>printing statistic values with a textual description, the field name of a statistic entry has this format: <strong class="source-inline">"&lt;Pass name&gt;.&lt;Statistic variable name&gt;"</strong> (the Pass name here is also the value of <strong class="source-inline">DEBUG_TYPE</strong>). Furthermore, you can print statistic results (either in default or JSON format) into a file using the <strong class="source-inline">-info-output-file=&lt;file name&gt;</strong> command-line option. The following code snippet shows an example of this:</p>
			<p class="source-code">$ opt -stats -stats-json <strong class="bold">-info-output-file=my_stats.json</strong> …</p>
			<p class="source-code">$ cat <strong class="bold">my_stats.json</strong></p>
			<p class="source-code">{</p>
			<p class="source-code">        "simple-mul-opt.NumMul": 87</p>
			<p class="source-code">}</p>
			<p class="source-code">$</p>
			<p>You have now <a id="_idIndexMarker587"/>learned how to collect simple statistic values <a id="_idIndexMarker588"/>using the <strong class="source-inline">Statistic</strong> class. In the next section, we are going to learn a statistic collecting method that is unique to compiler optimization.</p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor164"/>Using an optimization remark</h2>
			<p>A typical compiler optimization usually <a id="_idIndexMarker589"/>consists of two stages: <em class="italic">searching</em> for the desired patterns from the input code, followed by <em class="italic">modifying</em> the code. Take our <strong class="source-inline">SimpleMulOpt</strong> Pass as an example: the first stage is to look for multiplication instructions (<strong class="source-inline">BinaryOperator</strong> with the <strong class="source-inline">Instruction::Mul</strong> <strong class="bold">operation code</strong> (<strong class="bold">opcode</strong>)) with <a id="_idIndexMarker590"/>power-of-two constant operands. For the second stage, we create new left-shifting instructions via <strong class="source-inline">IRBuilder::CreateShl(…)</strong> and replace all old usages of multiplication instructions with these.</p>
			<p>There are many cases, however, where the optimization algorithm simply "bails out" during the first stage due to <em class="italic">infeasible</em> input code. For example, in <strong class="source-inline">SimpleMulOpt</strong>, we are looking for a multiplication instruction, but if the incoming instruction is not <strong class="source-inline">BinaryOperator</strong>, the Pass will not proceed to the second stage (and continue on to the next instruction). Sometimes, we want to know the <em class="italic">reason</em> behind this bailout, which can help us to improve the optimization algorithm or diagnose incorrect/suboptimal <a id="_idIndexMarker591"/>compiler optimization. LLVM provides a nice utility called an <strong class="bold">optimization remarks</strong> to collect and report this kind of bailout (or any kind of information) occurring in optimization Passes.</p>
			<p>For example, let's assume we have the following input code:</p>
			<p class="source-code">int foo(int *a, int N) {</p>
			<p class="source-code">  int <strong class="bold">x = a[5]</strong>;</p>
			<p class="source-code">  for (int i = 0; i &lt; N; <strong class="bold">i += 3</strong>) {</p>
			<p class="source-code">    a[i] += 2;</p>
			<p class="source-code">    <strong class="bold">x = a[5];</strong></p>
			<p class="source-code">  }</p>
			<p class="source-code">  return x;</p>
			<p class="source-code">}</p>
			<p>Theoretically, we <a id="_idIndexMarker592"/>can use <strong class="bold">loop-invariant code motion</strong> (<strong class="bold">LICM</strong>) to optimize this code into an equivalent code base such as this one:</p>
			<p class="source-code">int foo(int *a, int N) {</p>
			<p class="source-code">  for (int i = 0; i &lt; N; i += 3) {</p>
			<p class="source-code">    a[i] += 2;</p>
			<p class="source-code">  }</p>
			<p class="source-code">  <strong class="bold">return a[5];</strong></p>
			<p class="source-code">}</p>
			<p>We can do this as the <a id="_idIndexMarker593"/>fifth array element, <strong class="source-inline">a[5]</strong>, never changed its value inside the loop. However, if we run LLVM's LICM Pass over the <a id="_idIndexMarker594"/>original code, it fails to perform the expected optimization.</p>
			<p>To diagnose this problem, we can invoke the <strong class="source-inline">opt</strong> command with an additional option: <strong class="source-inline">--pass-remarks-output=&lt;filename&gt;</strong>. The filename will be a <strong class="bold">YAML Ain't Markup Language</strong> (<strong class="bold">YAML</strong>) file in <a id="_idIndexMarker595"/>which optimization remarks print out the possible reasons why LICM failed to optimize. Here is an example of this:</p>
			<p class="source-code">$ opt -licm input.ll <strong class="bold">–pass-remarks-output=licm_remarks.yaml</strong> …</p>
			<p class="source-code">$ cat licm_remarks.yaml</p>
			<p class="source-code">…</p>
			<p class="source-code">--- <strong class="bold">!Missed</strong></p>
			<p class="source-code">Pass:            licm</p>
			<p class="source-code">Name:            LoadWithLoopInvariantAddressInvalidated</p>
			<p class="source-code">Function:        foo</p>
			<p class="source-code">Args:</p>
			<p class="source-code">  - String:          <strong class="bold">failed to move load with loop-invariant address because the loop may invalidate its value</strong></p>
			<p class="source-code">...</p>
			<p class="source-code">$</p>
			<p>The <strong class="source-inline">cat</strong> command in the <a id="_idIndexMarker596"/>preceding output shows one of the optimization remark entries in <strong class="source-inline">licm_remarks.yaml</strong>. This entry tells us that there was a <em class="italic">missed</em> optimization that happened in the LICM Pass when it was processing the <strong class="source-inline">foo</strong> function. It also tells us the reason: LICM was not sure if a particular memory address was invalidated by the loop. Though this message doesn't provide fine-grained details, we can still infer that the problematic memory address concerning LICM was probably <strong class="source-inline">a[5]</strong>. LICM was not sure if the <strong class="source-inline">a[i] += 2</strong> statement modified the content of <strong class="source-inline">a[5]</strong>. </p>
			<p>With this knowledge, compiler developers <a id="_idIndexMarker597"/>can get hands-on in improving LICM—for example, teaching LICM to recognize induction variables (that is, the <strong class="source-inline">i</strong> variable in this loop) with a step value greater than 1 (in this case, it was 3, since <strong class="source-inline">i += 3</strong>).</p>
			<p>To generate optimization remarks such as the one shown in the preceding output, compiler developers need to integrate a specific utility API into their optimization Pass. To show you how to do that in your own Pass, we are going to reuse our <strong class="source-inline">SimpleMulOpt</strong> Pass as the sample. Here is part of the code that performs the first stage—<em class="italic">searching for multiplications</em> with power-of-two constant operands—in <strong class="source-inline">SimpleMulOpt</strong>:</p>
			<p class="source-code">…</p>
			<p class="source-code">for (auto &amp;I : instructions(F)) {</p>
			<p class="source-code">  if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I))</p>
			<p class="source-code">    if (BinOp-&gt;getOpcode() == Instruction::Mul) {</p>
			<p class="source-code">      auto *LHS = BinOp-&gt;getOperand(0),</p>
			<p class="source-code">           *RHS = BinOp-&gt;getOperand(1);</p>
			<p class="source-code">      // Has no constant operand</p>
			<p class="source-code">      <strong class="bold">if (!isa&lt;Constant&gt;(RHS)) continue;</strong></p>
			<p class="source-code">      const APInt &amp;Const = cast&lt;ConstantInt&gt;(RHS)-&gt;getValue();</p>
			<p class="source-code">      // Constant operand is not power of two</p>
			<p class="source-code">      <strong class="bold">if (!Const.isPowerOf2()) continue;</strong></p>
			<p class="source-code">      …</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>The preceding code <a id="_idIndexMarker598"/>checks if the operand is constant before making sure it's also a power-of-two operand. If either of these checks fails, the algorithm will bail out by continuing on to the next instruction in the function.</p>
			<p>We intentionally <a id="_idIndexMarker599"/>inserted a small flaw into this code to make it less powerful, and we are going to show you how to find that problem by using an optimization remark. Here are the steps to do this:</p>
			<ol>
				<li>First, we need to have an <strong class="source-inline">OptimizationRemarkEmitter</strong> instance, which can help you to emit remark messages. This can be obtained from its parent analyzer, <strong class="source-inline">OptimizationRemarkEmitterAnalysis</strong>. Here is how we include it at the beginning of the <strong class="source-inline">SimpleMulOpt::run</strong> method:<p class="source-code">#include "llvm/Analysis/OptimizationRemarkEmitter.h"</p><p class="source-code">PreservedAnalyses</p><p class="source-code">SimpleMulOpt::run(Function &amp;F, FunctionAnalysisManager &amp;<strong class="bold">FAM</strong>) {</p><p class="source-code">  <strong class="bold">OptimizationRemarkEmitter</strong> &amp;ORE</p><p class="source-code">    = FAM.getResult&lt;<strong class="bold">OptimizationRemarkEmitterAnalysis</strong>&gt;(F);</p><p class="source-code">  …</p><p class="source-code">}</p></li>
				<li>Then, we are going to use this <strong class="source-inline">OptimizationRemarkEmitter</strong> instance to emit an <a id="_idIndexMarker600"/>optimization remark if the <a id="_idIndexMarker601"/>multiplication instruction lacks a constant operand, as follows:<p class="source-code">#include "<strong class="bold">llvm/IR/DiagnosticInfo.h</strong>"</p><p class="source-code">…</p><p class="source-code">if (auto *BinOp = dyn_cast&lt;BinaryOperator&gt;(&amp;I))</p><p class="source-code">  if (BinOp-&gt;getOpcode() == Instruction::Mul) {</p><p class="source-code">    auto *LHS = BinOp-&gt;getOperand(0),</p><p class="source-code">         *RHS = BinOp-&gt;getOperand(1);</p><p class="source-code">    // Has no constant operand</p><p class="source-code">    if (!isa&lt;ConstantInt&gt;(RHS)) {</p><p class="source-code">      std::string InstStr;</p><p class="source-code">      raw_string_ostream SS(InstStr);</p><p class="source-code">      <strong class="bold">I.print(SS);</strong></p><p class="source-code">      <strong class="bold">ORE.emit</strong>([&amp;]() {</p><p class="source-code">        return <strong class="bold">OptimizationRemarkMissed</strong>(DEBUG_TYPE,</p><p class="source-code">                                    "NoConstOperand", &amp;F)</p><p class="source-code">               &lt;&lt; "Instruction" &lt;&lt; </p><p class="source-code">               &lt;&lt; <strong class="bold">ore::NV("Inst", SS.str())</strong></p><p class="source-code">               &lt;&lt; " does not have any constant operand";</p><p class="source-code">      });</p><p class="source-code">      continue;</p><p class="source-code">    }</p><p class="source-code">  }</p><p class="source-code">…</p><p>There are several things to be noticed here, as follows:</p><ul><li>The <strong class="source-inline">OptimizationRemarkEmitter::emit</strong> method takes a lambda function as the argument. This lambda function will be invoked to emit an optimization remark object if the <a id="_idIndexMarker602"/>optimization remark feature is turned on (via the <strong class="source-inline">–pass-remarks-output</strong> command-line option we've seen previously, for example).</li><li>The <strong class="source-inline">OptimizationRemarkMissed</strong> class (note that it is not declared in <strong class="source-inline">OptimizationRemarkEmitter.h</strong> but in the <strong class="source-inline">DiagnosticInfo.h</strong> header file) represents the remark of a missed <strong class="bold">optimization opportunity</strong>. In this case, the missed opportunity is the fact that instruction <strong class="source-inline">I</strong> does not have any constant operand. The <a id="_idIndexMarker603"/>constructor of <strong class="source-inline">OptimizationRemarkMissed</strong> takes three arguments: the name of the Pass, the name of the missed optimization opportunity, and the enclosing IR unit (in this case, we use the enclosing <strong class="source-inline">Function</strong>). In addition to constructing a <strong class="source-inline">OptimizationRemarkMissed</strong> object, we also concatenate several objects via the stream operator (<strong class="source-inline">&lt;&lt;</strong>) at the tail. These objects will eventually be put under the <strong class="source-inline">Args</strong> section of each optimization remark entry in the YAML file we saw previously.<p>In addition to using <strong class="source-inline">OptimizationRemarkMissed</strong> to notify you of missed optimization opportunities, you can also use other classes derived from <strong class="source-inline">DiagnosticInfoOptimizationBase</strong> to present different kinds of information—for example, use <strong class="source-inline">OptimizationRemark</strong> to find out which optimization has been <em class="italic">successfully</em> applied, and use <strong class="source-inline">OptimizationRemarkAnalysis</strong> to keep a log of analysis data/facts.</p></li><li>Among objects concatenated by the stream operator, <strong class="source-inline">ore::NV(…)</strong> seems to be a special case. Recall that in the optimization remark YAML file, each line under the <strong class="source-inline">Args</strong> section was a key-value pair (for example, <strong class="source-inline">String:  failed to move load with….</strong>, where <strong class="source-inline">String</strong> was the key). The <strong class="source-inline">ore::NV</strong> object allows you to customize the key-value pair. In this case, we are using <strong class="source-inline">Inst</strong> as the key and <strong class="source-inline">SS.str()</strong> as the value. This feature provides more flexibility to parse the <a id="_idIndexMarker604"/>optimization remark YAML file—for instance, if you want to write a little tool to visualize the optimization remarks, custom <strong class="source-inline">Args</strong> keys can give you an easier time (during the parsing stage) by distinguishing critical data from other strings.</li></ul></li>
				<li>Now that you have <a id="_idIndexMarker605"/>inserted the code to emit the optimization remark, it's time to test it. This time, we are going to use the following <strong class="source-inline">IR</strong> function as the input code: <p class="source-code">define i32 @bar(i32 %0) {</p><p class="source-code">  %2 = mul nsw i32 %0, 3</p><p class="source-code">  %3 = mul nsw i32 8, %3</p><p class="source-code">  ret %3</p><p class="source-code">}</p><p>You can rebuild the <strong class="source-inline">SimpleMulOpt</strong> Pass and run it using a command such as this:</p><p class="source-code">$ opt –load-pass-plugin=… –passes="simple-mul-opt" \</p><p class="source-code">      <strong class="bold">–pass-remarks-output=remark.yaml</strong> -disable-output        input.ll</p><p class="source-code">$ cat remark.yaml</p><p class="source-code">--- !Missed</p><p class="source-code">Pass:            simple-mul-opt</p><p class="source-code">Name:            <strong class="bold">NoConstOperand</strong></p><p class="source-code">Function:        bar</p><p class="source-code">Args:</p><p class="source-code">  - String:          '<strong class="bold">Instruction'</strong></p><p class="source-code">  - <strong class="bold">Inst</strong>:            '  <strong class="bold">%3 = mul nsw i32 8, %3</strong>'</p><p class="source-code">  - String:          ' <strong class="bold">does not contain any constant operand</strong>'</p><p class="source-code">...</p><p class="source-code">$</p><p>From this optimization remark entry, we can glean that <strong class="source-inline">SimpleMulOpt</strong> bailed out because it couldn't find a constant operand on one of the (multiplication) instructions. The <strong class="source-inline">Args</strong> section shows a detailed reason for this.</p><p>With this <a id="_idIndexMarker606"/>information, we realize that <strong class="source-inline">SimpleMulOpt</strong> is unable to optimize a multiplication whose <em class="italic">first</em> operand (LHS operand) is a <a id="_idIndexMarker607"/>power-of-two constant, albeit a proper optimization opportunity. Thus, we can now fix the implementation of <strong class="source-inline">SimpleMulOpt</strong> to check if <em class="italic">either</em> of the operands is constant, as follows:</p><p class="source-code">…</p><p class="source-code">if (BinOp-&gt;getOpcode() == Instruction::Mul) {</p><p class="source-code">  auto *LHS = BinOp-&gt;getOperand(0),</p><p class="source-code">       *RHS = BinOp-&gt;getOperand(1);</p><p class="source-code">  // Has no constant operand</p><p class="source-code">  if (<strong class="bold">!isa&lt;ConstantInt&gt;(RHS) &amp;&amp; !isa&lt;ConstantInt&gt;(LHS)</strong>) {</p><p class="source-code">    ORE.emit([&amp;]() {</p><p class="source-code">      return …</p><p class="source-code">    });</p><p class="source-code">    continue;</p><p class="source-code">  }</p><p class="source-code">  …</p><p class="source-code">}</p><p class="source-code">…</p><p>You have now learned how to emit optimization remarks in an LLVM Pass and how to use the generated report to discover potential optimization opportunities.</p></li>
			</ol>
			<p>So far, we have only <a id="_idIndexMarker608"/>studied the generated optimization remark YAML file. Though it has provided valuable diagnostic information, it would be great if we <a id="_idIndexMarker609"/>could have more fine-grained and intuitive location information to know where exactly these remarks happened. Luckily, Clang and LLVM have provided a way to achieve that.</p>
			<p>With the help of Clang, we can actually generate optimization remarks with <strong class="bold">source location</strong> (that is, line and column numbers in the original source file) attached. Furthermore, LLVM provides you with a small utility that can associate an optimization remark with its corresponding source location and visualize the result on a web page. Here's how to do this:</p>
			<ol>
				<li value="1">Let's reuse the following code as the input:<p class="source-code">int foo(int *a, int N) {</p><p class="source-code">  for (int i = 0; i &lt; N; i += 3) {</p><p class="source-code">    a[i] += 2;</p><p class="source-code">  }</p><p class="source-code">  return a[5];</p><p class="source-code">}</p><p>First, let's generate optimization remarks using this <strong class="source-inline">clang</strong> command: </p><p class="source-code">$ clang -O3 <strong class="bold">-foptimization-record-file=licm.remark.yaml</strong> \</p><p class="source-code">        -S opt_remark_licm.c</p><p>Though we're using a different name, <strong class="source-inline">-foptimization-record-file</strong> is the command-line option used to generate an optimization remark file with the given filename.</p></li>
				<li>After <strong class="source-inline">licm.remark.yaml</strong> is generated, let's use a utility called <strong class="source-inline">opt-viewer.py</strong> to <a id="_idIndexMarker610"/>visualize the remarks. The <strong class="source-inline">opt-viewer.py</strong> script is not installed in the typical location by default—instead of putting it in <strong class="source-inline">&lt;install path&gt;/bin</strong> (for example <strong class="source-inline">/usr/bin</strong>), it is installed in <strong class="source-inline">&lt;install path&gt;/share/opt-viewer</strong> (<strong class="source-inline">/usr/share/opt-viewer</strong>). We are going to invoke this script with the following command-line options:<p class="source-code">$ opt-viewer.py --source-dir=$PWD \ </p><p class="source-code">--target-dir=licm_remark licm.remark.yaml</p><p>(Note that <strong class="source-inline">opt-viewer.py</strong> depends on several Python packages such as <strong class="source-inline">pyyaml</strong> and <strong class="source-inline">pygments</strong>. Please install them before you use <strong class="source-inline">opt-viewer.py</strong>.)</p></li>
				<li>There <a id="_idIndexMarker611"/>will be a HTML file—<strong class="source-inline">index.html</strong>—generated inside the <strong class="source-inline">licm_remark</strong> folder. Before you open the web page, please copy the original source code—<strong class="source-inline">opt_remark_licm.c</strong>—into that folder as well. After that, you will be able to see a web page like this:<div id="_idContainer041" class="IMG---Figure"><img src="image/B14590_Figure_11.1.jpg" alt="Figure 11.1 – Web page of optimization remarks combined with the source file&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 11.1 – Web page of optimization remarks combined with the source file</p>
			<p>We are particularly <a id="_idIndexMarker612"/>interested in two of these columns: <strong class="bold">Source Location</strong> and <strong class="bold">Pass</strong>. The latter column shows the <a id="_idIndexMarker613"/>name of the Pass and the type of the optimization remark—<strong class="source-inline">Missed</strong>, <strong class="source-inline">Passed</strong>, or <strong class="source-inline">Analyzed</strong> rendered in red, green, and white, respectively—attached on a given line shown at the <strong class="bold">Source Location</strong> column.</p>
			<p>If we click on a link in the <strong class="bold">Source Location</strong> column, this will navigate you to a page that looks like this:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B14590_Figure_11.2.jpg" alt="Figure 11.2 – Details of an optimization remark&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.2 – Details of an optimization remark</p>
			<p>This page gives you a nice view of optimization remark details, interleaved with the originating source code line. For example, on <em class="italic">line 3</em>, <strong class="source-inline">loop-vectorize</strong> Pass said it couldn't vectorize this loop because its cost model didn't think it was beneficial to do so.</p>
			<p>You have now learned how to use <a id="_idIndexMarker614"/>optimization remarks to gain insights into the optimization Pass, which is especially useful when you're <a id="_idIndexMarker615"/>debugging a missing optimization opportunity or fixing a mis-compilation bug.</p>
			<p>In the next section, we are going to learn some useful skills to profile the execution time of LLVM.</p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor165"/>Adding time measurements</h1>
			<p>LLVM is an enormous software, with <a id="_idIndexMarker616"/>hundreds of components working closely together. Its ever-increasing running time is slowly becoming an issue. This affects many use cases that are sensitive to compilation time—for example, the <strong class="bold">Just-in-Time</strong> (<strong class="bold">JIT</strong>) compiler. To diagnose this <a id="_idIndexMarker617"/>problem in a systematic way, LLVM provides some useful utilities for <strong class="bold">profiling</strong> the execution time.</p>
			<p>Time profiling has always been an important topic in software development. With the running time collected from individual software components, we can spot performance bottlenecks more easily. In this section, we are going to learn about two tools provided by LLVM: the <strong class="source-inline">Timer</strong> class and the <strong class="source-inline">TimeTraceScope</strong> class. Let's start with the <strong class="source-inline">Timer</strong> class first.</p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor166"/>Using the Timer class</h2>
			<p>The <strong class="source-inline">Timer</strong> class, as suggested by its <a id="_idIndexMarker618"/>name, can measure the execution time of a code region. Here is an example of this:</p>
			<p class="source-code">#include "llvm/Support/Timer.h"</p>
			<p class="source-code">…</p>
			<p class="source-code">Timer T("MyTimer", "A simple timer");</p>
			<p class="source-code">T.<strong class="bold">startTimer</strong>();</p>
			<p class="source-code">// Do some time-consuming works…</p>
			<p class="source-code">T.<strong class="bold">stopTimer</strong>();</p>
			<p>In the preceding snippet, <strong class="source-inline">Timer</strong> instance <strong class="source-inline">T</strong> measures the time spent in the region, enclosed by the <strong class="source-inline">startTimer</strong> and <strong class="source-inline">stopTimer</strong> method calls.</p>
			<p>Now that we have collected the <a id="_idIndexMarker619"/>timing data, let's try to print it out. Here is an example of this:</p>
			<p class="source-code">Timer T(…);</p>
			<p class="source-code">…</p>
			<p class="source-code">TimeRecord TR = T.<strong class="bold">getTotalTime</strong>();</p>
			<p class="source-code">TR.<strong class="bold">print</strong>(TR, errs());</p>
			<p>In the previous code snippet, a <strong class="source-inline">TimeRecord</strong> instance encapsulates the data collected by the <strong class="source-inline">Timer</strong> class. We can then use <strong class="source-inline">TimeRecord::print</strong> to print it to a stream—in this case, the <strong class="source-inline">errs()</strong> stream. In addition, we assigned another <strong class="source-inline">TimeRecord</strong> instance—via the first argument of <strong class="source-inline">print</strong>—as the <em class="italic">total</em> time interval we want to compare it against. Let's look at the output of this code, as follows:</p>
			<p class="source-code">===---------------------------------------------------------===</p>
			<p class="source-code">                     Miscellaneous Ungrouped Timers</p>
			<p class="source-code">===---------------------------------------------------------===</p>
			<p class="source-code">   ---User Time---   --User+System--   ---Wall Time---  --- Name ---</p>
			<p class="source-code">   0.0002 (100.0%)   0.0002 (100.0%)   0.0002 (100.0%)  A simple timer</p>
			<p class="source-code">   0.0002 (100.0%)   0.0002 (100.0%)   0.0002 (100.0%)  Total</p>
			<p class="source-code">   0.0002 (100.0%)   0.0002 (100.0%)   0.0002 (100.0%)</p>
			<p>In the preceding output, the <a id="_idIndexMarker620"/>first row shows the <strong class="source-inline">TimeRecord</strong> instance collected from our previous <strong class="source-inline">Timer</strong> instance, whereas the second row shows the total time—the first argument of <strong class="source-inline">TimeRecord::print</strong>.</p>
			<p>We now know how to print the timing data collected by a single <strong class="source-inline">Timer</strong> instance, but what about multiple timers? LLVM provides another support utility for the <strong class="source-inline">Timer</strong> class: the <strong class="source-inline">TimerGroup</strong> class. Here's an example usage of the <strong class="source-inline">TimerGroup</strong> class:</p>
			<p class="source-code">TimerGroup TG("MyTimerGroup", "My collection of timers");</p>
			<p class="source-code">Timer T("MyTimer", "A simple timer", <strong class="bold">TG</strong>);</p>
			<p class="source-code">T.startTimer();</p>
			<p class="source-code">// Do some time-consuming works…</p>
			<p class="source-code">T.stopTimer();</p>
			<p class="source-code">Timer T2("MyTimer2", "Yet another simple timer", <strong class="bold">TG</strong>);</p>
			<p class="source-code">T2.startTimer();</p>
			<p class="source-code">// Do some time-consuming works…</p>
			<p class="source-code">T2.stopTimer();</p>
			<p class="source-code"><strong class="bold">TG.print(errs());</strong></p>
			<p>In the preceding code snippet, we declare a <strong class="source-inline">TimerGroup</strong> instance, <strong class="source-inline">TG</strong>, and use it as the third constructor argument for each <strong class="source-inline">Timer</strong> instance we create. Finally, we print them using <strong class="source-inline">TimerGroup::print</strong>. Here is the output of this code:</p>
			<p class="source-code">===---------------------------------------------------------===</p>
			<p class="source-code">                    My collection of timers</p>
			<p class="source-code">===---------------------------------------------------------===</p>
			<p class="source-code">  Total Execution Time: 0.0004 seconds (0.0004 wall clock)</p>
			<p class="source-code">   ---User Time---   --User+System--   ---Wall Time---  --- Name ---</p>
			<p class="source-code">   0.0002 ( 62.8%)   0.0002 ( 62.8%)   0.0002 ( 62.8%)  A simple timer</p>
			<p class="source-code">   0.0001 ( 37.2%)   0.0001 ( 37.2%)   0.0001 ( 37.2%)  Yet another simple timer</p>
			<p class="source-code">   0.0004 (100.0%)   0.0004 (100.0%)   0.0004 (100.0%)  Total</p>
			<p>Each row in the output (except the last one) is the <strong class="source-inline">TimeRecord</strong> instance for each <strong class="source-inline">Timer</strong> instance in this group.</p>
			<p>So far, we have <a id="_idIndexMarker621"/>been using <strong class="source-inline">Timer::startTimer</strong> and <strong class="source-inline">Timer::stopTimer</strong> to toggle the timer. To make measuring the time interval within a code block—namely, the region enclosed with curly brackets <strong class="source-inline">{}</strong>—easier without manually calling those two methods, LLVM provides another utility that automatically starts the timer upon entering a code block and turns it off when exiting. Let's see how to use the <strong class="source-inline">TimeRegion</strong> class with the following sample code:</p>
			<p class="source-code">TimerGroup TG("MyTimerGroup", "My collection of timers");</p>
			<p class="source-code">{</p>
			<p class="source-code">  <strong class="bold">Timer T</strong>("MyTimer", "A simple timer", TG);</p>
			<p class="source-code">  <strong class="bold">TimeRegion TR(T);</strong></p>
			<p class="source-code">  // Do some time-consuming works…</p>
			<p class="source-code">}</p>
			<p class="source-code">{</p>
			<p class="source-code">  <strong class="bold">Timer T</strong>("MyTimer2", "Yet another simple timer", TG);</p>
			<p class="source-code">  <strong class="bold">TimeRegion TR(T);</strong></p>
			<p class="source-code">  // Do some time-consuming works…</p>
			<p class="source-code">}</p>
			<p class="source-code">TG.print(errs());</p>
			<p>As you can see in the preceding snippet, instead of calling <strong class="source-inline">startTimer</strong>/<strong class="source-inline">stopTimer</strong>, we put the to-be-measured code into a separate code block and use a <strong class="source-inline">TimeRegion</strong> variable to automatically toggle the timer. This code will print out the same content as the previous example. With the help of <strong class="source-inline">TimeRegion</strong>, we can have a more concise syntax and avoid any mistakes where we <em class="italic">forget</em> to turn off the timer.</p>
			<p>You have now <a id="_idIndexMarker622"/>learned how to use <strong class="source-inline">Timer</strong> and its supporting utilities to measure the execution time of a certain code region. In the next section, we are going to learn a more advanced form of time measurement that captures the hierarchical structure of the program.</p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor167"/>Collecting the time trace</h2>
			<p>In the previous section, we learned how to use <strong class="source-inline">Timer</strong> to collect the execution time of a small range of code regions. Although <a id="_idIndexMarker623"/>that gave us a portrait of the compiler's runtime performance, we sometimes need a more <em class="italic">structural</em> timing profile in order to fully understand any systematic issues.</p>
			<p><strong class="source-inline">TimeTraceScope</strong> is a class <a id="_idIndexMarker624"/>provided by LLVM to perform global-scope time profiling. Its usage is pretty simple: similar to <strong class="source-inline">TimeRegion</strong>, which we saw in the previous section, a <strong class="source-inline">TimeTraceScope</strong> instance automatically turns the time profiler on and off upon entering and exiting a code block. Here is an example of this:</p>
			<p class="source-code">TimeTraceScope OuterTimeScope("<strong class="bold">TheOuterScope</strong>");</p>
			<p class="source-code">for (int i = 0; i &lt; 50; ++i) {</p>
			<p class="source-code">  {</p>
			<p class="source-code">    TimeTraceScope InnerTimeScope("<strong class="bold">TheInnerScope</strong>");</p>
			<p class="source-code">    <strong class="bold">foo();</strong></p>
			<p class="source-code">  }</p>
			<p class="source-code">  <strong class="bold">bar();</strong></p>
			<p class="source-code">}</p>
			<p>In the preceding code snippet, we create two <strong class="source-inline">TimeTraceScope</strong> instances: <strong class="source-inline">OuterTimeScope</strong> and <strong class="source-inline">InnerTimeScope</strong>. These try to profile the execution time of the whole region and the time spent on function <strong class="source-inline">foo</strong>, respectively.</p>
			<p>Normally, if we use <strong class="source-inline">Timer</strong> rather than <strong class="source-inline">TimeTraceScope</strong>, it can <a id="_idIndexMarker625"/>only give us the aggregate duration collected from each timer. However, in this case, we are more interested in how different parts of the code allocate themselves on the <em class="italic">timeline</em>. For example, does the <strong class="source-inline">foo</strong> function always <a id="_idIndexMarker626"/>spend the same amount of time ion every loop iteration? If that's not the case, which iterations spend more time than others?</p>
			<p>To see the result, we need to add additional command-line options to the <strong class="source-inline">opt</strong> command when running the Pass (assuming you use <strong class="source-inline">TimeTraceScope</strong> within a Pass). Here is an example of this:</p>
			<p class="source-code">$ opt –passes="…" <strong class="bold">-time-trace</strong> <strong class="bold">-time-trace-file=my_trace.json</strong> …</p>
			<p>The additional <strong class="source-inline">-time-trace</strong> flag is asking <strong class="source-inline">opt</strong> to export all the traces collected by <strong class="source-inline">TimeTraceScope</strong> to the file designated by the <strong class="source-inline">-time-trace-file</strong> option.</p>
			<p>After running this command, you will get a new file, <strong class="source-inline">my_trace.json</strong>. The content of this file is basically non-human-readable, but guess what? You can visualize it using the <strong class="bold">Chrome</strong> web browser. Here are the steps to do this:</p>
			<ol>
				<li value="1">Open your Chrome web browser and type in <strong class="source-inline">chrome://tracing</strong> in the <strong class="bold">Uniform Resource Locator</strong> (<strong class="bold">URL</strong>) bar. You <a id="_idIndexMarker627"/>will see an interface that looks like this:<div id="_idContainer043" class="IMG---Figure"><img src="image/B14590_Figure_11.3.jpg" alt="Figure 11.3 – The trace visualizer in Chrome&#13;&#10;"/></div><p class="figure-caption">Figure 11.3 – The trace visualizer in Chrome</p></li>
				<li>Click on the <strong class="bold">Load</strong> button in the top-left corner and select our <strong class="source-inline">my_trace.json</strong> file. You will see a page like this:<div id="_idContainer044" class="IMG---Figure"><img src="image/B14590_Figure_11.4.jpg" alt="Figure 11.4 – The view after opening my_trace.json&#13;&#10;"/></div><p class="figure-caption">Figure 11.4 – The view after opening my_trace.json</p><p>Each color block represents a time interval <a id="_idIndexMarker628"/>collected by a <strong class="source-inline">TimeTraceScope</strong> instance. </p></li>
				<li>Let's take a closer look: please press the number key <em class="italic">3</em> to switch to zoom mode. After that, you should be <a id="_idIndexMarker629"/>able to zoom in or out by clicking and dragging the mouse up or down. In the meantime, you can use the arrow keys to scroll the timeline left or right. Here is part of the timeline after we zoom in:<div id="_idContainer045" class="IMG---Figure"><img src="image/B14590_Figure_11.5.jpg" alt="Figure 11.5 – Part of the trace timeline&#13;&#10;"/></div><p class="figure-caption">Figure 11.5 – Part of the trace timeline</p><p>As we can see from <em class="italic">Figure 11.5</em>, there are several layers stacking together. This layout reflects how different <strong class="source-inline">TimeTraceScope</strong> instances are organized in <strong class="source-inline">opt</strong> (and in our Pass). For example, our  <strong class="source-inline">TimeTraceScope</strong> instance entitled <strong class="source-inline">TheOuterScope</strong> is stacked above multiple <strong class="source-inline">TheInnerScope</strong> blocks. Each of the <strong class="source-inline">TheInnerScope</strong> blocks represents the time spent on the <strong class="source-inline">foo</strong> function in each loop iteration we saw earlier.</p></li>
				<li>We can further inspect the properties of a block by clicking on it. For example, if we click one of the <strong class="source-inline">TheInnerScope</strong> blocks, its timing properties will be shown in the lower half of the screen. Here is an example of this:</li>
			</ol>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B14590_Figure_11.6.jpg" alt="Figure 11.6 – Details of a time interval block&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.6 – Details of a time interval block</p>
			<p>This gives us information such as the time interval and the starting time in this timeline.</p>
			<p>With this visualization, we can combine timing information with the structure of the compiler, which will help us to find out performance bottlenecks more rapidly.</p>
			<p>In addition to <strong class="source-inline">opt</strong>, <strong class="source-inline">clang</strong> can also generate the same trace JSON file. Please consider adding a <strong class="source-inline">-ftime-trace</strong> flag. Here is an example of this:</p>
			<p class="source-code">$ clang -O3 <strong class="bold">-ftime-trace</strong> -c foo.c</p>
			<p>This will generate a JSON trace file with the same name as the input file. In this case, it will be <strong class="source-inline">foo.json</strong>. You can use the skills we just learned to visualize it.</p>
			<p>In this section, we have <a id="_idIndexMarker630"/>learned some useful skills to collect statistics from LLVM. The <strong class="source-inline">Statistic</strong> class can be used as an integer counter to record the number of events occurring in the optimization. Optimization remarks, on the other hand, can give us insights into some of the decision-making process inside the optimization Pass, making it easier for compiler developers to diagnose missing optimization opportunities. With <strong class="source-inline">Timer</strong> and <strong class="source-inline">TimeTraceScope</strong>, developers can monitor LLVM's execution time in a more manageable way and handle compilation-speed regressions with confidence. These techniques can improve an LLVM developer's productivity when creating new inventions or fixing a challenging problem.</p>
			<p>In the next section of this chapter, we are going to learn how to write error-handling code in an efficient way, using utilities provided by LLVM.</p>
			<h1 id="_idParaDest-160"><a id="_idTextAnchor168"/>Error-handling utilities in LLVM</h1>
			<p>Error handling has <a id="_idIndexMarker631"/>always been a widely discussed topic in software development. It can be as simple as returning an error code—such as in many of the Linux APIs (for example, the <strong class="source-inline">open</strong> function)—or using an advanced mechanism such as throwing an exception, which has been widely adopted by many modern programming languages such as Java and C++.</p>
			<p>Although C++ has built-in <a id="_idIndexMarker632"/>support for exception handling, LLVM does <em class="italic">not</em> adopt it in its code base at all. The rationale behind this decision is that despite its convenience and expressive syntax, exception handling in C++ comes at a high cost in terms of performance. Simply speaking, exception handling makes the original code more complicated and hinders a compiler's ability to optimize it. Furthermore, during runtime, the program usually needs to spend more time recovering from an exception. Therefore, LLVM disables exception handling by default in its code base and falls back to other ways of error handling—for example, carrying an error with the return value or using the utilities we are going to learn about in this section.</p>
			<p>In the first half of this section, we are going to talk about the <strong class="source-inline">Error</strong> class, which—as the name suggests—represents an error. This is unlike conventional error representations—when using an integer as the error code, for instance, you cannot <em class="italic">ignore</em> the generated <strong class="source-inline">Error</strong> instances without handling it. We will explain this shortly.</p>
			<p>In addition to the <strong class="source-inline">Error</strong> class, developers found that in LLVM's code base a common pattern was shared by much of the error-handling code: an API may return a result <em class="italic">or</em> an error, but not both (at the same time). For instance, when we call a file-reading API, we are expecting to get the content of that file (the result) or an error when something goes wrong (for example, there is no such file). In the second part of this section, we are going to learn two utility classes that implement this pattern. </p>
			<p>Let's start with an introduction to the <strong class="source-inline">Error</strong> class first.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor169"/>Introducing the Error class</h2>
			<p>The concept <a id="_idIndexMarker633"/>represented by the <strong class="source-inline">Error</strong> class is pretty simple: it's an <a id="_idIndexMarker634"/>error with supplementary descriptions such as an error message or error code. It is designed to be passed by a value (as a function argument) or returned from a function. Developers are free to create their custom <strong class="source-inline">Error</strong> instance, too. For example, if we want to create a <strong class="source-inline">FileNotFoundError</strong> instance to tell users <a id="_idIndexMarker635"/>that a certain file does not exist, we can write the following code:</p>
			<p class="source-code">#include "llvm/Support/Error.h"</p>
			<p class="source-code">#include &lt;system_error&gt;</p>
			<p class="source-code">// In the header file…</p>
			<p class="source-code">struct FileNotFoundError : public <strong class="bold">ErrorInfo&lt;FileNoteFoundError&gt;</strong> {</p>
			<p class="source-code">  StringRef FileName;</p>
			<p class="source-code">  explicit FileNotFoundError(StringRef Name) : FileName(Name)    {}</p>
			<p class="source-code">  <strong class="bold">static char ID;</strong></p>
			<p class="source-code">  <strong class="bold">std::error_code convertToErrorCode()</strong> const override {</p>
			<p class="source-code">    return std::errc::no_such_file_or_directory;</p>
			<p class="source-code">  }</p>
			<p class="source-code">  <strong class="bold">void log(raw_ostream &amp;OS)</strong> const override {</p>
			<p class="source-code">    OS &lt;&lt; FileName &lt;&lt; ": No such file";</p>
			<p class="source-code">  }</p>
			<p class="source-code">};</p>
			<p class="source-code">// In the CPP file…</p>
			<p class="source-code">char FileNotFoundError::ID = 0;</p>
			<p>There are several <a id="_idIndexMarker636"/>requirements for implementing a custom <strong class="source-inline">Error</strong> instance. These are listed next:</p>
			<ul>
				<li>Derive from the <strong class="source-inline">ErrorInfo&lt;T&gt;</strong> class, where <strong class="source-inline">T</strong> is your custom class.</li>
				<li>Declare a unique <strong class="source-inline">ID</strong> variable. In this case, we use a static class member variable.</li>
				<li>Implement the <strong class="source-inline">convertToErrorCode</strong> method. This method designates a <strong class="source-inline">std::error_code</strong> instance for this <strong class="source-inline">Error</strong> instance. <strong class="source-inline">std::error_code</strong> is the error type used in the C++ standard library (since C++11). Please refer to the C++ reference documentation for available (predefined) <strong class="source-inline">std::error_code</strong> instances.</li>
				<li>Implement the <strong class="source-inline">log</strong> method to print out error messages.</li>
			</ul>
			<p>To create an <strong class="source-inline">Error</strong> instance, we can leverage a <strong class="source-inline">make_error</strong> utility function. Here is an example usage of this:</p>
			<p class="source-code">Error NoSuchFileErr = <strong class="bold">make_error</strong>&lt;FileNotFoundError&gt;(<strong class="bold">"foo.txt"</strong>);</p>
			<p>The <strong class="source-inline">make_error</strong> function takes an error class—in this case, our <strong class="source-inline">FileNotFoundError</strong> class—as the template argument and function arguments (in this case, <strong class="source-inline">foo.txt</strong>), if there are any. These will then be passed to its constructor.</p>
			<p>If you try to run the <a id="_idIndexMarker637"/>preceding code (in debug build) without doing anything to the <strong class="source-inline">NoSuchFileErr</strong> variable, the program will simply crash and show an <a id="_idIndexMarker638"/>error message such as this:</p>
			<p class="source-code">Program aborted due to an unhandled Error:</p>
			<p class="source-code">foo.txt: No such file</p>
			<p>It turns out that every <strong class="source-inline">Error</strong> instance is required to be <strong class="bold">checked</strong> and <strong class="bold">handled</strong> before the end of its lifetime (that is, when its destructor method is called). </p>
			<p>Let me first explain what <em class="italic">checking an</em> <strong class="source-inline">Error</strong> <em class="italic">instance</em> means. In addition to representing a real error, the <strong class="source-inline">Error</strong> class can also represent a <em class="italic">success</em> state—that is, no error. To give you a more concrete idea of this, many of the LLVM APIs have the following error-handling structure:</p>
			<p class="source-code"><strong class="bold">Error</strong> readFile(StringRef FileName) {</p>
			<p class="source-code">  if (openFile(FileName)) {</p>
			<p class="source-code">    // Success</p>
			<p class="source-code">    // Read the file content…</p>
			<p class="source-code">    return <strong class="bold">ErrorSuccess();</strong></p>
			<p class="source-code">  } else</p>
			<p class="source-code">    return <strong class="bold">make_error&lt;FileNotFoundError&gt;(FileName);</strong></p>
			<p class="source-code">}</p>
			<p>In other words, they return an <strong class="source-inline">ErrorSuccess</strong> instance in the case of success or an <strong class="source-inline">ErrorInfo</strong> instance otherwise. When the program returns from <strong class="source-inline">readFile</strong>, we need to <em class="italic">check</em> if the returned <strong class="source-inline">Error</strong> instance represents a success result or not by treating it as a Boolean variable, as follows:</p>
			<p class="source-code">Error E = readFile(…);</p>
			<p class="source-code">if (E) {</p>
			<p class="source-code">  <strong class="bold">// TODO: Handle the error</strong></p>
			<p class="source-code">} else {</p>
			<p class="source-code">  // Success!</p>
			<p class="source-code">}</p>
			<p>Note that you <em class="italic">always</em> need to <a id="_idIndexMarker639"/>check an <strong class="source-inline">Error</strong> instance even if you are 100% sure that it is in a <strong class="source-inline">Success</strong> state, otherwise the program will still abort.</p>
			<p>The preceding code snippet <a id="_idIndexMarker640"/>provides a good segue into the topic of handling <strong class="source-inline">Error</strong> instances. If an <strong class="source-inline">Error</strong> instance represents a real error, we need to use a special API to handle it: <strong class="source-inline">handleErrors</strong>. Here's how to use it:</p>
			<p class="source-code">Error E = readFile(…);</p>
			<p class="source-code">if (E) {</p>
			<p class="source-code">  Error UnhandledErr = <strong class="bold">handleErrors</strong>(</p>
			<p class="source-code">    <strong class="bold">std::move(E)</strong>,</p>
			<p class="source-code">    <strong class="bold">[&amp;](const FileNotFoundError &amp;NotFound)</strong> {</p>
			<p class="source-code">      NotFound.log(errs() &lt;&lt; "Error occurred: ");</p>
			<p class="source-code">      errs() &lt;&lt; "\n";</p>
			<p class="source-code">    });</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The <strong class="source-inline">handleErrors</strong> function takes ownership of the <strong class="source-inline">Error</strong> instance (by <strong class="source-inline">std::move(E)</strong>) and uses the provided lambda function to handle the error. You might notice that <strong class="source-inline">handleErrors</strong> returns another <strong class="source-inline">Error</strong> instance, which represents the <em class="italic">unhandled</em> error. What does that mean?</p>
			<p>In the <a id="_idIndexMarker641"/>previous example of the <strong class="source-inline">readFile</strong> function, the returned <strong class="source-inline">Error</strong> instance can represent either a <strong class="source-inline">Success</strong> state or a <strong class="source-inline">FileNotFoundError</strong> state. We <a id="_idIndexMarker642"/>can slightly modify the function to return a <strong class="source-inline">FileEmptyError</strong> instance when the opened file is empty, as follows:</p>
			<p class="source-code"><strong class="bold">Error</strong> readFile(StringRef FileName) {</p>
			<p class="source-code">  if (openFile(FileName)) {</p>
			<p class="source-code">    // Success</p>
			<p class="source-code">    …</p>
			<p class="source-code">    if (Buffer.empty())</p>
			<p class="source-code">      return <strong class="bold">make_error&lt;FileEmptyError&gt;()</strong>;</p>
			<p class="source-code">    else</p>
			<p class="source-code">      return <strong class="bold">ErrorSuccess();</strong></p>
			<p class="source-code">  } else</p>
			<p class="source-code">    return <strong class="bold">make_error&lt;FileNotFoundError&gt;(FileName);</strong></p>
			<p class="source-code">}</p>
			<p>Now, the <strong class="source-inline">Error</strong> instance returned from <strong class="source-inline">readFile</strong> can either be a <strong class="source-inline">Success</strong> state, a <strong class="source-inline">FileNotFoundError</strong> instance, <em class="italic">or</em> a <strong class="source-inline">FileEmptyError</strong> instance. However, the <strong class="source-inline">handleErrors</strong> code we wrote previously only handled the case of <strong class="source-inline">FileNotFoundError</strong>.</p>
			<p>Therefore, we need to use the following code to handle the case of <strong class="source-inline">FileEmptyError</strong>:</p>
			<p class="source-code">Error E = readFile(…);</p>
			<p class="source-code">if (E) {</p>
			<p class="source-code">  Error UnhandledErr = <strong class="bold">handleErrors</strong>(</p>
			<p class="source-code">    std::move(E),</p>
			<p class="source-code">    [&amp;](const <strong class="bold">FileNotFoundError</strong> &amp;NotFound) {…});</p>
			<p class="source-code">  UnhandledErr = <strong class="bold">handleErrors</strong>(</p>
			<p class="source-code">    std::move(UnhandledErr),</p>
			<p class="source-code">    [&amp;](const <strong class="bold">FileEmptyError</strong> &amp;IsEmpty) {…});</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>Be aware that you always need to take <a id="_idIndexMarker643"/>ownership of an <strong class="source-inline">Error</strong> instance when using <strong class="source-inline">handleErrors</strong>.</p>
			<p>Alternatively, you can <em class="italic">coalesce</em> two <strong class="source-inline">handleErrors</strong> function calls into one by using multiple lambda <a id="_idIndexMarker644"/>function arguments for each of the error types, as follows:</p>
			<p class="source-code">Error E = readFile(…);</p>
			<p class="source-code">if (E) {</p>
			<p class="source-code">  Error UnhandledErr = <strong class="bold">handleErrors</strong>(</p>
			<p class="source-code">    std::move(E),</p>
			<p class="source-code">    [&amp;](const <strong class="bold">FileNotFoundError</strong> &amp;NotFound) {…},</p>
			<p class="source-code">    [&amp;](const <strong class="bold">FileEmptyError</strong> &amp;IsEmpty) {…});</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>In other words, the <strong class="source-inline">handleErrors</strong> function is acting like a switch-case statement for an <strong class="source-inline">Error</strong> instance. It is effectively working like the following pseudocode:</p>
			<p class="source-code">Error E = readFile(…);</p>
			<p class="source-code">if (E) {</p>
			<p class="source-code">  <strong class="bold">switch</strong> (E) {</p>
			<p class="source-code">  case <strong class="bold">FileNotFoundError</strong>: …</p>
			<p class="source-code">  case <strong class="bold">FileEmptyError</strong>: …</p>
			<p class="source-code">  default:</p>
			<p class="source-code">    // generate the <strong class="bold">UnhandledError</strong></p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>Now, you might be <a id="_idIndexMarker645"/>wondering: <em class="italic">Since</em> <strong class="source-inline">handleErrors</strong> <em class="italic">will always return an</em> <strong class="source-inline">Error</strong> <em class="italic">representing the unhandled error, and I can't just ignore the returned instance, otherwise the program will abort, how should we end this "chain of error handling"?</em> There are two ways to do that, so let's have a look at each, as follows:</p>
			<ul>
				<li>If you are 100% sure that <a id="_idIndexMarker646"/>you have handled all possible error types—which means that the unhandled <strong class="source-inline">Error</strong> variable is in a <strong class="source-inline">Success</strong> state—you can call the <strong class="source-inline">cantFail</strong> function to make an assertion, as illustrated in the following code snippet:<p class="source-code">if (E) {</p><p class="source-code">  Error UnhandledErr = handleErrors(</p><p class="source-code">    std::move(E),</p><p class="source-code">    [&amp;](const FileNotFoundError &amp;NotFound) {…},</p><p class="source-code">    [&amp;](const FileEmptyError &amp;IsEmpty) {…});</p><p class="source-code">  <strong class="bold">cantFail(UnhandledErr);</strong></p><p class="source-code">}</p><p>If <strong class="source-inline">UnhandledErr</strong> still contains an error, the <strong class="source-inline">cantFail</strong> function will abort the program execution and print an error message.</p></li>
				<li>A more elegant solution would be to use the <strong class="source-inline">handleAllErrors</strong> function, as follows:<p class="source-code">if (E) {</p><p class="source-code">  <strong class="bold">handleAllErrors</strong>(</p><p class="source-code">    std::move(E),</p><p class="source-code">    [&amp;](const FileNotFoundError &amp;NotFound) {…},</p><p class="source-code">    [&amp;](const FileEmptyError &amp;IsEmpty) {…});</p><p class="source-code">  …</p><p class="source-code">}</p><p>This function will not <a id="_idIndexMarker647"/>return anything. It assumes that the given lambda functions are sufficient to handle all possible error types. Of course, if <a id="_idIndexMarker648"/>there is a missing one, <strong class="source-inline">handleAllErrors</strong> will still abort the program execution, just like what we have seen previously.</p></li>
			</ul>
			<p>You have now learned how to use the <strong class="source-inline">Error</strong> class and how to properly handle errors. Though the design of <strong class="source-inline">Error</strong> seems a little annoying at first glance (that is, we need to handle <em class="italic">all</em> possible error types or the execution will just abort halfway), these restrictions can decrease the number of mistakes made by programmers and create a more <strong class="bold">robust</strong> program.</p>
			<p>Next, we are going to introduce two other utility classes that can further improve the error-handling expressions in LLVM.</p>
			<h1 id="_idParaDest-162"><a id="_idTextAnchor170"/>Learning about the Expected and ErrorOr classes</h1>
			<p>As we briefly mentioned in the introduction of this section, in LLVM's code base it's pretty common to see a coding pattern where an API wants to return a result or an error if something goes wrong. LLVM tries to make this pattern more accessible by creating utilities that <em class="italic">multiplex</em> results and errors in a single object—they are the <strong class="source-inline">Expected</strong> and <strong class="source-inline">ErrorOr</strong> classes. Let's begin with the first one.</p>
			<h2 id="_idParaDest-163"><a id="_idTextAnchor171"/>The Expected class</h2>
			<p>The <strong class="source-inline">Expected</strong> class carries either a <strong class="source-inline">Success</strong> result or an <a id="_idIndexMarker649"/>error—for instance, the <a id="_idIndexMarker650"/>JSON library in LLVM uses it to represent the outcome of parsing an incoming string, as shown next:</p>
			<p class="source-code">#include "llvm/Support/JSON.h"</p>
			<p class="source-code"> using namespace llvm;</p>
			<p class="source-code">…</p>
			<p class="source-code">// `InputStr` has the type of `StringRef`</p>
			<p class="source-code"><strong class="bold">Expected&lt;json::Value&gt;</strong> JsonOrErr = json::parse(InputStr);</p>
			<p class="source-code">if (JsonOrErr) {</p>
			<p class="source-code">  // Success!</p>
			<p class="source-code">  <strong class="bold">json::Value &amp;Json = *JsonOrErr;</strong></p>
			<p class="source-code">  …</p>
			<p class="source-code">} else {</p>
			<p class="source-code">  // Something goes wrong…</p>
			<p class="source-code">  <strong class="bold">Error Err = JsonOrErr.takeError();</strong></p>
			<p class="source-code">  // Start to handle `Err`…</p>
			<p class="source-code">}</p>
			<p>The preceding <strong class="source-inline">JsonOrErr</strong> class has a type of <strong class="source-inline">Expected&lt;json::Value&gt;</strong>. This means that this <strong class="source-inline">Expected</strong> variable either carries a <strong class="source-inline">json::Value</strong>-type <strong class="source-inline">Success</strong> result or an error, represented by the <strong class="source-inline">Error</strong> class we just learned about in the previous section.</p>
			<p>Just as with the <strong class="source-inline">Error</strong> class, every <strong class="source-inline">Expected</strong> instance needs to be <em class="italic">checked</em>. If it represents an error, that <strong class="source-inline">Error</strong> instance needs to be <em class="italic">handled</em> as well. To check the status of an <strong class="source-inline">Expected</strong> instance, we <a id="_idIndexMarker651"/>can also cast it to a Boolean type. However, unlike with <strong class="source-inline">Error</strong>, if an <strong class="source-inline">Expected</strong> instance contains a <strong class="source-inline">Success</strong> result, it will be <strong class="source-inline">true</strong> after being casted into a Boolean.</p>
			<p>If the <strong class="source-inline">Expected</strong> instance <a id="_idIndexMarker652"/>represents a <strong class="source-inline">Success</strong> result, you can fetch the result using either the <strong class="source-inline">*</strong> operator (as shown in the preceding code snippet), the <strong class="source-inline">-&gt;</strong> operator, or the <strong class="source-inline">get</strong> method. Otherwise, you can retrieve the error by calling the <strong class="source-inline">takeError</strong> method before handling the <strong class="source-inline">Error</strong> instance, using the skills we learned in the previous section.</p>
			<p>Optionally, if you are sure that an <strong class="source-inline">Expected</strong> instance is in an <strong class="source-inline">Error</strong> state, you can check the underlying error type by calling the <strong class="source-inline">errorIsA</strong> method without retrieving the underlying <strong class="source-inline">Error</strong> instance first. For example, the following code checks if an error is a <strong class="source-inline">FileNotFoundError</strong> instance, which we <a id="_idIndexMarker653"/>created in the previous section:</p>
			<p class="source-code">if (JsonOrErr) {</p>
			<p class="source-code">  // Success!</p>
			<p class="source-code">  …</p>
			<p class="source-code">} else {</p>
			<p class="source-code">  // Something goes wrong…</p>
			<p class="source-code">  if (<strong class="bold">JsonOrErr.errorIsA&lt;FileNotFoundError&gt;()</strong>) {</p>
			<p class="source-code">    …</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>These are tips for <a id="_idIndexMarker654"/>consuming an <strong class="source-inline">Expected</strong> variable. To create an <strong class="source-inline">Expected</strong> instance, the most common way is to leverage the <em class="italic">implicit</em> type conversion to <strong class="source-inline">Expected</strong>. Here is an example of this:</p>
			<p class="source-code"><strong class="bold">Expected&lt;std::string&gt;</strong> readFile(StringRef FileName) {</p>
			<p class="source-code">  if (openFile(FileName)) {</p>
			<p class="source-code">    <strong class="bold">std::string Content</strong>;</p>
			<p class="source-code">    // Reading the file…</p>
			<p class="source-code">    return <strong class="bold">Content</strong>;</p>
			<p class="source-code">  } else</p>
			<p class="source-code">    return <strong class="bold">make_error&lt;FileNotFoundError&gt;(FileName)</strong>;</p>
			<p class="source-code">}</p>
			<p>The preceding code shows that in cases where something goes wrong, we can simply return an <strong class="source-inline">Error</strong> instance, which will be implicitly converted into an <strong class="source-inline">Expected</strong> instance representing that error. Similarly, if everything goes pretty smoothly, the <strong class="source-inline">Success</strong> result—in this case, the <strong class="source-inline">std::string</strong> type variable, <strong class="source-inline">Content</strong>—will also be implicitly <a id="_idIndexMarker655"/>converted into an <strong class="source-inline">Expected</strong> instance with a <strong class="source-inline">Success</strong> state.</p>
			<p>You have now learned <a id="_idIndexMarker656"/>how to use the <strong class="source-inline">Expected</strong> class. The last part of this section will show you how to use one of its sibling classes: <strong class="source-inline">ErrorOr</strong>.</p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor172"/>The ErrorOr class</h2>
			<p>The <strong class="source-inline">ErrorOr</strong> class <a id="_idIndexMarker657"/>uses a model that is <a id="_idIndexMarker658"/>nearly identical to the <strong class="source-inline">Expected</strong> class—it is either a <strong class="source-inline">Success</strong> result or an error. Unlike the <strong class="source-inline">Expected</strong> class, <strong class="source-inline">ErrorOr</strong> uses <strong class="source-inline">std::error_code</strong> to represent the error. Here is an example of using the <strong class="source-inline">MemoryBuffer</strong> API to read a file—<strong class="source-inline">foo.txt</strong>— and storing its content into a <strong class="source-inline">MemoryBuffer</strong> object:</p>
			<p class="source-code">#include "llvm/Support/MemoryBuffer.h"</p>
			<p class="source-code">…</p>
			<p class="source-code"><strong class="bold">ErrorOr&lt;std::unique_ptr&lt;MemoryBuffer&gt;&gt;</strong> ErrOrBuffer</p>
			<p class="source-code">  = MemoryBuffer::getFile("foo.txt");</p>
			<p class="source-code">if (ErrOrBuffer) {</p>
			<p class="source-code">  // Success!</p>
			<p class="source-code">  <strong class="bold">std::unique_ptr&lt;MemoryBuffer&gt; &amp;MB = *ErrOrBuffer</strong>;</p>
			<p class="source-code">} else {</p>
			<p class="source-code">  // Something goes wrong…</p>
			<p class="source-code">  <strong class="bold">std::error_code EC = ErrOrBuffer.getError()</strong>;</p>
			<p class="source-code">  …</p>
			<p class="source-code">}</p>
			<p>The previous code snippet shows a similar structure, with the sample code for <strong class="source-inline">Expected</strong> we saw previously: the <strong class="source-inline">std::unique_ptr&lt;MemoryBuffer&gt;</strong> instance is the type of success result here. We can also retrieve it using the <strong class="source-inline">*</strong> operator after checking the state of <strong class="source-inline">ErrOrBuffer</strong>.</p>
			<p>The only difference here is that if <strong class="source-inline">ErrOrBuffer</strong> is in an <strong class="source-inline">Error</strong> state, the error is represented by a <strong class="source-inline">std::error_code</strong> instance rather than <strong class="source-inline">Error</strong>. Developers are not <em class="italic">obliged</em> to handle a <strong class="source-inline">std::error_code</strong> instance—in other words, they can just ignore that error, which might increase the chances of other developers making mistakes in the code. Nevertheless, using the <strong class="source-inline">ErrorOr</strong> class <a id="_idIndexMarker659"/>can give you better <em class="italic">interoperability</em> with C++ standard library APIs, as many of them use <strong class="source-inline">std::error_code</strong> to represent errors. For details about how to use <strong class="source-inline">std::error_code</strong>, please refer to the C++ reference documentation.</p>
			<p>Finally, to create an <strong class="source-inline">ErrorOr</strong> instance, we are <a id="_idIndexMarker660"/>using the same trick we used on the <strong class="source-inline">Expected</strong> class—leveraging implicit conversion, as shown in the following code snippet:</p>
			<p class="source-code">#include &lt;system_error&gt;</p>
			<p class="source-code"><strong class="bold">ErrorOr&lt;std::string&gt;</strong> readFile(StringRef FileName) {</p>
			<p class="source-code">  if (openFile(FileName)) {</p>
			<p class="source-code">    std::string Content;</p>
			<p class="source-code">    // Reading the file…</p>
			<p class="source-code">    <strong class="bold">return Content;</strong></p>
			<p class="source-code">  } else</p>
			<p class="source-code">    <strong class="bold">return std::errc::no_such_file_or_directory;</strong></p>
			<p class="source-code">}</p>
			<p>The <strong class="source-inline">std::errc::no_such_file_or_directory</strong> object is one of the predefined <strong class="source-inline">std::error_code</strong> objects from the <strong class="source-inline">system_error</strong> header file.</p>
			<p>In this section, we learned how to use some error-handling utilities provided by LLVM—the important <strong class="source-inline">Error</strong> class that imposes strict rules on unhandled errors, and the <strong class="source-inline">Expected</strong> and <strong class="source-inline">ErrorOr</strong> classes that provide you with a handy way of multiplexing the program result and error state in a single object. These tools can help you to write expressive yet robust error-handling code when developing with LLVM.</p>
			<h1 id="_idParaDest-165"><a id="_idTextAnchor173"/>Summary</h1>
			<p>In this chapter, we learned lots of useful utilities that can improve our productivity when developing with LLVM. Some of them—such as optimization remarks or timers—are useful for diagnosing problems raised by LLVM, while others—the <strong class="source-inline">Error</strong> class, for instance—help you to build more robust code that scales well with the complexity of your own compiler.</p>
			<p>In the final chapter of this book, we are going to learn about <strong class="bold">profile-guided optimization</strong> (<strong class="bold">PGO</strong>) and sanitizer development, which are advanced topics that you can't miss.</p>
		</div>
	</body></html>