<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer195">
    <h1 class="chapterNumber">14</h1>
    <h1 id="_idParaDest-410" class="chapterTitle">Creating Immersive Interactive Worlds</h1>
    <p class="normal">Welcome to <a href=""><em class="italic">Chapter 14</em></a>! In the previous chapter, we added pathfinding and navigation to the instances. We started with a brief overview of navigation methods in computer games. Then we explored and implemented the A* algorithm to find a path between the instance position and a point in the virtual world. Next, we enhanced the models to serve as navigation targets and extended the instances to find a path to one of the targets. At the end of the chapter, we added the ability for an instance to follow the path and reach the desired target.</p>
    <p class="normal">In this chapter, we will explore different ideas to enhance the example code for more immersion and visual quality. We will look at the audible side for tools and methods to add sound effects and music to the application. Also, we will implement a simple audio manager class to play sounds and background music. To please not just the ears but also the eyes, we will collect some ideas about how to enhance the visual appearance next and implement two of the graphical enhancements to the application. We will end the book with this chapter by looking at the effects of daytime and weather changes on the virtual world and add a basic day/night cycle to the application.</p>
    <p class="normal">In this chapter, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">Adding sound effects and background music</li>
      <li class="bulletList">Enhancing visuals</li>
      <li class="bulletList">Extending immersion with daytime and weather</li>
    </ul>
    <h1 id="_idParaDest-411" class="heading-1">Technical requirements</h1>
    <p class="normal">The example code for this chapter is available in the <code class="inlineCode">chapter14</code> folder: the <code class="inlineCode">01_opengl_ideas</code> subfolder for OpenGL and the <code class="inlineCode">02_vulkan_ideas</code> subfolder for Vulkan.</p>
    <h1 id="_idParaDest-412" class="heading-1">Adding sound effects and background music</h1>
    <p class="normal">Running the example code from <a href="Chapter_13.xhtml"><em class="italic">Chapter 13</em></a> provides a lot of features, such as face animations, level loading, collision detection, and pathfinding and navigation. But sadly, all the animations on the screen are running in <a id="_idIndexMarker793"/>dead silence. No bleeping or beeping, no sound, and no music. Just silence.</p>
    <p class="normal">But sound and music are an important <a id="_idIndexMarker794"/>part of games for very good reasons. Whether you are enjoying the calm meadows or deep caves of Minecraft, grooving to the happy music of one of the Super Mario titles and hearing the sound effects as acoustic feedback of our actions, prefer roaming through the haunting worlds of the Dead Space or Silent Hill series while listening carefully to the environment sounds to be aware of your surroundings, or driving cars to the pumping music and fat sounds of racing games such as the Need for Speed series – without music and sound, games wouldn’t deliver the same experience for the player.</p>
    <p class="normal">To add sound output, we can include a freely available sound library, allowing us to easily play sound effects or music. Let’s look at some of the libraries first.</p>
    <h2 id="_idParaDest-413" class="heading-2">Using an audio library</h2>
    <p class="normal">Most audio libraries are <a id="_idIndexMarker795"/>written in C, but bindings for C++ can be found, encapsulating the operating-system-specific low-level function calls in an object-oriented manner. Just using the C functions and building a custom abstraction is also possible, similar to GLFW, OpenGL, and Vulkan.</p>
    <h3 id="_idParaDest-414" class="heading-3">Simple DirectMedia Layer</h3>
    <p class="normal"><strong class="keyWord">Simple DirectMedia Layer</strong> (<strong class="keyWord">SDL</strong>) is a <a id="_idIndexMarker796"/>cross-platform library for multimedia hardware components of a computer. SDL manages audio and can serve as a framework for window functions, graphics context, and input handling, like GLFW. In addition, there are several official <a id="_idIndexMarker797"/>libraries that provide support for importing and exporting images, custom networking, and font rendering to display text on the screen.</p>
    <h3 id="_idParaDest-415" class="heading-3">OpenAL</h3>
    <p class="normal"><strong class="keyWord">OpenAL</strong> is a cross-platform library that focuses on multi-channel, three-dimensional audio. By using 3D audio, the sound can be<a id="_idIndexMarker798"/> modeled to be in front of or behind the player, not just to the left or <a id="_idIndexMarker799"/>right, deepening the immersion.</p>
    <h3 id="_idParaDest-416" class="heading-3">PortAudio</h3>
    <p class="normal"><strong class="keyWord">PortAudio</strong> is another <a id="_idIndexMarker800"/>cross-platform audio library. It targets real-time audio playback and recording. PortAudio can be <a id="_idIndexMarker801"/>used if the scope of SDL and OpenAL is too large for the project, and the goal is to just have some audio playing.</p>
    <h3 id="_idParaDest-417" class="heading-3">FMOD</h3>
    <p class="normal">Although <strong class="keyWord">FMOD</strong> is a proprietary<a id="_idIndexMarker802"/> sound engine, it can be included in the list of freely available libraries <a id="_idIndexMarker803"/>as a non-commercial license exists, allowing us to use FMOD for free. A paid FMOD license is only needed if the final application or game will be distributed commercially. FMOD supports 3D engines such as Unreal and Unity, so you might <a id="_idIndexMarker804"/>even get in touch<a id="_idIndexMarker805"/> with FMOD if you are working on a game at some point in time.</p>
    <p class="normal">After exploring <em class="italic">which software</em> for sound and music replay could be included, let’s check out <em class="italic">what</em> could and should be played.</p>
    <h2 id="_idParaDest-418" class="heading-2">Playing sound effects</h2>
    <p class="normal">Since sound plays a key role in our lives, we<a id="_idIndexMarker806"/> will have some expectations of what we should hear in a game or a simulation. Failing to meet these expectations may harm immersion.</p>
    <h3 id="_idParaDest-419" class="heading-3">The game character’s footsteps</h3>
    <p class="normal">Probably the most important<a id="_idIndexMarker807"/> sound effects a player wants to hear are the footsteps of the character on the ground. By adjusting the sound in relation to the ground <a id="_idIndexMarker808"/>material and the speed of the character, instant feedback about the environment is delivered to the player. There is a significant difference between <a id="_idIndexMarker809"/>silently sneaking through grass or running on metal ground, and the player should be made aware of the “loudness” of the character’s actions, and by using collision detection and ground triangle discovery, as described in the <em class="italic">Finding ground triangles in level data</em> section of <a href="Chapter_12.xhtml"><em class="italic">Chapter 12</em></a><em class="italic">,</em> the material type of the ground triangle can be found easily.</p>
    <h3 id="_idParaDest-420" class="heading-3">Other character sounds</h3>
    <p class="normal">The character makes a lot more<a id="_idIndexMarker810"/> sounds, not just footsteps. Jumping and landing, climbing a ladder, swimming, or being hurt by an enemy character should also give audible feedback to the player for additional information about what happens with the character in the virtual world.</p>
    <h3 id="_idParaDest-421" class="heading-3">Local sound sources</h3>
    <p class="normal">Not only does the player-controlled character need sound effects, but also for the computer-controlled characters and inanimate<a id="_idIndexMarker811"/> objects in the virtual worlds audio effects should be played. Hearing doors opening and closing, the hammering of a blacksmith, or the call of a bird, and listening to the crackles of fireplaces, the sound of a waterfall, or wind in a high place in the world will intensify immersion greatly.</p>
    <h3 id="_idParaDest-422" class="heading-3">Ambient sounds</h3>
    <p class="normal">Ambient sounds are a mix of <a id="_idIndexMarker812"/>different sounds and frequencies coming from locations far away, losing some of their information on the way to the listener. A large group of people, the wind in a forest, or a street some meters away all produce well-known sounds for us that should be added to corresponding places of the virtual world.</p>
    <h3 id="_idParaDest-423" class="heading-3">Weather effects</h3>
    <p class="normal">If the world includes some kind of weather system, the sounds and effects should be added too. A distant thunderstorm or the silence <a id="_idIndexMarker813"/>of the ground after a snowfall can change the perception of the virtual world by the player.</p>
    <p class="normal">But not only can sound effects be useful for immersion; playing music can also help to keep a player’s attention.</p>
    <h2 id="_idParaDest-424" class="heading-2">Playing music</h2>
    <p class="normal">Since the early days of computer <a id="_idIndexMarker814"/>games, music has been added to games to keep players interested. As a result, we may still remember the music of a game when we see the title but not details of the gameplay or the game’s characters.</p>
    <h3 id="_idParaDest-425" class="heading-3">Menu music</h3>
    <p class="normal">The first screen a player will see <a id="_idIndexMarker815"/>when starting the application is most probably some kind of main menu. Throwing a player directly into the action, without being able to configure the controls for the virtual character, the visual quality, or the sound volume first, may not be the best idea. While the player explores the options in the menu, music can help to prevent the player from getting lost or bored straight away.</p>
    <h3 id="_idParaDest-426" class="heading-3">Ambient music</h3>
    <p class="normal">Similar to ambient sounds, ambient<a id="_idIndexMarker816"/> music helps to prevent dead silence in a game. Playing no sounds at all may be intended to build up tension, but running for hours and hours in silence through a game can become boring. Adding a music track with a style and tempo that fits the gameplay helps the player to enjoy even slow passages of the game.</p>
    <h3 id="_idParaDest-427" class="heading-3">Adaptive music play</h3>
    <p class="normal">When the player moves into a different <a id="_idIndexMarker817"/>area in an open world or enters an environment with a different style, or another room, changing the music to match the new place is a good idea. The famous “hearing boss music” moment when entering a room, combined with the sound of doors locking, will create unforgettable moments for a player.</p>
    <h3 id="_idParaDest-428" class="heading-3">Allowing custom music</h3>
    <p class="normal">An interesting option for music selection is to let the player add local music to the list of tracks played in the game or even<a id="_idIndexMarker818"/> replace the music entirely. Seeing the game’s character exploring a virtual world while listening to some favorite music tracks may be a plus for players.</p>
    <p class="normal">To experience the difference audio replay can make, we will add a C++ class to manage sound effects and music replay.</p>
    <h2 id="_idParaDest-429" class="heading-2">Hands-on: Implementing an audio manager</h2>
    <p class="normal">The audio manager class <a id="_idIndexMarker819"/>consists of two distinct parts. On one hand, we <a id="_idIndexMarker820"/>need a high-level interface between the audio manager and the renderer and other classes. On the other hand, the encapsulated low-level interface linking the audio manager functionality to the audio library of the operating system would allow us to replace the audio library with another variant.</p>
    <p class="normal">We will start with a brief overview of the high-level interface and dive into the low-level implementation afterward.</p>
    <h3 id="_idParaDest-430" class="heading-3">Defining the high-level interface</h3>
    <p class="normal">The new <code class="inlineCode">AudioManager</code> class, consisting of the <code class="inlineCode">AudioManager.h</code> header file and the <code class="inlineCode">AudioManager.cpp</code> implementation <a id="_idIndexMarker821"/>file will be added to the <code class="inlineCode">tools</code> folder. We <a id="_idIndexMarker822"/>will add the basic functions a usual music/sound player should have:</p>
    <ul>
      <li class="bulletList">Initializing and cleaning up the audio library</li>
      <li class="bulletList">Loading music tracks from files on the file system</li>
      <li class="bulletList">Loading sound effects from files on the file system</li>
      <li class="bulletList">Playing and stopping music and sound effects</li>
      <li class="bulletList">Pausing, resuming, and skipping the music tracks to the next and previous</li>
      <li class="bulletList">Retrieving, shuffling, and clearing the current playlist</li>
      <li class="bulletList">Changing the volume of music and sound effects</li>
    </ul>
    <p class="normal">For instance, the <code class="inlineCode">public</code> <code class="inlineCode">setMusicVolume()</code> and <code class="inlineCode">getMusicVolume()</code> methods are added to the <code class="inlineCode">AudioManager</code> class to control the music volume:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-type">void</span><span class="hljs-function"> </span><span class="hljs-title">setMusicVolume</span><span class="hljs-params">(</span><span class="hljs-type">int</span><span class="hljs-params"> volume)</span>;
    <span class="hljs-type">int</span><span class="hljs-function"> </span><span class="hljs-title">getMusicVolume</span><span class="hljs-params">()</span>;
</code></pre>
    <p class="normal">In addition, the <code class="inlineCode">private</code> member variable named <code class="inlineCode">mMusicVolume</code> is used to store the current volume of the music:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-type">int</span> mMusicVolume = <span class="hljs-number">64</span>;
</code></pre>
    <p class="normal">For the remaining functionalities in the list of functions, <code class="inlineCode">public</code> methods and <code class="inlineCode">private</code> member variables are created. Check the <code class="inlineCode">AudioManager.h</code> file to see the full number of methods and member variables that are available in the <code class="inlineCode">AudioManager</code> class.</p>
    <p class="normal">Now we must add a member variable for an object of the <code class="inlineCode">AudioManager</code> class along with the initialization and cleanup calls of the audio functionality to the application code. To keep the renderer for the video part only, the <code class="inlineCode">AudioManager</code> member variable and methods will be added to the <code class="inlineCode">Window</code> class.</p>
    <h4 class="heading-4">Adding the AudioManager class to the Window class</h4>
    <p class="normal">The two primary steps to <a id="_idIndexMarker823"/>add the audio functions to the <code class="inlineCode">Window</code> class are the same as for all other classes: including the <code class="inlineCode">AudioManager.h</code> header file at the top of the <code class="inlineCode">Window.h</code> header file and declaring the <code class="inlineCode">private</code> member variable named <code class="inlineCode">mAudioManager</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="code-highlight"><strong class="hljs-meta-slc">#</strong><strong class="hljs-keyword-slc">include</strong><strong class="hljs-meta-slc"> </strong><strong class="hljs-string-slc">"</strong><strong class="hljs-string-slc">AudioManager.h"</strong></span>
...
<span class="code-highlight"><strong class="hljs-slc">    AudioManager mAudioManager{};</strong></span>
</code></pre>
    <p class="normal">Then, in the <code class="inlineCode">init()</code> method of the <code class="inlineCode">Window</code> class in the <code class="inlineCode">Window.cpp</code> file, we try to initialize the <code class="inlineCode">AudioManager</code> object:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (!mAudioManager.<span class="hljs-built_in">init</span>()) {
    Logger::<span class="hljs-built_in">log</span>(<span class="hljs-number">1</span>, <span class="hljs-string">"%s error: unable to init audio,</span>
<span class="hljs-string">      skipping\n"</span>, __FUNCTION__);
  }
</code></pre>
    <p class="normal">Note that we use the <code class="inlineCode">Logger</code> class to print an error message, but we <em class="italic">do not</em> end the window initialization if the <code class="inlineCode">AudioManager</code> initialization fails. Audio replay should be kept optional, and we continue without music and <a id="_idIndexMarker824"/>sound replay instead of failing the application startup process.</p>
    <p class="normal">Loading the music tracks into the <code class="inlineCode">AudioManager</code> can be done right after the initialization call:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (mAudioManager.<span class="hljs-built_in">isInitialized</span>()) {
    mAudioManager.<span class="hljs-built_in">loadMusicFromFolder</span>(<span class="hljs-string">"assets/music"</span>, <span class="hljs-string">"mp3"</span>));
  }
</code></pre>
    <p class="normal">Here, we are trying to load all MP3 files in the <code class="inlineCode">assets/music</code> folder into the <code class="inlineCode">AudioManager</code> if the initialization is successful. Again, we don’t fail if no music files are found in the asset folder.</p>
    <div class="note">
      <p class="normal">Adding music tracks to the playlist</p>
      <p class="normal">In the <code class="inlineCode">AudioManager</code> class, support for loading MP3 and OGG files from the local folder <code class="inlineCode">assets/music</code> into a playlist has been implemented. You can add your own music to the <code class="inlineCode">assets/music</code> folder as the playlist will be populated when the application is started. In the <em class="italic">Practical sessions</em> section, a task is available to add a <strong class="screenText">Refresh</strong> button to the UI, allowing you to add or remove music tracks at application runtime.</p>
    </div>
    <p class="normal">Finally, we need to clean up the <code class="inlineCode">AudioManager</code> when shutting down the application. So, we add a call to the <code class="inlineCode">cleanup()</code> method of <code class="inlineCode">AudioManager</code> to the <code class="inlineCode">cleanup()</code> method of the <code class="inlineCode">Window</code> class:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-type">void</span><span class="hljs-function"> </span><span class="hljs-title">Window::cleanup</span><span class="hljs-params">()</span><span class="hljs-function"> </span>{
  mRenderer-&gt;<span class="hljs-built_in">cleanup</span>();
<span class="code-highlight"><strong class="hljs-slc">  mAudioManager.</strong><strong class="hljs-built_in-slc">cleanup</strong><strong class="hljs-slc">();</strong></span>
...
}
</code></pre>
    <p class="normal">Since we created the <code class="inlineCode">AudioManager</code> in the <code class="inlineCode">Window</code> class, we need to create callback functions to access the music and sound-effect functions from the renderer or the user interface.</p>
    <h4 class="heading-4">Using callbacks to make the AudioManager class available everywhere</h4>
    <p class="normal">By using these callback <a id="_idIndexMarker825"/>functions, changing the music track or playing footstep sounds can be done from anywhere in the code. As an example, we will use the functionality to play a specific music track here, given the track name as a parameter.</p>
    <p class="normal">First, we add the function signature for the callback named <code class="inlineCode">playMusicTitleCallback</code> to the <code class="inlineCode">Callbacks.h</code> file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">using</span> playMusicTitleCallback =
  std::function&lt;<span class="hljs-built_in">void</span>(std::string)&gt;;
</code></pre>
    <p class="normal">Next, we create a variable named <code class="inlineCode">micPlayMusicTitleCallbackFunction</code> to the <code class="inlineCode">ModelInstanceCamData</code> <code class="inlineCode">struct</code> in the <code class="inlineCode">ModelInstanceCamData.h</code> file:</p>
    <pre class="programlisting code"><code class="hljs-code">  playMusicTitleCallback micPlayMusicTitleCallbackFunction;
</code></pre>
    <p class="normal">We use the <code class="inlineCode">ModelInstanceCamData</code> <code class="inlineCode">struct</code> to avoid spreading the callback functions all over the code.</p>
    <p class="normal">Then, the callback variable will be bound to the corresponding <code class="inlineCode">AudioManager</code> function in the <code class="inlineCode">init()</code> method of the <code class="inlineCode">Window</code> class:</p>
    <pre class="programlisting code"><code class="hljs-code">  ModelInstanceCamData&amp; rendererMICData =
    mRenderer-&gt;<span class="hljs-built_in">getModInstCamData</span>();
    RendererMICData.micPlayMusicTitleCallbackFunction =
    [<span class="hljs-keyword">this</span>](std::string title) {
      mAudioManager.<span class="hljs-built_in">playTitle</span>(title);
    };
</code></pre>
    <p class="normal">Here, we get a reference to the variable containing the <code class="inlineCode">ModelInstanceCamData</code> <code class="inlineCode">struct</code> of the renderer class and assign the <code class="inlineCode">playTitle()</code> method of the <code class="inlineCode">AudioManager</code> class by using a lambda function.</p>
    <p class="normal">The same three steps of creating the callback function signature, adding a variable to the <code class="inlineCode">ModelInstanceCamData</code> <code class="inlineCode">struct</code>, and binding the callback function to the method of the <code class="inlineCode">AudioManger</code> class must be repeated for every audio method that should be available in the renderer.</p>
    <p class="normal">Now, let’s look at the implementation of the low-level part of the audio manager. We will use SDL as the audio functions are easy to use.</p>
    <h3 id="_idParaDest-431" class="heading-3">Using SDL for the low-level layer</h3>
    <p class="normal">Although SDL can <a id="_idIndexMarker826"/>handle more features than audio, it is possible to use only a subset of the functions provided by the SDL library. So, instead of using SDL for window and keyboard handling, which is done by GLFW in the application, we will only use the <a id="_idIndexMarker827"/>sound replay and mix functionality of SDL.</p>
    <p class="normal">To use audio replay with SDL, we need the core SDL library plus the separate mixer library named <code class="inlineCode">SDL_mixer</code>.</p>
    <h4 class="heading-4">Installing SDL and SDL_mixer on Windows</h4>
    <p class="normal">For Windows, precompiled versions of SDL and <code class="inlineCode">SDL_mixer</code> are available on GitHub. Go to the releases page at the following<a id="_idIndexMarker828"/> two URLs and download the latest stable development zip files for Visual Studio, containing both <code class="inlineCode">devel</code> and <code class="inlineCode">VC</code> in their names. As an <a id="_idIndexMarker829"/>example, the current development package of the main SDL library for Visual Studio is named <code class="inlineCode">SDL2-devel-2.30.9-VC.zip</code>. Here are the URLs:</p>
    <ul>
      <li class="bulletList">SDL: <a href="https://github.com/libsdl-org/SDL/releases"><span class="url">https://github.com/libsdl-org/SDL/releases</span></a></li>
      <li class="bulletList"><code class="inlineCode">SDL_mixer</code>: <a href="https://github.com/libsdl-org/"><span class="url">https://github.com/libsdl-org/SDL_mixer/releases</span></a></li>
    </ul>
    <p class="normal">Now, unpack the two zip files to your computer, but take care to avoid spaces and special characters like German umlauts in the path names to avoid problems since even in 2024 many tools have still problems with special characters in the paths.</p>
    <p class="normal">Next, add two <strong class="screenText">environment variables</strong> to help the CMake search scripts find the headers and libraries:</p>
    <ul>
      <li class="bulletList">The first variable is named <code class="inlineCode">SDL2DIR</code> and must point to the folder where the main SDL library was unpacked.</li>
      <li class="bulletList">The second variable is named <code class="inlineCode">SDL2MIXERDIR</code> and must point to the folder of the <code class="inlineCode">SDL_mixer</code> library.</li>
    </ul>
    <p class="normal"><em class="italic">Figure 14.1</em> shows an example of the environment variables:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_01.png" alt="" width="1250" height="628"/></figure>
    <p class="packt_figref">Figure 14.1: Example environment variables for SDL</p>
    <p class="normal">After installing the two libraries and adding the environment variables, the code for this chapter can be compiled. The CMake build script takes care of placing the two DLL files next to the executable file.</p>
    <h4 class="heading-4">Installing SDL and SDL_mixer on Linux</h4>
    <p class="normal">On Linux, the SDL libraries can<a id="_idIndexMarker830"/> be added by using the integrated <a id="_idIndexMarker831"/>package management. On Ubuntu or Debian, you can use the <code class="inlineCode">apt</code> package manager to install the main SDL library, the <code class="inlineCode">SDL_mixer</code> library, and all development headers and libraries by issuing the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">sudo apt install libsdl2-dev libsdl2-mixer-dev
</code></pre>
    <p class="normal">For an Arch-based distribution, use the <code class="inlineCode">pacman</code> package manager to add the two libraries to the system with the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">sudo pacman –S sdl2 sdl2_mixer
</code></pre>
    <p class="normal">To add SDL and <code class="inlineCode">SDL_mixer</code> to the <code class="inlineCode">AudioManager</code> class in order to use the SDL functions, we must include the two SDL headers after the existing <code class="inlineCode">#include</code> directives in the <code class="inlineCode">AudioManager.h</code> header file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">#</span><span class="hljs-keyword">include</span><span class="hljs-meta"> </span><span class="hljs-string">&lt;SDL.h&gt;</span>
<span class="hljs-meta">#</span><span class="hljs-keyword">include</span><span class="hljs-meta"> </span><span class="hljs-string">&lt;</span><code class="inlineCode">SDL_mixer</code><span class="hljs-string">.h&gt;</span>
</code></pre>
    <p class="normal">Since SDL is a C library, all structures only use raw pointers. The audio manager is one of the places where you will find variables<a id="_idIndexMarker832"/> with raw pointers in the code:</p>
    <pre class="programlisting code"><code class="hljs-code">std::unordered_map&lt;std::string, Mix_Music*&gt; mMusicTitles{};
Mix_Chunk* mWalkFootsteps;
</code></pre>
    <p class="normal">The <code class="inlineCode">mMusicTitles</code> variable is a map containing several SDL music objects, which are accessible by the name of the track as the key for the map. Every track is saved in a variable named <code class="inlineCode">Mix_Music</code>, where the prefix Mix states that this is a variable used by the <code class="inlineCode">SDL_mixer</code> library.</p>
    <p class="normal">In the <code class="inlineCode">mWalkFootsteps</code> variable, a so-called chunk of audio (using the terms of SDL) is stored. An <code class="inlineCode">SDL_mixer</code> chunk can be<a id="_idIndexMarker833"/> played by calling the respective sound effect’s replay function.</p>
    <p class="normal">Before sound effects or music can be played, the audio part of SDL must be initialized properly, and at the end of the application, the audio functions must be ended too.</p>
    <h4 class="heading-4">Initializing and shutting down SDL and the SDL_mixer</h4>
    <p class="normal">As the first step in the <code class="inlineCode">init()</code> method<a id="_idIndexMarker834"/> of the <code class="inlineCode">AudioManager</code> class, we try to<a id="_idIndexMarker835"/> initialize the audio part of SDL:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">SDL_Init</span>(SDL_INIT_AUDIO) &lt; <span class="hljs-number">0</span>) {
    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;
  }
</code></pre>
    <p class="normal">The <code class="inlineCode">SDL</code> prefix of both <code class="inlineCode">SDL_Init()</code> and the <code class="inlineCode">SDL_INIT_AUDIO</code> flag denotes that we are using the core functionality of SDL. If we cannot initialize the audio part of SDL, we stop the initialization of the <code class="inlineCode">AudioManager</code> right here. Beware that the initialization of the audio device can fail for various reasons, for instance, if the audio device is in use by another application that forbids sharing the device.</p>
    <p class="normal">Next, we try to set the parameters for the audio device by calling <code class="inlineCode">Mix_OpenAudio()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> (<span class="hljs-built_in">Mix_OpenAudio</span>(<span class="hljs-number">44100</span>, MIX_DEFAULT_FORMAT, <span class="hljs-number">2</span>, <span class="hljs-number">8192</span>) &lt; <span class="hljs-number">0</span>) {  <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;
}
</code></pre>
    <p class="normal">Now, we are in the realm of <code class="inlineCode">SDL_mixer</code>, which is visible on the <code class="inlineCode">Mix</code> prefix of <code class="inlineCode">Mix_OpenAudio</code>. The first parameter of <code class="inlineCode">Mix_OpenAudio</code> is the replay frequency in Hz. We are using the well-known value of 44.1 kHz, introduced by Sony’s <strong class="keyWord">compact disc</strong> specifications. As the second parameter, the internal audio format is configured. <code class="inlineCode">MIX_DEFAULT_FORMAT</code> stands for 16-bit signed integer values, which is also a common value in the audio world.</p>
    <p class="normal">The third parameter is the number <a id="_idIndexMarker836"/>of output channels to use. One output <a id="_idIndexMarker837"/>channel uses mono replay, and the two channels from the initialization call are for stereo output. Depending on the audio hardware and driver support, up to eight output channels for a 7.1 system are possible.</p>
    <p class="normal">With the fourth and last parameter, an internal audio buffer in the <code class="inlineCode">SDL_mixer</code> library is configured. A small buffer value may cause audio dropouts if the CPU load gets too high while filling the buffer, and a large buffer leads to delays since the buffer needs to be filled before the samples can be played. The unit of the buffer parameter is “sample frames,” so we configure <code class="inlineCode">SDL_mixer</code> to reserve space for 2,048 frames, every frame contains two 16-bit signed integers, one for every output channel.</p>
    <p class="normal">At the termination time of the application, the <code class="inlineCode">cleanup()</code> method of the <code class="inlineCode">AudioManager</code> is called by the <code class="inlineCode">cleanup()</code> method of the <code class="inlineCode">Window</code> class. Inside the <code class="inlineCode">cleanup()</code> method of the <code class="inlineCode">AudioManager</code> class, we close the audio device and signal both <code class="inlineCode">SDL_mixer</code> and SDL to run their respective cleanup code:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_CloseAudio</span>();
  <span class="hljs-built_in">Mix_Quit</span>();
  <span class="hljs-built_in">SDL_Quit</span>();
</code></pre>
    <p class="normal">Note that we did not call <code class="inlineCode">Mix_Init()</code> in the <code class="inlineCode">init()</code> method, but we have to call <code class="inlineCode">Mix_Quit()</code> here. SDL manages the mixer initialization for us without an explicit call to <code class="inlineCode">Mix_Init()</code>.</p>
    <p class="normal">Now we are ready to play music and sound effects. Let’s start with a look at the music replay code.</p>
    <h3 id="_idParaDest-432" class="heading-3">Controlling music replay</h3>
    <p class="normal">Loading a music track is done<a id="_idIndexMarker838"/> by calling <code class="inlineCode">Mix_LoadMUS()</code> with the C-style character array as a parameter:</p>
    <pre class="programlisting code"><code class="hljs-code">  Mix_Music* music = <span class="hljs-built_in">Mix_LoadMUS</span>(fileName.<span class="hljs-built_in">c_str</span>());
</code></pre>
    <p class="normal"><code class="inlineCode">SDL_mixer</code> supports several music formats, such as WAV, MP3, and OGG. The return value of <code class="inlineCode">Mix_LoadMUS()</code> is a pointer to the <code class="inlineCode">Mix_Music</code> <code class="inlineCode">struct</code>.</p>
    <p class="normal">To clean up a loaded music track, <code class="inlineCode">Mix_FreeMusic()</code> must be called with the pointer to the above <code class="inlineCode">Mix_Music</code> <code class="inlineCode">struct</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_FreeMusic</span>(music);
</code></pre>
    <p class="normal">A music track can be played by calling <code class="inlineCode">Mix_PlayMusic()</code> with two parameters:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_PlayMusic</span>(music, <span class="hljs-number">0</span>);
</code></pre>
    <p class="normal">The first parameter is a pointer to a valid <code class="inlineCode">Mix_Music</code> <code class="inlineCode">struct</code>, while the second parameter tells <code class="inlineCode">SDL_mixer</code> the number of loops to play. A loop value of <code class="inlineCode">0</code> disables looping and a value of <code class="inlineCode">-1</code> will loop the music infinitely.</p>
    <p class="normal">Stopping the music is done by calling <code class="inlineCode">Mix_HaltMusic()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_HaltMusic</span>();
</code></pre>
    <p class="normal">Since there is only one music <a id="_idIndexMarker839"/>track playing at a time, no parameters are needed, and in case the current track should be paused or resumed, the two <code class="inlineCode">Mix_PauseMusic()</code> and <code class="inlineCode">Mix_ResumeMusic()</code> calls are available:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_PauseMusic</span>();
  <span class="hljs-built_in">Mix_ResumeMusic</span>();
</code></pre>
    <p class="normal">Finally, the music volume is controlled by <code class="inlineCode">Mix_VolumeMusic()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_VolumeMusic</span>(volume);
</code></pre>
    <p class="normal">The parameter for <code class="inlineCode">Mix_VolumeMusic()</code> is an <code class="inlineCode">int</code> value between <code class="inlineCode">0</code> and <code class="inlineCode">128</code> to set the new volume, or a value of <code class="inlineCode">-1</code> to query the current volume of the music.</p>
    <p class="normal">By using the default <code class="inlineCode">SDL_mixer</code> calls, we can only play one music track once or with an infinite number of loops. If a dynamic music system is required, a manual implementation is needed, or even a different sound replay API should be considered. For the simple ability to advance to the next track in a playlist at the end of a track, we just need to implement a callback.</p>
    <h3 id="_idParaDest-433" class="heading-3">Adding a callback for continuous music playback</h3>
    <p class="normal"><code class="inlineCode">SDL_mixer</code> supports a callback to<a id="_idIndexMarker840"/> inform the application that the current music track has finished the number of loops. In this callback, we can simply forward to the next track in the playlist.</p>
    <p class="normal">Sadly, <code class="inlineCode">SDL_mixer</code> is a C audio library, and the callback must fulfill the C-style calling convention. The C++ calling convention is not compatible with the C calling convention and allows only calling static member functions of the <code class="inlineCode">AudioManager</code> class. We need to add a small hack to be able to call a non-static method of the <code class="inlineCode">AudioManager</code> class that has access to the playlist and the current position in the playlist.</p>
    <p class="normal">First, we declare a raw pointer named <code class="inlineCode">mCurrentManager</code> as <code class="inlineCode">private</code> member variable, plus the <code class="inlineCode">private</code> static <code class="inlineCode">staticMuscFinishedCallback()</code> member method for the C-style callback and a <code class="inlineCode">private</code> non-static member <code class="inlineCode">musicFinishedCallback()</code> for the translated callback:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-type">static</span> AudioManager* mCurrentManager;
    <span class="hljs-type">static</span><span class="hljs-function"> </span><span class="hljs-type">void</span><span class="hljs-function"> </span><span class="hljs-title">staticMusicFinshedCallback</span><span class="hljs-params">()</span>;
    <span class="hljs-type">void</span><span class="hljs-function"> </span><span class="hljs-title">musicFinishedCallback</span><span class="hljs-params">()</span>;
</code></pre>
    <p class="normal">In the <code class="inlineCode">init()</code> method of the <code class="inlineCode">AudioManager</code> class, we set the <code class="inlineCode">mCurrentManager</code> pointer to the current instance and call the callback hook setup method <code class="inlineCode">Mix_HookMusicFinished()</code> with the static callback method:</p>
    <pre class="programlisting code"><code class="hljs-code">  mCurrentManager = <span class="hljs-keyword">this</span>;
  <span class="hljs-built_in">Mix_HookMusicFinished</span>(staticMusicFinshedCallback);
</code></pre>
    <p class="normal">Whenever a music track ends now, <code class="inlineCode">staticMusicFinishedCallback()</code> is called by <code class="inlineCode">SDL_mixer</code>. To translate the callback to C++, we <a id="_idIndexMarker841"/>use the pointer to the current <code class="inlineCode">AudioManager</code> instance stored in <code class="inlineCode">mCurrentManager</code> to call the non-static callback <code class="inlineCode">musicFinishedCallback()</code> method:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (mCurrentManager)  {
    mCurrentManager-&gt;<span class="hljs-built_in">musicFinishedCallback</span>();
  }
</code></pre>
    <p class="normal">Inside <code class="inlineCode">musicFinishedCallback()</code>, we can now add code to advance one track in the playlist, enabling a continuous replay of all tracks in the playlist:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (mMusicPlaying) {
    <span class="hljs-built_in">playNextTitle</span>();
  }
</code></pre>
    <p class="normal">After the music replay is implemented, let’s go to the sound effect replay code.</p>
    <h3 id="_idParaDest-434" class="heading-3">Playing sound effects</h3>
    <p class="normal">Using <code class="inlineCode">SDL_mixer</code> to play sound effects has some subtle differences compared to playing music. The main difference is <a id="_idIndexMarker842"/>that by default eight sound effects can be played at the same time since <code class="inlineCode">SDL_mixer</code> allocates eight internal sound channels for the sound effect output.</p>
    <p class="normal">Note that these internal sound channels are not the same as the two output sound channels configured when we initialized the audio device.</p>
    <p class="normal">Allocating more or even less than these eight sound channels can be done by calling <code class="inlineCode">Mix_AllocateChannels()</code> with the number of desired channels as a parameter:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_AllocateChannels</span>(<span class="hljs-number">1</span>);
</code></pre>
    <p class="normal">We will use only one channel in the <code class="inlineCode">AudioManager</code> for now to allow a simple implementation of the footstep sound replay.</p>
    <p class="normal">As <code class="inlineCode">SDL_mixer</code> has only one channel available now, a second sound effect cannot be played if another sound effect is still playing. So, by limiting the number of channels to only one, we can avoid creating a complex system to switch between walking and running footstep sounds for the example implementation.</p>
    <p class="normal">Loading a sound file from the file system is similar to the music loading process. We call <code class="inlineCode">Mix_LoadWav()</code> with the C-style <a id="_idIndexMarker843"/>character array of the file name and store the returned result in a <code class="inlineCode">Mix_Chunk</code> <code class="inlineCode">struct</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  Mix_Chunk* mWalkFootsteps;
  mWalkFootsteps = <span class="hljs-built_in">Mix_LoadWAV</span>(fileName.<span class="hljs-built_in">c_str</span>());
</code></pre>
    <p class="normal">Cleaning up the sound effect is done by calling <code class="inlineCode">Mix_FreeChunk()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">Mix_FreeChunk</span>(mWalkFootsteps);
</code></pre>
    <p class="normal">Playing and stopping the replay of a sound effect is also like playing or stopping the music. A sound effect will be played by using <code class="inlineCode">Mix_PlayChannel()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  mSoundChannel = <span class="hljs-built_in">Mix_PlayChannel</span>(<span class="hljs-number">-1</span>, mRunFootsteps, <span class="hljs-number">0</span>);
</code></pre>
    <p class="normal">The first parameter of <code class="inlineCode">Mix_PlayChannel()</code> is the sound channel to use. The special value of <code class="inlineCode">-1</code> just uses the next available sound channel for the sound effect replay. The second parameter is a pointer to the <code class="inlineCode">Mix_Chunk</code> <code class="inlineCode">struct</code> to play, and the third parameter is again the number of loops.</p>
    <p class="normal">As the return parameter of <code class="inlineCode">Mix_PlayChannel()</code>, we get the sound channel number, on which this sound effect is played. We save the channel number in the <code class="inlineCode">mSoundChannel</code> member variable to be able to stop the replay with <code class="inlineCode">Mix_HaltChannel()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_HaltChannel</span>(mSoundChannel);
</code></pre>
    <p class="normal">Like for the music, we can control the volume of the sound channel by calling <code class="inlineCode">Mix_Volume()</code> with the channel number and desired volume as parameters:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">Mix_Volume</span>(mSoundChannel, volume);
</code></pre>
    <p class="normal">After we know how to play sound effects, we need to add a bit of code to the renderer to play a footstep sound whenever our instance is walking or running.</p>
    <h3 id="_idParaDest-435" class="heading-3">Using the footstep sound effects in the renderer</h3>
    <p class="normal">The implementation of the <a id="_idIndexMarker844"/>footstep replay will be just the bare minimum to show how and where the callbacks for the sound effects could be added. A full-featured sound effects replay system requires much more work and is out of the scope of this book.</p>
    <p class="normal">To add the footstep sounds, the following piece of code needs to be added to the <code class="inlineCode">handleMovementKeys()</code> method of the renderer, right after we set the next state of the instance by calling <code class="inlineCode">setNextInstanceState()</code>. At this point, we have all data about the current movement state of the instance.</p>
    <p class="normal">First, we retrieve the current animation state of the current instance and check if the instance is in the idle/walk/run cycle:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">if</span> (currentInstance-&gt;<span class="hljs-built_in">getAnimState</span>() ==
    animationState::playIdleWalkRun) {
</code></pre>
    <p class="normal">We only want to add sound effects at the same time as the walking and running animations replay.</p>
    <p class="normal">Then we check for the<a id="_idIndexMarker845"/> movement state of the instance and call the proper callback for the state:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-keyword">switch</span> (state) {
    <span class="hljs-keyword">case</span> moveState::run:
      mModelInstCamData.
        <span class="hljs-built_in">micPlayRunFootstepCallbackFunction</span>();
      <span class="hljs-keyword">break</span>;
    <span class="hljs-keyword">case</span> moveState::walk:
      mModelInstCamData.
        <span class="hljs-built_in">micPlayWalkFootstepCallbackFunction</span>();
      <span class="hljs-keyword">break</span>;
</code></pre>
    <p class="normal">When the instance is in the running state, we play the sound effect for running footsteps. And if the instance is in the walking state, we play the walking footsteps.</p>
    <p class="normal">If the instance is neither running nor walking, we stop the footstep sounds:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword">default</span>:
      mModelInstCamData.
        <span class="hljs-built_in">micStopFootstepCallbackFunction</span>();
      <span class="hljs-keyword">break</span>;
    }
</code></pre>
    <p class="normal">And if the instance is not in the idle/walk/run cycle, we also stop any sounds. This way, we catch all the actions like jumping or punching where no sound effect is available yet:</p>
    <pre class="programlisting code"><code class="hljs-code">  } <span class="hljs-keyword">else</span> {
    mModelInstCamData.
      <span class="hljs-built_in">micStopFootstepCallbackFunction</span>();
  }
</code></pre>
    <p class="normal">To hear the footsteps sounds, the following steps are required:</p>
    <ol>
      <li class="numberedList" value="1">Start the application and load a configuration with animation mapping.</li>
      <li class="numberedList">Select (or create) a first-person or third-person camera.</li>
      <li class="numberedList">Select an instance and set the instance by clicking on <strong class="screenText">Use Selected Instance</strong> in the <strong class="screenText">Camera</strong> section of the <strong class="screenText">Control</strong> window of the UI.</li>
      <li class="numberedList">Press <code class="inlineCode">F10</code> to switch to view mode.</li>
    </ol>
    <p class="normal">If you move around the controlled instance now by using the mouse and the <em class="italic">W</em>/<em class="italic">A</em>/<em class="italic">S</em>/<em class="italic">D</em> keys, you should hear two different <a id="_idIndexMarker846"/>footstep sounds, depending on the instance walking or running around in the virtual world.</p>
    <h3 id="_idParaDest-436" class="heading-3">Extending the audio manager class</h3>
    <p class="normal">To outline a possible<a id="_idIndexMarker847"/> expansion of the <code class="inlineCode">AudioManager</code> class to support more channels to achieve a more game-like sound management, we would need to keep track of the channel playing the footstep sound returned by the <code class="inlineCode">Mix_PlayChannel()</code> call. By reserving one channel exclusively for the local footstep sounds, we can achieve the same behavior, but we would be able to play more sound effects at the same time.</p>
    <p class="normal">Handling multiple sound effects can be achieved by adding a creating a pool of sound channels and adding a callback to the <code class="inlineCode">Mix_ChannelFinished()</code> SDL function, similar to <code class="inlineCode">Mix_HookMusicFinished()</code>. SDL triggers the <code class="inlineCode">Mix_ChannelFinished()</code> callback whenever a channel has finished the current sound clip, or when <code class="inlineCode">Mix_HaltChannel()</code> is called and delivers the number of the finished sound channel in the callback.</p>
    <p class="normal">The sound channel pool can be updated when a sound effect is played and when the effect replay has finished. By using the distance to the object creating the sound effect and scaling down the volume of the channel with <code class="inlineCode">Mix_Volume()</code> or by using <code class="inlineCode">Mix_SetDistance()</code>, the different distances of the source can be modeled. In addition, <code class="inlineCode">Mix_SetPanning()</code> can be used to adjust the position of the sound source to the left and right.</p>
    <p class="normal">Several tasks in the <em class="italic">Practical sessions</em> section are available to evolve the sound replay from the current state.</p>
    <p class="normal">As an example of how to use the <code class="inlineCode">AudioManager</code> callbacks from the <code class="inlineCode">UserInterface</code> class, a simple music replay control has been added to the user interface. In the <strong class="screenText">Music &amp; Sound</strong> section of the <strong class="screenText">Control</strong> window, you will find a combo box and some buttons to play the music from the playlist created from the <code class="inlineCode">assets/music</code> folder.</p>
    <h3 id="_idParaDest-437" class="heading-3">Using the music player in the UI</h3>
    <p class="normal">Adding music <a id="_idIndexMarker848"/>replay functionality to the <code class="inlineCode">UserInterface</code> class is a quick and simple task. By using the callbacks to the <code class="inlineCode">AudioManager</code> class, a basic music player is implemented with only a few code blocks to the UI.</p>
    <p class="normal">In <em class="italic">Figure 14.2</em>, the ImGui section with a basic music player using the <code class="inlineCode">AudioManager</code> class is shown:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_02.png" alt="" width="513" height="117"/></figure>
    <p class="packt_figref">Figure 14.2: A music player based on the AudioManager added to the user interface</p>
    <p class="normal">The desired music track to play can be chosen by using the <strong class="screenText">Tracks</strong> combo box, the current track can be played by pressing the <strong class="screenText">Play</strong> button, or a random track from the playlist will be chosen from the shuffled playlist by pressing <strong class="screenText">Play Random</strong>. The other four buttons, <strong class="screenText">Prev</strong>, <strong class="screenText">Pause</strong>, <strong class="screenText">Stop</strong>, and <strong class="screenText">Next</strong>, do exactly what the label states, and by using the sliders, the volume of music and sound effects can be set to a<a id="_idIndexMarker849"/> value between <code class="inlineCode">0</code> (for silence) and <code class="inlineCode">128</code>.</p>
    <h2 id="_idParaDest-438" class="heading-2">Alternative sound manager implementations</h2>
    <p class="normal">The <code class="inlineCode">AudioManager</code> class used for the application uses a straightforward implementation with direct control through C++ callback functions. For an advanced sound system, an event- or message-based<a id="_idIndexMarker850"/> implementation could be used. Such an implementation can use event managing code already in the game, and events or messages also decouple the sound effects replay from the code that is requesting to replay a sound effect or a music change.</p>
    <p class="normal">After having sound and music available in the virtual world, an update to the graphics of the application may appear also on the to-do list. Let’s explore some visual enhancements now.</p>
    <h1 id="_idParaDest-439" class="heading-1">Enhancing visuals</h1>
    <p class="normal">The OpenGL and Vulkan renderers in the example code support only a minimal set of features to bring an image to the screen: Both renderers can only draw textures triangles and colored lines. Adding one or more of the following enhancements will be a fantastic extension to the quality of the images.</p>
    <h2 id="_idParaDest-440" class="heading-2">Bringing colors to the world by using physically based rendering</h2>
    <p class="normal">Right now, we are using only the textures of the Assimp objects to render the model instances and level geometry to the screen. By using <strong class="keyWord">physically based rendering</strong>, short <strong class="keyWord">PBR</strong>, we could also model surface <a id="_idIndexMarker851"/>properties in the form of materials. With such PBR materials, it is easy to create surfaces that have a shininess <a id="_idIndexMarker852"/>and reflectivity of metal or make surfaces like concrete or bricks look more natural.</p>
    <p class="normal"><em class="italic">Figure 14.3</em> shows spheres drawn by the Vulkan PBR example code from Sascha Willems (the code is available at <a href="https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl"><span class="url">https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_03.png" alt="" width="1165" height="402"/></figure>
    <p class="packt_figref">Figure 14.3: Different PBR materials</p>
    <p class="normal">On the left side of <em class="italic">Figure 14.3</em>, the reflectiveness of the environment is set to a high value, resulting in a golden sphere. Between the spheres, the reflection settings change gradually, and on the right side, no reflectiveness<a id="_idIndexMarker853"/> at all is set.</p>
    <p class="normal">A link to the source code of the<a id="_idIndexMarker854"/> PBR rendering and other examples is available in the <em class="italic">Additional resources</em> section.</p>
    <h2 id="_idParaDest-441" class="heading-2">Adding transparency</h2>
    <p class="normal">A virtual world without windows and objects made of transparent materials may feel a bit strange since we are surrounded by transparent objects in the real world. However, rendering transparency is tricky due to the<a id="_idIndexMarker855"/> physics behind the color changes of the light on the path through more than one transparent object, requiring multiple transparent pixels on the same screen position to be drawn from back to front to calculate the correct final color for a pixel.</p>
    <p class="normal">Two different approaches exist, called ordered and order-independent transparency. While ordered transparency requires all transparent objects to be sorted from back to front, order-independent transparency rearranges the pixels to be drawn by itself into the correct order. Both methods have advantages and disadvantages, so the best way to choose is to test both versions.</p>
    <p class="normal"><em class="italic">Figure 14.4</em> shows two transparency examples from LearnOpenGL (<a href="https://learnopengl.com/"><span class="url">https://learnopengl.com/</span></a>) by Joey de Vries (<a href="https://x.com/JoeyDeVriez"><span class="url">https://x.com/JoeyDeVriez</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_04.png" alt="" width="1574" height="591"/></figure>
    <p class="packt_figref">Figure 14.4: Transparent plants (left) and translucent red glass (right)</p>
    <p class="normal">On the left side of <em class="italic">Figure 14.4</em>, partially transparent plants are rendered. By discarding pixels in the empty areas of the texture, a realistic effect of a plant can be achieved. On the right side of <em class="italic">Figure 14.4</em>, colored glass is rendered. Imitating glass for windows and other translucent objects by using transparent textures helps to create a better copy of the real world.</p>
    <h2 id="_idParaDest-442" class="heading-2">Looking up at a beautiful sky</h2>
    <p class="normal">If you start the virtual world<a id="_idIndexMarker856"/> created with the example code of the book and load a level that is partially made to be outside of a building, you will not see some sort of sky but just the default background color. Adding a beautiful sky to the scene requires not just a simple sky texture, but also a so-called cubemap and a distorted sky texture.</p>
    <p class="normal">A cubemap is a special kind of rendering object that represents the six sides of a cube, and the sky texture is projected onto the cubemap. The resulting skybox will create a seamless background that follows the view <a id="_idIndexMarker857"/>of the virtual camera, placing the level geometry and the instances into a realistic environment.</p>
    <p class="normal"><em class="italic">Figure 14.5</em> shows a skybox as environment around a wooden box, created with code from LearnOpenGL (<a href="https://learnopengl.com/"><span class="url">https://learnopengl.com/</span></a>) by Joey de Vries (<a href="https://x.com/JoeyDeVriez"><span class="url">https://x.com/JoeyDeVriez</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_05.png" alt="" width="794" height="596"/></figure>
    <p class="packt_figref">Figure 14.5: A wooden box with a skybox as the background</p>
    <p class="normal">The effect of using a skybox can be seen best when moving the view around. In a static picture like in <em class="italic">Figure 14.5</em>, the difference between the wooden box and the skybox can be seen.</p>
    <p class="normal">We will implement a skybox to our virtual world at the end of this section.</p>
    <h2 id="_idParaDest-443" class="heading-2">Playing with light and shadows</h2>
    <p class="normal">The current vertex shaders are using a hard-coded light source as virtual sun, emitting white light from a fixed position into the<a id="_idIndexMarker858"/> world. This basic lighting helps to identify the dimensions of the level geometry and the instances, even by using only flat shading. By adding more lights to the virtual world, other light-emitting objects can be modeled in a more realistic way, such as lamps, lanterns, fire, or torches. The flickering light of a fire in a dark place can be used to create various kinds of tension since it could mean a safe place to stay the night or an enemy position.</p>
    <p class="normal">The scene in <em class="italic">Figure 14.6</em> is illuminated by several thousand different colored light sources:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_06.png" alt="" width="640" height="353"/></figure>
    <p class="packt_figref">Figure 14.6: Multiple lights in a virtual world (image courtesy of Hannes Nevalainen)</p>
    <p class="normal">The image in <em class="italic">Figure 14.6</em> is a tech demo for the jMonkeyEngine made by Hannes Nevalainen, and the effect of many individual lights can be seen. The full video is available in the <em class="italic">Additional resources</em> section.</p>
    <p class="normal">When lights are added, shadows should be implemented too. For a simple start, the shadows of the objects cast by the virtual sun could be projected to the ground by using the so-called shadow mapping, creating the impression of lights and shadows taken from the real world. Shadows for the other lights can<a id="_idIndexMarker859"/> be added too, although the implementation is more complex. But the visual results will compensate for the effort as a lamp casting only the lit part of a window to the ground will bring a big smile to the programmer’s face.</p>
    <p class="normal"><em class="italic">Figure 14.7</em> was created from the Vulkan example code made by Sascha Willens (the code is available at <a href="https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl"><span class="url">https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl</span></a>), showing the shadows of trees created by using cascaded shadow maps:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_07.png" alt="" width="1273" height="715"/></figure>
    <p class="packt_figref">Figure 14.7: Cascaded shadow maps of trees</p>
    <p class="normal">Similar to the skybox, the effect <a id="_idIndexMarker860"/>of using shadow maps can be seen much better when light, objects, and/or cameras are moving. Shadows like in <em class="italic">Figure 14.7</em> are a great addition to the virtual world.</p>
    <h2 id="_idParaDest-444" class="heading-2">Swimming in realistic water</h2>
    <p class="normal">If water was added as part of the extended level environment, the visual appearance should also be checked and enhanced. While using a simple, static transparent water texture may be fine for the first implementation, the<a id="_idIndexMarker861"/> urge to create better water may come up at some point.</p>
    <p class="normal">By using a combination of reflection, refraction, and distortion of the light hitting the virtual water surface, realistic water can be created, and if the player should be able to dive into the water, a different kind of distortion could be utilized to create the illusion of being underwater.</p>
    <p class="normal"><em class="italic">Figure 14.8</em> shows a water simulation made in WebGL by Evan Wallace (the code is available at <a href="https://github.com/evanw/webgl-water/blob/master/index.html"><span class="url">https://github.com/evanw/webgl-water/blob/master/index.html</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_08.png" alt="" width="819" height="627"/></figure>
    <p class="packt_figref">Figure 14.8: Realistic water with waves and underwater caustics (courtesy of Evan Wallace)</p>
    <p class="normal">In <em class="italic">Figure 14.8</em>, the waves of the sphere falling into the water can be seen. Also, the refraction of the walls created by the water <a id="_idIndexMarker862"/>and the refraction of the light on the bottom of the pool are clearly visible.</p>
    <h2 id="_idParaDest-445" class="heading-2">Adding stunning post-processing effects</h2>
    <p class="normal">For even more realism in<a id="_idIndexMarker863"/> the virtual world, post-processing effects can be added to the renderers. The list of possible effects is long, so here is just a brief list of ideas that can be implemented quite quickly while creating great visuals:</p>
    <ul>
      <li class="bulletList">Lens flares for the illusion of looking through a camera</li>
      <li class="bulletList">God rays: visible rays in haze when the direct view into the sun is blocked</li>
      <li class="bulletList">Bloom effect simulating glowing objects</li>
      <li class="bulletList">Motion blur blurring the image when the view is moved</li>
      <li class="bulletList">Depth of field blurring the world around a sharp center</li>
      <li class="bulletList">Screen Space Ambient Occlusion darkening gaps and edges</li>
      <li class="bulletList">Screen Space Reflection, a cheap way to create reflective surfaces</li>
    </ul>
    <p class="normal">All these effects are created by using shaders and have different performance impacts. Nevertheless, even a bunch of the effects listed here will give the visual appearance a huge boost.</p>
    <p class="normal"><em class="italic">Figure 14.9</em> shows two post-processing <a id="_idIndexMarker864"/>effects, Bloom and <strong class="keyWord">Screen Space Ambient Occlusion</strong> (<strong class="keyWord">SSAO</strong>). The Bloom effect was created with code from LearnOpenGL (<a href="https://learnopengl.com/"><span class="url">https://learnopengl.com/</span></a>) by Joey de Vries (<a href="https://x.com/JoeyDeVriez"><span class="url">https://x.com/JoeyDeVriez</span></a>) and the SSAO picture is made with code from Sascha Willems’ Vulkan examples (the code is available at <a href="https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl"><span class="url">https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_09.png" alt="" width="1395" height="523"/></figure>
    <p class="packt_figref">Figure 14.9: Bloom (left) and SSAO (right)</p>
    <p class="normal">On the left side of <em class="italic">Figure 14.9</em>, the Bloom effect is shown. The characteristic part of the Bloom effect is the halo effect around the light sources. For the green light source, the light even overlaps the top left edge of the <a id="_idIndexMarker865"/>wooden crate.</p>
    <p class="normal">On the right side of <em class="italic">Figure 14.9</em>, SSAO is shown. The SSAO effect may be subtle, but it is visible: look at the floor below the curtains on the right side of the white line. The shadow creates the illusion of a darker room behind the curtains.</p>
    <h2 id="_idParaDest-446" class="heading-2">Upgrading to ray tracing</h2>
    <p class="normal">As the next step to realism, ray tracing can be added as an optional enhancement.</p>
    <p class="normal">Ray tracing uses virtual light rays <a id="_idIndexMarker866"/>emitted from the camera to compute the resulting pixel color by following the ray through the collisions with objects in the virtual world. Instead <a id="_idIndexMarker867"/>of just using the object color, the virtual ray is reflected by the physical rules and followed until the amount of light added falls below a threshold.</p>
    <p class="normal">With ray tracing, effects like a global illumination of the world, causing dark areas to be lit by light being reflected from the objects, or realistic reflections could be achieved. Imagine running through a room full of mirrors and seeing your character multiple times, drawn in a correct physical way.</p>
    <p class="normal"><em class="italic">Figure 14.10</em> shows a scene created by a ray tracing example from Sascha Willems Vulkan code (the code is available at <a href="https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl"><span class="url">https://github.com/SaschaWillems/Vulkan/tree/master/examples/pbribl</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_10.png" alt="" width="1171" height="710"/></figure>
    <p class="packt_figref">Figure 14.10: Real-time ray tracing scene</p>
    <p class="normal">The reflections on the floor, the spheres, and the teapot in <em class="italic">Figure 14.10</em> are calculated in real time by using ray tracing with the Vulkan API on an Nvidia RTX 4000 series GPU.</p>
    <p class="normal">The FPS counter was<a id="_idIndexMarker868"/> included to show how fast the current GPU generation is able to create ray tracing images. Only a few decades ago, a single frame of the same picture required several days to render.</p>
    <div class="note">
      <p class="normal">Ray tracing should be optional</p>
      <p class="normal">Note that the calculations for ray tracing require lots of computing power and creating complex scenes in real time needs both a GPU and a graphics API that support ray tracing. Right now, only Vulkan and DirectX 12 are able to use the ray tracing capabilities of modern GPUs. You need to check the availability of hardware and software support before switching to a graphics pipeline with ray tracing enabled.</p>
    </div>
    <h2 id="_idParaDest-447" class="heading-2">Diving into virtual reality</h2>
    <p class="normal">Even though virtual reality (VR) is still a small niche, implementing VR support can be a great step ahead for immersion. Being able <a id="_idIndexMarker869"/>not just to see the virtual world on a flat screen but to stand right in the middle of the world can become a memorable moment for a player. Using head tracking to move the virtual camera simultaneously to the head of the player and adding virtual hands for the VR controllers creates a lot of new opportunities for interaction.</p>
    <p class="normal"><em class="italic">Figure 14.11</em> shows a scene from the Godot XR Tool Demo (the code is available at <a href="https://github.com/GodotVR/godot-xr-template"><span class="url">https://github.com/GodotVR/godot-xr-template</span></a>):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_11.png" alt="" width="1178" height="961"/></figure>
    <p class="packt_figref">Figure 14.11: Godot XR Tools Demo</p>
    <p class="normal">The most notable detail of <em class="italic">Figure 14.11</em> is the two virtual hands. By using the integrated sensors of the Valve Index® controllers, not only the position of the controllers can be deduced in all 6 degrees of freedom, but also the<a id="_idIndexMarker870"/> individual fingers can be tracked to allow gestures or actions depending on the position of a finger.</p>
    <p class="normal">After the theoretical part of this section, we will now add a skybox to the application, acting as the global background.</p>
    <h2 id="_idParaDest-448" class="heading-2">Hands-on: Adding a skybox to the virtual world</h2>
    <p class="normal">A virtual sky is a <a id="_idIndexMarker871"/>great addition to a virtual world, especially above any open areas, as shown in <em class="italic">Figure 14.5</em>.</p>
    <h3 id="_idParaDest-449" class="heading-3">Exploring the technical details</h3>
    <p class="normal">From the technical side, a <a id="_idIndexMarker872"/>skybox is drawn from a texture applied on the inside of a unit cube. <em class="italic">Figure 14.12</em> shows the cube and the coordinates around the virtual camera placed in the center of the cube:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_12.png" alt="" width="1100" height="588"/></figure>
    <p class="packt_figref">Figure 14.12: The sampled area from the inside of a cubemap</p>
    <p class="normal">In <em class="italic">Figure 14.1</em>2, the red area of the cube will be sampled to create the background of the current frame. Note that the area is<a id="_idIndexMarker873"/> wrapping around the corner of the cube, but that is nothing to worry about. Both graphics libraries take care of such edge cases (pun intended) and will sample the respective areas of the two affected cube sides.</p>
    <p class="normal">The cubemap texture is usually stored as a set of six separate images or as a single image with the sides of the cube at specific locations in the image. <em class="italic">Figure 14.13</em> shows a skybox texture made by Jockum Skoglund (aka hipshot – <a href="https://opengameart.org/content/stormy-days-skybox"><span class="url">https://opengameart.org/content/stormy-days-skybox</span></a>) in a commonly used format plus the cube faces:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_13.png" alt="" width="1438" height="540"/></figure>
    <p class="packt_figref">Figure 14.13: A cubemap texture and the cube face of each picture</p>
    <p class="normal">On the left side of <em class="italic">Figure 14.13</em>, an example cubemap texture for a skymap is shown. You will find many cubemap textures as this kind of cross. On the right side of <em class="italic">Figure 14.13</em>, the cube faces for each of the smaller sub-images of the cubemap texture are listed. Remember that OpenGL and Vulkan with an inverted viewport have the negative Z-axis pointing into the virtual world, hence <code class="inlineCode">–Z</code> for the front image.</p>
    <p class="normal">Another noteworthy detail is the distortion of a cubemap image. Since the cubemap texture is applied to a cube but the virtual sky around us can be seen as a sphere, the pixels of a cubemap texture must be adjusted to <a id="_idIndexMarker874"/>appear as if the image was taken with a camera from inside a sphere. In <em class="italic">Figure 14.14</em>, the discrepancy between the projection inside a cube and inside a sphere is shown:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_14.png" alt="" width="1407" height="317"/></figure>
    <p class="packt_figref">Figure 14.14: Sampled point of a cube vs. the corrected projection of a sphere</p>
    <p class="normal">As you can see on the left side of <em class="italic">Figure 14.14</em>, the difference between a sample point taken from the cubemap and the position on the surface of the sphere gets larger the more we get near the edge of one side of the cubemap. On the right side of <em class="italic">Figure 14.14</em>, an area sampled from the cubemap and the required projection onto the surface of a sphere are highlighted as black bars. You can see that both the size and the angle of the areas differ. When building a cubemap texture for a skybox, a spherical distortion of the images for each of the cube faces must be applied to create a plausible sky.</p>
    <h3 id="_idParaDest-450" class="heading-3">Implementing the skybox</h3>
    <p class="normal">Adding the skybox to the<a id="_idIndexMarker875"/> code needs only a few components:</p>
    <ul>
      <li class="bulletList">New vertex and mesh types</li>
      <li class="bulletList">A new vertex buffer</li>
      <li class="bulletList">A unit cube model containing the coordinates of the faces.</li>
      <li class="bulletList">A new shader</li>
      <li class="bulletList">Loading a cubemap texture from a file</li>
    </ul>
    <p class="normal">We start with creating a new vertex type called <code class="inlineCode">OGLSkyboxVertex</code> and a new mesh type called <code class="inlineCode">OGLSkyboxMesh</code> in the <code class="inlineCode">OGLRenderData.h</code> file in the <code class="inlineCode">opengl</code> folder:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">struct</span> <span class="hljs-title">OGLSkyboxVertex</span> {
  glm::<span class="hljs-type">vec4</span> position = glm::<span class="hljs-type">vec4</span>(<span class="hljs-number">0.0f</span>);
};
 <span class="hljs-keyword">struct</span> <span class="hljs-title">OGLSkyboxMesh</span> {
  std::vector&lt;OGLSkyboxVertex&gt; vertices{};
};
</code></pre>
    <p class="normal">As always, for Vulkan, the two new <code class="inlineCode">struct</code> elements must be added to the <code class="inlineCode">VkRenderData.h</code> file in the <code class="inlineCode">vulkan</code> folder. For all the details of the Vulkan implementation, check the renderer class file, <code class="inlineCode">VkRenderer.cpp</code>.</p>
    <p class="normal">While we could reuse the vertex buffer of the models, doing so would waste a lot of resources since the cube only needs the position data for the vertices. The new vertex buffer class called <code class="inlineCode">SkyboxBuffer</code> uses only the <code class="inlineCode">position</code> element of the new vertex, <code class="inlineCode">struct</code> <code class="inlineCode">OGLSkyboxVertex</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">glVertexAttribPointer</span>(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, GL_FLOAT, GL_FALSE,
    <span class="hljs-built_in">sizeof</span>(OGLSkyboxVertex),
   (<span class="hljs-type">void</span>*) <span class="hljs-built_in">offsetof</span>(OGLSkyboxVertex, position));
  <span class="hljs-built_in">glEnableVertexAttribArray</span>(<span class="hljs-number">0</span>);
</code></pre>
    <p class="normal">For the cube model, we create a class called <code class="inlineCode">SkyboxModel</code> returning an <code class="inlineCode">OGLSkyboxMesh</code> consisting of 36 <a id="_idIndexMarker876"/>vertices, using two triangles for each side. In all three axes, the model coordinates are either <code class="inlineCode">1.0</code> or <code class="inlineCode">-1.0</code>, defining a unit cube.</p>
    <p class="normal">The new vertex shader named <code class="inlineCode">skybox.vert</code> outputs a <code class="inlineCode">vec3</code> with 3-dimensional texture coordinates. We need 3-dimensional coordinates here since we are inside a cube:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> texCoord;
</code></pre>
    <p class="normal">In the <code class="inlineCode">main()</code> method of the vertex shader, we invert the projection matrix and transpose the view matrix first:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-type">mat4</span> inverseProjection = <span class="hljs-built_in">inverse</span>(projection);
  <span class="hljs-type">mat3</span> inverseView = <span class="hljs-built_in">transpose</span>(<span class="hljs-type">mat3</span>(view));
</code></pre>
    <p class="normal">For the view matrix, we can use a cheaper transpose operation instead of taking the inverse matrix since we need to get rid of the translational part to stop the cube moving around with the camera.</p>
    <p class="normal">By multiplying the inverse matrices with the incoming point positions of the cube, we calculate the texture coordinates in world space:</p>
    <pre class="programlisting code"><code class="hljs-code">  texCoord = inverseView * (inverseProjection * aPos).xyz;
</code></pre>
    <p class="normal">Now, the texture coordinates to sample are from the inside of the cube, as shown in Figure <em class="italic">14.12</em>.</p>
    <p class="normal">As the last step for the vertex shader, we set the GLSL-internal variable <code class="inlineCode">gl_Position</code> to the incoming vertex position:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-built_in">gl_Position</span> = aPos.xyww;
</code></pre>
    <p class="normal">By setting the <code class="inlineCode">z</code> component of <code class="inlineCode">gl_Position</code> to the value of the <code class="inlineCode">w</code> component, we make sure to draw the pixels of the cubemap on the far-Z plane, creating a background that will not be overwritten by other pixels.</p>
    <p class="normal">The new fragment shader, <code class="inlineCode">skybox.frag</code>, uses the incoming texture coordinates to look up the texture data in the cubemap:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> texCoord;
<span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;
<span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> tex;
<span class="hljs-type">void</span> main() {
  FragColor = <span class="hljs-built_in">texture</span>(tex, texCoord);
}
</code></pre>
    <p class="normal">Please note that the type of the texture <code class="inlineCode">tex</code> is a <code class="inlineCode">samplerCube</code> and not a <code class="inlineCode">sampler2D</code> like on the other fragment shaders.</p>
    <p class="normal">Loading the cubemap<a id="_idIndexMarker877"/> texture is done in the <code class="inlineCode">Texture</code> class. In the new <code class="inlineCode">loadCubemapTexture()</code> method, we load an image shown in <em class="italic">Figure 14.1</em>3 and extract the six images. And since the values of the values of the texture map side definitions are in ascending order, we can just use the first side definition <code class="inlineCode">GL_TEXTURE_CUBE_MAP_POSITIVE_X</code> and add an integer value for the remaining sides to upload:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_CUBE_MAP_POSITIVE_X + face, <span class="hljs-number">0</span>, GL_SRGB8_ALPHA8, cubeFaceWidth, cubeFaceHeight, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_BYTE, subImage.<span class="hljs-built_in">data</span>());
</code></pre>
    <p class="normal">For the full implementation of the cubemap texture loading, please check the details in the <code class="inlineCode">Texture</code> class.</p>
    <h3 id="_idParaDest-451" class="heading-3">Drawing the skybox</h3>
    <p class="normal">Bringing the skybox to the<a id="_idIndexMarker878"/> screen is now done in two steps. First, we upload the unit cube model data to the vertex buffer in the <code class="inlineCode">init()</code> method of the <code class="inlineCode">OGLRenderer.cpp</code> renderer class file:</p>
    <pre class="programlisting code"><code class="hljs-code">  mSkyboxModel.<span class="hljs-built_in">init</span>();
  OGLSkyboxMesh skyboxMesh = mSkyboxModel.<span class="hljs-built_in">getVertexData</span>();
  mSkyboxBuffer.<span class="hljs-built_in">uploadData</span>(skyboxMesh.vertices);
</code></pre>
    <p class="normal">Then, before drawing the level data, we draw the skybox by using the new shader, binding the texture and drawing the cube from the vertex buffer:</p>
    <pre class="programlisting code"><code class="hljs-code">  mSkyboxShader.<span class="hljs-built_in">use</span>();
  mSkyboxTexture.<span class="hljs-built_in">bindCubemap</span>();
  mSkyboxBuffer.<span class="hljs-built_in">bindAndDraw</span>();
  mSkyboxTexture.<span class="hljs-built_in">unbindCubemap</span>();
</code></pre>
    <p class="normal">For Vulkan, we also upload the skybox model and the texture in the <code class="inlineCode">init()</code> method of the <code class="inlineCode">VkRenderData.cpp</code> file, bind the skybox pipeline, and draw the skybox model before the level data in the <code class="inlineCode">draw()</code> method.</p>
    <p class="normal">For both OpenGL and Vulkan renderers, a simple change should be made when drawing the skybox as the first object: disabling the depth test function. Without the depth test, the skybox texture overwrites all values of the previous color buffer, acting as the global background for the remaining objects, such as level data and instances. And that’s all.</p>
    <p class="normal">If everything was added <a id="_idIndexMarker879"/>correctly, the new and glorious sky above the level can be seen in <em class="italic">Figure 14.15</em> (the image is made from glTF level created by Zarudko (<a href="https://skfb.ly/6QYJw"><span class="url">https://skfb.ly/6QYJw</span></a>) using a texture created by Jockum Skoglund (aka hipshot – <a href="https://opengameart.org/content/stormy-days-skybox"><span class="url">https://opengameart.org/content/stormy-days-skybox</span></a>) as the skybox):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_15.png" alt="" width="1270" height="715"/></figure>
    <p class="packt_figref">Figure 14.15: Example level with an activated skybox</p>
    <p class="normal">As you can see in <em class="italic">Figure 14.15</em>, the skybox brings a real-world feel to levels with open areas. And since the cube does not move when the view changes like the level data, the illusion of an infinitely distant sky is created.</p>
    <p class="normal">But even with great graphics and cool sound effects and music, there’s room for improvement. The environment of the virtual world is still somehow static, so let’s add changes to the world itself.</p>
    <h1 id="_idParaDest-452" class="heading-1">Extending immersion with daytime and weather</h1>
    <p class="normal">Although they are <a id="_idIndexMarker880"/>natural phenomena in our lives, the cycle between day and night, weather effects, and different seasons are rarely used in computer games. But all these aspects can be a great boost for immersion in a game. Slight changes to the virtual world depending on an internal clock may help to create an environment that a player wants to stay in for a much longer time to experience the full cycle.</p>
    <h2 id="_idParaDest-453" class="heading-2">Adding a day/night cycle</h2>
    <p class="normal">A day/night cycle adds<a id="_idIndexMarker881"/> some sort of familiarity to a game. Seeing the sun rise or enjoying a colorful sunset, watching the changes when running through the world around noon or late at night… every aspect will remind the player of being in a more realistic world. And if not only the light changes, but also other characters and animals react to the time of day, the immersion will become better and better. For instance, it may be good to see some animals only at night, and kids only in the morning, characters appearing at work at some time and leaving for a pub in the afternoon.</p>
    <p class="normal">The in-game time could be running much faster than real time, reducing an entire day to a couple of minutes. Such a speedup can help if events that are frequently needed only occur at a specific time of the day.</p>
    <p class="normal">One of the most popular<a id="_idIndexMarker882"/> examples of the day/night cycle is Minecraft. A full day in Minecraft lasts 20 minutes by default, split into a 10-minute day and a 10-minute night. And since the light level changes, enemy spawning and food and tree growing behave completely differently in the day and the night.</p>
    <p class="normal"><em class="italic">Figure 14.16</em> shows the same spot in our application at noon and at night:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_16.png" alt="" width="1422" height="725"/></figure>
    <p class="packt_figref">Figure 14.16: Day and night in the example code from <a href=""><em class="italic">Chapter 14</em></a></p>
    <p class="normal">As you can see in <em class="italic">Figure 14.16</em>, even a simple change in the overall brightness of the virtual world could make an enormous difference. And changing more properties of the world depending on the time of day will bring more immersion for the player.</p>
    <h2 id="_idParaDest-454" class="heading-2">Allowing forward time travel</h2>
    <p class="normal">When working with time, one<a id="_idIndexMarker883"/> fact should not be underestimated: the time waiting for an event to happen can be boring and passes slowly. Instead of keeping the player waiting for the entire day or night to pass, special “time travel” events could be added, such as sleeping through the night, or waiting at a fireplace to let the time pass, having the game fast-forwarding the in-game time.</p>
    <h2 id="_idParaDest-455" class="heading-2">Playing in real time</h2>
    <p class="normal">Thinking about the time in<a id="_idIndexMarker884"/> a game, the idea of synchronizing the time in the virtual world to the time of the real world can be an interesting option. Only a few games utilize such a feature. Also, solving tasks or quests may be more complicated if they are bound to a special time of the day. But being “now” in a game may be fun.</p>
    <h2 id="_idParaDest-456" class="heading-2">Worshipping the weather god</h2>
    <p class="normal">Not only may the time of day change the world, but weather changes can also greatly influence characters, animals, and the environment. During a thunderstorm, the best advice is to stay inside, heavy rain may be so<a id="_idIndexMarker885"/> loud that other sounds never reach the player’s ears, and fresh snow will also absorb noises. So, roaming around in various weather states can give entirely different impressions of the same world.</p>
    <p class="normal">Environmental changes such as the addition of fog also change the perception of the virtual world.</p>
    <p class="normal"><em class="italic">Figure 14.17</em> shows different types of fog in our application:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_17.png" alt="" width="1455" height="742"/></figure>
    <p class="packt_figref">Figure 14.17: The effect of fog in the example code from <a href=""><em class="italic">Chapter 14</em></a></p>
    <p class="normal">On the left side of <em class="italic">Figure 14.17</em>, the virtual world is completely without fog, showing a clear day. In the middle of <em class="italic">Figure 14.17</em>, heavy fog was added, causing the world to fade out after a short distance. Fog was used in several old games to hide the appearance and disappearance of objects due to rendering limitations in early game engines. Finally, on the right side of <em class="italic">Figure 14.17</em>, the light color was adjusted to a green tone, creating the illusion of toxic fog in the streets of the map.</p>
    <h2 id="_idParaDest-457" class="heading-2">Listening to the oracle of seasons</h2>
    <p class="normal">The next evolutionary step after a day/night cycle and weather would be the implementation of the four seasons. The rotation<a id="_idIndexMarker886"/> between Spring, Summer, Fall, and Winter is a great opportunity to bring even more reality into the virtual world as the actions of characters or the appearance of animals will change throughout the year.</p>
    <p class="normal">Like the length of the in-game day, a virtual year should be shortened to a reasonable amount of real time, or a forward time travel functionality should be allowed if all tasks in the current season have been finished. Letting the player wait for no reason will kill their enthusiasm.</p>
    <p class="normal">A good example of the changing world properties depending on the season is “Legend of Zelda: Oracle of Seasons” by Nintendo for the GameBoy Color. Despite the age of the game, the changes of the seasons have been implemented with great detail, allowing the player to enter some areas of the world only in specific<a id="_idIndexMarker887"/> seasons. For instance, rivers are only frozen in Winter and snow fields elevate the parts of the landscape, while only in Summer, flower tendrils enable Link to climb up walls.</p>
    <p class="normal">In “Stardew Valley” by Eric Barone, seasons are also a key element of the gameplay. Each of the four seasons influences different parts of the game, like crop growth. A season is 28 in-game days long, and by accelerating the time, an entire year in Stardew Valley elapses in 26 hours of in-game time.</p>
    <p class="normal">For the application, we will create simple day/night light changes and fog as examples. Let’s start with day and night.</p>
    <h2 id="_idParaDest-458" class="heading-2">Hands-on: Adding day and night</h2>
    <p class="normal">Changing the light source’s color and position is easy. Most of the fragment shaders already contain a fixed light source definition to allow better visualizations of the instances and the level data.</p>
    <h3 id="_idParaDest-459" class="heading-3">Implementing light control</h3>
    <p class="normal">As the first step, we<a id="_idIndexMarker888"/> add two new variables called <code class="inlineCode">lightPos</code> and <code class="inlineCode">lightColor</code> to the <code class="inlineCode">Matrices</code> <code class="inlineCode">uniform</code> in all vertex and fragment shaders where <code class="inlineCode">Matrices</code> exists:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">std140</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">uniform</span> Matrices {
  ...
<span class="code-highlight"><strong class="hljs-slc">  </strong><strong class="hljs-type-slc">vec4</strong><strong class="hljs-slc"> lightPos;</strong></span>
<span class="code-highlight"><strong class="hljs-slc">  </strong><strong class="hljs-type-slc">vec4</strong><strong class="hljs-slc"> lightColor;</strong></span>
};
</code></pre>
    <p class="normal">In <code class="inlineCode">lightPos</code>, we will hand over the current position of the light source, allowing us to simulate the position of the Sun or Moon in the virtual world, and in <code class="inlineCode">lightColor</code>, we transport the color of the light source to the GPU, enabling us to simulate sunrise, noon, sunset, and so on.</p>
    <p class="normal">Since we defined the uniform buffer containing the view and projection matrix on the CPU to use <code class="inlineCode">glm::mat4</code> as the data type, we must add the two <code class="inlineCode">glm::vec4</code> vectors for the light position and color as the first two elements of a <code class="inlineCode">glm::mat4</code> that will be uploaded to the GPU before drawing the frame:</p>
    <pre class="programlisting code"><code class="hljs-code">  glm::<span class="hljs-type">mat4</span> lightMatrix = glm::<span class="hljs-type">mat4</span>(lightPos, lightColor,
    glm::<span class="hljs-type">vec4</span>(), glm::<span class="hljs-type">vec4</span>());
  matrixData.emplace_back(lightMatrix);
</code></pre>
    <p class="normal">Now all fragment shaders containing the light source definitions can be adjusted with a better light control for the surfaces.</p>
    <p class="normal">We start the new shader code in the <code class="inlineCode">main()</code> method by defining the ambient light level:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-type">float</span> ambientStrength = <span class="hljs-number">0.1</span>;
  <span class="hljs-type">vec3</span> ambient = ambientStrength * <span class="hljs-built_in">max</span>(<span class="hljs-type">vec3</span>(lightColor),
    <span class="hljs-type">vec3</span>(<span class="hljs-number">0.05</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">0.05</span>));
</code></pre>
    <p class="normal">The ambient light level is <a id="_idIndexMarker889"/>used to simulate the light scattering from other surfaces, enabling some sort of minimal lighting in the virtual world. By limiting the minimal ambient light, we also prevent the resulting picture from becoming pitch black.</p>
    <p class="normal">Next, we calculate the diffuse part by using the angle between the triangle normal and the direction of the light source:</p>
    <pre class="programlisting code"><code class="hljs-code">  <span class="hljs-type">vec3</span> norm = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">vec3</span>(normal));
  <span class="hljs-type">vec3</span> lightDir = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">vec3</span>(lightPos));
  <span class="hljs-type">float</span> diff = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(norm, lightDir), <span class="hljs-number">0.0</span>);
  <span class="hljs-type">vec3</span> diffuse = diff * <span class="hljs-type">vec3</span>(lightColor);
</code></pre>
    <p class="normal">The diffuse lighting of a surface changes with the angle between the surface and the light source. As the dot product of two normalized vectors equals the cosine of the angle between the two vectors, we can use the result of the <code class="inlineCode">dot()</code> call directly as a multiplier of the light source color.</p>
    <p class="normal">As the last step for the fragment shader code changes, we add up ambient and diffuse light and multiply the resulting light value by texture data and vertex color:</p>
    <pre class="programlisting code"><code class="hljs-code">  FragColor = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">min</span>(ambient + diffuse, <span class="hljs-type">vec3</span>(<span class="hljs-number">1.0</span>)), <span class="hljs-number">1.0</span>)*
    <span class="hljs-built_in">texture</span>(tex, texCoord) * color;
</code></pre>
    <p class="normal">We can now control the position and color of the light source from the application, and by sending a spherical position and a color, various times of the day can be simulated.</p>
    <h3 id="_idParaDest-460" class="heading-3">Adding a UI control</h3>
    <p class="normal">To control the light values, a <a id="_idIndexMarker890"/>new UI section will be created, enabling fine-grained settings of all light-related values. <em class="italic">Figure 14.18</em> shows the new <strong class="screenText">Environment</strong> section in the <code class="inlineCode">UserInterface</code> class:</p>
    <figure class="mediaobject"><img src="../Images/figure_14_18.png" alt="" width="892" height="322"/></figure>
    <p class="packt_figref">Figure 14.18: UI controls for light parameters and skybox</p>
    <p class="normal">By splitting the light angle into east/west and north/south, we can move the light around to any position of the virtual sky. The light intensity can be used to lower the overall brightness of the light without manually touching the color values.</p>
    <p class="normal">With the separate light color values, we can adjust the light to match the natural colors of the Sun or the Moon, at least within the limitations of the available color space, and by using a set of predefined color values, we<a id="_idIndexMarker891"/> can set the light color, intensity, and position immediately to a specific time of the day.</p>
    <p class="normal"><em class="italic">Figure 14.19</em> shows three different light settings for the virtual world (this image is created using the map by Zarudko (<a href="https://skfb.ly/6QYJw"><span class="url">https://skfb.ly/6QYJw</span></a>) and the skybox image is by Jockum Skoglund (aka hipshot – <a href="https://opengameart.org/content/stormy-days-skybox"><span class="url">https://opengameart.org/content/stormy-days-skybox</span></a>)):</p>
    <figure class="mediaobject"><img src="../Images/figure_14_19.png" alt="" width="1255" height="636"/></figure>
    <p class="packt_figref">Figure 14.19: The virtual world in the morning, at noon, and in the evening</p>
    <p class="normal">You can see in <em class="italic">Figure 14.19</em> that just changing the color of the light source can create entirely different moods in the virtual world. Combined with the skybox from the <em class="italic">Enhancing visuals</em> section, you can already create truly immersive worlds.</p>
    <h1 id="_idParaDest-461" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we explored ideas and tools to show how to upgrade the current animation editor to a small game engine with a built-in editor.</p>
    <p class="normal">First, we looked at a couple of audio libraries and when to play sound effects and music in a game. Sound effects and music are essential parts of the player’s experience, creating a basic form of immersion as the experience of the real world will be transferred to the virtual world.</p>
    <p class="normal">Then, we explored visual enhancements to the graphics of the application. Extending the basic renderer with transparency, a skybox, dynamic lights and shadows, realistic water, and post-processing effects such as God rays and motion blur will bring the visuals to the next level. Even though it’s optional due to the limited target group, adding support for ray tracing and VR could become viable options as both features are a big step forward in terms of visual quality and immersion.</p>
    <p class="normal">As the last step, we explored a day/night cycle, weather, and seasons as elements to change the environment of the virtual world. Already, a simple cycle of a day adds a lot of interesting opportunities to the virtual world, such as only meeting computer-controlled characters or animals at a certain time of the day or enemies that only appear at night. Weather effects and seasons also multiply the options to change behavior depending on the current environment.</p>
    <p class="normal">So... what to do next? Well, that’s completely up to you!</p>
    <p class="normal">You could start by learning how to use <strong class="keyWord">Blender</strong> to create your own animated characters, animals, objects, and levels. The created assets don’t have to be of the quality of recent games; even low-poly worlds are charming and have many fans. There are lots of books, tutorials, and videos available, handling many different art styles for virtual worlds.</p>
    <p class="normal">What about adding more objects? Vehicles and animals would enrich the virtual world, and doors and buttons lead to a lot more ways to interact with the world. For better gravity, you might even add a physics engine to the application, enabling other cool features such as force distribution on collisions between objects.</p>
    <p class="normal">You might also explore the world by using a camera with orthogonal projection. Watching the player, other characters, and the environment in an isometric projection or only from the side could open new ways of expressing a story. Since both the isometric projection and the side view are only different views of the three-dimensional world, all options mentioned in this chapter also apply when using the orthogonal projection.</p>
    <p class="normal">Another idea could be the creation of a storyline and quests for the player to handle. Forcing the player to move between various locations and interact with different characters to unlock more quests, items, or doors, or just to receive the next piece of the mental puzzle about a quest could engage the player to stay longer in your game.</p>
    <p class="normal">Or you could dive into the networking part of SDL and create a small network server, allowing you to explore the virtual worlds with your friends. Roaming around the levels and solving quests as a team is satisfying and brings new complexity to the quest system since you may or may not allow the players to use their shared knowledge of a quest over a long distance.</p>
    <p class="normal">But this is the most important next step: stay curious and experiment with the code.</p>
    <h1 id="_idParaDest-462" class="heading-1">Practical sessions</h1>
    <p class="normal">Here are some additions you could make to the code:</p>
    <ul>
      <li class="bulletList">Add a button to reload the music tracks from the asset folder.</li>
    </ul>
    <p class="normal-one">A nice-to-have feature to dynamically add or remove tracks.</p>
    <ul>
      <li class="bulletList">Add more sound effects for the instances.</li>
    </ul>
    <p class="normal-one">You could map a sound clip to every action of the instances, creating more realistic effects when controlling the selected instance.</p>
    <ul>
      <li class="bulletList">Play the step sound depending on the floor material.</li>
    </ul>
    <p class="normal-one">Here, you need to load more than one pair of footstep sounds for walking and running. The appropriate sound effect could be chosen by using the mesh type of the ground triangle as the index into the footstep sounds.</p>
    <ul>
      <li class="bulletList">Add sounds for nearby instances.</li>
    </ul>
    <p class="normal-one">The <code class="inlineCode">SDL_mixer</code> library allows us to set the volume and balance per channel. Using the distance and angle of the surrounding instances can be used to calculate the effective volume and direction of the sounds.</p>
    <ul>
      <li class="bulletList">Play ambient sound at special places on the map.</li>
    </ul>
    <p class="normal-one">Similar to the waypoint models, you could use small models as markers to play an ambient sound. And like the sounds for nearby instances, the volume and balance of the ambient sound can be adjusted to match the expectation.</p>
    <ul>
      <li class="bulletList">Add markers for music changes.</li>
    </ul>
    <p class="normal-one">This task is closely related to the ambient sound. You could use models and/or nodes to switch the music when your controlled instance enters a specific area of the map or interacts with other instances.</p>
    <ul>
      <li class="bulletList">Adjust level color and fog depending on the level location.</li>
    </ul>
    <p class="normal-one">Not only can the music be changed when roaming through the level; also, the light and fog settings can be adjusted. For instance, when entering a cave, the ambient light can be lowered and the fog density can be raised.</p>
    <h1 id="_idParaDest-463" class="heading-1">Additional resources</h1>
    <ul>
      <li class="bulletList">SDL: <a href="https://www.libsdl.org%0D%0A"><span class="url">https://www.libsdl.org</span></a></li>
      <li class="bulletList">OpenAL Soft: <a href="https://github.com/kcat/openal-soft%0D%0A"><span class="url">https://github.com/kcat/openal-soft</span></a></li>
      <li class="bulletList">PortAudio: <a href="https://www.portaudio.com%0D%0A"><span class="url">https://www.portaudio.com</span></a></li>
      <li class="bulletList">FMOD: <a href="https://www.fmod.com%0D%0A"><span class="url">https://www.fmod.com</span></a></li>
      <li class="bulletList"><em class="italic">Game Physics Engine Development</em> by <em class="italic">Ian Millington</em>, published by <em class="italic">CRC Press</em>: ISBN 978-0123819765</li>
      <li class="bulletList"><em class="italic">Game Physics by David H. Eberly</em>, published by <em class="italic">Morgan Kaufmann</em>: ISBN 978-0123749031</li>
      <li class="bulletList">Open-source physics engine: <a href="https://www.tapirgames.com/blog/open-source-physics-engines%0D%0A"><span class="url">https://www.tapirgames.com/blog/open-source-physics-engines</span></a></li>
      <li class="bulletList">Vulkan examples by Sascha Willems: <a href="https://github.com/SaschaWillems/Vulkan%0D%0A"><span class="url">https://github.com/SaschaWillems/Vulkan</span></a></li>
      <li class="bulletList">Ordered transparency: <a href="https://learnopengl.com/Advanced-OpenGL/Blending%0D%0A"><span class="url">https://learnopengl.com/Advanced-OpenGL/Blending</span></a></li>
      <li class="bulletList">Order-independent transparency: <a href="https://github.com/nvpro-samples/vk_order_independent_transparency%0D%0A"><span class="url">https://github.com/nvpro-samples/vk_order_independent_transparency</span></a></li>
      <li class="bulletList">OpenGL skybox: <a href="https://learnopengl.com/Advanced-OpenGL/Cubemaps%0D%0A"><span class="url">https://learnopengl.com/Advanced-OpenGL/Cubemaps</span></a></li>
      <li class="bulletList">How to create cubemaps: <a href="https://paulbourke.net/panorama/cubemaps/%0D%0A"><span class="url">https://paulbourke.net/panorama/cubemaps/</span></a></li>
      <li class="bulletList">OpenGL multiple lights: <a href="https://learnopengl.com/Lighting/Multiple-lights%0D%0A"><span class="url">https://learnopengl.com/Lighting/Multiple-lights</span></a></li>
      <li class="bulletList">Multiple lights demo by Hannes Nevalainen: <a href="https://www.youtube.com/watch?v=vooznqE-XMM%0D%0A"><span class="url">https://www.youtube.com/watch?v=vooznqE-XMM</span></a></li>
      <li class="bulletList">OpenGL shadow maps: <a href="https://learnopengl.com/Guest-Articles/2021/CSM"><span class="url">https://learnopengl.com/Guest-Articles/2021/CSM</span></a></li>
      <li class="bulletList">WebGL water simulation: <a href="https://madebyevan.com/webgl-water/%0D%0A"><span class="url">https://madebyevan.com/webgl-water/</span></a></li>
      <li class="bulletList">OpenGL realistic water: <a href="https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe%0D%0A"><span class="url">https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe</span></a></li>
      <li class="bulletList">OpenGL water caustics: <a href="https://medium.com/@martinRenou/real-time-rendering-of-water-caustics-59cda1d74aa%0D%0A"><span class="url">https://medium.com/@martinRenou/real-time-rendering-of-water-caustics-59cda1d74aa</span></a></li>
      <li class="bulletList">OpenGL lens flares: <a href="https://john-chapman.github.io/2017/11/05/pseudo-lens-flare.html%0D%0A"><span class="url">https://john-chapman.github.io/2017/11/05/pseudo-lens-flare.html</span></a></li>
      <li class="bulletList">OpenGL God rays: <a href="https://github.com/math-araujo/screen-space-godrays%0D%0A"><span class="url">https://github.com/math-araujo/screen-space-godrays</span></a></li>
      <li class="bulletList">OpenGL bloom effect: <a href="https://learnopengl.com/Advanced-Lighting/Bloom%0D%0A"><span class="url">https://learnopengl.com/Advanced-Lighting/Bloom</span></a></li>
      <li class="bulletList">OpenGL motion blur: <a href="https://www.nvidia.com/docs/io/8230/gdc2003_openglshadertricks.pdf%0D%0A"><span class="url">https://www.nvidia.com/docs/io/8230/gdc2003_openglshadertricks.pdf</span></a></li>
      <li class="bulletList">OpenGL depth of field: <a href="https://lettier.github.io/3d-game-shaders-for-beginners/depth-of-field.html%0D%0A"><span class="url">https://lettier.github.io/3d-game-shaders-for-beginners/depth-of-field.html</span></a></li>
      <li class="bulletList">OpenGL SSAO: <a href="https://lettier.github.io/3d-game-shaders-for-beginners/ssao.html%0D%0A"><span class="url">https://lettier.github.io/3d-game-shaders-for-beginners/ssao.html</span></a></li>
      <li class="bulletList">OpenGL SSR: <a href="https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html%0D%0A"><span class="url">https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html</span></a></li>
      <li class="bulletList">Vulkan raytracing: <a href="https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/%0D%0A"><span class="url">https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/</span></a></li>
      <li class="bulletList">OpenXR: <a href="https://www.khronos.org/openxr/%0D%0A"><span class="url">https://www.khronos.org/openxr/</span></a></li>
      <li class="bulletList">Godot XR Demo template: <a href="https://github.com/GodotVR/godot-xr-template%0D%0A"><span class="url">https://github.com/GodotVR/godot-xr-template</span></a></li>
      <li class="bulletList">Blender: <a href="https://www.blender.org%0D%0A"><span class="url">https://www.blender.org</span></a></li>
      <li class="bulletList">Open Game Art for assets: <a href="https://opengameart.org/%0D%0A"><span class="url">https://opengameart.org/</span></a></li>
    </ul>
    <h1 id="_idParaDest-464" class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers: <a href="https://packt.link/cppgameanimation%0D%0A"><span class="url">https://packt.link/cppgameanimation</span></a></p>
    <p class="normal"><img src="../Images/QR_code_Discord.png" alt="A qr code with black squares  AI-generated content may be incorrect." width="150" height="150"/></p>
  </div>
  <div id="_idContainer196" class="Basic-Text-Frame">
  </div>
</div></div></body></html>