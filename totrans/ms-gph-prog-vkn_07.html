<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer040">
<h1 class="chapter-number" id="_idParaDest-106"><a id="_idTextAnchor105"/>7</h1>
<h1 id="_idParaDest-107"><a id="_idTextAnchor106"/>Rendering Many Lights with Clustered Deferred Rendering</h1>
<p>Until now, our scene has been lit by a single point light. While this has worked fine so far as we focused our attention more on laying the foundations of our rendering engine, it’s not a very compelling and realistic use case. Modern games can have hundreds of lights in a given scene, and it’s important that the lighting stage is performed efficiently and within the budget of <span class="No-Break">a frame.</span></p>
<p>In this chapter, we will first describe the most common techniques that are used both in deferred and forward shading. We will highlight the pros and cons of each technique so that you can determine which one best fits <span class="No-Break">your needs.</span></p>
<p>Next, we are going to provide an overview of our G-buffer setup. While the G-buffer has been in place from the very beginning, we haven’t covered its implementation in detail. This is a good time to go into more detail, as the choice of a deferred renderer will inform our strategy for <span class="No-Break">clustered lighting.</span></p>
<p>Finally, we are going to describe our clustering algorithm in detail and highlight the relevant sections of the code. While the algorithm itself is not too complex, there are a lot of details that are important to get a <span class="No-Break">stable solution.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>A brief history of <span class="No-Break">clustered lighting</span></li>
<li>Our G-buffer setup <span class="No-Break">and implementation</span></li>
<li>Implementing clustered lighting using screen tiles <span class="No-Break">and Z-binning</span></li>
</ul>
<h1 id="_idParaDest-108"><a id="_idTextAnchor107"/>Technical requirements</h1>
<p>By the end of the chapter you will have a solid understanding of our G-buffer implementation. You will also learn how to implement a state of the art light clustering solution that can handle hundreds <span class="No-Break">of lights.</span></p>
<p>The code for this chapter can be found at the following <span class="No-Break">URL: </span><a href="https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter7"><span class="No-Break">https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter7</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor108"/>A brief history of clustered lighting</h1>
<p>In this section, we are <a id="_idIndexMarker332"/>going to explore the background of how clustered lighting came to be and how it has evolved over <span class="No-Break">the years.</span></p>
<p>In real-time applications, until the early 2000s, the most common way to handle lighting was by using the <a id="_idIndexMarker333"/>so-called <strong class="bold">forward rendering</strong>, a technique that renders each object on the screen with all the information needed, including light information. The problem with this approach is that it would limit the number of lights that could be processed to a low number, such as 4 or 8, a number that in the early 2000s would <span class="No-Break">be enough.</span></p>
<p>The concept of Deferred Rendering, and more specifically, shading the same pixel only once, was already pioneered by Michael Deering and colleagues in a seminal paper called <em class="italic">The triangle processor and normal vector shader: a VLSI system for high performance graphics</em> in 1988, even though the term <em class="italic">deferred</em> was still <span class="No-Break">not used.</span></p>
<p>Another key <a id="_idIndexMarker334"/>concept, the <strong class="bold">G-buffer</strong>, or <strong class="bold">geometric buffer</strong>, was pioneered by Takafumi Saito and Tokiichiro Takahashi <a id="_idIndexMarker335"/>in another pioneering paper, <em class="italic">Comprehensible Rendering of 3D Shapes</em>. In this paper, the authors cache depth and normals for each pixel to post-process the image – in this case, to add visual aids and comprehensibility to <span class="No-Break">the image.</span></p>
<p>Although the first commercial game with a deferred renderer was <em class="italic">Shrek</em> in 2001 on the original Xbox, it became increasingly popular with the game <em class="italic">Stalker</em> and its accompanying paper, <em class="italic">Deferred Shading in Stalker</em> (<a href="https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker">https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker</a>), and exploded in popularity with the CryEngine presentation at Siggraph 2010 called <em class="italic">Reaching the Speed of </em><span class="No-Break"><em class="italic">Light</em></span><span class="No-Break"> (</span><a href="http://advances.realtimerendering.com/s2010/Kaplanyan-CryEngine3%28SIGGRAPH%202010%20Advanced%20RealTime%20Rendering%20Course%29.pdf"><span class="No-Break">http://advances.realtimerendering.com/s2010/Kaplanyan-CryEngine3%28SIGGRAPH%202010%20Advanced%20RealTime%20Rendering%20Course%29.pdf</span></a><span class="No-Break">).</span></p>
<p>In the late 2000s/early 2010s, Deferred Rendering was all the rage, and basically, all engines were implementing some variations <span class="No-Break">of it.</span></p>
<p>Forward rendering made a comeback in 2012 when AMD launched a demo called <em class="italic">Leo</em> in which, thanks to the new <em class="italic">Compute Shaders</em> technology, they introduced the light list for each screen space tile and <span class="No-Break">created </span><span class="No-Break"><em class="italic">Forward+</em></span><span class="No-Break">.</span></p>
<p>The AMD Leo paper can be found <span class="No-Break">here:</span><span class="No-Break"> </span><a href="https://takahiroharada.files.wordpress.com/2015/04/forward_plus.pdf"><span class="No-Break">https://takahiroharada.files.wordpress.</span><span class="No-Break">com/2015/04/forward_plus.pdf</span></a><span class="No-Break">.</span></p>
<p>A few weeks after that paper, the first commercial game to use Forward+ was <em class="italic">Dirt Showdown</em>, but only the PC version, as consoles still did not have support for APIs that would help in that <span class="No-Break">area: </span><a href="https://web.archive.org/web/20210621112015/https://www.rage3d.com/articles/gaming/codemaster_dirt_showdown_tech_review/"><span class="No-Break">https://web.archive.org/web/20210621112015/https://www.rage3d.com/articles/gaming/codemaster_dirt_showdown_tech_review/</span></a><span class="No-Break">.</span></p>
<p>With this, the Forward+ technology came back into usage, as the light limitations were gone, and it added<a id="_idIndexMarker336"/> a lot of algorithmic exploration in different areas (such as post-process anti-aliasing for a deferred <span class="No-Break">depth prepass).</span></p>
<p>In the following years, more refined subdivision algorithms were developed, with tiles becoming clusters and moving from simple 2D screen space tiles to fully frustum-shaped <span class="No-Break">3D clusters.</span></p>
<p>This became famous with the <em class="italic">Just Cause 3</em> paper by Emil Persson, <a href="https://www.humus.name/Articles/PracticalClusteredShading.pdf">https://www.humus.name/Articles/PracticalClusteredShading.pdf</a>, and the concept was further enhanced by others for both deferred and forward <span class="No-Break">rendering (</span><a href="https://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf"><span class="No-Break">https://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf</span></a><span class="No-Break">).</span></p>
<p>Clustering has been a great idea, but the memory consumption of having a 3D grid can be big, especially with the increasing <span class="No-Break">rendering resolutions.</span></p>
<p>The current state of the art of clustering comes from Activision, which is our chosen solution, and we will see it in detail in the <em class="italic">Implementing light clusters</em> section of <span class="No-Break">this chapter.</span></p>
<p>Now that we have provided a brief historical overview of real-time light rendering techniques, we are going to go into more depth about the differences between forward and Deferred<a id="_idIndexMarker337"/> Rendering in the <span class="No-Break">next section.</span></p>
<h2 id="_idParaDest-110"><a id="_idTextAnchor109"/>Differences between forward and deferred techniques</h2>
<p>After talking <a id="_idIndexMarker338"/>about the history of forward and Deferred Rendering techniques, we want to highlight the key differences and talk about their common<a id="_idIndexMarker339"/> problem: <span class="No-Break"><strong class="bold">light assignment</strong></span><span class="No-Break">.</span></p>
<p>The main advantages of forward rendering are <span class="No-Break">as follows:</span></p>
<ul>
<li>Total freedom when <span class="No-Break">rendering materials</span></li>
<li>Same rendering path for opaque and <span class="No-Break">transparent objects</span></li>
<li>Support<a id="_idIndexMarker340"/> for <strong class="bold">Multi Sampled </strong><span class="No-Break"><strong class="bold">Anti-Aliasing</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">MSAA</strong></span><span class="No-Break">)</span></li>
<li>Lower memory bandwidth within <span class="No-Break">the GPU</span></li>
</ul>
<p>The main disadvantages of forward rendering are <span class="No-Break">as follows:</span></p>
<ul>
<li>A depth prepass could be necessary to reduce the number of fragments shaded. Without this preprocessing step, scenes that contain a large number of objects could waste a lot of processing time by shading fragments for objects that are not visible. For this reason, a pass that only writes to the depth buffer is executed at the beginning of <span class="No-Break">a frame.</span></li>
</ul>
<p>The <strong class="source-inline">depth-test</strong> function is then set to equal so that only the fragments for the visible objects will be shaded. Depending on the complexity of your scene, this pre-pass could be expensive, and in some cases, simplified geometry is used to reduce the cost of this pass at the expense of slightly less accurate results. You must also be careful and ensure that the Early-Z test is not disabled in the <span class="No-Break">graphics pipeline.</span></p>
<p>This happens when writing to the depth buffer from a fragment shader or when a fragment shader contains a <span class="No-Break">discard instruction.</span></p>
<ul>
<li>The complexity of shading a scene is the number of objects (<em class="italic">N</em>) multiplied by the number of lights (<em class="italic">L</em>). All the lights must be processed for each object as we don’t know in advance which lights affect a <span class="No-Break">given fragment.</span></li>
<li>Shaders become increasingly more complex, having to do a lot of operations and thus having a very high GPU register pressure (number of registers used), <span class="No-Break">impacting performance.</span></li>
</ul>
<p>Deferred Rendering (sometimes<a id="_idIndexMarker341"/> referred to as <strong class="bold">deferred shading</strong>) was introduced primarily to decouple the rendering of the geometry and the light computations. In Deferred Rendering, we create multiple render targets. Usually, we have a render target for albedo, normals, PBR parameters (roughness, metalness, and occlusion – see <a href="B18395_02.xhtml#_idTextAnchor030"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Improving Resources Management,</em> for more details), <span class="No-Break">and depth.</span></p>
<p>Once these render targets have been created, for each fragment we process the lights in the scene. We still have the same problem as before, since we still don’t know which lights affect a <a id="_idIndexMarker342"/>given shader; however, our scene complexity has gone from <em class="italic">N x L</em> to <em class="italic">N + </em><span class="No-Break"><em class="italic">L</em></span><span class="No-Break">.</span></p>
<p>The main <a id="_idIndexMarker343"/>advantages of deferred shading are <span class="No-Break">as follows:</span></p>
<ul>
<li>Decreased <span class="No-Break">shading complexity</span></li>
<li>No need for a <span class="No-Break">depth pre-pass</span></li>
<li>Less complex shaders, as writing information on the G-buffer and processing lights are <span class="No-Break">separate operations</span></li>
</ul>
<p>However, there are some disadvantages to this approach, <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">High memory usage</strong>: We<a id="_idIndexMarker344"/> listed three render targets that have to be stored in memory. With increasing resolutions of modern games, these start to add up, especially when more render targets are needed for other techniques – for example, motion vectors for <strong class="bold">Temporal Anti-Aliasing</strong> (<strong class="bold">TAA</strong>), which <a id="_idIndexMarker345"/>will be discussed in a later chapter. For this reason, developers tend to compress some of this data, which helps to reduce the amount of memory required by <span class="No-Break">the G-buffer.</span></li>
<li><strong class="bold">Loss of normals precision</strong>: Normals are usually encoded as full floats (or possibly as 16-bit floats) as part of the geometry. To save memory when writing the normals render target, these values get compressed to 8 bits, significantly reducing the accuracy of <span class="No-Break">these values.</span></li>
</ul>
<p>To further reduce memory usage, developers take advantage of the fact that normals are normalized. This allows us to store only two values and reconstruct the third. There are other techniques that can be used to compress normals, which will be referenced in the <em class="italic">Further reading</em> section. We will explain in detail the one we use in the <span class="No-Break">next section.</span></p>
<ul>
<li>Transparent objects need a separate pass and need to be shaded using a <span class="No-Break">forward technique.</span></li>
<li>Special materials need to have all their parameters packed into <span class="No-Break">the G-buffer.</span></li>
</ul>
<p>As you probably noticed, one problem is common to both techniques: we have to go through all the<a id="_idIndexMarker346"/> lights when processing an individual object or fragment. We are now going to describe the two most common techniques that are used to solve this issue: tiles <span class="No-Break">and clusters.</span></p>
<h3>Light tiles</h3>
<p>One approach to <a id="_idIndexMarker347"/>reducing the number of lights processed for a given fragment is to create a grid in screen space and determine which lights affect a given tile. When rendering the scene, we determine which tile the fragment we are shading belongs to and we iterate only over the lights that cover <span class="No-Break">that tile.</span></p>
<p>The following figure shows the debug visualization for a light in the scene (the green sphere) and the screen area that it covers (in yellow). We will use this data to determine which tiles are affected by a <span class="No-Break">given light.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer034">
<img alt="Figure 7.1 – The area covered by a point light in screen space" height="545" src="image/B8395_07_01.jpg" width="1090"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – The area covered by a point light in screen space</p>
<p>Building the tiles can be done on the CPU or with a compute shader on the GPU. Tile data can be stored in a flat array; we will explain this data structure in more detail later in <span class="No-Break">the chapter.</span></p>
<p>Traditional light tiles require a depth pre-pass to determine the minimum and maximum <em class="italic">Z</em> values. This approach can suffer from depth discontinuities; however, the final data structure is usually densely packed, meaning we are not <span class="No-Break">wasting memory.</span></p>
<h3>Light clusters</h3>
<p>Light clusters <a id="_idIndexMarker348"/>subdivide the frustum in a 3D grid. As for tiles, lights are assigned to each cell, and at render time, we only iterate over the lights that a given fragment <span class="No-Break">belongs to.</span></p>
<p>The following figure illustrates the shape of the clusters for one of the camera axes. Each cluster is composed of a <span class="No-Break">smaller frustum:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer035">
<img alt="Figure 7.2 – The frustum clusters covered by a point light" height="512" src="image/B8395_07_02.jpg" width="582"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – The frustum clusters covered by a point light</p>
<p>Lights can be stored in a 3D grid (a 3D texture, for instance) or more complex data structures – for<a id="_idIndexMarker349"/> example, a <strong class="bold">Bounded Volume Hierarchy</strong> (<strong class="bold">BVH</strong>) <span class="No-Break">or octree.</span></p>
<p>To build light clusters, we don’t need a depth pre-pass. Most implementations build <strong class="bold">Axis Aligned Bounding Boxes</strong> (<strong class="bold">AABBs</strong>) for <a id="_idIndexMarker350"/>each light and project them into clip space. This approach allows easy 3D lookups and, depending on the amount of memory that can be<a id="_idIndexMarker351"/> allocated for the data structure, it’s possible to achieve quite <span class="No-Break">accurate results.</span></p>
<p>In this section, we have highlighted the advantages and disadvantages of both forward and Deferred Rendering. We have introduced tiling and clustering techniques that can help reduce the <a id="_idIndexMarker352"/>number of lights that need to be processed for <span class="No-Break">each fragment.</span></p>
<p>In the next section, we are going to provide an overview of our <span class="No-Break">G-buffer implementation.</span></p>
<h1 id="_idParaDest-111"><a id="_idTextAnchor110"/>Implementing a G-buffer</h1>
<p>From the beginning<a id="_idIndexMarker353"/> of this project, we decided we would implement a deferred renderer. It’s one of the more common approaches, and some of the render targets will be needed in later chapters for <span class="No-Break">other techniques:</span></p>
<ol>
<li>The first step in setting up multiple render targets in Vulkan is to create the framebuffers – the textures that will store the G-buffer data – and the <span class="No-Break">render pass.</span></li>
</ol>
<p>This step is automated, thanks to the frame graph (see <a href="B18395_04.xhtml#_idTextAnchor064"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Implementing a Frame Graph</em>, for details); however, we want to highlight our use of a new Vulkan extension that simplifies render pass and framebuffer creation. The extension <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">VK_KHR_dynamic_rendering</strong></span><span class="No-Break">.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">This extension has become part of the core specification in Vulkan 1.3, so it’s possible to omit the <strong class="source-inline">KHR</strong> suffix on the data structures and <span class="No-Break">API calls.</span></p>
<ol>
<li value="2">With this extension, we don’t have to worry about creating the render pass and framebuffers ahead of time. We’ll start by analyzing the changes required when creating <span class="No-Break">a pipeline:</span><pre class="source-code">
VkPipelineRenderingCreateInfoKHR pipeline_rendering_create_info{</pre><pre class="source-code">
  VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO_KHR };</pre><pre class="source-code">
pipeline_rendering_create_info.viewMask = 0;</pre><pre class="source-code">
pipeline_rendering_create_info.colorAttachmentCount =</pre><pre class="source-code">
    creation.render_pass.num_color_formats;</pre><pre class="source-code">
pipeline_rendering_create_info.pColorAttachmentFormats</pre><pre class="source-code">
    = creation.render_pass.num_color_formats &gt; 0 ?</pre><pre class="source-code">
        creation.render_pass.color_formats : nullptr;</pre><pre class="source-code">
pipeline_rendering_create_info.depthAttachmentFormat =</pre><pre class="source-code">
    creation.render_pass.depth_stencil_format;</pre><pre class="source-code">
pipeline_rendering_create_info.stencilAttachmentFormat</pre><pre class="source-code">
    = VK_FORMAT_UNDEFINED;</pre><pre class="source-code">
pipeline_info.pNext = &amp;pipeline_rendering_create_info;</pre></li>
</ol>
<p>We have to<a id="_idIndexMarker354"/> populate a <strong class="source-inline">VkPipelineRenderingCreateInfoKHR</strong> structure with the number of attachments we are going to use and their format. We also need to specify the depth and stencil formats, <span class="No-Break">if used.</span></p>
<p>Once this structure has been filled, we chain it to the <strong class="source-inline">VkGraphicsPipelineCreateInfo</strong> structure. When using this extension we don’t populate the <span class="No-Break"><strong class="source-inline">VkGraphicsPipelineCreateInfo::renderPass</strong></span><span class="No-Break"> member.</span></p>
<ol>
<li value="3">At render time, instead of calling <strong class="source-inline">vkCmdBeginRenderPass</strong>, we call a new API, <strong class="source-inline">vkCmdBeginRenderingKHR</strong>. We start by creating an array to hold our <span class="No-Break"><strong class="source-inline">attachments</strong></span><span class="No-Break"> details:</span><pre class="source-code">
Array&lt;VkRenderingAttachmentInfoKHR&gt; color_attachments_info;</pre><pre class="source-code">
color_attachments_info.init( device-&gt;allocator,</pre><pre class="source-code">
    framebuffer-&gt;num_color_attachments,</pre><pre class="source-code">
        framebuffer-&gt;num_color_attachments );</pre></li>
<li>Next, we <a id="_idIndexMarker355"/>populate each entry with the details of <span class="No-Break">each attachment:</span><pre class="source-code">
for ( u32 a = 0; a &lt; framebuffer-&gt;</pre><pre class="source-code">
    num_color_attachments; ++a ) {</pre><pre class="source-code">
        Texture* texture = device-&gt;</pre><pre class="source-code">
            access_texture( framebuffer-&gt;</pre><pre class="source-code">
                color_attachments[a] );</pre><pre class="source-code">
    VkAttachmentLoadOp color_op = ...;</pre><pre class="source-code">
VkRenderingAttachmentInfoKHR&amp;</pre><pre class="source-code">
color_attachment_info = color_attachments_info[ a ];</pre><pre class="source-code">
color_attachment_info.sType =</pre><pre class="source-code">
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO_KHR;</pre><pre class="source-code">
color_attachment_info.imageView = texture-&gt;</pre><pre class="source-code">
    vk_image_view;</pre><pre class="source-code">
color_attachment_info.imageLayout =</pre><pre class="source-code">
    VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;</pre><pre class="source-code">
color_attachment_info.resolveMode =</pre><pre class="source-code">
    VK_RESOLVE_MODE_NONE;</pre><pre class="source-code">
color_attachment_info.loadOp = color_op;</pre><pre class="source-code">
color_attachment_info.storeOp =</pre><pre class="source-code">
    VK_ATTACHMENT_STORE_OP_STORE;</pre><pre class="source-code">
color_attachment_info.clearValue = render_pass-&gt;</pre><pre class="source-code">
    output.color_operations[ a ] ==</pre><pre class="source-code">
        RenderPassOperation::Enum::Clear ? clears[ 0 ]</pre><pre class="source-code">
            : VkClearValue{ };</pre><pre class="source-code">
}</pre></li>
<li>We have to <a id="_idIndexMarker356"/>fill a similar data structure for the <span class="No-Break"><strong class="source-inline">depth</strong></span><span class="No-Break"> attachment:</span><pre class="source-code">
VkRenderingAttachmentInfoKHR depth_attachment_info{</pre><pre class="source-code">
    VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO_KHR };</pre><pre class="source-code">
bool has_depth_attachment = framebuffer-&gt;</pre><pre class="source-code">
    depth_stencil_attachment.index != k_invalid_index;</pre><pre class="source-code">
if ( has_depth_attachment ) {</pre><pre class="source-code">
    Texture* texture = device-&gt;access_texture(</pre><pre class="source-code">
        framebuffer-&gt;depth_stencil_attachment );</pre><pre class="source-code">
    VkAttachmentLoadOp depth_op = ...;</pre><pre class="source-code">
depth_attachment_info.imageView = texture-&gt;</pre><pre class="source-code">
    vk_image_view;</pre><pre class="source-code">
depth_attachment_info.imageLayout =</pre><pre class="source-code">
    VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;</pre><pre class="source-code">
depth_attachment_info.resolveMode =</pre><pre class="source-code">
    VK_RESOLVE_MODE_NONE;</pre><pre class="source-code">
depth_attachment_info.loadOp = depth_op;</pre><pre class="source-code">
depth_attachment_info.storeOp =</pre><pre class="source-code">
    VK_ATTACHMENT_STORE_OP_STORE;</pre><pre class="source-code">
depth_attachment_info.clearValue = render_pass-&gt;</pre><pre class="source-code">
    output.depth_operation ==</pre><pre class="source-code">
        RenderPassOperation::Enum::Clear ? clears[ 1 ]</pre><pre class="source-code">
            : VkClearValue{ };</pre><pre class="source-code">
}</pre></li>
<li>Finally, we<a id="_idIndexMarker357"/> fill the <strong class="source-inline">VkRenderingInfoKHR</strong> structure that will be passed <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">vkCmdBeginRenderingKHR</strong></span><span class="No-Break">:</span><pre class="source-code">
VkRenderingInfoKHR rendering_info{</pre><pre class="source-code">
    VK_STRUCTURE_TYPE_RENDERING_INFO_KHR };</pre><pre class="source-code">
rendering_info.flags = use_secondary ?</pre><pre class="source-code">
    VK_RENDERING_CONTENTS_SECONDARY_COMMAND</pre><pre class="source-code">
        _BUFFERS_BIT_KHR : 0;</pre><pre class="source-code">
rendering_info.renderArea = { 0, 0, framebuffer-&gt;</pre><pre class="source-code">
    width, framebuffer-&gt;height };</pre><pre class="source-code">
rendering_info.layerCount = 1;</pre><pre class="source-code">
rendering_info.viewMask = 0;</pre><pre class="source-code">
rendering_info.colorAttachmentCount = framebuffer-&gt;</pre><pre class="source-code">
    num_color_attachments;</pre><pre class="source-code">
rendering_info.pColorAttachments = framebuffer-&gt;</pre><pre class="source-code">
    num_color_attachments &gt; 0 ?</pre><pre class="source-code">
        color_attachments_info.data : nullptr;</pre><pre class="source-code">
rendering_info.pDepthAttachment =</pre><pre class="source-code">
    has_depth_attachment ? &amp;depth_attachment_info :</pre><pre class="source-code">
        nullptr;</pre><pre class="source-code">
rendering_info.pStencilAttachment = nullptr;</pre></li>
</ol>
<p>Once we are done rendering, we are going to call <strong class="source-inline">vkCmdEndRenderingKHR</strong> instead <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">vkCmdEndRenderPass</strong></span><span class="No-Break">.</span></p>
<p>Now that we have set up our render targets, we are going to describe how they are used in our G-buffer shader. Our G-buffer has four render targets plus the depth buffer. As we mentioned<a id="_idIndexMarker358"/> in the previous section, there is no need for a depth pre-pass, although you might notice this was enabled in some of the earlier chapters for <span class="No-Break">testing purposes.</span></p>
<p>The first step is to declare multiple outputs in the <span class="No-Break">fragment shader:</span></p>
<pre class="source-code">
layout (location = 0) out vec4 color_out;
layout (location = 1) out vec2 normal_out;
layout (location = 2) out vec4
    occlusion_roughness_metalness_out;
layout (location = 3) out vec4 emissive_out;</pre>
<p>The location index must correspond to the order in which the attachments have been specified when calling <strong class="source-inline">vkCmdBeginRenderingKHR</strong> (or when creating the render pass and framebuffer objects). Writing to a given render target is done simply by writing to one of the variables we <span class="No-Break">just declared:</span></p>
<pre class="source-code">
colour_out = texture(global_textures[nonuniformEXT
    (albedo_texture)], uv);</pre>
<p>As we mentioned in the previous section, we must be conscious of memory usage. As you might have noticed, we only store two channels for normals. We use an octahedral encoding that allows storing only two values. We can reconstruct the full normal in the <span class="No-Break">lighting pass.</span></p>
<p>Here’s the <span class="No-Break">encoding function:</span></p>
<pre class="source-code">
vec2 octahedral_encode(vec3 n) {
    // Project the sphere onto the octahedron, and then
       onto the xy plane
    vec2 p = n.xy * (1.0f / (abs(n.x) + abs(n.y) +
        abs(n.z)));
    // Reflect the folds of the lower hemisphere over the
       diagonals
    return (n.z &lt; 0.0f) ? ((1.0 - abs(p.yx)) *
        sign_not_zero(p)) : p;
}</pre>
<p>And here is the<a id="_idIndexMarker359"/> <span class="No-Break">decoding function:</span></p>
<pre class="source-code">
vec3 octahedral_decode(vec2 f) {
    vec3 n = vec3(f.x, f.y, 1.0 - abs(f.x) - abs(f.y));
    float t = max(-n.z, 0.0);
    n.x += n.x &gt;= 0.0 ? -t : t;
    n.y += n.y &gt;= 0.0 ? -t : t;
    return normalize(n);
}</pre>
<p>The following table illustrates the data arrangement of our <span class="No-Break">G-buffer pass:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<img alt="Table 7.1 – G-buffer memory layout" height="229" src="image/B18395_07_Table_01.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.1 – G-buffer memory layout</p>
<p>Here are the<a id="_idIndexMarker360"/> screenshots for our <span class="No-Break">render targets:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<img alt="Figure 7.3 – From top to bottom: albedo, normals, and combined occlusion (red), roughness (green), and metalness (blue)" height="1815" src="image/B8395_07_03.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – From top to bottom: albedo, normals, and combined occlusion (red), roughness (green), and metalness (blue)</p>
<p>We could probably reduce the number of render targets further: we know that in the G-buffer pass, we are only shading opaque objects, so we don’t need the alpha channel. Also, nothing prevents us from mixing data for different render targets – for instance, we could have something like <span class="No-Break">the following:</span></p>
<ul>
<li><strong class="bold">RGBA8</strong>: <strong class="source-inline">r</strong>, <strong class="source-inline">g</strong>, <strong class="source-inline">b</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">normal_1</strong></span></li>
<li><strong class="bold">RGBA8</strong>: <strong class="source-inline">normal_2</strong>, <strong class="source-inline">roughness</strong>, <strong class="source-inline">metalness</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">occlusion</strong></span></li>
<li><span class="No-Break"><strong class="bold">RGBA8</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">emissive</strong></span></li>
</ul>
<p>We can also try to use different texture formats (<strong class="bold">R11G11B10</strong>, for example) to increase the accuracy of our data. We encourage you to experiment with different solutions and find the one that works best for your <span class="No-Break">use case!</span></p>
<p>In this section, we have introduced a new Vulkan extension that simplifies the creation and use of the render pass and framebuffer. We also provided details on the implementation<a id="_idIndexMarker361"/> of our G-buffer and highlighted potential optimizations. In the next section, we are going to look at the light clustering solution that we <span class="No-Break">have implemented.</span></p>
<h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>Implementing light clusters</h1>
<p>In this section, we <a id="_idIndexMarker362"/>are going to describe our implementation of the light clustering algorithm. It’s based on this presentation: <a href="https://www.activision.com/cdn/research/2017_Sig_Improved_Culling_final.pdf">https://www.activision.com/cdn/research/2017_Sig_Improved_Culling_final.pdf</a>. The main (and very smart) idea is to separate the <em class="italic">XY</em> plane from the <em class="italic">Z</em> range, combining the advantages of both tiling and clustering approaches. The algorithms are organized <span class="No-Break">as follows:</span></p>
<ol>
<li value="1">We sort the lights by their depth value in <span class="No-Break">camera space.</span></li>
<li>We then divide the depth range into bins of equal size, although a logarithmic subdivision might work better depending on your <span class="No-Break">depth range.</span></li>
<li>Next, we assign the lights to each bin if their bounding box falls within the bin range. We only store the minimum and maximum light index for a given bin, so we only need 16 bits for each bin, unless you need more than <span class="No-Break">65,535 lights!</span></li>
<li>We then divide the screen into tiles (8x8 pixels, in our case) and determine which lights cover a given tile. Each tile will store a bitfield representation for the <span class="No-Break">active lights.</span></li>
<li>Given a fragment that we want to shade, we determine the depth of the fragment and read the <span class="No-Break">bin index.</span></li>
<li>Finally, we iterate from the minimum to the maximum light index in that bin and read the corresponding tile to see whether the light is visible, this time using <em class="italic">x</em> and <em class="italic">y</em> coordinates to retrieve <span class="No-Break">the tile.</span></li>
</ol>
<p>This solution <a id="_idIndexMarker363"/>provides a very efficient way to loop through the active lights for a <span class="No-Break">given fragment.</span></p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor112"/>CPU lights assignment</h2>
<p>We’ll now look<a id="_idIndexMarker364"/> at the implementation. During<a id="_idIndexMarker365"/> each frame, we perform the <span class="No-Break">following steps:</span></p>
<ol>
<li value="1">We start by sorting the lights by their <span class="No-Break">depth value:</span><pre class="source-code">
float z_far = 100.0f;</pre><pre class="source-code">
for ( u32 i = 0; i &lt; k_num_lights; ++i ) {</pre><pre class="source-code">
    Light&amp; light = lights[ i ];</pre><pre class="source-code">
    vec4s p{ light.world_position.x,</pre><pre class="source-code">
        light.world_position.y,</pre><pre class="source-code">
            light.world_position.z, 1.0f };</pre><pre class="source-code">
    vec3s p_min = glms_vec3_add( light.world_position,</pre><pre class="source-code">
        glms_vec3_scale(</pre><pre class="source-code">
            light_camera_dir,</pre><pre class="source-code">
                -light.radius ) );</pre><pre class="source-code">
    vec3s p_max = glms_vec3_add( light.world_position,</pre><pre class="source-code">
        glms_vec3_scale(</pre><pre class="source-code">
            light_camera_dir,</pre><pre class="source-code">
                light.radius ) );</pre><pre class="source-code">
    vec4s projected_p = glms_mat4_mulv(</pre><pre class="source-code">
        world_to_camera, p );</pre><pre class="source-code">
    vec4s projected_p_min = glms_mat4_mulv(</pre><pre class="source-code">
        world_to_camera, p_min4 );</pre><pre class="source-code">
    vec4s projected_p_max = glms_mat4_mulv(</pre><pre class="source-code">
        world_to_camera, p_max4 );</pre><pre class="source-code">
   SortedLight&amp; sorted_light = sorted_lights[ i ];</pre><pre class="source-code">
    sorted_light.light_index = i;</pre><pre class="source-code">
    sorted_light.projected_z = ( -projected_p.z –</pre><pre class="source-code">
        scene_data.z_near ) / ( z_far –</pre><pre class="source-code">
            scene_data.z_near );</pre><pre class="source-code">
    sorted_light.projected_z_min = ( -</pre><pre class="source-code">
        projected_p_min.z - scene_data.z_near ) / (</pre><pre class="source-code">
            z_far - scene_data.z_near );</pre><pre class="source-code">
    sorted_light.projected_z_max = ( -</pre><pre class="source-code">
        projected_p_max.z - scene_data.z_near ) / (</pre><pre class="source-code">
            z_far - scene_data.z_near );</pre><pre class="source-code">
}</pre></li>
</ol>
<p>We compute<a id="_idIndexMarker366"/> the minimum and maximum point of <a id="_idIndexMarker367"/>the light sphere from the camera’s point of view. Notice that we use a closer <strong class="source-inline">far</strong> depth plane to gain precision in the <span class="No-Break">depth range.</span></p>
<ol>
<li value="2">To avoid having to sort the light list, we only sort the <span class="No-Break">light indices:</span><pre class="source-code">
qsort( sorted_lights.data, k_num_lights, sizeof(</pre><pre class="source-code">
    SortedLight ), sorting_light_fn );</pre><pre class="source-code">
u32* gpu_light_indices = ( u32* )gpu.map_buffer(</pre><pre class="source-code">
    cb_map );</pre><pre class="source-code">
if ( gpu_light_indices ) {</pre><pre class="source-code">
    for ( u32 i = 0; i &lt; k_num_lights; ++i ) {</pre><pre class="source-code">
        gpu_light_indices[ i ] = sorted_lights[ i ]</pre><pre class="source-code">
            .light_index;</pre><pre class="source-code">
    }</pre><pre class="source-code">
    gpu.unmap_buffer( cb_map );</pre><pre class="source-code">
}</pre></li>
</ol>
<p>This optimization allows us to upload the light array only once, while we only need to update the <span class="No-Break">light indices.</span></p>
<ol>
<li value="3">Next, we proceed with the tile assignment. We start by defining our bitfield array and some helper variables that will be used to compute the index within <span class="No-Break">the array:</span><pre class="source-code">
Array&lt;u32&gt; light_tiles_bits;</pre><pre class="source-code">
light_tiles_bits.init( context.scratch_allocator,</pre><pre class="source-code">
    tiles_entry_count, tiles_entry_count );</pre><pre class="source-code">
float near_z = scene_data.z_near;</pre><pre class="source-code">
float tile_size_inv = 1.0f / k_tile_size;</pre><pre class="source-code">
u32 tile_stride = tile_x_count * k_num_words;</pre></li>
<li>We <a id="_idIndexMarker368"/>then <a id="_idIndexMarker369"/>transform the light position in <span class="No-Break">camera space:</span><pre class="source-code">
for ( u32 i = 0; i &lt; k_num_lights; ++i ) {</pre><pre class="source-code">
    const u32 light_index = sorted_lights[ i ]</pre><pre class="source-code">
        .light_index;</pre><pre class="source-code">
    Light&amp; light = lights[ light_index ];</pre><pre class="source-code">
    vec4s pos{ light.world_position.x,</pre><pre class="source-code">
        light.world_position.y,</pre><pre class="source-code">
            light.world_position.z, 1.0f };</pre><pre class="source-code">
    float radius = light.radius;</pre><pre class="source-code">
    vec4s view_space_pos = glms_mat4_mulv(</pre><pre class="source-code">
        game_camera.camera.view, pos );</pre><pre class="source-code">
    bool camera_visible = view_space_pos.z - radius &lt;</pre><pre class="source-code">
        game_camera.camera.near_plane;</pre><pre class="source-code">
    if ( !camera_visible &amp;&amp;</pre><pre class="source-code">
        context.skip_invisible_lights ) {</pre><pre class="source-code">
        continue;</pre><pre class="source-code">
    }</pre></li>
</ol>
<p>If the light is behind the camera, we don’t do any <span class="No-Break">further processing.</span></p>
<ol>
<li value="5">Next, we <a id="_idIndexMarker370"/>compute the corners of the AABB <a id="_idIndexMarker371"/>projected to <span class="No-Break">clip space:</span><pre class="source-code">
for ( u32 c = 0; c &lt; 8; ++c ) {</pre><pre class="source-code">
    vec3s corner{ ( c % 2 ) ? 1.f : -1.f, ( c &amp; 2 ) ?</pre><pre class="source-code">
        1.f : -1.f, ( c &amp; 4 ) ? 1.f : -1.f };</pre><pre class="source-code">
    corner = glms_vec3_scale( corner, radius );</pre><pre class="source-code">
    corner = glms_vec3_add( corner, glms_vec3( pos ) );</pre><pre class="source-code">
    vec4s corner_vs = glms_mat4_mulv(</pre><pre class="source-code">
        game_camera.camera.view,</pre><pre class="source-code">
            glms_vec4( corner, 1.f ) );</pre><pre class="source-code">
    corner_vs.z = -glm_max(</pre><pre class="source-code">
        game_camera.camera.near_plane, -corner_vs.z );</pre><pre class="source-code">
    vec4s corner_ndc = glms_mat4_mulv(</pre><pre class="source-code">
        game_camera.camera.projection, corner_vs );</pre><pre class="source-code">
    corner_ndc = glms_vec4_divs( corner_ndc,</pre><pre class="source-code">
        corner_ndc.w );</pre><pre class="source-code">
    aabb_min.x = glm_min( aabb_min.x, corner_ndc.x );</pre><pre class="source-code">
    aabb_min.y = glm_min( aabb_min.y, corner_ndc.y );</pre><pre class="source-code">
    aabb_max.x = glm_max( aabb_max.x, corner_ndc.x );</pre><pre class="source-code">
    aabb_max.y = glm_max( aabb_max.y, corner_ndc.y );</pre><pre class="source-code">
}</pre><pre class="source-code">
aabb.x = aabb_min.x;</pre><pre class="source-code">
aabb.z = aabb_max.x;</pre><pre class="source-code">
aabb.w = -1 * aabb_min.y;</pre><pre class="source-code">
aabb.y = -1 * aabb_max.y;</pre></li>
<li>We then<a id="_idIndexMarker372"/> proceed to determine the size of<a id="_idIndexMarker373"/> the quad in <span class="No-Break">screen space:</span><pre class="source-code">
vec4s aabb_screen{ ( aabb.x * 0.5f + 0.5f ) * (</pre><pre class="source-code">
    gpu.swapchain_width - 1 ),</pre><pre class="source-code">
    ( aabb.y * 0.5f + 0.5f ) * (</pre><pre class="source-code">
    gpu.swapchain_height - 1 ),</pre><pre class="source-code">
    ( aabb.z * 0.5f + 0.5f ) * (</pre><pre class="source-code">
    gpu.swapchain_width - 1 ),</pre><pre class="source-code">
    ( aabb.w * 0.5f + 0.5f ) *</pre><pre class="source-code">
    ( gpu.swapchain_height - 1 ) };</pre><pre class="source-code">
f32 width = aabb_screen.z - aabb_screen.x;</pre><pre class="source-code">
f32 height = aabb_screen.w - aabb_screen.y;</pre><pre class="source-code">
if ( width &lt; 0.0001f || height &lt; 0.0001f ) {</pre><pre class="source-code">
    continue;</pre><pre class="source-code">
}</pre><pre class="source-code">
float min_x = aabb_screen.x;</pre><pre class="source-code">
float min_y = aabb_screen.y;</pre><pre class="source-code">
float max_x = min_x + width;</pre><pre class="source-code">
float max_y = min_y + height;</pre><pre class="source-code">
if ( min_x &gt; gpu.swapchain_width || min_y &gt;</pre><pre class="source-code">
    gpu.swapchain_height ) {</pre><pre class="source-code">
    continue;</pre><pre class="source-code">
}</pre><pre class="source-code">
if ( max_x &lt; 0.0f || max_y &lt; 0.0f ) {</pre><pre class="source-code">
    continue;</pre><pre class="source-code">
}</pre></li>
</ol>
<p>If the light is not visible on the screen, we move to the <span class="No-Break">next light.</span></p>
<ol>
<li value="7">The final <a id="_idIndexMarker374"/>step is to set the bit for the light we are <a id="_idIndexMarker375"/>processing on all the tiles <span class="No-Break">it covers:</span><pre class="source-code">
min_x = max( min_x, 0.0f );</pre><pre class="source-code">
min_y = max( min_y, 0.0f );</pre><pre class="source-code">
max_x = min( max_x, ( float )gpu.swapchain_width );</pre><pre class="source-code">
max_y = min( max_y, ( float )gpu.swapchain_height );</pre><pre class="source-code">
u32 first_tile_x = ( u32 )( min_x * tile_size_inv );</pre><pre class="source-code">
u32 last_tile_x = min( tile_x_count - 1, ( u32 )(</pre><pre class="source-code">
    max_x * tile_size_inv ) );</pre><pre class="source-code">
u32 first_tile_y = ( u32 )( min_y * tile_size_inv );</pre><pre class="source-code">
u32 last_tile_y = min( tile_y_count - 1, ( u32 )(</pre><pre class="source-code">
    max_y * tile_size_inv ) );</pre><pre class="source-code">
for ( u32 y = first_tile_y; y &lt;= last_tile_y; ++y ) {</pre><pre class="source-code">
    for ( u32 x = first_tile_x; x &lt;= last_tile_x; ++x</pre><pre class="source-code">
        ) {</pre><pre class="source-code">
              u32 array_index = y * tile_stride + x;</pre><pre class="source-code">
                  u32 word_index = i / 32;</pre><pre class="source-code">
                      u32 bit_index = i % 32;</pre><pre class="source-code">
    light_tiles_bits[ array_index + word_index ] |= (</pre><pre class="source-code">
        1 &lt;&lt; bit_index );</pre><pre class="source-code">
    }</pre><pre class="source-code">
}</pre></li>
</ol>
<p>We then upload all the light tiles and bin data to <span class="No-Break">the GPU.</span></p>
<p>At the end of this computation, we will have a bin table containing the minimum and maximum light ID for each depth slice. The following table illustrates an example of the values for the first <span class="No-Break">few slices:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<img alt="Table 7.2 – Example of the data contained in the depth bins" height="331" src="image/B18395_07_Table_02.jpg" width="1075"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.2 – Example of the data contained in the depth bins</p>
<p>The other<a id="_idIndexMarker376"/> data <a id="_idIndexMarker377"/>structure we computed is a 2D array, where each entry contains a bitfield tracking the active lights for the corresponding screen tile. The following table presents an example of the content of <span class="No-Break">this array:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<img alt="Table 7.3 – Example of the bitfield values tracking the active lights per tile" height="327" src="image/B18395_07_Table_03.jpg" width="1183"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.3 – Example of the bitfield values tracking the active lights per tile</p>
<p>In the preceding example, we have divided the screen into a 4x4 grid, and each tile entry has a bit set for every light that covers that tile. Note that each tile entry can be composed of multiple 32-bit values depending on the number of lights in <span class="No-Break">the scene.</span></p>
<p>In this section, we provided an overview of the algorithm we have implemented to assign lights<a id="_idIndexMarker378"/> to a given cluster. We then detailed the steps<a id="_idIndexMarker379"/> to implement the algorithm. In the next section, we are going to use the data we have just obtained to process lights on <span class="No-Break">the GPU.</span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor113"/>GPU light processing</h2>
<p>Now that we<a id="_idIndexMarker380"/> have<a id="_idIndexMarker381"/> all the data we need on the GPU, we can use it in our <span class="No-Break">lighting computation:</span></p>
<ol>
<li value="1">We start by determining which depth bin our fragment <span class="No-Break">belongs to:</span><pre class="source-code">
vec4 pos_camera_space = world_to_camera * vec4(</pre><pre class="source-code">
    world_position, 1.0 );</pre><pre class="source-code">
float z_light_far = 100.0f;</pre><pre class="source-code">
float linear_d = ( -pos_camera_space.z - z_near ) / (</pre><pre class="source-code">
    z_light_far - z_near );</pre><pre class="source-code">
int bin_index = int( linear_d / BIN_WIDTH );</pre><pre class="source-code">
uint bin_value = bins[ bin_index ];</pre><pre class="source-code">
uint min_light_id = bin_value &amp; 0xFFFF;</pre><pre class="source-code">
uint max_light_id = ( bin_value &gt;&gt; 16 ) &amp; 0xFFFF;</pre></li>
<li>We extract the minimum and maximum light index, as they are going to be used in the light <span class="No-Break">computation loop:</span><pre class="source-code">
uvec2 position = gl_GlobalInvocationID.xy;</pre><pre class="source-code">
uvec2 tile = position / uint( TILE_SIZE );</pre><pre class="source-code">
uint stride = uint( NUM_WORDS ) *</pre><pre class="source-code">
    ( uint( resolution.x ) / uint( TILE_SIZE ) );</pre><pre class="source-code">
uint address = tile.y * stride + tile.x;</pre></li>
<li>We first <a id="_idIndexMarker382"/>determine<a id="_idIndexMarker383"/> the address in the tile bitfield array. Next, we check whether there are any lights in this <span class="No-Break">depth bin:</span><pre class="source-code">
if ( max_light_id != 0 ) {</pre><pre class="source-code">
    min_light_id -= 1;</pre><pre class="source-code">
    max_light_id -= 1;</pre></li>
<li>If <strong class="source-inline">max_light_id</strong> is <strong class="source-inline">0</strong>, it means we didn’t store any lights in this bin, so no lights will affect this fragment. Next, we loop over the lights for this <span class="No-Break">depth bin:</span><pre class="source-code">
    for ( uint light_id = min_light_id; light_id &lt;=</pre><pre class="source-code">
        max_light_id; ++light_id ) {</pre><pre class="source-code">
            uint word_id = light_id / 32;</pre><pre class="source-code">
            uint bit_id = light_id % 32;</pre></li>
<li>After we compute the word and bit index, we determine which lights from the depth bin also cover the <span class="No-Break">screen tile:</span><pre class="source-code">
        if ( ( tiles[ address + word_id ] &amp;</pre><pre class="source-code">
            ( 1 &lt;&lt; bit_id ) ) != 0 ) {</pre><pre class="source-code">
                uint global_light_index =</pre><pre class="source-code">
                    light_indices[ light_id ];</pre><pre class="source-code">
                Light point_light = lights[</pre><pre class="source-code">
                    global_light_index ];</pre><pre class="source-code">
                final_color.rgb +=</pre><pre class="source-code">
                    calculate_point_light_contribution</pre><pre class="source-code">
                      ( albedo, orm, normal, emissive,</pre><pre class="source-code">
                          world_position, V, F0, NoV,</pre><pre class="source-code">
                              point_light );</pre><pre class="source-code">
        }</pre><pre class="source-code">
    }</pre><pre class="source-code">
}</pre></li>
</ol>
<p>This concludes our<a id="_idIndexMarker384"/> light clustering algorithm. The shader code also<a id="_idIndexMarker385"/> contains an optimized version that makes use of the subgroup instructions to improve register utilization. There are plenty of comments to explain how <span class="No-Break">it works.</span></p>
<p>We covered a fair amount of code in this section, so don’t worry if some things were not clear on the first read. We started by describing the steps of the algorithm. We then explained how the lights are sorted in depth bins and how we determine the lights that cover a given tile on the screen. Finally, we showed how these data structures are used in the lighting shader to determine which lights affect a <span class="No-Break">given fragment.</span></p>
<p>Note that this technique can be used both in forward and Deferred Rendering. Now that we have a<a id="_idIndexMarker386"/> performant lighting solution, one element is sorely<a id="_idIndexMarker387"/> missing from our scene: shadows! This will be the topic for the <span class="No-Break">next chapter.</span></p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor114"/>Summary</h1>
<p>In this chapter, we have implemented a light clustering solution. We started by explaining forward and Deferred Rendering techniques and their main advantages and shortcomings. Next, we described two approaches to group lights to reduce the computation needed to shade a <span class="No-Break">single fragment.</span></p>
<p>We then outlined our G-buffer implementation by listing the render targets that we use. We detailed our use of the <strong class="source-inline">VK_KHR_dynamic_rendering</strong> extension, which allows us to simplify the render pass and framebuffer use. We also highlighted the relevant code in the G-buffer shader to write to multiple render targets, and we provided the implementation for our normal encoding and decoding. In closing, we suggested some optimizations to further reduce the memory used by our <span class="No-Break">G-buffer implementation.</span></p>
<p>In the last section, we described the algorithm we selected to implement light clustering. We started by sorting the lights by their depth value into depth bins. We then proceeded to store the lights that affect a given screen tile using a bitfield array. Finally, we made use of these two data structures in our lighting shader to reduce the number of lights that need to be evaluated for <span class="No-Break">each fragment.</span></p>
<p>Optimizing the lighting stage of any game or application is paramount to maintaining interactive frame rates. We described one possible solution, but other options are available, and we suggest you experiment with them to find the one that best suits your <span class="No-Break">use case!</span></p>
<p>Now that we have added many lights, the scene still looks flat as there's one important element missing: shadows. That's the topic for the <span class="No-Break">next chapter!</span></p>
<h1 id="_idParaDest-116"><a id="_idTextAnchor115"/>Further reading</h1>
<ul>
<li>Some history about the first Deferred Rendering in the <em class="italic">Shrek</em> game, <span class="No-Break">2001: </span><a href="https://sites.google.com/site/richgel99/the-early-history-of-deferred-shading-and-lighting"><span class="No-Break">https://sites.google.com/site/richgel99/the-early-history-of-deferred-shading-and-lighting</span></a></li>
<li>Stalker Deferred Rendering <span class="No-Break">paper: </span><a href="https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker"><span class="No-Break">https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker</span></a></li>
<li>This is one of the first papers that introduced the concept of clustered <span class="No-Break">shading: </span><a href="http://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf"><span class="No-Break">http://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf</span></a></li>
<li>These two presentations are often cited as the inspiration for <span class="No-Break">many implementations:</span><ul><li><a href="https://www.activision.com/cdn/research/2017_Sig_Improved_Culling_final.pdf"><span class="No-Break">https://www.activision.com/cdn/research/2017_Sig_Improved_Culling_final.pdf</span></a></li><li><a href="http://www.humus.name/Articles/PracticalClusteredShading.pdf"><span class="No-Break">http://www.humus.name/Articles/PracticalClusteredShading.pdf</span></a></li></ul></li>
<li>In this chapter, we only covered point lights, but in practice, many other types of lights are used (spotlights, area lights, polygonal lights, and a few others). This article describes a way to determine the visibility of a spotlight approximated by <span class="No-Break">a cone:</span><ul><li><a href="https://bartwronski.com/2017/04/13/cull-that-cone/"><span class="No-Break">https://bartwronski.com/2017/04/13/cull-that-cone/</span></a></li></ul></li>
<li>These presentations describe variants of the clustering techniques we described in <span class="No-Break">this chapter:</span><ul><li><a href="https://www.intel.com/content/dam/develop/external/us/en/documents/lauritzen-deferred-shading-siggraph-2010-181241.pdf"><span class="No-Break">https://www.intel.com/content/dam/develop/external/us/en/documents/lauritzen-deferred-shading-siggraph-2010-181241.pdf</span></a></li><li><a href="https://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf"><span class="No-Break">https://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf</span></a></li><li><a href="https://www.ea.com/frostbite/news/parallel-graphics-in-frostbite-current-future"><span class="No-Break">https://www.ea.com/frostbite/news/parallel-graphics-in-frostbite-current-future</span></a></li></ul></li>
</ul>
</div>
</div></body></html>