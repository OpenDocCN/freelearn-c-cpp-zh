<html><head></head><body>
        

                            
                    <h1 class="header-title">Particle Systems and Animation</h1>
                
            
            
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Animating a surface with vertex displacement</li>
<li>Creating a particle fountain</li>
<li>Creating a particle system using transform feedback</li>
<li>Creating a particle system using instanced meshes</li>
<li>Simulating fire with particles</li>
<li>Simulating smoke with particles</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction</h1>
                
            
            
                
<p>Shaders provide us with the ability to leverage the massive parallelism offered by modern graphics processors. Since they have the ability to transform the vertex positions, they can be used to implement animation directly within the shaders themselves. This can provide a boost in efficiency if the animation algorithm can be parallelized appropriately for execution within the shader.</p>
<p>If a shader is to help with animation, it must not only compute the positions, but often it must write out the updated positions for use in the next frame. Shaders were not originally designed to write to arbitrary buffers (except, of course, the framebuffer). However, with recent versions, OpenGL has provided the ability to do so via a number of techniques including shader storage buffer objects and image load/store. As of OpenGL 3.0, we can also send the values of the vertex or geometry shader's output variables to an arbitrary buffer (or buffers). This feature is called <strong>transform feedback</strong>, and is particularly useful for particle systems.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In this chapter, we'll look at several examples of animation within shaders, focusing mostly on particle systems. The first example, animating with vertex displacement, demonstrates animation by transforming the vertex positions of an object based on a time-dependent function. In the <em>Creating a particle fountain</em> recipe, we will create a simple particle system under constant acceleration. In the <em>Creating a particle system using transform feedback</em> recipe, there is an example illustrating how to use OpenGL's transform feedback functionality within a particle system. The <em>Creating a particle system using instanced particles</em> recipe shows you how to animate many complex objects using instanced rendering.</p>
<p>The last two recipes demonstrate some particle systems for simulating complex, real phenomena such as smoke and fire.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Animating a surface with vertex displacement</h1>
                
            
            
                
<p>A straightforward way to leverage shaders for animation is to simply transform the vertices within the vertex shader based on some time-dependent function. The OpenGL application supplies static geometry, and the vertex shader modifies the geometry using the current time (supplied as a uniform variable). This moves the computation of the vertex position from the CPU to the GPU, and leverages whatever parallelism the graphics driver makes available.</p>
<p>In this example, we'll create a waving surface by transforming the vertices of a tessellated quad based on a sine wave. We'll send down the pipeline a set of triangles that make up a flat surface in the <em>x</em>-<em>z</em> plane. In the vertex shader, we'll transform the <em>y</em> coordinate of each vertex based on a time-dependent sine function, and compute the normal vector of the transformed vertex. The following image shows the desired result (you'll have to imagine that the waves are travelling across the surface from left to right):</p>
<div><img src="img/6fdf555b-2946-408d-b99d-b454326e94b2.png" style="width:14.58em;height:12.50em;"/></div>
<p>Alternatively, we could use a noise texture to animate the vertices (that make up the surface) based on a random function. (See <a href="5e6b75a0-9f0c-4798-bc37-b5d34b53ef4a.xhtml">Chapter 9</a>, <em>Using Noise in Shaders</em>, for details on noise textures.)</p>
<p>Before we jump into the code, let's take a look at the mathematics that we'll need.</p>
<p>We'll transform the <em>y </em>coordinate of the surface as a function of the current time and the modeling <em>x </em>coordinate. To do so, we'll use the basic plane wave equation, as shown in the following diagram:</p>
<div><img src="img/a3f07ddf-11f9-4abe-b84e-10bde8473cdb.png" style="width:31.58em;height:12.50em;"/></div>
<p><strong>A</strong> is the wave's amplitude (the height of the peaks), the lambda (<strong>λ</strong>) is the wavelength (the distance between successive peaks), and <strong>v</strong> is the wave's velocity. The previous diagram shows an example of the wave when <em>t = 0</em> and the wavelength is equal to one. We'll configure these coefficients through uniform variables.</p>
<p>In order to render the surface with proper shading, we also need the normal vector at the transformed location. We can compute the normal vector using the (partial) derivative of the previous function. The result is the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/77694054-ee14-4dac-bae7-ba391d3a6b6f.png" style="width:20.50em;height:3.08em;"/></p>
<p>Of course, this vector should be normalized before we use it in our shading model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Set up your OpenGL application to render a flat, tessellated surface in the <em>x</em>-<em>z</em> plane. The results will look better if you use a large number of triangles. Also, keep track of the animation time using whatever method you prefer. Provide the current time to the vertex shader via the uniform <kbd>Time</kbd> variable.</p>
<p class="mce-root"/>
<p>The other important uniform variables are the coefficients of the previous wave equation:</p>
<ul>
<li><kbd>K</kbd>: It is the wavenumber (<em>2π/λ</em>)</li>
<li><kbd>Velocity</kbd>: It is the wave's velocity</li>
<li><kbd>Amp</kbd>: It is the wave's amplitude</li>
</ul>
<p>Set up your program to provide appropriate uniform variables for your chosen shading model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>In the vertex shader, we translate the <em>y</em> coordinate of the vertex:</p>
<pre>layout (location = 0) in vec3 VertexPosition; 
 
out vec4 Position; 
out vec3 Normal; 
 
uniform float Time;  // The animation time 
 
// Wave parameters 
uniform float K;        // Wavenumber 
uniform float Velocity; // Wave's velocity 
uniform float Amp;      // Wave's amplitude 
 
uniform mat4 ModelViewMatrix; 
uniform mat3 NormalMatrix; 
uniform mat4 MVP; 
 
void main() {
  vec4 pos = vec4(VertexPosition,1.0); 
 
  // Translate the y coordinate 
  float u = K * (pos.x - Velocity * Time); 
  pos.y = Amp * sin( u ); 
 
  // Compute the normal vector 
  vec3 n = vec3(0.0); 
  n.xy = normalize(vec2(-K * Amp *cos( u ), 1.0)); 
 
  // Send position and normal (in camera cords) to frag. 
  Position = ModelViewMatrix * pos; 
  Normal = NormalMatrix * n; 
 
  // The position in clip coordinates 
  gl_Position = MVP * pos; 
} </pre>
<p>Create a fragment shader that computes the fragment color based on the <kbd>Position</kbd> and <kbd>Normal</kbd> variables using whatever shading model you choose.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The vertex shader takes the position of the vertex and updates the <em>y</em> coordinate using the wave equation discussed previously. After the first three statements, the variable <kbd>pos</kbd> is just a copy of the <kbd>VertexPosition</kbd> input variable with the modified <em>y</em> coordinate.</p>
<p>We then compute the normal vector using the previous equation, normalize the result, and store it in the <kbd>n</kbd> variable. Since the wave is really just a two-dimensional wave (it doesn't depend on <em>z</em>), the <em>z</em> component of the normal vector will be zero.</p>
<p>Finally, we pass along the new position and normal to the fragment shader after converting to camera coordinates. As usual, we also pass the position in clip coordinates to the built-in <kbd>gl_Position</kbd> variable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>Modifying the vertex position within the vertex shader is a straightforward way to offload some computation from the CPU to the GPU. It also eliminates the possible need to transfer vertex buffers between the GPU memory and main memory in order to modify the positions.</p>
<p>The main disadvantage is that the updated positions are not available on the CPU side. For example, they might be needed for additional processing (such as collision detection). However, there are a number of ways to provide this data back to the CPU. One technique might be the clever use of FBOs to receive the updated positions from the fragment shader. In a later recipe, we'll look at another technique that makes use of a newer OpenGL feature called <strong>transform feedback</strong>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li><kbd>chapter10/scenewave.cpp</kbd> in the example code</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a particle fountain</h1>
                
            
            
                
<p>In computer graphics, a particle system is a group of objects that are used to simulate a variety of <strong>fuzzy</strong> systems such as smoke, liquid spray, fire, explosions, or other similar phenomena. Each particle is considered to be a point object with a position, but no size. They could be rendered as point sprites (using the <kbd>GL_POINTS</kbd> primitive mode), or as camera aligned quads or triangles. Each particle has a lifetime: it is born, animates according to a set of rules, and then dies. The particle can then be resurrected and go through the entire process again. In this example, particles do not interact with other particles, but some systems, such as fluid simulations, would require a particle to interact. A common technique is to render the particle as a single, textured, camera-facing quad with transparency.</p>
<p>During the lifetime of a particle, it is animated according to a set of rules. These rules include the basic kinematic equations that define the movement of a particle that is subjected to constant acceleration (such as a gravitational field). In addition, we might take into account things such as wind, friction, or other factors. The particle may also change shape or transparency during its lifetime. Once the particle has reached a certain age (or position), it is considered to be <em>dead</em> and can be <em>recycled</em> and used again.</p>
<p>In this example, we'll implement a relatively simple particle system that has the look of a fountain of water. For simplicity, the particles in this example will not be <em>recycled</em>. Once they have reached the end of their lifetime, we'll draw them as fully transparent so that they are effectively invisible. This gives the fountain a finite lifetime, as if it only has a limited supply of material. In later recipes, we'll see some ways to improve this system by recycling particles.</p>
<p>The following image shows a sequence of images—several successive frames from the output of this simple particle system:</p>
<div><img src="img/086c3aa6-b2f0-4185-810c-66a6abf2160f.png" style="width:44.33em;height:8.58em;"/></div>
<p>To animate the particles, we'll use the standard kinematics equation for objects under constant acceleration:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/94fac40d-2580-4ef9-8d08-7725264501ce.png" style="width:13.75em;height:2.83em;"/></p>
<p>The previous equation describes the position of a particle at time <em>t</em>. <em>P<sub>0</sub></em> is the initial position, <em>v<sub>0</sub></em> is the initial velocity, and <em>a</em> is the acceleration.</p>
<p>We'll define the initial position of all particles to be the origin (0,0,0). The initial velocity will be determined randomly within a range of values. Each particle will be created at a slightly different time, so the time that we use in the previous equation will be relative to the start time for the particle.</p>
<p>Since the initial position is the same for all particles, we won't need to provide it as an input attribute to the shader. Instead, we'll just provide two other vertex attributes: the initial velocity and the start time (the particle's time of <em>birth</em>)<em>.</em> Prior to the particle's birth time, we'll render it completely transparent. During its lifetime, the particle's position will be determined using the previous equation with a value for <em>t</em> that is relative to the particle's start time (<kbd>Time - StartTime</kbd>).</p>
<p>To render our particles, we'll use a technique called <strong>instancing</strong>, along with a simple trick to generate screen-aligned quads. With this technique, we don't actually need any vertex buffers for the quad itself! Instead, we'll just invoke the vertex shader six times for each particle in order to generate two triangles (a quad). In the vertex shader, we'll compute the positions of the vertices as offsets from the particle's position. If we do so in screen space, we can easily create a screen-aligned quad. We'll need to provide input attributes that include the particle's initial velocity and <strong>birth time</strong>.</p>
<p>This technique makes use of the vertex shader to do all the work of animating the particles. We gain a great deal of efficiency over computing the positions on the CPU. The GPU can execute the vertex shader in parallel, and process several particles at once.</p>
<p>The core of this technique involves the use of the <kbd>glDrawArraysInstanced</kbd> function. This function is similar to the familiar <kbd>glDrawArrays</kbd>, but instead of just drawing once, it does so repeatedly. Where <kbd>glDrawArrays</kbd> would just <em>walk</em> through the vertex buffers once, <kbd>glDrawArraysInstanced</kbd> will do so a specified number of times. In addition, while <em>walking</em> through the buffers, we can also configure when to move to the next element in the buffer (how quickly to walk). Normally, we move to the next element with each invocation of the vertex shader (essentially once per vertex). However, with instanced drawing, we don't always want that. We might want several (sometimes hundreds) of invocations to get the same input value.</p>
<p class="mce-root"/>
<p>For example, each particle in our particle system has six vertices (two triangles). For each of these six vertices, we want the same velocity, (particle) position, and other per-particle parameters. The key to this is the <kbd>glVertexAttribDivisor</kbd> function, which makes it possible to specify how often the index is advanced for a given attribute. A divisor value of <kbd>0</kbd> indicates that the index is advanced once per vertex. A value that is greater than zero (<em>n &gt; 0</em>) indicates that the index advances once after n instances of the shape are drawn.</p>
<p>For example, suppose we have two attributes (A and B) and we set the divisor to zero for attribute A and one for attribute B. Then, we execute the following:</p>
<pre>glDrawArraysInstanced( GL_TRIANGLES, 0, 3, 3);</pre>
<p>The first three arguments are the same as <kbd>glDrawArrays</kbd>. The fourth argument is the number of instances. So, this call would draw three instances of a triangle primitive (for a total of nine vertices), and the values of attributes A and B would be taken from the corresponding buffers at the indices shown here:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Attribute</strong></td>
<td><strong>Vertex indices</strong></td>
</tr>
<tr>
<td>A</td>
<td>0,1,2,0,1,2,0,1,2</td>
</tr>
<tr>
<td>B</td>
<td>0,0,0,1,1,1,2,2,2</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Note how setting the vertex attribute divisor for B to one causes the index to advance once per instance, rather than once per vertex. In fact, in this recipe, we'll set the divisor for all of our attributes to one! We'll compute the positions of each vertex of a particle as offsets from the particle's position.</p>
<p>You might be wondering how it will be possible to distinguish one vertex from another in the vertex shader in order to determine the needed offsets if the attribute values are the same for all vertices of the particle. The solution comes via the built-in variable <kbd>gl_VertexID</kbd>. More on this follows.</p>
<p>We'll render each particle as a textured-point quad of two triangles. We'll increase the transparency of the particle linearly with the age of the particle, to make the particle appear to fade out as it animates.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>We'll create two buffers (or a single interleaved buffer) to store our input attributes. The first buffer will store the initial velocity for each particle. We'll choose the values randomly from a limited range of possible vectors. To create the <em>cone</em> of particles in the previous image, we'll choose randomly from a set of vectors within the cone. We will <em>tilt</em> the cone toward some direction by applying a rotation matrix (<kbd>emitterBasis</kbd>). The following code is one way to do this:</p>
<pre>glm::mat3 emitterBasis = ...; // Rotation matrix <br/>auto nParticles = 10000;<br/>glGenBuffers(1, &amp;initVel);<br/>glBindBuffer(GL_ARRAY_BUFFER, initVel);<br/>glBufferData(GL_ARRAY_BUFFER, <br/>    nParticles * sizeof(float) * 3, nullptr, GL_STATIC_DRAW);<br/><br/>glm::vec3 v(0);
float velocity, theta, phi; 
std::vector&lt;GLfloat&gt; data(nParticles * 3); 
for( uint32_t i = 0; i &lt; nParticles; i++ ) { 
  // Pick the direction of the velocity 
  theta = glm::mix(0.0f, glm::pi&lt;float&gt;() / 20.0f, randFloat()); 
  phi = glm::mix(0.0f, glm::two_pi&lt;float&gt;(), randFloat()); 
 
  v.x = sinf(theta) * cosf(phi); 
  v.y = cosf(theta); 
  v.z = sinf(theta) * sinf(phi); 
 
  // Scale to set the magnitude of the velocity (speed) 
  velocity = glm::mix(1.25f,1.5f,randFloat()); 
  v = glm::normalize(emitterBasis * v) * velocity; 
 
  data[3*i]   = v.x; 
  data[3*i+1] = v.y; 
  data[3*i+2] = v.z; 
} 
glBindBuffer(GL_ARRAY_BUFFER, initVel); 
glBufferSubData(GL_ARRAY_BUFFER, 0,  
                nParticles * 3 * sizeof(float), data.data()); </pre>
<p>In the previous code, the <kbd>randFloat</kbd> function returns a random value between zero and one. We pick random numbers within a range of possible values by using the GLM <kbd>mix</kbd> function (the GLM <kbd>mix</kbd> function works the same as the corresponding GLSL function—it performs a linear interpolation between the values of the first two arguments). Here, we choose a random <kbd>float</kbd> between zero and one and use that value to interpolate between the endpoints of our range.</p>
<p class="mce-root"/>
<p>To pick vectors from within our cone, we utilize spherical coordinates. The value of <kbd>theta</kbd> determines the angle between the center of the cone and the vector. The value of <kbd>phi</kbd> defines the possible directions around the <em>y </em>axis for a given value of <kbd>theta</kbd>. For more on spherical coordinates, grab your favorite math book.</p>
<p>Once a direction is chosen, the vector is scaled to have a magnitude between 1.25 and 1.5. This is a range that seems to work well for the desired effect. The magnitude of the velocity vector is the overall speed of the particle, and we can tweak this range to get a wider variety of speeds or faster/slower particles.</p>
<p>The last three lines in the loop assign the vector to the appropriate location in the vector <kbd>data</kbd>. After the loop, we copy the data into the buffer referred to by <kbd>initVel</kbd>. Set up this buffer to provide data for vertex attribute zero.</p>
<p>In the second buffer, we'll store the start time for each particle. This will provide only a single float per vertex (particle). For this example, we'll just create each particle in succession at a fixed rate. The following code will set up a buffer with each particle created a fixed number of seconds after the previous one:</p>
<pre>glGenBuffers(1, &amp;startTime);<br/>glBindBuffer(GL_ARRAY_BUFFER, startTime);<br/>glBufferData(GL_ARRAY_BUFFER, nParticles * sizeof(float), <br/>   nullptr, GL_STATIC_DRAW);<br/><br/>float rate = particleLifetime / nParticles;  
for( uint32_t i = 0; i &lt; nParticles; i++ ) { 
  data[i] = rate * i;
} 
glBindBuffer(GL_ARRAY_BUFFER, startTime); 
glBufferSubData(GL_ARRAY_BUFFER, 0, nParticles * sizeof(float), data.data()); </pre>
<p>This code simply creates an array of floats that starts at zero and gets incremented by <kbd>rate</kbd>. The array is then copied into the buffer referred to by <kbd>startTime</kbd>. Set this buffer to be the input for vertex attribute one.</p>
<p>Before continuing, we set the divisor for both attributes to one. This ensures that all vertices of a particle will receive the same value for the attributes:</p>
<pre>glVertexAttribDivisor(0,1);<br/>glVertexAttribDivisor(1,1);</pre>
<p>The preceding commands should be executed while the <strong>vertex array object</strong> (<strong>VAO</strong>) is bound. The divisor information is stored within the VAO. See the example code for details.</p>
<p class="mce-root"/>
<p>The vertex shader has a number of uniform variables that control the simulation. Set the following uniform variables from within the OpenGL program:</p>
<ul>
<li><kbd>ParticleTex</kbd>: The particle's texture</li>
<li><kbd>Time</kbd>: The amount of time that has elapsed since the animation began</li>
<li><kbd>Gravity</kbd>: The vector representing one half of the acceleration in the previous equation</li>
<li><kbd>ParticleLifetime</kbd>: Defines how long a particle survives after it is created</li>
<li><kbd>ParticleSize</kbd>:  Size of the particle</li>
<li><kbd>EmitterPos</kbd>:  The position of the particle emitter</li>
</ul>
<p>Since we want our particles to be partially transparent, we enable alpha blending using the following statements:</p>
<pre>glEnable(GL_BLEND); 
glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>In the vertex shader code, we <em>create</em> the particle by offsetting the particle position in camera coordinates. Note the use of <kbd>gl_VertexID</kbd> to identify the quad's vertex:</p>
<pre>layout (location = 0) in vec3 VertexInitVel;    // Particle initial velocity<br/>layout (location = 1) in float VertexBirthTime; // Particle birth time<br/><br/>out float Transp;  // Transparency of the particle<br/>out vec2 TexCoord; // Texture coordinate<br/><br/>uniform float Time; // Animation time<br/>uniform vec3 Gravity; // Gravity vector in world coords<br/>uniform float ParticleLifetime; // Max particle lifetime<br/>uniform float ParticleSize; // Particle size<br/>uniform vec3 EmitterPos;    // Emitter position in world coordinates<br/><br/>// Transformation matrices<br/>uniform mat4 MV, Proj;<br/><br/>// Offsets to the position in camera coordinates for each vertex of the<br/>// particle's quad<br/>const vec3 offsets[] = vec3[](<br/>    vec3(-0.5,-0.5,0), vec3(0.5,-0.5,0), vec3(0.5,0.5,0),<br/>    vec3(-0.5,-0.5,0), vec3(0.5,0.5,0), vec3(-0.5,0.5,0) );<br/>// Texture coordinates for each vertex of the particle's quad<br/>const vec2 texCoords[] = vec2[](<br/>     vec2(0,0), vec2(1,0), vec2(1,1), <br/>     vec2(0,0), vec2(1,1), vec2(0,1)); 
 
void main() {
    vec3 cameraPos; // Position in camera coordinates<br/>    float t = Time - VertexBirthTime;<br/>    if( t &gt;= 0 &amp;&amp; t &lt; ParticleLifetime ) {<br/>        vec3 pos = EmitterPos + VertexInitVel * t + Gravity * t * t;<br/>        cameraPos = (MV * vec4(pos,1)).xyz + (offsets[gl_VertexID] * <br/>        ParticleSize);<br/>        Transp = mix( 1, 0, t / ParticleLifetime );<br/>    } else {<br/>        // Particle doesn't "exist", draw fully transparent<br/>        cameraPos = vec3(0);<br/>        Transp = 0.0;<br/>    }<br/><br/>    TexCoord = texCoords[gl_VertexID];<br/>    gl_Position = Proj * vec4(cameraPos, 1);
} </pre>
<p>In the fragment shader, we just apply the texture and scale the alpha for the particle:</p>
<pre>in float Transp; <br/>in vec2 TexCoord;
uniform sampler2D ParticleTex; 

layout ( location = 0 ) out vec4 FragColor; 

void main() {
  FragColor = texture(ParticleTex, TexCoord); 
  FragColor.a *= Transp;
} </pre>
<p>To render our particles, we make the depth buffer read-only using <kbd>glDepthMask</kbd>, and issue a <kbd>glDrawArraysInstanced</kbd> call with six vertices per particle:</p>
<pre>glDepthMask(GL_FALSE);<br/>glBindVertexArray(particles);<br/>glDrawArraysInstanced(GL_TRIANGLES, 0, 6, nParticles);<br/>glBindVertexArray(0);<br/>glDepthMask(GL_TRUE);</pre>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The vertex shader receives the particle's initial velocity (<kbd>VertexInitVel</kbd>) and start time (<kbd>VertexBirthTime</kbd>) in its two input attributes. The <kbd>Time</kbd> variable stores the amount of time that has elapsed since the beginning of the animation. The <kbd>Transp</kbd> output variable is the overall transparency of the particle.</p>
<p>In the main function of the vertex shader, we start by determining the particle's age (<kbd>t</kbd>) as the current simulation time minus the particle's birth time. The following <kbd>if</kbd> statement determines whether the particle is alive yet. If the particle's age is greater than zero, the particle is alive, otherwise, the particle has yet to be <em>born</em>. In the latter case, the position is set to the camera's origin and the particle is rendered fully transparent. We do the same thing if the particle's age is greater than its lifetime.</p>
<p>If the particle is alive, the particle's position (<kbd>pos</kbd>) is determined using the kinematic equation described previously. The <kbd>cameraPos</kbd> vertex position is determined by offsetting the particle's position using the <kbd>offsets</kbd> array. We transform the position into camera coordinates (using <kbd>MV</kbd>), and add the offset for the current vertex using <kbd>gl_VertexID</kbd> as the index. </p>
<div><kbd>gl_VertexID</kbd> is a built-in variable in GLSL that takes on the index of the vertex of the current instance.  In this case, since we are using six vertices per particle, <kbd>gl_VertexID</kbd> will be between 0 and 5.</div>
<p>By applying the offsets in camera coordinates, we gain a quality that is often desired in particle systems. The particle's quad will always face the camera. This effect, called <strong>billboarding</strong>, gives the particles the illusion that they are solid shapes rather than just flat quads.</p>
<p>We scale the offset value by <kbd>ParticleSize</kbd> to set the size of the particle. The transparency is determined by linearly interpolating based on the particle's age:</p>
<pre>Transp = mix( 1, 0, t / ParticleLifetime );</pre>
<p>When the particle is born it is fully opaque, and linearly becomes transparent as it ages. The value of <kbd>Transp</kbd> is <kbd>1.0</kbd> at birth and <kbd>0.0</kbd> at the end of the particle's lifetime.</p>
<p>In the fragment shader, we color the fragment with the result of value of a texture lookup. Before finishing, we multiply the alpha value of the final color by the variable <kbd>Transp</kbd>, in order to scale the overall transparency of the particle based on the particle's age (as determined in the vertex shader).</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>This example is meant to be a fairly gentle introduction to GPU-based particle systems. There are many things that could be done to improve the power and flexibility of this system. For example, we could vary the rotation of the particles as they progress through their lifetime to produce different effects.</p>
<p>One of the most significant drawbacks of the technique in this recipe is that the particles can't be recycled easily. When a particle dies, it is simply rendered as transparent. It would be nice to be able to reuse each dead particle to create an apparently continuous stream of particles. Additionally, it would be useful to be able to have the particles respond appropriately to changing accelerations or modifications of the system (for example, wind or movement of the source). With the system described here, we couldn't do so because we are working with a single equation that defines the movement of the particle for all time. What would be needed is to incrementally update the positions based on the current forces involved (a simulation).</p>
<p>In order to accomplish the previous objective, we need some way to feed the output of the vertex shader (the particle's updated positions) back into the input of the vertex shader during the next frame. This would of course be simple if we weren't doing the simulation within the shader because we could simply update the positions of the primitives directly before rendering. However, since we are doing the work within the vertex shader, we are limited in the ways that we can write to memory.</p>
<p>In the following recipe, we'll see an example of how to use an OpenGL feature called <strong>transform feedback</strong> to accomplish exactly what was just described. We can designate certain output variables to be sent to buffers that can be read as input in subsequent rendering passes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter10/scene_particles.cpp</kbd> file in the example code</li>
<li>The <em>Animating a surface with vertex displacement</em> recipe</li>
<li>The <em>Creating a particle system using transform feedback</em> recipe</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a particle system using transform feedback</h1>
                
            
            
                
<p>Transform feedback provides a way to capture the output of the vertex (or geometry) shader to a buffer for use in subsequent passes. Originally introduced into OpenGL with version 3.0, this feature is particularly well-suited for particle systems, because among other things, it enables us to do discrete simulations. We can update a particle's position within the vertex shader and render that updated position in a subsequent pass (or the same pass). Then the updated positions can be used in the same way as input to the next frame of animation.</p>
<p>In this example, we'll implement the same particle system from the previous recipe (<em>Creating a particle fountain</em>), this time making use of transform feedback. Instead of using an equation that describes the particle's motion for all time, we'll update the particle positions incrementally, solving the equations of motion based on the forces involved at the time each frame is rendered.</p>
<p>A common technique is to make use of the Euler method, which approximates the position and velocity at time <kbd>t</kbd> based on the position, velocity, and acceleration at an earlier time:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/6a827dcc-e6c1-4c2e-90c2-33194a93e417.png" style="width:9.58em;height:3.17em;"/></p>
<p>In the previous equation, the subscripts represent the time step (or animation frame), <em>P</em> is the particle position, and <em>v</em> is the particle velocity. The equations describe the position and velocity at frame <em>n + 1</em> as a function of the position and velocity during the previous frame (<em>n</em>). The variable <em>h</em> represents the time step size, or the amount of time that has elapsed between frames. The term <em>a<sub>n</sub></em> represents the instantaneous acceleration. For our simulation, this will be a constant value, but in general it might be a value that changes depending on the environment (wind, collisions, inter-particle interactions, and so on).</p>
<p>The Euler method is actually numerically integrating the Newtonian equation of motion. It is one of the simplest techniques for doing so. However, it is a first-order technique, which means that it can introduce a significant amount of error. More accurate techniques include <strong>Verlet integration</strong> and <strong>Runge-Kutta integration</strong>. Since our particle simulation is designed to look good and physical accuracy is not of high importance, the Euler method should suffice.</p>
<p>To make our simulation work, we'll use a technique sometimes called <strong>buffer ping-ponging</strong>. We maintain two sets of vertex buffers and swap their uses each frame. For example, we use buffer <strong>A</strong> to provide the positions and velocities as input to the vertex shader. The vertex shader updates the positions and velocities using the Euler method and sends the results to buffer <strong>B</strong> using transform feedback. Then, in a second pass, we render the particles using buffer <strong>B</strong>:</p>
<div><img src="img/772c7ecf-5b73-4dac-8082-33f25d96fc8b.png" style="width:23.33em;height:13.17em;"/></div>
<p>In the next frame of animation, we repeat the same process, swapping the two buffers.</p>
<p>In general, transform feedback allows us to define a set of shader output variables that are to be written to a designated buffer (or set of buffers). There are several steps involved that will be demonstrated, but the basic idea is as follows. Just before the shader program is linked, we define the relationship between buffers and shader output variables using the <kbd>glTransformFeedbackVaryings</kbd> function. During rendering, we initiate a transform feedback pass. We bind the appropriate buffers to the transform feedback binding points. (If desired, we can disable rasterization so that the particles are not rendered.) We enable transform feedback using the <kbd>glBeginTransformFeedback</kbd> function and then draw the point primitives. The output from the vertex shader will be stored in the appropriate buffers. Then we disable transform feedback by calling <kbd>glEndTransformFeedback</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Create and allocate three pairs of buffers. The first pair will be for the particle positions, the second for the particle velocities, and the third for the <em>age</em> of each particle. For clarity, we'll refer to the first buffer in each pair as the A buffer, and the second as the B buffer. </p>
<p>Create two vertex arrays. The first vertex array should link the A position buffer with the first vertex attribute (attribute index 0), the A velocity buffer with vertex attribute one, and the A age buffer with vertex attribute two.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The second vertex array should be set up in the same way using the B buffers.  The handles to the two vertex arrays will be accessed via the <kbd>GLuint</kbd> array named <kbd>particleArray</kbd>.</p>
<p>Initialize the A buffers with appropriate initial values. For example, all of the positions could be set to the origin, and the velocities and start times could be initialized in the same way as described in the previous <em>Creating a particle fountain </em>recipe. The initial velocity buffer could simply be a copy of the velocity buffer.</p>
<p>When using transform feedback, we define the buffers that will receive the output data from the vertex shader by binding the buffers to the indexed binding points under the <kbd>GL_TRANSFORM_FEEDBACK_BUFFER</kbd> target. The index corresponds to the index of the vertex shader's output variable as defined by <kbd>glTransformFeedbackVaryings</kbd>.</p>
<p>To help simplify things, we'll make use of transform feedback objects. Use the following code to set up two transform feedback objects for each set of buffers:</p>
<pre>GLuint feedback[2];  // Transform feedback objects 
GLuint posBuf[2];    // Position buffers (A and B) 
GLuint velBuf[2];    // Velocity buffers (A and B) 
GLuint age[2];       // Age buffers (A and B) 
 
// Create and allocate buffers A and B for posBuf, velBuf, and age
<br/>// Fill in the first age buffer<br/>std::vector&lt;GLfloat&gt; tempData(nParticles);<br/>float rate = particleLifetime / nParticles;<br/>for( int i = 0; i &lt; nParticles; i++ ) {<br/>    tempData[i] = rate * (i - nParticles);<br/>}<br/>glBindBuffer(GL_ARRAY_BUFFER, age[0]);<br/>glBufferSubData(GL_ARRAY_BUFFER, 0, nParticles * sizeof(float),<br/> tempData.data()); <br/>// Setup the feedback objects 
glGenTransformFeedbacks(2, feedback); 
 
// Transform feedback 0 
glBindTransformFeedback(GL_TRANSFORM_FEEDBACK, feedback[0]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,0,posBuf[0]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,1,velBuf[0]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,2,age[0]); 
 
// Transform feedback 1 
glBindTransformFeedback(GL_TRANSFORM_FEEDBACK, feedback[1]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,0,posBuf[1]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,1,velBuf[1]); 
glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER,2,age[1]);</pre>
<p class="mce-root"/>
<p>Similar to vertex array objects, transform feedback objects store the buffer bindings to the <kbd>GL_TRANSFORM_FEEDBACK_BUFFER</kbd> binding point so that they can be reset quickly at a later time. In the previous code, we create two transform feedback objects, and store their handles in the array named <kbd>feedback</kbd>. For the first object, we bind <kbd>posBuf[0]</kbd> to index <kbd>0</kbd>, <kbd>velBuf[0]</kbd> to index <kbd>1</kbd>, and <kbd>startTime[0]</kbd> to index <kbd>2</kbd> of the binding point (buffer set A). These bindings are connected to the shader output variables with <kbd>glTransformFeedbackVaryings</kbd> (or via a layout qualifier; see the following <em>There's more...</em> section). The last argument for each is the buffer's handle. For the second object, we do the same thing using the buffer set B. Once this is set up, we can define the set of buffers to receive the vertex shader's output, by binding to one or the other transform feedback object.</p>
<p>The initial values for the age buffer are all negative values. The absolute value represents how long before the particle is <em>born</em>. A particle is born when its age reaches zero. </p>
<p>We also need some way of specifying the initial velocity of each particle. A simple solution is to use a texture of random velocities and query the texture when a random value is needed. We will use the built-in <kbd>gl_VertexID</kbd> variable to access a unique location within the texture for each particle. Create a 1D texture of float values and fill it with random initial velocities (the code omitted here, but is available in the example code).</p>
<p>The important uniform variables are as follows:</p>
<ul>
<li><kbd>ParticleTex</kbd>: The texture to apply to the point sprites</li>
<li><kbd>RandomTex</kbd>: The texture containing the random initial velocities</li>
<li><kbd>Time</kbd>: The simulation time</li>
<li><kbd>DeltaT</kbd>:  Defines the elapsed time between animation frames</li>
<li><kbd>Accel</kbd>: The acceleration</li>
<li><kbd>ParticleLifetime</kbd>: The length of time that a particle exists before it is recycled</li>
<li><kbd>Emitter</kbd>: The position of the particle emitter in world coordinates</li>
<li><kbd>EmitterBasis</kbd>: A rotation matrix for directing the emitter</li>
<li><kbd>ParticleSize</kbd>: The size of a particle</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>In the vertex shader, we have code that supports two passes: the update pass where the particles' position, age, and velocity are updated, and the render pass where the particles are drawn:</p>
<pre>const float PI = 3.14159265359;<br/>layout (location = 0) in vec3 VertexPosition;<br/>layout (location = 1) in vec3 VertexVelocity;<br/>layout (location = 2) in float VertexAge;<br/><br/>// Render pass<br/>uniform int Pass;<br/><br/>// Output to transform feedback buffers (pass 1)<br/>out vec3 Position;<br/>out vec3 Velocity;<br/>out float Age;<br/><br/>// Out to fragment shader (pass 2)<br/>out float Transp; // Transparency<br/>out vec2 TexCoord; // Texture coordinate <br/><br/>// Uniform variables here... (omitted)<br/><br/>vec3 randomInitialVelocity() {<br/>  // Access the texture containing random velocities using gl_VertexID...<br/>}<br/><br/>void update() {<br/>  if( VertexAge &lt; 0 || VertexAge &gt; ParticleLifetime ) {<br/>    // Recycle particle (or particle isn't born yet)<br/>    Position = Emitter;<br/>    Velocity = randomInitialVelocity();<br/>    if( VertexAge &lt; 0 ) Age = VertexAge + DeltaT;<br/>    else Age = (VertexAge - ParticleLifetime) + DeltaT;<br/> } else {<br/>    // The particle is alive, update.<br/>    Position = VertexPosition + VertexVelocity * DeltaT;<br/>    Velocity = VertexVelocity + Accel * DeltaT;<br/>    Age = VertexAge + DeltaT;<br/>  }<br/>}<br/><br/>void render() {<br/>  Transp = 0.0;<br/>  vec3 posCam = vec3(0.0);<br/>  if(VertexAge &gt;= 0.0) {<br/>    posCam = (MV * vec4(VertexPosition,1)).xyz + offsets[gl_VertexID] * <br/>    ParticleSize;<br/>    Transp = clamp(1.0 - VertexAge / ParticleLifetime, 0, 1);<br/>  }<br/>  TexCoord = texCoords[gl_VertexID];<br/>  gl_Position = Proj * vec4(posCam,1);<br/>}<br/><br/>void main() {<br/> if( Pass == 1 ) update();<br/> else render();<br/>}<br/></pre>
<p>The fragment shader code is simple and identical to that of the previous recipe.</p>
<p>After compiling the shader program, but before linking, use the following code to set up the connection between vertex shader output variables and output buffers:</p>
<pre>const char * outputNames[] = { "Position", "Velocity", "Age" };<br/>glTransformFeedbackVaryings(progHandle, 3, outputNames, GL_SEPARATE_ATTRIBS);</pre>
<p>In the OpenGL render function, we'll use two passes. The first pass sends the particle positions to the vertex shader for updating, and capture the results using transform feedback. The input to the vertex shader will come from buffer A, and the output will be stored in buffer B. During this pass, we enable <kbd>GL_RASTERIZER_DISCARD</kbd> so that nothing is actually rendered to the framebuffer:</p>
<pre>// Update pass<br/>prog.setUniform("Pass", 1);<br/><br/>glEnable(GL_RASTERIZER_DISCARD);<br/>glBindTransformFeedback(GL_TRANSFORM_FEEDBACK, feedback[drawBuf]);<br/>glBeginTransformFeedback(GL_POINTS);<br/><br/>glBindVertexArray(particleArray[1-drawBuf]);<br/>glVertexAttribDivisor(0,0);<br/>glVertexAttribDivisor(1,0);<br/>glVertexAttribDivisor(2,0);<br/>glDrawArrays(GL_POINTS, 0, nParticles);<br/>glBindVertexArray(0);<br/><br/>glEndTransformFeedback();<br/>glDisable(GL_RASTERIZER_DISCARD);</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Note that we set the divisor to zero for all particle buffers and use <kbd>glDrawArrays</kbd> here. There's no need to use instancing here because we're not actually rendering the particles.</p>
<p>In the second pass, we use the output gathered from the first pass to render the particles using <kbd>glDrawArraysInstanced</kbd>:</p>
<pre>// Render pass<br/>prog.setUniform("Pass", 2);<br/><br/>glDepthMask(GL_FALSE);<br/>glBindVertexArray(particleArray[drawBuf]);<br/>glVertexAttribDivisor(0,1);<br/>glVertexAttribDivisor(1,1);<br/>glVertexAttribDivisor(2,1);<br/>glDrawArraysInstanced(GL_TRIANGLES, 0, 6, nParticles);<br/>glBindVertexArray(0);<br/>glDepthMask(GL_TRUE);</pre>
<p>Finally, we swap the buffers:</p>
<pre>drawBuf = 1 - drawBuf; </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>There's quite a bit here to sort through. Let's start with the vertex shader.</p>
<p>The vertex shader is broken up into two primary functions (<kbd>update</kbd> and <kbd>render</kbd>). The <kbd>update</kbd> function is used during the first pass, and uses Euler's method to update the position and velocity of the particle. The <kbd>render</kbd> function is used during the second pass. It computes the transparency based on the age of the particle and sends the position and transparency along to the fragment shader.</p>
<p>The vertex shader has three output variables that are used during the first pass: <kbd>Position</kbd>, <kbd>Velocity</kbd>, and <kbd>Age</kbd>. They are used to write to the feedback buffers. </p>
<p>The <kbd>update</kbd> function updates the particle position and velocity using Euler's method unless the particle is not alive yet, or has passed its lifetime. If its age is greater than the lifetime of a particle, we recycle the particle by resetting its position to the emitter position, updating the particle's age by subtracting <kbd>ParticleLifetime</kbd>, and setting its velocity to a new random velocity determined by the <kbd>randomInitialVelocity</kbd> function. Note that we do the same thing if the particle hasn't been born for the first time yet (the age is less than zero), except that we just update the age by <kbd>DeltaT</kbd>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The <kbd>render</kbd> function is fairly straightforward. It draws the quad by offsetting the particle's position in camera coordinates in much the same way as the previous recipe. The <kbd>VertexAge</kbd> variable is used to determine the transparency of the particle, assigning the result to the <kbd>Transp</kbd> output variable. It transforms the vertex position into clip coordinates and places the result in the built-in <kbd>gl_Position</kbd> output variable.</p>
<p>The fragment shader is only utilized during the second pass. It is disabled during the first. It colors the fragment based on the <kbd>ParticleTex</kbd> texture and the transparency delivered from the vertex shader (<kbd>Transp</kbd>).</p>
<p>The next code segment is placed prior to linking the shader program and is responsible for setting up the correspondence between shader output variables and feedback buffers (buffers that are bound to indices of the <kbd>GL_TRANSFORM_FEEDBACK_BUFFER</kbd> binding point). The <kbd>glTransformFeedbackVaryings</kbd> function takes three arguments. The first is the handle to the shader program object. The second is the number of output variable names that will be provided. The third is an array of output variable names. The order of the names in this list corresponds to the indices of the feedback buffers. In this case, <kbd>Position</kbd> corresponds to index zero, <kbd>Velocity</kbd> to index one, and <kbd>Age</kbd> to index two. Check the previous code that creates our feedback buffer objects (the <kbd>glBindBufferBase</kbd> calls) to verify that this is indeed the case.</p>
<div><kbd>glTransformFeedbackVaryings</kbd> can be used to send data into an interleaved buffer instead (rather than separate buffers for each variable). Take a look at the OpenGL documentation for details.</div>
<p>The next code segments describe how you might implement the render function within the main OpenGL program. In this example, there two important GLuint arrays: <kbd>feedback</kbd> and <kbd>particleArray</kbd>. They are each of size two and contain the handles to the two feedback buffer objects, and the two vertex array objects respectively. The <kbd>drawBuf</kbd> variable is just an integer used to alternate between the two sets of buffers. At any given frame, <kbd>drawBuf</kbd> will be either zero or one.</p>
<p>The code for the first pass sets the <kbd>Pass</kbd> uniform to <kbd>1</kbd> to enable the update functionality within the vertex shader. The next call, <kbd>glEnable(GL_RASTERIZER_DISCARD)</kbd>, turns rasterization off so that nothing is rendered during this pass. The call to <kbd>glBindTransformFeedback</kbd> selects the set of buffers corresponding to the <kbd>drawBuf</kbd> variable as the target for the transform feedback output.</p>
<p class="mce-root"/>
<p>Before drawing the points (and thereby triggering our vertex shader), we call <kbd>glBeginTransformFeedback</kbd> to enable transform feedback. The argument is the kind of primitive that will be sent down the pipeline. In this case, we use <kbd>GL_POINTS</kbd> even though we'll actually be drawing triangles because we're not actually drawing any primitives. This pass is just used to update the particles, so there's no need to invoke the shader more than once per particle. This also indicates why we need to set the divisor to zero for our attributes in this pass. We're not using instancing in this pass, so we just want to invoke the vertex shader once per particle. We do so by calling <kbd>glDrawArrays</kbd>.</p>
<p>Output from the vertex shader will go to the buffers that are bound to the <kbd>GL_TRANSFORM_FEEDBACK_BUFFER</kbd> binding point until <kbd>glEndTransformFeedback</kbd> is called. In this case, we bound the vertex array corresponding to <kbd>1 - drawBuf</kbd> (if <kbd>drawBuf</kbd> is 0, we use 1 and vice versa).  </p>
<p>At the end of the update pass, we re-enable rasterization with <kbd>glEnable(GL_RASTERIZER_DISCARD)</kbd>, and move on to the render pass.</p>
<p>The render pass is straightforward; we just set <kbd>Pass</kbd> to <kbd>2</kbd> and draw the particles from the vertex array corresponding to <kbd>drawBuf</kbd>. That vertex array object contains the set of buffers that were written to in the previous pass. </p>
<p>Here, we use instancing in the same fashion as described in the previous recipe, so we set the divisor for all of our attributes back to one.  </p>
<p>Finally, at the end of the render pass, we swap our buffers by setting <kbd>drawBuf</kbd> to <kbd>1 - drawBuf</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>The use of transform feedback is an effective way to capture vertex shader output. However, there are alternatives that make use of recent features that were introduced in OpenGL. For example, image load/store or shader storage buffer objects could be used. These are writable buffers that can be made available to the shader. Instead of using transform feedback, the vertex shader could write its results directly to a buffer. This might enable you to do everything in a single pass. We use these with compute shaders in <a href="d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml">Chapter 11</a>, <em>Using Compute Shaders</em>, so look there for examples of their use.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Using layout qualifiers</h1>
                
            
            
                
<p>OpenGL 4.4 introduced layout qualifiers that make it possible to specify the relationship between the shader output variables and feedback buffers directly within the shader instead of using <kbd>glTransformFeedbackVaryings</kbd>. The <kbd>xfb_buffer</kbd>, <kbd>xfb_stride</kbd>, and <kbd>xfb_offset</kbd> layout qualifiers can be specified for each output variable that is to be used with transform feedback.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Querying transform feedback results</h1>
                
            
            
                
<p>It is often useful to determine how many primitives were written during transform feedback pass. For example, if a geometry shader was active, the number of primitives written could be different than the number of primitives that were sent down the pipeline.</p>
<p>OpenGL provides a way to query for this information using query objects. To do so, start by creating a query object:</p>
<pre>GLuint query; 
glGenQueries(1, &amp;query); </pre>
<p>Then, prior to starting the transform feedback pass, start the counting process using the following command:</p>
<pre>glBeginQuery(GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN, query); </pre>
<p>After the end of the transform feedback pass, call <kbd>glEndQuery</kbd> to stop counting:</p>
<pre>glEndQuery(GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN); </pre>
<p>Then, we can get the number of primitives by using the following code:</p>
<pre>GLuintprimWritten; 
glGetQueryObjectuiv(query, GL_QUERY_RESULT, &amp;primWritten); 
printf("Primitives written: %dn", primWritten); </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter10/sceneparticlesinstanced.cpp</kbd> file in the example code</li>
<li>The <em>Creating a particle fountain </em>recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a particle system using instanced meshes</h1>
                
            
            
                
<p>To give more geometric detail to each particle in a particle system, we can draw entire meshes instead of single quads. Instanced rendering is a convenient and efficient way to draw several copies of a particular object. OpenGL provides support for instanced rendering through the functions <kbd>glDrawArraysInstanced</kbd> and <kbd>glDrawElementsInstanced</kbd>.</p>
<p>In this example, we'll modify the particle system introduced in the previous recipes. Rather than drawing single quads, we'll render a more complex object in the place of each particle. The following image shows an example where each particle is rendered as a shaded torus:</p>
<div><img src="img/25d322a0-d832-49a4-b8e0-0e17d18abdad.png" style="width:20.17em;height:14.58em;"/></div>
<p>We covered the basics of instanced rendering in the previous recipes, so you may want to review those before reading this one. To draw full meshes, we'll use the same basic technique, with some minor changes.  </p>
<p>We'll also add another attribute to control the rotation of each particle so that each can independently spin at a random rotational velocity.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>We'll start the particle system as described in the <em>Creating a particle system using transform feedback </em>recipe. We'll just make a few modifications to that basic system. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Instead of three pairs of buffers, we'll use four this time. We'll need buffers for the particle's position, velocity, age, and rotation. The rotation buffer will store both the rotational velocity and the angle of rotation using the <kbd>vec2</kbd> type. The <em>x</em> component will be the rotational velocity and the <em>y</em> component will be the angle. All shapes will rotate around the same axis. If desired, you could extend this to support a per-particle axis of rotation.</p>
<p>Set up the other buffers in the same way as in the previous recipe.</p>
<p>Because we are drawing full meshes, we need attributes for the position and normal of each vertex of the mesh. These attributes will have a divisor of zero, while the per-particle attributes will have a divisor of one. During the update pass, we will ignore the mesh vertex and normal attributes, focusing on the per-particle attributes. During the render pass, we'll use all attributes.</p>
<p>To summarize, we need six attributes:</p>
<ul>
<li><strong>Attributes 0 and 1</strong>: Mesh vertex position and mesh vertex normal (divisor = 0)</li>
<li><strong>Attributes 3-6</strong>: Per-particle attributes—particle position, velocity, age, and rotation (<em>divisor = 1</em> during render, <em>divisor = 0</em> during update)</li>
</ul>
<p>Attribute 2 could be used for texture coordinates if desired.</p>
<p>We need pairs of buffers for the per-particle attributes, but we only need one buffer for our mesh data, so we'll share the mesh buffers with both vertex array objects. For details, see the example code.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>The vertex shader attributes include per-particle values and mesh values:</p>
<pre>// Mesh attributes<br/>layout (location = 0) in vec3 VertexPosition;<br/>layout (location = 1) in vec3 VertexNormal;<br/><br/>// Per-particle attributes<br/>layout (location = 3) in vec3 ParticlePosition;<br/>layout (location = 4) in vec3 ParticleVelocity;<br/>layout (location = 5) in float ParticleAge;<br/>layout (location = 6) in vec2 ParticleRotation;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>We include output variables for transform feedback, used during the update pass, and for the fragment shader, used during the render pass:</p>
<pre>// To transform feedback<br/>out vec3 Position;<br/>out vec3 Velocity;<br/>out float Age;<br/>out vec2 Rotation;<br/><br/>// To fragment shader<br/>out vec3 fPosition;<br/>out vec3 fNormal;</pre>
<p>The <kbd>update</kbd> function (vertex shader) is similar to the one used in the previous recipe, however, here we update the particle's rotation as well:</p>
<pre>void update() {<br/>    if( ParticleAge &lt; 0 || ParticleAge &gt; ParticleLifetime ) {<br/>        // The particle is past it's lifetime, recycle.<br/>        Position = Emitter;<br/>        Velocity = randomInitialVelocity();<br/>        Rotation = vec2( 0.0, randomInitialRotationalVelocity() );<br/>        if( ParticleAge &lt; 0 ) Age = ParticleAge + DeltaT;<br/>        else Age = (ParticleAge - ParticleLifetime) + DeltaT;<br/>    } else {<br/>        // The particle is alive, update.<br/>        Position = ParticlePosition + ParticleVelocity * DeltaT;<br/>        Velocity = ParticleVelocity + Accel * DeltaT;<br/>        Rotation.x = mod( ParticleRotation.x + ParticleRotation.y <br/>        * DeltaT, 2.0 * PI );<br/>        Rotation.y = ParticleRotation.y;<br/>        Age = ParticleAge + DeltaT;<br/>    }<br/>}</pre>
<p>The <kbd>render</kbd> function (in the vertex shader) applies the rotation and translation using a matrix built from the particle's rotation and position attributes:</p>
<pre>void render() {<br/>    float cs = cos(ParticleRotation.x);<br/>    float sn = sin(ParticleRotation.x);<br/>    mat4 rotationAndTranslation = mat4(<br/>        1, 0, 0, 0,<br/>        0, cs, sn, 0,<br/>        0, -sn, cs, 0,<br/>        ParticlePosition.x, ParticlePosition.y, ParticlePosition.z, 1<br/>    );
    mat4 m = MV * rotationAndTranslation;<br/>    fPosition = (m * vec4(VertexPosition, 1)).xyz;<br/>    fNormal = (m * vec4(VertexNormal, 0)).xyz;<br/>    gl_Position = Proj * vec4(fPosition, 1.0);<br/>}</pre>
<p>The fragment shader applies a shading model such as Blinn-Phong. The code is omitted here.</p>
<p>When invoking the transform feedback pass (the update pass), we disable the mesh attributes and set the divisor to zero for the particle attributes. We invoke the vertex shader for each particle using <kbd>glDrawArrays</kbd>:</p>
<pre>glEnable(GL_RASTERIZER_DISCARD);<br/>glBindTransformFeedback(GL_TRANSFORM_FEEDBACK, feedback[drawBuf]);<br/>glBeginTransformFeedback(GL_POINTS);<br/>glBindVertexArray(particleArray[1-drawBuf]);<br/>glDisableVertexAttribArray(0);<br/>glDisableVertexAttribArray(1);<br/>glVertexAttribDivisor(3,0);<br/>glVertexAttribDivisor(4,0);<br/>glVertexAttribDivisor(5,0);<br/>glVertexAttribDivisor(6,0);<br/>glDrawArrays(GL_POINTS, 0, nParticles);<br/>glBindVertexArray(0);<br/>glEndTransformFeedback();<br/>glDisable(GL_RASTERIZER_DISCARD);; </pre>
<p>To draw the particles, we re-enable the mesh attributes, set the divisor for the per-particle attributes to one, and draw the torus <kbd>nParticles</kbd> times using <kbd>glDrawElementsInstanced</kbd>: </p>
<pre>glBindVertexArray(particleArray[drawBuf]);<br/>glEnableVertexAttribArray(0);<br/>glEnableVertexAttribArray(1);<br/>glVertexAttribDivisor(3,1);<br/>glVertexAttribDivisor(4,1);<br/>glVertexAttribDivisor(5,1);<br/>glVertexAttribDivisor(6,1);<br/>glDrawElementsInstanced(GL_TRIANGLES, torus.getNumVerts(), <br/>   GL_UNSIGNED_INT, 0, nParticles);</pre>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>Recall that the first two input attributes to the vertex shader are not-instanced, meaning that they are advanced every vertex (and repeated every instance). The last four (attributes 3-6) are instanced attributes and only update every instance. Therefore, the effect is that all vertices of an instance of the mesh are transformed by the same matrix, ensuring that it acts as a single particle.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>OpenGL provides a built-in variable to the vertex shader named <kbd>gl_InstanceID</kbd>. This is simply a counter and takes on a different value for each instance that is rendered. The first instance will have an ID of zero, the second will have an ID of one, and so on. This can be useful as a way to index to texture data appropriate for each instance. Another possibility is to use the instance's ID as a way to generate some random data for that instance. For example, we could use the instance ID (or some hash) as a seed to a pseudo-random number generation routine to get a unique random stream for each instance.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter10/sceneparticlesinstanced.cpp</kbd> file in the example code</li>
<li>The <em>Creating a particle fountain</em> recipe</li>
<li>The <em>Creating a particle system using transform feedback</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Simulating fire with particles</h1>
                
            
            
                
<p>To create an effect that roughly simulates fire, we only need to make a few changes to our basic particle system. Since fire is a substance that is only slightly affected by gravity, we don't worry about a downward gravitational acceleration. In fact, we'll actually use a slight upwards acceleration to make the particles spread out near the top of the flame. We'll also spread out the initial positions of the particles so that the base of the flame is not just a single point. Of course, we'll need to use a particle texture that has the red and orange colors associated with flame.</p>
<p>The following image shows an example of the running particle system:</p>
<div><img src="img/a2cff4ec-04a3-4088-8a9d-6e0d148ee2b0.png" style="width:28.50em;height:15.08em;"/></div>
<p>The texture that was used for the particles looks like a light <em>smudge</em> of the flame's colors. It is not shown here because it would not be very visible in print.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Start with the basic particle system presented in the <em>Creating a particle system using transform feedback</em> recipe earlier in this chapter:</p>
<ol>
<li>Set the uniform variable <kbd>Accel</kbd> to a small upward value such as (0.0, 0.1, 0.0).</li>
<li>Set the <kbd>ParticleLifetime</kbd> uniform variable to about <kbd>3</kbd> seconds.</li>
<li>Create and load a texture for the particles that has fire-like colors. Bind it to the first texture channel, and set the uniform <kbd>ParticleTex</kbd> to <kbd>0</kbd>.</li>
<li>Use a particle size of about <kbd>0.5</kbd>. This is a good size for the texture that is used in this recipe, but you might use a different size depending on the number of particles and the texture.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>We'll use a texture filled with random values (two values per particle). The first value will be used to generate the initial velocity and the second, the initial position. For the initial positions, instead of using the the emitter position for all particles, we offset that with random x location. When generating the initial velocities, we'll set the <em>x</em> and <em>z</em> components to zero and take the <em>y</em> component from the random texture.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This, combined with the chosen acceleration, makes each particle move in only the <em>y</em> (vertical) direction:</p>
<pre>vec3 randomInitialVelocity() {<br/>    float velocity = mix(0.1, 0.5, texelFetch(RandomTex, 2 * <br/>    gl_VertexID, 0).r );<br/>    return EmitterBasis * vec3(0, velocity, 0);<br/>}<br/><br/>vec3 randomInitialPosition() {<br/>    float offset = mix(-2.0, 2.0, texelFetch(RandomTex, 2 *<br/>    gl_VertexID + 1, 0).r);<br/>    return Emitter + vec3(offset, 0, 0);<br/>} </pre>
<p>In the fragment shader, we mix the color with black proportional to the age of the particle. This gives the effect of the flame turning to smoke as it rises:</p>
<pre>FragColor = texture(ParticleTex, TexCoord);<br/>// Mix with black as it gets older, to simulate a bit of smoke<br/>FragColor = vec4(mix( vec3(0,0,0), FragColor.xyz, Transp ), FragColor.a);<br/>FragColor.a *= Transp;</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>We randomly distribute the <em>x</em> coordinate of the initial positions between -2.0 and 2.0 for all of the particles, and set the initial velocities to have a <em>y</em> coordinate between 0.1 and 0.5. Since the acceleration has only a <em>y</em> component, the particles will move only along a straight, vertical line in the y direction. The <em>x</em> or <em>z</em> component of the position should always remain at zero. This way, when recycling the particles, we can simply just reset the <em>y</em> coordinate to zero, to restart the particle at its initial position.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>Of course, if you want a flame that moves in different directions, perhaps blown by the wind, you'd need to use a different value for the acceleration. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter10/scenefire.cpp</kbd> file in the example code</li>
<li>The <em>Creating a particle system using transform feedback</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Simulating smoke with particles</h1>
                
            
            
                
<p>Smoke is characterized by many small particles that float away from the source, and spread out as they move through the air. We can simulate the floatation effect with particles by using a small upwards acceleration (or constant velocity), but simulating the diffusion of each small smoke particle might be too expensive. Instead, we can simulate the diffusion of many small particles by making our simulated particles change their size (grow) over time.</p>
<p>The following image shows an example of the results:</p>
<div><img src="img/fdfe21fd-0c01-4882-bb5c-d2f580675e63.png" style="width:21.17em;height:16.00em;"/></div>
<p>The texture for each particle is a very light <em>smudge</em> of grey or black color.</p>
<p>To make the particles grow over time, we'll simply increase the size of our quads.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Start with the basic particle system presented in the <em>Creating a particle system using transform feedback</em> recipe:</p>
<ol>
<li>Set the uniform variable <kbd>Accel</kbd> to a small upward value like (0.0, 0.1, 0.0).</li>
<li>Set the <kbd>ParticleLifetime</kbd> uniform variable to about <kbd>10</kbd> seconds.</li>
<li>Create and load a texture for the particles that looks like just a light-grey smudge. Bind it to texture unit zero, and set the uniform <kbd>ParticleTex</kbd> to <kbd>0</kbd>.</li>
<li>Set the <kbd>MinParticleSize</kbd> and <kbd>MaxParticleSize</kbd> uniform variables to <kbd>0.1</kbd> and <kbd>2.5</kbd> respectively.</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Within the vertex shader, add the following uniforms:</li>
</ol>
<pre style="padding-left: 60px">uniform float MinParticleSize = 0.1; <br/>uniform float MaxParticleSize = 2.5; </pre>
<ol start="2">
<li>Also, within the vertex shader, in the <kbd>render</kbd> function, we'll update the size of the particle based on its age:</li>
</ol>
<pre style="padding-left: 60px">void render() {<br/>    Transp = 0.0;<br/>    vec3 posCam = vec3(0.0);<br/>    if( VertexAge &gt;= 0.0 ) {<br/>        float agePct = VertexAge / ParticleLifetime;<br/>        Transp = clamp(1.0 - agePct, 0, 1);<br/>        posCam =<br/>            (MV * vec4(VertexPosition,1)).xyz +<br/>            offsets[gl_VertexID] *<br/>            mix(MinParticleSize, MaxParticleSize, agePct);<br/>    }<br/>    TexCoord = texCoords[gl_VertexID];<br/>    gl_Position = Proj * vec4(posCam,1);<br/>} </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The <kbd>render</kbd> function scales the particle's offsets by a value between <kbd>MinParticleSize</kbd> and <kbd>MaxParticleSize</kbd>, proportional to the age of the particle. This causes the size of the particles to grow as they evolve through the system.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter10/scenesmoke.cpp</kbd> file in the example code</li>
<li>The <em>Creating a particle system using transform feedback</em> recipe</li>
</ul>


            

            
        
    </body></html>