<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer054">
<h1 class="chapter-number" id="_idParaDest-86"><a id="_idTextAnchor086"/>6</h1>
<h1 id="_idParaDest-87"><a id="_idTextAnchor087"/> Concurrent System Programming with C++</h1>
<p>In this chapter, we will look at what concurrency means and how it is different from parallelism. We will go through the fundamentals and the theory behind processes and threads. We will look at the changes in the C++ memory model, which enforce native concurrency support in the language. We will also familiarize ourselves with what a race condition is, how it can lead to a data race, and how to prevent data races. Next, we will get acquainted with the C++20 <strong class="source-inline">std::jthread</strong> primitive, which enables multithreading support. We will learn about the specifics of the <strong class="source-inline">std::jthread</strong> class and how we can stop already running <strong class="source-inline">std::jthread</strong> instances by using the <strong class="source-inline">std::stop_source</strong> primitive. Finally, we will learn how to synchronize the execution of concurrent code and how to report calculation results from executed tasks. We will learn how to use C++ synchronization primitives such as <em class="italic">barriers</em> and <em class="italic">latches</em> to synchronize the execution of concurrent tasks, and how to properly report the result of these tasks using <em class="italic">promises</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">futures</em></span><span class="No-Break">.</span></p>
<p>To sum up, we will be covering the following topics in <span class="No-Break">this chapter:</span></p>
<ul>
<li>What <span class="No-Break">is concurrency?</span></li>
<li>Thread <span class="No-Break">versus process</span></li>
<li>Concurrency <span class="No-Break">with C++</span></li>
<li>Demystifying race conditions and <span class="No-Break">data races</span></li>
<li><span class="No-Break">Practical multithreading</span></li>
<li>Sharing data during <span class="No-Break">parallel execution</span></li>
</ul>
<p>So, let’s <span class="No-Break">get started!</span></p>
<h1 id="_idParaDest-88"><a id="_idTextAnchor088"/>Technical requirements</h1>
<p> All examples in this chapter have been tested in an environment with the <span class="No-Break">following configuration:</span></p>
<ul>
<li>Linux Mint 21 <span class="No-Break">Cinnamon Edition</span></li>
<li>GCC 12.2 with compiler flags – <strong class="source-inline">-</strong><span class="No-Break"><strong class="source-inline">std=c++20 -pthread</strong></span></li>
<li>A stable <span class="No-Break">internet connection</span></li>
<li>Please make sure your environment is at least this recent. For all the examples, you can alternatively <span class="No-Break">use </span><a href="https://godbolt.org/"><span class="No-Break">https://godbolt.org/</span></a><span class="No-Break">.</span></li>
<li>All code examples in this chapter are available to download <span class="No-Break">from </span><a href="https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%206"><span class="No-Break">https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%206</span></a><span class="No-Break">.</span></li>
</ul>
<h1 id="_idParaDest-89"><a id="_idTextAnchor089"/>What is concurrency?</h1>
<p>Modern cars <a id="_idIndexMarker464"/>have become highly intricate machines that provide not only transportation but also various other functionalities. These functionalities include infotainment systems, which allow users to play music and videos, and heating and air conditioning systems, which regulate the temperature for passengers. Consider a scenario in which these features did not work simultaneously. In such a case, the driver would have to choose between driving the car, listening to music, or staying in a comfortable climate. This is not what we expect from a car, right? We expect all of these features to be available at the same time, enhancing our driving experience and providing a comfortable trip. To achieve this, these features must operate <span class="No-Break">in parallel.</span></p>
<p>But do they really run in parallel, or do they just run concurrently? Is there <span class="No-Break">any difference?</span></p>
<p>In computer systems, <strong class="bold">concurrency</strong> and <strong class="bold">parallelism</strong> are <a id="_idIndexMarker465"/>similar in certain ways, but they are not the same. Imagine you have some work to do, but this work can be done in separate smaller chunks. Concurrency refers to the situation where multiple chunks of the work begin, execute, and finish during overlapping time intervals, without a guaranteed specific order of execution. On the other hand, parallelism is an execution policy where these chunks execute simultaneously on hardware with multiple computing resources, such as a <span class="No-Break">multi-core processor.</span></p>
<p>Concurrency happens when multiple chunks of work, which we <a id="_idIndexMarker466"/>call <strong class="bold">tasks</strong>, are executed in an unspecified order for a certain period of time. The operating system could run some of the tasks and force the rest to wait. In concurrent execution, the task <a id="_idIndexMarker467"/>continuously strives for an execution slot because the operating system does not guarantee that it will execute all of them at once. Furthermore, it is highly possible that while a task is being executed, it is suddenly suspended, and another task starts executing. This is called <strong class="bold">preemption</strong>. It is clear that in concurrent task execution, the order of how the tasks will be executed is <span class="No-Break">not guaranteed.</span></p>
<p>Let’s get back to our car example. In modern cars, the infotainment system is responsible for performing many activities simultaneously. For example, it can run the navigation part while allowing you to listen to music. This is possible because the system runs these tasks concurrently. It runs the tasks related to route calculation while processing the music content. If the hardware system has a single core, then these tasks should <span class="No-Break">run concurrently:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer050">
<img alt="Figure 6.1 – Concurrent task execution" height="300" src="image/Figure_6.01_B20833.jpg" width="961"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Concurrent task execution</p>
<p>From the preceding figure, you can see that each task gets a non-deterministic execution time in an unpredictable order. In addition, there is no guarantee that your task will be finished before the next one is started. This is where the preemption happens. While your task is running, it is suddenly suspended, and another task is scheduled for execution. Keep in mind that task switching is not a cheap process. The system consumes the processor’s computation resource to perform this action – to make the context switch. The conclusion should be the following: we have to design our systems to respect <span class="No-Break">these limitations.</span></p>
<p>On the other hand, parallelism is a form of concurrency that involves executing multiple operations simultaneously on <em class="italic">separate processing units</em>. For example, a computer with multiple CPUs can execute multiple tasks in parallel, which can lead to significant performance improvements. You don’t have to worry about the context switching and the preemption. It has its drawbacks, though, and we will discuss <span class="No-Break">them thoroughly.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer051">
<img alt="Figure 6.2 – Parallel task execution" height="624" src="image/Figure_6.02_B20833.jpg" width="703"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Parallel task execution</p>
<p>Going back to our car example, if the CPU of the infotainment system is multi-core, then the tasks related to the navigation system could be executed on one core, and the tasks for the music processing on some of the other cores. Therefore, you don’t have to take any action to design your code to support preemption. Of course, this is only true if you are sure that your code will be executed in such <span class="No-Break">an environment.</span></p>
<p>The fundamental connection between concurrency and parallelism lies in the fact that parallelism can be applied to concurrent computations without affecting the accuracy of the outcome, but the presence of concurrency alone does not <span class="No-Break">guarantee parallelism.</span></p>
<p>In summary, concurrency is an important concept in computing that allows multiple tasks to be executed simultaneously, even though that is not guaranteed. This could lead to improved performance and efficient resource utilization but at the cost of more complicated code respecting the pitfalls that concurrency brings. On the other hand, truly parallel execution of code is easier to handle from a software perspective but must be supported by the <span class="No-Break">underlying system.</span></p>
<p>In the next section, we will get familiar with the difference between execution threads and processes <span class="No-Break">in Linux.</span></p>
<h1 id="_idParaDest-90"><a id="_idTextAnchor090"/>Threads versus processes</h1>
<p>In Linux, a <strong class="bold">process</strong> is an<a id="_idIndexMarker468"/> instance of a program in execution. A process can have one or more threads of execution. A <strong class="bold">thread</strong> is a <a id="_idIndexMarker469"/>sequence of instructions that<a id="_idIndexMarker470"/> can proceed independently of other threads within the <span class="No-Break">same process.</span></p>
<p>Each process has its own memory space, system resources, and execution context. Processes are isolated from each other and do not share memory by default. They can only <a id="_idIndexMarker471"/>communicate through files and <strong class="bold">inter-process communication</strong> (<strong class="bold">IPC</strong>) mechanisms, such as pipes, queues, sockets, shared memory, and <span class="No-Break">so on.</span></p>
<p>A thread, on <a id="_idIndexMarker472"/>the other hand, is a lightweight unit of execution within a process. The overhead of loading the instructions from non-volatile memory to RAM or even the cache is already paid for by the process creating the thread – the parent process. Each thread has its own stack and register values but shares the memory space and system resources of the parent process. Because threads share memory within the process, they can easily communicate with each other and synchronize their own execution. In general, this makes them more efficient than processes for <span class="No-Break">concurrent execution.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<img alt="Figure 6.3 – IPC" height="312" src="image/Figure_6.03_B20833.jpg" width="929"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – IPC</p>
<p>The main differences between processes and threads are <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">Resource allocation</strong>: Processes are independent entities that have their own memory space, system resources, and scheduling priority. On the other hand, threads share the same memory space and system resources as the process they <span class="No-Break">belong to.</span></li>
<li><strong class="bold">Creation and destruction</strong>: Processes are created and destroyed by the operating system, while threads are created and managed by the process that they <span class="No-Break">belong to.</span></li>
<li><strong class="bold">Context switching</strong>: When a context switch occurs, the operating system switches the entire process context, including all its threads. In contrast, a thread context switch only requires switching the state of the current thread, which, in general, is faster and <span class="No-Break">less resource-intensive.</span></li>
<li><strong class="bold">Communication and synchronization</strong>: IPC mechanisms such as pipes, queues, sockets, and<a id="_idIndexMarker473"/> shared memory are used to enable communication between processes. Threads, on the other hand, can communicate <a id="_idIndexMarker474"/>directly by sharing memory within the same process. This also enables efficient synchronization between threads, as they can use locks and other synchronization primitives to coordinate their access to <span class="No-Break">shared resources.</span></li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">Linux schedules tasks in the kernel, which are either threads or single-threaded processes. Each task is represented through a kernel thread; thus, the scheduler does not differentiate between a thread and <span class="No-Break">a process.</span></p>
<p>Processes and threads have their analogy in real life. Let’s say you are working on a project with a group of people, and the project is divided into different tasks. Each task represents a unit of work that needs to be completed. You can think of the project as a process, and each task as <span class="No-Break">a thread.</span></p>
<p>In this analogy, the process (project) is a collection of related tasks that need to be completed to achieve a common goal. Each task (thread) is a separate unit of work that can be assigned to a specific person <span class="No-Break">to complete.</span></p>
<p>When you assign a task to <a id="_idIndexMarker475"/>someone, you are creating a new thread within the project (process). The person who is assigned the task (thread) can work on it independently, without interfering with the work of others. They may also communicate with other team members (threads) to coordinate their work, just as threads within a process can communicate with each other. They also need to use the common project resource to finish <span class="No-Break">their tasks.</span></p>
<p>In contrast, if<a id="_idIndexMarker476"/> you divide the project into different projects, you create multiple processes. Each process has its own resources, team members, and goals. It is harder to ensure that both processes share a resource needed for the project <span class="No-Break">to finish.</span></p>
<p>So, processes and threads in computing are like real-life projects and tasks, respectively. A process represents a collection of related tasks that need to be completed to achieve a common goal, while a thread is a separate unit of work that can be assigned to a specific person <span class="No-Break">to complete.</span></p>
<p>In Linux, processes are separate instances of a program with their own memory and resources, while threads are lightweight execution units within a process that share the same memory and resources. Threads can communicate more efficiently and are more suitable for tasks that require parallel execution, while processes provide better isolation and <span class="No-Break">fault tolerance.</span></p>
<p>Having all this in mind, let’s see how to write concurrent code <span class="No-Break">in C++.</span></p>
<h1 id="_idParaDest-91"><a id="_idTextAnchor091"/>Concurrency with C++</h1>
<p>The C++ language has <a id="_idIndexMarker477"/>had built-in support for managing and executing concurrent threads since C++11. But it doesn’t have any native support for managing concurrent processes. The C++ Standard Library <a id="_idIndexMarker478"/>provides various classes for thread management, synchronization and communication between threads, protection of shared data, atomic operations, and parallel algorithms. The <strong class="bold">C++ memory model</strong> is <a id="_idIndexMarker479"/>also designed with thread awareness in mind. This makes it a great choice for developing <span class="No-Break">concurrent applications.</span></p>
<p>Multithreading with C++ is the ability to have multiple threads of execution running concurrently within a single program. This allows a program to take advantage of multiple CPU cores and perform tasks in parallel, leading to faster completion of tasks and improved <span class="No-Break">overall performance.</span></p>
<p>The C++ Standard Library<a id="_idIndexMarker480"/> introduced the <strong class="source-inline">std::thread</strong> thread management class. Once it is instantiated, it is the responsibility of the user to take care of the thread’s objective. The users have to choose to either join the thread or detach it from its parent thread. If they don’t take care of it, the <span class="No-Break">program terminates.</span></p>
<p>With the <a id="_idIndexMarker481"/>release of C++20, a brand-new thread management class, <strong class="source-inline">std::jthread</strong>, was introduced. It makes it relatively easy to create and manage threads. To create a new thread, you can create an instance of the <strong class="source-inline">std::jthread</strong> class, passing the function or callable object that you want to run as a separate thread. A key advantage of <strong class="source-inline">std::jthread</strong> compared to <strong class="source-inline">std::thread</strong> is that you don’t have to explicitly worry about joining it. It will be done automatically during the <strong class="source-inline">std::jthread</strong> destruction. Later in the chapter, we will have a deeper look into <strong class="source-inline">std::jthread</strong> and how to <span class="No-Break">use it.</span></p>
<p>Bear in mind that multithreading will also make a program more complex, as it requires careful management of shared resources and synchronization of threads. If not properly managed, multithreading can lead to issues such as deadlocks and race conditions, which can cause a program to hang or produce <span class="No-Break">unexpected results.</span></p>
<p>Additionally, multithreading <a id="_idIndexMarker482"/>requires the developers to ensure that the code is thread-safe, which can be a challenging task. Not all tasks are suitable for multithreading; some tasks may actually run slower if attempted to <span class="No-Break">be parallelized.</span></p>
<p>Overall, multithreading with C++ can provide significant benefits in terms of performance and resource utilization, but it also requires careful consideration of the potential challenges <span class="No-Break">and pitfalls.</span></p>
<p>Now, let’s get familiar with the most common pitfalls of writing <span class="No-Break">concurrent code.</span></p>
<h1 id="_idParaDest-92"><a id="_idTextAnchor092"/>Demystifying race conditions and data races</h1>
<p>In C++, multithreading <a id="_idIndexMarker483"/>support was first introduced with the C++11 version of the language. One of the key elements provided by the C++11 standard<a id="_idIndexMarker484"/> to facilitate multithreading is the memory model. The memory model tackles two problems: the layout of objects in memory and the concurrent access to these objects. In C++, all data is represented by objects, which are blocks of memory that have various properties such as type, size, alignment, lifetime, value, and an optional name. Each object remains in memory for a specific period of time and is stored in one or more memory locations, depending on whether it is a simple scalar object or a more <span class="No-Break">complex type.</span></p>
<p>In the context of <a id="_idIndexMarker485"/>multithreaded<a id="_idIndexMarker486"/> programming in C++, it is crucial to consider how to tackle concurrent access by multiple threads to shared objects. If two or more threads try to access different memory locations, there<a id="_idIndexMarker487"/> is usually no problem. However, when threads attempt to write in the same memory location simultaneously, it can lead to data races, which can cause unexpected behaviors and errors in <span class="No-Break">the program.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">Data races occur when multiple threads try to access data and at least one of them attempts to modify it, and no precautions are taken to synchronize the memory access. Data races can cause undefined behavior in your program and are a source <span class="No-Break">of trouble.</span></p>
<p>But how does your program come to a <em class="italic">data race</em>? This happens when there is a <em class="italic">race condition</em> that hasn’t been properly handled. Let’s have a look into the difference between data races and <span class="No-Break">race conditions:</span></p>
<ul>
<li><strong class="bold">Race condition</strong>: A <a id="_idIndexMarker488"/>situation where the correctness of a code depends on specific timing or a strict sequence <span class="No-Break">of operation</span></li>
<li><strong class="bold">Data race</strong>: When <a id="_idIndexMarker489"/>two or more threads access one object and at least one of these threads <span class="No-Break">modifies it</span></li>
</ul>
<p>Based on these definitions, we can deduce that every data race that occurs in your program comes as a result of not correctly handling race conditions. But the opposite is not always true: not every race condition leads to a <span class="No-Break">data race.</span></p>
<p>There is no better way to understand race conditions and data races than by looking at an example. Let’s imagine a primitive banking system, really primitive, which we hope doesn’t <span class="No-Break">exist anywhere.</span></p>
<p>Bill and John have accounts in a bank. Bill has $100 in his account and John has $50. Bill owes John a total of $30. To pay off his debt, Bill decides to make two transfers to John’s account. The first is worth $10 and the second is $20. So de facto, Bill will repay John. After both transfers are complete, Bill will have $70 left in his account, while John will have accumulated a total <span class="No-Break">of $80.</span></p>
<p>Let’s define <a id="_idIndexMarker490"/>an <strong class="source-inline">Account</strong> structure that contains the name of the owner of the account together with their account balance at a <span class="No-Break">certain moment:</span></p>
<pre class="source-code">
struct Account {
    Account(std::string_view the_owner, unsigned
      the_amount) noexcept :
        balance{the_amount}, owner{the_owner} {}
    std::string GetBalance() const {
        return "Current account balance of " + owner +
                " is " + std::to_string(balance) + '\n';
    }
private:
    unsigned balance;
    std::string owner;
};</pre> <p>In the <strong class="source-inline">Account</strong> structure, we will also add the overloaded operator methods for <strong class="source-inline">+=</strong> and <strong class="source-inline">-=</strong>. These are responsible for depositing or withdrawing a specific amount of money to the corresponding account, respectively. Before and after each of the operations, the current balance of the account is printed. Here is the definition of these operators, which are part of the <span class="No-Break"><strong class="source-inline">Account</strong></span><span class="No-Break"> structure:</span></p>
<pre class="source-code">
Account&amp; operator+=(unsigned amount) noexcept {
        Print(" balance before depositing: ", balance,
          owner);
        auto temp{balance}; // {1}
        std::this_thread::sleep_for(1ms);
        balance = temp + amount; // {2}
        Print(" balance after depositing: ", balance,
          owner);
        return *this;
    }
    Account&amp; operator-=(unsigned amount) noexcept {
        Print(" balance before withdrawing: ", balance,
          owner);
        auto temp{balance}; // {1}
        balance = temp - amount; // {2}
        Print(" balance after withdrawing: ", balance,
          owner);
        return *this;
    }</pre> <p>Looking into <a id="_idIndexMarker491"/>the implementation of the operator functions shows that they first read the current balance of the account, then store it in a local object (marker <strong class="source-inline">{1}</strong>), and finally, using the value of the local object, they increment or decrement with the <span class="No-Break">specified amount.</span></p>
<p>As simple as <span class="No-Break">it gets!</span></p>
<p>The resulting value of the new balance of the account is written back into the <strong class="source-inline">balance</strong> member of the <strong class="source-inline">Account</strong> structure (<span class="No-Break">marker </span><span class="No-Break"><strong class="source-inline">{2}</strong></span><span class="No-Break">).</span></p>
<p>We also need to define a method that will be responsible for the actual <span class="No-Break">money transfer:</span></p>
<pre class="source-code">
void TransferMoney(unsigned amount, Account&amp; from, Account&amp; to) {
    from -= amount; // {1}
    to += amount; // {2}
}</pre> <p>The only thing it does is withdraw the desired amount from one account (marker <strong class="source-inline">{1}</strong>) and deposit <a id="_idIndexMarker492"/>it to the other account (marker <strong class="source-inline">{2}</strong>), which is exactly what we need to successfully transfer money <span class="No-Break">between accounts.</span></p>
<p>Now, let’s have a look at our <strong class="source-inline">main</strong> program method, which will execute <span class="No-Break">our example:</span></p>
<pre class="source-code">
int main() {
    Account bill_account{"Bill", 100}; // {1}
    Account john_account{"John", 50}; // {2}
    std::jthread first_transfer{[&amp;](){ TransferMoney(10,
      bill_account, john_account); }}; // {3}
    std::jthread second_transfer{[&amp;](){ TransferMoney(20,
      bill_account, john_account); }}; // {4}
    std::this_thread::sleep_for(100ms); // {5}
    std::cout &lt;&lt; bill_account.GetBalance(); // {6}
    std::cout &lt;&lt; john_account.GetBalance(); // {7}
    return 0;
}</pre> <p>First, we need to create accounts for Bill and John and deposit $100 and $70 into them, respectively (markers <strong class="source-inline">{1}</strong> and <strong class="source-inline">{2}</strong>). Then, we have to do the actual money transfers: one transfer for $10 and one for $20 (markers <strong class="source-inline">{3}</strong> and <strong class="source-inline">{4}</strong>). I know that this code may look unfamiliar to you but don’t worry, we will deep-dive into <strong class="source-inline">std::jthread</strong> shortly in <span class="No-Break">this chapter.</span></p>
<p>The only important detail you have to know so far is that we try to make both transfers <em class="italic">concurrently</em> with the help of the C++ multithreading library. At the end of the process, we set some time for both execution threads to finish the money transfers (marker <strong class="source-inline">{5}</strong>) and print the result (markers <strong class="source-inline">{6}</strong> and <strong class="source-inline">{7}</strong>). As we already discussed, after the transfers are<a id="_idIndexMarker493"/> finished, Bill should have $70 in his account while John should <span class="No-Break">have $80.</span></p>
<p>Let’s see the <span class="No-Break">program output:</span></p>
<pre class="console">
140278035490560 Bill balance before withdrawing: 100
140278027097856 Bill balance before withdrawing: 100
140278027097856 Bill balance after withdrawing: 80
140278035490560 Bill balance after withdrawing: 90
140278027097856 John balance before depositing: 50
140278035490560 John balance before depositing: 50
140278027097856 John balance after depositing: 70
140278035490560 John balance after depositing: 60
Current account balance of Bill is 80
Current account balance of John is 60</pre> <p>Wait, what? Bill has $80 while John has $60! How is <span class="No-Break">that possible?</span></p>
<p>It’s possible because we created a <em class="italic">race condition</em> that led to a <em class="italic">data race</em>! Let’s explain. Having a deeper look into the implementation of the <strong class="source-inline">operator+=</strong> method reveals the problem. By the way, the situation is absolutely the same with the other operator method <span class="No-Break">as well:</span></p>
<pre class="source-code">
Account&amp; operator+=(unsigned amount) noexcept {
    Print(" balance before withdrawing: ", balance, owner);
    auto temp{balance}; // {1}
    std::this_thread::sleep_for(1ms); // {2}
    balance = temp + amount; // {3}
    Print(" balance after withdrawing: ", balance, owner);
    return *this;
}</pre> <p>At marker <strong class="source-inline">{1}</strong>, we cache the current balance of the account into a local object living on <span class="No-Break">the stack.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">The C++ memory model guarantees that each thread has its own copy of all objects with automatic storage duration – the <span class="No-Break">stack objects.</span></p>
<p>Next, we give the<a id="_idIndexMarker494"/> current execution thread some rest time of at least <strong class="source-inline">1ms</strong> (marker <strong class="source-inline">{2}</strong>). With this statement, we put our thread to sleep, allowing other threads (if any) to take processor time and start executing. Nothing to worry about so far, right? Once the thread is back on executing, it uses its cached value of the account’s balance and increments it with the new amount. Finally, it stores the newly calculated value back to the <strong class="source-inline">balance</strong> member of the <span class="No-Break"><strong class="source-inline">Account</strong></span><span class="No-Break"> structure.</span></p>
<p>Having a closer look into the output of the program, we observe <span class="No-Break">the following:</span></p>
<pre class="console">
140278035490560 Bill balance before withdrawing: 100
140278027097856 Bill balance before withdrawing: 100
140278027097856 Bill balance after withdrawing: 80
140278035490560 Bill balance after withdrawing: 90</pre> <p>The first transfer starts executing. It is running as part of a thread with the <strong class="source-inline">140278035490560</strong> identifier. We see that before the withdrawal is finished, the second transfer is started too. Its identifier is <strong class="source-inline">140278027097856</strong>. The second transfer finishes the withdrawal first, leaving Bill’s bank account with a balance of $80. Then, the first withdrawal is back in action. But what happens then? Instead of taking $10 more from Bill’s account, it actually returns $10! This happens because the first thread was suspended when it had already cached the initial account balance of $100. A <em class="italic">race condition</em> was created. Meanwhile, the second transfer has changed the account balance, and now, when the first transfer is back to execution, it already works with outdated cached values. This results in blindly overriding the newer account balance with the outdated value. A <em class="italic">data </em><span class="No-Break"><em class="italic">race</em></span><span class="No-Break"> happened.</span></p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor093"/>How do we avoid them?</h2>
<p>Luckily, the C++ programming language provides various concurrency control mechanisms to address these challenges, such as atomic operations, locks, semaphores, condition variables, barriers, and others. These mechanisms help ensure that shared resources are accessed in a predictable and safe manner and that threads are coordinated effectively to avoid a data race. In the next sections, we will get deeper into some of these <span class="No-Break">synchronization primitives.</span></p>
<h1 id="_idParaDest-94"><a id="_idTextAnchor094"/>Practical multithreading</h1>
<p>In computer science, a thread of <a id="_idIndexMarker495"/>execution is a sequence of code instructions that can be managed independently by a scheduler of the operating system. On a Linux system, the thread is always part of a process. The C++ threads<a id="_idIndexMarker496"/> could be executed concurrently with each other via the multithreading capabilities provided by the standard. During execution, threads share common memory space, unlike processes, where each has its own. Specifically, the threads of a process share its executable code, the dynamically and globally allocated objects, which are not defined <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">thread_local</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor095"/>Hello C++ jthread</h2>
<p>Every C++ program contains at least <a id="_idIndexMarker497"/>one thread, and this is the thread that runs the <strong class="source-inline">int main()</strong> method. Multithreaded programs have additional threads started at some point in the execution of the main thread. Let’s have a <a id="_idIndexMarker498"/>look at a simple C++ program that uses multiple threads to print to the <span class="No-Break">standard output:</span></p>
<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;syncstream&gt;
#include &lt;array&gt;
int main() {
    std::array&lt;std::jthread, 5&gt; my_threads; // Just an
      array of 5 jthread objects which do nothing.
    const auto worker{[]{
        const auto thread_id = std::
           this_thread::get_id();  // 3
        std::osyncstream sync_cout{std::cout};
        sync_cout &lt;&lt; "Hello from new jthread with id:"
                  &lt;&lt; thread_id &lt;&lt; '\n';
    }};
    for (auto&amp; thread : my_threads) {
        thread = std::jthread{worker}; // This moves the
          new jthread on the place of the placeholder
    }
    std::osyncstream{std::cout} &lt;&lt; "Hello Main program
      thread with id:" &lt;&lt; std::this_thread::get_id() &lt;&lt;
        '\n';
    return 0; // jthread dtors join them here.
}</pre> <p>When the program <a id="_idIndexMarker499"/>starts, the <strong class="source-inline">int main()</strong> method is entered. Nothing surprising so far. At the beginning of the execution, we create a variable on the method stack, called <strong class="source-inline">my_threads</strong>. It is a type of <strong class="source-inline">std::array</strong>, which <a id="_idIndexMarker500"/>contains five elements in it. The <strong class="source-inline">std::array</strong> type represents a container from the Standard Library, encapsulating C-style, fixed-sized arrays. It has the advantages of a standard container, such as being aware of its own size, supporting assignment, random access iterators, and so on. As with any other array type in C++, we need to specify what kind of elements it contains. In our example, <strong class="source-inline">my_threads</strong> contains five <strong class="source-inline">std::jthread</strong> objects. The <strong class="source-inline">std::jthread</strong> class <a id="_idIndexMarker501"/>was introduced in the C++ Standard Library with the C++20 standard release. It represents a single thread of execution, just like <strong class="source-inline">std::thread</strong>, which was introduced with the release of C++11. Some advantages of <strong class="source-inline">std::jthread</strong> compared to <strong class="source-inline">std::thread</strong> are <a id="_idIndexMarker502"/>that it automatically rejoins on destruction and it can be canceled or stopped in some specific cases. It is defined in the <strong class="source-inline">&lt;thread&gt;</strong> header; therefore, we must include it in order to <span class="No-Break">compile successfully.</span></p>
<p>Yes, you are asking the<a id="_idIndexMarker503"/> right question! If we already defined an array of <strong class="source-inline">jthread</strong> objects, what job do they really perform? The expectation is that every thread is associated with some job that needs to be done. But here, the simple answer is <em class="italic">nothing</em>. Our array contains five <strong class="source-inline">jthread</strong> objects, which don’t actually represent an execution thread. They are used more like placeholders because, when <strong class="source-inline">std::array</strong> is instantiated, it also creates the objects it contains using their default constructors if no other arguments <span class="No-Break">are passed.</span></p>
<p>Let’s now define<a id="_idIndexMarker504"/> some workers that our threads can be associated with. The <strong class="source-inline">std::jthread</strong> class accepts, as a worker, any <em class="italic">callable</em> type. Such types provide a single operation that can be invoked. Widely known examples of such types are function objects and lambda expressions, which we already covered in detail in <a href="B20833_04.xhtml#_idTextAnchor060"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>. In our example, we will use lambda expressions because they provide a way of creating anonymous function objects (functors) that can be utilized in-line or passed as an argument. The introduction of lambda expressions in C++11 simplifies the process of creating anonymous functors, making it more efficient and straightforward. The following code shows our worker method defined as a <span class="No-Break">lambda expression:</span></p>
<pre class="source-code">
const auto worker{[]{
    const auto thread_id = std::this_thread::get_id();
    std::osyncstream sync_cout{std::cout};
    sync_cout &lt;&lt; "Hello from new jthread with id:" &lt;&lt;
      thread_id &lt;&lt; '\n';
}};</pre> <p>The defined lambda expression, <strong class="source-inline">const auto worker{…};</strong>, is pretty simple. It is instantiated on the function stack. It has no input parameters, and it doesn’t capture any state from outside. The only work it does is to print to the standard output the <strong class="source-inline">jthread</strong> object’s ID. Every thread in C++ provided by the standard concurrency support library has a unique identifier associated with it. The <strong class="source-inline">std::this_thread::get_id()</strong> method returns the ID of the specific thread in which it has been invoked. This means that if this lambda expression is passed to several different threads, it should print a different <span class="No-Break">thread ID.</span></p>
<p>Printing to <strong class="source-inline">std::cout</strong> by <a id="_idIndexMarker505"/>many concurrent threads could bring surprising results. The <strong class="source-inline">std::cout</strong> object is defined as a global, thread-safe object, which<a id="_idIndexMarker506"/> ensures that each character written to it is done so atomically. However, no guarantees are made about a sequence of characters such as strings, and it is likely that the output when multiple threads are concurrently writing strings to <strong class="source-inline">std::cout</strong> will be a mixture of these strings. Well, this is not what we really want here. We expect that each thread will be able to fully print its messages. Therefore, we need a synchronization mechanism, which ensures that writing a string to <strong class="source-inline">std::cout</strong> is fully atomic. Luckily, C++20 introduces a whole new family of class templates defined in the <strong class="source-inline">&lt;syncstream&gt;</strong> standard library header, which provides mechanisms to synchronize threads writing to one and the same stream. One of them is <strong class="source-inline">std::osyncstream</strong>. You can use it as a regular stream. Just create an instance of it by passing <strong class="source-inline">std::cout</strong> as a parameter. Then, with the help of its <strong class="source-inline">std::basic_ostream&amp; operator&lt;&lt;(...)</strong> class method, you can insert data, just like a regular stream. It is guaranteed that all of the inserted data will be flushed atomically to the output once the <strong class="source-inline">std::osyncstream</strong> object goes out of scope and is destroyed. In our example, the <strong class="source-inline">sync_cout</strong> object will be destroyed when the lambda is about to finish its execution and leave its scope. This is exactly the behavior <span class="No-Break">we want.</span></p>
<p>Finally, we are ready <a id="_idIndexMarker507"/>to give some work to our threads to do. This means that we need to associate worker lambdas with the five threads we have in the <strong class="source-inline">my_threads</strong> array. But the <strong class="source-inline">std::jthread</strong> type supports adding a worker method only as part of its construction. That’s why we need to create other <strong class="source-inline">jthread</strong> objects and replace them with the placeholders in the <span class="No-Break"><strong class="source-inline">my_threads</strong></span><span class="No-Break"> array:</span></p>
<pre class="source-code">
for (auto&amp; thread : my_threads) {
    thread = jthread{worker}; // This moves the new jthread
      on the place of the placeholder
}</pre> <p>Being a standard container, <strong class="source-inline">std::array</strong> natively supports range-based for loops. Therefore, we can easily iterate through all elements in <strong class="source-inline">my_threads</strong> and replace them with new <strong class="source-inline">jthread</strong> objects that already have associated workers with them. Firstly, we create new <strong class="source-inline">jthread</strong> objects with automatic storage duration and assign them a worker object. In our case, for every newly created thread, we assign one and the same worker object. This is possible because, in the current case, the <strong class="source-inline">jthread</strong> class makes a copy of the worker instance in the <strong class="source-inline">jthread</strong> objects and, therefore, each <strong class="source-inline">jthread</strong> object gets its own copy of the worker lambda. When constructing these objects, the process is carried out within the context of the caller. This means that any exceptions that occur during the evaluation and copying or movement of the arguments are thrown in the current <span class="No-Break"><strong class="source-inline">main</strong></span><span class="No-Break"> thread.</span></p>
<p>An important<a id="_idIndexMarker508"/> detail is that the newly created <strong class="source-inline">jthread</strong> objects are not copied to the existing elements of the array, but they are moved. Therefore, the <strong class="source-inline">std::jthread</strong> class has implicitly deleted its copy constructor and assignment operator because it doesn’t make much sense to copy a thread to an already existing thread. In our case, the newly created <strong class="source-inline">jthread</strong> objects will be created in the storage of the existing <span class="No-Break">array elements.</span></p>
<p>When a <strong class="source-inline">jthread</strong> object is<a id="_idIndexMarker509"/> constructed, the associated thread starts immediately, although there may be some delays due to Linux scheduling specifics. The thread begins executing at the function specified as an argument to the constructor. In our example, this is the worker lambda associated with each thread. If the worker returns a result, it will be ignored, and if it ends by throwing an exception, the <strong class="source-inline">std::terminate</strong> function is executed. Therefore, we need to make sure that either our worker code doesn’t throw or we catch <span class="No-Break">everything throwable.</span></p>
<p>When a thread is started, it begins executing its dedicated worker. Each thread has its own function stack space, which guarantees that any local variable defined in the worker will have a separate instance per thread. Therefore, <strong class="source-inline">const auto thread_id</strong> in the worker is initialized with a different ID depending on the thread it is run by. We do not need to take any precautions to ensure that the data stored in <strong class="source-inline">thread_id</strong> is consistent. It is guaranteed by the Standard that data with automatic storage duration is not shared between <span class="No-Break">the threads.</span></p>
<p>Once all the <strong class="source-inline">jthread</strong> objects have been created, the <strong class="source-inline">main</strong> thread concurrently prints its ID along with the rest of the threads. There is no guaranteed order of execution for each thread, and it is possible for one thread to be interrupted by another. As a result, it is important to ensure that the code is written in a manner that can handle potential preemption and remains robust in <span class="No-Break">all scenarios:</span></p>
<pre class="source-code">
std::osyncstream{std::cout} &lt;&lt; "Hello Main program thread
  with id:" &lt;&lt; std::this_thread::get_id() &lt;&lt; '\n';</pre> <p>All threads are now running<a id="_idIndexMarker510"/> concurrently with the <strong class="source-inline">main</strong> thread. We need to make sure that the <strong class="source-inline">main</strong> thread is also printing to the standard output in a thread-safe manner. We again use an instance of <strong class="source-inline">std::osyncstream</strong>, but this time, we don’t create a named variable – instead, we create a temporary one. This approach is favored due to its ease of use, similar <a id="_idIndexMarker511"/>to using the <strong class="source-inline">std::cout</strong> object. The standard guarantees that the output will be flushed at the end of each statement, as the temporary ones persist until the end of the statement and their destructor is invoked, resulting in the flushing of <span class="No-Break">the output.</span></p>
<p>Here is a sample output from <span class="No-Break">the program:</span></p>
<pre class="console">
Hello from new jthread with id:1567180544
Hello from new jthread with id:1476392704
Hello from new jthread with id:1468000000
Hello Main program thread with id:1567184704
Hello from new jthread with id:1558787840
Hello from new jthread with id:1459607296</pre> <p>The <strong class="source-inline">std::jthread</strong> name refers to a <em class="italic">joining</em> thread. Unlike <strong class="source-inline">std::thread</strong>, <strong class="source-inline">std::jthread</strong> also has the ability to <em class="italic">automatically</em> join the thread that it has been started by. The behavior of <strong class="source-inline">std::thread</strong> can be confusing at times. If <strong class="source-inline">std::thread</strong> has not been joined or detached, and it is still considered <em class="italic">joinable</em>, the <strong class="source-inline">std::terminate</strong> function will be called upon its destruction. A thread is considered joinable if neither the <strong class="source-inline">join()</strong> nor the <strong class="source-inline">detach()</strong> method has been called. In our example, all the <strong class="source-inline">jthread</strong> objects automatically join during their destruction and do not result in the termination of <span class="No-Break">the program.</span></p>
<h2 id="_idParaDest-96"><a id="_idTextAnchor096"/>Canceling threads – is this really possible?</h2>
<p>Before C++ 20 was<a id="_idIndexMarker512"/> released, this wasn’t quite possible. It was not guaranteed that <strong class="source-inline">std::thread</strong> was stoppable in the sense that there wasn’t a standard utility to halt the thread’s execution. Different mechanisms were used instead. Stopping <strong class="source-inline">std::thread</strong> required cooperation between the <strong class="source-inline">main</strong> and worker threads, typically using a flag or atomic variable or some kind of <span class="No-Break">messaging system.</span></p>
<p>With the release of C++20, there is now a standardized utility for requesting <strong class="source-inline">std::jthread</strong> objects to stop their execution. The stop tokens come to help. Looking at the C++ standard reference page about the<a id="_idIndexMarker513"/> definition of <strong class="source-inline">std::jthread</strong> (<a href="https://en.cppreference.com/w/cpp/thread/jthread">https://en.cppreference.com/w/cpp/thread/jthread</a>), we find <span class="No-Break">the following:</span></p>
<p class="author-quote">“The class jthread represents a single thread of execution. It has the same general behavior as std::thread, except that jthread automatically rejoins on destruction, and can be canceled/stopped in certain situations.”</p>
<p>We already saw that <strong class="source-inline">jthread</strong> objects automatically join on destruction, but what about canceling/stopping and what does “certain situations” mean? Let’s dig deeper <span class="No-Break">into this.</span></p>
<p>First of all, don’t <a id="_idIndexMarker514"/>expect that <strong class="source-inline">std::jthread</strong> exposes some magical mechanism, some red button that stops the running thread when it is pressed. It is always a matter of implementation, how exactly your worker function is implemented. If you want your thread to be cancelable, you have to make sure that you have implemented it in the right way in order to <span class="No-Break">allow cancellation:</span></p>
<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;syncstream&gt;
#include &lt;thread&gt;
#include &lt;array&gt;
using namespace std::literals::chrono_literals;
int main() {
    const auto worker{[](std::stop_token token, int num){
      // {1}
        while (!token.stop_requested()) { // {2}
            std::osyncstream{std::cout} &lt;&lt; "Thread with id
              " &lt;&lt; num &lt;&lt; " is currently working.\n";
            std::this_thread::sleep_for(200ms);
        }
        std::osyncstream{std::cout} &lt;&lt; "Thread with id " &lt;&lt;
          num &lt;&lt; " is now stopped!\n";
    }};
    std::array&lt;std::jthread, 3&gt; my_threads{
        std::jthread{worker, 0},
        std::jthread{worker, 1},
        std::jthread{worker, 2}
    };
    // Give some time to the other threads to start
      executing …
    std::this_thread::sleep_for(1s);
    // 'Let's stop them
    for (auto&amp; thread : my_threads) {
        thread.request_stop(); // {3} - this is not a
          blocking call, it is just a request.
    }
    std::osyncstream{std::cout} &lt; "Main thread just
      requested stop!\n";
    return 0; // jthread dtors join them here.
}</pre> <p>Looking at the <a id="_idIndexMarker515"/>definition of our worker lambda function, we observe that it is now slightly reworked (marker <strong class="source-inline">{1}</strong>). It accepts two new parameters – <strong class="source-inline">std::stop_token token</strong> and <strong class="source-inline">int num</strong>. The stop token reflects the shared stop state that a <strong class="source-inline">jthread</strong> object has. If the worker method accepts many parameters, then the stop token must always be the first <span class="No-Break">parameter passed.</span></p>
<p>It is imperative to ensure that the worker method is designed to be able to handle cancellation. This is what the stop token is used for. Our logic should be implemented in such a way that it regularly checks whether a stop request has been received. This is done with a call to the <strong class="source-inline">stop_requested()</strong> method of the <strong class="source-inline">std::stop_token</strong> object. Every specific implementation decides where and when these checks are to be done. If the code doesn’t respect the stop token state, then the thread can’t be canceled gracefully. So, it’s up to you to correctly design <span class="No-Break">your code.</span></p>
<p>Luckily, our worker <a id="_idIndexMarker516"/>lambda respects the state of the thread’s stop token. It continuously checks whether a stop is requested (marker <strong class="source-inline">{2}</strong>). If not, it prints the thread’s ID and goes to sleep for <strong class="source-inline">200ms</strong>. This loop continues until the parent thread decides to send stop requests to its worker threads (marker <strong class="source-inline">{3}</strong>). This is done by invoking the <strong class="source-inline">request_stop()</strong> method of the <span class="No-Break"><strong class="source-inline">std::jthread</strong></span><span class="No-Break"> object.</span></p>
<p>Here is the output of <span class="No-Break">the program:</span></p>
<pre class="console">
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 0 is currently working.
Thread with id 2 is currently working.
Thread with id 1 is currently working.
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 0 is currently working.
Thread with id 2 is currently working.
Main thread just requested stop!
Thread with id 1 is now stopped!
Thread with id 0 is now stopped!
Thread with id 2 is now stopped!</pre> <p>Now that we know how<a id="_idIndexMarker517"/> we can stop the execution of a specific <strong class="source-inline">std::jthread</strong> using <strong class="source-inline">std::stop_token</strong>, let’s see how we can stop the execution of multiple <strong class="source-inline">std::jthread</strong> objects using a single <span class="No-Break">stop source.</span></p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor097"/>std::stop_source</h2>
<p>The <strong class="source-inline">std::stop_source</strong> class <a id="_idIndexMarker518"/>enables you to<a id="_idIndexMarker519"/> signal a cancellation request for <strong class="source-inline">std::jthread</strong>. When a stop request is issued through a <strong class="source-inline">stop_source</strong> object, it becomes visible to all other <strong class="source-inline">stop_source</strong> and <strong class="source-inline">std::stop_token</strong> objects associated with the same stop state. You just need to signal it, and any thread worker that consumes it will <span class="No-Break">be notified.</span></p>
<p>By utilizing <strong class="source-inline">std::stop_token</strong> and <strong class="source-inline">std::stop_source</strong>, threads can signal or check for a request to stop their execution asynchronously. The request to stop is made through <strong class="source-inline">std::stop_source</strong>, which affects all related <strong class="source-inline">std::stop_token</strong> objects. These tokens can be passed to the worker functions and used to monitor stop requests. Both <strong class="source-inline">std::stop_source</strong> and <strong class="source-inline">std::stop_token</strong> share ownership of the stop state. The method of the <strong class="source-inline">std::stop_source</strong> class – <strong class="source-inline">request_stop()</strong> – and the methods in <strong class="source-inline">std::stop_token</strong> – <strong class="source-inline">stop_requested()</strong> and <strong class="source-inline">stop_possible()</strong> – are all atomic operations to ensure that no data race <span class="No-Break">will occur.</span></p>
<p>Let’s have a look at how our previous example could be reworked with the help of the <span class="No-Break">stop tokens:</span></p>
<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;syncstream&gt;
#include &lt;thread&gt;
#include &lt;array&gt;
using namespace std::literals::chrono_literals;
int main() {
    std::stop_source source;
    const auto worker{[](std::stop_source sr, int num){
        std::stop_token token = sr.get_token();
        while (!token.stop_requested()) {
            std::osyncstream{std::cout} &lt;&lt; "Thread with id
              " &lt;&lt; num &lt;&lt; " is currently working.\n";
            std::this_thread::sleep_for(200ms);
        }
        std::osyncstream{std::cout} &lt;&lt; "Thread with id " &lt;&lt;
          num &lt;&lt; " is now stopped!\n";
    }};
    std::array&lt;std::jthread, 3&gt; my_threads{
        std::jthread{worker, source, 0},
        std::jthread{worker, source, 1},
        std::jthread{worker, source, 2}
    };
    std::this_thread::sleep_for(1s);
    source.request_stop(); // this is not a blocking call,
      it is just a request. {1}
    Std::osyncstream{std::cout} &lt;&lt; "Main thread just
      requested stop!\n";
    return 0; // jthread dtors join them here.
}</pre> <p>The <strong class="source-inline">main</strong> method starts with the declaration of the <strong class="source-inline">std::stop_source</strong> source, which will be<a id="_idIndexMarker520"/> used by the <strong class="source-inline">main</strong> thread to signal all child worker threads and request them to stop. The worker lambda is slightly reworked in order to accept <strong class="source-inline">std::stop_source sr</strong> as an input. This is in fact the communication channel through which the worker is notified for a stop request. The <strong class="source-inline">std::stop_source</strong> object is copied in all workers associated with the <span class="No-Break">started threads.</span></p>
<p>Rather than<a id="_idIndexMarker521"/> iterating through all the threads and invoking on each of them a stop request, the only operation that we need to invoke is to directly call <strong class="source-inline">request_stop()</strong> on the source instance in the <strong class="source-inline">main</strong> thread (marker <strong class="source-inline">{1}</strong>). This will broadcast stop requests to all workers that <span class="No-Break">consume it.</span></p>
<p>As the name suggests, the call to the <strong class="source-inline">request_stop()</strong> method on the stop source object is just a request rather than a blocking call. So, don’t expect your threads to stop immediately once the call <span class="No-Break">is finished.</span></p>
<p>Here is the sample output from <span class="No-Break">the program:</span></p>
<pre class="console">
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 2 is currently working.
Thread with id 0 is currently working.
Thread with id 1 is currently working.
Thread with id 0 is currently working.
Thread with id 2 is currently working.
Thread with id 1 is currently working.
Thread with id 0 is currently working.
Thread with id 2 is currently working.
Main thread just requested stop!
Thread with id 1 is now stopped!
Thread with id 0 is now stopped!
Thread with id 2 is now stopped!</pre> <p>We are <a id="_idIndexMarker522"/>now familiar with two mechanisms for halting <a id="_idIndexMarker523"/>thread execution in C++. Now, it’s time to see how we can share data between <span class="No-Break">multiple threads.</span></p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor098"/>Sharing data during parallel execution</h1>
<p><em class="italic">Think in terms of tasks rather than </em><span class="No-Break"><em class="italic">threads</em></span><span class="No-Break"> (</span><a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#cp4-think-in-terms-of-tasks-rather-than-threads"><span class="No-Break">https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#cp4-think-in-terms-of-tasks-rather-than-threads</span></a><span class="No-Break">).</span></p>
<p>Referring <a id="_idIndexMarker524"/>back to the <em class="italic">C++ Core Guidelines</em>, they advise us that it is better to stick to tasks rather than threads. A thread is a technical implementation idea, a perspective on how the machine works. On the<a id="_idIndexMarker525"/> other hand, a task is a practical concept for work that you want to do, ideally alongside other tasks. In general, practical concepts are simpler to understand and provide better abstraction, and we <span class="No-Break">prefer them.</span></p>
<p>But what is a task in C++? Is it another standard library primitive or what? Let’s have <span class="No-Break">a look!</span></p>
<p>In C++, besides threads, tasks are also available to perform work asynchronously. A task consists of a worker and two <a id="_idIndexMarker526"/>associated components: a <strong class="bold">promise</strong> and a <strong class="bold">future</strong>. These components are connected through a shared state, which is a kind of data channel. The promise <a id="_idIndexMarker527"/>does the work and places the result in the shared state, while the future retrieves<a id="_idIndexMarker528"/> the result. Both the promise and the future can run in separate threads. One unique aspect of the future is that it can retrieve the result at a later time, making the calculation of the result by the promise independent from the retrieval of the result by the <span class="No-Break">associated future.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<img alt="Figure 6.4 – Inter-thread communication" height="205" src="image/Figure_6.04_B20833.jpg" width="588"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Inter-thread communication</p>
<p>The <strong class="source-inline">&lt;future&gt;</strong> header, defined<a id="_idIndexMarker529"/> in the<a id="_idIndexMarker530"/> Standard Library, is necessary for utilizing tasks. It provides the capability to obtain the results of functions executed in separate threads, also<a id="_idIndexMarker531"/> referred to as <strong class="bold">asynchronous tasks</strong>, and to manage any exceptions they may throw. Using the <strong class="source-inline">std::promise</strong> class, these results are communicated through a shared state, where the asynchronous task can store its return value or an exception. This shared state can then be accessed using <strong class="source-inline">std::future</strong> to retrieve the return value or the <span class="No-Break">stored exception.</span></p>
<p>Let’s have a look at a simple example where a thread reports a string as a result to its <span class="No-Break">parent thread:</span></p>
<pre class="source-code">
#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
using namespace std::literals::chrono_literals;
int main() {
    std::promise&lt;std::string&gt; promise; // {1}
    std::future&lt;std::string&gt; future{promise.get_future()};
      // {2} – Get the future from the promise.
    std::jthread th1{[p{std::move(promise)}]() mutable { //
      {3} – Move the promise inside the worker thread.
        std::this_thread::sleep_for(20ms);
        p.set_value_at_thread_exit("I promised to call you
          back once I am ready!\n"); // {4}
    }};
    std::cout &lt;&lt; "Main thread is ready.\n";
    std::cout &lt;&lt; future.get(); // {5} – This is a blocking
      call!
    return 0;
}</pre> <p>As we already<a id="_idIndexMarker532"/> discussed, threads <a id="_idIndexMarker533"/>communicate with each other using a shared state. In the <strong class="source-inline">int main()</strong> method, we declare <strong class="source-inline">std::promise&lt;std::string&gt; promise</strong>, which is our de facto data source (marker <strong class="source-inline">{1}</strong>). The <strong class="source-inline">std::promise</strong> class is a template class that needs to be parameterized once it is instantiated. In our example, we want our worker thread, <strong class="source-inline">std::thread th1</strong>, to return a string as a result. Therefore, we instantiate <strong class="source-inline">std::promise</strong> with the <strong class="source-inline">std::string</strong> type. We also need a way for the <strong class="source-inline">main</strong> thread to be able to get the result that will be set by the worker thread. In order to do so, we need to get a <strong class="source-inline">std::future</strong> object from the promise we already instantiated. This is possible because the <strong class="source-inline">std::promise</strong> type has a method that returns its associated future – <strong class="source-inline">std::future&lt;...&gt; get_future()</strong>. In our example, we instantiate a future object, <strong class="source-inline">future</strong>, which is initialized by the <strong class="source-inline">get_future()</strong> method of the promise (<span class="No-Break">marker </span><span class="No-Break"><strong class="source-inline">{2}</strong></span><span class="No-Break">).</span></p>
<p>Since we already have a promise and its associated future, we are now ready to move the promise as part of the worker thread. We are moving it in order to be sure that it won’t be used by the <strong class="source-inline">main</strong> thread anymore (marker <strong class="source-inline">{3}</strong>). Our worker thread is quite simple, and it just sleeps for <strong class="source-inline">20ms</strong> and sets the result in the promise (marker <strong class="source-inline">{4}</strong>). The <strong class="source-inline">std::promise</strong> type provides several ways to set a result. The result could be either a value of type by which the promise is parameterized or it could be an exception thrown during worker execution. The value is set by the <strong class="source-inline">set_value()</strong> and <strong class="source-inline">set_value_at_thread_exit()</strong>methods. The main difference between both methods is that <strong class="source-inline">set_value()</strong> immediately notifies the shared state that the value is ready, whereas <strong class="source-inline">set_value_at_thread_exit()</strong> does it when the thread execution <span class="No-Break">is finished.</span></p>
<p>Meanwhile, the <strong class="source-inline">main</strong> thread execution has been blocked waiting for the result of the worker <a id="_idIndexMarker534"/>thread. This<a id="_idIndexMarker535"/> is done on the call to the <strong class="source-inline">future.get()</strong> method. This is a blocking call on which the waiting thread is blocked until the shared state is notified that the result of the future is set. In our example, this happens after the completion of the worker thread because the shared state is only notified when the worker is finished (<span class="No-Break">marker </span><span class="No-Break"><strong class="source-inline">{5}</strong></span><span class="No-Break">).</span></p>
<p>The expected output from the program is <span class="No-Break">as follows:</span></p>
<pre class="console">
Main thread is ready.
I promised to call you back once I am ready!</pre> <h2 id="_idParaDest-99"><a id="_idTextAnchor099"/>Barriers and latches</h2>
<p>New thread <a id="_idIndexMarker536"/>synchronization primitives were introduced with the C++20 standard. Barriers and latches are straightforward thread synchronization primitives that block threads to wait until a counter reaches zero. These primitives are offered by the standard library in the form of the <strong class="source-inline">std::latch</strong> and <span class="No-Break"><strong class="source-inline">std::barrier</strong></span><span class="No-Break"> classes.</span></p>
<p>What distinguishes these two synchronization mechanisms? The key difference is that <strong class="source-inline">std::latch</strong> can<a id="_idIndexMarker537"/> only be used once, while <strong class="source-inline">std::barrier</strong> can be used multiple times by <span class="No-Break">multiple threads.</span></p>
<p>What advantages do barriers and latches offer over other synchronization primitives that the C++ standard provides, such as condition variables and locks? Barriers and latches are easier to use, more intuitive, and, in some circumstances, may provide <span class="No-Break">better performance.</span></p>
<p>Let’s have a<a id="_idIndexMarker538"/> look at <a id="_idIndexMarker539"/>the <span class="No-Break">following example:</span></p>
<pre class="source-code">
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;array&gt;
#include &lt;latch&gt;
#include &lt;syncstream&gt;
using namespace std::literals::chrono_literals;
int main() {
    std::latch progress{2}; // {1}
    std::array&lt;std::jthread, 2&gt; threads {
        std::jthread{[&amp;](int num){
            std::osyncstream{std::cout} &lt;&lt; "Starting thread
              " &lt;&lt; num &lt;&lt; " and go to sleep.\n";
            std::this_thread::sleep_for(100ms);
            std::osyncstream{std::cout} &lt;&lt; "Decrementing
              the latch for thread " &lt;&lt; num &lt;&lt; '\n';
            progress.count_down(); // {2}
            std::osyncstream{std::cout} &lt;&lt; "Thread " &lt;&lt; num
              &lt;&lt; " finished!\n";
        }, 0},
        std::jthread{[&amp;](int num){
            std::osyncstream{std::cout} &lt;&lt; "Starting thread
              " &lt;&lt; num &lt;&lt; ". Arrive on latch and wait to
                 become zero.\n";
            progress.arrive_and_wait(); // {3}
            std::osyncstream{std::cout} &lt;&lt; "Thread " &lt;&lt; num
              &lt;&lt; " finished!\n";
        }, 1}
    };
    std::osyncstream{std::cout} &lt;&lt; "Main thread waiting
      workers to finish.\n";
    progress.wait(); // {4} wait for all threads to finish.
    std::cout &lt;&lt; "Main thread finished!\n";
    return 0;
}</pre> <p>We have an array of two threads that are synchronized on a latch. This means that each thread starts its execution and does its work until it reaches <span class="No-Break">the latch.</span></p>
<p>The <strong class="source-inline">std::latch</strong> class <a id="_idIndexMarker540"/>is a synchronization mechanism that utilizes a downward-counting <a id="_idIndexMarker541"/>counter to coordinate threads. The counter is set at initialization and passed as an argument to the constructor. The threads can then wait until the counter reaches zero. It is not possible to increase or reset the counter once it is initialized. Access to the member functions of <strong class="source-inline">std::latch</strong> from multiple threads concurrently is guaranteed to be thread-safe and free from <span class="No-Break">data races.</span></p>
<p>In our example (marker <strong class="source-inline">{1}</strong>), we have initialized the latch with a value of <strong class="source-inline">2</strong> because we have two worker threads that need to be synchronized with the main one. Once the worker reaches the latch, it has <span class="No-Break">three options:</span></p>
<ul>
<li>Decrement it and continue (marker <strong class="source-inline">{2}</strong>). This is done using the member of the <strong class="source-inline">std::latch</strong> class – <strong class="source-inline">void count_down(n = 1)</strong>. This call is non-blocking and automatically decrements the latch’s internal counter value by <strong class="source-inline">n</strong>. It is undefined behavior if you try to decrement with a negative value or with a value greater than the value that the internal counter currently has. In our example, this is a worker thread with an ID of <strong class="source-inline">0</strong>, which, once it is ready, decrements the latch counter <span class="No-Break">and finishes.</span></li>
<li>Decrement it<a id="_idIndexMarker542"/> and wait until the latch becomes zero (marker <strong class="source-inline">{3}</strong>). In order to do so, you have to use another method of the <strong class="source-inline">std::latch</strong> class – <strong class="source-inline">void arrive_and_wait(n = 1)</strong>. This method, once it is invoked, decrements the latch by <strong class="source-inline">n</strong> and blocks it until the latch’s internal counter hits <strong class="source-inline">0</strong>. In our example, this is a worker thread with an ID of <strong class="source-inline">1</strong>, which, once it is ready, starts waiting until the other worker <span class="No-Break">is finished.</span></li>
<li>Just block and <a id="_idIndexMarker543"/>wait until the internal counter of the latch becomes zero (marker <strong class="source-inline">{4}</strong>). This is possible because <strong class="source-inline">std::latch</strong> provides a method – <strong class="source-inline">void wait() const</strong>. This is a blocking call on which the invoking thread is blocked until the internal counter of the latch hits zero. In our example, the <strong class="source-inline">main</strong> thread blocks and starts waiting for the worker threads to finish <span class="No-Break">their execution.</span></li>
</ul>
<p>The result of our program is that the <strong class="source-inline">main</strong> thread execution is suspended until the worker threads finish their jobs. The <strong class="source-inline">std::latch</strong> class provides a convenient way to synchronize the execution of <span class="No-Break">several threads:</span></p>
<pre class="console">
Main thread waiting workers to finish.
Starting thread 1. Arrive on latch and wait to become zero.
Starting thread 0 and go to sleep.
Decrementing the latch for thread 0
Thread 0 finished!
Main thread finished!
Thread 1 finished!</pre> <p>Another very similar synchronization primitive to <strong class="source-inline">std::latch</strong> is <strong class="source-inline">std::barrier</strong>. Barriers are thread synchronization primitives that permit a group of threads to wait until all of them reach a specific synchronization point. Unlike a latch, a barrier can be used multiple times. Once the threads have been released from the synchronization point, they can reuse the barrier. A synchronization point is a specific moment where a thread can pause its execution until a specific condition has been met. This makes barriers ideal for synchronizing repeated tasks or executing different phases from the same bigger task by <span class="No-Break">many threads.</span></p>
<p>In order to get a<a id="_idIndexMarker544"/> better understanding of what barriers are, let’s use an<a id="_idIndexMarker545"/> example. Imagine that you have a network of temperature sensors installed in your home. In each room, there is a sensor installed. Each sensor takes a temperature measurement at a specific time period and the result is buffered in its memory. When the sensor does 10 measurements, it sends them as a chunk to a server. This server is responsible for collecting all measurements from all sensors in your home and calculating temperature mean values – the mean temperature for each room and the mean temperature for your <span class="No-Break">entire home.</span></p>
<p>Let’s discuss the algorithm now. In order to calculate the mean temperature of your entire home, we first need to process the temperature measurements done by the sensors that are sent to the server at some specific time period. This means that we need to process all the temperature samples received for a specific room to calculate the mean temperature for that room, and we need to do this for all the rooms in your home. Finally, with the calculated mean temperatures for each room, we can calculate the mean temperature for the <span class="No-Break">entire home.</span></p>
<p>It sounds like we need to process a lot of data. It makes sense to try to parallelize the data processing wherever possible. Yes, you are right: not all of the data processing can be parallelized! There is a strict sequence of actions we need to respect. Firstly, we need to calculate the mean temperature in each room. There are no dependencies between the rooms, so we can execute these calculations in parallel. Once we have all the room temperatures calculated, we can continue to the calculation of the mean temperature of the entire home. This is exactly where <strong class="source-inline">std::barrier</strong> will come to <span class="No-Break">the rescue.</span></p>
<p>The <strong class="source-inline">std::barrier</strong> synchronization primitive blocks the threads at a specific synchronization point (the barrier) until all of them arrive. Then, it allows a callback to be invoked and a specific action to be performed. In our example, we need to wait for all room calculations to be finished – to wait on the barrier. Then, a callback will be executed where we will calculate the mean temperature for the <span class="No-Break">entire home:</span></p>
<pre class="source-code">
using Temperature =
    std::tuple&lt;std::string, // The name of the room
               std::vector&lt;double&gt;, // Temperature
                 measurements
               double&gt;; // Calculated mean temperature
                        // value for a specific room
std::vector&lt;Temperature&gt; room_temperatures {
    {"living_room",{}, 0.0},
    {"bedroom", {}, 0.0},
    {"kitchen", {}, 0.0},
    {"closet", {}, 0.0}
};</pre> <p>Let’s start with<a id="_idIndexMarker546"/> the<a id="_idIndexMarker547"/> definition of our data container where we will store the temperature measurements done for each room, together with their calculated mean values by our worker threads. We will use a vector of rooms, <strong class="source-inline">room_temperature</strong>, in which we will store the room name, a vector of measurements, and the <span class="No-Break">mean value.</span></p>
<p>Now, we need to define the workers that will, in parallel, calculate the mean values for <span class="No-Break">each room:</span></p>
<pre class="source-code">
std::stop_source message;
std::barrier measurementBarrier{ // {1}
    static_cast&lt;int&gt;(room_temperatures.size()), // {2}
    [&amp;message]() noexcept { // {3}
        // 1. Compute the mean temperature of the entire
          home.
        // 2. Push new temperature data
        // 3. After 5 measurement cycles request stop.
    }
};
std::vector&lt;std::jthread&gt; measurementSensors;
for (auto&amp; temp : room_temperatures) {
    measurementSensors.emplace_back([&amp;measurementBarrier,
      &amp;message, &amp;temp](){
        const auto&amp; token = message.get_token();
        while(!token.stop_requested()) {
            ProcessMeasurement(temp);
            measurementBarrier.arrive_and_wait(); // {4}
        }
    });
}</pre> <p>We create the same count of <strong class="source-inline">jthread</strong> instances as the count of the rooms. Each <strong class="source-inline">jthread</strong> instance is created and a worker lambda is assigned to it. As you can see, the worker lambda captures a <strong class="source-inline">std::stop_source</strong> object, which will be used to notify it that no other work is pending and the thread execution should be finished. The lambda also captures <strong class="source-inline">std::barrier measurementBarrier</strong>, which will be used to block each thread that is ready with its computation until all other threads are also ready (<span class="No-Break">marker </span><span class="No-Break"><strong class="source-inline">{1}</strong></span><span class="No-Break">).</span></p>
<p>The <strong class="source-inline">std::barrier</strong> instance<a id="_idIndexMarker548"/> needs to be initialized with the count of the synchronization points (marker <strong class="source-inline">{2}</strong>). This means that the barrier will be raised when the count of<a id="_idIndexMarker549"/> threads reaching the barrier is equal to the initialized value. In our example, we initialize the barrier with the count of the worker threads that will concurrently compute the mean temperatures for each room. An optional initialization parameter that the barrier accepts is a callback function (marker <strong class="source-inline">{3}</strong>). This function must not throw and, therefore, we mark it as <strong class="source-inline">noexcept</strong>. It will be invoked when all threads in a certain cycle arrive at the barrier and before the barrier is raised. Keep in mind that the standard doesn’t specify which thread this callback will be executed on. We will use this callback to do <span class="No-Break">the following:</span></p>
<ul>
<li>Iterate through all already computed mean temperatures for the rooms and compute the mean temperature of the entire home. This is the result we expect our program <span class="No-Break">to deliver.</span></li>
<li>Feed the worker threads with new temperature data for the next computation cycle. In contrast to <strong class="source-inline">std::latch</strong>, <strong class="source-inline">std::barrier</strong> allows us to use the same barrier as many times as <span class="No-Break">we need.</span></li>
<li>Check whether we have already calculated five times the mean temperature of the entire home and, if so, notify the workers that they need to gracefully stop and exit <span class="No-Break">the program.</span></li>
</ul>
<p>When a thread<a id="_idIndexMarker550"/> starts<a id="_idIndexMarker551"/> working and it is ready with its computation, it hits the barrier (marker <strong class="source-inline">{4}</strong>). This is possible because <strong class="source-inline">std::barrier</strong> exposes a method: <strong class="source-inline">void arrive_and_wait()</strong>. This call effectively decrements the internal counter of the barrier, which notifies it that the thread has arrived and blocks the thread until the counter hits zero and the barrier’s callback <span class="No-Break">is triggered.</span></p>
<p>In the following code, you can find the methods responsible for generating example temperature values and calculating the mean <span class="No-Break">temperature value:</span></p>
<pre class="source-code">
void GetTemperatures(Temperature&amp; temp) {
    std::mt19937 gen{std::random_device{}()};
    // Add normal distribution with mean = 20
    // and standard deviation of 8
    std::normal_distribution&lt;&gt; d{20, 8};
    auto&amp; input_data{std::get&lt;1&gt;(temp)};
    input_data.clear();
    for (auto n{0}; n &lt; 10; ++n) {
        // Add input data
        input_data.emplace_back(d(gen));
    }
}
void ProcessMeasurement(Temperature&amp; temp){
    const auto&amp; values{std::get&lt;1&gt;(temp)};
    auto&amp; mean{std::get&lt;2&gt;(temp)};
    mean = std::reduce(values.begin(), values.end()) /
      values.size();
}</pre> <p>Once we<a id="_idIndexMarker552"/> have <a id="_idIndexMarker553"/>all the code pieces available, let’s see the <strong class="source-inline">main</strong> method implementation of <span class="No-Break">our program:</span></p>
<pre class="source-code">
int main() {
    // Init data
    std::ranges::for_each(room_temperatures,
      GetTemperatures);
    std::stop_source message;
    std::barrier measurementBarrier{
        static_cast&lt;int&gt;(room_temperatures.size()),
        [&amp;message]() noexcept {
            // Get all results
            double mean{0.0};
            for (const auto&amp; room_t : room_temperatures) {
                std::cout &lt;&lt; "Mean temperature in "
                          &lt;&lt; std::get&lt;0&gt;(room_t)
                          &lt;&lt; " is " &lt;&lt; std::get&lt;2&gt;(room_t)
                            &lt;&lt; ".\n";
                mean += std::get&lt;2&gt;(room_t);
            }
            mean /= room_temperatures.size();
            std::cout &lt;&lt; "Mean temperature in your home is
              " &lt;&lt; mean &lt;&lt; " degrees Celsius.\n";
            std::cout &lt;&lt; "=======================
              ======================\n";
            // Add new input data
            std::ranges::for_each(room_temperatures,
              GetTemperatures);
            // Make 4 measurements and request stop.
            static unsigned timer{0};
            if (timer &gt;= 3) {
                message.request_stop();
            }
            ++timer;
        }
    };
    std::vector&lt;std::jthread&gt; measurementSensors;
    for (auto&amp; temp : room_temperatures) {
        measurementSensors.emplace_back
          ([&amp;measurementBarrier, &amp;message, &amp;temp](){
            const auto&amp; token = message.get_token();
            while(!token.stop_requested()) {
                ProcessMeasurement(temp);
                measurementBarrier.arrive_and_wait();
            }
        });
    }
    return 0;
}</pre> <p>For the<a id="_idIndexMarker554"/> input<a id="_idIndexMarker555"/> temperature data of our example, we use a random number generator, which produces data with normal distribution. As a result, we get the <span class="No-Break">following output:</span></p>
<pre class="console">
Mean temperature in living_room is 18.7834.
Mean temperature in bedroom is 16.9559.
Mean temperature in kitchen is 22.6351.
Mean temperature in closet is 20.0296.
Mean temperature in your home is 19.601 degrees Celsius.
=============================================
Mean temperature in living_room is 19.8014.
Mean temperature in bedroom is 20.4068.
Mean temperature in kitchen is 19.3223.
Mean temperature in closet is 21.2223.
Mean temperature in your home is 20.1882 degrees Celsius.
=============================================
Mean temperature in living_room is 17.9305.
Mean temperature in bedroom is 22.6204.
Mean temperature in kitchen is 17.439.
Mean temperature in closet is 20.3107.
Mean temperature in your home is 19.5752 degrees Celsius.
=============================================
Mean temperature in living_room is 19.4584.
Mean temperature in bedroom is 19.0377.
Mean temperature in kitchen is 16.3529.
Mean temperature in closet is 20.1057.
Mean temperature in your home is 18.7387 degrees Celsius.
=============================================</pre> <p>With the <a id="_idIndexMarker556"/>preceding example, we have demonstrated how you can use <a id="_idIndexMarker557"/>synchronization primitives with <strong class="source-inline">std::jthread</strong> to provide inter-thread synchronization for <span class="No-Break">your program.</span></p>
<h1 id="_idParaDest-100"><a id="_idTextAnchor100"/>Summary</h1>
<p>In this chapter, we explored several topics related to concurrency and parallelism in C++. We began by discussing the terminology and differences between concurrency and parallelism, including preemption. We then delved into how programs execute on single and multiple processing units, distinguishing between processes and execution threads and briefly exploring communication mechanisms such as pipes, sockets, and <span class="No-Break">shared memory.</span></p>
<p>In the context of C++, we examined how the language supports concurrency, specifically through the <strong class="source-inline">std::thread</strong> class and the new <strong class="source-inline">std::jthread</strong> primitive introduced in C++20. We also discussed the risks associated with race conditions and data races, including an example of a money transfer operation. To avoid these issues, we examined mechanisms such as locks, atomic operations, and <span class="No-Break">memory barriers.</span></p>
<p>Moving on, we looked closely at the <strong class="source-inline">std::jthread</strong> class, exploring its functionality and proper usage. Additionally, we learned about a new synchronized stream wrapper delivered in C++20 for printing in concurrent environments. We also covered how to cancel running threads using <strong class="source-inline">std::stop_token</strong> and how to request a stop to several threads <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">std::stop_source</strong></span><span class="No-Break">.</span></p>
<p>We then shifted our focus to returning results from threads using <strong class="source-inline">std::future</strong> and <strong class="source-inline">std::promise</strong>. Additionally, we discussed the use of <strong class="source-inline">std::latch</strong> and <strong class="source-inline">std::barrier</strong>, using an example of a temperature station to demonstrate how the latter can be used to <span class="No-Break">synchronize threads.</span></p>
<p>Overall, we explored a range of topics related to concurrency and parallelism in C++, from basic terminology and concepts to more advanced techniques and mechanisms for avoiding data races and synchronizing threads. But please stay tuned because, in the next chapter, you will get familiar with some mechanisms for IPC that are widely used in <span class="No-Break">software programming.</span></p>
</div>
</div></body></html>