<html><head></head><body>
		<div><h1 id="_idParaDest-64" class="chapter-number"><a id="_idTextAnchor064"/>3</h1>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor065"/>Mastering Memory and Allocators with std::vector</h1>
			<p>This chapter dives into the critical memory management concepts in modern C++ programming. We begin by distinguishing between the capacity and size of <code>std::vector</code>, which is fundamental to writing efficient code. As we progress, we’ll understand the mechanics of memory reservation and optimization, and why these actions matter in real-world applications. The chapter culminates with thoroughly exploring custom allocators, including when to use them and their impact on container performance. It equips us with the expertise to fine-tune memory usage for their programs.</p>
			<p>In this chapter, we are going to cover the following main topics:</p>
			<ul>
				<li>Understanding capacity versus size</li>
				<li>Resizing and reserving memory</li>
				<li>Custom allocator basics</li>
				<li>Creating a custom allocator</li>
				<li>Allocators and container performance</li>
			</ul>
			<h1 id="_idParaDest-66"><a id="_idTextAnchor066"/>Technical requirements</h1>
			<p>The code in this chapter can be found on GitHub:</p>
			<p><a href="https://github.com/PacktPublishing/Data-Structures-and-Algorithms-with-the-CPP-STL">https://github.com/PacktPublishing/Data-Structures-and-Algorithms-with-the-CPP-STL</a></p>
			<h1 id="_idParaDest-67"><a id="_idTextAnchor067"/>Understanding capacity versus size</h1>
			<p>As you <a id="_idIndexMarker122"/>venture deeper into the art of C++ programming with <code>std::vector</code>, it becomes crucial to grasp the distinctions between a vector’s size and capacity. While closely related, these terms serve different roles in managing and optimizing dynamic arrays, and understanding them will dramatically enhance both the efficiency and clarity of your code.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor068"/>Revisiting the basics</h2>
			<p>Recall from<a id="_idIndexMarker123"/> the previous chapter that the size of a vector denotes the number of elements it currently holds. When you add or remove elements, this size adjusts accordingly. So, if you have a vector containing five integers, its size is <code>5</code>. Remove an integer, and the size becomes <code>4</code>.</p>
			<p>But herein lies a compelling facet of <code>std::vector</code>: while its size changes based on its elements, the memory it allocates doesn’t always follow suit immediately. To understand this thoroughly, we need to explore the concept of capacity. Let us do that in the next section.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor069"/>What exactly is capacity?</h2>
			<p><code>std::vector</code>, pertains to the amount of memory the vector has reserved for itself – the number of elements it can hold before reallocating memory. This doesn’t always equal the number of elements it currently holds (its size). <code>std::vector</code> often allocates more memory than is required, a preemptive strategy to accommodate future elements. This is where the genius of <code>std::vector</code> shines; over-allocating reduces the need for frequent and, potentially, computationally costly reallocations.</p>
			<p>Let’s use an analogy to make this more straightforward. Think of a vector as a train with compartments (memory blocks). When the train (vector) starts its journey, it might only have a few passengers (elements). However, anticipating more passengers at upcoming stations, the train starts with some empty compartments. The train’s capacity is the total number of compartments, while its size is the number of compartments with passengers.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor070"/>Why this distinction matters</h2>
			<p>You might <a id="_idIndexMarker125"/>wonder why we don’t just expand the memory each time a new element is added. The answer lies in computational efficiency. Memory operations, especially reallocations, can be time-consuming. The vector minimizes these operations by allocating more memory than is immediately needed, ensuring that adding elements remains a fast operation in most scenarios. This optimization is one reason why <code>std::vector</code> has become a staple in C++ programming.</p>
			<p>However, there’s a flip side. Over-allocation means that some memory might go unused, at least temporarily. Understanding and managing capacity becomes paramount if memory usage is a critical concern. In some extreme cases, a vector might have a size of <code>10</code> but a capacity of <code>1000</code>!</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor071"/>Looking under the hood</h2>
			<p>One must occasionally peek under the hood to appreciate the nuances of size and capacity. Consider a newly initiated <code>std::vector&lt;int&gt; numbers;</code>. If you push 10 integers into it one by one and periodically check its capacity, you might notice something interesting: the capacity doesn’t increase by one for each integer! Instead, it might jump from <code>1</code> to <code>2</code>, then to <code>4</code>, then to <code>8</code>, and so on. This exponential growth strategy is a typical implementation approach, ensuring that the vector’s capacity doubles whenever it runs out of space.</p>
			<p>Let’s look at a code example that showcases the difference between size and capacity in <code>std::vector</code>:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;vector&gt;
int main() {
  std::vector&lt;int&gt; myVec;
  std::cout &lt;&lt; "Initial size: " &lt;&lt; myVec.size()
            &lt;&lt; ", capacity: " &lt;&lt; myVec.capacity() &lt;&lt; "\n";
  for (auto i = 0; i &lt; 10; ++i) {
    myVec.push_back(i);
    std::cout &lt;&lt; "After adding " &lt;&lt; i + 1
              &lt;&lt; " integers, size: " &lt;&lt; myVec.size()
              &lt;&lt; ", capacity: " &lt;&lt; myVec.capacity()
              &lt;&lt; "\n";
  }
  myVec.resize(5);
  std::cout &lt;&lt; "After resizing to 5 elements, size: "
            &lt;&lt; myVec.size()
            &lt;&lt; ", capacity: " &lt;&lt; myVec.capacity() &lt;&lt; "\n";
  myVec.shrink_to_fit();
  std::cout &lt;&lt; "After shrinking to fit, size: "
            &lt;&lt; myVec.size()
            &lt;&lt; ", capacity: " &lt;&lt; myVec.capacity() &lt;&lt; "\n";
  myVec.push_back(5);
  std::cout &lt;&lt; "After adding one more integer, size: "
            &lt;&lt; myVec.size()
            &lt;&lt; ", capacity: " &lt;&lt; myVec.capacity() &lt;&lt; "\n";
  return 0;
}</pre>			<p>Here is the example output:</p>
			<pre class="console">
Initial size: 0, capacity: 0
After adding 1 integers, size: 1, capacity: 1
After adding 2 integers, size: 2, capacity: 2
After adding 3 integers, size: 3, capacity: 3
After adding 4 integers, size: 4, capacity: 4
After adding 5 integers, size: 5, capacity: 6
After adding 6 integers, size: 6, capacity: 6
After adding 7 integers, size: 7, capacity: 9
After adding 8 integers, size: 8, capacity: 9
After adding 9 integers, size: 9, capacity: 9
After adding 10 integers, size: 10, capacity: 13
After resizing to 5 elements, size: 5, capacity: 13
After shrinking to fit, size: 5, capacity: 5
After adding one more integer, size: 6, capacity: 7</pre>			<p>Here is the<a id="_idIndexMarker126"/> explanation of this code block:</p>
			<ul>
				<li>We start by creating an empty <code>std::vector&lt;int&gt;</code> named <code>myVec</code>.</li>
				<li>We then print out the initial <code>size</code> and <code>capacity</code>. Since it is empty, the <code>size</code> value will be <code>0</code>. The initial <code>capacity</code> value might vary depending on the C++ <code>0</code> as well.</li>
				<li>We can see how size and capacity change as we push integers into the vector individually. The <code>size</code> value will always increase by one for each added element. However, the <code>capacity</code> value might remain unchanged or increase, often doubling, depending on when the underlying memory needs reallocation.</li>
				<li>Resizing the vector down to five elements demonstrates that while <code>size</code> decreases, <code>capacity</code> remains unchanged. This ensures that previously allocated memory remains reserved for potential future elements.</li>
				<li><code>shrink_to_fit()</code> reduces the vector’s <code>capacity</code> to match its <code>size</code>, thus releasing unused memory.</li>
				<li>We can observe how the capacity behaves again by adding one more element after the shrink.</li>
			</ul>
			<p>When you <a id="_idIndexMarker127"/>run this example, you’ll see firsthand the differences between size and capacity and how <code>std::vector</code> manages memory in the background.</p>
			<p>By understanding the relationship between size and capacity, you optimize memory usage and preempt potential performance pitfalls. It lays the foundation for the upcoming sections, where we’ll discuss manual memory management with vectors and understand how to iterate over them efficiently.</p>
			<p>This section deepened our understanding of <code>std::vector</code>’s size and capacity. We compared these concepts to a train’s compartments, emphasizing how capacity planning can prevent frequent, costly reallocations and lead to more memory-efficient programs. Grasping this is crucial for performance-sensitive and memory-constrained environments.</p>
			<p>Building on this, we’ll next look at <code>resize()</code>, <code>reserve()</code>, and <code>shrink_to_fit()</code>, learning to manage <code>std::vector</code>’s memory footprint proactively for optimal performance and memory usage.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor072"/>Resizing and reserving memory</h1>
			<p>In our <a id="_idIndexMarker128"/>exploration of <code>std::vector</code>, understanding how to manage its memory effectively is essential. A vector’s beauty is in its dynamism; it can <a id="_idIndexMarker129"/>grow and shrink, adapting to the ever-changing requirements of our applications. Yet, with this flexibility comes the responsibility to ensure efficient memory utilization. This section digs into the operations that let us manipulate vector sizes and their preallocated memory: <code>resize</code>, <code>reserve</code>, and <code>shrink_to_fit</code>.</p>
			<p>When working with vectors, we’ve seen how their capacity (preallocated memory) might differ from their actual size (number of elements). The methods to manage these aspects can significantly affect your programs’ performance and memory footprint. </p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor073"/>The power of resize()</h2>
			<p>Imagine you have <code>std::vector</code> holding five elements. If you suddenly need it to keep eight elements, or perhaps only three, how would you make this adjustment? The <code>resize()</code> function is your answer.</p>
			<p><code>resize()</code> is used<a id="_idIndexMarker130"/> to change the size of a vector. If you increase its size, the new elements will be default-initialized. For instance, for <code>std::vector&lt;int&gt;</code>, the new elements will have a value of <code>0</code>. Conversely, the extra elements will be discarded if you reduce its size.</p>
			<p>But remember, resizing doesn’t always influence the capacity. If you expand a vector beyond its current capacity, the capacity will grow (often more than the size to accommodate future growth). However, shrinking a vector’s size doesn’t reduce its capacity.</p>
			<p>Let’s look at an example that demonstrates manually resizing the capacity of a <code>std::vector</code> instance:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;vector&gt;
int main() {
  std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};
  auto printVectorDetails = [&amp;]() {
    std::cout &lt;&lt; "Vector elements: ";
    for (auto num : numbers) { std::cout &lt;&lt; num &lt;&lt; " "; }
    std::cout &lt;&lt; "\nSize: " &lt;&lt; numbers.size() &lt;&lt; "\n";
    std::cout &lt;&lt; "Capacity: " &lt;&lt; numbers.capacity()
              &lt;&lt; "\n";
  };
  std::cout &lt;&lt; "Initial vector:\n";
  printVectorDetails();
  numbers.resize(8);
  std::cout &lt;&lt; "After resizing to 8 elements:\n";
  printVectorDetails();
  numbers.resize(3);
  std::cout &lt;&lt; "After resizing to 3 elements:\n";
  printVectorDetails();
  std::cout &lt;&lt; "Reducing size doesn't affect capacity:\n";
  std::cout &lt;&lt; "Capacity after resize: "
            &lt;&lt; numbers.capacity() &lt;&lt; "\n";
  return 0;
}</pre>			<p>Here is <a id="_idIndexMarker131"/>the example output:</p>
			<pre class="console">
Initial vector:
Vector elements: 1 2 3 4 5
Size: 5
Capacity: 5
After resizing to 8 elements:
Vector elements: 1 2 3 4 5 0 0 0
Size: 8
Capacity: 10
After resizing to 3 elements:
Vector elements: 1 2 3
Size: 3
Capacity: 10
Reducing size doesn't affect capacity:
Capacity after resize: 10</pre>			<p>In this example, we<a id="_idIndexMarker132"/> saw the following:</p>
			<ul>
				<li>We start with <code>std::vector&lt;int&gt;</code> containing five elements.</li>
				<li>A print utility <code>printVectorDetails</code> lambda function displays the vector’s elements, size, and capacity.</li>
				<li>We resize the vector to hold eight elements and observe the changes.</li>
				<li>We then resize the vector to hold only three elements and see how the size decreases, but the capacity remains unchanged.</li>
			</ul>
			<p>This demonstrates the power of the <code>resize()</code> function and how it affects the size but not always the capacity of <code>std::vector</code>.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor074"/>Enter reserve()</h2>
			<p>Sometimes, we <a id="_idIndexMarker133"/>have foreknowledge about the data. Say you know you’ll insert 100 elements into a vector. Letting the vector adjust its capacity incrementally as elements are added would be inefficient. Here’s where <code>reserve()</code> comes into play.</p>
			<p>By calling <code>reserve()</code>, you can set aside a specific amount of memory for the vector upfront. It’s like booking seats in advance. The size remains unchanged, but the capacity is adjusted to at least the specified value. If you reserve less memory than the current capacity, the call has no effect; you cannot decrease capacity with <code>reserve()</code>.</p>
			<p>Let’s look at <a id="_idIndexMarker134"/>an example that demonstrates the utility of the <code>reserve()</code> function:</p>
			<pre class="source-code">
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
int main() {
  constexpr size_t numberOfElements = 100'000;
  std::vector&lt;int&gt; numbers1;
  auto start1 = std::chrono::high_resolution_clock::now();
  for (auto i = 0; i &lt; numberOfElements; ++i) {
    numbers1.push_back(i);
  }
  auto end1 = std::chrono::high_resolution_clock::now();
  std::chrono::duration&lt;double&gt; elapsed1 = end1 - start1;
  std::cout &lt;&lt; "Time without reserve: " &lt;&lt; elapsed1.count()
            &lt;&lt; " seconds\n";
  std::vector&lt;int&gt; numbers2;
  numbers2.reserve(
      numberOfElements); // Reserve memory upfront.
  auto start2 = std::chrono::high_resolution_clock::now();
  for (auto i = 0; i &lt; numberOfElements; ++i) {
    numbers2.push_back(i);
  }
  auto end2 = std::chrono::high_resolution_clock::now();
  std::chrono::duration&lt;double&gt; elapsed2 = end2 - start2;
  std::cout &lt;&lt; "Time with reserve:    " &lt;&lt; elapsed2.count()
            &lt;&lt; " seconds\n";
  return 0;
}</pre>			<p>Here is the example output:</p>
			<pre class="console">
Time without reserve: 0.01195 seconds
Time with reserve:    0.003685 seconds</pre>			<p>We learn<a id="_idIndexMarker135"/> the following from the preceding example:</p>
			<ul>
				<li>We intend to insert many elements (<code>numberOfElements</code>) into two vectors.</li>
				<li>In the first vector (<code>numbers1</code>), we directly insert the elements without reserving any memory upfront.</li>
				<li>In the second vector (<code>numbers2</code>), we use the <code>reserve()</code> function to preallocate memory for the elements before inserting them.</li>
				<li>We measure and compare the time taken to insert elements in both scenarios.</li>
			</ul>
			<p>When you run the code, you’ll likely notice that the insertion time is shorter (often significantly) with <code>reserve()</code> since it reduces the number of memory reallocations. This example effectively demonstrates the performance benefit of using <code>reserve() </code>judiciously. In this example, using <code>reserve()</code> was more than 3x faster than not calling <code>reserve()</code>.</p>
			<p>Using <code>reserve()</code> judiciously can significantly boost performance, especially when dealing with large datasets. Preallocating memory means fewer memory reallocations, leading to faster insertions.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor075"/>Optimizing with shrink_to_fit()</h2>
			<p>While <code>reserve()</code> lets<a id="_idIndexMarker136"/> you expand the preallocated memory, what if you want to do the opposite? What if, after numerous operations, you find a vector with a size of <code>10</code> but a capacity of <code>1000</code>? Holding onto that extra memory can be wasteful.</p>
			<p>The <code>shrink_to_fit()</code> function allows you to request the vector to reduce its capacity to match its size. Notice the word <em class="italic">request</em>. Implementations might not always guarantee the reduction, but in most cases, they’ll comply. Reclaiming memory after bulk deletions or when a vector’s growth phase has ended is an excellent way to reduce a vector’s capacity.</p>
			<p>Let’s illustrate the usage of <code>shrink_to_fit()</code> with the following simple code example:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;vector&gt;
int main() {
  std::vector&lt;int&gt; numbers;
  numbers.reserve(1000);
  std::cout &lt;&lt; "Initial capacity: " &lt;&lt; numbers.capacity()
            &lt;&lt; "\n";
  for (auto i = 0; i &lt; 10; ++i) { numbers.push_back(i); }
  std::cout &lt;&lt; "Size after adding 10 elements: "
            &lt;&lt; numbers.size() &lt;&lt; "\n";
  std::cout &lt;&lt; "Capacity after adding 10 elements: "
            &lt;&lt; numbers.capacity() &lt;&lt; "\n";
  numbers.shrink_to_fit();
  std::cout &lt;&lt; "Size after shrink_to_fit: "
            &lt;&lt; numbers.size() &lt;&lt; "\n";
  std::cout &lt;&lt; "Capacity after shrink_to_fit: "
            &lt;&lt; numbers.capacity() &lt;&lt; "\n";
  return 0;
}</pre>			<p>Here is the example output:</p>
			<pre class="console">
Initial capacity: 1000
Size after adding 10 elements: 10
Capacity after adding 10 elements: 1000
Size after shrink_to_fit: 10
Capacity after shrink_to_fit: 10</pre>			<p>The <a id="_idIndexMarker137"/>following are the key takeaways from the preceding example:</p>
			<ul>
				<li>We start with <code>std::vector&lt;int&gt;</code> and reserve memory for 1000 elements.</li>
				<li>We only add 10 elements to the vector.</li>
				<li>At this point, the size of the vector is 10, but its capacity is 1000.</li>
				<li>We then call <code>shrink_to_fit()</code> to reduce the vector’s capacity to match its size perfectly.</li>
				<li>We display the size and capacity after calling <code>shrink_to_fit()</code>.</li>
			</ul>
			<p>Upon running the code, you should observe that the vector’s capacity has been reduced closer to its size, illustrating the function’s utility in reclaiming memory.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor076"/>Real-world relevance</h2>
			<p>Understanding<a id="_idIndexMarker138"/> the distinction between size and capacity and knowing how to manipulate them has profound implications. Managing memory effectively is critical for applications where performance is paramount, such as real-time systems or high-frequency trading platforms. Similarly, ensuring that every byte is efficiently used in embedded systems or devices with limited memory is crucial.</p>
			<p>While <code>std::vector</code> provides a dynamic and efficient approach to handling arrays, wielding it with mastery requires a deep understanding of its memory behavior. By effectively using <code>resize</code>, <code>reserve</code>, and <code>shrink_to_fit</code>, developers can tailor memory usage to the exact requirements of their applications, achieving an optimal balance between performance and resource consumption.</p>
			<p>To master the art of C++, one must be more than just a coder; one must think like an architect, understanding the materials at hand and building structures that stand the test of time and load. As we move forward, we will dive deeper into iteration methods, bringing us closer to mastery of <code>std::vector</code>.</p>
			<p>This section has honed our understanding of <code>std::vector</code>’s memory allocation techniques. We learned how <code>reserve()</code> strategically allocates memory to optimize performance, while <code>shrink_to_fit()</code> can minimize memory footprint by releasing unneeded space. These strategies are pivotal for developers to enhance application efficiency and manage resources wisely.</p>
			<p>Next, we’ll examine allocators’ integral role in memory management. We’ll dissect the allocator interface and the scenarios that may necessitate custom allocators, evaluating their impact on performance and memory usage compared to standard practices.</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor077"/>Custom allocator basics</h1>
			<p>The magic <a id="_idIndexMarker139"/>behind dynamic memory management in <code>std::vector</code> (and many other STL containers) lies in a component that might not immediately catch your <a id="_idIndexMarker140"/>attention: the allocator. At its core, an <code>std::vector</code>, can function without being tethered to a specific memory source or allocation strategy.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor078"/>The role and responsibility of an allocator</h2>
			<p>Allocators <a id="_idIndexMarker142"/>are the unsung heroes of memory management. They handle allocating and deallocating memory chunks, thus ensuring that our data structures grow and shrink gracefully. Beyond these tasks, allocators can also construct and destroy objects. They bridge the gap between raw memory operations and higher-level object management.</p>
			<p>But why do we need such an abstraction? Why not simply use the <code>new</code> and <code>delete</code> operations? The answer lies in flexibility. The STL empowers developers to implement custom memory strategies by decoupling the container from specific memory operations. For performance-critical applications, this flexibility is a godsend.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor079"/>Under the hood – the allocator interface</h2>
			<p>A default <code>std::allocator</code> provides <a id="_idIndexMarker143"/>member functions that align closely with its responsibilities. Let us take a brief look at the member functions:</p>
			<ul>
				<li><code>allocate()</code>: Allocates a memory block suitable for holding a specified number of objects</li>
				<li><code>deallocate()</code>: Returns a block of memory previously allocated by the allocator to the system</li>
				<li><code>construct()</code>: Constructs an object in a given memory location</li>
				<li><code>destroy()</code>: Calls the destructor on an object at a given memory location</li>
			</ul>
			<p>Remember, while <code>std::allocator</code> uses the heap for memory operations by default, the true power of the allocator interface shines when custom allocators are in play.</p>
			<p>To demonstrate the benefits of <code>std::allocator</code>, let’s first illustrate how a simple custom allocator might look. This custom allocator will track and print its operations, allowing us to visualize its interactions.</p>
			<p>We’ll then use this custom allocator with <code>std::vector</code> in the following code block:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;memory&gt;
#include &lt;vector&gt;
template &lt;typename T&gt; class CustomAllocator {
public:
  using value_type = T;
  CustomAllocator() noexcept {}
  template &lt;typename U&gt;
  CustomAllocator(const CustomAllocator&lt;U&gt; &amp;) noexcept {}
  T *allocate(std::size_t n) {
    std::cout &lt;&lt; "Allocating " &lt;&lt; n &lt;&lt; " objects of size "
              &lt;&lt; sizeof(T) &lt;&lt; " bytes.\n";
    return static_cast&lt;T *&gt;(::operator new(n * sizeof(T)));
  }
  void deallocate(T *p, std::size_t) noexcept {
    std::cout &lt;&lt; "Deallocating memory.\n";
    ::operator delete(p);
  }
  template &lt;typename U, typename... Args&gt;
  void construct(U *p, Args &amp;&amp;...args) {
    std::cout &lt;&lt; "Constructing object.\n";
    new (p) U(std::forward&lt;Args&gt;(args)...);
  }
  template &lt;typename U&gt; void destroy(U *p) {
    std::cout &lt;&lt; "Destroying object.\n";
    p-&gt;~U();
  }
};
int main() {
  std::vector&lt;int, CustomAllocator&lt;int&gt;&gt; numbers;
  std::cout &lt;&lt; "Pushing back numbers 1 to 5:\n";
  for (int i = 1; i &lt;= 5; ++i) { numbers.push_back(i); }
  std::cout &lt;&lt; "\nClearing the vector:\n";
  numbers.clear();
  return 0;
}</pre>			<p>Here is the <a id="_idIndexMarker144"/>example output:</p>
			<pre class="console">
Pushing back numbers 1 to 5:
Allocating 1 objects of size 4 bytes.
Constructing object.
Allocating 2 objects of size 4 bytes.
Constructing object.
Constructing object.
Destroying object.
Deallocating memory.
Allocating 4 objects of size 4 bytes.
Constructing object.
Constructing object.
Constructing object.
Destroying object.
Destroying object.
Deallocating memory.
Constructing object.
Allocating 8 objects of size 4 bytes.
Constructing object.
Constructing object.
Constructing object.
Constructing object.
Constructing object.
Destroying object.
Destroying object.
Destroying object.
Destroying object.
Deallocating memory.
Clearing the vector:
Destroying object.
Destroying object.
Destroying object.
Destroying object.
Destroying object.
Deallocating memory.</pre>			<p>The<a id="_idIndexMarker145"/> following are the key takeaways from the preceding example:</p>
			<ul>
				<li>We’ve created a simple <code>CustomAllocator</code> that prints messages when it performs specific operations such as allocation, deallocation, construction, and destruction. It uses global <code>new</code> and <code>delete</code> operators for memory operations.</li>
				<li><code>std::vector</code> in the <code>main()</code> function uses our <code>CustomAllocator</code>.</li>
				<li>When we push elements into the vector, you’ll notice the messages indicating memory allocation and object construction.</li>
				<li>Clearing the vector will trigger object destruction and memory deallocation messages.</li>
			</ul>
			<p>Using our custom allocator, we’ve added custom behavior (printing in this case) to the memory management operations of <code>std::vector</code>. This showcases the flexibility allocators provide in STL and how they can be tailored for specific needs.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor080"/>Trade-offs and the need for custom allocators</h2>
			<p>You might <a id="_idIndexMarker146"/>be wondering, if <code>std::allocator</code> works out of the box, why bother with custom allocators? As with many things in<a id="_idIndexMarker147"/> software development, the answer boils down to trade-offs.</p>
			<p>The general-purpose nature of the default allocator ensures broad applicability. However, this jack-of-all-trades approach might not be optimal for specific scenarios. For instance, applications that frequently allocate and deallocate small chunks of memory might <a id="_idIndexMarker148"/>suffer from fragmentation if the default allocator is used.</p>
			<p>Additionally, some <a id="_idIndexMarker149"/>contexts might have unique memory constraints, such as embedded systems with limited memory or real-time systems with stringent performance requirements. In these situations, the control and optimization offered by custom allocators become invaluable.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor081"/>Choosing std::allocator over new, delete, and managed pointers</h2>
			<p>Regarding memory<a id="_idIndexMarker150"/> management in C++, several mechanisms are at a developer’s disposal. While using raw pointers with <code>new</code> and <code>delete</code> or even smart pointers such as <code>std::shared_ptr</code> and <code>std::unique_ptr</code> might seem intuitive, there’s a compelling case for relying on <code>std::allocator</code> when working with STL containers. Let’s explore these advantages.</p>
			<h3>Consistency with STL containers</h3>
			<p>Containers<a id="_idIndexMarker151"/> in the STL have been designed with allocators in mind. Using <code>std::allocator</code> ensures a level of compatibility and consistency across the library. It ensures that your customization or optimization can be applied uniformly across various containers.</p>
			<h3>Memory abstraction and customization</h3>
			<p>Raw <a id="_idIndexMarker152"/>memory operations and even managed pointers do not provide an immediate path to customizing memory allocation strategies. On the other hand, <code>std::allocator </code>(and its customizable brethren) offers an abstraction layer, paving the way for tailored memory management<a id="_idIndexMarker153"/> approaches. This means you can implement strategies that combat fragmentation, use <strong class="bold">memory pools</strong>, or tap into specialized hardware.</p>
			<h3>Centralized memory operations</h3>
			<p>With raw pointers and manual memory management, allocation and deallocation operations<a id="_idIndexMarker154"/> are scattered throughout the code. This decentralization can lead to errors and inconsistencies. <code>std::allocator</code> encapsulates these operations, ensuring that memory management remains consistent and traceable.</p>
			<h3>Safety against common pitfalls</h3>
			<p>Manual <a id="_idIndexMarker155"/>memory management with <code>new</code> and <code>delete</code> is prone<a id="_idIndexMarker156"/> to issues such as memory leaks, double<a id="_idIndexMarker157"/> deletions, and undefined behaviors. Even with smart pointers, cyclic references can become a headache. When used with containers, allocators mitigate many of these concerns by automating the underlying memory processes.</p>
			<h3>Better synergy with advanced STL features</h3>
			<p>Certain<a id="_idIndexMarker158"/> advanced features and optimizations in the STL, such as allocator-aware containers, directly leverage the capabilities of allocators. Using <code>std::allocator</code> (or a custom allocator) ensures you’re better positioned to harness these enhancements.</p>
			<p>While <code>new</code>, <code>delete</code>, and managed pointers have their places in C++ programming, when it comes to container-based memory management, <code>std::allocator</code> stands out as a clear choice. It offers a blend of customization, safety, and efficiency that’s hard to achieve with manual or semi-manual memory management techniques. As you navigate the rich landscape of C++ development, let the allocator be your steadfast companion in dynamic memory.</p>
			<p>This section examined allocators and their role in managing memory for <code>std::vector</code>. We uncovered how allocators provide an abstraction for memory operations in STL containers and examined the allocator interface’s workings. This understanding is essential for crafting memory management strategies that enhance application performance in various environments.</p>
			<p>Next, we will explore implementing custom allocators, investigating memory pools, and guiding you through creating a custom allocator for <code>std::vector</code>, showcasing the benefits of personalized memory management.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor082"/>Creating a custom allocator</h1>
			<p>Creating a<a id="_idIndexMarker159"/> custom allocator is a strategic decision to enhance memory management. This approach becomes particularly valuable when the default memory allocation strategies do not align with a specific application’s unique performance requirements or memory usage patterns. By designing a custom allocator, developers can fine-tune memory allocation and deallocation processes, potentially improving efficiency, reducing overhead, and ensuring better control over how resources are managed within their applications. This level of customization is crucial for applications where standard allocation schemes may fall short in addressing specialized needs or optimizing performance.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor083"/>Custom allocators – the heart of memory flexibility</h2>
			<p>When<a id="_idIndexMarker160"/> you think about how STL containers handle memory, there’s a hidden power beneath the surface. Containers such as <code>std::vector</code> have memory needs that are met through allocators. By default, they use <code>std::allocator</code>, a general-purpose allocator suitable for most tasks. However, in some scenarios, you might need more control over memory allocation and deallocation strategies. That’s where custom allocators come into play.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor084"/>Understanding the motivation behind custom allocators</h2>
			<p>At first glance, one might wonder why there’s a need for anything beyond the default allocator. After all, isn’t that sufficient? While <code>std::allocator</code> is versatile, it is designed to cater to a broad range of use cases. Specific situations call for particular memory strategies. Here are a few motivators:</p>
			<ul>
				<li><strong class="bold">Performance optimizations</strong>: Different <a id="_idIndexMarker161"/>applications have different memory access patterns. For instance, a graphics application might frequently allocate and deallocate small chunks of memory. A custom allocator can be optimized for such patterns.</li>
				<li><strong class="bold">Memory fragmentation mitigation</strong>: Fragmentation can lead to inefficient memory<a id="_idIndexMarker162"/> usage, especially in long-running applications. Custom allocators can employ strategies to reduce or even prevent fragmentation.</li>
				<li><strong class="bold">Specialized hardware or memory regions</strong>: Sometimes, applications might need to <a id="_idIndexMarker163"/>allocate memory from specific regions or even specialized hardware, such<a id="_idIndexMarker164"/> as <strong class="bold">graphics processing unit</strong> (<strong class="bold">GPU</strong>) memory. Custom allocators grant this flexibility.</li>
			</ul>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor085"/>Memory pools – a popular custom allocator strategy</h2>
			<p>One widely <a id="_idIndexMarker165"/>appreciated strategy in custom memory allocation is the concept of memory pools. Memory pools preallocate a chunk of memory and then distribute it in smaller blocks as needed by the application. The brilliance of <a id="_idIndexMarker166"/>memory pools lies in their simplicity and efficiency. Here’s why <a id="_idIndexMarker167"/>they’re beneficial:</p>
			<ul>
				<li><strong class="bold">Faster allocations and deallocation</strong>: Handing out smaller blocks is quick since a large chunk is already preallocated.</li>
				<li><strong class="bold">Reduced fragmentation</strong>: Memory pools naturally reduce fragmentation by controlling the memory layout and ensuring continuous blocks.</li>
				<li><strong class="bold">Predictable behavior</strong>: Memory pools can offer a level of predictability, especially beneficial in real-time systems where consistent performance is paramount.</li>
			</ul>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor086"/>Unlocking the potential of custom allocators</h2>
			<p>While<a id="_idIndexMarker168"/> diving into custom allocators can seem daunting, their benefits are tangible. Whether for performance enhancements, memory optimization, or specific application needs, understanding the potential of custom allocators is a valuable asset in a C++ developer’s toolkit. As you continue your journey with <code>std::vector</code>, remember that an allocator works diligently to manage memory efficiently beneath every element. With custom allocators, you can tailor this management to suit your application’s needs.</p>
			<p>This section introduced the design and use of custom allocators in <code>std::vector</code>, emphasizing how they allow for specialized memory management, which is crucial for optimizing <a id="_idIndexMarker169"/>applications with unique memory usage patterns. With this insight, developers can surpass STL’s default mechanisms, enhancing performance through tailored allocation strategies such as memory pools.</p>
			<p>We’ll next examine allocators’ effects on STL container performance, scrutinize <code>std::allocator</code>’s traits, identify scenarios for custom alternatives, and underline the role of <strong class="bold">profiling</strong> in informed allocator selection.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor087"/>Allocators and container performance</h1>
			<p>At the heart of every <a id="_idIndexMarker170"/>container’s efficiency lies its memory management strategy, and for <code>std::vector</code>, allocators play a crucial role. While memory allocation might seem straightforward, the nuances in allocator design can bring various performance implications.</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor088"/>Why allocators matter in performance</h2>
			<p>Before we can harness the potential of allocators, we need to understand why they matter. Memory allocation isn’t a one-size-fits-all operation. Depending on the application’s specific needs, the frequency of allocations, the size of memory blocks, and the lifetime of these allocations can vary drastically.</p>
			<ul>
				<li><strong class="bold">Speed of allocation and deallocation</strong>: The time it takes to allocate and deallocate memory can be a significant factor. Some allocators might optimize for speed at the expense of memory overhead, while others might do the opposite.</li>
				<li><strong class="bold">Memory overhead</strong>: The overhead involves the allocator’s extra memory for bookkeeping or fragmentation. A low overhead might mean a faster allocator but could lead to higher fragmentation. Conversely, a higher overhead allocator might be slower but could result in lower fragmentation.</li>
				<li><strong class="bold">Memory access patterns</strong>: How memory is accessed can influence cache performance. Allocators that ensure contiguous memory allocations can lead to better cache locality, boosting performance.</li>
			</ul>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor089"/>The performance characteristics of std::allocator</h2>
			<p>The default <code>std::allocator</code> aims<a id="_idIndexMarker171"/> to provide a balanced performance for the general case. It’s a jack of all trades, but it might not always be the master for specific use cases. Here’s what you can expect:</p>
			<ul>
				<li><strong class="bold">General purpose efficiency</strong>: It performs decently across various scenarios, making it a reliable choice for many applications</li>
				<li><strong class="bold">Low overhead</strong>: While the overhead is minimal, memory fragmentation is risky, especially in scenarios with frequent allocations and deallocations of varying sizes</li>
				<li><strong class="bold">Consistent behavior:</strong> Since it is part of the standard library, its behavior and performance are consistent across different platforms and compilers</li>
			</ul>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor090"/>When to consider alternative allocators</h2>
			<p>Given that <code>std::allocator</code> is a solid <a id="_idIndexMarker172"/>general-purpose choice, when should one consider alternatives? A few scenarios stand out:</p>
			<ul>
				<li><strong class="bold">Specialized workloads</strong>: If you know your application predominantly allocates small chunks of memory frequently, a memory-pool-based allocator might be more efficient</li>
				<li><strong class="bold">Real-time systems</strong>: For systems with predictable performance, custom allocators tailored to the application’s needs can make a difference</li>
				<li><strong class="bold">Hardware constraints</strong>: Custom allocators can be designed to fit those constraints if you’re working in an environment with limited or specialized memory</li>
			</ul>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor091"/>Profiling – the key to making informed decisions</h2>
			<p>While <a id="_idIndexMarker173"/>understanding the theoretical aspects of allocator performance is beneficial, there’s no substitute for actual profiling. Measuring the performance of your application using different allocators is the most reliable way to determine the best fit. Tools such as Valgrind or platform-specific profilers can offer insights into memory usage patterns, allocation times, and fragmentation.</p>
			<p>Though often behind the scenes, memory management is a cornerstone of efficient C++ programming. Allocators, serving as the unsung heroes, offer a means to tune this aspect finely. While <code>std::vector</code> provides incredible versatility and performance out of the box, understanding the role and potential of allocators allows developers to push their applications to new performance heights. As we wrap up this chapter, remember that while theory provides direction, profiling delivers clarity.</p>
			<p>In this section, we examined how allocators influence <code>std::vector</code>’s performance. We discovered the significant impact of allocator choice on container efficiency and learned about the default <code>std::allocator</code> in the C++ STL, including scenarios where an alternative might be preferable.</p>
			<p>This knowledge equips us to customize our container’s memory management to specific performance needs, ensuring our applications run more efficiently.</p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor092"/>Summary</h1>
			<p>In this chapter, we have thoroughly examined the relationship between memory management and the use of <code>std::vector</code>. We began by revisiting the fundamental concepts of capacity versus size, emphasizing their distinct roles and the importance of this distinction for efficient memory use. The mechanics underlying the <code>std::vector</code> container’s memory allocation were then explored, clarifying what happens internally when vectors grow or shrink.</p>
			<p>We discussed the nuances of resizing and reserving memory, where functions such as <code>reserve()</code> and <code>shrink_to_fit()</code> were introduced as tools for optimizing memory usage. The real-world relevance of these methods was underscored, highlighting their utility in high-performance applications.</p>
			<p>The chapter introduced the basics of custom allocators, elaborating on their role and delving into the allocator interface. We addressed the trade-offs and illustrated why custom allocators can be preferable to directly using <code>new</code>, <code>delete</code>, and managed pointers. Creating and implementing a custom memory pool allocator for <code>std::vector</code> demonstrated how custom allocators unlock the potential for greater memory flexibility.</p>
			<p>Finally, we analyzed the impact of allocators on container performance, detailing why allocators are a significant consideration for performance tuning. We covered the performance characteristics of <code>std::allocator</code> and discussed when alternative allocators should be considered. Profiling was presented as the key to making informed decisions about allocator use.</p>
			<p>The insights from this chapter are invaluable, equipping us with sophisticated techniques for mastering memory management with <code>std::vector</code>. This knowledge enables us to write high-performance C++ applications as it allows for granular control over memory allocation, which is especially important in environments with tight memory constraints or those requiring quick allocation and deallocation cycles.</p>
			<p>Next, we will focus on the algorithms operating on vectors. We will explore sorting techniques, search operations, and the manipulation of vector contents, emphasizing the importance of understanding the efficiency and versatility of these algorithms. We will discuss using custom comparators and predicates and how they can be leveraged to perform complex operations on user-defined data types. The next chapter will also provide guidance on maintaining container invariants and managing iterator invalidation, which is essential for ensuring robustness and correctness in multi-threaded scenarios.</p>
		</div>
	</body></html>