- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multithreading with Lua
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned some techniques to manage resources when
    integrating Lua into C++. In this chapter, we will learn how to work with multithreading
    with Lua. If you use Lua in a complex project, chances are that you need to create
    multiple Lua instances. First, we will learn how to contain the multithreading
    part in C++ and make Lua unaware of it. Then, we will see how Lua handles multithreading,
    in case you need to use it. Understanding multithreading will help with the technical
    planning for your projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading in C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multithreading in Lua
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `coroutine` with C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use the source code from *Chapter 10* as a base to develop the examples
    in this chapter. Make sure you can access the source code for this book: [https://github.com/PacktPublishing/Integrate-Lua-with-CPP/tree/main/Chapter11](https://github.com/PacktPublishing/Integrate-Lua-with-CPP/tree/main/Chapter11).'
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is **multithreading**?
  prefs: []
  type: TYPE_NORMAL
- en: There are a few definitions, depending on the point of view. From the CPU’s
    perspective, a multi-core processor that can execute multiple threads of instructions
    concurrently is real multithreading. From an application’s perspective, using
    multiple threads is multithreading. From a developer’s perspective, more focus
    might be on thread safety and various synchronization mechanisms, which are not
    multithreading itself, but its implications.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will learn how to use Lua with C++’s native multithreading
    support. Each C++ thread will have its own Lua state. Because the Lua library
    does not keep any state and Lua states are not shared among different threads,
    this is thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: How does C++ support multithreading?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since C++11, the standard library supports multithreading with `std::thread`.
    Each `std::thread` instance represents a thread of execution. The most important
    thing to provide to a thread is the thread function. This is what a thread executes.
    In its simplest form, we can create a thread as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, we passed a C++ function as the thread function to create a thread. The
    function can optionally take arguments and the `std::thread` constructor will
    forward the arguments to the thread function. After the thread is created, the
    thread function starts to execute in its own thread. When the thread function
    finishes, the thread is ended.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use a class member function or a class static member function as
    the thread function by invoking different constructors. You can refer to a C++
    reference manual to learn more about `std::thread`.
  prefs: []
  type: TYPE_NORMAL
- en: Before C++11
  prefs: []
  type: TYPE_NORMAL
- en: In the era before C++11, there was no standard multithreading support. People
    had to use third-party libraries or implement their own with a low-level library,
    such as **pthreads**.
  prefs: []
  type: TYPE_NORMAL
- en: This type of multithreading is unlikely to surprise you. This is the type of
    multithreading that people have talked about and have used most, which is **preemptive
    multithreading**. The thread function can be paused at any time and resumed at
    any time.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore a real example to see C++ multithreading in action.
  prefs: []
  type: TYPE_NORMAL
- en: Using multiple Lua instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will implement a thread function in which we’ll execute
    a Lua script. Then, we will create multiple threads to execute this same thread
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the source code from *Chapter 10*, wipe `main.cpp` clean and add the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, we added the necessary headers. `listener` is the Lua executor listener
    and will be shared for all Lua executor instances. `coutMutex` is a mutex for
    printing results with `std::cout`, whose usage we will see next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, implement the thread function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The thread function takes three integers as arguments, creates a Lua executor,
    and executes a Lua script to add the three integers. Then, it prints out the result.
  prefs: []
  type: TYPE_NORMAL
- en: Because there is only one place the standard output can print to, we are guarding
    the standard output with a mutex. Otherwise, the output sequence will be a mix
    of different threads and unreadable.
  prefs: []
  type: TYPE_NORMAL
- en: The way we use this mutex is by creating `std::lock_guard` instead of calling
    `std::mutex::lock` and `std::mutex::unlock` directly. The lock guard will acquire
    the mutex during construction and release the mutex when it goes out of scope
    and gets destroyed. This is an example of the *RAII* principle.
  prefs: []
  type: TYPE_NORMAL
- en: Recap of RAII
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about Resource Acquisition is Initialization
    (RAII). The C++ standard library adopts this principle in numerous places. Suppose
    that we do not use the lock this way, but acquire and release it manually. If
    anything goes wrong in between, there is a risk that the lock is not released
    in a thread and breaks the whole application. With the lock guard, the lock is
    always released even if an exception is raised because the C++ language guarantees
    that the lock’s destructor is called when the lock goes out of scope. Before C++11,
    people would implement their own lock guard by creating a wrapper class that acquires
    the lock in the constructor and releases the lock in the destructor. This idiom
    is called `std::scoped_lock`, which can lock on multiple mutexes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s implement the `main` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This creates a list of threads and waits for the threads to finish execution.
  prefs: []
  type: TYPE_NORMAL
- en: In the first `for` loop, we use `std::vector::emplace_back` to create the threads
    at the end of the vector in place. Internally, for most C++ implementations, it
    uses *placement new* and invokes `std::thread(threadFunc, i, a, a + 1, a + 2)`.
    We do this because `std::thread` is not copy-constructible. Understandably, it
    does not make sense to copy a thread.
  prefs: []
  type: TYPE_NORMAL
- en: In the second `for` loop, we use `std::thread::join` to wait for all threads
    to finish execution. The `main` function runs in the main thread of the application
    process. When `main` exits, all other threads will be aborted, even if they have
    not finished execution.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll test our example.
  prefs: []
  type: TYPE_NORMAL
- en: Testing it out
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Compile and execute the project. You should see an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If you run the project multiple times, you will see the order of the results
    from different threads changes. This verifies that we are using Lua with multiple
    threads.
  prefs: []
  type: TYPE_NORMAL
- en: For most projects, when integrating Lua into C++, this mechanism should suffice
    for multithreading. This is multithreading with C++. The Lua part just works without
    any additional effort. Each C++ thread has its own Lua instance and executes its
    copy of the Lua scripts. Different Lua instances do not interfere with or know
    about each other.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore multithreading in Lua.
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading in Lua
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand multithreading in Lua, let’s begin with a fundamental question.
  prefs: []
  type: TYPE_NORMAL
- en: How does Lua support multithreading?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Lua does not support* *multithreading. Period.*'
  prefs: []
  type: TYPE_NORMAL
- en: But we cannot finish this section yet. We will explain this further with two
    approaches – a contemporary one and an old-school one.
  prefs: []
  type: TYPE_NORMAL
- en: The contemporary approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lua is a scripting language and it does not support *preemptive multithreading*.
    It simply does not provide a library function to create a new thread, so there
    is no way to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, CPUs and operating systems are designed around *preemptive multithreading*
    – that is, a thread of execution can be paused and resumed at any time. A thread
    has no control over its execution schedule.
  prefs: []
  type: TYPE_NORMAL
- en: However, Lua provides a mechanism for `coroutine`, which is usually a function.
  prefs: []
  type: TYPE_NORMAL
- en: '`coroutine` is also very popular with Kotlin for Android and backend development.'
  prefs: []
  type: TYPE_NORMAL
- en: Cooperative multithreading
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about threads, most of the time, the implication is that they are
    threads for CPU cores to execute. When we talk about *cooperative multithreading*,
    in some cases, such as the one for Lua, you may find that there is only one thread
    being executed and one CPU core used, even with coroutines. Arguably, this is
    not multithreading at all. But we do not need to judge. We need to understand
    this because multiple terms can be used for this in different contexts. We can
    also call this **cooperative multitasking**, which is technically more accurate
    from a historical point of view.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see Lua’s `coroutine` in action and explain it more.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a Lua coroutine
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Replace the content of `script.lua` with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`create_square_seq_coroutine` creates a `coroutine` with `coroutine.create`,
    which, in turn, takes an anonymous function as its argument. You can roughly think
    that the inner anonymous function is `coroutine`. The inner function runs a loop
    and `1` to `n`.'
  prefs: []
  type: TYPE_NORMAL
- en: You can only use `yield` with coroutines. A coroutine will stop execution when
    it reaches a `yield` statement. The values provided to `yield` will be returned
    to the call site, similar to what `return` does. The next time you execute `coroutine`,
    it will resume the execution from where it yielded until it reaches another `yield`
    statement or a `return` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start an interactive Lua interpreter to test our `coroutine`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create a `coroutine` to return the squares from `1` to `3`. The first
    time we `resume` `coroutine`, it starts to execute from the beginning and returns
    two values, `true` and `1`. `true` is from `coroutine.resume` and means that `coroutine`
    is executed without any error. `1` is what `coroutine` yielded. The next time
    we `resume` `coroutine`, the loop continues with the next iteration and returns
    `4`. Pay special attention to the line when `coroutine.resume` only returns one
    value. The loop has finished but there is still code to be executed for `coroutine`,
    such as the implicit return statement. So, `coroutine.resume` returns `true`.
    After that, `coroutine` has finished and cannot be resumed and `coroutine.resume`
    will return `false` with an error message.
  prefs: []
  type: TYPE_NORMAL
- en: If this is the first time you have used `coroutine` with any programming language,
    this may seem magical and non-logical to you. How could a function, not in a thread,
    not reach its end and get executed from the middle of it again? I will explain
    why this is so ordinary (but do say you know `coroutine` and why it is so glorious
    in an interview) in the last part of this section. Before that, let’s explore
    another example to see a case in which `coroutine` can be very useful.
  prefs: []
  type: TYPE_NORMAL
- en: Lua coroutine as iterator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have seen how to use iterators with the *generic for* to simplify our lives,
    for example, `ipairs`.
  prefs: []
  type: TYPE_NORMAL
- en: But what is an iterator?
  prefs: []
  type: TYPE_NORMAL
- en: An `iterator` returns an **iterator function** that can be called again and
    again until it returns nil or nothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on `coroutine` that we have just implemented to generate a sequence of
    squares, let’s build an iterator. In `script.lua`, add another function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`square_seq` is a Lua `iterator` as it returns its inner function as an `iterator`
    `function`. The inner function continues to resume the coroutine created with
    `create_square_seq_coroutine`. It is the caller’s responsibility to stop calling
    the `iterator` `function` when the `iterator` `function` has returned nil or nothing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s test this `iterator` in an interactive Lua interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can see that three values are printed as expected for `1`, `2`, and `3`.
  prefs: []
  type: TYPE_NORMAL
- en: And by looking at the usage, you cannot even tell if any coroutine or cooperative
    multithreading is involved. This, I think, is one of the examples where this programming
    paradigm can be more valuable than preemptive multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have explored Lua `coroutine` and Lua `iterator`. They can be more
    complex, but these examples are enough to show you how they work. You can refer
    to the Lua reference manual to learn more about `coroutine` and `iterator`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let me indulge myself by explaining this in my own terms.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing multi-stacking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Traditionally, a thread is an execution unit for a CPU core, with its associated
    execution stack and the **program counter** (**PC**). The PC is a CPU register
    for the address of the next instruction to be executed. As you can see, this is
    quite low-level and involves more details that we are not going to talk about.
  prefs: []
  type: TYPE_NORMAL
- en: Because this traditional image has been imprinted in us too much, even implicitly,
    it may have become an obstacle for you to understand coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, let’s seek help with one of the fundamental principles in computer
    science – **decoupling**.
  prefs: []
  type: TYPE_NORMAL
- en: The widely understood preemptive multithreading mechanism is already an application
    of decoupling. It decouples the thread from the CPU core. With it, you can have
    unlimited threads in the pool while you have limited physical CPU cores.
  prefs: []
  type: TYPE_NORMAL
- en: When you accept this, we only need to go one step further. If you accept that
    the execution stack can be decoupled from the execution thread as well, that is
    how `coroutine` works.
  prefs: []
  type: TYPE_NORMAL
- en: In this cooperative multithreading mechanism, a thread can have its own pool
    of execution stacks. An execution stack contains the call stack and PC. So, now,
    we have a three-tier system.
  prefs: []
  type: TYPE_NORMAL
- en: 'I call these coroutines multi-stacking, a term I coinedto better explain it.
    Have a look at *Figure 11**.1*, which implicates the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The relationship between the CPU and threads**: There are more threads than
    CPU cores. A CPU core can execute any thread. When a thread is resumed, it can
    be picked up by any CPU core. This is the *preemptive multithreading* that we
    know of, which usually requires CPU hardware support and is managed by the operating
    system transparently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The relationship between threads and coroutines**: One thread can have multiple
    coroutines, each with its own execution stack. Because the operating system stops
    at the thread level, the operating system has no concept of coroutines. For a
    thread to execute another coroutine, the current coroutine must give up its execution
    and yield willingly. This is why it is called *cooperative multithreading*. The
    coroutine has no concept of threads either; its owning thread can be preempted
    and picked up by another CPU core later, but these are all transparent to the
    coroutine. A coroutine can also be picked up by different threads if the programming
    environment supports that.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Multi-stacking](img/B20927_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Multi-stacking
  prefs: []
  type: TYPE_NORMAL
- en: Take a moment and think about the two relationships, which are explained and
    illustrated in *Figure 11**.1*. This is one of the ways, albeit be unusual, to
    explain coroutines. The goal here is to find similarities between different mechanisms
    and technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at cooperative multithreading and `coroutine` from another
    perspective.
  prefs: []
  type: TYPE_NORMAL
- en: The old-school approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far in this section, we have focused on the contemporary approach to explain
    the `coroutine` concept. Hopefully, with the two relationships explained, you
    can understand and tell why `coroutine` adds another valuable layer of multithreading
    support in a modern computing system.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is nothing new. This is how computers have worked since the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, in the very beginning, as you know, we feed the machine paper tape
    with holes. So, it is hopeless for multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: Then, later, it becomes more complex. But still, there is only one processing
    unit in the CPU, and there is a privileged and primitive control program running
    in a dead loop. The main thing the loop does is check if another program wants
    to run. If there is one, it loads the starting address of that program into the
    PC – the program counter of the CPU. Then, the CPU starts to execute the other
    program.
  prefs: []
  type: TYPE_NORMAL
- en: You have probably guessed the problem. What if there is yet another program
    that wants to run? As it used to be, it has to wait for the first program to finish.
    This, as you can imagine, is not fair. So, we improve it and regulate that all
    programs should play nicely and yield their execution once in a while. Doing this
    allows the privileged control program to resume and find out if another program
    needs to run.
  prefs: []
  type: TYPE_NORMAL
- en: This is called *cooperative multithreading*. Each of the programs, besides the
    privileged one, is a `coroutine` instance, except that this term had not been
    invented in that era.
  prefs: []
  type: TYPE_NORMAL
- en: It helps, but not always. Suppose that one program decides to wait for an I/O
    that never happens and does not yield; the computer will be waiting endlessly
    in vain.
  prefs: []
  type: TYPE_NORMAL
- en: Much later, the computer became more powerful and could support running more
    complex operating systems. It moved the logic to decide which program to run into
    the operating system. If a program is waiting for I/O or has been running for
    enough time, the operating system will pause it and resume another program to
    run. This is *preemptive multithreading*. As it turns out, this is the right move.
    The operating system is fairer and the computer can do more.
  prefs: []
  type: TYPE_NORMAL
- en: Fast-forward to recent years – Moore’s law no longer applies or at least has
    been paused. So, the CPU is not getting 1,000 cores, but the threads in a working
    computer are ever-increasing. Thus, the cost for the operating system to preempt
    and iterate through all the threads has now become a concern.
  prefs: []
  type: TYPE_NORMAL
- en: What can we do?
  prefs: []
  type: TYPE_NORMAL
- en: Some smart guys found out that we just need to do what we did in the beginning
    – use cooperative multithreading again. But this time, the controlling program
    is your main program – since you can’t be selfish with yourself, you will be fair
    to all your coroutines to the best of your ability.
  prefs: []
  type: TYPE_NORMAL
- en: This is a simplified version of the evolution of the computer system. It is
    not historically perfect and has some dramatic touches to it. The goal is for
    you to realize that `coroutine` is a simple concept and that you can be comfortable
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn how to use coroutines with C++.
  prefs: []
  type: TYPE_NORMAL
- en: Using coroutine with C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do not use Lua `coroutine` with C++ if you have an alternative. As the iterator
    example showed, you can wrap `coroutine` in a normal function and keep calling
    it until it returns nil.
  prefs: []
  type: TYPE_NORMAL
- en: 'But to be less opinionated and for completeness, we can use the following Lua
    library function to start or resume a coroutine from C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The function is similar to `pcall`. It expects the function to be called and,
    optionally, its arguments on the stack. The function will be the coroutine. `L`
    is a stack for the coroutine. `from` is the stack from which the coroutine is
    called. `narg` is the number of arguments to the `coroutine` function. `nresults`
    points to an integer and Lua will output the number of values yielded or returned
    to the integer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example to understand how this works. In `LuaExecutor.h`, add
    a function declaration, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `resume` function supports `coroutine` in a limited way. It does not support
    passing parameters, but this is easy to do and you can refer to `LuaExecutor::call`.
    It only expects one return value as an integer. This is just to demonstrate the
    Lua API, not to add complete support for `coroutine` in our Lua executor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement `resume`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a five-step process, separated by newlines, which is explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It creates a new Lua state with `lua_newthread`. A reference to the new state
    is also pushed onto the main stack owned by `L`. We can call this new state the
    coroutine state. But `thd` is the coroutine stack. The Lua `lua_newthread` library
    function creates a new Lua state that shares the same global environment with
    the main state `L` but has its own execution stack. Yes, the API name is a bit
    misleading, but it is what it is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It pushes the function name to be executed as a coroutine onto the new Lua stack.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It calls `lua_resume` to start or resume the coroutine. Since we are always
    creating a new state named `thd`, we are always starting the coroutine afresh.
    To resume it, we need to save `thd` somewhere and pass it in for future calls.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It checks whether there is an error; or, in case the coroutine does not return
    any result, it means that it has ended.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It retrieves the single integer that we expect, pops it from the coroutine stack,
    pops the reference to the coroutine stack from the main stack, and returns the
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taking care of other Lua states
  prefs: []
  type: TYPE_NORMAL
- en: A coroutine needs its own Lua state to be executed. You need to keep a reference
    to its Lua state somewhere until you no longer need the coroutine. Without a reference,
    Lua will destroy the state during garbage collection. If you have many coroutines,
    keeping all of those extra Lua states in the main stack can be messy. So, if you
    want to work with coroutines in C++, you need to design a system to hold and query
    those Lua states.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add the following Lua function to `script.lua`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This function yields two values. The `for` loop is hardcoded because we do not
    support passing arguments in `LuaExecutor::resume`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the last bit of the demonstration, write `main.cpp` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This sets up the Lua executor and calls the `resume` function to start `coroutine`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compile and run the project; you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This shows how to work with `lua_resume`. You can read the Lua reference manual
    to get more detailed information about this API.
  prefs: []
  type: TYPE_NORMAL
- en: C++ code can also be executed as a coroutine. This can be done where a `lua_CFunction`
    implementation is provided to `lua_resume`, or Lua code in a coroutine calls a
    `lua_CFunction` implementation. In this case, C++ code can also yield by calling
    `lua_yieldk`.
  prefs: []
  type: TYPE_NORMAL
- en: Using coroutine with C++ can be very complex, but if you have your use cases
    defined, this can be abstracted to hide the complex details. This section is only
    an eye-opener. You can decide whether to use Lua this way or not.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With that, we have wrapped up the final chapter of this book. In this chapter,
    we focused on multithreading mechanisms, preemptive multithreading and cooperative
    multithreading, and Lua coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Lua coroutines can be used without C++ for advanced Lua programming and you
    can hide all these details from C++. We only touched the tip of the iceberg. You
    can read the Lua reference manual and practice more. You can also explore more
    on how to use coroutines with C++ by experimenting with the related Lua library
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we implemented `LuaExecutor` progressively. Each chapter added
    more features to it. However, it is not perfect. For example, `LuaValue` can be
    improved to make it easier to work with, and `LuaExecutor` can support more table
    operations. You can use `LuaExecutor` as a base and adapt it to your project or
    implement your own in a completely different way after you have learned the mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: I am confident that at this point, you can make improvements and add more features
    that suit you the best. You can always revisit the chapters as reminders and search
    the Lua reference manual for what you need.
  prefs: []
  type: TYPE_NORMAL
