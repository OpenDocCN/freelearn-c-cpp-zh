- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Temporal Anti-Aliasing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will expand on a concept touched on in the previous one
    when we talked about temporal reprojection. One of the most common ways to improve
    image quality is to sample more data (super-sampling) and filter it down to the
    needed sampling frequency.
  prefs: []
  type: TYPE_NORMAL
- en: The primary technique used in rendering is **Multi-Sample Anti-Aliasing**, or
    **MSAA**. Another technique used for super-sampling is temporal super-sampling
    or using the samples from two or more frames to reconstruct a higher-quality image.
  prefs: []
  type: TYPE_NORMAL
- en: In the Volumetric Fog technique, a similar approach is used to remove banding
    given by the low resolution of the Volume Texture in a very effective way. We
    will see how we can achieve better image quality using **Temporal** **Anti-Aliasing**
    (**TAA**).
  prefs: []
  type: TYPE_NORMAL
- en: This technique has become widely used in recent years after more and more games
    started using Deferred Rendering at their core and because of the difficulty in
    applying MSAA on it. There were various attempts to make MSAA and Deferred Rendering
    work together, but performance (both time- and memory-wise) has always been proven
    to not be feasible at the time and thus alternative solutions started to be developed.
  prefs: []
  type: TYPE_NORMAL
- en: Enter **Post-Process Anti-Aliasing** and its plethora of acronyms. The first
    one to be widely used was **Morphological Anti-Aliasing**, or **MLAA**, developed
    by Alexander Reshetov, working at Intel at the time, and presented at High-Performance
    Graphics in 2009.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm was developed to work on the CPU using Intel’s **Streaming SIMD
    Extensions** (**SSE**) instructions and introduced some interesting solutions
    to find and improve geometrical edge rendering, which fueled successive implementations.
    Later, Sony Santa Monica adopted MLAA for God of War III using the Cell **Synergisic
    Processing Unit** (**SPUs**) to be performed with real-time performances.
  prefs: []
  type: TYPE_NORMAL
- en: Post-Process Anti-Aliasing finally found a GPU implementation developed by Jorge
    Jimenez and others in 2011, opening a new rendering research field. Various other
    game studios started developing custom Post Process Anti-Aliasing techniques and
    sharing their details.
  prefs: []
  type: TYPE_NORMAL
- en: All those techniques were based on geometrical edge recognition and image enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect that started to emerge was the reuse of information from previous
    frames to further enhance visual quality, such as in **Sharp Morphological Anti-Aliasing**,
    or **SMAA**, which started adding a temporal component to enhance the final image.
  prefs: []
  type: TYPE_NORMAL
- en: The most adopted anti-aliasing technique is TAA, which comes with its own set
    of challenges but fits nicely within the rendering pipeline and lets other techniques
    (such as Volumetric Fog) increase their visual quality by reducing banding with
    the introduction of animated dithering.
  prefs: []
  type: TYPE_NORMAL
- en: TAA is now the standard in most game engines, both commercial and private. It
    comes with its own challenges, such as handling transparent objects and image
    blurriness, but we will see how to tackle those problems as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of the chapter, we will first see an overview of the algorithm and
    then dive into the implementation. We will also create an initial, incredibly
    simple implementation just to show the basic building blocks of the algorithm,
    allowing you to understand how to write a custom TAA implementation from scratch.
    Finally, we will see the different areas of improvement within the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example scene and highlight the TAA improvements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Temporally anti-aliased scene](img/B18395_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Temporally anti-aliased scene
  prefs: []
  type: TYPE_NORMAL
- en: The following are a couple of screenshots of the final result, with and without
    TAA enabled.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Details of Figure 11.1 without (left) and with (right) TAA](img/B18395_11_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Details of Figure 11.1 without (left) and with (right) TAA
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will have a look at the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the simplest TAA implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step-by-step improvement of the technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of image-sharpening techniques outside of TAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving banding in different image areas with noise and TAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter11](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter11).'
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see the algorithm overview of the TAA rendering technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'TAA is based on the collection of samples over time by applying small offsets
    to the camera projection matrix and applying some filters to generate the final
    image, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Frustum jitter](img/B18395_11_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Frustum jitter
  prefs: []
  type: TYPE_NORMAL
- en: There are various numerical sequences that can be used to offset the camera,
    as we will see in the implementation section. Moving the camera is called **jittering**,
    and by jittering the camera, we gather additional data that we can use to enhance
    the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an overview of the TAA shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – TAA algorithm overview](img/B18395_11_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – TAA algorithm overview
  prefs: []
  type: TYPE_NORMAL
- en: Based on *Figure 11**.4*, we’ve separated the algorithm into steps (blue rectangles)
    and texture reads (yellow ellipses:.
  prefs: []
  type: TYPE_NORMAL
- en: We calculate the coordinates to read the velocity from, represented by the **Velocity**
    **Coordinates** block.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is normally done by reading a neighborhood of 3x3 pixels around the current
    pixel position and finding the closest pixel, using the current frame’s **Depth
    Texture**. Reading from a 3x3 neighborhood has been proven to decrease ghosting
    and improve edge quality.
  prefs: []
  type: TYPE_NORMAL
- en: We read the velocity using the newly found coordinates from the **Velocity Texture**
    block, paying attention to use a linear sampler, as velocity is not just in increments
    of pixels, but can be in-between pixels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We read the color information from the **History Texture** block. This is basically
    the last frame’s TAA output. We can optionally apply a filter to read the texture
    to further enhance the quality.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will read the current scene color. In this step, we will also cache information
    again by reading a neighborhood around the current pixel position to constrain
    the history color we read previously and guide the final resolve phase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: History constraint. We try to limit the previous frame color inside an area
    of the current color to reject invalid samples coming from occlusion or disocclusion.
    Without doing that there would be a lot of ghosting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sixth and final step is **Resolve**. We combine the current color and the
    constraint history color to generate the final pixel color by applying some additional
    filters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The result of the current frame’s TAA will be the next frame history texture,
    so we simply switch the textures (history and TAA result) every frame without
    the need to copy the results over, as seen in some implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen an overview of the algorithm, we can start by implementing
    an initial TAA shader.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest TAA implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best way to understand this technique is to build a basic implementation
    missing some important steps and to have a blurry or jittery rendering as it is
    easy to do.
  prefs: []
  type: TYPE_NORMAL
- en: The basic ingredients for this technique are simple if done correctly, but each
    must be done in a precise way. We will first add jittering to the camera so that
    we can render slightly different points of view of the scene and gather additional
    data.
  prefs: []
  type: TYPE_NORMAL
- en: We will then add motion vectors so that we can read the previous frame color
    information in the right place. Finally, we will reproject, or simply put, read
    the history frame color data and combine it with current frame data.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see the different steps.
  prefs: []
  type: TYPE_NORMAL
- en: Jittering the camera
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The objective of this step is to translate the projection camera by a small
    amount in both the *x* and *y* axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have added some utility code in the `GameCamera` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Every step is important and error prone, so be careful.
  prefs: []
  type: TYPE_NORMAL
- en: We first want to reset the projection matrix, as we will manually modify it.
    We then build a translation matrix with the jittering values in `x` and `y`, and
    we will see later how to calculate them.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we multiply the projection matrix by the jittering matrix and calculate
    the new view-projection matrix. Beware of multiplication order, as if this is
    wrong you will see a jittery blurry mess even when not moving the camera!
  prefs: []
  type: TYPE_NORMAL
- en: 'Having this working, we can optimize the code by removing the matrix construction
    and multiplication, having cleaner and less error-prone code, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Choosing jittering sequences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now build a sequence of `x` and `y` values to jitter the camera. Normally
    there are different sequences that are used:'
  prefs: []
  type: TYPE_NORMAL
- en: Halton
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hammersley
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Martin Robert’s R2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interleaved gradients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are all the implementations for the preceding sequences in the code, and
    each can give a slightly different look to the image, as it changes how we collect
    samples over time.
  prefs: []
  type: TYPE_NORMAL
- en: There is plenty of material on using the different sequences that we will provide
    links to at the end of the chapter; right now what is important is to know that
    we have a sequence of two numbers that we repeat after a few frames to jitter
    the camera.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us say that we choose the Halton sequence. We first want to calculate the
    values for `x` and `y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'These values are in the `[0,1]` range, but we want to jitter in both directions,
    so we map it to the `[-``1.1]` range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We now apply them to the apply `jitter` method, with a caveat: we want to add
    sub-pixel jittering, thus we need to divide these offsets by the screen resolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have a jitter period to choose after how many frames we repeat
    the jittering numbers, updated like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: A good period is normally four frames, but in the accompanying code, there is
    the possibility to change this number and see the effect on the rendering image.
  prefs: []
  type: TYPE_NORMAL
- en: Another fundamental thing to do is to cache previous and current jittering values
    and send them to the GPU, so that motion vectors take into consideration the full
    movement.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve added `jitter_xy` and `previous_jitter_xy` as variables in the scene uniforms
    to be accessed in all shaders.
  prefs: []
  type: TYPE_NORMAL
- en: Adding motion vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we correctly jittered the camera and saved the offsets, it is time
    to add motion vectors to properly read the color data from the previous frame.
    There are two sources of motion: camera motion and dynamic object motion.'
  prefs: []
  type: TYPE_NORMAL
- en: We added a velocity texture with R16G16 format to store the per-pixel velocity.
    For each frame, we clear that to `(0,0)` and we calculate the different motions.
    For camera motion, we will calculate the current and previous screen space position,
    considering the jitter and the motion vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will perform this in a compute shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Dynamic meshes need an additional output to be written in the vertex or mesh
    shaders, with similar calculations done in the camera motion shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: And after this, just writing the velocity to its own render target will be all
    that is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the motion vectors, we can finally see the implementation of
    an extremely basic TAA shader.
  prefs: []
  type: TYPE_NORMAL
- en: First implementation code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We again run a compute shader to calculate TAA. The implementation of the simplest
    possible shader is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Going through the code, the steps are simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample the velocity at the pixel position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample the current color at the pixel position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample the history color at the previous pixel position, calculated using the
    motion vectors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mix the colors, taking something like 10% of the current frame colors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before moving on to any improvement it is paramount to have this working perfectly.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see a blurrier image with a big problem: ghosting when moving the
    camera or an object. If the camera and the scene are static, there should be no
    pixel movement. This is fundamental to knowing that jittering and reprojection
    are working properly.'
  prefs: []
  type: TYPE_NORMAL
- en: With this implementation working, we are now ready to see the different improvement
    areas to have a more solid TAA.
  prefs: []
  type: TYPE_NORMAL
- en: Improving TAA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are five areas to improve TAA: reprojection, history sampling, scene
    sampling, history constraint, and resolve.'
  prefs: []
  type: TYPE_NORMAL
- en: Each one has different parameters to be tweaked that can suit the rendering
    needs of a project – TAA is not exact or perfect, thus some extra care from a
    visual perspective needs to be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the different areas in detail so that the accompanying code will be
    clearer.
  prefs: []
  type: TYPE_NORMAL
- en: Reprojection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing to do is to improve reprojection and thus calculate the coordinates
    to read the velocity to drive the *History* *sampling* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the history texture pixel coordinates, the most common solution
    is to get the closest pixel in a 3x3 square around the current pixel, as an idea
    by Brian Karis. We will read the depth texture and use the depth value as a way
    to determine the closest pixel, and cache the `x` and `y` position of that pixel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'By just using the found pixel position as the read coordinate for the motion
    vectors, ghosting will be much less visible, and edges will be smoother:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: There can be other ways of reading the velocity, but this has proven to be the
    best trade-off between quality and performance. Another way to experiment would
    be to use the maximum velocity in a similar 3x3 neighborhood of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: There is no perfect solution, and thus experimentation and parametrization of
    the rendering technique are highly encouraged. After we have calculated the pixel
    position of the history texture to read, we can finally sample it.
  prefs: []
  type: TYPE_NORMAL
- en: History sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this case, the simplest thing to do is to just read the history texture at
    the calculated position. The reality is that we can apply a filter to enhance
    the visual quality of the read as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the code, we’ve added options to try different filters, and the standard
    choice here is to use a Catmull-Rom filter to enhance the sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After we have the history color, we will sample the current scene color and
    cache information needed for both the history constraint and the final resolve
    phase.
  prefs: []
  type: TYPE_NORMAL
- en: Using the history color without further processing would result in ghosting.
  prefs: []
  type: TYPE_NORMAL
- en: Scene sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, ghosting is less noticeable but still present, so with a similar
    mentality to searching for the closest pixel, we can search around the current
    pixel to calculate color information and apply a filter to it.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, we are treating a pixel like a signal instead of a simple color.
    The subject can be quite long and interesting and at the end of the chapter, there
    will be resources to dive deeper into this. Also, in this step, we will cache
    information used for the history boundaries used to constrain the color coming
    from the previous frames.
  prefs: []
  type: TYPE_NORMAL
- en: What we need to know is that we sample another 3x3 area around the current pixel
    and calculate the information necessary for the constraint to happen. The most
    valuable information is the minimum and maximum color in this area, and Variance
    Clipping (which we will look at later on) also requires mean color and square
    mean color (known as **moments**) to be calculated to aid history constraint.
    Finally, we will also apply some filtering to the sampling of the color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: What all this code does is sample color, filter it, and cache information for
    the history constraint, and thus we are ready to move on to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: The history constraint
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we arrived at the constraint of the history sampled color. Based on
    previous steps we have created a range of possible color values that we consider
    valid. If we think of each color channel as a value, we basically created an area
    of valid colors that we will constraint against.
  prefs: []
  type: TYPE_NORMAL
- en: A constraint is a way of accepting or discarding color information coming from
    the history texture, reducing ghosting to almost nothing. Over time, different
    ways to constrain history sampled color were developed in search of better criteria
    to discard colors.
  prefs: []
  type: TYPE_NORMAL
- en: Some implementations also tried relying on depth or velocity differences, but
    this seems to be the more robust solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have added four constraints to test:'
  prefs: []
  type: TYPE_NORMAL
- en: RGB clamp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RGB clip
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance clip
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance clip with clamped RGB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best quality is given by variance clip with the clamped RGB, but it is interesting
    to see the other ones, as they are the ones that were employed in the first implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `clip_aabb` function is the method that constrains the sampled history color
    within minimum and maximum color values.
  prefs: []
  type: TYPE_NORMAL
- en: In brief, we are trying to build an AABB in colorspace to limit the history
    color to be within that range, so that the final color is more plausible compared
    to the current one.
  prefs: []
  type: TYPE_NORMAL
- en: The last step in the TAA shader is resolve, or combining current and history
    colors and applying some filters to generate the final pixel color.
  prefs: []
  type: TYPE_NORMAL
- en: Resolve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once again, we will apply some additional filters to decide whether the previous
    pixel is usable or not and by how much.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, we start with using just 10% of the current frame pixel and rely
    on history, so without any of those filters the image will be quite blurry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The first filter we will see is the temporal one, which uses the cached neighborhood
    minimum and maximum colors to calculate how much to blend the current and previous
    colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The next two filters are linked; thus, we have them together.
  prefs: []
  type: TYPE_NORMAL
- en: 'They both work with luminance, with one used to suppress so-called **fireflies**,
    or very bright single pixels that can exist in images when there is a strong source
    of light, while the second uses the difference in luminance to further steer the
    weight toward either the current or previous colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We combine the result using the newly calculated weights, and finally, we output
    the color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the shader is complete and ready to be used. In the accompanying
    demo, there will be many tweaking parameters to learn the differences between
    the different filters and steps involved.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common complaints about TAA is the blurriness of the image.
    We will see a couple of ways to improve that next.
  prefs: []
  type: TYPE_NORMAL
- en: Sharpening the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One thing that can be noticed in the most basic implementation, and a problem
    often linked to TAA, is a decrease in the sharpness of the image.
  prefs: []
  type: TYPE_NORMAL
- en: We have already improved it by using a filter when sampling the scene, but we
    can work on the final image appearance outside of TAA in different ways. We will
    briefly discuss three different ways to improve the sharpening of the image.
  prefs: []
  type: TYPE_NORMAL
- en: Sharpness post-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the ways to improve the sharpness of the image is to add a simple sharpening
    shader in the post-process chain.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is simple, and it is luminance based:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Based on this code, when the sharpening amount is `0` the image is not sharpened.
    The standard value is `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Negative mip bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A global way to reduce blurriness is to modify the `mipLodBias` field in the
    `VkSamplerCreateInfo` structure to be a negative number, such as `–0.25`, thus
    shifting the texture **mip,** the pyramid of progressively smaller images of a
    texture to higher values.
  prefs: []
  type: TYPE_NORMAL
- en: This should be done by considering the performance difference, as we are sampling
    at a higher MIP level, and if the level is too high, we could re-introduce aliasing.
  prefs: []
  type: TYPE_NORMAL
- en: A global engine option to tweak would be a great solution to this.
  prefs: []
  type: TYPE_NORMAL
- en: Unjitter texture UVs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another possible fix to sample sharper textures is to calculate the UVs as
    the camera was without any jittering, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: I personally did not try this method but found it interesting and something
    to experiment with. It was written about by Emilio Lopez in his TAA article, linked
    in the *Reference* section, also citing a colleague named Martin Sobek who came
    up with the idea.
  prefs: []
  type: TYPE_NORMAL
- en: The combination of TAA and sharpening drastically improves the edges of the
    image while retaining the details inside the objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to look at one last aspect of the image: banding.'
  prefs: []
  type: TYPE_NORMAL
- en: Improving banding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Banding is a problem affecting various steps in the rendering of a frame. It
    affects Volumetric Fog and lighting calculations, for example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Banding problem detail in Volumetric Fog](img/B18395_11_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – Banding problem detail in Volumetric Fog
  prefs: []
  type: TYPE_NORMAL
- en: We can see in *Figure 11**.5* how this can be present in Volumetric Fog if no
    solution is implemented. A solution to remove banding in visuals is to add some
    dithering to various passes of the frame, but that also adds visual noise to the
    image.
  prefs: []
  type: TYPE_NORMAL
- en: Dithering is defined as the intentional addition of noise specifically to remove
    banding. Different type of noises can be used, as we will see in the accompaining
    code. Adding temporal reprojection smoothens the noise added, thus becoming one
    of the best ways to improve the visual quality of the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter 10*](B18395_10.xhtml#_idTextAnchor152), *Adding Volumetric Fog*,
    we saw a very simple temporal reprojection scheme, and we have also added noise
    to various steps of the algorithm. We have now seen a more complex implementation
    of a temporal reprojection scheme to enhance the image, and it should be clearer
    on reasoning behind animated dithering: animating dithering gives effectively
    more samples, and thanks to temporal reprojection, uses them effectively. Dithering
    is linked to its own temporal reprojection, thus in the Volumetric Fog steps,
    the dithering scale can be too large to be cleaned up by TAA.'
  prefs: []
  type: TYPE_NORMAL
- en: When applying Volumetric Fog to the scene though, we can add a small, animated
    dithering that increases the fog visuals while being cleaned up by TAA. Another
    dithering application is in the lighting shader, again at the per-pixel level
    and thus eligible to be cleaned up by TAA.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Trying to get a noise-free image is hard as the temporal reprojection uses more
    than one frame, thus it is not possible to show here in an image what appears
    banding-free in the accompanying application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the TAA rendering technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'We gave an overview of the algorithm by trying to highlight the different shader
    steps involved. We then moved on to create the simplest possible TAA shader: an
    exercise to give us a deeper understanding of the technique itself.'
  prefs: []
  type: TYPE_NORMAL
- en: Following that, we started enhancing the various steps using filters and information
    taken from the current scene. We encourage you to add custom filters and tweak
    parameters and different scenes to understand and develop the technique further.
  prefs: []
  type: TYPE_NORMAL
- en: An idea to experiment with could also be to apply the history constraint to
    the temporal reprojection phase of the Volumetric Fog, as suggested by my friend
    Marco Vallario a few months ago.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will add support for ray tracing to the Raptor Engine,
    a recent technological advancement that unlocks high-quality illumination techniques,
    which we will cover in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We touched on several topics in this chapter, from the history of post-process
    anti-aliasing to implementations of TAA, to banding and noise.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the graphics community, which shares a lot of information on their
    findings, it is possible to sharpen our knowledge on this subject.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some links to read:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For an index of the evolution of Post-Process Anti-Aliasing techniques: [http://www.iryoku.com/research-impact-retrospective-mlaa-from-2009-to-2017](http://www.iryoku.com/research-impact-retrospective-mlaa-from-2009-to-2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first MLAA paper: [https://www.intel.com/content/dam/develop/external/us/en/documents/z-shape-arm-785403.pdf](https://www.intel.com/content/dam/develop/external/us/en/documents/z-shape-arm-785403.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An MLAA GPU implementation: [http://www.iryoku.com/mlaa/](http://www.iryoku.com/mlaa/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SMAA, an evolution of MLAA: [http://www.iryoku.com/smaa/](http://www.iryoku.com/smaa/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The best article on signal processing and anti-aliasing by Matt Pettineo: [https://therealmjp.github.io/posts/msaa-resolve-filters/](https://therealmjp.github.io/posts/msaa-resolve-filters/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Temporal Reprojection Anti-Aliasing in Inside, containing the first full documentation
    of a TAA technique. Includes information about history constraints and AABB clipping:
    [http://s3.amazonaws.com/arena-attachments/655504/c5c71c5507f0f8bf344252958254fb7d.pdf?1468341463](http://s3.amazonaws.com/arena-attachments/655504/c5c71c5507f0f8bf344252958254fb7d.pdf?1468341463).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'High-Quality Temporal Supersampling, Unreal Engine TAA implementation: [https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf](https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An excursion in temporal super-sampling, introducing variance clipping: [https://developer.download.nvidia.com/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf](https://developer.download.nvidia.com/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A TAA article, with tips, such as UV unjittering and Mip bias: [https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/](https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another great TAA article with a full implementation: [https://alextardif.com/TAA.xhtml](https://alextardif.com/TAA.xhtml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Banding in games: [https://loopit.dk/banding_in_games.pdf](https://loopit.dk/banding_in_games.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
