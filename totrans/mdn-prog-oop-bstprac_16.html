<html><head></head><body>
		<div class="Content" id="_idContainer058">
			<h1 id="_idParaDest-224"><em class="italics"><a id="_idTextAnchor238"/>Chapter 14</em></h1>
		</div>
		<div class="Content" id="_idContainer059">
			<h1 id="_idParaDest-225"><a id="_idTextAnchor239"/>Ethics</h1>
		</div>
		<div class="Content" id="_idContainer060">
			<h2 id="_idParaDest-226"><a id="_idTextAnchor240"/>Introduction</h2>
			<p>The movement of developers – neophytes and experienced alike – to the iPhone with the launch of its app store has been <em class="italics">likened to a gold rush</em>—<a href="http://www.adweek.com/news/technology/inside-iphone-app-gold-rush-98856">http://www.adweek.com/news/technology/inside-iphone-app-gold-rush-98856</a>. Few people would hold the California gold rush of 1849 up as a shining example of humans behaving with humanity, though.</p>
			<p>Selfish drive for profit broke up existing communities: three-quarters of adult men in San Francisco left the city during the rush, excited to find new deposits of gold to exploit. They even destroyed other communities, coming into conflict with the Native Americans in the region as they dug up the land the indigenous people inhabited. Paranoid self-protection led to rule of the mob and uncommonly harsh punishments for crimes of property: hanging was a common consequence for those thought to have stolen gold from another.</p>
			<p>So, is the gold rush an acceptable model for today's programmers? Are we free to seek the highest financial income, whatever the cost to others – friends and strangers alike? Should we be <em class="italics">every coder for themselves</em>, or do we need to work together with fellow programmers and non-programmers alike? Is mob rule acceptable or is there a code of conduct we should be expected to follow?</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor241"/>Examples of Ethical Codes</h2>
			<p>Plenty of professions have their codes of ethics (The discussion of whether programming is a "profession" will take place in the next chapter). Indeed, the <strong class="bold">Online Ethics Center</strong> (<a href="http://www.onlineethics.org">http://www.onlineethics.org<span id="_idTextAnchor242"/></a>) has plenty of examples, case studies, and discussions. Rather than trawl through those, I'll focus on a couple from the computing field.</p>
			<p>The Association of Computing Machinery's <strong class="bold">code of ethics and professional conduct</strong>— <a href="http://www.acm.org/about/code-of-ethics">http://www.acm.org/about/code-of-ethics</a> is a short document, comprising 24 ethical imperatives members are expected to follow: one of which is that membership of the Association is contingent on abiding by the other imperatives.</p>
			<p>The code is both technology and practice agnostic, as it should be written at the level of abstraction of an entire industry's career lifetimes. Briefly, the four sections say:</p>
			<ul>
				<li>Respect other people and their property, do no harm, work to make humanity better</li>
				<li>Be up to date with what's going on in the profession, help others to stay up to date, and work to what the profession currently believes to be the highest standards and best practices</li>
				<li>Ensure that others in and affected by your organization are protected by these same standards</li>
				<li>Abide by and promote the code</li>
			</ul>
			<p>Unsurprisingly, the <em class="italics">British Computer Society</em>—<a href="http://www.bcs.org/category/6030">http://www.bcs.org/category/6030</a> has very similar ethical principles. Though their code is organized differently, it covers all the same points that the ACM's does.</p>
			<p>I don't feel the need to add anything to either code; each sets out some principles that the organization aspires to and would like to see in its members. Discussing whether something should be added or removed is a big topic, but let's leave these codes as they are for now. The questions remaining are: how should we <em class="italics">interpret</em> these codes, and <em class="italics">should</em> we apply them?</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor243"/>Application of The Ethical Code</h2>
			<p>Abiding by some code of ethics is more expensive than ignoring it. The ACM code tells us to "Honor property rights including copyrights and patent": obviously, it's cheaper to steal someone else's copyrighted work than to build an equivalent work. Examples could be found for the other moral imperatives in the code.</p>
			<p>Legal systems work, broadly speaking, by introducing a cost of non-compliance so that rational actors should also be abiding actors. This is an example of removing an <em class="italics">externality</em>, discussed in <em class="italics">Chapter 15, Philosophy</em>, of this book. If stealing the copyrighted work is going to cost the thief in legal fees, damages, and lost reputation, the other route becomes attractive.</p>
			<p>For most of us making software, the legal framework we operate in doesn't directly apply to our actions. Laws exist covering data protection, and certain fields are strongly regulated (principally, life-critical systems such as control software for medical devices). For the most part, software makers are free to act as we please, subject to market forces. This is largely the result, ironically, of groups including the ACM lobbying for self-regulation in the software sector. They want an ethical code but wouldn't like it if the courts could enforce it.</p>
			<p>Also, for the most part, software makers are <em class="italics">not</em> members of bodies such as the <strong class="bold">BCS</strong> (<strong class="bold">British Computer Society</strong>) so don't have the threat of expulsion for failing to comply with the ethical code. And finally, it's not obvious that ethics or morality enter into the hiring process either (though, once you're working for a company, their human resources department should be charged with ensuring that the whole company acts according to that company's ethical principles). I have certainly never been asked in an interview whether I've ever acted unethically. I've been asked what I know of Perl, and how I interact with other people on a team, but never whether I've failed to respect the privacy of others.</p>
			<p>So, where does the obligation to behave ethically come from, if it's going to introduce additional costs?</p>
			<p>One answer is that there <em class="italics">are</em> costs associated with acting unethically, albeit not direct financial ones. Acting outside of one's principles exerts an emotional cost, of which individuals can only pay so much.</p>
			<p>This concept of emotional cost is already used in relation to network security policies. It's well understood that when users are asked to comply with security policies, the tasks usually involve <em class="italics">additional mental effort</em>—<a href="http://hal.archives-ouvertes.fr/docs/00/69/18/18/PDF/Besnard-Arief-2004--Computer-security-impaired-legal-users.pdf">http://hal.archives-ouvertes.fr/docs/00/69/18/18/PDF/Besnard-Arief-2004--Computer-security-impaired-legal-users.pdf</a> beyond taking the easy, but insecure, approach. If this mental cost gets too great, then users might decide not to pay it, taking the easier, non-compliant route. This still has some mental effort in terms of the anguish involved in knowing that they are violating their employers' trust, and the fear that they might get caught out. This anxiety could cause distractions in their other work or they could even leave their job rather than work against their own principles.</p>
			<p>There are, additionally, reputation costs to unethical actions, as suppliers or customers may choose not to do business with companies or people they perceive to be unethical and may prefer to do business with those whose values align closely to their own. As described above, this is not really an <em class="italics">overt</em> input into the way the software marketplace works; that doesn't mean it's not a factor at all.</p>
			<p>This reputation factor is a large input into the golden rule (here, supplied in Boehm's modified version): do unto others as you would have them do unto you if you were like them. This can build into a reciprocal and valuable network of people and organizations acting in support of their mutual values and interests. And <em class="italics">that</em> can make working ethically more efficient and easier than the alternatives.</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor244"/>Ethical Ambiguities</h2>
			<p>It's always easier to model the world as a system of exclusive choices: this is good, that is bad; this is right, that is wrong; this is fast, that is slow. Unfortunately, such a model can quickly be found to have too many limitations. Different ethical principles all-too-readily come into conflict. Part of our responsibility as members of society is to identify and resolve these conflicts (after all, if ethics were a simple application of rules, we would've got a computer to do it by now).</p>
			<p>Let me provide an example from my own experience. I was offering advice to another programmer about applying and interviewing for new jobs, when this person told me about an interview they had attended. They described feeling that the interview had been discriminatory on the basis of candidates' ethnicities, which is clearly in breach of any professional ethics system. Referring to the ACM's code, this breaks imperative 1.4: Be fair and take action not to discriminate.</p>
			<p>Some people would react to this by suggesting that I "blow the whistle," calling out the company's discriminatory practices publicly and moving, if their employees are members of a professional body, to have them black-balled by that association. Not so fast, though! To do so would mean applying my <em class="italics">own</em> unfair standards: privileging one side of a story without hearing and evaluating the other. It would also mean going public with the tale of the interview that I had been told in confidence, which breaks the ethical imperatives to respect privacy and confidentiality (1.7 and 1.8 in ACM's code).</p>
			<p>In the end, I decided to recommend to the person who'd told me about this that <em class="italics">they</em> should lodge a complaint about the interview, and that I would support them in that. Regardless of whether you agree with that specific outcome, you can see that situations exist in which there is no clear "ethical" way to behave. Having an ethical code that you are aware of, can describe (even if only to yourself), and can relate to what you do is important. Looking to others for guidance and assimilating their advice is important. Knowing the "one true way" to act is best left to Taoism.</p>
			<p>In fact, there really is no one true way. Ethical imperatives are <em class="italics">normative</em>: they arise from the shared beliefs and values of the people interacting together, defining actions they consider acceptable (appropriate behavior, if you will) and those they do not. What's ethical now may not be considered so in the future, and vice versa. What's ethical to one group of people may not be considered so to another group.</p>
			<p>This change in ethical norms over time can be seen in the practice of psychology. After the post-WW2 war crimes trials disclosed the cruel experiments carried out on prisoners by the Nazi regime, psychologists accepted the need for a professional set of ethics and code of practice to govern their experiments. The first such rules were published as <strong class="bold">the Nuremberg Code</strong>—<a href="https://history.nih.gov/research/downloads/nuremberg.pdf">https://history.nih.gov/research/downloads/nuremberg.pdf</a> in 1949.</p>
			<p>Notice that the code says nothing about child subjects (or "participants" as modern psychologists would say). Indeed, the question of child participation has been answered in different ways in different countries and at different times. When Albert Bandura conducted his famous <strong class="bold">Bobo doll experiment</strong>—<a href="http://www.simplypsychology.org/bobo-doll.html">http://www.simplypsychology.org/bobo-doll.html</a> into childhood imitation of aggression, the parents involved would've known that their children were involved in an experiment, but the children could not have known. In modern experiments, it is likely that the children themselves would need to be made aware that they are participating in an experiment. Indeed, even <strong class="bold">primate research</strong>—<a href="http://digitaljournal.com/article/343702">http://digitaljournal.com/article/343702</a> can involve voluntary participation – considerations not made when the Nuremberg Code was created.</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor245"/>Respecting Privacy</h2>
			<p>A problem that's been at the forefront of ethical debates in the software industry for at least the last couple of decades, and will likely remain at the forefront for at least another decade, is the use or misuse of personal data. In a quest to drive adoption, many software vendors have ended up distributing their software below cost and gaining revenue by collecting data about their users to sell to advertisers and other aggregators.</p>
			<p>This practice of selling user data could be seen as unethical, as it may break the imperative to honor the privacy of others. This is especially true if the user did not give informed consent to sharing the data; if the user is a child who did not understand the implications of sharing the data; or if the information gathered is more than the minimum required to support the sharing activity.</p>
			<p>Because this is such a large and immediate problem that is continually being raised and discussed both in the tech press and the corridors of power, I applied the privacy imperative to personal data sharing and came up with the "Don't Be a Dick" guide to data privacy (Wil Wheaton deserves credit for popularizing the phrase "Don't be a dick," known in some circles as Wheaton's Law):</p>
			<ul>
				<li>The only things you are entitled to know are those things that the user told you.</li>
				<li>The only things you are entitled to share are those things that the user permitted you to share.</li>
				<li>The only entities with which you may share are those entities with which the user permitted you to share.</li>
				<li>The only reason for sharing a user's things is that the user wants to do something that requires the sharing of those things.</li>
			</ul>
			<p>It's simple, which makes for a good user experience. It's explicit, which means culturally situated ideas of acceptable implicit sharing do not muddy the issue.</p>
			<p>It's also general. One problem I've seen with privacy discussions is that different people have specific ideas of what the absolutely biggest privacy issue that must be solved now is. For many people, it's location; they don't like the idea that an organization (public or private) can see where they are at any time. For others, it's unique identifiers that would allow an entity to form an aggregate view of their data across multiple functions. For others still, it's conversations they have with their boss, mistress, whistle-blower, or others.</p>
			<p>Because the guide mentions none of these, it covers all of these – and more. Who knows what sensors and capabilities will exist in future smartphone kits? They might use mesh networks that can accurately position users in a crowd with respect to other members. They could include automatic person recognition to alert when your friends are nearby. A handset might include a blood sugar monitor. The fact is that, by not stopping to cover any particular form of data, the above guideline covers <em class="italics">all of these</em> and any others that I didn't think of.</p>
			<p>There's one thing it doesn't address: just because a user wants to share something, should the app allow it? This is particularly a question that makers of apps for children should ask themselves. However, children also deserve impartial guidance on what it is a good or a bad idea to share with the innerwebs at large, and that should be baked into the app experience. "Please check with a responsible adult before pressing this button" does not cut it: just don't give them the button.</p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor246"/>Epilogue</h2>
			<p>Of course, the picture I drew of the gold rush at the beginning of the chapter was deliberately one-sided. As people realized that they could only make tiny amounts of easily obtainable gold from single-person techniques such as panning, they started to work together. This collaboration – with the new social structures and rules attendant – led to technological advances in hydraulic mining, extracting both gold and useful minerals.</p>
		</div>
		<div>
			<div class="Content" id="_idContainer061">
			</div>
		</div>
	</body></html>