- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchronous Programming Using Boost.Asio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Boost.Asio** is a C++ library included in the well-known Boost libraries
    family that simplifies the development of solutions dealing with asynchronous
    **input/output** ( **I/O** ) tasks managed by the **operating system** ( **OS**
    ), making it easier to develop asynchronous software that deals with internal
    and external resources, such as network communications services or file operations.'
  prefs: []
  type: TYPE_NORMAL
- en: For that purpose, Boost.Asio defines OS services (services belonging to and
    managed by the OS), I/O objects (providing interfaces to OS services), and the
    I/O execution context object (an object that behaves as a services registry and
    proxy).
  prefs: []
  type: TYPE_NORMAL
- en: In the following pages, we will introduce Boost.Asio, describe its main building
    blocks, and explain some common patterns to develop asynchronous software with
    this library, which are widely used in the industry.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What Boost.Asio is and how it simplifies asynchronous programming with external
    resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What I/O objects and I/O execution contexts are, and how they interact with
    OS services and between each other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What the Proactor and Reactor design patterns are, and how they are related
    to Boost.Asio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to keep the program thread-safe and how to serialize tasks using strands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to efficiently pass data to asynchronous tasks using buffers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to cancel asynchronous operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of common practices with timers and networking applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, we will need to install the Boost C++ libraries. The most
    recent version when writing this book is Boost 1.85.0. Here are the release notes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.boost.org/users/history/version_1_85_0.html](https://www.boost.org/users/history/version_1_85_0.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For installation instructions in Unix variants systems (Linux, macOS), check
    out the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.boost.org/doc/libs/1_85_0/more/getting_started/unix-variants.html](https://www.boost.org/doc/libs/1_85_0/more/getting_started/unix-variants.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Windows systems, check out this link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.boost.org/doc/libs/1_85_0/more/getting_started/windows.html](https://www.boost.org/doc/libs/1_85_0/more/getting_started/windows.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, depending on the project we want to develop, we might need to configure
    **Boost.Asio** or install dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/using.html](https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/using.html)'
  prefs: []
  type: TYPE_NORMAL
- en: All code shown during this chapter will be supported by the C++20 version. Please
    check the technical requirements section in [*Chapter 3*](B22219_03.xhtml#_idTextAnchor051)
    with some guidance on how to install GCC 13 and Clang 8 compilers.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the complete code in the following GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The examples for this chapter are located under the **Chapter_09** folder.
    All source code files can be compiled using CMake as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Executable binaries will be generated under the *bin* directory.
  prefs: []
  type: TYPE_NORMAL
- en: What is Boost.Asio?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Boost.Asio** is a cross-platform C++ library created by Chris Kohlhoff that
    provides a portable network and low-level I/O programming, including sockets,
    timers, hostname resolution, socket iostreams, serial ports, file descriptors,
    and Windows HANDLEs, providing a consistent asynchronous model. It also provides
    coroutine support, but as we learned in the previous chapter, they are now available
    in C++20, so we will only introduce them briefly in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Boost.Asio allows the program to manage long-running operations without the
    explicit usage of threads and locks. Also, as it implements a layer on top of
    the OS services, it allows portability, efficiency, ease of use, and scalability,
    using the most appropriate underlying OS mechanisms to achieve these goals, for
    example, scatter-gather I/O operations or moving data across while minimizing
    costly copies.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by learning about the basic Boost.Asio blocks, I/O objects, and
    I/O execution context objects.
  prefs: []
  type: TYPE_NORMAL
- en: I/O objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, an application needs to access OS services, run asynchronous tasks
    on them, and collect the results or errors. **Boost.Asio** provides a mechanism
    composed of I/O objects and I/O execution context objects to allow this functionality.
  prefs: []
  type: TYPE_NORMAL
- en: I/O objects are task-oriented objects representing the actual entities performing
    I/O operations. As we can see in *Figure 9* *.1* , Boost.Asio provides core classes
    to manage concurrency, streams, buffers, or other core functionality to the library
    and also includes portable networking classes for network communications via **Transmission
    Control Protocol/Internet Protocol** ( **TCP/IP** ), **User Datagram Protocol**
    ( **UDP** ), or **Internet Control Message Protocol** ( **ICMP** ), classes to
    define the security layer, the transmission protocol and serial port, among other
    tasks, and also platform-specific classes to deal with specific settings depending
    on the underlying OS.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – I/O objects](img/B22219_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – I/O objects
  prefs: []
  type: TYPE_NORMAL
- en: 'The I/O objects do not directly execute their tasks in the OS. They need to
    communicate with the OS via an I/O execution context object. An instance of a
    context object is passed as the first argument in the I/O object constructors.
    Here, we are defining an I/O object (a timer with an expiration time of three
    seconds) and passing an I/O execution context object ( **io_context** ) via its
    constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Most I/O objects have methods whose name starts with **async_** . These methods
    trigger asynchronous operations, which will call a completion handler, a callable
    object passed as an argument to the method when the operation completes. These
    methods return immediately, not blocking the program flow. The current thread
    can continue performing other tasks while the task is not complete. Once completed,
    the completion handler will be called and executed, dealing with the result or
    error of the asynchronous task.
  prefs: []
  type: TYPE_NORMAL
- en: I/O objects also provide the blocking counterpart methods, which will block
    until completion. These methods do not need to receive a handler as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned before, note that the I/O objects don’t interact directly with
    the OS; they need an I/O execution context object. Let’s learn about this class
    of objects.
  prefs: []
  type: TYPE_NORMAL
- en: I/O execution context objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To access the I/O services, the program uses at least one I/O execution context
    object that represents the gateway to the OS I/O services. It’s implemented with
    the **boost::asio::io_context** class, providing the core I/O functionality of
    OS services to I/O objects. In Windows, **boost::asio::io_context** is based in
    **I/O completion ports** ( **IOCP** ), on Linux, it is based in **epoll** , and
    on FreeBSD/macOS, it is based in **kqueue** .
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Boost.Asio architecture](img/B22219_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Boost.Asio architecture
  prefs: []
  type: TYPE_NORMAL
- en: '**boost::asio::io_context** is a subclass of **boost::asio::execution_context**
    , a base class for function object execution also inherited by other execution
    context objects, such as **boost::asio::thread_pool** or **boost::asio::system_context**
    . In this chapter, we will be using **boost::asio::io_context** as our execution
    context object.'
  prefs: []
  type: TYPE_NORMAL
- en: The **boost::asio::io_context** class has been a replacement for the **boost::asio::io_service**
    class since version 1.66.0, embracing more modern features and practices from
    C++. **boost::asio::io_service** is still available for backward compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: As described earlier, Boost.Asio objects can schedule asynchronous operations
    using methods starting with **async_** . When all the asynchronous tasks are scheduled,
    the program needs to call the **boost::asio::io_context::run()** function to execute
    an event processing loop, allowing the OS to deal with the tasks and pass to the
    program the results and trigger the handlers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Coming back to our previous example, we will now set up the completion handler,
    **on_timeout()** , a callable object (in this case a function) that we pass as
    a parameter when calling the asynchronous **async_wait()** function. Here is the
    code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Running this code, we should see the message **Timer expired.** in the console
    after three seconds, or an error message if the asynchronous call fails for any
    reason.
  prefs: []
  type: TYPE_NORMAL
- en: '**boost::io_context::run()** is a blocking call. This is intended to keep the
    event loop running, allow the asynchronous operations to run, and prevent the
    program from exiting. Obviously, this function can be called in a new thread and
    leave the main thread unblocked to carry on with other tasks, as we have seen
    in previous chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: When there are no pending asynchronous operations, **boost::io_context::run()**
    will return. There is a template class, **boost::asio::executor_work_guard** ,
    that can keep **io_context** busy and avoid it exiting if needed. Let’s see how
    it works with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by defining a background task that will wait for two seconds before
    posting some work through **io_context** using the **boost::asio::io_context::post()**
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the **main()** function, the **io_context** object is created, and a **work_guard**
    object is constructed using that **io_context** object.
  prefs: []
  type: TYPE_NORMAL
- en: Then, two threads are created, **io_thread** , where **io_context** runs, and
    **worker** , where **background_task()** will run. We also pass **io_context**
    as a reference to the background task to post work, as explained earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that in place, the main thread does some work (waiting for five seconds)
    and then removes the work guard by calling its **reset()** function, letting **io_context**
    exit its **run()** function, and joins both threads before exiting, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run the previous code, this is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We can see how the background thread posts a background task correctly, and
    this is completed before the work guard is removed and the I/O context object
    stops its execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to keep the **io_context** object alive and servicing requests
    is to provide asynchronous tasks by continuously calling **async_** functions
    or posting work from the completion handlers. This is a common pattern when reading
    or writing to sockets or streams:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, **timer_handler** is the completion handler defined as a lambda
    function that captures the timer and itself. Every second, when the timer expires,
    it prints the **Handler: Timer expired.** message and restarts itself by enqueueing
    a new asynchronous task (using the **async_wait()** function) into the **io_context**
    object via the **timer** object.'
  prefs: []
  type: TYPE_NORMAL
- en: As we have already seen, the **io_context** object can run from any thread.
    By default, this object is thread-safe, but in some scenarios where we want better
    performance, we might want to avoid this safety. This can be adjusted during its
    construction, as we will see in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency hints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **io_context** constructor accepts as an argument a concurrency hint, suggesting
    to the implementation the number of active threads that should be used for running
    completion handlers.
  prefs: []
  type: TYPE_NORMAL
- en: By default, this value is **BOOST_ASIO_CONCURRENCY_HINT_SAFE** (value *1* ),
    indicating that the **io_context** object will run from a single thread, enabling
    several optimizations due to this fact. That doesn’t mean that **io_context**
    can only be used from one thread; it still provides thread safety, and it can
    use I/O objects from many threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other values that can be specified are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**BOOST_ASIO_CONCURRENCY_HINT_UNSAFE** : Disables locking so all operations
    on **io_context** or I/O objects must occur in the same thread.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BOOST_ASIO_CONCURRENCY_HINT_UNSAFE_IO** : Disables locking in the reactor
    but keeps it in the scheduler, so all operations in the **io_context** object
    can use different threads apart from the **run()** function and the other methods
    related to executing the event processing loop. We will learn about schedulers
    and reactors when explaining the design principles behind the library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now learn about what the event processing loop is and how to manage it.
  prefs: []
  type: TYPE_NORMAL
- en: The event processing loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the **boost::asio::io_context::run()** method, **io_context** blocks and
    keeps processing I/O asynchronous tasks until all have been completed and the
    completion handlers have been notified. This I/O requests processing is done in
    an internal event processing loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other methods to control the event loop and avoid blocking until
    all asynchronous events are processed. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**poll** : Run the event processing loop to execute ready handlers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**poll_one** : Run the event processing loop to execute one ready handler'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**run_for** : Run the event processing loop for a specified duration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**run_until** : Same as the previous one but only until a specified time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**run_one** : Run the event processing loop to execute at most one handler'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**run_one_for** : Same as the previous one but only for a specified duration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**run_one_until** : Same as the previous one but only until a specified time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event loop can also be stopped by calling the **boost::asio::io_context::stop()**
    method or checking if its status is stopped by calling **boost:asio::io_context::stopped()**
    .
  prefs: []
  type: TYPE_NORMAL
- en: When the event loop is not running, tasks already being scheduled will continue
    executing. Other tasks will remain pending. Pending tasks can be resumed and pending
    results collected by starting the event loop with one of the methods mentioned
    previously again.
  prefs: []
  type: TYPE_NORMAL
- en: In previous examples, the application sent some work to **io_context** by calling
    asynchronous methods or by using the **post()** function. Let’s learn now about
    **dispatch()** and its differences with **post()** .
  prefs: []
  type: TYPE_NORMAL
- en: Giving some work to the io_context
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apart from sending work to **io_context** via the asynchronous methods from
    the different I/O objects or by using **executor_work_guard** (explained below),
    we can also use the **boost::asio::post()** and **boost::asio::dispatch()** template
    methods. Both functions are used to schedule some work into an **io_context**
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **post()** function guarantees that the task will be executed. It places
    its completion handler in the execution queue and eventually, it will be executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, **dispatch()** may execute the task immediately if **io_context**
    or strand (more on strands later in this chapter) are in the same thread where
    the task is being dispatched, or otherwise placed in the queue for asynchronous
    execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, using **dispatch()** , we can optimize performance by reducing context
    switching or queuing delays.
  prefs: []
  type: TYPE_NORMAL
- en: Dispatched events can execute directly from the current worker thread even if
    there are other pending events queued up. The posted events must always need to
    be managed by the I/O execution context, waiting until other handlers complete
    before being allowed to be executed.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have already learned about some basic concepts, let’s learn how
    synchronous and asynchronous operations work under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with the OS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Boost.Asio** can interact with I/O services using synchronous and asynchronous
    operations. Let’s learn how they behave and what the main differences are.'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If the program wants to use an I/O service in a synchronous way, usually, it
    will create an I/O object and use its synchronous operation method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When calling **timer.wait()** , the request is sent to the I/O execution context
    object ( **io_context** ), which calls the OS to perform the operation. Once the
    OS finishes with the task, it returns the result to **io_context** , which then
    translates the result, or an error if anything went wrong, back to the I/O object
    ( **timer** ). Errors are of type **boost::system::error_code** . If an error
    occurs, an exception is thrown.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we don’t want exceptions to be thrown, we can pass an error object by reference
    to the synchronous method to capture the status of the operation and check it
    afterward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Asynchronous operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the case of asynchronous operations, we need to also pass a completion handler
    to the asynchronous method. This completion handler is a callable object that
    will be invoked by the I/O context object when the asynchronous operation finishes,
    notifying the program about the result or operation error. Its signature is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Continuing with the timer example, now, we need to call the asynchronous operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Again, the I/O object ( **timer** ) forwards the request to the I/O execution
    context object ( **io_context** ). **io_context** requests to the OS to start
    the asynchronous operation.
  prefs: []
  type: TYPE_NORMAL
- en: When the operation is finished, the OS places the result in a queue, where **io_context**
    is listening. Then, **io_context** dequeues the result, translates the error into
    an error code object, and triggers the completion handler to notify the program
    about the completion of the task and the result.
  prefs: []
  type: TYPE_NORMAL
- en: To allow **io_context** to follow these steps, the program must execute **boost::asio::io_context::run()**
    (or similar functions introduced earlier that manage the event processing loop)
    and block the current thread while processing any unfinished asynchronous operation.
    As already commented, if there are no pending asynchronous operations, **boost::asio::io_context::run()**
    exits.
  prefs: []
  type: TYPE_NORMAL
- en: Completion handlers are required to be copy-constructible, meaning that a copy-constructor
    must be available. If a temporary resource is needed (such as memory, thread,
    or file descriptor), this resource is released before calling the completion handler.
    That allows us to call the same operation without overlapping resource usage,
    avoiding increasing the peak resource usage in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned previously, **Boost.Asio** allows users to handle errors in two
    different ways: by using error codes or throwing exceptions. If we pass a reference
    to a **boost::system::error_code** object when calling an I/O object method, the
    implementation will pass errors through that variable; otherwise, an exception
    will be thrown.'
  prefs: []
  type: TYPE_NORMAL
- en: We already implemented some examples following the first approach by checking
    the error codes. Let’s now see how to catch exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example creates a timer with an expiration period of three seconds.
    The **io_context** object is running from the background thread, **io_thread**
    . When the timer starts the asynchronous task by calling its **async_wait()**
    function, it passes the **boost::asio::use_future** argument so the function returns
    a future object, **fut** , that later is used inside a try-catch block to call
    its **get()** function and retrieve the stored result or exception, as we learned
    in [*Chapter 6*](B22219_06.xhtml#_idTextAnchor125) . After starting the asynchronous
    operation, the main thread waits for one second and the timer cancels the operation
    by calling its **cancel()** function. As this happens before its expiration time
    (three seconds), an exception is thrown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The exception of type **boost::system::system_error** is caught, and its message
    is printed. If the timer cancels its operation after the asynchronous operation
    completes (in this example, by sleeping the main thread for more than three seconds),
    the timer expires successfully, and no exception is thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen the main building blocks of Boost.Asio and how they interact
    together, let’s recap and understand the design patterns behind its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The Reactor and Proactor design patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When using event handling applications, we can follow two approaches to designing
    the concurrent solution: the Reactor and Proactor design patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: These patterns describe the mechanisms followed to process events, indicating
    how these are initiated, received, demultiplexed, and dispatched. As the system
    collects and queues the I/O events coming from different resources, demultiplexing
    these events means separating them to be dispatched to their correct handlers.
  prefs: []
  type: TYPE_NORMAL
- en: The **Reactor pattern** demultiplexes and dispatches synchronously and serially
    service requests. It usually follows a non-blocking synchronous I/O strategy,
    returning the result if the operation can be executed, or an error if the system
    has no resources to complete the operation.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the **Proactor pattern** allows demultiplexing and dispatching
    service requests in an efficient asynchronous way by immediately returning the
    control to the caller, indicating that the operation has been initiated. Then,
    the called system will notify the caller when the operation is complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the Proactor pattern distributes responsibilities among two tasks: the
    long-duration operations that are executed asynchronously and the completion handlers
    that process the results and usually invoke other asynchronous operations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Boost.Asio** implements the Proactor design pattern by using the following
    elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initiator** : An I/O object that initiates the asynchronous operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous operation** : A task to run asynchronously by the OS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous operation processor** : This executes the asynchronous operation
    and queues results in the completion event queue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Completion event queue** : An event queue where the asynchronous operation
    processor pushes events, and the asynchronous event dequeues them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous event demultiplexer** : This blocks the I/O context, waiting
    for events, and returning completed events to the caller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Completion handler** : A callable object that will process the results of
    the asynchronous operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Proactor** : This calls the asynchronous event demultiplexer to dequeue events
    and dispatch them to the completion handler. This is what the I/O execution context
    does.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 9* *.3* clearly shows the relationship between all these elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Proactor design pattern](img/B22219_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Proactor design pattern
  prefs: []
  type: TYPE_NORMAL
- en: The Proactor pattern increases the separation of concerns at the same time as
    encapsulating concurrency mechanisms, simplifying application synchronization,
    and increasing performance.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, we have no control over how or when the asynchronous operations
    are scheduled or how efficiently the OS will perform these operations. Also, there
    is an increase in memory usage due to the completion event queue and increased
    complexity in debugging and testing.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect of the design of Boost.Asio is the thread safety of the execution
    context objects. Let’s now dig into how threading works with Boost.Asio.
  prefs: []
  type: TYPE_NORMAL
- en: Threading with Boost.Asio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I/O execution context objects are thread-safe; their methods can be called from
    different threads safely. That means that we can use a separate thread to run
    the blocking **io_context.run()** method and leave the main thread unblocked to
    carry on with other unrelated tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now explain the different ways to configure the asynchronous application
    in terms of how to use threads.
  prefs: []
  type: TYPE_NORMAL
- en: Single-threaded approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The starting point and preferred solution for any **Boost.Asio** application
    should follow a single-threaded approach where the I/O execution context object
    runs in the same thread where the completion handlers are being processed. These
    handlers must be short and non-blocking. Here is an example of a steady timer
    completion handler running in the same thread as the I/O context, the main thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the **steady_timer** timer calls the asynchronous **async_wait()**
    function, setting up the **handle_timer_expiry()** completion handler, in the
    same thread that the **io_context.run()** function is being executed in. When
    the asynchronous function finishes, its completion handler will run in the same
    thread.
  prefs: []
  type: TYPE_NORMAL
- en: As the completion handler is running in the main thread, its execution should
    be quick to avoid freezing the main thread and other relevant tasks that the program
    should perform. In the next section, we will learn how to deal with long-running
    tasks or completion handlers and keep the main thread responsive.
  prefs: []
  type: TYPE_NORMAL
- en: Threaded long-running tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For long-running tasks, we can keep the logic in the main thread but use other
    threads to pass work and get results back to the main thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In this example, after **io_context** is created, a work guard is used to avoid
    the **io_context.run()** function to immediately return before any work is posted.
  prefs: []
  type: TYPE_NORMAL
- en: The posted work consists of a **t** thread being created to run the **long_running_task()**
    function in the background. That **t** thread is detached before the lambda function
    exits; otherwise, the program would terminate.
  prefs: []
  type: TYPE_NORMAL
- en: In the background task function, the current thread sleeps for a given period
    and then posts another task into the **io_context** object to print a message
    and stop **io_context** itself. If we don’t call **io_context.stop()** , the event
    processing loop will continue running forever and the program will not finish,
    as **io_context.run()** will continue blocking due to the work guard.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple I/O execution context objects, one per thread
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This approach is like the single-threaded one, where each thread has its own
    **io_context** object and processes short and non-blocking completion handlers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In this example, four threads are created, each one running the **background_task()**
    function where an **io_context** object is created, and a timer is set up to timeout
    after one second together with its completion handler.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple threads with a single I/O execution context object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, there is only one **io_context** object but it is starting the asynchronous
    tasks from different I/O objects from different threads. In this case, the completion
    handlers can be called from any of those threads. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this example, only one **io_context** object is created and run in a separate
    thread, **io_context_thread** . Then, an additional four background threads are
    created, where work is posted into the **io_context** object. Finally, the main
    thread waits for five seconds to let all threads finish their work and resets
    the work guard, letting the **io_context.run()** function return if there is no
    more pending work. When the program exits, all threads automatically join, as
    they are instances of **std::jthread** .
  prefs: []
  type: TYPE_NORMAL
- en: Parallelizing work done by one I/O execution context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous example, a unique I/O execution context object was used with
    its **run()** function being called from different threads. Then, each thread
    posted some work that completion handlers were executing in available threads
    at the time of completion.
  prefs: []
  type: TYPE_NORMAL
- en: This is a common way to parallelize work done by one I/O execution context,
    by calling its **run()** function from multiple threads, distributing the processing
    of asynchronous operations across those threads. This is possible because the
    **io_context** object provides a thread-safe event dispatching system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another example where a pool of threads is created, with each thread
    running **io_context.run()** , making these threads compete to pull tasks from
    the queue and execute them. In this case, only one asynchronous task is created
    using a timer that expires in two seconds. One of the threads will pick up the
    task and execute it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This technique improves scalability, as the application better utilizes multiple
    cores, and reduces latency by handling asynchronous tasks concurrently. Also,
    contention can be reduced and throughput increased by reducing bottlenecks generated
    when single-threaded code processes many simultaneous I/O operations.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the completion handlers also must use synchronization primitives and
    be thread-safe if they are shared across different threads or modify shared resources.
  prefs: []
  type: TYPE_NORMAL
- en: Also, there is no guarantee in the order the completion handlers will be executed.
    As many threads can run simultaneously, any of them can complete earlier and call
    its associated completion handler.
  prefs: []
  type: TYPE_NORMAL
- en: As threads are competing to pull tasks from the queue, there might be potential
    lock contention or context-switching overhead if the thread pool size is not optimal,
    ideally matching the number of hardware threads, as done in this example.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it’s time to understand how the objects’ lifetime can affect the stability
    of our asynchronous programs developed with Boost.Asio.
  prefs: []
  type: TYPE_NORMAL
- en: Managing objects’ lifetime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main disastrous issues that can happen with asynchronous operations
    is that, when the operation takes place, some of the required objects have been
    destroyed. Therefore, managing objects’ lifetimes is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: In C++, an object’s lifetime begins when the constructor ends and ends when
    the destructor begins.
  prefs: []
  type: TYPE_NORMAL
- en: A common pattern used to keep objects alive is to let the object create a shared
    pointer instance to itself, ensuring that the object remains valid as long as
    there are shared pointers pointing to it, meaning that there are ongoing asynchronous
    operations needing that object.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is called **shared-from-this** and uses the **std::enable_shared_from_this**
    template base class, available since C++11, which provides the **shared_from_this()**
    method used by the object to obtain a shared pointer to itself.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an echo server – an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s see how it works by creating an echo server. At the same time, we will
    be discussing this technique, we will also be learning about how to use Boost.Asio
    for networking.
  prefs: []
  type: TYPE_NORMAL
- en: Transmission of data over a network can take a long time to complete, and several
    errors can occur. That makes network I/O services a special good case to be dealt
    with by Boost.Asio. Network I/O services were the first services to be included
    in the library.
  prefs: []
  type: TYPE_NORMAL
- en: The main common usage of Boost.Asio in the industry is to develop networking
    applications due to its support for the internet protocols TCP, UDP, and ICMP.
    The library also provides a socket interface based on the **Berkeley Software
    Distribution** ( **BSD** ) socket API to allow the development of efficient and
    scalable applications using a low-level interface.
  prefs: []
  type: TYPE_NORMAL
- en: However, as, in this book, we are interested in asynchronous programming, let’s
    focus on implementing an echo server using a high-level interface.
  prefs: []
  type: TYPE_NORMAL
- en: An echo server is a program that listens to a specific address and port and
    writes back everything that it reads from that port. For that purpose, we will
    create a TCP server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main program will simply create an **io_context** object, set up the **EchoServer**
    object by passing the **io_context** object and a port number to listen from,
    and call **io_context.run()** to start the event processing loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When **EchoServer** initializes, it will start listening for incoming connections.
    It does that by using a **boost::asio::tcp::acceptor** object. This object accepts
    via its constructor an **io_context** object (as usual for I/O objects) and a
    **boost::asio::tcp::endpoint** object, which indicates the connection protocol
    and port number used for listening. As a **boost::asio::tcp::v4()** object is
    used to initialize the endpoint object, the protocol that the **EchoServer** will
    use is IPv4. The IP address is not specified to the endpoint constructor, therefore
    the endpoint IP address will be *any address* ( **INADDR_ANY** for IPv4 or **in6addr_any**
    for IPv6). Next, the code implementing the **EchoServer** constructor is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The **EchoServer** constructor calls the **do_accept()** function after setting
    up the acceptor object. The **do_accept()** function calls the **async_accept()**
    function waiting for incoming connections. When a client connects to the server,
    the OS returns the connection’s socket ( **boost::asio::tcp::socket** ) or an
    error via the **io_context** object.
  prefs: []
  type: TYPE_NORMAL
- en: If there is no error and a connection is established, a shared pointer of a
    **Session** object is created, moving the socket into the **Session** object.
    Then, the **Session** object runs the **start()** function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Session** object encapsulates the state of a particular connection, in
    this case, the **socket_** object and the **data_** buffer. It also manages asynchronous
    reads and writes into that buffer by using **do_read()** and **do_write()** ,
    which we will implement in a moment. But before this, comment that **Session**
    inherits from **std::enable_shared_from_this<Session>** , allowing **Session**
    objects to create shared pointers to themselves, ensuring that the session objects
    remain alive throughout the lifetime of asynchronous operations needing them,
    as long as there is at least one shared pointer pointing to a **Session** instance
    managing that connection. This shared pointer is the one created in the **do_accept()**
    function in the **EchoServer** object when the connection was established. Here
    is the implementation of the **Session** class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Using a **Session** class allows us to separate the logic that manages the connection
    from the one that manages the server. **EchoServer** just needs to accept connections
    and create a **Session** object per connection. That way, a server can manage
    multiple clients, keeping their connections independent and asynchronously managed.
  prefs: []
  type: TYPE_NORMAL
- en: '**Session** is the one that manages the behavior of that connection using the
    **do_read()** and **do_write()** functions. When **Session** starts, its **start()**
    function calls the **do_read()** function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The **do_read()** function creates a shared pointer to the current session object
    ( **self** ) and uses the socket’s **async_read_some()** asynchronous function
    to read some data into the **data_** buffer. If successful, this operation returns
    the data copied into the **data_** buffer and the number of read bytes in the
    **length** variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, **do_write()** is called with that **length** variable, asynchronously
    writing the content of the **data_** buffer into the socket by using the **async_write()**
    function. When this asynchronous operation succeeds, it restarts the cycle by
    calling again the **do_read()** function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You might wonder why it is that **self** is defined but is not being used. It
    looks like **self** is redundant, but as the lambda function is capturing it by
    value, a copy is being created, increasing the reference count of the shared pointer
    to the **this** object, ensuring that the session will not be destroyed if the
    lambda is active. The **this** object is captured to provide access to its members
    into the lambda function.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, try to implement a **stop()** function that breaks the cycle
    between **do_read()** and **do_write()** . Once all asynchronous operations are
    complete and the lambda functions exit, the **self** objects will be destroyed
    and there will be no other shared pointers pointing to the **Session** object,
    thus the session will be destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern ensures robust and safe management of objects’ lifetimes during
    asynchronous operations, avoiding dangling pointers or early destruction, which
    would lead to undesired behavior or crashes.
  prefs: []
  type: TYPE_NORMAL
- en: To test this server, just start the server, open a new terminal, and use the
    **telnet** command to connect to the server and send data to it. As arguments,
    we can pass the **localhost** address, indicating that we are connecting to a
    server running on the same machine (IP address of **127.0.0.1** ) and the port,
    in this case, **1234** .
  prefs: []
  type: TYPE_NORMAL
- en: The **telnet** command will start and show some information about the connection
    and indicate that we need to hit the *Ctrl* + *}* keys to close the connection.
  prefs: []
  type: TYPE_NORMAL
- en: Typing anything and hitting the *Enter* key will send that entered line to the
    echo server, which will listen and send back the same content; in this example,
    it will be **Hello world!** .
  prefs: []
  type: TYPE_NORMAL
- en: 'Just close the connection and exit **telnet** by using the **quit** command
    to exit back to the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we have already used a buffer. Let’s learn a bit more about
    them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Transferring data using buffers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Buffers** are contiguous regions of memory used during I/O operations to
    transfer data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Boost.Asio defines two types of buffers: **mutable buffers** ( **boost::asio::mutable_buffer**
    ), where data can be written, and **constant buffers** ( **boost::asio::const_buffers**
    ), which are used to create read-only buffers. Mutable buffers can be converted
    into constant buffers, but not the opposite. Both types of buffers provide protection
    against overruns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also the **boost::buffer** function to help with the creation of mutable
    or constant buffers from different data types (a pointer to raw memory and size,
    a string ( **std::string** ), or an array or vector of **plain old data** ( **POD**
    ) structures (meaning a type, a structure, or a class that has no user-defined
    copy assignment operator or destructor, and without private or protected non-static
    data members). For example, to create a buffer from an array of chars, we can
    use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Also, note that the buffer’s ownership and lifetime are the responsibility of
    the program, not the Boost.Asio library.
  prefs: []
  type: TYPE_NORMAL
- en: Scatter-gather operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Buffers can be used efficiently by using scatter-gather operations where multiple
    buffers are used together to receive data (scatter-read) or to send data (gather-write).
  prefs: []
  type: TYPE_NORMAL
- en: '**Scatter-read** is the process of reading data from a unique source into different
    non-contiguous memory buffers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gather-write** is the opposite process; data is gathered from different non-contiguous
    memory buffers and written into a single destination.'
  prefs: []
  type: TYPE_NORMAL
- en: These techniques increase efficiency and performance as they reduce the number
    of system calls or data copying. They are not only used for I/O operations but
    also in other use cases, such as data processing, machine learning, or parallel
    algorithms, such as sorting or matrix multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: To allow scatter-gather operations, several buffers can be passed together to
    the asynchronous operation inside a container ( **std::vector** , **std::list**
    , **std::array** , or **boost::array** ).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of scatter-read where a socket reads some data asynchronously
    into both the **buf1** and **buf2** buffers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is how to achieve a gather-read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, the socket does the opposite operation, writing some data from both buffers
    into the socket buffer for asynchronous sending.
  prefs: []
  type: TYPE_NORMAL
- en: Stream buffers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also use stream buffers to manage data. **Stream buffers** are defined
    by the **boost::asio::basic_streambuf** class, based in the **std::basic_streambuf**
    C++ class and defined in the **<streambuf>** header file. It allows a dynamic
    buffer where its size can adapt to the amount of data being transferred.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see in the following example how stream buffers work together with scatter-gather
    operations. In this case, we are implementing a TCP server that listens and accepts
    clients’ connections from a given port, reads the messages sent by the clients
    into two stream buffers, and prints their content to the console. As we are interested
    in understanding stream buffers and scatter-gather operations, let’s simplify
    the example by using synchronous operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As in the previous example, in the **main()** function, we use a **boost::asio::ip::tcp::acceptor**
    object to set up the protocol and port that the TCP server will use to accept
    connections. Then, in an infinite loop, the server uses that acceptor object to
    attach a TCP socket ( **boost::asio::ip::tcp::socket** ) and call the **handle_client()**
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The **handle_client()** function creates two stream buffers: **buf1** and **buf2**
    , and adds them to a container, in this case, **std::array** , to be used in scatter-gather
    operations.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, the synchronous **read_some()** function from the socket is called. This
    function returns the number of bytes read from the socket and copies them into
    the buffers. If anything goes wrong with the socket connection, an error will
    be returned in the error code object, **ec** . In that case, the server will print
    the error message and exit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: If there are no errors, the stream buffers’ **commit()** function is used to
    transfer five bytes to each of the stream buffers, **buf1** and **buf2** . The
    contents of these buffers are extracted by using **std::istream** objects and
    printed to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'To execute this example, we need to open two terminals. In one terminal, we
    execute the server, and in the other, the **telnet** command, as shown earlier.
    In the **telnet** terminal, we can type a message (for example, *Hello World*
    ). This message is sent to the server. The server terminal will then show the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, only 10 bytes are processed and distributed into the two buffers.
    The space character between the two words is processed but discarded when parsing
    the input by the **iostream** objects.
  prefs: []
  type: TYPE_NORMAL
- en: Stream buffers are useful when the size of the incoming data is variable and
    unknown in advance. These types of buffers can be used together with fixed-sized
    buffers.
  prefs: []
  type: TYPE_NORMAL
- en: Signal handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Signal handling** allows us to catch signals sent by the OS and gracefully
    shut down the application before the OS decides to kill the application’s process.'
  prefs: []
  type: TYPE_NORMAL
- en: Boost.Asio provides the **boost::asio::signal_set** class for this purpose,
    which starts an asynchronous wait for one or more signals to occur.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an example of how to handle the **SIGINT** and **SIGTERM** signals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The **signals** object is **signal_set** , listing the signals that the program
    waits for, **SIGINT** and **SIGTERM** . This object has an **async_wait()** method
    that asynchronously waits for any of those signals to happen and triggers the
    completion handler, **handle_signal()** .
  prefs: []
  type: TYPE_NORMAL
- en: As usual in completion handlers, **handle_signal()** checks the error code,
    **ec** , and if there is no error, some cleanup code might execute to cleanly
    and gracefully exit the program. In this example, we just stop the event processing
    loop by calling **io_context.stop()** .
  prefs: []
  type: TYPE_NORMAL
- en: We could also wait synchronously for signals by using the **signals.wait()**
    method.
  prefs: []
  type: TYPE_NORMAL
- en: If the application is multithreaded, the signals event handler must run in the
    same thread as the **io_context** object, typically being the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to cancel operations.
  prefs: []
  type: TYPE_NORMAL
- en: Canceling operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some I/O objects, such as sockets or timers, have object-wide cancellation of
    outstanding asynchronous operations by calling their **close()** or **cancel()**
    methods. If an asynchronous operation is canceled, the completion handler will
    receive an error with the **boost::asio::error::operation_aborted** code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a timer is created, and its timeout period is set
    to five seconds. But after sleeping the main thread for only two seconds, the
    timer is canceled by calling its **cancel()** method, making the completion handler
    be called with a **boost::asio::error::operation_aborted** error code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: But if we want a per-operation cancellation, we need to set up a cancellation
    slot that will be triggered when a cancellation signal is emitted. This cancellation
    signal/slot pair composes a lightweight channel to communicate cancellation operations,
    like the ones created between promises and futures explained in [*Chapter 6*](B22219_06.xhtml#_idTextAnchor125)
    . The cancellation framework has been available in Boost.Asio since version 1.75.
  prefs: []
  type: TYPE_NORMAL
- en: This approach enables a more flexible cancellation mechanism where multiple
    operations can be canceled using the same signal, and it integrates seamlessly
    with Boost.Asio’s asynchronous operations. Synchronous operations can only be
    canceled by using the **cancel()** or **close()** methods described earlier; they
    are not supported by the cancellation slots mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s modify the previous example and use a cancellation signal/slot to cancel
    the timer. We only need to modify the way the timer is canceled in the **main()**
    function. Now, when the asynchronous **async_wait()** operation is executed, a
    cancellation slot is created by binding a slot from the cancellation signal and
    the completion handler using the **boost::asio::bind_cancellation_slot()** function.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, the timer has an expiration period of five seconds, and again, the
    main thread only sleeps for two seconds. This time, a cancellation signal is emitted
    by calling the **cancel_signal.emit()** function. The signal will trigger the
    counterpart cancellation slot and execute the completion handler with a **boost::asio::error::operation_aborted**
    error code, printing in the console the **Timer canceled.** message; see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: When the signal is emitted, a cancellation type must be specified, letting the
    target operation know what the application requires and the operation guarantees,
    thus controlling the scope and behavior of the cancellation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The various categories of cancellation are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**None** : No cancellation is performed. It can be useful if we want to test
    if a cancellation should occur.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Terminal** : The operation has unspecified side effects so the only safe
    way to cancel the operation is to close or destroy the I/O object, being its result
    final, for example, completing a task or transaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Partial** : The operation has well-defined side effects so the completion
    handler can take the required actions to resolve the issue, meaning that the operation
    is partially completed and can be resumed or retried.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total** or **All** : The operation has no side effects. Cancels both terminal
    and partial operations, enabling a comprehensive cancellation by stopping all
    ongoing asynchronous operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the cancellation type is not supported by the asynchronous operation, the
    cancellation request is discarded. For example, timer operations support all categories
    of cancellation, but sockets only support **Total** and **All** , meaning that
    if we try to cancel a socket asynchronous operation with a **Partial** cancellation,
    this cancellation will be ignored. This prevents undefined behavior if an I/O
    system tries to handle an unsupported cancellation request.
  prefs: []
  type: TYPE_NORMAL
- en: Also, cancellation requests made after the operation is initiated but before
    it starts, or after its completion, have no effect.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we need to run some work sequentially. Next, we will introduce how
    we can achieve this by using strands.
  prefs: []
  type: TYPE_NORMAL
- en: Serializing workload with strands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **strand** is a strict sequential and non-concurrent invocation of completion
    handlers. Using strands, asynchronous operations can be sequenced without explicit
    locking by using mutexes or other synchronization mechanisms seen earlier in this
    book. Strands can be implicit or explicit.
  prefs: []
  type: TYPE_NORMAL
- en: As shown earlier in this chapter, if we execute **boost::asio::io_context::run()**
    from only one thread, all event handlers will execute in an implicit strand, as
    they will be sequentially queued one by one and triggered from the I/O execution
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Another implicit strand happens when there are chained asynchronous operations
    where one asynchronous operation schedules the next asynchronous operation, and
    so on. Some previous examples in this chapter already used this technique, but
    here there is another one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, if there are no errors, the timer keeps restarting itself in
    the **handle_timer_expiry()** event handler by recursively setting up the expiration
    time and calling the **async_wait()** method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this example would print the **Timer expired. Count: <number>** line
    every second with the counter increasing on each line.'
  prefs: []
  type: TYPE_NORMAL
- en: In case some work needs to be serialized but these approaches are not appropriate,
    we can use explicit strands by using **boost::asio::strand** or its specialization
    for I/O context execution objects, **boost::asio::io_context::strand** . Posted
    work using these strand objects will serialize their handler execution in the
    order they enter the I/O execution context queue.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we will create a logger that serializes writing operations
    into a single log file from several threads. We will be logging messages from
    four threads, writing five messages from each. We expect the output to be correct,
    but this time without using any mutex or other synchronization mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by defining the **Logger** class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The **Logger** constructor accepts an I/O context object, used to create a strand
    object ( **boost::asio::io_context::strand** ), and **std::string** , specifying
    a log filename that is used to open the log file or create it if it does not exist.
    The log file is open for appending new content. If the file is not open before
    the constructor finishes, meaning that there was an issue when accessing or creating
    the file, the constructor throws an exception.
  prefs: []
  type: TYPE_NORMAL
- en: The logger also provides the public **log()** function that accepts **std::string**
    , specifying a message as a parameter. This function uses the strand to post new
    work into the **io_context** object. It does that by using a lambda function,
    capturing by value the logger instance (the object **this** ) and the message,
    and calls the private **do_log()** function, where a **std::fstream** object is
    used to write the message into the output file.
  prefs: []
  type: TYPE_NORMAL
- en: There will be only one instance of the **Logger** class in the program, shared
    by all threads. That way, the threads will write to the same file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define a **worker()** function that each thread will run to write **num_messages_per_thread**
    messages into the output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This function accepts a shared pointer to the **Logger** object and a thread
    identifier. It prints all the messages using the **Logger** ’s public **log()**
    function explained earlier.
  prefs: []
  type: TYPE_NORMAL
- en: To interleave the threads executions and rigorously test how the strands work,
    each thread will sleep for 100 ms after writing each message.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the **main()** function, we start an **io_context** object and a
    work guard to avoid an early exit from the **io_context** . Then, a shared pointer
    to a **Logger** instance is created, passing the necessary parameters explained
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: A thread pool (vector of **std::jthread** objects) is created by using the **worker()**
    function and passing the shared pointer to the logger and a unique identifier
    for each thread. Also, a thread running the **io_context.run()** function is added
    to the thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, as we know that all messages will be printed out in
    less than two seconds, we make **io_context** run for only that period, using
    **io_context.run_for(2s)** .
  prefs: []
  type: TYPE_NORMAL
- en: 'When the **run_for()** function exits, the program prints **Done!** to the
    console and finishes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this example will show the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the content of the generated **log.txt** log file. As the sleep time
    for each thread is the same, all threads and messages are sequentially ordered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If we remove the work guard, the log file only has the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This happens because the first batch of work is promptly posted and queued into
    **io_object** from each thread, but **io_object** exits after finishing dispatching
    the work guard and notifying the completion handlers before the second batch of
    messages is posted.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we also remove the **sleep_for()** instruction in the worker thread, now,
    the log file content is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Earlier, the content was sorted by message identifier, and now it’s by thread
    identifier. This is because now, when a thread starts and runs the **worker()**
    function, it posts all messages at once, without any delay. Therefore, the first
    thread (thread **0** ) enqueues all its work before the second thread has the
    chance to do that, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with further experiments, when we posted content into the strand,
    we captured the logger instance and the message by value, by using the following
    instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Capturing by value allows the lambda function running **do_log()** to use a
    copy of the needed objects, keeping them alive, as commented earlier in this chapter
    when we discussed object lifetimes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say, for some reason, we decided to capture by reference using the following
    instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Then, the resulting log file will have incomplete log messages and even incorrect
    characters because the logger is printing from memory areas that belonged to a
    message object that no longer exists when the **do_log()** function executes.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, always assume asynchronous changes; the OS might perform some changes
    out of our control, so always know what is under our control and, most importantly,
    what’s not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, instead of using a lambda expression and capturing the **this** and
    **message** objects by value, we could also use **std::bind** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn now how we can simplify the echo server we implemented earlier by
    using coroutines and improving it by adding a command to exit the connection from
    the client’s side.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Boost.Asio has also included support for coroutines since version 1.56.0 and
    supported native coroutines since version 1.75.0.
  prefs: []
  type: TYPE_NORMAL
- en: As we have learned in the previous chapter, using coroutines simplifies how
    the program is written as there is no need to add completion handlers and split
    the flow of the program into different asynchronous functions and callbacks. Instead,
    with coroutines, the program follows a sequential structure where an asynchronous
    operation call pauses the execution of the coroutine. When the asynchronous operation
    completes, the coroutine is resumed, letting the program continue its execution
    from where it was previously paused.
  prefs: []
  type: TYPE_NORMAL
- en: With newer versions (newer than 1.75.0), we can use native C++ coroutines via
    **co_await** , to wait for asynchronous operations within a coroutine, **boost::asio::co_spawn**
    to launch a coroutine, and **boost::asio::use_awaitable** to let Boost.Asio know
    that an asynchronous operation will use coroutines. With earlier versions (from
    1.56.0), coroutines were available using **boost::asio::spawn()** and **yield**
    contexts. As the newer approach is preferred, not only because it supports native
    C++20 coroutines, but the code is also more modern, clean, and readable, we will
    focus on this approach in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s implement again the echo server, but this time using Boost.Asio’s awaitable
    interface and coroutines. We will also add some improvements, such as support
    to close the connection from the client’s side when sending the **QUIT** command,
    showing how to process data or commands on the server side, and stopping handling
    connections and exiting if any exception is thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by implementing the **main()** function. The program starts by using
    **boost::asio::co_spawn** to create a new coroutine-based thread. This function
    accepts as parameters an execution context ( **io_context** , but can also use
    a strand), a function with the **boost::asio::awaitable<R,E>** return type, which
    will be used as the coroutine’s entry point (the **listener()** function that
    we will implement and explain next), and a completion token that will be called
    when the thread has completed. If we want to run the coroutine without being notified
    of its completion, we can pass the **boost::asio::detached** token.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we start processing asynchronous events by calling **io_context.run()**
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'In case there is any exception, it will be caught by the try-catch block, and
    the event processing loop will be stopped by calling **io_context.stop()** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The **listener()** function receives as parameters an **io_context** object
    and the port number that the listener will accept connections from, using an **acceptor**
    object as explained earlier. It also must have a return type of **boost::asio::awaitable<R,E>**
    , where **R** is the return type of the coroutine and **E** is the exception type
    that might be thrown. In this example, **E** is set as default, so not explicitly
    specified.
  prefs: []
  type: TYPE_NORMAL
- en: The connection is accepted by calling the **async_accept** acceptor function.
    As we are now using a coroutine, we need to specify **boost::asio::use_awaitable**
    to the asynchronous function and use **co_await** to stop the coroutine execution
    until is resumed when the asynchronous task completes.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the listener coroutine task resumes, **acceptor.async_accept()** returns
    a socket object. The coroutine continues by spawning a new thread, using the **boost::asio::co_spawn**
    function, executing the **echo()** function, and passing the **socket** object
    to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The **echo()** function is responsible for handling a single client connection.
    It must follow a similar signature as the **listener()** function; it needs a
    return type of **boost::asio::awaitable<R,E>** . As commented earlier, the **socket**
    object is moved into this function from the listener.
  prefs: []
  type: TYPE_NORMAL
- en: The function asynchronously reads content from the socket and writes it back
    in an infinite loop that only finishes if it receives the **QUIT** command or
    an exception is thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous reads are done by using the **socket.async_read_some()** function,
    which reads data into the data buffer using **boost::asio::buffer** and returns
    the number of bytes read ( **bytes_read** ). As the asynchronous task is managed
    by a coroutine, **boost::asio::use_awaitable** is passed to the asynchronous operation.
    Then, **co_wait** just instructs the coroutine engine to pause the execution until
    the asynchronous operation finishes.
  prefs: []
  type: TYPE_NORMAL
- en: Once some data is received, the execution of the coroutine resumes, checking
    if there is really some data to process, otherwise, it finishes the connection
    by exiting the loop, thus the **echo()** function as well.
  prefs: []
  type: TYPE_NORMAL
- en: If data is read, it converts it into **std::string** for easy manipulation.
    It removes the **\r\n** ending, if present, and compares the string against **QUIT**
    .
  prefs: []
  type: TYPE_NORMAL
- en: If **QUIT** is present, it performs an asynchronous write, sends the **Good
    bye!** message, and exits the loop. Otherwise, it sends the received data back
    to the client. In both cases, an asynchronous write operation is performed by
    using the **boost::asio::async_write()** function, passing the socket, **boost:asio::buffer**
    wrapping the data buffer to send, and **boost::asio::use_awaitable** as with the
    asynchronous read operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, **co_await** is used again to suspend the execution of the coroutine
    while the operation is performed. Once completed, the coroutine will resume and
    repeat these steps in a new loop iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The coroutine loops until no data is read, happening when the client closes
    the connection, when the **QUIT** command is received, or when an exception occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous operations are used throughout to ensure the server remains responsive,
    even when handling multiple clients simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about Boost.Asio and how to use this library to
    manage asynchronous tasks that deal with external resources managed by the OS.
  prefs: []
  type: TYPE_NORMAL
- en: For that purpose, we introduced the I/O objects and I/O execution context objects,
    with an in-depth explanation of how they work and interact together, how they
    access and communicate with OS services, what the design principles are behind
    them, and how to use them properly in single-threaded and multi-threaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: We also showed different techniques available in Boost.Asio to serialize work
    using strands, to manage the objects’ lifetimes used by asynchronous operations,
    how to start, interrupt, or cancel tasks, how to manage the event processing loop
    that the library uses, and how to handle signals sent by the OS.
  prefs: []
  type: TYPE_NORMAL
- en: Other concepts related to networking and coroutines were also introduced, and
    we also implemented some useful examples using this powerful library.
  prefs: []
  type: TYPE_NORMAL
- en: All these concepts and examples allow us to acquire a deeper knowledge of how
    to manage asynchronous tasks in C++ and how an extensively used library works
    under the hood to achieve this goal.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about another Boost library, Boost.Cobalt,
    that provides a rich and high-level interface to develop asynchronous software
    based in coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Boost.Asio official site: [https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio.html](https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boost.Asio reference: [https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/reference.html](https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/reference.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boost.Asio revision history: [https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/history.html](https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/history.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boost.Asio BSD socket API: [https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/overview/networking/bsd_sockets.html](https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/overview/networking/bsd_sockets.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BSD socket API: [https://web.mit.edu/macdev/Development/MITSupportLib/SocketsLib/Documentation/sockets.html](https://web.mit.edu/macdev/Development/MITSupportLib/SocketsLib/Documentation/sockets.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Boost C++ Libraries, Boris* *Schälig* : [https://theboostcpplibraries.com/boost.asio](https://theboostcpplibraries.com/boost.asio)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Thinking Asynchronously: Designing Applications with Boost.Asio, Christopher*
    *Kohlhoff* : [https://www.youtube.com/watch?v=D-lTwGJRx0o](https://www.youtube.com/watch?v=D-lTwGJRx0o)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CppCon 2016: Asynchronous IO with Boost.Asio, Michael* *Caisse* : [https://www.youtube.com/watch?v=rwOv_tw2eA4](https://www.youtube.com/watch?v=rwOv_tw2eA4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pattern-Oriented Software Architecture – Patterns for Concurrent and Networked
    Objects* , *Volume 2* , D. Schmidt et al, Wiley, 2000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Boost.Asio C++ Network Programming Cookbook* , Dmytro Radchuk, Packt Publishing,
    2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Proactor: An Object Behavioral Pattern for Demultiplexing and Dispatching
    handlers for Asynchronous events* , Irfan Pyarali, Tim Harrison, Douglas C Schmidt,
    Thomas D Jordan. 1997'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reactor: An Object Behavioral Pattern for Demultiplexing and Dispatching Handlers
    for Synchronous events* , Douglas C Schmidt, 1995'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Input/Output Completion* *Port* : [https://en.wikipedia.org/wiki/Input/output_completion_port](https://en.wikipedia.org/wiki/Input/output_completion_port)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*kqueue* : [https://en.wikipedia.org/wiki/Kqueue](https://en.wikipedia.org/wiki/Kqueue)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*epoll* : [https://en.wikipedia.org/wiki/Epoll](https://en.wikipedia.org/wiki/Epoll)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
