<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>Getting Started with Vulkan</title>
<link href="../styles/stylesheet1.css" rel="stylesheet" type="text/css"/>
<link href="../styles/stylesheet2.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="sbo-rt-content"><section class="level1 pkt" data-number="3" id="getting-started-with-vulkan">
<h1 data-number="3">2 Getting Started with Vulkan</h1>
<section class="level2" data-number="3.1" id="join-our-book-community-on-discord-1">
<h2 data-number="3.1">Join our book community on Discord</h2>
<p>
<img height="301" src="../media/file40.png" style="width:15rem" width="301"/>
</p>
<p><a href="https://packt.link/unitydev">https://packt.link/unitydev</a></p>
<p>In this chapter, we will learn how to do the first steps with Vulkan so that we can deal with swapchains, shaders, and pipelines. The recipes of this chapter will help you to get your first triangle on screen using Vulkan. The underlying Vulkan implementation is based on an open-source library, <em>LightweightVK</em> (<a href="https://github.com/corporateshark/lightweightvk">https://github.com/corporateshark/lightweightvk</a>), which we are going to explore in this chapter.</p>
<p>In the chapter, we will cover the following recipes:</p>
<ul>
<li>Initializing a Vulkan instance and graphical device</li>
<li>Initializing a Vulkan swapchain</li>
<li>Setting up Vulkan debugging capabilities</li>
<li>Using Vulkan command buffers</li>
<li>Initializing Vulkan shader modules</li>
<li>Initializing Vulkan pipelines</li>
</ul>
</section>
<section class="level2" data-number="3.2" id="technical-requirements">
<h2 data-number="3.2">Technical requirements</h2>
<p>To run the recipes from this chapter, you have to use a Windows or Linux computer with a video card and drivers supporting Vulkan 1.3. Read <em>Chapter 1</em>, <em>Establishing a Build Environment</em>, to learn how to configure it properly.</p>
</section>
<section class="level2" data-number="3.3" id="initializing-a-vulkan-instance-and-graphical-device">
<h2 data-number="3.3">Initializing a Vulkan instance and graphical device</h2>
<p>The Vulkan API is much more verbose compared to OpenGL, so we have to split the creation of our first graphical demo apps into a series of separate small recipes. In this recipe, we will learn how to create a Vulkan instance, enumerate all the physical devices in the system that are capable of 3D graphics rendering, and initialize one of these devices to create a window with an attached surface.</p>
<section class="level3" data-number="3.3.1" id="getting-ready-7">
<h3 data-number="3.3.1">Getting ready</h3>
<p>If you are completely new to Vulkan, we recommend starting with some beginner Vulkan books, such as <em>The Modern Vulkan Cookbook</em> by Preetish Kakkar and Mauricio Maurer, or <em>Vulkan Programming Guide: The Official Guide to Learning Vulkan</em> by Graham Sellers.</p>
<p>The hardest part in transitioning from OpenGL to Vulkan, or any similar modern graphics API, is getting used to the amount of explicit code necessary to set up the rendering process, which, thankfully, needs to be done only once. It is also useful to get a grasp of Vulkan’s object model. As a good starting point, we recommend reading <a href="https://gpuopen.com/understanding-vulkan-objects">https://gpuopen.com/understanding-vulkan-objects</a> by Adam Sawicki as a reference. For the further recipes in this chapter, we set our goal to start rendering 3D scenes with the bare minimum amount of setup.</p>
<p>All our Vulkan recipes use the LightweightVK library, which can be downloaded from <a href="https://github.com/corporateshark/lightweightvk">https://github.com/corporateshark/lightweightvk</a> using the following Bootstrap snippet. This library implements all the low-level Vulkan wrapper classes that we will discuss in this book:</p>
<div class="C1-SHCodePACKT">
<pre><code>{
  “name”: “ lightweightvk “,
  “source”: {
    “type”: “git”,
    “url”: “ https://github.com/corporateshark/lightweightvk.git “,
    “revision”: “1.0”
  }
}</code></pre>
</div>
<p>The complete Vulkan example for this recipe can be found in <code>Chapter02/01_Swapchain</code>.</p>
</section>
<section class="level3" data-number="3.3.2" id="how-to-do-it...-7">
<h3 data-number="3.3.2">How to do it...</h3>
<p>Before we jump into the actual implementation, let’s explore some scaffolding code that makes debugging Vulkan backends a bit easier. Let us start with some error-checking facilities:</p>
<ol>
<li>Any function call from a complex API may fail. To handle failure, or at least to let the developer know the exact location of the failure, <em>LightweightVK</em> wraps most of the Vulkan calls in the <code>VK_ASSERT()</code> and <code>VK_ASSERT_RETURN()</code> macros, which check the results of Vulkan operations. When starting to write a new Vulkan implementation from scratch, it will be helpful to have something similar right from the get-go:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>#define VK_ASSERT(func) {                                          \
    const VkResult vk_assert_result = func;                        \
    if (vk_assert_result != VK_SUCCESS) {                          \
      LLOGW(“Vulkan API call failed: %s:%i\n  %s\n  %s\n”,         \
                    __FILE__, __LINE__, #func,                     \
                    ivkGetVulkanResultString(vk_assert_result));   \
      assert(false);                                               \
    }                                                              \
  }</code></pre>
</div>
<ol>
<li>The <code>VK_ASSERT_RETURN()</code> macro is very similar and returns the control to the calling code:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>#define VK_ASSERT_RETURN(func) {                                   \
    const VkResult vk_assert_result = func;                        \
    if (vk_assert_result != VK_SUCCESS) {                          \
      LLOGW(“Vulkan API call failed: %s:%i\n  %s\n  %s\n”,         \
                    __FILE__, __LINE__, #func,                     \
                    ivkGetVulkanResultString(vk_assert_result));   \
      assert(false);                                               \
      return getResultFromVkResult(vk_assert_result);              \
    }                                                              \
  }</code></pre>
</div>
<p>Now, we can start creating our first Vulkan application. Let’s explore what is going on in the sample application <code>Chapter02/01_Swapchain</code>, which creates a window, a Vulkan instance, and a device together with a Vulkan swapchain, which will be explained shortly. The application code is very simple:</p>
<ol>
<li>We initialize the logger library and create a GLFW window, as we discussed in the recipe <em>Using the GLFW library</em> from <em>Chapter 1</em>. All the Vulkan initialization magic happens in the <code>lvk::createVulkanContextWithSwapchain()</code> helper function, which we will explore shortly:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>int main(void) {
  minilog::initialize(nullptr, { .threadNames = false });
  int width  = 960;
  int height = 540;
  GLFWwindow* window = lvk::initWindow(
    “Simple example”, width, height);
  std::unique_ptr&lt;lvk::IContext&gt; ctx =
    lvk::createVulkanContextWithSwapchain(window, width, height, {});</code></pre>
</div>
<ol>
<li>The application main loop updates the framebuffer size if the size of the window changes, acquires a command buffer, submits it, and presents the current swapchain image, or texture as it is called in <em>LightweightVK</em>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  while (!glfwWindowShouldClose(window)) {
    glfwPollEvents();
    glfwGetFramebufferSize(window, &amp;width, &amp;height);
    if (!width || !height) continue;
    lvk::ICommandBuffer&amp; buf = device-&gt;acquireCommandBuffer();
    ctx-&gt;submit(buf, ctx-&gt;getCurrentSwapchainTexture());
  }</code></pre>
</div>
<ol>
<li>The shutdown code is standard. We should destroy the <code>IDevice</code> object before destroying the GLFW window:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  ctx.reset();
  glfwDestroyWindow(window);
  glfwTerminate();
  return 0;
}</code></pre>
</div>
<ol>
<li>The application should render an empty black window, as shown in the following screenshot:</li>
</ol>
<figure>
<img alt="Figure 2.1: The main loop and swapchain" height="607" src="../media/file11.png" width="964"/><figcaption aria-hidden="true">Figure 2.1: The main loop and swapchain</figcaption>
</figure>
<p>Let’s explore <code>lvk::createVulkanContextWithSwapchain()</code> and take a sneak peek at its implementation. Again, we skip most of the error checking in the book text where it does not contribute to the understanding:</p>
<ol>
<li>This helper function calls <em>LightweightVK</em> to create a <em>VulkanContext</em> object, based on the GLFW window and display properties for our operating system:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>std::unique_ptr&lt;lvk::IContext&gt; createVulkanContextWithSwapchain(
  GLFWwindow* window, uint32_t width, uint32_t height,
  const lvk::vulkan::VulkanContextConfig&amp; cfg,
  lvk::HWDeviceType preferredDeviceType = lvk::HWDeviceType_Discrete) {
  std::unique_ptr&lt;vulkan::VulkanContext&gt; ctx;
#if defined(_WIN32)
  ctx = std::make_unique&lt;vulkan::VulkanContext&gt;(
    cfg, (void*)glfwGetWin32Window(window));
#elif defined(__linux__)
  ctx = std::make_unique&lt;vulkan::VulkanContext&gt;(
    cfg, (void*)glfwGetX11Window(window), (void*)glfwGetX11Display());
#else
#  error Unsupported OS
#endif</code></pre>
</div>
<ol>
<li>Then, we enumerate Vulkan physical devices and choose the most preferred one. Try to choose a discrete GPU first, and if there’s none, choose an integrated GPU:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  std::vector&lt;HWDeviceDesc&gt; devices;
  Result res = ctx-&gt;queryDevices(preferredDeviceType, devices);
  if (devices.empty()) {
    if (preferredDeviceType == HWDeviceType_Discrete) {
      res = ctx-&gt;queryDevices(HWDeviceType_Integrated, devices);
    }
    if (preferredDeviceType == HWDeviceType_Integrated) {
      res = ctx-&gt;queryDevices(HWDeviceType_Discrete, devices);
    }
  }</code></pre>
</div>
<ol>
<li>Once a physical device is chosen, call <code>VulkanContext::initContext()</code>, and it will create all Vulkan and <em>LightweightVK</em> internal data structures:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  if (!res.isOk() || devices.empty()) return nullptr;
  res = ctx-&gt;initContext(devices[0]);
  if (!res.isOk()) return nullptr;</code></pre>
</div>
<ol>
<li>If we have a non-empty viewport, initialize a Vulkan swapchain. The swapchain creation process will be explained in detail in the next recipe, <em>Initializing a Vulkan swapchain</em>.</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  if (width &gt; 0 &amp;&amp; height &gt; 0) {
    res = ctx-&gt;initSwapchain(width, height);
    if (!res.isOk()) return nullptr;
  }
  return std::move(ctx);
}</code></pre>
</div>
<p>That is all we need to do regarding the high-level code. Let’s dig deeper and look at the internals of <em>LightweightVK</em> to see how it works.</p>
</section>
<section class="level3" data-number="3.3.3" id="how-it-works...-2">
<h3 data-number="3.3.3">How it works...</h3>
<p>There are multiple functions involved to get Vulkan up and running. It all starts with the creation of a Vulkan instance in <code>VulkanContext::createInstance()</code>. Using the Vulkan instance, we can later acquire a list of physical devices with the required properties.</p>
<ol>
<li>First, we need to specify the names of all Vulkan instance extensions required to run our Vulkan graphics backend. We need <code>VK_KHR_surface</code> and another platform-specific extension that takes an OS window handle and attaches a rendering surface to it. On Linux, we only support the creation of a libXCB-based window. Similarly, the Wayland protocol can also be supported but is out of the scope of this book. Here is how Wayland was added to LightweightVK, <a href="https://github.com/corporateshark/lightweightvk/pull/13">https://github.com/corporateshark/lightweightvk/pull/13</a>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void VulkanContext::createInstance() {
  vkInstance_ = VK_NULL_HANDLE;
  const char* instanceExtensionNames[] = {
    VK_KHR_SURFACE_EXTENSION_NAME,
    VK_EXT_DEBUG_UTILS_EXTENSION_NAME,
#if defined(_WIN32)
    VK_KHR_WIN32_SURFACE_EXTENSION_NAME,
#elif defined(__linux__)
    VK_KHR_XLIB_SURFACE_EXTENSION_NAME,
#endif     VK_EXT_VALIDATION_FEATURES_EXTENSION_NAME
  };</code></pre>
</div>
<ol>
<li>We disable <code>VK_EXT_validation_features</code> when validation is not required, for example, in release builds:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const uint32_t numInstanceExtensions = config_.enableValidation ?
    (uint32_t)LVK_ARRAY_NUM_ELEMENTS(instanceExtensionNames) :
    (uint32_t)LVK_ARRAY_NUM_ELEMENTS(instanceExtensionNames) - 1;
  const VkValidationFeatureEnableEXT validationFeaturesEnabled[] = {
    VK_VALIDATION_FEATURE_ENABLE_GPU_ASSISTED_EXT };
  const VkValidationFeaturesEXT features = {
    .sType = VK_STRUCTURE_TYPE_VALIDATION_FEATURES_EXT,
    .pNext = nullptr,
    .enabledValidationFeatureCount = config_.enableValidation ?
      LVK_ARRAY_NUM_ELEMENTS(validationFeaturesEnabled) : 0u,
    .pEnabledValidationFeatures = config_.enableValidation ?
      validationFeaturesEnabled : nullptr,
  };</code></pre>
</div>
<ol>
<li>After constructing the list of surface-related extensions, we should fill in some mandatory information about our application:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkApplicationInfo appInfo = {
    .sType = VK_STRUCTURE_TYPE_APPLICATION_INFO,
    .pNext = nullptr,
    .pApplicationName = “LVK/Vulkan”,
    .applicationVersion = VK_MAKE_VERSION(1, 0, 0),
    .pEngineName = “LVK/Vulkan”,
    .engineVersion = VK_MAKE_VERSION(1, 0, 0),
    .apiVersion = VK_API_VERSION_1_3,
  };</code></pre>
</div>
<ol>
<li>To create a <code>VkInstance</code> object, we should populate the <code>VkInstanceCreateInfo</code> structure. We use a pointer to the aforementioned <code>appInfo</code> constant and the list of extensions in the member fields of <code>VkInstanceCreateInfo</code>. We use a list of so-called layers stored in a global variable, <code>kDefaultValidationLayers[]</code>, which will later allow us to enable debugging output for every Vulkan call. The only layer we use in our book is the Khronos validation layer, <code>VK_LAYER_KHRONOS_validation</code>. The same list of validation layers will be used to create a Vulkan device. Then, we use the <em>Volk</em> library to load all instance-related Vulkan functions for the created <code>VkInstance</code>.</li>
</ol>
<p>Volk is a meta-loader for Vulkan. It allows you to dynamically load entry points required to use Vulkan without linking to <code>vulkan-1.dll</code> or statically linking the Vulkan loader. Volk simplifies the use of Vulkan extensions by automatically loading all associated entry points. Besides that, Volk can load Vulkan entry points directly from the driver, which can increase performance by skipping loader dispatch overhead: <a href="https://github.com/zeux/volk">https://github.com/zeux/volk</a>.</p>
<div class="C1-SHCodePACKT">
<pre><code>  const VkInstanceCreateInfo ci = {
    .sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO,
    .pNext = config_.enableValidation ? &amp;features : nullptr,
    .flags = 0,
    .pApplicationInfo = &amp;appInfo,
    .enabledLayerCount = config_.enableValidation ?
      LVK_ARRAY_NUM_ELEMENTS(kDefaultValidationLayers) : 0,
    .ppEnabledLayerNames = config_.enableValidation ?
      kDefaultValidationLayers : nullptr,
    .enabledExtensionCount = numInstanceExtensions,
    .ppEnabledExtensionNames = instanceExtensionNames,
  };
  VK_ASSERT(vkCreateInstance(&amp;ci, nullptr, &amp;vkInstance_));
  volkLoadInstance(vkInstance_);</code></pre>
</div>
<ol>
<li>Last but not least, let’s print a nicely formatted list of all available Vulkan instance extensions:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  uint32_t count = 0;
  VK_ASSERT(vkEnumerateInstanceExtensionProperties(
    nullptr, &amp;count, nullptr));
  std::vector&lt;VkExtensionProperties&gt; allInstanceExtensions(count);
  VK_ASSERT(vkEnumerateInstanceExtensionProperties(
    nullptr, &amp;count, allInstanceExtensions.data()));
  LLOGL(“\nVulkan instance extensions:\n”);
  for (const auto&amp; extension : allInstanceExtensions) {
    LLOGL(“  %s\n”, extension.extensionName);
  }
}</code></pre>
</div>
<p>Once we have created a Vulkan instance, we can access the list of Vulkan physical devices that are necessary to continue setting up our Vulkan backend. Here’s how we can enumerate Vulkan physical devices and choose a suitable one:</p>
<ol>
<li>The function <code>vkEnumeratePhysicalDevices()</code> is called twice. The first time is to get the number of available physical devices and allocate <code>std::vector</code> storage for it. The second time is to retrieve the actual physical device data:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::Result VulkanContext::queryDevices(HWDeviceType deviceType,
  std::vector&lt;HWDeviceDesc&gt;&amp; outDevices) {
  outDevices.clear();
  uint32_t deviceCount = 0;
  VK_ASSERT_RETURN(
    vkEnumeratePhysicalDevices(vkInstance_, &amp;deviceCount, nullptr));
  std::vector&lt;VkPhysicalDevice&gt; vkDevices(deviceCount);
  VK_ASSERT_RETURN(vkEnumeratePhysicalDevices(
    vkInstance_, &amp;deviceCount, vkDevices.data()));</code></pre>
</div>
<ol>
<li>We iterate through the vector of devices to retrieve their properties and filter out non-suitable ones. The function <code>convertVulkanDeviceTypeToIGL()</code> converts a Vulkan enum, <code>VkPhysicalDeviceType</code>, into a <code>LightweightVK</code> enum, <code>HWDeviceType</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>enum HWDeviceType {
  HWDeviceType_Discrete = 1,
  HWDeviceType_External = 2,
  HWDeviceType_Integrated = 3,
  HWDeviceType_Software = 4,
};
  const HWDeviceType desiredDeviceType = deviceType;
  for (uint32_t i = 0; i &lt; deviceCount; ++i) {
    VkPhysicalDevice physicalDevice = vkDevices[i];
    VkPhysicalDeviceProperties deviceProperties;
    vkGetPhysicalDeviceProperties(physicalDevice, &amp;deviceProperties);
    const HWDeviceType deviceType =
      convertVulkanDeviceTypeToIGL(deviceProperties.deviceType);
    if (desiredDeviceType != HWDeviceType_Software &amp;&amp;         desiredDeviceType != deviceType) continue;
    outDevices.push_back(
      {.guid = (uintptr_t)vkDevices[i], .type = deviceType});
    strcpy(outDevices.back().name, deviceProperties.deviceName);
  }
  if (outDevices.empty()) return Result(RuntimeError,
    “No Vulkan devices matching your criteria”);
  return Result();
}</code></pre>
</div>
<p>Once we have selected a suitable Vulkan physical device, we can create a logical representation of a GPU <code>VkDevice</code>. We can think of Vulkan devices as essentially a collection of queues and memory heaps. To use a device for rendering, we need to specify a queue that is capable of executing graphics-related commands and a physical device that has such a queue. Let’s explore <em>LightweightVK</em> and some parts of the function <code>VulkanContext::initContext()</code>, which, among many other things we will cover later, detects suitable queue families and creates a Vulkan device. Once again, most of the error checking will be omitted here:</p>
<ol>
<li>The first thing we do in <code>VulkanContext::initContext()</code> is print some information related to the physical device we have just selected earlier and the Vulkan driver. This is very useful for debugging:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::Result VulkanContext::initContext(const HWDeviceDesc&amp; desc) {
  vkPhysicalDevice_ = (VkPhysicalDevice)desc.guid;
  vkGetPhysicalDeviceFeatures2(vkPhysicalDevice_, &amp;vkFeatures10_);
  vkGetPhysicalDeviceProperties2(
    vkPhysicalDevice_, &amp;vkPhysicalDeviceProperties2_);
  const uint32_t apiVersion =
    vkPhysicalDeviceProperties2_.properties.apiVersion;
  LLOGL(“Vulkan physical device: %s\n”,
    vkPhysicalDeviceProperties2_.properties.deviceName);
  LLOGL(“           API version: %i.%i.%i.%i\n”,
        VK_API_VERSION_MAJOR(apiVersion),
        VK_API_VERSION_MINOR(apiVersion),
        VK_API_VERSION_PATCH(apiVersion),
        VK_API_VERSION_VARIANT(apiVersion));
  LLOGL(“           Driver info: %s %s\n”,
        vkPhysicalDeviceDriverProperties_.driverName,
        vkPhysicalDeviceDriverProperties_.driverInfo);</code></pre>
</div>
<ol>
<li>Let’s enumerate and print all the extensions available on this Vulkan physical device, which is very helpful for debugging:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  uint32_t count = 0;
  vkEnumerateDeviceExtensionProperties(
    vkPhysicalDevice_, nullptr, &amp;count, nullptr);
  std::vector&lt;VkExtensionProperties&gt;     allPhysicalDeviceExtensions(count);
  vkEnumerateDeviceExtensionProperties(vkPhysicalDevice_, nullptr,
    &amp;count, allPhysicalDeviceExtensions.data());
  LLOGL(“Vulkan physical device extensions:\n”);
  for (const auto&amp; ext : allPhysicalDeviceExtensions) {
    LLOGL(“  %s\n”, ext.extensionName);
  }</code></pre>
</div>
<ol>
<li>Before creating a Vulkan device, we need to find queue family indices and create queues. This code block creates one or two device queues, graphical and compute, based on the actual queue availability on the provided physical device. The <code>lvk::findQueueFamilyIndex()</code> helper function, which is implemented in <code>lvk/vulkan/VulkanUtils.cpp</code>, returns the first dedicated queue family index that matches the requested queue flag. If you look into it, you can see how it ensures you select dedicated queues first.</li>
</ol>
<p>In Vulkan, <code>queueFamilyIndex</code> is the index of the queue family to which the queue belongs. A queue family is a collection of Vulkan queues with similar properties and functionality. Here, <code>deviceQueues_</code> is a member field holding a structure with queue information:</p>
<div class="C1-SHCodePACKT">
<pre><code>struct DeviceQueues {
  const static uint32_t INVALID = 0xFFFFFFFF;
  uint32_t graphicsQueueFamilyIndex = INVALID;
  uint32_t computeQueueFamilyIndex = INVALID;
  VkQueue graphicsQueue = VK_NULL_HANDLE;
  VkQueue computeQueue = VK_NULL_HANDLE;
};
  deviceQueues_.graphicsQueueFamilyIndex =
      lvk::findQueueFamilyIndex(vkPhysicalDevice_,
      VK_QUEUE_GRAPHICS_BIT);
  deviceQueues_.computeQueueFamilyIndex =
      lvk::findQueueFamilyIndex(vkPhysicalDevice_,
      VK_QUEUE_COMPUTE_BIT);
  const float queuePriority = 1.0f;
  const VkDeviceQueueCreateInfo ciQueue[2] = {
    {   .sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
        .queueFamilyIndex = deviceQueues_.graphicsQueueFamilyIndex,
        .queueCount = 1,
        .pQueuePriorities = &amp;queuePriority, },
    {   .sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
        .queueFamilyIndex = deviceQueues_.computeQueueFamilyIndex,
        .queueCount = 1,
        .pQueuePriorities = &amp;queuePriority, },
  };</code></pre>
</div>
<ol>
<li>Sometimes, especially on mobile GPUs, graphics and compute queues might be the same. Here, we take care of such corner cases:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const uint32_t numQueues =
    ciQueue[0].queueFamilyIndex == ciQueue[1].queueFamilyIndex ? 1:2;</code></pre>
</div>
<ol>
<li>5. A list of extensions that our logical device is required to support. A device has to support a swapchain object, which allows us to present rendered frames on the screen. We use Vulkan 1.3, which contains all other necessary functionality, so no extra extensions are required:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const char* deviceExtensionNames[] = {
    VK_KHR_SWAPCHAIN_EXTENSION_NAME,
  };</code></pre>
</div>
<ol>
<li>Let’s request all the necessary <em>Vulkan 1.0</em>–<em>1.3</em> features we are going to use in our backend. The most important features are descriptor indexing from <em>Vulkan 1.2</em> and dynamic rendering from <em>Vulkan 1.3</em>, which we will discuss in subsequent chapters. Take a look at the other features we are going to use.</li>
</ol>
<p>Descriptor indexing is a set of Vulkan 1.2 features that enable applications to access all of their resources and select from them those with dynamic indexes in shaders.</p>
<p>Dynamic rendering is a Vulkan 1.3 feature that allows applications to render directly into images without needing to create render pass objects or framebuffers.</p>
<div class="C1-SHCodePACKT">
<pre><code>  VkPhysicalDeviceFeatures deviceFeatures10 = {
      .geometryShader = VK_TRUE,
      .multiDrawIndirect = VK_TRUE,
      .drawIndirectFirstInstance = VK_TRUE,
      .depthBiasClamp = VK_TRUE,
      .fillModeNonSolid = VK_TRUE,
      .textureCompressionBC = VK_TRUE,
  };
  VkPhysicalDeviceVulkan11Features deviceFeatures11 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_1_FEATURES,
      .storageBuffer16BitAccess = VK_TRUE,
      .shaderDrawParameters = VK_TRUE,
  };
  VkPhysicalDeviceVulkan12Features deviceFeatures12 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_2_FEATURES,
      .pNext = &amp;deviceFeatures11,
      .descriptorIndexing = VK_TRUE,
      .shaderSampledImageArrayNonUniformIndexing = VK_TRUE,
      .descriptorBindingSampledImageUpdateAfterBind = VK_TRUE,
      .descriptorBindingStorageImageUpdateAfterBind = VK_TRUE,
      .descriptorBindingUpdateUnusedWhilePending = VK_TRUE,
      .descriptorBindingPartiallyBound = VK_TRUE,
      .descriptorBindingVariableDescriptorCount = VK_TRUE,
      .runtimeDescriptorArray = VK_TRUE,
      .uniformBufferStandardLayout = VK_TRUE,
      .timelineSemaphore = VK_TRUE,
      .bufferDeviceAddress = VK_TRUE,
  };
  VkPhysicalDeviceVulkan13Features deviceFeatures13 = {
      .sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_1_3_FEATURES,
      .pNext = &amp;deviceFeatures12,
      .subgroupSizeControl = VK_TRUE,
      .synchronization2 = VK_TRUE,
      .dynamicRendering = VK_TRUE,
      .maintenance4 = VK_TRUE,
  };</code></pre>
</div>
<ol>
<li>There are a few more steps before we create an actual device, such as checking our list of requested extensions against the list of available extensions and printing all the missing extensions in the log and terminating:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  std::vector&lt;VkExtensionProperties&gt; props;
  getDeviceExtensionProps(vkPhysicalDevice_, props);
  for (const char* layer : kDefaultValidationLayers)
    getDeviceExtensionProps(vkPhysicalDevice_, props, layer);
  std::string missingExtensions;
  for (const char* ext : deviceExtensionNames)
    if (!hasExtension(ext, props))
      missingExtensions += “\n   “ + std::string(ext);
  if (!missingExtensions.empty()) {
    MINILOG_LOG_PROC(minilog::FatalError,
      “Missing Vulkan device extensions: %s\n”,
      missingExtensions.c_str());
    return Result(Result::Code::RuntimeError);
  }</code></pre>
</div>
<ol>
<li>Finally, we should check all the requested Vulkan features against the actual available features. With the help of C-macros, we can do this easily. This code is useful, so we have printed it here in almost its entirety:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  {
    std::string missingFeatures;
#define CHECK_VULKAN_FEATURE(                       \
  reqFeatures, availFeatures, feature, version)     \
  if ((reqFeatures.feature == VK_TRUE) &amp;&amp;           \
      (availFeatures.feature == VK_FALSE))          \
        missingFeatures.append(“\n   “ version “ .” #feature);
#define CHECK_FEATURE_1_0(feature)                               \
  CHECK_VULKAN_FEATURE(deviceFeatures10, vkFeatures10_.features, \
  feature, “1.0 “);
    CHECK_FEATURE_1_0(robustBufferAccess);
    CHECK_FEATURE_1_0(fullDrawIndexUint32);
    CHECK_FEATURE_1_0(imageCubeArray);
    … // omitted a lot of other Vulkan 1.0 features here
#undef CHECK_FEATURE_1_0
#define CHECK_FEATURE_1_1(feature)                      \
  CHECK_VULKAN_FEATURE(deviceFeatures11, vkFeatures11_, \
    feature, “1.1 “);
    CHECK_FEATURE_1_1(storageBuffer16BitAccess);
    CHECK_FEATURE_1_1(uniformAndStorageBuffer16BitAccess);
    CHECK_FEATURE_1_1(storagePushConstant16);
    … // omitted a lot of other Vulkan 1.1 features here
#undef CHECK_FEATURE_1_1
#define CHECK_FEATURE_1_2(feature)                      \
  CHECK_VULKAN_FEATURE(deviceFeatures12, vkFeatures12_, \
  feature, “1.2 “);
    CHECK_FEATURE_1_2(samplerMirrorClampToEdge);
    CHECK_FEATURE_1_2(drawIndirectCount);
    CHECK_FEATURE_1_2(storageBuffer8BitAccess);
    … // omitted a lot of other Vulkan 1.2 features here
#undef CHECK_FEATURE_1_2
#define CHECK_FEATURE_1_3(feature)                      \
  CHECK_VULKAN_FEATURE(deviceFeatures13, vkFeatures13_, \
  feature, “1.3 “);
    CHECK_FEATURE_1_3(robustImageAccess);
    CHECK_FEATURE_1_3(inlineUniformBlock);
    … // omitted a lot of other Vulkan 1.3 features here
#undef CHECK_FEATURE_1_3
    if (!missingFeatures.empty()) {
      MINILOG_LOG_PROC(minilog::FatalError,
        “Missing Vulkan features: %s\n”, missingFeatures.c_str());
      return Result(Result::Code::RuntimeError);
    }
  }</code></pre>
</div>
<p>When we are missing some Vulkan features, this code will print a nicely formatted list of missing features marked by a corresponding Vulkan version. This is invaluable for debugging and making your Vulkan backend adjustable to fit different devices.</p>
<p>Now, we are ready to create a Vulkan device, load all related Vulkan functions with <em>Volk</em>, and get the actual device queues based on the queue family indices we selected earlier in this recipe:</p>
<div class="C1-SHCodePACKT">
<pre><code>  const VkDeviceCreateInfo ci = {
      .sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO,
      .pNext = &amp;deviceFeatures13,
      .queueCreateInfoCount = numQueues,
      .pQueueCreateInfos = ciQueue,
      .enabledLayerCount =
        LVK_ARRAY_NUM_ELEMENTS(kDefaultValidationLayers),
      .ppEnabledLayerNames = kDefaultValidationLayers,
      .enabledExtensionCount = 
        LVK_ARRAY_NUM_ELEMENTS(deviceExtensionNames),
      .ppEnabledExtensionNames = deviceExtensionNames,
      .pEnabledFeatures = &amp;deviceFeatures10,
  };
  VK_ASSERT_RETURN(vkCreateDevice(
    vkPhysicalDevice_, &amp;ci, nullptr, &amp;vkDevice_));
  volkLoadDevice(vkDevice_);
  vkGetDeviceQueue(vkDevice_, deviceQueues_.graphicsQueueFamilyIndex,
    0, &amp;deviceQueues_.graphicsQueue);
  vkGetDeviceQueue(vkDevice_, deviceQueues_.computeQueueFamilyIndex,
    0, &amp;deviceQueues_.computeQueue);
  … // other code in initContext() is unrelated to this recipe
}</code></pre>
</div>
<p>The Vulkan device is now ready to be used, but the initialization of the Vulkan rendering pipeline is far from complete. The next thing we need to do is create a swapchain object. Let’s follow the next recipe to learn how to do it.</p>
</section>
</section>
<section class="level2" data-number="3.4" id="initializing-a-vulkan-swapchain">
<h2 data-number="3.4">Initializing a Vulkan swapchain</h2>
<p>Normally, each frame is rendered into an offscreen image. After the rendering process is finished, the offscreen image should be made visible or “presented.” A <strong>swapchain</strong> is an object that holds a collection of available offscreen images, or, more specifically, a queue of rendered images waiting to be presented on the screen. In OpenGL, presenting an offscreen buffer to the visible area of a window is performed using system-dependent functions, namely <code>wglSwapBuffers()</code> on Windows, <code>eglSwapBuffers()</code> on OpenGL ES-embedded systems, and <code>glXSwapBuffers()</code> on Linux or automatically on macOS. Vulkan gives us much more fine-grained control. We need to select a presentation mode for swapchain images.</p>
<p>In this recipe, we will show how to create a Vulkan swapchain object using the Vulkan instance and device initialized in the previous recipe.</p>
<section class="level3" data-number="3.4.1" id="getting-ready-8">
<h3 data-number="3.4.1">Getting ready</h3>
<p>Revisit the previous recipe, <em>Initializing a Vulkan instance and graphical device</em>, which discusses the initial steps necessary to initialize Vulkan. The source code discussed in this recipe is implemented in the class <code>lvk::VulkanSwapchain</code>.</p>
</section>
<section class="level3" data-number="3.4.2" id="how-to-do-it...-8">
<h3 data-number="3.4.2">How to do it...</h3>
<p>In the previous recipe, we started learning how Vulkan instances and devices are created by exploring the helper function <code>lvk::createVulkanContextWithSwapchain()</code>. It lead us to the function <code>VulkanContext::initContext()</code>, which we discussed in detail in the previous recipe. Let’s continue our journey and explore <code>VulkanContext::initSwapchain()</code> and a related class <code>VulkanSwapchain</code> from <em>LightweightVK</em>:</p>
<ol>
<li>First, let us take a look at a function that retrieves various surface format support capabilities and stores them in the member fields of <code>VulkanContext</code>. The function checks depth format support as well, but only those depth formats that might be used by <em>LightweightVK</em>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void VulkanContext::querySurfaceCapabilities() {
   const VkFormat depthFormats[] = {
     VK_FORMAT_D32_SFLOAT_S8_UINT, VK_FORMAT_D24_UNORM_S8_UINT,
     VK_FORMAT_D16_UNORM_S8_UINT, VK_FORMAT_D32_SFLOAT,
     VK_FORMAT_D16_UNORM};
  for (const auto&amp; depthFormat : depthFormats) {
    VkFormatProperties formatProps;
    vkGetPhysicalDeviceFormatProperties(
      vkPhysicalDevice_, depthFormat, &amp;formatProps);
    if (formatProps.optimalTilingFeatures)
      deviceDepthFormats_.push_back(depthFormat);
  }</code></pre>
</div>
<ol>
<li>All the surface capabilities and surface formats are retrieved and stored. First, get the number of supported formats. Then, allocate the storage to hold them and read the actual properties:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  vkGetPhysicalDeviceSurfaceCapabilitiesKHR(
    vkPhysicalDevice_, vkSurface_, &amp;deviceSurfaceCaps_);
  uint32_t formatCount;
  vkGetPhysicalDeviceSurfaceFormatsKHR(
    vkPhysicalDevice_, vkSurface_, &amp;formatCount, nullptr);
  if (formatCount) {
    deviceSurfaceFormats_.resize(formatCount);
    vkGetPhysicalDeviceSurfaceFormatsKHR(vkPhysicalDevice_,
      vkSurface_, &amp;formatCount, deviceSurfaceFormats_.data());
  }</code></pre>
</div>
<ol>
<li>In a similar way, we store the surface present modes as well:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  uint32_t presentModeCount;
  vkGetPhysicalDeviceSurfacePresentModesKHR(vkPhysicalDevice_,
    vkSurface_, &amp;presentModeCount, nullptr);
  if (presentModeCount) {
    devicePresentModes_.resize(presentModeCount);
    vkGetPhysicalDeviceSurfacePresentModesKHR(vkPhysicalDevice_,
    vkSurface_, &amp;presentModeCount, devicePresentModes_.data());
  }
}</code></pre>
</div>
<p>Knowing all supported color surface formats, we can choose a suitable one for our swapchain. Let’s take a look at the <code>chooseSwapSurfaceFormat()</code> helper function on how to do it. The function takes in a list of available formats and a desired color space:</p>
<ol>
<li>First, it picks a preferred surface format, based on the desired color space and RGB/BGR native swapchain image format. RGB or BGR is decided by going through all available color formats, returned by Vulkan, and picking one format, RGB or BGR, whichever is closer to the beginning of the list. If BGR is encountered earlier, it will be the format of choice. Once the preferred image format and color space are selected, we can go through the list of supported formats and try to find an exact match.</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkSurfaceFormatKHR chooseSwapSurfaceFormat(   const std::vector&lt;VkSurfaceFormatKHR&gt;&amp; formats,
  lvk::ColorSpace colorSpace) {
  const VkSurfaceFormatKHR preferred = colorSpaceToVkSurfaceFormat(
    colorSpace, isNativeSwapChainBGR(formats));
  for (const auto&amp; fmt : formats)
    if (fmt.format == preferred.format &amp;&amp;         fmt.colorSpace == preferred.colorSpace) return fmt;</code></pre>
</div>
<ol>
<li>If you cannot find both a matching format and color space, try matching only the format. If you cannot match the format, default to the first available format. On many systems, it will be <code>VK_FORMAT_R8G8B8A8_UNORM</code> or a similar format:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  for (const auto&amp; fmt : formats) {
    if (fmt.format == preferred.format) return fmt;
  }
  return formats[0];
}</code></pre>
</div>
<p>This function is called from the constructor of <code>VulkanSwapchain</code>. Once the format has been selected, we need to do a few more checks before we can create an actual Vulkan swapchain:</p>
<ol>
<li>The first check is to ensure that the selected format supports presentation operation on the graphics queue family used to create the swapchain:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkBool32 queueFamilySupportsPresentation = VK_FALSE;
vkGetPhysicalDeviceSurfaceSupportKHR(ctx.getVkPhysicalDevice(),
  ctx.deviceQueues_.graphicsQueueFamilyIndex, ctx.vkSurface_,
  &amp;queueFamilySupportsPresentation));
IGL_ASSERT(queueFamilySupportsPresentation == VK_TRUE);</code></pre>
</div>
<ol>
<li>The second check is necessary to choose usage flags for swapchain images. Usage flags define if swapchain images can be used as color attachments, in transfer operations, or as storage images to allow compute shaders to operate directly on them. Different devices have different capabilities, and storage images are not always supported, especially on mobile GPUs:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkImageUsageFlags chooseUsageFlags(   VkPhysicalDevice pd, VkSurfaceKHR surface, VkFormat format)
{
  VkImageUsageFlags usageFlags = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT |
                                 VK_IMAGE_USAGE_TRANSFER_DST_BIT |
                                 VK_IMAGE_USAGE_TRANSFER_SRC_BIT;
  VkSurfaceCapabilitiesKHR caps;
  vkGetPhysicalDeviceSurfaceCapabilitiesKHR(pd, surface, &amp;caps);
  const bool isStorageSupported =
    (caps.supportedUsageFlags &amp; VK_IMAGE_USAGE_STORAGE_BIT) &gt; 0;
  VkFormatProperties props;
  vkGetPhysicalDeviceFormatProperties(pd, format, &amp;props);
  const bool isTilingOptimalSupported =
    (props.optimalTilingFeatures &amp; VK_IMAGE_USAGE_STORAGE_BIT) &gt; 0;
  if (isStorageSupported &amp;&amp; isTilingOptimalSupported) {
    usageFlags |= VK_IMAGE_USAGE_STORAGE_BIT;
  }
  return usageFlags;
}</code></pre>
</div>
<ol>
<li>Now, we should select the presentation mode. The preferred presentation mode is <code>VK_PRESENT_MODE_MAILBOX_KHR</code>, which specifies that the Vulkan presentation system should wait for the next vertical blanking period to update the current image. Visual tearing will not be observed in this case. However, this presentation mode is not guaranteed to be supported. In this situation, we can try picking <code>VK_PRESENT_MODE_IMMEDIATE_KHR</code> for the fastest frames per second without V-sync, or we can always fall back to <code>VK_PRESENT_MODE_FIFO_KHR</code>. The differences between all possible presentation mode are described in the Vulkan specification at <a href="https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkPresentModeKHR.xhtml">https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkPresentModeKHR.xhtml</a>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkPresentModeKHR chooseSwapPresentMode(   const std::vector&lt;VkPresentModeKHR&gt;&amp; modes) {
#if defined(__linux__)
  if (std::find(modes.cbegin(), modes.cend(),
      VK_PRESENT_MODE_IMMEDIATE_KHR) != modes.cend())
    return VK_PRESENT_MODE_IMMEDIATE_KHR;
#endif // __linux__
  if (std::find(modes.cbegin(), modes.cend(),
      VK_PRESENT_MODE_MAILBOX_KHR) != modes.cend())
    return VK_PRESENT_MODE_MAILBOX_KHR;
  return VK_PRESENT_MODE_FIFO_KHR;
}</code></pre>
</div>
<ol>
<li>The last helper function we need will choose the number of images in the swapchain object. It is based on the surface capabilities we retrieved earlier. Instead of using <code>minImageCount</code> directly, we request one additional image to make sure we are not waiting for the GPU to complete any operations:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>uint32_t chooseSwapImageCount(const VkSurfaceCapabilitiesKHR&amp; caps) {
  const uint32_t desired = caps.minImageCount + 1;
  const bool exceeded = caps.maxImageCount &gt; 0 &amp;&amp;                         desired &gt; caps.maxImageCount;
  return exceeded ? caps.maxImageCount : desired;
}</code></pre>
</div>
<ol>
<li>Let’s go back to the constructor <code>VulkanSwapchain::VulkanSwapchain()</code> and explore how it uses all the aforementioned helper functions to create a Vulkan swapchain object. The code here becomes rather short and consists only of filling in the <code>VkSwapchainCreateInfoKHR</code> structure:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>const VkImageUsageFlags usageFlags = chooseUsageFlags(
  ctx.getVkPhysicalDevice(), ctx.vkSurface_, surfaceFormat_.format);
const VkSwapchainCreateInfoKHR ci = {
  .sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR,
  .surface = ctx.vkSurface_,
  .minImageCount = chooseSwapImageCount(ctx.deviceSurfaceCaps_),
  .imageFormat = surfaceFormat_.format,
  .imageColorSpace = surfaceFormat_.colorSpace,
  .imageExtent = {.width = width, .height = height},
  .imageArrayLayers = 1,
  .imageUsage = usageFlags,
  .imageSharingMode = VK_SHARING_MODE_EXCLUSIVE,
  .queueFamilyIndexCount = 1,
  .pQueueFamilyIndices = &amp;ctx.deviceQueues_.graphicsQueueFamilyIndex,
  .preTransform = ctx.deviceSurfaceCaps_.currentTransform,
  .compositeAlpha = VK_COMPOSITE_ALPHA_INHERIT_BIT_KHR,
  .presentMode = chooseSwapPresentMode(ctx.devicePresentModes_),
  .clipped = VK_TRUE,
  .oldSwapchain = VK_NULL_HANDLE,
};
vkCreateSwapchainKHR(device_, &amp;ci, nullptr, &amp;swapchain_);</code></pre>
</div>
<ol>
<li>After the swapchain object has been created, we can retrieve swapchain images:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>vkGetSwapchainImagesKHR(
  device_, swapchain_, &amp;numSwapchainImages_, nullptr);
std::vector&lt;VkImage&gt; swapchainImages(numSwapchainImages_);
vkGetSwapchainImagesKHR(
  device_, swapchain_, &amp;numSwapchainImages_, swapchainImages.data());</code></pre>
</div>
<p>The retrieved <code>VkImage</code> objects can be used to create textures and attachments. This topic will be discussed in the recipe <em>Using texture data in Vulkan</em> in <em>Chapter 3</em>.</p>
<p>Now, we have initialized Vulkan and can actually run our first application, <em>Chapter02/01_Swapchain</em>. In the next recipe, we will learn how to use Vulkan’s built-in debugging capabilities.</p>
</section>
</section>
<section class="level2" data-number="3.5" id="setting-up-vulkan-debugging-capabilities">
<h2 data-number="3.5">Setting up Vulkan debugging capabilities</h2>
<p>Once we have created a Vulkan instance, we can start tracking all possible errors and warnings produced by the validation layers. To do so, we use the extension <code>VK_EXT_debug_utils</code> to create a callback function and register it with the Vulkan instance. In this recipe, we will learn how to set up and use them.</p>
<section class="level3" data-number="3.5.1" id="getting-ready-9">
<h3 data-number="3.5.1">Getting ready</h3>
<p>Please revisit the first recipe, <em>Initializing a Vulkan instance and graphical device</em>, for details on how to initialize Vulkan in your applications.</p>
</section>
<section class="level3" data-number="3.5.2" id="how-to-do-it...-9">
<h3 data-number="3.5.2">How to do it...</h3>
<p>We have to provide a callback function to Vulkan to catch the debug output. In <em>LightweightVK</em>, it is called <code>vulkanDebugCallback()</code>. Here’s how it can be passed into Vulkan to intercept logs:</p>
<ol>
<li>Let’s create a debug messenger that will pass along debug messages to an application-supplied callback, <code>vulkanDebugCallback()</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>const VkDebugUtilsMessengerCreateInfoEXT ci = {
  .sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT,
  .messageSeverity = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT |
                     VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT |
                     VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT |
                     VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT,
  .messageType = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT |
                 VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT |
                 VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT,
  .pfnUserCallback = &amp;vulkanDebugCallback,
  .pUserData = this,
};
vkCreateDebugUtilsMessengerEXT(
  vkInstance_, &amp;ci, nullptr, &amp;vkDebugUtilsMessenger_);</code></pre>
</div>
<ol>
<li>The callback itself is more elaborate and can provide information about a Vulkan object causing an error or warning. We do not cover tagged object allocation and associating used data. Some performance warnings are silenced to make the debug output more readable:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VKAPI_ATTR VkBool32 VKAPI_CALL
vulkanDebugCallback(   VkDebugUtilsMessageSeverityFlagBitsEXT msgSeverity,
  VkDebugUtilsMessageTypeFlagsEXT msgType,
  const VkDebugUtilsMessengerCallbackDataEXT* cbData,
  void* userData) {
  if (msgSeverity &lt; VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT)
    return VK_FALSE;
  const bool isError =
   (msgSeverity &amp; VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT) != 0;
  char errorName[128] = {};
  int object = 0;
  void* handle = nullptr;
  char typeName[128] = {};
  void* messageID = nullptr;
  if (sscanf(cbData-&gt;pMessage,
        “Validation Error : [ %127s ] Object %i: handle = %p, “         “type = %127s | MessageID = %p”,
        errorName, &amp;object, &amp;handle, typeName, messageID) &gt;= 2) {
    const char* message = strrchr(cbData-&gt;pMessage, ‘|’) + 1;
    LLOGL(“%sValidation layer:\n Validation Error: %s \n Object %i: “           “handle = %p, type = %s\n MessageID = %p \n%s \n”,
      isError ? “\nERROR:\n” : ““,
      errorName, object, handle, typeName, messageID, message);
  } else {
    LLOGL(“%sValidation layer:\n%s\n”, isError ? “\nERROR:\n” : ““,
      cbData-&gt;pMessage);
  }
  if (isError) {
    VulkanContext* ctx =
      static_cast&lt;lvk::vulkan::VulkanContext*&gt;(userData);
    if (ctx-&gt;config_.terminateOnValidationError) {
      IGL_ASSERT(false);
      std::terminate();
    }
  }
  return VK_FALSE;
}</code></pre>
</div>
<p>This code is sufficient to get you started with reading the validation layer messages and debugging your Vulkan applications. Also, please note that the destruction of the validation layer callbacks should be performed right before the Vulkan instance destruction. Check the full source code for all the details: <a href="https://github.com/corporateshark/lightweightvk/blob/master/lvk/vulkan/VulkanClasses.cpp">https://github.com/corporateshark/lightweightvk/blob/master/lvk/vulkan/VulkanClasses.cpp</a>.</p>
</section>
<section class="level3" data-number="3.5.3" id="theres-more">
<h3 data-number="3.5.3">There’s more…</h3>
<p>The extension <code>VK_EXT_debug_utils</code> provides you with the ability to identify specific Vulkan objects, using a textual name or tag to improve Vulkan object tracking and the debugging experience.</p>
<p>In <em>LightweightVK</em>, we can assign a name to our <code>VkDevice</code> object:</p>
<div class="C1-SHCodePACKT">
<pre><code>lvkSetDebugObjectName(vkDevice_, VK_OBJECT_TYPE_DEVICE,
   (uint64_t)vkDevice_, “Device: VulkanContext::vkDevice_”));</code></pre>
</div>
<p>This helper function is implemented in <code>lvk/vulkan/VulkanUtils.cpp</code> and looks as follows:</p>
<div class="C1-SHCodePACKT">
<pre><code>VkResult ivkSetDebugObjectName(VkDevice device, VkObjectType type,
  uint64_t handle, const char* name) {
  if (!name || !*name) return VK_SUCCESS;
  const VkDebugUtilsObjectNameInfoEXT ni = {
      .sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_NAME_INFO_EXT,
      .objectType = type,
      .objectHandle = handle,
      .pObjectName = name,
  };
  return vkSetDebugUtilsObjectNameEXT(device, &amp;ni);
}</code></pre>
</div>
</section>
</section>
<section class="level2" data-number="3.6" id="using-vulkan-command-buffers">
<h2 data-number="3.6">Using Vulkan command buffers</h2>
<p>In the previous recipes, we learned how to create a Vulkan instance, a device for rendering, and a swapchain. In this recipe, we will learn how to manage <strong>command buffers</strong> and submit them using <strong>command queues</strong>, which will bring us a bit closer to rendering our first image with Vulkan.</p>
<p>Vulkan command buffers are used to record Vulkan commands that can be then submitted to a device queue for execution. Command buffers are allocated from pools that allow the Vulkan implementation to amortize the cost of resource creation across multiple command buffers. Command pools are <strong>externally synchronized</strong>, which means one command pool should not be used between multiple threads. Let’s learn how to make a convenient user-friendly wrapper on top of Vulkan command buffers and pools.</p>
<section class="level3" data-number="3.6.1" id="getting-ready-10">
<h3 data-number="3.6.1">Getting ready</h3>
<p>We are going to explore the command buffers management code from the LightweightVK library. Take a look at the class <code>VulkanImmediateCommands</code> from <code>lvk/vulkan/VulkanClasses.h</code>. In the previous edition of our book, we used very rudimentary command buffers management code, which did not suppose any synchronization because every frame was “synchronized” with <code>vkDeviceWaitIdle()</code>. Here, we are going to explore a more pragmatic solution with some facilities for synchronization.</p>
<p>Let’s go back to our demo application from the recipe <em>Initializing a Vulkan swapchain</em>, which renders a black empty window, <em>Chapter02/01_Swapchain</em>. The main loop of the application looks as follows:</p>
<div class="C1-SHCodePACKT">
<pre><code>  while (!glfwWindowShouldClose(window)) {
    glfwPollEvents();
    glfwGetFramebufferSize(window, &amp;width, &amp;height);
    if (!width || !height) continue;
    lvk::ICommandBuffer&amp; buf = ctx-&gt;acquireCommandBuffer();
    ctx-&gt;submit(buf, ctx-&gt;getCurrentSwapchainTexture());
  }</code></pre>
</div>
<p>Here, we acquire a next command buffer and then submit it without writing any commands into it, allowing <code>LightweightVK</code> to run its swapchain presentation code and render a black window. Let’s dive deep into the implementation and learn how <code>lvk::VulkanImmediateCommands</code> does all the heavy lifting behind the scenes.</p>
</section>
<section class="level3" data-number="3.6.2" id="how-to-do-it...-10">
<h3 data-number="3.6.2">How to do it...</h3>
<ol>
<li>First, we need a helper, <code>struct SubmitHandle</code>, to identify previously submitted command buffers. This is going to be necessary to implement synchronization when someone wants to schedule some work, which depends on the results of a previously submitted command buffer. It contains an internal ID of the submitted buffer and an integer ID of the submit. Handles can be converted to and from 64-bit integers for convenience:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>struct SubmitHandle {
  uint32_t bufferIndex_ = 0;
  uint32_t submitId_ = 0;
  SubmitHandle() = default;
  explicit SubmitHandle(uint64_t handle) :
    bufferIndex_(uint32_t(handle &amp; 0xffffffff)),
    submitId_(uint32_t(handle &gt;&gt; 32)) {}
  bool empty() const { return submitId_ == 0; }
  uint64_t handle() const   { return (uint64_t(submitId_) &lt;&lt; 32) + bufferIndex_; }
};</code></pre>
</div>
<ol>
<li>Another helper struct <code>CommandBufferWrapper</code> is necessary to encapsulate all Vulkan objects associated with one command buffer. Here, we store the originally allocated and the currently active command buffers. The most recent submit handle is associated with this command buffer. A Vulkan fence and a Vulkan semaphore are associated with this command buffer. The fence is used to implement GPU-CPU synchronization. The semaphore is necessary to ensure that command buffers are processed by the GPU in sequence, as <code>LightweightVK</code> enforces all the command buffers to be processed in the order in which they were submitted. It simplifies many things in terms of rendering:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>struct CommandBufferWrapper {
  VkCommandBuffer cmdBuf_ = VK_NULL_HANDLE;
  VkCommandBuffer cmdBufAllocated_ = VK_NULL_HANDLE;
  SubmitHandle handle_ = {};
  VkFence fence_ = VK_NULL_HANDLE;
  VkSemaphore semaphore_ = VK_NULL_HANDLE;
  bool isEncoding_ = false;
};</code></pre>
</div>
<p>Now, let’s take a look at the interface of <code>lvk::VulkanImmediateCommands</code>:</p>
<ol>
<li>Vulkan command buffers are preallocated and used in a round-robin fashion. The number of command buffers that are preallocated is <code>kMaxCommandBuffers</code>. If we run out of buffers, <code>VulkanImmediateCommands</code> will wait until an existing command buffer becomes available by waiting on a fence. <code>64</code> command buffers ensure a non-blocking operation in most situations. The constructor takes the value of <code>queueFamilyIdx</code> to retrieve an appropriate Vulkan queue:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>class VulkanImmediateCommands final {
 public:
   static constexpr uint32_t kMaxCommandBuffers = 64;
  VulkanImmediateCommands(
    VkDevice device, uint32_t queueFamilyIdx, const char* debugName);
  ~VulkanImmediateCommands();</code></pre>
</div>
<ol>
<li>The <code>acquire()</code> method returns the next available command buffer. If all command buffers are busy, it will wait on a fence until one command buffer becomes available. The <code>submit()</code> method submits a command buffer to the assigned Vulkan queue:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const CommandBufferWrapper&amp; acquire();
  SubmitHandle submit(const CommandBufferWrapper&amp; wrapper);</code></pre>
</div>
<ol>
<li>The next two methods provide GPU-GPU synchronization mechanics. The first method, <code>waitSemaphore()</code>, makes the current command buffer wait on a given semaphore before running. A typical use case for this is to get an “acquire semaphore” from a <code>VulkanSwapchain</code> object, which waits to acquire a swapchain image, and make sure the command buffer will wait on it before starting to render into a swapchain image. The second method, <code>acquireLastSubmitSemaphore()</code>, returns and resets the semaphore, which is signaled when the last submitted command buffer is completed. This semaphore can be used by the swapchain before presentation to ensure the image rendering is completed:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  void waitSemaphore(VkSemaphore semaphore);
  VkSemaphore acquireLastSubmitSemaphore();</code></pre>
</div>
<ol>
<li>The next group of methods governs GPU-CPU synchronization. As we will see later in this recipe, submit handles are implemented using Vulkan fences and can be used to wait for specific GPU operations to be completed:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  SubmitHandle getLastSubmitHandle() const;
  bool isReady(SubmitHandle handle) const;
  void wait(SubmitHandle handle);
  void waitAll();</code></pre>
</div>
<ol>
<li>The private section of the class holds all the local state, including an array of pre-allocated <code>CommandBufferWrapper</code> objects <code>buffers_</code>.</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  private:
  void purge();
  VkDevice device_ = VK_NULL_HANDLE;
  VkQueue queue_ = VK_NULL_HANDLE;
  VkCommandPool commandPool_ = VK_NULL_HANDLE;
  uint32_t queueFamilyIndex_ = 0;
  const char* debugName_ = ““;
  CommandBufferWrapper buffers_[kMaxCommandBuffers];
  SubmitHandle lastSubmitHandle_ = SubmitHandle();
  VkSemaphore lastSubmitSemaphore_ = VK_NULL_HANDLE;
  VkSemaphore waitSemaphore_ = VK_NULL_HANDLE;
  uint32_t numAvailableCommandBuffers_ = kMaxCommandBuffers;
  uint32_t submitCounter_ = 1;
};</code></pre>
</div>
<p>The <code>VulkanImmediateCommands</code> class is really central to the entire operation of our Vulkan backend, so let’s explore its implementation in detail, one method at a time.</p>
<p>Let’s start with the class constructor and destructor. The constructor pre-allocates all command buffers. Error checking and debugging code will be skipped here in the text; please refer to the <em>LightweightVK</em> library source code for full details:</p>
<ol>
<li>First, we should retrieve a Vulkan device queue and allocate a command pool. We use the <code>VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT</code> flag to specify that any command buffers allocated from this pool can be individually reset to the initial state using the Vulkan function <code>vkResetCommandBuffer()</code>. To specify that command buffers allocated from this pool will be short-lived, we use the flag <code>VK_COMMAND_POOL_CREATE_TRANSIENT_BIT</code>, meaning that they will be reset or freed in a relatively short timeframe:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::VulkanImmediateCommands::VulkanImmediateCommands(VkDevice device,
  uint32_t queueFamilyIndex, const char* debugName) :
  device_(device), queueFamilyIndex_(queueFamilyIndex),
  debugName_(debugName)
{
  vkGetDeviceQueue(device, queueFamilyIndex, 0, &amp;queue_);
  const VkCommandPoolCreateInfo ci = {
      .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
      .flags = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT |
               VK_COMMAND_POOL_CREATE_TRANSIENT_BIT,
      .queueFamilyIndex = queueFamilyIndex,
  };
  VK_ASSERT(vkCreateCommandPool(device, &amp;ci, nullptr, &amp;commandPool_));</code></pre>
</div>
<ol>
<li>Now, we can pre-allocate all the command buffers from the command pool. Besides that, we create one semaphore and one fence per command buffer to enable our synchronization machinery:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkCommandBufferAllocateInfo ai = {
      .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
      .commandPool = commandPool_,
      .level = VK_COMMAND_BUFFER_LEVEL_PRIMARY,
      .commandBufferCount = 1,
  };
  for (uint32_t i = 0; i != kMaxCommandBuffers; i++) {
    auto&amp; buf = buffers_[i];
    buf.semaphore_ = lvk::createSemaphore(device, semaphoreName);
    buf.fence_ = lvk::createFence(device, fenceName);
    VK_ASSERT(
      vkAllocateCommandBuffers(device, &amp;ai, &amp;buf.cmdBufAllocated_));
    buffers_[i].handle_.bufferIndex_ = i;
  }
}</code></pre>
</div>
<ol>
<li>The destructor is trivial. All we have to do is wait for all command buffers to be processed before destroying the command pool, fences, and semaphores:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::VulkanImmediateCommands::~VulkanImmediateCommands() {
  waitAll();
  for (auto&amp; buf : buffers_) {
    vkDestroyFence(device_, buf.fence_, nullptr);
    vkDestroySemaphore(device_, buf.semaphore_, nullptr);
  }
  vkDestroyCommandPool(device_, commandPool_, nullptr);
}</code></pre>
</div>
<p>Now, let’s take a look at the implementation of our most important functions, <code>acquire()</code>. All the error-checking code is omitted again to simplify understanding:</p>
<ol>
<li>Before we can find an available command buffer, we have to be sure there is one. This busy-wait loop checks the number of currently available command buffers and calls the <code>purge()</code> function, which recycles processed command buffers and resets them to their initial state, until we get at least one buffer available:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>const lvk::VulkanImmediateCommands::CommandBufferWrapper&amp;   lvk::VulkanImmediateCommands::acquire()
{
  while (!numAvailableCommandBuffers_) purge();</code></pre>
</div>
<ol>
<li>Once we know there’s at least one command buffer available, we can find it by going through the array of all the buffers and picking the first one.</li>
<li>At this point, we decrement <code>numAvailableCommandBuffers</code>. This is to make sure we busy-wait properly the next time we call <code>acquire()</code>.<br/>
The <code>isEncoding</code> member field is used to safeguard against the reuse of the currently encoded, but not yet submitted, command buffer:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  VulkanImmediateCommands::CommandBufferWrapper* current = nullptr;
  for (auto&amp; buf : buffers_) {
    if (buf.cmdBuf_ == VK_NULL_HANDLE) {
      current = &amp;buf;
      break;
    }
  }
  current-&gt;handle_.submitId_ = submitCounter_;
  numAvailableCommandBuffers_--;
  current-&gt;cmdBuf_ = current-&gt;cmdBufAllocated_;
  current-&gt;isEncoding_ = true;</code></pre>
</div>
<ol>
<li>After we have done all the bookkeeping on the library side, we can call the Vulkan API to begin recording the current command buffer:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkCommandBufferBeginInfo bi = {
      .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
      .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT,
  };
  VK_ASSERT(vkBeginCommandBuffer(current-&gt;cmdBuf_, &amp;bi));
  return *current;
}</code></pre>
</div>
<ol>
<li>Before we explore the next series of functions, let’s take a look inside a short helper function, <code>purge()</code>, which was mentioned above in <code>acquire()</code>. This function calls <code>vkWaitForFences()</code> with a Vulkan fence and the <code>timeout</code> value of <code>0</code>, which returns the current status of the fence without waiting. If the fence is signaled, we can reset the command buffer and increment <code>numAvailableCommandBuffers</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void lvk::VulkanImmediateCommands::purge() {
  for (CommandBufferWrapper&amp; buf : buffers_) {
    if (buf.cmdBuf_ == VK_NULL_HANDLE || buf.isEncoding_)
      continue;
    const VkResult result =
      vkWaitForFences(device_, 1, &amp;buf.fence_, VK_TRUE, 0);
    if (result == VK_SUCCESS) {
      VK_ASSERT(vkResetCommandBuffer(
        buf.cmdBuf_, VkCommandBufferResetFlags{0}));
      VK_ASSERT(vkResetFences(device_, 1, &amp;buf.fence_));
      buf.cmdBuf_ = VK_NULL_HANDLE;
      numAvailableCommandBuffers_++;
    }
  }
}</code></pre>
</div>
<p>Another very important function is <code>submit()</code>, which submits a command buffer to a queue. Let’s take a look:</p>
<ol>
<li>First, we should call <code>vkEndCommandBuffer()</code> to finish recording a command buffer.</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>SubmitHandle lvk::VulkanImmediateCommands::submit(
  const CommandBufferWrapper&amp; wrapper) {
  VK_ASSERT(vkEndCommandBuffer(wrapper.cmdBuf_));</code></pre>
</div>
<ol>
<li>Then, we should prepare semaphores. We can set two optional semaphores to be waited on before the GPU processes our command buffer. The first one is the semaphore we inject with the <code>waitSemaphore()</code> function. It can be an “acquire semaphore” from a swapchain or any other user-provided semaphore if we want to organize a frame graph of some sort. The second semaphore, <code>lastSubmitSemaphore_</code>, is the semaphore signaled by a previously submitted command buffer. This ensures that all command buffers are processed sequentially one by one:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkPipelineStageFlags waitStageMasks[] = {
    VK_PIPELINE_STAGE_ALL_COMMANDS_BIT,
    VK_PIPELINE_STAGE_ALL_COMMANDS_BIT };
  VkSemaphore waitSemaphores[] = { VK_NULL_HANDLE, VK_NULL_HANDLE };
  uint32_t numWaitSemaphores = 0;
  if (waitSemaphore_)
    waitSemaphores[numWaitSemaphores++] = waitSemaphore_;
  if (lastSubmitSemaphore_)
    waitSemaphores[numWaitSemaphores++] = lastSubmitSemaphore_;</code></pre>
</div>
<ol>
<li>Once we have all the data in place, a call to <code>vkQueueSubmit()</code> is trivial. We set <code>pSignalSemaphores</code> to the semaphore store in the current <code>CommandBufferWrapper</code> object so that we can wait on it in the next <code>submit()</code> call:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkSubmitInfo si = {
      .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
      .waitSemaphoreCount = numWaitSemaphores,
      .pWaitSemaphores = waitSemaphores,
      .pWaitDstStageMask = waitStageMasks,
      .commandBufferCount = 1u,
      .pCommandBuffers = &amp;wrapper.cmdBuf_,
      .signalSemaphoreCount = 1u,
      .pSignalSemaphores = &amp;wrapper.semaphore_,
  };
  VK_ASSERT(vkQueueSubmit(queue_, 1u, &amp;si, wrapper.fence_));
  lastSubmitSemaphore_ = wrapper.semaphore_;
  lastSubmitHandle_ = wrapper.handle_;</code></pre>
</div>
<ol>
<li>Once the <code>waitSemaphore_</code> object is used, drop it. It should be used only with exactly one command buffer. The submit counter is used to set the <code>submitId</code> value in <code>SubmitHandle</code>. There’s one trick we can do here. <code>SubmitHandle</code> is considered empty when its command buffer and <code>submitId</code> are zero. One easy way to do it is to always skip the zero value of <code>submitCounter</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  waitSemaphore_ = VK_NULL_HANDLE;
  const_cast&lt;CommandBufferWrapper&amp;&gt;(wrapper).isEncoding_ = false;
  submitCounter_++;
  if (!submitCounter_) submitCounter_++;
  return lastSubmitHandle_;
}</code></pre>
</div>
<p>This code is already sufficient to organize command buffer management in an application. However, let’s inspect other methods of <code>VulkanImmediateCommands</code> that make the work with Vulkan fences much easier by hiding them behind <code>SubmitHandle</code>. The next most useful method is <code>isReady()</code>, which is our high-level equivalent of <code>vkWaitForFences()</code>, with the timeout set to <code>0</code>:</p>
<ol>
<li>First, we do a trivial check for an empty submit handle:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>bool VulkanImmediateCommands::isReady(const SubmitHandle handle) const {
  if (handle.empty()) return true;</code></pre>
</div>
<ol>
<li>Then, we inspect an actual command buffer wrapper and check if its command buffer has already been recycled:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const CommandBufferWrapper&amp; buf = buffers_[handle.bufferIndex_];
  if (buf.cmdBuf_ == VK_NULL_HANDLE) return true;</code></pre>
</div>
<ol>
<li>Another situation is when a command buffer has been recycled and then reused again. In this case, <code>submitId</code> values would be different. Only after this comparison can we invoke the Vulkan API to get the status of our <code>VkFence</code> object:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  if (buf.handle_.submitId_ != handle.submitId_)  return true;
  return vkWaitForFences(device_, 1, &amp;buf.fence_, VK_TRUE, 0) ==
    VK_SUCCESS;
}</code></pre>
</div>
<p>This <code>isReady()</code> method provides a simple interface to Vulkan fences that can be exposed to applications using <em>LightweightVK</em>.</p>
<p>There is a pair of similar methods that allow us to wait for command buffers or on a specific handle or <code>VkFence</code>:</p>
<ol>
<li>The first one is <code>wait()</code>, which waits for a single fence to be signaled. There are two important things to mention here. We can detect a wait operation on a not-submitted command buffer using the <code>isEncoding_</code> flag. Also, we call <code>purge()</code> at the end of the function because we are sure there is now at least one command buffer to be reclaimed:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void lvk::VulkanImmediateCommands::wait(const SubmitHandle handle) {
  if (isReady(handle)) return;
  if (!LVK_VERIFY(!buffers_[handle.bufferIndex_].isEncoding_)) return;
  VK_ASSERT(vkWaitForFences(device_, 1, 
    &amp;buffers_[handle.bufferIndex_].fence_, VK_TRUE, UINT64_MAX));
  purge();
}</code></pre>
</div>
<ol>
<li>The second function waits for all command buffers to be completed, which is handy when we want to delete all resources, for example, in the destructor. The implementation is straightforward, and we call <code>purge()</code> again to reclaim all the completed command buffers:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void lvk::VulkanImmediateCommands::waitAll() {
  VkFence fences[kMaxCommandBuffers];
  uint32_t numFences = 0;
  for (const auto&amp; buf : buffers_) {
    if (buf.cmdBuf_ != VK_NULL_HANDLE &amp;&amp; !buf.isEncoding_)
      fences[numFences++] = buf.fence_;
  }
  if (numFences) VK_ASSERT(vkWaitForFences(
    device_, numFences, fences, VK_TRUE, UINT64_MAX));
  purge();
}</code></pre>
</div>
<p>Those are all the details about the low-level implementation. Now, let’s take a look at how this code works with our demo application.</p>
</section>
<section class="level3" data-number="3.6.3" id="how-it-works">
<h3 data-number="3.6.3">How it works…</h3>
<p>Let’s go all the way back to our demo application and its main loop. We call the function <code>VulkanContext::acquireCommandBuffer()</code>, which returns a reference to some high-level interface, <code>lvk::ICommandBuffer</code>. Then, we call <code>VulkanContext::submit()</code> to submit that command buffer:</p>
<div class="C1-SHCodePACKT">
<pre><code>  while (!glfwWindowShouldClose(window)) {
    glfwPollEvents();
    glfwGetFramebufferSize(window, &amp;width, &amp;height);
    if (!width || !height) continue;
    lvk::ICommandBuffer&amp; buf = ctx-&gt;acquireCommandBuffer();
    ctx-&gt;submit(buf, ctx-&gt;getCurrentSwapchainTexture());
  }</code></pre>
</div>
<p>Here’s what is going on inside those functions.</p>
<ol>
<li>The first function, <code>VulkanContext::acquireCommandBuffer()</code>, is very simple. It creates a <code>lvk::CommandBuffer</code> object and returns a referent to it. This object implements the <code>lvk::ICommandBuffer</code> interface:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>ICommandBuffer&amp; VulkanContext::acquireCommandBuffer() {
  LVK_ASSERT_MSG(!pimpl_-&gt;currentCommandBuffer_.ctx_,
    “Cannot acquire more than 1 command buffer simultaneously”);
  pimpl_-&gt;currentCommandBuffer_ = CommandBuffer(this);
  return pimpl_-&gt;currentCommandBuffer_;
}</code></pre>
</div>
<ol>
<li>The function <code>VulkanContext::submit()</code> is more elaborate. Besides submitting a command buffer, it takes an optional argument of a swapchain texture to be presented. We will skip this part here and focus only on the command buffer submission part:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>void VulkanContext::submit(
  const lvk::ICommandBuffer&amp; commandBuffer, TextureHandle present) {
  vulkan::CommandBuffer* vkCmdBuffer =
    const_cast&lt;vulkan::CommandBuffer*&gt;(
      static_cast&lt;const vulkan::CommandBuffer*&gt;(&amp;commandBuffer));
  if (present) {
    // … do proper layout transitioning for the image …
  }</code></pre>
</div>
<ol>
<li>Here, we inject <code>acquireSemaphore_</code> from the swapchain into the <code>VulkanImmediateCommands</code> object so that we wait for it to be signaled before starting rendering:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const bool shouldPresent = hasSwapchain() &amp;&amp; present;
  if (shouldPresent) {
    immediate_-&gt;waitSemaphore(swapchain_-&gt;acquireSemaphore_);
  }</code></pre>
</div>
<ol>
<li>Then, we call the aforementioned <code>VulkanImmediateCommands::submit()</code> and use its last submit semaphore to tell the swapchain to wait until the rendering is completed:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  vkCmdBuffer-&gt;lastSubmitHandle_ =
    immediate_-&gt;submit(*vkCmdBuffer-&gt;wrapper_);
  if (shouldPresent) {
    swapchain_-&gt;present(immediate_-&gt;acquireLastSubmitSemaphore());
  }</code></pre>
</div>
<ol>
<li>On every submit operation, we process so-called deferred tasks. A deferred task is a <code>std::packaged_task</code> that should be run only when an associated <code>SubmitHandle</code> (a.k.a. <code>VkFence</code>) is ready. This mechanism is very helpful to manage or deallocate resources and will be discussed in subsequent chapters:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  processDeferredTasks();
  pimpl_-&gt;currentCommandBuffer_ = {};
}</code></pre>
</div>
<p>Now, we have a working subsystem to wrangle Vulkan command buffers and expose <code>VkFence</code> objects to user applications in a clean and straightforward way. We did not cover the <code>ICommandBuffer</code> interface in this recipe, but we will do it shortly in this chapter while doing our first Vulkan rendering demo. Before we can do rendering, let’s learn how to deal with compiled SPIR-V shaders from the recipe <em>Compiling Vulkan shaders at runtime</em> in <em>Chapter 1</em>.</p>
</section>
<section class="level3" data-number="3.6.4" id="see-also">
<h3 data-number="3.6.4">See also…</h3>
<p>We recommend referring to <em>Vulkan Cookbook</em> by Pawel Lapinski for in-depth coverage of swapchain creation and command queue management.</p>
</section>
</section>
<section class="level2" data-number="3.7" id="initializing-vulkan-shader-modules">
<h2 data-number="3.7">Initializing Vulkan shader modules</h2>
<p>Vulkan API consumes shaders in the form of compiled SPIR-V binaries. In one of the previous recipes in <em>Chapter 1</em>, <em>Compiling Vulkan shaders at runtime</em>, we learned how to compile shaders from GLSL source code to SPIR-V, using the open-source <code>glslang</code> compiler from Khronos. In this recipe, we will learn how to use GLSL shaders and precompiled binaries in Vulkan.</p>
<section class="level3" data-number="3.7.1" id="getting-ready-11">
<h3 data-number="3.7.1">Getting ready</h3>
<p>We recommend reading the recipe <em>Compiling Vulkan shaders at runtime</em> from <em>Chapter 1</em> before you proceed.</p>
</section>
<section class="level3" data-number="3.7.2" id="how-to-do-it...-11">
<h3 data-number="3.7.2">How to do it...</h3>
<p>Let’s take a look at our next demo application, <code>Chapter02/02_HelloTriangle</code>, to learn the high-level <em>LightweightVK</em> API for shader modules. As we will see, there’s a <code>createShaderModule()</code> method in <code>IContext</code> that does the work:</p>
<ol>
<li>Given a pointer to <code>IContext</code>, Vulkan shader modules can be created from GLSL shaders in the following way, where <code>codeVS</code> and <code>codeFS</code> are null-terminated strings holding the vertex and fragment shader source code, respectively. Note that these values are used to initialize a structure passed into <code>createShaderModule()</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>ctx-&gt;createShaderModule(
  { codeVS, lvk::Stage_Vert, “Shader Module: main (vert)” })
ctx-&gt;createShaderModule(
  { codeFS, lvk::Stage_Frag, “Shader Module: main (frag)” })</code></pre>
</div>
<ol>
<li>The first parameter of <code>createShaderModule()</code> is a structure, <code>ShaderModuleDesc</code>, containing all the properties required to create a Vulkan shader module. If the <code>dataSize</code> member field is non-zero, the <code>data</code> field is treated as a binary SPIR-V blob. If <code>dataSize</code> is zero, <code>data</code> is treated as a null-terminated string containing GLSL source code:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>struct ShaderModuleDesc {
  ShaderStage stage = Stage_Frag;
  const char* data = nullptr;
  size_t dataSize = 0;
  const char* debugName = ““;
  ShaderModuleDesc(const char* source, lvk::ShaderStage stage,
    const char* debugName) : stage(stage), data(source),
    debugName(debugName) {}
  ShaderModuleDesc(const void* data, size_t dataLength,
    lvk::ShaderStage stage, const char* debugName) :
    stage(stage), data(static_cast&lt;const char*&gt;(data)),
    dataSize(dataLength), debugName(debugName) {}
};</code></pre>
</div>
<ol>
<li>Inside <code>VulkanContext::createShaderModule()</code>, we do the branching for textual GLSL and binary SPIR-V shaders. An actual <code>VkShaderModule</code> object is stored in a pool, which we will discuss in subsequent chapters:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::Holder&lt;lvk::ShaderModuleHandle&gt;   VulkanContext::createShaderModule(const ShaderModuleDesc&amp; desc)
{
  VkShaderModule sm = desc.dataSize ?
    // binary SPIR-V
    createShaderModule(desc.data, desc.dataSize, desc.debugName) :
    // textual GLSL
    createShaderModule(desc.stage, desc.data, desc.debugName);
  return {this, shaderModulesPool_.create(std::move(sm))};
}</code></pre>
</div>
<ol>
<li>The creation of a Vulkan shader module from a binary SPIR-V blob looks as follows. Error checking is omitted for simplicity:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkShaderModule VulkanContext::createShaderModule(const void* data,
  size_t length, const char* debugName, Result* outResult) const {
  VkShaderModule vkShaderModule = VK_NULL_HANDLE;
  const VkShaderModuleCreateInfo ci = {
      .sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO,
      .codeSize = length,
      .pCode = (const uint32_t*)data,
  };
  vkCreateShaderModule(vkDevice_, &amp;ci, nullptr, &amp;vkShaderModule);
  return vkShaderModule;
}</code></pre>
</div>
<p>Now, Vulkan shader modules are ready to be used inside Vulkan pipelines. Let’s learn how to do so in the next recipe.</p>
</section>
</section>
<section class="level2" data-number="3.8" id="initializing-vulkan-pipelines">
<h2 data-number="3.8">Initializing Vulkan pipelines</h2>
<p>A Vulkan pipeline is an implementation of an abstract graphics pipeline, which is a sequence of operations to transform vertices and rasterize the resulting image. In essence, the idea is similar to a single snapshot of a “frozen” OpenGL state. Vulkan pipelines are mostly immutable, which means multiple Vulkan pipelines should be created to allow different data paths through the graphics pipeline. In this recipe, we will learn how to create a Vulkan pipeline suitable to render a colorful triangle, and we will explore how low-level and verbose Vulkan can be wrapped into a simple high-level interface.</p>
<section class="level3" data-number="3.8.1" id="getting-ready-12">
<h3 data-number="3.8.1">Getting ready</h3>
<p>To get all the basic information about Vulkan pipelines, we recommend reading <em>Vulkan Cookbook</em> by Pawel Lapinski, which was published by Packt, or the <em>Vulkan Tutorial</em> series by Alexander Overvoorde: <a href="https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics/Introduction">https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics/Introduction</a>.</p>
<p>For additional information on descriptor set layouts, check out the chapter at <a href="https://vulkan-tutorial.com/Uniform_buffers/Descriptor_layout_and_buffer">https://vulkan-tutorial.com/Uniform_buffers/Descriptor_layout_and_buffer</a>.</p>
<p>Vulkan pipelines require Vulkan shader modules. Check out the previous recipe, <em>Initializing Vulkan shader modules</em>, before going through this recipe.</p>
</section>
<section class="level3" data-number="3.8.2" id="how-to-do-it...-12">
<h3 data-number="3.8.2">How to do it...</h3>
<p>Let us dive deep into how to create and configure a Vulkan pipeline suitable for our application. Due to the extreme verbosity of Vulkan API, this recipe will be the longest. We will start from the high-level code in our demo application, <code>Chapter02/02_HelloTriangle</code>, and go all the way to the internals of <em>LightweightVK</em>. In the subsequent chapters, we will go into more detail, such as dynamic states, multisampling, vertex input, and others.</p>
<p>Let’s take a look at the initialization and main loop of <code>Chapter02/02_HelloTriangle</code>:</p>
<ol>
<li>First, we create a Vulkan context, as described in the previous recipes:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>std::unique_ptr&lt;lvk::IContext&gt; ctx =
  lvk::createVulkanContextWithSwapchain(window, width, height, {});</code></pre>
</div>
<ol>
<li>Then, we need to create a rendering pipeline. <em>LightweightVK</em> uses opaque handles to work with resources, so here, <code>lvk::RenderPipelineHandle</code> is an opaque handle that manages a collection of <code>VkPipeline</code> objects, and <code>lvk::Holder</code> is an RAII wrapper to automatically dispose of handles that go out of scope. The method <code>createRenderPipeline()</code> accepts a structure, <code>RenderPipelineDesc</code>, that contains data necessary to configure a rendering pipeline. For our first triangle demo, we want to be as minimalistic as possible, so we set vertex and fragment shaders and define the format of a color attachment. This is the absolute minimum we need to render something into a swapchain image:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>lvk::Holder&lt;lvk::RenderPipelineHandle&gt; rpTriangle =
  ctx-&gt;createRenderPipeline({
    .smVert = ctx-&gt;createShaderModule(
      { codeVS, lvk::Stage_Vert, “Shader Module: vert” }).release(),
    .smFrag = ctx-&gt;createShaderModule(
      { codeFS, lvk::Stage_Frag, “Shader Module: frag” }).release(),
    .color  = { { .format = ctx-&gt;getSwapchainFormat() } },
});</code></pre>
</div>
<ol>
<li>Inside the main loop, we acquire a command buffer, as described in the recipe <em>Using Vulkan command buffers</em>, and issue some drawing commands:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>while (!glfwWindowShouldClose(window)) {
  glfwPollEvents();
  glfwGetFramebufferSize(window, &amp;width, &amp;height);
  if (!width || !height) continue;
  lvk::ICommandBuffer&amp; buf = ctx-&gt;acquireCommandBuffer();</code></pre>
</div>
<ol>
<li>The member function <code>cmdBeginRendering()</code> wraps the Vulkan 1.3 dynamic rendering functionality, which enables rendering directly into Vulkan images without explicitly creating any render passes or framebuffer objects. It takes a description of a render pass, <code>lvk::RenderPass</code>, and a description of a framebuffer, <code>lvk::Framebuffer</code>. We will explore it in more detail in subsequent chapters. Here, we use the current swapchain texture as the first color attachment and clear it to while color before rendering, using the attachment load operation <code>LoadOp_Clear</code>, which corresponds to <code>VK_ATTACHMENT_LOAD_OP_CLEAR</code> in Vulkan. The store operation is set to <code>StoreOp_Store</code> by default:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  buf.cmdBeginRendering(
    {.color = {{ .loadOp = LoadOp_Clear, .clearColor = {1,1,1,1}}}},
    {.color = {{ .texture = ctx-&gt;getCurrentSwapchainTexture() }}});</code></pre>
</div>
<ol>
<li>The render pipeline can be bound to the command buffer in one line. Then, we can issue a drawing command, <code>cmdDraw()</code>, which is a wrapper on top of <code>vkCmdDraw()</code>. You may have noticed that we did not use any index or vertex buffers at all. We will see why in a moment when we look at GLSL shaders. The command <code>cmdEndRendering()</code> corresponds to <code>vkCmdEndRendering()</code> from Vulkan 1.3:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  buf.cmdBindRenderPipeline(rpTriangle);
  buf.cmdDraw(lvk::Primitive_Triangle, 0, 3);
  buf.cmdEndRendering();
  ctx-&gt;submit(buf, ctx-&gt;getCurrentSwapchainTexture());
}</code></pre>
</div>
<p>Let’s take a look at the GLSL shaders:</p>
<ol>
<li>As we do not provide any vertex input, the vertex shader has to generate vertex data for a triangle. We use the built-in variable <code>gl_VertexIndex</code>, which gets incremented automatically for every subsequent vertex, returning hardcoded values for positions and vertex colors:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>#version 460
layout (location=0) out vec3 color;
const vec2 pos[3] = vec2[3](
  vec2(-0.6, -0.4), vec2(0.6, -0.4), vec2(0.0, 0.6) );
const vec3 col[3] = vec3[3](
  vec3(1.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), vec3(0.0, 0.0, 1.0) );
void main() {
  gl_Position = vec4(pos[gl_VertexIndex], 0.0, 1.0);
  color = col[gl_VertexIndex];
}</code></pre>
</div>
<ol>
<li>The fragment shader is trivial and just outputs the interpolated color:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>#version 460
layout (location=0) in vec3 color;
layout (location=0) out vec4 out_FragColor;
void main() {
  out_FragColor = vec4(color, 1.0);
}</code></pre>
</div>
<p>The application should render a colorful triangle, as shown in the following figure.</p>
<figure>
<img alt="Figure 2.2: Hello triangle" height="756" src="../media/file12.png" width="1430"/><figcaption aria-hidden="true">Figure 2.2: Hello triangle</figcaption>
</figure>
<p>We learned how to draw a triangle with Vulkan using <em>LightweightVK</em>. It is time to look under the hood and find out how this high-level render pipeline management interface is implemented via Vulkan.</p>
</section>
<section class="level3" data-number="3.8.3" id="how-it-works-1">
<h3 data-number="3.8.3">How it works…</h3>
<p>To explore the underlying Vulkan implementation, we have to peel back a few layers one by one. When we want to create a graphics pipeline in our application, we call the member function <code>IContext::createRenderPipeline()</code>, which is implemented in <code>VulkanContext</code>. This function takes in a structure, <code>lvk::RenderPipelineDesc</code>, which describes our rendering pipeline. Let’s take a closer look at it.</p>
<ol>
<li>The structure contains a subset of information necessary to create a valid graphics <code>VkPipeline</code> object:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>struct RenderPipelineDesc final {
  VertexInput vertexInput;
  ShaderModuleHandle smVert;
  ShaderModuleHandle smGeom;
  ShaderModuleHandle smFrag;
  const char* entryPointVert = “main”;
  const char* entryPointFrag = “main”;
  const char* entryPointGeom = “main”;</code></pre>
</div>
<ol>
<li>The maximum number of color attachments is set to <code>4</code>. We do not store the number of used attachments here. Instead, we use a helper function to calculate how many attachments we actually have:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  ColorAttachment color[LVK_MAX_COLOR_ATTACHMENTS] = {};
  uint32_t getNumColorAttachments() const {
    uint32_t n = 0;
    while (n &lt; LVK_MAX_COLOR_ATTACHMENTS &amp;&amp;       color[n].format != Format_Invalid) n++;
    return n;
  }</code></pre>
</div>
<ol>
<li>Other member fields represent a typical rendering state with a cull mode, face winding, polygon mode, and so on.</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  Format depthFormat = Format_Invalid;
  Format stencilFormat = Format_Invalid;
  CullMode cullMode = lvk::CullMode_None;
  WindingMode frontFaceWinding = lvk::WindingMode_CCW;
  PolygonMode polygonMode = lvk::PolygonMode_Fill;
  StencilState backFaceStencil = {};
  StencilState frontFaceStencil = {};
  uint32_t samplesCount = 1u;
  const char* debugName = ““;
};</code></pre>
</div>
<p>When we call <code>VulkanContext::createRenderPipeline()</code>, all it does is do some sanity checks on <code>RenderPipelineDesc</code> and store all the values in the <code>RenderPipelineState</code> struct. As we already mentioned, <em>LightweightVK</em> pipelines cannot be directly one-to-one mapped to <code>VkPipeline</code> objects. The reason for this is that <code>RenderPipelineDesc</code> provides a more dynamic state than un-extended Vulkan 1.3 can support. For example, <em>LightweightVK</em> manages descriptor set layouts automatically. Vulkan requires a descriptor set layout to be specified for a pipeline object. To lift this limitation, the data stored in <code>RenderPipelineState</code> is used to lazily create actual <code>VkPipeline</code> objects in a function, <code>VulkanContext::getVkPipeline()</code>. Let’s take a look at this mechanism. Error checking and some unimportant details are omitted to simplify understanding:</p>
<ol>
<li>The constructor requires <code>VulkanContext</code> and <code>RenderPipelineDesc</code>. It does some preparation work but does not create actual <code>VkPipeline</code> objects. We will look into its implementation shortly:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>class RenderPipelineState final {
  RenderPipelineDesc desc_;
  uint32_t numBindings_ = 0;
  uint32_t numAttributes_ = 0;</code></pre>
</div>
<ol>
<li>Pre-cache some useful values so that we do not reinitialize them every time we create a new Vulkan pipeline object:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  VkVertexInputBindingDescription
    vkBindings_[VertexInput::LVK_VERTEX_BUFFER_MAX] = {};
  VkVertexInputAttributeDescription
    vkAttributes_[VertexInput::LVK_VERTEX_ATTRIBUTES_MAX] = {};
  VkDescriptorSetLayout lastVkDescriptorSetLayout_ = VK_NULL_HANDLE;
  VkShaderStageFlags shaderStageFlags_ = 0;
  VkPipelineLayout pipelineLayout_ = VK_NULL_HANDLE;
  VkPipeline pipeline_ = VK_NULL_HANDLE;
};</code></pre>
</div>
<p>With all data structures in place, we are now ready to go through the implementation code of <code>VulkanContext::createRenderPipeline()</code>:</p>
<ol>
<li>The constructor iterates over vertex input attributes and pre-caches all necessary data into Vulkan structures for further use:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VulkanContext::createRenderPipeline(
  const RenderPipelineDesc&amp; desc, Result* outResult)
{
  const bool hasColorAttachments = desc.getNumColorAttachments() &gt; 0;
  const bool hasDepthAttachment = desc.depthFormat != Format_Invalid;
  const bool hasAnyAttachments =
    hasColorAttachments || hasDepthAttachment;
  if (!LVK_VERIFY(hasAnyAttachments)) return {};
  if (!LVK_VERIFY(desc.smVert.valid())) return {};
  if (!LVK_VERIFY(desc.smFrag.valid())) return {};
  RenderPipelineState rps = {.desc_ = desc};</code></pre>
</div>
<ol>
<li>Iterate and cache the vertex input bindings and attributes. Vertex buffer bindings are tracked in <code>bufferAlreadyBound</code>. Everything else is very trivial conversion code from our high-level data structures to Vulkan:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const lvk::VertexInput&amp; vstate = rps.desc_.vertexInput;
  bool bufferAlreadyBound[VertexInput::LVK_VERTEX_BUFFER_MAX] = {};
  rps.numAttributes_ = vstate.getNumAttributes();
  for (uint32_t i = 0; i != rps.numAttributes_; i++) {
    const auto&amp; attr = vstate.attributes[i];
    rps.vkAttributes_[i] = { .location = attr.location,
                             .binding = attr.binding,
                             .format =
                               vertexFormatToVkFormat(attr.format),
                             .offset = (uint32_t)attr.offset };
    if (!bufferAlreadyBound[attr.binding]) {
      bufferAlreadyBound[attr.binding] = true;
      rps.vkBindings_[rps.numBindings_++] = {
        .binding = attr.binding,
        .stride = vstate.inputBindings[attr.binding].stride,
        .inputRate = VK_VERTEX_INPUT_RATE_VERTEX };
    }
  }
  return {this, renderPipelinesPool_.create(std::move(rps))};
}</code></pre>
</div>
<p>Now, we can create actual Vulkan pipelines. Well, almost. A couple of very long code snippets await us. These are the longest functions in the entire book, but we have to go through them at least once. That said, error checking is skipped to simplify things a bit:</p>
<ol>
<li>The <code>getVkPipeline()</code> function retrieves a <code>RenderPipelineState</code> struct associated with a provided pipeline handle:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkPipeline VulkanContext::getVkPipeline(RenderPipelineHandle handle)
{
  lvk::RenderPipelineState* rps = renderPipelinesPool_.get(handle);
  if (!rps) return VK_NULL_HANDLE;</code></pre>
</div>
<ol>
<li>Then, we check if a descriptor set layout used to create a pipeline layout for this <code>VkPipeline</code> object has changed. Our implementation uses descriptor indexing to manage all textures in a huge descriptor set and creates a descriptor set layout to store all the textures. Once new textures are loaded, there might not be enough space to store them, and a new descriptor set layout would have to be created. Every time this happens, we have to delete the old <code>VkPipeline</code> and <code>VkPipelineLayout</code> objects and create new ones:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  if (rps-&gt;lastVkDescriptorSetLayout_ != vkDSL_) {
    deferredTask(std::packaged_task&lt;void()&gt;(
      [device = getVkDevice(), pipeline = rps-&gt;pipeline_]() {
        vkDestroyPipeline(device, pipeline, nullptr); }));
    deferredTask(std::packaged_task&lt;void()&gt;(
      [device = getVkDevice(), layout = rps-&gt;pipelineLayout_]() {
        vkDestroyPipelineLayout(device, layout, nullptr); }));
    rps-&gt;pipeline_ = VK_NULL_HANDLE;
    rps-&gt;lastVkDescriptorSetLayout_ = vkDSL_;
  }</code></pre>
</div>
<ol>
<li>If there is already a valid graphics pipeline compatible with the current descriptor set layout, we can just return it:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  if (rps-&gt;pipeline_ != VK_NULL_HANDLE) {
    return rps-&gt;pipeline_;
  }</code></pre>
</div>
<ol>
<li>Let’s prepare to build a new Vulkan pipeline object. Not all color attachments are valid. We need to create color blend attachments only for active color attachments. Helper functions, such as <code>formatToVkFormat()</code>, convert <em>LightweightVK</em> enumerations to Vulkan:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  VkPipelineLayout layout = VK_NULL_HANDLE;
  VkPipeline pipeline = VK_NULL_HANDLE;
  const RenderPipelineDesc&amp; desc = rps-&gt;desc_;
  const uint32_t numColorAttachments = desc_.getNumColorAttachments();
  VkPipelineColorBlendAttachmentState
    colorBlendAttachmentStates[LVK_MAX_COLOR_ATTACHMENTS] = {};
  VkFormat colorAttachmentFormats[LVK_MAX_COLOR_ATTACHMENTS] = {};
  for (uint32_t i = 0; i != numColorAttachments; i++) {
    const auto&amp; attachment = desc_.color[i];
    colorAttachmentFormats[i] = formatToVkFormat(attachment.format);</code></pre>
</div>
<ol>
<li>Setting up blending states for color attachments is tedious but very simple:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>    if (!attachment.blendEnabled) {
      colorBlendAttachmentStates[i] =
        VkPipelineColorBlendAttachmentState{
          .blendEnable = VK_FALSE,
          .srcColorBlendFactor = VK_BLEND_FACTOR_ONE,
          .dstColorBlendFactor = VK_BLEND_FACTOR_ZERO,
          .colorBlendOp = VK_BLEND_OP_ADD,
          .srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE,
          .dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO,
          .alphaBlendOp = VK_BLEND_OP_ADD,
          .colorWriteMask = VK_COLOR_COMPONENT_R_BIT |
                            VK_COLOR_COMPONENT_G_BIT |
                            VK_COLOR_COMPONENT_B_BIT |
                            VK_COLOR_COMPONENT_A_BIT,
      };
    } else {
      colorBlendAttachmentStates[i] =
        VkPipelineColorBlendAttachmentState{
          .blendEnable = VK_TRUE,
          .srcColorBlendFactor = blendFactorToVkBlendFactor(
            attachment.srcRGBBlendFactor),
          .dstColorBlendFactor = blendFactorToVkBlendFactor(
            attachment.dstRGBBlendFactor),
          .colorBlendOp = blendOpToVkBlendOp(attachment.rgbBlendOp),
          .srcAlphaBlendFactor = blendFactorToVkBlendFactor(
            attachment.srcAlphaBlendFactor),
          .dstAlphaBlendFactor = blendFactorToVkBlendFactor(
            attachment.dstAlphaBlendFactor),
          .alphaBlendOp = blendOpToVkBlendOp(attachment.alphaBlendOp),
          .colorWriteMask = VK_COLOR_COMPONENT_R_BIT |
                            VK_COLOR_COMPONENT_G_BIT | 
                            VK_COLOR_COMPONENT_B_BIT |
                            VK_COLOR_COMPONENT_A_BIT,
      };
    }
  }</code></pre>
</div>
<ol>
<li>Retrieve <code>VkShaderModule</code> objects from the pool using opaque handles. We will discuss how pools work in the next chapters. Here, all we have to know is that they allow fast conversion of an integer handle into the actual data associated with it. The geometry shader is optional:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkShaderModule* vert =
    ctx_-&gt;shaderModulesPool_.get(desc_.smVert);
  const VkShaderModule* geom =
    ctx_-&gt;shaderModulesPool_.get(desc_.smGeom);
  const VkShaderModule* frag =
    ctx_-&gt;shaderModulesPool_.get(desc_.smFrag);</code></pre>
</div>
<ol>
<li>Prepare a <code>VkSpecializationInfo</code> structure to describe specialization constants for this graphics pipeline:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  VkSpecializationMapEntry entries[
    SpecializationConstantDesc::LVK_SPECIALIZATION_CONSTANTS_MAX] ={};
  const VkSpecializationInfo si =
    lvk::getPipelineShaderStageSpecializationInfo(
      desc.specInfo, entries);</code></pre>
</div>
<ol>
<li>Create a suitable <code>VkPipelineLayout</code> object for this pipeline. Use the current descriptor set layout stored in <code>VulkanContext</code>. Here, one descriptor set layout, <code>vkDSL_</code>, is duplicated multiple times to create a pipeline layout. This is necessary to ensure compatibility with MoltenVK, which does not allow the aliasing of different descriptor types. Push constant sizes are retrieved from precompiled shader modules:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>    const VkDescriptorSetLayout dsls[] =
      { vkDSL_, vkDSL_, vkDSL_, vkDSL_ };
    const VkPushConstantRange range = {
      .stageFlags = rps-&gt;shaderStageFlags_,
      .offset = 0,
      .size = pushConstantsSize,
    };
    const VkPipelineLayoutCreateInfo ci = {
      .sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO,
      .setLayoutCount = (uint32_t)LVK_ARRAY_NUM_ELEMENTS(dsls),
      .pSetLayouts = dsls,
      .pushConstantRangeCount = pushConstantsSize ? 1u : 0u,
      .pPushConstantRanges = pushConstantsSize ? &amp;range : nullptr,
  };
  VK_ASSERT(vkCreatePipelineLayout(vkDevice_, &amp;ci, nullptr, &amp;layout));</code></pre>
</div>
<p>Here’s a snippet to retrieve push constant sizes from shader modules:</p>
<div class="C1-SHCodePACKT">
<pre><code>#define UPDATE_PUSH_CONSTANT_SIZE(sm, bit) if (sm) { \
  pushConstantsSize = std::max(pushConstantsSize,    \
  sm-&gt;pushConstantsSize);                            \
  rps-&gt;shaderStageFlags_ |= bit; }
rps-&gt;shaderStageFlags_ = 0;
uint32_t pushConstantsSize = 0;
UPDATE_PUSH_CONSTANT_SIZE(vertModule, VK_SHADER_STAGE_VERTEX_BIT);
UPDATE_PUSH_CONSTANT_SIZE(tescModule,
  VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT);
UPDATE_PUSH_CONSTANT_SIZE(teseModule,
  VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT);
UPDATE_PUSH_CONSTANT_SIZE(geomModule, VK_SHADER_STAGE_GEOMETRY_BIT);
UPDATE_PUSH_CONSTANT_SIZE(fragModule, VK_SHADER_STAGE_FRAGMENT_BIT);
#undef UPDATE_PUSH_CONSTANT_SIZE</code></pre>
</div>
<ol>
<li>As we peel back more and more implementation layers, here is yet another level to peel. However, it is the last one. For convenience, the creation of actual <code>VkPipeline</code> objects is encapsulated into <code>VulkanPipelineBuilder</code>, which provides reasonable default values for all the numerous Vulkan data members that we do not want to set. Those familiar with Java will recognize some form of a typical <em>Builder</em> design pattern:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  lvk::vulkan::VulkanPipelineBuilder()
      // from Vulkan 1.0
      .dynamicState(VK_DYNAMIC_STATE_VIEWPORT)
      .dynamicState(VK_DYNAMIC_STATE_SCISSOR)
      .dynamicState(VK_DYNAMIC_STATE_DEPTH_BIAS)
      .dynamicState(VK_DYNAMIC_STATE_BLEND_CONSTANTS)
      // from Vulkan 1.3 
      .dynamicState(VK_DYNAMIC_STATE_DEPTH_TEST_ENABLE)
      .dynamicState(VK_DYNAMIC_STATE_DEPTH_WRITE_ENABLE)
      .dynamicState(VK_DYNAMIC_STATE_DEPTH_COMPARE_OP)
      .dynamicState(VK_DYNAMIC_STATE_DEPTH_BIAS_ENABLE)
      .primitiveTopology(dynamicState.getTopology())
      .depthBiasEnable(dynamicState.depthBiasEnable_)
      .depthCompareOp(dynamicState.getDepthCompareOp())
      .depthWriteEnable(dynamicState.depthWriteEnable_)
      .rasterizationSamples(
        getVulkanSampleCountFlags(desc_.samplesCount))
      .polygonMode(polygonModeToVkPolygonMode(desc_.polygonMode))
      .stencilStateOps(VK_STENCIL_FACE_FRONT_BIT,
        stencilOpToVkStencilOp(
          desc_.frontFaceStencil.stencilFailureOp),
        stencilOpToVkStencilOp(
          desc_.frontFaceStencil.depthStencilPassOp),
        stencilOpToVkStencilOp(
          desc_.frontFaceStencil.depthFailureOp),
        compareOpToVkCompareOp(
          desc_.frontFaceStencil.stencilCompareOp))
      .stencilStateOps(VK_STENCIL_FACE_BACK_BIT,
        stencilOpToVkStencilOp(
          desc_.backFaceStencil.stencilFailureOp),
        stencilOpToVkStencilOp(
          desc_.backFaceStencil.depthStencilPassOp),
        stencilOpToVkStencilOp(
          desc_.backFaceStencil.depthFailureOp),
        compareOpToVkCompareOp(
          desc_.backFaceStencil.stencilCompareOp))
      .stencilMasks(VK_STENCIL_FACE_FRONT_BIT, 0xFF,
        desc_.frontFaceStencil.writeMask,
        desc_.frontFaceStencil.readMask)
      .stencilMasks(VK_STENCIL_FACE_BACK_BIT, 0xFF,
        desc_.backFaceStencil.writeMask,
        desc_.backFaceStencil.readMask)</code></pre>
</div>
<ol>
<li>Shader modules are provided one by one. Only a vertex and a fragment shader are mandatory:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>      .shaderStage(lvk::getPipelineShaderStageCreateInfo(
        VK_SHADER_STAGE_VERTEX_BIT,
        vertModule-&gt;sm, desc.entryPointVert, &amp;si))
      .shaderStage(lvk::getPipelineShaderStageCreateInfo(
        VK_SHADER_STAGE_FRAGMENT_BIT,
        fragModule-&gt;sm, desc.entryPointFrag, &amp;si))
      .shaderStage(geomModule ? lvk::getPipelineShaderStageCreateInfo(
        VK_SHADER_STAGE_GEOMETRY_BIT,
        geomModule-&gt;sm, desc.entryPointGeom, &amp;si)
        : VkPipelineShaderStageCreateInfo{.module = VK_NULL_HANDLE})
      .cullMode(cullModeToVkCullMode(desc_.cullMode))
      .frontFace(windingModeToVkFrontFace(desc_.frontFaceWinding))
      .vertexInputState(vertexInputStateCreateInfo_)
      .colorBlendAttachmentStates(colorBlendAttachmentStates)
      .colorAttachmentFormats(colorAttachmentFormats)
      .depthAttachmentFormat(formatToVkFormat(desc_.depthFormat))
      .stencilAttachmentFormat(formatToVkFormat(desc_.stencilFormat))</code></pre>
</div>
<ol>
<li>Finally, we call the <code>VulkanPipelineBuilder::build()</code> method, which creates a <code>VkPipeline</code> object that we can store in our <code>RenderPipelineState</code> structure, together with the pipeline layout:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>      .build(
        vkDevice_, pipelineCache_, layout, &amp;pipeline, desc.debugName);
  rps-&gt;pipeline_ = pipeline;
  rps-&gt;pipelineLayout_ = layout;
  return pipeline;
}</code></pre>
</div>
<p>The last method we want to explore here is <code>VulkanPipelineBuilder::build()</code>, which is pure Vulkan. Let’s take a look at it to conclude the pipeline creation process:</p>
<ol>
<li>First, we put the provided dynamic states into <code>VkPipelineDynamicStateCreateInfo</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>VkResult VulkanPipelineBuilder::build(VkDevice device,
                                      VkPipelineCache pipelineCache,
                                      VkPipelineLayout pipelineLayout,
                                      VkPipeline* outPipeline,
                                      const char* debugName)
{
  const VkPipelineDynamicStateCreateInfo dynamicState = {
      .sType = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO,
      .dynamicStateCount = (uint32_t)dynamicStates_.size(),
      .pDynamicStates = dynamicStates_.data(),
  };</code></pre>
</div>
<ol>
<li>The Vulkan specifications say that the viewport and scissor can be <code>nullptr</code> if the viewport and scissor states are dynamic. We are definitely happy to make the most of this opportunity:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkPipelineViewportStateCreateInfo viewportState = {
      .sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO,
      .viewportCount = 1,
      .pViewports = nullptr,
      .scissorCount = 1,
      .pScissors = nullptr,
  };</code></pre>
</div>
<ol>
<li>Use the color blend states and attachments that we prepared earlier in this recipe:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkPipelineColorBlendStateCreateInfo colorBlendState = {
      .sType =
        VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO,
      .logicOpEnable = VK_FALSE,
      .logicOp = VK_LOGIC_OP_COPY,
      .attachmentCount = uint32_t(colorBlendAttachmentStates_.size()),
      .pAttachments = colorBlendAttachmentStates_.data(),
  };
  const VkPipelineRenderingCreateInfo renderingInfo = {
      .sType = VK_STRUCTURE_TYPE_PIPELINE_RENDERING_CREATE_INFO_KHR,
      .pNext = nullptr,
      .colorAttachmentCount =
        (uint32_t)colorAttachmentFormats_.size(),
      .pColorAttachmentFormats = colorAttachmentFormats_.data(),
      .depthAttachmentFormat = depthAttachmentFormat_,
      .stencilAttachmentFormat = stencilAttachmentFormat_,
  };</code></pre>
</div>
<ol>
<li>Put everything together into <code>VkGraphicsPipelineCreateInfo</code> and call <code>vkCreateGraphicsPipelines()</code>:</li>
</ol>
<div class="C1-SHCodePACKT">
<pre><code>  const VkGraphicsPipelineCreateInfo ci = {
      .sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO,
      .pNext = &amp;renderingInfo,
      .flags = 0,
      .stageCount = (uint32_t)shaderStages_.size(),
      .pStages = shaderStages_.data(),
      .pVertexInputState = &amp;vertexInputState_,
      .pInputAssemblyState = &amp;inputAssembly_,
      .pTessellationState = nullptr,
      .pViewportState = &amp;viewportState,
      .pRasterizationState = &amp;rasterizationState_,
      .pMultisampleState = &amp;multisampleState_,
      .pDepthStencilState = &amp;depthStencilState_,
      .pColorBlendState = &amp;colorBlendState,
      .pDynamicState = &amp;dynamicState,
      .layout = pipelineLayout,
      .renderPass = VK_NULL_HANDLE,
      .subpass = 0,
      .basePipelineHandle = VK_NULL_HANDLE,
      .basePipelineIndex = -1,
  };
  const auto result = vkCreateGraphicsPipelines(
    device, pipelineCache, 1, &amp;ci, nullptr, outPipeline);
  numPipelinesCreated_++;
}</code></pre>
</div>
<p>This code concludes the pipeline creation process. Besides the very simple example, <code>Chapter02/02_HelloTriangle</code>, we created a slightly more elaborate app to demonstrate how to use multiple render pipelines, rendering a rotating cube with a wireframe overlay that uses the GLM library for matrix math. Check it out in <code>Chapter02/03_GLM</code>, and see how it uses <code>cmdPushConstants()</code> to animate the cube. It should look like the following screenshot.</p>
<figure>
<img alt="Figure 2.3: GLM usage example" height="756" src="../media/file13.png" width="1430"/><figcaption aria-hidden="true">Figure 2.3: GLM usage example</figcaption>
</figure>
</section>
<section class="level3" data-number="3.8.4" id="theres-more-1">
<h3 data-number="3.8.4">There’s more…</h3>
<p>If you are familiar with older versions of Vulkan, you might have noticed that in this recipe, we completely left out any references to render passes. They are also not mentioned in any of the data structures. The reason for this is that we use Vulkan 1.3’s dynamic rendering functionality, which allows <code>VkPipeline</code> objects to not require a render pass.</p>
<p>If you want to implement a similar wrapper for older versions of Vulkan without using the <em>VK_KHR_dynamic_rendering</em> extension, you can maintain a “global” collection of render passes in an array inside <code>VulkanContext</code> and add an integer index of a corresponding render pass as a data member to <code>RenderPipelineDynamicState</code>. Since we can use only a very restricted number of distinct rendering passes—let’s say a maximum of 256—the index can be saved as <code>uint8_t</code>. This would enable the hash key to remain within the <code>uint32_t</code> size.</p>
<p>If you want to explore an actual working implementation of this approach, take a look at Meta’s IGL library at <a href="https://github.com/facebook/igl/blob/main/src/igl/vulkan/RenderPipelineState.h">https://github.com/facebook/igl/blob/main/src/igl/vulkan/RenderPipelineState.h</a>, and check out how <code>renderPassIndex</code> is handled there.</p>
<p>Now, let’s jump to the next chapter, <em>Working with Vulkan objects</em>, to learn how to use Vulkan in a user-friendly way to build more interesting examples.</p>
</section>
</section>
</section>
</div></body>
</html>