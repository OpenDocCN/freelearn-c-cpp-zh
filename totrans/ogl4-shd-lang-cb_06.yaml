- en: Image Processing and Screen Space Techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像处理和屏幕空间技术
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Applying an edge detection filter
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用边缘检测过滤器
- en: Applying a Gaussian blur filter
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用高斯模糊过滤器
- en: Implementing HDR lighting with tone mapping
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用色调映射实现HDR照明
- en: Creating a bloom effect
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建辉光效果
- en: Using gamma correction to improve image quality
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用伽玛校正提高图像质量
- en: Using multisample anti-aliasing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多采样抗锯齿
- en: Using deferred shading
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用延迟着色
- en: Screen space ambient occlusion
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 屏幕空间环境遮挡
- en: Configuring the depth test
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置深度测试
- en: Implementing order-independent transparency
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现无序透明度
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In this chapter, we will focus on techniques that work directly with the pixels
    in a framebuffer. These techniques typically involve multiple passes. An initial
    pass produces the pixel data and subsequent passes apply effects or further processes
    those pixels. To implement this, we often make use of the ability provided in
    OpenGL for rendering directly to a texture or set of textures (refer to the *Rendering
    to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于直接与帧缓冲区中的像素工作的技术。这些技术通常涉及多个遍历。初始遍历生成像素数据，后续遍历应用效果或进一步处理这些像素。为了实现这一点，我们经常利用OpenGL提供的直接渲染到纹理或纹理集的能力（参考第5章的*渲染到纹理*食谱，*使用纹理*）。
- en: The ability to render to a texture, combined with the power of the fragment
    shader, opens up a huge range of possibilities. We can implement image processing
    techniques such as brightness, contrast, saturation, and sharpness by applying
    an additional process in the fragment shader prior to output. We can apply **convolution**
    filters such as edge detection, smoothing (blur), or sharpening. We'll take a
    closer look at convolution filters in the recipe on edge detection.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 能够将渲染输出到纹理，结合片段着色器的强大功能，开辟了巨大的可能性。我们可以在输出之前在片段着色器中应用额外的过程来实现图像处理技术，如亮度、对比度、饱和度和锐度。我们可以应用**卷积**过滤器，如边缘检测、平滑（模糊）或锐化。我们将在边缘检测食谱中更详细地了解卷积过滤器。
- en: A related set of techniques involves rendering additional information to textures
    beyond the traditional color information and then, in a subsequent pass, further
    processing that information to produce the final rendered image. These techniques
    fall under the general category that is often called **deferred shading**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一组相关的技术涉及将额外的信息渲染到纹理中，这些信息超出了传统的颜色信息，然后在后续遍历中进一步处理这些信息以生成最终的渲染图像。这些技术属于通常被称为**延迟着色**的通用类别。
- en: In this chapter, we'll look at some examples of each of the preceding techniques.
    We'll start off with examples of convolution filters for edge detection, blur,
    and bloom. Then, we'll move on to the important topics of gamma correction and
    multisample anti-aliasing. Finally, we'll finish with a full example of deferred
    shading.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将查看前面提到的每种技术的示例。我们将从边缘检测、模糊和辉光卷积过滤器的示例开始。然后，我们将转向重要的伽玛校正和多采样抗锯齿主题。最后，我们将以延迟着色的完整示例结束。
- en: Most of the recipes in this chapter involve multiple passes. In order to apply
    a filter that operates on the pixels of the final rendered image, we start by
    rendering the scene to an intermediate buffer (a texture). Then, in a final pass,
    we render the texture to the screen by drawing a single fullscreen quad, applying
    the filter in the process. You'll see several variations on this theme in the
    following recipes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的大多数食谱都涉及多个遍历。为了应用一个作用于最终渲染图像像素的过滤器，我们首先将场景渲染到一个中间缓冲区（一个纹理）。然后，在最终遍历中，我们通过绘制一个全屏四边形并将纹理渲染到屏幕上，在这个过程中应用过滤器。你将在接下来的食谱中看到这个主题的几个变体。
- en: Applying an edge detection filter
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用边缘检测过滤器
- en: '**Edge detection** is an image processing technique that identifies regions
    where there is a significant change in the brightness of the image. It provides
    a way to detect the boundaries of objects and changes in the topology of the surface.
    It has applications in the field of computer vision, image processing, image analysis,
    and image pattern recognition. It can also be used to create some visually interesting
    effects. For example, it can make a 3D scene look similar to a 2D pencil sketch,
    as shown in the following image. To create this image, a teapot and torus were
    rendered normally, and then an edge detection filter was applied in a second pass:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**边缘检测**是一种图像处理技术，它识别图像亮度发生显著变化的区域。它提供了一种检测物体边界和表面拓扑变化的方法。它在计算机视觉、图像处理、图像分析和图像模式识别领域有应用。它还可以用于创建一些视觉上有趣的效果。例如，它可以使3D场景看起来类似于2D铅笔素描，如下面的图像所示。为了创建此图像，一个茶壶和一个环面被正常渲染，然后在第二次遍历中应用了边缘检测滤波器：'
- en: '![](img/9eef129b-0de4-4aab-addf-f86a80d9aa4e.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9eef129b-0de4-4aab-addf-f86a80d9aa4e.png)'
- en: 'The edge detection filter that we''ll use here involves the use of a convolution
    filter, or convolution kernel (also called a **filter kernel**). A convolution
    filter is a matrix that defines how to transform a pixel by replacing it with
    the sum of the products between the values of nearby pixels and a set of pre-determined
    weights. As a simple example, consider the following convolution filter:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的边缘检测滤波器涉及使用卷积滤波器，或卷积核（也称为**滤波器核**）。卷积滤波器是一个矩阵，它定义了如何通过用附近像素的值与一组预定的权重之间的乘积之和来替换像素。作为一个简单的例子，考虑以下卷积滤波器：
- en: '![](img/3e329a4b-f800-4746-a66e-3fcd27c13cb8.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3e329a4b-f800-4746-a66e-3fcd27c13cb8.png)'
- en: The 3 x 3 filter is shaded in gray, superimposed over a hypothetical grid of
    pixels. The numbers in bold represent the values of the filter kernel (weights),
    and the non-bold values are the pixel values. The values of the pixels could represent
    grayscale intensity or the value of one of the RGB components. Applying the filter
    to the center pixel in the gray area involves multiplying the corresponding cells
    together and summing the results. The result would be the new value for the center
    pixel (**25**). In this case, the value would be (*17 + 19 + 2 * 25 + 31 + 33*),
    or 150.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 3 x 3 滤波器以灰色阴影显示，叠加在一个假设的像素网格上。粗体数字代表滤波器核（权重）的值，非粗体值是像素值。像素的值可以代表灰度强度或RGB组件中的一个值。将滤波器应用于灰色区域的中心像素涉及将相应的单元格相乘并求和结果。结果将是中心像素的新值（**25**）。在这种情况下，该值将是（*17
    + 19 + 2 * 25 + 31 + 33*），或150。
- en: Of course, in order to apply a convolution filter, we need access to the pixels
    of the original image and a separate buffer to store the results of the filter.
    We'll achieve this here by using a two-pass algorithm. In the first pass, we'll
    render the image to a texture, and then in the second pass, we'll apply the filter
    by reading from the texture and send the filtered results to the screen.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，为了应用卷积滤波器，我们需要访问原始图像的像素以及一个单独的缓冲区来存储滤波器的结果。在这里，我们将通过使用两遍算法来实现这一点。在第一遍中，我们将图像渲染到纹理中，然后在第二遍中，我们将通过从纹理中读取并发送过滤后的结果到屏幕来应用滤波器。
- en: One of the simplest convolution-based techniques for edge detection is the so-called
    **Sobel operator**. The Sobel operator is designed to approximate the gradient
    of the image intensity at each pixel. It does so by applying two 3 x 3 filters.
    The results of the two are the vertical and horizontal components of the gradient.
    We can then use the magnitude of the gradient as our edge trigger. When the magnitude
    of the gradient is above a certain threshold, we assume that the pixel is on an
    edge.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘检测中最简单的基于卷积的技术之一是所谓的**Sobel算子**。Sobel算子旨在近似每个像素处的图像强度梯度。它是通过应用两个 3 x 3 滤波器来做到这一点的。这两个滤波器的结果是梯度的垂直和水平分量。然后我们可以使用梯度的幅度作为我们的边缘触发器。当梯度的幅度超过某个阈值时，我们假设该像素位于边缘上。
- en: 'The 3 x 3 filter kernels used by the Sobel operator are shown in the following
    equation:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Sobel算子使用的 3 x 3 滤波器核在以下方程中显示：
- en: '![](img/e867208d-05ba-4cd1-aad4-3e340f580e28.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e867208d-05ba-4cd1-aad4-3e340f580e28.png)'
- en: 'If the result of applying *S[x]* is *s[x]* and the result of applying *S[y]*
    is *s[y]*, then an approximation of the magnitude of the gradient is given by
    the following equation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用 *S[x]* 的结果是 *s[x]*，应用 *S[y]* 的结果是 *s[y]*，那么梯度的近似大小由以下方程给出：
- en: '![](img/3e91beb5-9542-4843-b4fc-c2b8623d842c.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3e91beb5-9542-4843-b4fc-c2b8623d842c.png)'
- en: If the value of *g* is above a certain threshold, we consider the pixel to be
    an edge pixel and we highlight it in the resulting image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*g*的值高于某个阈值，我们认为该像素是边缘像素，并在结果图像中突出显示它。
- en: In this example, we'll implement this filter as the second pass of a two-pass
    algorithm. In the first pass, we'll render the scene using an appropriate lighting
    model, but we'll send the result to a texture. In the second pass, we'll render
    the entire texture as a screen-filling quad, and apply the filter to the texture.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将实现此滤波器作为两遍算法的第二遍。在第一遍中，我们将使用适当的照明模型渲染场景，但将结果发送到纹理。在第二遍中，我们将整个纹理作为填充屏幕的四边形渲染，并将滤波器应用于纹理。
- en: Getting ready
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Set up a framebuffer object (refer to the *Rendering to a texture* recipe in
    [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml), *Using Textures*) that
    has the same dimensions as the main window. Connect the first color attachment
    of the FBO to a texture object in texture unit zero. During the first pass, we'll
    render directly to this texture. Make sure that the `mag` and `min` filters for
    this texture are set to `GL_NEAREST`. We don't want any interpolation for this
    algorithm.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个与主窗口具有相同维度的帧缓冲区对象（参考[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)，*使用纹理*中的*将渲染输出到纹理*配方），将FBO的第一个颜色附加连接到纹理单元零中的纹理对象。在第一遍中，我们将直接渲染到这个纹理。确保此纹理的`mag`和`min`过滤器设置为`GL_NEAREST`。我们不希望此算法有任何插值。
- en: Provide vertex information in vertex attribute zero, normals in vertex attribute
    one, and texture coordinates in vertex attribute two.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶点属性零中提供顶点信息，在顶点属性一中提供法线，在顶点属性二中提供纹理坐标。
- en: 'The following uniform variables need to be set from the OpenGL application:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下统一变量需要从OpenGL应用程序中设置：
- en: '`Width`: This is used to set the width of the screen window in pixels'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Width`：用于设置屏幕窗口的宽度（以像素为单位）'
- en: '`Height`: This is used to set the height of the screen window in pixels'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Height`：用于设置屏幕窗口的高度（以像素为单位）'
- en: '`EdgeThreshold`: This is the minimum value of `g` squared required to be considered
    *on an edge*'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EdgeThreshold`：这是被认为在边缘上的`g`平方的最小值'
- en: '`RenderTex`: This is the texture associated with the FBO'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RenderTex`：这是与FBO关联的纹理'
- en: Any other uniforms associated with the shading model should also be set from
    the OpenGL application.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与着色模型关联的任何其他统一变量也应从OpenGL应用程序中设置。
- en: How to do it...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To create a shader program that applies the Sobel edge detection filter, perform
    the following steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个应用Sobel边缘检测滤波器的着色器程序，请执行以下步骤：
- en: The vertex shader just converts the position and normal to camera coordinates
    and passes them along to the fragment shader.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顶点着色器仅将位置和法线转换为相机坐标，并将它们传递给片段着色器。
- en: 'The fragment shader applies the reflection model in the first pass, and applies
    the edge detection filter in the second pass:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 片段着色器在第一遍中应用反射模型，在第二遍中应用边缘检测滤波器：
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the render function of your OpenGL application, follow these steps for pass
    #1:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的OpenGL应用程序的渲染函数中，对于遍数#1，遵循以下步骤：
- en: Select FBO, and clear the color/depth buffers
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择FBO，并清除颜色/深度缓冲区
- en: Set the `Pass` uniform to `1`
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Pass`统一变量设置为`1`
- en: Set up the model, view, and projection matrices, and draw the scene
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置模型、视图和投影矩阵，并绘制场景
- en: 'For pass #2, carry out the following steps:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于遍数#2，执行以下步骤：
- en: Deselect the FBO (revert to the default framebuffer) and clear the color/depth
    buffers
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取消选择FBO（恢复到默认帧缓冲区）并清除颜色/深度缓冲区
- en: Set the `Pass` uniform to `2`
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Pass`统一变量设置为`2`
- en: Set the model, view, and projection matrices to the identity matrix
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型、视图和投影矩阵设置为单位矩阵
- en: Draw a single quad (or two triangles) that fills the screen (-1 to +1 in *x*
    and *y*), with texture coordinates that range from 0 to 1 in each dimension.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制一个填充屏幕的单个四边形（或两个三角形）（在*x*和*y*方向上为-1到+1），每个维度的纹理坐标从0到1。
- en: How it works...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The first pass renders all of the scene's geometry of sending the output to
    a texture. We select the function `pass1`, which simply computes and applies the
    Blinn-Phong reflection model (refer to [Chapter 3](74703f9d-f69a-4b08-bb38-6e1066371207.xhtml),
    *The Basics of GLSL Shaders*).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 第一遍渲染场景的所有几何形状并将输出发送到纹理。我们选择`pass1`函数，该函数简单地计算并应用Blinn-Phong反射模型（参考[第3章](74703f9d-f69a-4b08-bb38-6e1066371207.xhtml)，*GLSL着色器基础*）。
- en: In the second pass, we select the function `pass2`, and render only a single
    quad that covers the entire screen. The purpose of this is to invoke the fragment
    shader once for every pixel in the image. In the `pass2` function, we retrieve
    the values of the eight neighboring pixels of the texture containing the results
    from the first pass, and compute their brightness by calling the `luminance` function.
    The horizontal and vertical Sobel filters are then applied and the results are
    stored in `sx` and `sy`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次遍历中，我们选择`pass2`函数，并仅渲染一个覆盖整个屏幕的单个四边形。这样做是为了在图像中的每个像素上调用一次片段着色器。在`pass2`函数中，我们检索包含第一次遍历结果的纹理的八个相邻像素的值，并通过调用`luminance`函数计算它们的亮度。然后应用水平和垂直Sobel滤波器，并将结果存储在`sx`和`sy`中。
- en: The `luminance` function determines the brightness of an RGB value by computing
    a weighted sum of the intensities. The weights are from the ITU-R Recommendation
    Rec. 709\. For more details on this, see the Wikipedia entry for *luma*.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`luminance`函数通过计算强度的加权总和来确定RGB值的亮度。权重来自ITU-R建议书Rec. 709。有关此内容的更多详细信息，请参阅维基百科上的*亮度*条目。'
- en: We then compute the squared value of the magnitude of the gradient (in order
    to avoid the square root) and store the result in `g`. If the value of `g` is
    greater than `EdgeThreshold`, we consider the pixel to be on an edge and we output
    a white pixel. Otherwise, we output a solid black pixel.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算梯度幅度的平方值（为了避免开方）并将结果存储在`g`中。如果`g`的值大于`EdgeThreshold`，我们认为该像素位于边缘，并输出一个白色像素。否则，我们输出一个纯黑色像素。
- en: There's more...
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The Sobel operator is somewhat crude and tends to be sensitive to high frequency
    variations in the intensity. A quick look at Wikipedia will guide you to a number
    of other edge detection techniques that may be more accurate. It is also possible
    to reduce the amount of high frequency variation by adding a *blur pass* between
    the render and edge detection passes. The blur pass will smooth out the high frequency
    fluctuations and may improve the results of the edge detection pass.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Sobel算子相对简单，并且对强度的高频变化较为敏感。快速查看维基百科将引导你找到许多其他可能更精确的边缘检测技术。在渲染和边缘检测遍历之间添加一个*模糊遍历*也有可能减少高频变化量。模糊遍历将平滑高频波动，并可能改善边缘检测遍历的结果。
- en: Optimization techniques
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化技术
- en: 'The technique discussed here requires eight texture fetches. Texture accesses
    can be somewhat slow, and reducing the number of accesses can result in substantial
    speed improvements. Chapter 24 of *GPU Gems: Programming Techniques, Tips and
    Tricks for Real-Time Graphics*, edited by Randima Fernando (Addison-Wesley Professional
    2004), has an excellent discussion of ways to reduce the number of texture fetches
    in a filter operation by making use of so-called *helper* textures.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的技术需要执行八个纹理获取操作。纹理访问可能会有些慢，减少访问次数可以显著提高速度。由 Randima Fernando 编著的《GPU Gems：实时图形编程技巧、提示和技巧》（Addison-Wesley
    Professional 2004年出版）的第24章对如何通过使用所谓的*辅助*纹理来减少滤波操作中的纹理获取次数进行了出色的讨论。
- en: See also
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/sceneedge.cpp` file in the example code
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/sceneedge.cpp`文件
- en: 'D. Ziou and S. Tabbone (*1998*), *Edge detection techniques: An overview*,
    *International Journal of Computer Vision*, *Vol 24*, *Issue 3*'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D. Ziou 和 S. Tabbone（*1998*），*边缘检测技术：概述*，《国际计算机视觉杂志》，第24卷，第3期
- en: '*Frei-Chen edge detector*: [http://rastergrid.com/blog/2011/01/frei-chen-edge-detector/](http://rastergrid.com/blog/2011/01/frei-chen-edge-detector/)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Frei-Chen 边缘检测器*: [http://rastergrid.com/blog/2011/01/frei-chen-edge-detector/](http://rastergrid.com/blog/2011/01/frei-chen-edge-detector/)'
- en: The *Rendering to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)中的*将渲染输出到纹理*配方，《使用纹理》'
- en: Applying a Gaussian blur filter
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用高斯模糊过滤器
- en: A blur filter can be useful in many different situations where the goal is to
    reduce the amount of noise in the image. As mentioned in the previous recipe,
    applying a blur filter prior to the edge detection pass may improve the results
    by reducing the amount of high frequency fluctuation across the image. The basic
    idea of any blur filter is to mix the color of a pixel with that of nearby pixels
    using a weighted sum. The weights typically decrease with the distance from the
    pixel (in 2D screen space) so that pixels that are far away contribute less than
    those closer to the pixel being blurred.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊过滤器在许多不同的情况下都很有用，目标是在图像中减少噪声量。如前所述，在边缘检测之前应用模糊过滤器可以通过减少图像中的高频波动来提高结果。任何模糊过滤器的基本思想是使用加权总和混合像素及其附近像素的颜色。权重通常随着与像素的距离（在2D屏幕空间中）的增加而减小，因此远离像素的像素对模糊像素的贡献小于靠近像素的像素。
- en: 'A **Gaussian blur** uses the two-dimensional Gaussian function to weight the
    contributions of the nearby pixels:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯模糊**使用二维高斯函数来加权附近像素的贡献：'
- en: '![](img/176d86f8-545b-483b-a71d-f039f8430dad.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/176d86f8-545b-483b-a71d-f039f8430dad.png)'
- en: 'The sigma squared term is the **variance** of the Gaussian, and determines
    the width of the Gaussian curve. The Gaussian function is maximum at (0,0), which
    corresponds to the location of the pixel being blurred and its value decreases
    as *x* or *y* increases. The following graph shows the two-dimensional Gaussian
    function with a sigma squared value of 4.0:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 方差项是高斯函数的**方差**，决定了高斯曲线的宽度。高斯函数在（0,0）处达到最大值，这对应于被模糊像素的位置及其值，随着 *x* 或 *y* 的增加而减小。以下图表显示了方差平方值为4.0的两维高斯函数：
- en: '![](img/58b45fc2-0640-456d-8bb7-1f92ae40e81b.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58b45fc2-0640-456d-8bb7-1f92ae40e81b.png)'
- en: 'The following images show a portion of an image before (left) and after (right)
    the Gaussian blur operation:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了高斯模糊操作前后图像的一部分（左侧为之前，右侧为之后）：
- en: '![](img/b0930f16-21ef-4581-83db-3285266192ba.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b0930f16-21ef-4581-83db-3285266192ba.png)'
- en: 'To apply a Gaussian blur, for each pixel, we need to compute the weighted sum
    of all pixels in the image scaled by the value of the Gaussian function at that
    pixel (where the *x* and *y* coordinates of each pixel are based on an origin
    located at the pixel being blurred). The result of that sum is the new value for
    the pixel. However, there are two problems with the algorithm so far:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用高斯模糊，对于每个像素，我们需要计算该像素处高斯函数值的加权总和，即所有图像中像素的加权总和（其中每个像素的 *x* 和 *y* 坐标基于一个位于被模糊像素处的原点）。这个总和的结果是像素的新值。然而，到目前为止的算法有两个问题：
- en: As this is a *O(n²)* process (where *n* is the number of pixels in the image),
    it is likely to be too slow for real-time use
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这是一个 *O(n²)* 过程（其中 *n* 是图像中像素的数量），它可能对于实时应用来说太慢了
- en: The weights must sum to one in order to avoid changing the overall brightness
    of
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重必须加起来等于一，以避免改变整体亮度
- en: the image
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该图像
- en: As we sampled the Gaussian function at discrete locations, and didn't sum over
    the entire (infinite) bounds of the function, the weights almost certainly do
    not sum to one.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在离散位置采样高斯函数，而没有在整个（无限）函数范围内求和，因此权重几乎肯定不会加起来等于一。
- en: We can deal with both of the preceding problems by limiting the number of pixels
    that we blur with a given pixel (instead of the entire image), and by normalizing
    the values of the Gaussian function. In this example, we'll use a 9 x 9 Gaussian
    blur filter. That is, we'll only compute the contributions of the 81 pixels in
    the neighborhood of the pixel being blurred.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过限制给定像素（而不是整个图像）模糊的像素数量，以及通过归一化高斯函数的值来解决上述两个问题。在这个例子中，我们将使用一个9 x 9的高斯模糊过滤器。也就是说，我们只计算被模糊像素周围81个像素的贡献。
- en: Such a technique would require 81 texture fetches in the fragment shader, which
    is executed once for each pixel. The total number of texture fetches for an image
    of size 800 x 600 would be *800 * 600 * 81 = 38,880,000*. This seems like a lot,
    doesn't it? The good news is that we can substantially reduce the number of texture
    fetches by doing the Gaussian blur in two passes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的技术需要在片段着色器中进行81次纹理提取，而片段着色器是针对每个像素执行一次的。对于800 x 600大小的图像，总的纹理提取次数将是 *800
    * 600 * 81 = 38,880,000*。这看起来很多，不是吗？好消息是，我们可以通过在两次传递中执行高斯模糊来显著减少纹理提取的次数。
- en: 'The two-dimensional Gaussian function can be decomposed into the product of
    two one-dimensional Gaussians:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 二维高斯函数可以分解为两个一维高斯函数的乘积：
- en: '![](img/049816d2-d752-4b1f-ae5d-fce015f42579.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/049816d2-d752-4b1f-ae5d-fce015f42579.png)'
- en: 'Where the one-dimensional Gaussian function is given by the following equation:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一维高斯函数由以下方程给出：
- en: '![](img/9559cd7f-1c79-44d0-8fdd-6a0f1d61cb84.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9559cd7f-1c79-44d0-8fdd-6a0f1d61cb84.png)'
- en: 'So if *C[ij]* is the color of the pixel at pixel location (i, j), the sum that
    we need to compute is given by the following equation:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果 *C[ij]* 是像素位置 (i, j) 处的像素颜色，我们需要计算的总和由以下方程给出：
- en: '![](img/677564d4-341f-4106-ad15-2724de2feb47.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/677564d4-341f-4106-ad15-2724de2feb47.png)'
- en: 'This can be re-written using the fact that the two-dimensional Gaussian is
    a product of two one-dimensional Gaussians:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下事实重写：二维高斯是两个一维高斯的乘积：
- en: '![](img/0e10f9ad-b403-481f-a342-8bc9b63d63ec.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e10f9ad-b403-481f-a342-8bc9b63d63ec.png)'
- en: This implies that we can compute the Gaussian blur in two passes. In the first
    pass, we can compute the sum over *j* (the vertical sum) in the preceding equation
    and store the results in a temporary texture. In the second pass, we compute the
    sum over *i* (the horizontal sum) using the results from the previous pass.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以通过两次遍历来计算高斯模糊。在第一次遍历中，我们可以计算前一个方程中 *j*（垂直和）的总和，并将结果存储在一个临时纹理中。在第二次遍历中，我们使用前一次遍历的结果来计算
    *i*（水平和）的总和。
- en: 'Now, before we look at the code, there is one important point that has to be
    addressed. As we mentioned previously, the Gaussian weights must sum to one in
    order to be a true weighted average. Therefore, we need to normalize our Gaussian
    weights, as in the following equation:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们查看代码之前，有一个重要的问题需要解决。正如我们之前提到的，高斯权重必须加起来等于一，才能成为真正的加权平均值。因此，我们需要归一化我们的高斯权重，如下方程所示：
- en: '![](img/a66eea6d-85ae-4dac-a260-644243f99225.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a66eea6d-85ae-4dac-a260-644243f99225.png)'
- en: 'The value of *k* in the preceding equation is just the sum of the raw Gaussian
    weights:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个方程中 *k* 的值只是原始高斯权重的总和：
- en: '![](img/4a92509c-23af-4070-815d-1f9bba693e15.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4a92509c-23af-4070-815d-1f9bba693e15.png)'
- en: Phew! We've reduced the *O(n^([2]))* problem to one that is *O(n)*. OK, with
    that, let's move on to the code.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 呼！我们已经将 *O(n^([2]))* 问题简化为 *O(n)* 的问题。好的，有了这个，让我们继续看代码。
- en: We'll implement this technique using three passes and two textures. In the first
    pass, we'll render the entire scene to a texture. Then, in the second pass, we'll
    apply the first (vertical) sum to the texture from the first pass and store the
    results in another texture. Finally, in the third pass, we'll apply the horizontal
    sum to the texture from the second pass, and send the results to the default framebuffer.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用三次遍历和两个纹理来实现这项技术。在第一次遍历中，我们将整个场景渲染到纹理中。然后，在第二次遍历中，我们将第一次（垂直）求和应用于第一次遍历的纹理，并将结果存储在另一个纹理中。最后，在第三次遍历中，我们将水平求和应用于第二次遍历的纹理，并将结果发送到默认帧缓冲区。
- en: Getting ready
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Set up two framebuffer objects (refer to the *Rendering to a texture* recipe
    in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml), *Using Textures*),
    and two corresponding textures. The first FBO should have a depth buffer because
    it will be used for the first pass. The second FBO need not have a depth buffer
    because, in the second and third passes, we'll only render a single screen-filling
    quad in order to execute the fragment shader once for each pixel.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 设置两个帧缓冲对象（参考第5章中的*渲染到纹理*配方，*使用纹理*），以及两个相应的纹理。第一个FBO应该有一个深度缓冲区，因为它将用于第一次遍历。第二个FBO不需要深度缓冲区，因为在第二次和第三次遍历中，我们只渲染一个填充整个屏幕的四边形，以便为每个像素执行一次片段着色器。
- en: 'As with the previous recipe, we''ll use a uniform variable to select the functionality
    of each pass. The OpenGL program should also set the following uniform variables:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与前面的配方一样，我们将使用一个统一变量来选择每个遍历的功能。OpenGL程序还应设置以下统一变量：
- en: '`Width`: This is used to set the width of the screen in pixels'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Width`: 这用于设置屏幕的宽度（以像素为单位）'
- en: '`Height`: This is used to set the height of the screen in pixels'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Height`: 这用于设置屏幕的高度（以像素为单位）'
- en: '`Weight[]`: This is the array of normalized Gaussian weights'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Weight[]`: 这是一个归一化高斯权重的数组'
- en: '`Texture0`: This is to set this to texture unit zero'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Texture0`: 这是为了将其设置为纹理单元零'
- en: '`PixOffset[]`: This is the array of offsets from the pixel being blurred'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PixOffset[]`: 这是一个从被模糊的像素偏移的数组'
- en: How to do it...
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the fragment shader, we apply the Blinn-Phong reflection model in the first
    pass. In the second pass, we compute the vertical sum. In the third, we compute
    the horizontal sum:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在片段着色器中，我们在第一次遍历中应用Blinn-Phong反射模型。在第二次遍历中，我们计算垂直和。在第三次，我们计算水平和：
- en: '[PRE1]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the OpenGL application, compute the Gaussian weights for the offsets found
    in the uniform variable `PixOffset`, and store the results in the array `Weight`.
    You could use the following code to do so:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenGL应用程序中，计算在统一变量`PixOffset`中找到的偏移量的高斯权重，并将结果存储在`Weight`数组中。你可以使用以下代码来完成此操作：
- en: '[PRE2]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the main render function, implement the following steps for pass #1:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在主渲染函数中，为第1次传递实现以下步骤：
- en: Select the render framebuffer, enable the depth test, and clear the color/depth
    buffers
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择渲染帧缓冲区，启用深度测试，并清除颜色/深度缓冲区
- en: Set `Pass` to `1`
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Pass`设置为`1`
- en: Draw the scene
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制场景
- en: 'Use the following steps for pass #2:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下步骤进行第2次传递：
- en: Select the intermediate framebuffer, disable the depth test, and clear the color
    buffer
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择中间帧缓冲区，禁用深度测试，并清除颜色缓冲区
- en: Set `Pass` to `2`
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Pass`设置为`2`
- en: Set the view, projection, and model matrices to the identity matrix
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将视图、投影和模型矩阵设置为单位矩阵
- en: 'Bind the texture from pass #1 to texture unit zero'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第1次传递的纹理绑定到纹理单元0
- en: Draw a fullscreen quad
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制全屏四边形
- en: 'Use the following steps for pass #3:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下步骤进行第3次传递：
- en: Deselect the framebuffer (revert to the default), and clear the color buffer
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取消选择帧缓冲区（恢复默认），并清除颜色缓冲区
- en: Set `Pass` to `3`
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Pass`设置为`3`
- en: 'Bind the texture from pass #2 to texture unit zero'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第2次传递的纹理绑定到纹理单元0
- en: Draw a fullscreen quad
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制全屏四边形
- en: How it works...
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the preceding code for computing the Gaussian weights (code segment 3), the
    function named `gauss` computes the one-dimensional Gaussian function where the
    first argument is the value for `x` and the second argument is sigma squared.
    Note that we only need to compute the positive offsets because the Gaussian is
    symmetric about zero. As we are only computing the positive offsets, we need to
    carefully compute the sum of the weights. We double all of the non-zero values
    because they will be used twice (for the positive and negative offsets).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算高斯权重的先前代码（代码段3）中，名为`gauss`的函数计算一维高斯函数，其中第一个参数是`x`的值，第二个参数是sigma的平方。请注意，我们只需要计算正偏移，因为高斯关于零是对称的。由于我们只计算正偏移，我们需要仔细计算权重的总和。我们将所有非零值加倍，因为它们将被两次使用（正负偏移）。
- en: The first pass (function `pass1`) renders the scene to a texture using the Blinn-Phong
    reflection model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次传递（函数`pass1`）使用Blinn-Phong反射模型将场景渲染到纹理中。
- en: The second pass (function `pass2`) applies the weighted vertical sum of the
    Gaussian blur operation, and stores the results in yet another texture. We read
    pixels from the texture created in the first pass, offset in the vertical direction
    by the amounts in the `PixOffset` array. We sum using weights from the `Weight`
    array. (The `dy` term is the height of a texel in texture coordinates.) We sum
    in both directions at the same time, a distance of four pixels in each vertical
    direction.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次传递（函数`pass2`）应用高斯模糊操作的加权垂直总和，并将结果存储在另一个纹理中。我们从第一次传递中创建的纹理中读取像素，在垂直方向上偏移`PixOffset`数组中的值。我们使用`Weight`数组中的权重进行求和。（`dy`项是纹理坐标中texel的高度。）我们在两个方向上同时求和，每个垂直方向上4个像素的距离。
- en: The third pass (`pass3`) is very similar to the second pass. We accumulate the
    weighted, horizontal sum using the texture from the second pass. By doing so,
    we are incorporating the sums produced in the second pass into our overall weighted
    sum, as described earlier. Thereby, we are creating a sum over a 9 x 9 pixel area
    around the destination pixel. For this pass, the output color goes to the default
    framebuffer to make up the final result.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次传递（`pass3`）与第二次传递非常相似。我们使用第二次传递的纹理来累积加权水平总和。通过这样做，我们将第二次传递产生的总和纳入我们的整体加权总和，如前所述。因此，我们在目标像素周围9x9像素区域内创建一个总和。对于这次传递，输出颜色将发送到默认帧缓冲区以生成最终结果。
- en: There's more...
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Of course, we can also adapt the preceding technique to blur a larger range
    of texels by increasing the size of the arrays `Weight` and `PixOffset` and re-computing
    the weights, and/or we could use different values of `sigma2` to vary the shape
    of the Gaussian.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可以通过增加`Weight`和`PixOffset`数组的大小并重新计算权重，以及/或者使用不同的`sigma2`值来改变高斯形状，来调整更大范围的texels的模糊。
- en: See also
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/sceneblur.cpp` file in the example code
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/sceneblur.cpp`文件
- en: 'Bilateral filtering: [http://people.csail.mit.edu/sparis/bf_course/](http://people.csail.mit.edu/sparis/bf_course/)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双边滤波：[http://people.csail.mit.edu/sparis/bf_course/](http://people.csail.mit.edu/sparis/bf_course/)
- en: The *Rendering to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)中的*将渲染输出到纹理*配方，*使用纹理*'
- en: The *Applying an edge detection filter* recipe in this chapter
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*应用边缘检测滤波器*配方
- en: Implementing HDR lighting with tone mapping
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用色调映射实现HDR照明
- en: When rendering for most output devices (monitors or televisions), the device
    only supports a typical color precision of 8-bits per color component, or 24-bits
    per pixel. Therefore, for a given color component, we're limited to a range of
    intensities between 0 and 255\. Internally, OpenGL uses floating-point values
    for color intensities, providing a wide range of both values and precision. These
    are eventually converted to 8-bit values by mapping the floating-point range [0.0,
    1.0] to the range of an unsigned byte [0, 255] before rendering.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当为大多数输出设备（显示器或电视）渲染时，设备仅支持每个颜色组件的典型颜色精度为8位，或者每个像素24位。因此，对于给定的颜色组件，我们限制在0到255之间的强度范围内。OpenGL内部使用浮点值表示颜色强度，提供广泛的值和精度范围。在渲染之前，这些值最终通过将浮点范围[0.0,
    1.0]映射到无符号字节的范围[0, 255]来转换为8位值。
- en: Real scenes, however, have a much wider range of luminance. For example, light
    sources that are visible in a scene, or direct reflections of them, can be hundreds
    to thousands of times brighter than the objects that are illuminated by the source.
    When we're working with 8-bits per channel, or the floating-point range [0.0,
    -1.0], we can't represent this range of intensities. If we decide to use a larger
    range of floating point values, we can do a better job of internally representing
    these intensities, but in the end, we still need to compress down to the 8-bit
    range.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，真实场景的亮度范围要宽得多。例如，场景中可见的光源或它们的直接反射可能比光源照亮的物体亮数百到数千倍。当我们使用每个通道8位，或浮点范围[0.0,
    -1.0]工作时，我们无法表示这个强度范围。如果我们决定使用更大的浮点值范围，我们可以更好地内部表示这些强度，但最终我们仍然需要将其压缩到8位范围。
- en: The process of computing the lighting/shading using a larger dynamic range is
    often referred to as **High Dynamic Range rendering** (**HDR rendering**). Photographers
    are very familiar with this concept. When a photographer wants to capture a larger
    range of intensities than would normally be possible in a single exposure, he/she
    might take several images with different exposures to capture a wider range of
    values. This concept, called **High Dynamic Range imaging** (**HDR imaging**),
    is very similar in nature to the concept of HDR rendering. A post-processing pipeline
    that includes HDR is now considered a fundamentally essential part of any game
    engine.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更大动态范围计算光照/着色的过程通常被称为**高动态范围渲染**（**HDR渲染**）。摄影师非常熟悉这个概念。当摄影师想要捕捉比单次曝光通常可能捕捉到的更大范围的强度时，他/她可能会拍摄几张不同曝光的照片来捕捉更广泛的值。这个称为**高动态范围成像**（**HDR成像**）的概念在本质上与HDR渲染的概念非常相似。现在，包含HDR的后处理流程被认为是任何游戏引擎的基本组成部分。
- en: '**Tone mapping** is the process of taking a wide dynamic range of values and
    compressing them into a smaller range that is appropriate for the output device.
    In computer graphics, generally, tone mapping is about mapping to the 8-bit range
    from some arbitrary range of values. The goal is to maintain the dark and light
    parts of the image so that both are visible and neither is completely *washed
    out*.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**色调映射**是将广泛的动态范围值压缩到适合输出设备的较小范围的过程。在计算机图形学中，通常，色调映射是将某些任意值范围映射到8位范围。目标是保持图像的暗部和亮部，以便两者都可见，且没有任何部分是完全*褪色*的。'
- en: For example, a scene that includes a bright light source might cause our shading
    model to produce intensities that are greater than 1.0\. If we were to simply
    send that to the output device, anything greater than 1.0 would be clamped to
    255 and would appear white. The result might be an image that is mostly white,
    similar to a photograph that is over exposed.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，包含明亮光源的场景可能会导致我们的着色模型产生大于1.0的强度。如果我们直接将其发送到输出设备，任何大于1.0的部分都会被限制为255，并显示为白色。结果可能是一张大部分为白色的图像，类似于曝光过度的照片。
- en: Or, if we were to linearly compress the intensities to the [0, 255] range, the
    darker parts might be too dark or completely invisible. With tone mapping, we
    want to maintain the brightness of the light source and also maintain detail in
    the darker areas.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们把强度线性压缩到 [0, 255] 范围内，较暗的部分可能会太暗或完全看不见。使用色调映射，我们希望保持光源的亮度，同时也保持暗部区域的细节。
- en: This description just scratches the surface when it comes to tone mapping and
    HDR rendering/imaging. For more details, I recommend the book *High Dynamic Range
    Imaging* by Reinhard et al.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到色调映射和HDR渲染/成像时，这个描述只是触及了表面。对于更多细节，我推荐阅读 Reinhard 等人所著的《高动态范围成像》一书。
- en: The mathematical function used to map from one dynamic range to a smaller range
    is called the **Tone Mapping Operator** (**TMO**). These generally come in two
    flavors, local operators and global operators. A local operator determines the
    new value for a given pixel by using its current value and perhaps the value of
    some nearby pixels. A global operator needs some information about the entire
    image in order to do its work. For example, it might need to have the overall
    average luminance of all pixels in the image. Other global operators use a histogram
    of luminance values over the entire image to help fine-tune the mapping.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个动态范围映射到更小范围的数学函数称为**色调映射算子**（**TMO**）。这些通常有两种类型，局部算子和全局算子。局部算子通过使用给定像素的当前值以及可能的一些邻近像素的值来确定该像素的新值。全局算子需要有关整个图像的一些信息才能工作。例如，它可能需要知道图像中所有像素的整体平均亮度。其他全局算子使用整个图像上亮度值的直方图来帮助微调映射。
- en: 'In this recipe, we''ll use the simple global operator described in the book
    *Real Time Rendering*. This operator uses the log-average luminance of all pixels
    in the image. The log-average is determined by taking the logarithm of the luminance
    and averaging those values, then converting back, as shown in the following equation:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用书中《实时渲染》中描述的简单全局算子。此算子使用图像中所有像素的对数平均亮度。对数平均是通过取亮度的对数并平均这些值，然后转换回来得到的，如下方程所示：
- en: '![](img/4829befe-6c06-4f97-b736-ff0be2195116.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4829befe-6c06-4f97-b736-ff0be2195116.png)'
- en: '*L[w](x, y)* is the luminance of the pixel at *(x, y)*. The *0.0001* term is
    included in order to avoid taking the logarithm of zero for black pixels. This
    log-average is then used as part of the tone mapping operator shown as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*L[w](x, y)* 是 *(x, y)* 处像素的亮度。包含 *0.0001* 项是为了避免对黑色像素取对数。然后，这个对数平均被用作色调映射算子的一个部分，如下所示：'
- en: '![](img/d4d7308f-de54-4830-b68f-f947084806dd.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4d7308f-de54-4830-b68f-f947084806dd.png)'
- en: 'The *a* term in this equation is the key. It acts in a similar way to the exposure
    level in a camera. The typical values for *a* range from 0.18 to 0.72\. Since
    this tone mapping operator compresses the dark and light values a bit too much,
    we''ll use a modification of the previous equation that doesn''t compress the
    dark values as much, and includes a maximum luminance (*L[white]*), a configurable
    value that helps to reduce some of the extremely bright pixels:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程中的 *a* 项是关键。它以类似相机曝光级别的方式起作用。*a* 的典型值范围从 0.18 到 0.72。由于这个色调映射算子对暗部和亮部的值压缩得有点过多，我们将使用一个修改过的方程，它不会对暗部值压缩得那么厉害，并包括一个最大亮度
    (*L[white]*)，这是一个可配置的值，有助于减少一些极端明亮的像素：
- en: '![](img/4be147f8-a6dd-4961-b002-348bbb5437df.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4be147f8-a6dd-4961-b002-348bbb5437df.png)'
- en: This is the tone mapping operator that we'll use in this example. We'll render
    the scene to a high-resolution buffer, compute the log-average luminance, and
    then apply the previous tone-mapping operator in a second pass.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在本例中将要使用的色调映射算子。我们将场景渲染到一个高分辨率缓冲区中，计算对数平均亮度，然后在第二次遍历中应用之前的色调映射算子。
- en: However, there's one more detail that we need to deal with before we can start
    implementing. The previous equations all deal with luminance. Starting with an
    RGB value, we can compute its luminance, but once we modify the luminance, how
    do we modify the RGB components to reflect the new luminance without changing
    the hue (or chromaticity)?
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们开始实现之前，还有一个细节需要处理。之前的方程都处理亮度。从一个RGB值开始，我们可以计算它的亮度，但一旦我们修改了亮度，我们如何修改RGB分量以反映新的亮度而不改变色调（或色度）呢？
- en: The **chromaticity** is the perceived color, independent of the brightness of
    that color. For example, grey and white are two brightness levels for the same
    color.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**色度**是感知到的颜色，与该颜色的亮度无关。例如，灰色和白色是同一颜色的两种亮度级别。'
- en: The solution involves switching color spaces. If we convert the scene to a color
    space that separates out the luminance from the chromaticity, then we can change
    the luminance value independently. The **CIE XYZ** color space has just what we
    need. The CIE XYZ color space was designed so that the *Y* component describes
    the luminance of the color and the chromaticity can be determined by two derived
    parameters (*x* and *y*). The derived color space is called the **CIE xyY** space,
    and is exactly what we're looking for. The *Y* component contains the luminance
    and the *x* and *y* components contain the chromaticity. By converting to the
    *CIE xyY* space, we've factored out the luminance from the chromaticity allowing
    us to change the luminance without affecting the perceived color.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案涉及切换颜色空间。如果我们把场景转换到一个将亮度与色度分离的颜色空间，那么我们可以独立地改变亮度值。**CIE XYZ**颜色空间正好符合我们的需求。CIE
    XYZ颜色空间被设计成其*Y*分量描述颜色的亮度，而色度可以通过两个导出参数（*x*和*y*）来确定。导出的颜色空间被称为**CIE xyY**空间，这正是我们所寻找的。*Y*分量包含亮度，而*x*和*y*分量包含色度。通过转换为*CIE
    xyY*空间，我们已经将亮度从色度中分离出来，允许我们改变亮度而不影响感知到的颜色。
- en: So the process involves converting from RGB to CIE XYZ, then converting to CIE
    xyY, modifying the luminance, and reversing the process to get back to RGB. Converting
    from RGB to CIE XYZ (and vice-versa) can be described as a transformation matrix
    (refer to the code or the *See also* section for the matrix).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个过程涉及将RGB转换为CIE XYZ，然后转换为CIE xyY，修改亮度，并逆过程回到RGB。从RGB到CIE XYZ（反之亦然）可以描述为一个转换矩阵（请参阅代码或*另请参阅*部分以获取矩阵）。
- en: 'The conversion from XYZ to xyY involves the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从XYZ到xyY的转换涉及以下内容：
- en: '![](img/36de4b90-038e-4504-93da-cae3032f2530.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36de4b90-038e-4504-93da-cae3032f2530.png)'
- en: 'Finally, converting from xyY back to XYZ is done using the following equations:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用以下方程将xyY转换回XYZ：
- en: '![](img/5eced92f-b4a5-4b83-8757-5be68a3558d6.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5eced92f-b4a5-4b83-8757-5be68a3558d6.png)'
- en: 'The following images show an example of the results of this tone mapping operator.
    The left image shows the scene rendered without any tone mapping. The shading
    was deliberately calculated with a wide dynamic range using three strong light
    sources. The scene appears *blown out* because any values that are greater than
    1.0 simply get clamped to the maximum intensity. The image on the right uses the
    same scene and the same shading, but with the previous tone mapping operator applied.
    Note the recovery of the specular highlights from the *blown out* areas on the
    sphere and teapot:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了此色调映射算子的结果示例。左侧图像显示了未进行任何色调映射的场景渲染。阴影是故意使用三个强烈的光源计算出的，具有广泛的动态范围。由于任何大于1.0的值都会被限制在最大强度，因此场景看起来*过曝*。右侧的图像使用了相同的场景和相同的阴影，但应用了之前的色调映射算子。注意球体和茶壶上*过曝*区域的镜面高光恢复：
- en: '![](img/5f514e34-78dc-4e56-8b09-e45613529447.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f514e34-78dc-4e56-8b09-e45613529447.png)'
- en: Getting ready
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The steps involved are the following:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及的步骤如下：
- en: Render the scene to a high-resolution texture.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将场景渲染到高分辨率纹理中。
- en: Compute the log-average luminance (on the CPU).
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算对数平均亮度（在CPU上）。
- en: Render a screen-filling quad to execute the fragment shader for each screen
    pixel. In the fragment shader, read from the texture created in step 1, apply
    the tone mapping operator, and send the results to the screen.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渲染一个填充屏幕的四边形以执行每个屏幕像素的片段着色器。在片段着色器中，从步骤1中创建的纹理中读取，应用色调映射算子，并将结果发送到屏幕。
- en: To get set up, create a high-res texture (using `GL_RGB32F` or a similar format)
    attached to a framebuffer with a depth attachment. Set up your fragment shader
    with a uniform to select the pass. The vertex shader can simply pass through the
    position and normal in eye coordinates.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置环境，创建一个高分辨率纹理（使用`GL_RGB32F`或类似格式），并将其附加到一个具有深度附加的帧缓冲区。设置你的片段着色器，使用统一变量来选择通道。顶点着色器可以简单地传递眼睛坐标中的位置和法线。
- en: How to do it...
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'To implement HDR tone mapping, we''ll perform the following steps:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现HDR色调映射，我们将执行以下步骤：
- en: In the first pass, we want to just render the scene to the high-resolution texture.
    Bind to the framebuffer that has the texture attached and render the scene normally.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次遍历中，我们只想将场景渲染到高分辨率纹理中。绑定到已附加纹理的帧缓冲区，并正常渲染场景。
- en: 'Compute the log average luminance of the pixels in the texture. To do so, we''ll
    pull the data from the texture and loop through the pixels on the CPU side. We
    do this on the CPU for simplicity; a GPU implementation, perhaps with a compute
    shader, would be faster:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算纹理中像素的对数平均亮度。为此，我们将从纹理中提取数据，并在CPU端循环遍历像素。我们这样做是为了简单起见；一个GPU实现，可能使用计算着色器，会更快：
- en: '[PRE3]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Set the `AveLum` uniform variable using `logAve`. Switch back to the default
    frame buffer, and draw a screen-filling quad. In the fragment shader, apply the
    tone mapping operator to the values from the texture produced in step 1:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`logAve`设置`AveLum`统一变量。切换回默认帧缓冲区，并绘制一个填充屏幕的四边形。在片段着色器中，将色调映射算子应用于第一步生成的纹理值：
- en: '[PRE4]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the first step, we render the scene to an HDR texture. In step 2, we compute
    the log-average luminance by retrieving the pixels from the texture and doing
    the computation on the CPU (OpenGL side).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们将场景渲染到HDR纹理中。在第二步中，通过从纹理中检索像素并在CPU（OpenGL端）上进行计算来计算对数平均亮度。
- en: In step 3, we render a single screen-filling quad to execute the fragment shader
    for each screen pixel. In the fragment shader, we retrieve the HDR value from
    the texture and apply the tone-mapping operator. There are two *tunable* variables
    in this calculation. The `Exposure` variable corresponds to the *a* term in the
    tone mapping operator, and the variable `White` corresponds to *L[white]*. For
    the previous image, we used values of `0.35` and `0.928`, respectively.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三步中，我们渲染一个单独的填充屏幕四边形以执行每个屏幕像素的片段着色器。在片段着色器中，我们从纹理中检索HDR值并应用色调映射算子。在这个计算中有两个*可调*变量。`Exposure`变量对应于色调映射算子中的*a*项，而`White`变量对应于*L[white]*。对于前面的图像，我们分别使用了`0.35`和`0.928`的值。
- en: There's more...
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Tone mapping is not an exact science. Often, it is the process of experimenting
    with the parameters until you find something that works well and looks good.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 色调映射并不是一门精确的科学。通常，这是一个不断尝试参数直到找到既有效又美观的过程。
- en: We could improve the efficiency of the previous technique by implementing step
    2 on the GPU using compute shaders (refer to [Chapter 11](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml),
    *Using Compute Shaders*) or some other clever technique. For example, we could
    write the logarithms to a texture, then iteratively downsample the full frame
    to a 1 x 1 texture. The final result would be available in that single pixel.
    However, with the flexibility of the compute shader, we could optimize this process
    even more.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在GPU上使用计算着色器（参考[第11章](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml)，*使用计算着色器*）或某些其他巧妙的技术来提高先前技术的效率。例如，我们可以将对数写入纹理，然后迭代地将整个帧下采样到1
    x 1纹理。最终结果将可用在该单个像素中。然而，有了计算着色器的灵活性，我们可以进一步优化这个过程。
- en: See also
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The `chapter06/scenetonemap.cpp` file in the example code.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/scenetonemap.cpp`文件。
- en: 'Bruce Justin Lindbloom has provided a useful web resource for conversion between
    color spaces. It includes among other things the transformation matrices needed
    to convert from RGB to XYZ. Visit: [http://www.brucelindbloom.com/index.html?Eqn_XYZ_to_RGB.html](http://www.brucelindbloom.com/index.html?Eqn_XYZ_to_RGB.html).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布鲁斯·贾斯汀·林德布卢姆提供了一项有用的网络资源，用于颜色空间之间的转换。它包括将RGB转换为XYZ所需的各种转换矩阵。访问：[http://www.brucelindbloom.com/index.html?Eqn_XYZ_to_RGB.html](http://www.brucelindbloom.com/index.html?Eqn_XYZ_to_RGB.html)。
- en: The *Rendering to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)，*使用纹理*中的*渲染到纹理*配方。
- en: Creating a bloom effect
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建辉光效果
- en: A **bloom** is a visual effect where the bright parts of an image seem to have
    fringes that extend beyond the boundaries into the darker parts of the image.
    This effect has its basis in the way that cameras and the human visual system
    perceive areas of high contrast. Sources of bright light *bleed* into other areas
    of the image due to the so-called **airy disc**, which is a diffraction pattern
    produced by light that passes through an aperture.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**辉光**是一种视觉效果，图像的明亮部分似乎有边缘延伸到图像的较暗部分。这种效果基于相机和人类视觉系统感知高对比度区域的方式。由于所谓的**空气盘**（由通过孔的光产生的衍射图案），明亮的光源会*渗透*到图像的其他区域。'
- en: 'The following image shows a bloom effect in the animated film Elephant''s Dream
    (© 2006, Blender Foundation / Netherlands Media Art Institute / [www.elephantsdream.org](https://orange.blender.org/)).
    The bright white color from the light behind the door *bleeds* into the darker
    parts of the image:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了动画电影《大象之梦》（© 2006，Blender基金会 / 荷兰媒体艺术学院 / [www.elephantsdream.org](https://orange.blender.org/))中的溢出效果。门后的明亮白色光线*渗透*到图像的较暗部分：
- en: '![](img/c5a4b8cd-0e82-4ad9-bc80-d092d4ca280f.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c5a4b8cd-0e82-4ad9-bc80-d092d4ca280f.png)'
- en: Producing such an effect within an artificial CG rendering requires determining
    which parts of the image are bright enough, extracting those parts, blurring,
    and re-combining with the original image. Typically, the bloom effect is associated
    with HDR rendering. With HDR rendering, we can represent a larger range of intensities
    for each pixel (without quantizing artifacts). The bloom effect is more accurate
    when used in conjunction with HDR rendering due to the fact that a wider range
    of brightness values can be represented.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工CG渲染中产生这种效果需要确定图像中哪些部分足够明亮，提取这些部分，模糊，并与原始图像重新组合。通常，溢出效果与HDR渲染相关联。使用HDR渲染时，我们可以为每个像素表示更广泛的强度范围（而不产生量化伪影）。由于可以表示更广泛的亮度值，因此与HDR渲染结合使用时，溢出效果更准确。
- en: Despite the fact that HDR produces higher quality results, it is still possible
    to produce a bloom effect when using standard (non-HDR) color values. The result
    may not be as effective, but the principles involved are similar for either situation.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管HDR（高动态范围）可以产生更高质量的结果，但在使用标准（非HDR）颜色值时，仍然可能出现溢出效果。结果可能不会那么有效，但涉及的原则对两种情况都是相似的。
- en: 'In the following example, we''ll implement a bloom effect using five passes,
    consisting of four major steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将使用五次迭代实现溢出效果，包括四个主要步骤：
- en: In the first pass, we will render the scene to an HDR texture.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次迭代中，我们将场景渲染到HDR纹理中。
- en: The second pass will extract the parts of the image that are brighter than a
    certain threshold value. We'll refer to this as the **bright-pass filter**. We'll
    also downsample to a lower resolution buffer when applying this filter. We do
    so because we will gain additional blurring of the image when we read back from
    this buffer using a linear sampler.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二次迭代将提取图像中比某个阈值值更亮的部分。我们将此称为**亮通道滤波器**。在应用此滤波器时，我们还将下采样到较低分辨率的缓冲区。我们这样做是因为当我们使用线性采样器从这个缓冲区读取时，我们将获得图像的额外模糊。
- en: The third and fourth passes will apply the Gaussian blur to the bright parts
    (refer to the *Applying a Gaussian blur filter* recipe in this chapter).
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三和第四次迭代将对明亮部分应用高斯模糊（参考本章中的*应用高斯模糊滤波器*配方）。
- en: In the fifth pass, we'll apply tone mapping and add the tone-mapped result to
    the blurred bright-pass filter results.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第五次迭代中，我们将应用色调映射并将色调映射结果添加到模糊的亮通道滤波器结果中。
- en: The following diagram summarizes this process. The upper-left image shows the
    scene rendered to an HDR buffer, with some of the colors out of gamut, causing
    much of the image to be *blown-out*. The bright-pass filter produces a smaller
    (about a quarter or an eighth of the original size) image with only pixels that
    correspond to a luminance that is above a threshold. The pixels are shown as white
    because they have values that are greater than one in this example. A two-pass
    Gaussian blur is applied to the downsampled image, and tone mapping is applied
    to the original image. The final image is produced by combining the tone-mapped
    image with the blurred bright-pass filter image. When sampling the latter, we
    use a linear filter to get additional blurring.The final result is shown at the
    bottom.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下图总结了这一过程。左上角的图像显示了渲染到HDR缓冲区的场景，其中一些颜色超出色域，导致图像的大部分区域*过曝*。亮通道滤波器产生一个更小的（大约是原始大小的四分之一或八分之一）图像，其中只有对应于高于阈值的亮度的像素。在这些示例中，像素显示为白色，因为它们的值大于一。对下采样图像应用两次高斯模糊，并对原始图像应用色调映射。最终图像是通过将色调映射图像与模糊的亮通道滤波器图像组合而成的。在采样后者时，我们使用线性滤波器以获得额外的模糊。最终结果显示在底部。
- en: 'Note the bloom on the bright highlights on the sphere and the back wall:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注意球体和背墙上的明亮高光处的溢出效果：
- en: '![](img/7265b5a6-cb42-4b43-b879-96d34ee8589b.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7265b5a6-cb42-4b43-b879-96d34ee8589b.png)'
- en: Getting ready
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we'll need two framebuffer objects, each associated with a
    texture. The first will be used for the original HDR render, and the second will
    be used for the two passes of the Gaussian blur operation. In the fragment shader,
    we'll access the original render via the variable `HdrTex`, and the two stages
    of the Gaussian blur will be accessed via `BlurTex`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个配方，我们需要两个帧缓冲区对象，每个都与一个纹理相关联。第一个将用于原始HDR渲染，第二个将用于高斯模糊操作的两次传递。在片段着色器中，我们将通过变量`HdrTex`访问原始渲染，而高斯模糊的两个阶段将通过`BlurTex`访问。
- en: The uniform variable `LumThresh` is the minimum luminance value used in the
    second pass. Any pixels greater than that value will be extracted and blurred
    in the following passes.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 常量变量`LumThresh`是第二次传递中使用的最小亮度值。任何大于该值的像素将在后续传递中被提取并模糊。
- en: Use a vertex shader that passes through the position and normal in eye coordinates.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个顶点着色器，该着色器通过眼坐标传递位置和法线。
- en: How to do it...
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'To generate a bloom effect, perform the following steps:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成辉光效果，请执行以下步骤：
- en: In the first pass, render the scene to the framebuffer with a high-res backing
    texture.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次传递中，将场景渲染到具有高分辨率背板纹理的帧缓冲区中。
- en: 'In the second pass, switch to a framebuffer containing a high-res texture that
    is smaller than the size of the full render. In the example code, we use a texture
    that is one-eighth the size. Draw a fullscreen quad to initiate the fragement
    shader for each pixel, and in the fragment shader sample from the high-res texture,
    and write only those values that are larger than `LumThresh`. Otherwise, color
    the pixel black:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二次传递中，切换到一个包含高分辨率纹理的帧缓冲区，该纹理的大小小于完整渲染的大小。在示例代码中，我们使用一个大小为原始大小八分之一的纹理。绘制一个全屏四边形以启动每个像素的片段着色器，并在片段着色器中从高分辨率纹理中采样，并仅写入大于`LumThresh`的值。否则，将像素着色为黑色：
- en: '[PRE5]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the third and fourth passes, apply the Gaussian blur to the results of the
    second pass. This can be done with a single framebuffer and two textures. Ping-pong
    between them, reading from one and writing to the other. For details, refer to
    the *Applying a Gaussian blur filter* recipe in this chapter.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三次和第四次传递中，将高斯模糊应用于第二次传递的结果。这可以通过一个帧缓冲区和两个纹理来完成。在它们之间进行乒乓操作，从一个读取并写入另一个。有关详细信息，请参阅本章中的*应用高斯模糊过滤器*配方。
- en: 'In the fifth and final pass, switch to linear filtering from the texture that
    was produced in the fourth pass. Switch to the default frame buffer (the screen).
    Apply the tone-mapping operator from the *Implementing HDR lighting with tone
    mapping* recipe to the original image texture (`HdrTex`), and combine the results
    with the blurred texture from step 3\. The linear filtering and magnification
    should provide an additional blur:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第五次和最后一次传递中，从第四次传递产生的纹理切换到线性过滤。切换到默认帧缓冲区（屏幕）。将*使用色调映射实现HDR光照*配方中的色调映射操作应用于原始图像纹理（`HdrTex`），并将结果与步骤3中的模糊纹理组合。线性过滤和放大应提供额外的模糊：
- en: '[PRE6]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works...
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Due to space constraints, the entire fragment shader code isn't shown here.
    The full code is available from the GitHub repository. The fragment shader is
    implemented with five methods, one for each pass. The first pass renders the scene
    normally to the HDR texture. During this pass, the active framebuffer object is
    the one associated with the texture corresponding to `HdrTex`, so the output is
    sent directly to that texture.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空间限制，这里没有显示完整的片段着色器代码。完整的代码可以从GitHub仓库中获取。片段着色器使用五个方法实现，每个方法对应一个传递。第一次传递将场景正常渲染到HDR纹理中。在此传递期间，活动的帧缓冲区对象是与`HdrTex`对应的纹理所关联的，因此输出直接发送到该纹理。
- en: The second pass reads from `HdrTex`, and writes out only pixels that have a
    luminance above the threshold value `LumThresh`. The value is (0,0,0,0) for pixels
    that have a brightness (luma) value below `LumThresh`. The output goes to the
    second framebuffer, which contains a much smaller texture (one-eighth the size
    of the original).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次传递从`HdrTex`读取，并仅写入亮度值高于阈值`LumThresh`的像素。对于亮度（亮度）值低于`LumThresh`的像素，值为(0,0,0,0)。输出进入第二个帧缓冲区，其中包含一个大小大得多的纹理（原始大小的八分之一）。
- en: The third and fourth passes apply the basic Gaussian blur operation (refer to
    the *Applying a Gaussian blur filter* recipe in this chapter). In these passes,
    we ping-pong between `BlurTex1` and `BlurTex2`, so we must be careful to swap
    the appropriate texture into the framebuffer.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 第三和第四次迭代应用基本的高斯模糊操作（参见图章中的*应用高斯模糊滤波器*配方）。在这些迭代中，我们在`BlurTex1`和`BlurTex2`之间进行乒乓操作，因此我们必须小心地将适当的纹理交换到帧缓冲区中。
- en: In the fifth pass, we switch back to the default framebuffer, and read from
    `HdrTex` and `BlurTex1`. `BlurTex1` contains the final blurred result from step
    four, and `HdrTex` contains the original render. We apply tone mapping to the
    results of `HdrTex` and add to `BlurTex1`. When pulling from `BlurTex1`, we are
    applying a linear filter, gaining additional blurring.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在第五次迭代中，我们切换回默认帧缓冲区，并从`HdrTex`和`BlurTex1`中读取。`BlurTex1`包含第四步的最终模糊结果，而`HdrTex`包含原始渲染。我们对`HdrTex`的结果应用色调映射并添加到`BlurTex1`。在从`BlurTex1`中提取时，我们应用线性过滤器，从而获得额外的模糊效果。
- en: There's more...
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Note that we applied the tone-mapping operator to the original rendered image,
    but not to the blurred bright-pass filter image. One could choose to apply the
    TMO to the blurred image as well, but in practice, it is often not necessary.
    We should keep in mind that the bloom effect can also be visually distracting
    if it is overused. A little goes a long way.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已将色调映射运算符应用于原始渲染图像，但未应用于模糊亮通道滤波图像。有人可以选择将TMO应用于模糊图像，但在实践中，这通常不是必要的。我们应该记住，如果过度使用，光晕效果也可能在视觉上分散注意力。适可而止。
- en: See also
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/scenehdrbloom.cpp` file in the example code
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/scenehdrbloom.cpp`文件
- en: '*HDR meets Black & White 2* by Francesco Caruzzi in *Shader X6*'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*HDR meets Black & White 2* by Francesco Caruzzi in *Shader X6*'
- en: The *Rendering to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)中的*将渲染到纹理*配方，*使用纹理*'
- en: The *Applying an edge detection filter* recipe in this chapter
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*应用边缘检测滤波器*配方
- en: Using gamma correction to improve image quality
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用伽玛校正来提高图像质量
- en: It is common for many books about OpenGL and 3D graphics to somewhat neglect
    the subject of gamma correction. Lighting and shading calculations are performed,
    and the results are sent directly to the output buffer without modification. However,
    when we do this, we may produce results that don't quite end up looking the way
    we might expect. This may be due to the fact that computer monitors (both the
    old CRT and the newer LCD) have a non-linear response to pixel intensity. For
    example, without gamma correction, a grayscale value of 0.5 will not appear half
    as bright as a value of 1.0\. Instead, it will appear to be darker than it should.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 许多关于OpenGL和3D图形的书籍通常会忽视伽玛校正的主题。光照和着色计算被执行，结果未经修改直接发送到输出缓冲区。然而，当我们这样做时，我们可能产生与预期不完全一致的结果。这可能是因为计算机显示器（无论是老式的CRT还是较新的LCD）对像素强度的响应是非线性的。例如，没有伽玛校正，灰度值为0.5不会像值为1.0那样亮一半。相反，它看起来会比应有的更暗。
- en: 'The lower curve in the following graph shows the response curves of a typical
    monitor (gamma of **2.2**). The *x* axis is the intensity and the *y* axis is
    the perceived intensity. The dashed line represents a linear set of intensities.
    The upper curve represents gamma correction applied to linear values. The lower
    curve represents the response of a typical monitor. A grayscale value of **0.5**
    would appear to have a value of **0.218** on a screen that had a similar response
    curve:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中较低的曲线显示了典型显示器（伽玛为**2.2**）的响应曲线。*x*轴是强度，*y*轴是感知强度。虚线表示一系列线性强度。上曲线表示应用于线性值的伽玛校正。下曲线表示典型显示器的响应。在具有类似响应曲线的屏幕上，**0.5**的灰度值看起来会有**0.218**的值：
- en: '![](img/50cc84d4-57b2-4ad6-8c16-6deeed516115.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50cc84d4-57b2-4ad6-8c16-6deeed516115.png)'
- en: 'The non-linear response of a typical monitor can usually be modeled using a
    simple power function. The perceived intensity (*P*) is proportional to the pixel
    intensity (*I*) raised to a power that is usually called gamma:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 典型显示器的非线性响应通常可以用一个简单的幂函数来建模。感知强度（*P*）与像素强度（*I*）的幂成正比，这个幂通常称为伽玛：
- en: '![](img/ef0da10a-863e-47ba-b6bb-698d998a9f89.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef0da10a-863e-47ba-b6bb-698d998a9f89.png)'
- en: Depending on the display device, the value of *γ* is usually somewhere between
    2.0 and 2.4\. Some kind of monitor calibration is often needed to determine a
    precise value.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 根据显示设备的不同，*γ*的值通常在2.0到2.4之间。通常需要某种类型的显示器校准来确定精确的值。
- en: 'In order to compensate for this non-linear response, we can apply **gamma correction**
    before sending our results to the output framebuffer. Gamma correction involves
    raising the pixel intensities to a power that will compensate for the monitor''s
    non-linear response to achieve a perceived result that appears linear. Raising
    the linear-space values to the power of *1/γ* will do the trick:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了补偿这种非线性响应，我们可以在将结果发送到输出帧缓冲区之前应用**伽玛校正**。伽玛校正涉及将像素强度提升到一种幂，以补偿显示器对非线性的响应，从而实现看起来线性的感知结果。将线性空间值提升到*1/γ*的幂将起到作用：
- en: '![](img/4221d774-e06e-46f9-ba66-e9f8d89c78ea.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4221d774-e06e-46f9-ba66-e9f8d89c78ea.png)'
- en: When rendering, we can do all of our lighting and shading computations, ignoring
    the fact that the monitor's response curve is non-linear. This is sometimes referred
    to as working in *linear space*. When the final result is to be written to the
    output framebuffer, we can apply the gamma correction by raising the pixel to
    the power of 1/γ just before writing. This is an important step that will help
    to improve the look of the rendered result.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在渲染时，我们可以进行所有的光照和着色计算，忽略显示器响应曲线的非线性。这有时被称为在*线性空间*中工作。当最终结果要写入输出帧缓冲区时，我们可以在写入之前通过将像素提升到1/γ的幂来应用伽玛校正。这是一个重要的步骤，将有助于改善渲染结果的外观。
- en: 'As an example, consider the following images. The image on the left is the
    mesh rendered without any consideration of gamma at all. The reflection model
    is computed and the results are directly sent to the framebuffer. On the right
    is the same mesh with gamma correction applied to the color just prior to output:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下图像。左边的图像是在不考虑伽玛的情况下渲染的网格。反射模型被计算，结果直接发送到帧缓冲区。右边的图像是在输出之前对颜色应用伽玛校正的相同网格：
- en: '![](img/3fd4aef2-aafe-476b-bcd5-e22fc760592c.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fd4aef2-aafe-476b-bcd5-e22fc760592c.png)'
- en: The obvious difference is that the left image appears much darker than the image
    on the right. However, the more important distinction is the variations from light
    to dark across the face. While the transition at the shadow terminator seems stronger
    than before, the variations within the lighted areas are less extreme.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 明显的区别是，左边的图像看起来比右边的图像暗得多。然而，更重要的区别是面部从亮到暗的变化。虽然阴影终止器的过渡似乎比以前更强，但光照区域内的变化不那么极端。
- en: Applying gamma correction is an important technique, and can be effective in
    improving the results of a lighting model.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 应用伽玛校正是一项重要的技术，可以有效提高光照模型的结果。
- en: How to do it...
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Adding gamma correction to an OpenGL program can be as simple as carrying out
    the following steps:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 将伽玛校正添加到OpenGL程序可以像执行以下步骤一样简单：
- en: Set up a uniform variable named `Gamma` and set it to an appropriate value for
    your system.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个名为`Gamma`的统一变量，并将其设置为适合你系统的适当值。
- en: 'Use the following code or something similar in a fragment shader:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在片段着色器中使用以下代码或类似代码：
- en: '[PRE7]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If your shader involves texture data, care must be taken to make sure that the
    texture data is not already gamma-corrected so that you don't apply gamma correction
    twice (refer to the *There's more...* section of this recipe).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的着色器涉及纹理数据，必须小心确保纹理数据没有被预先进行伽玛校正，以免你两次应用伽玛校正（参考本食谱的*更多内容...*部分）。
- en: How it works...
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The color determined by the lighting/shading model is computed and stored in
    the variable `color`. We think of this as computing the color in linear space.
    There is no consideration of the monitor's response during the calculation of
    the shading model (assuming that we don't access any texture data that might already
    be gamma-corrected).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 由光照/着色模型确定的颜色被计算并存储在变量`color`中。我们将其视为在线性空间中计算颜色。在着色模型的计算过程中没有考虑显示器的响应（假设我们没有访问任何可能已经进行伽玛校正的纹理数据）。
- en: To apply the correction, in the fragment shader, we raise the color of the pixel
    to the power of `1.0 / Gamma`, and apply the result to the output variable `FragColor`.
    Of course, the inverse of `Gamma` could be computed outside the fragment shader
    to avoid the division operation.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用校正，在片段着色器中，我们将像素颜色提升到`1.0 / Gamma`的幂，并将结果应用到输出变量`FragColor`。当然，伽玛的倒数可以在片段着色器外部计算，以避免除法操作。
- en: We do not apply the gamma correction to the alpha component because it is typically
    not desired.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不对alpha分量应用伽玛校正，因为这通常是不希望的。
- en: There's more...
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The application of gamma correction is a good idea in general; however, some
    care must be taken to make sure that computations are done within the correct
    space. For example, textures could be photographs or images produced by other
    imaging applications that apply gamma correction before storing the data within
    the image file.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 伽玛校正的应用在一般情况下是个好主意；然而，必须小心确保在正确的空间内进行计算。例如，纹理可能是照片或其他在将数据存储在图像文件之前应用伽玛校正的图像应用产生的图像。
- en: Therefore, if we use a texture in our application as a part of the lighting
    model and then apply gamma correction, we will be effectively applying gamma correction
    twice to the data from the texture. Instead, we need to be careful to "decode"
    the texture data, by raising to the power of gamma prior to using the texture
    data in our lighting model.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们将纹理作为我们的光照模型的一部分并在其上应用伽玛校正，那么我们将对纹理数据实际上应用了两次伽玛校正。相反，我们需要小心地“解码”纹理数据，通过在将纹理数据用于我们的光照模型之前将其提升到伽玛的幂。
- en: There is a very detailed discussion about these and other issues surrounding
    gamma correction in Chapter 24, *The Importance of Being Linear* in the book *GPU
    Gems 3*, edited by Hubert Nguyen (Addison-Wesley Professional 2007), and this
    is highly recommended supplemental reading.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在《GPU Gems 3》一书中，由Hubert Nguyen编辑的“第24章，线性的重要性”中，对这些以及其他关于伽玛校正的问题进行了非常详细的讨论，这本书由Addison-Wesley
    Professional于2007年出版，强烈推荐作为补充阅读材料。
- en: See also
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/scenegamma.cpp` file in the example code
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/scenegamma.cpp`文件
- en: Using multisample anti-aliasing
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多采样抗锯齿
- en: '**Anti-aliasing** is the technique of removing or reducing the visual impact
    of **aliasing artifacts** that are present whenever high-resolution or continuous
    information is presented at a lower resolution. In real-time graphics, aliasing
    often reveals itself in the jagged appearance of polygon edges, or the visual
    distortion of textures that have a high degree of variation.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '**抗锯齿**是一种技术，用于消除或减少在高分辨率或连续信息以较低分辨率呈现时存在的**走样伪影**的视觉影响。在实时图形中，走样通常会在多边形边缘的锯齿状外观或具有高度变化的纹理的视觉失真中显现出来。'
- en: The following images show an example of aliasing artifacts at the edge of an
    object. On the left, we can see that the edge appears jagged. This occurs because
    each pixel is determined to lie either completely inside the polygon or completely
    outside it. If the pixel is determined to be inside, it is shaded, otherwise it
    is not. Of course, this is not entirely accurate. Some pixels lie directly on
    the edge of the polygon. Some of the screen area that the pixel encompasses actually
    lies within the polygon and some lies outside. Better results could be achieved
    if we were to modify the shading of a pixel based upon the amount of the pixel's
    area that lies within the polygon. The result could be a mixture of the shaded
    surface's color with the color outside the polygon, where the area that is covered
    by the pixel determines the proportions. You might be thinking that this sounds
    like it would be prohibitively expensive to do. That may be true; however, we
    can approximate the results by using multiple **samples** per pixel.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了物体边缘的走样伪影示例。在左侧，我们可以看到边缘看起来是锯齿状的。这是因为每个像素被确定要么完全位于多边形内部，要么完全位于多边形外部。如果像素被确定在内部，它会被着色，否则则不会。当然，这并不完全准确。一些像素直接位于多边形的边缘。像素覆盖的屏幕区域中，一些实际上位于多边形内部，而一些位于外部。如果我们根据像素面积在多边形内部的部分修改像素的着色，可能会得到更好的结果。结果可能是着色表面的颜色与多边形外部的颜色的混合，其中像素覆盖的区域决定了比例。你可能认为这样做可能会非常昂贵。这可能确实如此；然而，我们可以通过每个像素使用多个**样本**来近似结果。
- en: '**Multisample anti-aliasing** involves evaluating multiple samples per pixel
    and combining the results of those samples to determine the final value for the
    pixel. The samples are located at various points within the pixel''s extent. Most
    of these samples will fall inside the polygon, but for pixels near a polygon''s
    edge, some will fall outside. The fragment shader will typically execute only
    once for each pixel as usual. For example, with 4x **multisample anti-aliasing**
    (**MSAA**), rasterization happens at four times the frequency. For each pixel,
    the fragment shader is executed once and the result is scaled based on how many
    of the four samples fall within the polygon.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**多采样抗锯齿**涉及对每个像素进行多次采样并将这些样本的结果组合起来以确定像素的最终值。这些样本位于像素范围内的各个点。其中大部分样本将落在多边形内部，但对于靠近多边形边缘的像素，一些样本将落在多边形外部。片段着色器通常像往常一样为每个像素执行一次。例如，对于4x
    **多采样抗锯齿**（**MSAA**），光栅化发生的频率是四倍。对于每个像素，片段着色器执行一次，结果根据有多少个样本落在多边形内进行缩放。'
- en: 'The following image on the right shows the results when multisample anti-aliasing
    is used. The inset image is a zoomed portion of the inside edge of a torus. On
    the left, the torus is rendered without MSAA. The right-hand image shows the results
    with MSAA enabled:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的以下图像显示了使用多采样抗锯齿时的结果。内嵌图像是环面内部边缘的一个放大部分。在左侧，环面没有使用MSAA进行渲染。右侧的图像显示了启用MSAA后的结果：
- en: '![](img/48ab445e-7ee5-4686-b867-0b6bb88f129f.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48ab445e-7ee5-4686-b867-0b6bb88f129f.png)'
- en: OpenGL has supported multisampling for some time now, and it is nearly transparent
    to use. It is simply a matter of turning it on or off. It works by using additional
    buffers to store the subpixel samples as they are processed. Then, the samples
    are combined together to produce a final color for the fragment. Nearly all of
    this is automatic, and there is little that a programmer can do to fine-tune the
    results. However, at the end of this recipe, we'll discuss the interpolation qualifiers
    that can affect the results.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: OpenGL已经支持多采样一段时间了，使用起来几乎是透明的。这只是一个开启或关闭的问题。它是通过使用额外的缓冲区来存储在处理过程中产生的亚像素样本来工作的。然后，将这些样本组合起来以产生片段的最终颜色。几乎所有这些都是自动的，程序员几乎无法对结果进行微调。然而，在本食谱的末尾，我们将讨论可能影响结果的插值限定符。
- en: In this recipe, we'll see the code needed to enable multisample anti-aliasing
    in an OpenGL application.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将看到在OpenGL应用程序中启用多采样抗锯齿所需的代码。
- en: Getting ready
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The technique for enabling multisampling is unfortunately dependent on the window
    system API. In this example, we'll demonstrate how it is done using GLFW. The
    steps will be similar in GLUT or other APIs that support OpenGL.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 启用多采样的技术不幸地依赖于窗口系统API。在这个例子中，我们将演示如何使用GLFW来实现。步骤在GLUT或其他支持OpenGL的API中将是相似的。
- en: How to do it...
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To make sure that the multisample buffers are created and available, use the
    following steps:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保创建并可用多采样缓冲区，请按照以下步骤操作：
- en: 'When creating your OpenGL window, you need to select an OpenGL context that
    supports MSAA. The following is how one would do so in GLFW:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建你的OpenGL窗口时，你需要选择支持MSAA的OpenGL上下文。以下是在GLFW中这样做的方法：
- en: '[PRE8]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To determine whether multisample buffers are available and how many samples
    per-pixel are actually being used, you can use the following code (or something
    similar):'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要确定是否可用多采样缓冲区以及每像素实际使用多少个样本，你可以使用以下代码（或类似代码）：
- en: '[PRE9]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To enable multisampling, use the following:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启用多采样，请使用以下代码：
- en: '[PRE10]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To disable multisampling, use the following:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要禁用多采样，请使用以下代码：
- en: '[PRE11]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How it works...
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: As we just mentioned, the technique for creating an OpenGL context with multisample
    buffers is dependent on the API used for interacting with the window system. The
    preceding example demonstrates how it might be done using GLFW. Once the OpenGL
    context is created, it is easy to enable multisampling by simply using the `glEnable`
    call shown in the preceding example.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚才提到的，创建具有多采样缓冲区的OpenGL上下文的技术取决于与窗口系统交互所使用的API。前面的示例演示了如何使用GLFW来实现这一点。一旦创建了OpenGL上下文，就可以通过简单地使用前面示例中显示的`glEnable`调用来启用多采样。
- en: Stay tuned, because in the next section, we'll discuss a subtle issue surrounding
    interpolation of shader variables when multisample anti-aliasing is enabled.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请保持关注，因为在下一节中，我们将讨论在启用多采样抗锯齿时围绕着色器变量插值的一个微妙问题。
- en: There's more...
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: There are two interpolation qualifiers within the GLSL that allow the programmer
    to fine-tune some aspects of multisampling. They are `sample` and `centroid`.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在GLSL中有两个插值限定符，允许程序员微调多采样的一些方面。它们是`sample`和`centroid`。
- en: 'Before we can get into how `sample` and `centroid` work, we need a bit of background.
    Let''s consider the way that polygon edges are handled without multisampling.
    A fragment is determined to be inside or outside of a polygon by determining where
    the center of that pixel lies. If the center is within the polygon, the pixel
    is shaded, otherwise it is not. The following image represents this behavior.
    It shows pixels near a polygon edge without MSAA. The line represents the edge
    of the polygon. Gray pixels are considered to be inside the polygon. White pixels
    are outside and are not shaded. The dots represent the pixel centers:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够深入了解`sample`和`centroid`如何工作之前，我们需要一些背景知识。让我们考虑在没有多采样的情况下处理多边形边的方式。一个片段被判定为在多边形内部还是外部，是通过确定该像素中心的位置来实现的。如果中心位于多边形内，则该像素被着色，否则不被着色。以下图像展示了这种行为。它显示了没有MSAA的多边形边缘附近的像素。线条代表多边形的边缘。灰色像素被认为是多边形内部。白色像素在多边形外部，并且不被着色。点代表像素中心：
- en: '![](img/749a3226-d018-4f8f-8944-265097202507.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/749a3226-d018-4f8f-8944-265097202507.png)'
- en: The values for the interpolated variables (the fragment shader's input variables)
    are interpolated with respect to the center of each fragment, which will always
    be inside the polygon.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 对于插值变量（片段着色器的输入变量）的值，是相对于每个片段的中心进行插值的，这始终位于多边形内。
- en: When multisample anti-aliasing is enabled, multiple samples are computed per
    fragment at various locations within the fragment's extent. If any of those samples
    lie within the polygon, then the shader is executed at least once for that pixel
    (but not necessarily for each sample).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用多采样抗锯齿时，每个片段在其范围内的多个位置计算多个样本。如果其中任何一个样本位于多边形内，则至少为该像素执行一次着色器（但不一定是每个样本）。
- en: 'As a visual example, the following image represents pixels near a polygon''s
    edge. The dots represent the samples. The dark samples lie within the polygon
    and the white samples lie outside the polygon. If any sample lies within the polygon,
    the fragment shader is executed (usually only once) for that pixel. Note that
    for some pixels, the pixel center lies outside the polygon. So, with MSAA, the
    fragment shader may execute slightly more often near the edges of polygons:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 作为视觉示例，以下图像展示了多边形边缘附近的像素。点代表样本。深色样本位于多边形内，白色样本位于多边形外。如果任何样本位于多边形内，则对该像素执行片段着色器（通常只执行一次）。请注意，对于某些像素，像素中心位于多边形外。因此，在MSAA的情况下，片段着色器可能在多边形的边缘附近稍微执行得更频繁：
- en: '![](img/bba2698a-8fc3-40ce-8440-9f9a3db25a3d.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/bba2698a-8fc3-40ce-8440-9f9a3db25a3d.png)'
- en: Now, here's the important point. The values of the fragment shader's input variables
    are normally interpolated to the center of the pixel rather than to the location
    of any particular sample. In other words, the value that is used by the fragment
    shader is determined by interpolating to the location of the fragment's center,
    which may lie outside the polygon! If we are relying on the fact that the fragment
    shader's input variables are interpolated strictly between their values at the
    vertices (and not outside that range), then this might lead to unexpected results.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里有一个重要的观点。片段着色器的输入变量值通常是插值到像素中心，而不是任何特定样本的位置。换句话说，片段着色器使用的值是通过插值到片段中心的位置来确定的，这个位置可能位于多边形外部！如果我们依赖于片段着色器的输入变量严格插值在顶点值之间（而不是该范围之外），那么这可能会导致意外的结果。
- en: 'As an example, consider the following portion of a fragment shader:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下片段着色器的一部分：
- en: '[PRE12]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This shader is designed to color the polygon black unless the `s` component
    of the texture coordinate is greater than one. In that case, the fragment gets
    a yellow color. If we render a square with texture coordinates that range from
    zero to one in each direction, we may get the results shown in the following image
    on the left. The following images show the enlarged edge of a polygon where the
    `s` texture coordinate is about `1.0`. Both images were rendered using the preceding
    shader. The right-hand image was created using the `centroid` qualifier (more
    on this later in this chapter):'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 此着色器设计为将多边形着色为黑色，除非纹理坐标的`s`分量大于一。在这种情况下，片段将获得黄色。如果我们渲染一个每个方向纹理坐标范围从零到一的方形，我们可能会得到以下左侧图像所示的结果。以下图像显示了多边形边缘的放大图像，其中`s`纹理坐标约为`1.0`。两个图像都是使用前面的着色器渲染的。右侧图像是使用`centroid`修饰符创建的（关于这一点将在本章后面详细说明）：
- en: '![](img/434513f5-5d71-4f11-9093-e3de16063b00.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/434513f5-5d71-4f11-9093-e3de16063b00.png)'
- en: The left image shows that some pixels along the edge have a lighter color (yellow,
    if the image is in full color). This is due to the fact that the texture coordinate
    is interpolated to the pixel's center, rather than to any particular sample's
    location. Some of the fragments along the edge have a center that lies outside
    of the polygon and therefore end up with a texture coordinate that is greater
    than one!
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧图像显示边缘的一些像素颜色较浅（如果图像是全彩的，则为黄色）。这是由于纹理坐标被插值到像素中心，而不是任何特定的样本位置。边缘的一些片段中心位于多边形外部，因此最终得到的纹理坐标大于一！
- en: 'We can ask OpenGL to instead compute the value for the input variable by interpolating
    to some location that is not only within the pixel but also within the polygon.
    We can do so by using the `centroid` qualifier, as shown in the following code:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以要求OpenGL通过插值到像素内且在多边形内的某个位置来计算输入变量的值。我们可以通过使用`centroid`修饰符来实现，如下面的代码所示：
- en: '[PRE13]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: (The qualifier needs to also be included with the corresponding output variable
    in the vertex shader.) When `centroid` is used with the preceding shader, we get
    the preceding image shown on the right.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: （修饰符还需要与顶点着色器中相应的输出变量一起使用。）当与前面的着色器一起使用`centroid`时，我们得到右侧显示的先前图像。
- en: In general, we should use `centroid` or `sample` when we know that the interpolation
    of the input variables should not extend beyond the values of those variables
    at the vertices.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们知道输入变量的插值不应超出这些变量在顶点处的值时，我们应该使用`centroid`或`sample`。
- en: 'The `sample` qualifier forces OpenGL to interpolate the shader''s input variables
    to the actual location of the sample itself:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '`sample`修饰符强制OpenGL将着色器的输入变量插值到样本本身的实际位置：'
- en: '[PRE14]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This, of course, requires that the fragment shader be executed once for each
    sample. This will produce the most accurate results, but the performance hit may
    not be worthwhile, especially if the visual results produced by `centroid` (or
    without the default) are good enough.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然要求对于每个样本执行一次片段着色器。这将产生最准确的结果，但性能损失可能不值得，尤其是如果由`centroid`（或默认值）产生的视觉结果已经足够好的情况下。
- en: See also
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/scenemsaa.cpp` file in the example code
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/scenemsaa.cpp`文件
- en: Using deferred shading
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用延迟着色
- en: '**Deferred shading** is a technique that involves postponing (or *deferring*)
    the lighting/shading step to a second pass. We do this (among other reasons) in
    order to avoid shading a pixel more than once. The basic idea is as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**延迟着色**是一种涉及将（或*推迟*）光照/着色步骤到第二次遍历的技术。我们这样做（以及其他原因）是为了避免对像素进行多次着色。基本思想如下：'
- en: In the first pass, we render the scene, but instead of evaluating the reflection
    model to determine a fragment color, we simply store all of the geometry information
    (position, normal, texture coordinate, reflectivity, and so on) in an intermediate
    set of buffers, collectively called the **g-buffer** (g for geometry).
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次遍历中，我们渲染场景，但不是通过评估反射模型来确定片段颜色，而是简单地将所有几何信息（位置、法线、纹理坐标、反射率等）存储在一个中间缓冲区集中，统称为**g缓冲区**（g代表几何）。
- en: In the second pass, we simply read from the g-buffer, evaluate the reflection
    model, and produce a final color for each pixel.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二次遍历中，我们简单地从g缓冲区读取，评估反射模型，并为每个像素生成最终颜色。
- en: When deferred shading is used, we avoid evaluating the reflection model for
    a fragment that will not end up being visible. For example, consider a pixel located
    in an area where two polygons overlap. The fragment shader may be executed once
    for each polygon that covers that pixel; however, the resulting color of only
    one of the two executions will end up being the final color for that pixel (assuming
    that blending is not enabled). The cycles spent in evaluating the reflection model
    for one of the two fragments are effectively wasted. With deferred shading, the
    evaluation of the reflection model is postponed until all the geometry has been
    processed, and the visible geometry is known at each pixel location. Hence, the
    reflection model is evaluated only once for each pixel on the screen. This allows
    us to do lighting in a more efficient fashion. For example, we could use even
    hundreds of light sources because we are only evaluating the lighting once per
    screen pixel.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用延迟着色时，我们避免评估最终不会可见的片段的反射模型。例如，考虑一个位于两个多边形重叠区域中的像素。片段着色器可能为覆盖该像素的每个多边形执行一次；然而，只有两次执行中的一次的结果将成为该像素的最终颜色（假设没有启用混合）。评估其中一个片段的反射模型所花费的周期实际上是浪费的。使用延迟着色，反射模型的评估被推迟到所有几何体都已被处理，并且每个像素位置都已知可见几何体。因此，反射模型仅在屏幕上的每个像素上评估一次。这使我们能够以更高效的方式进行光照。例如，我们可以使用甚至数百个光源，因为我们只为每个屏幕像素评估一次光照。
- en: Deferred shading is fairly simple to understand and work with. It can therefore
    help with the implementation of complex lighting/reflection models.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟着色相对简单易懂，因此可以帮助实现复杂的光照/反射模型。
- en: 'In this recipe, we''ll go through a simple example of deferred shading. We''ll
    store the following information in our g-buffer: the position, normal, and diffuse
    color (the diffuse reflectivity). In the second pass, we''ll simply evaluate the
    diffuse lighting model using the data stored in the g-buffer.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将通过一个简单的延迟着色示例。我们将在我们的g-buffer中存储以下信息：位置、法线和漫反射颜色（漫反射反射率）。在第二次遍历中，我们将简单地使用存储在g缓冲区中的数据评估漫反射光照模型。
- en: This recipe is meant to be a starting point for deferred shading. If we were
    to use deferred shading in a more substantial (real-world) application, we'd probably
    need more components in our g-buffer. It should be straightforward to extend this
    example to use more complex lighting/shading models.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这个菜谱旨在作为延迟着色的起点。如果我们要在更实质的（现实世界）应用程序中使用延迟着色，我们可能需要在我们的g缓冲区中添加更多组件。扩展此示例以使用更复杂的光照/着色模型应该是直接明了的。
- en: Getting ready
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The g-buffer will contain three textures for storing the position, normal,
    and diffuse color. There are three uniform variables that correspond to these
    three textures: `PositionTex`, `NormalTex`, and `ColorTex`; these textures should
    be assigned to texture units `0`, `1`, and `2`, respectively. Likewise, the vertex
    shader assumes that position information is provided in vertex attribute `0`,
    the normal is provided in attribute `1`, and the texture coordinate in attribute
    `2`.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: g缓冲区将包含三个纹理来存储位置、法线和漫反射颜色。有三个统一变量对应于这三个纹理：`PositionTex`、`NormalTex`和`ColorTex`；这些纹理应分别分配到纹理单元`0`、`1`和`2`。同样，顶点着色器假定位置信息由顶点属性`0`提供，法线由属性`1`提供，纹理坐标由属性`2`提供。
- en: The fragment shader has several uniform variables related to light and material
    properties that must be set from the OpenGL program. Specifically, the structures
    `Light` and `Material` apply to the shading model used here.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 片段着色器有几个与光照和材质属性相关的统一变量，这些变量必须从OpenGL程序中设置。具体来说，`Light`和`Material`结构体适用于这里使用的着色模型。
- en: You'll need a variable named `deferredFBO` (type `GLuint`) to store the handle
    to the FBO.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个名为`deferredFBO`（类型为`GLuint`）的变量来存储FBO的句柄。
- en: How to do it...
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'To create the framebuffer object that contains our g-buffer(s) use the following
    code:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建包含我们的g-buffer（s）的帧缓冲对象，请使用以下代码：
- en: '[PRE15]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: During the first pass, the fragment shader writes to the G-buffers.  In the
    second pass, it reads from them and applies the shading model.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次遍历中，片段着色器将写入G缓冲区。在第二次遍历中，它将从这些缓冲区读取并应用着色模型。
- en: '[PRE16]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the `render` function of the OpenGL application, use the following steps
    for pass #1:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenGL应用程序的`render`函数中，对于遍历#1，使用以下步骤：
- en: Bind to the framebuffer object `deferredFBO`
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绑定到帧缓冲对象`deferredFBO`
- en: Clear the color/depth buffers, set `Pass` to `1`, and enable the depth test
    (if necessary)
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清除颜色/深度缓冲区，将`Pass`设置为`1`，并启用深度测试（如果需要）
- en: Render the scene normally
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正常渲染场景
- en: 'Use the following steps for pass #2:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下步骤进行第2次传递：
- en: Revert to the default FBO (bind to framebuffer 0)
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恢复到默认的FBO（绑定到帧缓冲区0）
- en: Clear the color buffer, set `Pass` to `2`, and disable the depth test (if desired)
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清除颜色缓冲区，将`Pass`设置为`2`，并禁用深度测试（如果需要）
- en: Render a screen-filling quad (or two triangles) with texture coordinates that
    range from zero to one in each direction
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用纹理坐标在每个方向上从零到一的屏幕填充四边形（或两个三角形）进行渲染
- en: How it works...
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: When setting up the FBO for the g-buffer, we use textures with the internal
    format `GL_RGB32F` for the position and normal components. As we are storing geometry
    information, rather than simply color information, there is a need to use a higher
    resolution (that is more bits per pixel). The buffer for the diffuse reflectivity
    just uses `GL_RGB8` since we don't need the extra resolution for these values.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置g-buffer的FBO时，我们使用具有内部格式`GL_RGB32F`的纹理来存储位置和法线分量。由于我们存储的是几何信息，而不是简单的颜色信息，因此需要使用更高分辨率的纹理（即每个像素更多的位）。漫反射率的缓冲区仅使用`GL_RGB8`，因为我们不需要为这些值提供额外的分辨率。
- en: 'The three textures are then attached to the framebuffer at color attachments
    `0`, `1`, and `2` using `glFramebufferTexture2D`. They are then connected to the
    fragment shader''s output variables with the call to `glDrawBuffers`:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将这三个纹理通过`glFramebufferTexture2D`附加到帧缓冲区的颜色附件`0`、`1`和`2`。接着，通过调用`glDrawBuffers`将它们连接到片段着色器的输出变量：
- en: '[PRE17]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The array `drawBuffers` indicates the relationship between the framebuffer's
    components and the fragment shader's output variable locations. The *i*^(th) item
    in the array corresponds to the *i*^(th) output variable location. This call sets
    color attachments `0`, `1`, and `2` to output variable locations `1`, `2`, and
    `3`, respectively. (Note that the fragment shader's corresponding variables are
    `PositionData`, `NormalData`, and `ColorData`.)
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 数组`drawBuffers`表示帧缓冲区组件与片段着色器输出变量位置之间的关系。数组中的第*i*项对应于第*i*个输出变量位置。此调用将颜色附件`0`、`1`和`2`分别设置为输出变量位置`1`、`2`和`3`。（注意，片段着色器中相应的变量是`PositionData`、`NormalData`和`ColorData`。）
- en: During pass 2, it is not strictly necessary to convert and pass through the
    normal and position, as they will not be used in the fragment shader at all. However,
    to keep things simple, this optimization is not included. It would be a simple
    matter to add a subroutine to the vertex shader in order to *switch off* the conversion
    during pass 2\. (Of course, we need to set `gl_Position` regardless.)
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2次传递过程中，转换和传递法线和位置不是严格必要的，因为它们在片段着色器中根本不会被使用。然而，为了保持简单，这个优化没有被包括在内。向顶点着色器中添加一个子例程来*关闭*第2次传递中的转换是件简单的事情。（当然，我们需要设置`gl_Position`。）
- en: In the fragment shader, the functionality depends on the value of the variable
    `Pass`. It will either call `pass1` or `pass2`, depending on its value. In the
    `pass1` function, we store the values of `Position`, `Normal`, and `Material.Kd`
    in the appropriate output variables, effectively storing them in the textures
    that we just talked about.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在片段着色器中，功能取决于变量`Pass`的值。它将根据其值调用`pass1`或`pass2`。在`pass1`函数中，我们将`Position`、`Normal`和`Material.Kd`的值存储在适当的输出变量中，实际上是将它们存储在我们刚刚提到的纹理中。
- en: In the `pass2` function, the values of the position, normal, and color are retrieved
    from the textures, and used to evaluate the diffuse lighting model. The result
    is then stored in the output variable `FragColor`. In this pass, `FragColor` should
    be bound to the default framebuffer, so the results of this pass will appear on
    the screen.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pass2`函数中，从纹理中检索位置、法线和颜色值，并用于评估漫反射光照模型。然后将结果存储在输出变量`FragColor`中。在这个传递过程中，`FragColor`应该绑定到默认帧缓冲区，因此这个传递的结果将显示在屏幕上。
- en: There's more...
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In the graphics community, the relative advantages and disadvantages of deferred
    shading are a source of some debate. Deferred shading is not ideal for all situations.
    It depends greatly on the specific requirements of your application, and one needs
    to carefully evaluate the benefits and drawbacks before deciding whether or not
    to use deferred shading.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在图形社区中，延迟着色的相对优缺点是某些争论的来源。延迟着色并不适用于所有情况。它很大程度上取决于你应用程序的具体要求，并且在决定是否使用延迟着色之前，需要仔细评估其利弊。
- en: Multi-sample anti-aliasing with deferred shading is possible in recent versions
    of OpenGL by making use of `GL_TEXTURE_2D_MULTISAMPLE`.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenGL的较新版本中，可以通过使用`GL_TEXTURE_2D_MULTISAMPLE`来实现具有延迟着色的多样本抗锯齿。
- en: Another consideration is that deferred shading can't do blending/transparency
    very well. In fact, blending is impossible with the basic implementation we saw
    some time ago. Additional buffers with depth-peeling can help by storing additional
    layered geometry information in the g-buffer.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个考虑因素是，延迟着色在混合/透明度方面做得不是很好。实际上，使用我们之前看到的基本实现进行混合是不可能的。通过在g缓冲区中存储额外的分层几何信息，使用具有深度剥离的额外缓冲区可以帮助解决这个问题。
- en: One notable advantage of deferred shading is that one can retain the depth information
    from the first pass and access it as a texture during the shading pass. Having
    access to the entire depth buffer as a texture can enable algorithms such as depth
    of field (depth blur), screen space ambient occlusion, volumetric particles, and
    other similar techniques.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟着色的一个显著优点是，可以保留第一次遍历中的深度信息，并在着色遍历期间将其作为纹理访问。能够将整个深度缓冲区作为纹理访问可以启用诸如景深（深度模糊）、屏幕空间环境光遮蔽、体积粒子以及其他类似技术等算法。
- en: For much more information about deferred shading, refer to Chapter 9 in *GPU
    Gems 2* edited by Matt Pharr and Randima Fernando (Addison-Wesley Professional
    2005) and Chapter 19 of *GPU Gems 3* edited by Hubert Nguyen (Addison-Wesley Professional
    2007). Both combined, provide an excellent discussion of the benefits and drawbacks
    of deferred shading, and how to make the decision whether or not to use it in
    your application.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多关于延迟着色的信息，请参阅由Matt Pharr和Randima Fernando编辑的《GPU Gems 2》（Addison-Wesley
    Professional 2005）的第9章以及由Hubert Nguyen编辑的《GPU Gems 3》（Addison-Wesley Professional
    2007）的第19章。这两章结合在一起，对延迟着色的优缺点进行了出色的讨论，并说明了如何在应用程序中决定是否使用它。
- en: See also
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/scenedeferred.cpp` file in the example code
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/scenedeferred.cpp`文件
- en: The *Rendering to a texture* recipe in [Chapter 5](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml),
    *Using Textures*
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章](a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml)中的*渲染到纹理*配方，*使用纹理*'
- en: Screen space ambient occlusion
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 屏幕空间环境光遮蔽
- en: '**Ambient occlusion** is a rendering technique that is based on the assumption
    that a surface receives uniform illumination from all directions. Some surface
    positions will receive less light than others due to objects nearby that occlude
    some of the light. If a surface point has a lot of local geometry nearby, some
    of this ambient illumination will be blocked causing the point to be darker.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '**环境光遮蔽**是一种基于假设表面从所有方向接收均匀光照的渲染技术。由于附近有遮挡一些光线的物体，一些表面位置会比其他位置接收到的光更少。如果一个表面点附近有大量的局部几何形状，那么一些这种环境光照将被阻挡，导致该点变暗。'
- en: 'An example of this is shown in the following image (generated using Blender):'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了这个示例（使用Blender生成）：
- en: '![](img/56affbb3-efb5-4155-acfc-31954f85d841.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/56affbb3-efb5-4155-acfc-31954f85d841.png)'
- en: This image is rendered using ambient occlusion only, without light sources.
    Note how the result looks like shadows in areas that have local geometry occluding
    the ambient illumination. The result is quite pleasing to the eye and adds a significant
    amount of realism to an image.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像仅使用环境光遮蔽渲染，没有光源。注意结果在具有局部几何形状遮挡环境光照的区域看起来像阴影。结果对眼睛来说非常令人愉悦，并为图像增添了大量的真实感。
- en: 'Ambient occlusion is calculated by testing the visibility of a surface point
    from the upper hemisphere centered at the surface point. Consider the two points
    **A** and **B** in the following diagram:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 环境光遮蔽是通过从以表面点为中心的上半球测试表面点的可见性来计算的。考虑以下图中**A**和**B**两个点：
- en: '![](img/192adb51-45a0-4f2c-9f50-ea51deedf14d.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/192adb51-45a0-4f2c-9f50-ea51deedf14d.png)'
- en: Point **A** is near a corner of the surface and point **B** is located on a
    flat area. The arrows represent directions for visibility testing. All directions
    in the hemisphere above point **B** are unoccluded, meaning that the rays do not
    intersect with any geometry. However, in the hemisphere above point **A**, roughly
    half of the directions are occluded (arrows with dashed lines). Therefore, **A**
    should receive less illumination and appear darker than point **B**.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 点**A**位于表面的一个角落附近，而点**B**位于一个平坦区域。箭头表示可见性测试的方向。点**B**上方的半球内所有方向都是未被遮挡的，这意味着光线不会与任何几何形状相交。然而，在点**A**上方的半球内，大约有一半的方向被遮挡（带有虚线的箭头）。因此，**A**应该接收到的光照较少，看起来比点**B**更暗。
- en: Essentially, ambient occlusion boils down to the following process. Sample as
    many directions as possible in the upper hemisphere around the surface point.
    Test each direction for visibility (occlusion). The fraction of rays that are
    unoccluded gives the ambient occlusion factor at that point.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，环境光遮蔽可以归结为以下过程。在表面点周围的半球上尽可能多地采样。测试每个方向的可视性（遮挡）。未被遮挡的射线比例给出了该点的环境光遮蔽因子。
- en: This process generally requires a large number of samples to produce acceptable
    results. To do this for every vertex of a mesh would be impractical in real time
    for complex scenes. However, the results can be precomputed and stored in a texture
    for static scenes. If the geometry can move, we need some approximation that is
    independent of the complexity of the scene.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程通常需要大量的样本才能产生可接受的结果。对于复杂场景中的每个网格顶点来说，在实时情况下这样做是不切实际的。然而，对于静态场景，结果可以预先计算并存储在纹理中。如果几何形状可以移动，我们需要一些与场景复杂度无关的近似方法。
- en: '**Screen space ambient occlusion** (or **SSAO**) is the name for a class of
    algorithms that attempt to approximate ambient occlusion in real time using screen
    space information. In other words, with SSAO, we compute the ambient occlusion
    in a post process after the scene has been rendered using the data stored in the
    depth buffer and/or geometry buffers. SSAO works naturally in conjunction with
    deferred shading (see the recipe *Using deferred shading*), but has been implemented
    with forward (non-deferred) renderers as well.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '**屏幕空间环境光遮蔽**（或 **SSAO**）是一类算法的名称，这些算法试图通过使用屏幕空间信息实时近似环境光遮蔽。换句话说，使用SSAO，我们将在场景渲染后，使用存储在深度缓冲区和/或几何缓冲区中的数据，在后期处理中计算环境光遮蔽。SSAO与延迟着色（参见配方
    *使用延迟着色*）自然结合，但也已与前向（非延迟）渲染器一起实现。'
- en: 'In this recipe, we''ll implement SSAO as part of a deferred rendering process.
    We''ll compute the ambient occlusion factor at each screen-space pixel, rather
    than on the surface of each object in the scene, ignoring any geometry that is
    occluded from the camera. After the first pass of a deferred shading renderer,
    we have position, normal, and color information for the visible surface locations
    at each screen pixel in our g-buffers (see the *Using deferred shading* recipe).
    For each pixel, we''ll use the position and normal vector to define the hemisphere
    above the surface point. Then, we will randomly choose locations (samples) within
    that hemisphere and test each location for visibility:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将作为延迟渲染过程的一部分实现SSAO。我们将计算每个屏幕空间像素的环境光遮蔽因子，而不是在场景中每个物体的表面上，忽略任何从相机遮挡的几何形状。在延迟着色渲染器的第一次遍历后，我们在我们的g-buffers（参见配方
    *使用延迟着色*）中具有每个屏幕像素的可见表面位置的位置、法线和颜色信息。对于每个像素，我们将使用位置和法线向量定义表面点上的半球。然后，我们将在该半球内随机选择位置（样本）并测试每个位置的可见性：
- en: '![](img/2f5d01ef-48b5-4df2-944a-7bdaf107dc60.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2f5d01ef-48b5-4df2-944a-7bdaf107dc60.png)'
- en: The preceding image represents occlusion testing for the surface point **P**.
    The filled and hollow circles are random sample points chosen within the hemisphere
    above **P**, centered along the normal vector. Hollow circles fail the visibility
    test and the filled circles pass.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图表示了表面点 **P** 的遮挡测试。实心圆和空心圆是在 **P** 上方的半球内随机选择的样本点，沿法向量中心分布。空心圆未通过可见性测试，而实心圆通过了测试。
- en: To accurately test for visibility, we would need to trace a ray from the surface
    point toward all sample points and check each ray for intersection with a surface.
    However, we can avoid that expensive process. Rather than tracing rays, we'll
    estimate the visibility by defining a point as visible from the surface point
    in the following way. If the point is visible from the camera, we'll assume that
    it is also visible from the surface point. This can be inaccurate for some cases,
    but is a good approximation for a wide variety of typical scenes.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确测试可见性，我们需要从表面点向所有样本点发射射线，并检查每条射线是否与表面相交。然而，我们可以避免这个过程。而不是追踪射线，我们将通过以下方式定义一个点从表面点可见：如果该点从相机可见，我们将假设它也从表面点可见。这在某些情况下可能不准确，但对于各种典型场景来说是一个很好的近似。
- en: 'In fact, we''ll use one additional approximation. We won''t trace a ray from
    the camera to the surface point; instead, we''ll just compare the *z* coordinates
    of the point being tested and the surface point at the same (x,y) position in
    camera space. This introduces another small amount of error, but not enough to
    be objectionable in practice. The following diagram illustrates this concept:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们将使用一个额外的近似。我们不会从相机到表面点追踪射线；相反，我们只需比较被测试点和表面点在相机空间中相同 (x,y) 位置的 *z* 坐标。这引入了另一小部分错误，但在实践中并不足以引起反感。以下图解说明了这个概念：
- en: '![](img/61ce5241-0d1c-464f-be2c-4a4418e977dd.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61ce5241-0d1c-464f-be2c-4a4418e977dd.png)'
- en: For each sample that we test within the hemisphere, we find the corresponding
    location on the camera-visible surface at the same (x,y) position in camera coordinates.
    This position is simply the value in the position g-buffer at the (x,y) location
    of the sample. We then compare the *z* coordinates of the sample and the surface
    point. If the *z* coordinate of the surface point is larger than the sample's
    *z* coordinate (remember, we're in camera coordinates so all *z* coordinates will
    be negative), then we consider the sample to be occluded by the surface.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们在半球内测试的每个样本，我们找到在相机坐标中相同 (x,y) 位置上相机可见表面上的对应位置。这个位置简单地是样本在 (x,y) 位置的 g-缓冲区中的值。然后我们比较样本和表面点的
    *z* 坐标。如果表面点的 *z* 坐标大于样本的 *z* 坐标（记住，我们在相机坐标中，所以所有 *z* 坐标都将为负），那么我们认为样本被表面遮挡。
- en: As the preceding diagram shows, this is an approximation of what a trace of
    the eye-ray might find. What precedes is a basic overview of the process and there's
    not much more to it than that. This algorithm boils down to testing a number of
    random samples in the hemisphere above each point.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，这是眼射线可能发现的近似。前面的内容是过程的基本概述，没有更多内容。此算法归结为在每个点的半球上测试多个随机样本。
- en: The proportion of visible samples is the ambient occlusion factor. Of course,
    there are a bunch of details to be worked out. Let's start with an overview of
    the process. We'll implement this algorithm with four passes.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 可见样本的比例是环境遮挡因子。当然，还有许多细节需要解决。让我们从过程概述开始。我们将使用四个遍历来实现此算法。
- en: 'The first pass renders the data to the g-buffers: camera space position, normal,
    and base color.'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一遍将数据渲染到 g-缓冲区：相机空间位置、法向量和基础颜色。
- en: The second pass computes the ambient occlusion factor for each screen pixel.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二遍计算每个屏幕像素的环境遮挡因子。
- en: The third pass is a simple blur of the ambient occlusion data to remove high
    frequency artifacts.
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三遍是对环境遮挡数据的简单模糊，以消除高频伪影。
- en: The final pass is a lighting pass. The reflection model is evaluated, integrating
    the ambient occlusion.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终遍历是光照遍历。评估反射模型，整合环境遮挡。
- en: The last three of these passes employs a screen-space technique, meaning that
    we invoke the fragment shader once for each pixel on the screen by rendering just
    a single screen filling quad. The actual geometry for the scene is only rendered
    during the first pass. The bulk of the interesting stuff here happens in pass
    2\. There we need to generate a number of random points in the hemisphere above
    the surface at each point. Random number generation within a shader is challenging
    for a number of reasons that we won't go into here. So, instead of trying to generate
    random numbers, we'll pre-generate a set of random points in a hemisphere centered
    around the *z* axis. We'll refer to this as our random kernel. We'll re-use this
    kernel at each point by transforming the points to camera space, aligning the
    kernel's *z* axis with the normal vector at the surface point. To squeeze out
    a bit more randomness, we'll also rotate the kernel around the normal vector by
    a random amount.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 最后三遍使用屏幕空间技术，这意味着我们通过仅渲染一个填充整个屏幕的四边形，为屏幕上的每个像素调用一次片段着色器。场景的实际几何图形仅在第一遍渲染。这里有趣的部分主要发生在第二遍。在那里，我们需要在每个点的表面上方生成多个随机点。在着色器内生成随机数由于多种原因而具有挑战性，这里我们不会深入探讨。因此，我们不会尝试生成随机数，而是在围绕
    *z* 轴中心的半球中预先生成一组随机点。我们将称之为我们的随机核。我们将通过将点转换到相机空间，使核的 *z* 轴与表面点的法向量对齐，在每个点重用此核。为了增加更多的随机性，我们还将随机量旋转核绕法向量。
- en: We'll cover the details in the steps presented in the following sections.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下章节中详细说明步骤。
- en: Getting ready
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: 'First, let''s build our random kernel. We need a set of points in the positive-z
    hemisphere centered at the origin. We''ll use a hemisphere with a radius of 1.0
    so that we can scale it to any size as needed:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们构建我们的随机核。我们需要一组以原点为中心的正 z 半球内的点。我们将使用半径为 1.0 的半球，这样我们就可以根据需要将其缩放到任何大小：
- en: '[PRE18]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `uniformHemisphere` function chooses a random point on the surface of the
    hemisphere in a uniform fashion. The details of how to do this were covered in
    an earlier recipe (see *Diffuse image based lighting*). To get a point within
    the hemisphere, we scale the point by the variable `scale`. This value will vary
    from 0 to 1 and is non-linear. It will produce more points close to the origin
    and fewer as we move away from the origin. We do this because we want to give
    slightly more weight to things that are close to the surface point.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '`uniformHemisphere` 函数以均匀的方式在半球表面选择一个随机点。如何实现这一点的细节在之前的配方中已有介绍（见 *基于扩散图像的照明*）。为了在半球内得到一个点，我们将点通过变量
    `scale` 进行缩放。这个值将在 0 到 1 之间变化，并且是非线性的。它会在靠近原点的地方产生更多的点，而当我们远离原点时，点会减少。我们这样做是因为我们希望给靠近表面点的物体赋予稍微更多的权重。'
- en: We assign the values of the kernel points to a uniform variable (array) in our
    shader named `SampleKernel`.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将核点的值分配到名为 `SampleKernel` 的着色器中的均匀变量（数组）。
- en: 'As mentioned earlier, we want to re-use this kernel for each surface point,
    but with a random rotation. To do so, we''ll build a small texture containing
    random rotation vectors. Each vector will be a unit vector in the x-y plane:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们希望为每个表面点重用这个核，但带有随机的旋转。为了做到这一点，我们将构建一个包含随机旋转向量的小纹理。每个向量将在 x-y 平面上是一个单位向量：
- en: '[PRE19]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `uniformCircle` function gives a random point on the unit circle in the
    x-y plane. We're using a 4 x 4 texture here, but you could use a larger size.
    We'll tile this texture across the screen, and we'll make it available to the
    shader (uniform variable `RandTex`).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '`uniformCircle` 函数在 x-y 平面的单位圆上给出一个随机点。在这里我们使用一个 4 x 4 的纹理，但您可以使用更大的尺寸。我们将把这个纹理平铺在整个屏幕上，并将其提供给着色器（均匀变量
    `RandTex`）。'
- en: You might be thinking that a 4 x 4 texture is too small to give us enough randomness.
    Yes, it will produce high-frequency patterns, but the blur pass will help to smooth
    that noise out.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想，4 x 4 的纹理太小，无法提供足够的随机性。是的，它会产生高频模式，但模糊遍历将有助于平滑这种噪声。
- en: In this example, we'll use a single shader and a single framebuffer. You could,
    of course, use several if desired. We'll need framebuffer textures for the camera
    space position, camera space normal, base color, and ambient occlusion. The AO
    buffer can be a single channel texture (for example, format `R_16F`). We'll also
    need one additional AO texture for the blur pass. We will swap each one into the
    framebuffer as necessary.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用单个着色器和单个帧缓冲区。当然，如果您愿意，您可以使用多个。我们需要用于相机空间位置、相机空间法线、基础颜色和环境遮挡的帧缓冲区纹理。AO
    缓冲区可以是一个单通道纹理（例如，格式 `R_16F`）。我们还需要一个额外的 AO 纹理用于模糊遍历。我们将根据需要将每个纹理交换到帧缓冲区中。
- en: How to do it...
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: In the first pass, render the scene to the geometry buffers (see *Using deferred
    shading* for details).
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次遍历中，将场景渲染到几何缓冲区（有关详细信息，请参阅 *使用延迟着色*）。
- en: In the second pass, we'll use this fragment shader code to compute the AO factor.
    To do so, we first compute a matrix for converting the kernel points into camera
    space. When doing so, we use a vector from `RandTex` to rotate the kernel. This
    process is similar to computing the tangent space matrix in normal mapping. For
    more on this, see *Using normal maps:*
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '在第二次遍历中，我们将使用这个片段着色器代码来计算 AO 因子。为此，我们首先计算一个将核点转换为相机空间的矩阵。在这样做的时候，我们使用 `RandTex`
    中的一个向量来旋转核。这个过程与计算法线映射中的切线空间矩阵类似。有关更多信息，请参阅 *使用法线图:* '
- en: '[PRE20]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we compute the ambient occlusion factor by looping over all of the kernel
    points, transforming them into camera coordinates, and then finding the surface
    point at the same (x,y) position and comparing the *z* values. We write the result
    to the AO buffer:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过遍历所有核点，将它们转换到相机坐标，然后在相同的 (x,y) 位置找到表面点并比较 *z* 值来计算环境遮挡因子。我们将结果写入 AO 缓冲区：
- en: '[PRE21]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the third pass, we do a simple blur, using a unweighted average of the nine
    nearest pixels. We read from the texture that was written in the previous pass,
    and write the results to our second AO buffer texture:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三次遍历中，我们进行简单的模糊处理，使用九个最近像素的无权平均值。我们从上一次遍历中写入的纹理中读取，并将结果写入我们的第二个 AO 缓冲区纹理：
- en: '[PRE22]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The fourth pass applies the reflection model using the ambient occlusion value
    from the previous pass. We scale the ambient portion by the value in the AO buffer
    raised to the fourth power (to slightly exaggerate the effect):'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第四次遍历使用前一次遍历的环境遮挡值应用反射模型。我们将环境部分按AO缓冲区中的值（提高到四次方）进行缩放（以略微夸张效果）：
- en: '[PRE23]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: How it works...
  id: totrans-390
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the second pass, we compute the ambient occlusion factor. To do so, the first
    step is to find the matrix that converts our kernel into camera space. We want
    a matrix that converts the kernel's *z* axis to the normal vector at the surface
    point, and applies a random rotation using a vector from `RandTex`. The columns
    of the matrix are the three ortho-normal vectors that define the tangent coordinate
    system in screen space. Since we want the kernel's *z* axis to be transformed
    to the normal vector, the third of these three vectors is the normal vector itself.
    The other two (`tang` and `biTang`) are determined by using cross products. To
    find `biTang`, we take the cross product of the normal vector (`n`) and the random
    rotation vector retrieved from the texture (`randDir`). As long as the two are
    not parallel, this will give us a vector that is perpendicular to both `n` and
    `randDir`. However, there is a small possibility that the two might be parallel.
    If so, the normal vector is in the x-y plane of camera space (because all of the
    rotation vectors in the texture are in the x-y plane). So in this case, we compute
    `biTang` by taking the cross product of `n` and the *z* axis. Next, we normalize
    `biTang`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次遍历中，我们计算环境遮挡因子。为此，第一步是找到将我们的核转换为相机空间的矩阵。我们希望一个矩阵将核的*z*轴转换为表面点的法向量，并使用`RandTex`中的向量应用随机旋转。矩阵的列是定义屏幕空间中切向坐标系统的三个正交归一化向量。由于我们希望核的*z*轴转换为法向量，所以这三个向量中的第三个就是法向量本身。其他两个（`tang`和`biTang`）通过使用叉积来确定。要找到`biTang`，我们取法向量（`n`）和从纹理中检索的随机旋转向量（`randDir`）的叉积。只要这两个向量不平行，这将给我们一个垂直于`n`和`randDir`的向量。然而，存在两个向量可能平行的微小可能性。如果是这样，法向量位于相机空间的x-y平面内（因为纹理中的所有旋转向量都在x-y平面内）。因此，在这种情况下，我们通过取`n`和*z*轴的叉积来计算`biTang`。接下来，我们对`biTang`进行归一化。
- en: Note that we scale the texture coordinates when accessing the random texture
    to get the random rotation vector. We do this because the texture is smaller than
    the size of the screen and we want to tile it to fill the screen so that a texel
    matches the size of a screen pixel.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在访问随机纹理以获取随机旋转向量时缩放纹理坐标。我们这样做是因为纹理的大小小于屏幕大小，我们希望将其平铺以填充屏幕，使得一个纹理元素匹配屏幕像素的大小。
- en: Now that we have two ortho-normal vectors, we can compute the third with the
    cross product of the two. The three vectors `tang`, `biTang`, and `n` make up
    the axes of the tangent space coordinate system. The matrix that converts from
    the tangent system to camera space (`toCamSpace`) has these three vectors as its
    columns.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了两个正交归一化向量，我们可以通过它们的叉积来计算第三个向量。向量`tang`、`biTang`和`n`构成了切向空间坐标系轴。将切向系统转换为相机空间的矩阵（`toCamSpace`）有这三个向量作为其列。
- en: 'Now that we have the `toCamSpace` matrix, we can loop over the 64 kernel points
    and test each of them. Note that we''re not actually treating these as points.
    Instead, they are treated as vectors that define an offset from the surface point.
    So a sample point is determined by the following line:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了`toCamSpace`矩阵，我们可以遍历64个核点并测试每个点。请注意，我们实际上并不是将这些点当作点来处理。相反，它们被视为定义从表面点偏移的向量。因此，一个采样点由以下行确定：
- en: '[PRE24]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, we take a vector from the sample kernel, convert it to camera space, scale
    it by `Radius`, and add it to the position of the surface point. The scale factor
    (`Radius`) is an important term that defines the size of the hemisphere around
    the point. It is a camera space value and may need to be adjusted for different
    scenes. In the example code, a value of `0.55` is used.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从样本核中取一个向量，将其转换为相机空间，按`Radius`缩放，并将其添加到表面点的位置。缩放因子（`Radius`）是一个重要的项，它定义了点周围半球的大小。它是一个相机空间值，可能需要根据不同场景进行调整。在示例代码中，使用了`0.55`的值。
- en: The next step is to find the visible surface at the sample point's (x,y) position.
    To do so, we need to look up the value of the position in the g-buffer at the
    sample position. We need the texture coordinates that correspond to that position.
    To find that, we first project the point to clip space, divide by the homogeneous
    *w* coordinate, and scale/translate to the texture space. Using that value, we
    then access the position g-buffer and retrieve the *z* coordinate of the surface
    position at that location (`surfaceZ` ). We don't need the *x* and *y* coordinates
    here as they are the same as the sample's.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是在样本点的 (x,y) 位置找到可见表面。要做到这一点，我们需要在样本位置查找 g-buffer 中该位置的位置值。我们需要与该位置相对应的纹理坐标。为了找到它，我们首先将点投影到裁剪空间，除以齐次
    *w* 坐标，并缩放/平移到纹理空间。使用该值，我们然后访问位置 g-buffer 并检索该位置表面位置的 *z* 坐标（`surfaceZ`）。在这里我们不需要
    *x* 和 *y* 坐标，因为它们与样本的相同。
- en: Now that we have the *z* coordinate of the projected point on the surface near
    the sample (`sampleZ`), we compute the difference (`dz`) between it and the *z*
    coordinate of the *original* surface point (the point being shaded, `pos`). If
    this value is less than zero or greater than `Radius`, then we know that the projected
    point on the surface at the sample location is outside of the hemisphere. In that
    case, we assume the sample is unoccluded. If that is not the case, we assume the
    projected point is within the hemisphere and we compare the *z* values. If `surfaceZ`
    is greater than `samplePos.z`, we know that the sample point is behind the surface.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了投影到样本附近表面上的 *z* 坐标（`sampleZ`），我们计算它与 *原始* 表面点（正在着色的点，`pos`）的 *z* 坐标之间的差值（`dz`）。如果这个值小于零或大于
    `Radius`，那么我们知道在样本位置上的表面投影点在半球之外。在这种情况下，我们假设样本未被遮挡。如果不是这种情况，我们假设投影点在半球内，并比较 *z*
    值。如果 `surfaceZ` 大于 `samplePos.z`，我们知道样本点在表面后面。
- en: This may seem strange, but remember, we're working in camera coordinates here.
    All of the *z* coordinates will be negative. These are not depth values—they are
    the camera space *z* coordinates.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来有些奇怪，但请记住，我们在这里是在相机坐标系下工作。所有的 *z* 坐标都将为负值。这些不是深度值——它们是相机空间的 *z* 坐标。
- en: We add `1.0` to `occlusionSum` if we determine that the point is occluded. The
    final result in `occlusionSum` after the loop will be the total number of points
    that were occluded. Since we want the opposite—the fraction of points that *are
    not* occluded—we subtract one from the average before writing to the output variable
    `AoData`.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们确定该点是遮挡的，我们将 `1.0` 添加到 `occlusionSum`。循环结束后 `occlusionSum` 中的最终结果将是被遮挡的总点数。由于我们想要的是相反的——未被遮挡的点数比例——我们在写入输出变量
    `AoData` 之前从平均值中减去一个。
- en: 'The following image (on the left) shows the results of this pass. Note that
    if you look closely, you can see some high frequency grid-like artifacts due to
    the re-use of the random rotation vectors throughout the image. This is smoothed
    out by the blur pass (right-hand image):'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像（左侧）显示了这一遍的结果。注意，如果你仔细看，你可以看到一些由于在整个图像中重复使用随机旋转向量而产生的高频网格状伪影。这通过模糊遍历（右侧图像）被平滑处理：
- en: '![](img/8a235afc-2b5d-45da-b3b2-c18f929d7894.png)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a235afc-2b5d-45da-b3b2-c18f929d7894.png)'
- en: The third pass is just a simple average of the nine texels near each texel.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 第三遍只是每个纹理素附近九个纹理素的简单平均值。
- en: The fourth pass applies the reflection model. In this example, we just compute
    the diffuse and ambient components of the Blinn-Phong model, scaling the ambient
    term by the blurred ambient occlusion value (`aoVal`). In this example, it is
    raised to a power of `4.0` to make it a bit darker and increase the effect.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 第四遍应用反射模型。在这个例子中，我们只计算 Blinn-Phong 模型的漫反射和环境分量，通过模糊的环境遮挡值（`aoVal`）缩放环境项。在这个例子中，它被提升到
    `4.0` 的幂，使其稍微暗一些并增强效果。
- en: 'The following images show the scene rendered without ambient occlusion (on
    the left) and with ambient occlusion (on the right). The ambient term is increased
    substantially to demonstrate the effect:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了没有环境遮挡（左侧）和有环境遮挡（右侧）的场景渲染效果。为了展示效果，环境项被显著增加：
- en: '![](img/62902435-c18e-4df6-9939-08daeb89d21b.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![](img/62902435-c18e-4df6-9939-08daeb89d21b.png)'
- en: See also
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `chapter06/scenessao.cpp` file in the example code
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的 `chapter06/scenessao.cpp` 文件
- en: '*The Using deferred shading* recipe in this chapter'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中 *使用延迟着色* 的配方
- en: Configuring the depth test
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置深度测试
- en: GLSL 4 provides the ability to configure how the depth test is performed. This
    gives us additional control over how and when fragments are tested against the
    depth buffer.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: GLSL 4提供了配置如何执行深度测试的能力。这使我们能够对如何以及何时测试片段与深度缓冲区进行更多控制。
- en: Many OpenGL implementations automatically provide an optimization known as the
    early depth test or early fragment test. With this optimization, the depth test
    is performed before the fragment shader is executed. Since fragments that fail
    the depth test will not appear on the screen (or the framebuffer), there is no
    point in executing the fragment shader at all for those fragments and we can save
    some time by avoiding the execution.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 许多OpenGL实现自动提供一种称为早期深度测试或早期片段测试的优化。使用这种优化，深度测试在片段着色器执行之前执行。由于深度测试失败的片段不会出现在屏幕（或帧缓冲区）上，因此对这些片段执行片段着色器根本没有必要，我们可以通过避免执行来节省一些时间。
- en: The OpenGL specification, however, states that the depth test must appear to
    be performed *after* the fragment shader. This means that if an implementation
    wishes to use the early depth test optimization, it must be careful. The implementation
    must make sure that if anything within the fragment shader might change the results
    of the depth test, then it should avoid using the early depth test.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，OpenGL规范指出，深度测试必须看起来是在片段着色器之后执行的*。这意味着如果实现希望使用早期深度测试优化，它必须小心。实现必须确保如果片段着色器中的任何内容可能会改变深度测试的结果，那么它应该避免使用早期深度测试。
- en: For example, a fragment shader can change the depth of a fragment by writing
    to the output variable, `gl_FragDepth`. If it does so, then the early depth test
    cannot be performed because, of course, the final depth of the fragment is not
    known prior to the execution of the fragment shader. However, the GLSL provides
    ways to notify the pipeline roughly how the depth will be modified, so that the
    implementation may determine when it might be okay to use the early depth test.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个片段着色器可以通过写入输出变量`gl_FragDepth`来改变片段的深度。如果这样做，那么早期深度测试将无法执行，因为当然，在片段着色器执行之前，片段的最终深度是未知的。然而，GLSL提供了通知管道大致如何修改深度的方法，这样实现可以确定何时可能可以使用早期深度测试。
- en: Another possibility is that the fragment shader might conditionally discard
    the fragment using the `discard` keyword. If there is any possibility that the
    fragment may be discarded, some implementations may not perform the early depth
    test.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是片段着色器可能会使用`discard`关键字有条件地丢弃片段。如果存在任何可能丢弃片段的情况，某些实现可能不会执行早期深度测试。
- en: There are also certain situations where we want to rely on the early depth test.
    For example, if the fragment shader writes to memory other than the framebuffer
    (with image load/store, shader storage buffers, or other incoherent memory writing),
    we might not want the fragment shader to execute for fragments that fail the depth
    test. This would help us to avoid writing data for fragments that fail. The GLSL
    provides a technique for forcing the early depth test optimization.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 也有某些情况下我们希望依赖早期深度测试。例如，如果片段着色器写入除帧缓冲区以外的内存（使用图像加载/存储、着色器存储缓冲区或其他非一致内存写入），我们可能不希望对深度测试失败的片段执行片段着色器。这将帮助我们避免为失败的片段写入数据。GLSL提供了一种强制早期深度测试优化的技术。
- en: How to do it...
  id: totrans-417
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'To ask the OpenGL pipeline to always perform the early depth test optimization,
    use the following layout qualifier in your fragment shader:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 要请求OpenGL管道始终执行早期深度测试优化，请在您的片段着色器中使用以下布局限定符：
- en: '[PRE25]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If your fragment shader will modify the fragment''s depth, but you still would
    like to take advantage of the early depth test when possible, use the following
    layout qualifier in a declaration of `gl_FragDepth` within your fragment shader:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的片段着色器将修改片段的深度，但你还想尽可能利用早期深度测试，请在片段着色器中`gl_FragDepth`的声明中使用以下布局限定符：
- en: '[PRE26]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this, `depth_*` is one of the following: `depth_any`, `depth_greater`, `depth_less`, or `depth_unchanged`.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`depth_*`是以下之一：`depth_any`、`depth_greater`、`depth_less`或`depth_unchanged`。
- en: How it works...
  id: totrans-423
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following statement forces the OpenGL implementation to always perform
    the early depth test:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 以下语句强制OpenGL实现始终执行早期深度测试：
- en: '[PRE27]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We must keep in mind that if we attempt to modify the depth anywhere within
    the shader by writing to `gl_FragDepth`, the value that is written will be ignored.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须记住，如果我们尝试通过写入`gl_FragDepth`在着色器中的任何地方修改深度，所写入的值将被忽略。
- en: If your fragment shader needs to modify the depth value, then we can't force
    early fragment tests. However, we can help the pipeline to determine when it can
    still apply the early test. We do so by using one of the layout qualifiers for `gl_FragDepth` as
    shown before. This places some limits on how the value will be modified. The OpenGL
    implementation can then determine if the fragment shader can be skipped. If it
    can be determined that the depth will not be changed in such a way that it would
    cause the result of the test to change, the implementation can still use the optimization.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的片段着色器需要修改深度值，那么我们无法强制执行早期片段测试。然而，我们可以帮助管线确定何时还可以应用早期测试。我们通过使用之前展示的`gl_FragDepth`的布局限定符来实现这一点。这为值的修改设定了一些限制。然后OpenGL实现可以确定是否可以跳过片段着色器。如果可以确定深度不会以改变测试结果的方式改变，实现仍然可以使用优化。
- en: The layout qualifier for the output variable `gl_FragDepth` tells the OpenGL
    implementation specifically how the depth might change within the fragment shader.
    The qualifier `depth_any` indicates that it could change in any way. This is the
    default.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 输出变量`gl_FragDepth`的布局限定符会具体告诉OpenGL实现片段着色器内深度可能如何改变。限定符`depth_any`表示它可能以任何方式改变。这是默认值。
- en: 'The other qualifiers describe how the value may change with respect to `gl_FragCoord.z`:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 其他限定符描述了值相对于`gl_FragCoord.z`可能如何改变：
- en: '`depth_greater`: This fragment shader promises to only increase the depth.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth_greater`：这个片段着色器承诺只会增加深度。'
- en: '`depth_less`: This fragment shader promises to only decrease the depth.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth_less`：这个片段着色器承诺只会减少深度。'
- en: '`depth_unchanged`: This fragment shader promises not to change the depth. If
    it writes to `gl_FragDepth`, the value will be equal to `gl_FragCoord.z`.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth_unchanged`：这个片段着色器承诺不会改变深度。如果它写入`gl_FragDepth`，值将等于`gl_FragCoord.z`。'
- en: If you use one of these qualifiers, but then go on to modify the depth in an
    incompatible way, the results are undefined. For example, if you declare `gl_FragDepth` with `depth_greater`,
    but decrease the depth of the fragment, the code will compile and execute, but
    you shouldn't expect to see accurate results.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用这些限定符之一，但随后以不兼容的方式修改深度，结果是不确定的。例如，如果你使用`depth_greater`声明`gl_FragDepth`，但减少了片段的深度，代码将编译并执行，但你不应期望看到准确的结果。
- en: If your fragment shader writes to `gl_FragDepth`, then it must be sure to write
    a value in all circumstances. In other words, it must write a value no matter
    which branches are taken within the code.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的片段着色器写入`gl_FragDepth`，那么它必须确保在所有情况下都写入一个值。换句话说，无论代码中采取哪个分支，它都必须写入一个值。
- en: See also
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The *Implementing order-independent transparency* recipe
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现无序透明度*的配方'
- en: Implementing order-independent transparency
  id: totrans-437
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现无序透明度
- en: Transparency can be a difficult effect to do accurately in pipeline architectures
    like OpenGL. The general technique is to draw opaque objects first, with the depth
    buffer enabled, then to make the depth buffer read-only (using `glDepthMask`),
    disable the depth test, and draw the transparent geometry. However, care must
    be taken to ensure that the transparent geometry is drawn from *back to front*.
    That is, objects farther from the viewer should be drawn before the objects that
    are closer. This requires some sort of depth-sorting to take place prior to rendering.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在像OpenGL这样的管线架构中，准确实现透明度可能是一个困难的效果。一般技术是首先绘制不透明对象，启用深度缓冲区，然后使深度缓冲区只读（使用`glDepthMask`），禁用深度测试，并绘制透明几何体。然而，必须小心确保透明几何体是从后向前绘制的。也就是说，距离观察者更远的对象应该在距离观察者更近的对象之前绘制。这需要在渲染之前进行某种深度排序。
- en: 'The following images show an example of a block of small, semi-transparent
    spheres with some semi-transparent cubes placed evenly within them. On the right-hand
    side, the objects are rendered in an arbitrary order, using standard OpenGL blending.
    The result looks incorrect because objects are blended in an improper order. The
    cubes, which were drawn last, appear to be on top of the spheres, and the spheres
    look jumbled, especially in the middle of the block. On the left, the scene is
    drawn using proper ordering, so objects appear to be oriented correctly with respect
    to depth, and the overall look is more realistic looking:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了一个示例，其中包含一些均匀放置在其中的半透明立方体的小型半透明球体。在右侧，物体以任意顺序渲染，使用标准的OpenGL混合。结果看起来不正确，因为物体以不正确的顺序混合。最后绘制的立方体似乎位于球体之上，球体看起来杂乱无章，尤其是在块的中心。在左侧，场景使用正确的顺序绘制，因此物体相对于深度看起来是正确定位的，整体看起来更真实：
- en: '![](img/e3e8ea27-c9d9-4059-8f83-5a1c7bdadbbb.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e3e8ea27-c9d9-4059-8f83-5a1c7bdadbbb.png)'
- en: '**Order Independent Transparency** (**OIT**) means that we can draw objects
    in any order and still get accurate results. Depth sorting is done at some other
    level, perhaps within the fragment shader, so that the programmer need not sort
    objects before rendering. There are a variety of techniques for doing this; one
    of the most common technique is to keep a list of colors for each pixel, sort
    them by depth, and then blend them together in the fragment shader. In this recipe
    we''ll use this technique to implement OIT, making use of some of the newest features
    in OpenGL 4.3.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '**顺序无关透明度**（**OIT**）意味着我们可以以任何顺序绘制物体，仍然可以得到准确的结果。深度排序在某个其他级别完成，可能在片段着色器内部，这样程序员在渲染之前就不需要排序物体。有各种技术来完成这项工作；其中最常见的技术是保留每个像素的颜色列表，按深度排序，然后在片段着色器中将它们混合在一起。在这个配方中，我们将使用这项技术来实现OIT，利用OpenGL
    4.3的一些最新特性。'
- en: '**Shader storage buffer objects** (**SSBO**) and **image load/store** are some
    of the newest features in OpenGL, introduced in 4.3 and 4.2, respectively. They
    allow arbitrary read/write access to data from within a shader. Prior to this,
    shaders were very limited in terms of what data they could access. They could
    read from a variety of locations (textures, uniforms, and so on), but writing
    was very limited. Shaders could only write to controlled, isolated locations such
    as fragment shader outputs and transform feedback buffers. This was for a very
    good reason. Since shaders can execute in parallel and in a seemingly arbitrary
    order, it is very difficult to ensure that data is consistent between instantiations
    of a shader. Data written by one shader instance might not be visible to another
    shader instance whether or not that instance is executed after the other. Despite
    this, there are good reasons for wanting to read and write to shared locations.
    With the advent of SSBOs and image load/store, that capability is now available
    to us. We can create buffers and textures (called images) with read/write access
    to any shader instance. This is especially important for compute shaders, the
    subject of [Chapter 11](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml), *Using Compute
    Shaders*. However, this power comes at a price. The programmer must now be very
    careful to avoid the types of memory consistency errors that come along with writing
    to memory that is shared among parallel threads. Additionally, the programmer
    must be aware of the performance issues that come with synchronization between
    shader invocations.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '**着色器存储缓冲区对象**（**SSBO**）和**图像加载/存储**是OpenGL的一些最新特性，分别于4.3和4.2版本中引入。它们允许从着色器内部进行任意的读写访问。在此之前，着色器在可访问的数据方面非常有限。它们可以从各种位置读取（纹理、统一变量等），但写入非常有限。着色器只能写入受控的、隔离的位置，例如片段着色器输出和变换反馈缓冲区。这有一个非常好的原因。由于着色器可以并行执行，并且似乎以任意顺序执行，因此很难确保着色器实例之间的数据一致性。一个着色器实例写入的数据可能对另一个着色器实例不可见，无论该实例是否在另一个实例之后执行。尽管如此，仍然有很好的理由想要读取和写入共享位置。随着SSBO和图像加载/存储的出现，这种能力现在对我们来说已经可用。我们可以创建具有对任何着色器实例读写访问权限的缓冲区和纹理（称为图像）。这对于计算着色器尤为重要，这是第11章的主题，*使用计算着色器*。然而，这种力量是有代价的。程序员现在必须非常小心，以避免伴随写入共享内存的内存一致性错误。此外，程序员必须意识到着色器调用之间同步带来的性能问题。'
- en: For a more thorough discussion of the issues involved with memory consistency
    and shaders, refer to Chapter 11, of *The OpenGL Programming Guide*, 8th Edition.
    That chapter also includes another similar implementation of OIT.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有关内存一致性和着色器问题的更深入讨论，请参阅《OpenGL编程指南》第8版第11章。该章节还包括OIT的另一个类似实现。
- en: In this recipe, we'll use SSBOs and image load/store to implement order-independent
    transparency. We'll use two passes. In the first pass, we'll render the scene
    geometry and store a linked list of fragments for each pixel. After the first
    pass, each pixel will have a corresponding linked list containing all fragments
    that were written to that pixel, including their depth and color. In the second
    pass, we'll draw a fullscreen quad to invoke the fragment shader for each pixel.
    In the fragment shader, we'll extract the linked list for the pixel, sort the
    fragments by depth (largest to smallest), and blend the colors in that order.
    The final color will then be sent to the output device.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用SSBOs（存储在存储器中的缓冲区对象）和图像加载/存储来实现无顺序透明度。我们将使用两次遍历。在第一次遍历中，我们将渲染场景几何形状，并为每个像素存储一个片段的链表。第一次遍历后，每个像素将有一个对应的链表，包含写入该像素的所有片段，包括它们的深度和颜色。在第二次遍历中，我们将绘制一个全屏四边形，以调用每个像素的片段着色器。在片段着色器中，我们将提取该像素的链表，按深度（从大到小）排序片段，并按此顺序混合颜色。最终的颜色将被发送到输出设备。
- en: 'That''s the basic idea, so let''s dig into the details. We''ll need three memory
    objects that are shared among the fragment shader instances:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是基本思路，让我们深入细节。我们需要三个在片段着色器实例之间共享的内存对象：
- en: '**An atomic counter:** This is just an unsigned integer that we''ll use to
    keep track of'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个原子计数器**：这只是一个无符号整数，我们将用它来跟踪'
- en: the size of our linked list buffer. Think of this as the index of the first
    unused slot in the buffer.
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们链表缓冲区的大小。将其视为缓冲区中第一个未使用槽位的索引。
- en: '**A head-pointer texture that corresponds to the size of the screen**: The
    texture will store a single unsigned integer in each texel. The value is the index
    of the head of the linked list for the corresponding pixel.'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**与屏幕尺寸相对应的头指针纹理**：纹理将存储每个texel中的单个无符号整数。该值是对应像素链表头部的索引。'
- en: '**A buffer containing all of our linked lists:** Each item in the buffer will
    correspond to a fragment, and contains a struct with the color and depth of the
    fragment as well as an integer, which is the index of the next fragment in the
    linked list.'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**包含所有链表的缓冲区**：缓冲区中的每个项目都对应一个片段，包含一个结构体，其中包含片段的颜色和深度，以及一个整数，它是链表中下一个片段的索引。'
- en: 'In order to understand how all of this works together, let''s consider a simple
    example. Suppose that our screen is three pixels wide and three pixels high. We''ll
    have a head pointer texture that is the same dimensions, and we''ll initialize
    all of the texels to a special value that indicates the end of the linked list
    (an empty list). In the following diagram, that value is shown as an **x**, but
    in practice, we''ll use `0xffffffff`. The initial value of the counter is zero,
    and the linked list buffer is allocated to a certain size but treated as empty
    initially. The initial state of our memory is shown in the following diagram:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解所有这些是如何协同工作的，让我们考虑一个简单的例子。假设我们的屏幕宽度为三个像素，高度为三个像素。我们将有一个与屏幕尺寸相同的头指针纹理，并将所有texels初始化为表示链表末尾的特殊值（一个空列表）。在以下图中，该值显示为**x**，但在实践中，我们将使用`0xffffffff`。计数器的初始值为零，链表缓冲区分配了特定的大小，但最初被视为空。我们的内存初始状态如下所示：
- en: '![](img/f8dd60ca-4750-4864-8662-e9f409b4c153.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f8dd60ca-4750-4864-8662-e9f409b4c153.png)'
- en: 'Now suppose that a fragment is rendered at the position (0,1) with a depth
    of 0.75\. The fragment shader will take the following steps:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设在位置（0，1）渲染了一个深度为0.75的片段。片段着色器将执行以下步骤：
- en: Increment the atomic counter. The new value will be 1, but we'll use the previous
    value (**0**) as the index for our new node in the linked list.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加原子计数器。新值将是1，但我们将使用之前的值（**0**）作为链表中新节点的索引。
- en: Update the head pointer texture at (0,1) with the previous value of the counter
    (**0**). This is the index of the new head of the linked list at that pixel. Hold
    on to the previous value that was stored there (**x**), as we'll need that in
    the next step.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用计数器的上一个值（**0**）更新（0，1）处的头指针纹理。这是该像素链表新头部的索引。保留存储在该处的上一个值（**x**），因为在下一步中我们需要它。
- en: Add a new value into the linked list buffer at the location corresponding to
    the previous value of the counter (**0**). Store the color of the fragment and
    its depth here. Store in the next component the previous value of the head pointer
    texture at (0,1) that we held on to in step 2\. In this case, it is the special
    value indicating the end of the list.
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计数器的上一个值对应的位置向链表缓冲区添加一个新值（**0**）。在这里存储片段的颜色及其深度。在下一个组件中存储我们在步骤2中保留的(0,1)处的头指针纹理的先前值。在这种情况下，它是表示列表结束的特殊值。
- en: 'After processing this fragment, the memory layout looks as follows:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此片段后，内存布局如下：
- en: '![](img/b62cb1aa-bced-41f8-b460-6fad6245100e.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b62cb1aa-bced-41f8-b460-6fad6245100e.png)'
- en: 'Now, suppose another fragment is rendered at (0,1), with a depth of 0.5\. The
    fragment shader will execute the same steps as the previous ones, resulting in
    the following memory layout:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设在(0,1)处渲染另一个片段，深度为0.5。片段着色器将执行与之前相同的步骤，导致以下内存布局：
- en: '![](img/d36be185-a17f-4146-838d-1981ed3f55f4.png)'
  id: totrans-459
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d36be185-a17f-4146-838d-1981ed3f55f4.png)'
- en: 'We now have a two-element linked list starting at index 1 and ending at index
    0\. Suppose, now that we have three more fragments in the following order: a fragment
    at (1,1) with a depth of 0.2, a fragment at (0,1) with a depth of 0.3, and a fragment
    at (1,1) with a depth of 0.4\. Following the same steps for each fragment, we
    get the following result:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个从索引1开始到索引0结束的两个元素链表。假设现在我们有三个更多的片段，顺序如下：一个在(1,1)处的片段，深度为0.2，一个在(0,1)处的片段，深度为0.3，以及一个在(1,1)处的片段，深度为0.4。对每个片段执行相同的步骤，我们得到以下结果：
- en: '![](img/269f6ef8-f08d-4037-9c41-a8ad6989a9e9.png)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/269f6ef8-f08d-4037-9c41-a8ad6989a9e9.png)'
- en: The linked list at (0,1) consists of fragments {3, 1, 0} and the linked list
    at (1,1) contains fragments {4, 2}.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 在(0,1)处的链表由片段{3, 1, 0}组成，而在(1,1)处的链表包含片段{4, 2}。
- en: Now, we must keep in mind that due to the highly parallel nature of GPUs, fragments
    can be rendered in virtually any order. For example, fragments from two different
    polygons might proceed through the pipeline in the opposite order as to when the
    draw instructions for polygons were issued. As a programmer, we must not expect
    any specific ordering of fragments. Indeed, instructions from separate instances
    of the fragment shader may interleave in arbitrary ways. The only thing that we
    can be sure of is that the statements within a particular instance of the shader
    will execute in order. Therefore, we need to convince ourselves that any interleaving
    of the previous three steps will still result in a consistent state. For example,
    suppose instance one executes steps 1 and 2, then another instance (another fragment,
    perhaps at the same fragment coordinates) executes steps 1, 2, and 3, before the
    first instance executes step 3\. Will the result still be consistent? I think
    you can convince yourself that it will be, even though the linked list will be
    broken for a short time during the process. Try working through other interleavings
    and convince yourself that we're OK.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须记住，由于GPU高度并行的特性，片段可以以几乎任何顺序渲染。例如，来自两个不同多边形的片段可能以与多边形绘制指令发出时相反的顺序通过管道。作为程序员，我们不应期望片段有任何特定的顺序。实际上，来自片段着色器不同实例的指令可能会以任意方式交织。我们唯一可以确定的是，着色器特定实例中的语句将按顺序执行。因此，我们需要确信任何交织的前三个步骤仍然会导致一致的状态。例如，假设实例一执行步骤1和2，然后另一个实例（另一个片段，可能在相同的片段坐标）在第一个实例执行步骤3之前执行步骤1、2和3。结果仍然一致吗？我想你可以自己说服自己，即使在这个过程中链表会在短时间内被破坏。尝试通过其他交织并说服自己我们没问题。
- en: Not only can statements within separate instances of a shader interleave with
    each other, but the sub-instructions that make up the statements can interleave.
    (For example, the sub-instructions for an increment operation consist of a load,
    increment, and a store.) What's more, they could actually execute at exactly the
    same time. Consequently, if we aren't careful, nasty memory consistency issues
    can crop up. To help avoid this, we need to make careful use of the GLSL support
    for atomic operations.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅着色器不同实例中的语句可以相互交织，构成语句的子指令也可以交织。例如，增量操作的子指令包括加载、增加和存储。更重要的是，它们实际上可以同时执行。因此，如果我们不小心，可能会出现讨厌的内存一致性问题。为了避免这种情况，我们需要仔细使用GLSL对原子操作的支持。
- en: Recent versions of OpenGL (4.2 and 4.3) have introduced the tools that we need
    to make this algorithm possible. OpenGL 4.2 introduced atomic counters and the
    ability to read and write to arbitrary locations within a texture (called image
    load/store). OpenGL 4.3 introduced shader storage buffer objects. We'll make use
    of all three of these features in this example, as well as the various atomic
    operations and memory barriers that go along with them.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 近期版本的OpenGL（4.2和4.3）引入了使这个算法成为可能所需的工具。OpenGL 4.2引入了原子计数器和在纹理内部任意位置读写的能力（称为图像加载/存储）。OpenGL
    4.3引入了着色器存储缓冲区对象。在这个例子中，我们将使用这三个功能，以及与之相关的各种原子操作和内存屏障。
- en: Getting ready
  id: totrans-466
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'There''s a bunch of setup needed here, so we''ll go into a bit of detail with
    some code segments. First, we''ll set up a buffer for our atomic counter:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要做很多设置，所以我们将通过一些代码片段进行一些详细说明。首先，我们将为我们的原子计数器设置一个缓冲区：
- en: '[PRE28]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we will create a buffer for our linked list storage:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个用于链表存储的缓冲区：
- en: '[PRE29]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`nodeSize` in the previous code is the size of `struct NodeType` used in the
    fragment shader (in the latter part of the code). This is computed based on the `std430` layout.
    For details on the `std430` layout, see the OpenGL specification document. For
    this example, `nodeSize` is `5 * sizeof(GLfloat) + sizeof(GLuint)`.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 之前代码中的`nodeSize`是片段着色器中使用的`struct NodeType`的大小（在代码的后半部分）。这是基于`std430`布局计算的。有关`std430`布局的详细信息，请参阅OpenGL规范文档。对于这个例子，`nodeSize`是`5
    * sizeof(GLfloat) + sizeof(GLuint)`。
- en: 'We also need to create a texture to hold the list head pointers. We''ll use
    32-bit unsigned integers, and bind it to image unit 0:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要创建一个用于存储列表头部指针的纹理。我们将使用32位无符号整数，并将其绑定到图像单元0：
- en: '[PRE30]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'After we render each frame, we need to clear the texture by setting all texels
    to a value of `0xffffffff`. To help with that, we''ll create a buffer of the same
    size as the texture, with each value set to our clear value:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们渲染每一帧之后，我们需要通过将所有texels设置为值`0xffffffff`来清除纹理。为了帮助完成这个任务，我们将创建一个与纹理大小相同的缓冲区，并将每个值设置为我们的清除值：
- en: '[PRE31]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: That's all the buffers we'll need. Note the fact that we've bound the head pointer
    texture to image unit 0, the atomic counter buffer to index 0 of the `GL_ATOMIC_COUNTER_BUFFER`
    binding point (`glBindBufferBase`), and the linked list storage buffer to index
    0 of the `GL_SHADER_STORAGE_BUFFER` binding point. We'll refer back to that later.
    Use a pass-through vertex shader that sends the position and normal along in eye
    coordinates.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是我们所需要的所有缓冲区。请注意，我们已经将头部指针纹理绑定到图像单元0，将原子计数器缓冲区绑定到`GL_ATOMIC_COUNTER_BUFFER`绑定点的索引0（`glBindBufferBase`），以及将链表存储缓冲区绑定到`GL_SHADER_STORAGE_BUFFER`绑定点的索引0。我们稍后会回过来提到这一点。使用一个传递型顶点着色器，将位置和法线以眼坐标的形式发送出去。
- en: How to do it...
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'With all of the buffers set up, we need two render passes. Before the first
    pass, we want to clear our buffers to default values (that is, empty lists), and
    to reset our atomic counter buffer to zero:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有缓冲区设置完毕后，我们需要两个渲染遍历。在第一次遍历之前，我们希望将我们的缓冲区清空到默认值（即空列表），并将我们的原子计数器缓冲区重置为零：
- en: '[PRE32]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the first pass, we''ll render the full scene geometry. Generally, we should
    render all the opaque geometry first and store the results in a texture. However,
    we''ll skip that step for this example to keep things simple and focused. Instead,
    we''ll render only transparent geometry. When rendering the transparent geometry,
    we need to make sure to put the depth buffer in read-only mode (use `glDepthMask`).
    In the fragment shader, we add each fragment to the appropriate linked list:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次遍历中，我们将渲染整个场景几何体。通常，我们应该首先渲染所有不透明几何体并将结果存储在纹理中。然而，为了保持示例简单和专注，我们将跳过这一步。相反，我们只渲染透明几何体。在渲染透明几何体时，我们需要确保将深度缓冲区设置为只读模式（使用`glDepthMask`）。在片段着色器中，我们将每个片段添加到适当的链表中：
- en: '[PRE33]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Before rendering the second pass, we need to be sure that all of the data has
    been written to our buffers. In order to ensure that is indeed the case, we can
    use a memory barrier:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 在渲染第二次遍历之前，我们需要确保所有数据都已写入我们的缓冲区。为了确保这一点，我们可以使用内存屏障：
- en: '[PRE34]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In the second pass, we don''t render the scene geometry, just a single, screen-filling
    quad in order to invoke the fragment shader for each screen pixel. In the fragment
    shader, we start by copying the linked list for the fragment into a temporary
    array:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次遍历中，我们不渲染场景几何体，只渲染一个填充整个屏幕的四边形，以便为每个屏幕像素调用片段着色器。在片段着色器中，我们首先将片段的链表复制到一个临时数组中：
- en: '[PRE35]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then, we sort the fragments using insertion sort:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用插入排序对片段进行排序：
- en: '[PRE36]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Finally, we blend the fragments manually, and send the result to the output
    variable:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们手动合并片段，并将结果发送到输出变量：
- en: '[PRE37]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works...
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To clear our buffers, prior to the first pass, we bind `clearBuf` to the `GL_PIXEL_UNPACK_BUFFER`
    binding point, and call `glTexSubImage2D` to copy data from `clearBuf` to the
    the head pointer texture. Note that when a non-zero buffer is bound to `GL_PIXEL_UNPACK_BUFFER`,
    `glTexSubImage2D` treats the last parameter as an offset into the buffer that
    is bound there. Therefore, this will initiate a copy from `clearBuf` into `headPtrTex`.
    Clearing the atomic counter is straightforward, but the use of `glBindBufferBase`
    may be a bit confusing. If there can be several buffers bound to the binding point
    (at different indices), how does `glBufferSubData` know which buffer to target?
    It turns out that when we bind a buffer using `glBindBufferBase`, it is also bound
    to the generic binding point as well.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一遍之前清除我们的缓冲区，我们将 `clearBuf` 绑定到 `GL_PIXEL_UNPACK_BUFFER` 绑定点，并调用 `glTexSubImage2D`
    将数据从 `clearBuf` 复制到头部指针纹理。请注意，当将非零缓冲区绑定到 `GL_PIXEL_UNPACK_BUFFER` 时，`glTexSubImage2D`
    将最后一个参数视为绑定到那里的缓冲区中的偏移量。因此，这将从 `clearBuf` 开始复制到 `headPtrTex`。清除原子计数器很简单，但使用 `glBindBufferBase`
    可能会有些令人困惑。如果有多个缓冲区绑定到绑定点（在不同的索引处），`glBufferSubData` 如何知道要针对哪个缓冲区？实际上，当我们使用 `glBindBufferBase`
    绑定缓冲区时，它也被绑定到通用绑定点。
- en: 'In the fragment shader during the first pass, we start with the layout specification
    enabling the early fragment test optimization:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一遍的片段着色器中，我们开始使用布局规范启用早期片段测试优化：
- en: '[PRE38]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This is important because if any fragments are obscured by the opaque geometry,
    we don't want to add them to a linked list. If the early fragment test optimization
    is not enabled, the fragment shader may be executed for fragments that will fail
    the depth test and hence will get added to the linked list. The previous statement
    ensures that the fragment shader will not execute for those fragments.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 这很重要，因为如果任何片段被不透明的几何形状遮挡，我们不希望将它们添加到链表中。如果早期片段测试优化未启用，片段着色器可能会为将失败深度测试的片段执行，因此这些片段将被添加到链表中。前面的语句确保片段着色器不会为这些片段执行。
- en: The definition of `struct NodeType` specifies the type of data that is stored
    in our linked list buffer. We need to store color, depth, and a pointer to the
    next node in the linked list.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '`struct NodeType` 的定义指定了存储在我们链表缓冲区中的数据类型。我们需要存储颜色、深度以及指向链表下一个节点的指针。'
- en: The next three statements declare the objects related to our linked list storage.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的三个语句声明了与我们的链表存储相关的对象。
- en: The first, `headPointers`, is the image object that stores the locations of
    the heads of each linked list. The layout qualifier indicates that it is located
    at image unit 0 (refer to the *Getting ready* section of this recipe), and the
    data type is `r32ui` (red, 32-bit unsigned integer).
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个，`headPointers`，是存储每个链表头部位置的图像对象。布局限定符表示它位于图像单元 0（参考本食谱的 *准备就绪* 部分），数据类型为
    `r32ui`（红色，32 位无符号整数）。
- en: The second object is our atomic counter `nextNodeCounter`. The layout qualifier
    indicates the index within the `GL_ATOMIC_COUTER_BUFFER` binding point (refer
    to the *Getting ready* section of this recipe) and the offset within the buffer
    at that location.  Since we only have a single value in the buffer, the offset
    is 0, but in general, you might have several atomic counters located within a
    single buffer.
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个对象是我们的原子计数器 `nextNodeCounter`。布局限定符表示在 `GL_ATOMIC_COUTER_BUFFER` 绑定点内的索引（参考本食谱的
    *准备就绪* 部分）以及在该位置缓冲区内的偏移量。由于我们缓冲区中只有一个值，偏移量为 0，但在一般情况下，你可能有多个原子计数器位于单个缓冲区中。
- en: Third is our linked-list storage buffer `linkedLists`. This is a shader storage
    buffer object. The organization of the data within the object is defined within
    the curly braces here. In this case, we just have an array of `NodeType` structures.
    The bounds of the array can be left undefined, the size being limited by the underlying
    buffer object that we created. The layout qualifiers define the binding and memory
    layout. The first, binding, indicates that the buffer is located at index 0 within
    the `GL_SHADER_STORAGE_BUFFER` binding point. The second, `std430`, indicates
    how memory is organized within the buffer. This is mainly important when we want
    to read the data back from the OpenGL side. As mentioned previously, this is documented
    in the OpenGL specification document.
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三是我们的链表存储缓冲区 `linkedLists`。这是一个着色器存储缓冲区对象。对象内部数据的组织方式在这里用大括号定义。在这种情况下，我们只有一个
    `NodeType` 结构体的数组。数组的边界可以留空，其大小由我们创建的底层缓冲区对象限制。布局限定符定义了绑定和内存布局。第一个，绑定，表示缓冲区位于
    `GL_SHADER_STORAGE_BUFFER` 绑定点内的索引 0。第二个，`std430`，表示缓冲区内部内存的组织方式。这在我们要从 OpenGL
    端读取数据时尤为重要。如前所述，这已在 OpenGL 规范文档中记录。
- en: The first step in the fragment shader during the first pass is to increment
    our atomic counter using `atomicCounterIncrement`. This will increment the counter
    in such a way that there is no possibility of memory consistency issues if another
    shader instance is attempting to increment the counter at the same time.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次遍历的片段着色器中的第一步是使用 `atomicCounterIncrement` 增加我们的原子计数器。这将以这种方式增加计数器，如果另一个着色器实例同时尝试增加计数器，则不存在内存一致性问题的可能性。
- en: An atomic operation is one that is isolated from other threads and can be considered
    to be a single, uninterruptable operation. Other threads cannot interleave with
    an atomic operation. It is always a good idea to use atomic operations when writing
    to shared data within a shader.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 原子操作是一种与其他线程隔离的操作，可以被视为一个单一且不可中断的操作。其他线程不能与原子操作交织。在向着色器中的共享数据写入时，始终使用原子操作是一个好主意。
- en: 'The return value of `atomicCounterIncrement` is the previous value of the counter.
    It is the next unused location in our linked list buffer. We''ll use this value
    as the location where we''ll store this fragment, so we store it in a variable
    named `nodeIdx`. It will also become the new head of the linked list, so the next
    step is to update the value in the `headPointers` image at this pixel''s location
    `gl_FragCoord.xy`. We do so using another atomic operation: `imageAtomicExchange`.
    This replaces the value within the image at the location specified by the second
    parameter with the value of the third parameter. The return value is the previous
    value of the image at that location. This is the previous head of our linked list.
    We hold on to this value in `prevHead`, because we want to link our new head to
    that node, thereby restoring the consistency of the linked list with our new node
    at the head.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '`atomicCounterIncrement` 的返回值是计数器的先前值。它是我们链表缓冲区中的下一个未使用位置。我们将使用此值作为存储此片段的位置，因此我们将其存储在一个名为
    `nodeIdx` 的变量中。它也将成为链表的新头节点，因此下一步是更新 `headPointers` 图像在此像素位置 `gl_FragCoord.xy`
    的值。我们通过另一个原子操作 `imageAtomicExchange` 来这样做。这会将第二个参数指定的图像位置中的值替换为第三个参数的值。返回值是图像在该位置的先前值。这是我们的链表先前头节点。我们保留这个值在
    `prevHead` 中，因为我们想将新头节点链接到那个节点，从而恢复链表与我们的新头部节点的一致性。'
- en: Finally, we update the node at `nodeIdx` with the color and depth of the fragment,
    and set the `next` value to the previous head of the list (`prevHead`). This completes
    the insertion of this fragment into the linked list at the head of the list.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用片段的颜色和深度更新 `nodeIdx` 处的节点，并将 `next` 值设置为列表的先前头节点 (`prevHead`)。这完成了将此片段插入链表头部的操作。
- en: After the first pass is complete, we need to make sure that all changes are
    written to our shader storage buffer and image object before proceeding. The only
    way to guarantee this is to use a memory barrier. The call to `glMemoryBarrier`
    will take care of this for us. The parameter to `glMemoryBarrier` is the type
    of barrier. We can fine tune the type of barrier to specifically target the kind
    of data that we want to read. However, just to be safe, and for simplicity, we'll
    use `GL_ALL_BARRIER_BITS`, which ensures that all possible data has been written.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次遍历完成后，在继续之前，我们需要确保所有更改都已写入我们的着色器存储缓冲区和图像对象。唯一保证这一点的办法是使用内存屏障。对`glMemoryBarrier`的调用将为我们处理这个问题。`glMemoryBarrier`的参数是屏障的类型。我们可以微调屏障的类型，以特别针对我们想要读取的数据类型。但是，为了安全起见，以及为了简单起见，我们将使用`GL_ALL_BARRIER_BITS`，这确保了所有可能的数据都已写入。
- en: In the second pass, we start by copying the linked list for the fragment into
    a temporary array. We start by getting the location of the head of the list from
    the `headPointers` image using `imageLoad`. Then we traverse the linked list with
    the `while` loop, copying the data into the `array` frags.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次遍历中，我们首先将片段的链接列表复制到一个临时数组中。我们首先使用`imageLoad`从`headPointers`图像中获取列表的头部位置。然后我们使用`while`循环遍历链接列表，将数据复制到`array`数组`frags`中。
- en: Next, we sort the array by depth from largest to smallest, using the insertion
    sort algorithm. Insertion sort works well on small arrays, so should be a fairly
    efficient choice here.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用插入排序算法按深度从大到小对数组进行排序。插入排序在小数组上表现良好，因此应该是一个相当高效的选择。
- en: Finally, we combine all the fragments in order, using the `mix` function to
    blend them together based on the value of the alpha channel. The final result
    is stored in the output variable `FragColor`.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们按顺序组合所有片段，使用`mix`函数根据alpha通道的值将它们混合在一起。最终结果存储在输出变量`FragColor`中。
- en: There's more...
  id: totrans-508
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: As mentioned previously, we've skipped anything that deals with opaque geometry.
    In general, one would probably want to render any opaque geometry first, with
    the depth buffer enabled, and store the rendered fragments in a texture. Then,
    when rendering the transparent geometry, one would disable writing to the depth
    buffer, and build the linked list as shown previously. Finally, you could use
    the value of the opaque texture as the background color when blending the linked
    lists.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们跳过了所有涉及不透明几何的内容。一般来说，人们可能希望首先渲染任何不透明几何，启用深度缓冲区，并将渲染的片段存储在纹理中。然后，在渲染透明几何时，将禁用写入深度缓冲区，并构建之前显示的链接列表。最后，你可以在混合链接列表时使用不透明纹理的值作为背景颜色。
- en: This is the first example in this book that makes use of reading and writing
    from/to arbitrary (shared) storage from a shader. This capability, has given us
    much more flexibility, but that comes at a price. As indicated previously, we
    have to be very careful to avoid memory consistency and coherence issues. The
    tools to do so include atomic operations and memory barriers, and this example
    has just scratched the surface. There's much more to come in [Chapter 11](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml),
    *Using Compute Shaders* when we look at compute shaders, and I recommend you read
    through the memory chapter in the *OpenGL Programming Guide* for much more detail
    than is provided here.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书中第一个利用从着色器读取和写入任意（共享）存储的例子。这种能力为我们提供了更多的灵活性，但这也带来了代价。如前所述，我们必须非常小心以避免内存一致性和一致性问题的出现。为此，我们可以使用原子操作和内存屏障，而此例只是触及了表面。在[第11章](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml)，*使用计算着色器*中，当我们查看计算着色器时，还有更多内容要介绍。我建议您阅读*OpenGL编程指南*中的内存章节，以获取比这里提供更多的详细信息。
- en: See also
  id: totrans-511
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料还包括
- en: The `chapter06/sceneoit.cpp` file in the example code
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码中的`chapter06/sceneoit.cpp`文件
- en: '[Chapter 11](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml), *Using Compute Shaders*'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第11章](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml)，*使用计算着色器*'
- en: '*OpenGL Development Cookbook* by Muhammad Mobeen Movania has several recipes
    in Chapter 6, *GPU-Based Alpha Blending and Global Illumination*'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenGL开发食谱*由Muhammad Mobeen Movania编写，在第6章*基于GPU的Alpha混合和全局照明*中有几个食谱。'
