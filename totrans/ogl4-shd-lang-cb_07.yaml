- en: Using Geometry and Tessellation Shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Point sprites with the geometry shader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing a wireframe on top of a shaded mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing silhouette lines using the geometry shader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a curve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a 2D quad
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a 3D surface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating based on depth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tessellation and geometry shaders provide programmers with additional ways to
    modify geometry as it progresses through the shader pipeline. Geometry shaders
    can be used to add, modify, or delete geometry in a very precise and user-controlled
    manner. Tessellation shaders can also be configured to automatically subdivide
    geometry to various degrees (levels of detail), potentially creating immensely
    dense geometry via the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll look at several examples of geometry and tessellation
    shaders in various contexts. However, before we get into the recipes, let's investigate
    how all of this fits together.
  prefs: []
  type: TYPE_NORMAL
- en: The shader pipeline extended
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following diagram shows a simplified view of the shader pipeline, when
    the shader program includes geometry and tessellation shaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5e7bd33-7a4f-4522-b079-7e5feb07d9ee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The tessellation portion of the shader pipeline includes two stages: the **Tessellation
    Control Shader** (**TCS**) and the **Tessellation Evaluation Shader** (**TES**).
    The geometry shader follows the tessellation stages and precedes the fragment
    shader. The tessellation shader and geometry shader are optional; however, when
    a shader program includes a tessellation or geometry shader, a vertex shader must
    be included.'
  prefs: []
  type: TYPE_NORMAL
- en: All shaders except the vertex shader are optional. When using a geometry shader,
    there is no requirement that you also include a tessellation shader and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: The geometry shader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **geometry shader** (**GS**) is designed to execute once for each primitive.
    It has access to all of the vertices of the primitive, as well as the values of
    any input variables associated with each vertex. In other words, if a previous
    stage (such as the vertex shader) provides an output variable, the geometry shader
    has access to the value of that variable for all vertices in the primitive. As
    a result, the input variables within the geometry shader are always arrays.
  prefs: []
  type: TYPE_NORMAL
- en: The geometry shader can output zero, one, or more primitives. Those primitives
    need not be of the same kind that were received by the geometry shader.
  prefs: []
  type: TYPE_NORMAL
- en: However, the GS can only output one primitive type. For example, a GS could
    receive a triangle, and output several line segments as a line strip, or a GS
    could receive a triangle and output zero or many triangles as a triangle strip.
  prefs: []
  type: TYPE_NORMAL
- en: This enables the GS to act in many different ways. A GS could be responsible
    for culling (removing) geometry based on some criteria, such as visibility based
    on occlusions. It could generate additional geometry to augment the shape of the
    object being rendered. The GS could simply compute additional information about
    the primitive and pass the primitive along unchanged, or the GS could produce
    primitives that are entirely different from the input geometry.
  prefs: []
  type: TYPE_NORMAL
- en: The functionality of the GS is centered around the two built-in functions: `EmitVertex`
    and `EndPrimitive`. These two functions allow the GS to send multiple vertices
    and primitives down the pipeline. The GS defines the output variables for a particular
    vertex, and then calls `EmitVertex`. After that, the GS can proceed to redefine
    the output variables for the next vertex, call `EmitVertex` again, and so on.
    After emitting all of the vertices for the primitive, the GS can call `EndPrimitive`
    to let the OpenGL system know that all the vertices of the primitive have been
    emitted. The `EndPrimitive` function is implicitly called when the GS finishes
    execution. If GS does not call `EmitVertex` at all, the input primitive is effectively
    dropped (it is not rendered).
  prefs: []
  type: TYPE_NORMAL
- en: In the following recipes, we'll examine a few examples of the geometry shader.
    In the *Point sprites with the geometry shader* recipe, we'll see an example where
    the input primitive type is entirely different from the output type. In the *Drawing
    a wireframe on top of a shaded mesh* recipe, we'll pass the geometry along unchanged,
    but also produce some additional information about the primitive to help in drawing
    wireframe lines. In the *Drawing silhouette lines using the geometry shader* recipe,
    we'll see an example where the GS passes along the input primitive, but generates
    additional primitives as well.
  prefs: []
  type: TYPE_NORMAL
- en: The tessellation shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the tessellation shaders are active, we can only render one kind of primitive:
    the patch (`GL_PATCHES`). Rendering any other kind of primitive (such as triangles,
    or lines) while a tessellation shader is active is an error. The **patch primitive**
    is an arbitrary *chunk* of geometry (or any information) that is completely defined
    by the programmer. It has no geometric interpretation beyond how it is interpreted
    within the TCS and TES. The number of vertices within the patch primitive is also
    configurable. The maximum number of vertices per patch is implementation-dependent,
    and can be queried via the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can define the number of vertices per patch with the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A very common application of this is when the patch primitive consists of a
    set of control points that define an interpolated surface or curve (such as a
    Bezier curve or surface). However, there is no reason why the information within
    the patch primitive couldn't be used for other purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The patch primitive is never actually rendered; instead, it is used as additional
    information for the TCS and TES. The primitives that actually make their way further
    down the pipeline are created by the **tessellation primitive generator** (**TPG**),
    which lies between the TCS and TES. Think of the tessellation-primitive generator
    as a configurable engine that produces primitives based on a set of standard tessellation
    algorithms. The TCS and TES have access to the entire input patch, but have fundamentally
    different responsibilities. The TCS is responsible for:'
  prefs: []
  type: TYPE_NORMAL
- en: setting up the TPG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: defining how the primitives should be generated by the TPG (how many and what
    algorithm to use)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: producing per-vertex output attributes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TES has the job of determining the position (and any other information)
    of each vertex of the primitives that are produced by the TPG. For example, the
    TCS might tell the TPG to generate a line strip consisting of 100 line segments,
    and the TES is responsible for determining the position of each vertex of those
    100 line segments. The TES would likely make use of the information within the
    entire patch primitive in order to do so.
  prefs: []
  type: TYPE_NORMAL
- en: The TCS is executed once for each vertex in a patch, but has access to all vertices
    of its associated patch. It can compute additional information about the patch
    and pass it along to the TES using output variables. However, the most important
    task of the TCS is to tell the TPG how many primitives it should produce. It does
    this by defining tessellation levels via the `gl_TessLevelInner` and `gl_TessLevelOuter`
    arrays. These arrays define the granularity of the tessellation produced by the
    TPG.
  prefs: []
  type: TYPE_NORMAL
- en: The TPG generates primitives based on a particular algorithm (quads, isolines,
    or triangles). Each algorithm produces primitives in a slightly different fashion,
    and we will see examples of isolines and quads in the recipes in this chapter.
    Each vertex of the generated primitives is associated with a position in parameter
    space (u, v, w). Each coordinate of this position is a number that can range from
    zero to one. This coordinate can be used to evaluate the location of the vertex,
    often by interpolation of the patch primitive's vertices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The primitive-generation algorithms produce vertices (and the associated parametric
    coordinates) in a slightly different fashion. The tessellation algorithms for
    quads and isolines make use of only the first two parametric coordinates: *u*
    and *v*. The following diagram illustrates the process for an input and output
    patch consisting of four vertices. In the diagram, the TPG uses the quad tessellation
    algorithm with the inner and outer tessellation levels set at four:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f134320-c9fe-44e2-b161-e538b96aed54.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of vertices in the input patch need not be the same as the number
    of vertices in the output patch, although that will be the case in all of the
    examples in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The TES is executed once for each parameter-space vertex that is generated by
    the TPG. Somewhat strangely, the TES is actually the shader that defines the algorithm
    used by the TPG. It does so via its input layout qualifier. As stated earlier,
    its main responsibility is to determine the position of the vertex (possibly along
    with other information, such as normal vector and texture coordinate). Typically,
    the TES uses the parametric coordinate (u,v) provided by the TPG along with the
    positions of all of the input patch vertices to do so. For example, when drawing
    a curve, the patch might consists of four vertices, which are the control points
    for the curve. The TPG would then generate 101 vertices to create a line strip
    (if the tessellation level was set to 100), and each vertex might have a *u* coordinate
    that ranged appropriately between zero and one. The TES would then use that *u*
    coordinate along with the positions of the four patch vertices to determine the
    position of the vertex associated with the shader's execution.
  prefs: []
  type: TYPE_NORMAL
- en: If all of this seems confusing, start with the *Tessellating a curve* recipe,
    and work your way through the following recipes.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Tessellating a curve* recipe, we'll go through a basic example where
    we use tessellation shaders to draw a Bezier curve with four control points. In
    the *Tessellating a 2D quad* recipe, we'll try to understand how the quad tessellation
    algorithm works by rendering a simple quad and visualizing the triangles produced
    by the TPG. In the *Tessellating a 3D surface* recipe, we'll use quad tessellation
    to render a 3D Bezier surface. Finally, in the *Tessellating based on depth* recipe,
    we'll see how the tessellation shaders make it easy to implement **level-of-detail**
    (**LOD**) algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Point sprites with the geometry shader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Point sprites** are simple quads (usually texture mapped) that are aligned
    such that they are always facing the camera. They are very useful for particle
    systems in 3D (refer to [Chapter 9](36422579-2eed-46ff-95b7-755859c387eb.xhtml),
    *Using Noise in Shaders*) or 2D games. The point sprites are specified by the
    OpenGL application as single-point primitives, via the `GL_POINTS` rendering mode.
    This simplifies the process, because the quad itself and the texture coordinates
    for the quad are determined automatically. The OpenGL side of the application
    can effectively treat them as point primitives, avoiding the need to compute the
    positions of the quad vertices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows a group of point sprites. Each sprite is rendered
    as a point primitive. The quad and texture coordinates are generated automatically
    (within the geometry shader) and aligned to face the camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6358f541-9692-4abf-92cd-ba82a0a22076.png)'
  prefs: []
  type: TYPE_IMG
- en: OpenGL already has built-in support for point sprites in the `GL_POINTS` rendering
    mode. When rendering point primitives using this mode, the points are rendered
    as screen-space squares that have a diameter (side length) as defined by the `glPointSize`
    function. In addition, OpenGL will automatically generate texture coordinates
    for the fragments of the square. These coordinates run from zero to one in each
    direction (horizontal and vertical), and are accessible in the fragment shader
    via the `gl_PointCoord` built-in variable.
  prefs: []
  type: TYPE_NORMAL
- en: There are various ways to fine-tune the rendering of point sprites within OpenGL.
    One can define the origin of the automatically-generated texture coordinates using
    the `glPointParameter` functions. The same set of functions also can be used to
    tweak the way that OpenGL defines the alpha value for points when multi-sampling
    is enabled.
  prefs: []
  type: TYPE_NORMAL
- en: The built-in support for point sprites does not allow the programmer to rotate
    the screen-space squares, or define them as different shapes, such as rectangles
    or triangles. However, one can achieve similar effects with the creative use of
    textures and transformations of the texture coordinates. For example, we could
    transform the texture coordinates using a rotation matrix to create the look of
    a rotating object even though the geometry itself is not actually rotating. In
    addition, the size of the point sprite is a screen-space size. In other words,
    the point size must be adjusted with the depth of the point sprite if we want
    to get a perspective effect (sprites get smaller with distance).
  prefs: []
  type: TYPE_NORMAL
- en: If these (and possibly other) issues make the default support for point sprites
    too limiting, we can use the geometry shader to generate our point sprites. In
    fact, this technique is a good example of using the geometry shader to generate
    different kinds of primitives than it receives. The basic idea here is that the
    geometry shader will receive point primitives (in camera coordinates) and will
    output a quad centered at the point and aligned so that it is facing the camera.
    The geometry shader will also automatically generate texture coordinates for the
    quad.
  prefs: []
  type: TYPE_NORMAL
- en: If desired, we could generate other shapes, such as hexagons, or we could rotate
    the quads before they are output from the geometry shader. The possibilities are
    endless.
  prefs: []
  type: TYPE_NORMAL
- en: Before jumping directly into the code, let's take a look at some of the mathematics.
    In the geometry shader, we'll need to generate the vertices of a quad that is
    centered at a point and aligned with the camera's coordinate system (eye coordinates).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the point location (**P**) in camera coordinates, we can generate the
    vertices of the corners of the quad by simply translating **P** in a plane parallel
    to the x-y plane of the camera''s coordinate system, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99afbe00-d819-4ce4-b58d-ed568411d828.png)'
  prefs: []
  type: TYPE_IMG
- en: The geometry shader will receive the point location in camera coordinates, and
    output the quad as a triangle strip with texture coordinates. The fragment shader
    will then just apply the texture to the quad.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this example, we'll need to render a number of point primitives. The positions
    can be sent via attribute location `0`. There's no need to provide normal vectors
    or texture coordinates for this one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following uniform variables are defined within the shaders, and need to
    be set within the OpenGL program:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Size2`: This should be half the width of the sprite''s square'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SpriteTex`: This is the texture unit containing the point sprite texture'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As usual, uniforms for the standard transformation matrices are also defined
    within the shaders, and need to be set within the OpenGL program.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that can be used to render point primitives as quads,
    use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader will convert the position to camera coordinates and assign
    to the `gl_Position` output variable. Note that we''re not converting to clip
    coordinates just yet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The geometry shader emits two triangles as a triangle strip. We use the `gl_in`
    variable to access the position from the vertex shader (camera coordinates):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader applies the texture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Within the OpenGL render function, render a set of point primitives.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader is almost as simple as it can get. It converts the point's
    position to camera coordinates by multiplying by the model-view matrix, and assigns
    the result to the built-in output variable, `gl_Position`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the geometry shader, we start by defining the kind of primitive that this
    geometry shader expects to receive. The first layout statement indicates that
    this geometry shader will receive point primitives:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The next layout statement indicates the kind of primitives produced by this
    geometry shader, and the maximum number of vertices that will be output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we want to produce a single quad for each point received, so we
    indicate that the output will be a triangle strip with a maximum of four vertices.
  prefs: []
  type: TYPE_NORMAL
- en: The input primitive is available to the geometry shader via the built-in input
    variable, `gl_in`. Note that it is an array of structures. You might be wondering
    why this is an array since a point primitive is only defined by a single position.
  prefs: []
  type: TYPE_NORMAL
- en: Well, in general, the geometry shader can receive triangles, lines, or points
    (and possibly adjacency information). So, the number of values available may be
    more than one. If the input were triangles, the geometry shader would have access
    to three input values (associated with each vertex). In fact, it could have access
    to as many as six values when `triangles_adjacency` is used (more on that in a
    later recipe).
  prefs: []
  type: TYPE_NORMAL
- en: The `gl_in` variable is an array of structs. Each struct contains the following
    fields: `gl_Position`, `gl_PointSize`, and `gl_ClipDistance[]`. In this example,
    we are only interested in `gl_Position`. However, the others can be set in the
    vertex shader to provide additional information to the geometry shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the `main` function of the geometry shader, we produce the quad (as
    a triangle strip) in the following way. For each vertex of the triangle strip,
    we execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the attributes for the vertex (in this case the position and texture
    coordinate), and assign their values to the appropriate output variables (`gl_Position`
    and `TexCoord`). Note that the position is also transformed by the projection
    matrix. We do this because the `gl_Position` variable must be provided in clip
    coordinates to later stages of the pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Emit the vertex (send it down the pipeline) by calling the built-in `EmitVertex()` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once we have emitted all vertices for the output primitive, we call `EndPrimitive()`
    to finalize the primitive and send it along.
  prefs: []
  type: TYPE_NORMAL
- en: It is not strictly necessary to call `EndPrimitive()` in this case because it
    is implicitly called when the geometry shader finishes. However, like closing
    files, it is a good practice.
  prefs: []
  type: TYPE_NORMAL
- en: The fragment shader is also very simple. It just applies the texture to the
    fragment using the (interpolated) texture coordinate provided by the geometry
    shader.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This example is fairly straightforward and is intended as a gentle introduction
    to geometry shaders. We could expand on this by allowing the quad to rotate or
    to be oriented in different directions. We could also use the texture to discard
    fragments (in the fragment shader) in order to create point sprites of arbitrary
    shapes. The power of the geometry shader opens up plenty of possibilities!
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenepointsprite.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing a wireframe on top of a shaded mesh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The preceding recipe demonstrated the use of a geometry shader to produce a
    different variety of primitives than it received. Geometry shaders can also be
    used to provide additional information to later stages. They are quite well-suited
    to doing so because they have access to all of the vertices of the primitive at
    once, and can do computations based on the entire primitive rather than a single
    vertex.
  prefs: []
  type: TYPE_NORMAL
- en: This example involves a geometry shader that does not modify the triangle at
    all. It essentially passes the primitive along unchanged. However, it computes
    additional information about the triangle that will be used by the fragment shader
    to highlight the edges of the polygon. The basic idea here is to draw the edges
    of each polygon directly on top of the shaded mesh.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows an example of this technique. The mesh edges are
    drawn on top of the shaded surface by using information computed within the geometry
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85998f4d-e8b2-413b-ae0d-248d1d8ffd20.png)'
  prefs: []
  type: TYPE_IMG
- en: There are many techniques for producing wireframe structures on top of shaded
    surfaces. This technique comes from an NVIDIA whitepaper published in 2007\. We
    make use of the geometry shader to produce the wireframe and shaded surface in
    a single pass. We also provide some simple anti-aliasing of the mesh lines that
    are produced, and the results are quite nice (refer to the preceding image).
  prefs: []
  type: TYPE_NORMAL
- en: To render the wireframe on top of the shaded mesh, we'll compute the distance
    from each fragment to the nearest triangle edge. When the fragment is within a
    certain distance from the edge, it will be shaded and mixed with the edge color.
    Otherwise, the fragment will be shaded normally.
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the distance from a fragment to the edge, we use the following technique.
    In the geometry shader, we compute the minimum distance from each vertex to the
    opposite edge (also called the **triangle altitude**). In the following diagram,
    the desired distances are **ha**, **hb**, and **hc**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9d927f2-7b3f-4bce-acd6-c80b8c0f1f33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can compute these altitudes using the interior angles of the triangle, which
    can be determined using the law of cosines. For example, to find **ha**, we use
    the interior angle at vertex **C** (**β**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff8aa61a-661c-44d8-8886-7aa2243ec2f7.png)'
  prefs: []
  type: TYPE_IMG
- en: The other altitudes can be computed in a similar way. (Note that **β** could
    be greater than 90 degrees, in which case, we would want the sine of 180-β. However,
    the sine of 180-β is the same as the sine of β.) Once we have computed these triangle
    altitudes, we can create an output vector (an *edge-distance* vector) within the
    geometry shader for interpolation across the triangle. The components of this
    vector represent the distances from the fragment to each edge of the triangle.
  prefs: []
  type: TYPE_NORMAL
- en: The *x* component represents the distance from edge **a**, the *y* component
    is the distance from edge **b**, and the *z* component is the distance from edge
    **c**. If we assign the correct values to these components at the vertices, the
    hardware will automatically interpolate them for us to provide the appropriate
    distances at each fragment. At vertex **A**, the value of this vector should be
    (**ha**, 0, 0) because vertex **A** is at a distance of ha from edge **a** and
    directly on edges **b** and **c**. Similarly, the value for vertex **B** is (0,
    **hb**, 0) and for vertex **C** is (0, 0, **hc**). When these three values are
    interpolated across the triangle, we should have the distance from the fragment
    to each of the three edges. We will calculate all of this in screen space. That
    is, we'll transform the vertices to screen space within the geometry shader before
    computing the altitudes.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are working in screen space, there's no need (and it would be incorrect)
    to interpolate the values in a perspective-correct manner. So we need to be careful
    to tell the hardware to interpolate linearly. Within the fragment shader, all
    we need to do is find the minimum of the three distances, and if that distance
    is less than the line width, we mix the fragment color with the line color. However,
    we'd also like to apply a bit of anti-aliasing while we're at it. To do so, we'll
    fade the edge of the line using the GLSL `smoothstep` function. We'll scale the
    intensity of the line in a two-pixel range around the edge of the line. Pixels
    that are at a distance of one or less from the true edge of the line get 100%
    of the line color, and pixels that are at a distance of one or more from the edge
    of the line get 0% of the line color. In between, we'll use the `smoothstep` function
    to create a smooth transition. Of course, the edge of the line itself is a configurable
    distance (we'll call it `Line.Width`) from the edge of the polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The typical setup is needed for this example. The vertex position and normal
    should be provided in attributes zero and one, respectively, and you need to provide
    the appropriate parameters for your shading model. As usual, the standard matrices
    are defined as uniform variables and should be set within the OpenGL application.
    However, note that this time we also need the viewport matrix (the `ViewportMatrix` uniform
    variable) in order to transform into screen space. There are a few uniforms related
    to the mesh lines that need to be set:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Line.Width`: This should be half the width of the mesh lines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Line.Color`: This is the color of the mesh lines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that utilizes the geometry shader to produce a wireframe
    on top of a shaded surface, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code for the vertex shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the geometry shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The vertex shader is pretty simple. It passes the normal and position along
    to the geometry shader after converting them into camera coordinates. The built-in `gl_Position` variable
    gets the position in clip coordinates. We''ll use this value in the geometry shader
    to determine the screen space coordinates. In the geometry shader, we begin by
    defining the input and output primitive types for this shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We don''t actually change anything about the geometry of the triangle, so the
    input and output types are essentially the same. We will output exactly the same
    triangle that was received as input. The output variables for the geometry shader
    are `GNormal`, `GPosition`, and `GEdgeDistance`. The first two are simply the
    values of the normal and position in camera coordinates, passed through unchanged.
    The third is the vector that will store the distance to each edge of the triangle
    (described previously). Note that it is defined with the `noperspective` qualifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `noperspective` qualifier indicates that the values are to be interpolated
    linearly, instead of the default perspective correct interpolation. As mentioned
    previously, these distances are in screen space, so it would be incorrect to interpolate
    them in a non-linear fashion. Within the `main` function, we start by transforming
    the position of each of the three vertices of the triangle from clip coordinates
    to screen space coordinates by multiplying with the viewport matrix. (Note that
    it is also necessary to divide by the *w* coordinate as the clip coordinates are
    homogeneous and may need to be converted back to true Cartesian coordinates.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we compute the three altitudes—`ha`, `hb`, and `hc`—using the law of
    cosines. Once we have the three altitudes, we set `GEdgeDistance` appropriately
    for the first vertex, pass along `GNormal`, `GPosition`, and `gl_Position` unchanged,
    and emit the first vertex by calling `EmitVertex()`. This finishes the vertex
    and emits the vertex position and all of the per-vertex output variables. We then
    proceed similarly for the other two vertices of the triangle, finishing the polygon
    by calling `EndPrimitive()`. In the fragment shader, we start by evaluating the
    basic shading model and storing the resulting color in `color`. At this stage
    in the pipeline, the three components of the `GEdgeDistance` variable should contain
    the distance from this fragment to each of the three edges of the triangle. We
    are interested in the minimum distance, so we find the minimum of the three components
    and store that in the `d` variable. The `smoothstep` function is then used to
    determine how much to mix the line color with the shaded color (`mixVal`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If the distance is less than `Line.Width - 1`, then `smoothstep` will return
    a value of `0`, and if it is greater than `Line.Width + 1`, it will return `1`.
    For values of `d` that are in between the two, we'll get a smooth transition.
    This gives us a value of `0` when inside the line, a value of `1` when outside
    the line, and in a two-pixel area around the edge, we'll get a smooth variation
    between 0 and 1\. Therefore, we can use the result to mix the color directly with
    the line color. Finally, the fragment color is determined by mixing the shaded
    color with the line color using `mixVal` as the interpolation parameter.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This technique produces very nice-looking results and has relatively few drawbacks.
    However, it does have some issues with triangles that are large in screen space
    (extend outside the view volume). If the *w* coordinate is small or zero, the
    position in viewport space can approach infinity, producing some ugly artifacts. 
    This happens when the vertex is at or near the *x*-*y* plane in camera space.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is a good example of how geometry shaders can be useful for tasks
    other than the modification of the actual geometry. In this case, we used the
    geometry shader simply to compute additional information about the primitive as
    it was being sent down the pipeline. This shader can be dropped in and applied
    to any mesh without any modification to the OpenGL side of the application. It
    can be useful when debugging mesh issues or when implementing a mesh modeling
    program. Other common techniques for accomplishing this effect typically involve
    rendering the shaded object and wireframe in two passes with a polygon offset
    (via the `glPolygonOffset` function) applied to avoid **z-fighting**, which takes
    place between the wireframe and the shaded surface beneath. This technique is
    not always effective because the modified depth values might not always be correct,
    or as desired, and it can be difficult to find the sweet spot for the polygon
    offset value. For a good survey of techniques, refer to *Section 11.4.2* in *Real
    Time Rendering*, *third edition*, by T Akenine-Moller, E Haines, and N Hoffman,
    AK Peters, 2008.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/sceneshadewire.cpp` file in the example code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This technique was originally published in an NVIDIA whitepaper in 2007 (*Solid
    Wireframe*, *NVIDIA Whitepaper WP-03014-001_v01* available at [developer.nvidia.com](http://developer.nvidia.com)).
    The white paper was listed as a Direct3D example, but of course our implementation
    here is provided in OpenGL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Creating shadows using shadow volumes and the geometry shader* recipe in
    [Chapter 8](43239816-a842-483f-9eca-284f919d0bd6.xhtml), *Shadows*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing silhouette lines using the geometry shader
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a cartoon or hand-drawn effect is desired, we often want to draw black
    outlines around the edges of a model and along ridges or creases (silhouette lines).
    In this recipe, we'll discuss one technique for doing this using the geometry
    shader, to produce the additional geometry for the silhouette lines. The geometry
    shader will approximate these lines by generating small, skinny quads aligned
    with the edges that make up the silhouette of the object. The following image
    shows the ogre mesh with black silhouette lines generated by the geometry shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'The lines are made up of small quads that are aligned with certain mesh edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39d7443c-089e-49d6-bcf2-26602ed1ddb7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The technique shown in this recipe is based on a technique published in a blog
    post by Philip Rideout: [prideout.net/blog/?p=54](http://prideout.net/blog/?p=54).
    His implementation uses two passes (base geometry and silhouette), and includes
    many optimizations, such as anti-aliasing and custom depth testing (with g-buffers).
    To keep things simple, as our main goal is to demonstrate the features of the
    geometry shader, we''ll implement the technique using a single pass without anti-aliasing
    or custom depth testing. If you are interested in adding these additional features,
    refer to Philip''s excellent blog post. One of the most important features of
    the geometry shader is that it allows us to provide additional vertex information
    beyond just the primitive being rendered. When geometry shaders were introduced
    in OpenGL, several additional primitive rendering modes were also introduced.
    These **adjacency modes** allow additional vertex data to be associated with each
    primitive. Typically, this additional information is related to the nearby primitives
    within a mesh, but there is no requirement that this be the case (we could actually
    use the additional information for other purposes if desired). The following list
    includes the adjacency modes along with a short description:'
  prefs: []
  type: TYPE_NORMAL
- en: '`GL_LINES_ADJACENCY`: This mode defines lines with adjacent vertices (four
    vertices per line segment)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_LINE_STRIP_ADJACENCY`: This mode defines a line strip with adjacent vertices
    (for *n* lines, there are *n+3* vertices)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_TRIANGLES_ADJACENCY`: This mode defines triangles along with vertices of
    adjacent triangles (six vertices per primitive)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GL_TRIANGLE_STRIP_ADJACENCY`: This mode defines a triangle strip along with
    vertices of adjacent triangles (for *n* triangles, there are *2(n+2)* vertices
    provided)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For full details on each of these modes, check out the official OpenGL documentation.
    In this recipe, we''ll use the `GL_TRIANGLES_ADJACENCY` mode to provide information
    about adjacent triangles in our mesh. With this mode, we provide six vertices
    per primitive. The following diagram illustrates the locations of these vertices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66d81906-1fe1-4b06-99ef-59f9a8992c80.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the solid line represents the triangle itself, and
    the dotted lines represent adjacent triangles. The first, third, and fifth vertices
    (**0**, **2**, and **4**) make up the triangle itself. The second, fourth, and
    sixth are vertices that make up the adjacent triangles.
  prefs: []
  type: TYPE_NORMAL
- en: Mesh data is not usually provided in this form, so we need to preprocess our
    mesh to include the additional vertex information. Typically, this only means
    expanding the element index array by a factor of two. The position, normal, and
    texture coordinate arrays can remain unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: When a mesh is rendered with adjacency information, the geometry shader has
    access to all six vertices associated with a particular triangle. We can then
    use the adjacent triangles to determine whether a triangle edge is part of the
    silhouette of the object. The basic assumption is that an edge is a silhouette
    edge if the triangle is front-facing and the corresponding adjacent triangle is
    not front-facing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can determine whether a triangle is front-facing within the geometry shader
    by computing the triangle''s normal vector (using a cross product). If we are
    working within eye coordinates (or clip coordinates), the *z* coordinate of the
    normal vector will be positive for front-facing triangles. Therefore, we only
    need to compute the *z* coordinate of the normal vector, which should save a few
    cycles. For a triangle with vertices *A*, *B*, and *C*, the *z* coordinate of
    the normal vector is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18f15f0e-3e95-4434-b8f9-f27ccfbf3c51.png)'
  prefs: []
  type: TYPE_IMG
- en: Once we determine which edges are silhouette edges, the geometry shader will
    produce additional skinny quads aligned with the silhouette edge. These quads,
    taken together, will make up the desired dark lines (refer to the previous figure).
    After generating all the silhouette quads, the geometry shader will output the
    original triangle.
  prefs: []
  type: TYPE_NORMAL
- en: In order to render the mesh in a single pass with appropriate shading for the
    base mesh, and no shading for the silhouette lines, we'll use an additional output
    variable. This variable will let the fragment shader know when we are rendering
    the base mesh and when we are rendering the silhouette edge.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Set up your mesh data so that adjacency information is included. As just mentioned,
    this probably requires expanding the element index array to include the additional
    information. This can be done by passing through your mesh and looking for shared
    edges. Due to space limitations, we won''t go through the details here, but the
    blog post mentioned some time back has some information about how this might be
    done. Also, the source code for this example contains a simple (albeit not very
    efficient) technique. The important uniform variables for this example are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`EdgeWidth`: This is the width of the silhouette edge in clip (normalized device)
    coordinates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PctExtend`: This is a percentage to extend the quads beyond the edge'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LineColor`: This is the color of the silhouette edge lines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As usual, there are also the appropriate uniforms for the shading model, and
    the standard matrices.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that utilizes the geometry shader to render silhouette
    edges, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code for the vertex shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the geometry shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader is a simple *passthrough* shader. It converts the vertex position
    and normal to camera coordinates and sends them along, via `VPosition` and `VNormal`.
    These will be used for shading within the fragment shader and will be passed along
    (or ignored) by the geometry shader. The position is also converted to clip coordinates
    (or normalized device coordinates) by transforming with the model-view projection
    matrix, and it is then assigned to the built-in `gl_Position`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The geometry shader begins by defining the input and output primitive types
    using the layout directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that the input primitive type is triangles with adjacency information,
    and the output type is triangle strips. This geometry shader will produce a single
    triangle (the original triangle) and at most one quad for each edge. This corresponds
    to a maximum of 15 vertices that could be produced, and we indicate that maximum
    within the output layout directive.
  prefs: []
  type: TYPE_NORMAL
- en: The `GIsEdge` output variable is used to indicate to the fragment shader whether
    or not the polygon is an edge quad. The fragment shader will use this value to
    determine whether to shade the polygon. There is no need to interpolate the value
    and since it is a Boolean, interpolation doesn't quite make sense, so we use the
    `flat` qualifier.
  prefs: []
  type: TYPE_NORMAL
- en: The first few lines within the `main` function take the position for each of
    the six vertices (in clip coordinates) and divide it by the fourth coordinate
    in order to convert it from its homogeneous representation to the true Cartesian
    value. This is necessary if we are using a perspective projection, but is not
    necessary for orthographic projections.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we determine whether the main triangle (defined by points `0`, `2`, and
    `4`) is front-facing. The `isFrontFacing` function returns whether the triangle
    defined by its three parameters is front-facing using the equation described previously.
    If the main triangle is front-facing, we will emit a silhouette edge quad only
    if the adjacent triangle is not front-facing.
  prefs: []
  type: TYPE_NORMAL
- en: The `emitEdgeQuad` function produces a quad that is aligned with an edge defined
    by the `e0` and `e1` points. It begins by computing `ext`, which is the vector
    from `e0` to `e1`, scaled by `PctExtend` (in order to slightly lengthen the edge
    quad). We lengthen the edge quad in order to cover gaps that may appear between
    quads (we'll discuss this further in *There's more...*).
  prefs: []
  type: TYPE_NORMAL
- en: Note also that we drop the *z* coordinate here. As the points are defined in
    clip coordinates, and we are going to produce a quad that is aligned with the
    x-y plane (facing the camera), we want to compute the positions of the vertices
    by translating within the x-y plane. Therefore we can ignore the *z* coordinate
    for now. We'll use its value unchanged in the final position of each vertex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the `v` variable is assigned to the normalized vector from `e0` to `e1`.
    The `n` variable gets a vector that is perpendicular to `v` (in 2D, this can be
    achieved by swapping the *x* and *y* coordinates and negating the new *x* coordinate).
    This is just a counter-clockwise 90-degree rotation in 2D. We scale the `n` vector
    by `EdgeWidth` because we want the length of the vector to be the same as the
    width of the quad. The `ext` and `n` vectors will be used to determine the vertices
    of the quad, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7c319c1-d834-485f-ae6a-5cccc4cfd2dd.png)'
  prefs: []
  type: TYPE_IMG
- en: The four corners of the quad are given by **e0 - ext**, **e0 - n - ext**, **e1
    + ext**, and **e1 - n + ext**. The *z* coordinate for the lower two vertices is
    the same as the *z* coordinate for **e0**, and the *z* coordinate for the upper
    two vertices is the *z* coordinate for **e1**.
  prefs: []
  type: TYPE_NORMAL
- en: We then finish up the `emitEdgeQuad` function by setting `GIsEdge` to `true`
    in order to let the fragment shader know that we are rendering a silhouette edge,
    and then emitting the four vertices of the quad. The function ends with a call
    to `EndPrimitive` to terminate the processing of the triangle strip for the quad.
  prefs: []
  type: TYPE_NORMAL
- en: Back within the `main` function, after producing the silhouette edges, we proceed
    by emitting the original triangle unchanged. `VNormal`, `VPosition`, and `gl_Position`
    for vertices `0`, `2`, and `4` are passed along without any modification to the
    fragment shader. Each vertex is emitted with a call to `EmitVertex`, and the primitive
    is completed with `EndPrimitive`.
  prefs: []
  type: TYPE_NORMAL
- en: Within the fragment shader, we either shade the fragment (using the toon shading
    algorithm), or simply give the fragment a constant color. The `GIsEdge` input
    variable will indicate which option to choose. If `GIsEdge` is `true`, then we
    are rendering a silhouette edge so the fragment is given the line color. Otherwise,
    we are rendering a mesh polygon, so we shade the fragment using the toon shading
    technique from [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting
    and Shading*.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the problems with the preceding technique is that **feathering** can
    occur due to the gaps between consecutive edge quads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b429c478-28a1-4a3a-8d84-953af16a5857.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows the feathering of a silhouette edge. The gaps between
    the polygons can be filled with triangles, but in our example, we simply extend
    the length of each quad to fill in the gap. This can, of course, cause artifacts
    if the quads are extended too far, but in practice they haven't been very distracting
    in my experience.
  prefs: []
  type: TYPE_NORMAL
- en: 'A second issue is related to depth testing. If an edge polygon extends into
    another area of the mesh, it can be clipped due to the depth test. The following
    is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/122f9288-2a45-42f8-9d84-4766a7737c9f.png)'
  prefs: []
  type: TYPE_IMG
- en: The edge polygon should extend vertically throughout the middle of the preceding
    image, but is clipped because it falls behind the part of the mesh that is nearby.
    This issue can be solved by using custom depth testing when rendering the silhouette
    edges. Refer to Philip Rideout's blog post mentioned earlier for details on this
    technique. It may also be possible to turn depth testing off when rendering the
    edges, being careful not to render any edges from the opposite side of the model.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenesilhouette.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A whitepaper on using the geometry shader for fur and fins: [http://developer.download.nvidia.com/whitepapers/2007/SDK10/FurShellsAndFins.pdf](http://developer.download.nvidia.com/whitepapers/2007/SDK10/FurShellsAndFins.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Creating shadows using shadow volumes and the geometry shader* recipe in
    [Chapter 8](43239816-a842-483f-9eca-284f919d0bd6.xhtml), *Shadows*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Creating a cartoon shading effect* recipe in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml),
    *Lighting and Shading*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a curve
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll take a look at the basics of tessellation shaders by
    drawing a **cubic Bezier curve**. A Bezier curve is a parametric curve defined
    by four control points. The control points define the overall shape of the curve.
    The first and last of the four points define the start and end of the curve, and
    the middle points guide the shape of the curve, but do not necessarily lie directly
    on the curve itself. The curve is defined by interpolating the four control points
    using a set of **blending functions**. The blending functions define how much
    each control point contributes to the curve for a given position along the curve.
    For Bezier curves, the blending functions are known as the **Bernstein polynomials**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3216e61-ff68-42d1-b1da-bd7b83d8b158.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding equation, the first term is the binomial coefficient function
    (shown in the following equation), **n** is the degree of the polynomial, **i**
    is the polynomial number, and **t** is the parametric parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3af2d66d-2378-40b9-b401-cabd3ffef959.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The general parametric form for the Bezier curve is then given as a sum of
    the products of the Bernstein polynomials with the control points (**P[i]**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29024019-198d-4c49-9596-f9cfb163f289.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we will draw a cubic Bezier curve, which involves four control
    points (*n = 3*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64cbe72d-f2f3-460f-9cc9-1704887d79c2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And the cubic Bernstein polynomials are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be67b6ba-69c0-4acc-b75b-34ab38eccbc8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As stated in the introduction to this chapter, the tessellation functionality
    within OpenGL involves two shader stages. They are the tessellation control shader
    (TCS) and the tessellation evaluation shader (TES). In this example, we''ll define
    the number of line segments for our Bezier curve within the TCS (by defining the
    outer tessellation levels), and evaluate the Bezier curve at each particular vertex
    location within the TES. The following image shows the output of this example
    for three different tessellation levels. The left figure uses three line segments
    (level 3), the middle uses level 5, and the right-hand figure is created with
    tessellation level 30\. The small squares are the control points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/020120fe-cf25-457f-9d36-caf299c6efe7.png)'
  prefs: []
  type: TYPE_IMG
- en: The control points for the Bezier curve are sent down the pipeline as a patch
    primitive consisting of four vertices. A patch primitive is a programmer-defined
    primitive type. Basically, it is a set of vertices that can be used for anything
    that the programmer chooses. The TCS is executed once for each vertex within the
    patch, and the TES is executed, a variable number of times, depending on the number
    of vertices produced by the TPG. The final output of the tessellation stages is
    a set of primitives. In our case, it will be a line strip.
  prefs: []
  type: TYPE_NORMAL
- en: Part of the job of the TCS is to define the tessellation level. In very rough
    terms, the tessellation level is related to the number of vertices that will be
    generated. In our case, the TCS will be generating a line strip, so the tessellation
    level is the number of line segments in the line strip. Each vertex that is generated
    for this line strip will be associated with a tessellation coordinate that will
    vary between zero and one. We'll refer to this as the *u* coordinate, and it will
    correspond to the parametric *t* parameter in the preceding Bezier curve equation.
  prefs: []
  type: TYPE_NORMAL
- en: What we've looked at so far is not, in fact, the whole story. Actually, the
    TCS will trigger the generation of a set of line strips called isolines. Each
    vertex in this set of isolines will have a *u* and a *v* coordinate. The *u* coordinate
    will vary from zero to one along a given isoline, and *v* will be constant for
    each isoline. The number of distinct values of *u* and *v* is associated with
    two separate tessellation levels, the so-called *outer* levels. For this example,
    however, we'll only generate a single line strip, so the second tessellation level
    (for *v*) will always be one.
  prefs: []
  type: TYPE_NORMAL
- en: Within the TES, the main task is to determine the position of the vertex associated
    with this execution of the shader. We have access to the *u* and *v* coordinates
    associated with the vertex, and we also have (read-only) access to all of the
    vertices of the patch. We can then determine the appropriate position for the
    vertex by using the parametric equation, with *u* as the parametric coordinate
    (*t* in the preceding equation).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the important uniform variables for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NumSegments`: This is the number of line segments to be produced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NumStrips`: This is the number of isolines to be produced. For this example,
    this should be set to `1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LineColor`: This is the color for the resulting line strip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the uniform variables within the main OpenGL application. There are a total
    of four shaders to be compiled and linked. They are the vertex, fragment, tessellation
    control, and tessellation evaluation shaders.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that will generate a Bezier curve from a patch of
    four control points, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code for the vertex shader. Note that we send the vertex
    position along to the TCS unmodified:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code as the tessellation control shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code as the tessellation evaluation shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'It is important to define the number of vertices per patch within the OpenGL
    application. You can do so using the `glPatchParameter` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Render the four control points as a patch primitive within the OpenGL application''s
    `render` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader is just a passthrough shader. It sends the vertex position
    along to the next stage without any modification.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tessellation control shader begins by defining the number of vertices in
    the output patch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Note that this is not the same as the number of vertices that will be produced
    by the tessellation process. In this case, the patch is our four control points,
    so we use a value of four.
  prefs: []
  type: TYPE_NORMAL
- en: The main method within the TCS passes the input position (of the patch vertex)
    to the output position without modification. The `gl_out` and `gl_in` arrays contain
    the input and output information associated with each vertex in the patch. Note
    that we assign and read from `gl_InvocationID` in these arrays. The `gl_InvocationID`
    variable defines the output patch vertex for which this invocation of the TCS
    is responsible. The TCS can access all of the `gl_in` array, but should only write
    to the location in `gl_out` corresponding to `gl_InvocationID`. The other indices
    will be written by other invocations of the TCS.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the TCS sets the tessellation levels by assigning to the `gl_TessLevelOuter`
    array. Note that the values for `gl_TessLevelOuter` are floating point numbers
    rather than integers. They will be rounded up to the nearest integer and clamped
    automatically by the OpenGL system.
  prefs: []
  type: TYPE_NORMAL
- en: The first element in the array defines the number of isolines that will be generated.
    Each isoline will have a constant value for `v`. In this example, the value of
    `gl_TessLevelOuter[0]` should be one since we only want to create a single curve.
    The second one defines the number of line segments that will be produced in the
    line strip. Each vertex in the strip will have a value for the parametric `u`
    coordinate that will vary from zero to one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the TES, we start by defining the input primitive type using a `layout`
    declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This indicates the type of subdivision that is performed by the tessellation
    primitive generator. Other possibilities here include `quads` and `triangles`.
  prefs: []
  type: TYPE_NORMAL
- en: Within the `main` function of the TES, the `gl_TessCoord` variable contains
    the tessellation's `u` and `v` coordinates for this invocation. As we are only
    tessellating in one dimension, we only need the `u` coordinate, which corresponds
    to the *x* coordinate of `gl_TessCoord`.
  prefs: []
  type: TYPE_NORMAL
- en: The next step accesses the positions of the four control points (all the points
    in our patch primitive). These are available in the `gl_in` array.
  prefs: []
  type: TYPE_NORMAL
- en: The cubic Bernstein polynomials are then evaluated at `u` and stored in `b0`,
    `b1`, `b2`, and `b3`. Next, we compute the interpolated position using the Bezier
    curve equation. The final position is converted to clip coordinates and assigned
    to the `gl_Position` output variable.
  prefs: []
  type: TYPE_NORMAL
- en: The fragment shader simply applies `LineColor` to the fragment.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a lot more to be said about tessellation shaders, but this example is
    intended to be a simple introduction so we'll leave that for the following recipes.
    Next, we'll look at tessellation across surfaces in two dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenebezcurve.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a 2D quad
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the best ways to understand OpenGL's hardware tessellation is to visualize
    the tessellation of a 2D quad. When linear interpolation is used, the triangles
    that are produced are directly related to the tessellation coordinates (u,v) that
    are produced by the tessellation primitive generator. It can be extremely helpful
    to draw a few quads with different inner and outer tessellation levels, and study
    the triangles produced. We will do exactly that in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using quad tessellation, the tessellation primitive generator subdivides
    (u,v) parameter space into a number of subdivisions based on six parameters. These
    are the inner tessellation levels for `u` and `v` (inner level 0 and inner level
    1), and the outer tessellation levels for `u` and `v` along both edges (outer
    levels 0 to 3). These determine the number of subdivisions along the edges of
    the parameter space and internally. Let''s look at each of these individually:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Outer level 0 (OL0)**: This is the number of subdivisions along the *v* direction
    where *u = 0*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outer level 1 (OL1)**: This is the number of subdivisions along the *u* direction
    where *v = 0*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outer level 2 (OL2)**: This is the number of subdivisions along the *v* direction
    where *u = 1*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outer level 3 (OL3)**: This is the number of subdivisions along the *u* direction
    where **v = 1**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inner level 0 (IL0)**: This is the number of subdivisions along the *u* direction
    for all internal values of *v*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inner level 1 (IL1)**: This is the number of subdivisions along the *v* direction
    for all internal values of *u*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram represents the relationship between the tessellation
    levels and the areas of parameter space that are affected by each. The outer levels
    define the number of subdivisions along the edges, and the inner levels define
    the number of subdivisions internally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7bdb2e0-832e-4cca-a02f-853ccb66980b.png)'
  prefs: []
  type: TYPE_IMG
- en: The six tessellation levels described some time back can be configured via the `gl_TessLevelOuter`
    and `gl_TessLevelInner` arrays. For example, `gl_TessLevelInner[0]` corresponds
    to **IL0**, `gl_TessLevelOuter[2]` corresponds to **OL2**, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we draw a patch primitive that consists of a single quad (four vertices),
    and use linear interpolation, the triangles that result can help us to understand
    how OpenGL does quad tessellation. The following diagram shows the results for
    various tessellation levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/3585c185-39d1-44ae-a026-6116257fcbc3.png)]'
  prefs: []
  type: TYPE_NORMAL
- en: When we use linear interpolation, the triangles that are produced represent
    a visual representation of parameter (u, v) space. The *x* axis corresponds to
    the *u* coordinate and the *y* axis corresponds to the *v* coordinate. The vertices
    of the triangles are the (u,v) coordinates generated by the tessellation primitive
    generator. The number of subdivisions can be clearly seen in the mesh of triangles.
    For example, when the outer levels are set to **2** and the inner levels are set
    to **8**, you can see that the outer edges have two subdivisions, but within the
    quad, u and v are subdivided into eight intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before jumping into the code, let''s discuss linear interpolation. If the four
    corners of the quad are as shown in the following figure, then any point within
    the quad can be determined by linearly interpolating the four corners with respect
    to the **u** and **v** parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf0b2180-2719-49b1-bc0f-01f2153c7645.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll let the tessellation-primitive generator create a set of vertices with
    appropriate parametric coordinates, and we'll determine the corresponding positions
    by interpolating the corners of the quad using the preceding equation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The outer and inner tessellation levels will be determined by the `Inner` and
    `Outer` uniform variables. In order to display the triangles, we will use the
    geometry shader.
  prefs: []
  type: TYPE_NORMAL
- en: Set up your OpenGL application to render a patch primitive consisting of four
    vertices in counterclockwise order, as shown in the previous figure.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that will generate a set of triangles using quad
    tessellation from a patch of four vertices, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code for the vertex shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code as the tessellation control shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code as the tessellation evaluation shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Use the geometry shader from the *Drawing a wireframe on top of a shaded mesh* recipe
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following code as the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the `render` function of your main OpenGL program, define the number
    of vertices within a patch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Render the patch as four 2D vertices in counterclockwise order
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader passes the position along to the TCS unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: 'The TCS defines the number of vertices in the patch using the layout directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In the `main` function, it passes along the position of the vertex without modification,
    and sets the inner and outer tessellation levels. All four of the outer tessellation
    levels are set to the value of `Outer`, and both of the inner tessellation levels
    are set to `Inner`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the tessellation evaluation shader, we define the tessellation mode and
    other tessellation parameters with the input layout directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `quads` parameter indicates that the tessellation-primitive generator should
    tessellate the parameter space using quad tessellation. The `equal_spacing` parameter
    says that the tessellation should be performed such that all subdivisions have
    equal length. The last parameter, `ccw`, indicates that the primitives should
    be generated with counterclockwise winding.
  prefs: []
  type: TYPE_NORMAL
- en: The `main` function in the TES starts by retrieving the parametric coordinates
    for this vertex by accessing the `gl_TessCoord` variable. Then we move on to read
    the positions of the four vertices in the patch from the `gl_in` array. We store
    them in temporary variables to be used in the interpolation calculation.
  prefs: []
  type: TYPE_NORMAL
- en: The built-in `gl_Position` output variable then gets the value of the interpolated
    point using the preceding equation. Finally, we convert the position into clip
    coordinates by multiplying by the model-view projection matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Within the fragment shader, we give all fragments a color that is possibly mixed
    with a line color in order to highlight the edges.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenequadtess.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Drawing a wireframe on top of a shaded mesh* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating a 3D surface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an example of tessellating a 3D surface, let's render (yet again) the *teapotahedron.*
    It turns out that the teapot's dataset is actually defined as a set of 4 x 4 patches
    of control points, suitable for cubic Bezier interpolation. Therefore, drawing
    the teapot really boils down to drawing a set of cubic Bezier surfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this sounds like a perfect job for tessellation shaders! We'll render
    each patch of 16 vertices as a patch primitive, use quad tessellation to subdivide
    the parameter space, and implement the Bezier interpolation within the tessellation
    evaluation shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows an example of the desired output. The left teapot
    is rendered with inner and outer tessellation level 2, the middle uses level 4,
    and the teapot on the right uses tessellation level 16\. The tessellation evaluation
    shader computes the Bezier surface interpolation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/932ce989-229a-448c-9787-af4343d398d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, let''s take a look at how cubic Bezier surface-interpolation works.
    If our surface is defined by a set of 16 control points (laid out in a 4 x 4 grid)
    *P[ij]*, with *i* and *j* ranging from 0 to 3, the parametric Bezier surface is
    given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af432160-f4c7-4a39-bb20-2bfec138a669.png)'
  prefs: []
  type: TYPE_IMG
- en: The instances of *B* in the preceding equation are the cubic Bernstein polynomials
    (refer to the previous recipe, *Tessellating a 2D quad*).
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to compute the normal vector at each interpolated location. To
    do so, we have to compute the cross product of the partial derivatives of the
    preceding equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6dd88cc-82cd-410e-a09b-d993113c2833.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The partial derivatives of the Bezier surface boil down to the partial derivatives
    of the Bernstein polynomials:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e786e253-d99d-4092-9707-7eb73ce7cb73.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll compute the partials within the TES and compute the cross product to determine
    the normal to the surface at each tessellated vertex.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Set up your shaders with a vertex shader that simply passes the vertex position
    along without any modification (you can use the same vertex shader as was used
    in the *Tessellating a 2D quad* recipe). Create a fragment shader that implements
    whatever shading model you choose. The fragment shader should receive the `TENormal`
    and `TEPosition` input variables, which will be the normal and position in camera
    coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: The `TessLevel` uniform variable should be given the value of the desired tessellation
    level. All of the inner and outer levels will be set to this value.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that creates Bezier patches from input patches of
    16 control points, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the vertex shader from the *Tessellating a 2D quad* recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following code for the tessellation control shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following code for the tessellation evaluation shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Implement your favorite shading model within the fragment shader utilizing the
    output variables from the TES.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Render the Bezier control points as a 16-vertex patch primitive. Don''t forget
    to set the number of vertices per patch within the OpenGL application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The tessellation control shader starts by defining the number of vertices in
    the patch using the layout directive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: It then simply sets the tessellation levels to the value of `TessLevel`. It
    passes the vertex position along, without any modification.
  prefs: []
  type: TYPE_NORMAL
- en: The tessellation evaluation shader starts by using a layout directive to indicate
    the type of tessellation to be used. As we are tessellating a 4 x 4 Bezier surface
    patch, quad tessellation makes the most sense.
  prefs: []
  type: TYPE_NORMAL
- en: The `basisFunctions` function evaluates the Bernstein polynomials and their
    derivatives for a given value of the `t` parameter. The results are returned in
    the `b` and `db` output parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Within the `main` function, we start by assigning the tessellation coordinates
    to the `u` and `v` variables, and reassigning all 16 of the patch vertices to
    variables with shorter names (to shorten the code that appears later).
  prefs: []
  type: TYPE_NORMAL
- en: We then call `basisFunctions` to compute the Bernstein polynomials and their
    derivatives at `u` and `v`, storing the results in `bu`, `dbu`, `bv`, and `dbv`.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is the evaluation of the sums from the preceding equations for
    the position (`TEPosition`), the partial derivative with respect to `u` (`du`),
    and the partial derivative with respect to `v` (`dv`). We compute the normal vector
    as the cross product of `du` and `dv`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we convert the position (`TEPosition`) to clip coordinates and assign
    the result to
  prefs: []
  type: TYPE_NORMAL
- en: '`gl_Position`. We also convert it to camera coordinates before it is passed
    along to the fragment shader.'
  prefs: []
  type: TYPE_NORMAL
- en: The normal vector is converted to camera coordinates by multiplying it with `NormalMatrix`,
    and the result is normalized and passed along to the fragment shader via `TENormal`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenetessteapot.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Tessellating a 2D quad* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tessellating based on depth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the greatest things about tessellation shaders is how easy it is to implement **level-of-detail**
    (**LOD**) algorithms. LOD is a general term in computer graphics that refers to
    the process of increasing/decreasing the complexity of an object's geometry with
    respect to the distance from the viewer (or other factors). As an object moves
    farther away from the camera, less geometric detail is needed to represent the
    shape because the overall size of the object becomes smaller. However, as the
    object moves closer to the camera, the object fills more and more of the screen,
    and more geometric detail is needed to maintain the desired appearance (smoothness
    or lack of other geometric artifacts).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows a few teapots rendered with tessellation levels that
    depend on distance from the camera. Each teapot is rendered using exactly the
    same code on the OpenGL side. The TCS automatically varies the tessellation levels
    based on depth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/406640f8-eae1-4876-911c-43b073ea62ba.png)'
  prefs: []
  type: TYPE_IMG
- en: When tessellation shaders are used, the tessellation level is what determines
    the geometric complexity of the object. As the tessellation levels can be set
    within the tessellation control shader, it is a simple matter to vary the tessellation
    levels with respect to the distance from the camera.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we'll vary the tessellation levels linearly (with respect to
    distance) between a minimum level and a maximum level. We'll compute the *distance
    from the camera* as the absolute value of the *z* coordinate in camera coordinates,
    (of course, this is not the true distance, but should work fine for the purposes
    of this example). The tessellation level will then be computed based on that value.
    We'll also define two additional values (as uniform variables): `MinDepth` and
    `MaxDepth`. Objects that are closer to the camera than `MinDepth` get the maximum
    tessellation level, and any objects that are further from the camera than `MaxDepth`
    will get the minimum tessellation level. The tessellation level for objects in
    between will be linearly interpolated.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This program is nearly identical to the one in the *Tessellating a 3D surface*
    recipe. The only difference lies within the TCS. We''ll remove the `TessLevel` uniform
    variable, and add a few new ones that are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MinTessLevel`: This is the lowest desired tessellation level'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MaxTessLevel`: This is the highest desired tessellation level'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MinDepth`: This is the minimum *distance* from the camera, where the tessellation
    level is maximal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MaxDepth`: This is the maximum *distance* from the camera, where the tessellation
    level is at a minimum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Render your objects as 16-vertex patch primitives as indicated in the *Tessellating
    a 3D surface* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that varies the tessellation level based on the
    depth, use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the vertex shader and tessellation evaluation shader from the *Tessellating
    a 3D surface* recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following code for the tessellation control shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As with the previous recipe, implement your favorite shading model within the
    fragment shader.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TCS takes the position and converts it to camera coordinates and stores
    the result in the `p` variable. The absolute value of the *z* coordinate is then
    scaled and clamped so that the result is between zero and one. If the *z* coordinate
    is equal to `MaxDepth`, the value of the depth will be `1.0`, if it is equal to
    `MinDepth`, the depth will be `0.0`. If *z* is between `MinDepth` and `MaxDepth`,
    the depth will get a value between zero and one. If *z* is outside that range,
    it will be clamped to `0.0` or `1.0` by the `clamp` function.
  prefs: []
  type: TYPE_NORMAL
- en: The value of `depth` is then used to linearly interpolate between `MaxTessLevel`
    and `MinTessLevel` using the `mix` function. The result (`tessLevel`) is used
    to set the inner and outer tessellation levels.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a somewhat subtle aspect to this example. Recall that the TCS is executed
    once for each output vertex in the patch. Therefore, assuming that we are rendering
    cubic Bezier surfaces, this TCS will be executed 16 times for each patch. Each
    time it is executed, the value of `depth` will be slightly different because it
    is evaluated based on the *z* coordinate of the vertex. You might be wondering,
    which of the 16 possible different tessellation levels will be the one that is
    used? It doesn't make sense for the tessellation level to be interpolated across
    the parameter space. What's going on?
  prefs: []
  type: TYPE_NORMAL
- en: The `gl_TessLevelInner` and `gl_TessLevelOuter` output arrays are per-patch
    output variables. This means that only a single value will be used per patch,
    similar to the way that the flat qualifier works for fragment shader input variables.
    The OpenGL specification seems to indicate that any of the values from each of
    the invocations of the TCS could be the value that ends up being used.
  prefs: []
  type: TYPE_NORMAL
- en: We should also note that if the tessellation level is different for patches
    that share an edge, then there is the potential for cracks to appear or other
    visual artifacts. Therefore we should take care to make sure that neighboring
    patches use the same tessellation level.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter07/scenetessteapotdepth.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DirectX 11 Terrain Tessellation at: [http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/TerrainTessellation_WhitePaper.pdf](http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/TerrainTessellation_WhitePaper.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Tessellating a 3D surface* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
