- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software testing stands as a cornerstone in the edifice of software development,
    holding paramount importance in the assurance of software quality, reliability,
    and maintainability. It is through the meticulous process of testing that developers
    can ensure their creations meet the highest standards of functionality and user
    satisfaction. The inception of any software project is invariably intertwined
    with the potential for bugs and unforeseen issues; it is testing that illuminates
    these hidden pitfalls, allowing developers to address them proactively, thereby
    enhancing the overall integrity and performance of the software.
  prefs: []
  type: TYPE_NORMAL
- en: At the heart of software testing lies a diverse array of methodologies, each
    tailored to examine distinct facets of the software. Among these, unit testing
    serves as the foundational layer, focusing on the smallest testable parts of the
    software to ensure their correct behavior. This granular approach facilitates
    the early detection of errors, streamlining the development process by enabling
    immediate corrections. Ascending from the micro to the macro perspective, integration
    testing takes precedence, wherein the interaction between integrated units is
    scrutinized. This method is pivotal in identifying issues in the interfacing of
    components, ensuring seamless communication and functionality within the software.
  prefs: []
  type: TYPE_NORMAL
- en: Progressing further, system testing emerges as a comprehensive examination of
    the complete and integrated software system. This methodology delves into the
    software’s adherence to specified requirements, offering an overarching assessment
    of its behavior and performance. It is a crucial phase that validates the software’s
    readiness for deployment, ensuring that it functions correctly in its intended
    environment. Lastly, acceptance testing marks the culmination of the testing process,
    where the software is evaluated to determine whether it fulfills the criteria
    for delivery to end users. This final stage is instrumental in affirming the software’s
    alignment with user needs and expectations, serving as the ultimate testament
    to its quality and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Embarking on this chapter, you will be guided through the intricate landscape
    of software testing, gaining insights into the pivotal role it plays in the development
    life cycle. The exploration will encompass the nuanced distinctions between testing
    methodologies, shedding light on their unique objectives and the scope of their
    application. Through this journey, you will acquire a comprehensive understanding
    of how testing underpins the creation of robust, reliable, and user-centric software,
    setting the stage for the subsequent chapters that delve deeper into the specifics
    of unit testing and beyond in the realm of C++.
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Test-driven development**, commonly abbreviated as **TDD**, is a modern software
    development approach that has revolutionized the way code is written and tested.
    At its core, TDD inverts traditional development methodologies by advocating for
    the creation of tests before the development of the actual functional code. This
    paradigm shift is encapsulated in a cyclic process known as “Red-Green-Refactor.”
    Initially, a developer writes a test that defines a desired improvement or a new
    function, which inevitably fails on the first run – this is the “Red” phase, indicating
    the absence of the corresponding functionality. Subsequently, in the “Green” phase,
    the developer crafts the minimum amount of code necessary to pass the test, thereby
    ensuring that the functionality meets the specified requirements. The cycle culminates
    in the “Refactor” phase, where the new code is refined and optimized without altering
    its behavior, thus maintaining the test’s successful outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: The adoption of TDD brings with it a plethora of advantages that contribute
    to a more robust and reliable code base. One of the most significant benefits
    is the marked improvement in code quality. Since TDD necessitates the definition
    of tests upfront, it inherently encourages a more thoughtful and deliberate design
    process, reducing the likelihood of bugs and errors. Moreover, tests crafted in
    the TDD process serve a dual purpose as detailed documentation of the code base.
    These tests provide clear insights into the code’s intended functionality and
    usage, offering valuable guidance for current and future developers. Additionally,
    TDD facilitates the design and refactoring of code by ensuring that changes do
    not inadvertently break existing functionalities, thereby fostering a code base
    that is both flexible and maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: Despite its numerous benefits, TDD is not without its challenges and potential
    drawbacks. One of the initial hurdles encountered when adopting TDD is the perceived
    slowdown in the development process. Writing tests before functionality can feel
    counterintuitive and may extend the time to deliver features, particularly in
    the early stages of adoption. Furthermore, TDD demands a steep learning curve,
    requiring developers to acquire new skills and adapt to a different mindset, which
    can be a significant investment in time and resources. It’s also worth noting
    that TDD may not be universally applicable or ideal for all scenarios. Certain
    types of projects, such as those involving complex user interfaces or requiring
    extensive interaction with external systems, may pose challenges to the TDD methodology,
    necessitating a more nuanced or hybrid approach to testing.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, while TDD presents a transformative approach to software development
    with its emphasis on test-first methodology, it is essential to weigh its benefits
    against the potential challenges. The effectiveness of TDD is contingent upon
    the context of its application, the proficiency of the development team, and the
    nature of the project at hand. As we delve deeper into the subsequent sections,
    the nuances of unit testing, integration with testing frameworks, and practical
    considerations will further illuminate the role of TDD in shaping high-quality,
    maintainable C++ code bases.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unit tests are a foundational aspect of TDD in software engineering, playing
    a pivotal role in the C++ development process. They focus on validating the smallest
    sections of code, known as units, which are typically individual functions, methods,
    or classes. By testing these components in isolation, unit tests ensure that each
    part of the software behaves as intended, which is crucial for the system’s overall
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: In the TDD framework, unit tests take on an even more significant role. They
    are often written before the actual code, guiding the development process and
    ensuring that the software is designed with testability and correctness in mind
    from the outset. This approach to writing unit tests before the implementation
    helps in identifying bugs early in the development cycle, allowing for timely
    corrections that prevent the bugs from becoming more complex or affecting other
    parts of the system. This proactive bug detection not only saves time and resources
    but also contributes to the software’s stability.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, unit tests act as a safety net for developers, enabling them to refactor
    code confidently without fear of breaking existing functionality. This is particularly
    valuable in TDD, where refactoring is a key step in the cycle of writing a test,
    making it pass, and then improving the code. Beyond their role in bug detection
    and facilitating refactoring, unit tests also serve as effective documentation,
    providing clear insights into the expected behavior of the system. This makes
    them an invaluable resource for developers, especially those new to the code base.
    Additionally, the process of writing unit tests in the TDD approach often highlights
    design improvements, leading to more robust and maintainable code.
  prefs: []
  type: TYPE_NORMAL
- en: C++ unit testing frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The C++ ecosystem is rich with unit testing frameworks designed to facilitate
    the creation, execution, and maintenance of tests. Among these, Google Test and
    Google Mock stand out for their comprehensive feature set, ease of use, and integration
    capabilities with C++ projects. In this section, we’ll delve into Google Test
    and Google Mock, highlighting their key features and syntax, and demonstrate how
    they can be integrated into a CMake project.
  prefs: []
  type: TYPE_NORMAL
- en: Google Test and Google Mock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`EXPECT_EQ` and `ASSERT_NE` to compare expected outcomes with actual results,
    ensuring precise validation of test conditions. Furthermore, Google Test simplifies
    the management of common test configurations through test fixtures, which define
    setup and teardown operations, providing a consistent environment for each test.'
  prefs: []
  type: TYPE_NORMAL
- en: Another significant feature is the support for parameterized tests, allowing
    developers to write a single test and run it with multiple inputs. This approach
    greatly enhances test coverage without the need for duplicative code. Complementing
    this, Google Test also supports type-parameterized tests, which permit the execution
    of the same test logic across different data types, broadening the scope of test
    coverage even further.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most user-friendly features of Google Test is its automatic test
    discovery mechanism. This feature eliminates the need for manual test registration,
    as Google Test automatically identifies and executes tests within the project,
    streamlining the testing process and saving valuable development time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Mock**, also known as **gMock**, complements Google Test by providing
    a robust mocking framework, which integrates seamlessly to simulate complex object
    behaviors. This capability is invaluable in creating conditions that mimic real-world
    scenarios, allowing for more thorough testing of code interactions. With Google
    Mock, developers gain the flexibility to set expectations on mocked objects, tailoring
    them to specific needs such as the number of times a function is called, the arguments
    it receives, and the sequence of calls. This level of control ensures that tests
    can verify not just the outcomes but also the interactions between different parts
    of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Google Mock is specifically designed to work in harmony with Google
    Test, facilitating the creation of comprehensive tests that can leverage both
    actual objects and their mocked counterparts. This integration simplifies the
    process of writing tests that are both extensive and reflective of real application
    behavior, thereby enhancing the reliability and maintainability of the codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Google Test into a C++ project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’re going to demonstrate how to incorporate Google Test into a CMake project,
    providing a step-by-step guide to configuring CMake to work with Google Test for
    unit testing in C++ projects.
  prefs: []
  type: TYPE_NORMAL
- en: To start, ensure that Google Test is included in your project. This can be done
    by adding Google Test as a submodule in your project’s repository or downloading
    it via CMake. Once Google Test is part of your project, the next step is to configure
    your `CMakeLists.txt` file to include Google Test in the build process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of how you might configure your `CMakeLists.txt` file to
    integrate Google Test via a submodule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Update `CMakeLists.txt` to include Google Test and Google Mock in the build:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this configuration, `add_subdirectory(external/googletest)` tells CMake to
    include Google Test in the build. `include_directories` ensures that the Google
    Test headers are accessible to your test files. `add_executable` defines a new
    executable for your tests, and `target_link_libraries` links the Google Test libraries
    to your test executable.
  prefs: []
  type: TYPE_NORMAL
- en: After configuring `CMakeLists.txt`, you can build and run your tests using CMake
    and make commands. This setup not only integrates Google Test into your project
    but also leverages CMake’s testing capabilities to automate running the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet demonstrates another way to configure CMake to use
    Google Test, which is by downloading Google Test via CMake’s `FetchContent` module.
    This approach allows CMake to download Google Test during the build process, ensuring
    that the project’s dependencies are automatically managed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: While this example focuses on integrating Google Test with CMake, it’s worth
    noting that Google Test is versatile and can be integrated into other build systems
    as well, such as Google’s own Bazel. For projects using different build systems
    or for more complex configurations, refer to the official Google Test documentation
    for comprehensive guidance and best practices. This documentation provides valuable
    insights into leveraging Google Test across various environments and build systems,
    ensuring that you can effectively implement unit testing in your C++ projects
    regardless of the development setup.
  prefs: []
  type: TYPE_NORMAL
- en: Usage of Google Test in C++ projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Test provides a comprehensive suite of functionalities to support various
    testing needs in C++ development. Understanding how to effectively leverage these
    features can significantly enhance your testing practices. Let’s explore the usage
    of Google Test through simple examples and explanations.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a simple test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A simple test in Google Test can be written using the `TEST` macro, which defines
    a test function. Within this function, you can use various assertions to verify
    the behavior of your code. Here’s a basic example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this example, `EXPECT_EQ` is used to assert that the `add` function returns
    the expected sum of two positive numbers. Google Test provides a variety of assertions
    such as `EXPECT_GT` (greater than), `EXPECT_TRUE` (Boolean `true`), and many others
    for different testing scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: The key difference between `EXPECT_*` and `ASSERT_*` assertions lies in their
    behavior upon failure. While `EXPECT_*` assertions allow the test to continue
    running after a failure, `ASSERT_*` assertions will halt the current test function
    immediately upon failure. Use `EXPECT_*` when subsequent lines of the test do
    not depend on the success of the current assertion, and `ASSERT_*` when the failure
    of an assertion would make the continuation of the test meaningless or potentially
    cause errors.
  prefs: []
  type: TYPE_NORMAL
- en: Using a test fixture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For tests that require a common setup and teardown for multiple test cases,
    Google Test offers the concept of a test fixture. This is achieved by defining
    a class derived from `::testing::Test` and then using the `TEST_F` macro to write
    tests that use this fixture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In this example, `SetUp` and `TearDown` are overridden to provide a common setup
    (initializing a `Calculator` object) and teardown (cleaning up the `Calculator`
    object) for each test case. `TEST_F` is used to define test functions that automatically
    use this setup and teardown, ensuring that each test starts with a fresh `Calculator`
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: The main function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the tests, Google Test requires a main function that initializes the
    Google Test framework and runs all the tests. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This main function initializes Google Test, passing the command-line arguments
    to it, which allows for controlling test execution from the command line. `RUN_ALL_TESTS()`
    runs all the tests that have been defined and returns `0` if all tests pass or
    `1` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: By following these examples and explanations, you can start using Google Test
    to write comprehensive tests for your C++ projects, ensuring that your code behaves
    as expected across a wide range of scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Running Google Test tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After setting up Google Test with your CMake project and compiling your tests,
    running them is straightforward. You execute the tests using the `ctest` command
    in your build directory, which CMake uses to run tests defined in your `CMakeLists.txt`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run the tests for a `Calculator` class, the standard output to your
    terminal might look like this if you execute the test binary directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This output details each test suite and test case, showing which tests were
    run (`[ RUN      ]`) and their results (`[       OK ]` for passed tests). It provides
    a clear breakdown of the testing process, including setup and teardown phases,
    and aggregates the results at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run the tests using `ctest`, the output is more concise by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this `ctest` output, each line corresponds to a test case, showing its start
    order, name, and result. The summary at the end gives a quick overview of the
    total number of tests, how many passed, and how many failed. This format is useful
    for getting a quick assessment of your test suite’s health without the detailed
    breakdown provided by the Google Test output.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced features of Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Test offers a range of advanced features designed to handle complex testing
    scenarios, providing developers with powerful tools to ensure their code’s robustness.
    Among these features, one notable capability is the support for *death tests*.
    Death tests are particularly useful for verifying that your code exhibits the
    expected behavior when it encounters fatal conditions, such as failed assertions
    or explicit calls to `abort()`. This is crucial in scenarios where you want to
    ensure that your application responds appropriately to unrecoverable errors, enhancing
    its reliability and safety.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a brief example of a death test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this example, `EXPECT_DEATH_IF_SUPPORTED` checks that `risky_function(true)`
    indeed causes the program to exit (due to the failed assertion), and it matches
    the specified error message. This ensures that the function behaves as expected
    under fatal conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Other advanced features of Google Test include *mocking* for simulating complex
    object interactions, *parameterized tests* for running the same test logic with
    various inputs, and *type-parameterized tests* for applying the same test logic
    across different data types. These features enable comprehensive testing strategies
    that can cover a wide range of scenarios and inputs, ensuring thorough validation
    of your code.
  prefs: []
  type: TYPE_NORMAL
- en: For developers seeking to leverage the full potential of Google Test, including
    its advanced features such as death tests and more, the official Google Test documentation
    serves as an invaluable resource. It offers detailed explanations, examples, and
    best practices, guiding you through the nuances of effective test writing and
    execution in C++ projects. By referring to this documentation, you can deepen
    your understanding of Google Test’s capabilities and integrate them effectively
    into your testing workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Using gMock in C++ projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the world of software testing, particularly within the methodology of TDD,
    a mock object plays a crucial role. It’s designed to mimic the behavior of real
    objects by implementing the same interface, allowing it to stand in for the actual
    object in tests. However, the power of a mock object lies in its flexibility;
    developers can specify its behavior at runtime, including which methods are called,
    their call order, frequency, argument specifications, and the return values. This
    level of control turns mock objects into powerful tools for testing interactions
    and integrations within the code.
  prefs: []
  type: TYPE_NORMAL
- en: Mocks address several challenges in testing complex or interconnected systems.
    When developing prototypes or tests, relying solely on real objects might not
    be feasible or practical due to constraints such as external dependencies, execution
    time, or costs associated with real operations. In such cases, mocks provide a
    lightweight, controllable substitute that replicates the necessary interactions
    without the overhead or side effects of the real implementations. They enable
    developers to focus on the behavior and integration of components rather than
    their underlying implementations, facilitating more focused and efficient testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The distinction between fake objects and mock objects is crucial to understanding
    their appropriate use cases. While both serve as substitutes for real objects
    in testing, they have different characteristics and purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fake objects**: These are simplified implementations that mimic real objects
    but typically take shortcuts for the sake of testing efficiency. An example would
    be an in-memory database that replicates the functionality of a real database
    system without persistent storage. Fakes are practical for tests where the exact
    workings of the real object are not under scrutiny.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mock objects**: Unlike fakes, mocks are pre-programmed with specific expectations
    that form a contract of how they should be used. They are ideal for testing the
    interactions between the system under test and its dependencies. For instance,
    when testing a class that relies on a service, a mock of the service can be used
    to ensure that the class interacts with the service as expected without actually
    invoking the service’s real implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: gMock, Google’s framework for creating mock classes in C++, provides a comprehensive
    solution akin to what jMock and EasyMock offer for Java. With gMock, developers
    first describe the interface of the object to be mocked using macros, which then
    generate the mock class implementation. Developers can then instantiate mock objects,
    setting up their expected behaviors and interactions using gMock’s intuitive syntax.
    During test execution, gMock monitors these mock objects, ensuring that all specified
    interactions adhere to the defined expectations, and flagging any deviations as
    errors. This immediate feedback is invaluable for identifying issues in how components
    interact with their dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Example of using gMock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In unit testing, particularly when interfacing with network operations, mocking
    is an invaluable technique. This is exemplified in the case of a `Socket` class,
    which serves as a foundational element for network communication. The `Socket`
    class abstracts the functionality of sending and receiving raw byte arrays over
    a network, providing methods such as `send` and `recv`. Concrete classes such
    as `TcpSocket`, `UdpSocket`, and `WebSocket` extend this base class to implement
    specific network protocols. The following code shows the definition of the `Socket`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'For instance, the `DataSender` class relies on a `Socket` instance to send
    data. This class is meticulously designed to manage data transmission, attempting
    retries as necessary and handling various scenarios such as partial data sends,
    peer-initiated connection closures, and connection errors. The objective in unit
    testing `DataSender` is to validate its behavior across these different scenarios
    without engaging in actual network communication. The `DataSender` class is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This requirement leads us to the use of a `MockSocket` class, derived from
    `Socket`, to simulate network interactions. Here’s how `MockSocket` is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `MockSocket` class utilizes the `MOCK_METHOD` macro from gMock to mock the
    `send` and `recv` methods of the `Socket` class, allowing for the specification
    of expected behavior during tests. The `override` keyword ensures that these mock
    methods correctly override their counterparts in the `Socket` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting expectations in gMock is done using constructs such as `WillOnce` and
    `WillRepeatedly`, which define how mock methods behave when invoked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this `HappyPath` test, `EXPECT_CALL` sets an expectation that `send` will
    be called exactly once, successfully transmitting all the data in a single attempt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This test expects two calls to `send`: the first transmits only a portion of
    the data, while the second completes the transmission, simulating a successful
    `send` on the second attempt.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the tests check various error scenarios, such as partial data transmission,
    connection closure by the peer, and connection errors. Here’s an example of a
    test for the scenario where data is sent partially:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Running these tests with gMock and observing the output allows us to confirm
    the `DataSender` class’s behavior under various conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The output succinctly reports the execution and outcomes of each test, indicating
    the successful validation of the `DataSender` class’s handling of different network
    communication scenarios. For more comprehensive details on utilizing gMock, including
    its full suite of features, the official gMock documentation serves as an essential
    resource, guiding developers through effective mocking strategies in C++ unit
    testing.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking non-virtual methods via dependency injection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In certain scenarios, you might encounter the need to mock non-virtual methods
    for unit testing. This can be challenging, as traditional mocking frameworks such
    as gMock primarily target virtual methods due to C++’s polymorphism requirements.
    However, one effective strategy to overcome this limitation is through dependency
    injection, coupled with the use of templates. This approach enhances testability
    and flexibility by decoupling the class dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring for testability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate this, let’s refactor the `Socket` class interface and the `DataSender`
    class to accommodate the mocking of non-virtual methods. We’ll introduce templates
    to `DataSender` to allow injecting either the real `Socket` class or its mock
    version.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, consider a simplified version of the `Socket` class without virtual
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we modify the `DataSender` class to accept a `template` parameter for
    the socket type, enabling the injection of either a real socket or a mock socket
    at compile-time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: With this template-based design, `DataSender` can now be instantiated with any
    type that conforms to the `Socket` interface, including mock types.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking with templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the mock version of `Socket`, we can define a `MockSocket` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This `MockSocket` class mimics the `Socket` interface but uses gMock’s `MOCK_METHOD`
    to define mock methods.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing with dependency injection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When writing tests for `DataSender`, we can now inject `MockSocket` using templates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In this test, `DataSender` is instantiated with `MockSocket`, allowing the `send`
    method to be mocked as desired. This demonstrates how templates and dependency
    injection enable the mocking of non-virtual methods, providing a flexible and
    powerful approach to unit testing in C++.
  prefs: []
  type: TYPE_NORMAL
- en: This technique, while powerful, requires careful design consideration to ensure
    that the code remains clean and maintainable. For complex scenarios or further
    exploration of mocking strategies, the official gMock documentation remains an
    invaluable resource, offering a wealth of information on advanced mocking techniques
    and best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking singletons
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Despite being considered an anti-pattern due to its potential to introduce a
    global state and tight coupling in software designs, the Singleton pattern is
    nevertheless prevalent in many code bases. Its convenience for ensuring a single
    instance of a class often leads to its use in scenarios such as database connections,
    where a single, shared resource is logically appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: The Singleton pattern’s characteristic of restricting class instantiation and
    providing a global access point presents a challenge for unit testing, particularly
    when the need arises to mock the singleton’s behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the example of a `Database` class implemented as a singleton:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In this scenario, the `DataHandler` class interacts with the `Database` singleton
    to perform operations, such as querying data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To facilitate testing of the `DataHandler` class without relying on the real
    `Database` instance, we can introduce a templated variation, `DataHandler1`, that
    allows injecting a mock database instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This approach leverages templates to decouple `DataHandler1` from the concrete
    `Database` singleton, enabling the substitution of a `MockDatabase` during tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'With `MockDatabase` in place, unit tests can now simulate database interactions
    without hitting the actual database, as demonstrated in the following test case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This test instantiates `DataHandler1` with `MockDatabase`, ensuring that the
    `doSomething` method interacts with the mock rather than the real database. The
    expected result is a predefined mock response, making the test predictable and
    isolated from external dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: This templated solution, a variation of the dependency injection technique discussed
    earlier, showcases the flexibility and power of templates in C++. It elegantly
    addresses the challenge of mocking singletons, thereby enhancing the testability
    of components that depend on singleton instances. For more complex scenarios or
    further exploration of mocking strategies, referring to the official gMock documentation
    is advisable, as it offers comprehensive insights into advanced mocking techniques
    and best practices.
  prefs: []
  type: TYPE_NORMAL
- en: The Nice, the Strict, and the Naggy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the world of unit testing with gMock, managing the behavior of mock objects
    and their interactions with the system under test is crucial. gMock introduces
    three modes to control this behavior: Naggy, Nice, and Strict. These modes determine
    how gMock handles uninteresting calls – those not matched by any `EXPECT_CALL`.'
  prefs: []
  type: TYPE_NORMAL
- en: Naggy mocks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, mock objects in gMock are “naggy.” This means that while they warn
    about uninteresting calls, these calls do not cause the test to fail. The warning
    serves as a reminder that there might be unexpected interactions with the mock,
    but it’s not critical enough to warrant a test failure. This behavior ensures
    that tests focus on the intended expectations without being too lenient or too
    strict about incidental interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following test scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this case, if there’s an uninteresting call to `recv`, gMock issues a warning
    but the test will pass, marking unanticipated interactions without failing the
    test.
  prefs: []
  type: TYPE_NORMAL
- en: Nice mocks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`NiceMock` objects go a step further by suppressing warnings for uninteresting
    calls. This mode is useful when the test’s focus is strictly on specific interactions,
    and other incidental calls to the mock should be ignored without cluttering the
    test output with warnings.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `NiceMock` in a test looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In this `Nice` mode, even if there are uninteresting calls to `recv`, gMock
    quietly ignores them, keeping the test output clean and focused on the defined
    expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Strict mocks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On the other end of the spectrum, `StrictMock` objects treat uninteresting calls
    as errors. This strictness ensures that every interaction with the mock is accounted
    for by an `EXPECT_CALL`. This mode is particularly useful in tests where precise
    control over mock interactions is necessary, and any deviation from the expected
    calls should lead to test failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'A test using `StrictMock` might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In `Strict` mode, any uninteresting call, such as to `recv`, results in a test
    failure, enforcing strict adherence to the defined expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Test output and recommended settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The behavior of these mocking modes is reflected in the test output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In `Naggy` mode, the test passes with a warning for uninteresting calls. `Nice`
    mode also passes but without any warnings. `Strict` mode, however, fails the test
    if there are uninteresting calls.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to start with `StrickMock` and then relax the mode as needed.
    This approach ensures that tests are initially strict about interactions with
    mock objects, providing a safety net for unexpected calls. As the test suite matures
    and the expected interactions become clearer, the mode can be relaxed to `Naggy`
    or `Nice` to reduce noise in the test output.
  prefs: []
  type: TYPE_NORMAL
- en: For further exploration of these modes and advanced mocking techniques, the
    official gMock documentation provides comprehensive insights and examples, guiding
    developers through effective mock object management in unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this section, we delved into the functionalities and practical applications
    of Google Test (GTest) and Google Mock (GMock), essential tools for enhancing
    the testing framework and development workflow of C++ projects. GTest offers a
    robust environment for creating, managing, and executing unit tests, featuring
    test fixtures for shared setup and teardown routines, parameterized tests for
    varied input testing, and type-parameterized tests for applying the same tests
    across different data types. Its comprehensive assertion library ensures thorough
    validation of code behavior, contributing to the stability and durability of the
    software.
  prefs: []
  type: TYPE_NORMAL
- en: Complementing GTest, GMock allows for the seamless creation and utilization
    of mock objects, enabling isolated component testing by mimicking the behavior
    of dependencies. This is invaluable in complex systems where direct testing with
    real dependencies is either impractical or counterproductive. With GMock, developers
    gain access to a suite of features including automatic mock generation, versatile
    expectation settings, and detailed behavior verification, enabling in-depth testing
    of component interactions.
  prefs: []
  type: TYPE_NORMAL
- en: By integrating GTest and GMock into the C++ development life cycle, developers
    can adopt a robust test-driven approach, ensuring code quality and facilitating
    continuous testing and integration practices, ultimately leading to more reliable
    and maintainable software projects.
  prefs: []
  type: TYPE_NORMAL
- en: Other notable C++ unit testing frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beyond Google Test and Google Mock, the C++ ecosystem is rich with unit testing
    frameworks, each offering unique features and philosophies. These frameworks cater
    to various testing needs and preferences, providing developers with multiple options
    for integrating unit testing into their projects.
  prefs: []
  type: TYPE_NORMAL
- en: Catch2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Catch2 stands out for its simplicity and ease of use, requiring minimal boilerplate
    code to get started. It adopts a header-only distribution, making it straightforward
    to integrate into projects. Catch2 supports a variety of testing paradigms, including
    BDD-style test cases, and offers expressive assertion macros that enhance test
    readability and intent. Its standout feature is the “Sections” mechanism, which
    provides a natural way to share setup and teardown code among tests in a flexible
    and hierarchical manner.
  prefs: []
  type: TYPE_NORMAL
- en: Boost.Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Part of the extensive Boost libraries, Boost.Test offers robust support for
    unit testing in C++. It provides a comprehensive assertion framework, test organization
    facilities, and integration with the Boost build system. Boost.Test can be used
    in a header-only mode or compiled mode, offering flexibility in its deployment.
    It’s known for its detailed test result reports and wide range of built-in tools
    for test case management, making it suitable for both small and large-scale projects.
  prefs: []
  type: TYPE_NORMAL
- en: Doctest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Doctest is designed with a focus on simplicity and speed, positioning itself
    as the lightest feature-rich C++ testing framework. It’s particularly appealing
    for TDD due to its fast compile times. Inspired by Catch2, Doctest offers a similar
    syntax but aims to be more lightweight and faster to compile, making it ideal
    for including tests in everyday development without impacting build times significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Google Test versus Catch2 versus Boost.Test versus Doctest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Simplicity**: Catch2 and Doctest excel in simplicity and ease of use, with
    Catch2 offering BDD-style syntax and Doctest being extremely lightweight'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration**: Google Test and Boost.Test will provide more extensive integration
    capabilities, particularly suited for larger projects with complex testing needs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: Doctest stands out for its compile-time and runtime performance,
    making it ideal for rapid development cycles'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: Boost.Test and Google Test come with a more comprehensive set
    of features out of the box, including advanced test case management and detailed
    reporting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the right framework often comes down to project-specific requirements,
    developer preferences, and the desired balance between simplicity, performance,
    and feature richness. Developers are encouraged to explore these frameworks further
    to determine which best fits their unit testing needs, contributing to more reliable,
    maintainable, and high-quality C++ software.
  prefs: []
  type: TYPE_NORMAL
- en: Good candidates for unit tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Identifying the optimal candidates for unit testing is pivotal in establishing
    a robust testing strategy. Unit tests excel when applied to parts of the code
    base that are well-suited to isolation and fine-grained verification. Here are
    some key examples and recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: Classes and functions with clear boundaries and well-defined responsibilities
    are prime candidates for unit testing. These components should ideally embody
    the Single Responsibility Principle, handling a specific aspect of the application’s
    functionality. Testing these isolated units allows for precise verification of
    their behavior, ensuring that they perform their intended tasks correctly under
    various conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Pure functions, which depend solely on their input parameters and produce no
    side effects, are excellent targets for unit tests. Their deterministic nature
    – where a given input always results in the same output – makes them straightforward
    to test and verify. Pure functions are often found in utility libraries, mathematical
    computations, and data transformation operations.
  prefs: []
  type: TYPE_NORMAL
- en: Components that interact with dependencies through well-defined interfaces are
    easier to test, especially when those dependencies can be easily mocked or stubbed.
    This facilitates testing the component in isolation, focusing on its logic rather
    than the implementation details of its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: The business logic layer, which encapsulates the core functionality and rules
    of the application, is typically well-suited for unit testing. This layer often
    involves calculations, data processing, and decision-making that can be tested
    in isolation from the user interface and external systems.
  prefs: []
  type: TYPE_NORMAL
- en: While many aspects of an application are suitable for unit testing, it’s prudent
    to recognize scenarios that pose challenges. Components that require complex interactions
    with external resources, such as databases, filesystems, and network services,
    might be difficult to effectively mock or might lead to flaky tests due to their
    reliance on external state or behavior. While mocking can simulate some of these
    interactions, the complexity and overhead might not always justify the effort
    in the context of unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: Although unit tests are invaluable for verifying individual components, they
    have their limitations, especially concerning integrations and end-to-end interactions.
    For code that is inherently difficult to isolate or requires complex external
    interactions, **end-to-end** (**E2E**) tests become crucial. E2E tests simulate
    real-world usage scenarios, covering the flow from the user interface through
    to the backend systems and external integrations. In the next section, we will
    delve into E2E testing, exploring its role in complementing unit tests and providing
    comprehensive coverage of the application’s functionality.
  prefs: []
  type: TYPE_NORMAL
- en: E2E testing in software development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: E2E testing is a comprehensive testing approach that evaluates the application’s
    functionality and performance from start to finish. Unlike unit testing, which
    isolates and tests individual components or units of code, E2E testing examines
    the application as an integrated whole, simulating real-world user scenarios.
    This method ensures that all the various components of the application, including
    its interfaces, databases, networks, and other services, work harmoniously to
    deliver the desired user experience.
  prefs: []
  type: TYPE_NORMAL
- en: E2E testing frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given that E2E testing often involves interacting with the application from
    the outside, it’s not confined to the language in which the application is written.
    For C++ applications, which might be part of a larger ecosystem or serve as backend
    systems, E2E testing can be conducted using a variety of frameworks across different
    languages. Some popular E2E testing frameworks include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selenium**: Predominantly used for web applications, Selenium can automate
    browsers to simulate user interactions with web interfaces, making it a versatile
    tool for E2E testing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cypress**: Another powerful tool for web applications, Cypress offers a more
    modern and developer-friendly approach to E2E testing with rich debugging capabilities
    and a robust API'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Postman**: For applications exposing RESTful APIs, Postman allows comprehensive
    API testing, ensuring that the application’s endpoints perform as expected under
    various conditions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to use E2E testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'E2E testing is particularly valuable in scenarios where the application’s components
    must interact in complex workflows, often involving multiple systems and external
    dependencies. It’s crucial for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Testing complex user workflows**: E2E testing shines in validating user journeys
    that span multiple application components, ensuring a seamless experience from
    the user’s perspective'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration scenarios**: When the application interacts with external systems
    or services, E2E testing verifies that these integrations work as intended, catching
    issues that might not be evident in isolation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Critical path testing**: For features and pathways that are critical to the
    application’s core functionality, E2E testing ensures reliability and performance
    under realistic usage conditions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Situations favoring E2E testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Complex interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In situations where the application’s components engage in intricate interactions,
    possibly spanning different technologies and platforms, unit tests might fall
    short. E2E testing is indispensable for ensuring that the collective behavior
    of these components aligns with the expected outcomes, especially in:'
  prefs: []
  type: TYPE_NORMAL
- en: The architecture outlined in the diagram represents a typical web application
    with several interconnected services, each serving a distinct role in the system.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – E2E testing](img/B19606_12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – E2E testing
  prefs: []
  type: TYPE_NORMAL
- en: At the frontend, there’s a **user UI**, which is the graphical interface where
    users interact with the application. It’s designed to send and receive data to
    and from the backend services through an **API gateway**. The API gateway acts
    as an intermediary that routes requests from the user UI to the appropriate backend
    services and aggregates responses to send back to the UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several backend services are illustrated:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Account management**: This service handles user accounts, including authentication,
    profile management, and other user-related data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Billing**: Responsible for managing billing information, subscriptions, and
    invoicing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Payments**: Processes financial transactions, such as credit card processing
    or interfacing with payment gateways'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Notifications**: Sends out alerts or messages to users, likely triggered
    by certain events in the account management or billing services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: External services, possibly third-party applications or data providers, can
    also interact with the API gateway, providing additional functionality or data
    that supports the main application.
  prefs: []
  type: TYPE_NORMAL
- en: For E2E testing of this system, tests would simulate user actions on the user
    UI, such as signing up for an account or making a payment. The tests would then
    verify that the UI correctly sends the appropriate requests through the API gateway
    to the backend services. Subsequently, the tests would confirm that the user UI
    responds correctly to the data received from the backend, ensuring that the entire
    workflow, from the user UI down to notifications, operates as expected. This comprehensive
    testing approach ensures that each component functions individually and in concert
    with the rest of the system, delivering a seamless experience for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, it is essential to consider E2E testing in scenarios where the
    application’s components engage in complex interactions, especially when these
    interactions span different technologies and platforms. E2E testing ensures that
    the collective behavior of these components aligns with the expected outcomes,
    providing a comprehensive assessment of the application’s functionality and performance.
    Here are some of the most common cases when E2E is beneficial:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multi-layered applications**: Applications with multiple layers or tiers,
    such as client-server architectures, benefit from E2E testing to ensure the layers
    communicate effectively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed systems**: For applications spread across different environments
    or services, E2E testing can validate the data flow and functionality across these
    distributed components'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-world environment testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the primary advantages of E2E testing is its ability to replicate the
    conditions close to the production environment. This includes testing the application
    on actual hardware, interacting with real databases, and navigating through the
    genuine network infrastructure. This level of testing is crucial for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance validation**: Ensuring that the application performs optimally
    under expected load conditions and user traffic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security assurance**: Verifying that the application’s security measures
    are effective in a realistic environment, protecting against potential vulnerabilities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E2E testing serves as the final checkpoint before software release, offering
    a comprehensive assessment of the application’s readiness for deployment. By simulating
    real-world scenarios, E2E testing ensures that the application not only meets
    its technical specifications but also delivers a reliable and user-friendly experience,
    making it an essential component of the software development life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic test coverage tracking tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the quest to ensure comprehensive testing of software projects, automatic
    test coverage tracking tools play a pivotal role. These tools provide invaluable
    insights into the extent to which the source code of an application is executed
    during testing, highlighting areas that are well-tested and those that may need
    additional attention.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic test coverage tracking tools with examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring comprehensive test coverage is a cornerstone of reliable software development.
    Tools such as `gcov` for the `llvm-cov` for LLVM projects automate the tracking
    of test coverage, providing crucial insights into how thoroughly the tests exercise
    the code.
  prefs: []
  type: TYPE_NORMAL
- en: Tool overview with examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two major tools used for automatic test coverage tracking in C++
    projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gcov` analyzes the execution paths taken in your code during test runs. For
    instance, after compiling a C++ `example.cpp` file with `g++ -fprofile-arcs -ftest-coverage
    example.cpp`, running the corresponding test suite generates coverage data. Running
    `gcov example.cpp` afterward produces a report detailing the number of times each
    line of code was executed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`llvm-cov` works with Clang to offer detailed coverage reports. Compiling with
    `clang++ -fprofile-instr-generate -fcoverage-mapping example.cpp` and then executing
    the test binary with `LLVM_PROFILE_FILE=”example.profraw” ./example` prepares
    the coverage data. `llvm-profdata merge -sparse example.profraw -o example.profdata`
    followed by `llvm-cov show ./example -instr-profile=example.profdata` generates
    a coverage report for `example.cpp`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration with C++ projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Integrating these tools into C++ projects involves compiling the source with
    coverage flags, executing the tests to generate coverage data, and then analyzing
    this data to produce reports.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a project with multiple files, you might compile with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: After running `./testExecutable` to execute your tests, use `gcov file1.cpp
    file2.cpp` to generate coverage reports for each source file.
  prefs: []
  type: TYPE_NORMAL
- en: With `llvm-cov`, the process is similar but tailored for Clang. After compilation
    and test execution, merging profile data with `llvm-profdata` and generating the
    report with `llvm-cov` provides a comprehensive view of test coverage.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting coverage reports
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The coverage reports generated by these tools offer several metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gcov` report might state `Lines executed:90.00% of 100`, meaning 90 out of
    100 lines were run during tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcov` report such as `Branches executed:85.00% of 40` shows that 85% of all
    branches were tested.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Functions executed:95.00% of 20` in a `gcov` report indicates that 95% of
    functions were invoked during testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, a simplified `gcov` report might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, an `llvm-cov` report provides detailed coverage metrics, along with
    the specific lines and branches covered, enhancing the ability to pinpoint areas
    needing additional tests.
  prefs: []
  type: TYPE_NORMAL
- en: These reports guide developers in improving test coverage by highlighting untested
    code paths and functions, but they should not be the sole metric for test quality.
    High coverage with poorly designed tests can give a false sense of security. Effective
    use of these tools involves not just aiming for high coverage percentages but
    also ensuring that tests are meaningful and reflective of real-world usage scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing hit maps for enhanced test coverage analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hit maps, produced by test coverage tracking tools such as `gcov` and `llvm-cov`,
    offer a granular view of how tests exercise the code, serving as a detailed guide
    for developers aiming to improve test coverage. These hit maps go beyond simple
    percentage metrics, showing precisely which lines of code were executed during
    tests and how many times, thus enabling a more informed approach to enhance test
    suites.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding hit maps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A hit map is essentially a detailed annotation of the source code, with each
    line accompanied by execution counts indicating how many times tests have run
    that particular line. This level of detail helps identify not only untested parts
    of the code but also areas that might be over-tested or need more varied testing
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: The `.gcov` files generated by `gcov` and the annotated source code produced
    by `llvm-cov` provide these hit maps, offering a clear picture of test coverage
    at the line level.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In this example, line 3 (`bool condition = checkCondition();`) was executed
    twice, while the `performAction();` line within the `if` statement was executed
    once, indicating that the condition was `true` in one of the test runs.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to `gcov`, after compiling with `clang++` using the `-fprofile-instr-generate
    -fcoverage-mapping` flags and executing the tests, `llvm-cov` can produce a hit
    map using the `llvm-cov show` command with the `-instr-profile` flag pointing
    to the generated profile data. For example, `llvm-cov show ./example -instr-profile=example.profdata
    example.cpp` outputs the annotated source code with execution counts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output would resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Here, the execution count is prefixed to each line, providing a clear picture
    of test coverage at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging hit maps for test improvement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By examining hit maps, developers can identify code sections that are not covered
    by any test case, indicated by execution counts of zero. These areas represent
    potential risks for undetected bugs and should be prioritized for additional testing.
    Conversely, lines with exceptionally high execution counts might indicate areas
    where tests are redundant or overly focused, suggesting an opportunity to diversify
    test scenarios or refocus testing efforts on less-covered parts of the code base.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating hit map analysis into regular development workflows encourages
    a proactive approach to maintaining and enhancing test coverage, ensuring that
    tests remain effective and aligned with the evolving code base. As with all testing
    strategies, the goal is not merely to achieve high coverage numbers but to ensure
    that the test suite comprehensively validates the software’s functionality and
    reliability in a variety of scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating hit maps into the development workflow has been made even more
    accessible with the advent of **integrated development environment** (**IDE**)
    plugins that integrate coverage visualization directly into the coding environment.
    A notable example is the “Code Coverage” plugin by Markis Taylor for **Visual
    Studio Code** (**VSCode**). This plugin overlays hit maps onto the source code
    within the VSCode editor, providing immediate, visual feedback on test coverage.
  prefs: []
  type: TYPE_NORMAL
- en: The “Code Coverage” plugin processes coverage reports generated by tools such
    as `gcov` or `llvm-cov` and visually annotates the source code in VSCode. Lines
    of code covered by tests are highlighted, typically in green, while uncovered
    lines are marked in red. This immediate visual representation allows developers
    to quickly identify untested code regions without leaving the editor or navigating
    through external coverage reports.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations for code coverage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Code coverage is a vital metric in the realm of software testing, providing
    insights into the extent to which the code base is exercised by the test suite.
    For C++ projects, leveraging tools such as `gcov` for GCC and `llvm-cov` for LLVM
    projects can offer detailed coverage analysis. These tools are adept at not only
    tracking coverage from unit tests but also from E2E tests, allowing for a comprehensive
    assessment of test coverage across different testing levels.
  prefs: []
  type: TYPE_NORMAL
- en: A robust testing strategy involves a combination of focused unit tests, which
    validate individual components in isolation, and broader E2E tests, which assess
    the system’s functionality as a whole. By employing `gcov` or `llvm-cov`, teams
    can aggregate coverage data from both testing types, providing a holistic view
    of the project’s test coverage. This combined approach helps identify areas of
    the code that are either under-tested or not tested at all, guiding efforts to
    enhance the test suite’s effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to keep a vigilant eye on code coverage metrics and strive
    to prevent any decrease in coverage percentages. A decline in coverage might indicate
    new code being added without adequate testing, potentially introducing undetected
    bugs into the system. To mitigate this risk, teams should integrate coverage checks
    into their **continuous integration** (**CI**) pipelines, ensuring that any changes
    that reduce coverage are promptly identified and addressed.
  prefs: []
  type: TYPE_NORMAL
- en: Periodically, it’s beneficial to allocate time specifically for increasing test
    coverage, especially in areas identified as critical or risky. This might involve
    writing additional tests for complex logic, edge cases, or error-handling paths
    that were previously overlooked. Investing in coverage improvement initiatives
    not only enhances the software’s reliability but also contributes to a more maintainable
    and robust code base in the long term.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided a thorough overview of testing in C++, covering essential
    topics from unit testing basics to advanced E2E testing. You learned about unit
    testing’s role in ensuring individual components work correctly and how tools
    such as Google Test and Google Mock help write and manage these tests effectively.
    The chapter also touched on mocking techniques for simulating complex behaviors
    in tests.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the importance of tracking test coverage using tools such as `gcov`
    and `llvm-cov` was discussed, emphasizing the need to maintain and improve coverage
    over time. E2E testing was highlighted as crucial for checking the entire application’s
    functionality, complementing the more focused unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: By exploring different C++ testing frameworks, the chapter offered insights
    into the various tools available for developers, helping them choose the right
    ones for their projects. In essence, this chapter equipped you with the knowledge
    to implement comprehensive and effective testing strategies in your C++ development
    endeavors, contributing to the creation of reliable and robust software.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore modern approaches to third-party management
    in C++, including Docker-based solutions and available package managers.
  prefs: []
  type: TYPE_NORMAL
