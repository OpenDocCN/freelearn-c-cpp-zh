["```cpp\n    VkPhysicalDeviceProperties::limits::framebufferColorSampleCounts\n    VkPhysicalDeviceProperties::limits::framebufferDepthSampleCounts\n    ```", "```cpp\n    VkImageCreateInfo newTexture = {\n      ...\n      .samples = VK_SAMPLE_COUNT_8_BIT,\n    };\n    ```", "```cpp\n    VkAttachmentDescription attachment = {\n      ...\n      .samples = VK_SAMPLE_COUNT_8_BIT,\n    };\n    ```", "```cpp\n    VkAttachmentDescription resolveAttachment = {\n      ...\n      .samples = VK_SAMPLE_COUNT_1_BIT,\n    }\n    ```", "```cpp\n    VkAttachmentReference resolveAttachmentRef{\n      .attachment = <index of resolve texture in the attachmentDescriptor vector>,\n      .layout =\n          VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,\n    }\n    ```", "```cpp\n    #version 460\n    layout(push_constant) uniform Viewport {\n      uvec2 size;\n    }\n    ViewportSize;\n    layout(set = 0, binding = 0) uniform sampler2D\n        inputTexture;\n    layout(location = 0) out vec4 outColor;\n    ```", "```cpp\n    float rgb2luma(vec3 rgb) {\n      return dot(rgb, vec3(0.299, 0.587, 0.114));\n    }\n    ```", "```cpp\n    const float EDGE_THRESHOLD_MIN = (1.0 / 16.0);\n    const float EDGE_THRESHOLD_MAX = (1.0 / 8.0);\n    const float PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING =\n        (3.0 / 4.0);\n    const float MIN_PIXEL_ALIASING_REQUIRED =\n        (1.0 / 8.0);\n    const float NUM_LOOP_FOR_EDGE_DETECTION = 1;\n    ```", "```cpp\n    const int Center      = 0;\n    const int Top         = 1;\n    const int Bottom      = 2;\n    const int Left        = 3;\n    const int Right       = 4;\n    const int TopRight    = 5;\n    const int BottomRight = 6;\n    const int TopLeft     = 7;\n    const int BottomLeft  = 8;\n    vec2 offsets[] = {\n        vec2( 0, 0), vec2( 0, -1), vec2( 0,  1),\n        vec2(-1, 0), vec2( 1,  0), vec2( 1, -1),\n        vec2( 1, 1), vec2(-1, -1), vec2(-1,  1)};\n    ```", "```cpp\n    vec4 applyFXAA(vec2 screenCoord,\n                   sampler2D inputTexture,\n                   uvec2 viewportSize) {\n    ```", "```cpp\n      const vec2 viewportSizeInverse = vec2(\n          1.0 / viewportSize.x, 1.0 / viewportSize.y);\n      const vec2 texCoord =\n          screenCoord * viewportSizeInverse;\n      float minLuma = 100000000;\n      float maxLuma = 0;\n      float lumas[9];\n      vec3 rgb[9];\n      vec3 rgbSum = vec3(0, 0, 0);\n      for (int i = 0; i < 9; ++i) {\n        rgb[i] =\n            texture(inputTexture,\n                    texCoord +\n                        offsets[i] *\n                            viewportSizeInverse)\n                .rgb;\n        rgbSum += rgb[i];\n        lumas[i] = rgb2luma(rgb[i]);\n        if (i < 5) {\n          minLuma = min(lumas[i], minLuma);\n          maxLuma = max(lumas[i], maxLuma);\n        }\n      }\n      const float rangeLuma = maxLuma - minLuma;\n      if (rangeLuma <\n          max(EDGE_THRESHOLD_MIN,\n              EDGE_THRESHOLD_MAX * maxLuma)) {\n        return vec4(rgb[Center], 1.0);\n      }\n    ```", "```cpp\n      const float lumaTopBottom =\n          lumas[Top] + lumas[Bottom];\n      const float lumaLeftRight =\n          lumas[Left] + lumas[Right];\n      const float lumaTopCorners =\n          lumas[TopLeft] + lumas[TopRight];\n      const float lumaBottomCorners =\n          lumas[BottomLeft] + lumas[BottomRight];\n      const float lumaLeftCorners =\n          lumas[TopLeft] + lumas[BottomLeft];\n      const float lumaRightCorners =\n          lumas[TopRight] + lumas[BottomRight];\n      const float lumaTBLR =\n          lumaTopBottom + lumaLeftRight;\n      const float averageLumaTBLR = (lumaTBLR) / 4.0;\n      const float lumaSubRange =\n          abs(averageLumaTBLR - lumas[Center]);\n      float pixelblendAmount =\n          max(0.0, (lumaSubRange / rangeLuma) -\n                       MIN_PIXEL_ALIASING_REQUIRED);\n      pixelblendAmount = min(\n          PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING,\n          pixelblendAmount *\n              (1.0 /\n               (1.0 - MIN_PIXEL_ALIASING_REQUIRED)));\n    ```", "```cpp\n      const vec3 averageRGBNeighbor =\n          rgbSum * (1.0 / 9.0);\n      const float verticalEdgeRow1 =\n          abs(-2.0 * lumas[Top] + lumaTopCorners);\n      const float verticalEdgeRow2 =\n          abs(-2.0 * lumas[Center] + lumaLeftRight);\n      const float verticalEdgeRow3 = abs(\n          -2.0 * lumas[Bottom] + lumaBottomCorners);\n      const float verticalEdge =\n          (verticalEdgeRow1 + verticalEdgeRow2 * 2.0 +\n           verticalEdgeRow3) /\n          12.0;\n      const float horizontalEdgeCol1 =\n          abs(-2.0 * lumas[Left] + lumaLeftCorners);\n      const float horizontalEdgeCol2 =\n          abs(-2.0 * lumas[Center] + lumaTopBottom);\n      const float horizontalEdgeCol3 =\n          abs(-2.0 * lumas[Right] + lumaRightCorners);\n      const float horizontalEdge =\n          (horizontalEdgeCol1 +\n           horizontalEdgeCol2 * 2.0 +\n           horizontalEdgeCol3) /\n          12.0;\n      const bool isHorizontal =\n          horizontalEdge >= verticalEdge;\n      const float luma1 =\n          isHorizontal ? lumas[Top] : lumas[Left];\n      const float luma2 =\n          isHorizontal ? lumas[Bottom] : lumas[Right];\n      const bool is1Steepest =\n          abs(lumas[Center] - luma1) >=\n          abs(lumas[Center] - luma2);\n      float stepLength =\n          isHorizontal ? -screenCoordToTextureCoord.y\n                       : -screenCoordToTextureCoord.x;\n      float lumaHighContrastPixel;\n      if (is1Steepest) {\n        lumaHighContrastPixel = luma1;\n      } else {\n        lumaHighContrastPixel = luma2;\n        // Also reverse the direction:\n        stepLength = -stepLength;\n      }\n      vec2 outPosToFetchTexelForEdgeAntiAliasing;\n      vec3 rgbEdgeAntiAliasingPixel = rgb[Center];\n    ```", "```cpp\n      const float res = findEndPointPosition(\n          inputTexture, texCoord,\n          lumas[Center], lumaHighContrastPixel,\n          stepLength, screenCoordToTextureCoord,\n          isHorizontal,\n          outPosToFetchTexelForEdgeAntiAliasing);\n    ```", "```cpp\n      if (res == 1.0) {\n        rgbEdgeAntiAliasingPixel =\n            texture(\n                inputTexture,\n                outPosToFetchTexelForEdgeAntiAliasing)\n                .rgb;\n      }\n      return vec4(mix(rgbEdgeAntiAliasingPixel,\n                      averageRGBNeighbor,\n                      pixelblendAmount),\n                  1.0);\n    }\n    ```", "```cpp\n    float findEndPointPosition(\n        sampler2D inputTexture,\n        vec2 textureCoordMiddle, float lumaMiddle,\n        float lumaHighContrastPixel, float stepLength,\n        vec2 screenCoordToTextureCoord,\n        bool isHorizontal,\n        out vec2\n            outPosToFetchTexelForEdgeAntiAliasing) {\n    ```", "```cpp\n      vec2 textureCoordOfHighContrastPixel =\n          textureCoordMiddle;\n      // Direction of the edge\n      vec2 edgeDir;\n      if (isHorizontal) {\n        textureCoordOfHighContrastPixel.y =\n            textureCoordMiddle.y + stepLength;\n        textureCoordOfHighContrastPixel.x =\n            textureCoordMiddle.x;\n        edgeDir.x = screenCoordToTextureCoord.x;\n        edgeDir.y = 0.0;\n      } else {\n        textureCoordOfHighContrastPixel.x =\n            textureCoordMiddle.x + stepLength;\n        textureCoordOfHighContrastPixel.y =\n            textureCoordMiddle.y;\n        edgeDir.y = screenCoordToTextureCoord.y;\n        edgeDir.x = 0.0;\n      }\n    ```", "```cpp\n      // Prepare for the search loop:\n      float lumaHighContrastPixelNegDir;\n      float lumaHighContrastPixelPosDir;\n      float lumaMiddlePixelNegDir;\n      float lumaMiddlePixelPosDir;\n      bool doneGoingThroughNegDir = false;\n      bool doneGoingThroughPosDir = false;\n      vec2 posHighContrastNegDir =\n          textureCoordOfHighContrastPixel - edgeDir;\n      vec2 posHighContrastPosDir =\n          textureCoordOfHighContrastPixel + edgeDir;\n      vec2 posMiddleNegDir =\n          textureCoordMiddle - edgeDir;\n      vec2 posMiddlePosDir =\n          textureCoordMiddle + edgeDir;\n    ```", "```cpp\n        for (int i = 0; i < NUM_LOOP_FOR_EDGE_DETECTION;\n           ++i) {\n        // Negative direction processing\n        if (!doneGoingThroughNegDir) {\n          processDirection(doneGoingThroughNegDir,\n                           posHighContrastNegDir,\n                           posMiddleNegDir, -edgeDir,\n                           lumaHighContrastPixel,\n                           lumaMiddle);\n        }\n        // Positive direction processing\n        if (!doneGoingThroughPosDir) {\n          processDirection(doneGoingThroughPosDir,\n                           posHighContrastPosDir,\n                           posMiddlePosDir, edgeDir,\n                           lumaHighContrastPixel,\n                           lumaMiddle);\n        }\n        // If both directions are done, exit the loop\n        if (doneGoingThroughNegDir &&\n            doneGoingThroughPosDir) {\n          break;\n        }\n      }\n    ```", "```cpp\n      float dstNeg;\n      float dstPos;\n      if (isHorizontal) {\n        dstNeg =\n            textureCoordMiddle.x - posMiddleNegDir.x;\n        dstPos =\n            posMiddlePosDir.x - textureCoordMiddle.x;\n      } else {\n        dstNeg =\n            textureCoordMiddle.y - posMiddleNegDir.y;\n        dstPos =\n            posMiddlePosDir.y - textureCoordMiddle.y;\n      }\n    ```", "```cpp\n      bool isMiddlePixelCloserToNeg = dstNeg < dstPos;\n      float dst = min(dstNeg, dstPos);\n      float lumaEndPointOfPixelCloserToMiddle =\n          isMiddlePixelCloserToNeg\n              ? lumaMiddlePixelNegDir\n              : lumaMiddlePixelPosDir;\n    ```", "```cpp\n      bool edgeAARequired =\n          abs(lumaEndPointOfPixelCloserToMiddle -\n              lumaHighContrastPixel) <\n          abs(lumaEndPointOfPixelCloserToMiddle -\n              lumaMiddle);\n    ```", "```cpp\n      float negInverseEndPointsLength =\n          -1.0 / (dstNeg + dstPos);\n      float pixelOffset =\n          dst * negInverseEndPointsLength + 0.5;\n      outPosToFetchTexelForEdgeAntiAliasing =\n          textureCoordMiddle;\n      if (isHorizontal) {\n        outPosToFetchTexelForEdgeAntiAliasing.y +=\n            pixelOffset * stepLength;\n      } else {\n        outPosToFetchTexelForEdgeAntiAliasing.x +=\n            pixelOffset * stepLength;\n      }\n    ```", "```cpp\n      return edgeAARequired ? 1.0 : 0.0;\n    }\n    ```", "```cpp\n    void processDirection(inout bool doneGoingThroughDir,\n                          inout vec2 posHighContrast,\n                          inout vec2 posMiddle,\n                          float edgeIncrement,\n                          float lumaHighContrastPixel,\n                          float lumaMiddle) {\n      float lumaHighContrastPixelDir = rgb2luma(\n          texture(inputTexture, posHighContrast).rgb);\n      float lumaMiddlePixelDir = rgb2luma(\n          texture(inputTexture, posMiddle).rgb);\n      doneGoingThroughDir =\n          abs(lumaHighContrastPixelDir -\n              lumaHighContrastPixel) >\n              abs(lumaHighContrastPixelDir -\n                  lumaMiddle) ||\n          abs(lumaMiddlePixelDir - lumaMiddle) >\n              abs(lumaMiddlePixelDir -\n                  lumaHighContrastPixel);\n      // Update position for next iteration if not\n      // done\n      if (!doneGoingThroughDir) {\n        posHighContrast += edgeIncrement;\n        posMiddle += edgeIncrement;\n      }\n    }\n    ```", "```cpp\n    void main() {\n      outColor =\n          applyFXAA(gl_FragCoord.xy, inputTexture,\n                    ViewportSize.size);\n    }\n    ```", "```cpp\n    void TAAComputePass::doAA(VkCommandBuffer cmd,\n                              int frameIndex,\n                              int isCamMoving) {\n      pipeline_->bind(cmd);\n      outColorTexture_->transitionImageLayout(\n          cmd, VK_IMAGE_LAYOUT_GENERAL);\n      historyTexture_->transitionImageLayout(\n          cmd, VK_IMAGE_LAYOUT_GENERAL);\n      vkCmdDispatch(…);\n      VkImageMemoryBarrier barriers[2] = {\n          {\n            …\n      };\n      vkCmdPipelineBarrier(\n          cmd, VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,\n          VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT, 0, 0,\n          nullptr, 0, nullptr, 2, barriers);\n      colorTexture_->transitionImageLayout(\n          cmd, VK_IMAGE_LAYOUT_GENERAL);\n      sharpenPipeline_->bind(cmd);\n      vkCmdDispatch(…);\n      colorTexture_->transitionImageLayout(\n          cmd,\n          VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);\n      outColorTexture_->transitionImageLayout(\n          cmd,\n          VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);\n    }\n    ```", "```cpp\n    void main() {\n      vec2 velocity;\n      const float closestDepth =\n          closestVelocityAndDepth(velocity);\n    ```", "```cpp\n      vec2 reprojectedUV = uv - velocity;\n    ```", "```cpp\n      float velocityLerp =\n          (taaConstData.isFirstFrame != 0)\n              ? texture(inHistoryBuffer,\n                        reprojectedUV)\n                    .w\n              : 0.0f;\n    ```", "```cpp\n      vec3 colorIn = getColorData(\n          ivec2(gl_GlobalInvocationID.xy));\n      vec3 colorHistory = catmullRomTextureFiltering(\n          reprojectedUV, vec2(workSize));\n    ```", "```cpp\n      const float boxSizeWhenMoving = 2000.0f;\n      const float boxSizeWhenStationary = 100.0f;\n      float boxSize =\n          (taaConstData.isCameraMoving == 0)\n              ? boxSizeWhenStationary\n              : mix(boxSizeWhenStationary,\n                    boxSizeWhenMoving, velocityLerp);\n      boxSize = mix(\n          0.5f, boxSize,\n          noGeometry ? 0.0f\n                     : smoothstep(0.02f, 0.0f,\n                                  length(velocity)));\n    ```", "```cpp\n      vec3 clampHistory =\n          varianceClampColor(colorHistory, boxSize);\n    ```", "```cpp\n      float blendFactor = calculateBlendFactor(\n          closestDepth, velocity, noGeometry,\n          workSize, colorIn, clampHistory,\n          velocityLerp);\n    ```", "```cpp\n      vec3 colorResolve =\n          mix(clampHistory, colorIn, blendFactor);\n      imageStore(outColorImage,\n                 ivec2(gl_GlobalInvocationID.xy),\n                 vec4(colorResolve, velocityLerp));\n    }\n    ```", "```cpp\n    void main() {\n      vec4 incolor = imageLoad(inColorImage, ivec2(gl_GlobalInvocationID.xy));\n      imageStore(outHistory, ivec2(gl_GlobalInvocationID.xy), incolor);\n      vec3 color = sharpen();\n      imageStore(outColorImage, ivec2(gl_GlobalInvocationID.xy), vec4(color, 1.0f));\n    }\n    ```", "```cpp\n    void DLSS::requiredExtensions(std::vector<std::string>& instanceExtensions,\n                                  std::vector<std::string>& deviceExtensions) {\n      unsigned int instanceExtCount;\n      const char** instanceExt;\n      unsigned int deviceExtCount;\n      const char** deviceExt;\n      auto result = NVSDK_NGX_VULKAN_RequiredExtensions(\n          &instanceExtCount, &instanceExt, &deviceExtCount, &deviceExt);\n      for (int i = 0; i < instanceExtCount; ++i) {\n        if (std::find(instanceExtensions.begin(), instanceExtensions.end(),\n                      instanceExt[i]) == instanceExtensions.end()) {\n          instanceExtensions.push_back(instanceExt[i]);\n        }\n      }\n      for (int i = 0; i < deviceExtCount; ++i) {\n        if (std::find(deviceExtensions.begin(), deviceExtensions.end(),\n                      deviceExt[i]) == deviceExtensions.end()) {\n          deviceExtensions.push_back(deviceExt[i]);\n          if (deviceExtensions.back() ==\n              \"VK_EXT_buffer_device_address\") {  // we are using 1.3, this extension\n                                                 // has been promoted\n            deviceExtensions.pop_back();\n          }\n        }\n      }\n    }\n    ```", "```cpp\n    void DLSS::init(int currentWidth, int currentHeight, float upScaleFactor, VulkanCore::CommandQueueManager& commandQueueManager) {\n      NVSDK_NGX_Result result = NGX_DLSS_GET_OPTIMAL_SETTINGS(paramsDLSS_, currentWidth, currentHeight, dlssQuality, &optimalRenderWidth, &optimalRenderHeight, &minRenderWidth, &minRenderHeight, &maxRenderWidth, &maxRenderHeight, &recommendedSharpness);\n      int dlssCreateFeatureFlags = NVSDK_NGX_DLSS_Feature_Flags_None;\n      dlssCreateFeatureFlags |= NVSDK_NGX_DLSS_Feature_Flags_MVLowRes;\n      dlssCreateFeatureFlags |= NVSDK_NGX_DLSS_Feature_Flags_DoSharpening;\n      NVSDK_NGX_DLSS_Create_Params dlssCreateParams{\n          .Feature =\n              {\n                  .InWidth = unsigned int(currentWidth),\n                  .InHeight = unsigned int(currentHeight),\n                  .InTargetWidth = unsigned int(currentWidth * upScaleFactor),\n                  .InTargetHeight = unsigned int(currentHeight * upScaleFactor),\n                  .InPerfQualityValue = NVSDK_NGX_PerfQuality_Value_MaxQuality,\n              },\n          .InFeatureCreateFlags = dlssCreateFeatureFlags,\n      };\n      auto commmandBuffer = commandQueueManager.getCmdBufferToBegin();\n      constexpr unsigned int creationNodeMask = 1;\n      constexpr unsigned int visibilityNodeMask = 1;\n      NVSDK_NGX_Result createDlssResult = NGX_VULKAN_CREATE_DLSS_EXT(commmandBuffer, creationNodeMask, visibilityNodeMask, &dlssFeatureHandle_, paramsDLSS_, &dlssCreateParams);\n      ASSERT(createDlssResult == NVSDK_NGX_Result_Success, \"Failed to create NVSDK NGX DLSS feature\");\n      commandQueueManager.endCmdBuffer(commmandBuffer);\n      VkSubmitInfo submitInfo{\n          .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,\n          .commandBufferCount = 1,\n          .pCommandBuffers = &commmandBuffer,\n      };\n      commandQueueManager.submit(&submitInfo);\n      commandQueueManager.waitUntilSubmitIsComplete();\n    }\n    ```", "```cpp\n    void DLSS::render(VkCommandBuffer commandBuffer, VulkanCore::Texture& inColorTexture, VulkanCore::Texture& inDepthTexture, VulkanCore::Texture& inMotionVectorTexture, VulkanCore::Texture& outColorTexture, glm::vec2 cameraJitter) {\n      NVSDK_NGX_Resource_VK inColorResource = NVSDK_NGX_Create_ImageView_Resource_VK(\n              inColorTexture.vkImageView(), inColorTexture.vkImage(),\n              {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}, VK_FORMAT_UNDEFINED,\n              inColorTexture.vkExtents().width, inColorTexture.vkExtents().height,\n              true);\n      NVSDK_NGX_Resource_VK outColorResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);\n      NVSDK_NGX_Resource_VK depthResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);\n      NVSDK_NGX_Resource_VK motionVectorResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);\n      outColorTexture.transitionImageLayout(commandBuffer, VK_IMAGE_LAYOUT_GENERAL);\n      NVSDK_NGX_VK_DLSS_Eval_Params evalParams = {\n          .Feature =\n              {\n                  .pInColor = &inColorResource,\n                  .pInOutput = &outColorResource,\n                  .InSharpness = 1.0,\n              },\n          .pInDepth = &depthResource,\n          .pInMotionVectors = &motionVectorResource,\n          .InJitterOffsetX = cameraJitter.x,\n          .InJitterOffsetY = cameraJitter.y,\n          .InRenderSubrectDimensions =\n              {\n                  .Width =\n                      static_cast<unsigned int>(inColorTexture.vkExtents().width),\n                  .Height =\n                      static_cast<unsigned int>(inColorTexture.vkExtents().height),\n              },\n          .InReset = 0,\n          .InMVScaleX = -1.0f * inColorResource.Resource.ImageViewInfo.Width,\n          .InMVScaleY = -1.0f * inColorResource.Resource.ImageViewInfo.Height,\n          .pInExposureTexture = nullptr,\n      };\n      NVSDK_NGX_Result result = NGX_VULKAN_EVALUATE_DLSS_EXT(commandBuffer, dlssFeatureHandle_, paramsDLSS_, &evalParams);\n      ASSERT(result == NVSDK_NGX_Result_Success, \"Failed to evaluate DLSS feature\");\n      if (result != NVSDK_NGX_Result_Success) {\n        auto store = GetNGXResultAsString(result);\n      }\n    }\n    ```"]