<html><head></head><body>
<div id="_idContainer037">
<h1 class="chapter-number" id="_idParaDest-319"><a id="_idTextAnchor832"/><span class="koboSpan" id="kobo.1.1">18</span></h1>
<h1 id="_idParaDest-320"><a id="_idTextAnchor833"/><span class="koboSpan" id="kobo.2.1">Patterns for Concurrency</span></h1>
<p><span class="koboSpan" id="kobo.3.1">The last chapter is dedicated to a set of patterns for use in concurrent programs. </span><span class="koboSpan" id="kobo.3.2">Concurrency and C++ have a somewhat complex relationship. </span><span class="koboSpan" id="kobo.3.3">On the one hand, C++ is a performance-oriented language, and concurrency is almost always employed to improve performance, so the two are a natural fit. </span><span class="koboSpan" id="kobo.3.4">Certainly, C++ was used to develop concurrent programs since the earliest days of the language. </span><span class="koboSpan" id="kobo.3.5">On the other hand, for a language so often used for writing concurrent programs, C++ has a surprising dearth of constructs and features that directly address the needs of concurrent programming. </span><span class="koboSpan" id="kobo.3.6">These needs are mostly addressed by a wide range of community-developed libraries and, often, application-specific solutions. </span><span class="koboSpan" id="kobo.3.7">In this chapter, we will review common problems encountered in the development of concurrent programs and solutions that emerged from years of experience; together, these are the two sides of a </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">design pattern.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">The following topics are covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">this chapter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">What is the state of concurrency support </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">in C++?</span></span></li>
<li><a id="_idTextAnchor834"/><span class="koboSpan" id="kobo.9.1">What are the main challenges </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">of concurrency?</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">The challenges of data synchronization and the C++ tools to </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">meet them</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">What is the design </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">for concurrency?</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">What are common patterns for managing concurrent workloads </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">in C++?</span></span></li>
</ul>
<h1 id="_idParaDest-321"><a id="_idTextAnchor835"/><span class="koboSpan" id="kobo.17.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.18.1">The example code for this chapter can be found on GitHub at the following link: </span><a href="https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter18"><span class="koboSpan" id="kobo.19.1">https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter18</span></a><span class="koboSpan" id="kobo.20.1">.</span><a id="_idTextAnchor836"/><span class="koboSpan" id="kobo.21.1"> Also, basic knowledge of concurrency in general as well as concurrency support in C++ are </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">a pre-requisite.</span></span></p>
<h1 id="_idParaDest-322"><a id="_idTextAnchor837"/><span class="koboSpan" id="kobo.23.1">C++ and concurrency</span></h1>
<p><span class="koboSpan" id="kobo.24.1">The concept of</span><a id="_idIndexMarker1127"/><span class="koboSpan" id="kobo.25.1"> concurrency</span><a id="_idIndexMarker1128"/><span class="koboSpan" id="kobo.26.1"> was introduced into the language in C++11, but concurrent programs were written in C++ long before that. </span><span class="koboSpan" id="kobo.26.2">This chapter is not meant to be an introduction to concurrency or even an introduction to concurrency in C++. </span><span class="koboSpan" id="kobo.26.3">This subject is well-covered in the literature (at the time of publication of this book, one of the works that are both general and up-to-date is the book </span><em class="italic"><span class="koboSpan" id="kobo.27.1">C++ Concurrency in Action</span></em><span class="koboSpan" id="kobo.28.1"> by Anthony Williams). </span><span class="koboSpan" id="kobo.28.2">Also, while concurrency is almost always used to improve performance, we will not directly address performance and optimization issues here; for that, you can refer to my book </span><em class="italic"><span class="koboSpan" id="kobo.29.1">The Art of Writing Efficient Programs</span></em><span class="koboSpan" id="kobo.30.1">. </span><span class="koboSpan" id="kobo.30.2">We are going to focus on the problems that arise in the design of </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">concurrent software.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">There are, broadly speaking, three types of challenges we encounter when developing concurrent programs. </span><span class="koboSpan" id="kobo.32.2">First, how to make sure the program is correct even when multiple threads operate on the same data concurrency? </span><span class="koboSpan" id="kobo.32.3">Second, how to execute the work of a program on multiple threads to improve the overall performance? </span><span class="koboSpan" id="kobo.32.4">Finally, how to design software in a way that allows us to reason about it, understand its functions, and maintain it, all with the added complexity </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">of concurrency.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">The first set of challenges broadly relates to data sharing and synchronization. </span><span class="koboSpan" id="kobo.34.2">We will examine the related patterns first: the program must be first and foremost correct, and great performance in a program that crashes or produces results that cannot be trusted </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">is useless.</span></span></p>
<h1 id="_idParaDest-323"><a id="_idTextAnchor838"/><span class="koboSpan" id="kobo.36.1">Synchronization patterns</span></h1>
<p><span class="koboSpan" id="kobo.37.1">Synchronization </span><a id="_idIndexMarker1129"/><span class="koboSpan" id="kobo.38.1">patterns have one overarching purpose: to ensure correct operations on data shared by multiple threads. </span><span class="koboSpan" id="kobo.38.2">These patterns are critically important for the absolute majority of concurrent programs. </span><span class="koboSpan" id="kobo.38.3">The only programs that do not have any need for synchronization are the ones that execute several entirely independent tasks that do not involve any common data (except for, possibly, reading shared and immutable inputs) and produce separate results. </span><span class="koboSpan" id="kobo.38.4">For every other program, there is a need to manage some shared state, which exposes us to the danger of the dreaded data races. </span><span class="koboSpan" id="kobo.38.5">Formally, the C++ standard says that concurrent access to the same object (same memory location) without the appropriate synchronization that guarantees exclusive access for each thread results in undefined behavior. </span><span class="koboSpan" id="kobo.38.6">To be precise, the behavior is undefined if at least one thread can modify the shared data: if the data is never changed by any thread, then there is no possibility of a data race. </span><span class="koboSpan" id="kobo.38.7">There are design patterns that take advantage of that loophole, but let us start with the most widely known synchronization pattern. </span><span class="koboSpan" id="kobo.38.8">What comes to mind first when you hear about</span><a id="_idIndexMarker1130"/><span class="koboSpan" id="kobo.39.1"> avoiding </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">data races?</span></span></p>
<h2 id="_idParaDest-324"><a id="_idTextAnchor839"/><span class="koboSpan" id="kobo.41.1">Mutex and locking patterns</span></h2>
<p><span class="koboSpan" id="kobo.42.1">If there is one </span><a id="_idIndexMarker1131"/><span class="koboSpan" id="kobo.43.1">tool for</span><a id="_idIndexMarker1132"/><span class="koboSpan" id="kobo.44.1"> writing concurrent programs, it is a mutex. </span><span class="koboSpan" id="kobo.44.2">A mutex is used to guarantee exclusive access to the shared data accessed by </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">multiple threads:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.46.1">
std::mutex m;
MyData data;
...
</span><span class="koboSpan" id="kobo.46.2">// On several threads:
m.lock();
transmogrify(data);
m.unlock();</span></pre>
<p><span class="koboSpan" id="kobo.47.1">The data-modifying operation </span><strong class="source-inline"><span class="koboSpan" id="kobo.48.1">transmogrify()</span></strong><span class="koboSpan" id="kobo.49.1"> must be guaranteed exclusive access to the shared data: only one thread may do this operation at any given time. </span><span class="koboSpan" id="kobo.49.2">The programmer </span><a id="_idIndexMarker1133"/><span class="koboSpan" id="kobo.50.1">uses a </span><strong class="bold"><span class="koboSpan" id="kobo.51.1">mutex</span></strong><span class="koboSpan" id="kobo.52.1"> (short for </span><strong class="bold"><span class="koboSpan" id="kobo.53.1">mutual exclusion</span></strong><span class="koboSpan" id="kobo.54.1">) to ensure this: only one thread at a time can lock the mutex and enter the critical section (the code between </span><strong class="source-inline"><span class="koboSpan" id="kobo.55.1">lock()</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.56.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.57.1">unlock()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.59.1">The use of a mutex is sufficient to ensure correct access to the shared data, but this is hardly a good design. </span><span class="koboSpan" id="kobo.59.2">The first issue is that it is error-prone: if </span><strong class="source-inline"><span class="koboSpan" id="kobo.60.1">transmogrify()</span></strong><span class="koboSpan" id="kobo.61.1"> throws an exception, or if the programmer adds a check for the return value and exits the critical section early, the final </span><strong class="source-inline"><span class="koboSpan" id="kobo.62.1">unlock()</span></strong><span class="koboSpan" id="kobo.63.1"> is never executed and the mutex remains locked forever, thus blocking every other thread from ever accessing </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.65.1">This challenge is easily addressed by a particular application of the very general C++ pattern we have already seen in </span><a href="B19262_05.xhtml#_idTextAnchor199"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.66.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.67.1">, </span><em class="italic"><span class="koboSpan" id="kobo.68.1">A Comprehensive Look at RAII</span></em><span class="koboSpan" id="kobo.69.1">. </span><span class="koboSpan" id="kobo.69.2">All we need is an object to lock and unlock the mutex, and the C++ standard library already provides </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">one, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.71.1">std::lock_guard</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.73.1">
// Example 01
std::mutex m;
int i = 0;
void add() {
  std::lock_guard&lt;std::mutex&gt; l(m);
  ++i;
}
...
</span><span class="koboSpan" id="kobo.73.2">std::thread t1(add);
std::thread t2(add);
t1.join();
t2.join();
std::cout &lt;&lt; i &lt;&lt; std::endl;</span></pre>
<p><span class="koboSpan" id="kobo.74.1">The function </span><strong class="source-inline"><span class="koboSpan" id="kobo.75.1">add()</span></strong><span class="koboSpan" id="kobo.76.1"> modifies the shared variable </span><strong class="source-inline"><span class="koboSpan" id="kobo.77.1">i</span></strong><span class="koboSpan" id="kobo.78.1"> and, therefore, needs exclusive access; this is provided by the use of the mutex </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">m</span></strong><span class="koboSpan" id="kobo.80.1">. </span><span class="koboSpan" id="kobo.80.2">Note that if you run this example without the mutex, chances </span><a id="_idIndexMarker1134"/><span class="koboSpan" id="kobo.81.1">are you will get the correct result</span><a id="_idIndexMarker1135"/><span class="koboSpan" id="kobo.82.1"> nonetheless because one of the threads will execute before the other. </span><span class="koboSpan" id="kobo.82.2">Sometimes the program will fail, and more often it won’t. </span><span class="koboSpan" id="kobo.82.3">This doesn’t make it correct, it just makes it hard to debug. </span><span class="koboSpan" id="kobo.82.4">You can see the race condition with the help </span><a id="_idIndexMarker1136"/><span class="koboSpan" id="kobo.83.1">of the </span><strong class="bold"><span class="koboSpan" id="kobo.84.1">thread sanitizer</span></strong><span class="koboSpan" id="kobo.85.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.86.1">TSAN</span></strong><span class="koboSpan" id="kobo.87.1">). </span><span class="koboSpan" id="kobo.87.2">If you are using GCC or Clang, add </span><strong class="source-inline"><span class="koboSpan" id="kobo.88.1">--sanitize=address</span></strong><span class="koboSpan" id="kobo.89.1"> to enable it. </span><span class="koboSpan" id="kobo.89.2">Remove the mutex from </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1">add()</span></strong><span class="koboSpan" id="kobo.91.1"> (</span><em class="italic"><span class="koboSpan" id="kobo.92.1">Example 02</span></em><span class="koboSpan" id="kobo.93.1">), compile with TSAN, run the program, and you will </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">see this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.95.1">
WARNING: ThreadSanitizer: data race
...
</span><span class="koboSpan" id="kobo.95.2">Location is global 'i' of size 4 at &lt;address&gt;</span></pre>
<p><span class="koboSpan" id="kobo.96.1">There is a lot more information shown to help you figure out which threads have a data race and for which variable. </span><span class="koboSpan" id="kobo.96.2">This is a far more reliable way to test for data races than waiting for your program </span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">to fail.</span></span></p>
<p><span class="koboSpan" id="kobo.98.1">In C++17, the use of </span><strong class="source-inline"><span class="koboSpan" id="kobo.99.1">std::lock_guard</span></strong><span class="koboSpan" id="kobo.100.1"> is slightly simpler since the compiler figures out the template argument from </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">the constructor:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.102.1">
// Example 03
std::lock_guard l(m);</span></pre>
<p><span class="koboSpan" id="kobo.103.1">In C++20, we can use </span><strong class="source-inline"><span class="koboSpan" id="kobo.104.1">std::jthread</span></strong><span class="koboSpan" id="kobo.105.1"> instead of calling </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.106.1">join()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.107.1"> explicitly:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.108.1">
// Example 03
{
  std::jthread t1(add);
  std::jthread t2(add);
}
std::cout &lt;&lt; i &lt;&lt; std::endl;</span></pre>
<p><span class="koboSpan" id="kobo.109.1">Note that care must be taken to destroy the threads before using the result of the computation since the destructor now joins the thread and waits for the calculation to complete. </span><span class="koboSpan" id="kobo.109.2">Otherwise, there is another data race: the main thread is reading the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.110.1">i</span></strong><span class="koboSpan" id="kobo.111.1"> while it is being incremented (TSAN finds this race </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">as well).</span></span></p>
<p><span class="koboSpan" id="kobo.113.1">The use of RAII ensures that every time a mutex is locked it is also unlocked, but this does not avoid other errors that can happen when using mutexes. </span><span class="koboSpan" id="kobo.113.2">The most common one is forgetting to use the mutex in the first place. </span><span class="koboSpan" id="kobo.113.3">The synchronization guarantees apply only if every thread uses the same mechanism to ensure exclusive access to the data. </span><span class="koboSpan" id="kobo.113.4">If even one thread does not use the mutex, even if it’s only to read the data, then the entire program </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">is incorrect.</span></span></p>
<p><span class="koboSpan" id="kobo.115.1">A pattern was developed to prevent unsynchronized access to the shared. </span><span class="koboSpan" id="kobo.115.2">This pattern usually goes by the name “mutex-guarded” or “mutex-protected” and it has two key elements: first, the </span><a id="_idIndexMarker1137"/><span class="koboSpan" id="kobo.116.1">data </span><a id="_idIndexMarker1138"/><span class="koboSpan" id="kobo.117.1">that needs to be protected and the mutex that is used to do so are combined in the same object. </span><span class="koboSpan" id="kobo.117.2">Second, the design ensures that every access to the data is protected by the mutex. </span><span class="koboSpan" id="kobo.117.3">Here is the basic mutex-guarded </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">class template:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.119.1">
// Example 04
template &lt;typename T&gt; class MutexGuarded {
  std::mutex m_;
  T data_ {};
  public:
  MutexGuarded() = default;
  template &lt;typename... </span><span class="koboSpan" id="kobo.119.2">Args&gt;
  explicit MutexGuarded(Args&amp;&amp;... </span><span class="koboSpan" id="kobo.119.3">args) :
    data_(std::forward&lt;Args&gt;(args)...) {}
  template &lt;typename F&gt; decltype(auto) operator()(F f) {
    std::lock_guard&lt;std::mutex&gt; l(m_);
    return f(data_);
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.120.1">As you can see, this template combines the mutex and the data guarded by it, and offers only one way to access the data: by invoking the </span><strong class="source-inline"><span class="koboSpan" id="kobo.121.1">MutexGuarded</span></strong><span class="koboSpan" id="kobo.122.1"> object with an arbitrary callable. </span><span class="koboSpan" id="kobo.122.2">This</span><a id="_idIndexMarker1139"/><span class="koboSpan" id="kobo.123.1"> ensures</span><a id="_idIndexMarker1140"/><span class="koboSpan" id="kobo.124.1"> that all data accesses </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">are synchronized:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.126.1">
// Example 04
MutexGuarded&lt;int&gt; i_guarded(0);
void add() {
  i_guarded([](int&amp; i) { ++i; });
}
...
</span><span class="koboSpan" id="kobo.126.2">// On many threads:
std::thread t1(add);
std::thread t2(add);
t1.join();
t2.join();
i_guarded([](int i) { std::cout &lt;&lt; i &lt;&lt; std::endl; });</span></pre>
<p><span class="koboSpan" id="kobo.127.1">These are the most basic versions of the patterns for the correct and reliable use of mutexes. </span><span class="koboSpan" id="kobo.127.2">In practice, the needs are often more complex, and so are the solutions: there are much more efficient locks than </span><strong class="source-inline"><span class="koboSpan" id="kobo.128.1">std::mutex</span></strong><span class="koboSpan" id="kobo.129.1"> (for example, spinlocks for guarding short computations, which you can find in my book </span><em class="italic"><span class="koboSpan" id="kobo.130.1">The Art of Writing Efficient Programs</span></em><span class="koboSpan" id="kobo.131.1">), and there are also more complex locks such as shared and exclusive locks for efficient read-write access. </span><span class="koboSpan" id="kobo.131.2">Also, often we have to operate on several shared objects at the same time, which leads to the problem of safely locking multiple mutexes. </span><span class="koboSpan" id="kobo.131.3">Many of these problems are solved by more complex variations of the patterns we have just seen. </span><span class="koboSpan" id="kobo.131.4">Some call for an entirely different approach to the synchronization of data accesses, and we will see several of those later in this section. </span><span class="koboSpan" id="kobo.131.5">Finally, some data access challenges are </span><a id="_idIndexMarker1141"/><span class="koboSpan" id="kobo.132.1">better</span><a id="_idIndexMarker1142"/><span class="koboSpan" id="kobo.133.1"> solved at a much higher level of the overall system design; this will also be illustrated in </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">Let us next review different approaches to data sharing that go beyond the commonly </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">used mutex.</span></span></p>
<h2 id="_idParaDest-325"><a id="_idTextAnchor840"/><span class="koboSpan" id="kobo.137.1">No sharing is the best sharing</span></h2>
<p><span class="koboSpan" id="kobo.138.1">While protecting </span><a id="_idIndexMarker1143"/><span class="koboSpan" id="kobo.139.1">shared data with a mutex does not seem that complicated, in reality, data races are the most common bugs in any concurrent program. </span><span class="koboSpan" id="kobo.139.2">While it may seem a useless truism to state that you cannot have data races accessing data you do not share, not sharing is a frequently overlooked alternative to sharing. </span><span class="koboSpan" id="kobo.139.3">To put it another way, it is often possible to redesign a program to avoid sharing some of the variables or to restrict access to shared data to a smaller part of </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">the code.</span></span></p>
<p><span class="koboSpan" id="kobo.141.1">This idea is the basis of a design pattern that is simple to explain but often hard to apply because it requires thinking outside of the box – the thread-specific data pattern. </span><span class="koboSpan" id="kobo.141.2">It is also known as “thread-local data,” but the name invites confusion with the C++ </span><strong class="source-inline"><span class="koboSpan" id="kobo.142.1">thread_local</span></strong><span class="koboSpan" id="kobo.143.1"> keyword. </span><span class="koboSpan" id="kobo.143.2">To illustrate the idea, we consider this example: we need to count certain events that may be happening in multiple threads simultaneously (for this demonstration, it does not matter what is counted). </span><span class="koboSpan" id="kobo.143.3">We need the total count of these events in the entire program, so the straightforward approach is to have a shared count and increment it when a thread detects an event (in the demonstration, we count random numbers divisible </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">by 10):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.145.1">
// Example 05
MutexGuarded&lt;size_t&gt; count;
void events(unsigned int s) {
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&amp;s) % 10) == 0) { // Event!
</span><span class="koboSpan" id="kobo.145.2">      count([](size_t&amp; i) { ++i; });
    }
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.146.1">This is a straightforward design; it is not the best one. </span><span class="koboSpan" id="kobo.146.2">Notice that while each thread is counting events, it does not need to know how many events were counted by other threads. </span><span class="koboSpan" id="kobo.146.3">This is not to be confused with the fact that, in our implementation, each thread needs to know what the current value of the count is so it can correctly increment it. </span><span class="koboSpan" id="kobo.146.4">The distinction is subtle but important and suggests an alternative: each thread can count its own events using a thread-specific count, one for each thread. </span><span class="koboSpan" id="kobo.146.5">None of these counts are correct, but it doesn’t matter as long as we can add all counts together when we need the correct total event count. </span><span class="koboSpan" id="kobo.146.6">There are several possible designs here. </span><span class="koboSpan" id="kobo.146.7">We can use a </span><a id="_idIndexMarker1144"/><span class="koboSpan" id="kobo.147.1">local count for the events and update the shared count once before the </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">thread exits:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.149.1">
// Example 06
MutexGuarded&lt;size_t&gt; count;
void events(unsigned int s) {
  size_t n = 0;
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&amp;s) % 10) == 0) { // Event!
</span><span class="koboSpan" id="kobo.149.2">      ++n;
    }
  }
  if (n &gt; 0) count([n](size_t&amp; i) { i += n; });
}</span></pre>
<p><span class="koboSpan" id="kobo.150.1">Any local (stack-allocated) variable declared in a function that is being executed by one or more threads is specific to each thread: there is a unique copy of this variable on the stack of each thread, and each thread accesses its own variable when they all refer to the same </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">name </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.152.1">n</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.154.1">We could also give each thread a unique count variable to increment and add them together in the main thread after all the counting threads </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">are finished:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.156.1">
// Example 07
void events(unsigned int s, size_t&amp; n) {
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&amp;s) % 10) == 0) ++n;
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.157.1">When calling this counting function on multiple threads, we have to take some precautions. </span><span class="koboSpan" id="kobo.157.2">Obviously, we should give each thread its own variable for the count </span><strong class="source-inline"><span class="koboSpan" id="kobo.158.1">n</span></strong><span class="koboSpan" id="kobo.159.1">. </span><span class="koboSpan" id="kobo.159.2">This is not enough: due to the hardware-related effect known as “false sharing,” we must also ensure</span><a id="_idIndexMarker1145"/><span class="koboSpan" id="kobo.160.1"> that the thread-specific counts are not adjacent in memory (a detailed description of false sharing can be found in my book </span><em class="italic"><span class="koboSpan" id="kobo.161.1">The Art of Writing </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.162.1">Efficient Programs</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.164.1">
// Example 07
alignas(64) size_t n1 = 0;
alignas(64) size_t n2 = 0;
std::thread t1(events, 1, std::ref(n1));
std::thread t2(events, 2, std::ref(n2));
t1.join();
t2.join();
size_t count = n1 + n2;</span></pre>
<p><span class="koboSpan" id="kobo.165.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.166.1">alignas</span></strong><span class="koboSpan" id="kobo.167.1"> attribute ensures 64-byte alignment for each count variable, thus ensuring that there is at least 64 bytes difference between the addresses of </span><strong class="source-inline"><span class="koboSpan" id="kobo.168.1">n1</span></strong><span class="koboSpan" id="kobo.169.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.170.1">n2</span></strong><span class="koboSpan" id="kobo.171.1"> (64 is the size of the cache line on most modern CPUs, including X86 and ARM). </span><span class="koboSpan" id="kobo.171.2">Note the </span><strong class="source-inline"><span class="koboSpan" id="kobo.172.1">std::ref</span></strong><span class="koboSpan" id="kobo.173.1"> wrapper that is needed for </span><strong class="source-inline"><span class="koboSpan" id="kobo.174.1">std::thread</span></strong><span class="koboSpan" id="kobo.175.1"> to invoke functions that use </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">reference arguments.</span></span></p>
<p><span class="koboSpan" id="kobo.177.1">The previous example reduces the need for shared data access to once per thread, while the last one does not have any shared data at all; the preferred solution depends on exactly when is the value of the total </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">count needed.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">The last example can be examined from a slightly different point of view; it would help to slightly </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">rewrite it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.181.1">
// Example 08
struct {
  alignas(64) size_t n1 = 0;
  alignas(64) size_t n2 = 0;
} counts;
std::thread t1(events, 1, std::ref(counts.n1));
std::thread t2(events, 2, std::ref(counts.n2));
t1.join();
t2.join();
size_t count = counts.n1 + counts.n2;</span></pre>
<p><span class="koboSpan" id="kobo.182.1">This does not change</span><a id="_idIndexMarker1146"/><span class="koboSpan" id="kobo.183.1"> anything of substance, but we can view the thread-specific counts as parts of the same data structure rather than independent variables created for each thread. </span><span class="koboSpan" id="kobo.183.2">This way of thinking leads us to another variant of the thread-specific data pattern: sometimes, multiple threads must operate on the same data, but it may be possible to partition the data and give each thread its own subset to </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">work on.</span></span></p>
<p><span class="koboSpan" id="kobo.185.1">In the next example, we need to clamp each element in the vector (if an element exceeds the maximum value, it is replaced by this value, so the result is always in the range between zero and the maximum). </span><span class="koboSpan" id="kobo.185.2">The computation is implemented by this </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">templated algorithm:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.187.1">
// Example 09
template &lt;typename IT, typename T&gt;
void clamp(IT from, IT to, T value) {
  for (IT it = from; it != to; ++it) {
    if (*it &gt; value) *it = value;
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.188.1">A production-quality implementation would ensure that the iterator arguments satisfy the iterator requirements and the maximum value is comparable with the iterator value type, but we omit all that for brevity (we had an entire chapter on concepts and other ways to </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">restrict templates).</span></span></p>
<p><span class="koboSpan" id="kobo.190.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">clamp()</span></strong><span class="koboSpan" id="kobo.192.1"> function can be called on any sequence, and sometimes we will be lucky to have separate unrelated data structures we can process independently on multiple threads. </span><span class="koboSpan" id="kobo.192.2">But to continue this example, let us say that we have only one vector we need to clamp. </span><span class="koboSpan" id="kobo.192.3">All is not lost, however, as we can process non-overlapping parts of it on multiple threads</span><a id="_idIndexMarker1147"/><span class="koboSpan" id="kobo.193.1"> with no risk of </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">data races:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.195.1">
// Example 09
std::vector&lt;int&gt; data = ... </span><span class="koboSpan" id="kobo.195.2">data ...;
std::thread t1([&amp;](){
  clamp(data.begin(), data.begin() + data.size()/2, 42);
});
std::thread t2([&amp;](){
  clamp(data.begin() + data.size()/2, data.end(), 42);
});
...
</span><span class="koboSpan" id="kobo.195.3">t1.join();
t2.join();</span></pre>
<p><span class="koboSpan" id="kobo.196.1">Even though the data structure in our program is shared between two threads and both threads modify it, this program is correct: for each vector element, there is only one thread that can modify it. </span><span class="koboSpan" id="kobo.196.2">But what about the vector object itself? </span><span class="koboSpan" id="kobo.196.3">Isn’t it shared between </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">all threads?</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">We have already highlighted that there is one case when data sharing is allowed without any synchronization: any number of threads can read the same variable as long as no other thread is modifying it. </span><span class="koboSpan" id="kobo.198.2">Our example takes advantage of this: all threads read the size of the vector and other data members of the vector object, but no threads </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">change them.</span></span></p>
<p><span class="koboSpan" id="kobo.200.1">The application of the thread-specific data pattern must be carefully thought through and often requires a good understanding of the data structures. </span><span class="koboSpan" id="kobo.200.2">We must be absolutely certain that none of the threads attempt to modify the variables they do share, such as the size and the pointer to the data that are members of the vector object itself. </span><span class="koboSpan" id="kobo.200.3">For example, if one of the threads could resize the vector, that would be a data race even if no two threads access the same element: the size of the vector is a variable that is modified by one or more threads without </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">a lock.</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">The last pattern we want to describe in this subsection applies when several threads need to modify the entire data set (so it cannot be partitioned) but the threads do not need to see the modifications done by other threads. </span><span class="koboSpan" id="kobo.202.2">Usually, this happens when the modifications are done as a part of the computation of some result, but the modified data itself is not the final result. </span><span class="koboSpan" id="kobo.202.3">In this case, sometimes the best approach is to create a thread-specific copy of the data for each thread. </span><span class="koboSpan" id="kobo.202.4">This pattern works best when such copy is a “throw-away” object: each thread needs to modify its copy but the result of the modifications does not need to be committed back to the original </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">data structure.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">In the following </span><a id="_idIndexMarker1148"/><span class="koboSpan" id="kobo.205.1">example, we use an algorithm to count unique elements in a vector that sorts the vector </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">in place:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.207.1">
// Example 10
void count_unique(std::vector&lt;int&gt; data, size_t&amp; count) {
  std::sort(data.begin(), data.end());
  count = std::unique(data.begin(),
                      data.end()) - data.begin();
}</span></pre>
<p><span class="koboSpan" id="kobo.208.1">Also, when we need to count only elements that satisfy a predicate, we erase all other elements first (</span><strong class="source-inline"><span class="koboSpan" id="kobo.209.1">std::erase_if</span></strong><span class="koboSpan" id="kobo.210.1"> is a C++20 addition, but is easy to implement in a prior version </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">of C++):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.212.1">
// Example 10
void count_unique_even(std::vector&lt;int&gt; data, size_t&amp; count) {
  std::erase_if(data, [](int i) { return i &amp; 1; });
  std::sort(data.begin(), data.end());
  count = std::unique(data.begin(),
                      data.end()) - data.begin();
}</span></pre>
<p><span class="koboSpan" id="kobo.213.1">Both are destructive operations on a vector, but they are only means to an end: the altered vector can be discarded once we have our count. </span><span class="koboSpan" id="kobo.213.2">The simplest, and often the most efficient, way to compute our counts on several threads simultaneously is to make thread-specific copies of the vector. </span><span class="koboSpan" id="kobo.213.3">Actually, we did this already: both counting functions take the vector argument by value and, therefore, make a copy. </span><span class="koboSpan" id="kobo.213.4">Usually, this would be a mistake, but in our case, it is intentional and allows both functions to operate on the same </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">vector concurrently:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.215.1">
// Example 10
std::vector&lt;int&gt; data = ...;
size_t unique_count = 0;
size_t unique_even_count = 0;
{
  std::jthread t1(count_unique, data,
                  std::ref(unique_count));
  std::jthread t2(count_unique_even, data,
                  std::ref(unique_even_count));
}</span></pre>
<p><span class="koboSpan" id="kobo.216.1">Of course, there is </span><a id="_idIndexMarker1149"/><span class="koboSpan" id="kobo.217.1">still concurrent access to the original data, and it is done without a lock: both threads need to make their thread-specific copies. </span><span class="koboSpan" id="kobo.217.2">However, this falls under the exception of read-only concurrent access and </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">is safe.</span></span></p>
<p><span class="koboSpan" id="kobo.219.1">In principle, avoiding data sharing when possible and using mutexes otherwise is sufficient to arrange race-free access to data in any program. </span><span class="koboSpan" id="kobo.219.2">However, this may not be an efficient way to accomplish this goal, and good performance is almost always the goal of concurrency. </span><span class="koboSpan" id="kobo.219.3">We will now consider several other patterns for concurrent access to shared data that, when applicable, can offer superior performance. </span><span class="koboSpan" id="kobo.219.4">We are going to start with synchronization primitives that go beyond a mutex and are specifically designed to allow</span><a id="_idIndexMarker1150"/><span class="koboSpan" id="kobo.220.1"> threads to efficiently wait for </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">some event.</span></span></p>
<h2 id="_idParaDest-326"><a id="_idTextAnchor841"/><span class="koboSpan" id="kobo.222.1">Waiting patterns</span></h2>
<p><span class="koboSpan" id="kobo.223.1">Waiting is a problem </span><a id="_idIndexMarker1151"/><span class="koboSpan" id="kobo.224.1">that is frequently encountered in concurrent programs and takes many forms. </span><span class="koboSpan" id="kobo.224.2">We have already seen one: the mutex. </span><span class="koboSpan" id="kobo.224.3">Indeed, if two threads are trying to enter the critical section simultaneously, one of them will have to wait. </span><span class="koboSpan" id="kobo.224.4">But waiting is not the goal here, just an unfortunate side effect of exclusive access to the critical section. </span><span class="koboSpan" id="kobo.224.5">There are other situations where waiting is the primary objective. </span><span class="koboSpan" id="kobo.224.6">For example, we may have threads that are waiting for some event to happen. </span><span class="koboSpan" id="kobo.224.7">This could be a user interface thread waiting for input (little to no performance requirements) or a thread waiting on a network socket (moderate performance requirements) or even a high-performance thread such as a computing thread in a thread pool waiting for a task to execute (extremely high performance requirements). </span><span class="koboSpan" id="kobo.224.8">Not surprisingly, there are different implementations for these scenarios, but fundamentally there are two approaches: polling and notifications. </span><span class="koboSpan" id="kobo.224.9">We are going to look at </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">notifications first.</span></span></p>
<p><span class="koboSpan" id="kobo.226.1">The basic pattern for waiting for a notification</span><a id="_idIndexMarker1152"/><span class="koboSpan" id="kobo.227.1"> is the </span><strong class="bold"><span class="koboSpan" id="kobo.228.1">condition pattern</span></strong><span class="koboSpan" id="kobo.229.1">. </span><span class="koboSpan" id="kobo.229.2">It usually consists of a condition variable and a mutex. </span><span class="koboSpan" id="kobo.229.3">One or more threads are blocked waiting on the condition variable. </span><span class="koboSpan" id="kobo.229.4">During this time, there is one more thread that locks the mutex (thus guaranteeing exclusive access) and does the work whose completion the other threads are waiting for. </span><span class="koboSpan" id="kobo.229.5">Once the work is done, the thread that completed it must release the mutex (so other threads can access the shared data containing the results of this work) and notify the waiting threads that they </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">can proceed.</span></span></p>
<p><span class="koboSpan" id="kobo.231.1">For example, in a thread pool, the waiting threads are the pool worker threads that are waiting for tasks to be added to the pool. </span><span class="koboSpan" id="kobo.231.2">Since the pool task queue is a shared resource, a thread needs exclusive access to push or pop tasks. </span><span class="koboSpan" id="kobo.231.3">A thread that adds one or more tasks to the queue must hold the mutex while doing it and then notify the worker threads that there are tasks for them </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">to execute.</span></span></p>
<p><span class="koboSpan" id="kobo.233.1">Let us now see a very basic example of the notification pattern with just two threads. </span><span class="koboSpan" id="kobo.233.2">First, we have the main thread that starts a worker thread and then waits for it to produce </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">some results:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.235.1">
// Example 11
std::mutex m;
std::condition_variable cv;
size_t n = 0;               // Zero until work is done
// Main thread
void main_thread() {
  std::unique_lock l(m);
  std::thread t(produce);     // Start the worker
  cv.wait(l, []{ return n != 0; });
  ... </span><span class="koboSpan" id="kobo.235.2">producer thread is done, we have the lock ...
</span><span class="koboSpan" id="kobo.235.3">}</span></pre>
<p><span class="koboSpan" id="kobo.236.1">The locking in this case is provided by </span><strong class="source-inline"><span class="koboSpan" id="kobo.237.1">std::unique_lock</span></strong><span class="koboSpan" id="kobo.238.1">, an object that wraps around a mutex and has a mutex-like interface with </span><strong class="source-inline"><span class="koboSpan" id="kobo.239.1">lock()</span></strong><span class="koboSpan" id="kobo.240.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.241.1">unlock()</span></strong><span class="koboSpan" id="kobo.242.1"> member functions. </span><span class="koboSpan" id="kobo.242.2">The mutex is locked in the constructor and almost immediately unlocked by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.243.1">wait()</span></strong><span class="koboSpan" id="kobo.244.1"> function when we start waiting on the condition. </span><span class="koboSpan" id="kobo.244.2">When the notification is received, </span><strong class="source-inline"><span class="koboSpan" id="kobo.245.1">wait()</span></strong><span class="koboSpan" id="kobo.246.1"> locks the mutex again before returning control to </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">the caller.</span></span></p>
<p><span class="koboSpan" id="kobo.248.1">Many implementations of waiting and conditions suffer from what is known as spurious wake-up: wait can be interrupted even without notification. </span><span class="koboSpan" id="kobo.248.2">This is why we also check whether the results are ready, in our case, by checking the result count </span><strong class="source-inline"><span class="koboSpan" id="kobo.249.1">n</span></strong><span class="koboSpan" id="kobo.250.1">: if it is still zero, there are no</span><a id="_idIndexMarker1153"/><span class="koboSpan" id="kobo.251.1"> results, the main thread has been awakened in error and we can go back to waiting (note that the waiting thread must still acquire the mutex before </span><strong class="source-inline"><span class="koboSpan" id="kobo.252.1">wait()</span></strong><span class="koboSpan" id="kobo.253.1"> returns, so it must wait for the worker thread to release </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">this mutex).</span></span></p>
<p><span class="koboSpan" id="kobo.255.1">The worker thread must lock the same mutex before it can access the shared data, then unlock it before notifying the main thread that the work </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">is done:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.257.1">
// Example 11
// Worker thread
void produce() {
  {
    std::lock_guard l(m);
    ... </span><span class="koboSpan" id="kobo.257.2">compute results ...
</span><span class="koboSpan" id="kobo.257.3">    n = ... </span><span class="koboSpan" id="kobo.257.4">result count ...
</span><span class="koboSpan" id="kobo.257.5">  } // Mutex unlocked
  cv.notify_one();          // Waiting thread notified
}</span></pre>
<p><span class="koboSpan" id="kobo.258.1">It is not necessary to hold the mutex the entire time the worker thread is active: its only purpose is to protect the shared data such as the result count </span><strong class="source-inline"><span class="koboSpan" id="kobo.259.1">n</span></strong><span class="koboSpan" id="kobo.260.1"> in </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">our example.</span></span></p>
<p><span class="koboSpan" id="kobo.262.1">The two synchronization primitives </span><strong class="source-inline"><span class="koboSpan" id="kobo.263.1">std::conditional_variable</span></strong><span class="koboSpan" id="kobo.264.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.265.1">std::unique_lock</span></strong><span class="koboSpan" id="kobo.266.1"> are standard C++ tools for implementing the waiting pattern with a condition. </span><span class="koboSpan" id="kobo.266.2">Just as with a mutex, there are </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">many variations.</span></span></p>
<p><span class="koboSpan" id="kobo.268.1">The alternative to notifications is polling. </span><span class="koboSpan" id="kobo.268.2">In this pattern, the waiting thread repeatedly checks whether some condition is met. </span><span class="koboSpan" id="kobo.268.3">In C++20, we can implement a simple example of polling wait using </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">std::atomic_flag</span></strong><span class="koboSpan" id="kobo.270.1"> which is essentially an atomic boolean variable (prior to C++20 we</span><a id="_idIndexMarker1154"/><span class="koboSpan" id="kobo.271.1"> could do the same </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">std::atomic&lt;bool&gt;</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.275.1">
// Example 12
std::atomic_flag flag;
// Worker thread:
void produce() {
  ... </span><span class="koboSpan" id="kobo.275.2">produce the results ...
</span><span class="koboSpan" id="kobo.275.3">  flag.test_and_set(std::memory_order_release);
}
// Waiting thread:
void main_thread() {
  flag.clear();
  std::thread t(produce);
  while (!flag.test(std::memory_order_acquire)) {} // Wait
  ... </span><span class="koboSpan" id="kobo.275.4">results are ready ...
</span><span class="koboSpan" id="kobo.275.5">}</span></pre>
<p><span class="koboSpan" id="kobo.276.1">Atomic operations such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">test_and_set()</span></strong><span class="koboSpan" id="kobo.278.1"> make </span><a id="_idIndexMarker1155"/><span class="koboSpan" id="kobo.279.1">use of </span><strong class="bold"><span class="koboSpan" id="kobo.280.1">memory barriers</span></strong><span class="koboSpan" id="kobo.281.1">: a kind of global synchronization flag that ensures that all changes made to the memory before the flag is set (release) are visible to any operation on any other thread that is executed after the flag is tested (acquire). </span><span class="koboSpan" id="kobo.281.2">There is a lot more to these barriers, but it is outside of the scope of this book and can be found in many books dedicated to concurrency </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">and efficiency.</span></span></p>
<p><span class="koboSpan" id="kobo.283.1">The most important difference between this and the previous example is the explicit polling loop for the waiting thread in </span><em class="italic"><span class="koboSpan" id="kobo.284.1">Example 12</span></em><span class="koboSpan" id="kobo.285.1">. </span><span class="koboSpan" id="kobo.285.2">If the wait is long, this is highly inefficient since the waiting thread is busy computing (reading from memory) the entire time it waits. </span><span class="koboSpan" id="kobo.285.3">Any practical implementation would introduce some sleep into the wait loop, but doing so also comes at a cost: the waiting thread will not wake up immediately after the worker thread sets the flag but must finish the sleep first. </span><span class="koboSpan" id="kobo.285.4">These efficiency concerns are outside of the scope of this book; here we want to show the overall structure and the components of </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">these patterns.</span></span></p>
<p><span class="koboSpan" id="kobo.287.1">The boundary between polling and waiting is not always clear. </span><span class="koboSpan" id="kobo.287.2">For example, for all we know, </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">wait()</span></strong><span class="koboSpan" id="kobo.289.1"> could be</span><a id="_idIndexMarker1156"/><span class="koboSpan" id="kobo.290.1"> implemented by polling some internal state of the condition variable periodically. </span><span class="koboSpan" id="kobo.290.2">In fact, the same atomic flag we just saw can be used to wait for </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">a notification:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.292.1">
// Example 13
std::atomic_flag flag;
// Worker thread:
void produce() {
  ... </span><span class="koboSpan" id="kobo.292.2">produce the results ...
</span><span class="koboSpan" id="kobo.292.3">  flag.test_and_set(std::memory_order_release);
  flag.notify_one();
}
// Waiting thread:
void main_thread() {
  flag.clear();
  std::thread t(produce);
  flag.wait(true, std::memory_order_acquire); // Wait
  while (!flag.test(std::memory_order_acquire)) {}
  ... </span><span class="koboSpan" id="kobo.292.4">results are ready ...
</span><span class="koboSpan" id="kobo.292.5">}</span></pre>
<p><span class="koboSpan" id="kobo.293.1">The call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.294.1">wait()</span></strong><span class="koboSpan" id="kobo.295.1"> requires a corresponding call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.296.1">notify_one()</span></strong><span class="koboSpan" id="kobo.297.1"> (or </span><strong class="source-inline"><span class="koboSpan" id="kobo.298.1">notify_all()</span></strong><span class="koboSpan" id="kobo.299.1"> if we have more than one thread waiting on the flag). </span><span class="koboSpan" id="kobo.299.2">Its implementation is almost certainly more efficient than our simple polling loop. </span><span class="koboSpan" id="kobo.299.3">After the notification is received and the wait is over, we check the flag to make sure it was really set. </span><span class="koboSpan" id="kobo.299.4">The standard says that this is not necessary and </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">std::atomic_flag::wait()</span></strong><span class="koboSpan" id="kobo.301.1"> does not suffer from spurious wakeups, but TSAN in both GCC and Clang disagree (this could be a false positive in TSAN or a bug in the standard </span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">library implementation).</span></span></p>
<p><span class="koboSpan" id="kobo.303.1">There are many other situations where waiting is needed, and the conditions we need to wait for vary widely. </span><span class="koboSpan" id="kobo.303.2">Another common need is to wait for a certain number of events to occur. </span><span class="koboSpan" id="kobo.303.3">For example, we may have several threads producing results and we may need all of them to complete their share of the work before the main thread can proceed. </span><span class="koboSpan" id="kobo.303.4">This is accomplished</span><a id="_idIndexMarker1157"/><span class="koboSpan" id="kobo.304.1"> by waiting on a barrier or a latch. </span><span class="koboSpan" id="kobo.304.2">Prior to C++20, we would need to implement these synchronization primitives ourselves or use a third-party library, but in C++20 they </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">became standard:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.306.1">
// Example 14
// Worker threads
void produce(std::latch&amp; latch) {
  ... </span><span class="koboSpan" id="kobo.306.2">do the work ...
</span><span class="koboSpan" id="kobo.306.3">  latch.count_down();     // One more thread is done
}
void main_thread() {
  constexpr size_t nthread = 4;
  std::jthread t[nthread];
  std::latch latch(nthread); // Wait for 4 count_down()
  for (size_t i = 0; i != nthread; ++i) {
    t[i] = std::jthread(std::ref(latch));
  }
  latch.wait();   // Wait for producers to finish
  ... </span><span class="koboSpan" id="kobo.306.4">results are ready ...
</span><span class="koboSpan" id="kobo.306.5">}</span></pre>
<p><span class="koboSpan" id="kobo.307.1">The latch is initialized with the count of events to wait for. </span><span class="koboSpan" id="kobo.307.2">It will unlock when that many </span><strong class="source-inline"><span class="koboSpan" id="kobo.308.1">count_down()</span></strong><span class="koboSpan" id="kobo.309.1"> calls have </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">been done.</span></span></p>
<p><span class="koboSpan" id="kobo.311.1">There are many other applications of waiting, but almost all waiting patterns fall broadly into one of the categories we have seen in this section (a specific implementation can have a dramatic effect on performance in a particular case, which is you are far more likely to see custom application-specific versions of these synchronization constructs than you are to find non-standard containers or other basic </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">data structures).</span></span></p>
<p><span class="koboSpan" id="kobo.313.1">We are now going </span><a id="_idIndexMarker1158"/><span class="koboSpan" id="kobo.314.1">to see several examples of very specialized and very efficient synchronization patterns. </span><span class="koboSpan" id="kobo.314.2">They are not for all situations, but when they fit the need, they often offer the </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">best performance.</span></span></p>
<h2 id="_idParaDest-327"><a id="_idTextAnchor842"/><span class="koboSpan" id="kobo.316.1">Lock-free synchronization patterns</span></h2>
<p><span class="koboSpan" id="kobo.317.1">Most of the time, safely</span><a id="_idIndexMarker1159"/><span class="koboSpan" id="kobo.318.1"> accessing </span><a id="_idIndexMarker1160"/><span class="koboSpan" id="kobo.319.1">shared data relies on mutexes. </span><span class="koboSpan" id="kobo.319.2">C++ also supports another type of synchronizing concurrent threads: atomic operations. </span><span class="koboSpan" id="kobo.319.3">Again, a detailed explanation is outside of the scope of this book, and this section requires some prior knowledge of </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">the atomics.</span></span></p>
<p><span class="koboSpan" id="kobo.321.1">The basic idea is this: some data types (usually integers) have special hardware instructions that allow a few simple operations such as reading or writing or incrementing the values to be done atomically, in a single event. </span><span class="koboSpan" id="kobo.321.2">During this atomic operation, other threads cannot access the atomic variable at all, so if one thread performs an atomic operation, all other threads can see the same variable as it was before the operation or after the operation but not in the middle of the operation. </span><span class="koboSpan" id="kobo.321.3">For example, an increment is a read-modify-write operation, but an atomic increment is a special hardware transaction such that once the read began, no other thread can access the variable until the write completes. </span><span class="koboSpan" id="kobo.321.4">These atomic operations are often accompanied by memory barriers; we have used them already to ensure that not just atomic but all other operations on all variables in the program are synchronized and free from </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">data races.</span></span></p>
<p><span class="koboSpan" id="kobo.323.1">The simplest but useful application of atomic operations is for counting. </span><span class="koboSpan" id="kobo.323.2">We often need to count something in programs, and in concurrent programs, we may need to count some events that can occur on multiple threads. </span><span class="koboSpan" id="kobo.323.3">If we are only interested in the total count after all threads are done, this is best handled by the “non-sharing” or thread-specific counter we saw earlier. </span><span class="koboSpan" id="kobo.323.4">But what if all threads need to know the current count as well? </span><span class="koboSpan" id="kobo.323.5">We can always use a mutex, but using a mutex to protect a simple increment of an integer is highly inefficient. </span><span class="koboSpan" id="kobo.323.6">C++ gives us a better way, the </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">atomic counter:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.325.1">
// Example 15
std::atomic&lt;size_t&gt; count;
void thread_work() {
  size_t current_count = 0;
  if (... </span><span class="koboSpan" id="kobo.325.2">counted even ...) {
    current_count =
      count.fetch_add(1, std::memory_order_relaxed);
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.326.1">There is only one </span><a id="_idIndexMarker1161"/><span class="koboSpan" id="kobo.327.1">shared variable</span><a id="_idIndexMarker1162"/><span class="koboSpan" id="kobo.328.1"> in this example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">count</span></strong><span class="koboSpan" id="kobo.330.1"> itself. </span><span class="koboSpan" id="kobo.330.2">Since we do not have any other shared data, we have no need for memory barriers (“relaxed” memory order means there are no requirements on the order of accesses to other data). </span><span class="koboSpan" id="kobo.330.3">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">fetch_add()</span></strong><span class="koboSpan" id="kobo.332.1"> operation is an atomic increment, it increments </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">count</span></strong><span class="koboSpan" id="kobo.334.1"> by one and returns the old value </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.336.1">count</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.338.1">The atomic count can also be used to let multiple threads work on the same data structure without any need for locking: to do this, we need to make sure there is only one thread working on each element of the data structure. </span><span class="koboSpan" id="kobo.338.2">When used in this manner, the pattern is often referred to as the atomic index. </span><span class="koboSpan" id="kobo.338.3">In the next example, we have an array of data that is shared between </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">all threads:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.340.1">
// Example 16
static constexpr size_t N = 1024;
struct Data { ... </span><span class="koboSpan" id="kobo.340.2">};
Data data[N] {};</span></pre>
<p><span class="koboSpan" id="kobo.341.1">We also have an atomic index that is used by all threads that need to store the results of their work in the array. </span><span class="koboSpan" id="kobo.341.2">To do so safely, each thread increments an atomic index and used the pre-increment value as the index into the array. </span><span class="koboSpan" id="kobo.341.3">No two atomic increment operations can produce the same value, therefore, each thread gets its own array elements to </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">work on:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.343.1">
// Example 16
std::atomic&lt;size_t&gt; index(0);
// Many producer threads
void produce(size_t&amp; n) {
  while (... </span><span class="koboSpan" id="kobo.343.2">more work … ) {
    const size_t s =
      index.fetch_add(1, std::memory_order_relaxed);
    if (s &gt;= N) return;     // No more space
    data[s] = ... </span><span class="koboSpan" id="kobo.343.3">results ...
</span><span class="koboSpan" id="kobo.343.4">  }
}</span></pre>
<p><span class="koboSpan" id="kobo.344.1">Each thread </span><a id="_idIndexMarker1163"/><span class="koboSpan" id="kobo.345.1">gets to </span><a id="_idIndexMarker1164"/><span class="koboSpan" id="kobo.346.1">initialize however many array elements it can and stops when it (and all other threads) fill the entire array. </span><span class="koboSpan" id="kobo.346.2">The main thread has to wait until all the work is done before accessing any of the results. </span><span class="koboSpan" id="kobo.346.3">This cannot be done with just the atomic index since it is incremented when a thread starts working on a particular array element, not when that thread is done with the work. </span><span class="koboSpan" id="kobo.346.4">We have to use some other synchronization mechanism to make the main thread wait until all the work is done, such as a latch or, in a simple case, joining the </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">producer threads:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.348.1">
// Example 16
void main_thread() {
  constexpr size_t nthread = 5;
  std::thread t[nthread];
  for (size_t i = 0; i != nthread; ++i) {
    t[i] = std::thread(produce);
  }
  // Wait for producers. </span><span class="koboSpan" id="kobo.348.2">to finish.
</span><span class="koboSpan" id="kobo.348.3">  for (size_t i = 0; i != nthread; ++i) {
    t[i].join();
  }
  ... </span><span class="koboSpan" id="kobo.348.4">all work is done, data is ready ...
</span><span class="koboSpan" id="kobo.348.5">}</span></pre>
<p><span class="koboSpan" id="kobo.349.1">The atomic count is good when we don’t rely on the value of the count to access the results that are already produced. </span><span class="koboSpan" id="kobo.349.2">In the last example, the producer threads did not need access to the array elements computed by other threads, and the main thread waits for all threads to complete before accessing the results. </span><span class="koboSpan" id="kobo.349.3">Often, this is not the case and we need to access data as it is being produced. </span><span class="koboSpan" id="kobo.349.4">This is where memory barriers </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">come in.</span></span></p>
<p><span class="koboSpan" id="kobo.351.1">The simplest but surprisingly powerful lock-free pattern that relies on memory barriers is known as</span><a id="_idIndexMarker1165"/><span class="koboSpan" id="kobo.352.1"> the </span><a id="_idIndexMarker1166"/><span class="koboSpan" id="kobo.353.1">publishing protocol. </span><span class="koboSpan" id="kobo.353.2">The pattern is applicable when one thread is producing some data that is going to be made accessible to one or more other threads when it is ready. </span><span class="koboSpan" id="kobo.353.3">The pattern looks </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.355.1">
// Example 17
std::atomic&lt;Data*&gt; data;
void produce() {
  Data* p = new Data;
  ... </span><span class="koboSpan" id="kobo.355.2">complete *p object ...
</span><span class="koboSpan" id="kobo.355.3">  data.store(p, std::memory_order_release);
}
void consume() {
  Data* p = nullptr;
  while (!(p = data.load(std::memory_order_acquire))) {}
  ... </span><span class="koboSpan" id="kobo.355.4">safe to use *p ...
</span><span class="koboSpan" id="kobo.355.5">}</span></pre>
<p><span class="koboSpan" id="kobo.356.1">The shared variable is an atomic pointer to the data. </span><span class="koboSpan" id="kobo.356.2">It is often called the “root” pointer because the data itself may be a complex data structure with multiple pointers connecting its parts. </span><span class="koboSpan" id="kobo.356.3">The key requirement of this pattern is that there is only one way to access the entire data structure and this is through the </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">root pointer.</span></span></p>
<p><span class="koboSpan" id="kobo.358.1">The producer thread builds all the data it needs to produce. </span><span class="koboSpan" id="kobo.358.2">It uses a thread-specific pointer, usually a local variable, to access the data. </span><span class="koboSpan" id="kobo.358.3">No other thread can see the data yet because the root pointer does not point to it and the local pointer of the producer thread is not shared with </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">other threads.</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">Finally, when the data is complete, the producer atomically stores the pointer to the data in the shared root pointer. </span><span class="koboSpan" id="kobo.360.2">It is often said that the producer atomically publishes the data, hence the name of the pattern, the </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">publishing protocol.</span></span></p>
<p><span class="koboSpan" id="kobo.362.1">The consumers must wait for the data to be published: as long as the root pointer is null, there is nothing for them to do. </span><span class="koboSpan" id="kobo.362.2">They wait for the root pointer to become non-null (the wait does not have to use polling, a notification mechanism is also possible). </span><span class="koboSpan" id="kobo.362.3">Once the data is published, the consumer threads can access it through the root pointer. </span><span class="koboSpan" id="kobo.362.4">Because there is no other synchronization, no thread can modify the data once it’s published (the</span><a id="_idIndexMarker1167"/><span class="koboSpan" id="kobo.363.1"> data</span><a id="_idIndexMarker1168"/><span class="koboSpan" id="kobo.364.1"> may contain a mutex or some other mechanism to allow parts of it to be </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">modified safely).</span></span></p>
<p><span class="koboSpan" id="kobo.366.1">The atomic variable itself is insufficient for this pattern to guarantee no data races: all threads access not just the atomic pointer but the memory it points to. </span><span class="koboSpan" id="kobo.366.2">This is why we needed the specific memory barriers: when publishing the data, the producer uses the release barrier to not only initialize the pointer atomically but also ensure that all memory modifications that were done before the atomic write operations on the pointer become visible to anyone who reads the new value of the pointer. </span><span class="koboSpan" id="kobo.366.3">The consumer uses the acquire barrier to ensure that any operation on the shared data that is done after the new value of the pointer is read observes the latest state of the shared data as it existed at the moment the data was published. </span><span class="koboSpan" id="kobo.366.4">In other words, if you read the value of the pointer and then dereference it, you generally do not know if you will get the latest value of the data the pointer points to. </span><span class="koboSpan" id="kobo.366.5">But if you read the pointer with the acquire barrier (and the pointer was written with the release barrier), then you can be sure that you will read (acquire) the data as it was last written (released). </span><span class="koboSpan" id="kobo.366.6">Together, the release and acquire barriers guarantee that the consumer sees the shared data exactly as it was seen by the producer at the moment it published the address of the data in the </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">root pointer.</span></span></p>
<p><span class="koboSpan" id="kobo.368.1">The same pattern can be used to publish completed elements of a larger data structure shared between threads. </span><span class="koboSpan" id="kobo.368.2">For example, we can have a producer thread publish how many array</span><a id="_idIndexMarker1169"/><span class="koboSpan" id="kobo.369.1"> elements it initialized with </span><a id="_idIndexMarker1170"/><span class="No-Break"><span class="koboSpan" id="kobo.370.1">the results:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.371.1">
// Example 18
constexpr size_t N = ...;
Data data[N];     // Shared, not locked
std::atomic&lt;size_t&gt; size;
void produce() {
  for (size_t n = 0; n != N; ++n) {
    data[n] = ... </span><span class="koboSpan" id="kobo.371.2">results ...
</span><span class="koboSpan" id="kobo.371.3">    size.store(n, std::memory_order_release);
  }
}
void consume() {
  size_t n = 0;
  do {
    n = size.load(std::memory_order_acquire);
    ... </span><span class="koboSpan" id="kobo.371.4">n elements are safe to access ...
</span><span class="koboSpan" id="kobo.371.5">  } while (n &lt; N - 1);
}</span></pre>
<p><span class="koboSpan" id="kobo.372.1">The idea is exactly the same as in the previous example, only instead of the pointer we use the index into an array. </span><span class="koboSpan" id="kobo.372.2">In both cases, we have one producer thread that computes and publishes data, and one or more consumer threads that wait for the data to be published. </span><span class="koboSpan" id="kobo.372.3">If we need multiple producers, we must use some other synchronization mechanism to ensure that they don’t work on the same data, such as the atomic index we </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">just saw.</span></span></p>
<p><span class="koboSpan" id="kobo.374.1">In a program with multiple producer and consumer threads, we often have to combine several synchronization patterns. </span><span class="koboSpan" id="kobo.374.2">In the next example, we have a large shared data structure organized as an array of pointers to the individual elements. </span><span class="koboSpan" id="kobo.374.3">Several producer threads fill this data structure with results; we are going to use the atomic index to ensure that each element is handled by only </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">one producer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.376.1">
// Example 19
static constexpr size_t N = 1024;
struct Data { ... </span><span class="koboSpan" id="kobo.376.2">};
std::atomic&lt;Data*&gt; data[N] {};
std::atomic&lt;size_t&gt; size(0);     // Atomic index
void produce() {
  Data* p = new Data;
  ... </span><span class="koboSpan" id="kobo.376.3">compute *p ...
</span><span class="koboSpan" id="kobo.376.4">  const size_t s =
    size.fetch_add(1, std::memory_order_relaxed);
  data[s].store(p, std::memory_order_release);
}</span></pre>
<p><span class="koboSpan" id="kobo.377.1">Our</span><a id="_idIndexMarker1171"/><span class="koboSpan" id="kobo.378.1"> producer</span><a id="_idIndexMarker1172"/><span class="koboSpan" id="kobo.379.1"> computes the result, then fetches the current index value and, at the same time, increments the index so the next producer cannot get the same index value. </span><span class="koboSpan" id="kobo.379.2">The array slot </span><strong class="source-inline"><span class="koboSpan" id="kobo.380.1">data[s]</span></strong><span class="koboSpan" id="kobo.381.1"> is, therefore, uniquely reserved for this producer thread. </span><span class="koboSpan" id="kobo.381.2">This is enough to avoid sharing conflicts between producers, but the consumers cannot use the same index to know how many elements are already in the array: the index is incremented before the corresponding array element is initialized. </span><span class="koboSpan" id="kobo.381.3">For the consumers, we use the publishing protocol: each array element is an atomic pointer that remains null until the data is published. </span><span class="koboSpan" id="kobo.381.4">The consumers must wait for a pointer to become non-null before they can access </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">the data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.383.1">
// Example 19
void consumer() {
  for (size_t i = 0; i != N; ++i) {
    const Data* p =
      data[i].load(std::memory_order_acquire);
    if (!p) break; // No more data
    ... </span><span class="koboSpan" id="kobo.383.2">*p is safe to access ...
</span><span class="koboSpan" id="kobo.383.3">  }
}</span></pre>
<p><span class="koboSpan" id="kobo.384.1">In this example, the consumer stops as soon as it finds a data element that is not ready. </span><span class="koboSpan" id="kobo.384.2">We could continue scanning the array: some of the subsequent elements may be ready because they were filled by another producer thread. </span><span class="koboSpan" id="kobo.384.3">If we do, we have to somehow remember to come back to handle the elements we missed. </span><span class="koboSpan" id="kobo.384.4">The right approach depends on the problem we need to solve, </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">of course.</span></span></p>
<p><span class="koboSpan" id="kobo.386.1">The literature on lock-free programming is extensive and full of (usually) very complex examples. </span><span class="koboSpan" id="kobo.386.2">The concurrency patterns we have demonstrated are only the basic building blocks for more </span><a id="_idIndexMarker1173"/><span class="koboSpan" id="kobo.387.1">complex data</span><a id="_idIndexMarker1174"/><span class="koboSpan" id="kobo.388.1"> structures and data </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">synchronization protocols.</span></span></p>
<p><span class="koboSpan" id="kobo.390.1">In the next section, we will see some of the much higher-level patterns that are applicable to the design of such data structures or even entire programs and their </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">major components.</span></span></p>
<h1 id="_idParaDest-328"><a id="_idTextAnchor843"/><span class="koboSpan" id="kobo.392.1">Concurrent design patterns and guidelines</span></h1>
<p><span class="koboSpan" id="kobo.393.1">Designing and </span><a id="_idIndexMarker1175"/><span class="koboSpan" id="kobo.394.1">implementing concurrent software is hard. </span><span class="koboSpan" id="kobo.394.2">Even the basic patterns for controlling access to shared data, such as the ones we saw in the last section, are complex and full of subtle details. </span><span class="koboSpan" id="kobo.394.3">Failing to notice one of these details usually results in hard-to-debug data races. </span><span class="koboSpan" id="kobo.394.4">To simplify the task of writing concurrent programs, the programming community came up with several guidelines. </span><span class="koboSpan" id="kobo.394.5">All of them arise out of earlier disastrous experiences, so take these guidelines seriously. </span><span class="koboSpan" id="kobo.394.6">Central to these guidelines is the concept of thread </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">safety guarantees.</span></span></p>
<h2 id="_idParaDest-329"><a id="_idTextAnchor844"/><span class="koboSpan" id="kobo.396.1">Thread safety guarantees</span></h2>
<p><span class="koboSpan" id="kobo.397.1">While this is not a </span><a id="_idIndexMarker1176"/><span class="koboSpan" id="kobo.398.1">pattern, it is </span><a id="_idIndexMarker1177"/><span class="koboSpan" id="kobo.399.1">a concept that is much broader in scope and one of the key design principles for any concurrent software. </span><span class="koboSpan" id="kobo.399.2">Every class, function, module, or component of a concurrent program should specify the thread safety guarantees it provides, as well as the guarantees it requires from the components </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">it uses.</span></span></p>
<p><span class="koboSpan" id="kobo.401.1">In general, a software component can offer three levels of </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">thread-safety guarantees:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.403.1">Strong thread safety guarantee</span></strong><span class="koboSpan" id="kobo.404.1">: Any</span><a id="_idIndexMarker1178"/><span class="koboSpan" id="kobo.405.1"> number of threads can access this component without restrictions and without encountering undefined behavior. </span><span class="koboSpan" id="kobo.405.2">For a function, it means that any number of threads can call this function at the same time (possibly, with some restrictions on parameters). </span><span class="koboSpan" id="kobo.405.3">For a class, it means that any number of threads can call member functions of this class concurrently. </span><span class="koboSpan" id="kobo.405.4">For a larger component, any number of threads can operate its interfaces (again, possibly with some restrictions). </span><span class="koboSpan" id="kobo.405.5">Such components, classes, and data structures are sometimes </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">called thread-safe.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.407.1">Weak thread safety guarantee</span></strong><span class="koboSpan" id="kobo.408.1">: Any number of threads can access this component for operations that are specified to not alter the state of the component (for a class, this is usually </span><strong class="source-inline"><span class="koboSpan" id="kobo.409.1">const</span></strong><span class="koboSpan" id="kobo.410.1"> member functions). </span><span class="koboSpan" id="kobo.410.2">Only one thread can modify the state of the component at any time, and the locking or another way of ensuring such exclusive access is the responsibility of the caller. </span><span class="koboSpan" id="kobo.410.3">Such components, classes, and data structures are sometimes called thread-compatible because you can build a concurrent program from them using the appropriate synchronization mechanisms. </span><span class="koboSpan" id="kobo.410.4">All STL containers offer this level </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">of guarantee.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.412.1">No thread-safety guarantee</span></strong><span class="koboSpan" id="kobo.413.1">: Such components cannot be used in a concurrent program at all and are sometimes called thread-hostile. </span><span class="koboSpan" id="kobo.413.2">These classes and functions often have hidden global states that cannot be accessed in a </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">thread-safe manner.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.415.1">By designing each component to provide certain thread safety guarantees, we can divide the intractable problem of making the entire program thread-safe into a hierarchy of design challenges where the more complex components take advantage of the guarantees </span><a id="_idIndexMarker1179"/><span class="koboSpan" id="kobo.416.1">provided by the simpler ones. </span><span class="koboSpan" id="kobo.416.2">Central to this process is the notion of the </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">transactional interface.</span></span></p>
<h2 id="_idParaDest-330"><a id="_idTextAnchor845"/><span class="koboSpan" id="kobo.418.1">Transactional interface design</span></h2>
<p><span class="koboSpan" id="kobo.419.1">The idea of the </span><a id="_idIndexMarker1180"/><span class="koboSpan" id="kobo.420.1">transactional </span><a id="_idIndexMarker1181"/><span class="koboSpan" id="kobo.421.1">interface design is very simple: every component should have an interface such that every operation is an atomic transaction. </span><span class="koboSpan" id="kobo.421.2">From the point of view of the rest of the program, the operation either has not happened yet or is done. </span><span class="koboSpan" id="kobo.421.3">No other thread can observe the state of the component during the operation. </span><span class="koboSpan" id="kobo.421.4">This can be accomplished using mutexes or any other synchronization scheme that fits the need – the particular implementation can influence performance but is not essential for correctness as long as the interface guarantees </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">transaction processing.</span></span></p>
<p><span class="koboSpan" id="kobo.423.1">This guideline is most useful for designing data structures for concurrent programs. </span><span class="koboSpan" id="kobo.423.2">Here, it is so important that it is generally accepted that one cannot design a thread-safe data structure that does not offer a transactional interface (at least not a useful data structure). </span><span class="koboSpan" id="kobo.423.3">For example, we can consider a queue. </span><span class="koboSpan" id="kobo.423.4">The C++ standard library offers a </span><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">std::queue</span></strong><span class="koboSpan" id="kobo.425.1"> template. </span><span class="koboSpan" id="kobo.425.2">As with any other STL container, it offers the weak guarantee: any number of threads can call </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1">const</span></strong><span class="koboSpan" id="kobo.427.1"> methods of the queue as long as no thread calls any non-</span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">const</span></strong><span class="koboSpan" id="kobo.429.1"> methods. </span><span class="koboSpan" id="kobo.429.2">Alternatively, any one thread can call a non-</span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">const</span></strong><span class="koboSpan" id="kobo.431.1"> method. </span><span class="koboSpan" id="kobo.431.2">To ensure the latter, we have to lock all accesses to the queue with an external mutex. </span><span class="koboSpan" id="kobo.431.3">If we want to pursue this approach, we should combine the queue and the mutex in a </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">new class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.433.1">
template &lt;typename T&gt; class ts_queue {
  std::mutex m_;
  std::queue&lt;T&gt; q_;
  public:
  ts_queue() = default;
  ...
</span><span class="koboSpan" id="kobo.433.2">};</span></pre>
<p><span class="koboSpan" id="kobo.434.1">To push another element onto a queue, we need to lock the mutex, since the </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">push()</span></strong><span class="koboSpan" id="kobo.436.1"> member function modifies </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">the queue:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.438.1">
template &lt;typename T&gt; class ts_queue {
  public:
  void push(const T&amp; t) {
    std::lock_guard l(m_);
    q_.push(t);
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.439.1">This works exactly as we want it to: any number of threads can call </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">push()</span></strong><span class="koboSpan" id="kobo.441.1"> and every element will be added to the queue exactly once (the order is going to be arbitrary if multiple calls happen simultaneously, but this is the nature of concurrency). </span><span class="koboSpan" id="kobo.441.2">We have successfully provided the strong thread </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">safety guarantee!</span></span></p>
<p><span class="koboSpan" id="kobo.443.1">The triumph is going to be short-lived, unfortunately. </span><span class="koboSpan" id="kobo.443.2">Let us see what it takes to pop an element from the</span><a id="_idIndexMarker1182"/><span class="koboSpan" id="kobo.444.1"> queue. </span><span class="koboSpan" id="kobo.444.2">There</span><a id="_idIndexMarker1183"/><span class="koboSpan" id="kobo.445.1"> is a member function </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1">pop()</span></strong><span class="koboSpan" id="kobo.447.1"> that removes the element from the queue, so we can protect it with the </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">same mutex:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.449.1">
template &lt;typename T&gt; class ts_queue {
  public:
  void pop() {
    std::lock_guard l(m_);
    q_.pop();
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.450.1">Notice that this function does not return anything: it removes the oldest element in the queue and destroys it, but that’s not what we need to find out what that element is (or was). </span><span class="koboSpan" id="kobo.450.2">For that, we need to use the function </span><strong class="source-inline"><span class="koboSpan" id="kobo.451.1">front()</span></strong><span class="koboSpan" id="kobo.452.1"> which returns a reference to the oldest element but does not modify the queue. </span><span class="koboSpan" id="kobo.452.2">It is a </span><strong class="source-inline"><span class="koboSpan" id="kobo.453.1">const</span></strong><span class="koboSpan" id="kobo.454.1"> member function, so we need to lock it only if we call any non-</span><strong class="source-inline"><span class="koboSpan" id="kobo.455.1">const</span></strong><span class="koboSpan" id="kobo.456.1"> functions at the same time; we are going to ignore this optimization possibility for now and always lock this call </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">as well:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.458.1">
template &lt;typename T&gt; class ts_queue {
  public:
  T&amp; front() const {
    std::lock_guard l(m_);
    return q_.front();
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.459.1">If we call </span><strong class="source-inline"><span class="koboSpan" id="kobo.460.1">front()</span></strong><span class="koboSpan" id="kobo.461.1"> from multiple threads and don’t call any other functions, this implementation is sub-optimal, but it is </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">not wrong.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">There is one special case we have neglected to mention: if the queue is empty, you should not call </span><strong class="source-inline"><span class="koboSpan" id="kobo.464.1">pop()</span></strong><span class="koboSpan" id="kobo.465.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">front()</span></strong><span class="koboSpan" id="kobo.467.1"> – doing so leads to undefined behavior, according to the standard. </span><span class="koboSpan" id="kobo.467.2">How do you know if it is safe to pop an element from the queue? </span><span class="koboSpan" id="kobo.467.3">You can check if the queue is empty. </span><span class="koboSpan" id="kobo.467.4">This is another </span><strong class="source-inline"><span class="koboSpan" id="kobo.468.1">const</span></strong><span class="koboSpan" id="kobo.469.1"> member function, and again we are going to over-protect it and lock every call </span><span class="No-Break"><span class="koboSpan" id="kobo.470.1">to it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.471.1">
template &lt;typename T&gt; class ts_queue {
  public:
  bool empty() const {
    std::lock_guard l(m_);
    return q_.empty();
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.472.1">Now every</span><a id="_idIndexMarker1184"/><span class="koboSpan" id="kobo.473.1"> member</span><a id="_idIndexMarker1185"/><span class="koboSpan" id="kobo.474.1"> function of the underlying </span><strong class="source-inline"><span class="koboSpan" id="kobo.475.1">std::queue</span></strong><span class="koboSpan" id="kobo.476.1"> is protected by a mutex. </span><span class="koboSpan" id="kobo.476.2">We can call any of them from any number of threads and be guaranteed that only one thread can access the queue at any time. </span><span class="koboSpan" id="kobo.476.3">Technically, we have achieved the strong guarantee. </span><span class="koboSpan" id="kobo.476.4">Unfortunately, it is not </span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">very useful.</span></span></p>
<p><span class="koboSpan" id="kobo.478.1">To see why, let us consider the process of removing an element from </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">the queue:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.480.1">
ts_queue&lt;int&gt; q;
int i = 0;
if (!q.empty()) {
  i = q.front();
  q.pop();
}</span></pre>
<p><span class="koboSpan" id="kobo.481.1">This works fine on one thread, but we didn’t need a mutex for that. </span><span class="koboSpan" id="kobo.481.2">It still (mostly) works when we have two threads, one of which is pushing new elements onto the queue and the other one is taking them from the queue. </span><span class="koboSpan" id="kobo.481.3">Let us consider what happens when two threads try to pop one element each. </span><span class="koboSpan" id="kobo.481.4">First, they both call </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">empty()</span></strong><span class="koboSpan" id="kobo.483.1">. </span><span class="koboSpan" id="kobo.483.2">Let us assume that the queue is not empty and both calls return </span><strong class="source-inline"><span class="koboSpan" id="kobo.484.1">true</span></strong><span class="koboSpan" id="kobo.485.1">. </span><span class="koboSpan" id="kobo.485.2">Then, they both call </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">front()</span></strong><span class="koboSpan" id="kobo.487.1">. </span><span class="koboSpan" id="kobo.487.2">Since neither thread did a </span><strong class="source-inline"><span class="koboSpan" id="kobo.488.1">pop()</span></strong><span class="koboSpan" id="kobo.489.1"> yet, both threads get the same front element. </span><span class="koboSpan" id="kobo.489.2">This is not what was supposed to happen if we want each thread to pop an element from the queue. </span><span class="koboSpan" id="kobo.489.3">Finally, both threads call </span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1">pop()</span></strong><span class="koboSpan" id="kobo.491.1">, and two elements are removed from the queue. </span><span class="koboSpan" id="kobo.491.2">One of these elements we have never seen and will never see again, so we lost some of the data that </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">was enqueued.</span></span></p>
<p><span class="koboSpan" id="kobo.493.1">But this isn’t the only way it can go wrong. </span><span class="koboSpan" id="kobo.493.2">What happens if there is only one element on the queue? </span><span class="koboSpan" id="kobo.493.3">Both calls to </span><strong class="source-inline"><span class="koboSpan" id="kobo.494.1">empty()</span></strong><span class="koboSpan" id="kobo.495.1"> still return true – a queue with one element is not empty. </span><span class="koboSpan" id="kobo.495.2">Both calls to </span><strong class="source-inline"><span class="koboSpan" id="kobo.496.1">front()</span></strong><span class="koboSpan" id="kobo.497.1"> still return the (same) front element. </span><span class="koboSpan" id="kobo.497.2">The first call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.498.1">pop()</span></strong><span class="koboSpan" id="kobo.499.1"> succeeds</span><a id="_idIndexMarker1186"/><span class="koboSpan" id="kobo.500.1"> but the </span><a id="_idIndexMarker1187"/><span class="koboSpan" id="kobo.501.1">second one is undefined behavior because the queue is now empty. </span><span class="koboSpan" id="kobo.501.2">It is also possible that one thread calls </span><strong class="source-inline"><span class="koboSpan" id="kobo.502.1">pop()</span></strong><span class="koboSpan" id="kobo.503.1"> before the other thread calls </span><strong class="source-inline"><span class="koboSpan" id="kobo.504.1">front()</span></strong><span class="koboSpan" id="kobo.505.1"> but after it calls </span><strong class="source-inline"><span class="koboSpan" id="kobo.506.1">empty()</span></strong><span class="koboSpan" id="kobo.507.1">. </span><span class="koboSpan" id="kobo.507.2">In this case, the second call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.508.1">front()</span></strong><span class="koboSpan" id="kobo.509.1"> is </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">also undefined.</span></span></p>
<p><span class="koboSpan" id="kobo.511.1">We have a perfectly safe and a perfectly useless data structure. </span><span class="koboSpan" id="kobo.511.2">Clearly, a thread safety guarantee is not enough. </span><span class="koboSpan" id="kobo.511.3">We also need an interface that does not expose us to undefined behavior, and the only way to do this is to perform all three steps of the pop operation (</span><strong class="source-inline"><span class="koboSpan" id="kobo.512.1">empty()</span></strong><span class="koboSpan" id="kobo.513.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.514.1">front()</span></strong><span class="koboSpan" id="kobo.515.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.516.1">pop()</span></strong><span class="koboSpan" id="kobo.517.1">) in a single critical section, i.e., without releasing the mutex between the calls. </span><span class="koboSpan" id="kobo.517.2">Unless we want the caller to supply their own mutex, the only way to do this is to change the interface of our </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.518.1">ts_queue</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.519.1"> class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.520.1">
// Example 20
template &lt;typename T&gt; class ts_queue {
  std::queue&lt;T&gt; q_;
  std::mutex m_;
  public:
  ts_queue() = default;
  template &lt;typename U&gt; void push(U&amp;&amp; u) {
    std::lock_guard l(m_);
    q_.push(std::forward&lt;U&gt;(u));
  }
  std::optional&lt;T&gt; pop() {
    std::lock_guard l(m_);
    if (q_.empty()) return {};
    std::optional&lt;T&gt; res(std::move(q_.front()));
    q_.pop();
    return res;
 }
};</span></pre>
<p><span class="koboSpan" id="kobo.521.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1">push()</span></strong><span class="koboSpan" id="kobo.523.1"> function is the same as it was before (we made the argument type more flexible, but this is </span><a id="_idIndexMarker1188"/><span class="koboSpan" id="kobo.524.1">not related </span><a id="_idIndexMarker1189"/><span class="koboSpan" id="kobo.525.1">to thread safety). </span><span class="koboSpan" id="kobo.525.2">The reason we did not need to change the push operation is that it is already transactional: at the end, the queue has one more element than it had at the beginning of the operation, and the state of the queue is otherwise identical. </span><span class="koboSpan" id="kobo.525.3">We just made it atomic by protecting it with a mutex (no other thread that also uses the same mutex correctly can observe our queue in its transitional </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">non-invariant state).</span></span></p>
<p><span class="koboSpan" id="kobo.527.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.528.1">pop()</span></strong><span class="koboSpan" id="kobo.529.1"> operation is where the transactional interface looks very different. </span><span class="koboSpan" id="kobo.529.2">In order to provide a meaningful thread safety guarantee, we have to provide an operation that returns the front element to the caller and removes it from the queue atomically: no other thread should be able to see the same front element, therefore, we have to lock both </span><strong class="source-inline"><span class="koboSpan" id="kobo.530.1">front()</span></strong><span class="koboSpan" id="kobo.531.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.532.1">pop()</span></strong><span class="koboSpan" id="kobo.533.1"> on the original queue with the same mutex. </span><span class="koboSpan" id="kobo.533.2">We also have to consider the possibility that the queue is empty and we have no front element to return to the caller. </span><span class="koboSpan" id="kobo.533.3">What do we return in this case? </span><span class="koboSpan" id="kobo.533.4">If we decided to return the front element by value, we would have to default-construct this value (or return some other agreed-upon value that means “no element”). </span><span class="koboSpan" id="kobo.533.5">In C++17, a better way is to return a </span><strong class="source-inline"><span class="koboSpan" id="kobo.534.1">std::optional</span></strong><span class="koboSpan" id="kobo.535.1"> that holds the front element if there </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">is one.</span></span></p>
<p><span class="koboSpan" id="kobo.537.1">Now both </span><strong class="source-inline"><span class="koboSpan" id="kobo.538.1">pop()</span></strong><span class="koboSpan" id="kobo.539.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.540.1">push()</span></strong><span class="koboSpan" id="kobo.541.1"> are atomic and transactional: we can call both methods from as many threads as we want, and the results are </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">always well-defined.</span></span></p>
<p><span class="koboSpan" id="kobo.543.1">You may wonder why didn’t </span><strong class="source-inline"><span class="koboSpan" id="kobo.544.1">std::queue</span></strong><span class="koboSpan" id="kobo.545.1"> offer this transactional interface, to begin with. </span><span class="koboSpan" id="kobo.545.2">First, STL was designed long before threads made it into the standard. </span><span class="koboSpan" id="kobo.545.3">But the other, very important, reason is that the queue interface was influenced by the need to provide exception safety. </span><span class="koboSpan" id="kobo.545.4">Exception safety is the guarantee that the object remains in a well-defined state if an exception is thrown. </span><span class="koboSpan" id="kobo.545.5">Here, the original queue interface does very well: </span><strong class="source-inline"><span class="koboSpan" id="kobo.546.1">empty()</span></strong><span class="koboSpan" id="kobo.547.1"> just returns the size and cannot throw an exception, </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">front()</span></strong><span class="koboSpan" id="kobo.549.1"> returns the reference to the front element and also cannot throw, and finally </span><strong class="source-inline"><span class="koboSpan" id="kobo.550.1">pop()</span></strong><span class="koboSpan" id="kobo.551.1"> calls the destructor of the front element, which normally does not throw either. </span><span class="koboSpan" id="kobo.551.2">Of course, when accessing the front element, the caller’s code may throw (for example, if the caller needs to copy the front element to another object) but the caller is expected to handle that. </span><span class="koboSpan" id="kobo.551.3">In any case, the queue itself remains in a </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">well-defined state.</span></span></p>
<p><span class="koboSpan" id="kobo.553.1">Our thread-safe queue, however, has an exception safety problem: the code that copies the front element of the queue to return it to the caller is now inside </span><strong class="source-inline"><span class="koboSpan" id="kobo.554.1">pop()</span></strong><span class="koboSpan" id="kobo.555.1">. </span><span class="koboSpan" id="kobo.555.2">If the copy constructor throws during the construction of the local </span><strong class="source-inline"><span class="koboSpan" id="kobo.556.1">std::optional</span></strong><span class="koboSpan" id="kobo.557.1"> variable </span><strong class="source-inline"><span class="koboSpan" id="kobo.558.1">res</span></strong><span class="koboSpan" id="kobo.559.1">, we are probably OK. </span><span class="koboSpan" id="kobo.559.2">However, if an exception is thrown when the result is returned to the</span><a id="_idIndexMarker1190"/><span class="koboSpan" id="kobo.560.1"> caller (which</span><a id="_idIndexMarker1191"/><span class="koboSpan" id="kobo.561.1"> can happen by move or copy), then </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">pop()</span></strong><span class="koboSpan" id="kobo.563.1"> was already done, so we are going to lose the element we just popped from </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">the queue.</span></span></p>
<p><span class="koboSpan" id="kobo.565.1">This tension between thread safety and exception safety is often unavoidable and has to be considered when designing thread-safe data structures for concurrent programs. </span><span class="koboSpan" id="kobo.565.2">Regardless, it must be reiterated that the only way to design thread-safe data structures or larger modules is to ensure that every interface call is a complete transaction: any steps that are conditionally defined must be packaged into a single transactional call together with the operations that are needed to ensure that such conditions are met. </span><span class="koboSpan" id="kobo.565.3">Then, the entire call should be guarded by a mutex or some other way to ensure race-free </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">exclusive access.</span></span></p>
<p><span class="koboSpan" id="kobo.567.1">Designing thread-safe data structures is generally very hard, especially if we want good performance (and what is the point of concurrency if we don’t?). </span><span class="koboSpan" id="kobo.567.2">That is why it is very important to take advantage of any use restrictions or special requirements that allow us to impose restrictions on how these data structures are used. </span><span class="koboSpan" id="kobo.567.3">In the next section, we will see one</span><a id="_idIndexMarker1192"/><span class="koboSpan" id="kobo.568.1"> common case of </span><span class="No-Break"><span class="koboSpan" id="kobo.569.1">such restrictions.</span></span></p>
<h2 id="_idParaDest-331"><a id="_idTextAnchor846"/><span class="koboSpan" id="kobo.570.1">Data structures with access limitations</span></h2>
<p><span class="koboSpan" id="kobo.571.1">Designing thread-safe</span><a id="_idIndexMarker1193"/><span class="koboSpan" id="kobo.572.1"> data structures is so hard that one should look for any opportunity to simplify the requirements and the implementation. </span><span class="koboSpan" id="kobo.572.2">If there is any scenario you don’t need right now, think if you can make your code simpler if you do not support that scenario. </span><span class="koboSpan" id="kobo.572.3">One obvious case is a data structure that is built by a single thread (no thread safety guarantees needed) then becomes immutable and is accessed by many threads that act as readers (a weak guarantee is sufficient). </span><span class="koboSpan" id="kobo.572.4">Any STL container, for example, can operate in this mode as-is. </span><span class="koboSpan" id="kobo.572.5">We still need to ensure that no reader can access the container while it’s still being filled with data, but that can be easily done with a barrier or a condition. </span><span class="koboSpan" id="kobo.572.6">This is a very useful but rather trivial case. </span><span class="koboSpan" id="kobo.572.7">Are there any other restrictions we can make </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">use of?</span></span></p>
<p><span class="koboSpan" id="kobo.574.1">In this section, we consider a particular use case that occurs quite frequently and allows for much simpler data structures. </span><span class="koboSpan" id="kobo.574.2">Specifically, we examine the situation when a particular data structure is accessed by only two threads. </span><span class="koboSpan" id="kobo.574.3">One thread is the producer, it adds data to the data structure. </span><span class="koboSpan" id="kobo.574.4">The other thread is the consumer, it removes the data. </span><span class="koboSpan" id="kobo.574.5">Both threads do modify the data structure but in different ways. </span><span class="koboSpan" id="kobo.574.6">This situation occurs rather frequently and often allows for very specialized and very efficient data structure implementations. </span><span class="koboSpan" id="kobo.574.7">It probably deserves recognition as a design pattern for concurrent designs, and it already has a commonly recognized name: “single-producer single-consumer </span><span class="No-Break"><span class="koboSpan" id="kobo.575.1">data structure.”</span></span></p>
<p><span class="koboSpan" id="kobo.576.1">In this section, we are going to see an example of a single-producer single-consumer queue. </span><span class="koboSpan" id="kobo.576.2">It is a data structure that is frequently used with one producer and one consumer thread, but the ideas we explore here can be used to design other data structures as well. </span><span class="koboSpan" id="kobo.576.3">The main distinguishing feature of this queue is going to be that it is lock-free: there are no mutexes in it at all, so we can expect much higher performance </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">from it.</span></span></p>
<p><span class="koboSpan" id="kobo.578.1">The queue is built on an array of a fixed size, so, unlike a regular queue, it cannot grow indefinitely (this is another common restriction used to simplify lock-free </span><span class="No-Break"><span class="koboSpan" id="kobo.579.1">data structures):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.580.1">
// Example 21
template &lt;typename T, size_t N&gt; class ts_queue {
  T buffer_[N];
  std::atomic&lt;size_t&gt; back_{0};
  std::atomic&lt;size_t&gt; front_{N - 1};
  ...
</span><span class="koboSpan" id="kobo.580.2">};</span></pre>
<p><span class="koboSpan" id="kobo.581.1">In our example, we default-construct elements in the array. </span><span class="koboSpan" id="kobo.581.2">If this is undesirable, we can also use a properly aligned uninitialized buffer. </span><span class="koboSpan" id="kobo.581.3">All accesses to the queue are determined by two atomic variables, </span><strong class="source-inline"><span class="koboSpan" id="kobo.582.1">back_</span></strong><span class="koboSpan" id="kobo.583.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.584.1">front_</span></strong><span class="koboSpan" id="kobo.585.1">. </span><span class="koboSpan" id="kobo.585.2">The former is the index of the array element that we will write into when we push a new element onto the queue. </span><span class="koboSpan" id="kobo.585.3">The latter is the index of the array element we will read from when we need to pop an element from the queue. </span><span class="koboSpan" id="kobo.585.4">All array elements in the range [</span><strong class="source-inline"><span class="koboSpan" id="kobo.586.1">front_</span></strong><span class="koboSpan" id="kobo.587.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.588.1">back_</span></strong><span class="koboSpan" id="kobo.589.1">) are filled with elements currently on the queue. </span><span class="koboSpan" id="kobo.589.2">Note that this range can wrap over the end of the buffer: after using the element </span><strong class="source-inline"><span class="koboSpan" id="kobo.590.1">buffer_[N-1]</span></strong><span class="koboSpan" id="kobo.591.1"> the queue does not run out of space but starts again from </span><strong class="source-inline"><span class="koboSpan" id="kobo.592.1">buffer_[0]</span></strong><span class="koboSpan" id="kobo.593.1">. </span><span class="koboSpan" id="kobo.593.2">This is known </span><a id="_idIndexMarker1194"/><span class="koboSpan" id="kobo.594.1">as a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.595.1">circular buffer</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.596.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.597.1">How do we use</span><a id="_idIndexMarker1195"/><span class="koboSpan" id="kobo.598.1"> these indices to manage the queue? </span><span class="koboSpan" id="kobo.598.2">Let us start with the </span><span class="No-Break"><span class="koboSpan" id="kobo.599.1">push operation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.600.1">
// Example 21
template &lt;typename T, size_t N&gt; class ts_queue {
  public:
  template &lt;typename U&gt; bool push(U&amp;&amp; u) {
    const size_t front =
      front_.load(std::memory_order_acquire);
    size_t back = back_.load(std::memory_order_relaxed);
    if (back == front) return false;
    buffer_[back] = std::forward&lt;U&gt;(u);
    back_.store((back + 1) % N, std::memory_order_release);
    return true;
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.601.1">We need to read the current value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.602.1">back_</span></strong><span class="koboSpan" id="kobo.603.1">, of course: this is the index of the array element we are about to write. </span><span class="koboSpan" id="kobo.603.2">We support only one producer, and only the producer thread can increment </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1">back_</span></strong><span class="koboSpan" id="kobo.605.1">, so we do not need any particular precautions here. </span><span class="koboSpan" id="kobo.605.2">We do, however, need to be careful to avoid overwriting any elements already in the queue. </span><span class="koboSpan" id="kobo.605.3">To do this we must check the current value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.606.1">front_</span></strong><span class="koboSpan" id="kobo.607.1"> (we can read it before or after reading </span><strong class="source-inline"><span class="koboSpan" id="kobo.608.1">back_</span></strong><span class="koboSpan" id="kobo.609.1">, it makes no difference). </span><span class="koboSpan" id="kobo.609.2">If the element </span><strong class="source-inline"><span class="koboSpan" id="kobo.610.1">buffer_[back]</span></strong><span class="koboSpan" id="kobo.611.1"> that we are about to overwrite is also the front element, then the queue is full and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">push()</span></strong><span class="koboSpan" id="kobo.613.1"> operation fails (note that there is another solution to this problem that is often used in real-time systems: if the queue is full, the oldest element is silently overwritten and lost). </span><span class="koboSpan" id="kobo.613.2">After the new element is stored, we atomically increment the </span><strong class="source-inline"><span class="koboSpan" id="kobo.614.1">back_</span></strong><span class="koboSpan" id="kobo.615.1"> value to signal to the consumer that this slot is now available for reading. </span><span class="koboSpan" id="kobo.615.2">Because we are publishing this memory location, we must use the release barrier. </span><span class="koboSpan" id="kobo.615.3">Also note the modular arithmetic: after reaching the array element </span><strong class="source-inline"><span class="koboSpan" id="kobo.616.1">N-1</span></strong><span class="koboSpan" id="kobo.617.1">, we’re looping back to </span><span class="No-Break"><span class="koboSpan" id="kobo.618.1">element 0.</span></span></p>
<p><span class="koboSpan" id="kobo.619.1">Next, let us </span><a id="_idIndexMarker1196"/><span class="koboSpan" id="kobo.620.1">see the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.621.1">pop()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.622.1"> operation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.623.1">
// Example 21
template &lt;typename T, size_t N&gt; class ts_queue {
  public:
  std::optional&lt;T&gt; pop() {
    const size_t back =
      back_.load(std::memory_order_acquire);
    const size_t front =
     (front_.load(std::memory_order_relaxed) + 1) % N;
    if (front == back) return {};
    std::optional&lt;T&gt; res(std::move(buffer_[front]));
    front_.store(front, std::memory_order_release);
    return res;
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.624.1">Again, we need to read both </span><strong class="source-inline"><span class="koboSpan" id="kobo.625.1">front_</span></strong><span class="koboSpan" id="kobo.626.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.627.1">back_</span></strong><span class="koboSpan" id="kobo.628.1">: </span><strong class="source-inline"><span class="koboSpan" id="kobo.629.1">front_</span></strong><span class="koboSpan" id="kobo.630.1"> is the index of the element we are about to read, and only the consumer can advance this index. </span><span class="koboSpan" id="kobo.630.2">On the other hand, </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">back_</span></strong><span class="koboSpan" id="kobo.632.1"> is needed to make sure we actually have an element to read: if the front and back are the same, the queue is empty; again, we use </span><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">std::optional</span></strong><span class="koboSpan" id="kobo.634.1"> to return a value that might not exist. </span><span class="koboSpan" id="kobo.634.2">We must use acquire barrier when reading </span><strong class="source-inline"><span class="koboSpan" id="kobo.635.1">back_</span></strong><span class="koboSpan" id="kobo.636.1"> to make sure we see the element values that were written into the array by the producer thread. </span><span class="koboSpan" id="kobo.636.2">Finally, we advance </span><strong class="source-inline"><span class="koboSpan" id="kobo.637.1">front_</span></strong><span class="koboSpan" id="kobo.638.1"> to ensure that we don’t read the same element again and to make this array slot available to the </span><span class="No-Break"><span class="koboSpan" id="kobo.639.1">producer thread.</span></span></p>
<p><span class="koboSpan" id="kobo.640.1">There are several subtle details here that must be pointed out. </span><span class="koboSpan" id="kobo.640.2">Reading </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1">back_</span></strong><span class="koboSpan" id="kobo.642.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.643.1">front_</span></strong><span class="koboSpan" id="kobo.644.1"> is not done in a single transaction (it is not atomic). </span><span class="koboSpan" id="kobo.644.2">In particular, if the producer reads </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">front_</span></strong><span class="koboSpan" id="kobo.646.1"> first, it is possible that, by the time it reads </span><strong class="source-inline"><span class="koboSpan" id="kobo.647.1">back_</span></strong><span class="koboSpan" id="kobo.648.1"> and compares the two, the consumer has already advanced </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1">front_</span></strong><span class="koboSpan" id="kobo.650.1">. </span><span class="koboSpan" id="kobo.650.2">That does not make our data structure incorrect, though. </span><span class="koboSpan" id="kobo.650.3">At worst, the producer can report that the queue is full when in fact, it is no longer full. </span><span class="koboSpan" id="kobo.650.4">We could read both values atomically, but this will only degrade the performance, and the caller still has to handle the case when the queue is full. </span><span class="koboSpan" id="kobo.650.5">Similarly, when </span><strong class="source-inline"><span class="koboSpan" id="kobo.651.1">pop()</span></strong><span class="koboSpan" id="kobo.652.1"> reports that the queue is empty, it may no longer be so by the time the call completes. </span><span class="koboSpan" id="kobo.652.2">Again, these are the inevitable complexities of concurrency: each operation reflects the state of the data at some point in time. </span><span class="koboSpan" id="kobo.652.3">By the time the caller</span><a id="_idIndexMarker1197"/><span class="koboSpan" id="kobo.653.1"> gets the return value and can analyze it, the data may have </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">changed already.</span></span></p>
<p><span class="koboSpan" id="kobo.655.1">Another note-worthy detail is the careful management of the queue elements’ lifetime. </span><span class="koboSpan" id="kobo.655.2">We default-construct all elements in the array, so the proper way to transfer the data from the caller into the queue during </span><strong class="source-inline"><span class="koboSpan" id="kobo.656.1">push()</span></strong><span class="koboSpan" id="kobo.657.1"> is by copy or move assignment (</span><strong class="source-inline"><span class="koboSpan" id="kobo.658.1">std::forward</span></strong><span class="koboSpan" id="kobo.659.1"> does both). </span><span class="koboSpan" id="kobo.659.2">On the other hand, once a value is returned to the caller by </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1">pop()</span></strong><span class="koboSpan" id="kobo.661.1">, we never need that value again, so the right operation here is move, first into the optional and then into the caller’s return value object. </span><span class="koboSpan" id="kobo.661.2">Note that moving an object is not the same as destroying it; indeed, the moved-from array elements are not destroyed until the queue itself is. </span><span class="koboSpan" id="kobo.661.3">If an array element is reused, it is copy- or move-assigned a new value, and assignments are two of the three operations that are safe to do on a moved-from object (the third one is the destructor, which we will also </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">call eventually).</span></span></p>
<p><span class="koboSpan" id="kobo.663.1">The single-producer single-consumer pattern is a common pattern that allows a programmer to greatly simplify their concurrent data structures. </span><span class="koboSpan" id="kobo.663.2">There are others, you can find them in books and papers dedicated to concurrent data structures. </span><span class="koboSpan" id="kobo.663.3">All these patterns are ultimately designed to help you write data structures that perform correctly and efficiently when accessed by multiple threads. </span><span class="koboSpan" id="kobo.663.4">We, however, must move on and finally </span><a id="_idIndexMarker1198"/><span class="koboSpan" id="kobo.664.1">tackle the problem of using these threads to get some useful </span><span class="No-Break"><span class="koboSpan" id="kobo.665.1">work done.</span></span></p>
<h1 id="_idParaDest-332"><a id="_idTextAnchor847"/><span class="koboSpan" id="kobo.666.1">Concurrent execution patterns</span></h1>
<p><span class="koboSpan" id="kobo.667.1">The next group of </span><a id="_idIndexMarker1199"/><span class="koboSpan" id="kobo.668.1">patterns for concurrency we must learn are execution patterns. </span><span class="koboSpan" id="kobo.668.2">These patterns are used to organize the computations done on multiple threads. </span><span class="koboSpan" id="kobo.668.3">You will find out that, just as with the synchronization patterns we saw earlier, all of these are low-level patterns: most solutions for practical problems must combine these patterns into larger, more complex, designs. </span><span class="koboSpan" id="kobo.668.4">This is not because C++ is ill-suited for such larger designs; if anything, it is the opposite: there are so many ways to implement, for example, a thread pool, in C++, that for every concrete application, there is a version that is ideally suited in terms of performance and features. </span><span class="koboSpan" id="kobo.668.5">This is why it is hard to describe these more complete solutions as patterns: while the problems they address are common, the solutions vary a great deal. </span><span class="koboSpan" id="kobo.668.6">But all of these designs have a number of challenges to resolve, and the solutions to those challenges usually use the same tools over and over, so we can at least describe these more basic challenges and their common solutions as </span><span class="No-Break"><span class="koboSpan" id="kobo.669.1">design patterns.</span></span></p>
<h2 id="_idParaDest-333"><a id="_idTextAnchor848"/><span class="koboSpan" id="kobo.670.1">Active object</span></h2>
<p><span class="koboSpan" id="kobo.671.1">The first concurrent </span><a id="_idIndexMarker1200"/><span class="koboSpan" id="kobo.672.1">execution pattern we are</span><a id="_idIndexMarker1201"/><span class="koboSpan" id="kobo.673.1"> going to see is the Active Object. </span><span class="koboSpan" id="kobo.673.2">An active object usually encapsulates the code to be executed, the data needed for the execution, and the flow of control needed to execute the code asynchronously. </span><span class="koboSpan" id="kobo.673.3">This flow of control could be as simple as a separate thread that the object starts and joins. </span><span class="koboSpan" id="kobo.673.4">In most cases, we do not start a new thread for every task, so an active object would have some way to run its code on a multi-threaded executor such as a thread pool. </span><span class="koboSpan" id="kobo.673.5">From the caller’s point of view, an active object is an object that the caller constructs, initializes with the data, then tells the object to execute itself, and the execution </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">happens asynchronously.</span></span></p>
<p><span class="koboSpan" id="kobo.675.1">The basic </span><a id="_idIndexMarker1202"/><span class="koboSpan" id="kobo.676.1">active</span><a id="_idIndexMarker1203"/><span class="koboSpan" id="kobo.677.1"> object looks </span><span class="No-Break"><span class="koboSpan" id="kobo.678.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.679.1">
// Example 22
class Job {
  ... </span><span class="koboSpan" id="kobo.679.2">data ...
</span><span class="koboSpan" id="kobo.679.3">  std::thread t_;
  bool done_ {};
  public:
  Job(... </span><span class="koboSpan" id="kobo.679.4">args ...) { ... </span><span class="koboSpan" id="kobo.679.5">initialize data ... </span><span class="koboSpan" id="kobo.679.6">}
  void operator()() {
    t_ = std::thread([this](){ ... </span><span class="koboSpan" id="kobo.679.7">computations ... </span><span class="koboSpan" id="kobo.679.8">}
  );
  }
  void wait() {
    if (done_) return;
    t_.join();
    done_ = true;
  }
  ~Job() { wait(); }
  auto get() { this-&gt;wait(); return ... </span><span class="koboSpan" id="kobo.679.9">results ...; }
};
Job j(... </span><span class="koboSpan" id="kobo.679.10">args ...);
j();     // Execute code on a thread
... </span><span class="koboSpan" id="kobo.679.11">do other work ...
</span><span class="koboSpan" id="kobo.679.12">std::cout &lt;&lt; j.get();  // Wait for results and print them</span></pre>
<p><span class="koboSpan" id="kobo.680.1">In the simplest case shown here, the active object contains a thread that is used to execute the code asynchronously. </span><span class="koboSpan" id="kobo.680.2">In most practical cases you would use an executor that schedules the work on one of the threads it manages, but this gets us into implementation-specific details. </span><span class="koboSpan" id="kobo.680.3">The execution starts when </span><strong class="source-inline"><span class="koboSpan" id="kobo.681.1">operator()</span></strong><span class="koboSpan" id="kobo.682.1"> is called; we can also make the object execute as soon as it is constructed by calling </span><strong class="source-inline"><span class="koboSpan" id="kobo.683.1">operator()</span></strong><span class="koboSpan" id="kobo.684.1"> from the constructor. </span><span class="koboSpan" id="kobo.684.2">At some point, we have to wait for the results. </span><span class="koboSpan" id="kobo.684.3">If we use a separate thread, we can join the thread at that time (and take care to not attempt to join it twice if the caller calls </span><strong class="source-inline"><span class="koboSpan" id="kobo.685.1">wait()</span></strong><span class="koboSpan" id="kobo.686.1"> again). </span><span class="koboSpan" id="kobo.686.2">If the object represents not a thread but a task in a thread pool or some other executor, we would do the cleanup necessary for </span><span class="No-Break"><span class="koboSpan" id="kobo.687.1">that case.</span></span></p>
<p><span class="koboSpan" id="kobo.688.1">As you can see, once we settle on a particular way to execute code asynchronously, writing active objects with different data and code is a rather repetitive task. </span><span class="koboSpan" id="kobo.688.2">Nobody writes active objects the way we just did, we always use some generic reusable framework. </span><span class="koboSpan" id="kobo.688.3">There are </span><a id="_idIndexMarker1204"/><span class="koboSpan" id="kobo.689.1">two general approaches to</span><a id="_idIndexMarker1205"/><span class="koboSpan" id="kobo.690.1"> implementing such a framework. </span><span class="koboSpan" id="kobo.690.2">The first one uses inheritance: the base class does the boilerplate work, and the derived class contains the unique task-specific data and code. </span><span class="koboSpan" id="kobo.690.3">Staying with our simple approach to active objects, we could write the base class </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.692.1">
// Example 23
class Job {
  std::thread t_;
  bool done_ {};
  virtual void operator()() = 0;
  public:
  void wait() {
    if (done_) return;
    t_.join();
    done_ = true;
  }
  void run() {
    t_ = std::thread([this](){ (*this)(); });
  }
  virtual ~Job() { wait(); }
};</span></pre>
<p><span class="koboSpan" id="kobo.693.1">The base object </span><strong class="source-inline"><span class="koboSpan" id="kobo.694.1">Job</span></strong><span class="koboSpan" id="kobo.695.1"> contains everything needed to implement the asynchronous control flow: the thread and the state flag needed to join the thread only once. </span><span class="koboSpan" id="kobo.695.2">It also defines the way to execute the code by calling the non-virtual function </span><strong class="source-inline"><span class="koboSpan" id="kobo.696.1">run()</span></strong><span class="koboSpan" id="kobo.697.1">. </span><span class="koboSpan" id="kobo.697.2">The code that is executed on the thread must be provided by the derived object by overriding </span><strong class="source-inline"><span class="koboSpan" id="kobo.698.1">operator()</span></strong><span class="koboSpan" id="kobo.699.1">. </span><span class="koboSpan" id="kobo.699.2">Note that only </span><strong class="source-inline"><span class="koboSpan" id="kobo.700.1">run()</span></strong><span class="koboSpan" id="kobo.701.1"> is public, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.702.1">operator()</span></strong><span class="koboSpan" id="kobo.703.1"> is not: this is the non-virtual idiom in action (we saw it in </span><a href="B19262_14.xhtml#_idTextAnchor640"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.704.1">Chapter 14</span></em></span></a><span class="koboSpan" id="kobo.705.1">, </span><em class="italic"><span class="koboSpan" id="kobo.706.1">The Template Method Pattern and the </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.707.1">Non-Virtual Idiom</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.708.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.709.1">The derived</span><a id="_idIndexMarker1206"/><span class="koboSpan" id="kobo.710.1"> object is problem-specific, of course, but </span><a id="_idIndexMarker1207"/><span class="koboSpan" id="kobo.711.1">generally looks </span><span class="No-Break"><span class="koboSpan" id="kobo.712.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.713.1">
// Example 23
class TheJob final : public Job {
  ... </span><span class="koboSpan" id="kobo.713.2">data ...
</span><span class="koboSpan" id="kobo.713.3">  void operator()() override { ... </span><span class="koboSpan" id="kobo.713.4">work ... </span><span class="koboSpan" id="kobo.713.5">}
  public:
  TheJob(... </span><span class="koboSpan" id="kobo.713.6">args ...) {
    ... </span><span class="koboSpan" id="kobo.713.7">initialize data ...
</span><span class="koboSpan" id="kobo.713.8">    this-&gt;run();
  }
  auto get() { this-&gt;wait(); return ... </span><span class="koboSpan" id="kobo.713.9">results ...; }
};</span></pre>
<p><span class="koboSpan" id="kobo.714.1">The only subtlety here is the call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1">run()</span></strong><span class="koboSpan" id="kobo.716.1"> done at the end of the constructor of the derived object. </span><span class="koboSpan" id="kobo.716.2">It is not necessary (we can execute the active object later ourselves) but if we do want the constructor to run it, it has to be done in the derived class. </span><span class="koboSpan" id="kobo.716.3">If we start the thread and the asynchronous execution in the base class constructor, then we will have a race between the execution on the thread – </span><strong class="source-inline"><span class="koboSpan" id="kobo.717.1">operator()</span></strong><span class="koboSpan" id="kobo.718.1"> – and the rest of the initialization which continues in the derived class constructor. </span><span class="koboSpan" id="kobo.718.2">For the same reason, an active object that starts executing from the constructor should not be derived from again; we ensure that by making the </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">object final.</span></span></p>
<p><span class="koboSpan" id="kobo.720.1">The use of our active object is very simple: we create it, the object starts executing the code in the background (on a separate thread), and when we need the result we ask for it (this may </span><span class="No-Break"><span class="koboSpan" id="kobo.721.1">involve waiting):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.722.1">
// Example 23
TheJob j1(... </span><span class="koboSpan" id="kobo.722.2">args ...);
TheJob j2(... </span><span class="koboSpan" id="kobo.722.3">args ...);
... </span><span class="koboSpan" id="kobo.722.4">do other stuff ...
</span><span class="koboSpan" id="kobo.722.5">std::cout &lt;&lt; "Results: " &lt;&lt; j1.get() &lt;&lt; " " &lt;&lt; j2.get();</span></pre>
<p><span class="koboSpan" id="kobo.723.1">If you’ve written </span><a id="_idIndexMarker1208"/><span class="koboSpan" id="kobo.724.1">any concurrent code in C++ at all, you </span><a id="_idIndexMarker1209"/><span class="koboSpan" id="kobo.725.1">will have definitely used an active object already: </span><strong class="source-inline"><span class="koboSpan" id="kobo.726.1">std::thread</span></strong><span class="koboSpan" id="kobo.727.1"> is an active object, it lets us execute arbitrary code on a separate thread. </span><span class="koboSpan" id="kobo.727.2">There are concurrency libraries for C++ where a thread is a base object and all concrete threads are derived from it. </span><span class="koboSpan" id="kobo.727.3">But this is not the approach chosen for the C++ standard thread. </span><span class="koboSpan" id="kobo.727.4">It follows the second way to implement a reusable active object: type erasure. </span><span class="koboSpan" id="kobo.727.5">If you need to familiarize yourself with it, reread </span><a href="B19262_06.xhtml#_idTextAnchor266"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.728.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.729.1">, </span><em class="italic"><span class="koboSpan" id="kobo.730.1">Understanding Type Erasure</span></em><span class="koboSpan" id="kobo.731.1">. </span><span class="koboSpan" id="kobo.731.2">Even though </span><strong class="source-inline"><span class="koboSpan" id="kobo.732.1">std::thread</span></strong><span class="koboSpan" id="kobo.733.1"> itself is a type-erased active object, we’re going to implement our own just to demonstrate the design (the standard library code is rather hard to read). </span><span class="koboSpan" id="kobo.733.2">This time, there is no base class. </span><span class="koboSpan" id="kobo.733.3">The framework is provided by a </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">single class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.735.1">
// Example 24
class Job {
  bool done_ {};
  std::function&lt;void()&gt; f_;
  std::thread t_;
  public:
  template &lt;typename F&gt; explicit Job(F&amp;&amp; f) :
    f_(f), t_(f_) {}
  void wait() {
     if (done_) return;
     t_.join();
     done_ = true;
  }
  ~Job() { wait(); }
};</span></pre>
<p><span class="koboSpan" id="kobo.736.1">To implement the type-erased callable, we use </span><strong class="source-inline"><span class="koboSpan" id="kobo.737.1">std::function</span></strong><span class="koboSpan" id="kobo.738.1"> (we could also use one of the more efficient implementations from </span><a href="B19262_06.xhtml#_idTextAnchor266"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.739.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.740.1">, </span><em class="italic"><span class="koboSpan" id="kobo.741.1">Understanding Type Erasure</span></em><span class="koboSpan" id="kobo.742.1">, or implement type erasure ourselves following the same approach). </span><span class="koboSpan" id="kobo.742.2">The code supplied by the caller to be executed on a thread comes from the callable </span><strong class="source-inline"><span class="koboSpan" id="kobo.743.1">f</span></strong><span class="koboSpan" id="kobo.744.1"> in the constructor argument. </span><span class="koboSpan" id="kobo.744.2">Note that the order of the class members is very important: the asynchronous execution starts as soon as the thread </span><strong class="source-inline"><span class="koboSpan" id="kobo.745.1">t_</span></strong><span class="koboSpan" id="kobo.746.1"> is initialized, so other data members, in particular, the callable </span><strong class="source-inline"><span class="koboSpan" id="kobo.747.1">f_</span></strong><span class="koboSpan" id="kobo.748.1">, must be initialized before </span><span class="No-Break"><span class="koboSpan" id="kobo.749.1">that happens.</span></span></p>
<p><span class="koboSpan" id="kobo.750.1">To use the active </span><a id="_idIndexMarker1210"/><span class="koboSpan" id="kobo.751.1">object of this style, we need to supply a</span><a id="_idIndexMarker1211"/><span class="koboSpan" id="kobo.752.1"> callable. </span><span class="koboSpan" id="kobo.752.2">It could be a lambda expression or a named object, </span><span class="No-Break"><span class="koboSpan" id="kobo.753.1">for example:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.754.1">
// Example 24
class TheJob {
  ... </span><span class="koboSpan" id="kobo.754.2">data ...
</span><span class="koboSpan" id="kobo.754.3">  public:
  TheJob(... </span><span class="koboSpan" id="kobo.754.4">args ...) { ... </span><span class="koboSpan" id="kobo.754.5">initialize data ... </span><span class="koboSpan" id="kobo.754.6">}
  void operator()() { // Callable!
</span><span class="koboSpan" id="kobo.754.7">    ... </span><span class="koboSpan" id="kobo.754.8">do the work ...
</span><span class="koboSpan" id="kobo.754.9">  }
};
Job j(TheJob(... </span><span class="koboSpan" id="kobo.754.10">args ...));
j.wait();</span></pre>
<p><span class="koboSpan" id="kobo.755.1">Note that, in this design, there is no easy way to access the data members of the callable </span><strong class="source-inline"><span class="koboSpan" id="kobo.756.1">TheJob</span></strong><span class="koboSpan" id="kobo.757.1">, unless it was created as a named object. </span><span class="koboSpan" id="kobo.757.2">For this reason, the results are usually returned through arguments passed to the constructor by reference (the same as we do </span><span class="No-Break"><span class="koboSpan" id="kobo.758.1">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.759.1">std::thread</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.761.1">
// Example 24
class TheJob {
  ... </span><span class="koboSpan" id="kobo.761.2">data ...
</span><span class="koboSpan" id="kobo.761.3">  double&amp; res_; // Result
  public:
  TheJob(double&amp; res, ... </span><span class="koboSpan" id="kobo.761.4">args ...) : res_(res) {
    ... </span><span class="koboSpan" id="kobo.761.5">initialize data ...
</span><span class="koboSpan" id="kobo.761.6">  }
  void operator()() { // Callable!
</span><span class="koboSpan" id="kobo.761.7">    ... </span><span class="koboSpan" id="kobo.761.8">do the work ...
</span><span class="koboSpan" id="kobo.761.9">    res_ = ... </span><span class="koboSpan" id="kobo.761.10">result ...
</span><span class="koboSpan" id="kobo.761.11">  }
};
double res = 0;
Job j(TheJob(res, ... </span><span class="koboSpan" id="kobo.761.12">args ...));
j.wait();
std::cout &lt;&lt; res;</span></pre>
<p><span class="koboSpan" id="kobo.762.1">Active objects can </span><a id="_idIndexMarker1212"/><span class="koboSpan" id="kobo.763.1">be found in every concurrent C++ program, but </span><a id="_idIndexMarker1213"/><span class="koboSpan" id="kobo.764.1">some uses of them are common and specialized, and so are recognized as concurrent design patterns in their own right. </span><span class="koboSpan" id="kobo.764.2">We will now see several of </span><span class="No-Break"><span class="koboSpan" id="kobo.765.1">these patterns.</span></span></p>
<h2 id="_idParaDest-334"><a id="_idTextAnchor849"/><span class="koboSpan" id="kobo.766.1">Reactor Object pattern</span></h2>
<p><span class="koboSpan" id="kobo.767.1">The Reactor</span><a id="_idIndexMarker1214"/><span class="koboSpan" id="kobo.768.1"> pattern often uses for event </span><a id="_idIndexMarker1215"/><span class="koboSpan" id="kobo.769.1">handling or responding to service requests. </span><span class="koboSpan" id="kobo.769.2">It solves a specific problem where we have multiple requests for certain actions that are issued by multiple threads; however, the nature of these actions is such that at least part of them must be executed on one thread or otherwise synchronized. </span><span class="koboSpan" id="kobo.769.3">The reactor object is the object that services these requests: it accepts requests from multiple threads and </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">executes them.</span></span></p>
<p><span class="koboSpan" id="kobo.771.1">Here is an example of a reactor that can accept requests to perform a specific computation with caller-supplied inputs and store the results. </span><span class="koboSpan" id="kobo.771.2">The requests can come from any number of threads. </span><span class="koboSpan" id="kobo.771.3">Each request is allocated a slot in the array of results – that is the part that must be synchronized across all threads. </span><span class="koboSpan" id="kobo.771.4">After the slot is allocated, we can do the computations concurrently. </span><span class="koboSpan" id="kobo.771.5">To implement this reactor, we are going to use the atomic index</span><a id="_idIndexMarker1216"/><span class="koboSpan" id="kobo.772.1"> to allocate unique array </span><a id="_idIndexMarker1217"/><span class="koboSpan" id="kobo.773.1">slots to </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">each request:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.775.1">
// Example 25
class Reactor {
  static constexpr size_t N = 1024;
  Data data_[N] {};
  std::atomic&lt;size_t&gt; size_{0};
  public:
  bool operator()(... </span><span class="koboSpan" id="kobo.775.2">args ...) {
    const size_t s =
      size_.fetch_add(1, std::memory_order_acq_rel);
    if (s &gt;= N) return false;  // Array is full
    data_[s] = ... </span><span class="koboSpan" id="kobo.775.3">result ...;
    return true;
  }
  void print_results() { ... </span><span class="koboSpan" id="kobo.775.4">}
};</span></pre>
<p><span class="koboSpan" id="kobo.776.1">The calls to </span><strong class="source-inline"><span class="koboSpan" id="kobo.777.1">operator()</span></strong><span class="koboSpan" id="kobo.778.1"> are thread-safe: any number of threads can call this operator simultaneously, and each call will add the result of the computation to the next array slot without overwriting any data produced by other calls. </span><span class="koboSpan" id="kobo.778.2">To retrieve the results from the object, we can either wait until all requests are done or implement another synchronization mechanism such as the publishing protocol to make calls to </span><strong class="source-inline"><span class="koboSpan" id="kobo.779.1">operator()</span></strong><span class="koboSpan" id="kobo.780.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.781.1">print_results()</span></strong><span class="koboSpan" id="kobo.782.1"> thread-safe with respect to </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">each other.</span></span></p>
<p><span class="koboSpan" id="kobo.784.1">Note that usually, a reactor object processes requests asynchronously: it has a separate thread to execute the computations and a queue to channel all the requests to a single thread. </span><span class="koboSpan" id="kobo.784.2">We can build such a reactor by combining several patterns we saw earlier, for example, we can add a thread-safe queue to our basic reactor to get an asynchronous reactor (we are about to see an example of such </span><span class="No-Break"><span class="koboSpan" id="kobo.785.1">a design).</span></span></p>
<p><span class="koboSpan" id="kobo.786.1">So far, we focused</span><a id="_idIndexMarker1218"/><span class="koboSpan" id="kobo.787.1"> on starting and executing</span><a id="_idIndexMarker1219"/><span class="koboSpan" id="kobo.788.1"> jobs, and then we wait for the work to complete. </span><span class="koboSpan" id="kobo.788.2">The next pattern focuses on handling the completion of </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">asynchronous tasks.</span></span></p>
<h2 id="_idParaDest-335"><a id="_idTextAnchor850"/><span class="koboSpan" id="kobo.790.1">Proactor Object pattern</span></h2>
<p><span class="koboSpan" id="kobo.791.1">The Proactor</span><a id="_idIndexMarker1220"/><span class="koboSpan" id="kobo.792.1"> pattern is used to execute </span><a id="_idIndexMarker1221"/><span class="koboSpan" id="kobo.793.1">asynchronous tasks, usually long-running, by requests from one or more threads. </span><span class="koboSpan" id="kobo.793.2">This sounds a lot like the Reactor, but the difference is what happens when a task is done: in the case of the Reactor, we just have to wait for the work to get done (the wait can be blocking or non-blocking, but in all cases, the caller initiates the check for completion). </span><span class="koboSpan" id="kobo.793.3">The Proactor object associates each task with a callback, and the callback is executed asynchronously when the task is done. </span><span class="koboSpan" id="kobo.793.4">The Reactor and the Proactor are the synchronous and asynchronous solutions to the same problem: handling the completion of </span><span class="No-Break"><span class="koboSpan" id="kobo.794.1">concurrent tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.795.1">A proactor object typically has a queue of tasks to be executed asynchronously or uses another executor to schedule these tasks. </span><span class="koboSpan" id="kobo.795.2">Each task is submitted with a callback, usually a callable. </span><span class="koboSpan" id="kobo.795.3">The callback is executed when the task is done; often, the same thread that executed the task will also invoke the callback. </span><span class="koboSpan" id="kobo.795.4">Since the callback is always asynchronous, care must be taken if it needs to modify any shared data (for example, any data that is accessed by the thread that submitted the task to the proactor). </span><span class="koboSpan" id="kobo.795.5">If there is any data shared between the callback and other threads, it must be accessed in a </span><span class="No-Break"><span class="koboSpan" id="kobo.796.1">thread-safe way.</span></span></p>
<p><span class="koboSpan" id="kobo.797.1">Here is an example of a proactor object that uses the thread-safe queue from the previous section. </span><span class="koboSpan" id="kobo.797.2">In this example, each task takes one integer as input and computes a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.798.1">double</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.799.1"> result:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.800.1">
// Example 26
class Proactor {
  using callback_t = std::function&lt;void(size_t, double)&gt;;
  struct op_task {
    size_t n;
    callback_t f;
  };
  std::atomic&lt;bool&gt; done_{false}; // Must come before t_
  ts_queue&lt;op_task&gt; q_;           // Must come before t_
  std::thread t_;
  public:
  Proactor() : t_([this]() {
    while (true) {
      auto task = q_.pop();
      if (!task) {                // Queue is empty
        if (done_.load(std::memory_order_relaxed)) {
          return;                 // Work is done
        }
        continue;                 // Wait for more work
      }
      ... </span><span class="koboSpan" id="kobo.800.2">do the work ...
</span><span class="koboSpan" id="kobo.800.3">      double x = ... </span><span class="koboSpan" id="kobo.800.4">result ...
</span><span class="koboSpan" id="kobo.800.5">      task-&gt;f(n, x);
    } // while (true)
  }) {}
  template &lt;typename F&gt;
  void operator()(size_t n, F&amp;&amp; f) {
    q_.push(op_task{n, std::forward&lt;F&gt;(f)});
  }
  ~Proactor() {
    done_.store(true, std::memory_order_relaxed);
    t_.join();
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.801.1">The queue stores the work requests which consist of the input and the callable; any number of threads can call </span><strong class="source-inline"><span class="koboSpan" id="kobo.802.1">operator()</span></strong><span class="koboSpan" id="kobo.803.1"> to add requests to the queue. </span><span class="koboSpan" id="kobo.803.2">A more generic proactor might take a callable for the work request instead of having the computation coded into the concrete proactor object. </span><span class="koboSpan" id="kobo.803.3">The proactor executes all the requests in order on a single thread. </span><span class="koboSpan" id="kobo.803.4">When the requested computation is done, the thread invokes the callback and passes the result to it. </span><span class="koboSpan" id="kobo.803.5">This is how we may use such a </span><span class="No-Break"><span class="koboSpan" id="kobo.804.1">proactor object:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.805.1">
// Example 26
Proactor p;
for (size_t n : ... </span><span class="koboSpan" id="kobo.805.2">all inputs ...) {
  p(n, [](double x) { std::cout &lt;&lt; x &lt;&lt; std::endl; });
}</span></pre>
<p><span class="koboSpan" id="kobo.806.1">Note that our proactor executes all callbacks on one thread, and the main thread does not do any output. </span><span class="koboSpan" id="kobo.806.2">Otherwise, we would have to protect </span><strong class="source-inline"><span class="koboSpan" id="kobo.807.1">std::cout</span></strong><span class="koboSpan" id="kobo.808.1"> with </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">a mutex.</span></span></p>
<p><span class="koboSpan" id="kobo.810.1">The Proactor </span><a id="_idIndexMarker1222"/><span class="koboSpan" id="kobo.811.1">pattern</span><a id="_idIndexMarker1223"/><span class="koboSpan" id="kobo.812.1"> is used to both execute asynchronous events and perform additional actions (callbacks) when these events happen. </span><span class="koboSpan" id="kobo.812.2">The last pattern we explore in this section does not execute anything but is used to react to </span><span class="No-Break"><span class="koboSpan" id="kobo.813.1">external events.</span></span></p>
<h2 id="_idParaDest-336"><a id="_idTextAnchor851"/><span class="koboSpan" id="kobo.814.1">Monitor pattern</span></h2>
<p><span class="koboSpan" id="kobo.815.1">The Monitor</span><a id="_idIndexMarker1224"/><span class="koboSpan" id="kobo.816.1"> pattern</span><a id="_idIndexMarker1225"/><span class="koboSpan" id="kobo.817.1"> is used when we need to observe, or monitor, some conditions and respond to certain events. </span><span class="koboSpan" id="kobo.817.2">Usually, a monitor runs on its own thread that is sleeping or waiting most of the time. </span><span class="koboSpan" id="kobo.817.3">The thread is awakened either by a notification or simply by the passage of time. </span><span class="koboSpan" id="kobo.817.4">Once awakened, the monitor object examines the state of the system it is tasked to observe. </span><span class="koboSpan" id="kobo.817.5">It may take certain actions if the specified conditions are met, then the thread goes back </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1">to waiting.</span></span></p>
<p><span class="koboSpan" id="kobo.819.1">We are going to see a monitor implementation that uses a timeout; a monitor with a condition variable can be implemented using the same approach but with the waiting on notification pattern as seen earlier in </span><span class="No-Break"><span class="koboSpan" id="kobo.820.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.821.1">First, we need something to monitor. </span><span class="koboSpan" id="kobo.821.2">Let us say that we have several producer threads that do some computations and store results in an array using an </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">atomic index:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.823.1">
// Example 27
static constexpr size_t N = 1UL &lt;&lt; 16;
struct Data {... </span><span class="koboSpan" id="kobo.823.2">data ... </span><span class="koboSpan" id="kobo.823.3">};
Data data[N] {};
std::atomic&lt;size_t&gt; index(0);
void produce(std::atomic&lt;size_t&gt;&amp; count) {
  for (size_t n = 0; ; ++n) {
    const size_t s =
      index.fetch_add(1, std::memory_order_acq_rel);
    if (s &gt;= N) return;
    const int niter = 1 &lt;&lt; (8 + data[s].n);
    data[s] = ... </span><span class="koboSpan" id="kobo.823.4">result ...
</span><span class="koboSpan" id="kobo.823.5">    count.store(n + 1, std::memory_order_relaxed);
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.824.1">Our producer</span><a id="_idIndexMarker1226"/><span class="koboSpan" id="kobo.825.1"> also</span><a id="_idIndexMarker1227"/><span class="koboSpan" id="kobo.826.1"> stores the count of results computed by the thread in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.827.1">count</span></strong><span class="koboSpan" id="kobo.828.1"> variable passed to it. </span><span class="koboSpan" id="kobo.828.2">Here is how we launch the </span><span class="No-Break"><span class="koboSpan" id="kobo.829.1">producer threads:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.830.1">
// Example 27
std::thread t[nthread];
std::atomic&lt;size_t&gt; work_count[nthread] = {};
for (size_t i = 0; i != nthread; ++i) {
  t[i] = std::thread(produce, std::ref(work_count[i]));
}</span></pre>
<p><span class="koboSpan" id="kobo.831.1">We have one result count per thread, so each producer has its own count to increment. </span><span class="koboSpan" id="kobo.831.2">Why, then, did we make the counts atomic? </span><span class="koboSpan" id="kobo.831.3">Because the counts are also what we are going to monitor: our monitor thread will periodically report on how much work is done. </span><span class="koboSpan" id="kobo.831.4">Thus, each work count is accessed by two threads, the producer and the monitor, and we need to either use atomic operations or a mutex to avoid </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1">data races.</span></span></p>
<p><span class="koboSpan" id="kobo.833.1">The monitor is going to be a separate thread that wakes up every now and then, reads the values of the result counts, and reports the progress of </span><span class="No-Break"><span class="koboSpan" id="kobo.834.1">the work:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.835.1">
// Example 27
std::atomic&lt;bool&gt; done {false};
std::thread monitor([&amp;]() {
  auto print = [&amp;]() { ... </span><span class="koboSpan" id="kobo.835.2">print work_count[] ... </span><span class="koboSpan" id="kobo.835.3">};
  std::cout &lt;&lt; "work counts:" &lt;&lt; std::endl;
  while (!done.load(std::memory_order_relaxed)) {
    std::this_threa</span><a id="_idTextAnchor852"/><a id="_idTextAnchor853"/><span class="koboSpan" id="kobo.836.1">d::sleep_for(
      std::chrono::duration&lt;double, std::milli&gt;(500));
    print();
  }
  print();
});</span></pre>
<p><span class="koboSpan" id="kobo.837.1">The monitor can </span><a id="_idIndexMarker1228"/><span class="koboSpan" id="kobo.838.1">be </span><a id="_idIndexMarker1229"/><span class="koboSpan" id="kobo.839.1">started before the producer threads, or at any time we need to monitor the progress of the work, and it will report how many results are computed by each producer thread, </span><span class="No-Break"><span class="koboSpan" id="kobo.840.1">for example:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.841.1">
work counts:
1096 1083 957 1046 1116 -&gt; 5298/65536
2286 2332 2135 2242 2335 -&gt; 11330/65536
...
</span><span class="koboSpan" id="kobo.841.2">13153 13061 13154 12979 13189 -&gt; 65536/65536
13153 13061 13154 12979 13189 -&gt; 65536/65536</span></pre>
<p><span class="koboSpan" id="kobo.842.1">Here we used five threads to compute the total of 64K results, and the monitor reports the counts for each thread and the total result count. </span><span class="koboSpan" id="kobo.842.2">To shut down the monitor, we need to set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.843.1">done</span></strong><span class="koboSpan" id="kobo.844.1"> flag and join the </span><span class="No-Break"><span class="koboSpan" id="kobo.845.1">monitor thread:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.846.1">
// Example 27
done.store(true, std::memory_order_relaxed);
monitor.join();</span></pre>
<p><span class="koboSpan" id="kobo.847.1">The other common variant of the Monitor pattern is the one where, instead of waiting on a timer, we wait on a condition. </span><span class="koboSpan" id="kobo.847.2">This monitor is a combination of the basic monitor and the pattern for waiting on a notification that we saw earlier in </span><span class="No-Break"><span class="koboSpan" id="kobo.848.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.849.1">The concurrent programming community has come up with many other patterns for solving common problems related to concurrency; most of these can be used in C++ programs but they are not specific to C++. </span><span class="koboSpan" id="kobo.849.2">There are C++-specific features such as atomic variables that influence the way we implement and use these patterns. </span><span class="koboSpan" id="kobo.849.3">The examples from this chapter should give you enough guidance to be able to adapt any other concurrent pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.850.1">to C++.</span></span></p>
<p><span class="koboSpan" id="kobo.851.1">The description </span><a id="_idIndexMarker1230"/><span class="koboSpan" id="kobo.852.1">of execution patterns mostly </span><a id="_idIndexMarker1231"/><span class="koboSpan" id="kobo.853.1">concludes the brief study of C++ patterns for concurrency. </span><span class="koboSpan" id="kobo.853.2">Before you turn the last page, I want to show you a totally different type of concurrent pattern that is just coming </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1">to C++.</span></span></p>
<h1 id="_idParaDest-337"><a id="_idTextAnchor854"/><span class="koboSpan" id="kobo.855.1">Coroutine patterns in C++</span></h1>
<p><span class="koboSpan" id="kobo.856.1">Coroutines are</span><a id="_idIndexMarker1232"/><span class="koboSpan" id="kobo.857.1"> a very recent addition to C++: they were introduced in C++20, and</span><a id="_idIndexMarker1233"/><span class="koboSpan" id="kobo.858.1"> their present state is a foundation for building libraries and frameworks as opposed to features you should use in the application code directly. </span><span class="koboSpan" id="kobo.858.2">It is a complex feature with many subtle details, and it would take an entire chapter to explain what it does (there is a chapter like that in my book </span><em class="italic"><span class="koboSpan" id="kobo.859.1">The Art of Writing Efficient Programs</span></em><span class="koboSpan" id="kobo.860.1">). </span><span class="koboSpan" id="kobo.860.2">Briefly, coroutines are functions that can suspend and resume themselves. </span><span class="koboSpan" id="kobo.860.3">They cannot be forced to suspend, a coroutine continues to execute until it suspends itself. </span><span class="koboSpan" id="kobo.860.4">They are used to implement what is known as cooperative multitasking, where multiple streams of execution voluntarily yield control to each other rather than being forcibly preempted by </span><span class="No-Break"><span class="koboSpan" id="kobo.861.1">the OS.</span></span></p>
<p><span class="koboSpan" id="kobo.862.1">Every execution pattern we saw in this chapter, and many more, can be implemented using coroutines. </span><span class="koboSpan" id="kobo.862.2">It is, however, too early to say whether this is going to become a common use of coroutines in C++, so we cannot say whether a “proactor coroutine” will ever become a pattern. </span><span class="koboSpan" id="kobo.862.3">One application of coroutines, however, is well on the way to becoming a new pattern in C++: the </span><span class="No-Break"><span class="koboSpan" id="kobo.863.1">coroutine generator.</span></span></p>
<p><span class="koboSpan" id="kobo.864.1">This pattern comes into play when we want to take some computation that is normally done with a complex loop and rewrite it as an iterator. </span><span class="koboSpan" id="kobo.864.2">For example, let us say that we have a 3D array and we want to iterate over all its elements and do some computation on them. </span><span class="koboSpan" id="kobo.864.3">This is easy enough to do with </span><span class="No-Break"><span class="koboSpan" id="kobo.865.1">a loop:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.866.1">
size_t*** a; // 3D array
for (size_t i = 0; i &lt; N1; ++i) {
  for (size_t j = 0; j &lt; N2; ++j) {
    for (size_t k = 0; k &lt; N3; ++k) {
      ... </span><span class="koboSpan" id="kobo.866.2">do work with a[i][j][k] ...
</span><span class="koboSpan" id="kobo.866.3">    }
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.867.1">But it’s hard to </span><a id="_idIndexMarker1234"/><span class="koboSpan" id="kobo.868.1">write </span><a id="_idIndexMarker1235"/><span class="koboSpan" id="kobo.869.1">reusable code this way: if we need to customize the work we do on each array element, we have to modify the inner loop. </span><span class="koboSpan" id="kobo.869.2">It would be much easier if we had an iterator that runs over the entire 3D array. </span><span class="koboSpan" id="kobo.869.3">Unfortunately, to implement this iterator we have to turn the loops inside out: first, we increment </span><strong class="source-inline"><span class="koboSpan" id="kobo.870.1">k</span></strong><span class="koboSpan" id="kobo.871.1"> until it reaches </span><strong class="source-inline"><span class="koboSpan" id="kobo.872.1">N3</span></strong><span class="koboSpan" id="kobo.873.1">; then, we increment </span><strong class="source-inline"><span class="koboSpan" id="kobo.874.1">j</span></strong><span class="koboSpan" id="kobo.875.1"> by one and go back to incrementing </span><strong class="source-inline"><span class="koboSpan" id="kobo.876.1">k</span></strong><span class="koboSpan" id="kobo.877.1">, and so on. </span><span class="koboSpan" id="kobo.877.2">The result is a very convoluted code that reduced many a programmer to counting on their fingers to avoid </span><span class="No-Break"><span class="koboSpan" id="kobo.878.1">one-off errors:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.879.1">
// Example 28
class Iterator {
  const size_t N1, N2, N3;
  size_t*** const a;
  size_t i = 0, j = 0, k = 0;
  bool done = false;
  public:
  Iterator(size_t*** a, size_t N1, size_t N2, size_t N3) :
    N1(N1), N2(N2), N3(N3), a(a) {}
  bool next(size_t&amp; x) {
    if (done) return false;
    x = a[i][j][k];
    if (++k == N3) {
      k = 0;
      if (++j == N2) {
        j = 0;
        if (++i == N1) return (done = true);
      }
    }
    return true;
  }
};</span></pre>
<p><span class="koboSpan" id="kobo.880.1">We even took </span><a id="_idIndexMarker1236"/><span class="koboSpan" id="kobo.881.1">a shortcut</span><a id="_idIndexMarker1237"/><span class="koboSpan" id="kobo.882.1"> and gave our iterator a </span><span class="No-Break"><span class="koboSpan" id="kobo.883.1">non-standard interface:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.884.1">
// Example 28
Iterator it(a, N1, N2, N3);
size_t val;
while (it.next(val)) {
  ... </span><span class="koboSpan" id="kobo.884.2">val is the current array element ...
</span><span class="koboSpan" id="kobo.884.3">}</span></pre>
<p><span class="koboSpan" id="kobo.885.1">The implementation is even more convoluted if we want to conform to the STL </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1">iterator interface.</span></span></p>
<p><span class="koboSpan" id="kobo.887.1">Problems such as this, where a complex function such as our nested loop must be suspended in the middle of the execution so the caller can execute some arbitrary code and resume the suspended function, are an ideal fit for coroutines. </span><span class="koboSpan" id="kobo.887.2">Indeed, a coroutine that produces the same sequence as our iterator looks very simple </span><span class="No-Break"><span class="koboSpan" id="kobo.888.1">and natural:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.889.1">
// Example 28
generator&lt;size_t&gt;
coro(size_t*** a, size_t N1, size_t N2, size_t N3) {
  for (size_t i = 0; i &lt; N1; ++i) {
    for (size_t j = 0; j &lt; N2; ++j) {
      for (size_t k = 0; k &lt; N3; ++k) {
        co_yield a[i][j][k];
      }
    }
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.890.1">That’s it; we have a</span><a id="_idIndexMarker1238"/><span class="koboSpan" id="kobo.891.1"> function </span><a id="_idIndexMarker1239"/><span class="koboSpan" id="kobo.892.1">that takes the parameters necessary to loop over a 3D array, a regular nested loop, and we do something to each element. </span><span class="koboSpan" id="kobo.892.2">The secret is in that innermost line where “something” happens: the C++20 keyword </span><strong class="source-inline"><span class="koboSpan" id="kobo.893.1">co_yield</span></strong><span class="koboSpan" id="kobo.894.1"> suspends the coroutine and returns the value </span><strong class="source-inline"><span class="koboSpan" id="kobo.895.1">a[i][j][k]</span></strong><span class="koboSpan" id="kobo.896.1"> to the caller. </span><span class="koboSpan" id="kobo.896.2">It is very similar to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.897.1">return</span></strong><span class="koboSpan" id="kobo.898.1"> operator, except </span><strong class="source-inline"><span class="koboSpan" id="kobo.899.1">co_yield</span></strong><span class="koboSpan" id="kobo.900.1"> does not exit the coroutine permanently: the caller can resume the coroutine, and the execution continues from the next line </span><span class="No-Break"><span class="koboSpan" id="kobo.901.1">after </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.902.1">co_yield</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.903.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.904.1">The use of this coroutine is </span><span class="No-Break"><span class="koboSpan" id="kobo.905.1">also straightforward:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.906.1">
// Example 28
auto gen = coro(a, N1, N2, N3);
while (true) {
  const size_t val = gen();
  if (!gen) break;
  ... </span><span class="koboSpan" id="kobo.906.2">val is the current array element ...
</span><span class="koboSpan" id="kobo.906.3">}</span></pre>
<p><span class="koboSpan" id="kobo.907.1">The coroutine magic happens inside the generator object that is returned by the coroutine. </span><span class="koboSpan" id="kobo.907.2">Its implementation is anything but simple, and, if you want to write one yourself, you have to become an expert on C++ coroutines (and do so by reading another book or article). </span><span class="koboSpan" id="kobo.907.3">You can find a very minimal implementation in </span><em class="italic"><span class="koboSpan" id="kobo.908.1">Example 28</span></em><span class="koboSpan" id="kobo.909.1">, and, with the help of a good reference for coroutines, you can understand its inner working line by line. </span><span class="koboSpan" id="kobo.909.2">Fortunately, if all you want is to write code like that shown previously, you don’t really have to learn the details of the coroutines: there are several open-source libraries that provide utility types such as the generator (with slightly different interfaces), and in C++23 </span><strong class="source-inline"><span class="koboSpan" id="kobo.910.1">std::generator</span></strong><span class="koboSpan" id="kobo.911.1"> will be added to the </span><span class="No-Break"><span class="koboSpan" id="kobo.912.1">standard library.</span></span></p>
<p><span class="koboSpan" id="kobo.913.1">While it is certainly easier to write the coroutine with a loop and </span><strong class="source-inline"><span class="koboSpan" id="kobo.914.1">co_yield</span></strong><span class="koboSpan" id="kobo.915.1"> than the convoluted inverted loop of the iterator, what is the price of this convenience? </span><span class="koboSpan" id="kobo.915.2">Obviously, you have to either write a generator or find one in a library, but once that is done, are there any more disadvantages to the coroutines? </span><span class="koboSpan" id="kobo.915.3">In general, a coroutine involves more work than</span><a id="_idIndexMarker1240"/><span class="koboSpan" id="kobo.916.1"> a</span><a id="_idIndexMarker1241"/><span class="koboSpan" id="kobo.917.1"> regular function, but the performance of the resulting code depends greatly on the compiler and can vary with seemingly insignificant changes to the code (as is the case for any compiler optimizations). </span><span class="koboSpan" id="kobo.917.2">The coroutines are still quite new and the compilers do not have comprehensive optimizations for them. </span><span class="koboSpan" id="kobo.917.3">That being said, the performance of coroutines can be comparable to that of the hand-crafted iterator. </span><span class="koboSpan" id="kobo.917.4">For our </span><em class="italic"><span class="koboSpan" id="kobo.918.1">Example 28</span></em><span class="koboSpan" id="kobo.919.1">, the current (at the moment of this writing) release of Clang 17 gives the </span><span class="No-Break"><span class="koboSpan" id="kobo.920.1">following results:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.921.1">
Iterator time: 9.20286e-10 s/iteration
Generator time: 6.39555e-10 s/iteration</span></pre>
<p><span class="koboSpan" id="kobo.922.1">On the other hand, GCC 13 gives an advantage to </span><span class="No-Break"><span class="koboSpan" id="kobo.923.1">the iterator:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.924.1">
Iterator time: 6.46543e-10 s/iteration
Generator time: 1.99748e-09 s/iteration</span></pre>
<p><span class="koboSpan" id="kobo.925.1">We can expect the compilers to get better at optimizing coroutines in </span><span class="No-Break"><span class="koboSpan" id="kobo.926.1">the future.</span></span></p>
<p><span class="koboSpan" id="kobo.927.1">Another variant of the coroutine generator is useful when the sequence of values that we want to produce is not limited in advance and we want to generate new elements only when they are needed (lazy generator). </span><span class="koboSpan" id="kobo.927.2">Again, the advantage of coroutines is the simplicity of returning results to the caller from inside of </span><span class="No-Break"><span class="koboSpan" id="kobo.928.1">the loop.</span></span></p>
<p><span class="koboSpan" id="kobo.929.1">Here is a simple random number generator implemented as </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">a coroutine:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.931.1">
// Example 29
generator&lt;size_t&gt; coro(size_t i) {
  while (true) {
    constexpr size_t m = 1234567890, k = 987654321;
    for (size_t j = 0; j != 11; ++j) {
      if (1) i = (i + k) % m; else ++i;
    }
    co_yield i;
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.932.1">This coroutine never</span><a id="_idIndexMarker1242"/><span class="koboSpan" id="kobo.933.1"> ends: it </span><a id="_idIndexMarker1243"/><span class="koboSpan" id="kobo.934.1">suspends itself to return the next pseudo-random number </span><strong class="source-inline"><span class="koboSpan" id="kobo.935.1">i</span></strong><span class="koboSpan" id="kobo.936.1">, and every time it is resumed, the execution jumps back into the infinite loop. </span><span class="koboSpan" id="kobo.936.2">Again, the generator is a rather complex object with a lot of boilerplate code that you would be better off getting from a library (or waiting until C++23). </span><span class="koboSpan" id="kobo.936.3">But once that’s done, the use of the generator is </span><span class="No-Break"><span class="koboSpan" id="kobo.937.1">very simple:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.938.1">
// Example 29
auto gen = coro(42);
size_t random_number = gen();</span></pre>
<p><span class="koboSpan" id="kobo.939.1">Every time you call </span><strong class="source-inline"><span class="koboSpan" id="kobo.940.1">gen()</span></strong><span class="koboSpan" id="kobo.941.1">, you get a new random number (of rather poor quality since we have implemented one of the oldest and simplest pseudo-random number generators, so consider this example useful for illustration only). </span><span class="koboSpan" id="kobo.941.2">The generator can be called as many times as you need; when it is finally destroyed, so is </span><span class="No-Break"><span class="koboSpan" id="kobo.942.1">the coroutine.</span></span></p>
<p><span class="koboSpan" id="kobo.943.1">We will likely see more design patterns that take advantage of coroutines develop in the coming years. </span><span class="koboSpan" id="kobo.943.2">For now, the generator is the only established one, and just recently at that, so it is fitting to conclude the last chapter of the book on C++ design patterns with the newest addition</span><a id="_idIndexMarker1244"/><span class="koboSpan" id="kobo.944.1"> to</span><a id="_idIndexMarker1245"/><span class="koboSpan" id="kobo.945.1"> our </span><span class="No-Break"><span class="koboSpan" id="kobo.946.1">pattern toolbox.</span></span></p>
<h1 id="_idParaDest-338"><a id="_idTextAnchor855"/><span class="koboSpan" id="kobo.947.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.948.1">In this chapter, we explored common C++ solutions</span><a id="_idTextAnchor856"/><span class="koboSpan" id="kobo.949.1"> to the problems of developing concurrent software. </span><span class="koboSpan" id="kobo.949.2">This is a very different type of problem compared to everything we studied before. </span><span class="koboSpan" id="kobo.949.3">Our main concerns here are correctness, specifically, by avoiding data races, and performance. </span><span class="koboSpan" id="kobo.949.4">Synchronization patterns are standard ways to control access to shared data to avoid undefined behavior. </span><span class="koboSpan" id="kobo.949.5">Execution patterns are the basic building blocks of thread schedulers and asynchronous executors. </span><span class="koboSpan" id="kobo.949.6">Finally, the high-level patterns and guidelines for the concurrent design are the ways we, the programmers, keep our </span><a id="_idTextAnchor857"/><span class="koboSpan" id="kobo.950.1">sanity while trying to think about all the things that could happen before, after, or at the same time as </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1">one another.</span></span></p>
<h1 id="_idParaDest-339"><a id="_idTextAnchor858"/><span class="koboSpan" id="kobo.952.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.953.1">What </span><span class="No-Break"><span class="koboSpan" id="kobo.954.1">is concurrency?</span></span></li>
<li><span class="koboSpan" id="kobo.955.1">How does C++ </span><span class="No-Break"><span class="koboSpan" id="kobo.956.1">support concurrency?</span></span></li>
<li><span class="koboSpan" id="kobo.957.1">What are synchronization </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1">design patterns?</span></span></li>
<li><span class="koboSpan" id="kobo.959.1">What are execution </span><span class="No-Break"><span class="koboSpan" id="kobo.960.1">design patterns?</span></span></li>
<li><span class="koboSpan" id="kobo.961.1">What overall guidelines for the design and the architecture of concurrent programs should </span><span class="No-Break"><span class="koboSpan" id="kobo.962.1">be followed?</span></span></li>
<li><span class="koboSpan" id="kobo.963.1">What is a </span><span class="No-Break"><span class="koboSpan" id="kobo.964.1">transactional interface?</span></span></li>
</ol>
</div>


<div id="_idContainer038">
<h1 id="_idParaDest-340"><a id="_idTextAnchor859"/><span class="koboSpan" id="kobo.1.1">Assessments</span></h1>
<h1 id="_idParaDest-341"><a id="_idTextAnchor860"/><span class="koboSpan" id="kobo.2.1">Chapter 1, An Introduction to Inheritance and Polymorphism</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.3.1">Objects and classes are the building blocks of a C++ program. </span><span class="koboSpan" id="kobo.3.2">By combining data and algorithms (</span><em class="italic"><span class="koboSpan" id="kobo.4.1">code</span></em><span class="koboSpan" id="kobo.5.1">) into a single unit, the C++ program represents the components of the system that it models, as well as </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">their interactions.</span></span></li>
<li><span class="koboSpan" id="kobo.7.1">Public inheritance represents an </span><em class="italic"><span class="koboSpan" id="kobo.8.1">is-a</span></em><span class="koboSpan" id="kobo.9.1"> relationship between objects—an object of the derived class can be used as if it was an object of the base class. </span><span class="koboSpan" id="kobo.9.2">This relation implies that the interface of the base class, with its invariants and restrictions, is also a valid interface for the derived class.Unlike public inheritance, private inheritance says nothing about the interfaces. </span><span class="koboSpan" id="kobo.9.3">It expresses a </span><em class="italic"><span class="koboSpan" id="kobo.10.1">has-a</span></em><span class="koboSpan" id="kobo.11.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.12.1">is implemented in terms of </span></em><span class="koboSpan" id="kobo.13.1">relationship. </span><span class="koboSpan" id="kobo.13.2">The derived class reuses the implementation provided by the base class. </span><span class="koboSpan" id="kobo.13.3">For the most part, the same can be accomplished by composition. </span><span class="koboSpan" id="kobo.13.4">Composition should be preferred when possible; however, empty base optimization and (less often) virtual method overrides are valid reasons to use </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">private inheritance.</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">A polymorphic object in C++ is an object whose behavior depends on its type, and the type is not known at compile time (at least at the point where the behavior in question is requested). </span><span class="koboSpan" id="kobo.15.2">An object that is referred to as a base class object can demonstrate the behavior of the derived class if that is its true type. </span><span class="koboSpan" id="kobo.15.3">In C++, polymorphic behavior is implemented using </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">virtual functions.</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Dynamic cast verifies at run time that the destination type of the cast is valid: it must be either the actual type of the object (the type the object was created with) or one if its base types. </span><span class="koboSpan" id="kobo.17.2">It is the latter part, checking all possible base types of an object, that makes dynamic </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">casts expensive.</span></span></li>
</ol>
<h1 id="_idParaDest-342"><a id="_idTextAnchor861"/><span class="koboSpan" id="kobo.19.1">Chapter 2, Class and Function Templates</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.20.1">A template is not a type; it is a </span><em class="italic"><span class="koboSpan" id="kobo.21.1">Factory</span></em><span class="koboSpan" id="kobo.22.1"> for many different types with similar structures. </span><span class="koboSpan" id="kobo.22.2">A template is written in terms of generic types; substituting concrete types for these generic types results in a type generated from </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">the template.</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">There are class, function, and variable templates. </span><span class="koboSpan" id="kobo.24.2">Each kind of template generates the corresponding entities—functions in the case of function templates, classes (types) from class templates, and variables from </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">variable templates.</span></span></li>
<li><span class="koboSpan" id="kobo.26.1">Templates can have type and non-type parameters. </span><span class="koboSpan" id="kobo.26.2">Type parameters are types. </span><span class="koboSpan" id="kobo.26.3">Non-type parameters can be integral or enumerated values or templates (in the case of variadic templates, the placeholders are also </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">non-type parameters).</span></span></li>
<li><span class="koboSpan" id="kobo.28.1">A template instantiation is the code generated by a template. </span><span class="koboSpan" id="kobo.28.2">Usually, the instantiations are implicit; the use of a template forces its instantiation. </span><span class="koboSpan" id="kobo.28.3">An explicit instantiation, without use, is also possible; it generates a type or a function that can be used later. </span><span class="koboSpan" id="kobo.28.4">An explicit specialization of a template is a specialization where all generic types are specified; it is not an instantiation, and no code is generated until the template is used. </span><span class="koboSpan" id="kobo.28.5">It is only an alternative recipe for generating code for these </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">specific types.</span></span></li>
<li><span class="koboSpan" id="kobo.30.1">Usually, the parameter pack is iterated over using recursion. </span><span class="koboSpan" id="kobo.30.2">The compiler will typically inline the code generated by this recursion, so the recursion exists only during compilation (as well as in the head of the programmer reading the code). </span><span class="koboSpan" id="kobo.30.3">In C++17 (and, rarely, in C++14), it is possible to operate on the entire pack </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">without recursion.</span></span></li>
<li><span class="koboSpan" id="kobo.32.1">Lambda expressions are essentially a compact way to declare local classes that can be called like functions. </span><span class="koboSpan" id="kobo.32.2">They are used to effectively store a fragment of code in a variable (or, rather, associate the code with a variable) so that this code can be </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">called later.</span></span></li>
<li><span class="koboSpan" id="kobo.34.1">Concepts impose restrictions on the template parameters. </span><span class="koboSpan" id="kobo.34.2">This can be used to avoid substituting types and instantiating a template that would lead to an error in the body of the template. </span><span class="koboSpan" id="kobo.34.3">In the more complex cases, concepts can be used to disambiguate the choice between multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">template overloads.</span></span></li>
</ol>
<h1 id="_idParaDest-343"><a id="_idTextAnchor862"/><span class="koboSpan" id="kobo.36.1">Chapter 3, Memory and Ownership</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.37.1">Clear memory ownership, and by extension, resource ownership, is one of the key attributes of a good design. </span><span class="koboSpan" id="kobo.37.2">With clear ownership, resources are certain to be created and made available in time for when they are needed, maintained while they are in use, and released/cleaned up when no </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">longer needed.</span></span></li>
<li><span class="koboSpan" id="kobo.39.1">Resource leaks, including memory leaks; dangling handles (resource handles, such as pointers, references, or iterators, pointing to resources that do not exist); multiple attempts to release the same resource; multiple attempts to construct the </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">same resource.</span></span></li>
<li><span class="koboSpan" id="kobo.41.1">Non-ownership, exclusive ownership, shared ownership, as well as conversion between different types of ownership and transfer </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">of ownership.</span></span></li>
<li><span class="koboSpan" id="kobo.43.1">Ownership-agnostic functions and classes should refer to objects by raw pointers and references if the corresponding ownership is handled through owning pointers. </span><span class="koboSpan" id="kobo.43.2">If the objects are owned by rich pointers or containers, the problem becomes more difficult. </span><span class="koboSpan" id="kobo.43.3">If the additional data contained in the rich pointer is not needed or a single element of a container is accessed, raw pointers and references are perfectly adequate. </span><span class="koboSpan" id="kobo.43.4">Otherwise, ideally, we would use a corresponding non-owning reference object like </span><strong class="source-inline"><span class="koboSpan" id="kobo.44.1">std::string_view</span></strong><span class="koboSpan" id="kobo.45.1"> or one of the views from the ranges library. </span><span class="koboSpan" id="kobo.45.2">If none is available, we may have to pass the owning object itself </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">by reference.</span></span></li>
<li><span class="koboSpan" id="kobo.47.1">Exclusive memory ownership is easier to understand and follow the control flow of the program. </span><span class="koboSpan" id="kobo.47.2">It is also </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">more efficient.</span></span></li>
<li><span class="koboSpan" id="kobo.49.1">Preferably, by allocating the object on the stack or as a data member of the owning class (including container classes). </span><span class="koboSpan" id="kobo.49.2">If reference semantics or certain move semantics are needed, a unique pointer should be used. </span><span class="koboSpan" id="kobo.49.3">For conditionally constructed objects, </span><strong class="source-inline"><span class="koboSpan" id="kobo.50.1">std::optional</span></strong><span class="koboSpan" id="kobo.51.1"> is a </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">great solution.</span></span></li>
<li><span class="koboSpan" id="kobo.53.1">Shared ownership should be expressed through a shared pointer such </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">as </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.55.1">std::shared_ptr</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.57.1">Shared ownership in a large system is difficult to manage and may delay the deallocation of resources unnecessarily. </span><span class="koboSpan" id="kobo.57.2">It also has a nontrivial performance overhead, compared to exclusive ownership. </span><span class="koboSpan" id="kobo.57.3">Maintaining shared ownership in a thread-safe concurrent program requires very </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">careful implementation.</span></span></li>
<li><span class="koboSpan" id="kobo.59.1">Views such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.60.1">std::string_view</span></strong><span class="koboSpan" id="kobo.61.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.62.1">std::span</span></strong><span class="koboSpan" id="kobo.63.1">, and views from </span><strong class="source-inline"><span class="koboSpan" id="kobo.64.1">std::ranges</span></strong><span class="koboSpan" id="kobo.65.1"> are essentially non-owning rich pointers. </span><span class="koboSpan" id="kobo.65.2">A string view to a string is what a raw pointer is to a unique pointer: a non-owning object containing the same information as the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">owning object.</span></span></li>
</ol>
<h1 id="_idParaDest-344"><a id="_idTextAnchor863"/><span class="koboSpan" id="kobo.67.1">Chapter 4, Swap - From Simple to Subtle</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.68.1">The swap function exchanges the state of the two objects. </span><span class="koboSpan" id="kobo.68.2">After the swap call, the objects should remain unchanged, except for the names they are </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">accessed by.</span></span></li>
<li><span class="koboSpan" id="kobo.70.1">Swap is usually employed in programs that provide commit-or-rollback semantics; a temporary copy of the result is created first, then swapped into its final destination only if no errors </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">were detected.</span></span></li>
<li><span class="koboSpan" id="kobo.72.1">The use of swap to provide commit-or-rollback semantics assumes that the swap operation itself cannot throw an exception or otherwise fail and leave the swapped objects in an </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">undefined state.</span></span></li>
<li><span class="koboSpan" id="kobo.74.1">A non-member swap function should always be provided, to ensure that the calls to non-member swap are executed correctly. </span><span class="koboSpan" id="kobo.74.2">A member swap function can also be provided, for two reasons—first, it is the only way to swap an object with a temporary, and second, the swap implementation usually needs access to the private data members of the class. </span><span class="koboSpan" id="kobo.74.3">If both are provided, the non-member function should call the member swap function on one of the </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">two parameters.</span></span></li>
<li><span class="koboSpan" id="kobo.76.1">All STL containers and some other standard library classes provide a member function </span><strong class="source-inline"><span class="koboSpan" id="kobo.77.1">swap()</span></strong><span class="koboSpan" id="kobo.78.1">. </span><span class="koboSpan" id="kobo.78.2">In addition, the non-member </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">std::swap() </span></strong><span class="koboSpan" id="kobo.80.1">function template has standard overloads for all </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">STL types.</span></span></li>
<li><span class="koboSpan" id="kobo.82.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.83.1">std:: qualifier</span></strong><span class="koboSpan" id="kobo.84.1"> disables the argument-dependent lookup and forces the default </span><strong class="source-inline"><span class="koboSpan" id="kobo.85.1">std::swap</span></strong><span class="koboSpan" id="kobo.86.1"> template instantiation to be called, even if a custom swap function was implemented with the class. </span><span class="koboSpan" id="kobo.86.2">To avoid this problem, it is recommended to also provide an explicit instantiation of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.87.1">std::swap</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.88.1"> template.</span></span></li>
</ol>
<h1 id="_idParaDest-345"><a id="_idTextAnchor864"/><span class="koboSpan" id="kobo.89.1">Chapter 5, Comprehensive Look at RAII</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.90.1">Memory is the most common resource, but any object can be a resource. </span><span class="koboSpan" id="kobo.90.2">Any virtual or physical quantity that the program operates on is </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">a resource.</span></span></li>
<li><span class="koboSpan" id="kobo.92.1">Resources should not be lost (leaked). </span><span class="koboSpan" id="kobo.92.2">If a resource is accessed through a handle, such as a pointer or an ID, that handle should not be dangling (referring to a resource that does not exist). </span><span class="koboSpan" id="kobo.92.3">Resources should be released when they are no longer needed, in the manner that corresponds to the way they </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">were acquired.</span></span></li>
<li><span class="koboSpan" id="kobo.94.1">Resource Acquisition Is Initialization is an idiom; it is the dominant C++ approach to resource management, where each resource is owned by an object, acquired in the constructor, and released in the destructor of </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">that object.</span></span></li>
<li><span class="koboSpan" id="kobo.96.1">An RAII object should always be created on the stack or as a data member of another object. </span><span class="koboSpan" id="kobo.96.2">When the flow of the program leaves the scope containing the RAII object or the larger object containing the RAII object is deleted, the destructor of the RAII object is executed. </span><span class="koboSpan" id="kobo.96.3">This happens regardless of how the control flow leaves </span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">the scope.</span></span></li>
<li><span class="koboSpan" id="kobo.98.1">If each resource is owned by an RAII object and the RAII object does not give out raw handles (or the user is careful to not clone the raw handle), the handle can only be obtained from the RAII object and the resource is not released as long as that </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">object remains.</span></span></li>
<li><span class="koboSpan" id="kobo.100.1">The most frequently used is </span><strong class="source-inline"><span class="koboSpan" id="kobo.101.1">std::unique_ptr</span></strong><span class="koboSpan" id="kobo.102.1"> for memory management; </span><strong class="source-inline"><span class="koboSpan" id="kobo.103.1">std::lock_guard</span></strong><span class="koboSpan" id="kobo.104.1"> is used to </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">manage mutexes.</span></span></li>
<li><span class="koboSpan" id="kobo.106.1">As a rule, RAII objects must be non-copyable. </span><span class="koboSpan" id="kobo.106.2">Moving an RAII object transfers the ownership of the resource; the classic RAII pattern does not support this, so most RAII objects should be non-movable (differentiate between </span><strong class="source-inline"><span class="koboSpan" id="kobo.107.1">std::unique_ptr</span></strong><span class="koboSpan" id="kobo.108.1"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.109.1">const std::unique_ptr</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">).</span></span></li>
<li><span class="koboSpan" id="kobo.111.1">RAII has difficulty handing release failures, because exceptions cannot propagate from the destructors, and hence there is no good way to report the failure to the caller. </span><span class="koboSpan" id="kobo.111.2">For that reason, failing to release a resource often results in undefined behavior (this approach is sometimes taken by the C++ standard </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">as well).</span></span></li>
</ol>
<h1 id="_idParaDest-346"><a id="_idTextAnchor865"/><span class="koboSpan" id="kobo.113.1">Chapter 6, Understanding Type Erasure</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.114.1">Type erasure is a programming technique where the program, as written, does not show an explicit dependence on some of the types it uses. </span><span class="koboSpan" id="kobo.114.2">It is a powerful design tool when used for separating abstract behavior from a </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">particular implementation.</span></span></li>
<li><span class="koboSpan" id="kobo.116.1">The implementation involves either a polymorphic object and a virtual function call, or a function that is implemented specifically for the erased type and is invoked through a function pointer. </span><span class="koboSpan" id="kobo.116.2">Usually, this is combined with generic programming to construct such polymorphic objects or generate functions from a template automatically and ensure that the reified type is always the same as the one provided </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">during construction.</span></span></li>
<li><span class="koboSpan" id="kobo.118.1">A program may be written in a way that avoids explicit mention of most types. </span><span class="koboSpan" id="kobo.118.2">The types are deduced by template functions and declared as </span><strong class="source-inline"><span class="koboSpan" id="kobo.119.1">auto</span></strong><span class="koboSpan" id="kobo.120.1"> or as template-deduced typedef types. </span><span class="koboSpan" id="kobo.120.2">However, the actual types of objects that are hidden by </span><strong class="source-inline"><span class="koboSpan" id="kobo.121.1">auto</span></strong><span class="koboSpan" id="kobo.122.1"> still depend on all types the object operates on (such as the deleter type for a pointer). </span><span class="koboSpan" id="kobo.122.2">The erased type is not captured by the object type at all. </span><span class="koboSpan" id="kobo.122.3">In other words, if you could get the compiler to tell you what this particular auto stands for, all types would be explicitly there. </span><span class="koboSpan" id="kobo.122.4">But if the type was erased, even the most detailed declaration of the containing object will not reveal it (such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.123.1">std::shared_ptr&lt;int&gt;</span></strong><span class="koboSpan" id="kobo.124.1"> —this is the entire type, the deleter type is </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">not there).</span></span></li>
<li><span class="koboSpan" id="kobo.126.1">The type is reified by the function that is generated for that type: while its signature (arguments) does not depend on the erased type, the body of the function does. </span><span class="koboSpan" id="kobo.126.2">Usually, the first step is casting one of the arguments from a generic pointer such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.127.1">void*</span></strong><span class="koboSpan" id="kobo.128.1"> to the pointer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">erased type.</span></span></li>
<li><span class="koboSpan" id="kobo.130.1">The performance of type erasure always incurs some overhead compared to invoking the same callable directly: there is always an extra indirection and the pointer associated with it. </span><span class="koboSpan" id="kobo.130.2">Almost all implementations use runtime polymorphism (virtual functions or dynamic casts) or the equivalent virtual table of function pointers, which increases both the time (indirect function calls) and memory (virtual pointers). </span><span class="koboSpan" id="kobo.130.3">The greatest overhead usually comes from additional memory allocations, necessary for storing objects whose size is not known at compile time. </span><span class="koboSpan" id="kobo.130.4">If such allocations can be minimized and the additional memory made local to the object, the total overhead at runtime may be quite small (the overhead in memory remains and is often increased by </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">such optimizations).</span></span></li>
</ol>
<h1 id="_idParaDest-347"><a id="_idTextAnchor866"/><span class="koboSpan" id="kobo.132.1">Chapter 7, SFINAE, Concepts, and Overload Resolution Management</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.133.1">For each function call, it is the set of all functions with the specified name that are accessible from the call location (the accessibility may be affected by the namespaces, nested scopes, and </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">so on).</span></span></li>
<li><span class="koboSpan" id="kobo.135.1">It is the process of selecting which function in the overload set is going to be called, given the arguments and </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">their types.</span></span></li>
<li><span class="koboSpan" id="kobo.137.1">For template functions and member functions (and class constructors in C++17), type deduction determines the types of template parameters from the types of the function arguments. </span><span class="koboSpan" id="kobo.137.2">For each parameter, it may be possible to deduce the type from several arguments. </span><span class="koboSpan" id="kobo.137.3">In this case, the results of this deduction must be the same, otherwise, the type deduction fails. </span><span class="koboSpan" id="kobo.137.4">Once the template parameter types are deduced, the concrete types are substituted for the template parameters in all arguments, the return type, and the default arguments. </span><span class="koboSpan" id="kobo.137.5">This is a </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">type substitution.</span></span></li>
<li><span class="koboSpan" id="kobo.139.1">Type substitution, described previously, can result in invalid types, such as a member function pointer for a type that has no member functions. </span><span class="koboSpan" id="kobo.139.2">Such substitution failures do not generate compilation errors; instead, the failing overload is removed from the </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">overload set.</span></span></li>
<li><span class="koboSpan" id="kobo.141.1">This is only in the function declaration (return type, parameter types, and default values). </span><span class="koboSpan" id="kobo.141.2">Substitution failures in the body of the function chosen by the overload resolution are </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">hard errors.</span></span></li>
<li><span class="koboSpan" id="kobo.143.1">If each overload returns a different type, these types can be examined at compile time. </span><span class="koboSpan" id="kobo.143.2">The types must have some way to distinguish them, for example, different sizes or different values of embedded constants. </span><span class="koboSpan" id="kobo.143.3">For </span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1">constexpr</span></strong><span class="koboSpan" id="kobo.145.1"> functions, we can also examine the return values (the function needs the body in </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">this case).</span></span></li>
<li><span class="koboSpan" id="kobo.147.1">It is used with great care and caution. </span><span class="koboSpan" id="kobo.147.2">By deliberately causing substitution failures, we can direct the overload resolution toward a particular overload. </span><span class="koboSpan" id="kobo.147.3">Generally, the desired overload is preferred unless it fails; otherwise, the variadic overload remains and is chosen, indicating that the expression we wanted to test was invalid. </span><span class="koboSpan" id="kobo.147.4">By differentiating between the overloads using their return types, we can generate a compile-time (</span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1">constexpr</span></strong><span class="koboSpan" id="kobo.149.1">) constant that can be used in </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">conditional compilation.</span></span></li>
<li><span class="koboSpan" id="kobo.151.1">C++20 constraints offer a more natural, easier-to-understand syntax. </span><span class="koboSpan" id="kobo.151.2">They also result in much clearer error messages when a called function does not meet the requirements. </span><span class="koboSpan" id="kobo.151.3">Also, unlike SFINAE, constraints are not limited to the substituted parameters of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">function templates.</span></span></li>
<li><span class="koboSpan" id="kobo.153.1">The standard did not just define concepts and constraints in the language. </span><span class="koboSpan" id="kobo.153.2">It also offers a way of thinking about template restrictions. </span><span class="koboSpan" id="kobo.153.3">While a wide range of SFINAE-based techniques exists, the code is easier to read and maintain if the use of SFINAE is restricted to a few powerful approaches that resemble the use </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">of concepts.</span></span></li>
</ol>
<h1 id="_idParaDest-348"><a id="_idTextAnchor867"/><span class="koboSpan" id="kobo.155.1">Chapter 8, The Curiously Recurring Template Pattern</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.156.1">While not very expensive in absolute numbers (a few nanoseconds at most), a virtual function call is several times more expensive than a non-virtual one, and could easily be an order of magnitude or more slower than an inlined function call. </span><span class="koboSpan" id="kobo.156.2">The overhead comes from the indirection: a virtual function is always invoked by a function pointer, and the actual function is unknown at compile time and cannot </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">be inlined.</span></span></li>
<li><span class="koboSpan" id="kobo.158.1">If the compiler knows the exact function that is going to be called, it can optimize away the indirection and may be able to inline </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">the function.</span></span></li>
<li><span class="koboSpan" id="kobo.160.1">Just like the runtime polymorphic calls are made through the pointer to the base class, the static polymorphic calls must be also made through a pointer or reference to the base class. </span><span class="koboSpan" id="kobo.160.2">In the case of CRTP and static polymorphism, the base type is actually a whole collection of types generated by the base class template, one for each derived class. </span><span class="koboSpan" id="kobo.160.3">To make a polymorphic call we have to use a function template that can be instantiated on any of these </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">base types.</span></span></li>
<li><span class="koboSpan" id="kobo.162.1">When the derived class is called directly, the use of CRTP is quite different from the compile-time equivalent of the virtual functions. </span><span class="koboSpan" id="kobo.162.2">It becomes an implementation technique, where common functionality is provided to multiple derived classes, and each one expands and customizes the interface of the base </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">class template.</span></span></li>
<li><span class="koboSpan" id="kobo.164.1">Strictly speaking, nothing new is needed to use multiple CRTP bases: the derived class can inherit from several such base types, each an instantiation of a CRTP base class template. </span><span class="koboSpan" id="kobo.164.2">However, listing these based together with the correct template parameter (derived class itself) for each one becomes cumbersome. </span><span class="koboSpan" id="kobo.164.3">It is easier and less error-prone to declare the derived class as a variadic template with a template template parameter and inherit from the entire </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">parameter pack.</span></span></li>
</ol>
<h1 id="_idParaDest-349"><a id="_idTextAnchor868"/><span class="koboSpan" id="kobo.166.1">Chapter 9, Named Arguments, Method Chaining, and the Builder Pattern</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.167.1">It is easy to miscount arguments, change the wrong argument, or use an argument of the wrong type that happens to convert to the parameter type. </span><span class="koboSpan" id="kobo.167.2">Also, adding a new parameter requires changing all function signatures that must pass these </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">parameters along.</span></span></li>
<li><span class="koboSpan" id="kobo.169.1">The argument values within the aggregate have explicit names. </span><span class="koboSpan" id="kobo.169.2">Adding a new value does not require changing the function signatures. </span><span class="koboSpan" id="kobo.169.3">Classes made for different groups of arguments have different types and cannot be </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">accidentally mixed.</span></span></li>
<li><span class="koboSpan" id="kobo.171.1">The named argument idiom permits the use of temporary aggregate objects. </span><span class="koboSpan" id="kobo.171.2">Instead of changing each data member by name, we write a method to set the value of each argument. </span><span class="koboSpan" id="kobo.171.3">All such methods return a reference to the object itself and can be chained together in </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">one statement.</span></span></li>
<li><span class="koboSpan" id="kobo.173.1">Method cascading applies multiple methods to the same object. </span><span class="koboSpan" id="kobo.173.2">In a method chain, in general, each method returns a new object and the next method applies to it. </span><span class="koboSpan" id="kobo.173.3">Often, method chaining is used to cascade methods. </span><span class="koboSpan" id="kobo.173.4">In this case, all chained methods return the reference to the </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">original object.</span></span></li>
<li><span class="koboSpan" id="kobo.175.1">The Builder pattern is a design pattern that uses a separate builder object to construct complex objects. </span><span class="koboSpan" id="kobo.175.2">It is used when a constructor is not sufficient or not easy to use to construct an object in its desired fully built state. </span><span class="koboSpan" id="kobo.175.3">The need for a builder can arise when the constructor of the object being built cannot be modified (a general object used for a particular purpose), when a desired constructor would have many similar arguments and be hard to use when the construction process is complex, or when the construction process is computationally expensive but some of the results can </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">be reused.</span></span></li>
<li><span class="koboSpan" id="kobo.177.1">The fluent interface is an interface that uses method chaining to present multiple instructions, commands, or operations that can be executed on an object. </span><span class="koboSpan" id="kobo.177.2">In particular, fluent builders are used in C++ to split complex object construction into multiple smaller steps. </span><span class="koboSpan" id="kobo.177.3">Some of these steps can be conditional or depend on </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">other data.</span></span></li>
</ol>
<h1 id="_idParaDest-350"><a id="_idTextAnchor869"/><span class="koboSpan" id="kobo.179.1">Chapter 10, Local Buffer Optimization</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.180.1">Micro-benchmarks can measure the performance of small fragments of code in isolation. </span><span class="koboSpan" id="kobo.180.2">To measure the performance of the same fragment in the context of a program, we have to use </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">a profiler.</span></span></li>
<li><span class="koboSpan" id="kobo.182.1">Processing small amounts of data usually involve a correspondingly small amount of computing and are therefore very fast. </span><span class="koboSpan" id="kobo.182.2">Memory allocation adds a constant overhead, not proportional to the data size. </span><span class="koboSpan" id="kobo.182.3">The relative impact is larger when the processing time is short. </span><span class="koboSpan" id="kobo.182.4">In addition, memory allocation may use a global lock or otherwise serialize </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">multiple threads.</span></span></li>
<li><span class="koboSpan" id="kobo.184.1">Local buffer optimization replaces external memory allocation with a buffer that is a part of the object itself. </span><span class="koboSpan" id="kobo.184.2">This avoids the cost, and the overhead, of an additional </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">memory allocation.</span></span></li>
<li><span class="koboSpan" id="kobo.186.1">The object has to be constructed and the memory for it must be allocated, regardless of whether any secondary allocations happen. </span><span class="koboSpan" id="kobo.186.2">This allocation has some cost – more if the object is allocated on the heap and less if it’s a stack variable – but that cost must be paid before the object can be used. </span><span class="koboSpan" id="kobo.186.3">Local buffer optimization increases the size of the object and therefore of the original allocation, but that usually does not significantly affect the cost of </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">that allocation.</span></span></li>
<li><span class="koboSpan" id="kobo.188.1">Short string optimization involves storing string characters in a local buffer contained inside the string object, up to a certain length of </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">the string.</span></span></li>
<li><span class="koboSpan" id="kobo.190.1">Small vector optimization involves storing a few elements of the vector’s content in a local buffer contained in the </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">vector object.</span></span></li>
</ol>
<h1 id="_idParaDest-351"><a id="_idTextAnchor870"/><span class="koboSpan" id="kobo.192.1">Chapter 11, ScopeGuard</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.193.1">An error-safe program maintains a well-defined state (a set of invariants) even if it encounters an error. </span><span class="koboSpan" id="kobo.193.2">Exception safety is a particular kind of error safety; it assumes that errors are signaled by throwing expressions. </span><span class="koboSpan" id="kobo.193.3">The program must not enter an undefined state when an (allowed) expression is thrown. </span><span class="koboSpan" id="kobo.193.4">An exception-safe program may require that certain operations do not </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">throw exceptions.</span></span></li>
<li><span class="koboSpan" id="kobo.195.1">If a consistent state must be maintained across several actions, each of which may fail, then the prior actions must be undone if a subsequent action fails. </span><span class="koboSpan" id="kobo.195.2">This often requires that the actions do not commit fully until the end of the transaction is reached successfully. </span><span class="koboSpan" id="kobo.195.3">The final commit operation must not fail (for example, throw an exception), otherwise error safety cannot be guaranteed. </span><span class="koboSpan" id="kobo.195.4">The rollback operation also must </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">not fail.</span></span></li>
<li><span class="koboSpan" id="kobo.197.1">RAII classes ensure that a certain action is always taken when the program leaves a scope, such as a function. </span><span class="koboSpan" id="kobo.197.2">With RAII, the closing action cannot be skipped or bypassed, even if the function exits the scope prematurely with an early return or by throwing </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">an exception.</span></span></li>
<li><span class="koboSpan" id="kobo.199.1">The classic RAII needs a special class for every action. </span><span class="koboSpan" id="kobo.199.2">ScopeGuard automatically generates an RAII class from an arbitrary code fragment (at least, if lambda expressions </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">are supported).</span></span></li>
<li><span class="koboSpan" id="kobo.201.1">If the status is returned through error codes, it cannot. </span><span class="koboSpan" id="kobo.201.2">If all errors in the program are signaled by exceptions and any return from a function is a success, we can detect at runtime whether an exception was thrown. </span><span class="koboSpan" id="kobo.201.3">The complication is that the guarded operation may itself take place during stack unwinding caused by another exception. </span><span class="koboSpan" id="kobo.201.4">That exception is propagating when the guard class has to decide whether the operation succeeded or failed, but its presence does not indicate the failure of the guarded operation (it may indicate that something else failed elsewhere). </span><span class="koboSpan" id="kobo.201.5">Robust exception detection must keep track of how many exceptions are propagating at the beginning and at the end of the guarded scope, which is possible only in C++17 (or using </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">compiler extensions).</span></span></li>
<li><span class="koboSpan" id="kobo.203.1">The ScopeGuard classes are usually template instantiations. </span><span class="koboSpan" id="kobo.203.2">This means that the concrete type of the ScopeGuard is unknown to the programmer, or at least difficult to specify explicitly. </span><span class="koboSpan" id="kobo.203.3">The ScopeGuard relies on lifetime extension and template argument deduction to manage this complexity. </span><span class="koboSpan" id="kobo.203.4">A type-erased ScopeGuard is a concrete type; it does not depend on the code it holds. </span><span class="koboSpan" id="kobo.203.5">The downside is that type erasure requires runtime polymorphism and, most of the time, a </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">memory allocation.</span></span></li>
</ol>
<h1 id="_idParaDest-352"><a id="_idTextAnchor871"/><span class="koboSpan" id="kobo.205.1">Chapter 12, Friend Factory</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.206.1">A non-member friend function has the same access to the members of the class as a </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">member function.</span></span></li>
<li><span class="koboSpan" id="kobo.208.1">Granting friendship to a template makes every instantiation of this template a friend; this includes instantiations of the same template but with different, </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">unrelated, types.</span></span></li>
<li><span class="koboSpan" id="kobo.210.1">Binary operators implemented as member functions are always called on the left-hand-side operand of the operator, with no conversions allowed for that object. </span><span class="koboSpan" id="kobo.210.2">Conversions are allowed for the right-hand-side operand, according to the type of the argument of the member operator. </span><span class="koboSpan" id="kobo.210.3">This creates an asymmetry between expressions such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1">x + 2</span></strong><span class="koboSpan" id="kobo.212.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">2 + x</span></strong><span class="koboSpan" id="kobo.214.1">, where the latter cannot be handled by a member function since the type of </span><strong class="source-inline"><span class="koboSpan" id="kobo.215.1">2</span></strong><span class="koboSpan" id="kobo.216.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.217.1">int</span></strong><span class="koboSpan" id="kobo.218.1">) does not </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">have any.</span></span></li>
<li><span class="koboSpan" id="kobo.220.1">The first operand of the inserter is always the stream, not the object that is printed. </span><span class="koboSpan" id="kobo.220.2">Therefore, a member function would have to be on that stream, which is a part of the standard library; it cannot be extended by the user to include </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">user-defined types.</span></span></li>
<li><span class="koboSpan" id="kobo.222.1">While the details are complex, the main difference is that user-defined conversions (implicit constructors and conversion operators) are considered when calling non-template functions but, for template functions, the argument types must match the parameter types (almost) exactly, and no user-defined conversions </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">are permitted.</span></span></li>
<li><span class="koboSpan" id="kobo.224.1">Defining an in situ friend function (with the definition immediately following the declaration) in a class template causes every instantiation of that template to generate one non-template, non-member function with the given name and parameter types in the </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">containing scope.</span></span></li>
</ol>
<h1 id="_idParaDest-353"><a id="_idTextAnchor872"/><span class="koboSpan" id="kobo.226.1">Chapter 13, Virtual Constructors and Factories</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.227.1">There are several reasons, but the simplest is that the memory must be allocated in the amount </span><strong class="source-inline"><span class="koboSpan" id="kobo.228.1">sizeof(T)</span></strong><span class="koboSpan" id="kobo.229.1">, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.230.1">T</span></strong><span class="koboSpan" id="kobo.231.1"> is the actual object type, and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.232.1">sizeof()</span></strong><span class="koboSpan" id="kobo.233.1"> operator is </span><strong class="source-inline"><span class="koboSpan" id="kobo.234.1">constexpr</span></strong><span class="koboSpan" id="kobo.235.1"> (a </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">compile-time constant).</span></span></li>
<li><span class="koboSpan" id="kobo.237.1">The Factory pattern is a creational pattern that solves the problem of creating objects without having to explicitly specify the type of </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">the object.</span></span></li>
<li><span class="koboSpan" id="kobo.239.1">While in C++ the actual type has to be specified at the construction point, the Factory pattern allows us to separate the point of construction from the place where the program has to decide what object to construct and identify the type using some alternative identifier, a number, a value, or </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">another type.</span></span></li>
<li><span class="koboSpan" id="kobo.241.1">The virtual copy constructor is a particular kind of factory where the object to construct is identified by the type of another object we already have. </span><span class="koboSpan" id="kobo.241.2">A typical implementation involves a virtual </span><strong class="source-inline"><span class="koboSpan" id="kobo.242.1">clone()</span></strong><span class="koboSpan" id="kobo.243.1"> method that is overridden in every </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">derived class.</span></span></li>
<li><span class="koboSpan" id="kobo.245.1">The Template pattern describes the design where the overall control flow is dictated by the base class, with derived classes providing customizations at certain predefined points. </span><span class="koboSpan" id="kobo.245.2">In our case, the overall control flow is that of factory construction, and the customization point is the act of construction of an object (memory allocation and </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">constructor invocation).</span></span></li>
<li><span class="koboSpan" id="kobo.247.1">The Builder pattern is used when it is necessary (or just more convenient) to delegate the work of constructing an object to another class instead of doing the complete initialization in the constructor. </span><span class="koboSpan" id="kobo.247.2">An object that constructs other objects of different types depending on some run-time information using the factory method is also a builder. </span><span class="koboSpan" id="kobo.247.3">In addition to the factory itself, such builders, or factory classes, usually have other run-time data that is used for constructing objects and must be stored in another object – in our case, the factory object, which is also the </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">builder object.</span></span></li>
</ol>
<h1 id="_idParaDest-354"><a id="_idTextAnchor873"/><span class="koboSpan" id="kobo.249.1">Chapter 14, The Template Method Pattern and the  Non-Virtual Idiom</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.250.1">A behavioral pattern describes a way to solve a common problem by using a specific method to communicate between </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">different objects.</span></span></li>
<li><span class="koboSpan" id="kobo.252.1">The template method pattern is a standard way to implement an algorithm that has a rigid </span><em class="italic"><span class="koboSpan" id="kobo.253.1">skeleton,</span></em><span class="koboSpan" id="kobo.254.1"> or the overall flow of control, but allows for one or more customization points for specific kinds </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">of problems.</span></span></li>
<li><span class="koboSpan" id="kobo.256.1">The Template Method lets the sub-classes (derived types) implement specific behaviors of the otherwise generic algorithm. </span><span class="koboSpan" id="kobo.256.2">The key to this pattern is the way the base and the derived </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">types interact.</span></span></li>
<li><span class="koboSpan" id="kobo.258.1">The more common hierarchical approach to design sees the low-level code provide </span><em class="italic"><span class="koboSpan" id="kobo.259.1">building blocks</span></em><span class="koboSpan" id="kobo.260.1"> from which the high-level code builds the specific algorithm, by combining them in a particular flow of control. </span><span class="koboSpan" id="kobo.260.2">In the template pattern, the high-level code does not determine the overall algorithm and is not in control of the overall flow. </span><span class="koboSpan" id="kobo.260.3">The lower-level code controls the algorithm and determines when the high-level code is called to adjust specific aspects of </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">the execution.</span></span></li>
<li><span class="koboSpan" id="kobo.262.1">It is a pattern where the public interface of a class hierarchy is implemented by non-virtual public methods of the base class and the derived classes contain only virtual private methods (as well as any necessary data and non-virtual methods needed to </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">implement them).</span></span></li>
<li><span class="koboSpan" id="kobo.264.1">A public virtual function performs two separate tasks – it provides the interface (since it is public) and also modifies the implementation. </span><span class="koboSpan" id="kobo.264.2">A better separation of concerns is to use virtual functions only to customize the implementation and to specify the common interface using the non-virtual functions of the </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">base class.</span></span></li>
<li><span class="koboSpan" id="kobo.266.1">Once the NVI is employed, virtual functions can usually be made private. </span><span class="koboSpan" id="kobo.266.2">One exception is when the derived class needs to invoke a virtual function of the base class to delegate part of the implementation. </span><span class="koboSpan" id="kobo.266.3">In this case, the function should be </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">made protected.</span></span></li>
<li><span class="koboSpan" id="kobo.268.1">Destructors are called in </span><em class="italic"><span class="koboSpan" id="kobo.269.1">nested</span></em><span class="koboSpan" id="kobo.270.1"> order, starting from the most derived class. </span><span class="koboSpan" id="kobo.270.2">When the destructor for the derived class is done, it calls the destructor of the base class. </span><span class="koboSpan" id="kobo.270.3">By that time, the </span><em class="italic"><span class="koboSpan" id="kobo.271.1">extra</span></em><span class="koboSpan" id="kobo.272.1"> information that the derived class contained is already destroyed, and only the base portion is left. </span><span class="koboSpan" id="kobo.272.2">If the base class destructor were to call a virtual function, it would have to be dispatched to the base class (since the derived class is gone by then). </span><span class="koboSpan" id="kobo.272.3">There is no way for the base class destructor to call the virtual functions of the </span><span class="No-Break"><span class="koboSpan" id="kobo.273.1">derived class.</span></span></li>
<li><span class="koboSpan" id="kobo.274.1">The fragile base class problem manifests itself when a change to the base class unintentionally breaks the derived class. </span><span class="koboSpan" id="kobo.274.2">While not specific to the template method, it affects, potentially, all object-oriented designs, including ones based on the template pattern. </span><span class="koboSpan" id="kobo.274.3">In the simplest example, changing the non-virtual public function in the base class, in a way that changes the names of the virtual functions called to customize the behavior of the algorithm, will break all existing derived classes because their current customizations, implemented by the virtual functions with the old names, would suddenly stop working. </span><span class="koboSpan" id="kobo.274.4">To avoid this problem, the existing customization points should not </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">be changed.</span></span></li>
</ol>
<h1 id="_idParaDest-355"><a id="_idTextAnchor874"/><span class="koboSpan" id="kobo.276.1">Chapter 15, Policy-Based Design</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.277.1">The Strategy pattern is a behavioral pattern that allows the user to customize a certain aspect of the behavior of the class by selecting an algorithm that implements this behavior from a set of provided alternatives, or by providing a </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">new implementation.</span></span></li>
<li><span class="koboSpan" id="kobo.279.1">While the traditional OOP Strategy applies at runtime, C++ combines generic programming with the Strategy pattern in a technique known as policy-based design. </span><span class="koboSpan" id="kobo.279.2">In this approach, the primary class template delegates certain aspects of its behavior to the user-specified </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">policy types.</span></span></li>
<li><span class="koboSpan" id="kobo.281.1">In general, there are almost no restrictions on the policy type, although the particular way in which the type is declared and used imposes certain restrictions by convention. </span><span class="koboSpan" id="kobo.281.2">For example, if a policy is invoked as a function, then any callable type can be used. </span><span class="koboSpan" id="kobo.281.3">On the other hand, if a specific member function of the policy is called, the policy must necessarily be a class and provide the required member function. </span><span class="koboSpan" id="kobo.281.4">Template policies can be used as well but must match the specified number of template </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">parameters exactly.</span></span></li>
<li><span class="koboSpan" id="kobo.283.1">The two primary ways are composition and inheritance. </span><span class="koboSpan" id="kobo.283.2">The composition should generally be preferred; however, many policies in practice are empty classes with no data members and can benefit from empty base class optimization. </span><span class="koboSpan" id="kobo.283.3">Private inheritance should be preferred unless the policy must also modify the public interface of the primary class. </span><span class="koboSpan" id="kobo.283.4">Policies that need to operate on the primary policy-based class itself often have to employ CRTP. </span><span class="koboSpan" id="kobo.283.5">In other cases, when the policy object itself does not depend on the types used in the construction of the primary template, the policy behavior can be exposed through a static </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">member function.</span></span></li>
<li><span class="koboSpan" id="kobo.285.1">As a general rule, policies that contain only constants and are used to constrain the public interface are easier to write and maintain. </span><span class="koboSpan" id="kobo.285.2">However, there are several cases when injecting public member functions through the base class policies is preferred: when we also need to add member variables to the class or when the complete set of public functions would be difficult to maintain or lead </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">to conflicts.</span></span></li>
<li><span class="koboSpan" id="kobo.287.1">The primary drawback is complexity, in various manifestations. </span><span class="koboSpan" id="kobo.287.2">Policy-based types with different policies are, generally, different types (the only alternative, type erasure, usually carries a prohibitive runtime overhead). </span><span class="koboSpan" id="kobo.287.3">This may force large parts of the code to be templated as well. </span><span class="koboSpan" id="kobo.287.4">Long lists of policies are difficult to maintain and use correctly. </span><span class="koboSpan" id="kobo.287.5">For this reason, care should be taken to avoid creating unnecessary or hard-to-justify policies. </span><span class="koboSpan" id="kobo.287.6">Sometimes a type with two sufficiently unrelated sets of policies is better to be split into two </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">separate types.</span></span></li>
</ol>
<h1 id="_idParaDest-356"><a id="_idTextAnchor875"/><span class="koboSpan" id="kobo.289.1">Chapter 16, Adapters and Decorators</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.290.1">The Adapter is a very general pattern that modifies an interface of a class or a function (or a template, in C++) so it can be used in a context that requires a different interface but similar </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">underlying behavior.</span></span></li>
<li><span class="koboSpan" id="kobo.292.1">The Decorator pattern is a more narrow pattern; it modifies the existing interface by adding or removing behavior but does not convert an interface into a completely </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">different one.</span></span></li>
<li><span class="koboSpan" id="kobo.294.1">In the classic OOP implementation, both the decorated class and the Decorator class inherit from a common base class. </span><span class="koboSpan" id="kobo.294.2">This has two limitations; the most important one is that the decorated object preserves the polymorphic behavior of the decorated class but cannot preserve the interface that is added in a concrete (derived) decorated class and was not present in the base class. </span><span class="koboSpan" id="kobo.294.3">The second limitation is that the Decorator is specific to a particular hierarchy. </span><span class="koboSpan" id="kobo.294.4">We can remove both limitations using the generic programming tools </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">of C++.</span></span></li>
<li><span class="koboSpan" id="kobo.296.1">In general, a Decorator preserves as much of the interface of the decorated class as possible. </span><span class="koboSpan" id="kobo.296.2">Any functions the behavior of which is not modified are left unchanged. </span><span class="koboSpan" id="kobo.296.3">For that reason, public inheritance is commonly used. </span><span class="koboSpan" id="kobo.296.4">If a Decorator has to forward most calls to the decorated class explicitly, then the inheritance aspect is less important, and composition or private inheritance can </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">be used.</span></span></li>
<li><span class="koboSpan" id="kobo.298.1">Unlike Decorators, adapters usually present a very different interface from that of the original class. </span><span class="koboSpan" id="kobo.298.2">Composition is often preferred in this case. </span><span class="koboSpan" id="kobo.298.3">The exception is compile-time adapters that modify the template parameters but otherwise are essentially the same class template (similar to template aliases). </span><span class="koboSpan" id="kobo.298.4">These adapters must use </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">public inheritance.</span></span></li>
<li><span class="koboSpan" id="kobo.300.1">The main limitation is that it cannot be applied to template functions. </span><span class="koboSpan" id="kobo.300.2">It also cannot be used to replace function arguments with expressions containing </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">those arguments.</span></span></li>
<li><span class="koboSpan" id="kobo.302.1">Template aliases are never considered by the argument type deduction when function templates are instantiated. </span><span class="koboSpan" id="kobo.302.2">Both adapter and policy patterns can be used to add or modify the public interface of </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">a class.</span></span></li>
<li><span class="koboSpan" id="kobo.304.1">Adapters are easy to stack (compose) to build a complex interface one function at a time. </span><span class="koboSpan" id="kobo.304.2">The features that are not enabled do not need any special treatment at all; if the corresponding adapter is not used, then that feature is not enabled. </span><span class="koboSpan" id="kobo.304.3">The traditional policy pattern requires predetermined slots for every pattern. </span><span class="koboSpan" id="kobo.304.4">With the exception of the default arguments after the last explicitly specified one, all policies, even the default ones, must be explicitly specified. </span><span class="koboSpan" id="kobo.304.5">On the other hand, the adapters in the middle of the stack do not have access to the final type of the object, which complicates the implementation. </span><span class="koboSpan" id="kobo.304.6">The policy-based class is always the final type, and using CRTP, this type can be propagated into the policies that </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">need it.</span></span></li>
</ol>
<h1 id="_idParaDest-357"><a id="_idTextAnchor876"/><span class="koboSpan" id="kobo.306.1">Chapter 17, The Visitor Pattern and Multiple Dispatch</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.307.1">The Visitor pattern provides a way to separate the implementation of algorithms from the objects they operate on; in other words, it is a way to add operations to classes without modifying them by writing new </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">member functions.</span></span></li>
<li><span class="koboSpan" id="kobo.309.1">The Visitor pattern allows us to extend the functionality of class hierarchies. </span><span class="koboSpan" id="kobo.309.2">It can be used when the source code of the class is not available for modification or when such modifications would be difficult </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">to maintain.</span></span></li>
<li><span class="koboSpan" id="kobo.311.1">Double dispatch is the process of dispatching a function call (selecting the algorithm to run) based on two factors. </span><span class="koboSpan" id="kobo.311.2">Double dispatch can be implemented at runtime using the Visitor pattern (virtual functions provide the single dispatch) or at compile time using templates or </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">compile-time visitors.</span></span></li>
<li><span class="koboSpan" id="kobo.313.1">The classic visitor has a circular dependency between the visitor class hierarchy and the visitable class hierarchy. </span><span class="koboSpan" id="kobo.313.2">While the visitable classes do not need to be edited when a new visitor is added, they do need to be recompiled when the visitor hierarchy changes. </span><span class="koboSpan" id="kobo.313.3">The latter must happen every time a new visitable class is added, hence a dependency circle. </span><span class="koboSpan" id="kobo.313.4">The Acyclic Visitor breaks this circle by using cross-casting and </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">multiple inheritance.</span></span></li>
<li><span class="koboSpan" id="kobo.315.1">A natural way to accept a visitor into an object composed of smaller objects is to visit each of these objects one by one. </span><span class="koboSpan" id="kobo.315.2">This pattern, implemented recursively, ends up visiting every built-in data member contained in an object and does so in a fixed, predetermined order. </span><span class="koboSpan" id="kobo.315.3">Hence, the pattern maps naturally onto the requirement for serialization and deserialization, where we must deconstruct an object into a collection of built-in types, then </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">restore it.</span></span></li>
</ol>
<h1 id="_idParaDest-358"><a id="_idTextAnchor877"/><span class="koboSpan" id="kobo.317.1">Chapter 18, Patterns for Concurrency</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.318.1">Concurrency is the property of a program that allows multiple tasks to execute at the same time or partially overlapping in time. </span><span class="koboSpan" id="kobo.318.2">Usually, concurrency is achieved through the use of </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">multiple threads.</span></span></li>
<li><span class="koboSpan" id="kobo.320.1">C++11 has the basic support for writing concurrent programs: threads, mutexes, and condition variables. </span><span class="koboSpan" id="kobo.320.2">C++14 and C++17 added several convenience classes and utilities, but the next major addition to concurrency features of C++ is C++20: here, we have several new synchronization primitives as well as the introduction of </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">the coroutines.</span></span></li>
<li><span class="koboSpan" id="kobo.322.1">Synchronization patterns are the common solutions to the basic problems of accessing shared data. </span><span class="koboSpan" id="kobo.322.2">Usually, they provide ways to arrange exclusive access to the data that is modified by multiple threads or is accessed by some threads while being modified </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">by others.</span></span></li>
<li><span class="koboSpan" id="kobo.324.1">Execution patterns are the standard ways to arrange asynchronous execution of some computations using one or more threads. </span><span class="koboSpan" id="kobo.324.2">These patterns offer ways to initiate the execution of some code and receive the results of this execution without the caller being responsible for the execution itself (some other entity in the program has </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">that duty).</span></span></li>
<li><span class="koboSpan" id="kobo.326.1">The most important guideline for design for concurrency is modularity; when applies specifically to concurrency, it means building concurrent software from components that satisfy certain restrictions on their behavior in concurrent programs. </span><span class="koboSpan" id="kobo.326.2">The most important of these restrictions is the thread safety guarantee: generally, it is much easier to build concurrent software from components that allow a wide range of </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">thread-safe operations.</span></span></li>
<li><span class="koboSpan" id="kobo.328.1">In order to be useful in concurrent programs, any data structure or component must provide a transactional interface. </span><span class="koboSpan" id="kobo.328.2">An operation is a transaction if it performs a well-defined complete computation and leaves the system in a well-defined state. </span><span class="koboSpan" id="kobo.328.3">A simplified way to identify which operations are and are not transactions is this: if a concurrent program executes each operation under lock but there are no order guarantees between the operations, is the state of the system guaranteed to be well-defined? </span><span class="koboSpan" id="kobo.328.4">If it isn’t, then some of the operations should be executed as a sequence without releasing the lock. </span><span class="koboSpan" id="kobo.328.5">That sequence is a transaction; the operations that are the steps of the sequence are not transactions by themselves. </span><span class="koboSpan" id="kobo.328.6">It should not be the responsibility of the caller to arrange these operations in a sequence. </span><span class="koboSpan" id="kobo.328.7">Instead, the data structure or component should offer the interface for performing the entire transaction as a </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">single operation.</span></span></li>
</ol>
</div>
</body></html>