<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-185">
    <a id="_idTextAnchor184">
    </a>
    
     9
    
   </h1>
   <h1 id="_idParaDest-186">
    <a id="_idTextAnchor185">
    </a>
    
     Asynchronous Programming Using Boost.Asio
    
   </h1>
   <p>
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     is a C++ library
    
    <a id="_idIndexMarker628">
    </a>
    
     included in the well-known Boost libraries family that simplifies the development of solutions dealing with asynchronous
    
    <strong class="bold">
     
      input/output
     
    </strong>
    
     (
    
    <strong class="bold">
     
      I/O
     
    </strong>
    
     ) tasks
    
    <a id="_idIndexMarker629">
    </a>
    
     managed by the
    
    <strong class="bold">
     
      operating system
     
    </strong>
    
     (
    
    <strong class="bold">
     
      OS
     
    </strong>
    
     ), making it
    
    <a id="_idIndexMarker630">
    </a>
    
     easier to develop asynchronous software that deals with internal and external resources, such as network communications services or
    
    
     
      file operations.
     
    
   </p>
   <p>
    
     For that purpose, Boost.Asio defines OS services (services belonging to and managed by the OS), I/O objects (providing interfaces to OS services), and the I/O execution context object (an object that behaves as a services registry
    
    
     
      and proxy).
     
    
   </p>
   <p>
    
     In the following pages, we will introduce Boost.Asio, describe its main building blocks, and explain some common patterns to develop asynchronous software with this library, which are widely used in
    
    
     
      the industry.
     
    
   </p>
   <p>
    
     In this chapter, we’re going to cover the following
    
    
     
      main topics:
     
    
   </p>
   <ul>
    <li>
     
      What Boost.Asio is and how it simplifies asynchronous programming with
     
     
      
       external resources
      
     
    </li>
    <li>
     
      What I/O objects and I/O execution contexts are, and how they interact with OS services and between
     
     
      
       each other
      
     
    </li>
    <li>
     
      What the Proactor and Reactor design patterns are, and how they are related
     
     
      
       to Boost.Asio
      
     
    </li>
    <li>
     
      How to keep the program thread-safe and how to serialize tasks
     
     
      
       using strands
      
     
    </li>
    <li>
     
      How to efficiently pass data to asynchronous tasks
     
     
      
       using buffers
      
     
    </li>
    <li>
     
      How to cancel
     
     
      
       asynchronous operations
      
     
    </li>
    <li>
     
      Examples of common practices with timers and
     
     
      
       networking applications
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-187">
    <a id="_idTextAnchor186">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     For this chapter, we will need to install the Boost C++ libraries.
    
    
     The most recent version when writing this book is Boost 1.85.0.
    
    
     Here are the
    
    
     
      release notes:
     
    
   </p>
   <p>
    <a href="https://www.boost.org/users/history/version_1_85_0.html">
     
      
       https://www.boost.org/users/history/version_1_85_0.html
      
     
    </a>
   </p>
   <p>
    
     For installation instructions in Unix variants systems (Linux, macOS), check out the
    
    
     
      following link:
     
    
   </p>
   <p>
    <a href="https://www.boost.org/doc/libs/1_85_0/more/getting_started/unix-variants.html">
     
      
       https://www.boost.org/doc/libs/1_85_0/more/getting_started/unix-variants.html
      
     
    </a>
   </p>
   <p>
    
     For Windows systems, check out
    
    
     
      this link:
     
    
   </p>
   <p>
    <a href="https://www.boost.org/doc/libs/1_85_0/more/getting_started/windows.html">
     
      
       https://www.boost.org/doc/libs/1_85_0/more/getting_started/windows.html
      
     
    </a>
   </p>
   <p>
    
     Also, depending on the project we want to develop, we might need to configure
    
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     or
    
    
     
      install dependencies:
     
    
   </p>
   <p>
    <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/using.html">
     
      
       https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/using.html
      
     
    </a>
   </p>
   <p>
    
     All code shown during this chapter will be supported by the C++20 version.
    
    
     Please check the technical requirements section in
    
    <a href="B22219_03.xhtml#_idTextAnchor051">
     
      <em class="italic">
       
        Chapter 3
       
      </em>
     
    </a>
    
     with some guidance on how to install GCC 13 and Clang
    
    
     
      8 compilers.
     
    
   </p>
   <p>
    
     You can find the complete code in the following
    
    
     
      GitHub repository:
     
    
   </p>
   <p>
    <a href="https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP">
     
      
       https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP
      
     
    </a>
   </p>
   <p>
    
     The examples for this chapter are located under the
    
    <strong class="source-inline">
     
      Chapter_09
     
    </strong>
    
     folder.
    
    
     All source code files can be compiled using CMake
    
    
     
      as follows:
     
    
   </p>
   <pre class="source-code">
cmake . &amp;&amp; cmake —build .</pre>
   <p>
    
     Executable binaries will be generated under the
    
    
     <em class="italic">
      
       bin
      
     </em>
    
    
     
      directory.
     
    
   </p>
   <h1 id="_idParaDest-188">
    <a id="_idTextAnchor187">
    </a>
    
     What is Boost.Asio?
    
   </h1>
   <p>
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     is a
    
    <a id="_idIndexMarker631">
    </a>
    
     cross-platform C++ library created by Chris Kohlhoff that provides a portable network and low-level I/O programming, including sockets, timers, hostname resolution, socket iostreams, serial ports, file descriptors, and Windows HANDLEs, providing a consistent asynchronous model.
    
    
     It also provides coroutine support, but as we learned in the previous chapter, they are now available in C++20, so we will only introduce them briefly in
    
    
     
      this chapter.
     
    
   </p>
   <p>
    
     Boost.Asio allows the program to manage long-running operations without the explicit usage of threads and locks.
    
    
     Also, as it implements a layer on top of the OS services, it allows portability, efficiency, ease of use, and scalability, using the most appropriate underlying OS mechanisms to achieve these goals, for example, scatter-gather I/O operations or moving data across while minimizing
    
    
     
      costly copies.
     
    
   </p>
   <p>
    
     Let’s start by learning
    
    <a id="_idIndexMarker632">
    </a>
    
     about the basic Boost.Asio blocks, I/O objects, and I/O execution
    
    
     
      context objects.
     
    
   </p>
   <h2 id="_idParaDest-189">
    <a id="_idTextAnchor188">
    </a>
    
     I/O objects
    
   </h2>
   <p>
    
     Sometimes, an application
    
    <a id="_idIndexMarker633">
    </a>
    
     needs to access OS services, run asynchronous
    
    <a id="_idIndexMarker634">
    </a>
    
     tasks on them, and collect the results or errors.
    
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     provides a mechanism composed of I/O objects and I/O execution context objects to allow
    
    
     
      this functionality.
     
    
   </p>
   <p>
    
     I/O objects are task-oriented objects representing the actual entities performing I/O operations.
    
    
     As we can see in
    
    
     <em class="italic">
      
       Figure 9
      
     </em>
    
    <em class="italic">
     
      .1
     
    </em>
    
     , Boost.Asio provides core classes to manage concurrency, streams, buffers, or other core functionality to the library and also includes portable
    
    <a id="_idIndexMarker635">
    </a>
    
     networking classes for
    
    <a id="_idIndexMarker636">
    </a>
    
     network communications via
    
    <strong class="bold">
     
      Transmission Control Protocol/Internet Protocol
     
    </strong>
    
     (
    
    <strong class="bold">
     
      TCP/IP
     
    </strong>
    
     ),
    
    <strong class="bold">
     
      User Datagram Protocol
     
    </strong>
    
     (
    
    <strong class="bold">
     
      UDP
     
    </strong>
    
     ), or
    
    <strong class="bold">
     
      Internet Control Message Protocol
     
    </strong>
    
     (
    
    <strong class="bold">
     
      ICMP
     
    </strong>
    
     ), classes to define the security layer, the
    
    <a id="_idIndexMarker637">
    </a>
    
     transmission protocol and serial port, among other tasks, and also platform-specific classes to deal with specific settings depending on the
    
    
     
      underlying OS.
     
    
   </p>
   <div><div><img alt="Figure 9.1 – I/O objects" src="img/B22219_09_1.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 9.1 – I/O objects
    
   </p>
   <p>
    
     The I/O objects do not directly execute their tasks in the OS.
    
    
     They need to communicate with the OS via an I/O execution context object.
    
    
     An instance of a context object is passed as the first argument in the I/O object constructors.
    
    
     Here, we are defining an I/O object (a timer with an expiration time of three seconds) and passing an I/O execution context object (
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     ) via
    
    
     
      its constructor:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
using namespace std::chrono_literals;
boost::asio::io_context io_context;
boost::asio::steady_timer timer(io_context, 3s);</pre>
   <p>
    
     Most I/O objects have methods whose name starts with
    
    <strong class="source-inline">
     
      async_
     
    </strong>
    
     .
    
    
     These methods trigger asynchronous operations, which will call a completion handler, a callable object passed as an argument to the method when the operation completes.
    
    
     These methods return immediately, not blocking the program flow.
    
    
     The current thread can continue performing other tasks while the task is not complete.
    
    
     Once completed, the completion handler will be called and executed, dealing with the result or error of the
    
    
     
      asynchronous task.
     
    
   </p>
   <p>
    
     I/O objects also provide the blocking counterpart methods, which will block until completion.
    
    
     These methods do not need to receive a handler as
    
    
     
      a parameter.
     
    
   </p>
   <p>
    
     As mentioned before, note that the I/O objects don’t interact directly with the OS; they need an I/O execution
    
    <a id="_idIndexMarker638">
    </a>
    
     context object.
    
    
     Let’s learn about this class
    
    
     
      of
     
    
    
     <a id="_idIndexMarker639">
     </a>
    
    
     
      objects.
     
    
   </p>
   <h2 id="_idParaDest-190">
    <a id="_idTextAnchor189">
    </a>
    
     I/O execution context objects
    
   </h2>
   <p>
    
     To access the I/O services, the
    
    <a id="_idIndexMarker640">
    </a>
    
     program uses at least
    
    <a id="_idIndexMarker641">
    </a>
    
     one I/O execution context object that represents the gateway to the OS I/O services.
    
    
     It’s implemented with the
    
    <strong class="source-inline">
     
      boost::asio::io_context
     
    </strong>
    
     class, providing the core I/O functionality of OS services to I/O objects.
    
    
     In Windows,
    
    <strong class="source-inline">
     
      boost::asio::io_context
     
    </strong>
    
     is based
    
    <a id="_idIndexMarker642">
    </a>
    
     in
    
    <strong class="bold">
     
      I/O completion ports
     
    </strong>
    
     (
    
    <strong class="bold">
     
      IOCP
     
    </strong>
    
     ), on Linux, it is based in
    
    <strong class="bold">
     
      epoll
     
    </strong>
    
     , and on FreeBSD/macOS, it is based
    
    <a id="_idIndexMarker643">
    </a>
    
     
      in
     
    
    
     <strong class="bold">
      
       kqueue
      
     </strong>
    
    
     
      .
     
    
   </p>
   <div><div><img alt="Figure 9.2 – Boost.Asio architecture" src="img/B22219_09_2.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 9.2 – Boost.Asio architecture
    
   </p>
   <p>
    <strong class="source-inline">
     
      boost::asio::io_context
     
    </strong>
    
     is a subclass of
    
    <strong class="source-inline">
     
      boost::asio::execution_context
     
    </strong>
    
     , a base class for function object execution also inherited by other execution context objects, such as
    
    <strong class="source-inline">
     
      boost::asio::thread_pool
     
    </strong>
    
     or
    
    <strong class="source-inline">
     
      boost::asio::system_context
     
    </strong>
    
     .
    
    
     In this chapter, we
    
    <a id="_idIndexMarker644">
    </a>
    
     will be using
    
    <strong class="source-inline">
     
      boost::asio::io_context
     
    </strong>
    
     as our execution
    
    
     
      context object.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      boost::asio::io_context
     
    </strong>
    
     class has been a replacement for the
    
    <strong class="source-inline">
     
      boost::asio::io_service
     
    </strong>
    
     class since version 1.66.0, embracing more modern features and practices from C++.
    
    <strong class="source-inline">
     
      boost::asio::io_service
     
    </strong>
    
     is still available for
    
    
     
      backward compatibility.
     
    
   </p>
   <p>
    
     As described earlier, Boost.Asio objects can schedule asynchronous operations using methods starting with
    
    <strong class="source-inline">
     
      async_
     
    </strong>
    
     .
    
    
     When all the asynchronous tasks are scheduled, the program needs to call the
    
    <strong class="source-inline">
     
      boost::asio::io_context::run()
     
    </strong>
    
     function to execute an event processing loop, allowing the OS to deal with the tasks and pass to the program the results and trigger
    
    
     
      the handlers.
     
    
   </p>
   <p>
    
     Coming back to our previous example, we will now set up the completion handler,
    
    <strong class="source-inline">
     
      on_timeout()
     
    </strong>
    
     , a callable object (in this case a function) that we pass as a parameter when calling the
    
    <a id="_idIndexMarker645">
    </a>
    
     asynchronous
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     function.
    
    
     Here
    
    <a id="_idIndexMarker646">
    </a>
    
     is the
    
    
     
      code example:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;
void on_timeout(const boost::system::error_code&amp; ec) {
    if (!ec) {
        std::cout &lt;&lt; "Timer expired.\n" &lt;&lt; std::endl;
    } else {
        std::cerr &lt;&lt; "Error: " &lt;&lt; ec.message() &lt;&lt; '\n';
    }
}
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context,
                              std::chrono::seconds(3));
    timer.async_wait(&amp;on_timeout);
    io_context.run();
    return 0;
}</pre>
   <p>
    
     Running this code, we should see the message
    
    <strong class="source-inline">
     
      Timer expired.
     
    </strong>
    
     in the console after three seconds, or an error message if the asynchronous call fails for
    
    
     
      any reason.
     
    
   </p>
   <p>
    <strong class="source-inline">
     
      boost::io_context::run()
     
    </strong>
    
     is a blocking call.
    
    
     This is intended to keep the event loop running, allow the asynchronous operations to run, and prevent the program from exiting.
    
    
     Obviously, this function can be called in a new thread and leave the main thread unblocked to carry on with other tasks, as we have seen in
    
    
     
      previous chapters.
     
    
   </p>
   <p>
    
     When there are no pending asynchronous operations,
    
    <strong class="source-inline">
     
      boost::io_context::run()
     
    </strong>
    
     will return.
    
    
     There is a template class,
    
    <strong class="source-inline">
     
      boost::asio::executor_work_guard
     
    </strong>
    
     , that can keep
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     busy and avoid it exiting if needed.
    
    
     Let’s see how it works with
    
    
     
      an example.
     
    
   </p>
   <p>
    
     Let’s start by
    
    <a id="_idIndexMarker647">
    </a>
    
     defining a background task that will wait
    
    <a id="_idIndexMarker648">
    </a>
    
     for two seconds before posting some work through
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     using the
    
    
     <strong class="source-inline">
      
       boost::asio::io_context::post()
      
     </strong>
    
    
     
      function:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
using namespace std::chrono_literals;
void background_task(boost::asio::io_context&amp; io_context) {
    std::this_thread::sleep_for(2s);
    std::cout &lt;&lt; "Posting a background task.\n";
    io_context.post([]() {
        std::cout &lt;&lt; "Background task completed!\n";
    });
}</pre>
   <p>
    
     In the
    
    <strong class="source-inline">
     
      main()
     
    </strong>
    
     function, the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object is created, and a
    
    <strong class="source-inline">
     
      work_guard
     
    </strong>
    
     object is constructed using that
    
    
     <strong class="source-inline">
      
       io_context
      
     </strong>
    
    
     
      object.
     
    
   </p>
   <p>
    
     Then, two threads are created,
    
    <strong class="source-inline">
     
      io_thread
     
    </strong>
    
     , where
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     runs, and
    
    <strong class="source-inline">
     
      worker
     
    </strong>
    
     , where
    
    <strong class="source-inline">
     
      background_task()
     
    </strong>
    
     will run.
    
    
     We also pass
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     as a reference to the background task to post work, as
    
    
     
      explained earlier.
     
    
   </p>
   <p>
    
     With that in place, the main thread does some work (waiting for five seconds) and then removes the work guard by calling its
    
    <strong class="source-inline">
     
      reset()
     
    </strong>
    
     function, letting
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     exit its
    
    <strong class="source-inline">
     
      run()
     
    </strong>
    
     function, and joins
    
    <a id="_idIndexMarker649">
    </a>
    
     both threads before exiting, as
    
    <a id="_idIndexMarker650">
    </a>
    
     
      shown here:
     
    
   </p>
   <pre class="source-code">
int main() {
    boost::asio::io_context io_context;
    auto work_guard = boost::asio::make_work_guard(
                      io_context);
    std::thread io_thread([&amp;io_context]() {
        std::cout &lt;&lt; "Running io_context.\n";
        io_context.run();
        std::cout &lt;&lt; "io_context stopped.\n";
    });
    std::thread worker(background_task,
                       std::ref(io_context));
    // Main thread doing some work.
    std::this_thread::sleep_for(5s);
    std::cout &lt;&lt; "Removing work_guard." &lt;&lt; std::endl;
    work_guard.reset();
    worker.join();
    io_thread.join();
    return 0;
}</pre>
   <p>
    
     If we run the previous code, this is
    
    
     
      the output:
     
    
   </p>
   <pre class="console">
Running io_context.
Posting a background task.
Background task completed!
Removing work_guard.
io_context stopped.</pre>
   <p>
    
     We can see how the background thread posts a background task correctly, and this is completed before the work guard is removed and the I/O context object stops
    
    
     
      its execution.
     
    
   </p>
   <p>
    
     Another way to keep the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object alive and servicing requests is to provide asynchronous tasks by continuously calling
    
    <strong class="source-inline">
     
      async_
     
    </strong>
    
     functions or posting work from the completion handlers.
    
    
     This is
    
    <a id="_idIndexMarker651">
    </a>
    
     a common pattern when
    
    <a id="_idIndexMarker652">
    </a>
    
     reading or writing to sockets
    
    
     
      or streams:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;functional&gt;
#include &lt;iostream&gt;
using namespace std::chrono_literals;
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 3s);
    std::function&lt;void(const boost::system::error_code&amp;)&gt;
                  timer_handler;
    timer_handler = [&amp;timer, &amp;timer_handler](
                     const boost::system::error_code&amp; ec) {
        if (!ec) {
            std::cout &lt;&lt; "Handler: Timer expired.\n";
            timer.expires_after(1s);
            timer.async_wait(timer_handler);
        } else {
            std::cerr &lt;&lt; "Handler error: "
                      &lt;&lt; ec.message() &lt;&lt; std::endl;
        }
    };
    timer.async_wait(timer_handler);
    io_context.run();
    return 0;
}</pre>
   <p>
    
     In this case,
    
    <strong class="source-inline">
     
      timer_handler
     
    </strong>
    
     is the completion handler defined as a lambda function that captures the timer and itself.
    
    
     Every second, when the timer expires, it prints the
    
    <strong class="source-inline">
     
      Handler: Timer expired.
     
    </strong>
    
     message and restarts itself by enqueueing a new asynchronous task (using the
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     function) into the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object via the
    
    
     <strong class="source-inline">
      
       timer
      
     </strong>
    
    
     
      object.
     
    
   </p>
   <p>
    
     As we have already seen, the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object can run from any thread.
    
    
     By default, this object is thread-safe, but in some scenarios where we want better performance, we might want to avoid
    
    <a id="_idIndexMarker653">
    </a>
    
     this safety.
    
    
     This can be adjusted
    
    <a id="_idIndexMarker654">
    </a>
    
     during its construction, as we will see in the
    
    
     
      next section.
     
    
   </p>
   <h3>
    
     Concurrency hints
    
   </h3>
   <p>
    
     The
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     constructor
    
    <a id="_idIndexMarker655">
    </a>
    
     accepts as an argument a concurrency hint, suggesting to the implementation the number of active threads that should be used for running
    
    
     
      completion handlers.
     
    
   </p>
   <p>
    
     By default, this value is
    
    <strong class="source-inline">
     
      BOOST_ASIO_CONCURRENCY_HINT_SAFE
     
    </strong>
    
     (value
    
    <em class="italic">
     
      1
     
    </em>
    
     ), indicating that the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object will run from a single thread, enabling several optimizations due to this fact.
    
    
     That doesn’t mean that
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     can only be used from one thread; it still provides thread safety, and it can use I/O objects from
    
    
     
      many threads.
     
    
   </p>
   <p>
    
     Other values that can be specified are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       BOOST_ASIO_CONCURRENCY_HINT_UNSAFE
      
     </strong>
     
      : Disables locking so all operations on
     
     <strong class="source-inline">
      
       io_context
      
     </strong>
     
      or I/O objects must occur in the
     
     
      
       same thread.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       BOOST_ASIO_CONCURRENCY_HINT_UNSAFE_IO
      
     </strong>
     
      : Disables locking in the reactor but keeps it in the scheduler, so all operations in the
     
     <strong class="source-inline">
      
       io_context
      
     </strong>
     
      object can use different threads apart from the
     
     <strong class="source-inline">
      
       run()
      
     </strong>
     
      function and the other methods related to executing the event processing loop.
     
     
      We will learn about schedulers and reactors when explaining the design principles behind
     
     
      
       the library.
      
     
    </li>
   </ul>
   <p>
    
     Let’s now learn about what the event processing loop is and how to
    
    
     
      manage it.
     
    
   </p>
   <h2 id="_idParaDest-191">
    <a id="_idTextAnchor190">
    </a>
    
     The event processing loop
    
   </h2>
   <p>
    
     Using the
    
    <strong class="source-inline">
     
      boost::asio::io_context::run()
     
    </strong>
    
     method,
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     blocks and keeps
    
    <a id="_idIndexMarker656">
    </a>
    
     processing I/O
    
    <a id="_idIndexMarker657">
    </a>
    
     asynchronous tasks until all have been completed and the completion handlers have been notified.
    
    
     This I/O requests processing is done in an internal event
    
    
     
      processing loop.
     
    
   </p>
   <p>
    
     There are other methods to control the event loop and avoid blocking until all asynchronous events are processed.
    
    
     These are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       poll
      
     </strong>
     
      : Run the event processing loop to execute
     
     
      
       ready handlers
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       poll_one
      
     </strong>
     
      : Run the event processing loop to execute one
     
     
      
       ready handler
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       run_for
      
     </strong>
     
      : Run the event processing loop for a
     
     
      
       specified duration
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       run_until
      
     </strong>
     
      : Same as the previous one but only until a
     
     
      
       specified time
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       run_one
      
     </strong>
     
      : Run the event processing loop to execute at most
     
     
      
       one handler
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       run_one_for
      
     </strong>
     
      : Same as the previous one but only for a
     
     
      
       specified duration
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       run_one_until
      
     </strong>
     
      : Same as the previous one but only until a
     
     
      
       specified time
      
     
    </li>
   </ul>
   <p>
    
     The event loop can also be stopped by calling the
    
    <strong class="source-inline">
     
      boost::asio::io_context::stop()
     
    </strong>
    
     method or checking if its status is stopped by
    
    
     
      calling
     
    
    
     <strong class="source-inline">
      
       boost:asio::io_context::stopped()
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     When the event loop is not running, tasks already being scheduled will continue executing.
    
    
     Other tasks will remain pending.
    
    
     Pending tasks can be resumed and pending results collected by starting the event loop with one of the methods mentioned
    
    
     
      previously again.
     
    
   </p>
   <p>
    
     In previous examples, the application sent some work to
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     by calling asynchronous methods
    
    <a id="_idIndexMarker658">
    </a>
    
     or by using the
    
    <strong class="source-inline">
     
      post()
     
    </strong>
    
     function.
    
    
     Let’s learn now about
    
    <strong class="source-inline">
     
      dispatch()
     
    </strong>
    
     and its
    
    <a id="_idIndexMarker659">
    </a>
    
     differences
    
    
     
      with
     
    
    
     <strong class="source-inline">
      
       post()
      
     </strong>
    
    
     
      .
     
    
   </p>
   <h3>
    
     Giving some work to the io_context
    
   </h3>
   <p>
    
     Apart from
    
    <a id="_idIndexMarker660">
    </a>
    
     sending work to
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     via the asynchronous methods from the different I/O objects or by using
    
    <strong class="source-inline">
     
      executor_work_guard
     
    </strong>
    
     (explained below), we can also use the
    
    <strong class="source-inline">
     
      boost::asio::post()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      boost::asio::dispatch()
     
    </strong>
    
     template methods.
    
    
     Both functions are used to schedule some work into an
    
    
     <strong class="source-inline">
      
       io_context
      
     </strong>
    
    
     
      object.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      post()
     
    </strong>
    
     function guarantees that the task will be executed.
    
    
     It places its completion handler in the execution queue and eventually, it will
    
    
     
      be executed:
     
    
   </p>
   <pre class="source-code">
boost::asio::io_context io_context;
io_context.post([] {
    std::cout &lt;&lt; "This will always run asynchronously.\n";
});</pre>
   <p>
    
     On the other hand,
    
    <strong class="source-inline">
     
      dispatch()
     
    </strong>
    
     may execute the task immediately if
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     or strand (more on strands later in this chapter) are in the same thread where the task is being dispatched, or otherwise placed in the queue for
    
    
     
      asynchronous execution:
     
    
   </p>
   <pre class="source-code">
boost::asio::io_context io_context;
io_context.dispatch([] {
    std::cout &lt;&lt; "This might run immediately or be queued.\n";
});</pre>
   <p>
    
     Therefore, using
    
    <strong class="source-inline">
     
      dispatch()
     
    </strong>
    
     , we can optimize performance by reducing context switching or
    
    
     
      queuing delays.
     
    
   </p>
   <p>
    
     Dispatched events can execute directly from the current worker thread even if there are other pending events queued up.
    
    
     The posted events must always need to be managed by the I/O execution
    
    <a id="_idIndexMarker661">
    </a>
    
     context, waiting until other handlers complete before being allowed to
    
    
     
      be executed.
     
    
   </p>
   <p>
    
     Now that we have already learned about some basic concepts, let’s learn how synchronous and asynchronous operations work under
    
    
     
      the hood.
     
    
   </p>
   <h1 id="_idParaDest-192">
    <a id="_idTextAnchor191">
    </a>
    
     Interacting with the OS
    
   </h1>
   <p>
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     can interact with I/O services
    
    <a id="_idIndexMarker662">
    </a>
    
     using synchronous and asynchronous operations.
    
    
     Let’s learn how they behave and what the main
    
    
     
      differences are.
     
    
   </p>
   <h2 id="_idParaDest-193">
    <a id="_idTextAnchor192">
    </a>
    
     Synchronous operations
    
   </h2>
   <p>
    
     If the program
    
    <a id="_idIndexMarker663">
    </a>
    
     wants to use an I/O service
    
    <a id="_idIndexMarker664">
    </a>
    
     in a synchronous way, usually, it will create an I/O object and use its synchronous
    
    
     
      operation method:
     
    
   </p>
   <pre class="source-code">
boost::asio::io_context io_context;
boost::asio::steady_timer timer(io_context, 3s);
timer.wait();</pre>
   <p>
    
     When calling
    
    <strong class="source-inline">
     
      timer.wait()
     
    </strong>
    
     , the request is sent to the I/O execution context object (
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     ), which calls the OS to perform the operation.
    
    
     Once the OS finishes with the task, it returns the result to
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     , which then translates the result, or an error if anything went wrong, back to the I/O object (
    
    <strong class="source-inline">
     
      timer
     
    </strong>
    
     ).
    
    
     Errors are of type
    
    <strong class="source-inline">
     
      boost::system::error_code
     
    </strong>
    
     .
    
    
     If an error occurs, an exception
    
    
     
      is thrown.
     
    
   </p>
   <p>
    
     If we don’t want exceptions to be thrown, we can pass an error object by reference to the synchronous method to capture the status of the operation and check
    
    
     
      it afterward:
     
    
   </p>
   <pre class="source-code">
boost::system::error_code ec;
Timer.wait(server_endpoint, ec);</pre>
   <h2 id="_idParaDest-194">
    <a id="_idTextAnchor193">
    </a>
    
     Asynchronous operations
    
   </h2>
   <p>
    
     In the case
    
    <a id="_idIndexMarker665">
    </a>
    
     of asynchronous
    
    <a id="_idIndexMarker666">
    </a>
    
     operations, we need to also pass a completion handler to the asynchronous method.
    
    
     This completion handler is a callable object that will be invoked by the I/O context object when the asynchronous operation finishes, notifying the program about the result or operation error.
    
    
     Its signature is
    
    
     
      as follows:
     
    
   </p>
   <pre class="source-code">
void completion_handler(
     const boost::system::error_code&amp; ec);</pre>
   <p>
    
     Continuing with the timer example, now, we need to call the
    
    
     
      asynchronous operation:
     
    
   </p>
   <pre class="source-code">
socket.async_wait(completion_handler);</pre>
   <p>
    
     Again, the I/O object (
    
    <strong class="source-inline">
     
      timer
     
    </strong>
    
     ) forwards the request to the I/O execution context object (
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     ).
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     requests to the OS to start the
    
    
     
      asynchronous operation.
     
    
   </p>
   <p>
    
     When the operation is finished, the OS places the result in a queue, where
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     is listening.
    
    
     Then,
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     dequeues the result, translates the error into an error code object, and triggers the completion handler to notify the program about the completion of the task and
    
    
     
      the result.
     
    
   </p>
   <p>
    
     To allow
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     to follow these steps, the program must execute
    
    <strong class="source-inline">
     
      boost::asio::io_context::run()
     
    </strong>
    
     (or similar functions introduced earlier that manage the event processing loop) and block the current thread while processing any unfinished asynchronous operation.
    
    
     As already commented, if there are no pending asynchronous operations,
    
    
     <strong class="source-inline">
      
       boost::asio::io_context::run()
      
     </strong>
    
    
     
      exits.
     
    
   </p>
   <p>
    
     Completion handlers are required to be copy-constructible, meaning that a copy-constructor must be available.
    
    
     If a temporary resource is needed (such as memory, thread, or file descriptor), this resource is released before calling the completion handler.
    
    
     That allows
    
    <a id="_idIndexMarker667">
    </a>
    
     us to call
    
    <a id="_idIndexMarker668">
    </a>
    
     the same operation without overlapping resource usage, avoiding increasing the peak resource usage in
    
    
     
      the system.
     
    
   </p>
   <h3>
    
     Error handling
    
   </h3>
   <p>
    
     As mentioned
    
    <a id="_idIndexMarker669">
    </a>
    
     previously,
    
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     allows users to handle errors in two different ways: by using error codes or throwing exceptions.
    
    
     If we pass a reference to a
    
    <strong class="source-inline">
     
      boost::system::error_code
     
    </strong>
    
     object when calling an I/O object method, the implementation will pass errors through that variable; otherwise, an exception will
    
    
     
      be thrown.
     
    
   </p>
   <p>
    
     We already implemented some examples following the first approach by checking the error codes.
    
    
     Let’s now see how to
    
    
     
      catch exceptions.
     
    
   </p>
   <p>
    
     The following example creates a timer with an expiration period of three seconds.
    
    
     The
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object is running from the background thread,
    
    <strong class="source-inline">
     
      io_thread
     
    </strong>
    
     .
    
    
     When the timer starts the asynchronous task by calling its
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     function, it passes the
    
    <strong class="source-inline">
     
      boost::asio::use_future
     
    </strong>
    
     argument so the function returns a future object,
    
    <strong class="source-inline">
     
      fut
     
    </strong>
    
     , that later is used inside a try-catch block to call its
    
    <strong class="source-inline">
     
      get()
     
    </strong>
    
     function and retrieve the stored result or exception, as we learned in
    
    <a href="B22219_06.xhtml#_idTextAnchor125">
     
      <em class="italic">
       
        Chapter 6
       
      </em>
     
    </a>
    
     .
    
    
     After starting the asynchronous operation, the main thread waits for one second and the timer cancels the operation by calling its
    
    <strong class="source-inline">
     
      cancel()
     
    </strong>
    
     function.
    
    
     As this happens before its expiration time (three seconds), an exception
    
    
     
      is thrown:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
using namespace std::chrono_literals;
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 1s);
    auto fut = timer.async_wait(
                     boost::asio::use_future);
    std::thread io_thread([&amp;io_context]() {
                        io_context.run();
    });
    std::this_thread::sleep_for(3s);
    timer.cancel();
    try {
        fut.get();
        std::cout &lt;&lt; "Timer expired successfully!\n";
    } catch (const boost::system::system_error&amp; e) {
        std::cout &lt;&lt; "Timer failed: "
                  &lt;&lt; e.code().message() &lt;&lt; '\n';
    }
    io_thread.join();
    return 0;
}</pre>
   <p>
    
     The exception of type
    
    <strong class="source-inline">
     
      boost::system::system_error
     
    </strong>
    
     is caught, and its message is printed.
    
    
     If the timer cancels its operation after the asynchronous operation completes (in this example, by sleeping the main thread for more than three seconds), the timer expires successfully, and no exception
    
    
     
      is thrown.
     
    
   </p>
   <p>
    
     Now that we have
    
    <a id="_idIndexMarker670">
    </a>
    
     seen the main building blocks of Boost.Asio and how they interact together, let’s recap and understand the design patterns behind
    
    
     
      its implementation.
     
    
   </p>
   <h1 id="_idParaDest-195">
    <a id="_idTextAnchor194">
    </a>
    
     The Reactor and Proactor design patterns
    
   </h1>
   <p>
    
     When using event
    
    <a id="_idIndexMarker671">
    </a>
    
     handling
    
    <a id="_idIndexMarker672">
    </a>
    
     applications, we can follow two approaches to designing the concurrent solution: the Reactor and Proactor
    
    
     
      design patterns.
     
    
   </p>
   <p>
    
     These patterns describe the mechanisms followed to process events, indicating how these are initiated, received, demultiplexed, and dispatched.
    
    
     As the system collects and queues the I/O events coming from different resources, demultiplexing these events means separating them to be dispatched to their
    
    
     
      correct handlers.
     
    
   </p>
   <p>
    
     The
    
    <strong class="bold">
     
      Reactor pattern
     
    </strong>
    
     demultiplexes and dispatches synchronously and serially service requests.
    
    
     It usually follows a non-blocking synchronous I/O strategy, returning the result if the operation can be executed, or an error if the system has no resources to complete
    
    
     
      the operation.
     
    
   </p>
   <p>
    
     On the other hand, the
    
    <strong class="bold">
     
      Proactor pattern
     
    </strong>
    
     allows demultiplexing and dispatching service requests in an efficient asynchronous way by immediately returning the control to the caller, indicating that the operation has been initiated.
    
    
     Then, the called system will notify the caller when the operation
    
    
     
      is complete.
     
    
   </p>
   <p>
    
     Thus, the Proactor pattern distributes responsibilities among two tasks: the long-duration operations that are executed asynchronously and the completion handlers that process the results
    
    <a id="_idIndexMarker673">
    </a>
    
     and
    
    <a id="_idIndexMarker674">
    </a>
    
     usually invoke other
    
    
     
      asynchronous operations.
     
    
   </p>
   <p>
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     implements the Proactor design pattern by using the
    
    
     
      following elements:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Initiator
      
     </strong>
     
      : An I/O object that initiates the
     
     
      
       asynchronous operation.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Asynchronous operation
      
     </strong>
     
      : A task to run asynchronously by
     
     
      
       the OS.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Asynchronous operation processor
      
     </strong>
     
      : This executes the asynchronous operation and queues results in the completion
     
     
      
       event queue.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Completion event queue
      
     </strong>
     
      : An event queue where the asynchronous operation processor pushes events, and the asynchronous event
     
     
      
       dequeues them.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Asynchronous event demultiplexer
      
     </strong>
     
      : This blocks the I/O context, waiting for events, and returning completed events to
     
     
      
       the caller.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Completion handler
      
     </strong>
     
      : A callable object that will process the results of the
     
     
      
       asynchronous operation.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Proactor
      
     </strong>
     
      : This calls the asynchronous event demultiplexer to dequeue events and dispatch them to the completion handler.
     
     
      This is what the I/O execution
     
     
      
       context does.
      
     
    </li>
   </ul>
   <p>
    
     <em class="italic">
      
       Figure 9
      
     </em>
    
    <em class="italic">
     
      .3
     
    </em>
    
     clearly shows the relationship between all
    
    
     
      these elements:
     
    
   </p>
   <div><div><img alt="Figure 9.3 – Proactor design pattern" src="img/B22219_09_3.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 9.3 – Proactor design pattern
    
   </p>
   <p>
    
     The Proactor pattern increases the separation of concerns at the same time as encapsulating concurrency mechanisms, simplifying application synchronization, and
    
    
     
      increasing performance.
     
    
   </p>
   <p>
    
     On the other hand, we have no control over how or when the asynchronous operations are scheduled or how efficiently the OS will perform these operations.
    
    
     Also, there is an increase in memory usage due
    
    <a id="_idIndexMarker675">
    </a>
    
     to
    
    <a id="_idIndexMarker676">
    </a>
    
     the completion event queue and increased complexity in debugging
    
    
     
      and testing.
     
    
   </p>
   <p>
    
     Another aspect of the design of Boost.Asio is the thread safety of the execution context objects.
    
    
     Let’s now dig into how threading works
    
    
     
      with Boost.Asio.
     
    
   </p>
   <h1 id="_idParaDest-196">
    <a id="_idTextAnchor195">
    </a>
    
     Threading with Boost.Asio
    
   </h1>
   <p>
    
     I/O execution context
    
    <a id="_idIndexMarker677">
    </a>
    
     objects are thread-safe; their methods can be called from different threads safely.
    
    
     That means that we can use a separate thread to run the blocking
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     method and leave the main thread unblocked to carry on with other
    
    
     
      unrelated tasks.
     
    
   </p>
   <p>
    
     Let’s now explain the different ways to configure the asynchronous application in terms of how to
    
    
     
      use threads.
     
    
   </p>
   <h2 id="_idParaDest-197">
    <a id="_idTextAnchor196">
    </a>
    
     Single-threaded approach
    
   </h2>
   <p>
    
     The starting point
    
    <a id="_idIndexMarker678">
    </a>
    
     and preferred solution for any
    
    <strong class="bold">
     
      Boost.Asio
     
    </strong>
    
     application should follow a single-threaded approach where the I/O execution context object runs in the same thread where the completion handlers are being processed.
    
    
     These handlers must be short and non-blocking.
    
    
     Here is an example of a steady timer completion handler running in the same thread as the I/O context, the
    
    
     
      main thread:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
using namespace std::chrono_literals;
void handle_timer_expiry(
            const boost::system::error_code&amp; ec) {
    if (!ec) {
        std::cout &lt;&lt; "Timer expired!\n";
    } else {
        std::cerr &lt;&lt; "Error in timer: "
                  &lt;&lt; ec.message() &lt;&lt; std::endl;
    }
}
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context,
                              std::chrono::seconds(1));
    timer.async_wait(&amp;handle_timer_expiry);
    io_context.run();
    return 0;
}</pre>
   <p>
    
     As we can see, the
    
    <strong class="source-inline">
     
      steady_timer
     
    </strong>
    
     timer calls the asynchronous
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     function, setting up the
    
    <strong class="source-inline">
     
      handle_timer_expiry()
     
    </strong>
    
     completion handler, in the same thread that the
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     function is being executed in.
    
    
     When the asynchronous function finishes, its completion handler will run in the
    
    
     
      same thread.
     
    
   </p>
   <p>
    
     As the completion handler is running in the main thread, its execution should be quick to avoid freezing the main thread and other relevant tasks that the program should perform.
    
    
     In the next section, we will learn how to deal with long-running tasks or completion handlers
    
    <a id="_idIndexMarker679">
    </a>
    
     and keep the main
    
    
     
      thread responsive.
     
    
   </p>
   <h2 id="_idParaDest-198">
    <a id="_idTextAnchor197">
    </a>
    
     Threaded long-running tasks
    
   </h2>
   <p>
    
     For long-running tasks, we
    
    <a id="_idIndexMarker680">
    </a>
    
     can keep the logic in the main thread but use other threads to pass work and get results back to the
    
    
     
      main thread:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
void long_running_task(boost::asio::io_context&amp; io_context,
                       int task_duration) {
    std::cout &lt;&lt; "Background task started: Duration = "
              &lt;&lt; task_duration &lt;&lt; " seconds.\n";
    std::this_thread::sleep_for(
                      std::chrono::seconds(task_duration));
    io_context.post([&amp;io_context]() {
        std::cout &lt;&lt; "Background task completed.\n";
        io_context.stop();
    });
}
int main() {
    boost::asio::io_context io_context;
    auto work_guard = boost::asio::make_work_guard
                                        (io_context);
    io_context.post([&amp;io_context]() {
        std::thread t(long_running_task,
                      std::ref(io_context), 2);
        std::cout &lt;&lt; "Detaching thread" &lt;&lt; std::endl;
        t.detach();
    });
    std::cout &lt;&lt; "Running io_context...\n";
    io_context.run();
    std::cout &lt;&lt; "io_context exit.\n";
    return 0;
}</pre>
   <p>
    
     In this example, after
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     is created, a work guard is used to avoid the
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     function
    
    <a id="_idIndexMarker681">
    </a>
    
     to immediately return before any work
    
    
     
      is posted.
     
    
   </p>
   <p>
    
     The posted work consists of a
    
    <strong class="source-inline">
     
      t
     
    </strong>
    
     thread being created to run the
    
    <strong class="source-inline">
     
      long_running_task()
     
    </strong>
    
     function in the background.
    
    
     That
    
    <strong class="source-inline">
     
      t
     
    </strong>
    
     thread is detached before the lambda function exits; otherwise, the program
    
    
     
      would terminate.
     
    
   </p>
   <p>
    
     In the background task function, the current thread sleeps for a given period and then posts another task into the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object to print a message and stop
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     itself.
    
    
     If we don’t call
    
    <strong class="source-inline">
     
      io_context.stop()
     
    </strong>
    
     , the event processing loop will continue running forever and the program will not finish, as
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     will
    
    <a id="_idIndexMarker682">
    </a>
    
     continue blocking due to the
    
    
     
      work guard.
     
    
   </p>
   <h2 id="_idParaDest-199">
    <a id="_idTextAnchor198">
    </a>
    
     Multiple I/O execution context objects, one per thread
    
   </h2>
   <p>
    
     This approach is like the
    
    <a id="_idIndexMarker683">
    </a>
    
     single-threaded one, where each thread has its own
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object and processes short and non-blocking
    
    
     
      completion handlers:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;syncstream&gt;
#include &lt;thread&gt;
#define sync_cout std::osyncstream(std::cout)
using namespace std::chrono_literals;
void background_task(int i) {
    sync_cout &lt;&lt; "Thread " &lt;&lt; i &lt;&lt; ": Starting...\n";
    boost::asio::io_context io_context;
    auto work_guard =
              boost::asio::make_work_guard(io_context);
    sync_cout &lt;&lt; "Thread " &lt;&lt; i &lt;&lt; ": Setup timer...\n";
    boost::asio::steady_timer timer(io_context, 1s);
    timer.async_wait(
        [&amp;](const boost::system::error_code&amp; ec) {
            if (!ec) {
                sync_cout &lt;&lt; "Timer expired successfully!"
                          &lt;&lt; std::endl;
            } else {
                sync_cout &lt;&lt; "Timer error: "
                          &lt;&lt; ec.message() &lt;&lt; ‚\n';
        }
        work_guard.reset();
    });
    sync_cout &lt;&lt; "Thread " &lt;&lt; i &lt;&lt; ": Running
                      io_context...\n";
    io_context.run();
}
int main() {
    const int num_threads = 4;
    std::vector&lt;std::jthread&gt; threads;
    for (auto i = 0; i &lt; num_threads; ++i) {
        threads.emplace_back(background_task, i);
    }
    return 0;
}</pre>
   <p>
    
     In this example, four threads are created, each one running the
    
    <strong class="source-inline">
     
      background_task()
     
    </strong>
    
     function where an
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object is created, and a timer is set up
    
    <a id="_idIndexMarker684">
    </a>
    
     to timeout after one second together with its
    
    
     
      completion handler.
     
    
   </p>
   <h2 id="_idParaDest-200">
    <a id="_idTextAnchor199">
    </a>
    
     Multiple threads with a single I/O execution context object
    
   </h2>
   <p>
    
     Now, there is
    
    <a id="_idIndexMarker685">
    </a>
    
     only one
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object but it is starting the asynchronous tasks from different I/O objects from different threads.
    
    
     In this case, the completion handlers can be called from any of those threads.
    
    
     Here is
    
    
     
      an example:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;syncstream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
#define sync_cout std::osyncstream(std::cout)
using namespace std::chrono_literals;
void background_task(int task_id) {
    boost::asio::post([task_id]() {
        sync_cout &lt;&lt; "Task " &lt;&lt; task_id
                  &lt;&lt; " is being handled in thread "
                  &lt;&lt; std::this_thread::get_id()
                  &lt;&lt; std::endl;
        std::this_thread::sleep_for(2s);
        sync_cout &lt;&lt; "Task " &lt;&lt; task_id
                  &lt;&lt; " complete.\n";
    });
}
int main() {
    boost::asio::io_context io_context;
    auto work_guard = boost::asio::make_work_guard(
                                   io_context);
    std::jthread io_context_thread([&amp;io_context]() {
        io_context.run();
    });
    const int num_threads = 4;
    std::vector&lt;std::jthread&gt; threads;
    for (int i = 0; i &lt; num_threads; ++i) {
        background_task(i);
    }
    std::this_thread::sleep_for(5s);
    work_guard.reset();
    return 0;
}</pre>
   <p>
    
     In this example, only
    
    <a id="_idIndexMarker686">
    </a>
    
     one
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object is created and run in a separate thread,
    
    <strong class="source-inline">
     
      io_context_thread
     
    </strong>
    
     .
    
    
     Then, an additional four background threads are created, where work is posted into the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object.
    
    
     Finally, the main thread waits for five seconds to let all threads finish their work and resets the work guard, letting the
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     function return if there is no more pending work.
    
    
     When the program exits, all
    
    <a id="_idIndexMarker687">
    </a>
    
     threads automatically join, as they are instances
    
    
     
      of
     
    
    
     <strong class="source-inline">
      
       std::jthread
      
     </strong>
    
    
     
      .
     
    
   </p>
   <h2 id="_idParaDest-201">
    <a id="_idTextAnchor200">
    </a>
    
     Parallelizing work done by one I/O execution context
    
   </h2>
   <p>
    
     In the previous
    
    <a id="_idIndexMarker688">
    </a>
    
     example, a unique I/O execution context object was used with its
    
    <strong class="source-inline">
     
      run()
     
    </strong>
    
     function being called from different threads.
    
    
     Then, each thread posted some work that completion handlers were executing in available threads at the time
    
    
     
      of completion.
     
    
   </p>
   <p>
    
     This is a common way to parallelize work done by one I/O execution context, by calling its
    
    <strong class="source-inline">
     
      run()
     
    </strong>
    
     function from multiple threads, distributing the processing of asynchronous operations across those threads.
    
    
     This is possible because the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object provides a thread-safe event
    
    
     
      dispatching system.
     
    
   </p>
   <p>
    
     Here is another example where a pool of threads is created, with each thread running
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     , making these threads compete to pull tasks from the queue and execute them.
    
    
     In this case, only one asynchronous task is created using a timer that expires in two seconds.
    
    
     One of the threads will pick up the task and
    
    
     
      execute it:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
using namespace std::chrono_literals;
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 2s);
    timer.async_wait(
        [](const boost::system::error_code&amp; /*ec*/) {
            std::cout &lt;&lt; "Timer expired!\n";
    });
    const std::size_t num_threads =
                std::thread::hardware_concurrency();
    std::vector&lt;std::thread&gt; threads;
    for (std::size_t i = 0;
         i &lt; std::thread::hardware_concurrency(); ++i) {
            threads.emplace_back([&amp;io_context]() {
                io_context.run();
            });
    }
    for (auto&amp; t : threads) {
        t.join();
    }
    return 0;
}</pre>
   <p>
    
     This technique
    
    <a id="_idIndexMarker689">
    </a>
    
     improves scalability, as the application better utilizes multiple cores, and reduces latency by handling asynchronous tasks concurrently.
    
    
     Also, contention can be reduced and throughput increased by reducing bottlenecks generated when single-threaded code processes many simultaneous
    
    
     
      I/O operations.
     
    
   </p>
   <p>
    
     Note that the completion handlers also must use synchronization primitives and be thread-safe if they are shared across different threads or modify
    
    
     
      shared resources.
     
    
   </p>
   <p>
    
     Also, there is no guarantee in the order the completion handlers will be executed.
    
    
     As many threads can run simultaneously, any of them can complete earlier and call its associated
    
    
     
      completion handler.
     
    
   </p>
   <p>
    
     As threads are competing to pull tasks from the queue, there might be potential lock contention or context-switching overhead if the thread pool size is not optimal, ideally matching the number of hardware threads, as done in
    
    
     
      this example.
     
    
   </p>
   <p>
    
     Now, it’s time to
    
    <a id="_idIndexMarker690">
    </a>
    
     understand how the objects’ lifetime can affect the stability of our asynchronous programs developed
    
    
     
      with Boost.Asio.
     
    
   </p>
   <h1 id="_idParaDest-202">
    <a id="_idTextAnchor201">
    </a>
    
     Managing objects’ lifetime
    
   </h1>
   <p>
    
     One of the main
    
    <a id="_idIndexMarker691">
    </a>
    
     disastrous issues that can happen with asynchronous operations is that, when the operation takes place, some of the required objects have been destroyed.
    
    
     Therefore, managing objects’ lifetimes
    
    
     
      is crucial.
     
    
   </p>
   <p>
    
     In C++, an object’s lifetime begins when the constructor ends and ends when the
    
    
     
      destructor begins.
     
    
   </p>
   <p>
    
     A common pattern used to keep objects alive is to let the object create a shared pointer instance to itself, ensuring that the object remains valid as long as there are shared pointers pointing to it, meaning that there are ongoing asynchronous operations needing
    
    
     
      that object.
     
    
   </p>
   <p>
    
     This technique is called
    
    <strong class="source-inline">
     
      shared-from-this
     
    </strong>
    
     and uses the
    
    <strong class="source-inline">
     
      std::enable_shared_from_this
     
    </strong>
    
     template base class, available since C++11, which provides the
    
    <strong class="source-inline">
     
      shared_from_this()
     
    </strong>
    
     method used by the object to obtain a shared pointer
    
    
     
      to itself.
     
    
   </p>
   <h2 id="_idParaDest-203">
    <a id="_idTextAnchor202">
    </a>
    
     Implementing an echo server – an example
    
   </h2>
   <p>
    
     Let’s see how it works by
    
    <a id="_idIndexMarker692">
    </a>
    
     creating an echo server.
    
    
     At the same time, we will be discussing this technique, we will also be learning about how to use Boost.Asio
    
    
     
      for networking.
     
    
   </p>
   <p>
    
     Transmission of data over a network can take a long time to complete, and several errors can occur.
    
    
     That makes network I/O services a special good case to be dealt with by Boost.Asio.
    
    
     Network I/O services were the first services to be included in
    
    
     
      the library.
     
    
   </p>
   <p>
    
     The main common usage of Boost.Asio in the industry is to develop networking applications due to its support for the internet protocols TCP, UDP, and ICMP.
    
    
     The library also provides a socket interface based on the
    
    <strong class="bold">
     
      Berkeley Software Distribution
     
    </strong>
    
     (
    
    <strong class="bold">
     
      BSD
     
    </strong>
    
     ) socket API to
    
    <a id="_idIndexMarker693">
    </a>
    
     allow the development of efficient and scalable applications using a
    
    
     
      low-level interface.
     
    
   </p>
   <p>
    
     However, as, in this book, we are interested in asynchronous programming, let’s focus on implementing an echo server using a
    
    
     
      high-level interface.
     
    
   </p>
   <p>
    
     An echo server is a program that listens to a specific address and port and writes back everything that it reads from that port.
    
    
     For that purpose, we will create a
    
    
     
      TCP server.
     
    
   </p>
   <p>
    
     The main program will simply create an
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object, set up the
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     object by passing the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object and a port number to listen from, and call
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     to start
    
    <a id="_idIndexMarker694">
    </a>
    
     the event
    
    
     
      processing loop:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;memory&gt;
constexpr int port = 1234;
int main() {
    try {
        boost::asio::io_context io_context;
        EchoServer server(io_context, port);
        io_context.run();
    } catch (std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; "\n";
    }
    return 0;
}</pre>
   <p>
    
     When
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     initializes, it will start listening for incoming connections.
    
    
     It does that by using a
    
    <strong class="source-inline">
     
      boost::asio::tcp::acceptor
     
    </strong>
    
     object.
    
    
     This object accepts via its constructor an
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object (as usual for I/O objects) and a
    
    <strong class="source-inline">
     
      boost::asio::tcp::endpoint
     
    </strong>
    
     object, which indicates the connection protocol and port number used for listening.
    
    
     As a
    
    <strong class="source-inline">
     
      boost::asio::tcp::v4()
     
    </strong>
    
     object is used to initialize the endpoint object, the protocol that the
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     will use is IPv4.
    
    
     The IP address is not specified to the endpoint constructor, therefore the endpoint IP address will be
    
    <em class="italic">
     
      any address
     
    </em>
    
     (
    
    <strong class="source-inline">
     
      INADDR_ANY
     
    </strong>
    
     for IPv4 or
    
    <strong class="source-inline">
     
      in6addr_any
     
    </strong>
    
     for IPv6).
    
    
     Next, the code implementing
    
    <a id="_idIndexMarker695">
    </a>
    
     the
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     constructor is
    
    
     
      as follows:
     
    
   </p>
   <pre class="source-code">
using boost::asio::ip::tcp;
class EchoServer {
   public:
    EchoServer(boost::asio::io_context&amp; io_context,
               short port)
        : acceptor_(io_context,
                    tcp::endpoint(tcp::v4(),
                    port)) {
        do_accept();
    }
   private:
    void do_accept() {
        acceptor_.async_accept([this](
                    boost::system::error_code ec,
                    tcp::socket socket) {
            if (!ec) {
                std::make_shared&lt;Session&gt;(
                    std::move(socket))-&gt;start();
            }
            do_accept();
        });
    }
    tcp::acceptor acceptor_;
};</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     constructor calls the
    
    <strong class="source-inline">
     
      do_accept()
     
    </strong>
    
     function after setting up the acceptor object.
    
    
     The
    
    <strong class="source-inline">
     
      do_accept()
     
    </strong>
    
     function calls the
    
    <strong class="source-inline">
     
      async_accept()
     
    </strong>
    
     function waiting for incoming connections.
    
    
     When a client connects to the server, the OS returns the connection’s socket (
    
    <strong class="source-inline">
     
      boost::asio::tcp::socket
     
    </strong>
    
     ) or an error via the
    
    
     <strong class="source-inline">
      
       io_context
      
     </strong>
    
    
     
      object.
     
    
   </p>
   <p>
    
     If there is no error and a connection is established, a shared pointer of a
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object is created, moving the socket into the
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object.
    
    
     Then, the
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object runs the
    
    
     <strong class="source-inline">
      
       start()
      
     </strong>
    
    
     
      function.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object
    
    <a id="_idIndexMarker696">
    </a>
    
     encapsulates the state of a particular connection, in this case, the
    
    <strong class="source-inline">
     
      socket_
     
    </strong>
    
     object and the
    
    <strong class="source-inline">
     
      data_
     
    </strong>
    
     buffer.
    
    
     It also manages asynchronous reads and writes into that buffer by using
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      do_write()
     
    </strong>
    
     , which we will implement in a moment.
    
    
     But before this, comment that
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     inherits from
    
    <strong class="source-inline">
     
      std::enable_shared_from_this&lt;Session&gt;
     
    </strong>
    
     , allowing
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     objects to create shared pointers to themselves, ensuring that the session objects remain alive throughout the lifetime of asynchronous operations needing them, as long as there is at least one shared pointer pointing to a
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     instance managing that connection.
    
    
     This shared pointer is the one created in the
    
    <strong class="source-inline">
     
      do_accept()
     
    </strong>
    
     function in the
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     object when the connection was established.
    
    
     Here is the implementation of the
    
    
     <strong class="source-inline">
      
       Session
      
     </strong>
    
    
     
      class:
     
    
   </p>
   <pre class="source-code">
class Session
    : public std::enable_shared_from_this&lt;Session&gt;
{
   public:
    Session(tcp::socket socket)
        : socket_(std::move(socket)) {}
    void start() { do_read(); }
   private:
    static const size_t max_length = 1024;
    void do_read();
    void do_write(std::size_t length);
    tcp::socket socket_;
    char data_[max_length];
};</pre>
   <p>
    
     Using a
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     class allows us to separate the logic that manages the connection from the one that manages the server.
    
    <strong class="source-inline">
     
      EchoServer
     
    </strong>
    
     just needs to accept connections and create a
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object per connection.
    
    
     That way, a server can manage multiple clients, keeping their connections independent and
    
    
     
      asynchronously managed.
     
    
   </p>
   <p>
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     is the one that
    
    <a id="_idIndexMarker697">
    </a>
    
     manages the behavior of that connection using the
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      do_write()
     
    </strong>
    
     functions.
    
    
     When
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     starts, its
    
    <strong class="source-inline">
     
      start()
     
    </strong>
    
     function calls the
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     function, as
    
    
     
      shown here:
     
    
   </p>
   <pre class="source-code">
void Session::do_read() {
    auto self(shared_from_this());
    socket_.async_read_some(boost::asio::buffer(data_,
                                          max_length),
        [this, self](boost::system::error_code ec,
                     std::size_t length) {
            if (!ec) {
                do_write(length);
            }
        });
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     function creates a shared pointer to the current session object (
    
    <strong class="source-inline">
     
      self
     
    </strong>
    
     ) and uses the socket’s
    
    <strong class="source-inline">
     
      async_read_some()
     
    </strong>
    
     asynchronous function to read some data into the
    
    <strong class="source-inline">
     
      data_
     
    </strong>
    
     buffer.
    
    
     If successful, this operation returns the data copied into the
    
    <strong class="source-inline">
     
      data_
     
    </strong>
    
     buffer and the number of read bytes in the
    
    
     <strong class="source-inline">
      
       length
      
     </strong>
    
    
     
      variable.
     
    
   </p>
   <p>
    
     Then,
    
    <strong class="source-inline">
     
      do_write()
     
    </strong>
    
     is called with that
    
    <strong class="source-inline">
     
      length
     
    </strong>
    
     variable, asynchronously writing the content of the
    
    <strong class="source-inline">
     
      data_
     
    </strong>
    
     buffer into the socket by using the
    
    <strong class="source-inline">
     
      async_write()
     
    </strong>
    
     function.
    
    
     When this asynchronous operation succeeds, it restarts the cycle by calling again the
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     function, as
    
    <a id="_idIndexMarker698">
    </a>
    
     
      shown here:
     
    
   </p>
   <pre class="source-code">
void Session::do_write(std::size_t length) {
    auto self(shared_from_this());
    boost::asio::async_write(socket_,
                             boost::asio::buffer(data_,
                                                length),
        [this, self](boost::system::error_code ec,
                     std::size_t length) {
            if (!ec) {
                do_read();
            }
        });
}</pre>
   <p>
    
     You might wonder why it is that
    
    <strong class="source-inline">
     
      self
     
    </strong>
    
     is defined but is not being used.
    
    
     It looks like
    
    <strong class="source-inline">
     
      self
     
    </strong>
    
     is redundant, but as the lambda function is capturing it by value, a copy is being created, increasing the reference count of the shared pointer to the
    
    <strong class="source-inline">
     
      this
     
    </strong>
    
     object, ensuring that the session will not be destroyed if the lambda is active.
    
    
     The
    
    <strong class="source-inline">
     
      this
     
    </strong>
    
     object is captured to provide access to its members into the
    
    
     
      lambda function.
     
    
   </p>
   <p>
    
     As an exercise, try to implement a
    
    <strong class="source-inline">
     
      stop()
     
    </strong>
    
     function that breaks the cycle between
    
    <strong class="source-inline">
     
      do_read()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      do_write()
     
    </strong>
    
     .
    
    
     Once all asynchronous operations are complete and the lambda functions exit, the
    
    <strong class="source-inline">
     
      self
     
    </strong>
    
     objects will be destroyed and there will be no other shared pointers pointing to the
    
    <strong class="source-inline">
     
      Session
     
    </strong>
    
     object, thus the session will
    
    
     
      be destroyed.
     
    
   </p>
   <p>
    
     This pattern ensures robust and safe management of objects’ lifetimes during asynchronous operations, avoiding dangling pointers or early destruction, which would lead to undesired behavior
    
    
     
      or crashes.
     
    
   </p>
   <p>
    
     To test this server, just start the server, open a new terminal, and use the
    
    <strong class="source-inline">
     
      telnet
     
    </strong>
    
     command to connect to the server and send data to it.
    
    
     As arguments, we can pass the
    
    <strong class="source-inline">
     
      localhost
     
    </strong>
    
     address, indicating that we are connecting to a server running on the same machine (IP address of
    
    <strong class="source-inline">
     
      127.0.0.1
     
    </strong>
    
     ) and the port, in this
    
    
     
      case,
     
    
    
     <strong class="source-inline">
      
       1234
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      telnet
     
    </strong>
    
     command will start and show some information about the connection and indicate that we need to hit the
    
    <em class="italic">
     
      Ctrl
     
    </em>
    
     +
    
    <em class="italic">
     
      }
     
    </em>
    
     keys to close
    
    
     
      the connection.
     
    
   </p>
   <p>
    
     Typing anything and hitting the
    
    <em class="italic">
     
      Enter
     
    </em>
    
     key will send that entered line to the echo server, which will listen and send
    
    <a id="_idIndexMarker699">
    </a>
    
     back the same content; in this example, it will be
    
    
     <strong class="source-inline">
      
       Hello world!
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Just close the connection and exit
    
    <strong class="source-inline">
     
      telnet
     
    </strong>
    
     by using the
    
    <strong class="source-inline">
     
      quit
     
    </strong>
    
     command to exit back to
    
    
     
      the terminal:
     
    
   </p>
   <pre class="console">
$ telnet localhost 1234
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
Hello world!
Hello world!
telnet&gt; quit
Connection closed.</pre>
   <p>
    
     In this example, we have
    
    <a id="_idIndexMarker700">
    </a>
    
     already used a buffer.
    
    
     Let’s learn a bit more about them in the
    
    
     
      next section.
     
    
   </p>
   <h1 id="_idParaDest-204">
    <a id="_idTextAnchor203">
    </a>
    
     Transferring data using buffers
    
   </h1>
   <p>
    <strong class="bold">
     
      Buffers
     
    </strong>
    
     are contiguous
    
    <a id="_idIndexMarker701">
    </a>
    
     regions of memory used during I/O operations to
    
    
     
      transfer data.
     
    
   </p>
   <p>
    
     Boost.Asio defines two types of
    
    <a id="_idIndexMarker702">
    </a>
    
     buffers:
    
    <strong class="bold">
     
      mutable buffers
     
    </strong>
    
     (
    
    <strong class="source-inline">
     
      boost::asio::mutable_buffer
     
    </strong>
    
     ), where data can be written, and
    
    <strong class="bold">
     
      constant buffers
     
    </strong>
    
     (
    
    <strong class="source-inline">
     
      boost::asio::const_buffers
     
    </strong>
    
     ), which
    
    <a id="_idIndexMarker703">
    </a>
    
     are used to create read-only buffers.
    
    
     Mutable buffers can be converted into constant buffers, but not the opposite.
    
    
     Both types of buffers provide protection
    
    
     
      against overruns.
     
    
   </p>
   <p>
    
     There is also the
    
    <strong class="source-inline">
     
      boost::buffer
     
    </strong>
    
     function to help with the creation of mutable or constant buffers from different data types (a pointer to raw memory and size, a string (
    
    <strong class="source-inline">
     
      std::string
     
    </strong>
    
     ), or an array or vector
    
    <a id="_idIndexMarker704">
    </a>
    
     of
    
    <strong class="bold">
     
      plain old data
     
    </strong>
    
     (
    
    <strong class="bold">
     
      POD
     
    </strong>
    
     ) structures (meaning a type, a structure, or a class that has no user-defined copy assignment operator or destructor, and without private or protected non-static data members).
    
    
     For example, to create a buffer from an array of chars, we can use
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
char data[1024];
mutable_buffer buffer = buffer(data, sizeof(data));</pre>
   <p>
    
     Also, note that the buffer’s ownership and lifetime are the responsibility of the program, not the
    
    
     
      Boost.Asio library.
     
    
   </p>
   <h2 id="_idParaDest-205">
    <a id="_idTextAnchor204">
    </a>
    
     Scatter-gather operations
    
   </h2>
   <p>
    
     Buffers can be used
    
    <a id="_idIndexMarker705">
    </a>
    
     efficiently by using scatter-gather
    
    <a id="_idIndexMarker706">
    </a>
    
     operations where multiple buffers are used together to receive data (scatter-read) or to send
    
    
     
      data (gather-write).
     
    
   </p>
   <p>
    <strong class="bold">
     
      Scatter-read
     
    </strong>
    
     is the process of reading data from a unique source into different non-contiguous
    
    
     
      memory buffers.
     
    
   </p>
   <p>
    <strong class="bold">
     
      Gather-write
     
    </strong>
    
     is the opposite
    
    <a id="_idIndexMarker707">
    </a>
    
     process; data is gathered from different non-contiguous memory buffers and written into a
    
    
     
      single destination.
     
    
   </p>
   <p>
    
     These techniques increase efficiency and performance as they reduce the number of system calls or data copying.
    
    
     They are not only used for I/O operations but also in other use cases, such as data processing, machine learning, or parallel algorithms, such as sorting or
    
    
     
      matrix multiplication.
     
    
   </p>
   <p>
    
     To allow scatter-gather operations, several buffers can be passed together to the asynchronous operation inside a container (
    
    <strong class="source-inline">
     
      std::vector
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::list
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::array
     
    </strong>
    
     ,
    
    
     
      or
     
    
    
     <strong class="source-inline">
      
       boost::array
      
     </strong>
    
    
     
      ).
     
    
   </p>
   <p>
    
     Here is an example of scatter-read where a socket reads some data asynchronously into both the
    
    <strong class="source-inline">
     
      buf1
     
    </strong>
    
     and
    
    
     <strong class="source-inline">
      
       buf2
      
     </strong>
    
    
     
      buffers:
     
    
   </p>
   <pre class="source-code">
std::array&lt;char, 128&gt; buf1, buf2;
std::vector&lt;boost::asio::mutable_buffer&gt; buffers = {
    boost::asio::buffer(buf1),
    boost::asio::buffer(buf2)
};
socket.async_read_some(buffers, handler);</pre>
   <p>
    
     Here is how to achieve
    
    
     
      a gather-read:
     
    
   </p>
   <pre class="source-code">
std::array&lt;char, 128&gt; buf1, buf2;
std::vector&lt;boost::asio::const_buffer&gt; buffers = {
    boost::asio::buffer(buf1),
    boost::asio::buffer(buf2)
};
socket.async_write_some(buffers, handler);</pre>
   <p>
    
     Now, the socket
    
    <a id="_idIndexMarker708">
    </a>
    
     does the opposite operation, writing
    
    <a id="_idIndexMarker709">
    </a>
    
     some data from both buffers into the socket buffer for
    
    
     
      asynchronous sending.
     
    
   </p>
   <h2 id="_idParaDest-206">
    <a id="_idTextAnchor205">
    </a>
    
     Stream buffers
    
   </h2>
   <p>
    
     We can also use
    
    <a id="_idIndexMarker710">
    </a>
    
     stream buffers to manage data.
    
    <strong class="bold">
     
      Stream buffers
     
    </strong>
    
     are
    
    <a id="_idIndexMarker711">
    </a>
    
     defined by the
    
    <strong class="source-inline">
     
      boost::asio::basic_streambuf
     
    </strong>
    
     class, based in the
    
    <strong class="source-inline">
     
      std::basic_streambuf
     
    </strong>
    
     C++ class and defined in the
    
    <strong class="source-inline">
     
      &lt;streambuf&gt;
     
    </strong>
    
     header file.
    
    
     It allows a dynamic buffer where its size can adapt to the amount of data
    
    
     
      being transferred.
     
    
   </p>
   <p>
    
     Let’s see in the following example how stream buffers work together with scatter-gather operations.
    
    
     In this case, we are implementing a TCP server that listens and accepts clients’ connections from a given port, reads the messages sent by the clients into two stream buffers, and prints their content to the console.
    
    
     As we are interested in understanding stream buffers and scatter-gather operations, let’s simplify the example by using
    
    
     
      synchronous operations.
     
    
   </p>
   <p>
    
     As in the previous example, in the
    
    <strong class="source-inline">
     
      main()
     
    </strong>
    
     function, we use a
    
    <strong class="source-inline">
     
      boost::asio::ip::tcp::acceptor
     
    </strong>
    
     object to set up the protocol and port that the TCP server will use to accept connections.
    
    
     Then, in an infinite loop, the server uses that acceptor object to attach a TCP socket (
    
    <strong class="source-inline">
     
      boost::asio::ip::tcp::socket
     
    </strong>
    
     ) and
    
    <a id="_idIndexMarker712">
    </a>
    
     call
    
    <a id="_idIndexMarker713">
    </a>
    
     the
    
    
     <strong class="source-inline">
      
       handle_client()
      
     </strong>
    
    
     
      function:
     
    
   </p>
   <pre class="source-code">
#include &lt;array&gt;
#include &lt;iostream&gt;
#include &lt;boost/asio.hpp&gt;
#include &lt;boost/asio/streambuf.hpp&gt;
using boost::asio::ip::tcp;
constexpr int port = 1234;
int main() {
    try {
        boost::asio::io_context io_context;
        tcp::acceptor acceptor(io_context,
                      tcp::endpoint(tcp::v4(), port));
        std::cout &lt;&lt; "Server is running on port "
                  &lt;&lt; port &lt;&lt; "...\n";
        while (true) {
            tcp::socket socket(io_context);
            acceptor.accept(socket);
            std::cout &lt;&lt; "Client connected...\n";
            handle_client(socket);
            std::cout &lt;&lt; "Client disconnected...\n";
        }
    } catch (std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; '\n';
    }
    return 0;
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      handle_client()
     
    </strong>
    
     function creates two stream buffers:
    
    <strong class="source-inline">
     
      buf1
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      buf2
     
    </strong>
    
     , and adds them to a container, in this case,
    
    <strong class="source-inline">
     
      std::array
     
    </strong>
    
     , to be used in
    
    
     
      scatter-gather operations.
     
    
   </p>
   <p>
    
     Then, the synchronous
    
    <strong class="source-inline">
     
      read_some()
     
    </strong>
    
     function from the socket is called.
    
    
     This function returns the number of bytes read from the socket and copies them into the buffers.
    
    
     If anything goes wrong with the socket connection, an error will be returned in the error code object,
    
    <strong class="source-inline">
     
      ec
     
    </strong>
    
     .
    
    
     In
    
    <a id="_idIndexMarker714">
    </a>
    
     that
    
    <a id="_idIndexMarker715">
    </a>
    
     case, the server will print the error message
    
    
     
      and exit.
     
    
   </p>
   <p>
    
     Here is
    
    
     
      the implementation:
     
    
   </p>
   <pre class="source-code">
void handle_client(tcp::socket&amp; socket) {
    const size_t size_buffer = 5;
    boost::asio::streambuf buf1, buf2;
    std::array&lt;boost::asio::mutable_buffer, 2&gt; buffers = {
        buf1.prepare(size_buffer),
        buf2.prepare(size_buffer)
    };
    boost::system::error_code ec;
    size_t bytes_recv = socket.read_some(buffers, ec);
    if (ec) {
        std::cerr &lt;&lt; "Error on receive: "
                  &lt;&lt; ec.message() &lt;&lt; '\n';
        return;
    }
    std::cout &lt;&lt; "Received " &lt;&lt; bytes_recv &lt;&lt; " bytes\n";
    buf1.commit(5);
    buf2.commit(5);
    std::istream is1(&amp;buf1);
    std::istream is2(&amp;buf2);
    std::string data1, data2;
    is1 &gt;&gt; data1;
    is2 &gt;&gt; data2;
    std::cout &lt;&lt; "Buffer 1: " &lt;&lt; data1 &lt;&lt; std::endl;
    std::cout &lt;&lt; "Buffer 2: " &lt;&lt; data2 &lt;&lt; std::endl;
}</pre>
   <p>
    
     If there are no
    
    <a id="_idIndexMarker716">
    </a>
    
     errors, the
    
    <a id="_idIndexMarker717">
    </a>
    
     stream buffers’
    
    <strong class="source-inline">
     
      commit()
     
    </strong>
    
     function is used to transfer five bytes to each of the stream buffers,
    
    <strong class="source-inline">
     
      buf1
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      buf2
     
    </strong>
    
     .
    
    
     The contents of these buffers are extracted by using
    
    <strong class="source-inline">
     
      std::istream
     
    </strong>
    
     objects and printed to
    
    
     
      the console.
     
    
   </p>
   <p>
    
     To execute this example, we need to open two terminals.
    
    
     In one terminal, we execute the server, and in the other, the
    
    <strong class="source-inline">
     
      telnet
     
    </strong>
    
     command, as shown earlier.
    
    
     In the
    
    <strong class="source-inline">
     
      telnet
     
    </strong>
    
     terminal, we can type a message (for example,
    
    <em class="italic">
     
      Hello World
     
    </em>
    
     ).
    
    
     This message is sent to the server.
    
    
     The server terminal will then show
    
    
     
      the following:
     
    
   </p>
   <pre class="console">
Server is running on port 1234...
Client connected...
Received 10 bytes
Buffer 1: Hello
Buffer 2: Worl
Client disconnected...</pre>
   <p>
    
     As we can see, only 10 bytes are processed and distributed into the two buffers.
    
    
     The space character between the two words is processed but discarded when parsing the input by the
    
    
     <strong class="source-inline">
      
       iostream
      
     </strong>
    
    
     
      objects.
     
    
   </p>
   <p>
    
     Stream buffers
    
    <a id="_idIndexMarker718">
    </a>
    
     are useful when the size of the incoming data is
    
    <a id="_idIndexMarker719">
    </a>
    
     variable and unknown in advance.
    
    
     These types of buffers can be used together with
    
    
     
      fixed-sized buffers.
     
    
   </p>
   <h1 id="_idParaDest-207">
    <a id="_idTextAnchor206">
    </a>
    
     Signal handling
    
   </h1>
   <p>
    <strong class="bold">
     
      Signal handling
     
    </strong>
    
     allows us
    
    <a id="_idIndexMarker720">
    </a>
    
     to catch signals sent by the OS and gracefully shut down
    
    <a id="_idIndexMarker721">
    </a>
    
     the application before the OS decides to kill the
    
    
     
      application’s process.
     
    
   </p>
   <p>
    
     Boost.Asio provides the
    
    <strong class="source-inline">
     
      boost::asio::signal_set
     
    </strong>
    
     class for this purpose, which starts an asynchronous wait for one or more signals
    
    
     
      to occur.
     
    
   </p>
   <p>
    
     This is an example of how to handle the
    
    <strong class="source-inline">
     
      SIGINT
     
    </strong>
    
     and
    
    
     <strong class="source-inline">
      
       SIGTERM
      
     </strong>
    
    
     
      signals:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;
int main() {
    try {
        boost::asio::io_context io_context;
        boost::asio::signal_set signals(io_context,
                                  SIGINT, SIGTERM);
        auto handle_signal = [&amp;](
                const boost::system::error_code&amp; ec,
                int signal) {
            if (!ec) {
                std::cout &lt;&lt; "Signal received: "
                          &lt;&lt; signal &lt;&lt; std::endl;
                // Code to perform cleanup or shutdown.
                io_context.stop();
            }
        };
        signals.async_wait(handle_signal);
        std::cout &lt;&lt; "Application is running. "
                  &lt;&lt; "Press Ctrl+C to stop...\n";
        io_context.run();
        std::cout &lt;&lt; "Application has exited cleanly.\n";
    } catch (std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; '\n';
    }
    return 0;
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      signals
     
    </strong>
    
     object is
    
    <strong class="source-inline">
     
      signal_set
     
    </strong>
    
     , listing the signals that the program waits for,
    
    <strong class="source-inline">
     
      SIGINT
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      SIGTERM
     
    </strong>
    
     .
    
    
     This object has an
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     method that asynchronously waits for any of those signals to happen and triggers the completion
    
    
     
      handler,
     
    
    
     <strong class="source-inline">
      
       handle_signal()
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     As usual in completion handlers,
    
    <strong class="source-inline">
     
      handle_signal()
     
    </strong>
    
     checks the error code,
    
    <strong class="source-inline">
     
      ec
     
    </strong>
    
     , and if there is no error, some cleanup code might execute to cleanly and gracefully exit the program.
    
    
     In this example, we just stop the event processing loop by
    
    
     
      calling
     
    
    
     <strong class="source-inline">
      
       io_context.stop()
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     We could also wait synchronously for signals by using the
    
    
     <strong class="source-inline">
      
       signals.wait()
      
     </strong>
    
    
     
      method.
     
    
   </p>
   <p>
    
     If the application is multithreaded, the signals event handler must run in the same thread as
    
    <a id="_idIndexMarker722">
    </a>
    
     the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object, typically
    
    <a id="_idIndexMarker723">
    </a>
    
     being the
    
    
     
      main thread.
     
    
   </p>
   <p>
    
     In the next section, we will learn how to
    
    
     
      cancel operations.
     
    
   </p>
   <h1 id="_idParaDest-208">
    <a id="_idTextAnchor207">
    </a>
    
     Canceling operations
    
   </h1>
   <p>
    
     Some I/O objects, such
    
    <a id="_idIndexMarker724">
    </a>
    
     as sockets or timers, have object-wide cancellation of
    
    <a id="_idIndexMarker725">
    </a>
    
     outstanding asynchronous operations by calling their
    
    <strong class="source-inline">
     
      close()
     
    </strong>
    
     or
    
    <strong class="source-inline">
     
      cancel()
     
    </strong>
    
     methods.
    
    
     If an asynchronous operation is canceled, the completion handler will receive an error with the
    
    
     <strong class="source-inline">
      
       boost::asio::error::operation_aborted
      
     </strong>
    
    
     
      code.
     
    
   </p>
   <p>
    
     In the following example, a timer is created, and its timeout period is set to five seconds.
    
    
     But after sleeping the main thread for only two seconds, the timer is canceled by calling its
    
    <strong class="source-inline">
     
      cancel()
     
    </strong>
    
     method, making the completion handler be called with a
    
    <strong class="source-inline">
     
      boost::asio::error::operation_aborted
     
    </strong>
    
     
      error code:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
using namespace std::chrono_literals;
void handle_timeout(const boost::system::error_code&amp; ec) {
    if (ec == boost::asio::error::operation_aborted) {
        std::cout &lt;&lt; "Timer canceled.\n";
    } else if (!ec) {
        std::cout &lt;&lt; "Timer expired.\n";
    } else {
        std::cout &lt;&lt; "Error: " &lt;&lt; ec.message()
                  &lt;&lt; std::endl;
    }
}
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 5s);
    timer.async_wait(handle_timeout);
    std::this_thread::sleep_for(2s);
    timer.cancel();
    io_context.run();
    return 0;
}</pre>
   <p>
    
     But if we want a per-operation cancellation, we need to set up a cancellation slot that will be triggered when a cancellation signal is emitted.
    
    
     This cancellation signal/slot pair composes a lightweight channel to communicate cancellation operations, like the ones created between promises and futures explained in
    
    <a href="B22219_06.xhtml#_idTextAnchor125">
     
      <em class="italic">
       
        Chapter 6
       
      </em>
     
    </a>
    
     .
    
    
     The cancellation framework has been available in Boost.Asio since
    
    
     
      version 1.75.
     
    
   </p>
   <p>
    
     This approach enables a more flexible cancellation mechanism where multiple operations can be canceled using the same signal, and it integrates seamlessly with Boost.Asio’s asynchronous operations.
    
    
     Synchronous operations can only be canceled by using the
    
    <strong class="source-inline">
     
      cancel()
     
    </strong>
    
     or
    
    <strong class="source-inline">
     
      close()
     
    </strong>
    
     methods described earlier; they are not supported by the cancellation
    
    
     
      slots mechanism.
     
    
   </p>
   <p>
    
     Let’s modify the previous example and use a cancellation signal/slot to cancel the timer.
    
    
     We only need to modify the way the timer is canceled in the
    
    <strong class="source-inline">
     
      main()
     
    </strong>
    
     function.
    
    
     Now, when the asynchronous
    
    <strong class="source-inline">
     
      async_wait()
     
    </strong>
    
     operation is executed, a cancellation slot is created by binding a slot from the cancellation signal and the completion handler using the
    
    
     <strong class="source-inline">
      
       boost::asio::bind_cancellation_slot()
      
     </strong>
    
    
     
      function.
     
    
   </p>
   <p>
    
     As before, the timer has an expiration period of five seconds, and again, the main thread only sleeps for two seconds.
    
    
     This time, a cancellation signal is emitted by calling the
    
    <strong class="source-inline">
     
      cancel_signal.emit()
     
    </strong>
    
     function.
    
    
     The signal will trigger the counterpart cancellation slot
    
    <a id="_idIndexMarker726">
    </a>
    
     and
    
    <a id="_idIndexMarker727">
    </a>
    
     execute the completion handler with a
    
    <strong class="source-inline">
     
      boost::asio::error::operation_aborted
     
    </strong>
    
     error code, printing in the console the
    
    <strong class="source-inline">
     
      Timer canceled.
     
    </strong>
    
     message; see
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 5s);
    boost::asio::cancellation_signal cancel_signal;
    timer.async_wait(boost::asio::bind_cancellation_slot(
        cancel_signal.slot(),
        handle_timeout
    ));
    std::this_thread::sleep_for(2s);
    cancel_signal.emit(
        boost::asio::cancellation_type::all);
    io_context.run();
    return 0;
}</pre>
   <p>
    
     When the signal is emitted, a cancellation type must be specified, letting the target operation know what the application requires and the operation guarantees, thus controlling the
    
    <a id="_idIndexMarker728">
    </a>
    
     scope
    
    <a id="_idIndexMarker729">
    </a>
    
     and behavior of
    
    
     
      the cancellation.
     
    
   </p>
   <p>
    
     The various categories of cancellation are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       None
      
     </strong>
     
      : No cancellation is performed.
     
     
      It can be useful if we want to test if a cancellation
     
     
      
       should occur.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       Terminal
      
     </strong>
     
      : The operation has unspecified side effects so the only safe way to cancel the operation is to close or destroy the I/O object, being its result final, for example, completing a task
     
     
      
       or transaction.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       Partial
      
     </strong>
     
      : The operation has well-defined side effects so the completion handler can take the required actions to resolve the issue, meaning that the operation is partially completed and can be resumed
     
     
      
       or retried.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       Total
      
     </strong>
     
      or
     
     <strong class="source-inline">
      
       All
      
     </strong>
     
      : The operation has no side effects.
     
     
      Cancels both terminal and partial operations, enabling a comprehensive cancellation by stopping all ongoing
     
     
      
       asynchronous operations.
      
     
    </li>
   </ul>
   <p>
    
     If the cancellation type is not supported by the asynchronous operation, the cancellation request is discarded.
    
    
     For example, timer operations support all categories of cancellation, but sockets only support
    
    <strong class="source-inline">
     
      Total
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      All
     
    </strong>
    
     , meaning that if we try to cancel a socket asynchronous operation with a
    
    <strong class="source-inline">
     
      Partial
     
    </strong>
    
     cancellation, this cancellation will be ignored.
    
    
     This prevents undefined behavior if an I/O system tries to handle an unsupported
    
    
     
      cancellation request.
     
    
   </p>
   <p>
    
     Also, cancellation requests made after the operation is initiated but before it starts, or after its completion, have
    
    
     
      no effect.
     
    
   </p>
   <p>
    
     Sometimes, we need
    
    <a id="_idIndexMarker730">
    </a>
    
     to run some work sequentially.
    
    
     Next, we will introduce how we
    
    <a id="_idIndexMarker731">
    </a>
    
     can achieve this by
    
    
     
      using strands.
     
    
   </p>
   <h1 id="_idParaDest-209">
    <a id="_idTextAnchor208">
    </a>
    
     Serializing workload with strands
    
   </h1>
   <p>
    
     A
    
    <strong class="bold">
     
      strand
     
    </strong>
    
     is a strict
    
    <a id="_idIndexMarker732">
    </a>
    
     sequential
    
    <a id="_idIndexMarker733">
    </a>
    
     and non-concurrent invocation of completion handlers.
    
    
     Using strands, asynchronous operations can be sequenced without explicit locking by using mutexes or other synchronization mechanisms seen earlier in this book.
    
    
     Strands can be implicit
    
    
     
      or explicit.
     
    
   </p>
   <p>
    
     As shown earlier in this chapter, if we execute
    
    <strong class="source-inline">
     
      boost::asio::io_context::run()
     
    </strong>
    
     from only one thread, all event handlers will execute in an implicit strand, as they will be sequentially queued one by one and triggered from the I/O
    
    
     
      execution context.
     
    
   </p>
   <p>
    
     Another implicit strand happens when there are chained asynchronous operations where one asynchronous operation schedules the next asynchronous operation, and so on.
    
    
     Some previous examples in this chapter already used this technique, but here there is
    
    
     
      another one.
     
    
   </p>
   <p>
    
     In this case, if there are no errors, the timer keeps restarting itself in the
    
    <strong class="source-inline">
     
      handle_timer_expiry()
     
    </strong>
    
     event handler by recursively setting up the expiration time and calling the
    
    
     <strong class="source-inline">
      
       async_wait()
      
     </strong>
    
    
     
      method:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
using namespace std::chrono_literals;
void handle_timer_expiry(boost::asio::steady_timer&amp; timer,
                        int count) {
    std::cout &lt;&lt; "Timer expired. Count: " &lt;&lt; count
              &lt;&lt; std::endl;
    timer.expires_after(1s);
    timer.async_wait([&amp;timer, count](
                const boost::system::error_code&amp; ec) {
        if (!ec) {
            handle_timer_expiry(timer, count + 1);
        } else {
            std::cerr &lt;&lt; „Error: „ &lt;&lt; ec.message()
                      &lt;&lt; std::endl;
        }
    });
}
int main() {
    boost::asio::io_context io_context;
    boost::asio::steady_timer timer(io_context, 1s);
    int count = 0;
    timer.async_wait([&amp;](
                const boost::system::error_code&amp; ec) {
        if (!ec) {
            handle_timer_expiry(timer, count);
        } else {
            std::cerr &lt;&lt; "Error: " &lt;&lt; ec.message()
                      &lt;&lt; std::endl;
        }
    });
    io_context.run();
    return 0;
}</pre>
   <p>
    
     Running this example would print the
    
    <strong class="source-inline">
     
      Timer expired.
     
     
      Count: &lt;number&gt;
     
    </strong>
    
     line every second with the counter increasing on
    
    
     
      each line.
     
    
   </p>
   <p>
    
     In case some work needs to be serialized but these approaches are not appropriate, we can use explicit strands by using
    
    <strong class="source-inline">
     
      boost::asio::strand
     
    </strong>
    
     or its specialization for I/O context execution objects,
    
    <strong class="source-inline">
     
      boost::asio::io_context::strand
     
    </strong>
    
     .
    
    
     Posted work using these strand objects will serialize their handler execution in the order they enter the I/O execution
    
    
     
      context queue.
     
    
   </p>
   <p>
    
     In the following example, we will create a logger that serializes writing operations into a single log file from several threads.
    
    
     We will be logging messages from four threads, writing five messages from each.
    
    
     We expect the output to be correct, but this time without using any
    
    <a id="_idIndexMarker734">
    </a>
    
     mutex or other
    
    
     
      synchronization
     
    
    
     <a id="_idIndexMarker735">
     </a>
    
    
     
      mechanism.
     
    
   </p>
   <p>
    
     Let’s start by defining the
    
    
     <strong class="source-inline">
      
       Logger
      
     </strong>
    
    
     
      class:
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;chrono&gt;
#include &lt;fstream&gt;
#include &lt;iostream&gt;
#include &lt;memory&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
using namespace std::chrono_literals;
class Logger {
   public:
    Logger(boost::asio::io_context&amp; io_context,
           const std::string&amp; filename)
        : strand_(io_context), file_(filename
        , std::ios::out | std::ios::app)
    {
        if (!file_.is_open()) {
            throw std::runtime_error(
                      "Failed to open log file");
        }
    }
    void log(const std::string message) {
        strand_.post([this, message](){
            do_log(message);
        });
    }
   private:
    void do_log(const std::string message) {
        file_ &lt;&lt; message &lt;&lt; std::endl;
    }
    boost::asio::io_context::strand strand_;
    std::ofstream file_;
};</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      Logger
     
    </strong>
    
     constructor accepts an I/O context object, used to create a strand object (
    
    <strong class="source-inline">
     
      boost::asio::io_context::strand
     
    </strong>
    
     ), and
    
    <strong class="source-inline">
     
      std::string
     
    </strong>
    
     , specifying a log filename that is used to open the log file or create it if it does not exist.
    
    
     The log file is open for appending new content.
    
    
     If the file is not open before the constructor finishes, meaning that there was an issue when accessing or creating the file, the constructor throws
    
    
     
      an exception.
     
    
   </p>
   <p>
    
     The logger also provides the public
    
    <strong class="source-inline">
     
      log()
     
    </strong>
    
     function that accepts
    
    <strong class="source-inline">
     
      std::string
     
    </strong>
    
     , specifying a message as a parameter.
    
    
     This function uses the strand to post new work into the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object.
    
    
     It does that by using a lambda function, capturing by value the logger instance (the object
    
    <strong class="source-inline">
     
      this
     
    </strong>
    
     ) and the message, and calls the private
    
    <strong class="source-inline">
     
      do_log()
     
    </strong>
    
     function, where a
    
    <strong class="source-inline">
     
      std::fstream
     
    </strong>
    
     object is used to write the message into the
    
    
     
      output file.
     
    
   </p>
   <p>
    
     There will be only one instance of the
    
    <strong class="source-inline">
     
      Logger
     
    </strong>
    
     class in the program, shared by all threads.
    
    
     That way, the
    
    <a id="_idIndexMarker736">
    </a>
    
     threads will write to the
    
    
     
      same
     
    
    
     <a id="_idIndexMarker737">
     </a>
    
    
     
      file.
     
    
   </p>
   <p>
    
     Let’s define a
    
    <strong class="source-inline">
     
      worker()
     
    </strong>
    
     function that each thread will run to write
    
    <strong class="source-inline">
     
      num_messages_per_thread
     
    </strong>
    
     messages into the
    
    
     
      output file:
     
    
   </p>
   <pre class="source-code">
void worker(std::shared_ptr&lt;Logger&gt; logger, int id) {
    for (unsigned i=0; i &lt; num_messages_per_thread; ++i) {
        std::ostringstream oss;
        oss &lt;&lt; "Thread " &lt;&lt; id &lt;&lt; " logging message " &lt;&lt; i;
        logger-&gt;log(oss.str());
        std::this_thread::sleep_for(100ms);
    }
}</pre>
   <p>
    
     This function accepts a shared pointer to the
    
    <strong class="source-inline">
     
      Logger
     
    </strong>
    
     object and a thread identifier.
    
    
     It prints all the messages using the
    
    <strong class="source-inline">
     
      Logger
     
    </strong>
    
     ’s public
    
    <strong class="source-inline">
     
      log()
     
    </strong>
    
     function
    
    
     
      explained earlier.
     
    
   </p>
   <p>
    
     To interleave the threads executions and rigorously test how the strands work, each thread will sleep for 100 ms after writing
    
    
     
      each message.
     
    
   </p>
   <p>
    
     Finally, in the
    
    <strong class="source-inline">
     
      main()
     
    </strong>
    
     function, we start an
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object and a work guard to avoid an early exit from the
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     .
    
    
     Then, a shared pointer to a
    
    <strong class="source-inline">
     
      Logger
     
    </strong>
    
     instance is created, passing the necessary parameters
    
    
     
      explained earlier.
     
    
   </p>
   <p>
    
     A thread pool (vector of
    
    <strong class="source-inline">
     
      std::jthread
     
    </strong>
    
     objects) is created by using the
    
    <strong class="source-inline">
     
      worker()
     
    </strong>
    
     function and passing the shared pointer to the logger and a unique identifier for each thread.
    
    
     Also, a thread running the
    
    <strong class="source-inline">
     
      io_context.run()
     
    </strong>
    
     function is added to the
    
    
     
      thread pool.
     
    
   </p>
   <p>
    
     In the following example, as we know that all messages will be printed out in less than two seconds, we make
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     run for only that period,
    
    
     
      using
     
    
    
     <strong class="source-inline">
      
       io_context.run_for(2s)
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     When the
    
    <strong class="source-inline">
     
      run_for()
     
    </strong>
    
     function
    
    <a id="_idIndexMarker738">
    </a>
    
     exits, the program
    
    <a id="_idIndexMarker739">
    </a>
    
     prints
    
    <strong class="source-inline">
     
      Done!
     
    </strong>
    
     to the console
    
    
     
      and finishes:
     
    
   </p>
   <pre class="source-code">
const std::string log_filename = "log.txt";
const unsigned num_threads = 4;
const unsigned num_messages_per_thread = 5;
int main() {
    try {
        boost::asio::io_context io_context;
        auto work_guard = boost::asio::make_work_guard(
                                 io_context);
        std::shared_ptr&lt;Logger&gt; logger =
             std::make_shared&lt;Logger&gt;(
                  io_context, log_filename);
        std::cout &lt;&lt; "Logging "
                  &lt;&lt; num_messages_per_thread
                  &lt;&lt; " messages from " &lt;&lt; num_threads
                  &lt;&lt; " threads\n";
        std::vector&lt;std::jthread&gt; threads;
        for (unsigned i = 0; i &lt; num_threads; ++i) {
            threads.emplace_back(worker, logger, i);
        }
        threads.emplace_back([&amp;]() {
            io_context.run_for(2s);
        });
    } catch (std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; '\n';
    }
    std::cout &lt;&lt; "Done!" &lt;&lt; std::endl;
    return 0;
}</pre>
   <p>
    
     Running this example
    
    <a id="_idIndexMarker740">
    </a>
    
     will show the
    
    
     
      following
     
    
    
     <a id="_idIndexMarker741">
     </a>
    
    
     
      output:
     
    
   </p>
   <pre class="console">
Logging 5 messages from 4 threads
Done!</pre>
   <p>
    
     This is the content of the generated
    
    <strong class="source-inline">
     
      log.txt
     
    </strong>
    
     log file.
    
    
     As the sleep time for each thread is the same, all threads and messages are
    
    
     
      sequentially ordered:
     
    
   </p>
   <pre class="console">
Thread 0 logging message 0
Thread 1 logging message 0
Thread 2 logging message 0
Thread 3 logging message 0
Thread 0 logging message 1
Thread 1 logging message 1
Thread 2 logging message 1
Thread 3 logging message 1
Thread 0 logging message 2
Thread 1 logging message 2
Thread 2 logging message 2
Thread 3 logging message 2
Thread 0 logging message 3
Thread 1 logging message 3
Thread 2 logging message 3
Thread 3 logging message 3
Thread 0 logging message 4
Thread 1 logging message 4
Thread 2 logging message 4
Thread 3 logging message 4</pre>
   <p>
    
     If we remove the
    
    <a id="_idIndexMarker742">
    </a>
    
     work guard, the log file only has the
    
    <a id="_idIndexMarker743">
    </a>
    
     
      following content:
     
    
   </p>
   <pre class="console">
Thread 0 logging message 0
Thread 1 logging message 0
Thread 2 logging message 0
Thread 3 logging message 0</pre>
   <p>
    
     This happens because the first batch of work is promptly posted and queued into
    
    <strong class="source-inline">
     
      io_object
     
    </strong>
    
     from each thread, but
    
    <strong class="source-inline">
     
      io_object
     
    </strong>
    
     exits after finishing dispatching the work guard and notifying the completion handlers before the second batch of messages
    
    
     
      is posted.
     
    
   </p>
   <p>
    
     If we also remove the
    
    <strong class="source-inline">
     
      sleep_for()
     
    </strong>
    
     instruction in the worker thread, now, the log file content is
    
    
     
      as follows:
     
    
   </p>
   <pre class="console">
Thread 0 logging message 0
Thread 0 logging message 1
Thread 0 logging message 2
Thread 0 logging message 3
Thread 0 logging message 4
Thread 1 logging message 0
Thread 1 logging message 1
Thread 1 logging message 2
Thread 1 logging message 3
Thread 1 logging message 4
Thread 2 logging message 0
Thread 2 logging message 1
Thread 2 logging message 2
Thread 2 logging message 3
Thread 2 logging message 4
Thread 3 logging message 0
Thread 3 logging message 1
Thread 3 logging message 2
Thread 3 logging message 3
Thread 3 logging message 4</pre>
   <p>
    
     Earlier, the content
    
    <a id="_idIndexMarker744">
    </a>
    
     was
    
    <a id="_idIndexMarker745">
    </a>
    
     sorted by message identifier, and now it’s by thread identifier.
    
    
     This is because now, when a thread starts and runs the
    
    <strong class="source-inline">
     
      worker()
     
    </strong>
    
     function, it posts all messages at once, without any delay.
    
    
     Therefore, the first thread (thread
    
    <strong class="source-inline">
     
      0
     
    </strong>
    
     ) enqueues all its work before the second thread has the chance to do that, and
    
    
     
      so on.
     
    
   </p>
   <p>
    
     Continuing with further experiments, when we posted content into the strand, we captured the logger instance and the message by value, by using the
    
    
     
      following instruction:
     
    
   </p>
   <pre class="source-code">
strand_.post([this, message]() { do_log(message); });</pre>
   <p>
    
     Capturing by value allows the lambda function running
    
    <strong class="source-inline">
     
      do_log()
     
    </strong>
    
     to use a copy of the needed objects, keeping them alive, as commented earlier in this chapter when we discussed
    
    
     
      object lifetimes.
     
    
   </p>
   <p>
    
     Say, for some reason, we decided to capture by reference using the
    
    
     
      following instruction:
     
    
   </p>
   <pre class="source-code">
strand_.post([&amp;]() { do_log(message); });</pre>
   <p>
    
     Then, the resulting log file will have incomplete log messages and even incorrect characters because the logger is printing from memory areas that belonged to a message object that no longer exists when the
    
    <strong class="source-inline">
     
      do_log()
     
    </strong>
    
     
      function executes.
     
    
   </p>
   <p>
    
     Therefore, always assume asynchronous changes; the OS might perform some changes out of our control, so always know what is under our control and, most importantly,
    
    
     
      what’s not.
     
    
   </p>
   <p>
    
     Finally, instead of using a lambda expression and capturing the
    
    <strong class="source-inline">
     
      this
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      message
     
    </strong>
    
     objects by value, we could also use
    
    <strong class="source-inline">
     
      std::bind
     
    </strong>
    
     
      as follows:
     
    
   </p>
   <pre class="source-code">
strand_.post(std::bind(&amp;Logger::do_log, this, message));</pre>
   <p>
    
     Let’s learn now how
    
    <a id="_idIndexMarker746">
    </a>
    
     we can simplify the echo server we
    
    <a id="_idIndexMarker747">
    </a>
    
     implemented earlier by using coroutines and improving it by adding a command to exit the connection from the
    
    
     
      client’s side.
     
    
   </p>
   <h1 id="_idParaDest-210">
    <a id="_idTextAnchor209">
    </a>
    
     Coroutines
    
   </h1>
   <p>
    
     Boost.Asio has also
    
    <a id="_idIndexMarker748">
    </a>
    
     included support for coroutines since version 1.56.0 and
    
    <a id="_idIndexMarker749">
    </a>
    
     supported native coroutines since
    
    
     
      version 1.75.0.
     
    
   </p>
   <p>
    
     As we have learned in the previous chapter, using coroutines simplifies how the program is written as there is no need to add completion handlers and split the flow of the program into different asynchronous functions and callbacks.
    
    
     Instead, with coroutines, the program follows a sequential structure where an asynchronous operation call pauses the execution of the coroutine.
    
    
     When the asynchronous operation completes, the coroutine is resumed, letting the program continue its execution from where it was
    
    
     
      previously paused.
     
    
   </p>
   <p>
    
     With newer versions (newer than 1.75.0), we can use native C++ coroutines via
    
    <strong class="source-inline">
     
      co_await
     
    </strong>
    
     , to wait for asynchronous operations within a coroutine,
    
    <strong class="source-inline">
     
      boost::asio::co_spawn
     
    </strong>
    
     to launch a coroutine, and
    
    <strong class="source-inline">
     
      boost::asio::use_awaitable
     
    </strong>
    
     to let Boost.Asio know that an asynchronous operation will use coroutines.
    
    
     With earlier versions (from 1.56.0), coroutines were available using
    
    <strong class="source-inline">
     
      boost::asio::spawn()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      yield
     
    </strong>
    
     contexts.
    
    
     As the newer approach is preferred, not only because it supports native C++20 coroutines, but the code is also more modern, clean, and readable, we will focus on this approach in
    
    
     
      this section.
     
    
   </p>
   <p>
    
     Let’s implement again the echo server, but this time using Boost.Asio’s awaitable interface and coroutines.
    
    
     We will also add some improvements, such as support to close the connection from the client’s side when sending the
    
    <strong class="source-inline">
     
      QUIT
     
    </strong>
    
     command, showing how to process data or commands on the server side, and stopping handling connections and exiting if any exception
    
    
     
      is thrown.
     
    
   </p>
   <p>
    
     Let’s start by implementing the
    
    <strong class="source-inline">
     
      main()
     
    </strong>
    
     function.
    
    
     The program starts by using
    
    <strong class="source-inline">
     
      boost::asio::co_spawn
     
    </strong>
    
     to create a new coroutine-based thread.
    
    
     This function accepts as parameters an execution context (
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     , but can also use a strand), a function with the
    
    <strong class="source-inline">
     
      boost::asio::awaitable&lt;R,E&gt;
     
    </strong>
    
     return type, which will be used as the coroutine’s entry point (the
    
    <strong class="source-inline">
     
      listener()
     
    </strong>
    
     function that we will implement and explain next), and
    
    <a id="_idIndexMarker750">
    </a>
    
     a completion token that will be called when the thread
    
    <a id="_idIndexMarker751">
    </a>
    
     has completed.
    
    
     If we want to run the coroutine without being notified of its completion, we can pass the
    
    
     <strong class="source-inline">
      
       boost::asio::detached
      
     </strong>
    
    
     
      token.
     
    
   </p>
   <p>
    
     Finally, we start processing asynchronous events by
    
    
     
      calling
     
    
    
     <strong class="source-inline">
      
       io_context.run()
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     In case there is any exception, it will be caught by the try-catch block, and the event processing loop will be stopped by
    
    
     
      calling
     
    
    
     <strong class="source-inline">
      
       io_context.stop()
      
     </strong>
    
    
     
      :
     
    
   </p>
   <pre class="source-code">
#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;
using boost::asio::ip::tcp;
int main() {
    boost::asio::io_context io_context;
    try {
        boost::asio::co_spawn(io_context,
                    listener(io_context, 12345),
                    boost::asio::detached);
        io_context.run();
    } catch (std::exception&amp; e) {
        std::cerr &lt;&lt; "Error: " &lt;&lt; e.what() &lt;&lt; std::endl;
        io_context.stop();
    }
    return 0;
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      listener()
     
    </strong>
    
     function
    
    <a id="_idIndexMarker752">
    </a>
    
     receives as parameters an
    
    <strong class="source-inline">
     
      io_context
     
    </strong>
    
     object and the
    
    <a id="_idIndexMarker753">
    </a>
    
     port number that the listener will accept connections from, using an
    
    <strong class="source-inline">
     
      acceptor
     
    </strong>
    
     object as explained earlier.
    
    
     It also must have a return type of
    
    <strong class="source-inline">
     
      boost::asio::awaitable&lt;R,E&gt;
     
    </strong>
    
     , where
    
    <strong class="source-inline">
     
      R
     
    </strong>
    
     is the return type of the coroutine and
    
    <strong class="source-inline">
     
      E
     
    </strong>
    
     is the exception type that might be thrown.
    
    
     In this example,
    
    <strong class="source-inline">
     
      E
     
    </strong>
    
     is set as default, so not
    
    
     
      explicitly specified.
     
    
   </p>
   <p>
    
     The connection is accepted by calling the
    
    <strong class="source-inline">
     
      async_accept
     
    </strong>
    
     acceptor function.
    
    
     As we are now using a coroutine, we need to specify
    
    <strong class="source-inline">
     
      boost::asio::use_awaitable
     
    </strong>
    
     to the asynchronous function and use
    
    <strong class="source-inline">
     
      co_await
     
    </strong>
    
     to stop the coroutine execution until is resumed when the asynchronous
    
    
     
      task completes.
     
    
   </p>
   <p>
    
     When the listener coroutine task resumes,
    
    <strong class="source-inline">
     
      acceptor.async_accept()
     
    </strong>
    
     returns a socket object.
    
    
     The coroutine continues by spawning a new thread, using the
    
    <strong class="source-inline">
     
      boost::asio::co_spawn
     
    </strong>
    
     function, executing the
    
    <strong class="source-inline">
     
      echo()
     
    </strong>
    
     function, and passing the
    
    <strong class="source-inline">
     
      socket
     
    </strong>
    
     object
    
    
     
      to it:
     
    
   </p>
   <pre class="source-code">
boost::asio::awaitable&lt;void&gt; listener(boost::asio::io_context&amp; io_context, unsigned short port) {
    tcp::acceptor acceptor(io_context,
                           tcp::endpoint(tcp::v4(), port));
    while (true) {
        std::cout &lt;&lt; "Accepting connections...\n";
        tcp::socket socket = co_await
                acceptor.async_accept(
                    boost::asio::use_awaitable);
        std::cout &lt;&lt; "Starting an Echo "
                  &lt;&lt; "connection handler...\n";
        boost::asio::co_spawn(io_context,
                              echo(std::move(socket)),
                              boost::asio::detached);
    }
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      echo()
     
    </strong>
    
     function is
    
    <a id="_idIndexMarker754">
    </a>
    
     responsible for handling a single client connection.
    
    
     It
    
    <a id="_idIndexMarker755">
    </a>
    
     must follow a similar signature as the
    
    <strong class="source-inline">
     
      listener()
     
    </strong>
    
     function; it needs a return type of
    
    <strong class="source-inline">
     
      boost::asio::awaitable&lt;R,E&gt;
     
    </strong>
    
     .
    
    
     As commented earlier, the
    
    <strong class="source-inline">
     
      socket
     
    </strong>
    
     object is moved into this function from
    
    
     
      the listener.
     
    
   </p>
   <p>
    
     The function asynchronously reads content from the socket and writes it back in an infinite loop that only finishes if it receives the
    
    <strong class="source-inline">
     
      QUIT
     
    </strong>
    
     command or an exception
    
    
     
      is thrown.
     
    
   </p>
   <p>
    
     Asynchronous reads are done by using the
    
    <strong class="source-inline">
     
      socket.async_read_some()
     
    </strong>
    
     function, which reads data into the data buffer using
    
    <strong class="source-inline">
     
      boost::asio::buffer
     
    </strong>
    
     and returns the number of bytes read (
    
    <strong class="source-inline">
     
      bytes_read
     
    </strong>
    
     ).
    
    
     As the asynchronous task is managed by a coroutine,
    
    <strong class="source-inline">
     
      boost::asio::use_awaitable
     
    </strong>
    
     is passed to the asynchronous operation.
    
    
     Then,
    
    <strong class="source-inline">
     
      co_wait
     
    </strong>
    
     just instructs the coroutine engine to pause the execution until the asynchronous
    
    
     
      operation finishes.
     
    
   </p>
   <p>
    
     Once some data is received, the execution of the coroutine resumes, checking if there is really some data to process, otherwise, it finishes the connection by exiting the loop, thus the
    
    <strong class="source-inline">
     
      echo()
     
    </strong>
    
     function
    
    
     
      as well.
     
    
   </p>
   <p>
    
     If data is read, it converts it into
    
    <strong class="source-inline">
     
      std::string
     
    </strong>
    
     for easy manipulation.
    
    
     It removes the
    
    <strong class="source-inline">
     
      \r\n
     
    </strong>
    
     ending, if present, and compares the string
    
    
     
      against
     
    
    
     <strong class="source-inline">
      
       QUIT
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     If
    
    <strong class="source-inline">
     
      QUIT
     
    </strong>
    
     is present, it performs an asynchronous write, sends the
    
    <strong class="source-inline">
     
      Good bye!
     
    </strong>
    
     message, and exits the loop.
    
    
     Otherwise, it sends the received data back to the client.
    
    
     In both cases, an asynchronous write operation is performed by using the
    
    <strong class="source-inline">
     
      boost::asio::async_write()
     
    </strong>
    
     function, passing the socket,
    
    <strong class="source-inline">
     
      boost:asio::buffer
     
    </strong>
    
     wrapping the data buffer to send, and
    
    <strong class="source-inline">
     
      boost::asio::use_awaitable
     
    </strong>
    
     as with the asynchronous
    
    
     
      read operation.
     
    
   </p>
   <p>
    
     Then,
    
    <strong class="source-inline">
     
      co_await
     
    </strong>
    
     is used again to suspend the execution of the coroutine while the operation is performed.
    
    
     Once
    
    <a id="_idIndexMarker756">
    </a>
    
     completed, the coroutine will resume and repeat
    
    <a id="_idIndexMarker757">
    </a>
    
     these steps in a new
    
    
     
      loop iteration:
     
    
   </p>
   <pre class="source-code">
boost::asio::awaitable&lt;void&gt; echo(tcp::socket socket) {
    char data[1024];
    while (true) {
        std::cout &lt;&lt; "Reading data from socket...\n";
        std::size_t bytes_read = co_await
                 socket.async_read_some(
                        boost::asio::buffer(data),
                        boost::asio::use_awaitable);
        if (bytes_read == 0) {
            std::cout &lt;&lt; "No data. Exiting loop...\n";
            break;
        }
        std::string str(data, bytes_read);
        if (!str.empty() &amp;&amp; str.back() == '\n') {
            str.pop_back();
        }
        if (!str.empty() &amp;&amp; str.back() == '\r') {
            str.pop_back();
        }
        if (str == "QUIT") {
            std::string bye("Good bye!\n");
            co_await boost::asio::async_write(socket,
                         boost::asio::buffer(bye),
                         boost::asio::use_awaitable);
            break;
        }
        std::cout &lt;&lt; "Writing '" &lt;&lt; str
                  &lt;&lt; "' back into the socket...\n";
        co_await boost::asio::async_write(socket,
                     boost::asio::buffer(data,
                                         bytes_read),
                     boost::asio::use_awaitable);
    }
}</pre>
   <p>
    
     The coroutine loops until no data is read, happening when the client closes the connection, when the
    
    <strong class="source-inline">
     
      QUIT
     
    </strong>
    
     command is received, or when an
    
    
     
      exception occurs.
     
    
   </p>
   <p>
    
     Asynchronous operations
    
    <a id="_idIndexMarker758">
    </a>
    
     are used throughout to ensure the server remains
    
    <a id="_idIndexMarker759">
    </a>
    
     responsive, even when handling multiple
    
    
     
      clients simultaneously.
     
    
   </p>
   <h1 id="_idParaDest-211">
    <a id="_idTextAnchor210">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     In this chapter, we learned about Boost.Asio and how to use this library to manage asynchronous tasks that deal with external resources managed by
    
    
     
      the OS.
     
    
   </p>
   <p>
    
     For that purpose, we introduced the I/O objects and I/O execution context objects, with an in-depth explanation of how they work and interact together, how they access and communicate with OS services, what the design principles are behind them, and how to use them properly in single-threaded and
    
    
     
      multi-threaded applications.
     
    
   </p>
   <p>
    
     We also showed different techniques available in Boost.Asio to serialize work using strands, to manage the objects’ lifetimes used by asynchronous operations, how to start, interrupt, or cancel tasks, how to manage the event processing loop that the library uses, and how to handle signals sent by
    
    
     
      the OS.
     
    
   </p>
   <p>
    
     Other concepts related to networking and coroutines were also introduced, and we also implemented some useful examples using this
    
    
     
      powerful library.
     
    
   </p>
   <p>
    
     All these concepts and examples allow us to acquire a deeper knowledge of how to manage asynchronous tasks in C++ and how an extensively used library works under the hood to achieve
    
    
     
      this goal.
     
    
   </p>
   <p>
    
     In the next chapter, we will learn about another Boost library, Boost.Cobalt, that provides a rich and high-level interface to develop asynchronous software based
    
    
     
      in coroutines.
     
    
   </p>
   <h1 id="_idParaDest-212">
    <a id="_idTextAnchor211">
    </a>
    
     Further reading
    
   </h1>
   <ul>
    <li>
     
      Boost.Asio official
     
     
      
       site:
      
     
     <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio.html">
      
       
        https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio.html
       
      
     </a>
    </li>
    <li>
     
      Boost.Asio
     
     
      
       reference:
      
     
     <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/reference.html">
      
       
        https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/reference.html
       
      
     </a>
    </li>
    <li>
     
      Boost.Asio revision
     
     
      
       history:
      
     
     <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/history.html">
      
       
        https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/history.html
       
      
     </a>
    </li>
    <li>
     
      Boost.Asio BSD socket
     
     
      
       API:
      
     
     <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/overview/networking/bsd_sockets.html">
      
       
        https://www.boost.org/doc/libs/1_85_0/doc/html/boost_asio/overview/networking/bsd_sockets.html
       
      
     </a>
    </li>
    <li>
     
      BSD socket
     
     
      
       API:
      
     
     <a href="https://web.mit.edu/macdev/Development/MITSupportLib/SocketsLib/Documentation/sockets.html">
      
       
        https://web.mit.edu/macdev/Development/MITSupportLib/SocketsLib/Documentation/sockets.html
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       The Boost C++ Libraries, Boris
      
     </em>
     
      <em class="italic">
       
        Schälig
       
      </em>
     
     
      
       :
      
     
     <a href="https://theboostcpplibraries.com/boost.asio">
      
       
        https://theboostcpplibraries.com/boost.asio
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Thinking Asynchronously: Designing Applications with Boost.Asio, Christopher
      
     </em>
     
      <em class="italic">
       
        Kohlhoff
       
      </em>
     
     
      
       :
      
     
     <a href="https://www.youtube.com/watch?v=D-lTwGJRx0o">
      
       
        https://www.youtube.com/watch?v=D-lTwGJRx0o
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       CppCon 2016: Asynchronous IO with Boost.Asio, Michael
      
     </em>
     
      <em class="italic">
       
        Caisse
       
      </em>
     
     
      
       :
      
     
     <a href="https://www.youtube.com/watch?v=rwOv_tw2eA4">
      
       
        https://www.youtube.com/watch?v=rwOv_tw2eA4
       
      
     </a>
    </li>
    <li>
     <em class="italic">
      
       Pattern-Oriented Software Architecture – Patterns for Concurrent and Networked Objects
      
     </em>
     
      ,
     
     <em class="italic">
      
       Volume 2
      
     </em>
     
      , D.
     
     
      Schmidt et al,
     
     
      
       Wiley, 2000
      
     
    </li>
    <li>
     <em class="italic">
      
       Boost.Asio C++ Network Programming Cookbook
      
     </em>
     
      , Dmytro Radchuk, Packt
     
     
      
       Publishing, 2016
      
     
    </li>
    <li>
     <em class="italic">
      
       Proactor: An Object Behavioral Pattern for Demultiplexing and Dispatching handlers for Asynchronous events
      
     </em>
     
      , Irfan Pyarali, Tim Harrison, Douglas C Schmidt, Thomas D
     
     
      
       Jordan.
      
      
       1997
      
     
    </li>
    <li>
     <em class="italic">
      
       Reactor: An Object Behavioral Pattern for Demultiplexing and Dispatching Handlers for Synchronous events
      
     </em>
     
      , Douglas C
     
     
      
       Schmidt, 1995
      
     
    </li>
    <li>
     <em class="italic">
      
       Input/Output Completion
      
     </em>
     
      <em class="italic">
       
        Port
       
      </em>
     
     
      
       :
      
     
     <a href="https://en.wikipedia.org/wiki/Input/output_completion_port">
      
       
        https://en.wikipedia.org/wiki/Input/output_completion_port
       
      
     </a>
    </li>
    <li>
     
      <em class="italic">
       
        kqueue
       
      </em>
     
     
      
       :
      
     
     <a href="https://en.wikipedia.org/wiki/Kqueue">
      
       
        https://en.wikipedia.org/wiki/Kqueue
       
      
     </a>
    </li>
    <li>
     
      <em class="italic">
       
        epoll
       
      </em>
     
     
      
       :
      
     
     <a href="https://en.wikipedia.org/wiki/Epoll">
      
       
        https://en.wikipedia.org/wiki/Epoll
       
      
     </a>
    </li>
   </ul>
  </div>
 </body></html>