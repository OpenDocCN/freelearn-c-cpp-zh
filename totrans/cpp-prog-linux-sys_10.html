<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-147"><a id="_idTextAnchor147"/>10</h1>
<h1 id="_idParaDest-148"><a id="_idTextAnchor148"/>Using Coroutines in C++ for System Programming</h1>
<p>We are almost at the end of our book. The final chapter is dedicated to a feature that is very useful for the purposes of system programming but is fairly new to the C++ standard. <strong class="bold">Coroutine</strong> objects <a id="_idIndexMarker905"/>found their application fast, becoming first-class state machine objects. Their power is in hiding logic behind<a id="_idIndexMarker906"/> the <strong class="bold">coroutine frame</strong>. Be advised that this is an advanced topic, and the coroutine interface of C++ is neither simple nor comfortable to use. It is well thought out but definitely not the most user-friendly in comparison to other programming languages.</p>
<p>In this chapter, you will learn the basics of using this facility. If you are new to it, then you’ll spend some time understanding its requirements. You’ll have an easier time with coroutines if you have previous experience with them in other programming languages. Still, we will use this chapter to propose their application in system programming.</p>
<p>We will present two practical solutions of previous examples related to <strong class="bold">networking</strong> and <strong class="bold">shared memory</strong>. You will immediately see the predictability and the clear execution path of the routines. We hope that you are impressed by the concurrent manner of execution without the use of synchronization primitives. Direct reuse in a real-world environment is possible; just make sure you have the required compilers, as the feature is still new. Without further ado, let’s get to our final topic.</p>
<p>In this chapter, we are going to cover the following main topics:</p>
<ul>
<li>Introducing coroutines</li>
<li>Network programming and coroutines in C++</li>
<li>Revisiting the shared memory problem through coroutines in C++</li>
<li>Final thoughts on coroutines and their implementations in C++</li>
</ul>
<h1 id="_idParaDest-149"><a id="_idTextAnchor149"/>Technical requirements</h1>
<p>In order to run the code examples, you must prepare the following:</p>
<ul>
<li>A Linux-based system capable of compiling and executing C++20 (for example, <strong class="bold">Linux </strong><strong class="bold">Mint 21</strong>)</li>
<li>The GCC12.2 compiler – <a href="https://gcc.gnu.org/git/gcc.gitgcc-source">https://gcc.gnu.org/git/gcc.git gcc-source</a>:<ul><li>With the <code>-fcoroutines</code>, <code>-std=c++2a</code>, <code>-lpthread</code>, and <code>-</code><code>lrt</code> flags</li></ul></li>
<li>For some of the examples, you can alternatively use <a href="https://godbolt.org/">https://godbolt.org/</a>.</li>
<li>All code examples in this chapter are available for download from <a href="https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010">https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010</a></li>
</ul>
<h1 id="_idParaDest-150"><a id="_idTextAnchor150"/>Introducing coroutines</h1>
<p>At the end of your<a id="_idIndexMarker907"/> journey, we’d like to remind you about the knowledge you received in <a href="B20833_01.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a> and <a href="B20833_02.xhtml#_idTextAnchor029"><em class="italic">Chapter 2</em></a> about <strong class="bold">processes</strong> and <strong class="bold">threads</strong>. If you remember well, a process is simply a running instance of a program. It has its respective address space, which is not shared with others, except through shared memory. Threads reside in a process, and they cannot exist outside of them, although both processes and threads are treated as <strong class="bold">tasks</strong> in Linux. They are scheduled in the same manner and have the same controlling structures on the <strong class="bold">kernel</strong> level. Still, threads are considered lightweight because the bigger overhead for the initial load of a program is taken by the parent process.</p>
<p>But this is not the full picture. There<a id="_idIndexMarker908"/> are <strong class="bold">fibers</strong> and coroutines as well. If the processes and threads are truly <strong class="bold">concurrent</strong> and working in parallel over shared resources, fibers are just like threads but are not <strong class="bold">concurrency</strong>-compliant. While threads often depend on <strong class="bold">preemptive</strong> time-slicing <a id="_idIndexMarker909"/>because of the task scheduler, fibers <a id="_idIndexMarker910"/>use <strong class="bold">cooperative multitasking</strong>. That is, they yield themselves to run another fiber while executing. They are also known as <strong class="bold">stackful coroutines</strong>. Meanwhile, <a id="_idIndexMarker911"/>coroutines in C++ are known as <strong class="bold">stackless coroutines</strong> and <a id="_idIndexMarker912"/>are not OS-managed. In other words, stackful coroutines could be suspended in a nested stack frame, while stackless coroutines can only be nested by the top-level routine.</p>
<p>Both facilities are considered implicitly synchronized, so all of the synchronization primitives and the <strong class="bold">atomic</strong> constructs from the previous chapters are needless. But you could picture the early example with reading from the file system – where the OS waits for the file to be opened, and the process-caller is signaled to continue its work. Imagine that the fibers and the coroutines are useful exactly for that reactive access, which does not need additional CPU processing. Actually, the networking and the file systems are the areas where the fibers and coroutines are considered most valuable. When a request is made, a fiber gives control to the main thread, and when the I/O operation is finished, the fiber continues where it yielded.</p>
<p>The coroutines technique <a id="_idIndexMarker913"/>is rather old. C++ introduced it recently, and it is very useful for network programming, I/O operations, event management, and so on. Coroutines are also considered executions with the ability to pause. Still, they provide multitasking in a cooperative fashion and do not work in parallel. This means that tasks cannot be executed simultaneously. At the same time, they are real-timw-friendly, allowing switching context between coroutines to be fast, and not requiring system calls. In fact, they are <strong class="bold">hard-RTOS</strong>-friendly because the order of execution and scheduling is controlled by the system programmer, as you will see later in the chapter. The coroutines in C++ are very useful for implementing task graphs and state machines, too.</p>
<p>Some of you are probably wondering what the difference between coroutines and standard single-threaded functional programming is. Well, the latter is considered a synchronous approach, while the former is an asynchronous approach with synchronous readability. But coroutines are really about reducing the needless (busy) waiting and doing something useful while a required resource or a call is being prepared. The following diagram is simple but reminds us of the respective differences between sync and async executions.</p>
<div><div><img alt="Figure 10.1 – Synchronous versus asynchronous application execution" height="566" src="img/Figure_10.01_B20833.jpg" width="923"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Synchronous versus asynchronous application execution</p>
<p>A regular single-threaded <a id="_idIndexMarker914"/>execution is also limited in some ways. First of all, calling, suspending, or resuming a function is not traceable inside a program, or at least not through a reference. In other words, the control flow happens in the background and is implicit. In addition, the control flow has a strict direction – a function could either return to its caller or proceed inward toward calling another function. Each function call creates a new record on the stack and happens immediately, and once invoked, a method cannot be delayed. As soon as that function returns, its portion of the stack is cleared and cannot be restored. In other words, the activation is not traceable.</p>
<p>On the other hand, coroutines have their own lifetime. A coroutine is an object and can be referenced explicitly. If the coroutine should outlive its caller or should be transferred to another, then it could be stored<a id="_idIndexMarker915"/> in the <code>int func(int arg)</code> prototype would mean a function with the name <code>func</code>, receiving an argument, <code>arg</code>, of an integer type, returning an integer. A similar coroutine may never return to its caller and the value that the caller expects may be produced by another coroutine. Let see how this happens in C++.</p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor151"/>The coroutine facility in C++</h2>
<p>Initially, you can <a id="_idIndexMarker916"/>think about them<a id="_idIndexMarker917"/> like <code>Task exCoroutine()</code> task (a task is different from the Linux definition of task) – it is interpreted as a coroutine if it uses one of the following three operators: <code>co_await</code>, <code>co_yield</code>, or <code>co_return</code>. Here’s an example:</p>
<pre class="source-code">
#include &lt;coroutine&gt;
...
Task exCoroutine() {
    co_return;
}
int main() { Task async_task = exCoroutine(); }</pre> <p>The wrapper type is currently <code>Task</code>. It is known on the caller level. The coroutine object is identified as the <code>exCoroutine()</code> function through the <code>co_return</code> operator. It’s the job of the system programmer to create the <code>Task</code> class. It is not a part of the Standard library. What’s the <code>Task</code> class then?</p>
<pre class="source-code">
struct Task {
    struct promise_type {
        Task get_return_object()
            { return {}; }
        std::suspend_never initial_suspend()
            { return {}; }
        std::suspend_never final_suspend() noexcept
            { return {}; }
        void return_void() {}
        void unhandled_exception() {}
    };
};</pre> <p class="callout-heading">Important note</p>
<p class="callout">This is a very generic pattern that is used in almost every coroutine example. You should initially refer to it at <a href="https://en.cppreference.com/w/cpp/language/coroutines">https://en.cppreference.com/w/cpp/language/coroutines</a>.</p>
<p>We call a task a <a id="_idIndexMarker918"/>coroutine that executes a given routine but doesn’t return a value. In addition, the coroutine is associated with a <code>promise</code> object – we spoke about that in <a href="B20833_06.xhtml#_idTextAnchor086"><em class="italic">Chapter 6</em></a>. The <code>promise</code> object is manipulated on a coroutine level. The coroutine returns the operation result or raises an exception through this object. This facility also requires<a id="_idIndexMarker919"/> the <code>promise</code>. It also consists of the passed parameters – copied by value, a representation of the current invocation reference; the suspension point, so that the coroutine is resumed accordingly; and the local variables outside the scope of that point. So, what does our code do? Well, from a user standpoint, it does nothing, but there’s a lot happening in the background. Let’s observe the following diagram:</p>
<div><div><img alt="Figure 10.2 – Simple demonstration of a coroutine startup" height="460" src="img/Figure_10.02_B20833.jpg" width="1633"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Simple demonstration of a coroutine startup</p>
<p>Remember, by-value parameters are copied or moved in the scope of the coroutine, and the by-reference parameters remain as references. This means that the programmer should consider their lifetime in the task-caller, so no dangling pointers appear. Afterward, the <code>promise</code> is constructed and <code>get_return_object()</code> is called. The result will be returned to the task-caller when the coroutine first suspends.</p>
<p><em class="italic">Figure 10</em><em class="italic">.2</em> demonstrates a case where the <code>promise</code> returns <code>suspend_always</code> and we have lazily started a coroutine. The <code>initial_suspend()</code> operation resumes and, without the knowledge or the context of how to continue, the coroutine will never be resumed and will leak. In order to handle this, we need... a <code>handle</code> object. You can think of the <code>handle</code> object as a view. Similar to the relationships between the <code>string_view</code> object and a <code>string</code> object, or a <code>vector</code> object and a <code>range</code> object with a <code>range view</code> object, the <code>handle</code> object is used to provide indirect access to <code>*this</code>. Through the <code>handle</code> object, we can call <code>resume()</code> to continue the coroutine’s work. It must<a id="_idIndexMarker921"/> be suspended first, or the behavior will be undefined:</p>
<div><div><img alt="Figure 10.3 – Graph demonstrating a coroutine’s creation and resumption" height="915" src="img/Figure_10.03_B20833.jpg" width="1588"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Graph demonstrating a coroutine’s creation and resumption</p>
<p>The <code>initial_suspend()</code> operation is called and the result is handled through <code>co_await</code>. This is done through the compiler generating additional code in the background around the <code>suspend_never</code> awaitable – the coroutine is not created in a lazy manner as with <code>suspend_always</code>, but is immediately started. Both are defined in the C++ Standard Library.</p>
<p>The current coroutine does a <code>co_return</code> keyword (in <code>exCoroutine()</code>). But that way, the coroutine body is exited. If we want to use it to produce constantly new or the next generated values, then we require the <code>co_yield</code> operator. We call such a coroutine a <code>co_yield</code> operator as <code>co_await promise.yield_value(&lt;some expression&gt;)</code>. Otherwise, if it simply calls <code>co_await</code>, it is a task, as mentioned earlier. Now, if we look at <em class="italic">Figure 10</em><em class="italic">.3</em> again, using the <code>co_yield</code> operator <a id="_idIndexMarker923"/>will redirect the arrow from <em class="italic">thread-caller in control</em> to <em class="italic">coroutine execution</em>, thus providing the opportunity to coroutine to continue work. In other words, the <code>co_return</code> keyword will lead to execution completion, while the <code>co_yield</code> keyword will just suspend the coroutine temporarily.</p>
<p>Let’s go a step back and take a look<a id="_idIndexMarker924"/> at <code>co_await</code> call. Their work is presented in the following diagram:</p>
<div><div><img alt="Figure 10.4 – Graph representing generated invocations after a co_await call" height="894" src="img/Figure_10.04_B20833.jpg" width="1607"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Graph representing generated invocations after a co_await call</p>
<p>Now, a private variable of the <code>Handle</code> type is used to call the true <code>resume()</code> function. Let’s check the code:</p>
<pre class="source-code">
using namespace std;
struct Task {
    struct promise_type {
        using Handle = coroutine_handle&lt;promise_type&gt;;
        Task get_return_object() {
            return Task { Handle::from_promise(*this) };
        }
...</pre> <p>We will use the <code>explicit</code> specifier. In C++ 20, it allows you to be more restrictive on constructor <a id="_idIndexMarker925"/>calls. That is, it cannot be used for copy tnitialization or implicit conversions. Additionally, we keep our <code>handle</code> object private. Now, let’s see how this might come in handy (markers {1} and {2}, while a wrapper is provided to the caller – markers {1} and {3}):</p>
<pre class="source-code">
    explicit Task (promise_type::Handle crtHdnl) :
                                 crtHandle(crtHdnl) {}
    void resume() { crtHandle.resume(); } // {1}
private:
        promise_type::Handle crtHandle;   // {2}
...
    auto async_task = exCoroutine();
    async_task.resume();  // {3}</pre> <p>Let’s use this code structure to build a fully functional example. We will rename the <code>Task</code> struct  <code>Generator</code>, and implement a coroutine with a generator functionality. The full code can be found here: <a href="https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010">https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010</a>.</p>
<p>We will increment a variable N number of times through the coroutine. That’s why it needs to be able to yield, and we add the following to <code>Generator</code>:</p>
<pre class="source-code">
...
   suspend_always yield_value(auto value) {
            currValue = value;
            return {};
        }
...
        uint32_t currValue;
    };</pre> <p>Then, getting the next element happens as follows:</p>
<pre class="source-code">
    int next() {
        crtHndl.resume();
        return crtHndl.promise().currValue; } ...</pre> <p>Proceeding with the <a id="_idIndexMarker926"/>coroutine body and its creation in the main thread. The increment will happen 100,000 times. This example allows the programmer to generate data lazily and not use a big portion of the RAM. At the same time, no separate thread is used, so the execution remains in the user space without extensive context switching:</p>
<pre class="source-code">
Generator exCoroutine() {
    auto idx = 0;
    for (;;) {
        co_yield idx++;
    }
}
int main() {
    auto crt = exCoroutine();
    for (auto idx = 1; (idx = crt.next()) &lt;= 100000; )
        cout &lt;&lt; idx &lt;&lt; " ";
    cout &lt;&lt; endl;
    return 0;
}</pre> <p>The shortened version of the output is as follows:</p>
<pre class="console">
1 2 3 4 ... 100000</pre> <p>Unfortunately, you<a id="_idIndexMarker927"/> probably already understand why it is not that trivial to create a simple coroutine application in C++. As a new feature, this facility continues to improve and there are new interfaces expected in upcoming C++ versions, which should simplify coroutine usage. But this shouldn’t discourage you from continuing to use them. This example could be easily extended to other functionalities, and you could build up your knowledge step by step. In the next sections, we will do exactly this and get the discussion back in the area of system programming.</p>
<h1 id="_idParaDest-152"><a id="_idTextAnchor152"/>Network programming and coroutines in C++</h1>
<p>In <a href="B20833_07.xhtml#_idTextAnchor101"><em class="italic">Chapter 7</em></a>, you<a id="_idIndexMarker928"/> learned about the <code>Generator</code> definition to match the type of the <strong class="bold">coroutine</strong>, as discussed earlier. Traditionally, that object is made move-only – this allows us to restrict the usage of the coroutine wrapper, but in general cases, coroutine objects are non-copyable and non-moveable, because <a id="_idIndexMarker931"/>the <strong class="bold">coroutine frame</strong> is a part of them, and some local variables can be references or pointers to other local variables. Thus, let’s extend the structure accordingly:</p>
<p class="callout-heading">Important note</p>
<p class="callout">This, again, is a very generic pattern that is used in almost every coroutine example. You should initially refer to it at <a href="https://en.cppreference.com/w/cpp/language/coroutines">https://en.cppreference.com/w/cpp/language/coroutines</a>.</p>
<pre class="source-code">
template&lt;typename T&gt; struct Generator {
    Generator(const Generator&amp;)              = delete;
    Generator&amp; operator = (const Generator&amp;) = delete;
    Generator(Generator&amp;&amp; other) noexcept :
        c_routine(other.c_routine) {
        other.c_routine = {};
    }</pre> <p>You’ll notice <a id="_idIndexMarker932"/>that the <code>struct</code> object is defined as a <code>template</code> in order to be generic. We overload the <code>()</code> operator in order to be able to appropriately give the <a id="_idIndexMarker933"/>control back to the caller:</p>
<pre class="source-code">
    Generator&amp; operator = (Generator&amp;&amp; other) noexcept {
        if (this == &amp;other)
            return *this;
        if (c_routine)
            c_routine.destroy();
        c_routine = other.c_routine;
        other.c_routine = {};
        return *this;
    }
    optional&lt;T&gt; operator()() {
        c_routine.resume();
        if (c_routine.done()) {
            return nullopt;
        }
        return c_routine.promise().currValue;
    }</pre> <p>We also add a behavior during an exception – the application will be terminated:</p>
<pre class="source-code">
        void unhandled_exception() {
            exit(EXIT_FAILURE);
   }</pre> <p>In the main thread, we create <a id="_idIndexMarker934"/>and join two threads – a server and a client. Each of them will execute the coroutines for the respective domains. We provide a <code>socket</code> (marker {9} in the following code):</p>
<pre class="source-code">
   auto sockfd = 0;
    if ((sockfd = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) {
        const auto ecode{ make_error_code(errc{errno}) };
        cerr &lt;&lt; "Error opening shm region";
        system_error exception{ ecode };
        throw exception;
    }
    auto server = jthread([&amp;sockfd] {
        struct sockaddr_in servaddr = { 0 };
        servaddr.sin_family = AF_INET;
        servaddr.sin_addr.s_addr = INADDR_ANY;
        servaddr.sin_port = htons(PORT);
        if (bind(sockfd,
            (const struct sockaddr*)&amp;servaddr,
            sizeof(struct sockaddr_in)) &lt; 0) {
            perror("Bind failed");
            exit(EXIT_FAILURE);
        }
        cout &lt;&lt; "\nsend_to():\n";
        string_view message{ "This is a test!" };
        auto sender = send_to(sockfd, message,
           servaddr);
                                                   // {9}</pre> <p>Inside the <code>sendto()</code> method. We use a <code>string_view</code> object, the<a id="_idIndexMarker936"/> same way we did in <a href="B20833_03.xhtml#_idTextAnchor047"><em class="italic">Chapter 3</em></a> – the reasoning is primarily the safety of the code and the compactness of the data and its size. At<a id="_idIndexMarker937"/> the end of the loop, we use <code>co_yield value</code>, thus providing the number of bytes sent to the main thread. The endless loop allows the coroutine to run until truly canceled by outer logic – in this, it’s called 10 times, because of the <code>for</code> loop in the main thread (marker {10} in the following code):</p>
<pre class="source-code">
    for (int i = 1; i &lt;= 10; i++) {
            auto sentData = sender();
            cout &lt;&lt; i &lt;&lt; " Bytes sent: "
                 &lt;&lt; *sentData &lt;&lt; endl;     // {10}
        }
    });</pre> <p>The client thread is implemented in a similar fashion:</p>
<pre class="source-code">
    auto client = jthread([&amp;sockfd] {
        cout &lt;&lt; "\nrecv_from():\n" &lt;&lt; endl;
        struct sockaddr_in clntaddr = { 0 };
        auto receiver = recv_from(sockfd, clntaddr);
        for (auto i = 1; i &lt;= 10; i++) {
            auto recvData = receiver();
            cout &lt;&lt; i &lt;&lt; " Message received: "
                 &lt;&lt; *recvData &lt;&lt; endl;   // {11}
        }
    });
    server.join(); client.join();
    close(sockfd); return 0;
}</pre> <p>The<a id="_idIndexMarker938"/> server-side <a id="_idIndexMarker939"/>coroutine has the following body:</p>
<pre class="source-code">
Generator&lt;size_t&gt; send_to(int sockfd,
                          string_view buffer,
                          auto servaddr) noexcept {
    for (;;) {
        auto value = sendto(sockfd,
                            buffer.data(),
                            buffer.size(),
                            MSG_DONTWAIT,
                            (const struct sockaddr*)
                                &amp;servaddr,
                            sizeof(servaddr));
        co_yield value;
    }
}</pre> <p>The client-side coroutines are implemented in a similar fashion:</p>
<pre class="source-code">
Generator&lt;string&gt; recv_from(int sockfd,
                                 auto clntaddr,
                                 size_t buf_size =
                                       BUF_SIZE) noexcept {
    socklen_t len = sizeof(struct sockaddr_in);
    array&lt;char, BUF_SIZE&gt; tmp_buf = {};</pre> <p>The <a id="_idIndexMarker940"/>coroutine function calls the <code>recvfrom()</code> system call. At <a id="_idIndexMarker941"/>the end, instead of the bytes received, the message coming from the socket is stored in the <code>currValue</code> member variable. It’s then printed out in the main thread. We also use the <code>MSG_DONTWAIT</code> flag. The respective output will be printed out in different ways every time as the code is asynchronous. The last part is as expected:</p>
<pre class="source-code">
    for (;;) {
         recvfrom(sockfd,
                  tmp_buf.data(),
                  tmp_buf.size(),
                  MSG_DONTWAIT,
                  (struct sockaddr*)&amp;clntaddr,
                  &amp;len);
         co_yield tmp_buf.data();
    }</pre> <p>The merging or misplacing of text is to be expected, but it proves the useability of coroutines. The shortened version of the output is the following:</p>
<pre class="console">
send_to():
1 Bytes sent: 15
...
10 Bytes sent: 15
recv_from():
1 Message received: This is a test!
...
10 Message received: This is a test!</pre> <p>The full example can be found at https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010.</p>
<p>In the previous chapter, we also had the issue of synchronizing parallel threads, but the code was not truly parallel every time. For example, waiting for an event such as “the resource is accessible” is a matter of concurrency, not parallel execution. That said, coroutines are a powerful tool in the shared memory problem, too – let’s check it out in the next section.</p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor153"/>Revisiting the shared memory problem through coroutines in C++</h1>
<p>One of <a id="_idIndexMarker942"/>the issues we had with <strong class="bold">condition variables</strong> was synchronization during process startup. In other words, for the producer-consumer example, we didn’t know which threads were going to be first. We synchronized the code through a <a id="_idIndexMarker943"/>condition variable – its <strong class="bold">mutex</strong>, together with a predicate in order to handle the correct sequence of events. Otherwise, we would’ve risked losing information or ending in a <strong class="bold">deadlock</strong>. For<a id="_idIndexMarker944"/> a good portion of this book’s example preparations, we got to this situation, which made the writing experience even better. But coroutines provide another way of doing it, which could be more efficient at times and simpler to use (after you get used to the interface of coroutines as it is not the easiest to grasp).</p>
<p>The next example is motivated by<a id="_idIndexMarker945"/> the <strong class="bold">awaitable-awaiter</strong> pattern. It is similar to the condition variable, but it doesn’t use such synchronization primitives. Still, the notification signaling is dependent on an atomic variable. We’ll get back to the Task coroutine. It will used for handling the receiver end. The full example can be found here: <a href="https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010">https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%2010</a>.</p>
<p class="callout-heading">Important note</p>
<p class="callout">The example is inspired by <a href="https://www.modernescpp.com/index.php/c-20-thread-synchronization-with-coroutines/">https://www.modernescpp.com/index.php/c-20-thread-synchronization-with-coroutines/</a>.</p>
<p>We reuse <a id="_idIndexMarker946"/>the code from the <strong class="bold">shared memory</strong> example<a id="_idIndexMarker947"/> from <a href="B20833_09.xhtml#_idTextAnchor129"><em class="italic">Chapter 9</em></a>:</p>
<pre class="source-code">
template&lt;typename T, typename N&gt;
Task receiver(Event&amp; event, int fd, N size) {
    co_await event;
    ftruncate(fd, size);</pre> <p>We align the shared memory and set its size first, then we continue mapping the pointer to it:</p>
<pre class="source-code">
    if (const auto ptr = mmap(0, size,
                           PROT_RW, MAP_SHARED,
                           fd, 0); ptr != MAP_FAILED) {
        auto* obj = static_cast&lt;T*&gt;(ptr);
        auto del = mmap_deallocator&lt;T&gt;(size);
        auto res =
            unique_ptr&lt;T, mmap_deallocator&lt;T&gt;&gt;(obj, del);
        if (res != nullptr)
            cout &lt;&lt; "Receiver: " &lt;&lt; *res &lt;&lt; endl;
    }
    else {
        cerr &lt;&lt; "Error mapping shm region";
    } }</pre> <p>It is really important that the address of <code>res</code> is accessible for dereferencing inside the coroutine. Otherwise, the code will crash with <code>Segmentation fault</code>, which is preferable to a dangling pointer. Another remark is that different compilers (or environments) will give you different behavior for this code. Before we get to the <code>Event</code> struct, let’s see what the sender does – again, we step on our previous code:</p>
<pre class="source-code">
template&lt;typename T, typename N&gt;
void Event::notify(T buffer, int fd, N size) noexcept {
    notified = false;
    auto* waiter =
        static_cast&lt;Awaiter*&gt;(suspended.load());
    if (waiter != nullptr) {
        ftruncate(fd, size);</pre> <p>Again, we make <a id="_idIndexMarker948"/>sure the shared memory is of the correct size and we map the pointer to it:</p>
<pre class="source-code">
        if (const auto ptr = mmap(0, size,
                                  PROT_RW, MAP_SHARED,
                                  fd, 0);
                              ptr != MAP_FAILED) {
            auto* obj = new (ptr) T(buffer);
            auto del = mmap_deallocator&lt;T&gt;(size);
            auto res =
                unique_ptr&lt;T, mmap_deallocator&lt;T&gt;&gt;
                                                (obj, del);
        }
        else {
            cerr &lt;&lt; "Error mapping shm region";
        }
        waiter-&gt;coroutineHandle.resume();
    }
}</pre> <p>Initially, the notification flag is set to <code>false</code>, meaning that the coroutine will not behave as a regular function but is going to be suspended. Then, the <code>waiter</code> object is loaded, which is <code>nullptr</code>, because it’s not previously set. Its respective <code>resume()</code> operation is not called. The subsequentially performed <code>await_suspend()</code> function gets the <code>waiter</code> state is stored in the <code>suspended</code> member variable. Later, <code>notify()</code> is triggered and it’s executed fully:</p>
<pre class="source-code">
bool
Event::Awaiter::await_suspend(coroutine_handle&lt;&gt; handle)
  noexcept {
    coroutineHandle = handle;
    if (event.notified) return false;
    event.suspended.store(this);
    return true;
}</pre> <p>In the main thread, an <code>Event</code> object is required to synchronize the workflow. A shared memory region is defined as well. If <code>shm_open()</code> is called inside each coroutine, it will not really be shared virtual memory, as the file descriptor will access private regions for each of the coroutines. Thus, we will end up with <code>Segmentation fault</code>. There are two threads, representing the sender and the receiver ends. The aforementioned coroutines are called respectively after the threads are joined:</p>
<pre class="source-code">
    Event event{};
    int fd = shm_open(SHM_ID, O_CREAT | O_RDWR, 0644);
    auto senderT = jthread([&amp;event, &amp;fd]{
         event.notify&lt;const char*, size_t&gt;(message.data(),
                                           fd,
                                           message.size());
    });</pre> <p>The receiver’s code is similar, but the <code>event</code> object is passed as an argument:</p>
<pre class="source-code">
    auto receiverT = jthread([&amp;event, &amp;fd]{
         receiver&lt;char*, size_t&gt;(ref(event),
                                 fd, (message.size())); });</pre> <p>The output is as follows:</p>
<pre class="console">
This is a testing message!</pre> <p>This example<a id="_idIndexMarker951"/> gives you the flexibility to manage your shared resources in a concurrent manner. The notification mechanism of awaiter-awaitable will do the job without the need for synchronization primitives. We encourage you to try it out yourself. In the meantime, we’ll proceed with some final notes on coroutines usage in system programming.</p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor154"/>Final thoughts on coroutines and their implementations in C++</h1>
<p>The <a id="_idIndexMarker952"/>examples earlier were practical, although not so simple. They were useful in understanding the sequence that a coroutine’s execution might take. It is good to visualize the state graph of coroutines, although we still believe it would be confusing for inexperienced developers.</p>
<p>As presented earlier, <em class="italic">Figure 10</em><em class="italic">.2</em>, <em class="italic">Figure 10</em><em class="italic">.3</em>, and <em class="italic">Figure 10</em><em class="italic">.4</em> pretty much cover what we’ve already explained through the code examples. It is useful to understand how much additional logic is generated around the coroutine and its members. Most of it happens in the background, and the system programmer only arranges the scheduling. In this chapter’s examples, we did this through the <code>promise</code> object and awaitables. The fact that the aforementioned figures partially represent a coroutine’s execution as a finite state machine should hint to you that this is another application where coroutines are useful. They transform state machines into first-class objects. Once the coroutine frame is defined, much of the logic remains there and it’s hidden from callers. This provides the opportunity for system programmers to put aside the concurrent logic for a moment and just focus on calling the coroutines through short code snippets, as we did. The system behavior code and task scheduling will be simpler and more obvious. Thus, much of the power of managing algorithms, parsers, data structure traversals, polling, and so on could be interpreted by this technique. Unfortunately, we cannot cover everything here, but we believe it’s worthwhile checking these things out.</p>
<p>Last but not least, we’d<a id="_idIndexMarker953"/> like to emphasize that coroutines are fairly new to the language. As the coroutine interface in C++ is still lacking comfort and simplicity, you can find many custom-made coroutine libraries on the internet. We advise you to rely only on the trustworthy ones or wait for the next Standard features of this facility. It makes more sense to apply those than to implement them anew yourself. As you can see, it’s quite a complex concept, and there’s a lot of research being done on the matter. For curious readers, we encourage you to spend some time learning about the evolution of coroutines in C++, especially in recent years. There are three techniques discussed in the C++ Standard – Coroutines TS, Core Coroutines, and Resumable expressions. Although just one is currently used in the Standard, the three of them deserve attention. A great summary and analysis has been done by Geoffrey Romer, Gor Nishanov, Lewis Baker, and Mihail Mihailov here: <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1493r0.pdf">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1493r0.pdf</a>.</p>
<p>Feel free to check it out. Many of the clarifications we gave in this chapter are presented in the document as a great visual comparison of the regular functions and coroutines. Meanwhile, we continue to the finish.</p>
<h1 id="_idParaDest-155"><a id="_idTextAnchor155"/>Summary</h1>
<p>With this, we’ve covered all the topics of this book. With the upcoming improvements of C++23, coroutines and their evolution will be analyzed more and more, especially in the system programming domain – and applied there, of course. Although complex to understand at first, coroutines allow you to continue sharpening the usage of C++ and give you one more instrument to enhance code.</p>
<p>In this chapter, you learned how to apply them in your concurrent applications, but their usefulness is far greater. We are excited about what comes next. We expect the <code>modules</code> language feature, which we didn’t cover in this book – intentionally – to be fully covered by the compilers and be broadly applied. Another interesting feature is <code>std::generator</code> – a view for the synchronous creation of coroutines in C++23. <code>std::stacktrace</code> from a thrown exception, which will help you in code debugging. And for easier printing, you’ll be able to use <code>std::print</code> as well. The monadic interface of <code>std::expected</code> will allow you to store either of two values. In addition to all this, files will be loaded at compile time as arrays through <code>#embed</code>.</p>
<p>We’d like to use this opportunity to express our gratitude to you – the reader! We hope you found this book useful and will apply parts of it in your daily job. We also hope you enjoyed the experience the way we enjoyed writing the book. It was a tremendous journey for us, and we’d be glad to share future journeys with you. With this, we wish you good fortune in all your projects!</p>
</div>
</div></body></html>