- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anti-Aliasing Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anti-aliasing can be achieved in many ways, the most common being the one usually
    provided by the graphics API. In this chapter, we start by looking at how to enable
    and use the anti-aliasing provided by Vulkan, going over a multitude of other
    techniques that are more suitable for other use cases that require better anti-aliasing
    or that need a different algorithm altogether, such as temporal anti-aliasing.
    In this chapter, we will guide you through various anti-aliasing techniques, starting
    from enabling and using the one provided by Vulkan to exploring other more advanced
    and suitable methods for different use cases. The goal is to empower you with
    the knowledge and skills to choose and implement the most appropriate anti-aliasing
    technique for your specific needs, thereby improving the visual quality of your
    rendered graphics.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Enabling and using Vulkan’s MSAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying FXAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing TAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying DLSS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need to make sure you have VS 2022 installed along
    with the Vulkan SDK. Basic familiarity with the C++ programming language and an
    understanding of OpenGL or any other graphics API will be useful. Please revisit
    [*Chapter 1*](B18491_01.xhtml#_idTextAnchor019)*, Vulkan Core Concepts*, under
    the *Technical requirements* section for details on setting up and building executables
    for this chapter. This chapter has multiple recipes, which can be launched using
    the following executables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter06_MSAA.exe`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Chapter06_FXAA.exe`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Chapter06_TAA.exe`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Chapter06_DLSS.exe`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enabling and using Vulkan’s MSAA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'MSAA is an anti-aliasing technique that is used to reduce the jagged edges
    that can appear on curved lines and diagonal edges. Here’s an overview of how
    it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple samples**: Instead of sampling a pixel once (like in regular rendering),
    MSAA takes multiple samples within each pixel. For example, 4 x MSAA needs 4 samples
    while 8 x MSAA needs 8 samples. The fragment shader runs for each one of the samples,
    and their output is stored for processing in *step 3*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Edge detection**: MSAA only multi-samples pixels that are at the edges of
    geometry. This makes it more performance-efficient compared to techniques such
    as super-sampling, which samples the entire image at a higher resolution.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Combining samples**: Once the samples are taken, they are averaged (or resolved)
    into a single-color value for the pixel. If some of the samples are within an
    object and some are outside it, the final pixel color will be a blend, creating
    a smoother transition and thereby reducing the appearance of jagged edges.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this recipe, we will describe what steps you need to take to enable MSAA
    in Vulkan, as it is provided by the API.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enabling MSAA in Vulkan requires changes to multiple locations in the source
    code. The following are high-level steps to implement MSAA:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you need to ensure that the system supports MSAA. Additionally, you need
    to determine the maximum number of samples per pixel that are supported.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Textures need to be created with the number of samples they support.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additional textures need to be created to serve as the output after combining
    the samples (also referred to as resolve attachments).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Render passes need to specify the number of samples per attachment and provide
    extra information about the resolve attachments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, framebuffers need to refer to the resolve attachments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rendering with MSAA involves images with sample counts greater than 1\. However,
    these multi-sampled images cannot be presented directly using `VK_IMAGE_LAYOUT_PRESENT_SRC_KHR`.
    The `VK_IMAGE_LAYOUT_PRESENT_SRC_KHR` layout is designed for single-sampled images
    that are ready for presentation, with one color value per pixel. That’s why a
    *resolve* operation is needed to convert the multi-sampled image into a single-sampled
    image. The final anti-aliased output, which is suitable for presentation, needs
    to be written to another image with a sample count of `VK_SAMPLE_COUNT_1_BIT`.
    This implies that every color attachment with a sample count greater than 1 requires
    an associated attachment with a sample count equal to `VK_SAMPLE_COUNT_1_BIT`.
    These additional attachments, known as resolve attachments, are used to store
    the final anti-aliased output. During the resolve operation, the values from the
    multi-samples are combined and written into the *resolve* attachment, creating
    the final single-sample image that can be presented.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enabling MSAA in Vulkan is not difficult but needs changes in multiple parts
    of the code. Here’s a step-by-step guide on how to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code block, we deal with `VkPhysicalDeviceProperties` objects,
    specifically focusing on the `framebufferColorSampleCounts` and `framebufferDepthSampleCounts`
    properties. These properties help us determine the maximum number of samples per
    pixel supported for color and depth respectively. This capability is hardware-dependent,
    which makes it necessary to check it first before usage. The maximum supported
    value is found in the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The maximum number of samples is provided as a bit field of type `VkSampleCountFlagBits`,
    with flags such as `VK_SAMPLE_COUNT_1_BIT`, `VK_SAMPLE_COUNT_2_BIT`, `VK_SAMPLE_COUNT_4_BIT`,
    and so on, up to `VK_SAMPLE_COUNT_64_BIT`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'During image creation, the number of samples that a texture supports must be
    specified. This is done by setting the `samples` member of the `VkImageCreateInfo`
    structure, which is of type `VkSampleCountFlagBits`, such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'While creating a render pass, the attachment descriptions must indicate the
    sample count by setting the `VkAttachmentDescription::samples` field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'An instance of the `VkAttachmentDescription` structure needs to be added to
    the render pass’s list of attachments, `VkSubpassDescription::pColorAttachments`,
    for each resolve attachment in the render pass. The resolve attachments must have
    their samples field set to `VK_SAMPLE_COUNT_1_BIT`, as the resolution of the multi-sampled
    image results in a single sample per pixel. This is because the multiple samples
    from the multi-sampled image are resolved into one final color value for that
    pixel. Here is how you can create and configure such a `VkAttachmentDescription`
    instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'An instance of the `VkAttachmentReference` structure must be created to reference
    this resolve attachment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `VkAttachmentReference::attachment` field is an integer that points to the
    resolve attachment at the corresponding index of the `VkRenderPassCreateInfo::pAttachments`
    array.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, the list of attachment references that describe the resolve attachments
    is added to the `VkSubpassDescription::pResolveAttachments` field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 6**.1* illustrates how each component is set up and how they are referenced
    by a render pass and subpass description structures. The depth/stencil attachment
    must have the same sample count as the color attachments, and the number of resolve
    attachments must be equal to the number of color attachments.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Render pass configuration](img/B18491_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Render pass configuration
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, we showcased the configuration of texture sample count
    and its reference by both the render pass and subpass description structures.
    This arrangement is crucial for enabling MSAA in Vulkan.
  prefs: []
  type: TYPE_NORMAL
- en: Applying FXAA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: FXAA is a screen-space anti-aliasing technique that can be implemented as an
    extra full-screen post-process pass. FXAA works by identifying edges in the image
    and then smoothing them to reduce the appearance of aliasing. Without the need
    for any additional information from the scene, FXAA can be easily integrated into
    existing code. It’s also fast because it processes only the final rendered image
    pixels and some of their neighbors. In this recipe, you will learn about the FXAA
    technique. You will understand how it functions as a screen-space anti-aliasing
    method, how it can be applied through a post-process pass, and why it is a beneficial
    tool due to its ease of integration and speed. Note that FXAA is generally applied
    before gamma correction or any sRGB conversion. The reason for this is that FXAA
    works best on linear RGB data. If you apply FXAA after gamma correction or sRGB
    conversion, it may result in incorrect edge detection and thus less effective
    anti-aliasing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The FXAA algorithm is implemented in our repository by the `FXAAPass` class,
    found in the `source/enginecore/passes/FXAA.cpp` and `FXAA.hpp` files. The shader
    used by the pass is located at `source/enginecore/resources/shaders/fxaa.frag`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The algorithm can be implemented entirely in a fragment shader that uses the
    final render image as input. The shader also needs the size of the viewport, which
    can be provided as a push constant:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The shader is simple in terms of input and output and only needs an input texture
    and the size of the viewport for processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The FXAA algorithm operates on the luminance of the pixels, so we need a function
    to convert RGB values to luminance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are some constants for the edge-detection part:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To simplify the code, we’ll use an array to store the luminance and RGB values
    for the neighboring pixels. We’ll also use constants to help refer to elements
    of the vector without using just integers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The algorithm is encapsulated in the `applyFXAA` function that takes the screen
    coordinates in pixels, the rendered image to be processed, and the size of the
    viewport:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first step is to compute the luminance and the RGB values of all eight
    neighboring pixels, as well as the range between the lowest and the highest luminance.
    If the value is below a certain threshold, we don’t perform the anti-aliasing.
    The **threshold** is used to determine whether a pixel is on an edge; its value
    represents the minimum difference in luminance that must exist between a pixel
    and its neighbors for that pixel to be considered part of an edge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The difference between the average luminance of all neighboring pixels and
    the center pixels tells us whether we need to perform the anti-aliasing algorithm
    and the amount of blending required. It also clamps the blend amount between 0
    and `PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING` to reduce blurring:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step consists of determining whether the edge is more vertical than
    horizontal and initializing the variables that will be used to find the edge endpoints,
    with the `findEndPointPosition` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `findEndPointPosition` function returns `1` if it deems antialiasing is
    needed and `0` otherwise. It also returns the coordinate of the texel that will
    be blended with the pixel being anti-aliased. We will investigate the `findEndPointPosition`
    function in *step 11*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the return value is `1.0`, we perform the antialiasing by blending the original
    pixel’s color with the color from the texel at the `outPosToFetchTexelForEdgeAntiAliasing`
    coordinate. The blending factor to use (`pixelblendAmount`) was computed previously,
    in *step 7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `findEndPointPosition` function performs an important task – it traverses
    the image in search of edge endpoints, moving in both directions from the central
    pixel that’s being processed. To accomplish this, it requires several pieces of
    information. First, it needs the texture that’s being processed, which is the
    image that the function will traverse. Next, it requires the coordinate of the
    pixel being processed, which serves as the starting point for the function’s traversal.
    The function also needs to know the luminance, or brightness, of the pixel. In
    addition, it must be aware of the luminance of the highest contrast pixel, an
    element that is determined based on whether the edge being examined is more horizontal
    or more vertical. Another crucial piece of information is the step length, which,
    like the luminance of the highest contrast pixel, is also dependent on the angle
    of the edge. The function needs the length of one pixel in texture coordinates
    for accurate image traversal. Finally, it requires a flag that indicates whether
    the edge is more horizontal or more vertical to correctly understand the edge’s
    orientation. It returns `1` if it deems anti-aliasing needs to be performed and
    `0` otherwise. It also returns the coordinate of the pixel that contains the RGB
    value to be used for the anti-aliasing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Depending on whether the edge is horizontal or not, the function initializes
    the direction and position of the high-contrast pixel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before we proceed to start looking for the edge endpoints, we need to set up
    some variables used in the loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The loop iterates a maximum of `NUM_LOOP_FOR_EDGE_DETECTION` times. It checks
    for edges by looking at the luminance differences in both the positive and negative
    directions from the middle pixel. The edge is detected when the luminance difference
    between two consecutive points in one direction exceeds a threshold (we will look
    at the `processDirection` function in *step 20*):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The function now calculates the distances from the middle pixel to the detected
    edge endpoints, in both the negative and positive directions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It also checks which endpoint is closer to the middle pixel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Anti-aliasing is deemed necessary, based on the luminance difference between
    the endpoint that is closer to the middle pixel and the middle pixel itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the distances to the edge endpoints, the following code snippet calculates
    the pixel offset that is required for anti-aliasing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The function returns `1.0` if edge anti-aliasing is required and `0.0` otherwise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `processDirection` inspects the luma values of pixels in a certain direction
    (given by `edgeIncrement`) to check for high contrast or edges. It will continue
    to inspect positions in this direction until a certain contrast condition is met.
    Once the condition is met, it will set the `doneGoingThroughDir` flag to `true`,
    signaling that it’s done processing in this direction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The fragment code calls `applyFXAA`, which returns the new color to output
    from the shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: And there you have it – the recipe for applying FXAA, a powerful tool for smoothing
    out jaggies in your graphics. As we wrap this up, remember that the beauty of
    FXAA lies not just in its ability to enhance visual output but also in its flexibility
    and ease of integration into existing systems.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing TAA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike the previously discussed anti-aliasing methods, which only consider spatial
    information, TAA is based on temporal information – that is, it utilizes both
    the current and previous frames to smooth out these aliasing artifacts. The reason
    aliasing artifacts happens is because of insufficient samples; TAA solves this
    by sampling data over the frame sequence, significantly reducing the pressure
    on a single frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic idea is to apply subpixel jittering – that is, slightly shift the
    projection matrix of the camera for each new frame. This results in slightly different
    viewpoints for each frame, giving us more information about the scene than a static
    viewpoint would. When sampling textures during rendering, the resulting color
    value can be different due to the jitter. This creates a different aliasing pattern
    per frame, which, when accumulated over time, averages out and reduces the visible
    aliasing in the scene. This is demonstrated in the following screenshot in *Figure
    6**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – A temporal anti-aliasing overview](img/B18491_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – A temporal anti-aliasing overview
  prefs: []
  type: TYPE_NORMAL
- en: The concept outlined here performs exceptionally well for static scenes. However,
    in scenarios where either the objects or the camera is in motion, consecutive
    frames can exhibit substantial differences. This can lead to a visual artifact
    where moving objects appear to leave behind a series of their *ghosts*, creating
    what is known as the **ghosting** effect.
  prefs: []
  type: TYPE_NORMAL
- en: To get rid of ghosting, we use what is commonly called a **velocity** buffer,
    and the motion in the scene is captured using motion vectors. For each pixel,
    a motion vector is calculated that represents how much a pixel has moved compared
    to the previous frame. The result is a velocity buffer that stores these motion
    vectors. The previously rendered frame is then re-projected onto the current frame
    using the velocity buffer. This means that for each pixel, the color of the corresponding
    pixel in the previous frame is looked up using the motion vector. This color is
    then blended with the current color of the pixel, which results in a smoothing
    of the colors over time.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.3* shows a high-level overview of the TAA algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – A TAA frame overview](img/B18491_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – A TAA frame overview
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to implement TAA, an advanced technique that
    can significantly reduce flickering and provide smoother visuals in your graphics.
    You’ll understand the intricacies of TAA and how to adeptly integrate it into
    your code, adding another powerful tool to your graphics rendering toolbox.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository, the TAA algorithm is implemented by the `TAAComputePass`
    class, located in the `source/enginecore/passes/TAAComputePass.hpp` and `cpp`
    files. The shaders are implemented using a compute shader, located in `source/enginecore/resources/shaders/taaresolve.comp`
    and `source/enginecore/resources/shaders/taahistorycopyandsharpen.comp`. TAA example
    can be launched by running the `Chapter06_TAA` executable.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.4* illustrates the flow of the TAA algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – A TAA algorithm in a deferred renderer](img/B18491_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – A TAA algorithm in a deferred renderer
  prefs: []
  type: TYPE_NORMAL
- en: 'TAA is implemented as a two-step compute shader:'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is the TAA resolve shader, which takes `ColorTexture`, `DepthTexture`,
    `HistoryTexture`, and `VelocityTexture` as input and writes to an intermediate
    image. The velocity, color, and depth texture are produced from the `Gbuffer`
    pass in the given example; however, conceptually, the same could be produced in
    forward rendering as well.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The second step is running a compute shader that is responsible for the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copying the results of the previously produced intermediate texture into a history
    texture.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Refining these intermediate results, we don’t need to generate an additional
    texture to store the refined results, instead, we can utilize the provided `ColorTexture`
    in the TAA resolve shader. This is the same `ColorTexture` that eventually gets
    displayed. A known downside of TAA is the potential of causing a minor blur in
    the image. To mitigate this, a sharpening filter is applied post-TAA. This sharpening
    phase is designed to intensify the edges and intricate details in the image, thereby
    reinstating some of the sharpness that might have been compromised during the
    TAA resolve process.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement TAA, we first need to construct a jitter matrix. This matrix will
    be used in tandem with the **Model-View-Projection** (**MVP**) matrix during the
    rendering process. Furthermore, we will need color, depth, and velocity buffers.
    Conveniently, these buffers are already generated as part of the G-buffer pipeline,
    which we implemented in [*Chapter 4*](B18491_04.xhtml#_idTextAnchor241)*, Exploring
    Techniques for Lighting, Shading, and Shadows* in the *Implementing the G-buffer
    for deferred* *rendering* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: The `TAAComputePass::init` method is in charge of initializing various resources.
    It establishes two pipelines – one for resolving to an output color, and another
    for transferring the output color into a history texture and enhancing the output
    color’s sharpness.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The majority of work happens in the `TAAComputePass::doAA` function. This function
    simply operates the resolve compute pipeline, followed by the pipeline that handles
    the copying of the history texture and the sharpening of the output color. We’ve
    highlighted key components of the `doAA` function as follows, omitting less critical
    parts to avoid verbosity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The actual magic happens in the two compute shaders; specifically, the resolve
    shader is the most important. The resolve shader is implemented in `taaresolve.comp`.
    Let’s look at how the shaders work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we will expand on some auxiliary functions. `catmullRomTextureFiltering`
    helps smooth out the temporal aliasing by blending the colors of pixels between
    frames, using Catmull-Rom interpolation. Catmull-Rom interpolation is a form of
    cubic interpolation that provides a smoother appearance than linear interpolation.
    The function uses the Catmull-Rom weights (`w0, w1, w2, w3`) to calculate the
    weight for the center (`w12`) and the offset from the center (`offset12`). Then,
    the function calculates three new texture positions (`texPos0`, `texPos3`, and
    `texPos12`) and adjusts these positions to match the texture resolution. The function
    then uses these weights and texture positions to calculate the resulting pixel
    color, by accessing the history buffer texture at the specific positions, multiplying
    the retrieved color by the respective weights, and summing them together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `varianceClampColor` function is used in anti-aliasing TAA to deal with
    issues of ghosting and blurring that can occur, due to the temporal reprojection
    of color data. The function works by limiting the color value of a given pixel,
    based on the color variance of its surrounding pixels. It loops over a 3x3 neighborhood
    around the current pixel. For each neighboring pixel, the function retrieves its
    color data (`neighColor`) and calculates a weight (`w`), based on the Euclidean
    distance from the current pixel. This weight is designed to give closer pixels
    more influence over the final color result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `calculateBlendFactor` function is responsible for performing calculations
    to determine the blend factor of a pixel, based on its velocity and luminance.
    Firstly, the pixel movement is calculated on two levels, the overall motion and
    the tiny subpixel motion, resulting in values called `subpixelMotion` and `dynamicBlendFactor`
    respectively. Then, to adjust the pixel’s brightness or luminance, the difference
    between the current color and the previous frame color is determined. This entire
    process enhances the realism of the pixel’s movement and color changes over time,
    significantly improving the overall image quality when there’s movement of objects
    or camera. The implementation of `catmullRomTextureFiltering` and `varianceClampColor`
    are very verbose; we suggest looking at `taaresolve.comp` for implementation details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we present the `main` function; this helps to produce a smoother, more
    stable image by reducing flickering and ghosting artifacts that can occur, due
    to the rapid movement of the camera or objects in a scene. The following sub-steps
    will walk you through the specifics of its implementation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the closest depth and corresponding velocity around the current pixel:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reproject the current pixel position to its position in the previous frame
    using the calculated velocity:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate `velocityLerp` using the history buffer at the reprojected location.
    Note the use of `taaConstData.isFirstFrame`, which helps to determine whether
    we are dealing with the first frame of the sequence or not. If it is the first
    frame, `velocityLerp` is simply initialized to `0.0f`. In the context of camera
    cuts or teleports (i.e., a sudden change from one perspective to another), the
    first frame assumption is also applicable. Whenever these events occur, the scene
    changes dramatically from one frame to another. In such cases, it’s beneficial
    to treat the frame right after the cut or teleport as a first frame. This is because
    the data from the previous frame is no longer a good reference for the current
    frame, due to the drastic changes in scene content:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the current frame color (`colorIn`) and calculate `colorHistory` using
    `catmullRomTextureFiltering`:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define two constants, `boxSizeWhenMoving` and `boxSizeWhenStationary`. We determine
    value of `boxSize` based on whether the camera is moving or not and is interpolated
    between the stationary and moving values, based on `velocityLerp`:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Historical color (`colorHistory`) is then clamped using the `varianceClampColor`
    function to ensure that the color is within a certain range, based on the variance
    of surrounding pixels:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate `blendFactor`, which determines how much of the current color and
    the historical color should be used to get the final color:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the final color (`colorResolve`) as a mix of the clamped historical
    color and the current color, based on `blendFactor`; also, store `velocityLerp`
    in the `alpha` channel:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will show how `taahistorycopyandsharpen.comp` works; this shader is
    responsible for copying the data into history texture, as well as sharpening the
    results produced by *step 5* (`taaresolve.comp`). The main function is presented
    as follows, and the code is simple – it first copies `incolor` (which is the image
    produced by previous *step 5*) into the history texture. Then, the `sharpen` method
    is called. This method works by first loading pixel colors from the center and
    four directly adjacent locations (top, left, right, and bottom). It then uses
    an unsharp masking technique, which involves subtracting a blurred or *unsharp*
    version of the image from the original image to create a mask that represents
    the detail of the image. The function applies this mask to enhance the original
    image, making it appear sharper. The final color produced by the `sharpen` method
    is stored in `outColorImage`, which is finally copied to the swapchain image.
    For the sake of brevity, we’re not detailing the `sharpen` function here. However,
    you can review its implementation in the `taahistorycopyandsharpen.comp` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Despite its widespread use and numerous benefits, TAA isn’t without its shortcomings:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When object motion uncovers new areas on a screen, these areas are either not
    present in the history buffer or are inaccurately depicted by the motion vectors.
    Additionally, camera rotation and reverse translation can lead to extensive uncovered
    areas at the screen’s edges.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Features with subpixel dimensions, such as wires, may be missed by a consecutive
    frame, leading to their absence in motion vectors in the subsequent frame. Transparent
    surfaces can generate pixels where the motion vectors from opaque objects don’t
    align with the overall movement of the objects depicted. Lastly, shadows and reflections
    don’t follow the direction of the motion vectors of the surfaces they shade.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When TAA doesn’t work properly, it either results in ghosting (a blurring effect
    caused by integrating incorrect values) or it exposes the original aliasing, leading
    to jagged edges, flickering, and noise.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs: []
  type: TYPE_NORMAL
- en: 'For further reading and a deeper understanding of TAA, consider exploring the
    following resources. These references will provide you with more detailed information,
    practical applications, and insights into the latest advancements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://research.nvidia.com/publication/2019-03_improving-temporal-antialiasing-adaptive-ray-tracing](https://research.nvidia.com/publication/2019-03_improving-temporal-antialiasing-adaptive-ray-tracing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/temporal-anti-aliasing](https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/temporal-anti-aliasing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying DLSS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DLSS is an AI-powered technology developed by NVIDIA for their RTX series of
    graphics cards. DLSS uses the power of machine learning and AI to increase the
    resolution of rendered frames by intelligently upscaling lower resolution images
    in real time. This results in a high-quality, high-resolution image that requires
    less computational power to produce. We can also use DLSS to render frames at
    a lower base resolution and then use AI to upscale the image to a higher resolution.
  prefs: []
  type: TYPE_NORMAL
- en: Note that to use DLSS, you must have an NVIDIA RTX series graphics card.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you’ll learn how to apply DLSS, an innovative technique for
    enhancing the resolution of rendered frames in real time. You will gain an understanding
    of how DLSS leverages machine learning and AI to upscale lower-resolution images
    intelligently, thereby achieving superior image quality with less computational
    power.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the repository, DLSS is implemented by the `DLSS` class, located in the `source/enginecore/DLSS.hpp`
    and `cpp` files. The DLSS example can be launched by running the `chapter06_DLSS`
    executable.
  prefs: []
  type: TYPE_NORMAL
- en: DLSS also requires color, depth and velocity textures, the same textures that
    were used by the TAA algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The DLSS is integrated using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to query the device and instance extensions that are required
    for DLSS; these extensions need to be enabled before Vulkan is initialized. NVIDIA’s
    DLSS SDK provides `NVSDK_NGX_VULKAN_RequiredExtensions`, which needs to be used
    to query extensions. The following code block presents a static function that
    can append extensions required by DLSS; this needs to be called before initializing
    the Vulkan device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will look at `DLSS init` method. This method is responsible for initializing
    the DLSS feature provided by the NVSDK. It takes the current width and height
    of the viewport, an upscale factor, and a reference to a `CommandQueueManager`
    object. The function first sets the upscale factor and then determines the optimal
    settings for DLSS, based on the current viewport size and desired quality level.
    It then configures DLSS features such as motion vector resolution, frame sharpening,
    and others based on specific flags. Finally, it creates the DLSS feature and submits
    the command to the Vulkan command buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to call DLSS’s `render` method, which is responsible for applying
    DLSS to the provided input textures to enhance the image quality. It takes a Vulkan
    command buffer and several texture objects as inputs – color, depth, motion vector,
    and output color texture, along with a 2D vector for the camera jitter. Firstly,
    we create resources for each of the input textures using the `NVSDK_NGX_Create_ImageView_Resource_VK`
    function; afterward, we transition the layout of the output color texture to `VK_IMAGE_LAYOUT_GENERAL`
    to prepare it for writing. Next, this function sets up the parameters for the
    DLSS evaluation, including input color and output resources, sharpness level,
    depth resource, motion vector resource, and camera jitter offsets. The last part
    is to call `NGX_VULKAN_EVALUATE_DLSS_EXT` to apply DLSS to the images, which enhances
    the image quality, based on the parameters provided:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next section, we present valuable links for further reading and deeper
    understanding of the topic.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For more in-depth knowledge and practical insights on DLSS, the following resource
    will prove invaluable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/NVIDIA/DLSS/blob/main/doc/DLSS_Programming_Guide_Release.pdf](https://github.com/NVIDIA/DLSS/blob/main/doc/DLSS_Programming_Guide_Release.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we started with Vulkan’s MSAA. This is a method used to combat
    the spatial aliasing of high-contrast edges, often seen as jagged or staircase
    lines in the rendered image. We discussed the process of enabling MSAA in Vulkan,
    which involves configuring the multi-sample state during pipeline creation and
    allocating a separate multi-sample image. We also covered how MSAA operates by
    averaging the color of multiple sample points, reducing the jagged appearance,
    and providing a smoother, more natural look to the edges.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we addressed FXAA. This technique is a screen-space, post-processing method,
    meaning that it works directly on the final image. Its primary advantage is its
    speed and simplicity, offering a good trade-off between performance and quality.
    FXAA smooths edges by finding high-contrast pixels and blending them with their
    surroundings. Despite being an approximation, FXAA can often provide a significant
    improvement in perceived image quality, particularly in scenes with many high-contrast
    edges.
  prefs: []
  type: TYPE_NORMAL
- en: The third technique we discussed was TAA. This method uses the concept of temporal
    reprojection, where it leverages information from previous frames to minimize
    aliasing artifacts in the current frame. We covered how TAA operates by accumulating
    samples over multiple frames and applying a filter to reduce the temporal aliasing
    effects, such as crawling and flickering. When implemented correctly, TAA can
    offer superior results over purely spatial techniques, particularly in scenes
    with high levels of motion and detail.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we explored the cutting-edge technique of DLSS. Powered by AI, DLSS
    is a proprietary technology developed by NVIDIA. It works by training a deep learning
    model to predict high-resolution images from lower-resolution inputs. The trained
    model is then used to upscale images in real time. We also talked about how DLSS
    can maintain or even improve visual fidelity while significantly boosting performance.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provided a comprehensive overview of various anti-aliasing techniques,
    each with its strengths and use cases. By understanding these methods, you can
    make informed choices on which technique to implement, based on the specific needs
    of your Vulkan applications.
  prefs: []
  type: TYPE_NORMAL
