<html><head></head><body>
		<div><h1 id="_idParaDest-361" class="chapter-number"><a id="_idTextAnchor361"/>9</h1>
			<h1 id="_idParaDest-362"><a id="_idTextAnchor362"/>Advanced Container  Adaptor Usage</h1>
			<p>Container adaptors, as their name suggests, adapt underlying containers to provide specific interfaces and functionalities. Think of them as a way to enhance or modify an existing container so that it serves a different purpose without having to reinvent the wheel. They wrap around base containers and provide a distinct set of member functions, imbuing them with behavior that can be useful in various programming scenarios.</p>
			<p>This chapter provides references for the following containers:</p>
			<ul>
				<li><code>std::stack</code></li>
				<li><code>std::queue</code></li>
				<li><code>std::priority_queue</code></li>
				<li><code>std::flat_set</code></li>
				<li><code>std::flat_map</code></li>
				<li><code>std::flat_multiset</code></li>
				<li><code>std::flat_multimap</code></li>
			</ul>
			<h1 id="_idParaDest-363"><a id="_idTextAnchor363"/>Technical requirements</h1>
			<p>The code in this chapter can be found on GitHub:</p>
			<p><a href="https://github.com/PacktPublishing/Data-Structures-and-Algorithms-with-the-CPP-STL">https://github.com/PacktPublishing/Data-Structures-and-Algorithms-with-the-CPP-STL</a></p>
			<h1 id="_idParaDest-364"><a id="_idTextAnchor364"/>std::stack</h1>
			<p><code>std::stack</code> is a<a id="_idIndexMarker570"/> data structure that represents a stack, a <code>std::deque</code>, <code>std::vector</code>, and <code>std::list</code>, providing a simple and easy-to-use interface for working with stacks. You can push elements onto the top of the stack, pop elements from the top, and access the top element without accessing elements at other positions. <code>std::stack</code> is commonly used for tasks that require a stack-like behavior, such as tracking function call sequences, parsing expressions, and managing temporary data. It provides a convenient way to manage data to ensure the most recently added element is the first to be removed.</p>
			<h2 id="_idParaDest-365"><a id="_idTextAnchor365"/>Purpose and suitability</h2>
			<p><code>std::stack</code> is a container<a id="_idIndexMarker572"/> adapter that’s designed to provide a LIFO data structure. It operates on top of another container, such as <code>std::vector</code>, <code>std::deque</code>, or <code>std::list</code>.</p>
			<p>It’s particularly<a id="_idIndexMarker573"/> suitable in the following scenarios:</p>
			<ul>
				<li>When a LIFO behavior is needed</li>
				<li>When you only need to access the most recently added element</li>
				<li>When insertions and deletions happen solely at one end</li>
			</ul>
			<p>Choose <code>std::stack</code> when you require a simple interface to manage data in a LIFO manner. For more flexible operations, consider its underlying container.</p>
			<h2 id="_idParaDest-366"><a id="_idTextAnchor366"/>Ideal use cases</h2>
			<p>The following <a id="_idIndexMarker574"/>are some of the ideal use cases for <code>std::stack</code>:</p>
			<ul>
				<li><strong class="bold">Expression evaluations and parsing</strong>: An example of this is evaluating postfix expressions</li>
				<li><strong class="bold">Backtracking algorithms</strong>: An example of this is performing depth-first search in graphs</li>
				<li><strong class="bold">Undo operations in software</strong>: Maintaining a history of user actions to revert them</li>
			</ul>
			<h2 id="_idParaDest-367"><a id="_idTextAnchor367"/>Performance</h2>
			<p>Since <code>std::stack</code> is a <a id="_idIndexMarker575"/>container adaptor, its algorithmic performance is dependent on the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion (</strong><strong class="bold">push)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Deletion (</strong><strong class="bold">pop)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Access (</strong><strong class="bold">top)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Memory overhead</strong>: Directly tied to the underlying container</li>
			</ul>
			<h2 id="_idParaDest-368"><a id="_idTextAnchor368"/>Memory management</h2>
			<p><code>std::stack</code> behaves<a id="_idIndexMarker576"/> like its underlying container does. For instance, if <code>std::vector</code> is the base, resizing might involve reallocation, doubling its memory.</p>
			<h2 id="_idParaDest-369"><a id="_idTextAnchor369"/>Thread safety</h2>
			<p>Like most STL<a id="_idIndexMarker577"/> containers, <code>std::stack</code> isn’t thread-safe for write operations. External synchronization is necessary for concurrent writes or a combination of reads and writes.</p>
			<h2 id="_idParaDest-370"><a id="_idTextAnchor370"/>Extensions and variants</h2>
			<p><code>std::queue</code> and <code>std::priority_queue</code> are <a id="_idIndexMarker578"/>other <a id="_idIndexMarker579"/>adapters in the STL, serving <strong class="bold">first-in, first-out</strong> (<strong class="bold">FIFO</strong>) behaviors and priority-driven access, respectively.</p>
			<h2 id="_idParaDest-371"><a id="_idTextAnchor371"/>Sorting and searching complexity</h2>
			<p>Sorting and searching <a id="_idIndexMarker580"/>are not inherently suited for <code>std::stack</code>. You might have to transfer elements to a different container to sort or search.</p>
			<h2 id="_idParaDest-372"><a id="_idTextAnchor372"/>Special interface and member functions</h2>
			<p><code>std::stack</code> is <a id="_idIndexMarker581"/>designed <a id="_idIndexMarker582"/>to offer three special member functions:</p>
			<ul>
				<li><code>push</code>: Pushes an element onto the top of the stack</li>
				<li><code>pop</code>: Removes (pops) an element from the top of the stack</li>
				<li><code>top</code>: Gets the value of the top element in the stack without removing it</li>
			</ul>
			<h2 id="_idParaDest-373"><a id="_idTextAnchor373"/>Comparisons</h2>
			<p>Compared <a id="_idIndexMarker583"/>to the raw underlying containers, <code>std::stack</code> offers a restricted interface tailored for LIFO operations.</p>
			<h2 id="_idParaDest-374"><a id="_idTextAnchor374"/>Interactions with algorithms</h2>
			<p>Direct interactions<a id="_idIndexMarker584"/> with STL algorithms are limited due to the lack of iterator support. For algorithmic operations, consider the underlying container directly.</p>
			<h2 id="_idParaDest-375"><a id="_idTextAnchor375"/>Exceptions</h2>
			<p>Attempting <a id="_idIndexMarker585"/>operations on an empty stack, such as <code>pop</code> or <code>top</code>, doesn’t throw but leads to undefined behavior. Ensure the stack isn’t empty before such operations.</p>
			<h2 id="_idParaDest-376"><a id="_idTextAnchor376"/>Customization</h2>
			<p>While the <a id="_idIndexMarker586"/>behavior of <code>std::stack</code> can’t be altered much, using custom allocators or selecting a specific underlying container can influence performance and storage characteristics.</p>
			<h2 id="_idParaDest-377"><a id="_idTextAnchor377"/>Example</h2>
			<p>The <a id="_idIndexMarker587"/>following code shows an example demonstrating the use of <code>std::stack</code>. This example implements a function to evaluate <strong class="bold">Reverse Polish Notation</strong> (<strong class="bold">RPN</strong>) expressions, a <a id="_idIndexMarker588"/>postfix mathematical notation. Using a stack is a natural fit for this type of problem:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;stack&gt;
#include &lt;string&gt;
double evaluateRPN(const std::string &amp;expression) {
  std::stack&lt;double&gt; s;
  std::istringstream iss(expression);
  std::string token;
  while (iss &gt;&gt; token) {
    if (token == "+" || token == "-" || token == "*" ||
        token == "/") {
      if (s.size() &lt; 2) {
        throw std::runtime_error("Invalid RPN expression");
      }
      double b = s.top();
      s.pop();
      double a = s.top();
      s.pop();
      if (token == "+") {
        s.push(a + b);
      } else if (token == "-") {
        s.push(a - b);
      } else if (token == "*") {
        s.push(a * b);
      } else if (token == "/") {
        if (b == 0.0) {
          throw std::runtime_error("Division by zero");
        }
        s.push(a / b);
      }
    } else {
      s.push(std::stod(token));
    }
  }
  if (s.size() != 1) {
    throw std::runtime_error("Invalid RPN expression");
  }
  return s.top();
}
int main() {
  try {
    // Evaluate RPN expressions
    std::cout &lt;&lt; "46 2 + = " &lt;&lt; evaluateRPN("46 2 +")
              &lt;&lt; "\n"; // 48
    std::cout &lt;&lt; "5 1 2 + 4 * + 3 - = "
              &lt;&lt; evaluateRPN("5 1 2 + 4 * + 3 -")
              &lt;&lt; "\n"; // 14
    std::cout &lt;&lt; "3 4 5 * - = " &lt;&lt; evaluateRPN("3 4 5 * -")
              &lt;&lt; "\n"; // -17
  } catch (const std::exception &amp;e) {
    std::cerr &lt;&lt; "Error: " &lt;&lt; e.what() &lt;&lt; "\n";
  }
  return 0;
}</pre>			<p>Here’s the example output:</p>
			<pre class="console">
46 2 + = 48
5 1 2 + 4 * + 3 - = 14
3 4 5 * - = -17</pre>			<p>In the<a id="_idIndexMarker589"/> preceding example, the following occurs:</p>
			<ul>
				<li>We use <code>std::stack</code> to manage operands and evaluate the RPN expression.</li>
				<li>Operands are pushed onto the stack. When an operator is encountered, the necessary number of operands (usually two) are popped from the stack. Next, the operation is performed. Finally, the result is pushed back onto the stack.</li>
				<li>If the expression is valid at the end of the evaluation, there should be precisely one number on the stack: the result.</li>
				<li>The function handles possible errors, such as an invalid RPN expression or division by zero.</li>
			</ul>
			<p>This is a typical <a id="_idIndexMarker590"/>use of <code>std::stack</code> as it showcases the LIFO nature of the data structure and its principle operations (<code>push</code>, <code>pop</code>, and <code>top</code>).</p>
			<h2 id="_idParaDest-378"><a id="_idTextAnchor378"/>Best practices</h2>
			<p>Let’s explore<a id="_idIndexMarker591"/> the best practices of using <code>std::stack</code>:</p>
			<ul>
				<li><strong class="bold">Maintain a LIFO discipline</strong>: A stack is designed for LIFO operations. Avoid manipulating the underlying container directly to access anything other than the top element. Bypassing the LIFO logic compromises the purpose and integrity of using a stack.</li>
				<li><code>top()</code> or <code>pop()</code>, always validate if the stack is empty using the <code>empty()</code> function. Accessing or popping from an empty stack leads to undefined behavior and potential runtime errors.</li>
				<li><code>std::stack</code> uses <code>std::deque</code> as its container, which typically provides efficient push and pop operations. While you can customize this with containers such as <code>std::vector</code> or <code>std::list</code>, be aware of their respective performance and memory characteristics. For instance, while <code>std::vector</code> might have occasional resizing overheads, <code>std::list</code> has per-element overheads.</li>
				<li><code>std::stack</code> itself does not guarantee thread safety. If you’re accessing or modifying a stack from multiple threads, employ proper synchronization mechanisms, such as <code>std::mutex</code>, to prevent data races and maintain consistency.</li>
				<li><code>std::stack</code> interface restricts you to the top element, the underlying container might not. Directly using the underlying container can provide broader access and introduce errors if you’re not cautious.</li>
				<li><code>emplace</code> to construct the element directly<a id="_idIndexMarker592"/> within the stack. This can reduce the need for temporary objects and potential copy/move operations, leading to more efficient and concise code.</li>
				<li><strong class="bold">Exception safety</strong>: Certain operations might provide basic or strong exception safety, depending on the underlying container. Awareness of these guarantees is essential, especially if your application requires a certain level of exception safety.</li>
				<li><code>std::stack</code> doesn’t expose capacity or reservation mechanisms directly, the underlying container, especially if it’s <code>std::vector</code>, might have such behaviors. If you’re confident about the stack’s growth patterns, consider using an appropriate underlying container and managing its capacity for optimization.</li>
				<li><code>auto</code>, be explicitly aware of your stack’s type. This includes the type of elements it holds and the underlying container. This clarity ensures you remain informed about the stack’s performance characteristics and limitations.</li>
				<li><code>std::vector&lt;bool&gt;</code>, using <code>std::stack&lt;bool&gt;</code> with certain underlying containers can have unexpected behaviors or inefficiencies due to container specializations. If you need a stack of Boolean values, consider alternatives or be well-informed about the specific container’s behavior with Boolean types.</li>
			</ul>
			<h1 id="_idParaDest-379"><a id="_idTextAnchor379"/>std::queue</h1>
			<p><code>std::queue</code> represents <a id="_idIndexMarker593"/>a FIFO data structure. It is implemented as an adapter class and is typically based on other underlying containers, such as <code>std::deque</code> or <code>std::list</code>. <code>std::queue</code> provides a straightforward interface for working with queues, allowing you to enqueue (push) elements at the back and dequeue (pop) elements from the front. It is commonly used in C++ for situations where data needs to be processed in the order it was added, such as task scheduling, breadth-first traversal of graphs or trees, and managing work items in multi-threaded programs. <code>std::queue</code> ensures that the element in the queue that is the longest is the first to be dequeued, making it a useful tool for managing ordered data processing.</p>
			<h2 id="_idParaDest-380"><a id="_idTextAnchor380"/>Purpose and suitability</h2>
			<p><code>std::queue</code> is a<a id="_idIndexMarker594"/> container adapter that’s built on top of another container such as <code>std::deque</code>, <code>std::list</code>, or <code>std::vector</code>. Its primary purpose is to provide FIFO data access.</p>
			<p>It’s especially suitable in the following scenarios:</p>
			<ul>
				<li>When sequential access is needed</li>
				<li>When elements are to be processed in their insertion order</li>
			</ul>
			<p>If searching, sorting, or random access is a primary concern, <code>std::queue</code> might not be the optimal choice.</p>
			<h2 id="_idParaDest-381"><a id="_idTextAnchor381"/>Ideal use cases</h2>
			<p>The following are<a id="_idIndexMarker595"/> some of the ideal use cases for <code>std::queue</code>:</p>
			<ul>
				<li><strong class="bold">Task scheduling</strong>: Manage tasks in the order they arrive</li>
				<li><strong class="bold">Data serialization</strong>: Ensure data is processed in the order it’s received</li>
				<li><strong class="bold">Tree Traversal:</strong> Breadth-first traversal of graphs or trees</li>
			</ul>
			<h2 id="_idParaDest-382"><a id="_idTextAnchor382"/>Performance</h2>
			<p>Since <code>std::queue</code> is a <a id="_idIndexMarker596"/>container adaptor, its algorithmic performance depends on the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion (</strong><strong class="bold">push)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Deletion (</strong><strong class="bold">pop)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Access (front and </strong><strong class="bold">back)</strong>: <em class="italic">O(1)</em></li>
				<li><strong class="bold">Memory overhead</strong>: Depends on the underlying container</li>
			</ul>
			<p>The performance characteristics derive mainly from the base container, which is typically <code>std::deque</code>.</p>
			<h2 id="_idParaDest-383"><a id="_idTextAnchor383"/>Memory management</h2>
			<p>Its memory <a id="_idIndexMarker597"/>behavior depends on the underlying container. For instance, if you’re using <code>std::deque</code>, it manages blocks of memory and can grow both ends.</p>
			<h2 id="_idParaDest-384"><a id="_idTextAnchor384"/>Thread safety</h2>
			<p>Reads and<a id="_idIndexMarker598"/> writes aren’t inherently thread-safe. External synchronization, such as mutexes, is necessary if concurrent access is required.</p>
			<h2 id="_idParaDest-385"><a id="_idTextAnchor385"/>Extensions and variants</h2>
			<p><code>std::priority_queue</code> is <a id="_idIndexMarker599"/>another adapter that provides access to the top-most element based on a priority, not insertion order.</p>
			<h2 id="_idParaDest-386"><a id="_idTextAnchor386"/>Sorting and searching complexity</h2>
			<p>Sorting and<a id="_idIndexMarker600"/> searching does not apply to <code>std::queue</code>. <code>std::queue</code> is designed for FIFO access. Sorting or random searching would require manual iteration through the underlying container, which is suboptimal and defies the purpose of a queue.</p>
			<h2 id="_idParaDest-387"><a id="_idTextAnchor387"/>Special interface and member functions</h2>
			<p>Its primary<a id="_idIndexMarker601"/> operations include <code>push()</code>, <code>pop()</code>, <code>front()</code>, and <code>back()</code>. <code>size()</code> and <code>empty()</code> are <a id="_idIndexMarker602"/>used for size checks and emptiness.</p>
			<h2 id="_idParaDest-388"><a id="_idTextAnchor388"/>Comparisons</h2>
			<p>Compared<a id="_idIndexMarker603"/> to <code>std::stack</code>, which offers LIFO access, <code>std::queue</code> ensures FIFO behavior. If random access is required, then <code>std::vector</code> might be more appropriate.</p>
			<h2 id="_idParaDest-389"><a id="_idTextAnchor389"/>Interactions with algorithms</h2>
			<p>Direct interaction<a id="_idIndexMarker604"/> with most STL algorithms is limited due to the lack of iterators. If algorithmic operations are needed, you’d typically work on the underlying container directly.</p>
			<h2 id="_idParaDest-390"><a id="_idTextAnchor390"/>Exceptions</h2>
			<p>The exceptions<a id="_idIndexMarker605"/> that are thrown depend on the operations of the underlying container. However, accessing elements from an empty queue (using <code>front()</code> or <code>back()</code>) can lead to undefined behavior.</p>
			<h2 id="_idParaDest-391"><a id="_idTextAnchor391"/>Customization</h2>
			<p>Memory <a id="_idIndexMarker606"/>management can be customized by choosing an appropriate underlying container and possibly using custom allocators.</p>
			<h2 id="_idParaDest-392"><a id="_idTextAnchor392"/>Example</h2>
			<p>One<a id="_idIndexMarker607"/> everyday use case for <code>std::queue</code> is implementing a <code>std::queue</code>. Here is a basic BFS implementation on an undirected graph that uses an adjacency list representation:</p>
			<pre class="source-code">
#include &lt;iostream&gt;
#include &lt;queue&gt;
#include &lt;vector&gt;
class Graph {
public:
  Graph(int vertices) : numVertices(vertices) {
    adjList.resize(vertices);
  }
  void addEdge(int v, int w) {
    adjList[v].push_back(w);
    adjList[w].push_back(v);
  }
  void BFS(int startVertex) {
    std::vector&lt;bool&gt; visited(numVertices, false);
    std::queue&lt;int&gt; q;
    visited[startVertex] = true;
    q.push(startVertex);
    while (!q.empty()) {
      int currentVertex = q.front();
      std::cout &lt;&lt; currentVertex &lt;&lt; " ";
      q.pop();
      for (int neighbor : adjList[currentVertex]) {
        if (!visited[neighbor]) {
          visited[neighbor] = true;
          q.push(neighbor);
        }
      }
    }
  }
private:
  int numVertices{0};
  std::vector&lt;std::vector&lt;int&gt;&gt; adjList;
};
int main() {
  Graph g(6);
  g.addEdge(0, 1);
  g.addEdge(0, 2);
  g.addEdge(1, 3);
  g.addEdge(1, 4);
  g.addEdge(2, 4);
  g.addEdge(3, 4);
  g.addEdge(3, 5);
  std::cout &lt;&lt; "BFS starting from vertex 0: ";
  g.BFS(0); // Output: 0 1 2 3 4 5
  return 0;
}</pre>			<p>Here’s the example output:</p>
			<pre class="console">
BFS starting from vertex 0: 0 1 2 3 4 5</pre>			<p>The following <a id="_idIndexMarker608"/>points explain the code:</p>
			<ul>
				<li>The <code>Graph</code> class uses an adjacency list (<code>adjList</code>) to represent the graph.</li>
				<li>The BFS traversal starts from a given vertex, marks it as visited, and then explores its neighbors. Neighbors are added to the queue and processed in the order they are encountered (FIFO order), ensuring a breadth-first traversal.</li>
				<li>As vertices are visited, they are marked in the visited vector to ensure they’re not processed multiple times.</li>
				<li>The BFS function uses the primary operations of <code>std::queue: push</code> to add vertices to the queue, <code>front</code> to inspect the next vertex to be processed, and <code>pop</code> to remove it.</li>
			</ul>
			<h2 id="_idParaDest-393"><a id="_idTextAnchor393"/>Best practices</h2>
			<p>Let’s explore <a id="_idIndexMarker609"/>the best practices of using <code>std::queue</code>:</p>
			<ul>
				<li><strong class="bold">Maintain a FIFO discipline</strong>: A queue is inherently designed for FIFO operations. Attempting to use it for other purposes, such as random access or stack operations with LIFO order, can lead to suboptimal designs and complexities.</li>
				<li><code>std::queue</code> does not expose direct iterators. If you need to iterate over the elements, consider if a queue is the proper data structure for your needs or if the underlying container should be accessed directly.</li>
				<li><code>front()</code> or <code>back()</code>, always check if the queue is empty using the <code>empty()</code> function. This prevents undefined behavior that could arise from trying to access elements in an empty queue.</li>
				<li><code>std::queue</code> is <code>std::deque</code>, but you can use others, such as <code>std::list</code>. Each container has its characteristics, trade-offs, and memory <a id="_idIndexMarker610"/>overhead. For example, while <code>std::list</code> offers efficient insertions and deletions, its memory overhead per element is higher than <code>std::deque</code>.</li>
				<li><code>std::mutex</code>, to avoid data races and inconsistencies. The operations on <code>std::queue</code> itself are not inherently thread-safe.</li>
				<li><code>std::vector</code> container (though this is rare for a queue). This can be a performance concern in real-time or performance-critical applications.</li>
				<li><code>emplace</code> to construct the element directly within the queue. This can lead to more efficient code as it avoids temporary object creation.</li>
				<li><code>std::vector</code>, <code>std::queue</code> doesn’t have capacity-related member functions. Without explicit knowledge or control, do not make assumptions about the underlying container’s size or capacity.</li>
				<li><code>std::deque</code> provides strong exception safety for its operations, ensuring data isn’t corrupted during exceptions.</li>
				<li><strong class="bold">Be cautious with type aliases</strong>: If you’re using type aliases or auto-typing, be sure you know the exact type of your queue, especially if you’re working with queues of different underlying containers in the same code base. This ensures you don’t mistakenly assume a different container type’s characteristics or performance trade-offs.</li>
			</ul>
			<h1 id="_idParaDest-394"><a id="_idTextAnchor394"/>std::priority_queue</h1>
			<h2 id="_idParaDest-395"><a id="_idTextAnchor395"/>Purpose and suitability</h2>
			<p><code>std::priority_queue</code> is an adapter container built on top of a random-access container type, primarily <code>std::vector</code>. Its core strength revolves around the following:</p>
			<ul>
				<li>Always having the highest priority element at the top</li>
				<li>Ensuring efficient insertion and retrieval of the top element</li>
			</ul>
			<p>It shines in the <a id="_idIndexMarker612"/>following scenarios:</p>
			<ul>
				<li>When priority-based access is required</li>
				<li>When insertions are random but access always targets the element of the highest importance</li>
			</ul>
			<p>In scenarios where order is not a concern or insertion order matters more than access priority, <code>std::priority_queue</code> might not be the ideal choice.</p>
			<h2 id="_idParaDest-396"><a id="_idTextAnchor396"/>Ideal use cases</h2>
			<p>The <a id="_idIndexMarker613"/>following are some of the ideal use cases for <code>std::priority_queue</code>:</p>
			<ul>
				<li><strong class="bold">Job scheduling</strong>: Assigning jobs based on their urgency or priority</li>
				<li><strong class="bold">Pathfinding algorithms</strong>: An example of such an algorithm is Dijkstra’s algorithm, where nodes with the shortest tentative distance are processed first</li>
				<li><strong class="bold">Simulation systems</strong>: For events that should be processed based on priority rather than sequence</li>
			</ul>
			<h2 id="_idParaDest-397"><a id="_idTextAnchor397"/>Performance</h2>
			<p>Since <code>std::priority_queue</code> is a container adaptor, its algorithmic performance<a id="_idIndexMarker614"/> depends on the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion</strong>: <em class="italic">O(log n)</em>, as the element is placed in its suitable position based on its priority</li>
				<li><strong class="bold">Deletion</strong>: <em class="italic">O(log n)</em> for the top element as the queue restructures itself</li>
				<li><strong class="bold">Access</strong>: <em class="italic">O(1)</em> to the top element</li>
				<li><strong class="bold">Memory overhead</strong>: Moderate, contingent on the underlying container</li>
			</ul>
			<p>Note that when using <code>std::vector</code> as the underlying container, additional memory overheads might appear when it resizes.</p>
			<h2 id="_idParaDest-398"><a id="_idTextAnchor398"/>Memory management</h2>
			<p>This is <a id="_idIndexMarker615"/>inherently dependent on the underlying container. With <code>std::vector</code>, memory reallocation might happen upon reaching capacity. Allocators can be utilized for customization.</p>
			<h2 id="_idParaDest-399"><a id="_idTextAnchor399"/>Thread safety</h2>
			<p>Concurrent <a id="_idIndexMarker616"/>access requires caution. Multiple reads are safe, but simultaneous reads or writes demand external synchronization mechanisms, such as mutexes.</p>
			<h2 id="_idParaDest-400"><a id="_idTextAnchor400"/>Extensions and variants</h2>
			<p>If you <a id="_idIndexMarker617"/>want a container that ensures sequence preservation, you might consider <code>std::queue</code>. If an associative container with key-value pairs and inherent ordering is needed, <code>std::map</code> or <code>std::set</code> might be more apt.</p>
			<h2 id="_idParaDest-401"><a id="_idTextAnchor401"/>Sorting and searching complexity</h2>
			<p>Sorting<a id="_idIndexMarker618"/> does not apply to <code>std::priority_queue</code>. Direct access to the top priority element for searching is <em class="italic">O(1)</em>. However, searching for other elements is not straightforward and isn’t the primary intent of this container.</p>
			<h2 id="_idParaDest-402"><a id="_idTextAnchor402"/>Special interface and member functions</h2>
			<p>Beyond the <a id="_idIndexMarker619"/>basics (<code>push</code>, <code>pop</code>, <code>top</code>), explore <a id="_idIndexMarker620"/>the following:</p>
			<ul>
				<li><code>emplace</code>: Directly constructs an element within the priority queue</li>
				<li><code>size</code>: Retrieves the number of elements</li>
				<li><code>swap</code>: Exchanges the contents of two priority queues</li>
			</ul>
			<h2 id="_idParaDest-403"><a id="_idTextAnchor403"/>Comparisons</h2>
			<p>In <a id="_idIndexMarker621"/>contrast to <code>std::queue</code>, which respects FIFO ordering,  <code>std::priority_queue</code>  always ensures the highest priority element is accessible. Compared with <code>std::set</code>, the latter allows ordered access to all elements, while the former focuses on priority.</p>
			<h2 id="_idParaDest-404"><a id="_idTextAnchor404"/>Interactions with algorithms</h2>
			<p>Given the <a id="_idIndexMarker622"/>lack of iterators, most STL algorithms can’t interact directly with <code>std::priority_queue</code>. However, it naturally aligns with user-defined algorithms that focus on the highest-priority elements, such as those that use <code>push()</code> and <code>pop()</code>.</p>
			<h2 id="_idParaDest-405"><a id="_idTextAnchor405"/>Exceptions</h2>
			<p>Throwing <a id="_idIndexMarker623"/>can occur during underlying container operations, such as memory allocation. Exception safety often aligns with that of the underlying container.</p>
			<h2 id="_idParaDest-406"><a id="_idTextAnchor406"/>Customization</h2>
			<p>Here are <a id="_idIndexMarker624"/>some customization options:</p>
			<ul>
				<li><strong class="bold">Allocators</strong>: Customize memory allocation using custom allocators</li>
				<li><strong class="bold">Comparators</strong>: Modify the priority logic using custom comparator functions, allowing for a custom definition of <em class="italic">priority</em></li>
			</ul>
			<h2 id="_idParaDest-407"><a id="_idTextAnchor407"/>Example</h2>
			<p><code>std::priority_queue</code> is <a id="_idIndexMarker625"/>often used in scenarios where elements need to be processed based on their priorities. One of the most common examples of using <code>std::priority_queue</code> is implementing Dijkstra’s shortest path algorithm for weighted graphs.</p>
			<p>The following code shows an example of implementing Dijkstra’s algorithm with <code>std::priority_queue</code>:</p>
			<pre class="source-code">
#include &lt;climits&gt;
#include &lt;iostream&gt;
#include &lt;list&gt;
#include &lt;queue&gt;
#include &lt;vector&gt;
class WeightedGraph {
public:
  WeightedGraph(int vertices) : numVertices(vertices) {
    adjList.resize(vertices);
  }
  void addEdge(int u, int v, int weight) {
    adjList[u].push_back({v, weight});
    adjList[v].push_back({u, weight});
  }
  void dijkstra(int startVertex) {
    std::priority_queue&lt;std::pair&lt;int, int&gt;,
                        std::vector&lt;std::pair&lt;int, int&gt;&gt;,
                        std::greater&lt;std::pair&lt;int, int&gt;&gt;&gt;
        pq;
    std::vector&lt;int&gt; distances(numVertices, INT_MAX);
    pq.push({0, startVertex});
    distances[startVertex] = 0;
    while (!pq.empty()) {
      int currentVertex = pq.top().second;
      pq.pop();
      for (auto &amp;neighbor : adjList[currentVertex]) {
        int vertex = neighbor.first;
        int weight = neighbor.second;
        if (distances[vertex] &gt;
            distances[currentVertex] + weight) {
          distances[vertex] =
              distances[currentVertex] + weight;
          pq.push({distances[vertex], vertex});
        }
      }
    }
    std::cout &lt;&lt; "Distances from vertex " &lt;&lt; startVertex
              &lt;&lt; ":\n";
    for (int i = 0; i &lt; numVertices; ++i) {
      std::cout &lt;&lt; i &lt;&lt; " -&gt; " &lt;&lt; distances[i] &lt;&lt; '\n';
    }
  }
private:
  int numVertices{0};
  std::vector&lt;std::list&lt;std::pair&lt;int, int&gt;&gt;&gt; adjList;
};
int main() {
  WeightedGraph g(5);
  g.addEdge(0, 1, 9);
  g.addEdge(0, 2, 6);
  g.addEdge(0, 3, 5);
  g.addEdge(1, 3, 2);
  g.addEdge(2, 4, 1);
  g.addEdge(3, 4, 2);
  g.dijkstra(0);
  return 0;
}</pre>			<p>Here’s the example output:</p>
			<pre class="console">
Distances from vertex 0:
0 -&gt; 0
1 -&gt; 7
2 -&gt; 6
3 -&gt; 5
4 -&gt; 7</pre>			<p>The following<a id="_idIndexMarker626"/> happens in this implementation:</p>
			<ul>
				<li>The <code>WeightedGraph</code> class uses an adjacency list to represent the graph, where each list element is a pair representing the neighboring vertex and the weight of the edge.</li>
				<li>The <code>dijkstra</code> function calculates the shortest distance from a given vertex to all other vertices in the graph.</li>
				<li><code>std::priority_queue</code> is used to select the next vertex with the shortest known distance to process.</li>
				<li>Distances<a id="_idIndexMarker627"/> to vertices are updated based on the currently processed vertex and its neighbors.</li>
				<li>As the algorithm progresses, <code>priority_queue</code> ensures that vertices are processed in increasing order of their known shortest distances.</li>
			</ul>
			<p>Using <code>std::priority_queue</code> provides an efficient way to always process the vertex with the smallest known distance in Dijkstra’s algorithm.</p>
			<h2 id="_idParaDest-408"><a id="_idTextAnchor408"/>Best practices</h2>
			<p>Let’s explore<a id="_idIndexMarker628"/> the best practices of using <code>std::priority_queue</code>:</p>
			<ul>
				<li><code>std::priority_queue</code> is to efficiently access the highest-priority element, not to provide ordered access to all its elements. Do not assume you can access the elements in a fully sorted order.</li>
				<li><strong class="bold">Custom priority rules</strong>: If the default comparison logic doesn’t meet your needs, always provide a custom comparator. This ensures that the queue maintains elements according to your specific priority rules.</li>
				<li><code>std::priority_queue</code> uses <code>std::vector</code> as its underlying container. While this is often suitable, switching to containers such as <code>std::deque</code> or <code>std::list</code> can influence performance. Choose the container that aligns with your specific requirements.</li>
				<li><strong class="bold">Check for emptiness</strong>: Before trying to access the top element or perform a pop operation, always verify that the queue isn’t empty. This prevents undefined behavior.</li>
				<li><strong class="bold">Avoid underlying container manipulation</strong>: Directly manipulating the underlying container can disrupt the integrity of the priority queue. Avoid this to ensure that the priority order remains consistent.</li>
				<li><code>emplace</code> method over <code>push</code>. This provides more efficient in-place construction and can save on unnecessary copies or moves.</li>
				<li><code>std::priority_queue</code> is not inherently thread-safe. If you need to access or modify it across multiple threads, ensure you use appropriate synchronization mechanisms.</li>
				<li><strong class="bold">Awareness of internal sorting</strong>: While it’s tempting to think of the priority queue as always holding a sorted list of elements, remember that it only ensures that the top-most element is the highest priority. The internal order of other elements is not guaranteed to be sorted.</li>
				<li><code>std::priority_queue</code> does not provide iterators to its elements. This design intentionally keeps users from inadvertently breaking the queue’s priority invariants.</li>
				<li><strong class="bold">Size considerations</strong>: Be mindful of the size and capacity of the underlying container, especially if you’re dealing with large datasets. Periodically checking and managing capacity can help in optimizing memory usage.</li>
			</ul>
			<p>By following these best practices, you can ensure that you use <code>std::priority_queue</code> in a manner that is efficient and consistent with its design intentions.</p>
			<h1 id="_idParaDest-409"><a id="_idTextAnchor409"/>std::flat_set</h1>
			<p><code>std::flat_set</code> is a<a id="_idIndexMarker630"/> sorted associative container that’s designed to store a collection of unique elements in a sorted order. What sets <code>std::flat_set</code> apart from other associative containers, such as <code>std::set</code>, is that it is implemented as a flat container, often based on a sorted <code>std::vector</code> container. This means that elements are stored contiguously in memory, leading to optimal memory usage and faster iteration times compared to traditional tree-based associative containers.</p>
			<p><code>std::flat_set</code> maintains <a id="_idIndexMarker631"/>its elements in a sorted order, allowing for efficient searching, insertion, and deletion operations, while also providing similar functionality and interface to other set-like containers in the C++ STL. It is especially useful when you need the advantages of both sorted storage and efficient memory management.</p>
			<h2 id="_idParaDest-410"><a id="_idTextAnchor410"/>Purpose and suitability</h2>
			<p><code>std::flat_set</code> is a container that represents an associative set stored in a sorted flat array. It merges the benefits of a <code>std::vector</code> container (such as cache-friendliness) with those of a <code>std::set</code> container (such as ordered storage).</p>
			<p>Use <code>std::flat_set</code> in the <a id="_idIndexMarker632"/>following scenarios:</p>
			<ul>
				<li>When you need ordered data with set properties</li>
				<li>When memory allocation overhead is a concern</li>
				<li>When you want to leverage cache locality advantages similar to those of <code>std::vector</code></li>
			</ul>
			<p>If you need to perform many insertions and deletions, other set types, such as <code>std::set</code>, may be more suitable due to their tree-based implementation.</p>
			<h2 id="_idParaDest-411"><a id="_idTextAnchor411"/>Ideal use cases</h2>
			<p>The following<a id="_idIndexMarker633"/> are some of the ideal use cases for <code>std::flat_set</code>:</p>
			<ul>
				<li><code>std::flat_set</code> container and sorting it can be efficient</li>
				<li><code>std::flat_set</code> container can be notably faster than tree-based sets for smaller sizes</li>
				<li><code>std::flat_set</code> can be advantageous</li>
			</ul>
			<h2 id="_idParaDest-412"><a id="_idTextAnchor412"/>Performance</h2>
			<p>Since <code>std::flat_set</code> is a container adaptor, its algorithmic performance depends on<a id="_idIndexMarker635"/> the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion</strong>: <em class="italic">O(n)</em> since shifting may be required</li>
				<li><strong class="bold">Deletion</strong>: <em class="italic">O(n)</em> for the same reasons</li>
				<li><strong class="bold">Access</strong>: <em class="italic">O(log n)</em> for lookup using binary search</li>
				<li><strong class="bold">Memory overhead</strong>: Less than tree-based structures due to fewer memory allocations</li>
			</ul>
			<p>The trade-off is the speed of lookups versus the cost of insertion and deletion, especially as the set grows.</p>
			<h2 id="_idParaDest-413"><a id="_idTextAnchor413"/>Memory management</h2>
			<p><code>std::flat_set</code> uses <a id="_idIndexMarker636"/>a contiguous block of memory (similar to <code>std::vector</code>). Reallocations occur when this block is exhausted. You can influence the allocation strategy using custom allocators.</p>
			<h2 id="_idParaDest-414"><a id="_idTextAnchor414"/>Thread safety</h2>
			<p>As with most<a id="_idIndexMarker637"/> STL containers, concurrent reads are safe, but writes or mixed operations necessitate external synchronization.</p>
			<h2 id="_idParaDest-415"><a id="_idTextAnchor415"/>Extensions and variants</h2>
			<p><code>std::flat_map</code> is a cousin of <code>std::flat_set</code> that stores key-value pairs in a flat <a id="_idIndexMarker638"/>structure. It offers similar performance characteristics and uses.</p>
			<h2 id="_idParaDest-416"><a id="_idTextAnchor416"/>Sorting and searching complexity</h2>
			<p>Its <a id="_idIndexMarker639"/>sorting and search complexity is characterized as follows:</p>
			<ul>
				<li><strong class="bold">Sorting</strong>: Inherent to the container and usually <em class="italic">O(n </em><em class="italic">log n)</em></li>
				<li><strong class="bold">Searching</strong>: <em class="italic">O(log n)</em> due to binary search on sorted data</li>
			</ul>
			<h2 id="_idParaDest-417"><a id="_idTextAnchor417"/>Special interface and member functions</h2>
			<p>Apart from<a id="_idIndexMarker640"/> the typical set functions (<code>insert</code>, <code>erase</code>, <code>find</code>), consider <a id="_idIndexMarker641"/>the following:</p>
			<ul>
				<li><code>reserve</code>: Allocates memory in anticipation of insertions</li>
				<li><code>capacity</code>: Returns the current allocation size</li>
			</ul>
			<h2 id="_idParaDest-418"><a id="_idTextAnchor418"/>Comparisons</h2>
			<p>In <a id="_idIndexMarker642"/>contrast to <code>std::set</code>, <code>std::flat_set</code> offers better cache locality but can become inefficient with frequent insertions/deletions in large datasets.</p>
			<h2 id="_idParaDest-419"><a id="_idTextAnchor419"/>Interactions with algorithms</h2>
			<p>STL algorithms<a id="_idIndexMarker643"/> that require random-access iterators, such as <code>std::sort()</code>, can be applied directly. However, remember that <code>std::flat_set</code> maintains its sorted order, so sorting manually is redundant.</p>
			<h2 id="_idParaDest-420"><a id="_idTextAnchor420"/>Exceptions</h2>
			<p>Misusing<a id="_idIndexMarker644"/> iterators or exceeding capacity can cause exceptions. Many operations provide strong exception safety, ensuring container consistency.</p>
			<h2 id="_idParaDest-421"><a id="_idTextAnchor421"/>Customization</h2>
			<p><code>std::flat_set</code> permits <a id="_idIndexMarker645"/>custom allocators, allowing for refined memory control. You can also supply custom comparators for specialized sorting.</p>
			<h2 id="_idParaDest-422"><a id="_idTextAnchor422"/>Best practices</h2>
			<p>Let’s explore<a id="_idIndexMarker646"/> the best practices of using <code>std::flat_set</code>:</p>
			<ul>
				<li><code>std::flat_set</code> is best suited for use cases where the set is built once and queried multiple times. If your application demands frequent insertions and deletions, a traditional tree-based <code>std::set</code> container might be more appropriate.</li>
				<li><code>std::flat_set</code> over other set implementations is its continuous memory layout, making it cache-friendly. This can lead to significant performance improvements for smaller datasets or when the data can fit into the cache.</li>
				<li><code>std::flat_set</code> containers and need to merge them, consider inserting all elements into a single container first, then sort and make the entire collection unique. This approach is often more efficient than merging sorted sets element by element.</li>
				<li><code>reserve</code> method is advisable if you have a reasonable estimate of the number of elements you’ll be inserting. This can minimize memory reallocations and enhance performance.</li>
				<li><code>std::set</code> container, which is tree-based and can handle such modifications more gracefully.</li>
				<li><code>std::flat_set</code> maintains its elements in<a id="_idIndexMarker647"/> a sorted order, it’s crucial to avoid manually sorting the container. Adding elements to a <code>std::flat_set</code> container will keep them in order based on the provided comparator.</li>
				<li><code>std::flat_set</code> offers member functions such as <code>find</code> for efficient searching, they are optimized for its internal structure. Using these member functions is generally more efficient than applying generic algorithms. If you ever need to use algorithms, ensure they are designed for sorted sequences, such as <code>std::lower_bound</code> or <code>std::upper_bound</code>.</li>
				<li><code>std::flat_set</code> is <code>std::less</code>. However, if your data requires custom sorting logic, ensure you provide a custom comparator during the set’s construction. Remember, this comparator should give a strict weak ordering to maintain the set’s properties.</li>
				<li><code>std::flat_set</code> provides. If your use case has such patterns, evaluate if other containers might be more suitable.</li>
				<li><code>std::set</code>, modifying elements (for example, through iterators) in a <code>std::flat_set</code> container without ensuring the order can lead to undefined behavior. Always confirm that the sorted order is maintained post modifications.</li>
				<li><code>std::flat_set</code> works well with algorithms that have been optimized for random-access <a id="_idIndexMarker648"/>iterators. However, be cautious with algorithms that modify the order or content as they can violate the set’s properties.</li>
			</ul>
			<h1 id="_idParaDest-423"><a id="_idTextAnchor423"/>std::flat_map</h1>
			<p><code>std::flat_map</code> is<a id="_idIndexMarker649"/> a sorted associative container that combines the features of a map and a flat container. Similar to <code>std::map</code>, it allows you to store key-value pairs, and the keys are unique and ordered. However, unlike <code>std::map</code>, which is typically implemented as a balanced binary search tree, <code>std::flat_map</code> is implemented as a flat container, often based on a sorted <code>std::vector</code> container. This means that <code>std::flat_map</code> offers efficient memory usage and faster iteration times than traditional tree-based associative containers such as <code>std::map</code>. Elements in a <code>std::flat_map</code> container are stored contiguously in memory, which can lead to better cache locality and improved performance for certain use cases.</p>
			<p><code>std::flat_map</code> provides functionality and interface similar to <code>std::map</code>, allowing you to perform operations such as insertion, deletion, and searching while maintaining the elements in a sorted order. It’s beneficial when you need both the advantages of sorted storage and the benefits of a flat container.</p>
			<h2 id="_idParaDest-424"><a id="_idTextAnchor424"/>Purpose and suitability</h2>
			<p><code>std::flat_map</code> is a container that pairs together keys and values, functioning as an associative array. The <a id="_idIndexMarker650"/>following reasons set it apart from other map containers:</p>
			<ul>
				<li>It uses a vector-like structure, granting advantages in cache locality.</li>
				<li>This contiguous memory layout fosters improved lookup times in some scenarios.</li>
			</ul>
			<p>Its niche lies <a id="_idIndexMarker651"/>in the following scenarios:</p>
			<ul>
				<li>When the map is mainly built once and then often queried</li>
				<li>When iteration speed and cache locality take precedence over insertion/deletion speed</li>
				<li>When a <a id="_idIndexMarker652"/>sorted map representation is essential</li>
			</ul>
			<p>If you foresee frequent modifications post-initialization, consider using <code>std::map</code>.</p>
			<h2 id="_idParaDest-425"><a id="_idTextAnchor425"/>Ideal use cases</h2>
			<p>The<a id="_idIndexMarker653"/> following are some of the ideal use cases for <code>std::flat_map</code>:</p>
			<ul>
				<li><strong class="bold">Configuration data</strong>: Storing configuration key-value pairs loaded once at startup but queried frequently during application runtime</li>
				<li><strong class="bold">Spatial indexing</strong>: In graphics or game development, quick iteration and retrieval are more critical than frequent modifications</li>
				<li><strong class="bold">Data serialization</strong>: For datasets that require sorting and occasional lookups but aren’t modified regularly</li>
			</ul>
			<h2 id="_idParaDest-426"><a id="_idTextAnchor426"/>Performance</h2>
			<ul>
				<li><strong class="bold">Insertion</strong>: <em class="italic">O(n)</em> due to<a id="_idIndexMarker654"/> the underlying vector structure</li>
				<li><strong class="bold">Deletion</strong>: <em class="italic">O(n)</em> because elements may need to be shifted</li>
				<li><strong class="bold">Access</strong>: <em class="italic">O(log n)</em> due to binary search on the sorted array</li>
				<li><strong class="bold">Memory overhead</strong>: Generally, this is low, but it can escalate if the reserved capacity isn’t utilized efficiently</li>
			</ul>
			<h2 id="_idParaDest-427"><a id="_idTextAnchor427"/>Memory management</h2>
			<p><code>std::flat_map</code>, like <code>std::vector</code>, may reallocate when its capacity is surpassed. It’s <a id="_idIndexMarker655"/>wise to employ <code>reserve</code> if you can predict the eventual size. Allocators can provide control over memory management behaviors.</p>
			<h2 id="_idParaDest-428"><a id="_idTextAnchor428"/>Thread safety</h2>
			<p>While concurrent <a id="_idIndexMarker656"/>reads are safe, writes or a mixture of both necessitate external synchronization – for example, using mutexes.</p>
			<h2 id="_idParaDest-429"><a id="_idTextAnchor429"/>Extensions and variants</h2>
			<p>For <a id="_idIndexMarker657"/>unordered associative containers, the STL offers <code>std::unordered_map</code>. If a balanced tree structure with ordered keys is preferred, then <code>std::map</code> is your go-to.</p>
			<h2 id="_idParaDest-430"><a id="_idTextAnchor430"/>Sorting and searching complexity</h2>
			<p>Its <a id="_idIndexMarker658"/>sorting and search complexity is characterized as follows:</p>
			<ul>
				<li><strong class="bold">Sorting</strong>: Inherent to its structure, it always maintains order</li>
				<li><strong class="bold">Searching</strong>: <em class="italic">O(log n)</em> due to binary search</li>
			</ul>
			<h2 id="_idParaDest-431"><a id="_idTextAnchor431"/>Interface and member functions</h2>
			<p>Common<a id="_idIndexMarker659"/> members such as <code>insert</code>, <code>find</code>, and <code>erase</code> are present. However, you <a id="_idIndexMarker660"/>should also explore the following gems:</p>
			<ul>
				<li><code>emplace</code>: Directly constructs elements in place</li>
				<li><code>lower_bound</code> and <code>upper_bound</code>: These provide efficient range searches</li>
				<li><code>at</code>: Provides direct access to values by key with bounds-checking</li>
			</ul>
			<h2 id="_idParaDest-432"><a id="_idTextAnchor432"/>Comparisons</h2>
			<p><code>std::flat_map</code> excels<a id="_idIndexMarker661"/> in iteration and lookup performance, especially for smaller datasets. However, if frequent modifications dominate your use case, you might lean toward <code>std::map</code>.</p>
			<h2 id="_idParaDest-433"><a id="_idTextAnchor433"/>Interactions with algorithms</h2>
			<p>Due to <a id="_idIndexMarker662"/>its random-access nature, <code>std::flat_map</code> pairs well with STL algorithms that thrive on such iterators. However, any algorithm that disrupts the key order should be approached cautiously.</p>
			<h2 id="_idParaDest-434"><a id="_idTextAnchor434"/>Exceptions</h2>
			<p>Exceeding <a id="_idIndexMarker663"/>capacity or accessing out-of-bounds keys might trigger exceptions. Many operations offer strong exception safety, preserving map states if exceptions arise.</p>
			<h2 id="_idParaDest-435"><a id="_idTextAnchor435"/>Customization</h2>
			<p><code>std::flat_map</code> allows<a id="_idIndexMarker664"/> for custom allocators, and you can specify a custom comparator during construction to dictate the key order.</p>
			<h2 id="_idParaDest-436"><a id="_idTextAnchor436"/>Best practices</h2>
			<p>Let’s explore<a id="_idIndexMarker665"/> the best practices of using <code>std::flat_map:</code></p>
			<ul>
				<li><code>std::flat_map</code> for frequent insertions and deletions due to the high cost. For such cases, consider alternatives, such as <code>std::map</code>.</li>
				<li><strong class="bold">Key modifications</strong>: Do not alter keys directly using iterators. This disrupts the sorted order of the map. If keys need to be modified, consider erasing the old key-value pair and inserting a new one to ensure order maintenance.</li>
				<li><code>reserve()</code> to reduce the frequency of memory reallocations, enhancing performance.</li>
				<li><code>emplace</code> to construct key-value pairs in place efficiently, maximizing performance and avoiding unnecessary temporary object creation.</li>
				<li><code>std::map</code> may offer better performance profiles in such scenarios.</li>
				<li><strong class="bold">Concurrency</strong>: Ensure thread safety during multi-threaded access. Concurrent reads are generally safe, but writing or mixed read-write operations require external synchronization, such as mutexes.</li>
				<li><code>std::flat_map</code>. It offers superior cache locality and efficient lookups, especially when the map is mainly queried post-initialization.</li>
				<li><code>std::flat_map</code>, be cautious of operations that may disrupt this order. Always validate the order after any modifications to ensure the container’s integrity.</li>
				<li><code>lower_bound </code>and <code>upper_bound</code> for efficient range-based queries, leveraging the container’s sorted characteristics.</li>
				<li><code>std::less</code>) works for many scenarios, <code>std::flat_map</code> allows you to specify custom comparators during instantiation, tailoring the key order to specific needs.</li>
			</ul>
			<h1 id="_idParaDest-437"><a id="_idTextAnchor437"/>std::flat_multiset</h1>
			<p><code>std::flat_multiset</code> is a<a id="_idIndexMarker667"/> container that was introduced in the C++ STL that’s designed to store elements in a sorted order. Unlike <code>std::multiset</code>, which is typically implemented as a red-black tree, <code>std::flat_multiset</code> stores its elements in a contiguous memory block, similar to a <code>std::vector</code> container. This design choice offers improved cache performance due to data locality, making it efficient for scenarios where the container is not frequently modified after being filled.</p>
			<h2 id="_idParaDest-438"><a id="_idTextAnchor438"/>Purpose and suitability</h2>
			<p><code>Std::flat_multiset</code> is a container that stores elements in a sorted array, similar to <code>std::flat_set</code>, but allows <a id="_idIndexMarker668"/>for multiple occurrences of equivalent elements.</p>
			<p>This container offers the following:</p>
			<ul>
				<li>Efficient lookup times thanks to its sorted nature</li>
				<li>Improved cache locality and predictability in memory usage</li>
			</ul>
			<p>It’s especially<a id="_idIndexMarker669"/> suitable in the following scenarios:</p>
			<ul>
				<li>When duplicates are permissible and you need sorted access</li>
				<li>When cache locality is prioritized</li>
				<li>When the dataset’s size is relatively stable post-initialization</li>
			</ul>
			<p>However, other containers might be more appropriate when frequent insertions or deletions become the norm.</p>
			<h2 id="_idParaDest-439"><a id="_idTextAnchor439"/>Ideal use cases</h2>
			<p>The following<a id="_idIndexMarker670"/> are some of the ideal use cases for <code>std::flat_multiset</code>:</p>
			<ul>
				<li><strong class="bold">Historical records</strong>: Storing repeated events in chronological order, such as transaction logs</li>
				<li><strong class="bold">Frequency counter</strong>: Counting occurrences of elements when order and access speed are vital</li>
				<li><strong class="bold">Sorted buffers</strong>: Temporary storage during processing, where the order is crucial, and duplicates are expected</li>
			</ul>
			<h2 id="_idParaDest-440"><a id="_idTextAnchor440"/>Performance</h2>
			<p>Since <code>std::flat_multiset</code> is a<a id="_idIndexMarker671"/> container adaptor, its algorithmic performance depends on the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion</strong>: <em class="italic">O(n)</em> since maintaining order may necessitate element shifting</li>
				<li><strong class="bold">Deletion</strong>: <em class="italic">O(n)</em> due to the possibility of shifting to fill gaps</li>
				<li><strong class="bold">Access</strong>: <em class="italic">O(log n)</em> for lookups owing to binary search</li>
				<li><code>std::vector</code>, but the lack of tree structures minimizes memory overhead</li>
			</ul>
			<h2 id="_idParaDest-441"><a id="_idTextAnchor441"/>Memory management</h2>
			<p><code>std::flat_multiset</code> manages <a id="_idIndexMarker672"/>memory in chunks. Pre-allocating memory using <code>reserve()</code> can prevent frequent reallocations. Custom allocators can further modify allocation behavior.</p>
			<h2 id="_idParaDest-442"><a id="_idTextAnchor442"/>Thread safety</h2>
			<p>Simultaneous<a id="_idIndexMarker673"/> reads are safe. However, concurrent modifications or simultaneous reads and writes need external synchronization mechanisms.</p>
			<h2 id="_idParaDest-443"><a id="_idTextAnchor443"/>Extensions and variants</h2>
			<p>While <code>std::flat_multiset</code> stores <a id="_idIndexMarker674"/>multiple instances of an element, <code>std::flat_set</code> is its unique element counterpart. For hash-based approaches, you might want to look at <code>std::unordered_multiset</code>.</p>
			<h2 id="_idParaDest-444"><a id="_idTextAnchor444"/>Sorting and searching complexity</h2>
			<p>Its sorting <a id="_idIndexMarker675"/>and search complexity is characterized as follows:</p>
			<ul>
				<li><code>std::flat_multiset</code> maintains order</li>
				<li><strong class="bold">Searching</strong>: Efficient <em class="italic">O(log n)</em> due to binary searching</li>
			</ul>
			<h2 id="_idParaDest-445"><a id="_idTextAnchor445"/>Special interface and member functions</h2>
			<p><code>std::flat_multiset</code> offers much the same interface as its underlying type. Here are<a id="_idIndexMarker676"/> some especially <a id="_idIndexMarker677"/>useful functions:</p>
			<ul>
				<li><code>equal_range</code>: Returns range of equivalent elements</li>
				<li><code>count</code>: Efficiently counts the occurrences of an element</li>
				<li><code>emplace</code>: Constructs elements directly in place</li>
			</ul>
			<h2 id="_idParaDest-446"><a id="_idTextAnchor446"/>Comparisons</h2>
			<p>Compared to <code>std::multiset</code>, <code>std::flat_multiset</code> offers a better cache locality <a id="_idIndexMarker678"/>but may suffer from frequent modifications. It excels in read-heavy scenarios post-initialization.</p>
			<h2 id="_idParaDest-447"><a id="_idTextAnchor447"/>Interactions with algorithms</h2>
			<p>Being <a id="_idIndexMarker679"/>sorted, <code>std::flat_multiset</code> resonates well with binary search-based algorithms. However, those that shuffle or reorder might not be ideal.</p>
			<h2 id="_idParaDest-448"><a id="_idTextAnchor448"/>Exceptions</h2>
			<p>Attempting to <a id="_idIndexMarker680"/>access out-of-bounds or mismanaging memory can lead to exceptions. Generally, operations are exception-safe, ensuring the container remains consistent.</p>
			<h2 id="_idParaDest-449"><a id="_idTextAnchor449"/>Customization</h2>
			<p><code>std::flat_multiset</code> supports<a id="_idIndexMarker681"/> custom allocators, allowing for memory allocation fine-tuning. Moreover, custom comparators can adjust the sorting behavior.</p>
			<h2 id="_idParaDest-450"><a id="_idTextAnchor450"/>Best practices</h2>
			<p>Let’s explore <a id="_idIndexMarker682"/>the best practices of using <code>std::flat_multiset</code>:</p>
			<ul>
				<li><code>std::flat_multiset</code> primarily in scenarios where the set size stabilizes post-initialization. Frequent insertions or deletions will lead to inefficiencies due to the need to maintain a sorted order, often leading to element shifting.</li>
				<li><code>std::multiset</code>, the iterators for <code>std::flat_multiset</code> can become invalidated post-modification, especially those that change the container’s size. Always reassess iterator validity after altering the container.</li>
				<li><code>std::flat_multiset</code> container, employ <code>reserve()</code> to allocate sufficient memory upfront. This prevents recurrent and costly reallocations. While reserving space for anticipated growth is important, over-reservation can lead to unnecessary memory consumption. Aim for a balance between the two.</li>
				<li><code>std::flat_multiset</code> is more suitable than <code>std::flat_set</code>. It retains all instances of an element, whereas the latter only keeps unique entries.</li>
				<li><code>std::list</code> or <code>std::multiset</code> might offer more efficiency for such operations.</li>
				<li><code>emplace()</code> to construct elements directly within the set. This can eliminate unnecessary temporary constructions and copies, particularly for complex data types.</li>
				<li><code>std::flat_multiset</code> is safe. Writing operations, whether they’re insertions, deletions, or modifications, require synchronization in a multi-threaded<a id="_idIndexMarker683"/> environment to ensure data integrity and prevent data races.</li>
				<li><code>std::flat_multiset</code> pairs well with STL algorithms that benefit from sorted datasets, such as <code>std::lower_bound</code> or <code>std::upper_bound</code>. However, remember that algorithms that alter the order or introduce elements might invalidate this inherent sorting.</li>
				<li><code>std::flat_multiset</code> to control its ordering behavior.</li>
				<li><strong class="bold">Exception safety</strong>: Be aware of operations that can throw exceptions, such as memory allocation failures. Ensuring exception-safe code will prevent data inconsistencies and potential memory leaks.</li>
			</ul>
			<h1 id="_idParaDest-451"><a id="_idTextAnchor451"/>std::flat_multimap</h1>
			<p><code>std::flat_multimap</code> is a <a id="_idIndexMarker684"/>container adapter that combines the characteristics of associative and sequence containers. It stores key-value pairs, similar to <code>std::multimap</code>, but with a significant distinction: the elements are stored in a flat, contiguous memory space, akin to a <code>std::vector</code> container. This storage approach enhances cache performance due to improved data locality, which is especially beneficial for read-intensive operations.</p>
			<h2 id="_idParaDest-452"><a id="_idTextAnchor452"/>Purpose and suitability</h2>
			<p><code>Std::flat_multimap</code> is a container <a id="_idIndexMarker685"/>within the STL that’s optimized for fast associative lookups. Its distinguishing features include the following:</p>
			<ul>
				<li>Storage in a sorted contiguous block of memory, akin to <code>std::vector</code></li>
				<li>Allows multiple key-value pairs with identical keys</li>
			</ul>
			<p>It is most suitable in the <a id="_idIndexMarker686"/>following scenarios:</p>
			<ul>
				<li>When cache locality and associative lookups are both desired</li>
				<li>When the dataset stabilizes post-initialization since it’s not optimized for frequent insertions or deletions</li>
			</ul>
			<p>Pick <code>std::flat_multimap</code> over other containers when the advantages of flat storage and allowance for key duplicity align with your use case.</p>
			<h2 id="_idParaDest-453"><a id="_idTextAnchor453"/>Ideal use cases</h2>
			<p>The following are some of the<a id="_idIndexMarker687"/> ideal use cases for <code>std::flat_multimap</code>:</p>
			<ul>
				<li><strong class="bold">Web browser history</strong>: Storing URLs with timestamps. Multiple entries (timestamps) can exist for the same URL (key).</li>
				<li><strong class="bold">Word frequency counter</strong>: When words in a piece of text can have multiple meanings and you want to store each meaning alongside its count.</li>
				<li><strong class="bold">Event scheduler</strong>: To maintain events (values) that occur at specific times (keys), where multiple events might happen at the same timestamp.</li>
			</ul>
			<h2 id="_idParaDest-454"><a id="_idTextAnchor454"/>Performance</h2>
			<p>Since <code>std::flat_multimap</code> is a<a id="_idIndexMarker688"/> container adaptor, its algorithmic performance depends on the underlying container implementation:</p>
			<ul>
				<li><strong class="bold">Insertion</strong>: <em class="italic">O(n)</em> due to potential element shifting</li>
				<li><strong class="bold">Deletion</strong>: <em class="italic">O(n)</em> due to maintaining order</li>
				<li><strong class="bold">Access</strong>: <em class="italic">O(log n)</em> due to binary search on a sorted array</li>
				<li><strong class="bold">Memory overhead</strong>: Relatively low with advantages in cache locality</li>
			</ul>
			<p>The trade-off lies in enjoying faster lookups at the cost of slower insertions and deletions.</p>
			<h2 id="_idParaDest-455"><a id="_idTextAnchor455"/>Memory management</h2>
			<p><code>std::flat_multimap</code> manages<a id="_idIndexMarker689"/> memory akin to <code>std::vector</code>. The <code>reserve()</code> function can anticipate and allocate memory for growth. Custom allocators can further tailor memory behaviors.</p>
			<h2 id="_idParaDest-456"><a id="_idTextAnchor456"/>Thread safety</h2>
			<p>Concurrent reads <a id="_idIndexMarker690"/>are safe. However, writes or mixed read-writes require synchronization mechanisms such as mutexes.</p>
			<h2 id="_idParaDest-457"><a id="_idTextAnchor457"/>Extensions and variants</h2>
			<p>For a container <a id="_idIndexMarker691"/>without duplicate key allowance, there’s <code>std::flat_map</code>. For unsorted and bucketed storage, you might want to consider <code>std::unordered_multimap</code>.</p>
			<h2 id="_idParaDest-458"><a id="_idTextAnchor458"/>Sorting and searching complexity</h2>
			<p>Its<a id="_idIndexMarker692"/> sorting and search complexity is characterized as follows:</p>
			<ul>
				<li><strong class="bold">Sorting</strong>: Inherent to the container and managed internally</li>
				<li><strong class="bold">Searching</strong>: <em class="italic">O(log n)</em> due to binary search</li>
			</ul>
			<h2 id="_idParaDest-459"><a id="_idTextAnchor459"/>Interface and member functions</h2>
			<p>Apart <a id="_idIndexMarker693"/>from the<a id="_idIndexMarker694"/> standard functions (<code>insert</code>, <code>erase</code>, <code>find</code>), explore the following:</p>
			<ul>
				<li><code>equal_range</code>: Returns bounds of all entries matching a key</li>
				<li><code>emplace</code>: Directly constructs key-value pairs inside the map</li>
			</ul>
			<h2 id="_idParaDest-460"><a id="_idTextAnchor460"/>Comparisons</h2>
			<p>Compared to <code>std::multimap</code>, <code>std::flat_multimap</code> offers better cache locality but <a id="_idIndexMarker695"/>slower modifications. When juxtaposed with <code>std::unordered_multimap</code>, it trades faster lookups for inherent sorting.</p>
			<h2 id="_idParaDest-461"><a id="_idTextAnchor461"/>Interactions with algorithms</h2>
			<p><code>std::flat_multimap</code> is beneficial <a id="_idIndexMarker696"/>with algorithms such as <code>std::lower_bound</code> and <code>std::upper_bound</code> due to its sorted nature. However, be cautious with algorithms that modify order or introduce elements.</p>
			<h2 id="_idParaDest-462"><a id="_idTextAnchor462"/>Exceptions</h2>
			<p>Key insertions<a id="_idIndexMarker697"/> or lookups won’t throw, but be wary of memory allocation failures, especially during insertions, which can cause exceptions. Exception safety is prioritized, with many operations offering strong guarantees.</p>
			<h2 id="_idParaDest-463"><a id="_idTextAnchor463"/>Customization</h2>
			<p>While<a id="_idIndexMarker698"/> custom allocators are permitted, <code>std::flat_multimap</code> relies on its internal sorting mechanism. Thus, custom comparators are essential to define key order.</p>
			<h2 id="_idParaDest-464"><a id="_idTextAnchor464"/>Best practices</h2>
			<p>Let’s explore<a id="_idIndexMarker699"/> the best practices of using <code>std::flat_multimap</code>:</p>
			<ul>
				<li><code>std::flat_multimap</code> when the use case involves continuous or frequent insertions and deletions. Due to the container’s linear nature, such operations can be costly.</li>
				<li><code>std::flat_multimap</code> only supports input, output, forward, and bidirectional iterators. It does not provide random-access iterators.</li>
				<li><strong class="bold">Key data type considerations</strong>: Prefer concise and lightweight data types for keys. Using large custom data types can exacerbate the costs of element shifting<a id="_idIndexMarker700"/> during insertions and deletions.</li>
				<li><code>std::flat_multimap</code>, leverage the <code>reserve()</code> function. Pre-allocating memory can mitigate expensive reallocations and copying.</li>
				<li><code>emplace</code> method for in-situ construction of key-value pairs. This can be more efficient than creating and inserting an entry separately.</li>
				<li><code>std::multimap</code> or <code>std::unordered_multimap</code>. These containers might offer better performance for such scenarios.</li>
				<li><code>std::flat_multimap</code>. Concurrent reads are typically safe but write operations can lead to race conditions without proper synchronization.</li>
				<li><code>std::flat_multimap</code> retains its internal ordering based on your specific requirements.</li>
				<li><code>std::flat_multimap</code>, binary search algorithms, such as <code>std::lower_bound  </code>and <code>std::upper_bound</code>, can be used efficiently for operations such as range queries or finding specific keys.</li>
				<li><code>std::flat_multimap</code> offer strong exception guarantees, ensuring that the container remains consistent, even if an operation throws an exception.</li>
				<li><code>std::flat_multimap</code>, use member functions such as <code>equal_range</code> to handle and process all entries associated with a specific key.</li>
				<li><code>std::flat_multimap</code> using member functions such as <code>capacity()</code>  and <code>size()</code>. If excess reserved space isn’t being utilized, consider using <code>shrink_to_fit()</code> to release this memory.</li>
			</ul>
		</div>
	</body></html>