<html><head></head><body>
		<div><h1 id="_idParaDest-292"><em class="italic"><a id="_idTextAnchor291"/>Chapter 9</em>: Concurrency and Parallelism</h1>
			<p>Concurrency and parallelism refer to the ability to run code in separate <em class="italic">threads of execution</em>.</p>
			<p>More specifically, <em class="italic">concurrency</em> is the ability to run threads<a id="_idIndexMarker787"/> in the background, and <em class="italic">parallelism</em> is the ability to run threads<a id="_idIndexMarker788"/> simultaneously in separate cores of a processor. The run-time library, along with the host operating system, will choose between concurrent and parallel execution models for a given thread on a given hardware environment.</p>
			<p>In a modern multi-tasking operating system, the <code>main()</code> function already represents a thread of execution. When a new thread is started, it's said to be <em class="italic">spawned</em> by an existing thread. A group<a id="_idIndexMarker789"/> of threads may be called a <em class="italic">swarm</em>.</p>
			<p>In the C++ standard library, the <code>std::thread</code> class provides the basic unit of threaded execution. Other classes build upon <code>thread</code> to provide <em class="italic">locks</em>, <em class="italic">mutexes</em>, and other concurrency patterns. Depending on system architecture, execution threads may run concurrently on one processor, or in parallel on separate cores.</p>
			<p>In this chapter, we will cover these tools and more in the following recipes:</p>
			<ul>
				<li>Sleep for a specific amount of time</li>
				<li>Use <code>std::thread</code> for concurrency</li>
				<li>Use <code>std::async</code> for concurrency</li>
				<li>Run STL algorithms in parallel with execution policies</li>
				<li>Share data safely with mutex and locks</li>
				<li>Share flags and values with <code>std::atomic</code></li>
				<li>Initialize threads with <code>std::call_once</code></li>
				<li>Use <code>std::condition_variable</code> to resolve the producer-consumer problem</li>
				<li>Implement multiple producers and consumers</li>
			</ul>
			<h1 id="_idParaDest-293"><a id="_idTextAnchor292"/>Technical requirements</h1>
			<p>You can find the code files for this chapter on GitHub at <a href="https://github.com/PacktPublishing/CPP-20-STL-Cookbook/tree/main/chap09">https://github.com/PacktPublishing/CPP-20-STL-Cookbook/tree/main/chap09</a>.</p>
			<h1 id="_idParaDest-294"><a id="_idTextAnchor293"/>Sleep for a specific amount of time</h1>
			<p>The <code>&lt;thread&gt;</code> header provides two functions for putting a thread to sleep, <code>sleep_for()</code> and <code>sleep_until()</code>. Both functions are in the <code>std::this_thread</code> namespace.</p>
			<p>This recipe explores<a id="_idIndexMarker790"/> the use of these functions, as we will be using<a id="_idIndexMarker791"/> them later in this chapter.</p>
			<h2 id="_idParaDest-295"><a id="_idTextAnchor294"/>How to do it…</h2>
			<p>Let's look at how to use the <code>sleep_for()</code> and <code>sleep_until()</code> functions:</p>
			<ul>
				<li>The sleep-related functions are in the <code>std::this_thread</code> namespace. Because it has just a few symbols, we'll go ahead and issue <code>using</code> directives for <code>std::this_thread</code> and <code>std::chrono_literals</code>:<pre>using namespace std::this_thread;
using namespace std::chrono_literals;</pre></li>
			</ul>
			<p>The <code>chrono_literals</code> namespace has symbols for representing durations, such as <code>1s</code> for one second, or <code>100ms</code> for 100 milliseconds.</p>
			<ul>
				<li>In <code>main()</code>, we'll mark a point in time with <code>steady_clock::now()</code>, so we can time our test:<pre>int main() {
    auto t1 = <strong class="bold">steady_clock::now()</strong>;
    cout &lt;&lt; "sleep for 1.3 seconds\n";
    <strong class="bold">sleep_for(1s + 300ms);</strong>
    cout &lt;&lt; "sleep for 2 seconds\n";
    <strong class="bold">sleep_until(steady_clock::now() + 2s);</strong>
    duration&lt;double&gt; dur1 = <strong class="bold">steady_clock::now() - t1</strong>;
    cout &lt;&lt; format("total duration: {:.5}s\n", 
      dur1.count());
}</pre></li>
			</ul>
			<p>The <code>sleep_for()</code> function<a id="_idIndexMarker792"/> takes a <code>duration</code> object to specify<a id="_idIndexMarker793"/> the amount of time to sleep. The argument <code>(1s + 300ms)</code> uses <code>chrono_literal</code> operators to return a <code>duration</code> object representing 1.3 seconds.</p>
			<p>The <code>sleep_until()</code> function takes a <code>time_point</code> object to specify a specific time to resume from sleep. In this case, the <code>chrono_literal</code> operators are used to modify the <code>time_point</code> object returned from <code>steady_clock::now()</code>.</p>
			<p>This is our output:</p>
			<pre><strong class="bold">sleep for 1.3 seconds</strong>
<strong class="bold">sleep for 2 seconds</strong>
<strong class="bold">total duration: 3.3005s</strong></pre>
			<h2 id="_idParaDest-296"><a id="_idTextAnchor295"/>How it works…</h2>
			<p>The <code>sleep_for(duration)</code> and <code>sleep_until(time_point)</code> functions suspend execution of the current thread for the specified <code>duration</code>, or until the <code>time_point</code> is reached.</p>
			<p>The <code>sleep_for()</code> function will use the <code>steady_clock</code> implementation, if supported. Otherwise, the duration may be subject to time adjustments. Both functions may block for longer due to scheduling or resource delays.</p>
			<h2 id="_idParaDest-297"><a id="_idTextAnchor296"/>There's more…</h2>
			<p>Some systems support<a id="_idIndexMarker794"/> a POSIX function, <code>sleep()</code>, which suspends execution for the number of seconds specified:</p>
			<pre>unsigned int sleep(unsigned int seconds);</pre>
			<p>The <code>sleep()</code> function is part of the POSIX standard and is not part of the C++ standard.</p>
			<h1 id="_idParaDest-298"><a id="_idTextAnchor297"/>Use std::thread for concurrency</h1>
			<p>A <em class="italic">thread</em> is a unit of<a id="_idIndexMarker795"/> concurrency. The <code>main()</code> function may be thought of as the <em class="italic">main thread of execution</em>. Within the context<a id="_idIndexMarker796"/> of the operating<a id="_idIndexMarker797"/> system, the main thread runs concurrently with other threads owned by other processes.</p>
			<p>The <code>std::thread</code> class is the root of concurrency in the STL. All other concurrency features are built on the foundation of the <code>thread</code> class.</p>
			<p>In this recipe, we will examine the basics of <code>std::thread</code> and how <code>join()</code> and <code>detach()</code> determine its execution context.</p>
			<h2 id="_idParaDest-299"><a id="_idTextAnchor298"/>How to do it…</h2>
			<p>In this recipe, we create some <code>std::thread</code> objects and experiment with their execution options.</p>
			<ul>
				<li>We start with a convenience function for sleeping a thread, in milliseconds:<pre>void <strong class="bold">sleepms</strong>(const unsigned <strong class="bold">ms</strong>) {
    using std::chrono::milliseconds;
    std::this_thread::<strong class="bold">sleep_for</strong>(milliseconds(<strong class="bold">ms</strong>));
}</pre></li>
			</ul>
			<p>The <code>sleep_for()</code> function takes a <code>duration</code> object and blocks execution of the current thread for the specified duration. This <code>sleepms()</code> function serves as a convenience wrapper that takes an <code>unsigned</code> value for the number of milliseconds to sleep.</p>
			<ul>
				<li>Now, we need a function<a id="_idIndexMarker798"/> for our thread. This function sleeps<a id="_idIndexMarker799"/> for a variable number of milliseconds, based on an integer parameter:<pre>void <strong class="bold">fthread</strong>(const int <strong class="bold">n</strong>) {
    cout &lt;&lt; format("This is t{}\n", n);
    
    for(size_t i{}; i &lt; 5; ++i) {
        <strong class="bold">sleepms</strong>(100 * <strong class="bold">n</strong>);
        cout &lt;&lt; format("t{}: {}\n", n, i + 1);
    }
    cout &lt;&lt; format("Finishing t{}\n", n);
}</pre></li>
			</ul>
			<p><code>fthread()</code> calls <code>sleepms()</code> five times, sleeping each time for <code>100 * n</code> milliseconds.</p>
			<ul>
				<li>We can run this in a separate thread with <code>std::thread</code> from <code>main()</code>:<pre>int main() {
    <strong class="bold">thread</strong> t1(<strong class="bold">fthread</strong>, 1);
    cout &lt;&lt; "end of main()\n";
}</pre></li>
			</ul>
			<p>It compiles but we get this error when we run it:</p>
			<pre><strong class="bold">terminate called without an active exception</strong>
<strong class="bold">Aborted</strong></pre>
			<p>(Your error message will vary. This is the error message on Debian with GCC.)</p>
			<p>The problem is that the operating system doesn't know what to do with the thread object when it goes out of scope. We must specify if the caller waits for the thread, or if it's detached and runs independently.</p>
			<ul>
				<li>We use the <code>join()</code> method to indicate<a id="_idIndexMarker800"/> that the caller will wait<a id="_idIndexMarker801"/> for the thread to finish:<pre>int main() {
    thread t1(fthread, 1);
    t1.<strong class="bold">join</strong>();
    cout &lt;&lt; "end of main()\n";
}</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">This is t1</strong>
<strong class="bold">t1: 1</strong>
<strong class="bold">t1: 2</strong>
<strong class="bold">t1: 3</strong>
<strong class="bold">t1: 4</strong>
<strong class="bold">t1: 5</strong>
<strong class="bold">Finishing t1</strong>
<strong class="bold">end of main()</strong></pre>
			<p>Now, <code>main()</code> waits for the thread to finish.</p>
			<ul>
				<li>If we call <code>detach()</code> instead of <code>join()</code>, then <code>main()</code> doesn't wait, and the program ends before the thread can run:<pre>thread t1(fthread, 1);
t1.detach();</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">end of main()</strong></pre>
			<ul>
				<li>When the thread<a id="_idIndexMarker802"/> is detached, we need to give it time<a id="_idIndexMarker803"/> to run:<pre>thread t1(fthread, 1);
t1.<strong class="bold">detach</strong>();
cout &lt;&lt; "main() sleep 2 sec\n";
<strong class="bold">sleepms</strong>(2000);</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">main() sleep 2 sec</strong>
<strong class="bold">This is t1</strong>
<strong class="bold">t1: 1</strong>
<strong class="bold">t1: 2</strong>
<strong class="bold">t1: 3</strong>
<strong class="bold">t1: 4</strong>
<strong class="bold">t1: 5</strong>
<strong class="bold">Finishing t1</strong>
<strong class="bold">end of main()</strong></pre>
			<ul>
				<li>Let's start and detach a second thread and see what happens:<pre>int main() {
    thread t1(fthread, 1);
    thread t2(fthread, 2);
    t1.detach();
    t2.detach();
    cout &lt;&lt; "main() sleep 2 sec\n";
    sleepms(2000);
    cout &lt;&lt; "end of main()\n";
}</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">main() sleep 2 sec</strong>
<strong class="bold">This is t1</strong>
<strong class="bold">This is t2</strong>
<strong class="bold">t1: 1</strong>
<strong class="bold">t2: 1</strong>
<strong class="bold">t1: 2</strong>
<strong class="bold">t1: 3</strong>
<strong class="bold">t2: 2</strong>
<strong class="bold">t1: 4</strong>
<strong class="bold">t1: 5</strong>
<strong class="bold">Finishing t1</strong>
<strong class="bold">t2: 3</strong>
<strong class="bold">t2: 4</strong>
<strong class="bold">t2: 5</strong>
<strong class="bold">Finishing t2</strong>
<strong class="bold">end of main()</strong></pre>
			<p>Because our <code>fthread()</code> function uses<a id="_idIndexMarker804"/> its parameter as a multiplier for <code>sleepms()</code>, the second thread<a id="_idIndexMarker805"/> runs a bit slower than the first. We can see the timers interlaced in the output.</p>
			<ul>
				<li>If we do this with <code>join()</code> instead of <code>detatch()</code>, we get a similar result:<pre>int main() {
    thread t1(fthread, 1);
    thread t2(fthread, 2);
    t1.join();
    t2.join();
    cout &lt;&lt; "end of main()\n";
}</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">This is t1</strong>
<strong class="bold">This is t2</strong>
<strong class="bold">t1: 1</strong>
<strong class="bold">t2: 1</strong>
<strong class="bold">t1: 2</strong>
<strong class="bold">t1: 3</strong>
<strong class="bold">t2: 2</strong>
<strong class="bold">t1: 4</strong>
<strong class="bold">t1: 5</strong>
<strong class="bold">Finishing t1</strong>
<strong class="bold">t2: 3</strong>
<strong class="bold">t2: 4</strong>
<strong class="bold">t2: 5</strong>
<strong class="bold">Finishing t2</strong>
<strong class="bold">end of main()</strong></pre>
			<p>Because <code>join()</code> waits for the thread<a id="_idIndexMarker806"/> to finish, we no longer<a id="_idIndexMarker807"/> need the 2-second <code>sleepms()</code> in <code>main()</code> to wait for the threads to finish.</p>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor299"/>How it works…</h2>
			<p>A <code>std::thread</code> object represents a thread of execution. There is a one-to-one relationship between object and thread. One <code>thread</code> object represents one thread, and one thread is represented by one <code>thread</code> object. A <code>thread</code> object cannot be copied or assigned, but it can be moved.</p>
			<p>The <code>thread</code> constructor looks like this:</p>
			<pre>explicit thread( Function&amp;&amp; f, Args&amp;&amp;… args );</pre>
			<p>A thread is constructed with a function pointer and zero or more arguments. The function is called immediately with the arguments provided:</p>
			<pre>thread t1(fthread, 1);</pre>
			<p>This creates the object <code>t1</code> and immediately calls the function <code>fthread(int)</code> with the literal value <code>1</code> as the argument.</p>
			<p>After creating the thread, we must use either <code>join()</code> or <code>detach()</code> on the thread:</p>
			<pre>t1.join();</pre>
			<p>The <code>join()</code> method blocks execution of the calling thread until the <code>t1</code> thread has completed:</p>
			<pre>t1.detach();</pre>
			<p>The <code>detach()</code> method allows the calling thread to continue independently of the <code>t1</code> thread.</p>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor300"/>There's more…</h2>
			<p>C++20 provides <code>std::jthread</code>, which automatically joins<a id="_idIndexMarker808"/> the caller at the end of its scope:</p>
			<pre>int main() {
    std::jthread t1(fthread, 1);
    cout "&lt; "end of main("\n";
}</pre>
			<p>Output:</p>
			<pre>end of main()
This is t1
t1: 1
t1: 2
t1: 3
t1: 4
t1: 5
Finishing t1</pre>
			<p>This allows the <code>t1</code> thread to execute<a id="_idIndexMarker809"/> independently and then automatically join the <code>main()</code> thread at the end of its scope.</p>
			<h1 id="_idParaDest-302"><a id="_idTextAnchor301"/>Use std::async for concurrency</h1>
			<p><code>std::async()</code> runs a target function<a id="_idIndexMarker810"/> asynchronously and returns a <code>std::future</code> object to carry<a id="_idIndexMarker811"/> the target function's return value. In this way, <code>async()</code> operates much like <code>std::thread</code> but allows return values.</p>
			<p>Let's consider the use of <code>std::async()</code> with a few examples.</p>
			<h2 id="_idParaDest-303"><a id="_idTextAnchor302"/>How to do it…</h2>
			<p>In its simplest forms, the <code>std::async()</code> function performs much the same task as <code>std::thread</code>, without the need to call <code>join()</code> or <code>detach()</code> and while also allowing return values via a <code>std::future</code> object. </p>
			<p>In this recipe, we'll use a function that counts the number of primes in a range. We'll use <code>chrono::steady_clock</code> to time the execution of each thread.</p>
			<ul>
				<li>We'll start with a couple of convenience aliases:<pre>using launch = std::launch;
using secs = std::chrono::duration&lt;double&gt;;</pre></li>
			</ul>
			<p><code>std::launch</code> has launch policy constants, for use with the <code>async()</code> call. The <code>secs</code> alias is a <code>duration</code> class, for timing our prime number calculations.</p>
			<ul>
				<li>Our target function <a id="_idIndexMarker812"/>counts prime numbers in a range. This is essentially<a id="_idIndexMarker813"/> a way to understand the execution policies by eating some clock cycles:<pre>struct <strong class="bold">prime_time</strong> {
    secs dur{};
    uint64_t count{};
};
<strong class="bold">prime_time</strong> count_primes(const uint64_t&amp; max) {
    <strong class="bold">prime_time</strong> <strong class="bold">ret</strong>{};
    constexpr auto <strong class="bold">isprime</strong> = [](const uint64_t&amp; n) {
        for(uint64_t i{ 2 }; i &lt; n / 2; ++i) {
            if(n % i == 0) return false;
        }
        return true;
    };
    uint64_t start{ 2 };
    uint64_t end{ max };
    auto t1 = <strong class="bold">steady_clock::now()</strong>;
    for(uint64_t i{ start }; i &lt;= end ; ++i) {
        if(isprime(i)) <strong class="bold">++ret.count</strong>;
    }
    <strong class="bold">ret.dur</strong> = <strong class="bold">steady_clock::now() - t1</strong>;
    return <strong class="bold">ret</strong>;
}</pre></li>
			</ul>
			<p>The <code>prime_time</code> structure is for the return<a id="_idIndexMarker814"/> value, with elements for duration and count. This allows<a id="_idIndexMarker815"/> us to time the loop itself. The <code>isprime</code> lambda returns <code>true</code> if a value is prime. We use <code>steady_clock</code> to calculate the duration of the loop that counts primes.</p>
			<ul>
				<li>In <code>main()</code>, we call our function and report its timing:<pre>int main() {
    constexpr uint64_t MAX_PRIME{ 0x1FFFF };
    auto pt = <strong class="bold">count_primes(MAX_PRIME)</strong>;
    cout &lt;&lt; format("primes: {} {:.3}\n", <strong class="bold">pt.count</strong>, 
      <strong class="bold">pt.dur</strong>);
}</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">primes: 12252 1.88008s</strong></pre>
			<ul>
				<li>Now, we can run <code>count_primes()</code> asynchronously with <code>std::async()</code>:<pre>int main() {
    constexpr uint64_t MAX_PRIME{ 0x1FFFF };
    <strong class="bold">auto primes1</strong> = <strong class="bold">async</strong>(count_primes, MAX_PRIME);
    auto <strong class="bold">pt</strong> = <strong class="bold">primes1.get()</strong>;
    cout &lt;&lt; format("primes: {} {:.3}\n", <strong class="bold">pt.count</strong>, 
      <strong class="bold">pt.dur</strong>);
}</pre></li>
			</ul>
			<p>Here, we call <code>async()</code> with our <code>count_primes</code> function and the <code>MAX_PRIME</code> parameter. This runs <code>count_primes()</code> in the background.</p>
			<p><code>async()</code> returns a <code>std::future</code> object, which carries the return value of an asynchronous operation. The <code>future</code> object's <code>get()</code> method blocks until the asynchronous function<a id="_idIndexMarker816"/> has completed and then returns the return<a id="_idIndexMarker817"/> object from the function.</p>
			<p>This runs with almost the same timing as we got without <code>async()</code>:</p>
			<pre><strong class="bold">primes: 12252 1.97245s</strong></pre>
			<ul>
				<li>The <code>async()</code> function optionally takes execution policy flags as its first parameter:<pre>auto primes1 = async(<strong class="bold">launch::async</strong>, count_primes, MAX_PRIME);</pre></li>
			</ul>
			<p>The choices are <code>async</code> or <code>deferred</code>. These flags are in the <code>std::launch</code> namespace.</p>
			<p>The <code>async</code> flag enables asynchronous operation, and the <code>deferred</code> flag enables lazy evaluation. These flags are bitmapped and may be combined with the bitwise or <code>|</code> operator.</p>
			<p>The default is for both bits to be set, as if <code>async | deferred</code> was specified.</p>
			<ul>
				<li>We can run several instances of our function simultaneously with <code>async()</code>:<pre>int main() {
    constexpr uint64_t MAX_PRIME{ 0x1FFFF };
    <strong class="bold">list&lt;std::future&lt;prime_time&gt;&gt; swarm</strong>;
    cout &lt;&lt; "start parallel primes\n";
    auto t1{ <strong class="bold">steady_clock::now()</strong> };
    for(size_t i{}; i &lt; 15; ++i) {
        swarm.emplace_back(
            <strong class="bold">async(launch::async, count_primes, </strong>
<strong class="bold">              MAX_PRIME)</strong>
        );
    }
    for(auto&amp; f : swarm) {
        static size_t i{};
        auto pt = <strong class="bold">f.get()</strong>;
        cout &lt;&lt; format("primes({:02}): {} {:.5}\n",
            ++i, pt.count, pt.dur);
    }
    secs dur_total{ <strong class="bold">steady_clock::now() - t1</strong> };
    cout &lt;&lt; format("total duration: {:.5}s\n", 
        dur_total.count());
}</pre></li>
			</ul>
			<p>We know that <code>async</code> returns a <code>future</code> object. So, we can<a id="_idIndexMarker818"/> run 15 threads by storing the <code>future</code> objects<a id="_idIndexMarker819"/> in a container. Here's our output on a 6-core i7 running Windows:</p>
			<pre><strong class="bold">start parallel primes</strong>
<strong class="bold">primes(01): 12252 4.1696s</strong>
<strong class="bold">primes(02): 12252 3.7754s</strong>
<strong class="bold">primes(03): 12252 3.78089s</strong>
<strong class="bold">primes(04): 12252 3.72149s</strong>
<strong class="bold">primes(05): 12252 3.72006s</strong>
<strong class="bold">primes(06): 12252 4.1306s</strong>
<strong class="bold">primes(07): 12252 4.26015s</strong>
<strong class="bold">primes(08): 12252 3.77283s</strong>
<strong class="bold">primes(09): 12252 3.77176s</strong>
<strong class="bold">primes(10): 12252 3.72038s</strong>
<strong class="bold">primes(11): 12252 3.72416s</strong>
<strong class="bold">primes(12): 12252 4.18738s</strong>
<strong class="bold">primes(13): 12252 4.07128s</strong>
<strong class="bold">primes(14): 12252 2.1967s</strong>
<strong class="bold">primes(15): 12252 2.22414s</strong>
<strong class="bold">total duration: 5.9461s</strong></pre>
			<p>Even though the 6-core i7 is not able to run<a id="_idIndexMarker820"/> all the processes in separate<a id="_idIndexMarker821"/> cores, it still completes 15 instances in under 6 seconds.</p>
			<p>It looks like it finishes the first 13 threads in about 4 seconds, and then takes another 2 seconds to finish the last 2 threads. It appears to take advantage of Intel's Hyper-Threading technology that allows 2 threads to run in one core under some circumstances.</p>
			<p>When we run the same code on a 12-core Xeon, we get this result:</p>
			<pre><strong class="bold">start parallel primes</strong>
<strong class="bold">primes(01): 12252 0.96221s</strong>
<strong class="bold">primes(02): 12252 0.97346s</strong>
<strong class="bold">primes(03): 12252 0.92189s</strong>
<strong class="bold">primes(04): 12252 0.97499s</strong>
<strong class="bold">primes(05): 12252 0.98135s</strong>
<strong class="bold">primes(06): 12252 0.93426s</strong>
<strong class="bold">primes(07): 12252 0.90294s</strong>
<strong class="bold">primes(08): 12252 0.96307s</strong>
<strong class="bold">primes(09): 12252 0.95015s</strong>
<strong class="bold">primes(10): 12252 0.94255s</strong>
<strong class="bold">primes(11): 12252 0.94971s</strong>
<strong class="bold">primes(12): 12252 0.95639s</strong>
<strong class="bold">primes(13): 12252 0.95938s</strong>
<strong class="bold">primes(14): 12252 0.92115s</strong>
<strong class="bold">primes(15): 12252 0.94122s</strong>
<strong class="bold">total duration: 0.98166s</strong></pre>
			<p>The 12-core Xeon gets<a id="_idIndexMarker822"/> through all 15 processes in under<a id="_idIndexMarker823"/> a second.</p>
			<h2 id="_idParaDest-304"><a id="_idTextAnchor303"/>How it works…</h2>
			<p>The key to understanding <code>std::async</code> is in its use of <code>std::promise</code> and <code>std::future</code>.</p>
			<p>The <code>promise</code> class allows a <code>thread</code> to store an object that may later be retrieved asynchronously by a <code>future</code> object.</p>
			<p>For example, let's say we have a function like this:</p>
			<pre>void f() {
    cout &lt;&lt; "this is f()\n";
}</pre>
			<p>We can run it with <code>std::thread</code>, like this:</p>
			<pre>int main() {
    std::thread t1(f);
    t1.join();
    cout &lt;&lt; "end of main()\n";
}</pre>
			<p>That works fine for a simple<a id="_idIndexMarker824"/> function with no return value. When we want<a id="_idIndexMarker825"/> to return a value from <code>f()</code>, we can use <code>promise</code> and <code>future</code>.</p>
			<p>We set up the promise and future objects in the <code>main()</code> thread:</p>
			<pre>int main() {
    <strong class="bold">std::promise&lt;int&gt; value_promise</strong>;
    <strong class="bold">std::future&lt;int&gt; value_future</strong> = 
      value_promise.<strong class="bold">get_future()</strong>;
    std::thread t1(f, <strong class="bold">std::move(value_promise)</strong>);
    t1.detach();
    cout &lt;&lt; format("value is {}\n", <strong class="bold">value_future.get()</strong>);
    cout &lt;&lt; "end of main()\n";
}</pre>
			<p>And we pass the <code>promise</code> object to our function:</p>
			<pre>void f(<strong class="bold">std::promise&lt;int&gt; value</strong>) {
    cout &lt;&lt; "this is f()\n";
    <strong class="bold">value.set_value(47)</strong>;
}</pre>
			<p>Note that a <code>promise</code> object cannot be copied, so we need to use <code>std::move</code> to pass it to the function.</p>
			<p>The <code>promise</code> object serves as a bridge to a <code>future</code> object, which allows us to retrieve the value when it becomes available.</p>
			<p><code>std::async()</code> is just a helper function to simplify the creation of the <code>promise</code> and <code>future</code> objects. With <code>async()</code>, we can do all of that like this:</p>
			<pre>int f() {
    cout &lt;&lt; "this is f()\n";
    return 47;
}
int main() {
    auto <strong class="bold">value_future = std::async(f)</strong>;
    cout &lt;&lt; format("value is {}\n", <strong class="bold">value_future.get()</strong>);
    cout &lt;&lt; "end of main()\n";
}</pre>
			<p>That's the value<a id="_idIndexMarker826"/> of <code>async()</code>. For many purposes, it makes<a id="_idIndexMarker827"/> the use of <code>promise</code> and <code>future</code> much easier.</p>
			<h1 id="_idParaDest-305"><a id="_idTextAnchor304"/>Run STL algorithms in parallel with execution policies</h1>
			<p>Beginning with C++17, many of the standard STL algorithms can run with <em class="italic">parallel execution</em>. This feature allows an algorithm<a id="_idIndexMarker828"/> to split its work into sub-tasks to run<a id="_idIndexMarker829"/> simultaneously on multiple cores. These algorithms accept an execution policy object that specifies the kind of parallelism applied to the algorithm. This feature requires hardware support.</p>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor305"/>How to do it…</h2>
			<p>Execution policies are defined in the <code>&lt;execution&gt;</code> header and in the <code>std::execution</code> namespace. In this recipe, we will test the available policies using the <code>std::transform()</code> algorithm:</p>
			<ul>
				<li>For timing purposes, we'll use the <code>duration</code> object with the <code>std::milli</code> ratio so that we can measure in milliseconds:<pre>using dur_t = duration&lt;double, std::milli&gt;;</pre></li>
				<li>For demonstration<a id="_idIndexMarker830"/> purposes, we'll start<a id="_idIndexMarker831"/> with a <code>vector</code> of <code>int</code> with 10 million random values:<pre>int main() {
    std::vector&lt;unsigned&gt; v(10 * 1000 * 1000);
    std::random_device rng;
    for(auto &amp;i : v) i = rng() % 0xFFFF;
    ...</pre></li>
				<li>Now, we apply a simple transformation:<pre>auto mul2 = [](int n){ return n * 2; };
auto t1 = steady_clock::now();
std::transform(v.begin(), v.end(), v.begin(), mul2);
dur_t dur1 = steady_clock::now() - t1;
cout &lt;&lt; format("no policy: {:.3}ms\n", dur1.count());</pre></li>
			</ul>
			<p>The <code>mul2</code> lambda simply multiplies a value by 2. The <code>transform()</code> algorithm applies <code>mul2</code> to every member of the vector.</p>
			<p>This transformation does not specify an execution policy.</p>
			<p>Output:</p>
			<pre><strong class="bold">no policy: 4.71ms</strong></pre>
			<ul>
				<li>We can specify an execution policy in the first argument of the algorithm:<pre>std::transform(<strong class="bold">execution::seq</strong>,
    v.begin(), v.end(), v.begin(), mul2);</pre></li>
			</ul>
			<p>The <code>seq</code> policy means that the algorithm shall not be parallelized. This is the same as no execution policy.</p>
			<p>Output:</p>
			<pre><strong class="bold">execution::seq: 4.91ms</strong></pre>
			<p>Notice that the duration<a id="_idIndexMarker832"/> is roughly the same as without<a id="_idIndexMarker833"/> a policy. It will never be exact because it varies each time it's run.</p>
			<ul>
				<li>The <code>execution::par</code> policy allows the algorithm to parallelize its workload:<pre>std::transform(<strong class="bold">execution::par</strong>,
    v.begin(), v.end(), v.begin(), mul2);</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">execution::par: 3.22ms</strong></pre>
			<p>Notice that the algorithm runs somewhat faster with the parallel execution policy.</p>
			<ul>
				<li>The <code>execution::par_unseq</code> policy allows unsequenced parallel execution of the workload:<pre>std::transform(<strong class="bold">execution::par_unseq</strong>,
    v.begin(), v.end(), v.begin(), mul2);</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">execution::par_unseq: 2.93ms</strong></pre>
			<p>Here, we notice another increase in performance with this policy.</p>
			<p>The <code>execution::par_unseq</code> policy has tighter requirements of the algorithm. The algorithm must not perform operations that require concurrent or sequential operation.</p>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor306"/>How it works…</h2>
			<p>The execution policies interface doesn't specify how the algorithm workloads are parallelized. It's designed<a id="_idIndexMarker834"/> to work with a diverse set of hardware<a id="_idIndexMarker835"/> and processors under varying loads and circumstances. It may be implemented entirely in the library or rely on compiler or hardware support.</p>
			<p>Parallelization will show the most improvement on algorithms that do more than <em class="italic">O(n)</em> work. For example, <code>sort()</code> shows a dramatic improvement. Here's a <code>sort()</code> with no parallelization:</p>
			<pre>auto t0 = steady_clock::now();
std::sort(v.begin(), v.end());
dur_t dur0 = steady_clock::now() - t0;
cout &lt;&lt; format("sort: {:.3}ms\n", dur0.count());</pre>
			<p>Output:</p>
			<pre>sort: 751ms</pre>
			<p>With <code>execution::par</code>, we see significant performance gains:</p>
			<pre>std::sort(<strong class="bold">execution::par</strong>, v.begin(), v.end());</pre>
			<p>Output:</p>
			<pre>sort: 163ms</pre>
			<p>The improvement with <code>execution::par_unseq</code> is better still:</p>
			<pre>std::sort(<strong class="bold">execution::par_unseq</strong>, v.begin(), v.end());</pre>
			<p>Output:</p>
			<pre>sort: 152ms</pre>
			<p>It's a good idea to do a lot of testing when using the parallelized algorithms. If your algorithm or predicates do not lend themselves well to parallelization, you may end up with minimal performance gains or unintended side effects.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">At the time of writing, execution policies are poorly supported in GCC and not yet supported by LLVM/Clang. This recipe was tested on a 6-core i7 running Windows 10 and a preview release of Visual C++.</p>
			<h1 id="_idParaDest-308"><a id="_idTextAnchor307"/>Share data safely with mutex and locks</h1>
			<p>The term <em class="italic">mutex</em> refers to <em class="italic">mutually exclusive</em> access to shared<a id="_idIndexMarker836"/> resources. A mutex<a id="_idIndexMarker837"/> is commonly used to avoid<a id="_idIndexMarker838"/> data corruption<a id="_idIndexMarker839"/> and race conditions, due to multiple threads<a id="_idIndexMarker840"/> of execution attempting to access<a id="_idIndexMarker841"/> the same data. A mutex will typically use <em class="italic">locks</em> to restrict access to one thread at a time.</p>
			<p>The STL provides <em class="italic">mutex</em> and <em class="italic">lock</em> classes in the <code>&lt;mutex&gt;</code> header.</p>
			<h2 id="_idParaDest-309"><a id="_idTextAnchor308"/>How to do it…</h2>
			<p>In this recipe, we will use a simple <code>Animal</code> class to experiment with <em class="italic">locking</em> and <em class="italic">unlocking</em> a <code>mutex</code>:</p>
			<ul>
				<li>We start by creating a <code>mutex</code> object:<pre>std::mutex animal_mutex;</pre></li>
			</ul>
			<p>The <code>mutex</code> is declared in the global scope, so it's accessible to all the relevant objects.</p>
			<ul>
				<li>Our <code>Animal</code> class has a name and a list of friends:<pre>class Animal {
    using friend_t = list&lt;Animal&gt;;
    string_view s_name{ "unk" };
    friend_t l_friends{};
public:
    Animal() = delete;
    Animal(const string_view n) : s_name{n} {}
    ...
}</pre></li>
			</ul>
			<p>Adding and deleting<a id="_idIndexMarker842"/> friends will<a id="_idIndexMarker843"/> be a useful<a id="_idIndexMarker844"/> test case<a id="_idIndexMarker845"/> for our <code>mutex</code>.</p>
			<ul>
				<li>The equality operator is the only operator we'll need:<pre>bool operator==(const Animal&amp; o) const {
    return s_name.data() == o.s_name.data();
}</pre></li>
			</ul>
			<p>The <code>s_name</code> member is a <code>string_view</code> object, so we can test the address of its data store for equality.</p>
			<ul>
				<li>The <code>is_friend()</code> method tests if another <code>Animal</code> is in the <code>l_friends</code> list:<pre>bool is_friend(const Animal&amp; o) const {
    for(const auto&amp; a : l_friends) {
        if(a == o) return true;
    }
    return false;
}</pre></li>
				<li>The <code>find_friend()</code> method returns an <code>optional</code>, with an iterator to the <code>Animal</code> if found:<pre>optional&lt;friend_t::iterator&gt;
find_friend(const Animal&amp; o) noexcept {
    for(auto it{l_friends.begin()};
            it != l_friends.end(); ++it) {
        if(*it == o) return it;
    }
    return {};
}</pre></li>
				<li>The <code>print()</code> method<a id="_idIndexMarker846"/> prints <code>s_name</code> along<a id="_idIndexMarker847"/> with names<a id="_idIndexMarker848"/> of each of the <code>Animal</code> objects<a id="_idIndexMarker849"/> in the <code>l_friends</code> list:<pre>void print() const noexcept {
    auto n_animals{ l_friends.size() };
    cout &lt;&lt; format("Animal: {}, friends: ", s_name);
    if(!n_animals) cout &lt;&lt; "none";
    else {
        for(auto n : l_friends) {
            cout &lt;&lt; n.s_name;
            if(--n_animals) cout &lt;&lt; ", ";
        }
    }
    cout &lt;&lt; '\n';
}</pre></li>
				<li>The <code>add_friend()</code> method adds an <code>Animal</code> object to the <code>l_friends</code> list:<pre>bool add_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("add_friend {} -&gt; {}\n", s_name, 
      o.s_name);
    if(*this == o) return false;
    std::lock_guard&lt;std::mutex&gt; l(animal_mutex);
    if(!is_friend(o)) l_friends.emplace_back(o);
    if(!o.is_friend(*this))
      o.l_friends.emplace_back(*this);
    return true;
}</pre></li>
				<li>The <code>delete_friend()</code> method<a id="_idIndexMarker850"/> removes<a id="_idIndexMarker851"/> an <code>Animal</code> object<a id="_idIndexMarker852"/> from<a id="_idIndexMarker853"/> the <code>l_friends</code> list:<pre>bool delete_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("delete_friend {} -&gt; {}\n",
        s_name, o.s_name);
    if(*this == o) return false;
    if(auto it = find_friend(o)) 
      l_friends.erase(it.value());
    if(auto it = o.find_friend(*this))
        o.l_friends.erase(it.value());
    return true;
}</pre></li>
				<li>In the <code>main()</code> function, we create some <code>Animal</code> objects:<pre>int main() {
    auto cat1 = std::make_unique&lt;Animal&gt;("Felix");
    auto tiger1 = std::make_unique&lt;Animal&gt;("Hobbes");
    auto dog1 = std::make_unique&lt;Animal&gt;("Astro");
    auto rabbit1 = std::make_unique&lt;Animal&gt;("Bugs");
    ...</pre></li>
				<li>We call <code>add_friends()</code> on our objects with <code>async()</code>, to run them in separate threads:<pre>auto a1 = std::async([&amp;]{ cat1-&gt;add_friend(*tiger1); });
auto a2 = std::async([&amp;]{ cat1-&gt;add_friend(*rabbit1); });
auto a3 = std::async([&amp;]{ rabbit1-&gt;add_friend(*dog1); });
auto a4 = std::async([&amp;]{ rabbit1-&gt;add_friend(*cat1); });
a1.wait();
a2.wait();
a3.wait();
a4.wait();</pre></li>
			</ul>
			<p>We call <code>wait()</code> to allow<a id="_idIndexMarker854"/> our threads<a id="_idIndexMarker855"/> to complete <a id="_idIndexMarker856"/>before<a id="_idIndexMarker857"/> continuing.</p>
			<ul>
				<li>We call <code>print()</code> to see our <code>Animals</code> and their relationships:<pre>auto p1 = std::async([&amp;]{ cat1-&gt;print(); });
auto p2 = std::async([&amp;]{ tiger1-&gt;print(); });
auto p3 = std::async([&amp;]{ dog1-&gt;print(); });
auto p4 = std::async([&amp;]{ rabbit1-&gt;print(); });
p1.wait();
p2.wait();
p3.wait();
p4.wait();</pre></li>
				<li>And finally, we call <code>delete_friend()</code> to remove one of our relationships:<pre>auto a5 = std::async([&amp;]{ cat1-&gt;delete_friend(*rabbit1); });
a5.wait();
auto p5 = std::async([&amp;]{ cat1-&gt;print(); });
auto p6 = std::async([&amp;]{ rabbit1-&gt;print(); });</pre></li>
				<li>At this<a id="_idIndexMarker858"/> point, our<a id="_idIndexMarker859"/> output<a id="_idIndexMarker860"/> looks like<a id="_idIndexMarker861"/> this:<pre>add_friend Bugs -&gt; Felix
add_friend Felix -&gt; Hobbes
add_friend Felix -&gt; Bugs
add_friend Bugs -&gt; Astro
Animal: Felix, friends: Bugs, Hobbes
Animal: Hobbes, friends: Animal: Bugs, friends: FelixAnimal: Astro, friends: Felix
, Astro
Bugs
delete_friend Felix -&gt; Bugs
Animal: Felix, friends: Hobbes
Animal: Bugs, friends: Astro</pre></li>
			</ul>
			<p>This output is somewhat scrambled. It will be different each time you run it. It may be fine sometimes, but don't let that fool you. We need to add some mutex locks to control access to the data.</p>
			<ul>
				<li>One way to use <code>mutex</code> is with its <code>lock()</code> and <code>unlock()</code> methods. Let's add them to the <code>add_friend()</code> function:<pre>bool add_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("add_friend {} -&gt; {}\n", s_name, o.s_name);
    if(*this == o) return false;
    <strong class="bold">animal_mutex.lock()</strong>;
    if(!is_friend(o)) l_friends.emplace_back(o);
    if(!o.is_friend(*this)) o.l_friends.emplace_back(*this);
    <strong class="bold">animal_mutex.unlock()</strong>;
    return true;
}</pre></li>
			</ul>
			<p>The <code>lock()</code> method<a id="_idIndexMarker862"/> attempts<a id="_idIndexMarker863"/> to acquire a lock on the <code>mutex</code>. If the mutex<a id="_idIndexMarker864"/> is already locked, it will wait (block execution) until<a id="_idIndexMarker865"/> the <code>mutex</code> is unlocked.</p>
			<ul>
				<li>We also need to add a lock to <code>delete_friend()</code>:<pre>bool delete_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("delete_friend {} -&gt; {}\n",
        s_name, o.s_name);
    if(*this == o) return false;
    <strong class="bold">animal_mutex.lock()</strong>;
    if(auto it = find_friend(o)) 
      l_friends.erase(it.value());
    if(auto it = o.find_friend(*this))
        o.l_friends.erase(it.value());
    <strong class="bold">animal_mutex.unlock()</strong>;
    return true;
}</pre></li>
				<li>Now, we need<a id="_idIndexMarker866"/> to add a lock to <code>print()</code> so that<a id="_idIndexMarker867"/> data<a id="_idIndexMarker868"/> is not changed<a id="_idIndexMarker869"/> while printing:<pre>void print() const noexcept {
    <strong class="bold">animal_mutex.lock()</strong>;
    auto n_animals{ l_friends.size() };
    cout &lt;&lt; format("Animal: {}, friends: ", s_name);
    if(!n_animals) cout &lt;&lt; "none";
    else {
        for(auto n : l_friends) {
            cout &lt;&lt; n.s_name;
            if(--n_animals) cout &lt;&lt; ", ";
        }
    }
    cout &lt;&lt; '\n';
    <strong class="bold">animal_mutex.unlock()</strong>;
}</pre></li>
			</ul>
			<p>Now, our output is sensible:</p>
			<pre><strong class="bold">add_friend Bugs -&gt; Felix</strong>
<strong class="bold">add_friend Bugs -&gt; Astro</strong>
<strong class="bold">add_friend Felix -&gt; Hobbes</strong>
<strong class="bold">add_friend Felix -&gt; Bugs</strong>
<strong class="bold">Animal: Felix, friends: Bugs, Hobbes</strong>
<strong class="bold">Animal: Hobbes, friends: Felix</strong>
<strong class="bold">Animal: Astro, friends: Bugs</strong>
<strong class="bold">Animal: Bugs, friends: Felix, Astro</strong>
<strong class="bold">delete_friend Felix -&gt; Bugs</strong>
<strong class="bold">Animal: Felix, friends: Hobbes</strong>
<strong class="bold">Animal: Bugs, friends: Astro</strong></pre>
			<p>Your output<a id="_idIndexMarker870"/> may have the lines <a id="_idIndexMarker871"/>in a different order<a id="_idIndexMarker872"/> due to asynchronous<a id="_idIndexMarker873"/> operation.</p>
			<ul>
				<li>The <code>lock()</code> and <code>unlock()</code> methods are rarely called directly. The <code>std::lock_guard</code> class manages<a id="_idIndexMarker874"/> locks with a proper <code>add_friend()</code> method with <code>lock_guard</code>:<pre>bool add_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("add_friend {} -&gt; {}\n", s_name, o.s_name);
    if(*this == o) return false;
    <strong class="bold">std::lock_guard&lt;std::mutex&gt; l(animal_mutex)</strong>;
    if(!is_friend(o)) l_friends.emplace_back(o);
    if(!o.is_friend(*this)) 
      o.l_friends.emplace_back(*this);
    return true;
}</pre></li>
			</ul>
			<p>The <code>lock_guard</code> object is created and holds a lock until it is destroyed. Like the <code>lock()</code> method, <code>lock_guard</code> also blocks until a lock is available.</p>
			<ul>
				<li>Let's<a id="_idIndexMarker875"/> apply <code>lock_guard</code> to<a id="_idIndexMarker876"/> the <code>delete_friend()</code> and <code>print()</code> methods.</li>
			</ul>
			<p>Here is <code>delete_friend()</code>:</p>
			<pre>bool delete_friend(Animal&amp; o) noexcept {
    cout &lt;&lt; format("delete_friend {} -&gt; {}\n",
        s_name, o.s_name);
    if(*this == o) return false;
    <strong class="bold">std::lock_guard&lt;std::mutex&gt; l(animal_mutex)</strong>;
    if(auto it = find_friend(o)) 
      l_friends.erase(it.value());
    if(auto it = o.find_friend(*this))
        o.l_friends.erase(it.value());
    return true;
}</pre>
			<p>And<a id="_idIndexMarker877"/> here<a id="_idIndexMarker878"/> is <code>print()</code>:</p>
			<pre>void print() const noexcept {
    <strong class="bold">std::lock_guard&lt;std::mutex&gt; l(animal_mutex)</strong>;
    auto n_animals{ l_friends.size() };
    cout &lt;&lt; format("Animal: {}, friends: ", s_name);
    if(!n_animals) cout &lt;&lt; "none";
    else {
        for(auto n : l_friends) {
            cout &lt;&lt; n.s_name;
            if(--n_animals) cout &lt;&lt; ", ";
        }
    }
    cout &lt;&lt; '\n';
}</pre>
			<p>Our output remains coherent:</p>
			<pre><strong class="bold">add_friend Felix -&gt; Hobbes</strong>
<strong class="bold">add_friend Bugs -&gt; Astro</strong>
<strong class="bold">add_friend Felix -&gt; Bugs</strong>
<strong class="bold">add_friend Bugs -&gt; Felix</strong>
<strong class="bold">Animal: Felix, friends: Bugs, Hobbes</strong>
<strong class="bold">Animal: Astro, friends: Bugs</strong>
<strong class="bold">Animal: Hobbes, friends: Felix</strong>
<strong class="bold">Animal: Bugs, friends: Astro, Felix</strong>
<strong class="bold">delete_friend Felix -&gt; Bugs</strong>
<strong class="bold">Animal: Felix, friends: Hobbes</strong>
<strong class="bold">Animal: Bugs, friends: Astro</strong></pre>
			<p>As before, your<a id="_idIndexMarker879"/> output may have<a id="_idIndexMarker880"/> the lines in a different<a id="_idIndexMarker881"/> order due to asynchronous<a id="_idIndexMarker882"/> operation.</p>
			<h2 id="_idParaDest-310"><a id="_idTextAnchor309"/>How it works…</h2>
			<p>It's important to understand<a id="_idIndexMarker883"/> that a <code>mutex</code> does not lock data; it blocks execution. As shown<a id="_idIndexMarker884"/> in this recipe, when a <code>mutex</code> is applied in object<a id="_idIndexMarker885"/> methods, it can be used to enforce mutually exclusive<a id="_idIndexMarker886"/> access to data.</p>
			<p>When one thread locks a <code>mutex</code>, with either <code>lock()</code> or <code>lock_guard</code>, that thread is said to <em class="italic">own</em> the <code>mutex</code>. Any other thread that tries to lock the same <code>mutex</code> will be blocked until it's unlocked by the owner.</p>
			<p>The <code>mutex</code> object must not be destroyed while it's owned by any thread. Likewise, a thread must not be destroyed while it owns a <code>mutex</code>. An RAII-compliant wrapper, such as <code>lock_guard</code>, will help ensure this doesn't happen.</p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor310"/>There's more…</h2>
			<p>While <code>std::mutex</code> provides an exclusive mutex suitable for many purposes, the STL does provide a few other choices:</p>
			<ul>
				<li><code>shared_mutex</code> allows more than one thread<a id="_idIndexMarker887"/> to simultaneously own a mutex.</li>
				<li><code>recursive_mutex</code> allows one thread to stack multiple<a id="_idIndexMarker888"/> locks on a single mutex.</li>
				<li><code>timed_mutex</code> provides a timeout for mutex<a id="_idIndexMarker889"/> blocks. Both <code>shared_mutex</code> and <code>recursive_mutex</code> also have timed versions available.</li>
			</ul>
			<h1 id="_idParaDest-312"><a id="_idTextAnchor311"/>Share flags and values with std::atomic</h1>
			<p>The <code>std::atomic</code> class encapsulates<a id="_idIndexMarker890"/> a single object and guarantees<a id="_idIndexMarker891"/> it to be <em class="italic">atomic</em>. Writing to the <em class="italic">atomic object</em> is controlled by memory-order<a id="_idIndexMarker892"/> policies and reads<a id="_idIndexMarker893"/> may occur simultaneously. It's typically used to synchronize access among different threads.</p>
			<p><code>std::atomic</code> defines an <em class="italic">atomic type</em> from its template type. The type must be <em class="italic">trivial</em>. A type is trivial if it occupies contiguous memory, has no user-defined constructor, and has no virtual member functions. All primitive types are trivial.</p>
			<p>While it is possible to construct a trivial type, <code>std::atomic</code> is most often used with simple primitive types, such as <code>bool</code>, <code>int</code>, <code>long</code>, <code>float</code>, and <code>double</code>.</p>
			<h2 id="_idParaDest-313"><a id="_idTextAnchor312"/>How to do it…</h2>
			<p>This recipe uses a simple function<a id="_idIndexMarker894"/> that loops over a counter to demonstrate sharing<a id="_idIndexMarker895"/> atomic objects. We will spawn<a id="_idIndexMarker896"/> a swarm of these loops as threads<a id="_idIndexMarker897"/> that share atomic values:</p>
			<ul>
				<li>Atomic objects are often placed in a global namespace. They must be accessible to all the threads that need to share its value:<pre>std::<strong class="bold">atomic&lt;bool&gt; ready</strong>{};
std::<strong class="bold">atomic&lt;uint64_t&gt; g_count</strong>{};
std::<strong class="bold">atomic_flag winner</strong>{};</pre></li>
			</ul>
			<p>The <code>ready</code> object is a <code>bool</code> type that gets set to <code>true</code> when all the threads are ready to start counting.</p>
			<p>The <code>g_count</code> object is a global counter. It is incremented by each of the threads.</p>
			<p>The <code>winner</code> object is a special <code>atomic_flag</code> type. It is used to indicate which thread finishes first.</p>
			<ul>
				<li>We use a couple of constants to control the number of threads and the number of loops for each thread:<pre>constexpr int <strong class="bold">max_count</strong>{1000 * 1000};
constexpr int <strong class="bold">max_threads</strong>{100};</pre></li>
			</ul>
			<p>I've set it to run 100 threads and count 1,000,000 iterations in each thread.</p>
			<ul>
				<li>The <code>countem()</code> function is spawned for each thread. It loops <code>max_count</code> times and increments <code>g_count</code> for each iteration of the loop. This is where we use our atomic values:<pre>void countem (int <strong class="bold">id</strong>) {
    while(<strong class="bold">!ready</strong>) std::this_thread::<strong class="bold">yield()</strong>;
    for(int i{}; i &lt; <strong class="bold">max_count</strong>; ++i) <strong class="bold">++g_count</strong>;
    if(!<strong class="bold">winner.test_and_set()</strong>) {
        std::cout &lt;&lt; format("thread {:02} won!\n", 
          <strong class="bold">id</strong>);
    }
};</pre></li>
			</ul>
			<p>The <code>ready</code> atomic<a id="_idIndexMarker898"/> value is used to synchronize<a id="_idIndexMarker899"/> the threads. Each thread<a id="_idIndexMarker900"/> will call <code>yield()</code> until <a id="_idIndexMarker901"/>the <code>ready</code> value is set <code>true</code>. The <code>yield()</code> function yields execution to other threads.</p>
			<p>Each iteration of the <code>for</code> loop increments the <code>g_count</code> atomic value. The final value should be equal to <code>max_count * max_threads</code>.</p>
			<p>After the loop is complete, the <code>test_and_set()</code> method of the <code>winner</code> object is used to report the winning thread. <code>test_and_set()</code> is a method of the <code>atomic_flag</code> class. It sets the flag and returns the <code>bool</code> value from before it is set.</p>
			<ul>
				<li>We've used the <code>make_commas()</code> function before. It displays a number with thousands of separators:<pre>string make_commas(const uint64_t&amp; num) {
    string s{ std::to_string(num) };
    for(long l = s.length() - 3; l &gt; 0; l -= 3) {
        s.insert(l, ",");
    }
    return s;
}</pre></li>
				<li>The <code>main()</code> function<a id="_idIndexMarker902"/> spawns<a id="_idIndexMarker903"/> the threads<a id="_idIndexMarker904"/> and reports<a id="_idIndexMarker905"/> the results:<pre>int main() {
    <strong class="bold">vector&lt;std::thread&gt; swarm</strong>;
    cout &lt;&lt; format("spawn {} threads\n", <strong class="bold">max_threads</strong>);
    for(int i{}; i &lt; <strong class="bold">max_threads</strong>; ++i) {
        <strong class="bold">swarm.emplace_back(countem, i)</strong>;
    }
    <strong class="bold">ready = true</strong>;
    for(auto&amp; t : <strong class="bold">swarm</strong>) <strong class="bold">t.join()</strong>;
    cout &lt;&lt; format("global count: {}\n",
        <strong class="bold">make_commas(g_count)</strong>);
    return 0;
}</pre></li>
			</ul>
			<p>Here, we create a <code>vector&lt;std::thread&gt;</code> object to hold the threads.</p>
			<p>In the <code>for</code> loop, we use <code>emplace_back()</code> to create each <code>thread</code> in the <code>vector</code>.</p>
			<p>Once the threads have been spawned, we set the <code>ready</code> flag so that the threads may start their loops.</p>
			<p>Output:</p>
			<pre><strong class="bold">spawn 100 threads</strong>
<strong class="bold">thread 67 won!</strong>
<strong class="bold">global count: 100,000,000</strong></pre>
			<p>Every time you run it, a different thread will win.</p>
			<h2 id="_idParaDest-314"><a id="_idTextAnchor313"/>How it works…</h2>
			<p>The <code>std::atomic</code> class encapsulates<a id="_idIndexMarker906"/> an object<a id="_idIndexMarker907"/> to synchronize<a id="_idIndexMarker908"/> access among multiple<a id="_idIndexMarker909"/> threads.</p>
			<p>The encapsulated object<a id="_idIndexMarker910"/> must be a <em class="italic">trivial type</em>, which means it occupies contiguous memory, has no user-defined constructor, and has no virtual member functions. All primitive types are trivial.</p>
			<p>It is possible to use a simple struct with <code>atomic</code>:</p>
			<pre>struct Trivial {
    int a;
    int b;
};
std::atomic&lt;Trivial&gt; triv1;</pre>
			<p>While this usage is possible, it's not practical. Anything beyond setting and retrieving compound values loses the benefits of the atomicity and ends up requiring a <em class="italic">mutex</em>. The atomic class is best suited for <em class="italic">scalar</em> values.</p>
			<h3>Specializations</h3>
			<p>There are specializations<a id="_idIndexMarker911"/> of the <code>atomic</code> class for a few different purposes:</p>
			<ul>
				<li><code>std::atomic&lt;U*&gt;</code> specialization includes support for atomic pointer arithmetic operations, including <code>fetch_add()</code> for addition and <code>fetch_sub()</code> for subtraction.</li>
				<li><code>float</code>, <code>double</code>, and <code>long double</code>, <code>std::atomic</code> includes support for atomic floating-point arithmetic operations, including <code>fetch_add()</code> for addition and <code>fetch_sub()</code> for subtraction.</li>
				<li><code>std::atomic</code> provides support for additional atomic operations, including <code>fetch_add()</code>, <code>fetch_sub()</code>, <code>fetch_and()</code>, <code>fetch_or()</code>, and <code>fetch_xor()</code>.</li>
			</ul>
			<h3>Standard aliases</h3>
			<p>The STL provides type aliases<a id="_idIndexMarker913"/> for all the standard scalar integral types. This means that instead of these declarations in our code:</p>
			<pre>std::atomic&lt;bool&gt; ready{};
std::atomic&lt;uint64_t&gt; g_count{};</pre>
			<p>We could use:</p>
			<pre>std::atomic_bool ready{};
std::atomic_uint64_t g_count{};</pre>
			<p>There are 46 standard aliases, one for each of the standard integral types:</p>
			<div><div><img src="img/B18267_table_9.1.jpg" alt=""/>
				</div>
			</div>
			<h3>Lock-free variations</h3>
			<p>Most modern architectures<a id="_idIndexMarker914"/> provide <em class="italic">atomic CPU instructions</em> for performing<a id="_idIndexMarker915"/> atomic operations. <code>std::atomic</code> should use hardware support for atomic instructions where supported by your hardware. Some atomic types may not be supported on some hardware. <code>std::atomic</code> may use a <em class="italic">mutex</em> to ensure thread-safe operations for those specializations, causing threads to block while waiting for other threads to complete<a id="_idIndexMarker916"/> operations. Specializations that use hardware support are said to be <em class="italic">lock-free</em> because they don't require a mutex.</p>
			<p>The <code>is_lock_free()</code> method checks whether a specialization is lock-free:</p>
			<pre>cout &lt;&lt; format("is g_count lock-free? {}\n", 
    g_count.is_lock_free());</pre>
			<p>Output:</p>
			<pre>is g_count lock-free? true</pre>
			<p>This result will be <code>true</code> for most modern architectures.</p>
			<p>There are a few guaranteed lock-free variations<a id="_idIndexMarker917"/> of <code>std::atomic</code> available. These specializations guarantee the use of the most efficient hardware atomic operations for each purpose:</p>
			<ul>
				<li><code>std::atomic_signed_lock_free</code> is an alias for the most efficient lock-free specialization of a signed integral type.</li>
				<li><code>std::atomic_unsigned_lock_free</code> is an alias for the most efficient lock-free specialization of an unsigned integral type.</li>
				<li>The <code>std::atomic_flag</code> class provides a lock-free atomic Boolean type.<p class="callout-heading">Important Note</p><p class="callout">Current Windows systems don't support 64-bit hardware integers, even on 64-bit systems. When testing this code on one of these systems in my lab, replacing <code>std::atomic&lt;uint64_t&gt;</code> with <code>std::atomic_unsigned_lock_free</code> resulted in a <em class="italic">3x</em> performance improvement. Performance was unchanged on 64-bit Linux and Mac systems.</p></li>
			</ul>
			<h2 id="_idParaDest-315"><a id="_idTextAnchor314"/>There's more…</h2>
			<p>When multiple threads read and write variables simultaneously, one thread may observe the changes in a different order than they were written. <code>std::memory_order</code> specifies how memory accesses are ordered around an atomic operation.</p>
			<p><code>std::atomic</code> provides methods for accessing and changing its managed value. Unlike the associated operators, these access methods provide arguments for <code>memory_order</code> to be specified. For example:</p>
			<pre>g_count.fetch_add(1, std::memory_order_seq_cst);</pre>
			<p>In this case, <code>memory_order_seq_cst</code> specifies <em class="italic">sequentially consistent</em> ordering. So, this call to <code>fetch_add()</code> will add 1 to the value of <code>g_count</code> with sequentially consistent ordering.</p>
			<p>The possible <code>memory_order</code> constants are:</p>
			<ul>
				<li><code>memory_order_relaxed</code>: This is a <em class="italic">relaxed operation</em>. No synchronization or ordering<a id="_idIndexMarker918"/> constraints are imposed; only the operation's atomicity is guaranteed.</li>
				<li><code>memory_order_consume</code>: This is a <em class="italic">consume operation</em>. Access in the current thread<a id="_idIndexMarker919"/> that is dependent on the value cannot be reordered before this load. This only affects compiler optimization.</li>
				<li><code>memory_order_acquire</code>: This is an <em class="italic">acquire operation</em>. Access cannot<a id="_idIndexMarker920"/> be reordered before this load.</li>
				<li><code>memory_order_release</code>: This is a <em class="italic">store operation</em>. Access in the current thread<a id="_idIndexMarker921"/> cannot be reordered after this store.</li>
				<li><code>memory_order_acq_rel</code>: This is both <em class="italic">acquire</em> and <em class="italic">release</em>. Access in the current thread<a id="_idIndexMarker922"/> cannot be reordered before or after this store.</li>
				<li><code>memory_order_seq_cst</code>: This is <em class="italic">sequentially consistent</em> ordering, either <em class="italic">acquire</em> or <em class="italic">release</em>, depending on the context. A load<a id="_idIndexMarker923"/> performs acquire, a store performs release, and a read/write/modify performs both. All threads observe all modifications in the same order.</li>
			</ul>
			<p>If no <code>memory_order</code> is specified, <code>memory_order_seq_cst</code> is the default.</p>
			<h1 id="_idParaDest-316"><a id="_idTextAnchor315"/>Initialize threads with std::call_once</h1>
			<p>You may need to run<a id="_idIndexMarker924"/> the same code in many threads but must initialize<a id="_idIndexMarker925"/> that code only once.</p>
			<p>One solution would be to call the initialization code before running the threads. This approach can work but has some drawbacks. By separating the initialization, it may be called when unnecessary, or it may be missed when necessary.</p>
			<p>The <code>std::call_once</code> function provides a more robust solution. <code>call_once</code> is in the <code>&lt;mutex&gt;</code> header.</p>
			<h2 id="_idParaDest-317"><a id="_idTextAnchor316"/>How to do it…</h2>
			<p>In this recipe, we use a print function for the initialization, so we can clearly see when it's called:</p>
			<ul>
				<li>We'll use a constant for the number of threads to spawn:<pre>constexpr size_t max_threads{ 25 };</pre></li>
			</ul>
			<p>We also need a <code>std::once_flag</code> to synchronize the <code>std::call_once</code> function:</p>
			<pre>std::once_flag <strong class="bold">init_flag</strong>;</pre>
			<ul>
				<li>Our initialization function simply prints a string to let us know it's been called:<pre>void do_init(size_t <strong class="bold">id</strong>) {
    cout &lt;&lt; format("do_init ({}): ", <strong class="bold">id</strong>);
}</pre></li>
				<li>Our worker function, <code>do_print()</code>, uses <code>std::call_once</code> to call the initialization function then prints its own <code>id</code>:<pre>void do_print(size_t <strong class="bold">id</strong>) {
    <strong class="bold">std::call_once(init_flag, do_init, id)</strong>;
    cout &lt;&lt; format("{} ", <strong class="bold">id</strong>);
}</pre></li>
				<li>In <code>main()</code>, we use a <code>list</code> container<a id="_idIndexMarker926"/> to manage<a id="_idIndexMarker927"/> the <code>thread</code> objects:<pre>int main() {
    <strong class="bold">list&lt;thread&gt; spawn</strong>;
    for (size_t id{}; id &lt; max_threads; ++id) {
        <strong class="bold">spawn.emplace_back(do_print, id)</strong>;
    }
    for (auto&amp; t : spawn) <strong class="bold">t.join()</strong>;
    cout &lt;&lt; '\n';
}</pre></li>
			</ul>
			<p>Our output shows the initialization happens first, and only once:</p>
			<pre><strong class="bold">do_init (8): 12 0 2 1 9 6 13 10 11 5 16 3 4 17 7 15 8 14 18 19 20 21 22 23 24</strong> </pre>
			<p>Notice that it's not always the first spawned thread (<code>0</code>) that ends up calling the initialization function, but it is always called first. If you run this repeatedly, you'll see thread <code>0</code> gets the initialization often, but not every time. You'll see thread <code>0</code> in the initialization more often on a system with fewer cores.</p>
			<h2 id="_idParaDest-318"><a id="_idTextAnchor317"/>How it works…</h2>
			<p><code>std::call_once</code> is a template function that takes a flag, a <em class="italic">callable</em> (function or functor), and a parameter pack of arguments:</p>
			<pre>template&lt;class Callable, class... Args&gt;
void call_once(once_flag&amp; flag, Callable&amp;&amp; f, Args&amp;&amp;... args);</pre>
			<p>The callable <code>f</code> is called exactly one time. Even if <code>call_once</code> is called concurrently from several threads, <code>f</code> is still called once and only once.</p>
			<p>This requires a <code>std::once_flag</code> object for coordination. The <code>once_flag</code> constructor sets its state to indicate that the callable has not yet been called.</p>
			<p>When <code>call_once</code> invokes<a id="_idIndexMarker928"/> the callable, any other calls<a id="_idIndexMarker929"/> on the same <code>once_flag</code> are blocked until the callable returns. After the callable returns, the <code>once_flag</code> is set, and any subsequent calls to <code>call_once</code> return without invoking <code>f</code>.</p>
			<h1 id="_idParaDest-319"><a id="_idTextAnchor318"/>Use std::condition_variable to resolve the producer-consumer problem</h1>
			<p>The simplest version<a id="_idIndexMarker930"/> of the <em class="italic">producer-consumer problem</em> is where you have one<a id="_idIndexMarker931"/> process that <em class="italic">produces</em> data and another that <em class="italic">consumes</em> data, using one <em class="italic">buffer</em> or container to hold the data. This requires coordination between the producer and consumer to manage the buffer and prevent unwanted side effects.</p>
			<h2 id="_idParaDest-320"><a id="_idTextAnchor319"/>How to do it…</h2>
			<p>In this recipe, we consider a simple solution to the producer-consumer problem using <code>std::condition_variable</code> to coordinate the processes:</p>
			<ul>
				<li>We begin with some namespace and alias declarations for convenience:<pre>using namespace std::chrono_literals;
namespace this_thread = std::this_thread;
using <strong class="bold">guard_t</strong> = std::lock_guard&lt;std::mutex&gt;;
using <strong class="bold">lock_t</strong> = std::unique_lock&lt;std::mutex&gt;;</pre></li>
			</ul>
			<p>The <code>lock_guard</code> and <code>unique_lock</code> aliases make it easier to use these types without error.</p>
			<ul>
				<li>We use a couple of constants:<pre>constexpr size_t num_items{ 10 };
constexpr auto delay_time{ 200ms };</pre></li>
			</ul>
			<p>Keeping these in one place makes it safer and easier to experiment with different values.</p>
			<ul>
				<li>We're using these global<a id="_idIndexMarker932"/> variables for coordinating<a id="_idIndexMarker933"/> the data store:<pre>std::deque&lt;size_t&gt; q{};
std::mutex mtx{};
<strong class="bold">std::condition_variable</strong> cond{};
bool finished{};</pre></li>
			</ul>
			<p>We're using <code>deque</code> to hold<a id="_idIndexMarker934"/> the data as a <strong class="bold">First-In-First-Out</strong> (<strong class="bold">FIFO</strong>) queue.</p>
			<p><code>mutex</code> is used with the <code>condition_variable</code> to coordinate the movement of data from producer to consumer.</p>
			<p>The <code>finished</code> flag indicates that there is no more data.</p>
			<ul>
				<li>The producer thread will use this function:<pre>void producer() {
    for(size_t i{}; i &lt; <strong class="bold">num_items</strong>; ++i) {
        this_thread::<strong class="bold">sleep_for</strong>(delay_time);
        <strong class="bold">guard_t x{ mtx }</strong>;
        q.push_back(i);
        <strong class="bold">cond.notify_all()</strong>;
    }
    <strong class="bold">guard_t x{ mtx }</strong>;
    finished = true;
    <strong class="bold">cond.notify_all()</strong>;
}</pre></li>
			</ul>
			<p>The <code>producer()</code> function loops <code>num_items</code> iterations and pushes a number onto the <code>deque</code> each time through the loop.</p>
			<p>We include a <code>sleep_for()</code> call to simulate<a id="_idIndexMarker935"/> a delay in producing<a id="_idIndexMarker936"/> each value.</p>
			<p>The <code>conditional_variable</code> requires a <code>mutex</code> lock to operate. We use <code>lock_guard</code> (via the <code>guard_t</code> alias) to obtain the lock, then push the value onto the <code>deque</code>, and then call <code>notify_all()</code> on the <code>conditional_variable</code>. This tells the consumer thread that there is a new value available.</p>
			<p>When the loop completes, we set the <code>finished</code> flag and notify the consumer thread that the producer is completed.</p>
			<ul>
				<li>The consumer thread waits for each value from the producer, displays it on the console, and waits for the <code>finished</code> flag:<pre>void consumer() {
    while(<strong class="bold">!finished</strong>) {
        lock_t lck{ mtx };
        <strong class="bold">cond.wait(lck, [] { return !q.empty() || </strong>
<strong class="bold">          finished; })</strong>;
        while(!q.empty()) {
            cout &lt;&lt; format("Got {} from the queue\n",
                q.front());
            q.pop_front();
        }
    }
}</pre></li>
			</ul>
			<p>The <code>wait()</code> method waits to be notified by the producer. It uses the lambda as a predicate to continue waiting until the <code>deque</code> is <em class="italic">not empty</em> or the <code>finished</code> flag is set.</p>
			<p>When we get<a id="_idIndexMarker937"/> a value, we display<a id="_idIndexMarker938"/> it and then pop it from the <code>deque</code>.</p>
			<ul>
				<li>We run this in <code>main()</code> with simple <code>thread</code> objects:<pre>int main() {
    thread t1{ producer };
    thread t2{ consumer };
    t1.join();
    t2.join();
    cout &lt;&lt; "finished!\n";
}</pre></li>
			</ul>
			<p>Output:</p>
			<pre><strong class="bold">Got 0 from the queue</strong>
<strong class="bold">Got 1 from the queue</strong>
<strong class="bold">Got 2 from the queue</strong>
<strong class="bold">Got 3 from the queue</strong>
<strong class="bold">Got 4 from the queue</strong>
<strong class="bold">Got 5 from the queue</strong>
<strong class="bold">Got 6 from the queue</strong>
<strong class="bold">Got 7 from the queue</strong>
<strong class="bold">Got 8 from the queue</strong>
<strong class="bold">Got 9 from the queue</strong>
<strong class="bold">finished!</strong></pre>
			<p>Notice that there's a 200 ms delay between<a id="_idIndexMarker939"/> each line. This tells<a id="_idIndexMarker940"/> us that the producer-consumer coordination is working as expected.</p>
			<h2 id="_idParaDest-321"><a id="_idTextAnchor320"/>How it works…</h2>
			<p>The producer-consumer problem requires coordination between writing and reading a buffer or container. In this example, our container is a <code>deque&lt;size_t&gt;</code>:</p>
			<pre>std::deque&lt;size_t&gt; q{};</pre>
			<p>The <code>condition_variable</code> class can block a thread, or multiple threads, while a shared variable is modified. It may then notify other threads that the value is available.</p>
			<p><code>condition_variable</code> requires a <code>mutex</code> to perform the lock:</p>
			<pre><strong class="bold">std::lock_guard</strong> x{ mtx };
q.push_back(i);
cond.<strong class="bold">notify_all()</strong>;</pre>
			<p>The <code>std::lock_guard</code> acquires a lock, so we can push a value onto our <code>deque</code>.</p>
			<p>The <code>wait()</code> method on <code>condition_variable</code> is used to block the current thread until it receives a notification:</p>
			<pre>void wait( std::unique_lock&lt;std::mutex&gt;&amp; lock );
void wait( std::unique_lock&lt;std::mutex&gt;&amp; lock,
    Pred stop_waiting );</pre>
			<p>The predicate form of <code>wait()</code> is equivalent to:</p>
			<pre>while (!stop_waiting()) {
    wait(lock);
}</pre>
			<p>The predicate form is used to prevent spurious waking while waiting for a specific condition. We use it with a lambda in our example:</p>
			<pre>cond.wait(lck, []{ return !q.empty() || finished; });</pre>
			<p>This prevents our consumer<a id="_idIndexMarker941"/> from waking until the <code>deque</code> has data<a id="_idIndexMarker942"/> or the <code>finished</code> flag is set.</p>
			<p>The <code>condition_variable</code> class has two notification methods:</p>
			<ul>
				<li><code>notify_one()</code> unblocks one waiting thread</li>
				<li><code>notify_all()</code> unblocks all waiting threads</li>
			</ul>
			<p>We used <code>notify_all()</code> in our example. Because there is only one consumer thread, either notification method would work the same.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Note that <code>unique_lock</code> is the <em class="italic">only</em> form of lock<a id="_idIndexMarker943"/> that supports the <code>wait()</code> method on a <code>condition_variable</code> object.</p>
			<h1 id="_idParaDest-322"><a id="_idTextAnchor321"/>Implement multiple producers and consumers</h1>
			<p>The <em class="italic">producer-consumer problem</em> is really a set<a id="_idIndexMarker944"/> of problems. Solutions will differ if the buffer<a id="_idIndexMarker945"/> is bounded or unbounded, or if there are multiple<a id="_idIndexMarker946"/> producers, multiple consumers, or both.</p>
			<p>Let's consider a case with multiple producers, multiple consumers, and a bounded (limited capacity) buffer. This is a common condition.</p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor322"/>How to do it…</h2>
			<p>In this recipe, we'll look at a case with multiple producers and consumers<a id="_idIndexMarker947"/> and a <em class="italic">bounded buffer</em>, using a variety of techniques we've covered in this chapter:</p>
			<ul>
				<li>We'll start with some constants for convenience and reliability:<pre>constexpr auto <code>delay_time</code> is a <code>duration</code> object, used with <code>sleep_for()</code>.</li><li><code>consumer_wait</code> is a <code>duration</code> object, used with the <code>consumer</code> condition variable.</li><li><code>queue_limt</code> is the buffer limit – the maximum number of items in the <code>deque</code>.</li><li><code>num_items</code> is the maximum number of items produced per <code>producer</code>.</li><li><code>num_producers</code> is the number of spawned producers.</li><li><code>num_producers</code> is the number of spawned consumers.</li></ul></li>
				<li>Now, we need some objects<a id="_idIndexMarker948"/> to control<a id="_idIndexMarker949"/> the process:<pre>deque&lt;string&gt; <code>qs</code> is a <code>deque</code> of <code>string</code> that holds the produced objects.</li><li><code>q_mutex</code> controls access to <code>deque</code>.</li><li><code>cv_producer</code> is a condition variable that coordinates producers.</li><li><code>cv_consumer</code> is a condition variable that coordinates consumers.</li><li><code>production_complete</code> is set <code>true</code> when all producer threads have finished.</li></ul></li>
				<li>The <code>producer()</code> threads<a id="_idIndexMarker950"/> run this<a id="_idIndexMarker951"/> function:<pre>void <strong class="bold">producer</strong>(const size_t <strong class="bold">id</strong>) {
    for(size_t i{}; i &lt; <strong class="bold">num_items</strong>; ++i) {
        this_thread::<strong class="bold">sleep_for</strong>(<strong class="bold">delay_time</strong> * id);
        unique_lock&lt;mutex&gt; <strong class="bold">lock</strong>(<strong class="bold">q_mutex</strong>);
        cv_producer.wait(<strong class="bold">lock</strong>,
            [&amp;]{ return qs.size() &lt; <strong class="bold">queue_limit</strong>; });
        qs.<strong class="bold">push_back</strong>(format("pid {}, qs {}, 
          item {:02}\n", id, qs.size(), i + 1));
        cv_consumer.<strong class="bold">notify_all</strong>();
    }
}</pre></li>
			</ul>
			<p>The passed value <code>id</code> is a sequential number used to identify the producer.</p>
			<p>The main <code>for</code> loop repeats <code>num_item</code> times. The <code>sleep_for()</code> function is used to simulate some work required to produce an item.</p>
			<p>Then we obtain a <code>unique_lock</code> from <code>q_mutex</code> and invoke <code>wait()</code> on <code>cv_producer</code>, using a lambda that checks the size of the <code>deque</code> against the <code>queue_limit</code> constant. If the <code>deque</code> has reached maximum size, the <code>producer</code> waits for <code>consumer</code> threads to reduce the size of the <code>deque</code>. This represents the <em class="italic">bounded buffer</em> limit<a id="_idIndexMarker952"/> on the producer.</p>
			<p>Once the condition is satisfied, we push an <em class="italic">item</em> onto the <code>deque</code>. The item is a formatted string with the producer's <code>id</code>, the size of <code>qs</code>, and an item number (<code>i + 1</code>) from the loop control variable.</p>
			<p>Finally, we notify the consumers that new data is available, with <code>notify_all()</code> on the <code>cv_consumer</code> condition variable.</p>
			<ul>
				<li>The <code>consumer()</code> threads<a id="_idIndexMarker953"/> run this<a id="_idIndexMarker954"/> function:<pre>void consumer(const size_t <strong class="bold">id</strong>) {
    while(!<strong class="bold">production_complete</strong>) {
        unique_lock&lt;mutex&gt; lock(<strong class="bold">q_mutex</strong>);
        cv_consumer.<strong class="bold">wait_for</strong>(lock, <strong class="bold">consumer_wait</strong>,
            [&amp;]{ return !qs.empty(); });
        if(!qs.empty()){
            cout &lt;&lt; format("cid {}: {}", id, 
              <strong class="bold">qs.front</strong>());
            qs.<strong class="bold">pop_front</strong>();
        }
        cv_producer.<strong class="bold">notify_all</strong>();
    }
}</pre></li>
			</ul>
			<p>The passed <code>id</code> value is a sequential number used to identify the consumer.</p>
			<p>The main <code>while()</code> loop continues until <code>production_complete</code> is set.</p>
			<p>We obtain <code>unique_lock</code> from <code>q_mutex</code> and invoke <code>wait_for()</code> on <code>cv_consumer</code>, with a timeout and a lambda that tests if the <code>deque</code> is empty. We need the timeout because it's possible for the <code>producer</code> threads to finish while some of the <code>consumer</code> threads are still running, leaving the <code>deque</code> empty.</p>
			<p>Once we have a non-empty <code>deque</code>, we can print (<em class="italic">consume</em>) an <em class="italic">item</em> and pop it off the <code>deque</code>.</p>
			<ul>
				<li>In <code>main()</code>, we use <code>async()</code> to spawn the <code>producer</code> and <code>consumer</code> threads. <code>async()</code> conforms to the RAII<a id="_idIndexMarker955"/> pattern, so I'll usually prefer<a id="_idIndexMarker956"/> it over <code>thread</code>, where possible. <code>async()</code> returns a <code>future</code> object, so we'll keep a list of <code>future&lt;void&gt;</code> objects for process management:<pre>int main() {
    list&lt;<strong class="bold">future&lt;void&gt;</strong>&gt; <strong class="bold">producers</strong>;
    list&lt;<strong class="bold">future&lt;void&gt;</strong>&gt; <strong class="bold">consumers</strong>;
    for(size_t i{}; i &lt; <strong class="bold">num_producers</strong>; ++i) {
        <strong class="bold">producers</strong>.emplace_back(<strong class="bold">async(producer, i)</strong>);
    }
    for(size_t i{}; i &lt; <strong class="bold">num_consumers</strong>; ++i) {
        <strong class="bold">consumers</strong>.emplace_back(<strong class="bold">async(consumer, i)</strong>);
    }
    ...</pre></li>
			</ul>
			<p>We use <code>for</code> loops to create <code>producer</code> and <code>consumer</code> threads.</p>
			<ul>
				<li>Finally, we use <code>list</code> of <code>future</code> objects to determine when our <code>producer</code> and <code>consumer</code> threads are complete:<pre>for(auto&amp; f : <strong class="bold">producers</strong>) f.<strong class="bold">wait()</strong>;
<strong class="bold">production_complete = true</strong>;
cout &lt;&lt; "producers done.\n";
for(auto&amp; f : <strong class="bold">consumers</strong>) f.<strong class="bold">wait()</strong>;
cout &lt;&lt; "consumers done.\n";</pre></li>
			</ul>
			<p>We loop through our <code>producers</code> container, calling <code>wait()</code> to allow the <code>producer</code> threads to complete. Then, we can set the <code>production_complete</code> flag. We likewise loop through the <code>consumers</code> container, calling <code>wait()</code> to allow the <code>consumer</code> threads to complete. We could perform<a id="_idIndexMarker957"/> any final analysis or completion<a id="_idIndexMarker958"/> processes here.</p>
			<ul>
				<li>The output is a bit long to show in its entirety:<pre><strong class="bold">cid 0: pid 0, qs  0, item 01</strong>
<strong class="bold">cid 0: pid 0, qs  1, item 02</strong>
<strong class="bold">cid 0: pid 0, qs  2, item 03</strong>
<strong class="bold">cid 0: pid 0, qs  3, item 04</strong>
<strong class="bold">cid 0: pid 0, qs  4, item 05</strong>
<strong class="bold">...</strong>
<strong class="bold">cid 4: pid 2, qs  0, item 12</strong>
<strong class="bold">cid 4: pid 2, qs  </strong><strong class="bold">0, item 13</strong>
<strong class="bold">cid 3: pid 2, qs  0, item 14</strong>
<strong class="bold">cid 0: pid 2, qs  0, item 15</strong>
<strong class="bold">producers done.</strong>
<strong class="bold">consumers done.</strong></pre></li>
			</ul>
			<h2 id="_idParaDest-324"><a id="_idTextAnchor323"/>How it works…</h2>
			<p>The heart of this recipe is in the use of two <code>condition_variable</code> objects to control the <code>producer</code> and <code>consumer</code> threads asynchronously:</p>
			<pre>condition_variable cv_producer{};
condition_variable cv_consumer{};</pre>
			<p>In the <code>producer()</code> function, the <code>cv_producer</code> object obtains a <code>unique_lock</code>, waits for the <code>deque</code> to be available, and notifies the <code>cv_consumer</code> object when an item has been produced:</p>
			<pre>void producer(const size_t id) {
    for(size_t i{}; i &lt; num_items; ++i) {
        this_thread::sleep_for(delay_time * id);
        <strong class="bold">unique_lock</strong>&lt;mutex&gt; lock(q_mutex);
        <strong class="bold">cv_producer.wait</strong>(lock,
            [&amp;]{ return qs.size() &lt; queue_limit; });
        qs.push_back(format("pid {}, qs  {}, item {:02}\n",
            id, qs.size(), i + 1));
        <strong class="bold">cv_consumer.notify_all</strong>();
    }
}</pre>
			<p>Conversely, in the <code>consumer()</code> function, the <code>cv_consumer</code> object obtains a <code>unique_lock</code>, waits<a id="_idIndexMarker959"/> for the <code>deque</code> to have items, and notifies<a id="_idIndexMarker960"/> the <code>cv_producer</code> object when an item has been consumed:</p>
			<pre>void consumer(const size_t id) {
    while(!production_complete) {
        <strong class="bold">unique_lock</strong>&lt;mutex&gt; lock(q_mutex);
        <strong class="bold">cv_consumer.wait_for</strong>(lock, consumer_wait,
            [&amp;]{ return !qs.empty(); });
        if(!qs.empty()) {
            cout &lt;&lt; format("cid {}: {}", id, qs.front());
            qs.pop_front();
        }
        <strong class="bold">cv_producer.notify_all</strong>();
    }
}</pre>
			<p>These complementary<a id="_idIndexMarker961"/> locks, waits, and notifications constitute the balance <a id="_idIndexMarker962"/>of coordination between multiple producers and consumers.</p>
		</div>
	</body></html>