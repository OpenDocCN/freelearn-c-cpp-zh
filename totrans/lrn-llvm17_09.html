<html><head></head><body><div><p>&#13;
			<h1 id="_idParaDest-115" class="chapter-number"><a id="_idTextAnchor117"/>7</h1>&#13;
			<h1 id="_idParaDest-116"><a id="_idTextAnchor118"/>Optimizing IR</h1>&#13;
			<p>LLVM uses a series of passes to optimize the IR. A pass operates on a unit of IR, such as a function or a module. The operation can be a transformation, which changes the IR in a defined way, or an analysis, which collects information such as dependencies. This series of passes is called the <strong class="bold">pass pipeline</strong>. The<a id="_idIndexMarker399"/> pass manager executes the pass pipeline on the IR, which our compiler produces. Therefore, you need to know what the pass manager does and how to construct a pass pipeline. The semantics of a programming language may require the development of new passes, and we must add these passes to the pipeline.</p>&#13;
			<p>In this chapter, you will learn about the following:</p>&#13;
			<ul>&#13;
				<li>How to leverage the LLVM pass manager to implement passes within LLVM</li>&#13;
				<li>How to implement an instrumentation pass, as an example, within the LLVM project, as well as a separate plugin</li>&#13;
				<li>In using the ppprofiler pass with LLVM tools, you will learn how to use a pass plugin with <code>opt</code> and <code>clang</code></li>&#13;
				<li>In adding an optimization pipeline to your compiler, you will extend the <code>tinylang</code> compiler with an optimization pipeline based on the new pass manager</li>&#13;
			</ul>&#13;
			<p>By the end of this chapter, you will know how to develop a new pass and how you can add it to a pass pipeline. You will also be able to set up the pass pipeline in your compiler.</p>&#13;
			<h1 id="_idParaDest-117"><a id="_idTextAnchor119"/>Technical requirements</h1>&#13;
			<p>The source code for this chapter is available at <a href="https://github.com/PacktPublishing/Learn-LLVM-17/tree/main/Chapter07">https://github.com/PacktPublishing/Learn-LLVM-17/tree/main/Chapter07</a>.</p>&#13;
			<h1 id="_idParaDest-118"><a id="_idTextAnchor120"/>The LLVM pass manager</h1>&#13;
			<p>The LLVM core libraries <a id="_idIndexMarker400"/>optimize the IR that your compiler creates and turn it into object code. This giant task is broken down into separate steps called <strong class="bold">passes</strong>. These<a id="_idIndexMarker401"/> passes need to be executed in the right order, which is the objective of the pass manager.</p>&#13;
			<p>Why not hard-code the order of the passes? The user of your compiler usually expects your compiler to provide a different level of optimization. Developers prefer fast compilation speed over optimization during development time. The final application should run as fast as possible, and your compiler should be able to perform sophisticated optimizations, with longer a compilation time being accepted. A different level of optimization means a different number of optimization passes that need to be executed. Thus, as a compiler writer, you may want to provide your own passes to take advantage of your knowledge of your source language. For example, you may want to replace well-known library functions with inlined IR or even with the precomputed result. For C, such a pass is part of the LLVM libraries, but for other languages, you will need to provide it yourself. After introducing your own passes, you may need to re-order or add some passes. For example, if you know that the operation of your pass leaves some IR code unreachable, then you want to run the dead code removal pass additionally after your pass. The pass manager helps organize these requirements.</p>&#13;
			<p>A pass is often categorized by the scope on which it works:</p>&#13;
			<ul>&#13;
				<li>A <em class="italic">module pass</em> takes <a id="_idIndexMarker402"/>a whole module as input. Such a pass performs its work on the given module and can be used for intra-procedure operations inside this module.</li>&#13;
				<li>A <em class="italic">call graph</em> pass <a id="_idIndexMarker403"/>operates on the <strong class="bold">strongly connected components</strong> (<strong class="bold">SCCs</strong>) of a call graph. It traverses the components in bottom-up order.</li>&#13;
				<li>A <em class="italic">function pass</em> takes <a id="_idIndexMarker404"/>a single function as input and performs its work on this function only.</li>&#13;
				<li>A <em class="italic">loop pass</em> works <a id="_idIndexMarker405"/>on a loop inside a function.</li>&#13;
			</ul>&#13;
			<p>Besides the IR code, a pass may also require, update, or invalidate some analysis results. A lot of different analyses are performed, for example, alias analysis or the construction of a dominator tree. If a pass requires such analyses, then it can request it from an analyses manager. If the information is already computed, then the cached result will be returned. Otherwise, the information will be computed. If a pass changes the IR code, then it needs to announce which analysis results are preserved so that the cached analysis information can be invalidated if necessary.</p>&#13;
			<p>Under the hood, the <a id="_idIndexMarker406"/>pass manager ensures the following:</p>&#13;
			<ul>&#13;
				<li>Analysis results are shared among passes. This requires keeping track of which pass requires which analysis and the state of each analysis. The goal is to avoid needless precomputation of analysis and to free up memory held by analysis results as soon as possible.</li>&#13;
				<li>The passes are executed in a pipeline fashion. For example, if several function passes should be executed in sequence, then the pass manager runs each of these function passes on the first function. Then, it will run all function passes on the second function, and so on. The underlying idea here is to improve the cache behavior as the compiler only performs transformations on a limited set of data (one IR function) and then moves on to the next limited set of data.</li>&#13;
			</ul>&#13;
			<p>Let’s implement a new IR transformation pass and explore how to add it to the optimization pipeline.</p>&#13;
			<h1 id="_idParaDest-119"><a id="_idTextAnchor121"/>Implementing a new pass</h1>&#13;
			<p>A <a id="_idIndexMarker407"/>pass can perform arbitrary complex transformations on the LLVM IR. To illustrate the mechanics of adding a new pass, we add a pass that performs a simple instrumentation.</p>&#13;
			<p>To investigate the performance of a program, it is interesting to know how often functions are called, and how long they run. One way to collect this data is to insert counters into each function. This process <a id="_idIndexMarker408"/>is called <code>ppprofiler</code>. We will develop the new pass so that it can be used as a standalone plugin or added as a plugin to the LLVM source tree. After that, we’ll look at how the passes that come with LLVM are integrated into the framework.</p>&#13;
			<h2 id="_idParaDest-120"><a id="_idTextAnchor122"/>Developing the ppprofiler pass as a plugin</h2>&#13;
			<p>In this<a id="_idIndexMarker409"/> section, we’ll look at creating a new pass as a plugin out of the LLVM tree. The goal of the new pass is to insert a call to the <code>__ppp_enter()</code> function at the entry of a function, and a call to the <code>__ppp_exit()</code> function before each return instruction. Only the name of the current function is passed as a parameter. The implementation of these functions can then count the number of calls and measure the elapsed time. We will implement this runtime support at the end of this chapter. We’ll examine how to develop the pass.</p>&#13;
			<p>We’ll store the source in the <code>PPProfiler.cpp</code> file. Follow these steps:</p>&#13;
			<ol>&#13;
				<li>First, let’s include some files:<pre class="source-code">&#13;
#include "llvm/ADT/Statistic.h"&#13;
#include "llvm/IR/Function.h"&#13;
#include "llvm/IR/PassManager.h"&#13;
#include "llvm/Passes/PassBuilder.h"&#13;
#include "llvm/Passes/PassPlugin.h"&#13;
#include "llvm/Support/Debug.h"</pre></li>				<li>To shorten the source, we’ll tell the compiler that we’re using the <code>llvm</code> namespace:<pre class="source-code">&#13;
using namespace llvm;</pre></li>				<li>The built-in debug infrastructure of LLVM requires that we define a debug type, which is a string. This string is later shown in the printed statistic:<pre class="source-code">&#13;
#define DEBUG_TYPE "ppprofiler"</pre></li>				<li>Next, we’ll define one counter variable with the <code>ALWAYS_ENABLED_STATISTIC</code> macro. The first parameter is the name of the counter variable, while the second parameter is the text that will be printed in the statistic:<pre class="source-code">&#13;
ALWAYS_ENABLED_STATISTIC(&#13;
    NumOfFunc, "Number of instrumented functions.");</pre></li>			</ol>&#13;
			<p class="callout-heading">Note</p>&#13;
			<p class="callout">Two macros can be used to define a counter variable. If you use the <code>STATISTIC</code> macro, then the statistic value will only be collected in a debug build if assertions are enabled, or if <code>LLVM_FORCE_ENABLE_STATS</code> is set to <code>ON</code> on the CMake command line. If you use the <code>ALWAYS_ENABLED_STATISTIC</code> macro instead, then the statistic value is always collected. However, printing the statistics using the<code>–stats</code> command-line option only works with the former methods. If needed, you can print the collected statistics by calling the <code>llvm::PrintStatistics(llvm::raw_ostream)</code> function.</p>&#13;
			<ol>&#13;
				<li value="5">Next, we <a id="_idIndexMarker410"/>must declare the pass class in an anonymous namespace. The class inherits from the <code>PassInfoMixin</code> template. This template only adds some boilerplate code, such as a <code>name()</code> method. It is not used to determine the type of the pass. The <code>run()</code> method is called by LLVM when the pass is executed. We also need a helper method called <code>instrument()</code>:<pre class="source-code">&#13;
namespace {&#13;
class PPProfilerIRPass&#13;
    : public llvm::PassInfoMixin&lt;PPProfilerIRPass&gt; {&#13;
public:&#13;
  llvm::PreservedAnalyses&#13;
  run(llvm::Module &amp;M, llvm::ModuleAnalysisManager &amp;AM);&#13;
private:&#13;
  void instrument(llvm::Function &amp;F,&#13;
                  llvm::Function *EnterFn,&#13;
                  llvm::Function *ExitFn);&#13;
};&#13;
}</pre></li>				<li>Now, let’s define<a id="_idIndexMarker411"/> how a function is instrumented. Besides the function to instrument, the functions to call are passed:<pre class="source-code">&#13;
void PPProfilerIRPass::instrument(llvm::Function &amp;F,&#13;
                                  Function *EnterFn,&#13;
                                  Function *ExitFn) {</pre></li>				<li>Inside the function, we update the statistic counter:<pre class="source-code">&#13;
  ++NumOfFunc;</pre></li>				<li>To easily insert IR code, we need an instance of the <code>IRBuilder</code> class. We will set it to the first basic block, which is the entry block of the function:<pre class="source-code">&#13;
  IRBuilder&lt;&gt; Builder(&amp;*F.getEntryBlock().begin());</pre></li>				<li>Now that we have the builder, we can insert a global constant that holds the name of the function we wish to instrument:<pre class="source-code">&#13;
  GlobalVariable *FnName =&#13;
      Builder.CreateGlobalString(F.getName());</pre></li>				<li>Next, we will insert a call to the <code>__ppp_enter()</code> function, passing the name as an argument:<pre class="source-code">&#13;
  Builder.CreateCall(EnterFn-&gt;getFunctionType(), EnterFn,&#13;
                     {FnName});</pre></li>				<li>To call the <code>__ppp_exit()</code> function, we have to locate all return instructions. Conveniently, the insertion point that’s set by the calling <code>SetInsertionPoint()</code> function is before the instruction that’s passed as a parameter, so <a id="_idIndexMarker412"/>we can just insert the call at that point:<pre class="source-code">&#13;
  for (BasicBlock &amp;BB : F) {&#13;
    for (Instruction &amp;Inst : BB) {&#13;
      if (Inst.getOpcode() == Instruction::Ret) {&#13;
        Builder.SetInsertPoint(&amp;Inst);&#13;
        Builder.CreateCall(ExitFn-&gt;getFunctionType(),&#13;
                           ExitFn, {FnName});&#13;
      }&#13;
    }&#13;
  }&#13;
}</pre></li>				<li>Next, we will implement the <code>run()</code> method. LLVM passes in the module our pass works on and an analysis manager from which we can request analysis results if needed:<pre class="source-code">&#13;
PreservedAnalyses&#13;
PPProfilerIRPass::run(Module &amp;M,&#13;
                      ModuleAnalysisManager &amp;AM) {</pre></li>				<li>There is a slight annoyance here: if the runtime module that contains the implementation of the <code>__ppp_enter()</code> and <code>__ppp_exit()</code> functions are instrumented, then we run into trouble because we create an infinite recursion. To avoid this, we must simply do nothing if one of those functions is defined:<pre class="source-code">&#13;
  if (M.getFunction("__ppp_enter") ||&#13;
      M.getFunction("__ppp_exit")) {&#13;
    return PreservedAnalyses::all();&#13;
  }</pre></li>				<li>Now, we are <a id="_idIndexMarker413"/>ready to declare the functions. There is nothing unusual here: first, the function type is created, followed by the functions:<pre class="source-code">&#13;
  Type *VoidTy = Type::getVoidTy(M.getContext());&#13;
  PointerType *PtrTy =&#13;
      PointerType::getUnqual(M.getContext());&#13;
  FunctionType *EnterExitFty =&#13;
      FunctionType::get(VoidTy, {PtrTy}, false);&#13;
  Function *EnterFn = Function::Create(&#13;
      EnterExitFty, GlobalValue::ExternalLinkage,&#13;
      "__ppp_enter", M);&#13;
  Function *ExitFn = Function::Create(&#13;
      EnterExitFty, GlobalValue::ExternalLinkage,&#13;
      "__ppp_exit", M);</pre></li>				<li>All we need to do now is loop over all the functions of the module and instrument the found functions by calling our <code>instrument()</code> method. Of course, we need to ignore function declarations, which are just prototypes. There can also be functions without a name, which does not work well with our approach. We’ll filter out those functions too:<pre class="source-code">&#13;
  for (auto &amp;F : M.functions()) {&#13;
    if (!F.isDeclaration() &amp;&amp; F.hasName())&#13;
      instrument(F, EnterFn, ExitFn);&#13;
  }</pre></li>				<li>Lastly, we must declare that we did not preserve any analysis. This is most likely too pessimistic but we are on the safe side by doing so:<pre class="source-code">&#13;
  return PreservedAnalyses::none();&#13;
}</pre><p class="list-inset">The <a id="_idIndexMarker414"/>functionality of our new pass is now implemented. To be able to use our pass, we need to register it with the <code>PassBuilder</code> object. This can happen in two ways: statically or dynamically. If the plugin is statically linked, then it needs to provide a function called <code>get&lt;Plugin-Name&gt;PluginInfo()</code>. To use dynamic linking, the <code>llvmGetPassPluginInfo()</code> function needs to be provided. In both cases, an instance of the <code>PassPluginLibraryInfo</code> struct is returned, which provides some basic information about a plugin. Most importantly, this structure contains a pointer to the function that registers the pass. Let’s add this to our source.</p></li>				<li>In the <code>RegisterCB()</code> function, we register a Lambda function that is called when a pass pipeline string is parsed. If the name of the pass is <code>ppprofiler</code>, then we add our pass to the module pass manager. These callbacks will be expanded upon in the next section:<pre class="source-code">&#13;
void RegisterCB(PassBuilder &amp;PB) {&#13;
  PB.registerPipelineParsingCallback(&#13;
      [](StringRef Name, ModulePassManager &amp;MPM,&#13;
         ArrayRef&lt;PassBuilder::PipelineElement&gt;) {&#13;
        if (Name == "ppprofiler") {&#13;
          MPM.addPass(PPProfilerIRPass());&#13;
          return true;&#13;
        }&#13;
        return false;&#13;
      });&#13;
}</pre></li>				<li>The <code>getPPProfilerPluginInfo()</code> function is called when the plugin is statically linked. It returns some basic information about the plugin:<pre class="source-code">&#13;
llvm::PassPluginLibraryInfo getPPProfilerPluginInfo() {&#13;
  return {LLVM_PLUGIN_API_VERSION, "PPProfiler", "v0.1",&#13;
          RegisterCB};&#13;
}</pre></li>				<li>Finally, if the<a id="_idIndexMarker415"/> plugin is dynamically linked, then the <code>llvmGetPassPluginInfo()</code> function is called when the plugin is loaded. However, when linking this code statically into a tool, you might end up with linker errors because that function could be defined in several source files. The solution is to guard the function with a macro:<pre class="source-code">&#13;
#ifndef LLVM_PPPROFILER_LINK_INTO_TOOLS&#13;
extern "C" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo&#13;
llvmGetPassPluginInfo() {&#13;
  return getPPProfilerPluginInfo();&#13;
}&#13;
#endif</pre></li>			</ol>&#13;
			<p>With that, we’ve implemented the pass plugin. Before we look at how to use the new plugin, let’s examine what needs to be changed if we want to add the pass plugin to the LLVM source tree.</p>&#13;
			<h2 id="_idParaDest-121"><a id="_idTextAnchor123"/>Adding the pass to the LLVM source tree</h2>&#13;
			<p>Implementing<a id="_idIndexMarker416"/> a new pass as a plugin is useful if you plan to use it with a precompiled clang, for example. On the other hand, if you write your own compiler, then there can be good reasons to add your new passes directly to the LLVM source tree. There are two different ways you can do this – as a plugin and as a fully integrated pass. The plugin approach requires fewer changes.</p>&#13;
			<h3>Utilizing the plugin mechanisms inside the LLVM source tree</h3>&#13;
			<p>The <a id="_idIndexMarker417"/>source of passes that perform transformations on LLVM IR is located in the <code>llvm-project/llvm/lib/Transforms</code> directory. Inside this directory, create a new directory called <code>PPProfiler</code> and copy the source file, <code>PPProfiler.cpp</code>, into it. You do not need to make any source changes!</p>&#13;
			<p>To integrate the new plugin into the build system, create a file called <code>CMakeLists.txt</code> with the following content:</p>&#13;
			<pre class="source-code">&#13;
add_llvm_pass_plugin(PPProfiler PPProfiler.cpp)</pre>			<p>Finally, in the <code>CmakeLists.txt</code> file in the parent directory, you need to include the new source directory by adding the following line:</p>&#13;
			<pre class="source-code">&#13;
add_subdirectory(PPProfiler)</pre>			<p>You are now ready to build LLVM with <code>PPProfiler</code> added. Change into the build directory of LLVM and manually run Ninja:</p>&#13;
			<pre class="console">&#13;
$ ninja install</pre>			<p>CMake will detect a change in the build description and rerun the configuration step. You will see an additional line:</p>&#13;
			<pre class="console">&#13;
-- Registering PPProfiler as a pass plugin (static build: OFF)</pre>			<p>This tells you that the plugin was detected and has been built as a shared library. After the installation step, you will find that shared library, <code>PPProfiler.so</code>, in the <code>&lt;install </code><code>directory&gt;/lib</code> directory.</p>&#13;
			<p>So far, the only difference to the pass plugin from the previous section is that the shared library is installed as part of LLVM. But you can also statically link the new plugin to the LLVM tools. To<a id="_idIndexMarker418"/> do this, you need to rerun the CMake configuration and add the <code>-DLLVM_PPPROFILER_LINK_INTO_TOOLS=ON</code> option on the command line. Look for this information from CMake to confirm the changed build option:</p>&#13;
			<pre class="console">&#13;
-- Registering PPProfiler as a pass plugin (static build: ON)</pre>			<p>After compiling and installing LLVM again, the following has changed:</p>&#13;
			<ul>&#13;
				<li>The plugin is compiled into the static library, <code>libPPProfiler.a</code>, and that library is installed in the <code>&lt;install </code><code>directory&gt;/lib</code> directory.</li>&#13;
				<li>The LLVM tools, such as <strong class="bold">opt</strong>, are linked against that library.</li>&#13;
				<li>The plugin is registered as an extension. You can check that the <code>&lt;install directory&gt;/include/llvm/Support/Extension.def</code> file now contains the following line:<pre class="source-code">&#13;
HANDLE_EXTENSION(PPProfiler)</pre></li>			</ul>&#13;
			<p>In addition, all tools that support this extension mechanism pick up the new pass. In the <em class="italic">Creating an optimization pipeline</em> section, you will learn how to do this in your compiler.</p>&#13;
			<p>This approach works well because the new source files reside in a separate directory, and only one existing file was changed. This minimizes the probability of merge conflicts if you try to keep your modified LLVM source tree in sync with the main repository.</p>&#13;
			<p>There are also situations where adding the new pass as a plugin is not the best way. The passes that LLVM provides use a different way for registration. If you develop a new pass and propose to add it to LLVM, and the LLVM community accepts your contribution, then you will want to use the same registration mechanism.</p>&#13;
			<h3>Fully integrating the pass into the pass registry</h3>&#13;
			<p>To fully integrate <a id="_idIndexMarker419"/>the new pass into LLVM, the source of the plugin needs to be structured slightly differently. The main reason for this is that the constructor of the pass class is called from the pass registry, which requires the class interface to be put into a header file.</p>&#13;
			<p>Like before, you<a id="_idIndexMarker420"/> must put the new pass into the <code>Transforms</code> component of LLVM. Begin the implementation by creating the <code>llvm-project/llvm/include/llvm/Transforms/PPProfiler/PPProfiler.h</code> header file. The content of that file is the class definition; put it into the <code>llvm</code> namespace. No other changes are required:</p>&#13;
			<pre class="source-code">&#13;
#ifndef LLVM_TRANSFORMS_PPPROFILER_PPPROFILER_H&#13;
#define LLVM_TRANSFORMS_PPPROFILER_PPPROFILER_H&#13;
#include "llvm/IR/PassManager.h"&#13;
namespace llvm {&#13;
class PPProfilerIRPass&#13;
    : public llvm::PassInfoMixin&lt;PPProfilerIRPass&gt; {&#13;
public:&#13;
  llvm::PreservedAnalyses&#13;
  run(llvm::Module &amp;M, llvm::ModuleAnalysisManager &amp;AM);&#13;
private:&#13;
  void instrument(llvm::Function &amp;F,&#13;
                  llvm::Function *EnterFn,&#13;
                  llvm::Function *ExitFn);&#13;
};&#13;
} // namespace llvm&#13;
#endif</pre>			<p>Next, copy the source file of the pass plugin, <code>PPProfiler.cpp</code>, into the new directory, <code>llvm-project/llvm/lib/Transforms/PPProfiler</code>. This file needs to be <a id="_idIndexMarker421"/>updated in the following way:</p>&#13;
			<ol>&#13;
				<li>Since the class definition is now in a header file, you must remove the class definition from this file. At the top, add the <code>#include</code> directive for the header file:<pre class="source-code">&#13;
#include "llvm/Transforms/PPProfiler/PPProfiler.h"</pre></li>				<li>The <code>llvmGetPassPluginInfo()</code> function must be removed because the pass wasn’t built into a shared library of its own.</li>&#13;
			</ol>&#13;
			<p>As before, you also need to provide a <code>CMakeLists.txt</code> file for the build. You must declare the new pass as a new component:</p>&#13;
			<pre class="source-code">&#13;
add_llvm_component_library(LLVMPPProfiler&#13;
  PPProfiler.cpp&#13;
  LINK_COMPONENTS&#13;
  Core&#13;
  Support&#13;
)</pre>			<p>After, like in the previous section, you need to include the new source directory by adding the following line to the <code>CMakeLists.txt</code> file in the parent directory:</p>&#13;
			<pre class="source-code">&#13;
add_subdirectory(PPProfiler)</pre>			<p>Inside LLVM, the available passes are kept in the <code>llvm/lib/Passes/ PassRegistry.def</code> database file. You need to update this file. The new pass is a module pass, so we need to search inside the file for the section in which module passes are defined, for example, by searching for the <code>MODULE_PASS</code> macro. Inside this section, add the following line:</p>&#13;
			<pre class="source-code">&#13;
MODULE_PASS("ppprofiler", PPProfilerIRPass())</pre>			<p>This database file is used in the <code>llvm/lib/Passes/PassBuilder.cpp</code> class. This file needs to include your new header file:</p>&#13;
			<pre class="source-code">&#13;
#include "llvm/Transforms/PPProfiler/PPProfiler.h"</pre>			<p>These are <a id="_idIndexMarker422"/>all required source changes based on the plugin version of the new pass.</p>&#13;
			<p>Since you created a new LLVM component, it is also necessary to add a link dependency in the <code>llvm/lib/Passes/CMakeLists.txt</code> file. Under the <code>LINK_COMPONENTS</code> keyword, you need to add a line with the name of the new component:</p>&#13;
			<pre class="source-code">&#13;
  PPProfiler</pre>			<p>Et voilà – you are ready to build and install LLVM. The new pass, <code>ppprofiler</code>, is now available to all LLVM tools. It has been compiled into the <code>libLLVMPPProfiler.a</code> library and available in the build system as the <code>PPProfiler</code> component.</p>&#13;
			<p>So far, we have talked about how to create a new pass. In the next section, we will examine how to use the <code>ppprofiler</code> pass.</p>&#13;
			<h1 id="_idParaDest-122"><a id="_idTextAnchor124"/>Using the ppprofiler pass with LLVM tools</h1>&#13;
			<p>Recall<a id="_idIndexMarker423"/> the ppprofiler pass that we developed as a plugin out of the LLVM tree in the <em class="italic">Developing the ppprofiler pass as a plugin</em> section. Here, we’ll learn how to use this pass with LLVM tools, such as <code>opt</code> and <code>clang</code>, as they can load plugins.</p>&#13;
			<p>Let’s look at <code>opt</code> first.</p>&#13;
			<h3>Run the pass plugin in opt</h3>&#13;
			<p>To play <a id="_idIndexMarker424"/>around with the new plugin, you need a file containing LLVM IR. The easiest way to do this is to translate a C program, such as a basic “Hello World” style program:</p>&#13;
			<pre class="source-code">&#13;
#include &lt;stdio.h&gt;&#13;
int main(int argc, char *argv[]) {&#13;
  puts("Hello");&#13;
  return 0;&#13;
}</pre>			<p>Compile this file, <code>hello.c</code>, with <code>clang</code>:</p>&#13;
			<pre class="console">&#13;
$ clang -S -emit-llvm -O1 hello.c</pre>			<p>You will <a id="_idIndexMarker425"/>get a very simple IR file called <code>hello.ll</code> that contains the following code:</p>&#13;
			<pre class="console">&#13;
$ cat hello.ll&#13;
@.str = private unnamed_addr constant [6 x i8] c"Hello\00",&#13;
        align 1&#13;
define dso_local i32 @main(&#13;
          i32 noundef %0, ptr nocapture noundef readnone %1) {&#13;
  %3 = tail call i32 @puts(&#13;
                 ptr noundef nonnull dereferenceable(1) @.str)&#13;
  ret i32 0&#13;
}</pre>			<p>This is enough to test the pass.</p>&#13;
			<p>To run the pass, you have to provide a couple of arguments. First, you need to tell <code>opt</code> to load the shared library via the <code>--load-pass-plugin</code> option. To run a single pass, you must specify the<code>–-passes</code> option. Using the <code>hello.ll</code> file as input, you can run the following:</p>&#13;
			<pre class="console">&#13;
$ opt --load-pass-plugin=./PPProfile.so \&#13;
      --passes="ppprofiler" --stats hello.ll -o hello_inst.bc</pre>			<p>If statistic generation is enabled, you will see the following output:</p>&#13;
			<pre class="console">&#13;
===--------------------------------------------------------===&#13;
                 ... Statistics Collected ...&#13;
===--------------------------------------------------------===&#13;
1 ppprofiler - Number of instrumented functions.</pre>			<p>Otherwise, you<a id="_idIndexMarker426"/> will be informed that statistic collection is not enabled:</p>&#13;
			<pre class="console">&#13;
Statistics are disabled.  Build with asserts or with&#13;
-DLLVM_FORCE_ENABLE_STATS</pre>			<p>The bitcode file, <code>hello_inst.bc</code>, is the result. You can turn this file into readable IR with the <code>llvm-dis</code> tool. As expected, you will see the calls to the <code>__ppp_enter()</code> and <code>__ppp_exit()</code> functions and a new constant for the name of the function:</p>&#13;
			<pre class="console">&#13;
$ llvm-dis hello_inst.bc -o –&#13;
@.str = private unnamed_addr constant [6 x i8] c"Hello\00",&#13;
        align 1&#13;
@0 = private unnamed_addr constant [5 x i8] c"main\00",&#13;
     align 1&#13;
define dso_local i32 @main(i32 noundef %0,&#13;
                          ptr nocapture noundef readnone %1) {&#13;
  call void @__ppp_enter(ptr @0)&#13;
  %3 = tail call i32 @puts(&#13;
                 ptr noundef nonnull dereferenceable(1) @.str)&#13;
  call void @__ppp_exit(ptr @0)&#13;
  ret i32 0&#13;
}</pre>			<p>This already looks good! It would be even better if we could turn this IR into an executable and run it. For this, you need to provide implementations for the called functions.</p>&#13;
			<p>Often, the<a id="_idIndexMarker427"/> runtime support for a feature is more complicated than adding that feature to the compiler itself. This is also true in this case. When the <code>__ppp_enter()</code> and <code>__ppp_exit()</code> functions are called, you can view this as an event. To analyze the data later, it is necessary to save the events. The basic data you would like to get is the event of the type, the name of the function and its address, and a timestamp. Without tricks, this is not as easy as it seems. Let’s give it a try.</p>&#13;
			<p>Create a file called <code>runtime.c</code> with the following content:</p>&#13;
			<ol>&#13;
				<li>You need the file I/O, standard functions, and time support. This is provided by the following includes:<pre class="source-code">&#13;
#include &lt;stdio.h&gt;&#13;
#include &lt;stdlib.h&gt;&#13;
#include &lt;time.h&gt;</pre></li>				<li>For the file, a file descriptor is needed. Moreover, when the program finishes, that file descriptor should be closed properly:<pre class="source-code">&#13;
static FILE *FileFD = NULL;&#13;
static void cleanup() {&#13;
  if (FileFD == NULL) {&#13;
    fclose(FileFD);&#13;
    FileFD = NULL;&#13;
  }&#13;
}</pre></li>				<li>To simplify the runtime, only a fixed name for the output is used. If the file is not open, then open the file and register the <code>cleanup</code> function:<pre class="source-code">&#13;
static void init() {&#13;
  if (FileFD == NULL) {&#13;
    FileFD = fopen("ppprofile.csv", "w");&#13;
    atexit(&amp;cleanup);&#13;
  }&#13;
}</pre></li>				<li>You can <a id="_idIndexMarker428"/>call the <code>clock_gettime()</code> function to get a timestamp. The <code>CLOCK_PROCESS_CPUTIME_ID</code> parameter returns the time consumed by this process. Please note that not all systems support this parameter. You can use one of the other clocks, such as <code>CLOCK_REALTIME</code>, if necessary:<pre class="source-code">&#13;
typedef unsigned long long Time;&#13;
static Time get_time() {&#13;
  struct timespec ts;&#13;
  clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &amp;ts);&#13;
  return 1000000000L * ts.tv_sec + ts.tv_nsec;&#13;
}</pre></li>				<li>Now, it is easy to define the <code>__ppp_enter()</code> function. Just make sure the file is open, get the timestamp, and write the event:<pre class="source-code">&#13;
void __ppp_enter(const char *FnName) {&#13;
  init();&#13;
  Time T = get_time();&#13;
  void *Frame = __builtin_frame_address(1);&#13;
  fprintf(FileFD,&#13;
          // "enter|name|clock|frame"&#13;
          „enter|%s|%llu|%p\n", FnName, T, Frame);&#13;
}</pre></li>				<li>The <code>__ppp_exit()</code> function only differs in terms of the event type:<pre class="source-code">&#13;
void __ppp_exit(const char *FnName) {&#13;
  init();&#13;
  Time T = get_time();&#13;
  void *Frame = __builtin_frame_address(1);&#13;
  fprintf(FileFD,&#13;
          // "exit|name|clock|frame"&#13;
          „exit|%s|%llu|%p\n", FnName, T, Frame);&#13;
}</pre></li>			</ol>&#13;
			<p>That<a id="_idIndexMarker429"/> concludes a very simple implementation for runtime support. Before we try it, some remarks should be made about the implementation as it should be obvious that there are several problematic parts.</p>&#13;
			<p>First of all, the implementation is not thread-safe since there is only one file descriptor, and access to it is not protected. Trying to use this runtime implementation with a multithreaded program will most likely lead to disturbed data in the output file.</p>&#13;
			<p>In addition, we omitted checking the return value of the I/O-related functions, which can result in data loss.</p>&#13;
			<p>But most importantly, the timestamp of the event is not precise. Calling a function already adds overhead, but performing I/O operations in that function makes it even worse. In principle, you can match the enter and exit events for a function and calculate the runtime of the function. However, this value is inherently flawed because it may include the time required for I/O. In summary, do not trust the times recorded here.</p>&#13;
			<p>Despite all the flaws, this small runtime file allows us to produce some output. Compile the bitcode of the instrumented file together with the file containing the runtime code and run the resulting executable:</p>&#13;
			<pre class="console">&#13;
$ clang hello_inst.bc runtime.c&#13;
$ ./a.out</pre>			<p>This results in a <a id="_idIndexMarker430"/>new file called <code>ppprofile.csv</code> in the directory that contains the following content:</p>&#13;
			<pre class="console">&#13;
$ cat ppprofile.csv&#13;
enter|main|3300868|0x1&#13;
exit|main|3760638|0x1</pre>			<p>Cool – the new pass and the runtime seem to work!</p>&#13;
			<p class="callout-heading">Specifying a pass pipeline</p>&#13;
			<p class="callout">With the <code>–-passes</code> option, you can not only name a single pass but you can also describe a whole pipeline. For example, the default pipeline for optimization level 2 is named <code>default&lt;O2&gt;</code>. You can run the <code>ppprofile</code> pass before the default pipeline with the<code>–-passes="ppprofile,default&lt;O2&gt;"</code> argument. Please note that the pass names in such a pipeline description must be of the same type.</p>&#13;
			<p>Now, let’s turn to using the new pass with <code>clang</code>.</p>&#13;
			<h3>Plugging the new pass into clang</h3>&#13;
			<p>In the<a id="_idIndexMarker431"/> previous section, you learned how you can run a single pass using <code>opt</code>. This is useful if you need to debug a pass but for a real compiler, the steps should not be that involved.</p>&#13;
			<p>To achieve the best result, a compiler needs to run the optimization passes in a certain order. The LLVM pass manager <a id="_idIndexMarker432"/>has a default order for pass execution. This is also called the <code>opt</code>, you can specify a different pass pipeline with the <code>–passes</code> option. This is flexible but also complicated for the user. It also turns out that most of the time, you just want to add a new pass at very specific points, such as before optimization passes are run or at the end of the loop optimization processes. These points are<a id="_idIndexMarker433"/> called <code>PassBuilder</code> class allows you to register a pass at an extension point. For example, you can call the <code>registerPipelineStartEPCallback()</code> method to add a pass to the beginning of the optimization pipeline. This is exactly the place we need for the <code>ppprofiler</code> pass. During optimization, functions may be inlined, and the pass will miss those inline functions. Instead, running the pass before the optimization passes guarantees that all functions are instrumented.</p>&#13;
			<p>To use this<a id="_idIndexMarker434"/> approach, you need to extend the <code>RegisterCB()</code> function in the pass plugin. Add the following code to the function:</p>&#13;
			<pre class="source-code">&#13;
  PB.registerPipelineStartEPCallback(&#13;
      [](ModulePassManager &amp;PM, OptimizationLevel Level) {&#13;
        PM.addPass(PPProfilerIRPass());&#13;
      });</pre>			<p>Whenever the pass manager populates the default pass pipeline, it calls all the callbacks for the extension points. We simply add the new pass here.</p>&#13;
			<p>To load the plugin into <code>clang</code>, you can use the <code>-fpass-plugin</code> option. Creating the instrumented executable of the <code>hello.c</code> file now becomes almost trivial:</p>&#13;
			<pre class="console">&#13;
$ clang -fpass-plugin=./PPProfiler.so hello.c runtime.c</pre>			<p>Please run the executable and verify that the run creates the <code>ppprofiler.csv</code> file.</p>&#13;
			<p class="callout-heading">Note</p>&#13;
			<p class="callout">The <code>runtime.c</code> file is not instrumented because the pass checks that the special functions are not yet declared in a module.</p>&#13;
			<p>This already looks better, but does it scale to larger programs? Let’s assume you want to build an instrumented binary of the <code>tinylang</code> compiler for <a href="B19561_05.xhtml#_idTextAnchor091"><em class="italic">Chapter 5</em></a>. How would you do this?</p>&#13;
			<p>You can pass compiler and linker flags on the CMake command line, which is exactly what we need. The flags for the C++ compiler are given in the <code>CMAKE_CXX_FLAGS</code> variable. Thus, specifying the following on the CMake command line adds the new pass to all compiler runs:</p>&#13;
			<pre class="source-code">&#13;
-DCMAKE_CXX_FLAGS="-fpass-plugin=&lt;PluginPath&gt;/PPProfiler.so"</pre>			<p>Please <a id="_idIndexMarker435"/>replace <code>&lt;PluginPath&gt;</code> with the absolute path to the shared library.</p>&#13;
			<p>Similarly, specifying the following adds the <code>runtime.o</code> file to each linker invocation. Again, please replace <code>&lt;RuntimePath&gt;</code> with the absolute path to a compiled version of <code>runtime.c</code>:</p>&#13;
			<pre class="source-code">&#13;
-DCMAKE_EXE_LINKER_FLAGS="&lt;RuntimePath&gt;/runtime.o"</pre>			<p>Of course, this requires <code>clang</code> as the build compiler. The fastest way to make sure <code>clang</code> is used as the build compiler is to set the <code>CC</code> and <code>CXX</code> environment variables accordingly:</p>&#13;
			<pre class="source-code">&#13;
export CC=clang&#13;
export CXX=clang++</pre>			<p>With these additional options, the CMake configuration from <a href="B19561_05.xhtml#_idTextAnchor091"><em class="italic">Chapter 5</em></a> should run as usual.</p>&#13;
			<p>After building the <code>tinylang</code> executable, you can run it with the example <code>Gcd.mod</code> file. The <code>ppprofile.csv</code> file will also be written, this time with more than 44,000 lines!</p>&#13;
			<p>Of course, having such a dataset raises the question of if you can get something useful out of it. For example, getting a list of the 10 most often called functions, together with the call count and the time spent in the function, would be useful information. Luckily, on a Unix system, you have a couple of tools that can help. Let’s build a short pipeline that matches enter events with exit events, counts the functions, and displays the top 10 functions. The <code>awk</code> Unix tool helps with most of these steps.</p>&#13;
			<p>To match an enter event with an exit event, the enter event must be stored in the <code>record</code> associative map. When an exit event is matched, the stored enter event is looked up, and the new record is written. The emitted line contains the timestamp from the enter event, the timestamp from the exit event, and the difference between both. We must put this into the <code>join.awk</code> file:</p>&#13;
			<pre class="source-code">&#13;
BEGIN { FS = "|"; OFS = "|" }&#13;
/enter/ { record[$2] = $0 }&#13;
/exit/ { split(record[$2],val,"|")&#13;
         print val[2], val[3], $3, $3-val[3], val[4] }</pre>			<p>To count <a id="_idIndexMarker436"/>the function calls and the execution, two associative maps, <code>count</code> and <code>sum</code>, are used. In <code>count</code>, the function calls are counted, while in <code>sum</code>, the execution time is added. In the end, the maps are dumped. You can put this into the <code>avg.awk</code> file:</p>&#13;
			<pre class="source-code">&#13;
BEGIN { FS = "|"; count[""] = 0; sum[""] = 0 }&#13;
{ count[$1]++; sum[$1] += $4 }&#13;
END { for (i in count) {&#13;
        if (i != "") {&#13;
          print count[i], sum[i], sum[i]/count[i], I }&#13;
} }</pre>			<p>After running these two scripts, the result can be sorted in descending order, and then the top 10 lines can be taken from the file. However, we can still improve the function names, <code>__ppp_enter()</code> and <code>__ppp_exit()</code>, which are mangled and are therefore difficult to read. Using the <code>llvm-cxxfilt</code> tool, the names can be demangled. The <code>demangle.awk</code> script is as follows:</p>&#13;
			<pre class="source-code">&#13;
{ cmd = "llvm-cxxfilt " $4&#13;
  (cmd) | getline name&#13;
  close(cmd); $4 = name; print }</pre>			<p>To get the top 10 function calls, you can run the following:</p>&#13;
			<pre class="console">&#13;
$ cat ppprofile.csv | awk -f join.awk | awk -f avg.awk |\&#13;
  sort -nr | head -15 | awk -f demangle.awk</pre>			<p>Here are some sample lines from the output:</p>&#13;
			<pre class="source-code">&#13;
446 1545581 3465.43 charinfo::isASCII(char)&#13;
409 826261 2020.2 llvm::StringRef::StringRef()&#13;
382 899471 2354.64&#13;
           tinylang::Token::is(tinylang::tok::TokenKind) const&#13;
171 1561532 9131.77 charinfo::isIdentifierHead(char)</pre>			<p>The <a id="_idIndexMarker437"/>first number is the call count of the function, the second is the cumulated execution time, and the third number is the average execution time. As explained previously, do not trust the time values, though the call counts should be accurate.</p>&#13;
			<p>So far, we’ve implemented a new instrumentation pass, either as a plugin or as an addition to LLVM, and we used it in some real-world scenarios. In the next section, we’ll explore how to set up an optimization pipeline in our compiler.</p>&#13;
			<h1 id="_idParaDest-123"><a id="_idTextAnchor125"/>Adding an optimization pipeline to your compiler</h1>&#13;
			<p>The <code>tinylang</code> compiler <a id="_idIndexMarker438"/>we developed in the<a id="_idIndexMarker439"/> previous chapters performs no optimizations on the IR code. In the next few subsections, we’ll add an optimization pipeline to the compiler to achieve this accordingly.</p>&#13;
			<h2 id="_idParaDest-124"><a id="_idTextAnchor126"/>Creating an optimization pipeline</h2>&#13;
			<p>The <code>PassBuilder</code> class is<a id="_idIndexMarker440"/> central to setting up the optimization pipeline. This class knows about all registered passes and can construct a pass pipeline from a textual description. We can use this class to either create the pass pipeline from a description given on the command line or use a default pipeline based on the requested optimization level. We also support the use of pass plugins, such as the <code>ppprofiler</code> pass plugin we discussed in the previous section. With this, we can mimic part of the functionality <a id="_idIndexMarker441"/>of the <strong class="bold">opt</strong> tool and also use similar names for the command-line options.</p>&#13;
			<p>The <code>PassBuilder</code> class populates an instance of a <code>ModulePassManager</code> class, which is the pass manager that holds the constructed pass pipeline and runs it. The code generation passes still use the old pass manager. Therefore, we have to retain the old pass manager for this purpose.</p>&#13;
			<p>For the implementation, we will extend the <code>tools/driver/Driver.cpp</code> file from our <code>tinylang</code> compiler:</p>&#13;
			<ol>&#13;
				<li>We’ll use new classes, so we’ll begin with adding new include files. The <code>llvm/Passes/PassBuilder.h</code> file defines the <code>PassBuilder</code> class. The <code>llvm/Passes/PassPlugin.h</code> file is required for plugin support. Finally, the <code>llvm/Analysis/TargetTransformInfo.h</code> file provides a pass that connects IR-level transformations with target-specific information:<pre class="source-code">&#13;
#include "llvm/Passes/PassBuilder.h"&#13;
#include "llvm/Passes/PassPlugin.h"&#13;
#include "llvm/Analysis/TargetTransformInfo.h"</pre></li>				<li>To use<a id="_idIndexMarker442"/> certain features of the new pass manager, we must add three command-line options, using the same names as the <code>opt</code> tool does. The <code>--passes</code> option allows the textual specification of the pass pipeline, while the <code>--load-pass-plugin</code> option allows the use of pass plugins. If the <code>--debug-pass-manager</code> option is given, then the pass manager prints out information about the executed passes:<pre class="source-code">&#13;
static cl::opt&lt;bool&gt;&#13;
    DebugPM("debug-pass-manager", cl::Hidden,&#13;
            cl::desc("Print PM debugging information"));&#13;
static cl::opt&lt;std::string&gt; PassPipeline(&#13;
    "passes",&#13;
    cl::desc("A description of the pass pipeline"));&#13;
static cl::list&lt;std::string&gt; PassPlugins(&#13;
    "load-pass-plugin",&#13;
    cl::desc("Load passes from plugin library"));</pre></li>				<li>The user influences the construction of the pass pipeline with the optimization level. The <code>PassBuilder</code> class supports six different optimization levels: no optimization, three levels for optimizing speed, and two levels for reducing size. We can <a id="_idIndexMarker443"/>capture all levels in one command-line option:<pre class="source-code">&#13;
static cl::opt&lt;signed char&gt; OptLevel(&#13;
    cl::desc("Setting the optimization level:"),&#13;
    cl::ZeroOrMore,&#13;
    cl::values(&#13;
        clEnumValN(3, "O", "Equivalent to -O3"),&#13;
        clEnumValN(0, "O0", "Optimization level 0"),&#13;
        clEnumValN(1, "O1", "Optimization level 1"),&#13;
        clEnumValN(2, "O2", "Optimization level 2"),&#13;
        clEnumValN(3, "O3", "Optimization level 3"),&#13;
        clEnumValN(-1, "Os",&#13;
                   "Like -O2 with extra optimizations "&#13;
                   "for size"),&#13;
        clEnumValN(&#13;
            -2, "Oz",&#13;
            "Like -Os but reduces code size further")),&#13;
    cl::init(0));</pre></li>				<li>The plugin mechanism of LLVM supports a plugin registry for statically linked plugins, which is created during the configuration of the project. To make use of this registry, we must include the <code>llvm/Support/Extension.def</code> database file to create the prototype for the functions that return the plugin information:<pre class="source-code">&#13;
#define HANDLE_EXTENSION(Ext)                          \&#13;
  llvm::PassPluginLibraryInfo get##Ext##PluginInfo();&#13;
#include "llvm/Support/Extension.def"</pre></li>				<li>Now, we <a id="_idIndexMarker444"/>must replace the existing <code>emit()</code> function with a new version. Additionally, we must declare the required <code>PassBuilder</code> instance at the top of the function:<pre class="source-code">&#13;
bool emit(StringRef Argv0, llvm::Module *M,&#13;
          llvm::TargetMachine *TM,&#13;
          StringRef InputFilename) {&#13;
  PassBuilder PB(TM);</pre></li>				<li>To implement the support for pass plugins given on the command line, we must loop through the list of plugin libraries given by the user and try to load the plugin. We’ll emit an error message if this fails; otherwise, we’ll register the passes:<pre class="source-code">&#13;
  for (auto &amp;PluginFN : PassPlugins) {&#13;
    auto PassPlugin = PassPlugin::Load(PluginFN);&#13;
    if (!PassPlugin) {&#13;
      WithColor::error(errs(), Argv0)&#13;
          &lt;&lt; "Failed to load passes from '" &lt;&lt; PluginFN&#13;
          &lt;&lt; "'. Request ignored.\n";&#13;
      continue;&#13;
    }&#13;
    PassPlugin-&gt;registerPassBuilderCallbacks(PB);&#13;
  }</pre></li>				<li>The information<a id="_idIndexMarker445"/> from the static plugin registry is used in a similar way to register those plugins with our <code>PassBuilder</code> instance:<pre class="source-code">&#13;
#define HANDLE_EXTENSION(Ext)                          \&#13;
  get##Ext##PluginInfo().RegisterPassBuilderCallbacks( \&#13;
      PB);&#13;
#include "llvm/Support/Extension.def"</pre></li>				<li>Now, we need to declare variables for the different analysis managers. The only parameter is the debug flag:<pre class="source-code">&#13;
  LoopAnalysisManager LAM(DebugPM);&#13;
  FunctionAnalysisManager FAM(DebugPM);&#13;
  CGSCCAnalysisManager CGAM(DebugPM);&#13;
  ModuleAnalysisManager MAM(DebugPM);</pre></li>				<li>Next, we must populate the analysis managers with calls to the respective <code>register</code> method on the <code>PassBuilder</code> instance. Through this call, the analysis manager is populated with the default analysis passes and also runs registration callbacks. We must also make sure that the function analysis manager uses the default alias-analysis pipeline and that all analysis managers know about each other:<pre class="source-code">&#13;
  FAM.registerPass(&#13;
      [&amp;] { return PB.buildDefaultAAPipeline(); });&#13;
  PB.registerModuleAnalyses(MAM);&#13;
  PB.registerCGSCCAnalyses(CGAM);&#13;
  PB.registerFunctionAnalyses(FAM);&#13;
  PB.registerLoopAnalyses(LAM);&#13;
  PB.crossRegisterProxies(LAM, FAM, CGAM, MAM);</pre></li>				<li>The <code>MPM</code> module pass manager holds the pass pipeline that we constructed. The instance is initialized with the debug flag:<pre class="source-code">&#13;
  ModulePassManager MPM(DebugPM);</pre></li>				<li>Now, we <a id="_idIndexMarker446"/>need to implement two different ways to populate the module pass manager with the pass pipeline. If the user provided a pass pipeline on the command line – that is, they have used the <code>--passes</code> option – then we use this as the pass pipeline:<pre class="source-code">&#13;
  if (!PassPipeline.empty()) {&#13;
    if (auto Err = PB.parsePassPipeline(&#13;
            MPM, PassPipeline)) {&#13;
      WithColor::error(errs(), Argv0)&#13;
          &lt;&lt; toString(std::move(Err)) &lt;&lt; "\n";&#13;
      return false;&#13;
    }&#13;
  }</pre></li>				<li>Otherwise, we use the chosen optimization level to determine the pass pipeline to construct. The name of the default pass pipeline is <code>default</code>, and it takes the optimization level as a parameter:<pre class="source-code">&#13;
  else {&#13;
    StringRef DefaultPass;&#13;
    switch (OptLevel) {&#13;
    case 0: DefaultPass = "default&lt;O0&gt;"; break;&#13;
    case 1: DefaultPass = "default&lt;O1&gt;"; break;&#13;
    case 2: DefaultPass = "default&lt;O2&gt;"; break;&#13;
    case 3: DefaultPass = "default&lt;O3&gt;"; break;&#13;
    case -1: DefaultPass = "default&lt;Os&gt;"; break;&#13;
    case -2: DefaultPass = "default&lt;Oz&gt;"; break;&#13;
    }&#13;
    if (auto Err = PB.parsePassPipeline(&#13;
            MPM, DefaultPass)) {&#13;
      WithColor::error(errs(), Argv0)&#13;
          &lt;&lt; toString(std::move(Err)) &lt;&lt; "\n";&#13;
      return false;&#13;
    }&#13;
  }</pre></li>				<li>With that, the <a id="_idIndexMarker447"/>pass pipeline to run transformations on the IR code has been set up. After this step, we need an open file to write the result to. The system assembler and LLVM IR output are text-based, so we should set the <code>OF_Text</code> flag for them:<pre class="source-code">&#13;
  std::error_code EC;&#13;
  sys::fs::OpenFlags OpenFlags = sys::fs::OF_None;&#13;
  CodeGenFileType FileType = codegen::getFileType();&#13;
  if (FileType == CGFT_AssemblyFile)&#13;
    OpenFlags |= sys::fs::OF_Text;&#13;
  auto Out = std::make_unique&lt;llvm::ToolOutputFile&gt;(&#13;
      outputFilename(InputFilename), EC, OpenFlags);&#13;
  if (EC) {&#13;
    WithColor::error(errs(), Argv0)&#13;
        &lt;&lt; EC.message() &lt;&lt; '\n';&#13;
    return false;&#13;
  }</pre></li>				<li>For the code generation process, we have to use the old pass manager. We must simply declare the <code>CodeGenPM</code> instances and add the pass, which makes target-specific information available at the IR transformation level:<pre class="source-code">&#13;
  legacy::PassManager CodeGenPM;&#13;
  CodeGenPM.add(createTargetTransformInfoWrapperPass(&#13;
      TM-&gt;getTargetIRAnalysis()));</pre></li>				<li>To output<a id="_idIndexMarker448"/> LLVM IR, we must add a pass that prints the IR into a stream:<pre class="source-code">&#13;
  if (FileType == CGFT_AssemblyFile &amp;&amp; EmitLLVM) {&#13;
    CodeGenPM.add(createPrintModulePass(Out-&gt;os()));&#13;
  }</pre></li>				<li>Otherwise, we must let the <code>TargetMachine</code> instance add the required code generation passes, direc<a id="_idTextAnchor127"/>ted by the <code>FileType</code> value we pass as an argument:<pre class="source-code">&#13;
  else {&#13;
    if (TM-&gt;addPassesToEmitFile(CodeGenPM, Out-&gt;os(),&#13;
                                nullptr, FileType)) {&#13;
      WithColor::error()&#13;
          &lt;&lt; "No support for file type\n";&#13;
      return false;&#13;
    }&#13;
  }</pre></li>				<li>After all this preparation, we are now ready to execute the passes. First, we must run the optimization pipeline on the IR module. Next, the code generation passes are run. Of course, after all this work, we want to keep the output file:<pre class="source-code">&#13;
  MPM.run(*M, MAM);&#13;
  CodeGenPM.run(*M);&#13;
  Out-&gt;keep();&#13;
  return true;&#13;
}</pre></li>				<li>That was<a id="_idIndexMarker449"/> a lot of code, but the process was straightforward. Of course, we have to update the dependencies in the <code>tools/driver/CMakeLists.txt</code> build file too. Besides adding the target components, we must add all the transformation and code generation components from LLVM. The names roughly resemble the directory names where the source is located. The component name is translated into the link library name during the configuration process:<pre class="source-code">&#13;
set(LLVM_LINK_COMPONENTS ${LLVM_TARGETS_TO_BUILD}&#13;
  AggressiveInstCombine Analysis AsmParser&#13;
  BitWriter CodeGen Core Coroutines IPO IRReader&#13;
  InstCombine Instrumentation MC ObjCARCOpts Remarks&#13;
  ScalarOpts Support Target TransformUtils Vectorize&#13;
  Passes)</pre></li>				<li>Our compiler driver supports plugins, and we must announce this support:<pre class="source-code">&#13;
add_tinylang_tool(tinylang Driver.cpp SUPPORT_PLUGINS)</pre></li>				<li>As before, we have to link against our own libraries:<pre class="source-code">&#13;
target_link_libraries(tinylang&#13;
  PRIVATE tinylangBasic tinylangCodeGen&#13;
  tinylangLexer tinylangParser tinylangSema)</pre><p class="list-inset">These are necessary additions to the source code and the build system.</p></li>				<li>To build the extended compiler, you must change into your <code>build</code> directory and type the following:<pre class="source-code">&#13;
<strong class="bold">$ ninja</strong></pre></li>			</ol>&#13;
			<p>Changes to the files of the build system are automatically detected, and <code>cmake</code> is run before compiling and linking our changed source. If you need to re-run the configuration step, please follow the instructions in <a href="B19561_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Installing LLVM</em>, the <em class="italic">Compiling the tinylang </em><em class="italic">application</em> section.</p>&#13;
			<p>As we have used the options for the <code>opt</code> tool as a blueprint, you should try running <code>tinylang</code> with the options to load a pass plugin and run the pass, as we did in the previous sections.</p>&#13;
			<p>With the current<a id="_idIndexMarker450"/> implementation, we can either run a default pass pipeline or we can construct one ourselves. The latter is very flexible, but in almost all cases, it would be overkill. The default pipeline runs very well for C-like languages. However, what is missing is a way to extend the pass pipeline. We’ll look at how to implement this in the next section.</p>&#13;
			<h2 id="_idParaDest-125"><a id="_idTextAnchor128"/>Extending the pass pipeline</h2>&#13;
			<p>In the previous<a id="_idIndexMarker451"/> section, we used the <code>PassBuilder</code> class to create a pass pipeline, either from a user-provided description or a predefined name. Now, let’s look at another way to customize the pass pipeline: using extension points.</p>&#13;
			<p>During the construction of the pass pipeline, the pass builder allows passes contributed by the user to be added. These places are<a id="_idIndexMarker452"/> called <strong class="bold">extension points</strong>. A couple of extension points exist, as follows:</p>&#13;
			<ul>&#13;
				<li>The pipeline start extension point, which allows us to add passes at the beginning of the pipeline</li>&#13;
				<li>The peephole extension point, which allows us to add passes after each instance of the instruction combiner pass</li>&#13;
			</ul>&#13;
			<p>Other extension points exist too. To employ an extension point, you must register a callback. During the construction of the pass pipeline, your callback is run at the defined extension point and can add passes to the given pass manager.</p>&#13;
			<p>To register a callback for the pipeline start extension point, you must call the <code>registerPipelineStartEPCallback()</code> method of the <code>PassBuilder</code> class. For example, to add our <code>PPProfiler</code> pass to the beginning of the pipeline, you would adapt the pass to be used as a module pass with a call to the <code>createModuleToFunctionPassAdaptor()</code> template function and then add the pass to the module pass manager:</p>&#13;
			<pre class="source-code">&#13;
PB.registerPipelineStartEPCallback(&#13;
    [](ModulePassManager &amp;MPM) {&#13;
        MPM.addPass(PPProfilerIRPass());&#13;
    });</pre>			<p>You can add this snippet in the pass pipeline setup code anywhere before the pipeline is created – that is, before the <code>parsePassPipeline()</code> method is called.</p>&#13;
			<p>A very natural <a id="_idIndexMarker453"/>extension to what we did in the previous section is to let the user pass a pipeline description for an extension point on the command line. The <code>opt</code> tool allows this too. Let’s do this for the pipeline start extension point. Add the following code to the <code>tools/driver/Driver.cpp</code> file:</p>&#13;
			<ol>&#13;
				<li>First, we must a new command line for the user to specify the pipeline description. Again, we take the option name from the <code>opt</code> tool:<pre class="source-code">&#13;
static cl::opt&lt;std::string&gt; PipelineStartEPPipeline(&#13;
    "passes-ep-pipeline-start",&#13;
    cl::desc("Pipeline start extension point));</pre></li>				<li>Using a Lambda function as a callback is the most convenient way to do this. To parse the pipeline description, we must call the <code>parsePassPipeline()</code> method of the <code>PassBuilder</code> instance. The passes are added to the <code>PM</code> pass manager and given as an argument to the Lambda function. If an error occurs, we only print an error message without stopping the application. You can add this snippet after the call to the <code>crossRegisterProxies()</code> method:<pre class="source-code">&#13;
  PB.registerPipelineStartEPCallback(&#13;
      [&amp;PB, Argv0](ModulePassManager &amp;PM) {&#13;
        if (auto Err = PB.parsePassPipeline(&#13;
                PM, PipelineStartEPPipeline)) {&#13;
          WithColor::error(errs(), Argv0)&#13;
              &lt;&lt; "Could not parse pipeline "&#13;
              &lt;&lt; PipelineStartEPPipeline.ArgSt<a id="_idTextAnchor129"/>r &lt;&lt; ": "&#13;
              &lt;&lt; toString(std::move(Err)) &lt;&lt; "\n";&#13;
        }&#13;
      });</pre></li>			</ol>&#13;
			<p class="callout-heading">Tip</p>&#13;
			<p class="callout">To allow the user to add passes at every extension point, you need to add the preceding code snippet for each extension point.</p>&#13;
			<ol>&#13;
				<li value="3">Now is <a id="_idIndexMarker454"/>a good time to try out the different <code>pass manager</code> options. With the <code>--debug-pass-manager</code> option, you can follow which passes are executed in which order. You can also print the IR before or after each pass, which is invoked with the <code>--print-before-all</code> and <code>--print-after-all</code> options. If you created your own pass pipeline, then you can insert the <code>print</code> pass in points of interest. For example, try the <code>--passes="print,inline,print"</code> option. Furthermore, to identify which pass changes the IR code, you can use the <code>--print-changed</code> option, which will only print the IR code if it has changed compared to the result from the pass before. The greatly reduced output makes it much easier to follow IR transformations.<p class="list-inset">The <code>PassBuilder</code> class has a nested <code>OptimizationLevel</code> class to represent the six different optimization levels. Instead of using the <code>"default&lt;O?&gt;" </code>pipeline description as an argument to the <code>parsePassPipeline()</code> method, we can also call the <code>buildPerModuleDefaultPipeline()</code> method, which builds the default optimization pipeline for the request level – except for level <code>O0</code>. This optimization level means that no optimization is performed.</p><p class="list-inset">Consequently, no passes are added to the pass manager. If we still want to run a certain pass, then we can add it to the pass manager manually. A simple pass to run at this level is the <code>AlwaysInliner</code> pass, which inlines a function marked with the <code>always_inline</code> attribute into the caller. After translating the command-line option value for the optimization level into the corresponding member <a id="_idIndexMarker455"/>of the <code>OptimizationLevel</code> class, we can implement this as follows:</p><pre class="source-code">&#13;
    PassBuilder::OptimizationLevel Olevel = …;&#13;
    if (OLevel == PassBuilder::OptimizationLevel::O0)&#13;
      MPM.addPass(AlwaysInlinerPass());&#13;
    else&#13;
      MPM = PB.buildPerModuleDefaultPipeline(OLevel, DebugPM);</pre><p class="list-inset">Of course, it is possible to add more than one pass to the pass manager in this fashion. <code>PassBuilder</code> also uses the <code>addPass()</code> method when constructing the pass pipeline.</p></li>			</ol>&#13;
			<p class="callout-heading">Running extension point callbacks</p>&#13;
			<p class="callout">Because the pass pipeline is not populated for optimization level <code>O0</code>, the registered extension points are not called. If you use the extension points to register passes that should also run at <code>O0</code> level, this is problematic. You can call the <code>runRegisteredEPCallbacks()</code> method to run the registered extension point callbacks, resulting in a pass manager populated only with the passes that were registered through the extension points.</p>&#13;
			<p>By adding the optimization pipeline to <code>tinylang</code>, you created an optimizing compiler similar to <code>clang</code>. The LLVM community works on improving the optimizations and the optimization pipeline with each release. Due to this, it is very seldom that the default pipeline is not used. Most often, new<a id="_idIndexMarker456"/> passes are added to implement certain semantics of the programming language.</p>&#13;
			<h1 id="_idParaDest-126"><a id="_idTextAnchor130"/>Summary</h1>&#13;
			<p>In this chapter, you learned how to create a new pass for LLVM. You ran the pass using a pass pipeline description and an extension point. You extended your compiler with the construction and execution of a pass pipeline similar to <code>clang</code>, turning <code>tinylang</code> into an optimizing compiler. The pass pipeline allows the addition of passes at extension points, and you learned how you can register passes at these points. This allows you to extend the optimization pipeline with your developed passes or existing passes.</p>&#13;
			<p>In the next chapter, you will learn the basics of the <code>clang</code> to significantly reduce manual programming.</p>&#13;
		</p>&#13;
	</div></body></html>