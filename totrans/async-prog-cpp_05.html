<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-98">
    <a id="_idTextAnchor097">
    </a>
    
     5
    
   </h1>
   <h1 id="_idParaDest-99">
    <a id="_idTextAnchor098">
    </a>
    
     Atomic Operations
    
   </h1>
   <p>
    
     In
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     , we learned about lock-based thread synchronization.
    
    
     We learned about mutexes, condition variables, and other thread synchronization primitives, which are all based on acquiring and releasing locks.
    
    
     Those synchronization mechanisms are built on top of
    
    <em class="italic">
     
      atomic types and operations
     
    </em>
    
     , this
    
    
     
      chapter’s topic.
     
    
   </p>
   <p>
    
     We will study what atomic operations are and how they differ from lock-based synchronization primitives.
    
    
     After reading this chapter, you will have a basic knowledge of atomic operations and some of their applications.
    
    
     Lock-free (not using locks) synchronization based on atomic operations is a very complex subject requiring years to master, but we will give you what we hope will be a good introduction to
    
    
     
      the subject.
     
    
   </p>
   <p>
    
     In this chapter, we will cover the following
    
    
     
      main topics:
     
    
   </p>
   <ul>
    <li>
     
      What are
     
     
      
       atomic operations?
      
     
    </li>
    <li>
     
      An introduction to the C++
     
     
      
       memory model
      
     
    </li>
    <li>
     
      What atomic types and operations are provided by the C++
     
     
      
       Standard Library?
      
     
    </li>
    <li>
     
      Some examples of atomic operations, from a simple counter to be used to gather statistics and a basic mutex-like lock to a full
     
     <strong class="bold">
      
       single-producer-single-consumer
      
     </strong>
     
      (
     
     <strong class="bold">
      
       SPSC
      
     </strong>
     
      ) lock-free
     
     
      
       bounded queue
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-100">
    <a id="_idTextAnchor099">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     You will need a recent C++ compiler with C++20 support.
    
    
     Some short code examples will be provided as links to the very useful godbolt website (
    
    <a href="https://godbolt.org">
     
      https://godbolt.org
     
    </a>
    
     ).
    
    
     For full code examples, we will use the book repo, which is available
    
    
     
      at
     
    
    <a href="https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP">
     
      
       https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The examples can be compiled and run locally.
    
    
     We have tested the code on an Intel CPU computer running Linux (Ubuntu 24.04 LTS).
    
    
     For atomic operations and especially for memory ordering (more on this later in this chapter), Intel CPUs are different from
    
    
     
      Arm CPUs.
     
    
   </p>
   <p>
    
     Please note here that code performance and profiling will be the subject of
    
    <a href="B22219_13.xhtml#_idTextAnchor267">
     
      <em class="italic">
       
        Chapter 13
       
      </em>
     
    </a>
    
     .
    
    
     We will just make some remarks on performance in this chapter to avoid making it
    
    
     
      unnecessarily long.
     
    
   </p>
   <h1 id="_idParaDest-101">
    <a id="_idTextAnchor100">
    </a>
    
     Introduction to atomic operations
    
   </h1>
   <p>
    
     Atomic operations are
    
    <a id="_idIndexMarker322">
    </a>
    
     indivisible (hence the word atomic, from the Greek
    
    <em class="italic">
     
      ἄτομος
     
    </em>
    
     ,
    
    
     <em class="italic">
      
       atomos
      
     </em>
    
    
     
      , indivisible).
     
    
   </p>
   <p>
    
     In this section, we will introduce atomic operations, what they are, and some reasons to use (and not to
    
    
     
      use!) them.
     
    
   </p>
   <h2 id="_idParaDest-102">
    <a id="_idTextAnchor101">
    </a>
    
     Atomic operations versus non-atomic operations – an example
    
   </h2>
   <p>
    
     If you remember the simple counter example from
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     , we needed to use a synchronization mechanism (we used a mutex) for modifying the counter variable from different threads to avoid race
    
    <a id="_idIndexMarker323">
    </a>
    
     conditions.
    
    
     The cause of the race condition was that incrementing the counter required three operations: reading the
    
    <a id="_idIndexMarker324">
    </a>
    
     counter value, incrementing it, and writing the modified counter value back to memory.
    
    
     If only we could do that in one go, there would be no
    
    
     
      race condition.
     
    
   </p>
   <p>
    
     This is exactly what could be achieved with an atomic operation: if we had some kind of
    
    <strong class="source-inline">
     
      atomic_increment
     
    </strong>
    
     operation, each thread would read, increment, and write the counter in a single instruction, avoiding the race condition because at any time, incrementing the counter would be fully done.
    
    
     By fully done we mean that each thread would either increment the counter or do nothing at all, making interruptions in the middle of a counter increment
    
    
     
      operation impossible.
     
    
   </p>
   <p>
    
     The following two examples are for illustration purposes only and are not multithreaded.
    
    
     We focus here on just the operations, whether atomic
    
    
     
      or non-atomic.
     
    
   </p>
   <p>
    
     Let’s see this in the code.
    
    
     For the C++ code and the generated assembly language shown in the following example, refer
    
    
     
      to
     
    
    <a href="https://godbolt.org/z/f4dTacsKW">
     
      
       https://godbolt.org/z/f4dTacsKW
      
     
    </a>
    
     
      :
     
    
   </p>
   <pre class="source-code">
int counter {0};
int main() {
    counter++;
    return 0;
}</pre>
   <p>
    
     The code increments a global counter.
    
    
     Now let’s see the assembly code generated by the compiler and what
    
    <a id="_idIndexMarker325">
    </a>
    
     instructions the CPU executes (the full assembly can be found in the
    
    
     
      previous link):
     
    
   </p>
   <pre class="source-code">
    Mov    eax, DWORD PTR counter[rip]
    Add    eax, 1
    Move    DWORD PTR counter[rip], eax</pre>
   <p>
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     copies the value stored in
    
    <strong class="source-inline">
     
      counter
     
    </strong>
    
     to the
    
    <strong class="source-inline">
     
      eax
     
    </strong>
    
     register,
    
    <strong class="source-inline">
     
      [2]
     
    </strong>
    
     adds
    
    <strong class="source-inline">
     
      1
     
    </strong>
    
     to the value stored in
    
    <strong class="source-inline">
     
      eax
     
    </strong>
    
     , and finally,
    
    <strong class="source-inline">
     
      [3]
     
    </strong>
    
     copies back the content of the
    
    <strong class="source-inline">
     
      eax
     
    </strong>
    
     register to the
    
    <strong class="source-inline">
     
      counter
     
    </strong>
    
     variable.
    
    
     So, a thread
    
    <a id="_idIndexMarker326">
    </a>
    
     could execute
    
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     and then be scheduled out, and another thread execute all three instructions after that.
    
    
     When the first thread finishes incrementing the result, the counter will be incremented just once and thus the result will
    
    
     
      be incorrect.
     
    
   </p>
   <p>
    
     The following code does the same: it increments a global counter.
    
    
     This time, though, it uses atomic types and operations.
    
    
     To get the code and the generated assembly in the following example, refer
    
    
     
      to
     
    
    <a href="https://godbolt.org/z/9hrbo31vx">
     
      
       https://godbolt.org/z/9hrbo31vx
      
     
    </a>
    
     
      :
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
std::atomic&lt;int&gt; counter {0};
int main() {
    counter++;
    return 0;
}</pre>
   <p>
    
     We will explain the
    
    <strong class="source-inline">
     
      std::atomic&lt;int&gt;
     
    </strong>
    
     type and the atomic increment
    
    
     
      operation later.
     
    
   </p>
   <p>
    
     The generated assembly code is
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
    lock add    DWORD PTR counter[rip], 1</pre>
   <p>
    
     Just one instruction has been generated to add
    
    <strong class="source-inline">
     
      1
     
    </strong>
    
     to the value stored in the
    
    <strong class="source-inline">
     
      counter
     
    </strong>
    
     variable.
    
    
     The
    
    <strong class="source-inline">
     
      lock
     
    </strong>
    
     prefix here means that the following instruction (in this case
    
    <strong class="source-inline">
     
      add
     
    </strong>
    
     ) is going to be executed atomically.
    
    
     Hence, in this second example, a thread cannot be interrupted in the middle of incrementing the counter.
    
    
     As a side note, some Intel x64 instructions execute atomically and don’t use the
    
    
     <strong class="source-inline">
      
       lock
      
     </strong>
    
    
     
      prefix.
     
    
   </p>
   <p>
    
     Atomic operations allow threads to read, modify (for example, increase a value), and write indivisibly, and can also be used as synchronization primitives (similar to the mutexes we saw in
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     ).
    
    
     In fact, all the lock-based synchronization primitives we have seen so far in this book are implemented using atomic operations.
    
    
     Atomic operations must be provided by the CPU (as in the
    
    <strong class="source-inline">
     
      lock
     
    </strong>
    
     <strong class="source-inline">
      
       add
      
     </strong>
    
    
     
      instruction).
     
    
   </p>
   <p>
    
     In this section, we have introduced atomic operations, defined what they are, and studied a very simple example
    
    <a id="_idIndexMarker327">
    </a>
    
     of how they are implemented by looking at the assembly instructions that the
    
    <a id="_idIndexMarker328">
    </a>
    
     compiler generates.
    
    
     In the next section, we will look at some of the advantages and disadvantages of
    
    
     
      atomic operations.
     
    
   </p>
   <h2 id="_idParaDest-103">
    <a id="_idTextAnchor102">
    </a>
    
     When to use (and when not to use) atomic operations
    
   </h2>
   <p>
    
     Using atomic operations is a complex subject and it can be very difficult (or at least quite tricky) to master.
    
    
     It requires a lot of experience, and we have attended some courses on this very subject where we were advised not to do it!
    
    
     Anyway, you can always learn the basics and experiment as you do so.
    
    
     We hope this book will help you progress in your
    
    
     
      learning journey.
     
    
   </p>
   <p>
    
     Atomic operations can be used in the
    
    <a id="_idIndexMarker329">
    </a>
    
     
      following cases:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       If multiple threads share a mutable state
      
     </strong>
     
      : The need to synchronize threads is the most common case.
     
     
      Of course, it is possible to use locks such as mutexes, but atomic
     
     <a id="_idIndexMarker330">
     </a>
     
      operations, in some cases, will provide better performance.
     
     
      Please note, however, that the use of atomic operations
     
     <em class="italic">
      
       does not
      
     </em>
     
      guarantee
     
     
      
       better performance.
      
     
    </li>
    <li>
     <strong class="bold">
      
       If synchronized access to shared state is fine-grained
      
     </strong>
     
      : If the data we must synchronize is an integer or a pointer or any other variable of a C++ intrinsic type, then using atomic operations may be better than
     
     
      
       using locks.
      
     
    </li>
    <li>
     <strong class="bold">
      
       To improve performance
      
     </strong>
     
      : If you want to achieve maximum performance, then atomic operations can help reduce thread context switches (see
     
     <a href="B22219_02.xhtml#_idTextAnchor035">
      
       <em class="italic">
        
         Chapter 2
        
       </em>
      
     </a>
     
      ) and reduce the overhead introduced by locks, thus lowering latency.
     
     
      Remember to always profile your code to be sure that performance is improved (we will see this in depth in
     
     <a href="B22219_13.xhtml#_idTextAnchor267">
      
       <em class="italic">
        
         Chapter 13
        
       </em>
      
     </a>
     
      
       ).
      
     
    </li>
   </ul>
   <p>
    
     Locks can be used in the
    
    <a id="_idIndexMarker331">
    </a>
    
     
      following cases:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       If the protected data is not fine-grained
      
     </strong>
     
      : For example, we are synchronizing access to a data structure or an object bigger than 8 bytes (in
     
     
      
       modern CPUs).
      
     
    </li>
    <li>
     <strong class="bold">
      
       If performance is not an issue
      
     </strong>
     
      : Locks are much simpler to use and reason about (in some cases using locks gives better performance than using
     
     
      
       atomic operations).
      
     
    </li>
    <li>
     <strong class="bold">
      
       To avoid the need to acquire low-level knowledge
      
     </strong>
     
      : To get the maximum performance out of atomic operations, a lot of low-level knowledge is required.
     
     
      We will introduce some of it in the section,
     
     <em class="italic">
      
       The C++
      
     </em>
     
      <em class="italic">
       
        memory model
       
      </em>
     
     
      
       .
      
     
    </li>
   </ul>
   <p>
    
     We have just learned when to use and when not to use atomic operations.
    
    
     Some applications such as low-latency/high-frequency trading systems require maximum performance and use atomic operations to achieve the lowest latency possible.
    
    
     Most applications will work just fine synchronizing
    
    
     
      with locks.
     
    
   </p>
   <p>
    
     In the next section, we will study the differences between blocking and non-blocking data structures and some related
    
    
     
      concept definitions.
     
    
   </p>
   <h1 id="_idParaDest-104">
    <a id="_idTextAnchor103">
    </a>
    
     Non-blocking data structures
    
   </h1>
   <p>
    
     In
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     we studied the implementation of a synchronized queue.
    
    
     We used mutexes and condition variables
    
    <a id="_idIndexMarker332">
    </a>
    
     as synchronization primitives.
    
    
     Data structures synchronized with locks are called
    
    <strong class="bold">
     
      blocking data structures
     
    </strong>
    
     because threads are
    
    <em class="italic">
     
      blocked
     
    </em>
    
     (by the operating system), waiting until the locks
    
    
     
      become available.
     
    
   </p>
   <p>
    
     Data structures that don’t use locks
    
    <a id="_idIndexMarker333">
    </a>
    
     are called
    
    <strong class="bold">
     
      non-blocking data structures
     
    </strong>
    
     .
    
    
     Most (but not all) of them
    
    
     
      are lock-free.
     
    
   </p>
   <p>
    
     A data structure or algorithm is considered lock-free if each synchronized action completes in a finite number of steps, not allowing indefinite waiting for a condition to become true
    
    
     
      or false.
     
    
   </p>
   <p>
    
     The types of lock-free data structures are
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Obstruction-free
      
     </strong>
     
      : A thread will complete its operation in a bounded number of steps if all other threads
     
     <a id="_idIndexMarker334">
     </a>
     
      
       are suspended
      
     
    </li>
    <li>
     <strong class="bold">
      
       Lock-free
      
     </strong>
     
      : A thread
     
     <a id="_idIndexMarker335">
     </a>
     
      will complete its operation in a bounded number of steps while multiple threads are working on the
     
     
      
       data structure
      
     
    </li>
    <li>
     <strong class="bold">
      
       Wait-free
      
     </strong>
     
      : All the threads
     
     <a id="_idIndexMarker336">
     </a>
     
      will complete their operations in a bounded number of steps while multiple threads are working on the
     
     
      
       data structure
      
     
    </li>
   </ul>
   <p>
    
     Implementing lock-free data
    
    <a id="_idIndexMarker337">
    </a>
    
     structures is very complicated and before doing it, we need to be sure it’s necessary.
    
    
     The reasons to use lock-free data structures are
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Achieving maximum concurrency
      
     </strong>
     
      : As we saw earlier, atomic operations are a good choice when the
     
     <a id="_idIndexMarker338">
     </a>
     
      data access synchronization involves fine-grained data (such as native-type variables).
     
     
      From the preceding definitions, a lock-free data structure will allow at least one of the threads accessing the data structure to make some progress in a bounded number of steps.
     
     
      A wait-free structure will allow all the threads accessing the data structure to make
     
     
      
       some progress.
      
     
     <p class="list-inset">
      
       When we use locks, however, a thread owns the lock while the rest of the threads are just waiting for the lock to be available, so the concurrency achievable with lock-free data structures can be
      
      
       
        much better.
       
      
     </p>
    </li>
    <li>
     <strong class="bold">
      
       No deadlocks
      
     </strong>
     
      : Because there are no locks involved, it is impossible to have any deadlocks in
     
     
      
       our code.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Performance
      
     </strong>
     
      : Some applications must achieve the lowest latency possible and so waiting for a lock can be unacceptable.
     
     
      When a thread tries to acquire the lock, and it is not available, then the operating system blocks the thread.
     
     
      While the thread is blocked, there
     
     <a id="_idIndexMarker339">
     </a>
     
      is a context switch for the scheduler to be able to schedule another thread for execution.
     
     
      These context switches take time, and that time may be too
     
     <a id="_idIndexMarker340">
     </a>
     
      much in a low-latency application such as a high-performance network
     
     
      
       packet receiver/processor.
      
     
    </li>
   </ul>
   <p>
    
     We have now looked at what blocking and non-blocking data structures are and what lock-free code is.
    
    
     We will introduce the C++ memory model in the
    
    
     
      next section.
     
    
   </p>
   <h1 id="_idParaDest-105">
    <a id="_idTextAnchor104">
    </a>
    
     The C++ memory model
    
   </h1>
   <p>
    
     This section explains the
    
    <a id="_idIndexMarker341">
    </a>
    
     C++ memory model and how it deals with concurrency.
    
    
     The C++ memory model comes with C++11, and defines the two main features of memory
    
    
     
      in C++:
     
    
   </p>
   <ul>
    <li>
     
      How objects are laid out in memory (that is, structural aspects).
     
     
      This subject won’t be covered in this book, which is about
     
     
      
       asynchronous programming.
      
     
    </li>
    <li>
     
      Memory modification order (that is, concurrency aspects).
     
     
      We will see the different memory modification orders specified in the
     
     
      
       memory model.
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-106">
    <a id="_idTextAnchor105">
    </a>
    
     Memory access order
    
   </h2>
   <p>
    
     Before we explain the C++ memory model and the different memory orderings it supports, let’s clarify
    
    <a id="_idIndexMarker342">
    </a>
    
     what we mean by memory order.
    
    
     Memory order refers to the order in which memory (that is, the variables in a program) is accessed.
    
    
     Memory access can be either read or write (load and store).
    
    
     But what is the actual order in which the variables of a program are accessed?
    
    
     For the following code, there are three points of view: the written code order, the compiler-generated instructions order, and finally, the order in which the instructions are executed by the CPU.
    
    
     These three orderings can all be the same or (more
    
    
     
      likely) different.
     
    
   </p>
   <p>
    
     The first and obvious ordering is the one in the code.
    
    
     An example of this is in the following
    
    
     
      code snippet:
     
    
   </p>
   <pre class="source-code">
void func_a(int&amp; a, int&amp; b) {
    a += 1;
    b += 10;
    a += 2;
}</pre>
   <p>
    
     The
    
    <strong class="source-inline">
     
      func_a
     
    </strong>
    
     function first adds 1 to variable
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     , then adds 10 to variable
    
    <strong class="source-inline">
     
      b
     
    </strong>
    
     , and finally, adds 2 to variable
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     .
    
    
     This is our intention and the order in which we define the statements to
    
    
     
      be executed.
     
    
   </p>
   <p>
    
     The compiler will
    
    <a id="_idIndexMarker343">
    </a>
    
     transform the preceding code into assembly instructions.
    
    
     The compiler can change the order of our statements to make the generated code more efficient if the outcome of the code execution is unchanged.
    
    
     For example, with the preceding code, the compiler could either do the two additions with variable
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     first and then the addition with variable
    
    <strong class="source-inline">
     
      b
     
    </strong>
    
     , or it could simply add 3 to
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     and then 10 to
    
    <strong class="source-inline">
     
      b
     
    </strong>
    
     .
    
    
     As we mentioned previously, the compiler can do whatever it wants to optimize the code if the result is
    
    
     
      the same.
     
    
   </p>
   <p>
    
     Let’s now consider the
    
    
     
      following code:
     
    
   </p>
   <pre class="source-code">
void func_a(int&amp; a, int&amp; b) {
    a += 1;
    b += 10 + a;
    a += 2;
}</pre>
   <p>
    
     In this case, the operation on
    
    <strong class="source-inline">
     
      b
     
    </strong>
    
     depends on the previous operation on
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     , so the compiler cannot reorder the statements, and the generated code will be like the code we write (same order
    
    
     
      of operations).
     
    
   </p>
   <p>
    
     The CPU (which used in this book is a modern Intel x64 CPU) will run the generated code.
    
    
     It can execute the compiler-generated instructions in a different order.
    
    
     This is called out-of-order execution.
    
    
     The CPU
    
    <a id="_idIndexMarker344">
    </a>
    
     can do this, again, if the result
    
    
     
      is correct.
     
    
   </p>
   <p>
    
     See this link for the generated code shown in the preceding
    
    
     
      example:
     
    
    <a href="https://godbolt.org/z/Mhrcnsr9e">
     
      
       https://godbolt.org/z/Mhrcnsr9e
      
     
    </a>
   </p>
   <p>
    
     First, the generated instructions for
    
    <strong class="source-inline">
     
      func_1
     
    </strong>
    
     show an optimization: the compiler combined both additions into one by adding 3 to variable
    
    <strong class="source-inline">
     
      a
     
    </strong>
    
     in one instruction.
    
    
     Second, the generated instructions for
    
    <strong class="source-inline">
     
      func_2
     
    </strong>
    
     are in the same order as the C++ statements we wrote.
    
    
     In this case, the CPU could execute the instructions out of order, as there is no dependency among
    
    
     
      the operations.
     
    
   </p>
   <p>
    
     To conclude, we can say that the code that the CPU will run can be different from the code we wrote (again, given that the result of the execution is the same as we intended in the program
    
    
     
      we wrote).
     
    
   </p>
   <p>
    
     All the examples we have shown are fine for code that runs in a single thread.
    
    
     The code instructions may be executed in different order depending on the compiler optimizations and the CPU out-of-order execution and the result will still
    
    
     
      be correct.
     
    
   </p>
   <p>
    
     See the following
    
    <a id="_idIndexMarker345">
    </a>
    
     code for an example of
    
    
     
      out-of-order execution:
     
    
   </p>
   <pre class="source-code">
    mov    eax, [var1]  ; load variable var1 into reg eax
    inc    eax          ; eax += 1
    mov    [var1], eax  ; store reg eax into var1
    xor    ecx, ecx     ; ecx = 0
    inc    ecx          ; ecx += 1
    add    eax, ecx     ; eax = eax + ecx</pre>
   <p>
    
     The CPU could execute the instructions in the order shown in the preceding code, that is,
    
    <strong class="source-inline">
     
      load var1 [1]
     
    </strong>
    
     .
    
    
     Then, while the variable is being read, it could issue some of the later instructions, such as
    
    <strong class="source-inline">
     
      [4]
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      [5]
     
    </strong>
    
     , and then, once
    
    <strong class="source-inline">
     
      var1
     
    </strong>
    
     has been read, execute
    
    <strong class="source-inline">
     
      [2]
     
    </strong>
    
     , then
    
    <strong class="source-inline">
     
      [3]
     
    </strong>
    
     , and, finally,
    
    <strong class="source-inline">
     
      [6]
     
    </strong>
    
     .
    
    
     The instructions were executed in a different order, but the result is still the same.
    
    
     This is a typical example of out-of-order execution: the CPU issues a load instruction and instead of waiting for the data to become available, it executes some other instructions, if possible, to avoid being idle and to
    
    
     
      maximize performance.
     
    
   </p>
   <p>
    
     All the optimizations we have mentioned (both compiler and CPU) are always done without considering the interactions between threads.
    
    
     Neither the compiler nor the CPU knows about different threads.
    
    
     In these cases, we need to tell the compiler what it can and cannot do.
    
    
     Atomic operations and locks are the way to
    
    
     
      do this.
     
    
   </p>
   <p>
    
     When, for example, we use atomic variables, we may not only require the operations to be atomic but also to follow a certain order for the code to work properly when running multiple threads.
    
    
     This cannot be done by just the compiler or the CPU because neither has any information involving multiple threads.
    
    
     To specify what order we want to use, the C++
    
    <a id="_idIndexMarker346">
    </a>
    
     memory model offers
    
    
     
      different
     
    
    
     <a id="_idIndexMarker347">
     </a>
    
    
     
      options:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Relaxed
      
     </strong>
     
      <strong class="bold">
       
        ordering
       
      </strong>
     
     
      
       :
      
     
     
      <strong class="source-inline">
       
        std::memory_order_relaxed
       
      </strong>
     
    </li>
    <li>
     <strong class="bold">
      
       Acquire and release ordering
      
     </strong>
     
      :
     
     <strong class="source-inline">
      
       std::memory_order_acquire
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       std::memory_order_release
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       std::memory_order_acq_rel
      
     </strong>
     
      ,
     
     
      
       and
      
     
     
      <strong class="source-inline">
       
        std::memory_order_consume
       
      </strong>
     
    </li>
    <li>
     <strong class="bold">
      
       Sequential consistency
      
     </strong>
     
      <strong class="bold">
       
        ordering
       
      </strong>
     
     
      
       :
      
     
     
      <strong class="source-inline">
       
        std::memory_order_seq_cst
       
      </strong>
     
    </li>
   </ul>
   <p>
    
     The C++ memory model defines an abstract
    
    <a id="_idIndexMarker348">
    </a>
    
     machine to achieve independence from any specific CPU.
    
    
     However, the CPU is still there and the features available in the memory model may not be
    
    <a id="_idIndexMarker349">
    </a>
    
     available to a specific CPU.
    
    
     For example, the Intel x64 architecture is quite restrictive and enforces quite a strong
    
    
     
      memory order.
     
    
   </p>
   <p>
    
     The Intel x64 architecture uses a processor-ordered memory-ordering model that can be defined as being
    
    <em class="italic">
     
      write-ordered with store-buffer forwarding
     
    </em>
    
     .
    
    
     In a single-processor system, the memory-ordering model respects the
    
    
     
      following principles:
     
    
   </p>
   <ul>
    <li>
     
      Reads are not reordered with
     
     
      
       any reads
      
     
    </li>
    <li>
     
      Writes are not reordered with
     
     
      
       any writes
      
     
    </li>
    <li>
     
      Writes are not reordered with
     
     
      
       older reads
      
     
    </li>
    <li>
     
      Reads may be reordered with older writes (if the read and write to be reordered refer to different
     
     
      
       memory locations)
      
     
    </li>
    <li>
     
      Reads and writes are not reordered with locked (
     
     
      
       atomic) instructions
      
     
    </li>
   </ul>
   <p>
    
     There are more details in the Intel manuals (see the references at the end of the chapter), but the preceding principles are the
    
    
     
      most relevant.
     
    
   </p>
   <p>
    
     In a multi-processor system, the following
    
    
     
      principles apply:
     
    
   </p>
   <ul>
    <li>
     
      Each of the individual processors uses the same ordering principles as in a
     
     
      
       single-processor system
      
     
    </li>
    <li>
     
      Writes by a single processor are observed in the same order by
     
     
      
       all processors
      
     
    </li>
    <li>
     
      Writes from an individual processor are not ordered with respect to the writes from
     
     
      
       other processors
      
     
    </li>
    <li>
     
      Memory ordering
     
     
      
       obeys causality
      
     
    </li>
    <li>
     
      Any two stores are seen in a consistent order by processors other than those performing
     
     
      
       the store
      
     
    </li>
    <li>
     
      Locked (atomic) instructions have
     
     
      
       total order
      
     
    </li>
   </ul>
   <p>
    
     The Intel architecture is strongly ordered; the store operations (write instructions) for each processor are observed by other processors in the same order they were performed, and each processor
    
    <a id="_idIndexMarker350">
    </a>
    
     executes the stores in the same order as they appear in the program.
    
    
     This is called
    
    <strong class="bold">
     
      Total Store
     
    </strong>
    
     <strong class="bold">
      
       Ordering
      
     </strong>
    
    
     
      (
     
    
    
     <strong class="bold">
      
       TSO
      
     </strong>
    
    
     
      ).
     
    
   </p>
   <p>
    
     The ARM
    
    <a id="_idIndexMarker351">
    </a>
    
     architecture supports
    
    <strong class="bold">
     
      Weak Ordering
     
    </strong>
    
     (
    
    <strong class="bold">
     
      WO
     
    </strong>
    
     ).
    
    
     These are the
    
    
     
      main principles:
     
    
   </p>
   <ul>
    <li>
     
      Reads and
     
     <a id="_idIndexMarker352">
     </a>
     
      writes can be performed out of order.
     
     
      In contrast to TSO where, as we have seen, there is no local reordering except of reads after writes to different addresses, the ARM architecture allows local reordering (unless otherwise specified using
     
     
      
       special instructions).
      
     
    </li>
    <li>
     
      A write is not guaranteed to be visible to all threads at the same time as it was in the
     
     
      
       Intel architecture.
      
     
    </li>
    <li>
     
      In general, this relatively non-restrictive memory ordering allows the cores to reorder instructions more freely, potentially increasing
     
     
      
       multicore performance.
      
     
    </li>
   </ul>
   <p>
    
     We must say here that the more relaxed the memory order is, the more difficult it is to reason about the executed code, and the more challenging it becomes to correctly synchronize multiple threads with atomic operations.
    
    
     Also, you should bear in mind that the atomicity is always guaranteed irrespective of the
    
    
     
      memory order.
     
    
   </p>
   <p>
    
     In this section, we have seen what is meant by order when accessing memory and how the ordering we specify in the code may not be the same order in which the CPU executes the code.
    
    
     In the next section, we will see how to enforce some ordering using atomic types
    
    
     
      and operations.
     
    
   </p>
   <h2 id="_idParaDest-107">
    <a id="_idTextAnchor106">
    </a>
    
     Enforcing ordering
    
   </h2>
   <p>
    
     We have seen already in
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     and earlier in this chapter that non-atomic operations on the same memory addresses executed from different threads may cause data races and undefined behavior.
    
    
     To enforce the ordering of the operations between threads, we will use atomic types and their operations.
    
    
     This section will explore what the use of atomics
    
    <a id="_idIndexMarker353">
    </a>
    
     achieves in
    
    
     
      multithreaded code.
     
    
   </p>
   <p>
    
     The following simple example will help us to see what can be done with
    
    
     
      atomic operations:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
std::string message;
std::atomic&lt;bool&gt; ready{false};
void reader() {
    using namespace std::chrono::literals;
    while (!ready.load()) {
        std::this_thread::sleep_for(1ms);
    }
    std::cout &lt;&lt; "Message received = " &lt;&lt; message &lt;&lt; std::endl;
}
void writer() {
    message = "Hello, World!";
    ready.store(true);
}
int main() {
    std::thread t1(reader);
    std::thread t2(writer);
    t1.join();
    t2.join();
    return 0;
}</pre>
   <p>
    
     In this example,
    
    <strong class="source-inline">
     
      reader()
     
    </strong>
    
     waits until the
    
    <strong class="source-inline">
     
      ready
     
    </strong>
    
     variable is
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     and then prints a message set by
    
    <strong class="source-inline">
     
      writer()
     
    </strong>
    
     .
    
    
     The
    
    <strong class="source-inline">
     
      writer()
     
    </strong>
    
     function sets the message and then sets the
    
    <strong class="source-inline">
     
      store
     
    </strong>
    
     variable
    
    
     
      to
     
    
    
     <strong class="source-inline">
      
       true
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Atomic
    
    <a id="_idIndexMarker354">
    </a>
    
     operations provide us with two features for enforcing a certain order of execution in
    
    
     
      multithreaded code:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Happens before
      
     </strong>
     
      : In the preceding code,
     
     <strong class="source-inline">
      
       [1]
      
     </strong>
     
      (setting the
     
     <strong class="source-inline">
      
       message
      
     </strong>
     
      variable) happens before
     
     <strong class="source-inline">
      
       [2]
      
     </strong>
     
      (setting the atomic
     
     <strong class="source-inline">
      
       ready
      
     </strong>
     
      variable to
     
     <strong class="source-inline">
      
       true
      
     </strong>
     
      ).
     
     
      Also,
     
     <strong class="source-inline">
      
       [3]
      
     </strong>
     
      , reading the
     
     <strong class="source-inline">
      
       ready
      
     </strong>
     
      variable in a loop until it is
     
     <strong class="source-inline">
      
       true
      
     </strong>
     
      , happens before
     
     <strong class="source-inline">
      
       [4]
      
     </strong>
     
      , printing the message.
     
     
      In this case, we are using sequential consistency memory order (the default
     
     
      
       memory order).
      
     
    </li>
    <li>
     <strong class="bold">
      
       Synchronizes with
      
     </strong>
     
      : This only happens between atomic operations.
     
     
      In the preceding example, this means that when
     
     <strong class="source-inline">
      
       ready
      
     </strong>
     
      is set by
     
     <strong class="source-inline">
      
       [1]
      
     </strong>
     
      the value will be visible for subsequent reads (or writes) in different threads (of course, it is visible in the
     
     <a id="_idIndexMarker355">
     </a>
     
      current thread), and when
     
     <strong class="source-inline">
      
       ready
      
     </strong>
     
      is read by
     
     <strong class="source-inline">
      
       [3]
      
     </strong>
     
      , the changed value will
     
     
      
       be visible.
      
     
    </li>
   </ul>
   <p>
    
     Now that we have seen how atomic operations enforce memory access order from different threads, let’s see in detail each of the memory order options provided by the C++
    
    
     
      memory model.
     
    
   </p>
   <p>
    
     Before we start, let’s remember here that the Intel x64 architecture (Intel and AMD desktop processors) is quite restrictive in relation to memory order, that there is no need for any additional instructions for acquire/release, and sequential consistency is cheap in terms of
    
    
     
      performance cost.
     
    
   </p>
   <h2 id="_idParaDest-108">
    <a id="_idTextAnchor107">
    </a>
    
     Sequential consistency
    
   </h2>
   <p>
    
     Sequential consistency
    
    <a id="_idIndexMarker356">
    </a>
    
     guarantees the execution of the program in the way you wrote it.
    
    
     In 1979 Leslie Lamport defined sequential consistency as being “
    
    <em class="italic">
     
      the result of an execution is the same as if the reads and writes occurred in some order, and the operations of each individual processor appear in this sequence in the order specified by
     
    </em>
    
     <em class="italic">
      
       its program.
      
     </em>
    
    
     
      ”
     
    
   </p>
   <p>
    
     In C++, sequential consistency is specified with the
    
    <strong class="source-inline">
     
      std::memory_order_seq_cst
     
    </strong>
    
     option.
    
    
     This is the most stringent memory order and it’s also the default one.
    
    
     If no ordering option is specified, then sequential consistency will
    
    
     
      be used.
     
    
   </p>
   <p>
    
     The C++ memory model by default ensures sequential consistency in the absence of race conditions within your code.
    
    
     Consider it a pact: if we properly synchronize our program to prevent race conditions, C++ will maintain the appearance that the program executes in the sequence it
    
    
     
      was written.
     
    
   </p>
   <p>
    
     In this model, all threads must see the same order of operations.
    
    
     Operations can still be reordered as far as the visible result of the computation has the same result as the result of the unordered code.
    
    
     The instructions and operations can be reordered if the reads and writes are performed in the same order as in the compiled code.
    
    
     The CPU is free to reorder any other instructions between the reads and writes if the dependencies are satisfied.
    
    
     Because of the consistent ordering it defines, sequential consistency is the most intuitive form of ordering.
    
    
     To illustrate sequential consistency, let’s consider the
    
    
     
      following
     
    
    
     <a id="_idIndexMarker357">
     </a>
    
    
     
      example:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
std::atomic&lt;bool&gt; x{ false };
std::atomic&lt;bool&gt; y{ false };
std::atomic&lt;int&gt; z{ 0 };
void write_x() {
    x.store(true, std::memory_order_seq_cst);
}
void write_y() {
    y.store(true, std::memory_order_seq_cst);
}
void read_x_then_y() {
    while (!x.load(std::memory_order_seq_cst)) {}
    if (y.load(std::memory_order_seq_cst)) {
        ++z;
    }
}
void read_y_then_x()
{
    while (!y.load(std::memory_order_seq_cst)) {}
    if (x.load(std::memory_order_seq_cst)) {
        ++z;
    }
}
int main() {
    std::thread t1(write_x);
    std::thread t2(write_y);
    std::thread t3(read_x_then_y);
    std::thread t4(read_y_then_x);
    t1.join();
    t2.join();
    t3.join();
    t4.join();
    if (z.load() == 0) {
        std::cout &lt;&lt; "This will never happen\n";
    }
    {
        std::cout &lt;&lt; "This will always happen and z = " &lt;&lt; z &lt;&lt; "\n";
    }
    return 0;
}</pre>
   <p>
    
     Because we are using
    
    <strong class="source-inline">
     
      std::memory_order_seq_cst
     
    </strong>
    
     when running the code, we should note
    
    
     
      the
     
    
    
     <a id="_idIndexMarker358">
     </a>
    
    
     
      following:
     
    
   </p>
   <ul>
    <li>
     
      Operations in each thread are executed in the given order (no reordering of
     
     
      
       atomic operations).
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       t1
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       t2
      
     </strong>
     
      update
     
     <strong class="source-inline">
      
       x
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       y
      
     </strong>
     
      in order, and
     
     <strong class="source-inline">
      
       t3
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       t4
      
     </strong>
     
      see the same order.
     
     
      Without this property,
     
     <strong class="source-inline">
      
       t3
      
     </strong>
     
      could see
     
     <strong class="source-inline">
      
       x
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       y
      
     </strong>
     
      change in order, but
     
     <strong class="source-inline">
      
       t4
      
     </strong>
     
      could see
     
     
      
       the opposite.
      
     
    </li>
    <li>
     
      Any other ordering may print
     
     <strong class="source-inline">
      
       This will never happen
      
     </strong>
     
      because
     
     <strong class="source-inline">
      
       t3
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       t4
      
     </strong>
     
      could see the changes to
     
     <strong class="source-inline">
      
       x
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       y
      
     </strong>
     
      in the opposite order.
     
     
      We will see an example of this in the
     
     
      
       next section.
      
     
    </li>
   </ul>
   <p>
    
     The sequential consistency in this example means that the following two things
    
    
     
      will happen:
     
    
   </p>
   <ul>
    <li>
     
      Each store is seen by all the threads; that is, each store operation synchronizes with all the load operations for each variable, and all the threads see these changes in the same order they
     
     
      
       are made
      
     
    </li>
    <li>
     
      The operations happen in the same order for each thread (operations run in the same order as in
     
     
      
       the code)
      
     
    </li>
   </ul>
   <p>
    
     Please note that the order between operations in different threads is not guaranteed and instructions from different threads may be executed in any order because the threads may
    
    
     
      be scheduled.
     
    
   </p>
   <h2 id="_idParaDest-109">
    <a id="_idTextAnchor108">
    </a>
    
     Acquire-release ordering
    
   </h2>
   <p>
    <strong class="bold">
     
      Acquire-release ordering
     
    </strong>
    
     is less stringent than sequential consistency ordering.
    
    
     We don’t get the total
    
    <a id="_idIndexMarker359">
    </a>
    
     ordering of operations we had with sequential consistency ordering, but some synchronization is still possible.
    
    
     In general, as we add more freedom to the memory ordering we may see a performance gain, but it will get more difficult to reason about the execution order of
    
    
     
      our code.
     
    
   </p>
   <p>
    
     In this ordering model, the atomic load operations are the
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     operations, the atomic store operations are the
    
    <strong class="source-inline">
     
      std::memory_order_release
     
    </strong>
    
     operations, and the atomic read-modify-write operations may be the
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::memory_order_release
     
    </strong>
    
     or
    
    
     <strong class="source-inline">
      
       std::memory_order_acq_rel
      
     </strong>
    
    
     
      operations.
     
    
   </p>
   <p>
    <strong class="bold">
     
      Acquire semantics
     
    </strong>
    
     (used with
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     ) ensure that all of the read or write operations in
    
    <a id="_idIndexMarker360">
    </a>
    
     one thread that appear
    
    <em class="italic">
     
      after
     
    </em>
    
     the acquire operation in the source code happen after the acquire operation.
    
    
     This prevents the memory from reordering the reads and writes that follow the
    
    
     
      acquire operation.
     
    
   </p>
   <p>
    <strong class="bold">
     
      Release semantics
     
    </strong>
    
     (used with
    
    <strong class="source-inline">
     
      std::memory_order_release
     
    </strong>
    
     ) ensure that the read or write operations in one thread that appear
    
    <em class="italic">
     
      before
     
    </em>
    
     the release operation in the source code are completed before
    
    <a id="_idIndexMarker361">
    </a>
    
     the release operation.
    
    
     This prevents the memory reordering of the reads and writes that follow the
    
    
     
      release operation.
     
    
   </p>
   <p>
    
     The following example shows the same code as that shown in the previous section about sequential consistency, but in this case, we use the acquire-release memory order for the
    
    
     
      atomic operations:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
std::atomic&lt;bool&gt; x{ false };
std::atomic&lt;bool&gt; y{ false };
std::atomic&lt;int&gt; z{ 0 };
void write_x() {
    x.store(true, std::memory_order_release);
}
void write_y() {
    y.store(true, std::memory_order_release);
}
void read_x_then_y() {
    while (!x.load(std::memory_order_acquire)) {}
    if (y.load(std::memory_order_acquire)) {
        ++z;
    }
}
void read_y_then_x() {
    while (!y.load(std::memory_order_acquire)) {}
    if (x.load(std::memory_order_acquire)) {
        ++z;
    }
}
int main() {
    std::thread t1(write_x);
    std::thread t2(write_y);
    std::thread t3(read_x_then_y);
    std::thread t4(read_y_then_x);
    t1.join();
    t2.join();
    t3.join();
    t4.join();
    if (z.load() == 0) {
        std::cout &lt;&lt; "This will never happen\n";
    }
    {
        std::cout &lt;&lt; "This will always happen and z = " &lt;&lt; z &lt;&lt; "\n";
    }
    return 0;
}</pre>
   <p>
    
     In this case, it is possible for the value of
    
    <strong class="source-inline">
     
      z
     
    </strong>
    
     to be 0.
    
    
     Because we don’t have sequential consistency anymore
    
    <a id="_idIndexMarker362">
    </a>
    
     after
    
    <strong class="source-inline">
     
      t1
     
    </strong>
    
     sets
    
    <strong class="source-inline">
     
      x
     
    </strong>
    
     to
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      t2
     
    </strong>
    
     sets
    
    <strong class="source-inline">
     
      y
     
    </strong>
    
     to
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      t3
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      t4
     
    </strong>
    
     may have different views of how memory access is being performed.
    
    
     Because of the use of the acquire-release memory ordering,
    
    <strong class="source-inline">
     
      t3
     
    </strong>
    
     may see
    
    <strong class="source-inline">
     
      x
     
    </strong>
    
     as
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      y
     
    </strong>
    
     as
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     (remember, there is no enforce ordering) and
    
    <strong class="source-inline">
     
      t4
     
    </strong>
    
     may see
    
    <strong class="source-inline">
     
      x
     
    </strong>
    
     as
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      y
     
    </strong>
    
     as
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     .
    
    
     When this happens, the value of
    
    <strong class="source-inline">
     
      z
     
    </strong>
    
     will
    
    
     
      be 0.
     
    
   </p>
   <p>
    
     Besides
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      std::memory_order_release
     
    </strong>
    
     , and
    
    <strong class="source-inline">
     
      std::memory_order_acq_rel
     
    </strong>
    
     , the acquire-release memory ordering also includes the
    
    <strong class="source-inline">
     
      std::memory_order_consume
     
    </strong>
    
     option.
    
    
     We won’t be describing it because according to the online
    
    <a id="_idIndexMarker363">
    </a>
    
     C++ reference, “
    
    <em class="italic">
     
      the specification of release-consume ordering is being revised, and the use of std::memory_order_consume is
     
    </em>
    
     <em class="italic">
      
       temporarily discouraged
      
     </em>
    
    
     
      .”
     
    
   </p>
   <h2 id="_idParaDest-110">
    <a id="_idTextAnchor109">
    </a>
    
     Relaxed memory ordering
    
   </h2>
   <p>
    
     To perform the atomic
    
    <a id="_idIndexMarker364">
    </a>
    
     operation with
    
    <strong class="bold">
     
      relaxed memory ordering
     
    </strong>
    
     , we specify
    
    <strong class="source-inline">
     
      std::memory_order_relaxed
     
    </strong>
    
     as the memory
    
    
     
      order option.
     
    
   </p>
   <p>
    
     Relaxed memory ordering is the
    
    <a id="_idIndexMarker365">
    </a>
    
     weakest form of synchronization.
    
    
     It offers
    
    
     
      two guarantees:
     
    
   </p>
   <ul>
    <li>
     
      Atomicity of
     
     
      
       the operations.
      
     
    </li>
    <li>
     
      Atomic operations on the same atomic variable in a single thread are not reordered.
     
     
      This is called
     
     <strong class="bold">
      
       modification order consistency
      
     </strong>
     
      .
     
     
      There is no guarantee, however, that the other
     
     <a id="_idIndexMarker366">
     </a>
     
      threads will see these operations in the
     
     
      
       same order.
      
     
    </li>
   </ul>
   <p>
    
     Let’s consider the following scenario: one thread (
    
    <strong class="source-inline">
     
      th1
     
    </strong>
    
     ) stores values into an atomic variable.
    
    
     After a certain random interval of time, the variable will be overwritten with a new random value.
    
    
     We should assume for the sake of this example, that the sequence written is 2, 12, 23, 4, 6.
    
    
     Another thread,
    
    <strong class="source-inline">
     
      th2
     
    </strong>
    
     , reads the same variable periodically.
    
    
     The first time the variable is read,
    
    <strong class="source-inline">
     
      th2
     
    </strong>
    
     gets the value 23.
    
    
     Remember that the variable is atomic and that both load and store operations are done using the relaxed
    
    
     
      memory order.
     
    
   </p>
   <p>
    
     If
    
    <strong class="source-inline">
     
      th2
     
    </strong>
    
     reads the variable again, it can get the same value or any value written
    
    <em class="italic">
     
      after
     
    </em>
    
     the previously read value.
    
    
     It cannot read any value written before because the modification order consistency property would be violated.
    
    
     In the current example, the second read may get 23, 4, or 6 but not 2 or 12.
    
    
     If we get 4, th1 will go on to write 8, 19, and 7.
    
    
     Now th2 may get 4, 6, 8, 19, or 7 but not any number before 4 and
    
    
     
      so on.
     
    
   </p>
   <p>
    
     Between two or more threads, there is no guarantee of any order, but once a value is read, a previously written value cannot
    
    
     
      be read.
     
    
   </p>
   <p>
    
     The relaxed model cannot be used to synchronize threads, because there is no visibility order guarantee, but it is useful in scenarios where operations do not need to be coordinated tightly between threads, which can lead to
    
    
     
      performance improvements.
     
    
   </p>
   <p>
    
     It is generally safe to use when the order of execution does not affect the correctness of the program, such as incrementing counters used for statistics or reference counters where the exact order of increment is
    
    
     
      not important.
     
    
   </p>
   <p>
    
     In this section, we learned
    
    <a id="_idIndexMarker367">
    </a>
    
     about the C++ memory model and how it allows the order and synchronization of atomic operations with different memory order constraints.
    
    
     In the next section, we will see the atomic types and operations provided by the C++
    
    
     
      Standard Library.
     
    
   </p>
   <h1 id="_idParaDest-111">
    <a id="_idTextAnchor110">
    </a>
    
     C++ Standard Library atomic types and operations
    
   </h1>
   <p>
    
     We will now introduce the data types and functions provided by the C++ Standard Library to support atomic types and operations.
    
    
     As we have already seen, an atomic operation is an indivisible operation.
    
    
     To be able to perform atomic operations in C++, we need to use the atomic types provided by the C++
    
    
     
      Standard Library.
     
    
   </p>
   <h2 id="_idParaDest-112">
    <a id="_idTextAnchor111">
    </a>
    
     C++ Standard Library atomic types
    
   </h2>
   <p>
    
     The atomic types provided
    
    <a id="_idIndexMarker368">
    </a>
    
     by the C++ Standard Library are defined in the
    
    <strong class="source-inline">
     
      &lt;atomic&gt;
     
    </strong>
    
     
      header file.
     
    
   </p>
   <p>
    
     You can see the documentation for all the atomic types defined in the
    
    <strong class="source-inline">
     
      &lt;atomic&gt;
     
    </strong>
    
     header in the online C++ reference, which you can access at
    
    <a href="https://en.cppreference.com/w/cpp/atomic/atomic">
     
      https://en.cppreference.com/w/cpp/atomic/atomic
     
    </a>
    
     .
    
    
     We won’t include all the content in this reference here (that’s what the reference is for!), but we will introduce the main concepts and use examples to further elaborate
    
    
     
      our explanations.
     
    
   </p>
   <p>
    
     The atomic types provided by the C++ Standard Library are
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       std::atomic_flag
      
     </strong>
     
      : Atomic Boolean type (but different from
     
     <strong class="source-inline">
      
       std::atomic&lt;bool&gt;
      
     </strong>
     
      ).
     
     
      It is the only atomic type that is guaranteed to be lock-free.
     
     
      It does not provide load or store operations.
     
     
      It is the most basic atomic type of all.
     
     
      We will use it to implement a very simple
     
     
      
       mutex-like lock.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       std::atomic&lt;T&gt;
      
     </strong>
     
      : This is a template for defining atomic types.
     
     
      All the intrinsic types have their own corresponding atomic type defined using this template.
     
     
      The following are some examples of
     
     
      
       these types:
      
     
     <ul>
      <li>
       <strong class="source-inline">
        
         std::atomic&lt;bool&gt;
        
       </strong>
       
        (and its alias
       
       <strong class="source-inline">
        
         atomic_bool
        
       </strong>
       
        ): We will use this atomic type to implement the lazy one-time initialization of a variable from
       
       
        
         several threads.
        
       
      </li>
      <li>
       <strong class="source-inline">
        
         std::atomic&lt;int&gt;
        
       </strong>
       
        (and its alias
       
       <strong class="source-inline">
        
         atomic_int
        
       </strong>
       
        ): We have seen this atomic type
       
       <a id="_idIndexMarker369">
       </a>
       
        already in the simple counter example.
       
       
        We will use it again in an example to gather statistics (very similar to the
       
       
        
         counter example).
        
       
      </li>
      <li>
       <strong class="source-inline">
        
         std::atomic&lt;intptr_t&gt;
        
       </strong>
       
        (and its
       
       
        
         alias
        
       
       
        <strong class="source-inline">
         
          atomic_intptr_t
         
        </strong>
       
       
        
         ).
        
       
      </li>
      <li>
       
        C++20 introduced atomic smart pointers:
       
       <strong class="source-inline">
        
         std::atomic&lt;std::shared_ptr&lt;U&gt;&gt;
        
       </strong>
       
        
         and
        
       
       
        <strong class="source-inline">
         
          std::atomic&lt;std::weak_ptr&lt;U&gt;&gt;
         
        </strong>
       
       
        
         .
        
       
      </li>
     </ul>
    </li>
    <li>
     
      Since the release of C++20, there is a new atomic
     
     
      
       type,
      
     
     
      <strong class="source-inline">
       
        std::atomic_ref&lt;T&gt;
       
      </strong>
     
     
      
       .
      
     
    </li>
   </ul>
   <p>
    
     In this chapter, we will focus on
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     and some of the
    
    <strong class="source-inline">
     
      std::atomic
     
    </strong>
    
     types.
    
    
     For the other atomic types we have mentioned here, you can access the online C++ reference using the
    
    
     
      previous link.
     
    
   </p>
   <p>
    
     Before any further explanation of some of these types, there is a very important clarification to be made: just because a type is
    
    <em class="italic">
     
      atomic
     
    </em>
    
     , that doesn’t guarantee it is
    
    <em class="italic">
     
      lock-free
     
    </em>
    
     .
    
    
     By atomic here, we mean indivisible operation, and by lock-free, we mean with special CPU atomic instructions support.
    
    
     If there is no hardware support for certain atomic operations, they will be implemented using locks by the C++
    
    
     
      Standard Library.
     
    
   </p>
   <p>
    
     To check whether an atomic type is lock-free we can use the following member function of any of the
    
    
     <strong class="source-inline">
      
       std::atomic&lt;T&gt;
      
     </strong>
    
    
     
      types:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       bool is_lock_free() const noexcept
      
     </strong>
     
      : This returns
     
     <strong class="source-inline">
      
       true
      
     </strong>
     
      if all the atomic operations of this type are lock-free, and
     
     <strong class="source-inline">
      
       false
      
     </strong>
     
      otherwise (except for
     
     <strong class="source-inline">
      
       std::atomic_flag
      
     </strong>
     
      , which is guaranteed to always be lock-free).
     
     
      The rest of the atomic types can be implemented using locks such as mutexes to guarantee the atomicity of the operations.
     
     
      Also, some atomic types may be lock-free only sometimes.
     
     
      If only aligned memory access can be lock-free in a certain CPU, then the misaligned
     
     <a id="_idIndexMarker370">
     </a>
     
      objects of that same atomic type will be implemented
     
     
      
       using locks.
      
     
    </li>
   </ul>
   <p>
    
     There is also a constant used to indicate whether an atomic type is
    
    
     
      always lock-free:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       static constexpr bool is_always_lock_free = /* implementation defined */
      
     </strong>
     
      : The value of this constant will be
     
     <strong class="source-inline">
      
       true
      
     </strong>
     
      if the atomic type is always lock-free (even for misaligned objects,
     
     
      
       for example)
      
     
    </li>
   </ul>
   <p>
    
     It is important to be aware of this: an atomic type is not guaranteed to be lock-free.
    
    
     The
    
    <strong class="source-inline">
     
      std::atomic&lt;T&gt;
     
    </strong>
    
     template is not a magic mechanism that can turn all atomic types into lock-free
    
    
     
      atomic types.
     
    
   </p>
   <h2 id="_idParaDest-113">
    <a id="_idTextAnchor112">
    </a>
    
     C++ Standard Library atomic operations
    
   </h2>
   <p>
    
     There are two main types of
    
    <a id="_idIndexMarker371">
    </a>
    
     
      atomic operations:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Member functions of atomic types
      
     </strong>
     
      : For example,
     
     <strong class="source-inline">
      
       std::atomic&lt;int&gt;
      
     </strong>
     
      has the
     
     <strong class="source-inline">
      
       load()
      
     </strong>
     
      member function to atomically read
     
     
      
       its value
      
     
    </li>
    <li>
     <strong class="bold">
      
       Free functions
      
     </strong>
     
      : The
     
     <strong class="source-inline">
      
       const std::atomic_load(const std::atomic&lt;T&gt;* obj)
      
     </strong>
     
      function does exactly the same as the
     
     
      
       previous one
      
     
    </li>
   </ul>
   <p>
    
     You can access the following code (and the generated assembly code, if you are interested) at
    
    <a href="https://godbolt.org/z/Yhdr3Y1Y8">
     
      https://godbolt.org/z/Yhdr3Y1Y8
     
    </a>
    
     .
    
    
     This code shows the use of both member functions and
    
    
     
      free functions:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;iostream&gt;
std::atomic&lt;int&gt; counter {0};
int main() {
    // Using member functions
    int count = counter.load();
    std::cout &lt;&lt; count &lt;&lt; std::endl;
    count++;
    counter.store(count);
    // Using free functions
    count = std::atomic_load(&amp;counter);
    std::cout &lt;&lt; count &lt;&lt; std::endl;
    count++;
    std::atomic_store(&amp;counter, count);
    return 0;
}</pre>
   <p>
    
     Most of the atomic operation functions have a parameter to indicate the memory order.
    
    
     We have already explained
    
    <a id="_idIndexMarker372">
    </a>
    
     what the memory order is, and what memory ordering types are provided by C++ in the section about the C++
    
    
     
      memory model.
     
    
   </p>
   <h2 id="_idParaDest-114">
    <a id="_idTextAnchor113">
    </a>
    
     Example – simple spin-lock implemented using the C++ atomic flag
    
   </h2>
   <p>
    
     The
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     atomic type is the most basic standard atomic type.
    
    
     It only has two states: set
    
    <a id="_idIndexMarker373">
    </a>
    
     and not set (which we can also call true and false).
    
    
     It is always lock-free, in contrast to any other standard atomic type.
    
    
     Because it is so simple, it is mainly used as a
    
    
     
      building block.
     
    
   </p>
   <p>
    
     This is the code for the atomic
    
    
     
      flag example:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
class spin_lock {
public:
    spin_lock() = default;
    spin_lock(const spin_lock &amp;) = delete;
    spin_lock &amp;operator=(const spin_lock &amp;) = delete;
    void lock() {
        while  (flag.test_and_set(std::memory_order_acquire)) {
        }
    }
    void unlock() {
        flag.clear(std::memory_order_release);
    }
private:
    std::atomic_flag flag = ATOMIC_FLAG_INIT;
};</pre>
   <p>
    
     We need to initialize
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     before using it.
    
    
     The following code shows how to
    
    
     
      do that:
     
    
   </p>
   <pre class="source-code">
std::atomic_flag flag = ATOMIC_FLAG_INIT;</pre>
   <p>
    
     This is the only way to initialize
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     to a definite value.
    
    
     The value of
    
    <strong class="source-inline">
     
      ATOMIC_FLAG_INIT
     
    </strong>
    
     is
    
    
     
      implementation defined.
     
    
   </p>
   <p>
    
     Once the flag is initialized, we
    
    <a id="_idIndexMarker374">
    </a>
    
     can perform two atomic operations
    
    
     
      on it:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       clear
      
     </strong>
     
      : This atomically sets the flag
     
     
      
       to
      
     
     
      <strong class="source-inline">
       
        false
       
      </strong>
     
    </li>
    <li>
     <strong class="source-inline">
      
       test_and_set
      
     </strong>
     
      : This atomically sets the flag to
     
     <strong class="source-inline">
      
       true
      
     </strong>
     
      and obtains its
     
     
      
       previous value
      
     
    </li>
   </ul>
   <p>
    
     The
    
    <strong class="source-inline">
     
      clear
     
    </strong>
    
     function can only be called with a relaxed, release, or sequential consistency memory order.
    
    
     The
    
    <strong class="source-inline">
     
      test_and_set
     
    </strong>
    
     function can only be called with relaxed, acquire, or sequential consistency.
    
    
     Using any other memory order will result in
    
    
     
      undefined behavior.
     
    
   </p>
   <p>
    
     Now let’s see how we can implement a simple spinlock using
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     .
    
    
     First, we know that the operations are atomic, so the thread either clears the flag or it doesn’t, and if a thread clears the flag, it is fully cleared.
    
    
     It is not possible for the thread to
    
    <em class="italic">
     
      half-clear
     
    </em>
    
     the flag (remember this would be possible for some non-atomic flags).
    
    
     The
    
    <strong class="source-inline">
     
      test_and_set
     
    </strong>
    
     function is atomic too, so the flag is set to
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     , and we get the previous state in just
    
    
     
      one go.
     
    
   </p>
   <p>
    
     To implement the basic spinlock, we need an atomic flag to atomically handle the lock status and two functions:
    
    <strong class="source-inline">
     
      lock()
     
    </strong>
    
     to acquire the lock (as we have for a mutex) and
    
    <strong class="source-inline">
     
      unlock()
     
    </strong>
    
     to release
    
    
     
      the lock.
     
    
   </p>
   <h3>
    
     Simple spin lock unlock() function
    
   </h3>
   <p>
    
     We will begin with
    
    <strong class="source-inline">
     
      unlock()
     
    </strong>
    
     , the simplest
    
    <a id="_idIndexMarker375">
    </a>
    
     function.
    
    
     It will only reset the flag (by making it false) and
    
    
     
      nothing more:
     
    
   </p>
   <pre class="source-code">
void unlock()
{
    flag.clear(std::memory_order_release);
}</pre>
   <p>
    
     The code is straightforward.
    
    
     If we leave out the
    
    <strong class="source-inline">
     
      std::memory_order_seq_cst
     
    </strong>
    
     parameter, the strictest memory order option, sequential consistency, will
    
    
     
      be applied.
     
    
   </p>
   <h3>
    
     Simple spin lock lock() function
    
   </h3>
   <p>
    
     The lock function has more steps.
    
    
     First, let’s explain what it does:
    
    <strong class="source-inline">
     
      lock()
     
    </strong>
    
     must see whether the atomic flag is on.
    
    
     If it is off, then
    
    <a id="_idIndexMarker376">
    </a>
    
     turn it on and finish.
    
    
     If the flag is on, then keep on looking until another thread turns it off.
    
    
     We will use
    
    <strong class="source-inline">
     
      test_and_set()
     
    </strong>
    
     to make this
    
    
     
      function work:
     
    
   </p>
   <pre class="source-code">
void lock()
{
    while (flag.test_and_set(std::memory_order_acquire)) {}
}</pre>
   <p>
    
     The preceding code works in the following way: inside a
    
    <strong class="source-inline">
     
      while
     
    </strong>
    
     loop,
    
    <strong class="source-inline">
     
      test_and_set
     
    </strong>
    
     sets the flag to
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     and returns the previous value.
    
    
     If the flag is already set, setting it again doesn’t change anything and the function returns
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     , so the loop keeps on setting the flag.
    
    
     When, eventually,
    
    <strong class="source-inline">
     
      test_and_set
     
    </strong>
    
     returns
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     , this means that the flag was cleared and we can exit
    
    
     
      the loop.
     
    
   </p>
   <h3>
    
     Simple spin lock issues
    
   </h3>
   <p>
    
     The simple spin lock implementation has been included in this chapter to introduce the use of atomic types (
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     , the simplest standard atomic type) and operations (
    
    <strong class="source-inline">
     
      clear
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      test_and_set
     
    </strong>
    
     ), but it has some
    
    
     
      serious issues:
     
    
   </p>
   <ul>
    <li>
     
      The first of these is its bad performance.
     
     
      The code in the repo will let you experiment.
     
     
      Expect the
     
     <a id="_idIndexMarker377">
     </a>
     
      spinlock performance to be much worse than that of
     
     
      
       the mutex.
      
     
    </li>
    <li>
     
      The thread is spinning all the time waiting for the flag to be cleared.
     
     
      This busy wait is something to avoid, especially if there is
     
     
      
       thread contention.
      
     
    </li>
   </ul>
   <p>
    
     You can try out the preceding code for this example.
    
    
     We got these results, shown in
    
    <em class="italic">
     
      Table 5.1
     
    </em>
    
     , when we ran it.
    
    
     The code adds 1 to a counter 200 million times in
    
    
     
      each thread.
     
    
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table001-2">
    <colgroup>
     <col/>
     <col/>
     <col/>
     <col/>
    </colgroup>
    <thead>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           std::mutex
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           spinlock
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic counter
          
         </strong>
        
       </p>
      </td>
     </tr>
    </thead>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         
          One thread
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          1.03 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          1.33 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          0.82 s
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         
          Two threads
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          10.15 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          39.14 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          4.52 s
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         
          Four threads
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          24.61 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          128.84 s
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          9.13 s
         
        
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Table 5.1: Synchronization primitives profiling results
    
   </p>
   <p>
    
     We can see from the preceding table how poorly the simple spinlock works and how it worsens with the addition of threads.
    
    
     Note that this simple example is only for learning and that both the simple
    
    <strong class="source-inline">
     
      std::mutex
     
    </strong>
    
     spinlock and the atomic counter can be improved so that the atomic type
    
    
     
      performs better.
     
    
   </p>
   <p>
    
     In this section, we have looked at
    
    <strong class="source-inline">
     
      std::atomic_flag
     
    </strong>
    
     , the most basic atomic type provided by the C++ Standard Library.
    
    
     For further information about this type and about the new functionality added in C++20 please refer to the online C++ reference, which is available
    
    
     
      at
     
    
    <a href="https://en.cppreference.com/w/cpp/atomic/atomic_flag">
     
      
       https://en.cppreference.com/w/cpp/atomic/atomic_flag
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     In the following section, we will look at how to create a simple way for a thread to tell the main thread how many items it
    
    
     
      has processed.
     
    
   </p>
   <h2 id="_idParaDest-115">
    <a id="_idTextAnchor114">
    </a>
    
     Example – thread progress reporting
    
   </h2>
   <p>
    
     Sometimes we want to
    
    <a id="_idIndexMarker378">
    </a>
    
     check the progress of a thread or be notified when it finishes.
    
    
     This can be done in different ways, for example, using a mutex and a condition variable, or a shared variable synchronized by a mutex, as we have seen in
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     .
    
    
     We also saw how to use atomic operations to synchronize a counter in this chapter.
    
    
     We will use a similar counter in the
    
    
     
      following example:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
constexpr int NUM_ITEMS{100000};
int main() {
    std::atomic&lt;int&gt; progress{0};
    std::thread worker([&amp;progress] {
        for (int i = 1; i &lt;= NUM_ITEMS; ++i) {
            progress.store(i, std::memory_order_relaxed);
            std::this_thread::sleep_for(std::chrono::milliseconds(1));
        }
    });
    while (true) {
        int processed_items = progress.load(std::memory_order_relaxed);
        std::cout &lt;&lt; "Progress: "
                  &lt;&lt; processed_items &lt;&lt; " / " &lt;&lt; NUM_ITEMS
                  &lt;&lt; std::endl;
        if (processed_items == NUM_ITEMS) {
            break;
        }
        std::this_thread::sleep_for(std::chrono::seconds(10));
    }
    worker.join();
    return 0;
}</pre>
   <p>
    
     The preceding code implements a thread (
    
    <strong class="source-inline">
     
      worker
     
    </strong>
    
     ) that handles a certain number of items (here the handling is simulated just by making the thread sleep).
    
    
     Every time the thread handles an item, it increments
    
    <a id="_idIndexMarker379">
    </a>
    
     the variable progress.
    
    
     The main thread executes a
    
    <strong class="source-inline">
     
      while
     
    </strong>
    
     loop and, in each iteration, it accesses the
    
    <strong class="source-inline">
     
      progress
     
    </strong>
    
     variable and writes a report of the progress (number of items handled).
    
    
     Once all the items are handled, the loop
    
    
     
      is finished.
     
    
   </p>
   <p>
    
     In this example, we use the
    
    <strong class="source-inline">
     
      std::atomic&lt;int&gt;
     
    </strong>
    
     atomic type (an atomic integer) and two
    
    
     
      atomic operations:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       load()
      
     </strong>
     
      : This atomically retrieves the value of the
     
     
      <strong class="source-inline">
       
        progress
       
      </strong>
     
     
      
       variable
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       store()
      
     </strong>
     
      : This atomically modifies the value of the
     
     
      <strong class="source-inline">
       
        progress
       
      </strong>
     
     
      
       variable
      
     
    </li>
   </ul>
   <p>
    
     The
    
    <strong class="source-inline">
     
      worker
     
    </strong>
    
     thread processing
    
    <strong class="source-inline">
     
      progress
     
    </strong>
    
     is read and written atomically, so no race conditions occur when two threads access the
    
    
     <strong class="source-inline">
      
       progress
      
     </strong>
    
    
     
      variable.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      load()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      store()
     
    </strong>
    
     atomic operations have an extra parameter to indicate the memory order.
    
    
     In this example, we have used
    
    <strong class="source-inline">
     
      std::memory_order_relaxed
     
    </strong>
    
     .
    
    
     This is a typical example of the use of the relaxed memory order: one thread increases a counter, and another reads it.
    
    
     The only ordering we need is reading increasing values and for that, the relaxed memory order
    
    
     
      is enough.
     
    
   </p>
   <p>
    
     Having introduced the
    
    <strong class="source-inline">
     
      load()
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      store()
     
    </strong>
    
     atomic operations to atomically read and write a variable, let’s see another example of a simple
    
    
     
      statistic-gathering application.
     
    
   </p>
   <h2 id="_idParaDest-116">
    <a id="_idTextAnchor115">
    </a>
    
     Example – simple statistics
    
   </h2>
   <p>
    
     This example builds on the same idea as the previous one: a thread can use atomic operations to communicate progress (for example, the number of items processed) to another thread.
    
    
     In this new example, one thread will produce some data that another thread will read.
    
    
     We need to synchronize memory access because we have two threads sharing the same memory and
    
    <a id="_idIndexMarker380">
    </a>
    
     at least one of them is changing the memory.
    
    
     As in the previous example, we will use atomic operations for
    
    
     
      this purpose.
     
    
   </p>
   <p>
    
     The following code declares the atomic variables we are going to use to gather statistics – one for the number of items processed and two more (for the total processing time and average processing time for each
    
    
     
      item, respectively):
     
    
   </p>
   <pre class="source-code">
std::atomic&lt;int&gt; processed_items{0};
std::atomic&lt;float&gt; total_time{0.0f};
std::atomic&lt;double&gt; average_time{0.0};</pre>
   <p>
    
     We use atomic float and double for total time and average time.
    
    
     In the full example code, we make sure both types are lock-free, which means they use atomic instructions from the CPU (all modern CPUs should
    
    
     
      have that).
     
    
   </p>
   <p>
    
     Now let’s see how the worker thread uses
    
    
     
      the variables:
     
    
   </p>
   <pre class="source-code">
processed_items.fetch_add(1, std::memory_order_relaxed);
total_time.fetch_add(elapsed_s, std::memory_order_relaxed);
average_time.store(total_time.load() / processed_items.load(), std::memory_order_relaxed);</pre>
   <p>
    
     The first line increments the processed items by 1 in an atomic way.
    
    
     The
    
    <strong class="source-inline">
     
      fetch_add
     
    </strong>
    
     function adds
    
    <strong class="source-inline">
     
      1
     
    </strong>
    
     to the variable value and gives back the old value (we are not using it in
    
    
     
      this case).
     
    
   </p>
   <p>
    
     The second line adds
    
    <strong class="source-inline">
     
      elapsed_s
     
    </strong>
    
     (the time it took to process one item in seconds) to the
    
    <strong class="source-inline">
     
      total_time
     
    </strong>
    
     variable, which we use to keep track of the time it takes to process all
    
    
     
      the items.
     
    
   </p>
   <p>
    
     Then, the third line computes the mean time for each item by atomically reading
    
    <strong class="source-inline">
     
      total_time
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      processed_items
     
    </strong>
    
     and atomically writing the result in
    
    <strong class="source-inline">
     
      average_time
     
    </strong>
    
     .
    
    
     Alternatively, we could use the values from the
    
    <strong class="source-inline">
     
      fetch_add()
     
    </strong>
    
     calls to calculate the mean time, but they don’t include the last item that was processed.
    
    
     We could also do the calculation of
    
    <strong class="source-inline">
     
      average_time
     
    </strong>
    
     in the main thread, but we do it in the worker thread here, just as an example and to practice using atomic operations.
    
    
     Keep in mind that our aim (at least in this chapter) is not so much speed but learning how to use
    
    
     
      atomic operations.
     
    
   </p>
   <p>
    
     The following is
    
    <a id="_idIndexMarker381">
    </a>
    
     the full code for the
    
    
     
      statistics example:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
constexpr int NUM_ITEMS{10000};
void process() {
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution&lt;&gt; dis(1, 20);
    int sleep_duration = dis(gen);
        std::this_thread::sleep_for(std::chrono::milliseconds(sleep_duration));
}
int main() {
    std::atomic&lt;int&gt; processed_items{0};
    std::atomic&lt;float&gt; total_time{0.0f};
    std::atomic&lt;double&gt; average_time{0.0};
    std::thread worker([&amp;] {
        for (int i = 1; i &lt;= NUM_ITEMS; ++i) {
            auto now = std::chrono::high_resolution_clock::now();
            process();
            auto elapsed = 
                std::chrono::high_resolution_clock::now() - now;
            float elapsed_s =
                std::chrono::duration&lt;float&gt;(elapsed).count();
            processed_items.fetch_add(1, std::memory_order_relaxed);
            total_time.fetch_add(elapsed_s, std::memory_order_relaxed);
            average_time.store(total_time.load() / processed_items.load(), std::memory_order_relaxed);
        }
    });
    while (true) {
        int items = processed_items.load(std::memory_order_relaxed);
        std::cout &lt;&lt; "Progress: " &lt;&lt; items &lt;&lt; " / " &lt;&lt; NUM_ITEMS &lt;&lt; std::endl;
        float time = total_time.load(std::memory_order_relaxed);
        std::cout &lt;&lt; "Total time: " &lt;&lt; time &lt;&lt; " sec" &lt;&lt; std::endl;
        double average = average_time.load(std::memory_order_relaxed);
        std::cout &lt;&lt; "Average time: " &lt;&lt; average * 1000 &lt;&lt; " ms" &lt;&lt; std::endl;
        if (items == NUM_ITEMS) {
            break;
        }
        std::this_thread::sleep_for(std::chrono::seconds(5));
    }
    worker.join();
    return 0;
}</pre>
   <p>
    
     Let’s summarize what we have seen up to this point in the
    
    
     
      current section:
     
    
   </p>
   <ul>
    <li>
     
      C++ standard atomic types: we used
     
     <strong class="source-inline">
      
       std::atomic_flag
      
     </strong>
     
      to implement a simple spinlock and we have used some of the
     
     <strong class="source-inline">
      
       std::atomic&lt;T&gt;
      
     </strong>
     
      types to implement
     
     <a id="_idIndexMarker382">
     </a>
     
      communication of simple data between threads.
     
     
      All the atomic types that we have seen
     
     
      
       are lock-free.
      
     
    </li>
    <li>
     
      The
     
     <strong class="source-inline">
      
       load()
      
     </strong>
     
      atomic operation to atomically read the value of an
     
     
      
       atomic variable.
      
     
    </li>
    <li>
     
      The
     
     <strong class="source-inline">
      
       store()
      
     </strong>
     
      atomic operation to atomically write a new value to an
     
     
      
       atomic variable.
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       clear()
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       test_and_set()
      
     </strong>
     
      , the special atomic operations provided
     
     
      
       by
      
     
     
      <strong class="source-inline">
       
        std::atomic_flag
       
      </strong>
     
     
      
       .
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       fetch_add()
      
     </strong>
     
      , to atomically add some value to an atomic variable and get its previous value.
     
     
      Integral and floating-point types also implement
     
     <strong class="source-inline">
      
       fetch_sub()
      
     </strong>
     
      , to subtract a certain value from an atomic variable and return its previous value.
     
     
      Some
     
     <a id="_idIndexMarker383">
     </a>
     
      functions for performing bitwise logic operations have been implemented just for integral types:
     
     <strong class="source-inline">
      
       fetch_and()
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       fetch_or()
      
     </strong>
     
      ,
     
     
      
       and
      
     
     
      <strong class="source-inline">
       
        fetch_xor()
       
      </strong>
     
     
      
       .
      
     
    </li>
   </ul>
   <p>
    
     The following table summarizes atomic types and operations.
    
    
     For an exhaustive description, please refer to the online C++
    
    
     
      reference:
     
    
    <a href="https://en.cppreference.com/w/cpp/atomic/atomic">
     
      
       https://en.cppreference.com/w/cpp/atomic/atomic
      
     
    </a>
   </p>
   <p>
    
     The table shows three new operations:
    
    <strong class="source-inline">
     
      exchange
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      compare_exchange_weak
     
    </strong>
    
     , and
    
    <strong class="source-inline">
     
      compare_exchange_strong
     
    </strong>
    
     .
    
    
     We will explain them using an example later.
    
    
     Most of the operations (that is, the functions, not the operators) have another parameter for the
    
    
     
      memory order.
     
    
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table002-1">
    <colgroup>
     <col/>
     <col/>
     <col/>
     <col/>
     <col/>
     <col/>
    </colgroup>
    <thead>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           Operation
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic_
          
         </strong>
        
       </p>
       <p>
        
         <strong class="bold">
          
           flag
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic &lt;bool&gt;
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic &lt;integral&gt;
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic &lt;floating-point&gt;
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         <strong class="bold">
          
           atomic &lt;other&gt;
          
         </strong>
        
       </p>
      </td>
     </tr>
    </thead>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline" lang="en-US" xml:lang="en-US">
          
           test_and_set
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           Clear
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           Load
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           Store
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline" lang="en-US" xml:lang="en-US">
          
           fetch_add, +=
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           fetch_sub, -=
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           fetch_and, &amp;=
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           fetch_or, |=
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           fetch_xor, ^=
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <strong class="source-inline">
         
          ++, --
         
        </strong>
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline">
          
           Exchange
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        
         <strong class="source-inline" lang="en-US" xml:lang="en-US">
          
           compare_exchange_weak,
          
         </strong>
        
       </p>
       <p>
        
         <strong class="source-inline" lang="en-US" xml:lang="en-US">
          
           compare_exchange_strong
          
         </strong>
        
       </p>
      </td>
      <td class="No-Table-Style">
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        
         
          YES
         
        
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Table 5.2: Atomic types and operations
    
   </p>
   <p>
    
     Let’s review the
    
    <strong class="source-inline">
     
      is_lock_free()
     
    </strong>
    
     function and the
    
    <strong class="source-inline">
     
      is_always_lock_free
     
    </strong>
    
     constant.
    
    
     We saw that if
    
    <strong class="source-inline">
     
      is_lock_free()
     
    </strong>
    
     is true, then the atomic type has lock-free operations with special CPU instructions.
    
    
     An atomic type can be lock-free only sometimes, so the
    
    <strong class="source-inline">
     
      is_always_lock_free
     
    </strong>
    
     constant tells us if the type is always lock-free.
    
    
     So far, all the
    
    <a id="_idIndexMarker384">
    </a>
    
     types we have seen are lock-free.
    
    
     Let’s see what happens when an atomic type
    
    
     
      is non-lock-free.
     
    
   </p>
   <p>
    
     The following shows the code for the non-lock-free
    
    
     
      atomic type:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;iostream&gt;
struct no_lock_free {
    int a[128];
    no_lock_free() {
        for (int i = 0; i &lt; 128; ++i) {
            a[i] = i;
        }
    }
};
int main() {
    std::atomic&lt;no_lock_free&gt; s;
    std::cout &lt;&lt; "Size of no_lock_free: " &lt;&lt; sizeof(no_lock_free) &lt;&lt; " bytes\n";
    std::cout &lt;&lt; "Size of std::atomic&lt;no_lock_free&gt;: " &lt;&lt; sizeof(s) &lt;&lt; " bytes\n";
    std::cout &lt;&lt; "Is std::atomic&lt;no_lock_free&gt; always lock-free: " &lt;&lt; std::boolalpha
              &lt;&lt; std::atomic&lt;no_lock_free&gt;::is_always_lock_free &lt;&lt; std::endl;
    std::cout &lt;&lt; "Is std::atomic&lt;no_lock_free&gt; lock-free: " &lt;&lt; std::boolalpha &lt;&lt; s.is_lock_free() &lt;&lt; std::endl;
    no_lock_free s1;
    s.store(s1);
    return 0;
}</pre>
   <p>
    
     When you execute the code, you will notice that the
    
    <strong class="source-inline">
     
      std::atomic&lt;no_lock_free&gt;
     
    </strong>
    
     type is not lock-free.
    
    
     Its size, 512 bytes, is the cause of this.
    
    
     When we assign a value to the atomic variable, that value is written
    
    <em class="italic">
     
      atomically
     
    </em>
    
     , but this operation does not use CPU atomic instructions, that is, it is not lock-free.
    
    
     The implementation of this operation depends on the compiler but, in general, it uses either a mutex or a special spinlock (such as Microsoft
    
    
     
      Visual C++).
     
    
   </p>
   <p>
    
     The lesson here is that all
    
    <a id="_idIndexMarker385">
    </a>
    
     atomic types have atomic operations, but they are not all magically lock-free.
    
    
     If an atomic type is not lock-free, it is always better to implement it
    
    
     
      using locks.
     
    
   </p>
   <p>
    
     We learned that some atomic types are not lock-free.
    
    
     Now we will look at another example that shows the atomic operations we have not covered yet: the
    
    <strong class="source-inline">
     
      exchange
     
    </strong>
    
     and
    
    
     <strong class="source-inline">
      
       compare_exchange
      
     </strong>
    
    
     
      operations.
     
    
   </p>
   <h2 id="_idParaDest-117">
    <a id="_idTextAnchor116">
    </a>
    
     Example – lazy one-time initialization
    
   </h2>
   <p>
    
     Sometimes initializing an
    
    <a id="_idIndexMarker386">
    </a>
    
     object can be costly.
    
    
     For example, a given object may need to connect to a database or a server, and establishing this connection can take a long time.
    
    
     In these cases, we should initialize the object just before its use, and not when we define it in our program.
    
    
     This is called
    
    <strong class="bold">
     
      lazy initialization
     
    </strong>
    
     .
    
    
     Now let’s assume that more than one thread needs to use the object for the first time.
    
    
     If more than one thread initializes the object, then different connections would be created, and that would be wrong because the object opens and closes only one connection.
    
    
     For this reason, multiple initializations must be avoided.
    
    
     To ensure the object is initialized only once, we will utilize a method known as lazy
    
    
     
      one-time initialization.
     
    
   </p>
   <p>
    
     The following shows the code for lazy
    
    
     
      one-time initialization:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;
constexpr int NUM_THREADS{8};
void process() {
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution&lt;&gt; dis(1, 1000000);
    int sleep_duration = dis(gen);
    std::this_thread::sleep_for(std::chrono::microseconds(sleep_duration));
}
int main() {
    std::atomic&lt;int&gt; init_thread{0};
    auto worker = [&amp;init_thread](int i) {
        process();
        int init_value = init_thread.load(std::memory_order::seq_cst);
        if (init_value == 0) {
            int expected = 0;
            if (init_thread.compare_exchange_strong(expected, i, std::memory_order::seq_cst)) {
                std::cout &lt;&lt; "Previous value of init_thread: " &lt;&lt; expected &lt;&lt; "\n";
                std::cout &lt;&lt; "Thread " &lt;&lt; i &lt;&lt; " initialized\n";
            } else {
                // init_thread was already initialized
            }
        } else {
            // init_thread was already initialized
        }
    };
    std::vector&lt;std::thread&gt; threads;
    for (int i = 1; i &lt;= NUM_THREADS; ++i) {
        threads.emplace_back(worker, i);
    }
    for (auto &amp;t: threads) {
        t.join();
    }
    std::cout &lt;&lt; "Thread: " &lt;&lt; init_thread.load() &lt;&lt; " initialized\n";
    return 0;
}</pre>
   <p>
    
     There are some operations in the atomic type operations table that we saw earlier in this chapter that we have not yet discussed.
    
    
     We will now explain
    
    <strong class="source-inline">
     
      compare_exchange_strong
     
    </strong>
    
     using an example.
    
    
     In the example, we have a variable that starts with a value of 0.
    
    
     Several threads are running, each with a unique integer ID (1, 2, 3, and so on).
    
    
     We want to set the variable’s value to the ID of the thread that sets it first and initialize the
    
    <a id="_idIndexMarker387">
    </a>
    
     variable only once.
    
    
     In
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     , we learned about
    
    <strong class="source-inline">
     
      std::once_flag
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      std::call_once
     
    </strong>
    
     , which we could use to implement this one-time initialization, but this chapter is about atomic types and operations, so we will use those to achieve
    
    
     
      our goal.
     
    
   </p>
   <p>
    
     To be sure that the initialization of the
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     variable is done only once and to avoid race conditions due to write access from more than one thread, we use an atomic
    
    <strong class="source-inline">
     
      int
     
    </strong>
    
     .
    
    
     Line
    
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     atomically reads the content of
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     .
    
    
     If the value is not 0, then that means it has been already initialized and the worker thread does
    
    
     
      nothing else.
     
    
   </p>
   <p>
    
     The current value of
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     is stored in the
    
    <strong class="source-inline">
     
      expected
     
    </strong>
    
     variable, which represents the value we expect
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     will have when we try to initialize it.
    
    
     Now line
    
    <strong class="source-inline">
     
      [2]
     
    </strong>
    
     performs the
    
    
     
      following steps:
     
    
   </p>
   <ol>
    <li>
     
      Compare the
     
     <strong class="source-inline">
      
       init_thread
      
     </strong>
     
      current value to the
     
     <strong class="source-inline">
      
       expected
      
     </strong>
     
      value (which, again, is equal
     
     
      
       to 0).
      
     
    </li>
    <li>
     
      If the comparison is not successful, copy the
     
     <strong class="source-inline">
      
       init_thread
      
     </strong>
     
      current value into
     
     <strong class="source-inline">
      
       expected
      
     </strong>
     
      and
     
     
      
       return
      
     
     
      <strong class="source-inline">
       
        false
       
      </strong>
     
     
      
       .
      
     
    </li>
    <li>
     
      If the comparison is successful, copy the
     
     <strong class="source-inline">
      
       init_thread
      
     </strong>
     
      current value into
     
     <strong class="source-inline">
      
       expected
      
     </strong>
     
      , then set the
     
     <strong class="source-inline">
      
       init_thread
      
     </strong>
     
      current value to
     
     <strong class="source-inline">
      
       i
      
     </strong>
     
      and
     
     
      
       return
      
     
     
      <strong class="source-inline">
       
        true
       
      </strong>
     
     
      
       .
      
     
    </li>
   </ol>
   <p>
    
     The current thread will have initialized
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     only if
    
    <strong class="source-inline">
     
      compare_exchange_strong
     
    </strong>
    
     returns
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     .
    
    
     Also, note that we need to perform a comparison again (even if line
    
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     returned 0 as the current value of
    
    <strong class="source-inline">
     
      init_thread
     
    </strong>
    
     ) because it is possible that another thread has already initialized
    
    
     
      the variable.
     
    
   </p>
   <p>
    
     It is very important to note that if
    
    <strong class="source-inline">
     
      compare_exchange_strong
     
    </strong>
    
     returns
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     , then the comparison has failed, and if it returns
    
    <strong class="source-inline">
     
      true
     
    </strong>
    
     , then the comparison was successful.
    
    
     This is always true of
    
    <strong class="source-inline">
     
      compare_exchange_strong
     
    </strong>
    
     .
    
    
     On the other hand,
    
    <strong class="source-inline">
     
      compare_exchange_weak
     
    </strong>
    
     can fail (i.e., return
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     ) even if the comparison is successful.
    
    
     The reason for using it is that in some platforms it gives better performance when it is called inside
    
    
     
      a loop.
     
    
   </p>
   <p>
    
     For more information on these two functions, please refer to the online C++
    
    
     
      reference:
     
    
    <a href="https://en.cppreference.com/w/cpp/atomic/atomic/compare_exchange">
     
      
       https://en.cppreference.com/w/cpp/atomic/atomic/compare_exchange
      
     
    </a>
   </p>
   <p>
    
     In this section about
    
    <a id="_idIndexMarker388">
    </a>
    
     the C++ Standard Library atomic types and operations, we have seen
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      The most commonly used standard atomic types, such as
     
     <strong class="source-inline">
      
       std::atomic_flag
      
     </strong>
     
      
       and
      
     
     
      <strong class="source-inline">
       
        std::atomic&lt;int&gt;
       
      </strong>
     
    </li>
    <li>
     
      The most-used atomic operations:
     
     <strong class="source-inline">
      
       load()
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       store()
      
     </strong>
     
      ,
     
     
      
       and
      
     
     
      <strong class="source-inline">
       
        exchange_compare_strong()
       
      </strong>
     
     
      
       /
      
     
     
      <strong class="source-inline">
       
        exchange_compare_weak()
       
      </strong>
     
    </li>
    <li>
     
      Basic examples incorporating these atomic types and operations, including lazy one-time initialization and thread
     
     
      
       progress communication
      
     
    </li>
   </ul>
   <p>
    
     We have mentioned several times that most of the atomic operations (functions) let us pick the memory order we want to use.
    
    
     In the next section, we will implement a lock-free programming example: an SPSC
    
    
     
      lock-free queue.
     
    
   </p>
   <h1 id="_idParaDest-118">
    <a id="_idTextAnchor117">
    </a>
    
     SPSC lock-free queue
    
   </h1>
   <p>
    
     We have already looked at the C++ Standard Library’s features for atomics, such as atomic types and operations
    
    <a id="_idIndexMarker389">
    </a>
    
     and the memory model and orderings.
    
    
     Now we will see a complete example of using atomics to implement an SPSC
    
    
     
      lock-free queue.
     
    
   </p>
   <p>
    
     The main features of this
    
    <a id="_idIndexMarker390">
    </a>
    
     queue are
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       SPSC
      
     </strong>
     
      : This queue is designed to
     
     <a id="_idIndexMarker391">
     </a>
     
      work with two threads, one pushing elements to the queue and another getting elements from
     
     
      
       the queue.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Bounded
      
     </strong>
     
      : This queue has a fixed size.
     
     
      We need a method for checking when the queue reaches its capacity and
     
     <a id="_idIndexMarker392">
     </a>
     
      when it has
     
     
      
       no elements).
      
     
    </li>
    <li>
     <strong class="bold">
      
       Lock-free
      
     </strong>
     
      : This queue uses
     
     <a id="_idIndexMarker393">
     </a>
     
      atomic types that are always lock-free on modern Intel
     
     
      
       x64 CPUs.
      
     
    </li>
   </ul>
   <p>
    
     Before you begin to develop the queue, keep in mind that lock-free is not the same as wait-free (also keep in mind that wait-free does not eliminate waiting entirely; it just ensures that there is a limit to the number of steps required for each queue push/pop).
    
    
     Some aspects that mostly affect performance will be discussed in
    
    <a href="B22219_13.xhtml#_idTextAnchor267">
     
      <em class="italic">
       
        Chapter 13
       
      </em>
     
    </a>
    
     .
    
    
     In that chapter, we will also optimize the queue’s performance.
    
    
     For now, in this chapter, we will build an SPSC lock-free queue that is correct and performs adequately – we will show how its performance can be
    
    
     
      improved later.
     
    
   </p>
   <p>
    
     We used mutex and
    
    <a id="_idIndexMarker394">
    </a>
    
     condition variables to make an SPSC queue in
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     that consumer and producer threads could access safely.
    
    
     This chapter will use atomic operations to achieve the
    
    
     
      same goal.
     
    
   </p>
   <p>
    
     We will store the items in the queue using the same data structure:
    
    <strong class="source-inline">
     
      std::vector&lt;T&gt;
     
    </strong>
    
     with a fixed size, that is, a power of 2.
    
    
     This way, we can improve performance and find the next head and tail indices quickly without using the modulo operator that needs a division instruction.
    
    
     When using lock-free atomic types for better performance, we need to pay attention to everything that
    
    
     
      affects performance.
     
    
   </p>
   <h2 id="_idParaDest-119">
    <a id="_idTextAnchor118">
    </a>
    
     Why do we use a power of 2 buffer size?
    
   </h2>
   <p>
    
     We will use a vector to hold the queue items.
    
    
     The vector will have a fixed size, say
    
    <strong class="source-inline">
     
      N
     
    </strong>
    
     .
    
    
     We will make the vector act
    
    <a id="_idIndexMarker395">
    </a>
    
     similarly to a ring buffer, meaning that the index for accessing an element in the vector will loop back to the start after the end.
    
    
     The first element will follow the last one.
    
    
     As we learned in
    
    <a href="B22219_04.xhtml#_idTextAnchor074">
     
      <em class="italic">
       
        Chapter 4
       
      </em>
     
    </a>
    
     , we can do this with the
    
    
     
      modulo operator:
     
    
   </p>
   <pre class="source-code">
size_t next_index = (curr_index + 1) % N;</pre>
   <p>
    
     If the size is, for example, four elements, the index to the next element will be calculated as in the preceding code.
    
    
     For the last index, we have the
    
    
     
      following code:
     
    
   </p>
   <pre class="source-code">
next_index = (3 + 1) % 4 = 4 % 4 = 0;</pre>
   <p>
    
     Therefore, as we said, the vector will be a ring buffer because, after the last element, we will go back to the first one, then the second one, and
    
    
     
      so on.
     
    
   </p>
   <p>
    
     We can use this method to get the next index for any buffer size
    
    <strong class="source-inline">
     
      N
     
    </strong>
    
     .
    
    
     But why do we only use sizes that are powers of 2?
    
    
     The answer is easy: performance.
    
    
     The modulo (
    
    <strong class="source-inline">
     
      %
     
    </strong>
    
     ) operator requires a division
    
    <a id="_idIndexMarker396">
    </a>
    
     instruction, which is expensive.
    
    
     When the size
    
    <strong class="source-inline">
     
      N
     
    </strong>
    
     is a power of 2, we can just do
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
size_t next_index = curr_index &amp; (N – 1);</pre>
   <p>
    
     This is much faster than using the
    
    
     
      modulo operator.
     
    
   </p>
   <h2 id="_idParaDest-120">
    <a id="_idTextAnchor119">
    </a>
    
     Buffer access synchronization
    
   </h2>
   <p>
    
     To access the queue buffer, we need
    
    
     
      two indices:
     
    
   </p>
   <ul>
    <li>
     <strong class="source-inline">
      
       head
      
     </strong>
     
      : The index of the current element to
     
     
      
       be read
      
     
    </li>
    <li>
     <strong class="source-inline">
      
       tail
      
     </strong>
     
      : The index of the next element to
     
     
      
       be written
      
     
    </li>
   </ul>
   <p>
    
     The consumer thread will use the head index to read and write.
    
    
     The producer thread will use the tail index to read and
    
    <a id="_idIndexMarker397">
    </a>
    
     write.
    
    
     We need to synchronize access to these variables because
    
    
     
      of this:
     
    
   </p>
   <ul>
    <li>
     
      Only one thread (the consumer) writes
     
     <strong class="source-inline">
      
       head
      
     </strong>
     
      , meaning that it can read it with relaxed memory ordering because it always sees its own changes.
     
     
      Reading
     
     <strong class="source-inline">
      
       tail
      
     </strong>
     
      is done by the reader thread and it needs to synchronize with the producer’s writing of
     
     <strong class="source-inline">
      
       tail
      
     </strong>
     
      , so it needs acquire memory ordering.
     
     
      We could use sequential consistency for everything, but we want the best performance.
     
     
      When the consumer thread writes
     
     <strong class="source-inline">
      
       head
      
     </strong>
     
      , it needs to synchronize with the producer’s read of it, so it needs release
     
     
      
       memory ordering.
      
     
    </li>
    <li>
     
      For
     
     <strong class="source-inline">
      
       tail
      
     </strong>
     
      , only the producer thread writes it, so we can use relaxed memory ordering to read it, but we need release memory ordering to write it and synchronize it with the consumer thread’s reading.
     
     
      To synchronize with the consumer thread’s writing, we need acquire memory ordering to
     
     
      
       read
      
     
     
      <strong class="source-inline">
       
        head
       
      </strong>
     
     
      
       .
      
     
    </li>
   </ul>
   <p>
    
     The queue class member variables are
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
const std::size_t capacity_; // power of two buffer size
std::vector&lt;T&gt; buffer_; // buffer to store queue items handled like a ring buffer
std::atomic&lt;std::size_t&gt; head_{ 0 };
std::atomic&lt;std::size_t&gt; tail_{ 0 };</pre>
   <p>
    
     In this section, we have seen how to synchronize access to
    
    
     
      queue buffer.
     
    
   </p>
   <h2 id="_idParaDest-121">
    <a id="_idTextAnchor120">
    </a>
    
     Pushing elements into the queue
    
   </h2>
   <p>
    
     Once we have decided
    
    <a id="_idIndexMarker398">
    </a>
    
     on the data representation of the queue and how to synchronize access to its elements, let’s implement the function for pushing elements into
    
    
     
      the queue:
     
    
   </p>
   <pre class="source-code">
bool push(const T&amp; item) {
    std::size_t tail =
        tail_.load(std::memory_order_relaxed);
    std::size_t next_tail =
       (tail + 1) &amp; (capacity_ - 1);
    if (next_tail != head_.load(std::memory_order_acquire)) {
        buffer_[tail] = item;
        tail_.store(next_tail, std::memory_order_release);
        return true;
    }
    return false;
}</pre>
   <p>
    
     The current tail index, which is the buffer slot where the data item is to be pushed (if possible) into the queue, is atomically read in line
    
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     .
    
    
     As we mentioned earlier, this read can use
    
    <strong class="source-inline">
     
      std::memory_order_relaxed
     
    </strong>
    
     because only the producer thread changes this variable, and it is the only thread that
    
    
     
      calls push.
     
    
   </p>
   <p>
    
     Line
    
    <strong class="source-inline">
     
      [2]
     
    </strong>
    
     calculates the next index modulo capacity (remember that the buffer is a ring).
    
    
     We need to do this to check whether the queue
    
    
     
      is full.
     
    
   </p>
   <p>
    
     We perform the check in line
    
    <strong class="source-inline">
     
      [3]
     
    </strong>
    
     .
    
    
     We first atomically read the current value of the head using
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     because we want the producer thread to observe the modifications that the consumer thread has made to this variable.
    
    
     Then we compare its value with the next
    
    
     
      head index.
     
    
   </p>
   <p>
    
     If the next tail value is equal to the current head value, then (as per our convention) the queue is full, and we
    
    
     
      return
     
    
    
     <strong class="source-inline">
      
       false
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     If the queue is not full, line
    
    <strong class="source-inline">
     
      [4]
     
    </strong>
    
     copies the data item to the queue buffer.
    
    
     It is worth commenting here
    
    <a id="_idIndexMarker399">
    </a>
    
     that the data copy is
    
    
     
      not atomic.
     
    
   </p>
   <p>
    
     Line
    
    <strong class="source-inline">
     
      [5]
     
    </strong>
    
     atomically writes the new tail index value into
    
    <strong class="source-inline">
     
      tail_
     
    </strong>
    
     .
    
    
     Then,
    
    <strong class="source-inline">
     
      std::memory_order_release
     
    </strong>
    
     is used to make the changes visible to the consumer thread that atomically reads this variable
    
    
     
      with
     
    
    
     <strong class="source-inline">
      
       std::memory_order_acquire
      
     </strong>
    
    
     
      .
     
    
   </p>
   <h2 id="_idParaDest-122">
    <a id="_idTextAnchor121">
    </a>
    
     Popping elements from the queue
    
   </h2>
   <p>
    
     Let’s now
    
    <a id="_idIndexMarker400">
    </a>
    
     see how the
    
    <strong class="source-inline">
     
      pop
     
    </strong>
    
     function
    
    
     
      is implemented:
     
    
   </p>
   <pre class="source-code">
bool pop(T&amp; item) {
    std::size_t head =
        head_.load(std::memory_order_relaxed);
    if (head == tail_.load(std::memory_order_acquire)) {
        return false;
    }
    item = buffer_[head];
    head_.store((head + 1) &amp; (capacity_ - 1), std::memory_order_release);
    return true;
}</pre>
   <p>
    
     Line
    
    <strong class="source-inline">
     
      [1]
     
    </strong>
    
     atomically reads the current value of
    
    <strong class="source-inline">
     
      head_
     
    </strong>
    
     (index for the next item to be read).
    
    
     We use
    
    <strong class="source-inline">
     
      std::memory_order_relaxed
     
    </strong>
    
     because no order enforcement is required due to the
    
    <strong class="source-inline">
     
      head_
     
    </strong>
    
     variable being modified only by the consumer thread, which is the only thread
    
    
     
      calling
     
    
    
     <strong class="source-inline">
      
       pop
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Line
    
    <strong class="source-inline">
     
      [2]
     
    </strong>
    
     checks whether the queue is empty.
    
    
     If the current value of
    
    <strong class="source-inline">
     
      head_
     
    </strong>
    
     is the same as the current value of
    
    <strong class="source-inline">
     
      tail_
     
    </strong>
    
     , then the queue is empty, and the function just returns
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     .
    
    
     We atomically
    
    <a id="_idIndexMarker401">
    </a>
    
     read the value of
    
    <strong class="source-inline">
     
      tail_
     
    </strong>
    
     with
    
    <strong class="source-inline">
     
      std::memory_order_acquire
     
    </strong>
    
     to see the latest change done to
    
    <strong class="source-inline">
     
      tail_
     
    </strong>
    
     by the
    
    
     
      producer thread.
     
    
   </p>
   <p>
    
     Line
    
    <strong class="source-inline">
     
      [3]
     
    </strong>
    
     copies the data from the queue to the item reference passed as an argument to
    
    <strong class="source-inline">
     
      pop
     
    </strong>
    
     .
    
    
     Again, this copy is
    
    
     
      not atomic.
     
    
   </p>
   <p>
    
     Finally, line
    
    <strong class="source-inline">
     
      [4]
     
    </strong>
    
     updates the value of
    
    <strong class="source-inline">
     
      head_
     
    </strong>
    
     .
    
    
     Again, we atomically write the value using
    
    <strong class="source-inline">
     
      std::memory order_release
     
    </strong>
    
     for the consumer thread to see the changes made to
    
    <strong class="source-inline">
     
      head_
     
    </strong>
    
     by the
    
    
     
      consumer thread.
     
    
   </p>
   <p>
    
     The code for the SPSC lock-free queue implementation is
    
    
     
      the following:
     
    
   </p>
   <pre class="source-code">
#include &lt;atomic&gt;
#include &lt;cassert&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;thread&gt;
template&lt;typename T&gt;
class spsc_lock_free_queue {
public:
    // capacity must be power of two to avoid using modulo operator when calculating the index
    explicit spsc_lock_free_queue(size_t capacity) : capacity_(capacity), buffer_(capacity) {
        assert((capacity &amp; (capacity - 1)) == 0 &amp;&amp; "capacity must be a power of 2");
    }
    spsc_lock_free_queue(const spsc_lock_free_queue &amp;) = delete;
    spsc_lock_free_queue &amp;operator=(const spsc_lock_free_queue &amp;) = delete;
    bool push(const T &amp;item) {
        std::size_t tail = tail_.load(std::memory_order_relaxed);
        std::size_t next_tail = (tail + 1) &amp; (capacity_ - 1);
        if (next_tail != head_.load(std::memory_order_acquire)) {
            buffer_[tail] = item;
            tail_.store(next_tail, std::memory_order_release);
            return true;
        }
        return false;
    }
    bool pop(T &amp;item) {
        std::size_t head = head_.load(std::memory_order_relaxed);
        if (head == tail_.load(std::memory_order_acquire)) {
            return false;
        }
        item = buffer_[head];
        head_.store((head + 1) &amp; (capacity_ - 1), std::memory_order_release);
        return true;
    }
private:
    const std::size_t capacity_;
    std::vector&lt;T&gt; buffer_;
    std::atomic&lt;std::size_t&gt; head_{0};
    std::atomic&lt;std::size_t&gt; tail_{0};
};</pre>
   <p>
    
     The code for the full example can be found in the following book
    
    
     
      repo:
     
    
    <a href="https://github.com/PacktPublishing/Asynchronous-Programming-in-CPP/blob/main/Chapter_05/5x09-SPSC_lock_free_queue.cpp">
     
      
       https://github.com/PacktPublishing/Asynchronous-Programming-in-CPP/blob/main/Chapter_05/5x09-SPSC_lock_free_queue.cpp
      
     
    </a>
   </p>
   <p>
    
     In this section, we have
    
    <a id="_idIndexMarker402">
    </a>
    
     implemented an SPSC lock-free queue as an application of atomic types and operations.
    
    
     In
    
    <a href="B22219_13.xhtml#_idTextAnchor267">
     
      <em class="italic">
       
        Chapter 13
       
      </em>
     
    </a>
    
     , we will revisit this implementation and improve
    
    
     
      its performance.
     
    
   </p>
   <h1 id="_idParaDest-123">
    <a id="_idTextAnchor122">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     This chapter has introduced atomic types and operations, the C++ memory model, and a basic implementation of an SPSC
    
    
     
      lock-free queue.
     
    
   </p>
   <p>
    
     The following is a summary of what we have
    
    
     
      looked at:
     
    
   </p>
   <ul>
    <li>
     
      The C++ Standard Library atomic types and operations, what they are, and how to use them with
     
     
      
       some examples.
      
     
    </li>
    <li>
     
      The C++ memory model, and especially the different memory orderings it defines.
     
     
      Bear in mind that this is a very complex subject and that this section was just a basic introduction
     
     
      
       to it.
      
     
    </li>
    <li>
     
      How to implement a basic SPSC lock-free queue.
     
     
      As we mentioned previously, we will demonstrate how to improve its performance in
     
     <a href="B22219_13.xhtml#_idTextAnchor267">
      
       <em class="italic">
        
         Chapter 13
        
       </em>
      
     </a>
     
      .
     
     
      Examples of performance-improving actions include eliminating false sharing (what happens when two variables are in the same cache line and each variable is just modified by one thread) and reducing true sharing.
     
     
      Don’t worry if you don’t understand any of this now.
     
     
      We will cover it later and demonstrate how to run
     
     
      
       performance tests.
      
     
    </li>
   </ul>
   <p>
    
     This is a basic introduction to atomic operations to synchronize memory access from different threads.
    
    
     In some cases, the use of atomic operations is quite easy, similar to gathering statistics and simple counters.
    
    
     More involved applications, such as the implementation of an SPSC lock-free queue, require a deeper knowledge of atomic operations.
    
    
     The material we have seen in this chapter helps build an understanding of the basics and builds a foundation for further study of this
    
    
     
      complex subject.
     
    
   </p>
   <p>
    
     In the next chapter, we will look at promises and futures, two fundamental building blocks of asynchronous programming
    
    
     
      in C++.
     
    
   </p>
   <h1 id="_idParaDest-124">
    <a id="_idTextAnchor123">
    </a>
    
     Further reading
    
   </h1>
   <ul>
    <li>
     
      [Butenhof, 1997] David R.
     
     
      Butenhof, Programming with POSIX Threads, Addison
     
     
      
       Wesley, 1997.
      
     
    </li>
    <li>
     
      [Williams, 2019] Anthony Williams, C++ Concurrency in Action, Second Edition,
     
     
      
       Manning, 2019.
      
     
    </li>
    <li>
     
      Memory Model: Get Your Shared Data Under Control, Jana
     
     
      
       Machutová,
      
     
     <a href="https://www.youtube.com/watch?v=L5RCGDAan2Y">
      
       
        https://www.youtube.com/watch?v=L5RCGDAan2Y
       
      
     </a>
     
      
       .
      
     
    </li>
    <li>
     <em class="italic">
      
       C++ Atomics: From Basic To Advanced
      
     </em>
     
      , Fedor
     
     
      
       Pikus,
      
     
     <a href="https://www.youtube.com/watch?v=ZQFzMfHIxng">
      
       
        https://www.youtube.com/watch?v=ZQFzMfHIxng
       
      
     </a>
     
      
       .
      
     
    </li>
    <li>
     <em class="italic">
      
       Intel 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A: System Programming Guide, Part 1
      
     </em>
     
      , Intel
     
     
      
       Corporation,
      
     
     <a href="https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf">
      
       
        https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf
       
      
     </a>
     
      
       .
      
     
    </li>
   </ul>
  </div>
 

  <div><h1 id="_idParaDest-125" lang="en-US" xml:lang="en-US">
    <a id="_idTextAnchor124">
    </a>
    
     Part 3: Asynchronous Programming with Promises, Futures, and Coroutines
    
   </h1>
  </div>
  <div><p>
    
     In this part, we shift our focus to the core subject of this book, asynchronous programming, a critical aspect of building responsive, high-performance applications.
    
    
     We will learn how to execute tasks concurrently without blocking the main execution flow by utilizing tools such as promises, futures, packaged tasks, the
    
    <strong class="source-inline">
     
      std::async
     
    </strong>
    
     function, and coroutines, a revolutionary feature enabling asynchronous programming without the overhead of creating threads.
    
    
     We will also cover advanced techniques for sharing futures and examine real-world scenarios where these concepts are essential.
    
    
     These powerful mechanisms allow us to develop efficient, scalable, and maintainable asynchronous software needed for modern
    
    
     
      software systems.
     
    
   </p>
   <p>
    
     This part has the
    
    
     
      following chapters:
     
    
   </p>
   <ul>
    <li>
     <a href="B22219_06.xhtml#_idTextAnchor125">
      <em class="italic">
       
        Chapter 6
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Promises and Futures
      
     </em>
    </li>
    <li>
     <a href="B22219_07.xhtml#_idTextAnchor143">
      <em class="italic">
       
        Chapter 7
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       The Async Function
      
     </em>
    </li>
    <li>
     <a href="B22219_08.xhtml#_idTextAnchor164">
      <em class="italic">
       
        Chapter 8
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Asynchronous Programming Using Coroutines
      
     </em>
    </li>
   </ul>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
 </body></html>