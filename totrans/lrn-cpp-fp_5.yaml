- en: Procrastinating the Execution Process Using Lazy Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed recursion for repeating the function invocation
    in the functional approach. Now, we will discuss lazy evaluation that can make
    our code become more efficient since it will only run when we need it. We will
    also apply recursion, the topic we talked about in the previous chapter, to produce
    the lazy code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we discuss **lazy evaluation** to make code run faster. This
    will make the code become efficient since it will make sure that unnecessary code
    won''t be executed. The following are the topics we will discuss to dive into
    lazy evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: Distinguishing the difference between eager and lazy evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing code using the caching technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refactoring eager evaluation into lazy evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing the useful classes that can be reused in others' functional code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the expression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every programming language has its own strategy to determine when to evaluate
    the arguments of a function call and what type of value that has to be passed
    to the parameter. There are two kinds of strategy evaluation that are mostly used
    in a programming language--**strict** (eager) evaluation and **non-strict** (lazy)
    evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Running the expression immediately with strict evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Strict evaluation is used in the most imperative programming language. It will
    immediately execute the code we have. Let''s suppose we have the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In a strict evaluation, the innermost bracket will be calculated first, then
    work outwards for the preceding equation. This means we will calculate `y * z`,
    then add the result to `x`. To make it clearer, let''s see the following `strict.cpp`
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As we discussed earlier, the execution of the preceding code will be `y * z`
    first, then we will add the result to `x`, as we can see in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5df7ea63-3801-47d1-9fbd-e50d30c1f8ec.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding execution order is what we usually expect. However, in non-strict
    evaluation, we will reorder this execution process.
  prefs: []
  type: TYPE_NORMAL
- en: Delaying the expression with non-strict evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a non-strict evaluation, the `+` operator is reduced first, and then we
    reduce the inner formula, which is `(y * z)`. We will see that the evaluation
    will be started from the outside to the inside. We will refactor our previous
    `strict.cpp` code to make it become a non-strict evaluation. The code should be
    like the following `non_strict.cpp` code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, we modify the `OuterFormula()` function in the `strict.cpp`
    code into an `OuterFormulaNonStrict()` function in the `non_strict.cpp` code.
    In the `OuterFormulaNonStrict()` function, we pass a function as the argument
    in addition to the three variables--`x`, `y`, and `z`. As a result, the order
    of execution of the preceding expression is changed. Here is what we should see
    on the console screen when we run the `non_strict.cpp` code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce639e69-1325-47bc-b524-6894d77af3b5.png)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding output, we have proved that our code is performing non-strict
    evaluation since it now calculates the addition operator (`+`) first instead of
    the multiplication (`*`). However, the result is still correct, although the order
    has been changed.
  prefs: []
  type: TYPE_NORMAL
- en: The basic concept of lazy evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we create a lazy code, let's discuss the basic concepts of lazy evaluation.
    We will use the delaying process to make our code lazy, the caching technique
    to increase the performance of the code by avoiding needless calculations, and
    the optimizing technique to speed up the code by storing the results of expensive
    function calls and returning the cached result when the same inputs occur again.
    After we have looked at these techniques, we will try to develop the real lazy
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Delaying the process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic concept of laziness is delaying a process. In this section, we will
    discuss how to delay the execution of a particular process. We will create a new
    class named `Delay`. We will pass a function into it when we construct the class.
    The function won''t be run unless we invoke the `Fetch()` method. The implementation
    of the function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s consume the `Delay` class to procrastinate the execution. We will
    create a file named `delaying.cpp` that will run two functions--`multiply` and
    `division`. However, these two functions will only be run after we call the `Fetch()`
    method. The content of the file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As we discussed in [Chapter 1](58c8c3cc-432a-4664-be4d-a78917b16f15.xhtml),
    *Diving into Modern C++*, we can use a Lambda expression to build the `multiply`
    and `division` functions. We then pass them in each `Delay` constructor. In this
    stage, the function is not run yet. It will be run after the `Fetch()` method
    is invoked--`multiply.Fetch()` and `division.Fetch()`. The output we will see
    on the screen should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ade918f-d163-4d2b-9d84-d41ddc962d86.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see in the preceding output screenshot, the `multiply` and `division`
    instance is constructed when the `Fetch()` method is invoked (see the two white
    arrows), not when the constructor of the `Delay` class is invoked. Now, we have
    successfully delayed the execution, and we can say that the process is only executed
    when it is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Caching the value using the memoization technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now have successfully delayed the execution of the function by consuming
    the `Delay` class. However, since the function of the `Delay` class instance will
    be run each time the `Fetch()` method is invoked, an unexpected result might occur
    if the function is not pure or has side effects. Let''s refactor our previous
    `delaying.cpp` code by modifying the `multiply` function. This function now becomes
    a non-pure function since it depends on an outside variable. The code should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the preceding code, we now have a new Lambda expression named
    `multiply_impure`, which is the refactored version of the `multiply` function
    we created in the `delaying.cpp` code. The `multiply_impure` function depends
    on the `multiplexer` variable, whose value will be increased each time before
    we invoke the `Fetch()` method. The following is the screenshot output we should
    see on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1e15207-1b93-4d22-b534-54ce6b0bba97.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the `Fetch()` method gives a different result each time it's
    invoked. We now have to refactor the `Delay` class to ensure that it will return
    the exact same result each time the `Fetch()` method runs the function with the
    same passed arguments. To achieve it, we will use the memoization technique that
    stores the results of the function calls and returns the cached result when the
    same inputs occur again.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will rename the `Delay` class to `Memoization` class. This will not only
    delay the function call, it will also record the function with specific passed
    arguments. So the next time the function with those arguments occurs, the function
    itself will not be run but it will just return the cached result instead. To ease
    our discussion, let''s take a look at the following `Memoization` class implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the preceding code snippet, we now have `FetchRecording()`
    and `DoRecording()` to get and set the function we have stored. Moreover, when
    the class is constructed, it will record the passed function and save it to `m_subRoutine`.
    The class will inspect `m_subRoutine` when the `Fetch()` method is called and
    find whether it has the value from the function with current passed arguments.
    If yes, it simply returns the value from `m_subRoutine` instead of running the
    function. Now, let''s see the following `delaying_non_pure_memoization.cpp` code,
    that consumes the `Memoization` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code snippet, we see we don''t have much modification in
    the `main()` function. What we modify is only the class type we use for the `multiply_impure`
    variable, from `Delay` to `Memoization`. However, the result has now changed since
    we will get the exact same return value from the five times invocation of the
    `multiply_impure()` function. Let''s take a look at the following screenshot to
    prove it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb597eec-cfe2-4c06-b0eb-a546e3a26fb5.png)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding screenshot, we can see that even the value of the `Multiplexer`
    is increased and the return of the calculation is always the same. This is because
    the return value of the first function invocation is recorded, so there's no need
    to run the function again for the remaining invocation.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 2](a1baf007-8f40-4616-8718-9887f95120b0.xhtml),
    *Manipulating Functions in Functional Programming*, having an impure function
    seems wrong in functional programming. Hiding an impure function behind memoization
    might also cause a bug if the code really needs a different result (non-cached
    result). Use the preceding technique for caching the impure function wisely.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the code using the memoization technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memoization is quite useful for applying in a non-pure function or a function
    that has been the side effect. However, it can also be used to optimize the code.
    By using memoization, the code we have developed will be run faster. Let's suppose
    we need to run the exact same functions with the exact same passed arguments multiple
    times. It will be faster if the code fetches the value from the place we record
    the value instead of running the function. It would also be better for an expensive
    function call because by using memoization, we don't need to execute the unnecessary
    expensive function call over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a code to discuss the further optimization. We will use the `Delay`
    class to demonstrate it''s not an optimized code compared to the `Memoization`
    class. We will have the `not_optimize_code.cpp` code that will consume the `Delay`
    class. In this unoptimized code, we will call the `fibonacci()` function that
    we created in [Chapter 4](7c3fb034-5951-4003-905f-48dd745a1c6f.xhtml), *Repeating
    Method Invocation Using Recursive Algorithm*. We will pass `40` as the argument
    to the `fibonacci()` function and call the `Fetch()` method from the `fib40` class
    instance five times. We will also calculate the elapsed time in each invocation
    of the method, using the `high_resolution_clock` class resided in the `chrono`
    header, to record the **start** and **end** time to retrieve the elapsed time
    by subtracting the end value with the start value. In addition to the elapsed
    time of each `Fetch()` method invocation, we also calculate the elapsed time of
    the entire code. The implementation of the `not_optimize_code.cpp` code is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s run the code to obtain the elapsed time of the preceding code process.
    The following screenshot is what we will see on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2ef7cc8-601b-47af-ae9f-19797be02341.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding screenshot, we can see that we need about `2357.79` milliseconds
    to process the code. And each time it invokes the `fib40.Fetch()` method, it needs
    an average of about `470` milliseconds, although we pass the exact same argument
    to the `fibonacci()` function, which is `40`. Now, let''s see what will happen
    if we use the memoization technique on the preceding code. We won''t modify the
    code much, just refactor the instantiation of `fib40`. Instead of instancing from
    the `Delay` class, now it instances from the `Memoization` class. The code should
    be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what we''ll get on the console screen when we run the `optimizing_memoization.cpp`
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c030b41-e024-44bc-b1fc-986e0504eae2.png)'
  prefs: []
  type: TYPE_IMG
- en: Surprisingly, we just need `494.681` milliseconds to execute the `optimizing_memoization.cpp`
    code. Compared to the `not_optimize_code.cpp` code, the speed of the code is about
    `4.7` times faster. This happens because the code successfully cached the result
    of the `fibonacci()` function when it passed the `40` to its parameter. Each time
    we call the `fib40.Fetch()` method again, it will invoke the `fibonacci()` function
    again, with the exact same input. The code will just return the cached result
    so it can avoid running the expensive function calls that are unnecessary to run.
  prefs: []
  type: TYPE_NORMAL
- en: Lazy evaluation in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having discussed the basic concept of lazy evaluation, let''s dig into lazy
    evaluation by designing the code in the lazy approach. In this section, we will
    develop an eager evaluation code first, then refactor that code into the lazy
    evaluation one. The code we develop will generate a sequence of prime numbers.
    First, we will use the `for` loop to iterate the integer number to obtain the
    prime number in the eager evaluation. The following `prime.cpp` code is what we
    are talking about:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the preceding code, we have a simple `PrimeCheck()` function
    to analyze whether the integer number is a prime number or not. Afterward, the
    code iterates the infinity integer numbers using the `for` loop, then checks whether
    it''s a prime number. The loop will be ended if we''ve got one hundred prime numbers.
    The following screenshot is the output on the console we should see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3263a17d-40a8-4065-82ad-48cfa4601359.png)'
  prefs: []
  type: TYPE_IMG
- en: We now have a code generating prime numbers using eager evaluation. As we can
    see in the preceding screenshot, we have a hundred prime numbers that we generated
    using the `for` loop. Next, we will refactor it into the lazy code.
  prefs: []
  type: TYPE_NORMAL
- en: Designing Chunk and Row classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `prime.cpp` code, we generate a row of integer numbers using the `for`
    loop. In this row, there are several numbers that are called **Chunk**. Now, before
    we refactor the code, we will prepare a class named `Row` and `Chunk` for our
    further discussion. From our preceding analogy, the `Row` class will hold the
    sequence of integer number and the `Chunk` class will hold a single number. We
    will start with the smallest part in the data, which is the chunk. And here is
    the implementation of the `Chunk` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the `Row` class is constructed from several `Chunk` classes, besides
    the value of `Chunk` itself, the `Chunk` class also has the next value of `Chunk`
    in the current `Row` notated by the `m_lastRow` member variable. We also can get
    the `m_lastRow` value by invoking the `ShiftLastToFirst()` method. Now, let''s
    move to the `Row` class. The implementation of the class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As we can see in the preceding code snippet, the `Row` class has only one private
    member to store a memoization of the `Chunk` data. There are four constructors
    the `Row` class has, and we will use them all in our next code. It also has the
    `Fetch()` method, which we got when we designed the `Memoization` class in the
    previous section, to get the `m_lazyChunk` value. The other methods are also useful
    to our next lazy code. The `IsEmpty()` method will check if the `m_lazyChunk`
    value is empty, the `ShiftLastToFirst()` method will take the last row of `m_lazyChunk`,
    and the `Pick(int n)` method will take out the first `n` row's elements that we
    will use if we need to take out a hundred of the integer prime numbers later.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also see that one of the `Row` constructors is invoking the `ChunkPreparation`
    class constructor. The `ChunkPreparation` class will initialize a new `Chunk`
    class constructor using the given value and the last row value. The implementation
    of the class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, by invoking `operator ()`, the new `Chunk` will be generated
    with the given `m_value` and `m_row` value.
  prefs: []
  type: TYPE_NORMAL
- en: Concatenating several rows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we plan to generate a row of prime numbers, we have to be able to concatenate
    the current with the new row generated by code. To address this need, the following
    is the implementation of the `ConcatenateRows()` function that will concatenate
    the two rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It's quite clear what the `ConcatenateRows()` function does when we take a look
    at the preceding code snippet. If `leftRow` is still empty, just return the second
    row, which is `rightRow`. If `leftRow` and `rightRow` is available, we can return
    the chunks of the given rows that have been formed as a row.
  prefs: []
  type: TYPE_NORMAL
- en: Iterating each Row class' element
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After we construct the row of prime numbers, we need to iterate each row''s
    element to manipulate it, for instance, to print the value to the console. For
    this purpose, we have to develop the following `ForEach()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We will pass the row itself and a function into the `ForEach()` method. The
    function we passed to it will be run to each element of the row.
  prefs: []
  type: TYPE_NORMAL
- en: For our convenience in developing the lazy code in this chapter, I will bundle
    our previous discussion `template` class into a single header file named `lazyevaluation.h`;
    we can also reuse it for other projects. The header will contain the `Memoization`,
    `Row`, `Chunk`, `ChunkPreparation`, `ConcatenateRows`, and `ForEach` template
    class. You can create the header file yourself or download it from the code repository
    on the Packt website ([https://github.com/PacktPublishing/LearningCPPFunctionalProgramming](https://github.com/PacktPublishing/LearningCPPFunctionalProgramming)).
  prefs: []
  type: TYPE_NORMAL
- en: Generating the infinite integer row
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now it''s time to generating the infinite integer row as we did using the `for`
    loop in our previous `prime.cpp` code. However, we will now create a new function
    named `GenerateInfiniteIntRow()` to generate an integer row from several integer
    chunks. The following code snippet is an implementation of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, first, we create `Chunk` from `initialNumber` until infinity.
    The chunks will be transformed to the `Row` data type at the end. To stop this
    recursive function, we can call the `Pick()` method inside the `Row` class.
  prefs: []
  type: TYPE_NORMAL
- en: Generating an infinite prime numbers row
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After successfully generated infinite numbers, we now have to limit the row
    to only generate the prime number. We will modify the `CheckPrime()` function
    from the `prime.cpp` code. We will change the return value of the function, `Row<void*>(nullptr)`
    if it''s not a prime number or `Row<void*>()` if the opposite. The implementation
    of the function should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Why do we need to change the return value of the function? Because we want
    to pass the return value to the `JoiningPrimeNumber()` function, which will join
    the generated Chunk with the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, the `MappingRowByValue()` function will map the given row to the
    given function. The implementation of the function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After we have successfully joined all prime numbers using the `JoiningPrimeNumber()`
    function, we have to bind it to the existing row using the `Binding()` function
    with the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code snippet, the `MappingRow()` function will map the given
    row to the given function, then `JoiningAllRows()` will join all rows from the
    `MappingRow()` return value. The implementation of the `MappingRow()` and `JoiningAllRows()`
    functions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create a function to limit the infinite integer number rows with
    the following implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the second argument of the `JoiningPrimeNumber()` function needs a row
    as a data type, we need to convert the `Chunk` to `Row` using the `ConvertChunkToRow()`
    function with the following implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now we can consume all preceding classes and functions to refactor our `prime.cpp`
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring eager evaluation to lazy evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have all the functions we need to refactor the `prime.cpp` code into a lazy
    code. We will create a `prime_lazy.cpp` code that will generate infinite integer
    numbers first and pick the first one hundred of its elements. After that, we iterate
    a hundred elements and give them to the function that will print the value on
    the console. The code should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see from the preceding code, we have `r` that holds the infinite
    numbers, then we pick the first one hundred prime numbers and store them to `firstAHundredPrimeNumbers`.
    To print the value of the element to the console, we use the `ForEach()` function
    and pass the Lambda expression to it. If we run the code, the result is exactly
    the same as the `prime.cpp` code, except the title that is used is a differentiator.
    The following output is what we should see on the console if we run the `prime_lazy.cpp`
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c60d9bc0-433e-4a8a-ad78-6b0691382add.png)'
  prefs: []
  type: TYPE_IMG
- en: By using the `template` class, we have revealed in this chapter that we can
    develop other lazy code to gain the benefit of being lazy.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding `prime_lazy.cpp` code, I omitted several lines of code that
    were written in the previous section to avoid the code redundancy. If you find
    any difficulty following the code because it's not complete, go to [https://github.com/PacktPublishing/LearningCPPFunctionalProgramming](https://github.com/PacktPublishing/LearningCPPFunctionalProgramming).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lazy evaluation is not only useful for functional programming, but it actually
    also has benefits for imperative programming. Using the lazy evaluation, we can
    have an efficient and faster code by implementing caching and optimizing techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will talk about metaprogramming that we can use in the
    functional approach. We will discuss how to use metaprogramming to gain all its
    benefits, including code optimization.
  prefs: []
  type: TYPE_NORMAL
