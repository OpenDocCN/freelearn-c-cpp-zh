<html><head></head><body><div><p>&#13;
			<h1 id="_idParaDest-35" class="chapter-number"><a id="_idTextAnchor037"/>2</h1>&#13;
			<h1 id="_idParaDest-36"><a id="_idTextAnchor038"/>The Structure of a Compiler</h1>&#13;
			<p>Compiler technology is a well-studied field of computer science. The high-level task is to translate a source language into machine code. Typically, this task is divided into three parts, the <strong class="bold">frontend</strong>, the <strong class="bold">middle end</strong>, and the <strong class="bold">backend</strong>. The frontend deals mainly with the source language, while the middle end performs transformation to improve the code and the backend is responsible for the generation of machine code. Since the LLVM core libraries provide the middle end and the backend, we will focus on the frontend within this chapter.</p>&#13;
			<p>In this chapter, you will cover the following sections and topics:</p>&#13;
			<ul>&#13;
				<li><em class="italic">Building blocks of a compiler</em>, in which you will learn about the components typically found in a compiler</li>&#13;
				<li><em class="italic">An arithmetic expression language</em>, which will introduce you to an example language and show how grammar is used to define a language</li>&#13;
				<li><em class="italic">Lexical analysis</em>, which discusses how to implement a lexer for the language</li>&#13;
				<li><em class="italic">Syntactical analysis</em>, which covers the construction of a parser from the grammar</li>&#13;
				<li><em class="italic">Semantic analysis</em>, in which you will learn how a semantic check can be implemented</li>&#13;
				<li><em class="italic">Code generation with the LLVM backend</em>, which discusses how to interface with the LLVM backend and glue all the preceding phases together to create a complete compiler</li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-37"><a id="_idTextAnchor039"/>Building blocks of a compiler</h1>&#13;
			<p>Since computers <a id="_idIndexMarker050"/>became available, thousands of programming languages have been developed. It turns out that all compilers must solve the same tasks and that the implementation of a compiler is best structured according to these tasks. At a high level, there are three components. The frontend turns the source code into an <strong class="bold">intermediate representation </strong>(<strong class="bold">IR</strong>). Then the middle end performs <a id="_idIndexMarker051"/>transformations on the IR, with the goal of either improving performance or reducing the size of the code. Finally, the backend produces machine code from the IR. The LLVM core libraries provide a middle end consisting of very sophisticated transformations and backends for all popular platforms. Furthermore, the LLVM core libraries also defines an intermediate representation used as input for the middle end and the backend. This design has the advantage that you only need to care about the frontend for the programming language you want to implement.</p>&#13;
			<p>The input for the frontend is the source code, usually a text file. To make sense of it, the frontend first <a id="_idIndexMarker052"/>identifies the words of the language, such as numbers and identifiers, which are <a id="_idIndexMarker053"/>usually called tokens. This step is performed by the <strong class="bold">lexer</strong>. Next, the syntactical structure formed by the tokens is analyzed. The so-called <strong class="bold">parser</strong> performs <a id="_idIndexMarker054"/>this step, and the result is the <strong class="bold">abstract syntax tree </strong>(<strong class="bold">AST</strong>). Last, the frontend needs to check that the rules of the programming <a id="_idIndexMarker055"/>language are obeyed, which is done by the <strong class="bold">semantic analyzer</strong>. If no errors <a id="_idIndexMarker056"/>were detected, then the AST is transformed into IR and handed over to the middle end.</p>&#13;
			<p>In the following sections, we will construct a compiler for an expression language, which produces LLVM IR from its input. The LLVM <code>llc</code> static compiler, representing the backend, can then be used to compile the IR into object code. It all begins with defining the language. Keep in mind that all of the C++ implementation of the files within this chapter will be contained within a directory called <code>src/</code>.</p>&#13;
			<h1 id="_idParaDest-38"><a id="_idTextAnchor040"/>An arithmetic expression language</h1>&#13;
			<p>Arithmetic <a id="_idIndexMarker057"/>expressions are a part of every programming language. Here is an example of an arithmetic expression calculation language called <strong class="bold">calc</strong>. The calc <a id="_idIndexMarker058"/>expressions are compiled into an application that evaluates the following expression:</p>&#13;
			<pre class="source-code">&#13;
with a, b: a * (4 + b)</pre>			<p>The used variables in the expression must be declared with the keyword, <code>with</code>. This program is compiled into an application that asks the user for the values of the <code>a</code> and <code>b</code> variables and prints the result.</p>&#13;
			<p>Examples are always welcome but, as a compiler writer, you need a more thorough specification than this for implementation and testing. The vehicle for the syntax of the programming language is the grammar.</p>&#13;
			<h2 id="_idParaDest-39"><a id="_idTextAnchor041"/>Formalism for specifying the syntax of a programming language</h2>&#13;
			<p>The elements <a id="_idIndexMarker059"/>of a language, for example, keywords, identifiers, strings, numbers, and operators, are called <strong class="bold">tokens</strong>. In this sense, a program is a <a id="_idIndexMarker060"/>sequence of tokens, and the grammar specifies which sequences are valid.</p>&#13;
			<p>Usually, grammar <a id="_idIndexMarker061"/>is written in the <strong class="bold">extended Backus-Naur form </strong>(<strong class="bold">EBNF</strong>). A rule in grammar has a left and a right side. The left side is just a single <a id="_idIndexMarker062"/>symbol called <strong class="bold">non-terminal</strong>. The right side of a rule consists of non-terminals, tokens, and meta-symbols for alternatives and repetitions. Let’s have a look at the grammar of the calc language:</p>&#13;
			<pre class="source-code">&#13;
calc : ("with" ident ("," ident)* ":")? expr ;&#13;
expr : term (( "+" | "-" ) term)* ;&#13;
term : factor (( "*" | "/") factor)* ;&#13;
factor : ident | number | "(" expr ")" ;&#13;
ident : ([a-zAZ])+ ;&#13;
number : ([0-9])+ ;</pre>			<p>In the first line, <code>calc</code> is a non-terminal. If not otherwise stated, then the first non-terminal of a grammar is the start symbol. The colon (<code>:</code>) is the separator between the left and the right side of the rule. Here, <code>"with"</code>, <code>","</code> and <code>":"</code> are tokens that represent this string. Parentheses are used for grouping. A group can be optional or repeated. A question mark (<code>?</code>) after the closing parenthesis denotes an optional group. A star <code>*</code> denotes zero or more repetitions and a plus <code>+</code> denotes one or more repetitions. <code>Ident</code> and <code>expr</code> are non-terminals. For each of them, another rule exists. The semicolon (<code>;</code>) marks the end of a rule. The pipe <code>|</code>, in the second line, denotes an alternative. And last, the brackets <code>[ ]</code>, in the last two lines, denote a character class. The valid characters are written inside the brackets. For example, the character class <code>[a-zA-Z]</code> matches an upper- or lower-case letter, and <code>([a-zA-Z])+</code> matches one or more of these letters. This corresponds to a regular expression.</p>&#13;
			<h2 id="_idParaDest-40"><a id="_idTextAnchor042"/>How does grammar help the compiler writer?</h2>&#13;
			<p>Such grammar may look like a theoretical toy, but it is of value to the compiler writer. First, all the tokens are defined, which is needed to create the lexical analyzer. The rules of the grammar <a id="_idIndexMarker063"/>can be translated into the parser. And of course, if questions arise about whether the parser works correctly, then the grammar serves as a good specification.</p>&#13;
			<p>However, grammar does not define all aspects of a programming language. The meaning – the semantics – of the syntax must also be defined. Formalisms for this purpose were developed, too, but very often, they are specified in plain text, as they were usually drawn up at the initial introduction of the language.</p>&#13;
			<p>Equipped with this knowledge, the next two sections show how the lexical analysis turns the input into a sequence of tokens and how the grammar is coded in C++ for the syntactical analysis.</p>&#13;
			<h1 id="_idParaDest-41"><a id="_idTextAnchor043"/>Lexical analysis</h1>&#13;
			<p>As already seen in the example in the previous section, a programming language consists of <a id="_idIndexMarker064"/>many elements such as keywords, identifiers, numbers, operators, and so on. The task of the lexical analyzer is to take the textual input and create <a id="_idIndexMarker065"/>a sequence of tokens from it. The calc language consists of the tokens <code>with</code>, <code>:</code>, <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>(</code>, <code>)</code>, and regular expressions <code>([a-zA-Z])+</code> (an identifier) and <code>([0-9])+</code> (a number). We assign a unique number to each token to make the handling of tokens easier.</p>&#13;
			<h2 id="_idParaDest-42"><a id="_idTextAnchor044"/>A hand-written lexer</h2>&#13;
			<p>The implementation <a id="_idIndexMarker066"/>of a lexical analyzer is often called <code>Lexer</code>. Let’s create a header file called <code>Lexer.h</code> and get started with the definition of <code>Token</code>. It begins with the usual header guard and the inclusion of the required headers:</p>&#13;
			<pre class="source-code">&#13;
#ifndef LEXER_H&#13;
#define LEXER_H&#13;
#include "llvm/ADT/StringRef.h"&#13;
#include "llvm/Support/MemoryBuffer.h"</pre>			<p>The <code>llvm::MemoryBuffer</code> class provides read-only access to a block of memory, filled with the content of a file. On request, a trailing zero character (<code>'\x00'</code>) is added to the end of the buffer. We use this feature to read through the buffer without checking the length of the buffer at each access. The <code>llvm::StringRef</code> class encapsulates a pointer to a C string and its length. Because the length is stored, the string need not <a id="_idIndexMarker067"/>be terminated with a zero character (<code>'\x00'</code>) like normal C strings. This allows an instance of <code>StringRef</code> to point to the memory managed by <code>MemoryBuffer</code>.</p>&#13;
			<p>With this in mind, we begin by implementing the <code>Lexer</code> class:</p>&#13;
			<ol>&#13;
				<li>First, the <code>Token</code> class contains the definition of the enumeration for the unique token numbers mentioned previously:<pre class="source-code">&#13;
class Lexer;&#13;
class Token {&#13;
  friend class Lexer;&#13;
public:&#13;
  enum TokenKind : unsigned short {&#13;
    eoi, unknown, ident, number, comma, colon, plus,&#13;
    minus, star, slash, l_paren, r_paren, KW_with&#13;
  };</pre><p class="list-inset">Besides defining a member for each token, we added two additional values: <code>eoi</code> and <code>unknown</code>. <code>eoi</code> stands for <em class="italic">end of input</em> and is returned when all characters of the input are processed. <code>unknown</code> is used in the event of an error at the lexical level, e.g., <code>#</code> is no token of the language and would therefore be mapped to <code>unknown</code>.</p></li>				<li>In addition to the enumeration, the class has a <code>Text</code> member, which points to the start of the text of the token. It uses the <code>StringRef</code> class mentioned previously:<pre class="source-code">&#13;
private:&#13;
  TokenKind Kind;&#13;
  llvm::StringRef Text;&#13;
public:&#13;
  TokenKind getKind() const { return Kind; }&#13;
  llvm::StringRef getText() const { return Text; }</pre><p class="list-inset">This is useful <a id="_idIndexMarker068"/>for semantic processing, e.g., for an identifier, it is useful to know the name.</p></li>				<li>The <code>is()</code> and <code>isOneOf()</code> methods are used to test whether the token is of a certain kind. The <code>isOneOf()</code> method uses a variadic template, allowing a variable number of arguments:<pre class="source-code">&#13;
  bool is(TokenKind K) const { return Kind == K; }&#13;
  bool isOneOf(TokenKind K1, TokenKind K2) const {&#13;
    return is(K1) || is(K2);&#13;
  }&#13;
  template &lt;typename... Ts&gt;&#13;
  bool isOneOf(TokenKind K1, TokenKind K2, Ts... Ks) const {&#13;
    return is(K1) || isOneOf(K2, Ks...);&#13;
  }&#13;
};</pre></li>				<li>The <code>Lexer</code> class itself has a similar simple interface and comes next in the header file:<pre class="source-code">&#13;
class Lexer {&#13;
  const char *BufferStart;&#13;
  const char *BufferPtr;&#13;
public:&#13;
  Lexer(const llvm::StringRef &amp;Buffer) {&#13;
    BufferStart = Buffer.begin();&#13;
    BufferPtr = BufferStart;&#13;
  }&#13;
  void next(Token &amp;token);&#13;
private:&#13;
  void formToken(Token &amp;Result, const char *TokEnd,&#13;
                 Token::TokenKind Kind);&#13;
};&#13;
#endif</pre><p class="list-inset">Except for <a id="_idIndexMarker069"/>the constructor, the public interface has only the <code>next()</code> method, which returns the next token. The method acts like an iterator, always advancing to the next available token. The only members of the class are pointers to the beginning of the input and the next unprocessed character. It is assumed that the buffer ends with a terminating <code>0</code> (just like a C string).</p></li>				<li>Let’s implement the <code>Lexer</code> class in the <code>Lexer.cpp</code> file. It begins with some helper functions to classify characters:<pre class="source-code">&#13;
#include "Lexer.h"&#13;
namespace charinfo {&#13;
LLVM_READNONE inline bool isWhitespace(char c) {&#13;
  return c == ' ' || c == '\t' || c == '\f' ||&#13;
         c == '\v' ||&#13;
c == '\r' || c == '\n';&#13;
}&#13;
LLVM_READNONE inline bool isDigit(char c) {&#13;
  return c &gt;= '0' &amp;&amp; c &lt;= '9';&#13;
}&#13;
LLVM_READNONE inline bool isLetter(char c) {&#13;
  return (c &gt;= 'a' &amp;&amp; c &lt;= 'z') ||&#13;
         (c &gt;= 'A' &amp;&amp; c &lt;= 'Z');&#13;
}&#13;
}</pre><p class="list-inset">These functions <a id="_idIndexMarker070"/>are used to make conditions more readable.</p></li>			</ol>&#13;
			<p class="callout-heading">Note</p>&#13;
			<p class="callout">We are not using the functions provided by the <code>&lt;cctype&gt;</code> standard library header for two reasons. First, these functions change behavior based on the locale defined in the environment. For example, if the locale is a German-language area, then German umlauts can be classified as letters. This is usually not wanted in a compiler. Second, since the functions have <code>int</code> as a parameter type, a conversion from the <code>char</code> type is required. The result of this conversion depends on whether <code>char</code> is treated as a signed or unsigned type, causing portability problems.</p>&#13;
			<ol>&#13;
				<li value="6">From the grammar in the previous section, we know all the tokens of the language. But the <a id="_idIndexMarker071"/>grammar does not define the characters that should be ignored. For example, a space or newline character adds only whitespace and are often ignored. The <code>next()</code> method begins with ignoring these characters:<pre class="source-code">&#13;
void Lexer::next(Token &amp;token) {&#13;
  while (*BufferPtr &amp;&amp;&#13;
         charinfo::isWhitespace(*BufferPtr)) {&#13;
    ++BufferPtr;&#13;
  }</pre></li>				<li>Next, make sure that there are still characters left to process:<pre class="source-code">&#13;
  if (!*BufferPtr) {&#13;
    token.Kind = Token::eoi;&#13;
    return;&#13;
  }</pre><p class="list-inset">There is at least one character to process.</p></li>				<li>We first check whether the character is lowercase or uppercase. In this case, the token is either an identifier or the <code>with</code> keyword, because the regular expression for the identifier also matches the keyword. The most common solution here is to collect the characters matched by the regular expression and check whether the string happens to be the keyword:<pre class="source-code">&#13;
  if (charinfo::isLetter(*BufferPtr)) {&#13;
    const char *end = BufferPtr + 1;&#13;
    while (charinfo::isLetter(*end))&#13;
      ++end;&#13;
    llvm::StringRef Name(BufferPtr, end - BufferPtr);&#13;
    Token::TokenKind kind =&#13;
        Name == "with" ? Token::KW_with : Token::ident;&#13;
    formToken(token, end, kind);&#13;
    return;&#13;
  }</pre><p class="list-inset">The <code>formToken()</code> private method is used to populate the token.</p></li>				<li>Next, we check <a id="_idIndexMarker072"/>for a number. The code for this is very similar to the preceding snippet:<pre class="source-code">&#13;
  else if (charinfo::isDigit(*BufferPtr)) {&#13;
    const char *end = BufferPtr + 1;&#13;
    while (charinfo::isDigit(*end))&#13;
      ++end;&#13;
    formToken(token, end, Token::number);&#13;
    return;&#13;
  }</pre><p class="list-inset">Now only the tokens defined by fixed strings are left.</p></li>				<li>This is done easily with a <code>switch</code>. As all of these tokens have only one character, the <code>CASE</code> preprocessor macro is used to reduce typing:<pre class="source-code">&#13;
  else {&#13;
    switch (*BufferPtr) {&#13;
#define CASE(ch, tok) \&#13;
case ch: formToken(token, BufferPtr + 1, tok); break&#13;
CASE('+', Token::plus);&#13;
CASE('-', Token::minus);&#13;
CASE('*', Token::star);&#13;
CASE('/', Token::slash);&#13;
CASE('(', Token::Token::l_paren);&#13;
CASE(')', Token::Token::r_paren);&#13;
CASE(':', Token::Token::colon);&#13;
CASE(',', Token::Token::comma);&#13;
#undef CASE</pre></li>				<li>Last, we need <a id="_idIndexMarker073"/>to check for unexpected characters:<pre class="source-code">&#13;
    default:&#13;
      formToken(token, BufferPtr + 1, Token::unknown);&#13;
    }&#13;
    return;&#13;
  }&#13;
}</pre><p class="list-inset">Only the <code>formToken()</code> private helper method is still missing.</p></li>				<li>It populates the members of the <code>Token</code> instance and updates the pointer to the next unprocessed character:<pre class="source-code">&#13;
void Lexer::formToken(Token &amp;Tok, const char *TokEnd,&#13;
                      Token::TokenKind Kind) {&#13;
  Tok.Kind = Kind;&#13;
  Tok.Text = llvm::StringRef(BufferPtr,&#13;
                             TokEnd - BufferPtr);&#13;
  BufferPtr = TokEnd;&#13;
}</pre></li>			</ol>&#13;
			<p>In the next section, we have a look at how to construct a parser for syntactical analysis.</p>&#13;
			<h1 id="_idParaDest-43"><a id="_idTextAnchor045"/>Syntactical analysis</h1>&#13;
			<p>The syntactical analysis is done by the parser, which we will implement next. The base of this is the <a id="_idIndexMarker074"/>grammar and the lexer from the previous sections. The result of the parsing process is a dynamic data structure called an <strong class="bold">abstract syntax tree </strong>(<strong class="bold">AST</strong>). The AST <a id="_idIndexMarker075"/>is a very condensed representation of the input and is well-suited for semantic analysis.</p>&#13;
			<p>First, we will implement the parser, and after that, we will have a look at the parsing process within the AST.</p>&#13;
			<h2 id="_idParaDest-44"><a id="_idTextAnchor046"/>A hand-written parser</h2>&#13;
			<p>The interface <a id="_idIndexMarker076"/>of the parser is defined in the header file, <code>Parser.h</code>. It begins <a id="_idIndexMarker077"/>with some <code>include</code> declarations:</p>&#13;
			<pre class="source-code">&#13;
#ifndef PARSER_H&#13;
#define PARSER_H&#13;
#include "AST.h"&#13;
#include "Lexer.h"&#13;
#include "llvm/Support/raw_ostream.h"</pre>			<p>The <code>AST.h</code> header file declares the interface for the AST and is shown later. The coding guidelines from LLVM forbid the use of the <code>&lt;iostream&gt;</code> library, therefore, the header of the equivalent LLVM functionality is included. It is needed to emit an error message:</p>&#13;
			<ol>&#13;
				<li>The <code>Parser</code> class first declares some private members:<pre class="source-code">&#13;
class Parser {&#13;
  Lexer &amp;Lex;&#13;
  Token Tok;&#13;
  bool HasError;</pre><p class="list-inset"><code>Lex</code> and <code>Tok</code> are instances of the classes from the previous section. <code>Tok</code> stores the next <a id="_idIndexMarker078"/>token (the look-ahead) and <code>Lex</code> is used to retrieve <a id="_idIndexMarker079"/>the next token from the input. The <code>HasError</code> flag indicates whether an error was detected.</p></li>				<li>A couple of methods deal with the token:<pre class="source-code">&#13;
  void error() {&#13;
    llvm::errs() &lt;&lt; "Unexpected: " &lt;&lt; Tok.getText()&#13;
                 &lt;&lt; "\n";&#13;
    HasError = true;&#13;
  }&#13;
  void advance() { Lex.next(Tok); }&#13;
  bool expect(Token::TokenKind Kind) {&#13;
    if (Tok.getKind() != Kind) {&#13;
      error();&#13;
      return true;&#13;
    }&#13;
    return false;&#13;
  }&#13;
  bool consume(Token::TokenKind Kind) {&#13;
    if (expect(Kind))&#13;
      return true;&#13;
    advance();&#13;
    return false;&#13;
  }</pre><p class="list-inset"><code>advance()</code> retrieves the next token from the lexer. <code>expect()</code> tests whether the look-ahead <a id="_idIndexMarker080"/>has the expected kind and emits an error message if not. Finally, <code>consume()</code> retrieves the next token if the look-ahead has the expected kind. If an error message is emitted, the <code>HasError</code> flag is set to true.</p></li>				<li>For each <a id="_idIndexMarker081"/>non-terminal of the grammar, a method to parse the rule is declared:<pre class="source-code">&#13;
  AST *parseCalc();&#13;
  Expr *parseExpr();&#13;
  Expr *parseTerm();&#13;
  Expr *parseFactor();</pre></li>			</ol>&#13;
			<p class="callout-heading">Note:</p>&#13;
			<p class="callout">There are no methods for <code>ident</code> and <code>number</code>. Those rules only return the token and are replaced by the corresponding token.</p>&#13;
			<ol>&#13;
				<li value="4">The public interface follows. The constructor initializes all members and retrieves the first token from the lexer:<pre class="source-code">&#13;
public:&#13;
  Parser(Lexer &amp;Lex) : Lex(Lex), HasError(false) {&#13;
    advance();&#13;
  }</pre></li>				<li>A function is required to get the value of the error flag:<pre class="source-code">&#13;
  bool hasError() { return HasError; }</pre></li>				<li>And finally, the <code>parse()</code> method is the main entry point into parsing:<pre class="source-code">&#13;
  AST *parse();&#13;
};&#13;
#endif</pre></li>			</ol>&#13;
			<h3>Parser implementation</h3>&#13;
			<p>Let’s dive <a id="_idIndexMarker082"/>into the implementation of the parser!</p>&#13;
			<ol>&#13;
				<li>Our implementation in the <code>Parser.cpp</code> file and begins with the <code>parse()</code> method:<pre class="source-code">&#13;
#include "Parser.h"&#13;
AST *Parser::parse() {&#13;
  AST *Res = parseCalc();&#13;
  expect(Token::eoi);&#13;
  return Res;&#13;
}</pre><p class="list-inset">The main point of the <code>parse()</code> method is that the whole input has been consumed. Do you remember that the parsing example in the first section added a special symbol to denote the end of the input? We check it here.</p></li>				<li>The <code>parseCalc()</code> method implements the corresponding rule. It’s worth having a closer look at this method as the other parsing methods follow the same patterns. Let’s recall the rule from the first section:<pre class="source-code">&#13;
calc : ("with" ident ("," ident)* ":")? expr ;</pre></li>				<li>The method begins with declaring some local variables:<pre class="source-code">&#13;
AST *Parser::parseCalc() {&#13;
  Expr *E;&#13;
  llvm::SmallVector&lt;llvm::StringRef, 8&gt; Vars;</pre></li>				<li>The first decision to be made is whether the optional group must be parsed or not. The group begins with the <code>with</code> token, so we compare the token to this value:<pre class="source-code">&#13;
  if (Tok.is(Token::KW_with)) {&#13;
    advance();</pre></li>				<li>Next, we <a id="_idIndexMarker083"/>expect an identifier:<pre class="source-code">&#13;
    if (expect(Token::ident))&#13;
      goto _error;&#13;
    Vars.push_back(Tok.getText());&#13;
    advance();</pre><p class="list-inset">If there is an identifier, then we save it in the <code>Vars</code> vector. Otherwise, it is a syntax error, which is handled separately.</p></li>				<li>Next in the grammar follows a repeating group, which parses more identifiers, separated with commas:<pre class="source-code">&#13;
    while (Tok.is(Token::comma)) {&#13;
      advance();&#13;
      if (expect(Token::ident))&#13;
        goto _error;&#13;
      Vars.push_back(Tok.getText());&#13;
      advance();&#13;
    }</pre><p class="list-inset">By now, this should not be surprising. The repetition group begins with the token (<code>,</code>). The test for the token becomes the condition of the <code>while</code> loop, implementing zero or more repetition. The identifier inside the loop is treated as before.</p></li>				<li>Finally, the optional group requires a colon at the end:<pre class="source-code">&#13;
    if (consume(Token::colon))&#13;
      goto _error;&#13;
  }</pre></li>				<li>Last, the rule for <code>expr</code> must be parsed:<pre class="source-code">&#13;
  E = parseExpr();</pre></li>				<li>With this call, the parsing of the rule is finished successfully. The collected information <a id="_idIndexMarker084"/>is now used to create the AST node for this rule:<pre class="source-code">&#13;
  if (Vars.empty()) return E;&#13;
  else return new WithDecl(Vars, E);</pre></li>			</ol>&#13;
			<p>Now only the error handling is missing. Detecting a syntax error is easy but recovering from it is <a id="_idIndexMarker085"/>surprisingly complicated. Here, a simple approach called <strong class="bold">panic mode</strong> is used.</p>&#13;
			<p>In panic mode, tokens are deleted from the token stream until one is found that the parser can use to continue its work. Most programming languages have symbols that denote an end, e.g., in C++, a <code>;</code> (end of a statement) or a <code>}</code> (end of a block). Such tokens are good candidates to look for.</p>&#13;
			<p>On the other hand, the error can be that the symbol we are looking for is missing. In this case, probably a lot of tokens are deleted before the parser can continue. This is not as bad as it sounds. Today, it is more important that a compiler is fast. In the event of an error, the developer looks at the first error message, fixes it, and restarts the compiler. This is quite different from using punch cards, where it was important to get as many error messages as possible, as the next run of the compiler would possibly be only on the next day.</p>&#13;
			<h3>Error handling</h3>&#13;
			<p>Instead of using some arbitrary tokens to look for, another set of tokens is used here. For each <a id="_idIndexMarker086"/>non-terminal, there is a set of tokens that can follow this non-terminal in a rule:</p>&#13;
			<ol>&#13;
				<li>In the case of <code>calc</code>, only the end of input follows this non-terminal. The implementation is trivial:<pre class="source-code">&#13;
_error:&#13;
  while (!Tok.is(Token::eoi))&#13;
    advance();&#13;
  return nullptr;&#13;
}</pre></li>				<li>The other <a id="_idIndexMarker087"/>parsing methods are similarly constructed. <code>parseExpr()</code> is the translation of the rule for <code>expr</code>:<pre class="source-code">&#13;
Expr *Parser ::parseExpr() {&#13;
  Expr *Left = parseTerm() ;&#13;
  while (Tok.isOneOf(Token::plus, Token::minus)) {&#13;
    BinaryOp::Operator Op =&#13;
       Tok.is(Token::plus) ? BinaryOp::Plus :&#13;
                             BinaryOp::Minus;&#13;
    advance();&#13;
    Expr *Right = parseTerm();&#13;
    Left = new BinaryOp(Op, Left, Right);&#13;
  }&#13;
  return Left;&#13;
}</pre><p class="list-inset">The repeated group inside the rule is translated as a <code>while</code> loop. Note how the use of the <code>isOneOf()</code> method simplifies the check for several tokens.</p></li>				<li>The coding of the <code>term</code> rule looks the same:<pre class="source-code">&#13;
Expr *Parser::parseTerm() {&#13;
  Expr *Left = parseFactor();&#13;
  while (Tok.isOneOf(Token::star, Token::slash)) {&#13;
    BinaryOp::Operator Op =&#13;
        Tok.is(Token::star) ? BinaryOp::Mul :&#13;
                              BinaryOp::Div;&#13;
    advance();&#13;
    Expr *Right = parseFactor();&#13;
    Left = new BinaryOp(Op, Left, Right);&#13;
  }&#13;
  return Left;&#13;
}</pre><p class="list-inset">This method is strikingly similar to <code>parseExpr()</code>, and you may be tempted to combine <a id="_idIndexMarker088"/>them into one. In a grammar, it is possible to have one rule dealing with multiplicative and additive operators. The advantage of using two rules instead is that then the precedence of the operators fits well with the mathematical order of evaluation. If you combine both rules, then you need to figure out the evaluation order somewhere else.</p></li>				<li>Last, you need to implement the rule for <code>factor</code>:<pre class="source-code">&#13;
Expr *Parser::parseFactor() {&#13;
  Expr *Res = nullptr;&#13;
  switch (Tok.getKind()) {&#13;
  case Token::number:&#13;
    Res = new Factor(Factor::Number, Tok.getText());&#13;
    advance(); break;</pre><p class="list-inset">Instead of using a chain of <code>if</code> and <code>else if</code> statements, a <code>switch</code> statement seems more suitable here, because each alternative begins with just one token. In general, you should think about which translation patterns you like to use. If you later need <a id="_idIndexMarker089"/>to change the parsing methods, then it is an advantage if not every method has a different way of implementing a grammar rule.</p></li>				<li>If you use a <code>switch</code> statement, then error handling happens in the <code>default</code> case:<pre class="source-code">&#13;
  case Token::ident:&#13;
    Res = new Factor(Factor::Ident, Tok.getText());&#13;
    advance(); break;&#13;
  case Token::l_paren:&#13;
    advance();&#13;
    Res = parseExpr();&#13;
    if (!consume(Token::r_paren)) break;&#13;
  default:&#13;
    if (!Res) error();</pre><p class="list-inset">We guard emitting the error message here because of the fall-through.</p></li>				<li>If there was a syntax error in the parenthesis’s expression, then an error message was already emitted. The guard prevents a second error message:<pre class="source-code">&#13;
    while (!Tok.isOneOf(Token::r_paren, Token::star,&#13;
                        Token::plus, Token::minus,&#13;
                        Token::slash, Token::eoi))&#13;
      advance();&#13;
  }&#13;
  return Res;&#13;
}</pre></li>			</ol>&#13;
			<p>That was easy, wasn’t it? Once you have memorized the patterns used, it is almost tedious work <a id="_idIndexMarker090"/>to code the parser based on the grammar rules. This type of parser is called a <strong class="bold">recursive </strong><strong class="bold">descent parser</strong>.</p>&#13;
			<p class="callout-heading">A recursive descent parser can’t be constructed from every grammar</p>&#13;
			<p class="callout">A grammar must satisfy certain conditions to be suitable for the construction of a recursive descent parser. This class of grammar is called LL(1). In fact, most grammar that you can find on the internet does not belong to this class of grammar. Most books about the theory of compiler constructions explain the reason for this. The classic book on this topic is the so-called <em class="italic">dragon book</em>, <em class="italic">Compilers: Principles, Techniques, and Tools</em> by Aho, Lam, Sethi, and Ullman.</p>&#13;
			<h2 id="_idParaDest-45"><a id="_idTextAnchor047"/>The abstract syntax tree</h2>&#13;
			<p>The result of the parsing process is the AST. The AST is another compact representation of the input program. It captures the essential information. Many programming languages have <a id="_idIndexMarker091"/>symbols that are needed as separators but do not carry further meaning. For example, in C++, a semicolon<code>;</code> denotes the <a id="_idIndexMarker092"/>end of a single statement. Of course, this information is important for the parser. As soon as we turn the statement into an in-memory representation, the semicolon is not important anymore and can be dropped.</p>&#13;
			<p>If you look at the first rule of the example expression language, then it is clear that the <code>with</code> keyword, the comma (<code>,</code>), and the colon (<code>:</code>) are not important for the meaning of a program. What is important is the list of declared variables, which could be used in the expression. The result is that only a couple of classes are required to record the information: <code>Factor</code> holds a number or an identifier, <code>BinaryOp</code> holds the arithmetic operator and the left and right sides of an expression, and <code>WithDecl</code> stores the list of declared variables and the expression. <code>AST</code> and <code>Expr</code> are only used to create a common class hierarchy.</p>&#13;
			<p>In addition to the information from the parsed input, tree traversal using the <code>AST.h</code> header file:</p>&#13;
			<ol>&#13;
				<li>It begins with the visitor interface:<pre class="source-code">&#13;
#ifndef AST_H&#13;
#define AST_H&#13;
#include "llvm/ADT/SmallVector.h"&#13;
#include "llvm/ADT/StringRef.h"&#13;
class AST;&#13;
class Expr;&#13;
class Factor;&#13;
class BinaryOp;&#13;
class WithDecl;&#13;
class ASTVisitor {&#13;
public:&#13;
  virtual void visit(AST &amp;){};&#13;
  virtual void visit(Expr &amp;){};&#13;
  virtual void visit(Factor &amp;) = 0;&#13;
  virtual void visit(BinaryOp &amp;) = 0;&#13;
  virtual void visit(WithDecl &amp;) = 0;&#13;
};</pre><p class="list-inset">The visitor <a id="_idIndexMarker093"/>pattern needs to know each class to visit. Because <a id="_idIndexMarker094"/>each class also refers to the visitor, we declare all classes at the top of the file. Please note that the <code>visit()</code> methods for <code>AST</code> and <code>Expr</code> have a default implementation, which does nothing.</p></li>				<li>The <code>AST</code> class is the root of the hierarchy:<pre class="source-code">&#13;
class AST {&#13;
public:&#13;
  virtual ~AST() {}&#13;
  virtual void accept(ASTVisitor &amp;V) = 0;&#13;
};</pre></li>				<li>Similarly, <code>Expr</code> is the <a id="_idIndexMarker095"/>root for <code>AST</code> classes <a id="_idIndexMarker096"/>related to expressions:<pre class="source-code">&#13;
class Expr : public AST {&#13;
public:&#13;
  Expr() {}&#13;
};</pre></li>				<li>The <code>Factor</code> class stores a number or the name of a variable:<pre class="source-code">&#13;
class Factor : public Expr {&#13;
public:&#13;
  enum ValueKind { Ident, Number };&#13;
private:&#13;
  ValueKind Kind;&#13;
  llvm::StringRef Val;&#13;
public:&#13;
  Factor(ValueKind Kind, llvm::StringRef Val)&#13;
      : Kind(Kind), Val(Val) {}&#13;
  ValueKind getKind() { return Kind; }&#13;
  llvm::StringRef getVal() { return Val; }&#13;
  virtual void accept(ASTVisitor &amp;V) override {&#13;
    V.visit(*this);&#13;
  }&#13;
};</pre><p class="list-inset">In this example, numbers and variables are treated almost identically, therefore, we decided to create only one AST node class to represent them. The <code>Kind</code> member tells <a id="_idIndexMarker097"/>us which of both cases the instances represent. In more <a id="_idIndexMarker098"/>complex languages, you usually want to have different AST classes, such as a <code>NumberLiteral</code> class for numbers and a <code>VariableAccess</code> class for a reference to a variable.</p></li>				<li>The <code>BinaryOp</code> class holds the data needed for evaluating an expression:<pre class="source-code">&#13;
class BinaryOp : public Expr {&#13;
public:&#13;
  enum Operator { Plus, Minus, Mul, Div };&#13;
private:&#13;
  Expr *Left;&#13;
  Expr *Right;&#13;
  Operator Op;&#13;
public:&#13;
  BinaryOp(Operator Op, Expr *L, Expr *R)&#13;
      : Op(Op), Left(L), Right(R) {}&#13;
  Expr *getLeft() { return Left; }&#13;
  Expr *getRight() { return Right; }&#13;
  Operator getOperator() { return Op; }&#13;
  virtual void accept(ASTVisitor &amp;V) override {&#13;
    V.visit(*this);&#13;
  }&#13;
};</pre><p class="list-inset">In contrast to the parser, the <code>BinaryOp</code> class makes no distinction between multiplicative <a id="_idIndexMarker099"/>and additive operators. The <a id="_idIndexMarker100"/>precedence of the operators is implicitly available in the tree structure.</p></li>				<li>And last, the <code>WithDecl</code> class stores the declared variables and the expression:<pre class="source-code">&#13;
class WithDecl : public AST {&#13;
  using VarVector =&#13;
                   llvm::SmallVector&lt;llvm::StringRef, 8&gt;;&#13;
  VarVector Vars;&#13;
  Expr *E;&#13;
public:&#13;
  WithDecl(llvm::SmallVector&lt;llvm::StringRef, 8&gt; Vars,&#13;
           Expr *E)&#13;
      : Vars(Vars), E(E) {}&#13;
  VarVector::const_iterator begin()&#13;
                                { return Vars.begin(); }&#13;
  VarVector::const_iterator end() { return Vars.end(); }&#13;
  Expr *getExpr() { return E; }&#13;
  virtual void accept(ASTVisitor &amp;V) override {&#13;
    V.visit(*this);&#13;
  }&#13;
};&#13;
#endif</pre></li>			</ol>&#13;
			<p>The AST is <a id="_idIndexMarker101"/>constructed during parsing. The semantic analysis checks that <a id="_idIndexMarker102"/>the tree adheres to the meaning of the language (e.g., that used variables are declared) and possibly augments the tree. After that, the tree is used for code generation.</p>&#13;
			<h1 id="_idParaDest-46"><a id="_idTextAnchor048"/>Semantic analysis</h1>&#13;
			<p>The semantic analyzer walks the AST and checks various semantic rules of the language, e.g. a variable must be declared before use or types of variables must be compatible in an expression. The semantic analyzer can also print out warnings if it finds a situation that can <a id="_idIndexMarker103"/>be improved. For the example expression language, the semantic analyzer must check that each used variable is declared because that is what the language requires. A possible extension (which is not implemented here) is to print a warning if a declared variable is not used.</p>&#13;
			<p>The semantic analyzer is implemented in the <code>Sema</code> class, which is performed by the <code>semantic()</code> method. Here is the complete <code>Sema.h</code> header file:</p>&#13;
			<pre class="source-code">&#13;
#ifndef SEMA_H&#13;
#define SEMA_H&#13;
#include "AST.h"&#13;
#include "Lexer.h"&#13;
class Sema {&#13;
public:&#13;
  bool semantic(AST *Tree);&#13;
};&#13;
#endif</pre>			<p>The implementation is in the <code>Sema.cpp</code> file. The interesting part is the semantic analysis, which is implemented using a visitor. The basic idea is that the name of each declared variable <a id="_idIndexMarker104"/>is stored in a set. During the creation of the set, each name can be checked for uniqueness, and later it can be checked that the given name is in the set:</p>&#13;
			<pre class="source-code">&#13;
#include "Sema.h"&#13;
#include "llvm/ADT/StringSet.h"&#13;
namespace {&#13;
class DeclCheck : public ASTVisitor {&#13;
  llvm::StringSet&lt;&gt; Scope;&#13;
  bool HasError;&#13;
  enum ErrorType { Twice, Not };&#13;
  void error(ErrorType ET, llvm::StringRef V) {&#13;
    llvm::errs() &lt;&lt; "Variable " &lt;&lt; V &lt;&lt; " "&#13;
                 &lt;&lt; (ET == Twice ? "already" : "not")&#13;
                 &lt;&lt; " declared\n";&#13;
    HasError = true;&#13;
  }&#13;
public:&#13;
  DeclCheck() : HasError(false) {}&#13;
  bool hasError() { return HasError; }</pre>			<p>As in the <code>Parser</code> class, a flag is used to indicate that an error occurred. The names are stored in <a id="_idIndexMarker105"/>a set called <code>Scope</code>. On a <code>Factor</code> node that holds a variable name, it is checked that the variable name is in the set:</p>&#13;
			<pre class="source-code">&#13;
  virtual void visit(Factor &amp;Node) override {&#13;
    if (Node.getKind() == Factor::Ident) {&#13;
      if (Scope.find(Node.getVal()) == Scope.end())&#13;
        error(Not, Node.getVal());&#13;
    }&#13;
  };</pre>			<p>For a <code>BinaryOp</code> node, there is nothing to check other than that both sides exist and are visited:</p>&#13;
			<pre class="source-code">&#13;
  virtual void visit(BinaryOp &amp;Node) override {&#13;
    if (Node.getLeft())&#13;
      Node.getLeft()-&gt;accept(*this);&#13;
    else&#13;
      HasError = true;&#13;
    if (Node.getRight())&#13;
      Node.getRight()-&gt;accept(*this);&#13;
    else&#13;
      HasError = true;&#13;
  };</pre>			<p>On a <code>WithDecl</code> node, the set is populated and the walk over the expression is started:</p>&#13;
			<pre class="source-code">&#13;
  virtual void visit(WithDecl &amp;Node) override {&#13;
    for (auto I = Node.begin(), E = Node.end(); I != E;&#13;
         ++I) {&#13;
      if (!Scope.insert(*I).second)&#13;
        error(Twice, *I);&#13;
    }&#13;
    if (Node.getExpr())&#13;
      Node.getExpr()-&gt;accept(*this);&#13;
    else&#13;
      HasError = true;&#13;
  };&#13;
};&#13;
}</pre>			<p>The <code>semantic()</code> method only <a id="_idIndexMarker106"/>starts the tree walk and returns the error flag:</p>&#13;
			<pre class="source-code">&#13;
bool Sema::semantic(AST *Tree) {&#13;
  if (!Tree)&#13;
    return false;&#13;
  DeclCheck Check;&#13;
  Tree-&gt;accept(Check);&#13;
  return Check.hasError();&#13;
}</pre>			<p>If required, much more could be done here. It would also be possible to print a warning if a declared variable is not used. We leave this for you to implement as an exercise. If the semantic analysis finishes without error, then we can generate the LLVM IR from the AST. This is done in the next section.</p>&#13;
			<h1 id="_idParaDest-47"><a id="_idTextAnchor049"/>Generating code with the LLVM backend</h1>&#13;
			<p>The task <a id="_idIndexMarker107"/>of the backend is to create optimized <a id="_idIndexMarker108"/>machine code from the LLVM IR of a module. The IR is the interface to the backend and can be created using a C++ interface or in textual form. Again, the IR is generated from the AST.</p>&#13;
			<h2 id="_idParaDest-48"><a id="_idTextAnchor050"/>Textual representation of LLVM IR</h2>&#13;
			<p>Before trying <a id="_idIndexMarker109"/>to generate the LLVM IR, it should be clear what we want to generate. For our example expression language, the high-level plan is as follows:</p>&#13;
			<ol>&#13;
				<li>Ask the user for the value of each variable.</li>&#13;
				<li>Calculate the value of the expression.</li>&#13;
				<li>Print the result.</li>&#13;
			</ol>&#13;
			<p>To ask the user to provide a value for a variable and to print the result, two library functions are used: <code>calc_read()</code> and <code>calc_write()</code>. For the <code>with a: 3*a</code> expression, the generated IR is as follows:</p>&#13;
			<ol>&#13;
				<li>The library functions must be declared, like in C. The syntax also resembles C. The type before the function name is the return type. The type names surrounded by parenthesis are the argument types. The declaration can appear anywhere in the file:<pre class="source-code">&#13;
declare i32 @calc_read(ptr)&#13;
declare void @calc_write(i32)</pre></li>				<li>The <code>calc_read()</code> function takes the variable name as a parameter. The following construct defines a constant, holding <code>a</code> and the null byte used as a string terminator in C:<pre class="source-code">&#13;
@a.str = private constant [2 x i8] c"a\00"</pre></li>				<li>It follows the <code>main()</code> function. The parameter names are omitted because they are not used. Just as in C, the body of the function is enclosed in braces:<pre class="source-code">&#13;
define i32 @main(i32, ptr) {</pre></li>				<li>Each basic <a id="_idIndexMarker110"/>block must have a label. Because this is the first basic block of the function, we name it <code>entry</code>:<pre class="source-code">&#13;
entry:</pre></li>				<li>The <code>calc_read()</code> function is called to read the value for the <code>a</code> variable. The nested <code>getelemenptr</code> instruction performs an index calculation to compute the pointer to the first element of the string constant. The function result is assigned to the unnamed <code>%</code><code>2</code> variable.<pre class="source-code">&#13;
  %2 = call i32 @calc_read(ptr @a.str)</pre></li>				<li>Next, the variable is multiplied by <code>3</code>:<pre class="source-code">&#13;
  %3 = mul nsw i32 3, %2</pre></li>				<li>The result is printed on the console via a call to the <code>calc_write()</code> function:<pre class="source-code">&#13;
  call void @calc_write(i32 %3)</pre></li>				<li>Last, the <code>main()</code> function returns <code>0</code> to indicate a successful execution:<pre class="source-code">&#13;
  ret i32 0&#13;
}</pre></li>			</ol>&#13;
			<p>Each value in the LLVM IR is typed, with <code>i32</code> denoting the 32-bit bit integer type and <code>ptr</code> denoting a pointer.</p>&#13;
			<p class="callout-heading">Note</p>&#13;
			<p class="callout">Previous versions of LLVM used typed pointers. For example, a pointer to a byte was expressed as i8* in LLVM. Since <a id="_idIndexMarker111"/>LLVM 16, <code>ptr</code>.</p>&#13;
			<p>Since it is now clear what the IR looks like, let’s generate it from the AST.</p>&#13;
			<h2 id="_idParaDest-49"><a id="_idTextAnchor051"/>Generating the IR from the AST</h2>&#13;
			<p>The <a id="_idIndexMarker112"/>interface, provided in the <code>CodeGen.h</code> header file, is very small:</p>&#13;
			<pre class="source-code">&#13;
#ifndef CODEGEN_H&#13;
#define CODEGEN_H&#13;
#include "AST.h"&#13;
class CodeGen&#13;
{&#13;
public:&#13;
 void compile(AST *Tree);&#13;
};&#13;
#endif</pre>			<p>Because <a id="_idIndexMarker113"/>the AST contains the information, the basic idea is to use a visitor to walk the AST. The <code>CodeGen.cpp</code> file is implemented as follows:</p>&#13;
			<ol>&#13;
				<li>The required includes are at the top of the file:<pre class="source-code">&#13;
#include "CodeGen.h"&#13;
#include "llvm/ADT/StringMap.h"&#13;
#include "llvm/IR/IRBuilder.h"&#13;
#include "llvm/IR/LLVMContext.h"&#13;
#include "llvm/Support/raw_ostream.h"</pre></li>				<li>The namespace of the LLVM libraries is used for name lookups:<pre class="source-code">&#13;
using namespace llvm;</pre></li>				<li>First, some private members are declared in the visitor. Each compilation unit is represented in LLVM by the <code>Module</code> class and the visitor has a pointer to the module called <code>M</code>. For easy IR generation, the <code>Builder</code> (of type <code>IRBuilder&lt;&gt;)</code> is used. LLVM has a class hierarchy to represent types in IR. You can look up the instances for basic types such as <code>i32</code> from the LLVM context.<p class="list-inset">These <a id="_idIndexMarker114"/>basic types are used <a id="_idIndexMarker115"/>very often. To avoid repeated lookups, we cache the needed type instances: <code>VoidTy</code>, <code>Int32Ty</code>, <code>PtrTy</code>, and <code>Int32Zero</code>. The <code>V</code> member is the current calculated value, which is updated through the tree traversal. And last, <code>nameMap</code> maps a variable name to the value returned from the <code>calc_read()</code> function:</p><pre class="source-code">&#13;
namespace {&#13;
class ToIRVisitor : public ASTVisitor {&#13;
  Module *M;&#13;
  IRBuilder&lt;&gt; Builder;&#13;
  Type *VoidTy;&#13;
  Type *Int32Ty;&#13;
  PointerType *PtrTy;&#13;
  Constant *Int32Zero;&#13;
  Value *V;&#13;
  StringMap&lt;Value *&gt; nameMap;</pre></li>				<li>The constructor initializes all members:<pre class="source-code">&#13;
public:&#13;
  ToIRVisitor(Module *M) : M(M), Builder(M-&gt;getContext())&#13;
  {&#13;
    VoidTy = Type::getVoidTy(M-&gt;getContext());&#13;
    Int32Ty = Type::getInt32Ty(M-&gt;getContext());&#13;
    PtrTy = PointerType::getUnqual(M-&gt;getContext());&#13;
    Int32Zero = ConstantInt::get(Int32Ty, 0, true);&#13;
  }</pre></li>				<li>For each <a id="_idIndexMarker116"/>function, a <code>FunctionType</code> instance must be created. In C++ terminology, this is a function <a id="_idIndexMarker117"/>prototype. A function itself is defined with a <code>Function</code> instance. The <code>run()</code> method defines the <code>main()</code> function in the LLVM IR first:<pre class="source-code">&#13;
  void run(AST *Tree) {&#13;
    FunctionType *MainFty = FunctionType::get(&#13;
        Int32Ty, {Int32Ty, PtrTy}, false);&#13;
    Function *MainFn = Function::Create(&#13;
        MainFty, GlobalValue::ExternalLinkage,&#13;
        "main", M);</pre></li>				<li>Then we create the <code>BB</code> basic block with the <code>entry</code> label, and attach it to the IR builder:<pre class="source-code">&#13;
    BasicBlock *BB = BasicBlock::Create(M-&gt;getContext(),&#13;
                                        "entry", MainFn);&#13;
    Builder.SetInsertPoint(BB);</pre></li>				<li>With this preparation done, the tree traversal can begin:<pre class="source-code">&#13;
    Tree-&gt;accept(*this);</pre></li>				<li>After the tree traversal, the computed value is printed via a call to the <code>calc_write()</code> function. Again, a function prototype (an instance of <code>FunctionType</code>) has to be created. The only parameter is the current value, <code>V</code>:<pre class="source-code">&#13;
    FunctionType *CalcWriteFnTy =&#13;
        FunctionType::get(VoidTy, {Int32Ty}, false);&#13;
    Function *CalcWriteFn = Function::Create(&#13;
        CalcWriteFnTy, GlobalValue::ExternalLinkage,&#13;
        "calc_write", M);&#13;
    Builder.CreateCall(CalcWriteFnTy, CalcWriteFn, {V});</pre></li>				<li>The <a id="_idIndexMarker118"/>generation finishes <a id="_idIndexMarker119"/>by returning <code>0</code> from the <code>main()</code> function:<pre class="source-code">&#13;
    Builder.CreateRet(Int32Zero);&#13;
  }</pre></li>				<li>A <code>WithDecl</code> node holds the names of the declared variables. First, we create a function prototype for the <code>calc_read()</code> function:<pre class="source-code">&#13;
  virtual void visit(WithDecl &amp;Node) override {&#13;
    FunctionType *ReadFty =&#13;
        FunctionType::get(Int32Ty, {PtrTy}, false);&#13;
    Function *ReadFn = Function::Create(&#13;
        ReadFty, GlobalValue::ExternalLinkage,&#13;
        "calc_read", M);</pre></li>				<li>The method loops through the variable names:<pre class="source-code">&#13;
    for (auto I = Node.begin(), E = Node.end(); I != E;&#13;
         ++I) {</pre></li>				<li>For each <a id="_idIndexMarker120"/>variable, a string <a id="_idIndexMarker121"/>with a variable name is created:<pre class="source-code">&#13;
      StringRef Var = *I;&#13;
      Constant *StrText = ConstantDataArray::getString(&#13;
          M-&gt;getContext(), Var);&#13;
      GlobalVariable *Str = new GlobalVariable(&#13;
          *M, StrText-&gt;getType(),&#13;
          /*isConstant=*/true,&#13;
          GlobalValue::PrivateLinkage,&#13;
          StrText, Twine(Var).concat(".str"));</pre></li>				<li>Then the IR code to call the <code>calc_read()</code> function is created. The string created in the previous step is passed as a parameter:<pre class="source-code">&#13;
      CallInst *Call =&#13;
          Builder.CreateCall(ReadFty, ReadFn, {Str});</pre></li>				<li>The returned value is stored in the <code>mapNames</code> map for later use:<pre class="source-code">&#13;
      nameMap[Var] = Call;&#13;
    }</pre></li>				<li>The tree traversal continues with the expression:<pre class="source-code">&#13;
    Node.getExpr()-&gt;accept(*this);&#13;
  };</pre></li>				<li>A <code>Factor</code> node is either a variable name or a number. For a variable name, the value is <a id="_idIndexMarker122"/>looked up in the <code>mapNames</code> map. For a number, the value is converted to an integer and turned <a id="_idIndexMarker123"/>into a constant value:<pre class="source-code">&#13;
  virtual void visit(Factor &amp;Node) override {&#13;
    if (Node.getKind() == Factor::Ident) {&#13;
      V = nameMap[Node.getVal()];&#13;
    } else {&#13;
      int intval;&#13;
      Node.getVal().getAsInteger(10, intval);&#13;
      V = ConstantInt::get(Int32Ty, intval, true);&#13;
    }&#13;
  };</pre></li>				<li>And last, for a <code>BinaryOp</code> node, the right calculation operation must be used:<pre class="source-code">&#13;
  virtual void visit(BinaryOp &amp;Node) override {&#13;
    Node.getLeft()-&gt;accept(*this);&#13;
    Value *Left = V;&#13;
    Node.getRight()-&gt;accept(*this);&#13;
    Value *Right = V;&#13;
    switch (Node.getOperator()) {&#13;
    case BinaryOp::Plus:&#13;
      V = Builder.CreateNSWAdd(Left, Right); break;&#13;
    case BinaryOp::Minus:&#13;
      V = Builder.CreateNSWSub(Left, Right); break;&#13;
    case BinaryOp::Mul:&#13;
      V = Builder.CreateNSWMul(Left, Right); break;&#13;
    case BinaryOp::Div:&#13;
      V = Builder.CreateSDiv(Left, Right); break;&#13;
    }&#13;
  };&#13;
};&#13;
}</pre></li>				<li>With this, the visitor class is complete. The <code>compile()</code> method creates the global <a id="_idIndexMarker124"/>context and the <a id="_idIndexMarker125"/>module, runs the tree traversal, and dumps the generated IR to the console:<pre class="source-code">&#13;
void CodeGen::compile(AST *Tree) {&#13;
  LLVMContext Ctx;&#13;
  Module *M = new Module("calc.expr", Ctx);&#13;
  ToIRVisitor ToIR(M);&#13;
  ToIR.run(Tree);&#13;
  M-&gt;print(outs(), nullptr);&#13;
}</pre></li>			</ol>&#13;
			<p>We now have implemented the frontend of the compiler, from reading the source up to generating the IR. Of course, all these components must work together on user input, which is the task of the compiler driver. We also need to implement the functions needed at runtime. Both are topics of the next section.</p>&#13;
			<h2 id="_idParaDest-50"><a id="_idTextAnchor052"/>The missing pieces – the driver and the runtime library</h2>&#13;
			<p>All the <a id="_idIndexMarker126"/>phases from the previous sections are glued together <a id="_idIndexMarker127"/>by the <code>Calc.cpp</code> driver, which we implement as follows: a parameter for the input expression is declared, LLVM is initialized, and all the phases from the previous sections are called:</p>&#13;
			<ol>&#13;
				<li>First, we include the required header files:<pre class="source-code">&#13;
#include "CodeGen.h"&#13;
#include "Parser.h"&#13;
#include "Sema.h"&#13;
#include "llvm/Support/CommandLine.h"&#13;
#include "llvm/Support/InitLLVM.h"&#13;
#include "llvm/Support/raw_ostream.h"</pre></li>				<li>LLVM comes with its own system for declaring command-line options. You only need to <a id="_idIndexMarker128"/>declare a static variable for each option you <a id="_idIndexMarker129"/>need. In doing so, the option is registered with a global command line parser. The advantage of this approach is that each component can add command-line options when needed. We declare an option for the input expression:<pre class="source-code">&#13;
static llvm::cl::opt&lt;std::string&gt;&#13;
    Input(llvm::cl::Positional,&#13;
          llvm::cl::desc("&lt;input expression&gt;"),&#13;
          llvm::cl::init(""));</pre></li>				<li>Inside the <code>main()</code> function, the LLVM libraries are initialized first. You need to call the <code>ParseCommandLineOptions()</code> function to handle the options given on the command line. This also handles the printing of help information. In the event of an error, this method exits the application:<pre class="source-code">&#13;
int main(int argc, const char **argv) {&#13;
  llvm::InitLLVM X(argc, argv);&#13;
  llvm::cl::ParseCommandLineOptions(&#13;
      argc, argv, "calc - the expression compiler\n");</pre></li>				<li>Next, we call the lexer and the parser. After the syntactical analysis, we check whether any errors occurred. If this is the case, then we exit the compiler with a return code indicating a failure:<pre class="source-code">&#13;
  Lexer Lex(Input);&#13;
  Parser Parser(Lex);&#13;
  AST *Tree = Parser.parse();&#13;
  if (!Tree || Parser.hasError()) {&#13;
    llvm::errs() &lt;&lt; "Syntax errors occured\n";&#13;
    return 1;&#13;
  }</pre></li>				<li>And we <a id="_idIndexMarker130"/>do the same if there was a semantic error:<pre class="source-code">&#13;
  Sema Semantic;&#13;
  if (Semantic.semantic(Tree)) {&#13;
    llvm::errs() &lt;&lt; "Semantic errors occured\n";&#13;
    return 1;&#13;
  }</pre></li>				<li>As the <a id="_idIndexMarker131"/>last step in the driver, the code generator is called:<pre class="source-code">&#13;
  CodeGen CodeGenerator;&#13;
  CodeGenerator.compile(Tree);&#13;
  return 0;&#13;
}</pre></li>			</ol>&#13;
			<p>Now we have successfully created some IR code for the user input. We delegate the object code generation to the LLVM <code>llc</code> static compiler, so this finishes the implementation of our compiler. We link all the components together to create the <code>calc</code> application.</p>&#13;
			<p>The runtime <a id="_idIndexMarker132"/>library consists of a single file, <code>rtcalc.c</code>. It has the implementation for the <code>calc_read()</code> and <code>calc_write()</code> functions, written in C:</p>&#13;
			<pre class="source-code">&#13;
#include &lt;stdio.h&gt;&#13;
#include &lt;stdlib.h&gt;&#13;
void calc_write(int v)&#13;
{&#13;
  printf("The result is: %d\n", v);&#13;
}</pre>			<p><code>calc_write()</code> only writes <a id="_idIndexMarker133"/>the result value to the terminal:</p>&#13;
			<pre class="source-code">&#13;
int calc_read(char *s)&#13;
{&#13;
  char buf[64];&#13;
  int val;&#13;
  printf("Enter a value for %s: ", s);&#13;
  fgets(buf, sizeof(buf), stdin);&#13;
  if (EOF == sscanf(buf, "%d", &amp;val))&#13;
  {&#13;
    printf("Value %s is invalid\n", buf);&#13;
    exit(1);&#13;
  }&#13;
  return val;&#13;
}</pre>			<p><code>calc_read()</code> reads an integer number from the terminal. Nothing prevents the user from entering letters or other characters, so we must carefully check the input. If the input is not <a id="_idIndexMarker134"/>a number, we exit the application. A more complex <a id="_idIndexMarker135"/>approach would be to make the user aware of the problem and ask for a number again.</p>&#13;
			<p>The next step is to build and try out our compiler, <code>calc</code>, which is an application that creates IR from an expression.</p>&#13;
			<h3>Building and testing the calc application</h3>&#13;
			<p>In order <a id="_idIndexMarker136"/>to build <code>calc</code>, we first need to create a new <code>CMakeLists.txt</code> file outside of the original <code>src</code> directory that contains all of the source file implementation:</p>&#13;
			<ol>&#13;
				<li>First, we set <a id="_idIndexMarker137"/>the minimum required CMake version to the number required by LLVM, and give the project the name <code>calc</code>:<pre class="source-code">&#13;
cmake_minimum_required (VERSION 3.20.0)&#13;
project ("calc")</pre></li>				<li>Next, the LLVM package needs to be loaded, and we add the directory of the CMake modules provided by LLVM to the search path:<pre class="source-code">&#13;
find_package(LLVM REQUIRED CONFIG)&#13;
message("Found LLVM ${LLVM_PACKAGE_VERSION}, build type ${LLVM_BUILD_TYPE}")&#13;
list(APPEND CMAKE_MODULE_PATH ${LLVM_DIR})</pre></li>				<li>We also need to add the definitions and the include path from LLVM. The used LLVM components are mapped to the library names with a function call:<pre class="source-code">&#13;
separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS})&#13;
add_definitions(${LLVM_DEFINITIONS_LIST})&#13;
include_directories(SYSTEM ${LLVM_INCLUDE_DIRS})&#13;
llvm_map_components_to_libnames(llvm_libs Core)</pre></li>				<li>Lastly, we indicate that we need to include the <code>src</code> subdirectory in our build, as this is where all of the C++ implementation that was done within this chapter resides:<pre class="source-code">&#13;
add_subdirectory ("src")</pre></li>			</ol>&#13;
			<p>There also <a id="_idIndexMarker138"/>needs to be a new <code>CMakeLists.txt</code> file inside of the <code>src</code> subdirectory. This CMake description inside the <code>src</code> directory appears as follows. We simply <a id="_idIndexMarker139"/>define the name of the executable, called <code>calc</code>, then list the source files to compile and the library to link against:</p>&#13;
			<pre class="source-code">&#13;
add_executable (calc&#13;
  Calc.cpp CodeGen.cpp Lexer.cpp Parser.cpp Sema.cpp)&#13;
target_link_libraries(calc PRIVATE ${llvm_libs})</pre>			<p>Finally, we can begin building the <code>calc</code> application. Outside of the <code>src</code> directory, we create a new build directory and change into it. Afterwards, we can run the CMake and build invocation as follows:</p>&#13;
			<pre class="console">&#13;
$ cmake -GNinja -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DLLVM_DIR=&lt;path to llvm installation configuration&gt; ../&#13;
$ ninja</pre>			<p>We now should have a newly built, functional <code>calc</code> application that can generate LLVM IR code. This can further be used with <code>llc</code>, which is the LLVM static backend compiler, to compile the IR code into an object file.</p>&#13;
			<p>You can then use your favorite C compiler to link against the small runtime library. On Unix on X86, you can type the following:</p>&#13;
			<pre class="console">&#13;
$ calc "with a: a*3" | llc –filetype=obj \&#13;
  -relocation-model=pic  –o=expr.o&#13;
$ clang –o expr expr.o rtcalc.c&#13;
$ expr&#13;
Enter a value for a: 4&#13;
The result is: 12</pre>			<p>On other Unix platforms such as AArch64 or PowerPC, you have to remove the <code>-</code><code>relocation-model=pic</code> option.</p>&#13;
			<p>On Windows, you need <a id="_idIndexMarker140"/>to use the <code>cl</code> compiler as follows:</p>&#13;
			<pre class="console">&#13;
$ calc "with a: a*3" | llc –filetype=obj –o=expr.obj&#13;
$ cl expr.obj rtcalc.c&#13;
$ expr&#13;
Enter a value for a: 4&#13;
The result is: 12</pre>			<p>You have now <a id="_idIndexMarker141"/>created your first LLVM-based compiler! Please take some time to play around with various expressions. Especially check that multiplicative operators are evaluated before additive operators and that using parentheses changes the evaluation order, as we would expect from a basic calculator.</p>&#13;
			<h1 id="_idParaDest-51"><a id="_idTextAnchor053"/>Summary</h1>&#13;
			<p>In this chapter, you learned about the typical components of a compiler. An arithmetic expression language was used to introduce you to the grammar of programming languages. You learned how to develop the typical components of a frontend for this language: a lexer, a parser, a semantic analyzer, and a code generator. The code generator only produced LLVM IR, and the LLVM <code>llc</code> static compiler was used to create object files from it. You have now developed your first LLVM-based compiler!</p>&#13;
			<p>In the next chapter, you will deepen this knowledge, constructing the frontend for a programming language.</p>&#13;
		</p>&#13;
	</div></body></html>