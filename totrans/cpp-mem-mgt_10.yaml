- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Arena-Based Memory Management and Other Optimizations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于区域的内存管理和其他优化
- en: Our memory-management toolbox is growing with every chapter. We now know how
    to overload memory allocation operators ([*Chapter 7*](B21071_07.xhtml#_idTextAnchor116))
    and how to put this skill to work in ways that solve a variety of concrete problems
    ([*Chapter 8*](B21071_08.xhtml#_idTextAnchor128) and [*Chapter 9*](B21071_09.xhtml#_idTextAnchor141)
    both give a few illustrative, real-world examples).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内存管理工具箱随着每一章的增长而增长。我们现在知道如何重载内存分配运算符（[*第7章*](B21071_07.xhtml#_idTextAnchor116)）以及如何将这项技能应用于解决各种具体问题的方法（[*第8章*](B21071_08.xhtml#_idTextAnchor128)和[*第9章*](B21071_09.xhtml#_idTextAnchor141)都提供了一些说明性的、现实世界的例子）。
- en: One important reason why one would want to take control of memory allocation
    mechanisms is *performance*. Now, it would be presumptuous (and plain wrong!)
    to state that it’s trivial to beat the implementation of these functions as provided
    by your library vendor, as these are good, often *very* good, for the average
    case. The key element of the previous phrase, of course, is “for the average case.”
    When one’s use case has specificities that are known of beforehand, it is sometimes
    possible to benefit from that information and carve an implementation that outperforms,
    maybe by a wide margin, anything that could have been designed for excellent *average*
    performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 想要控制内存分配机制的一个重要原因是**性能**。现在，声称能够轻易击败库供应商提供的这些函数的实现是轻率的（而且显然是错误的！），因为这些实现对于平均情况来说通常是好的，很多时候是非常好的。当然，前一句话的关键元素是“对于平均情况”。当一个人的使用案例在事先已知其特定性时，有时可以利用这些信息，设计出一个超越任何可能为优秀**平均**性能设计的实现的实现。
- en: This chapter is about using knowledge of the memory management problem we want
    to solve and building a solution that excels for us. This can mean a solution
    that’s faster on average, that’s fast enough even in the worst case, that shows
    deterministic execution times, that reduces memory fragmentation, and so on. There
    are many different needs and constraints in real-world programs after all, and
    we often have to make choices.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是关于使用我们想要解决的内存管理问题的知识来构建一个对我们来说表现卓越的解决方案。这可能意味着一个平均情况下更快、在最坏情况下也足够快、显示确定性的执行时间、减少内存碎片等解决方案。毕竟，现实世界程序中有许多不同的需求和约束，我们经常不得不做出选择。
- en: 'Once this chapter is over, our toolbox will be expanded to let us do the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦本章结束，我们的工具箱将扩展，使我们能够做到以下事情：
- en: Write arena-based allocation strategy algorithms optimized to face a priori
    known constraints
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写针对事先已知约束优化的基于区域的分配策略算法
- en: Write per-memory block-size allocation strategies
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写按内存块大小分配的策略
- en: Understand the benefits as well as the risks associated with such techniques
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解与这些技术相关的益处以及风险
- en: 'The techniques covered in this chapter will lead us to explore use cases very
    close to those for which memory allocation operators are overloaded in some specialized
    application domains. Thus, we will initially apply them to a “real life” problem:
    the fight between Orcs and Elves in a medieval fantasy game.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的技术将引导我们探索与某些专用应用领域中内存分配运算符重载非常接近的使用案例。因此，我们最初将它们应用于一个“真实生活”问题：中世纪幻想游戏中兽人与精灵之间的战斗。
- en: On the (sometimes diminishing) returns of optimization
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关于优化的（有时是减少的）回报
- en: 'Since we will be discussing optimization techniques (among other things) in
    this chapter, some words of warning are in order: *optimization is a tricky thing*,
    a moving target, and what makes code better one day could pessimize it another
    day. Similarly, what can seem like a good idea in theory can lead to slowdowns
    in practice once implemented and tested, and one can sometimes spend a lot of
    time optimizing a piece of code that is rarely taken, effectively wasting time
    and money.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在本章中讨论优化技术（以及其他内容），因此需要一些警告：**优化是一件棘手的事情**，是一个移动的目标，今天使代码变得更好的东西，明天可能会使其变差。同样，理论上看起来不错的主意，一旦实施和测试，可能会在实践中导致减速，有时人们可能会花费大量时间优化很少使用的代码，实际上是在浪费时间和金钱。
- en: Before trying to optimize parts of your program, it’s generally wise to measure,
    ideally with a profiling tool, and identify the parts that might benefit from
    your efforts. Then, keep a simple (but correct) version of your code close by
    and use it as a baseline. Whenever you try an optimization, compare the results
    with the baseline code and run these tests regularly, particularly when changing
    hardware, library, compiler, or version thereof. Sometimes, something such as
    a compiler upgrade might induce a new optimization that “sees through” the simple
    baseline code and makes it faster than your finely crafted alternative. Be humble,
    be reasonable, measure early, and measure often.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find the code files for this chapter in the book’s GitHub repository
    here: [https://github.com/PacktPublishing/C-Plus-Plus-Memory-Management/tree/main/chapter10](https://github.com/PacktPublishing/C-Plus-Plus-Memory-Management/tree/main/chapter10).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Arena-based memory management
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea behind arena-based memory management is to allocate a chunk of memory
    at a known moment in the program and manage it as a “small, personalized heap”
    based on a strategy that benefits from knowledge of the situation or of the problem
    domain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many variants on this general theme, including the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: In a game, allocate and manage the memory by scene or by level, deallocating
    it as a single chunk at the end of said scene or level. This can help reduce memory
    fragmentation in the program.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the conditions in which allocations and deallocations are known to follow
    a given pattern or have bounded memory requirements, specialize allocation functions
    to benefit from this information.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Express a form of ownership for a group of similar objects in such as way as
    to destroy them all at a later point in the program instead of doing so one object
    at a time.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best way to explain how arena-based allocation works is probably to write
    an example program that uses it and shows both what it does and what benefits
    this provides. We will write code in such a way as to use the same test code with
    either the standard library-provided allocation functions or our own specialized
    implementation, depending on the presence of a macro, and, of course, we will
    measure the allocation and deallocation code to see whether there is a benefit
    to our efforts.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Specific example – size-based implementation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose we are working on a video game where the action converges toward a stupendous
    finale where Orcs and Elves meet in a grandiose battle. No one really remembers
    why these two groups hate each other, but there is a suspicion that one day, one
    of the Elves said to one of the Orcs “You know, you don’t smell all that bad today!”
    and this Orc was so insulted that it started a feud that still goes on today.
    It’s a rumor, anyway.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'It so happens that, in this game, some things are known about the behavior
    of Orc-using code, specifically, the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: There will never be more than a certain number of dynamically allocated `Orc`
    objects overall, so we have an upper bound to the space required to store these
    beasties.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总共动态分配的`Orc`对象数量将不会超过某个特定数量，因此我们有存储这些生物所需空间的上限。
- en: The Orcs that die will not come back to life in that game, as there are no shamans
    to resurrect them. Expressed otherwise, there is no need to implement a strategy
    that reuses the storage of an `Orc` object once it has been destroyed.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在那个游戏中，死亡的兽人将不会复活，因为没有萨满可以将其复活。换句话说，没有必要实现一个在对象被销毁后重用`Orc`对象存储的策略。
- en: 'These two properties open algorithmic options for us:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个属性为我们提供了算法选择：
- en: If we have enough memory available, we could allocate upfront a single memory
    block large enough to put all the `Orc` objects in the game as we know what the
    worst-case scenario is
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们有足够的内存可用，我们可以预先分配一个足够大的内存块，以便将所有`Orc`对象放入游戏中，因为我们知道最坏的情况是什么。
- en: Since we know that we will not need to reuse the memory associated with individual
    `Orc` objects, we can implement a simple (and very fast) strategy for allocation
    that does almost no bookkeeping and, as we will see, lets us achieve deterministic,
    constant-time allocation *for* *this type*
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于我们知道我们不需要重用与单个`Orc`对象关联的内存，我们可以实现一个简单（并且非常快速）的分配策略，这个策略几乎不做记录，并且正如我们将看到的，让我们能够实现针对这种类型的确定性、常数时间分配。
- en: 'For the sake of this example, the `Orc` class will be represented by three
    data members, `name` (a `char[4]` as these beasties have a limited vocabulary),
    `strength` (of type `int`), and `smell` (of the `double` type as these things
    have… a reputation), as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个例子，`Orc`类将由三个数据成员表示，`name`（一个`char[4]`，因为这些生物的词汇有限），`strength`（类型为`int`），和`smell`（类型为`double`，因为这些生物有…声誉），如下所示：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will use arbitrary default values for our `Orc` objects as we are only concerned
    about allocation and deallocation for this example. You can write more elaborate
    test code that uses non-default values if you feel like it, of course, but that
    would not impact our discussion so we will target simplicity.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将为`Orc`对象使用任意默认值，因为我们只关心这个例子中的分配和释放。当然，如果你愿意，你可以编写更复杂的测试代码来使用非默认值，但这不会影响我们的讨论，所以我们将目标定为简单。
- en: 'Since we are discussing the memory allocation of a large block upfront through
    our size-based arena, we need to look at memory size consumption for `Orc` objects.
    Supposing `sizeof(int)==4` and `sizeof(double)==8` and supposing that, being fundamental
    types, their alignment requirements match their respective sizes, we can assume
    that `sizeof(Orc)==16` in this case. If we aim to allocate enough space for all
    `Orc` objects at once, ensuring `sizeof(Orc)` remains reasonable for the resources
    at our disposal is important. For example, defining the maximum number of `Orc`
    objects in a program as `Orc::NB_MAX` and the maximal amount of memory we can
    allocate at once for `Orc` objects as some hypothetical constant named `THRESHOLD`,
    we could leave a `static_assert` such as the following in our source code as a
    form of *constraints-respected check*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们通过基于大小的竞技场预先讨论了大型内存块的内存分配，我们需要查看`Orc`对象的内存大小消耗。假设`sizeof(int)==4`和`sizeof(double)==8`，并且假设作为基本类型，它们的对齐要求与它们各自的大小相匹配，在这种情况下，我们可以假设`sizeof(Orc)==16`。如果我们旨在一次性为所有`Orc`对象分配足够的空间，确保`sizeof(Orc)`对于我们的资源来说是合理的，这一点很重要。例如，将程序中`Orc`对象的最大数量定义为`Orc::NB_MAX`，以及我们可以一次性为`Orc`对象分配的最大内存量定义为某个假设的常量`THRESHOLD`，我们可以在源代码中留下一个如下的`static_assert`作为*约束检查*的形式：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This way, if we end up evolving the `Orc` class to the point where resources
    become an issue, the code will stop compiling and we will be able to reevaluate
    the situation. In our case, with a memory consumption of approximately 16 MB,
    we will suppose we are within budget and that we can proceed with our arena.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，如果我们最终将`Orc`类发展到资源成为问题的情况，代码将无法编译，我们就能重新评估情况。在我们的例子中，考虑到大约16 MB的内存消耗，我们假设我们处于预算范围内，可以继续我们的竞技场开发。
- en: We will want to compare our arena-based implementation with a baseline implementation,
    which, in this case, will be the standard library-provided implementation of the
    memory allocation functions. It’s important to note upfront that each standard
    library implementation provides its own version of these functions, so you might
    want to run the code we will be writing here on more than one implementation to
    get a better perspective on the impact of our techniques.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: To write code that allows us to do a proper comparison, we will need two distinct
    executables as we will be in an either/or situation (we either get the standard
    version or the “homemade” one we are writing), so this is a good use case for
    macro-based conditional compilation. We will thus write a single set of source
    files that will conditionally replace the standard library-provided versions of
    the allocation operators with ours but will otherwise be essentially identical.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'We will work from three files: `Orc.h`, which declares the `Orc` class and
    the conditionally defined allocation operator overloads; `Orc.cpp`, which provides
    the implementation for these overloads as well as the arena implementation itself;
    and a test program that allocates `Orc::NB_MAX` objects of type `Orc` then later
    destroys them and measures the time it takes to do these two operations. Of course,
    as with most microbenchmarks, take these measurements with a grain of salt: the
    numbers will not be the same in a real program where allocations are interspersed
    with other code, but at least we will apply the same tests to both implementations
    of the allocation operators so the comparison should be reasonably fair.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Declaring the Orc class
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, let us examine `Orc.h`, which we have already seen in part when showing
    the data member layout of the `Orc` class earlier:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `HOMEMADE_VERSION` macro can be uncommented to use our version of the allocation
    functions. As can be expected, since we are applying a special strategy for the
    `Orc` class and its expected usage patterns, we are using member-function overloads
    for the allocation operators. (We would not want to treat `int` objects or – imagine!
    – Elves the same way we will treat Orcs, would we? I thought not.)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Orc class and implementing an arena
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The essence of the memory management-related code will be in `Orc.cpp`. We will
    go through it in two steps, the arena implementation and the allocation operator
    overloads, and analyze the different important parts separately. The whole implementation
    found in this file will be conditionally compiled based on the `HOMEMADE_VERSION`
    macro.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'We will name our arena class `Tribe`, and it will be a singleton. Yes, that
    reviled design pattern we used in [*Chapter 8*](B21071_08.xhtml#_idTextAnchor128)
    again, but we really do want a single `Tribe` object in our program so that conveys
    the intent well. The important parts of our implementation are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'The default (and only) constructor of the `Tribe` class allocates a single
    block of `Orc::NB_MAX*sizeof(Orc)` bytes. It is important to note right away that
    there are no `Orc` objects in that chunk: this memory block is just the right
    size and shape to put all the `Orc` objects we will need. A key idea for arena-based
    allocation is that, at least for this implementation, *the arena manages raw memory,
    not objects*: object construction and destruction are the province of user code,
    and any object not properly destroyed at the end of the program is user code’s
    fault, not the fault of the arena.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We validate at once that the allocation succeeded. I used an `assert()` in this
    case, as the rest of the code depends on this success, but throwing `std::bad_alloc`
    or calling `std::abort()` would also have been reasonable options. A `Tribe` object
    keeps two pointers, `p` and `cur`, both initially pointing at the beginning of
    the block. We will use `p` as the *beginning of block* marker, and `cur` as the
    *pointer to the next block to return*; as such, `p` will remain stable throughout
    program execution and `cur` will move forward by `sizeof(Orc)` bytes with each
    allocation.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using char* or Orc*
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: This `Tribe` implementation uses `char*` for the `p` and `cur` pointers but
    `Orc*` would have been a correct choice also. One simply needs to remember that,
    as far as the `Tribe` object is concerned, there are no `Orc` objects in the arena
    and the use of type `Orc*` is simply a convenient lie to simplify pointer arithmetic.
    The changes this would entail would be replacing `static_cast<char*>` with `static_cast<Orc*>`
    in the constructor, and replacing `cur+=sizeof(Orc)` with `++cur` in the implementation
    of the `allocate()` member function. It’s mostly a matter of style and personal
    preference.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'The destructor frees the entire block of memory managed by the `Tribe` object.
    This is a very efficient procedure: it’s quicker than separately freeing smaller
    blocks, and it leads to very little memory fragmentation.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This first implementation uses the Meyers singleton technique seen in [*Chapter
    8*](B21071_08.xhtml#_idTextAnchor128), but we will use a different approach later
    in this chapter to compare the performance impacts of two implementation strategies
    for the same design pattern… because there are such impacts, as we will see.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The way our size-based arena implementation will benefit from our a priori
    knowledge of the expected usage pattern is as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Each allocation will return a sequentially “allocated” `Orc`-sized block, meaning
    that there is no need to search for an appropriately sized block – we always know
    where it is.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no work to do when deallocating as we are not reusing the blocks once
    they have been used. Note that, per standard rules, the allocation and deallocation
    functions have to be thread-safe, which explains our use of `std::mutex` in this
    implementation.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you might have guessed already, these allocation conditions are close to
    optimal, but they happen more often than we would think in practice. A similarly
    efficient usage pattern would model a stack (the last block allocated is the next
    block freed), and we write code that uses local variables every day without necessarily
    realizing that we are using what is often an optimal usage pattern for the underlying
    memory.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'We then come to the overloaded allocation operators. To keep this implementation
    simple, we will suppose there will be no array of `Orc` objects to allocate, but
    you can refine the implementation to take arrays into account (it’s not a difficult
    task; it’s just more complicated to write relevant test code). The role played
    by these functions is to delegate the work to the underlying arena, and they will
    only be used for the `Orc` class (there is a caveat to this, which will be discussed
    in the *When parameters change* section later in this chapter). As such, they
    are almost trivial:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Testing our implementation
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We then come to the test code implementation we will be using. This program
    will be made of a microbenchmark function named `test()` and of a `main()` function.
    We will examine both separately.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'The `test()` function will take a non-`void` function, `f()`, a variadic pack
    of arguments, `args`, and call `f(args...)` making sure to use perfect forwarding
    for the arguments in that call to make sure the arguments are passed with the
    semantic intended in the original call. It reads a clock before and after the
    call to `f()` and returns a `pair` made of the result of executing `f(args...)`
    and the time elapsed during this call. I used `high_resolution_clock` in my code
    but there are valid reasons to use either `system_clock` or `steady_clock` in
    this situation:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You might wonder why we are requiring non-`void` functions and returning the
    result of calling `f(args...)` even if, in some cases, the return value might
    be a little artificial. The idea here is to ensure that the compiler thinks the
    result of `f(args...)` is useful and does not optimize it away. Compilers are
    clever beasts indeed and can remove code that seems useless under what is colloquially
    known as the “as-if rule” (simply put, if there is no visible effect to calling
    a function, just get rid of it!).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'For the test program itself, pay attention to the following aspects:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: First, we will use `std::vector<Orc*>`, not `std::vector<Orc>`. This might seem
    strange at first, but since we are testing the speed of `Orc::operator new()`
    and `Orc::operator delete()`, we will want to actually call these operators! If
    we were using a container of `Orc` objects, there would be no call to our operators
    whatsoever.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We call `reserve()` on that `std::vector` object before running our tests,
    to allocate the space to put the pointers to the `Orc` objects we will be constructing.
    That is an important aspect of our measurements: calls to `push_back()` and similar
    insertion functions in a `std::vector` object will need to reallocate if we try
    to add an element to a full container, and this reallocation will add noise to
    our benchmarks, so ensuring the container will not need to reallocate during the
    tests helps us focus on what we want to measure.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What we measure with our `test()` function (used many times already in this
    book) is a sequence of `Orc::NB_MAX` calls to `Orc::operator new()`, eventually
    followed by the same number of calls to `Orc::operator delete()`. We suppose a
    carnage of sorts in the time between the constructions and the destructions, but
    we are not showing this violence out of respect for you, dear reader.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we reach the end, we print out the results of our measurements, using microseconds
    as the measurement unit – our computers today are fast enough that milliseconds
    would probably not be granular enough.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: At this point, you might wonder whether this is all worth the effort. After
    all, our standard libraries are probably very efficient (and indeed, they are,
    on average, excellent!). The only way to know whether the results will make us
    happy is to run the test code and see for ourselves.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the numbers
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using an online gcc 15 compiler with the -O2 optimization level and running
    this code twice (once with the standard library version and once with the homemade
    version using a Meyers singleton), I get the following numbers for calls to the
    `new` and `delete` operators on `Orc::NB_MAX` (here, 106) objects:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Homemade |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: '| N=106 | Standard library | Meyers singleton |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
- en: '| `operator new()` | 23433μs | 17906μs |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
- en: '| `operator delete()` | 7943μs | 638μs |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
- en: Table 10.1 – Speed comparison with Meyers singleton implementation
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Actual numbers will vary depending on a variety of factors, of course, but
    the interesting aspect of the comparison is the ratio: our homemade `operator
    new()` only took 76.4% of the time consumed by the standard library-provided version
    and our homemade `operator delete()` took… 8.03% of the time required by our baseline.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Those are quite pleasant results, but they should not really surprise us: we
    perform constant-time allocation and essentially “no time” deallocation. We do
    take the time to lock and unlock a `std::mutex` object on every allocation, but
    most standard libraries implement mutexes that expect low contention and are very
    fast under those circumstances, and it so happens that our program does single-threaded
    allocations and deallocations that lead to code that is clearly devoid of contention.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Now, your acute reasoning skills might lead you to be surprised that deallocation
    is not actually faster than what we just measured. It’s an empty function we are
    calling, after all, so what’s consuming this CPU time?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: The answer is… our singleton, or more precisely, access to the `static` local
    variable used for the Meyers implementation. Remember from [*Chapter 8*](B21071_08.xhtml#_idTextAnchor128)
    that this technique aims to ensure that a singleton is created when needed, and
    `static` local variables are constructed the first time their enclosing function
    is called.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'C++ implements “magic statics” where the call to the `static` local object’s
    constructor is guarded by synchronization mechanisms that ensure the object is
    constructed only once. As we can see, this synchronization, efficient as it is,
    is not free. In our case, if we can guarantee that no other global object will
    need to call `Tribe::get()` before `main()` is called, we can replace the Meyers
    approach with a more classical approach where the singleton is simply a `static`
    data member of the `Tribe` class, declared within the scope of that class and
    defined at global scope:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Moving the definition of the singleton object away from within the function
    – placing it at global scope – removes the need for synchronization around the
    call to its constructor. We can now compare this implementation with our previous
    results to evaluate the costs involved, and the gains to be made (if any).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'With the same test setup as used previously, adding the “global” singleton
    to the set of implementations under comparison, we get the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '| N=106 |  | Homemade |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
- en: '| Standard library | Meyers singleton | Global singleton |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
- en: '| `Operator new()` | 23433μs | 17906μs | 17573μs |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: '| `Operator delete()` | 7943μs | 638μs | 0μs |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: Table 10.2 – Speed comparison with Meyers and “global” singleton implementations
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Now, this is more like it! The calls to `operator new()` are slightly faster
    than they were 74.99% (of the time it took with the standard library version,
    and 98.14% of the time it took with the Meyers singleton), but the calls to `operator
    delete()` have become no-ops. It’s hard to do better than this!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'So, is it worth the effort? It depends on your needs, of course. Speed is a
    factor; in some programs, the speed gain can be a necessity, but in others, it
    can be a non-factor or almost so. The reduction in memory fragmentation can make
    a big difference in some programs too, and some will use arenas precisely for
    that reason. The point is this: if you need to do this, now you know how.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing to SizeBasedArena<T,N>
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Tribe` class as written seems specific to the `Orc` class but, in practice,
    it really is specific to `Orc`-*sized* objects as it never calls any function
    of the `Orc` class; it never constructs an `Orc` object, nor does it ever destroy
    one. This means that we could turn that class into a generic class and reuse it
    for other types that are expected to be used under similar constraints.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve this, we would decouple the arena code from the `Orc` class and
    put it in a separate file, maybe called `SizeBasedArena.h`, for example:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It might be surprising that we used `T` and `N` as template parameters. Why
    type `T` instead of an integer initialized with `sizeof(T)` if we do not use `T`
    in the arena? Well, if the `Elf` class (for example) used a size-based arena too,
    and if we were unlucky enough that `sizeof(Orc)==sizeof(Elf)`, then basing ourselves
    on the sizes of the types rather than on the types themselves might, if the values
    for their respective `N` parameters are the same, lead `Orc` and `Elf` to use
    the same arena… and we do not want that (nor do they!).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: To simplify the initialization of the singleton in this generic example, we
    went back to the Meyers technique. It’s more difficult to guarantee the absence
    of interdependence at construction time for global objects when writing generic
    code than it was writing the `Orc`-specific equivalent, as the move to generic
    code just enlarged the potential user base significantly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation in `Orc.cpp` would now be as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You might have noted that since `SizeBasedArena<T,N>` implements allocation
    functions for a single object or an array of `n` objects, we have extended the
    `Orc` class’s member function allocation operator overloads to cover `operator
    new[]()` and `operator delete[]()`. There’s really no reason not to do so at this
    point.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: When parameters change
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our size-based arena implementation is very specific: it supposes the possibility
    of sequential allocations and the ability to dismiss the (generally important)
    question of reusing memory after it has been freed.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'An important caveat to any size-based implementation is, obviously, that we
    are counting on a specific size. Know, thus, that with this constraint, our current
    implementation is slightly dangerous. Indeed, consider the following evolution
    of our program, where we envision tougher, meaner `Orc` subclasses such as the
    following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It might not be apparent at first, but we just might have broken something important
    with this new class, as *the member function allocation operators are inherited
    by derived classes*. This means that the `Tribe` class, also known under the somewhat
    noisier name of `SizeBasedArena<Orc,Orc::NB_MAX>`, would implement a strategy
    meant for blocks of `sizeof(Orc)` bytes but be used (accidentally) also for objects
    of size `MeanOrc`. This can only lead to pain.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'We can protect ourselves from this disastrous situation in two ways. For the
    `Orc` class, we could disallow derived classes altogether by marking the class
    as `final`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This removes the possibility of writing `MeanOrc` as a derived class of `Orc`;
    we can still write `MeanOrc`, but through composition or other techniques, which
    would sidestep the inherited operators problem.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'From the perspective of `SizeBasedArena<T,N>` itself, we can also decide to
    restrict our implementation to `final` types, as in this example:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This last part might not be for everyone, however. There are lots of types (fundamental
    types, for example) that are not `final` and that could reasonably be used in
    a size-based arena, so it’s up to you to see whether this is a good idea or not
    for the kind of code you write. If it’s not good for you, then these constraints
    could be expressed as prose rather than as code.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最后一部分可能并不适合所有人。有许多类型（例如基本类型）不是`final`的，并且可以在基于大小的竞技场中合理使用，所以这取决于你，看看这对你所写的代码来说是否是一个好主意。如果你觉得不好，那么这些约束可以用散文而不是代码来表达。
- en: Size-based arenas are far from the only use case for memory arenas. We could
    envision many variations on both the size-based theme and the allocation strategy.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大小的竞技场远非内存竞技场的唯一用例。我们可以在基于大小的主题和分配策略上设想许多变体。
- en: 'For example, suppose we introduce shamans in our game and the need to reuse
    memory becomes a reality. We could have a situation where there are, at most,
    `Orc::NB_MAX` objects of the `Orc` type in the program *at once*, but there might
    be more than that number *overall* during the entire program’s execution. In such
    a situation, we need to consider the following things:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们在游戏中引入了萨满，并且内存重用成为现实需求。我们可能会遇到这样的情况：在程序中，最多有`Orc::NB_MAX`个`Orc`类型的对象*同时存在*，但在整个程序执行期间，总数可能超过这个数字。在这种情况下，我们需要考虑以下事项：
- en: If we allow arrays, we will have to deal with *internal* fragmentation within
    the arena, so we might want to consider an implementation that allocates more
    than `N*sizeof(T)` bytes per arena, but how much more?
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们允许数组，我们将在竞技场内部处理*内部*碎片化，因此我们可能想要考虑一种实现方式，为每个竞技场分配超过`N*sizeof(T)`字节的内存，但要多多少呢？
- en: We will need a strategy to reuse memory. There are many approaches at our disposal,
    including maintaining an ordered list of `begin,end` pairs to delimit the free
    blocks (and fuse them more easily to reduce fragmentation) or keeping a stack
    (maybe a set of stacks based on block size) of recently freed blocks to make it
    easier to reuse freed blocks quickly.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要一种策略来重用内存。我们有多种方法可供选择，包括维护一个有序的`begin,end`对列表来界定空闲块（并且更容易将它们融合以减少碎片化）或者保留一个堆栈（可能是一系列基于块大小的堆栈）来存储最近释放的块，以便更快地重用这些块。
- en: 'Answers to such questions as “*What is the best approach for our code base?*”
    are in part technical and in part political: what makes allocation fast may slow
    down deallocation, what makes allocation speed deterministic may cost more in
    memory space overhead, and so on. The question is to determine what trade-offs
    work best in our situation and measure to ensure we reap the desired benefits.
    If we cannot manage to do better than the standard library already does, then
    by all means, use the standard library!'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“*我们代码库的最佳方法是什么？*”这样的问题，部分是技术性的，部分是政治性的：什么使得分配快速可能会减慢释放，什么使得分配速度确定性可能会在内存空间开销上付出更多，等等。问题是要确定在我们的情况下哪些权衡效果最好，并测量以确保我们获得预期的收益。如果我们无法做得比标准库更好，那么无论如何，使用标准库吧！
- en: Chunked pools
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分块池
- en: Our size-based arena example was optimized for a single block size and specific
    usage patterns, but there are many other reasons to want to apply a specialized
    allocation strategy. In this section, we will explore the idea of a “chunked pool,”
    or a pool of pre-allocated raw memory of selected block sizes. This is meant as
    an academic example to build upon more than as something to use in production;
    the code that follows will be reasonably fast and can be made to become very fast,
    but in this book, we will focus on the general approach and leave you, dear reader,
    to enjoy optimizing it to your liking.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于大小的竞技场示例是为了优化单个块大小和特定的使用模式，但还有许多其他原因想要应用专门的分配策略。在本节中，我们将探讨“分块池”的概念，或者说是预分配选定块大小的原始内存的池。这更多的是作为一个学术示例来构建，而不是作为生产中使用的示例；接下来的代码将相当快速，并且可以变得非常快速，但在这本书中，我们将关注一般方法，并让你，亲爱的读者，去享受优化它到你满意的程度。
- en: The idea in this example is that user code plans to allocate objects of similar
    (but not necessarily identical) sizes and of various types and supposes an upper
    bound on the maximal number of objects. This gives us additional knowledge; using
    that knowledge, we will write a `ChunkSizedAllocator<N,Sz...>` type where `N`
    will be the number of objects of each “size category” and each integral value
    in `Sz...` will be a distinct size category.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: To give a clarifying example, a `ChunkSizedAllocator<10,20,40,80,160>` object
    would pre-allocate sufficient raw memory to hold 10 objects of size 20 bytes,
    40 bytes, 80 bytes, and 160 bytes each for a total of at least 3,000 bytes (the
    sum of the minimal size required for each size category being *200 + 400 + 800
    + 1600*). We say “at least” in this case because to be useful, our class will
    need to consider alignment and will generally need more than the minimal amount
    of memory if we are to avoid allocating misaligned objects.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand what we are going to do, here are some pointers (pun intended):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: In the variadic sequence of integral values `Sz...` we will require the values
    to be sorted in ascending order, as this will make further lookup faster (linear
    complexity rather than quadratic complexity). Since these values are known at
    compile time, being part of the template parameters of our type, this has no runtime
    costs and is more of a constraint imposed on the user. We will, of course, validate
    this at compile time to avoid unpleasant mishaps.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In C++, variadic packs can be empty, but in our case, an empty set of size categories
    would make no sense so we will ensure that does not happen (at compile time, of
    course). Obviously, `N` has to be more than zero for this class to be useful so
    we will validate this also.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What might not be self-evident is that values in `Sz...` have to be at least
    `sizeof(std::max_align_t)` (we could have tested for `alignof` too but, for fundamental
    types, this is redundant) and that, in practice, we will need to make the effective
    size categories powers of two to make sure arbitrary types can be allocated. This
    latter part will be handled internally, as it’s trickier to impose on user code.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Looking at the code, we can see these constraints expressed explicitly. Note
    that to make the “code narrative” easier to follow, the code that follows is presented
    step by step, so make sure to look at the complete example if you want to experiment
    with it:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that we have two data members – namely, `blocks`, which will contain a
    pointer to a block of raw memory for each size category, and `cur`, which will
    contain the index of the next allocation within a block for each size category
    (initialized to zero by default, as we will start from the beginning in each case).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this class continues shortly. For now, you might notice some unexplained
    helper functions:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: We use `make_array(Sz...)`, a `constexpr` function that constructs an object
    of type `std::array<T,N>` from the values of `Sz...`, expecting all values to
    be of the same type (the type of the first value of `Sz...`). We know `N` for
    the resulting `std::array<T,N>` to be a compile-time constant as it is computed
    from the number of values in `Sz...`.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`make_array(Sz...)`，这是一个`constexpr`函数，它从`Sz...`的值构建一个类型为`std::array<T,N>`的对象，期望所有值都是同一类型（`Sz...`的第一个值的类型）。我们知道`N`对于结果`std::array<T,N>`是一个编译时常数，因为它是从`Sz...`中的值的数量计算出来的。
- en: We use the `is_sorted()` predicate on that `std::array<T,N>` object to ensure,
    at compile time, that the values are sorted in ascending order, as we expect them
    to be. Unsurprisingly, this will simply call the `std::is_sorted()` algorithm,
    which is `constexpr` and thus usable in this context.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`is_sorted()`谓词在`std::array<T,N>`对象上，以确保在编译时值是按升序排序的，正如我们所期望的那样。不出所料，这会简单地调用`std::is_sorted()`算法，它是一个`constexpr`，因此可以在这种上下文中使用。
- en: 'The non-`static` member array named `sizes` will contain the next power of
    two for each value in `Sz...`, including that value, of course: if the value is
    already a power of two, wonderful! Thus, if `Sz...` is `10,20,32`, then `sizes`
    will contain `16,32,32`.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名为`sizes`的非`static`成员数组将包含`Sz...`中每个值（包括该值）的下一个2的幂：如果该值已经是2的幂，那太好了！因此，如果`Sz...`是`10,20,32`，那么`sizes`将包含`16,32,32`。
- en: Why powers of two?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么是2的幂？
- en: In practice, blocks that are not powers of two will lead to misaligned objects
    after the first allocation if we allocate them contiguously, and managing padding
    to avoid this is possible but would complicate our implementation significantly.
    To make allocations quicker, we compute the next power to two for each element
    of `Sz...` at compile time and store them in the `sizes` array. This means we
    could have two size categories that end up being of the same size (for example,
    `40` and `60` would both lead to 64 bytes blocks) but that’s a minor issue (as
    code would still work) considering that this is a specialized facility designed
    for knowledgeable users.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，如果我们连续分配不是2的幂的块，那么在第一次分配之后，这些块将导致对象对齐错误，为了避免这种情况而管理填充可能会变得可能，但这将显著复杂化我们的实现。为了使分配更快，我们在编译时计算`Sz...`每个元素的下一个2的幂，并将它们存储在`sizes`数组中。这意味着我们可能会有两个最终大小相同的尺寸类别（例如，`40`和`60`都会导致64字节的块），但这是一个小问题（因为代码仍然可以工作），考虑到这是一个为知识渊博的用户设计的专用设施。
- en: 'The code for these helper functions, in practice, defined before the declaration
    of the `ChunkSizedAllocator<N,Sz...>` class is as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些辅助函数的代码，在实践中，是在`ChunkSizedAllocator<N,Sz...>`类的声明之前定义的，如下所示：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that `make_array()` uses concepts to constrain that all values are of the
    same type, and that `is_power_of_two(n)` ensures that the proper bits of `n` are
    tested to make this test quick (it also tests `n` to ensure we do not report `0`
    as being a power of two). The `next_power_of_two()` function could probably be
    made much faster but that’s of little consequence here as it is only used at compile
    time (we could enforce this by making it `consteval` instead of `constexpr`, but
    there might be users that want to choose between run time and compile time usage
    so we’ll give them that choice).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`make_array()`使用概念来约束所有值都是同一类型，`is_power_of_two(n)`确保测试`n`的正确位以使此测试快速（它还测试`n`以确保我们不报告`0`为2的幂）。`next_power_of_two()`函数可能可以做得更快，但在这里这影响不大，因为它仅在编译时使用（我们可以通过将其改为`consteval`而不是`constexpr`来强制执行这一点，但可能有一些用户想要在运行时和编译时使用之间进行选择，所以我们将给他们这个选择）。
- en: 'Returning to our `ChunkSizedAllocator<N,Sz...>` implementation after this short
    digression on helper functions, we have a member function named `within_block(p,i)`
    that returns `true` only if pointer `p` is within `blocks[i]`, which is the `i`-th
    pre-allocated block of memory of our object. The logic for that function seems
    deceptively simple: one might simply want to test something that looks like `blocks[i]<=p&&p<blocks[i]+N`
    but with the proper casts applied, as the `blocks[i]` variable is of type `void*,`
    which precludes pointer arithmetic, but that happens to be incorrect in C++ (remember
    our discussion of the intricacies of pointer arithmetic in [*Chapter 2*](B21071_02.xhtml#_idTextAnchor027)).
    It probably works in practice for compatibility with C code, but it’s not something
    you want to rely on.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要讨论了辅助函数之后，我们回到`ChunkSizedAllocator<N,Sz...>`实现，这里有一个名为`within_block(p,i)`的成员函数，它仅在指针`p`位于`blocks[i]`内时返回`true`，`blocks[i]`是我们对象内存的`i`-th预分配块。该函数的逻辑看似简单：人们可能只想测试类似`blocks[i]<=p&&p<blocks[i]+N`的东西，但考虑到`blocks[i]`变量是`void*`类型，这阻止了指针运算，但在C++中这实际上是错误的（记得我们在[*第二章*](B21071_02.xhtml#_idTextAnchor027)中关于指针运算复杂性的讨论）。在实践中，这可能因为与C代码的兼容性而有效，但这不是你想要依赖的东西。
- en: 'As of this writing, there are ongoing discussions to add a standard library
    function to test whether a pointer is between two others, but until this happens,
    we can at least use the standard library-provided `std::less` functor to make
    the comparisons somewhat legal. This is unsatisfactory, I know, but it will probably
    work on all compilers today… and by making this test local to a specialized function,
    we will simplify source code updates once we have a real standard solution to
    this problem:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，正在进行讨论，以添加一个标准库函数来测试一个指针是否位于两个其他指针之间，但直到这种情况发生，我们至少可以使用标准库提供的`std::less`函数对象来使比较变得合法。我知道这并不令人满意，但今天它可能适用于所有编译器……通过将这个测试局部化到一个专用函数中，一旦我们有一个真正的标准解决方案来解决这个问题，我们就可以简化源代码的更新：
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'There’s no reason to make objects of `ChunkSizedAllocator<N,Sz...>` globally
    available: this is a tool that could be instantiated many times in a program and
    used to solve various problems. We do not want that type to be copyable, however
    (we could, but that would really complicate the design for limited returns).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 没有必要使`ChunkSizedAllocator<N,Sz...>`对象全局可用：这是一个可以在程序中多次实例化并用于解决各种问题的工具。然而，我们不希望该类型是可复制的（我们可以这样做，但这会真正复杂化设计，而回报有限）。
- en: Through `std::malloc()`, our constructor allocates the raw memory blocks for
    the various sizes in `Sz...`, or at least the next power of two for each of these
    sizes, as explained earlier in this section, ensuring afterward that all of the
    allocations succeeded. We used `assert()` for this, but one could also throw `std::bad_alloc`
    on failure as long as one carefully called `std::free()` on the memory blocks
    that were successfully allocated before doing so.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`std::malloc()`，我们的构造函数为`Sz...`中的各种大小分配了原始内存块，或者至少是每个这些大小的下一个2的幂，正如本节前面所解释的，之后确保所有分配都成功。我们使用了`assert()`来做到这一点，但也可以在成功分配内存块后抛出`std::bad_alloc`异常，前提是必须小心地调用`std::free()`。
- en: 'Our destructor, unsurprisingly, calls `std::free()` on each memory block: as
    with the arena implementation earlier in this chapter, a `ChunkSizedAllocator<N,Sz...>`
    object is responsible for memory, not the objects put there by client code, so
    we have to suppose that client code destroyed all objects stored within the memory
    blocks of a `ChunkSizedAllocator` object before that object’s destructor is called.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的析构函数，不出所料，对每个内存块调用`std::free()`：正如本章前面提到的区域实现一样，`ChunkSizedAllocator<N,Sz...>`对象负责内存，而不是客户端代码放入其中的对象，因此我们必须假设在调用该对象的析构函数之前，客户端代码已经销毁了存储在`ChunkSizedAllocator`对象内存块中的所有对象。
- en: 'Note the presence of a `std::mutex` data member, as we will need this (or some
    other synchronization tool) to ensure allocations and deallocations are thread-safe
    later:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意存在一个`std::mutex`数据成员，因为我们稍后需要这个（或某种其他同步工具）来确保分配和释放是线程安全的：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Finally, we reach the crux of our effort with the `allocate()` and `deallocate()`
    member functions. In `allocate(n)`, we search for the smallest element, `sizes[i]`,
    for which the allocated block size is sufficiently big to hold `n` bytes. Once
    one such block is found, we lock our `std::mutex` object to avoid race conditions
    and then look to see whether there is still at least one available block in `blocks[i]`;
    this implementation takes them sequentially and does not reuse them, to keep the
    discussion simple. If there is one, we take it, update `cur[i]`, and return the
    appropriate address to the user code.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that when we do not find a free block in our pre-allocated blocks, or
    when `n` is too large for the blocks we allocated upfront, we delegate the allocation
    responsibility to `::operator new()` such that the allocation request might still
    succeed. We could also have thrown `std::bad_alloc` in this case, depending on
    what the intent is: if it’s important to us that the allocation is made within
    our blocks and nowhere else, throwing or otherwise failing is a better choice.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: How could failing be a good thing?
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Some applications, particularly in embedded systems of low-latency or real-time
    system domains, are such that software that delivers the right answer or produces
    the right computation but not in due time is as bad as software that produces
    a wrong answer. Think, for example, of a system that controls the brakes of a
    car: a car that stops after colliding is of limited usefulness indeed. Such systems
    are rigorously tested to catch failures before being released and will count on
    specific runtime behavior; for that reason, when under development, they might
    prefer failing (in a way that will be caught during their testing phase) rather
    than defaulting to a strategy that might sometimes not meet their timing requirements.
    Of course, please do not ship critical systems that stop working when used in
    real life: test them well and make sure users are kept safe! But maybe you are
    developing a system where, if something bad happens, you will prefer to print
    “Sorry, we messed up” somewhere and just restart the program, and that’s perfectly
    fine too sometimes.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: The `deallocate(p)` deallocation function goes through each memory block to
    see whether `p` is within that block. Remember that our `within_block()` function
    would benefit from a pointer comparison test that the standard does not yet provide
    as of this writing, so if you use this code in practice, make sure you leave yourself
    a note to apply this new function as soon as it becomes available. If `p` is in
    none of our blocks, then it was probably allocated through `::operator new()`
    so we make sure to free it through `::operator delete()` as we should.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'As stated previously, our implementation does not reuse memory once it has
    been freed, but the location where that reuse should happen has been left in comments
    (along with code that locks the mutex for that section) so feel free to implement
    memory block reuse logic there if you want to:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们的实现一旦释放内存就不会重用内存，但重用应该发生的位置已被留在了注释中（以及锁定该部分的互斥锁的代码），所以如果你想要实现内存块重用逻辑，请随意：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Since this is a specialized form of allocation to be used by client code as
    needed, we will use specialized overloads of the allocation operators. As can
    be expected, these overloads will be templates based on the parameters of the
    `ChunkSizedAllocator` object to be used:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一种客户端代码按需使用的特殊分配形式，我们将使用分配运算符的特殊重载。正如预期的那样，这些重载将是基于要使用的`ChunkSizedAllocator`对象参数的模板：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now, we wrote these allocation facilities, but we need to test them, as we need
    to see whether there are benefits to this approach.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经编写了这些分配设施，但我们需要测试它们，因为我们需要看到这种方法的益处。
- en: Testing ChunkSizedAllocator
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试ChunkSizedAllocator
- en: We will now write a simple test program that uses a `ChunkSizedAllocator` object
    with an appropriate set of size categories, then allocate and deallocate objects
    with sizes that fit within these categories in ways that should benefit our class.
    In so doing, we are supposing that users of this class do so seeking to benefit
    from a priori known size categories. Other tests could be conducted to verify
    the code’s behavior with inappropriate size requests or in the presence of throwing
    constructors, for example, so feel free to write a more elaborate test harness
    than the one we will be providing for the sake of our execution speed-related
    discussion.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将编写一个简单的测试程序，该程序使用一个具有适当大小类别的`ChunkSizedAllocator`对象，然后以应该对我们类有益的方式分配和释放适合这些类别的对象大小。通过这样做，我们假设这个类的用户这样做是为了从先验已知的大小类别中受益。还可以进行其他测试，以验证代码在请求不适当的大小或在存在抛出构造函数的情况下行为，例如，所以请随意编写比我们为执行速度相关讨论提供的更详尽的测试框架。
- en: The `test()` function used to test our size-based arena earlier in this chapter
    will be used here again. See that section for an explanation of its workings.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面用于测试基于大小的竞技场的`test()`函数将再次在这里使用。参见该部分以了解其工作原理。
- en: It’s not trivial to write a good test program to validate the behavior of a
    program that allocates and deallocates objects of various sizes. What we will
    do is use a `dummy<N>` type whose objects will each occupy a space of `N` bytes
    in memory (as we will use `char[N]` data members to get this result, we know that
    `alignof(dummy<N>)==1` for all valid values of `N`).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个良好的测试程序来验证分配和释放各种大小对象的程序的行为并非易事。我们将要做的是使用一个`dummy<N>`类型，其对象在内存中将各自占用`N`字节的空间（由于我们将使用`char[N]`数据成员来获取这个结果，我们知道对于所有有效的`N`值，`alignof(dummy<N>)==1`）。
- en: We will also write two distinct `test_dummy<N>()` functions. Each of these functions
    will allocate and then construct the `dummy<N>` object and set up the associated
    destroy-then-deallocate code, but one will use the standard library implementation
    of the allocation operators and the other will use our overloads.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将编写两个不同的`test_dummy<N>()`函数。每个这样的函数都将分配并构造`dummy<N>`对象，并设置相关的销毁然后释放代码，但一个将使用标准库实现的分配运算符，另一个将使用我们的重载。
- en: 'You will note that both of our `test_dummy<N>()` functions return a pair of
    values: one will be a pointer to the allocated object and the other will be the
    code to destroy and deallocate that object. Since we will store this information
    in client code, we need these pairs to be abstractions that share a common type,
    which explains our use of `void*` for the address and `std::function<void(void*)>`
    for the destruction code. We need `std::function` or something similar here: a
    function pointer would not suffice as the destruction code can be stateful (we
    sometimes need to remember what object was used to manage the allocation).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们的两个`test_dummy<N>()`函数都返回一对值：一个将是分配对象的指针，另一个将是销毁和释放该对象的代码。由于我们将在此存储信息，我们需要这些对是共享公共类型的抽象，这解释了我们为什么使用`void*`作为地址和`std::function<void(void*)>`作为销毁代码。我们需要`std::function`或类似的东西：函数指针不足以作为销毁代码，因为销毁代码可以是状态化的（我们有时需要记住用于管理分配的对象）。
- en: 'The code for these tools follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具的代码如下：
- en: '[PRE19]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Finally, we have to write the test program. We will discuss this program step
    by step to make sure we grasp all the subtleties involved in the process.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须编写测试程序。我们将逐步讨论这个程序，以确保我们掌握过程中涉及的所有细微差别。
- en: 'Our program first decides on a value of `N` for the `ChunkSizedAllocator` object
    as well as on size categories `Sz...` for that memory manager to use (the value
    I picked for `N` is arbitrary). I deliberately used one *non-power-of-two* size
    category to show that the values are “rounded up” to the next power of two appropriately:
    the size request of `62` is translated into `64` when constructing the `sizes`
    data member of our type. We then construct that object and name it `chunks` because…
    well, why not?'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们程序首先为`ChunkSizedAllocator`对象确定一个`N`的值，以及内存管理器要使用的`Sz...`大小类别（我选择的`N`的值是任意的）。我故意使用了一个非2的幂的大小类别，以表明这些值被适当地“向上取整”到下一个2的幂：`62`的大小请求在构建我们的类型的数据成员`sizes`时被转换为`64`。然后我们构建这个对象，并将其命名为`chunks`，因为……好吧，为什么不呢？
- en: '[PRE20]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The tests that follow take the same form for the standard library and for our
    specialized facility. Let’s look at them in detail:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的测试对于标准库和我们的专用设施具有相同的形式。让我们详细看看：
- en: We create a `std::vector` object of pairs named `ptrs` filled with default values
    (null pointers and non-callable functions) for `N` objects in three size categories
    (because `sizeof...(Sz)==3` in our example). This ensures that the allocation
    for the space used by the `std::vector` object is performed prior to our measurements
    (prior to the execution of the lambda expression passed to `test()`) and does
    not interfere with them later. Note that each tested lambda is mutable as it needs
    to modify the captured `ptrs` object.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`ptrs`的`std::vector`对象对，填充了默认值（空指针和非可调用函数），用于三个大小类别的`N`个对象。这确保了`std::vector`对象使用的空间分配在我们测量之前（在传递给`test()`的lambda表达式执行之前）进行，并且不会干扰它们。请注意，每个测试的lambda都是可变的，因为它需要修改捕获的`ptrs`对象。
- en: For each of the three size categories, we then allocate `N` objects of sizes
    that fit in that category and remember through the returned `pair` both that object’s
    address and the code that will correctly finalize it later.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于三个大小类别中的每一个，我们随后分配适合该类别的`N`个对象，并通过返回的`pair`记住该对象的地址以及稍后正确终结它的代码。
- en: Then, to end each test, we use the finalization code on each object and destroy
    and then deallocate it.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，为了结束每个测试，我们使用每个对象的finalization代码，将其销毁并重新分配。
- en: 'It sounds worse than it is, happily for us. Once the tests have run to completion,
    we print out the execution time of each test expressed as microseconds:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这听起来比实际情况要糟糕。一旦测试运行完成，我们就打印出每个测试的执行时间，以微秒为单位：
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Okay, so that was slightly intricate but hopefully instructive. Is it worth
    the trouble? Well, it depends on your needs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，所以这稍微有点复杂，但希望是有教育意义的。这值得麻烦吗？嗯，这取决于你的需求。
- en: 'When I ran this code on the same online gcc 15 compiler with the -O2 optimization
    level as with the size-based arena, the standard library version reported an execution
    time of 13,360, whereas the time reported for the “chunked” version was 12,032,
    effectively 90.05% of the standard version’s execution time. This kind of speedup
    can be lovely as long as we remember that the initial allocation done in the constructor
    of our `chunks` object was not measured: the idea here is to show we can save
    time when it’s important and choose to pay for it when we are not in a hurry.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当我用相同的在线gcc 15编译器运行此代码，并且使用与基于大小的区域相同的-O2优化级别时，标准库版本报告的执行时间为13,360微秒，而“分块”版本报告的时间为12,032微秒，相当于标准版本执行时间的90.05%。只要我们记住，在`chunks`对象的构造函数中进行的初始分配没有被测量：这里的想法是表明，当时间重要时，我们可以节省时间，并且当我们不急于求成时，我们愿意为此付费。
- en: It’s important to remember that this implementation does not reuse memory, but
    the standard version does so, which means our speedup might be counterbalanced
    by a loss of functionality (if it’s a functionality you need, of course). In the
    tests I ran, locking the `std::mutex` object or not doing so had a significant
    impact on speedup, so (a) depending on your platform, there might be a better
    choice of synchronization mechanism at your disposal, and (b) this implementation
    is probably too naïve to bring benefits as is if the `deallocate()` member function
    also needs to lock the `std::mutex` object.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，这种实现不会重用内存，但标准版本会这样做，这意味着我们的加速可能被功能性的损失所抵消（如果这是你需要的功能的话）。在我进行的测试中，锁定`std::mutex`对象或不锁定它对加速有显著影响，所以（a）根据你的平台，你可能会有更好的同步机制可供选择，并且（b）这种实现可能过于天真，如果`deallocate()`成员函数也需要锁定`std::mutex`对象，那么它可能无法带来任何好处。
- en: Of course, one could optimize this (quite academic) version quite a bit, and
    I invite you dear readers to do so (and test the results every step of the way!).
    The point of this section was more to show (a) that chunk size-based allocation
    can be done, (b) how it can be done from an architectural standpoint, and (c)
    point out some risks and potential pitfalls along the way.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可以对这种（相当学术的）版本进行相当多的优化，我邀请亲爱的读者们这样做（并且每一步都测试结果！）本节的目的更多的是为了展示（a）基于块大小的分配是可以实现的，（b）从架构的角度来看如何实现，以及（c）指出沿途的一些风险和潜在陷阱。
- en: That was fun, wasn’t it?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 那很有趣，不是吗？
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: As a reminder, in this chapter, we examined arena-based allocation with a concrete
    example (a size-based arena with a particular usage pattern) and saw we could
    get significant results from it, and then saw another use case with pre-allocated
    memory blocks from which we picked chunks where we placed objects, again seeing
    some benefits. These techniques showed new ways to control memory management,
    but in no way are they meant to represent an exhaustive discussion on the subject.
    To be honest, this entire book cannot be an exhaustive treatise on the subject,
    but it can hopefully give us ideas!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，在本章中，我们通过一个具体的例子（基于大小的特定使用模式的区域）考察了基于区域的分配，并看到我们可以从中获得显著的结果，然后看到了另一个使用预分配内存块的用例，我们从其中挑选了放置对象的块，再次看到了一些好处。这些技术展示了控制内存管理的新方法，但它们绝对不是对这一主题的全面讨论。说实话，整本书都不可能对这一主题进行全面论述，但希望它能给我们一些启发！
- en: 'The next step in our journey will be to expand the techniques seen in this
    chapter and write something that is not really a garbage collector but is in some
    ways weaker and in some ways better: deferred reclamation memory zones. This will
    be our last step before we start discussing memory management in containers.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们旅程的下一步将是扩展本章中看到的技巧，并编写一些实际上不是垃圾回收器但在某些方面较弱且在某些方面更好的内容：延迟回收内存区域。这将是我们开始讨论容器内存管理之前的最后一步。
