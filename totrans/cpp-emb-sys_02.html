<html><head></head><body>
<div><h1 class="chapterNumber">1</h1>
<h1 class="chapterTitle" id="_idParaDest-17">Debunking Common Myths about C++</h1>
<p class="normal">Writing software for microcontrollers and embedded systems is challenging. In order to get the most out of resource-constrained systems, embedded developers need to have a good knowledge of platform architecture. They need to be aware of available resources, including processor capabilities, available memory, and peripherals. The need to have direct access to hardware through memory-mapped peripherals has made <strong class="keyWord">C</strong> the language of choice for embedded systems for half a century.</p>
<p class="normal">The goal of any programming language is to carry out the process of converting application-specific <a id="_idIndexMarker000"/>abstractions into code that can be transformed into machine code. For instance, <strong class="keyWord">Common Business-Oriented Language</strong> (<strong class="keyWord">COBOL</strong>) is used for banking applications, and <strong class="keyWord">Fortran</strong> is used <a id="_idIndexMarker001"/>for scientific research and heavy mathematic calculations. C is, on the other hand, a general-purpose programming language <a id="_idIndexMarker002"/>commonly used in <strong class="keyWord">operating systems</strong> (<strong class="keyWord">OSs</strong>) and embedded system applications.</p>
<p class="normal">C is a language with a simple and easy-to-learn syntax. Having a simple syntax means it is incapable of expressing complex ideas. C allows for complex operations but requires more explicit and detailed code to manage complexity, compared to higher-level languages that abstract these details away.</p>
<p class="normal">In the late 1970s, high-level languages couldn’t meet the performance of C. This motivated Danish computer scientist Bjarne Stroustrup to start working on <strong class="keyWord">C with Classes</strong>, a predecessor to C++. Nowadays, C++ is a multiparadigm language designed with performance in mind. The origin of C++ is still a source of some myths, which often causes hesitation in adopting it for embedded systems programming. This chapter will introduce you to those myths and debunk them. The following topics will be covered in this chapter:</p>
<ul>
<li class="bulletList">A short history of C++</li>
<li class="bulletList">C with Classes</li>
<li class="bulletList">Bloat and runtime overhead</li>
</ul>
<h1 class="heading-1" id="_idParaDest-18">Technical requirements</h1>
<p class="normal">To get the most out of this chapter, I strongly recommend using Compiler Explorer (<a href="https://godbolt.org/">https://godbolt.org/</a>) as you read through the examples. Select GCC as your compiler and target x86 architecture. This will allow you to see standard output (stdio) results and better observe the code’s behavior. The examples from this chapter are available on GitHub (<a href="https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter01">https://github.com/PacktPublishing/Cpp-in-Embedded-Systems/tree/main/Chapter01</a>).</p>
<h1 class="heading-1" id="_idParaDest-19">A short history of C++</h1>
<p class="normal">In the mid-60s, the simulation programming language <strong class="keyWord">SIMULA</strong> introduced classes and objects to the <a id="_idIndexMarker003"/>world of software <a id="_idIndexMarker004"/>development. <strong class="keyWord">Classes</strong> are abstractions that allow us to represent real-world concepts in programming in a concise way, making <a id="_idIndexMarker005"/>the code <a id="_idIndexMarker006"/>more human-readable. In embedded development, <strong class="keyWord">UART</strong>, <strong class="keyWord">SPI</strong>, <strong class="keyWord">TemperatureSensor</strong>, <strong class="keyWord">PidController</strong>, and <strong class="keyWord">TemperatureController</strong> are some <a id="_idIndexMarker007"/>concepts that <a id="_idIndexMarker008"/>can be implemented as <a id="_idIndexMarker009"/>classes. SIMULA also introduced hierarchical relationships between classes. For example, <code class="inlineCode">PT100</code> class is also a <code class="inlineCode">TemperatureSensor</code> class, and <code class="inlineCode">TemperatureController</code> class has a member instance (object) of <code class="inlineCode">TemperatureSensor</code> and a <code class="inlineCode">PidController</code>. This <a id="_idIndexMarker010"/>became known as <strong class="keyWord">object-oriented programming</strong> (<strong class="keyWord">OOP</strong>).</p>
<p class="normal">In reflecting on the evolution of programming languages, Bjarne Stroustrup, the creator of C++, shared his approach to designing C++. Stroustrup aimed to bridge the gap between high-level abstractions and low-level efficiency. He said the following:</p>
<blockquote class="packt_quote">
<p class="quote"> My idea was very simple. To take ideas from SIMULA for general abstractions for the benefits of humans representing things, so humans could get it, with low-level stuff, which at that time the best language for that was C, which was done at Bell Labs by Dennis Ritchie. And take those two ideas and bring them together so that you could do high-level abstraction, but efficiently enough and close enough to hardware, for really demanding computing tasks</p>
</blockquote>
<p class="normal">Originally started as C with Classes by Bjarne Stroustrup, C++ transformed into a modern programming language that still provides direct access to hardware and memory-mapped peripherals. Using powerful abstractions makes writing expressive and highly modular code possible in C++. C++ is a general-purpose, multiparadigm language supporting procedural, object-oriented, and, to some extent, functional programming paradigms.</p>
<p class="normal">While C is still the <a id="_idIndexMarker011"/>language of choice for embedded development, accounting for up to 60% of embedded projects, the adoption of C++ has grown steadily. With an estimated usage of 20-30% in the embedded development field, C++ offers classes, improved type safety, and compile-time computation, among other features.</p>
<p class="normal">Despite the features that C++ offers, C is still dominant in embedded programming. There are many reasons for this, and this chapter will address some of them. C++ is a more complex language than C, making it harder for beginner developers. C is easier to learn and makes it possible to involve beginner developers in a project faster.</p>
<p class="normal">The simplicity of C is good as it allows beginner developers to start contributing to projects faster, but it also makes writing complex logic too verbose. This usually results in a larger code base due to a lack of expressiveness. This is where C++ steps in with higher abstractions, which, if embraced, make code easier to read and comprehend.</p>
<p class="normal">The other reasons why C++ is not more widely adopted are related to myths about C++. It is still believed that C++ is just “C with classes,” that using C++ is absolutely unacceptable for safety-critical systems due to dynamic memory allocation in the standard library, or that it produces bloat code and adds space and time overhead. This chapter will address some of the most common myths about C++ in the context of embedded development. Let’s debunk these myths and shine a new light on C++ in embedded systems!</p>
<h1 class="heading-1" id="_idParaDest-20">C with Classes</h1>
<p class="normal">Historically speaking, C++ started as C with Classes. The <a id="_idIndexMarker012"/>first C++ compiler, <strong class="keyWord">Cfront</strong>, converted C++ to C, but that <a id="_idIndexMarker013"/>was a long time ago. Over time, C and C++ evolved separately and are now defined by separate language standards. C has maintained its simplicity, while C++ has become a modern language that enables abstract solutions for problems without sacrificing performance levels. But C++ is still sometimes called C with Classes, which implies that there is no added value in C++ except the classes.</p>
<p class="normal">The C++11 standard was released in 2011, and it is the second major version of C++. It is packed with features that modernize the language, such as range-based loops, lambdas, and <code class="inlineCode">constexpr</code>. Subsequent releases, C++14, C++17, C++20, and C++23, kept modernizing the language and introducing features that make C with Classes merely a distant predecessor of modern C++.</p>
<h2 class="heading-2" id="_idParaDest-21">Modern C++</h2>
<p class="normal">To demonstrate that C++ is not just C with Classes, let’s explore a couple of short C code examples and <a id="_idIndexMarker014"/>their modern C++ equivalents. Let’s start with a <a id="_idIndexMarker015"/>simple example of printing elements from an integer buffer:</p>
<pre class="programlisting code"><code class="hljs-code">#define N 20
int buffer[N];
for(int i = 0; i &lt; N; i ++) {
    printf("%d ", buffer[i]);
}
</code></pre>
<p class="normal">The preceding C code can be translated into the following C++ code:</p>
<pre class="programlisting code"><code class="hljs-code">std::array&lt;int, 20&gt; buffer;
for(const auto&amp; element : buffer) {
    printf("%d ", element);
}
</code></pre>
<p class="normal">The first thing we notice is that the C++ version is shorter. It has fewer words, and it’s closer to English than the C code. It is easier to read. Now, if you come from a C background and have not been exposed to higher-level languages, the first version may look easier to read, but let’s compare them. The first thing we notice is that the C code has defined the constant <code class="inlineCode">N</code>, which determines the size of <code class="inlineCode">buffer</code>. This constant is used to define <code class="inlineCode">buffer</code> and as a boundary for the <code class="inlineCode">for</code> loop.</p>
<p class="normal">Range-based loops, introduced in C++11, remove the cognitive burden of using the size of the container in the loop stop condition. The size information is already contained in the <code class="inlineCode">std::array</code> container, which is utilized by the range-based loop to iterate through the array effortlessly. Also, there is no indexing of the buffer, as elements are accessed using constant reference, ensuring that the elements are not modified inside the loop.</p>
<p class="normal">Let’s look at some simple C code that copies all elements from the <code class="inlineCode">array_a</code> integer to <code class="inlineCode">array_b</code> if smaller than <code class="inlineCode">10</code>:</p>
<pre class="programlisting code"><code class="hljs-code">int w_idx = 0;
for(int i = 0; i &lt; sizeof(array_a)/sizeof(int); i++) {
    if(array_a[i] &lt; 10) {
        array_b[w_idx++] = array_a[i];
    }
}
</code></pre>
<p class="normal">Here is the C++ code with the same functionality:</p>
<pre class="programlisting code"><code class="hljs-code">auto less_than_10 =  [](auto x) -&gt; bool {
    return x &lt; 10;
};
std::copy_if(std::begin(array_a), std::end(array_a), std::begin(array_b), less_than_10);
</code></pre>
<p class="normal">Instead of manually iterating through <code class="inlineCode">array_a</code> and copying elements to <code class="inlineCode">array_b</code> only if they exceed <code class="inlineCode">10</code>, we can use the <code class="inlineCode">copy_if</code> function from C++’s standard template library. The first two arguments for <code class="inlineCode">std::copy_if</code> are iterators that define the range of elements to consider in <code class="inlineCode">array_a</code>: the first iterator points to the beginning of the array, and the second iterator points <a id="_idIndexMarker016"/>to the position just beyond the last element. The third argument <a id="_idIndexMarker017"/>is the iterator pointing to the start of <code class="inlineCode">array_b</code>, and the fourth is the <code class="inlineCode">less_than_10</code> lambda expression.</p>
<p class="normal">A lambda expression is an anonymous function object that can be declared at a location where it’s invoked or passed as an argument to a function. Please note that lambdas will be covered in more detail in <a href="Chapter_10.xhtml"><em class="italic">Chapter 10</em></a>. In the case of <code class="inlineCode">std::copy_if</code>, the <code class="inlineCode">less_than_10</code> lambda is used to determine whether elements from <code class="inlineCode">array_a</code> are to be copied to <code class="inlineCode">array_b</code>. We could also define a standalone <code class="inlineCode">less_than_10</code> function that accepts an integer and returns a Boolean if it is larger than 10, but using a lambda, we can write this functionality close to the place where we pass it to an algorithm, which makes code more compact and expressive.</p>
<h2 class="heading-2" id="_idParaDest-22">Generic types</h2>
<p class="normal">Previous examples used the <code class="inlineCode">std::array</code> standard library container. It is a class template that wraps <a id="_idIndexMarker018"/>a C-style array along with its size information. Please note that templates will be covered in more detail in <a href="Chapter_08.xhtml"><em class="italic">Chapter 8</em></a>. When you use <code class="inlineCode">std::array</code> with a specific underlying type and size, the compiler defines a new type in the process of <strong class="keyWord">instantiation</strong>.</p>
<p class="normal"><code class="inlineCode">std::array&lt;int, 10&gt;</code> creates a container type that has an underlying C-style array of integers with <a id="_idIndexMarker019"/>a size of <code class="inlineCode">10</code>. The <code class="inlineCode">std::array&lt;int, 20&gt;</code> is a container type that has an underlying C-style array of integers with a size of <code class="inlineCode">20</code>. The <code class="inlineCode">std::array&lt;int, 10&gt;</code> and <code class="inlineCode">std::array&lt;int, 20&gt;</code> are different types. Both have the same underlying type, but a different size.</p>
<p class="normal"><code class="inlineCode">std::array&lt;float, 10&gt;</code> would result in a third type, as it differs from <code class="inlineCode">std::array&lt;int, 10&gt;</code> by the underlying type. Using different parameters yields different types. Template types are generic types that become concrete only upon instantiation.</p>
<p class="normal">To better understand generic types and appreciate them, let’s examine the implementation of a ring buffer in C and compare it with a template-based solution in C++.</p>
<h3 class="heading-3" id="_idParaDest-23">Ring buffer in C</h3>
<p class="normal">A <strong class="keyWord">ring</strong> or <strong class="keyWord">circular buffer</strong> is a commonly <a id="_idIndexMarker020"/>used data structure in embedded <a id="_idIndexMarker021"/>programming. It is commonly implemented as a set of functions <a id="_idIndexMarker022"/>around an array with write and read indexes used to access elements of the array. The <code class="inlineCode">count</code> variable is used for array space management. The interface consists of push and pop functions, which are explained here:</p>
<ul>
<li class="bulletList">A <strong class="keyWord">push</strong> function is <a id="_idIndexMarker023"/>used to store elements in a ring buffer. On every push, a data element is stored in the array, and the write index is incremented. If the write index becomes equal to the number of elements in the data array, it is reset to 0.</li>
<li class="bulletList">A <strong class="keyWord">pop</strong> function is <a id="_idIndexMarker024"/>used to retrieve an element from a ring buffer. On every pop, if the underlying array is not empty, we return an element of the array indexed with the read index. We increment the read index.</li>
</ul>
<p class="normal">On every push, we increment the <code class="inlineCode">count</code> variable and decrement it on pop. If the count becomes equal to the size of the data array, we need to move the read index forward.</p>
<p class="normal">Let us define <a id="_idIndexMarker025"/>the implementation requirements of the ring buffer we want to implement in our C module:</p>
<ul>
<li class="bulletList">It should not use dynamic memory allocation</li>
<li class="bulletList">When the buffer is full, we will overwrite the oldest element</li>
<li class="bulletList">Provide push and pop functions for storing data in the buffer and retrieving it</li>
<li class="bulletList">Integers will be stored in the ring buffer</li>
</ul>
<p class="normal">Here is a simple solution for the preceding requirements in C:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;stdio.h&gt;
#define BUFFER_SIZE 5
typedef struct {
int arr[BUFFER_SIZE]; // Array to store int values directly
size_t write_idx;     // Index of the next element to write (push)
size_t read_idx;      // Index of the next element to read (pop)
size_t count;         // Number of elements in the buffer
} int_ring_buffer;
void int_ring_buffer_init(int_ring_buffer *rb) {
  rb-&gt;write_idx = 0;
  rb-&gt;read_idx = 0;
  rb-&gt;count = 0;
}
void int_ring_buffer_push(int_ring_buffer *rb, int value) {
  rb-&gt;arr[rb-&gt;write_idx] = value;
  rb-&gt;write_idx = (rb-&gt;write_idx + 1) % BUFFER_SIZE;
  if (rb-&gt;count &lt; BUFFER_SIZE) {
    rb-&gt;count++;
  } else {
    // Buffer is full, move read_idx forward
    rb-&gt;read_idx = (rb-&gt;read_idx + 1) % BUFFER_SIZE;
  }
}
int int_ring_buffer_pop(int_ring_buffer *rb) {
  if (rb-&gt;count == 0) {
    return 0;
  }
  int value = rb-&gt;arr[rb-&gt;read_idx];
  rb-&gt;read_idx = (rb-&gt;read_idx + 1) % BUFFER_SIZE;
  rb-&gt;count--;
  return value;
}
int main() {
  int_ring_buffer rb;
  int_ring_buffer_init(&amp;rb);
  for (int i = 0; i &lt; 10; i++) {
    int_ring_buffer_push(&amp;rb, i);
  }
  while (rb.count &gt; 0) {
    int value = int_ring_buffer_pop(&amp;rb);
    printf("%d\n", value);
  }
  return 0;
}
</code></pre>
<p class="normal">We are using a <code class="inlineCode">for</code> loop to <a id="_idIndexMarker026"/>initialize the buffer. As the buffer size is <code class="inlineCode">5</code>, values from <code class="inlineCode">5</code> to <code class="inlineCode">9</code> will be stored in the buffer as the ring buffer overwrites the existing data. Now, what if we want to store floats in our ring buffer, chars, or a user-defined data structure? We could implement the same logic for different types and create a new set of data structures and functions called <code class="inlineCode">float_ring_buffer</code> or <code class="inlineCode">char_ring_buffer</code>. Can we make a solution that could store different data types and use the same functions?</p>
<p class="normal">We could use an <code class="inlineCode">unsigned char</code> array as storage for different data types and use a <code class="inlineCode">void</code> pointer to pass different data types to push and pop functions. The only thing that’s missing is knowing the <a id="_idIndexMarker027"/>size of the data type, and we can address that by adding a <code class="inlineCode">size_t elem_size</code> member to the <code class="inlineCode">ring_buffer</code> structure:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#define BUFFER_SIZE 20 // Total bytes available in the buffer
typedef struct {
unsigned char data[BUFFER_SIZE]; // Array to store byte values
size_t write_idx;                // Index of the next byte to write
size_t read_idx;                 // Index of the next byte to read
size_t count;     // Number of bytes currently used in the buffer
size_t elem_size; // Size of each element in bytes
} ring_buffer;
void ring_buffer_init(ring_buffer *rb, size_t elem_size) {
  rb-&gt;write_idx = 0;
  rb-&gt;read_idx = 0;
  rb-&gt;count = 0;
  rb-&gt;elem_size = elem_size;
}
void ring_buffer_push(ring_buffer *rb, void *value) {
  if (rb-&gt;count + rb-&gt;elem_size &lt;= BUFFER_SIZE) {
    rb-&gt;count += rb-&gt;elem_size;
  } else {
    rb-&gt;read_idx = (rb-&gt;read_idx + rb-&gt;elem_size) % BUFFER_SIZE;
  }
  memcpy(&amp;rb-&gt;data[rb-&gt;write_idx], value, rb-&gt;elem_size);
  rb-&gt;write_idx = (rb-&gt;write_idx + rb-&gt;elem_size) % BUFFER_SIZE;
}
int ring_buffer_pop(ring_buffer *rb, void *value) {
  if (rb-&gt;count &lt; rb-&gt;elem_size) {
    // Not enough data to pop
return 0;
  }
  memcpy(value, &amp;rb-&gt;data[rb-&gt;read_idx], rb-&gt;elem_size);
  rb-&gt;read_idx = (rb-&gt;read_idx + rb-&gt;elem_size) % BUFFER_SIZE;
  rb-&gt;count -= rb-&gt;elem_size;
  return 1; // Success
}
int main() {
  ring_buffer rb;
  ring_buffer_init(&amp;rb, sizeof(int)); // Initialize buffer for int values
for (int i = 0; i &lt; 10; i++) {
    int val = i;
    ring_buffer_push(&amp;rb, &amp;val);
  }
  int pop_value;
  while (ring_buffer_pop(&amp;rb, &amp;pop_value)) {
    printf("%d\n", pop_value);
  }
  return 0;
}
</code></pre>
<p class="normal">This ring buffer solution can be used to store different data types. As we avoid using dynamic memory <a id="_idIndexMarker028"/>allocation and the <code class="inlineCode">data</code> buffer size was determined at compile time, we are not flexible when it comes to defining the size of the memory needed for different instances of the ring buffer. Another problem we have is type safety. We can easily call <code class="inlineCode">ring_buffer_push</code> with a pointer to a float and <code class="inlineCode">ring_buffer_pop</code> with a pointer to an integer. The compiler can’t address this concern, and the possibility of a catastrophe is real. Also, by using a void pointer, we added a layer of indirection as we have to rely on memory to retrieve data from the data buffer.</p>
<p class="normal">Can we address type-safety concerns and make it possible to define the size of the ring buffer in C? We can use the token-pasting (<code class="inlineCode">##</code>) operator to create a set of functions for different types and sizes using macros. Let’s quickly go through a simple example of using the <code class="inlineCode">##</code> operator before jumping into ring buffer implementation using this technique:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;stdio.h&gt;
// Macro to define a function for summing two numbers
#define DEFINE_SUM_FUNCTION(TYPE) \
TYPE sum_##TYPE(TYPE a, TYPE b) { \
    return a + b; \
}
// Define sum functions for int and float
DEFINE_SUM_FUNCTION(int)
DEFINE_SUM_FUNCTION(float)
int main() {
    int result_int = sum_int(5, 3);
    printf("Sum of integers: %d\n", result_int);
    float result_float = sum_float(3.5f, 2.5f);
    printf("Sum of floats: %.2f\n", result_float);
    return 0;
}
</code></pre>
<p class="normal"><code class="inlineCode">DEFINE_SUM_FUNCTION(int)</code> will create a <code class="inlineCode">sum_int</code> function that accepts and returns integers. If we call the <code class="inlineCode">DEFINE_SUM_FUNCTION</code> macro with <code class="inlineCode">float</code>, it will result in creating <code class="inlineCode">sum_float</code>. Now that <a id="_idIndexMarker029"/>we have a good understanding of the token-pasting operator, let’s continue with ring buffer implementation:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
// Macro to declare ring buffer type and functions for a specific type and size
#define DECLARE_RING_BUFFER(TYPE, SIZE) \
typedef struct { \
    TYPE data[SIZE]; \
    size_t write_idx; \
    size_t read_idx; \
    size_t count; \
} ring_buffer_##TYPE##_##SIZE; \
void ring_buffer_init_##TYPE##_##SIZE(ring_buffer_##TYPE##_##SIZE *rb) { \
    rb-&gt;write_idx = 0; \
    rb-&gt;read_idx = 0; \
    rb-&gt;count = 0; \
} \
void ring_buffer_push_##TYPE##_##SIZE(ring_buffer_##TYPE##_##SIZE *rb, TYPE value) { \
    rb-&gt;data[rb-&gt;write_idx] = value; \
    rb-&gt;write_idx = (rb-&gt;write_idx + 1) % SIZE; \
    if (rb-&gt;count &lt; SIZE) { \
        rb-&gt;count++; \
    } else { \
        rb-&gt;read_idx = (rb-&gt;read_idx + 1) % SIZE; \
    } \
} \
int ring_buffer_pop_##TYPE##_##SIZE(ring_buffer_##TYPE##_##SIZE *rb, TYPE *value) { \
    if (rb-&gt;count == 0) { \
        return 0; /* Buffer is empty */ \
    } \
    *value = rb-&gt;data[rb-&gt;read_idx]; \
    rb-&gt;read_idx = (rb-&gt;read_idx + 1) % SIZE; \
    rb-&gt;count--; \
    return 1; /* Success */ \
}
// Example usage with int type and size 5
DECLARE_RING_BUFFER(int, 5) // Declare the ring buffer type and functions for integers
int main() {
    ring_buffer_int_5 rb;
    ring_buffer_init_int_5(&amp;rb); // Initialize the ring buffer
// Push values into the ring buffer
for (int i = 0; i &lt; 10; ++i) {
        ring_buffer_push_int_5(&amp;rb, i);
    }
    // Pop values from the ring buffer and print them
int value;
    while (ring_buffer_pop_int_5(&amp;rb, &amp;value)) {
        printf("%d\n", value);
    }
    return 0;
}
</code></pre>
<p class="normal">Now, this solution <a id="_idIndexMarker030"/>solves our problems of type safety and defining the size of a ring buffer, but it suffers from readability, both in implementation and when using it. We need to “call” <code class="inlineCode">DECLARE_RING_BUFFER</code> outside of any function, as it is basically a macro that defines a set of functions. We also need to know what it does and the signature of functions it will generate. We can do this better with templates. Let’s see what an implementation of a ring buffer looks like in C++.</p>
<h3 class="heading-3" id="_idParaDest-24">Ring buffer in C++</h3>
<p class="normal">Let’s make <a id="_idIndexMarker031"/>a generic implementation of a ring buffer using templates. We can use a <code class="inlineCode">std::array</code> class template as the underlying type and wrap our push-and-pop logic around it. The following is code that illustrates how the <code class="inlineCode">ring_buffer</code> type could look in C++:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;array&gt;
#include &lt;cstdio&gt;
template &lt;class T, std::size_t N&gt; struct ring_buffer {
  std::array&lt;T, N&gt; arr;
  std::size_t write_idx = 0; // Index of the next element to write (push)
  std::size_t read_idx = 0;  // Index of the next element to read (pop)
  std::size_t count = 0;     // Number of elements in the buffer
void push(T t) {
    arr.at(write_idx) = t;
    write_idx = (write_idx + 1) % N;
    if (count &lt; N) {
      count++;
    } else {
      // buffer is full, move forward read_idx
      read_idx = (read_idx + 1) % N;
    }
  }
  T pop() {
    if (count == 0) {
      // Buffer is empty, return a default-constructed T.
return T{};
    }
    T value = arr.at(read_idx);
    read_idx = (read_idx + 1) % N;
    --count;
    return value;
  }
  bool is_empty() const { return count == 0; }
};
int main() {
  ring_buffer&lt;int, 5&gt; rb;
  for (int i = 0; i &lt; 10; ++i) {
    rb.push(i);
  }
  while (!rb.is_empty()) {
    printf("%d\n", rb.pop());
  }
  return 0;
}
</code></pre>
<p class="normal">The ring buffer implementation in C++ using templates is more readable and easier to use than the token-pasting-based solution in C. The <code class="inlineCode">ring_buffer</code> template class can be used to instantiate ring <a id="_idIndexMarker032"/>buffer types with integer, float, or any other underlying types with different sizes. The same push-and-pop logic can be applied to ring buffers <a id="_idIndexMarker033"/>with different underlying types. We can apply the <strong class="keyWord">Don’t Repeat Yourself</strong> (<strong class="keyWord">DRY</strong>) principle to <a id="_idIndexMarker034"/>different types thanks to templates. <strong class="keyWord">Templates</strong> make generic types easy to implement, something that’s quite challenging and verbose in C.</p>
<p class="normal">Templates are <a id="_idIndexMarker035"/>also used for <strong class="keyWord">template metaprogramming</strong> (<strong class="keyWord">TMP</strong>), a programming technique in which a compiler uses templates to generate temporary source code, which is merged by the compiler with the rest of the source code and then compiled. One of the most famous examples of TMP is calculating a <strong class="keyWord">factorial at compile time</strong>. TMP is an advanced technique that will be covered in <a href="Chapter_08.xhtml"><em class="italic">Chapter 8</em></a>. Modern C++ also features the <code class="inlineCode">constexpr</code> specifier, a much more beginner-friendly technique for compile-time computation.</p>
<h2 class="heading-2" id="_idParaDest-25">constexpr</h2>
<p class="normal">C++11 introduced the <code class="inlineCode">constexpr</code> specifier, which <a id="_idIndexMarker036"/>declares that it is possible to evaluate the value of the function or a variable at compile time. The specifier evolved over time, extending the functionality. A <code class="inlineCode">constexpr</code> variable must be immediately initialized, and its type must be a <code class="inlineCode">literal</code> type (int, float, etc.). This is how we declare a <code class="inlineCode">constexpr</code> variable:</p>
<pre class="programlisting code"><code class="hljs-code">constexpr double pi = 3.14159265359;
</code></pre>
<p class="normal">Using the <code class="inlineCode">constexpr</code> specifier is the preferred way of declaring compile-time constants in C++ over using a C-style approach with macros. Let’s analyze a simple example using C-style macros:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;cstdio&gt;
#define VOLTAGE 3300
#define CURRENT 1000
int main () {
    const float resistance = VOLTAGE / CURRENT;
    printf("resistance = %.2f\r\n", resistance);
    return 0;
}
</code></pre>
<pre class="programlisting con"><code class="hljs-con">The output of this simple program might be surprising:
resistance = 3.00
</code></pre>
<p class="normal">Both <code class="inlineCode">VOLTAGE</code> and <code class="inlineCode">CURRENT</code> are parsed as integer <code class="inlineCode">literal</code>s, and so is the result of the division. Floating-point <code class="inlineCode">literal</code>s are declared using the <code class="inlineCode">f</code> suffix, which was omitted in this case. Using <code class="inlineCode">constexpr</code> to define <a id="_idIndexMarker037"/>compile-time constants is safer, as it allows us to specify the type of a constant. This is how we would write the same example using <code class="inlineCode">constexpr</code>:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;cstdio&gt;
constexpr float voltage = 3300;
constexpr float current = 1000;
int main () {
    const float resistance = voltage / current;
    printf("resistance = %.2f\r\n", resistance);
    return 0;
}
</code></pre>
<pre class="programlisting con"><code class="hljs-con">This would result in
resistance = 3.30
</code></pre>
<p class="normal">This simple example shows that <code class="inlineCode">constexpr</code> compile-time constants are both safer and easier to read than traditional C-style macro constants. The other major usage of the <code class="inlineCode">constexpr</code> specifier is to hint to the compiler that a function can be evaluated at compile time. Some of the requirements that a <code class="inlineCode">constexpr</code> function must meet are as follows:</p>
<ul>
<li class="bulletList">The return type must be a <code class="inlineCode">literal</code> type</li>
<li class="bulletList">Each of the function parameters must be a <code class="inlineCode">literal</code> type </li>
<li class="bulletList">If the <code class="inlineCode">constexpr</code> function is not a constructor, it needs to have precisely one <code class="inlineCode">return</code> statement</li>
</ul>
<p class="normal">Let us examine <a id="_idIndexMarker038"/>a simple example utilizing <code class="inlineCode">constexpr</code> functions:</p>
<pre class="programlisting code"><code class="hljs-code">int square(int a) {
    return a*a;
}
int main () {
    int ret = square(2);
    return ret;
}
</code></pre>
<p class="normal">To better understand what is going on under the hood, we will inspect the assembly output of the preceding code. Assembly is quite close to the machine code, or the instructions that will be executed on our target, thus inspecting it gives us an estimate of the work (number of instructions) performed by the processor. The assembly output of the compilation of the preceding program for the ARM architecture using an ARM GCC compiler and no optimization is shown in the following:</p>
<pre class="programlisting code"><code class="hljs-code">square(int):
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        ldr r3, [r7, #4]
        mul r3, r3, r3
mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
main:
push    {r7, lr}
        sub sp, sp, #8
add r7, sp, #0
movs r0, #2
bl      square(int)
        str r0, [r7, #4]
        ldr r3, [r7, #4]
        mov r0, r3
adds r7, r7, #8
mov sp, r7
pop     {r7, pc}
</code></pre>
<p class="normal">The resulting <a id="_idIndexMarker039"/>assembly code is doing the following:</p>
<ul>
<li class="bulletList">Manipulating the stack pointer</li>
<li class="bulletList">Calling the square function</li>
<li class="bulletList">Storing value returned by <code class="inlineCode">r0</code> to address contained into <code class="inlineCode">r7</code> with offset <code class="inlineCode">4</code></li>
<li class="bulletList">Loading the value from address stored in <code class="inlineCode">r7</code> with offset <code class="inlineCode">4</code> into <code class="inlineCode">r3</code></li>
<li class="bulletList">Moving the value from <code class="inlineCode">r3</code> to <code class="inlineCode">r0</code>, which is the ARM calling convention’s designated register for storing return values</li>
</ul>
<p class="normal">We can see that there are some unnecessary operations in the output binary, which both increase the binary size and affect the performance. This example is, both valid C and valid C++ code, and compiling it with both C and C++ compilers will yield the same assembly code.</p>
<p class="normal">If we use the <code class="inlineCode">constexpr</code> specifier for the <code class="inlineCode">square</code> function, we are instructing the compiler that it is possible to evaluate it at compile time:</p>
<pre class="programlisting code"><code class="hljs-code">constexpr int square(int a) {
    return a*a;
}
int main() {
    constexpr int val = square(2);
    return ret;
}
</code></pre>
<p class="normal">This code results in a compile-time evaluation of the <code class="inlineCode">square(2)</code> expression, making the <code class="inlineCode">val</code> integer a <code class="inlineCode">constexpr</code> variable, that is, a compile-time constant. The following is the resulting assembly code:</p>
<pre class="programlisting code"><code class="hljs-code">main:
push    {r7}
        sub sp, sp, #12
add r7, sp, #0
movs r3, #4
str r3, [r7, #4]
        movs r3, #4
mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
</code></pre>
<p class="normal">As we can see, the program returns the value <code class="inlineCode">4</code>, which is the result of the <code class="inlineCode">square(2)</code> compile-time computation. There is no <code class="inlineCode">square</code> function in the generated assembly, just the result of the calculation that the compiler performed for us. This simple example demonstrates the power of compile-time computing. We can move heavy computation from runtime to compile <a id="_idIndexMarker040"/>time whenever we know all the computation parameters, which is often. This approach can be used to generate lookup tables or complex mathematical signals, which will be demonstrated in the following chapters of this book.</p>
<p class="normal">C++ has come a long way since C with Classes. The examples in this chapter show what C++ can offer over C – expressive, more readable, compact code; standard template library containers; algorithms; user-defined generic types; and compile-time computation, just to start with. I hope I managed to debunk the myth that C++ is just C with classes. The next common myth about C++ is that it makes bloated code and adds runtime overhead. Let’s keep debunking the myths about C++!</p>
<h1 class="heading-1" id="_idParaDest-26">Bloat and runtime overhead</h1>
<p class="normal">The term <strong class="keyWord">bloatware</strong> describes <a id="_idIndexMarker041"/>unwanted software that is preinstalled with an OS on a device. Unwanted software in the world of programming describes code inserted in a binary by a framework, a library, or a language construct itself. Language constructs in C++ that are blamed for causing code bloat are constructors, destructors, and templates. We will analyze these misconceptions by examining assembly output generated from C++ code.</p>
<h2 class="heading-2" id="_idParaDest-27">Constructors and destructors</h2>
<p class="normal">The first thing that comes to mind to non-C++ developers when you mention C++ is that it is an object-oriented <a id="_idIndexMarker042"/>language and that you are bound to instantiate objects. Objects are instances of classes. They are variables that occupy memory. Special functions, called <strong class="keyWord">constructors</strong>, are used to construct or instantiate objects.</p>
<p class="normal">Constructors are used to initialize objects, including the initialization of class members, and destructors are used to clean up resources. They are tightly tied to an object’s life cycle. An object is created using a constructor, and when the object variable goes out of scope, the <strong class="keyWord">destructor</strong> is called.</p>
<p class="normal">Constructors <a id="_idIndexMarker043"/>and destructors both increase the size of the binary and add runtime overhead, as their execution takes time. We will examine the impact of constructors and destructors on a simple example of a class with one private member, a constructor, a destructor, and a getter:</p>
<pre class="programlisting code"><code class="hljs-code">class MyClass
{
    private:
         int num;
    public:
        MyClass(int t_num):num(t_num){}
        ~MyClass(){}
        int getNum() const {
            return num;
        }
};
int main () {
   MyClass obj(1);
   return obj.getNum();
}
</code></pre>
<p class="normal"><code class="inlineCode">MyClass</code> is a very simple class <a id="_idIndexMarker044"/>that has one private member, which we set through the constructor. We can access it through a getter, and just for good measure, we declared <a id="_idIndexMarker045"/>a destructor, which is empty. The following is the assembly equivalent of the preceding code compiled with no optimization enabled:</p>
<pre class="programlisting code"><code class="hljs-code">MyClass::MyClass(int) [base object constructor]:
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        str r1, [r7]
        ldr r3, [r7, #4]
        ldr r2, [r7]
        str r2, [r3]
        ldr r3, [r7, #4]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
MyClass::~MyClass() [base object destructor]:
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        ldr r3, [r7, #4]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
MyClass::getNum() const:
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        ldr r3, [r7, #4]
        ldr r3, [r3]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
main:
push    {r4, r7, lr}
        sub sp, sp, #12
add r7, sp, #0
adds r3, r7, #4
movs r1, #1
mov r0, r3
bl      MyClass::MyClass(int) [complete object constructor]
        adds r3, r7, #4
mov r0, r3
bl      MyClass::getNum() const
        mov r4, r0
nop
adds r3, r7, #4
mov r0, r3
bl      MyClass::~MyClass() [complete object destructor]
        mov r3, r4
mov r0, r3
adds r7, r7, #12
mov sp, r7
pop     {r4, r7, pc}
</code></pre>
<p class="normal">Don’t worry about the assembly if you don’t understand it. We can see there are some labels for functions and a whole lot of instructions. That’s a lot of instructions for a simple abstraction of a class; this is the bloat code that we don’t want in our binary. To be more precise, we have 59 lines of assembly code. If we were to enable optimization, the resulting assembly would be <a id="_idIndexMarker046"/>a couple of lines long, but let’s keep analyzing this problem with <a id="_idIndexMarker047"/>no optimization involved. The first thing we are noticing is that the destructor doesn’t do anything useful. If we remove it from the C++ code, the resulting assembly is 44 lines long:</p>
<pre class="programlisting code"><code class="hljs-code">MyClass::MyClass(int) [base object constructor]:
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        str r1, [r7]
        ldr r3, [r7, #4]
        ldr r2, [r7]
        str r2, [r3]
        ldr r3, [r7, #4]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
MyClass::getNum() const:
        push    {r7}
        sub sp, sp, #12
add r7, sp, #0
str r0, [r7, #4]
        ldr r3, [r7, #4]
        ldr r3, [r3]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
main:
push    {r7, lr}
        sub sp, sp, #8
add r7, sp, #0
adds r3, r7, #4
movs r1, #1
mov r0, r3
bl      MyClass::MyClass(int) [complete object constructor]
        adds r3, r7, #4
mov r0, r3
bl      MyClass::getNum() const
        mov r3, r0
nop
mov r0, r3
adds r7, r7, #8
mov sp, r7
pop     {r7, pc}
</code></pre>
<p class="normal">As we can see, there is no call to the destructor, and there is no destructor code in the binary. The lesson is <em class="italic">you don’t pay for what you don’t use</em>. This is one of the design principles of C++. By deleting <a id="_idIndexMarker048"/>the destructor, there is no need for the compiler to generate any code for it and to call it when the object variable goes out of the scope.</p>
<p class="normal">The next thing <a id="_idIndexMarker049"/>we must realize is that C++ is not an OOP language. It is a multiparadigm language. It is procedural, object-oriented, generic, and even a little bit functional at the same time. If we want to have private members that can be set only through constructors, then we need to pay the price for that. Structs in C++ have public members by default, so let’s change the <code class="inlineCode">MyClass</code> class to a <code class="inlineCode">MyClass</code> struct with no constructor:</p>
<pre class="programlisting code"><code class="hljs-code">struct MyClass
{
    int num;
};
int main () {
   MyClass obj(1);
  
   return obj.num;
}
</code></pre>
<p class="normal">Setter and getter functions are common in the OOP paradigm, but C++ is not (just) an OOP language and we are not bound to using setters and getters. When we remove the <code class="inlineCode">getNum</code> getter, we have a very basic example of a struct with just one member. The resulting assembly is only 14 lines long:</p>
<pre class="programlisting code"><code class="hljs-code">main:
push    {r7}
        sub sp, sp, #12
add r7, sp, #0
movs r3, #1
str r3, [r7, #4]
        ldr r3, [r7, #4]
        mov r0, r3
adds r7, r7, #12
mov sp, r7
ldr r7, [sp], #4
bx lr
</code></pre>
<p class="normal">As trivial as this example is, its purpose is to establish two ground truths:</p>
<ul>
<li class="bulletList">You don’t pay for what you don’t use</li>
<li class="bulletList">Using C++ doesn’t mean you are bound to an OOP paradigm</li>
</ul>
<p class="normal">We need to pay the price in binary size if we want to use abstractions such as constructors and destructors. Using types (classes and structs) without instantiating objects in C++ offers significant benefits <a id="_idIndexMarker050"/>to your embedded software design beyond traditional <a id="_idIndexMarker051"/>object-oriented approaches. We’ll explore this through detailed examples in the upcoming chapters.</p>
<p class="normal">In this and previous examples, we compiled C++ code with disabled optimizations, and we were able to see the resulting assembly code results in unnecessary operations that can be removed. Let’s check the assembly code for the last example with the <code class="inlineCode">O3</code> optimization level enabled:</p>
<pre class="programlisting code"><code class="hljs-code">main:
movs r0, #1
bx lr
</code></pre>
<p class="normal">The preceding assembly is the output of the original example with the class, constructor, destructor, and getter function. The resulting program has just two instructions. The value of the <code class="inlineCode">num</code> member of the <code class="inlineCode">obj</code> variable is stored in the <code class="inlineCode">r0</code> register as the return value. Assembly code is stripped of all necessary instructions related to stack manipulation and usage of <code class="inlineCode">r3</code> to store a value in a stack pointer with an offset of <code class="inlineCode">4</code>, reload it to <code class="inlineCode">r3</code>, and move it to <code class="inlineCode">r0</code>. The resulting assembly is just a few lines of code.</p>
<p class="normal">Removing unnecessary instructions is a job for the optimization process. Yet, optimization is often avoided in embedded projects, as some claim that it breaks code. But is that true?</p>
<h2 class="heading-2" id="_idParaDest-28">Optimization</h2>
<p class="normal">Unoptimized code results in unnecessary instructions affecting binary size and performance. However, many embedded <a id="_idIndexMarker052"/>projects are still built with disabled optimization, as developers <em class="italic">do not trust the compiler</em> and are afraid it will <em class="italic">break the program</em>. There is some truth to this, but as it turns out, this happens when the program is not well formed. The program is not well formed if it contains undefined behavior.</p>
<p class="normal">One of the best-known <a id="_idIndexMarker053"/>examples of undefined behavior is signed <strong class="keyWord">integer overflow</strong>. The standard doesn’t define what happens if you add <code class="inlineCode">1</code> to the maximum value of the signed integer on your platform. The compiled program is not required to do anything meaningful. A program is not well formed. Let’s examine the following code:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;cstdio&gt;
#include &lt;limits&gt;
int foo(int x) {
    int y = x + 1;
    return y &gt; x;
}
int main() {
    if(foo(std::numeric_limits&lt;int&gt;::max())) {
        printf("X is larger than X + 1\r\n");
    }
    else {
        printf("X is NOT larger than X + 1. Oh nooo !\r\n");
    }
    return 0;
}
</code></pre>
<p class="normal">Compiling the code using GCC for both x86 and Arm Cortex-M4 will yield the same results. If the program is compiled without the optimization, the <code class="inlineCode">foo</code> function returns <code class="inlineCode">0</code>, and you can see <strong class="screenText">X is NOT larger than X + 1. Oh nooo !</strong> in the output. The compiler does the integer overflow, and if we pass the maximum integer value to <code class="inlineCode">foo</code>, it will return <code class="inlineCode">0</code>. Keep in mind that the standard does not specify this, and this behavior depends on the compiler. </p>
<p class="normal">If we compile the program with optimization enabled, the output is <strong class="screenText">X is larger than X + 1</strong><code class="inlineCode">,</code> which means that <code class="inlineCode">foo</code> returns <code class="inlineCode">1</code>. Let’s examine the assembly output of the program compiled with the optimization:</p>
<pre class="programlisting code"><code class="hljs-code">foo(int):
        movs r0, #1
bx lr
.LC0:
.ascii "X is larger then X + 1\015\000"
main:
push    {r3, lr}
        movw    r0, #:lower16:.LC0
        movt r0, #:upper16:.LC0
        bl      puts
        movs r0, #0
pop     {r3, pc}
</code></pre>
<p class="normal">As we can see, <code class="inlineCode">foo</code> doesn’t perform any calculations. The compiler assumes that the program is well formed and that there is no undefined behavior. <code class="inlineCode">foo</code> will always return <code class="inlineCode">1</code>. It is up to the developer to ensure that there is no undefined behavior in the program. This is exactly the reason why the myth that the optimization breaks the program is still alive. It is easier to blame the compiler for not handling the undefined behavior.</p>
<p class="normal">Of course, it is possible that there is a bug in a compiler that breaks the functionality of the program if the optimization is used, and the program works fine if it is disabled. This is very rare but not unheard of, and that’s why there are verification techniques such as unit and integration testing that ensure the functionality of the code, whether it is built with or without the optimization enabled.</p>
<p class="normal">Optimization is <a id="_idIndexMarker054"/>reducing the binary size and improving performance by removing unnecessary instructions from the machine code. Undefined behavior is compiler-dependent and must be handled by the developer to ensure the program is well formed. Techniques such as unit and integration testing should be put in place to validate the functionality of the program, mitigating the risk of compiler malforming the program. The optimization process is essential for using abstractions in C++ code while keeping the binary footprint minimum and performance at a maximum. We will use the highest optimization level, <code class="inlineCode">O3</code>, in the rest of the book.</p>
<p class="normal">The next suspect for code bloat that we will examine are templates. How do they cause the code bloat, and what value do they bring to our embedded code bases?</p>
<h2 class="heading-2" id="_idParaDest-29">Templates</h2>
<p class="normal">Instantiating <strong class="keyWord">templates</strong> with different <a id="_idIndexMarker055"/>parameters will result in the compiler generating distinct types, which effectively increases the binary size. This is to be expected. We have the exact same situation with the generic implementation of a ring buffer in C using the token-pasting operator and macros. An alternative is type erasure, which we used in C implementation using a void pointer. It suffers in flexibility if we impose the restriction of static data allocation and performance due to pointer indirection.</p>
<p class="normal">Using generic types is a choice of design. We can use them and pay the price in increased binary size, but that would also happen if we were to implement ring buffers for different data types separately (<code class="inlineCode">ring_buffer_int</code>, <code class="inlineCode">ring_buffer_float</code>, etc.). Maintaining a single templated type is much easier than fixing the same bug in a few different places in the code base. The usage of generic types doesn’t result in a binary size any larger than the size of an equivalent implementation <a id="_idIndexMarker056"/>of individual types. Let’s examine the impact of templates on binary size in relation to separate implementations using the <code class="inlineCode">ring_buffer</code> example:</p>
<pre class="programlisting code"><code class="hljs-code">int main() {
#ifdef USE_TEMPLATES
  ring_buffer&lt;int, 10&gt; buffer1;
  ring_buffer&lt;float, 10&gt; buffer2;
#else
  ring_buffer_int buffer1;
  ring_buffer_float buffer2;
#endif
for (int i = 0; i &lt; 20; i++) {
    buffer1.push(i);
    buffer2.push(i + 0.2f);
  }
  for (int i = 0; i &lt; 10; i++) {
    printf("%d, %.2f\r\n", buffer1.pop(), buffer2.pop());
  }
  return 0;
}
</code></pre>
<p class="normal">The program will use a generic <code class="inlineCode">ring_buffer type</code> if built with <code class="inlineCode">USE_TEMPLATES</code> defined, and it will use the <code class="inlineCode">ring_buffer_int</code> and <code class="inlineCode">ring_buffer_float</code> types otherwise. If we build this example with GCC with no optimization enabled, it will result in a slightly bigger binary size in the template version (24 bytes). This is due to larger symbols in the symbol table when using the templated version. If we strip the symbol table from the object files, they will result in the same size. Also, building two versions with <code class="inlineCode">O3</code> results in the same binary size.</p>
<p class="normal">Generic types do not increase the binary size more than if we wrote instantiated types by hand as separate types. Templates have an effect on the build time due to the instantiation of concrete types in different compilation units, and there are techniques to avoid this if needed. All functions related to the instantiated types <a id="_idIndexMarker057"/>with the same parameters will result in a single function in the binary, as the linker will remove duplicate symbols.</p>
<h2 class="heading-2" id="_idParaDest-30">RTTI and exceptions</h2>
<p class="normal"><strong class="keyWord">Runtime type information</strong> (<strong class="keyWord">RTTI</strong>) in C++ is a mechanism that allows the type of an object to be determined <a id="_idIndexMarker058"/>at runtime. Most compilers implement RTTI using the virtual tables. Each polymorphic class (a class with at least one virtual function) has a virtual table that, among other things, includes type information for runtime type identification. RTTI imposes both time and space costs. It increases binary size and affects the runtime performance if type identification is used. This is the reason why compilers have a way of disabling RTTI. Let’s examine a simple example with a base and derived class:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;cstdio&gt;
struct Base {
    virtual void print () {
        printf("Base\r\n");
    }
};
struct Derived : public Base {
    void print () override {
        printf("Derived\r\n");
    }
};
void printer (Base &amp;base) {
    base.print();
}
int main() {
    Base base;
    Derived derived;
    printer(base);
    printer(derived);
  return 0;
}
</code></pre>
<p class="normal">The output of the program is as follows:</p>
<pre class="programlisting con"><code class="hljs-con">Base
Derived
</code></pre>
<p class="normal">Classes with virtual functions have vtables that are used for dynamic dispatching. Dynamic dispatch is a process of selecting which implementation of a polymorphic function is used. The <code class="inlineCode">printer</code> function accepts a reference to the <code class="inlineCode">Base</code> class. Depending on the type of reference passed to <code class="inlineCode">printer</code> (<code class="inlineCode">Base</code> or <code class="inlineCode">Derived</code>), the dynamic dispatching process will select the <code class="inlineCode">print</code> method from either the <code class="inlineCode">Base</code> or <code class="inlineCode">Derived</code> class. Vtables are also used to store type information.</p>
<p class="normal">By using <code class="inlineCode">dynamic_cast</code>, as a part of the RTTI mechanism, we can find the information about the type using <a id="_idIndexMarker059"/>a reference or pointer to the superclass. Let’s modify the <code class="inlineCode">printer</code> method from the previous example:</p>
<pre class="programlisting code"><code class="hljs-code">void printer (Base &amp;base) {
    base.print();
    if(Derived *derived = dynamic_cast&lt;Derived*&gt;(&amp;base); derived!=nullptr) {
        printf("We found Base using RTTI!\r\n");
    }
}
</code></pre>
<p class="normal">The output is as follows:</p>
<pre class="programlisting con"><code class="hljs-con">Base
Derived
We found Base using RTTI!
</code></pre>
<p class="normal">As we already mentioned, RTTI can be disabled. In GCC, we can do this by passing the <code class="inlineCode">-fno-rtti</code> flag to the compiler. If we try to compile the modified example using this flag, the compiler will raise <code class="inlineCode">error: dynamic_cast' not permitted with '-fno-rtti'</code>. If we restore the <code class="inlineCode">printer</code> method to the original implementation, remove the <code class="inlineCode">if</code> statement, and build it with both RTTI enabled and then disabled, we can notice that the binary size is larger when RTTI is enabled. RTTI is useful in certain scenarios, but it adds a massive overhead to resource-constrained devices, so we will leave it disabled.</p>
<p class="normal">Another C++ feature that is often disabled in embedded projects in C++ is exceptions. <strong class="keyWord">Exceptions</strong> are an <a id="_idIndexMarker060"/>error-handling mechanism based on a try-catch block. Let’s take a look at a simple example utilizing exceptions to understand them better:</p>
<pre class="programlisting code"><code class="hljs-code">#include &lt;cstdio&gt;
struct A {
  A() { printf("A is created!\r\n"); }
  ~A() { printf("A is destroyed!\r\n"); }
};
struct B {
  B() { printf("B is created!\r\n"); }
  ~B() { printf("B is destroyed!\r\n"); }
};
void bar() {
    B b;
    throw 0;
}
void foo() {
  A a;
  bar();
  A a1;
}
int main() {
  try {
    foo();
  } catch (int &amp;p) {
    printf("Catching an exception!\r\n");
  }
  return 0;
}
</code></pre>
<p class="normal">The output of the program is as follows:</p>
<pre class="programlisting con"><code class="hljs-con">A is created!
B is created!
B is destroyed!
A is destroyed!
Catching an exception!
</code></pre>
<p class="normal">In this simple example, <code class="inlineCode">foo</code> is called in the <code class="inlineCode">try</code> block. It creates a local object, <code class="inlineCode">a</code>, and calls <code class="inlineCode">bar</code>. The <code class="inlineCode">bar</code> function creates a local object, <code class="inlineCode">b</code>, and throws an exception. In the output, we see that <code class="inlineCode">A</code> and <code class="inlineCode">B</code> are created, then <code class="inlineCode">B</code> gets destroyed, then <code class="inlineCode">A</code> gets destroyed, and we finally see that the <code class="inlineCode">catch</code> block gets <a id="_idIndexMarker061"/>executed. This is called <strong class="keyWord">stack unwinding</strong>, and for it to happen, standard implementations most commonly utilize unwind tables, which store information about catch handlers, destructors to be called, and so on. Unwind tables can grow large and become complex, which increases the memory footprint of the application and introduces non-determinism due to the mechanism used at runtime for exception handling. This is why exceptions are often disabled in embedded system projects.</p>
<h1 class="heading-1" id="_idParaDest-31">Summary</h1>
<p class="normal">C++ is guided by the <strong class="keyWord">zero-overhead principle</strong>. The only two language features that do not follow it are RTTI and exceptions, and that’s why compilers support a switch for turning them off.</p>
<p class="normal">The zero-overhead principle is based on two statements that we established in this chapter:</p>
<ul>
<li class="bulletList">You don’t pay for what you don’t use</li>
<li class="bulletList">What you do use is just as efficient as what you could reasonably write by hand</li>
</ul>
<p class="normal">RTTI and exceptions are disabled in most embedded projects, so you don’t pay for them. Using generic types and templates is a design choice and is no more expensive than writing individual types by hand (<code class="inlineCode">ring_buffer_int</code>, <code class="inlineCode">ring_buffer_float</code>, and so on), but it lets you reuse the code logic for different types, makes the code more readable and easier for maintenance.</p>
<p class="normal">Working on high-risk systems is not a reason to disable compiler optimization capabilities. Code functionality needs to be verified whether we are building a program with optimization disabled or enabled. The most common source of bugs when optimization is enabled is undefined behavior. Understanding the undefined behavior and preventing it is up to the developer.</p>
<p class="normal">Modern C++ is a language that has a lot to offer to the embedded world. The mission of this book is to help you discover C++ and what it can do for your embedded projects, so let’s embark on the path of discovering C++ and utilizing it to solve problems in the embedded domain.</p>
<p class="normal">In the next chapter, we will go over challenges in embedded systems with limited resources and dynamic memory management in C++.</p>
<h1 class="heading-1" id="_idParaDest-32">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/embeddedsystems">https://packt.link/embeddedsystems</a></p>
<p class="normal"><img alt="" role="presentation" src="img/QR_code_Discord.png"/></p>
</div>
</body></html>