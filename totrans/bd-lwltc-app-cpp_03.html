<html><head></head><body>
<div id="_idContainer021">
<h1 class="chapter-number" id="_idParaDest-54"><a id="_idTextAnchor056"/><span class="koboSpan" id="kobo.1.1">3</span></h1>
<h1 id="_idParaDest-55"><a id="_idTextAnchor057"/><span class="koboSpan" id="kobo.2.1">Exploring C++ Concepts from A Low-Latency Application’s Perspective</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we assume that the reader has an intermediate level of understanding of C++ programming concepts, features, and so on. </span><span class="koboSpan" id="kobo.3.2">We will discuss how to approach low-latency application development in C++. </span><span class="koboSpan" id="kobo.3.3">We will move on to discussing what C++ features to avoid specifically when it comes to low-latency applications. </span><span class="koboSpan" id="kobo.3.4">We will then discuss the key C++ features that make it perfect for low-latency applications and how we will use them in the rest of the book. </span><span class="koboSpan" id="kobo.3.5">We will conclude by discussing how to maximize compiler optimizations and which C++ compiler flags are important for </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">low-latency applications.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">Approaching low-latency application development </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">in C++</span></span></li>
<li><span class="koboSpan" id="kobo.9.1">Avoiding pitfalls and leveraging C++ features to minimize </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">application latency</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Maximizing C++ compiler </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">optimization parameters</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.13.1">Let us start by discussing the higher-level ideas when it comes to approaching low-latency application development in C++ in the </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">next section.</span></span></p>
<h1 id="_idParaDest-56"><a id="_idTextAnchor058"/><span class="koboSpan" id="kobo.15.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.16.1">All the code for this book can be found in the GitHub repository for this book at </span><a href="https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP"><span class="koboSpan" id="kobo.17.1">https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP</span></a><span class="koboSpan" id="kobo.18.1">. </span><span class="koboSpan" id="kobo.18.2">The source code for this chapter is in the Chapter3 directory in </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">the repository.</span></span></p>
<h1 id="_idParaDest-57"><a id="_idTextAnchor059"/><span class="koboSpan" id="kobo.20.1">Approaching low-latency application development in C++</span></h1>
<p><span class="koboSpan" id="kobo.21.1">In this section, we </span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.22.1">will discuss the higher-level ideas to keep in mind when trying to build low-latency applications in C++. </span><span class="koboSpan" id="kobo.22.2">Overall, the ideas are to understand the architecture that your application runs on, your application use cases that are latency-sensitive, the programming language of your choice (C++ in this case), how to work with the development tools (the compiler, linker, etc.) and how to measure application performance in practice to understand which parts of the application to </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">optimize first.</span></span></p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor060"/><span class="koboSpan" id="kobo.24.1">Coding for correctness first, optimizing second</span></h2>
<p><span class="koboSpan" id="kobo.25.1">For low-latency applications, correct behavior of the application under different use cases and scenarios and robust handling of edge conditions is still the primary focus. </span><span class="koboSpan" id="kobo.25.2">A fast application that does not do what we need is useless, so the best approach when it comes to developing a low-latency application is to first code for correctness, not speed. </span><span class="koboSpan" id="kobo.25.3">Once the application works correctly, only then the focus should be shifted to optimizing the critical parts of the application while maintaining correctness. </span><span class="koboSpan" id="kobo.25.4">This ensures that developers spend time focusing on the correct parts to optimize because it is common to find that our intuition on which pieces are critical to performance does not match what happens in practice. </span><span class="koboSpan" id="kobo.25.5">Optimizing the code can also take significantly longer than coding for correctness, so it is important to optimize the most important </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">things first.</span></span></p>
<h2 id="_idParaDest-59"><a id="_idTextAnchor061"/><span class="koboSpan" id="kobo.27.1">Designing optimal data structures and algorithms</span></h2>
<p><span class="koboSpan" id="kobo.28.1">Designing custom data structures that are optimal for the application’s use cases is an important part of building low-latency applications. </span><span class="koboSpan" id="kobo.28.2">A good amount of thought needs to be put into each data structure used in the critical parts of the application in terms of scalability, robustness, and performance under the use cases and data encountered </span><em class="italic"><span class="koboSpan" id="kobo.29.1">in practice</span></em><span class="koboSpan" id="kobo.30.1">. </span><span class="koboSpan" id="kobo.30.2">It is important to understand why we mention the term </span><em class="italic"><span class="koboSpan" id="kobo.31.1">in practice</span></em><span class="koboSpan" id="kobo.32.1"> here because different data structure choices will perform better under different use cases and input data even if the different data structures themselves have the same output or behavior. </span><span class="koboSpan" id="kobo.32.2">Before </span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.33.1">we discuss an example of different possible data structures and algorithms to solve the same problem, let us quickly review Big-O notation. </span><span class="koboSpan" id="kobo.33.2">Big-O notation is used to describe the asymptotic worst-case time complexity of performing a certain task. </span><span class="koboSpan" id="kobo.33.3">The term asymptotic here is used to describe the fact that we discuss cases where we measure the performance over a theoretically infinite (in practice an exceptionally large) number of data points. </span><span class="koboSpan" id="kobo.33.4">The asymptotic performance eliminates all the constant terms and describes the performance only as a function of the number of input </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">data elements.</span></span></p>
<p><span class="koboSpan" id="kobo.35.1">A simple example of using different data structures to solve the same problem would be searching for an entry in a container by a key value. </span><span class="koboSpan" id="kobo.35.2">We can solve this either by using a hash map implementation that has an expected </span><em class="italic"><span class="koboSpan" id="kobo.36.1">amortized</span></em><span class="koboSpan" id="kobo.37.1"> complexity of </span><strong class="source-inline"><span class="koboSpan" id="kobo.38.1">O(1)</span></strong><span class="koboSpan" id="kobo.39.1"> or using an array that has a complexity of </span><strong class="source-inline"><span class="koboSpan" id="kobo.40.1">O(n)</span></strong><span class="koboSpan" id="kobo.41.1">, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.42.1">n</span></strong><span class="koboSpan" id="kobo.43.1"> is the number of elements in the container. </span><span class="koboSpan" id="kobo.43.2">While on paper it might appear that the hash map is clearly the way to go, other factors such as the number of elements, the complexity of applying the hash function to the keys, and so on might change which data structure is the way to go. </span><span class="koboSpan" id="kobo.43.3">In this case, for a handful of elements, the array solution is faster due to better cache performance, while for many elements, the hash map solution is better. </span><span class="koboSpan" id="kobo.43.4">Here, we chose a suboptimal algorithm because the underlying data structure for the suboptimal algorithm performed better in practice due to </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">cache performance.</span></span></p>
<p><span class="koboSpan" id="kobo.45.1">Another slightly different example would be using lookup tables over recomputing values for some mathematical functions, say, trigonometric functions. </span><span class="koboSpan" id="kobo.45.2">While it makes complete sense that looking up the result in a precomputed lookup table </span><em class="italic"><span class="koboSpan" id="kobo.46.1">should</span></em><span class="koboSpan" id="kobo.47.1"> always be faster compared to performing some calculations, this might not always be true. </span><span class="koboSpan" id="kobo.47.2">For instance, if the lookup table is very large, then the cost of evaluating a floating-point expression might be less than the cost of getting a cache miss and reading the lookup table value from the main memory. </span><span class="koboSpan" id="kobo.47.3">The overall application performance might also be better if accessing the lookup table from the main memory leads to a lot of cache pollution, leading to performance degradation in other parts of the </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">application code.</span></span></p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor062"/><span class="koboSpan" id="kobo.49.1">Being mindful of the processor</span></h2>
<p><span class="koboSpan" id="kobo.50.1">Modern processors have a lot of architectural and functional details that a low-latency application developer should understand, especially a C++ developer since it allows very low-level control. </span><span class="koboSpan" id="kobo.50.2">Modern processors have multiple cores, larger and specialized register banks, pipelined instruction processing where instructions needed next are prefetched while executing the current one, instruction level parallelism, branch predictions, extended instruction sets to facilitate faster and specialized processing, and so on. </span><span class="koboSpan" id="kobo.50.3">The better the application developer understands these aspects of the processor on which their applications </span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.51.1">will run, the better they can avoid sub-optimal code and/or compilation choices and make sure that the compiled machine code is optimal for their target architecture. </span><span class="koboSpan" id="kobo.51.2">At the very least, the developer should instruct the compiler to output code for their specific target architecture using compiler optimization flags, but we will discuss that topic later in </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">this chapter.</span></span></p>
<h2 id="_idParaDest-61"><a id="_idTextAnchor063"/><span class="koboSpan" id="kobo.53.1">Understanding the cache and memory access costs</span></h2>
<p><span class="koboSpan" id="kobo.54.1">Typically, a lot of effort is put into the design and development of data structures and algorithms when it comes to low-latency application development from the perspective of reducing the amount of work done or the number of instructions executed. </span><span class="koboSpan" id="kobo.54.2">While this is the correct approach, in this section, we would like to point out that thinking about cache and memory accesses is </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">equally important.</span></span></p>
<p><span class="koboSpan" id="kobo.56.1">We saw in the previous sub-section, </span><em class="italic"><span class="koboSpan" id="kobo.57.1">Designing optimal data structures and algorithms</span></em><span class="koboSpan" id="kobo.58.1">, that it is common for data structures and algorithms that are sub-optimal on paper to outperform ones that are optimal on paper. </span><span class="koboSpan" id="kobo.58.2">A large reason behind that can be the higher cache and memory access costs for the optimal solution outweighing the time saved because of the reduced number of instructions the processor needs to execute. </span><span class="koboSpan" id="kobo.58.3">Another way to think about this is that even though the amount of work from the perspective of the number of algorithmic steps is less, in practice, it takes longer to finish with the modern processor, cache, and memory access </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">architectures today.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">Let us quickly review the memory hierarchy in a modern computer architecture. </span><span class="koboSpan" id="kobo.60.2">Note that details of what we will recap here can be found in our other book, </span><em class="italic"><span class="koboSpan" id="kobo.61.1">Developing High-Frequency Trading Systems</span></em><span class="koboSpan" id="kobo.62.1">. </span><span class="koboSpan" id="kobo.62.2">The key points here are that the memory hierarchy works in such a way that if the CPU cannot find the data or instruction it needs next in the register, it goes to the L0 cache, and if it cannot find it there, goes to the L1 cache, L2, other caches, and so on, then goes to the main memory in that order. </span><span class="koboSpan" id="kobo.62.3">Note that the storage is accessed from fastest to slowest, which also happens to be least amount of space to most amount of space. </span><span class="koboSpan" id="kobo.62.4">The art of effective low-latency and cache-friendly application development relies on writing code that is cognizant of code and data access patterns to maximize the likelihood of finding data in the fastest form of storage possible. </span><span class="koboSpan" id="kobo.62.5">This relies on maximizing the concepts of </span><strong class="bold"><span class="koboSpan" id="kobo.63.1">temporal locality</span></strong><span class="koboSpan" id="kobo.64.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.65.1">spatial locality</span></strong><span class="koboSpan" id="kobo.66.1">. </span><span class="koboSpan" id="kobo.66.2">These terms </span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.67.1">mean that data accessed recently is likely to be in the cache and data next to what </span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.68.1">we just accessed is likely to be in the cache, respectively. </span><span class="koboSpan" id="kobo.68.2">The following diagram visually lays out the register, cache, and memory banks and </span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.69.1">provides some data on access times from the CPU. </span><span class="koboSpan" id="kobo.69.2">Note that there is a good amount of variability in the access times depending on the hardware and the constant improvements being made to technologies. </span><span class="koboSpan" id="kobo.69.3">The key takeaway here should be that there is a significant increase in access times as we go from CPU registers to cache banks to the </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">main memory.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer020">
<span class="koboSpan" id="kobo.71.1"><img alt="Figure 3.1 – The hierarchy of memory in modern computer architectures. " src="image/Figure_3.1_B19434.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.72.1">Figure 3.1 – The hierarchy of memory in modern computer architectures.</span></p>
<p><span class="koboSpan" id="kobo.73.1">I would advise you to think carefully about the cache and memory access patterns for the algorithm locally, as well as the entire application globally, to make sure that your source code optimizes cache and memory access patterns, which will boost overall application performance. </span><span class="koboSpan" id="kobo.73.2">If you have a function that executes very quickly when it is called but causes </span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.74.1">a lot of cache pollution, that will degrade the complete application’s performance because other components will incur additional cache miss penalties. </span><span class="koboSpan" id="kobo.74.2">In such a case, we have failed in our objective of having an application that performs optimally even though we might have managed to make this function perform </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">optimally locally.</span></span></p>
<h2 id="_idParaDest-62"><a id="_idTextAnchor064"/><span class="koboSpan" id="kobo.76.1">Understanding how C++ features work under the hood</span></h2>
<p><span class="koboSpan" id="kobo.77.1">When developing low-latency applications, it is very important that the developers have an extremely good understanding of how the high-level language abstractions work at a lower level or “under the hood.” </span><span class="koboSpan" id="kobo.77.2">For applications that are not latency-sensitive, this is perhaps not as important since if the application behaves the way the developer intends it to, the extremely low-level details of how their source code achieves that is </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">not relevant.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">For low-latency applications in C++, the more knowledge the developer has of how their program gets compiled into machine code, the better they can use the programming language to achieve low-latency performance. </span><span class="koboSpan" id="kobo.79.2">A lot of high-level abstractions available in C++ improve the ease and speed of development, robustness and safety, maintainability, software design elegance, and so on, but not all of them might be optimal when it comes to </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">low-latency applications.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">Many C++ features, such as dynamic polymorphism, dynamic memory allocation, and exception handling, are great additions to the language for most applications. </span><span class="koboSpan" id="kobo.81.2">However, these are best avoided </span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.82.1">or used sparingly or used in a specific manner when it comes to low-latency applications since they have </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">larger overheads.</span></span></p>
<p><span class="koboSpan" id="kobo.84.1">Conversely, traditional programming practices suggest the developer break everything down into numerous very small functions for reusability; use recursive functions when applicable; use </span><strong class="bold"><span class="koboSpan" id="kobo.85.1">Object-Oriented Programming</span></strong><span class="koboSpan" id="kobo.86.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.87.1">OOP</span></strong><span class="koboSpan" id="kobo.88.1">) principles, such as inheritance and virtual </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.89.1">functions; always use smart pointers instead of raw pointers; and so on. </span><span class="koboSpan" id="kobo.89.2">These principles are sensible for most applications, but for low-latency applications, these need to be evaluated and used carefully because they might add non-trivial amounts of overhead </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">and latency.</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">The key takeaway here is that it is important for low-latency application developers to understand each one of these C++ features very well to understand how they are implemented in machine code and what impact they have on the hardware resources and how they perform </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">in practice.</span></span></p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.93.1">Leveraging the C++ compiler</span></h2>
<p><span class="koboSpan" id="kobo.94.1">The modern C++ compiler is truly a fascinating piece of software. </span><span class="koboSpan" id="kobo.94.2">There is an immense amount of effort </span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.95.1">invested into building these compilers to be robust and correct. </span><span class="koboSpan" id="kobo.95.2">A lot of effort is also made to make them very intelligent in terms of the transformations and optimizations they apply to the developer’s high-level source code. </span><span class="koboSpan" id="kobo.95.3">Understanding how the compiler translates the developer’s code into machine instructions, how it tries to optimize the code, and when it fails is important for low-latency application developers looking to squeeze as much performance out of their applications as possible. </span><span class="koboSpan" id="kobo.95.4">We will discuss the workings of the compiler and optimization opportunities extensively in this chapter so that we can learn to work with the compiler instead of against it when it comes to optimizing our final application’s representation (machine </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">code executable).</span></span></p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.97.1">Measuring and improving performance</span></h2>
<p><span class="koboSpan" id="kobo.98.1">We mentioned that the ideal application development journey involves first building the application for correctness and then worrying about optimizing it after that. </span><span class="koboSpan" id="kobo.98.2">We also mentioned that it is not uncommon for a developer’s intuition to be incorrect when it comes to identifying </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">performance bottlenecks.</span></span></p>
<p><span class="koboSpan" id="kobo.100.1">Finally, we also mentioned that the task of optimizing an application can take significantly longer than the task of developing it to perform correctly. </span><span class="koboSpan" id="kobo.100.2">For that reason, it is advisable that before embarking on an optimization journey, the developer try to run the application under practical constraints and inputs to check performance. </span><span class="koboSpan" id="kobo.100.3">It is important to add instrumentation </span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.101.1">to the application in different forms to measure the performance and find bottlenecks to understand and prioritize the optimization opportunities. </span><span class="koboSpan" id="kobo.101.2">This is also an important step since as the application evolves, measuring and improving performance continues to be part of the workflow, that is, measuring and improving performance is a part of the application’s evolution. </span><span class="koboSpan" id="kobo.101.3">In the last section of this book, </span><em class="italic"><span class="koboSpan" id="kobo.102.1">Analyzing and improving performance</span></em><span class="koboSpan" id="kobo.103.1">, we will discuss this idea with a real case study to understand </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">this better.</span></span></p>
<h1 id="_idParaDest-65"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.105.1">Avoiding pitfalls and leveraging C++ features to minimize application latency</span></h1>
<p><span class="koboSpan" id="kobo.106.1">In this section, we will look at different C++ features that, if used correctly, can minimize application </span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.107.1">latency. </span><span class="koboSpan" id="kobo.107.2">We will </span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.108.1">also discuss the details of using these features in a manner that optimizes application performance throughout this sub-section. </span><span class="koboSpan" id="kobo.108.2">Now, let us start learning about how to use these features correctly to maximize application performance and avoid the pitfalls to minimize latency. </span><span class="koboSpan" id="kobo.108.3">Note that all the code snippets for this chapter are in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.109.1">Chapter3</span></strong><span class="koboSpan" id="kobo.110.1"> directory in the GitHub repository for </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">this book.</span></span></p>
<h2 id="_idParaDest-66"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.112.1">Choosing storage</span></h2>
<p><span class="koboSpan" id="kobo.113.1">Local variables </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.114.1">created within a function are stored on the stack by default and the stack memory is also used to store function return values. </span><span class="koboSpan" id="kobo.114.2">Assuming no large objects are created, the same range of stack storage space is reused a lot, resulting in great cache performance due to locality </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">of reference.</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">Register variables are closest to the processor and are the fastest possible form of storage available. </span><span class="koboSpan" id="kobo.116.2">They are extremely limited, and the compiler will try to use them for the local variables that are used the most, another reason to prefer </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.117.1">local variables</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.119.1">Static variables are inefficient from the perspective of cache performance since that memory cannot be re-used for other variables and accessing static variables is likely a small fraction of all memory accesses. </span><span class="koboSpan" id="kobo.119.2">So, it is best to avoid static variables as well as global variables, which have similarly inefficient </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">cache performance.</span></span></p>
<p><span class="koboSpan" id="kobo.121.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.122.1">volatile</span></strong><span class="koboSpan" id="kobo.123.1"> keyword instructs the compiler to disable a lot of optimizations that rely on the assumption that the variable value does not change without the compiler’s knowledge. </span><span class="koboSpan" id="kobo.123.2">This should only ever be used carefully in multi-threaded use cases since it prevents optimizations such as storing the variables in registers and force-flushing them to the main memory from the cache every time the </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">value changes.</span></span></p>
<p><span class="koboSpan" id="kobo.125.1">Dynamically allocated memory is inefficient to allocate and deallocate and, depending on how it is used, can suffer from poor cache performance. </span><span class="koboSpan" id="kobo.125.2">More on dynamically allocated memory inefficiencies will be discussed later in this section in the </span><em class="italic"><span class="koboSpan" id="kobo.126.1">Dynamically allocating </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.127.1">memory</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.128.1"> sub-section.</span></span></p>
<p><span class="koboSpan" id="kobo.129.1">An example of C++ optimization technique that leverages storage choice optimization is </span><strong class="bold"><span class="koboSpan" id="kobo.130.1">Small String Optimization</span></strong><span class="koboSpan" id="kobo.131.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.132.1">SSO</span></strong><span class="koboSpan" id="kobo.133.1">). </span><span class="koboSpan" id="kobo.133.2">SSO attempts to use local storage for short strings if they are smaller than </span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.134.1">a certain size (typically 32 characters) instead of the default of dynamically allocated memory for string </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">content storage.</span></span></p>
<p><span class="koboSpan" id="kobo.136.1">In summary, you should think carefully about where the data gets stored during the execution of your </span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.137.1">program, especially in the critical sections. </span><span class="koboSpan" id="kobo.137.2">We should try to use registers and local variables as much as possible and optimize cache performance. </span><span class="koboSpan" id="kobo.137.3">Use volatile, static, global, and dynamic memory only when necessary or when it does not affect performance on the </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">critical path.</span></span></p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.139.1">Choosing data types</span></h2>
<p><span class="koboSpan" id="kobo.140.1">C++ integer operations </span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.141.1">are typically super-fast as long as the size of the largest register is larger than the integer size. </span><span class="koboSpan" id="kobo.141.2">Integers smaller or larger than the register size are sometimes slightly slower than regular integers. </span><span class="koboSpan" id="kobo.141.3">This is because the processor must use multiple registers for a single variable and apply some carry-over logic for large integers. </span><span class="koboSpan" id="kobo.141.4">Conversely, handling integers smaller than a register size is usually handled by using a regular register, zeroing out the upper bits, using only the lower bits, and possibly invoking a type conversion operation. </span><span class="koboSpan" id="kobo.141.5">Note that the extra overhead is very small and generally not something to worry about. </span><span class="koboSpan" id="kobo.141.6">Signed and unsigned integers are equally fast, but in some cases unsigned integers are faster than signed integers. </span><span class="koboSpan" id="kobo.141.7">The only cases where signed integer operations are a tiny bit slower is where the processor needs to check and adjust for the sign bit. </span><span class="koboSpan" id="kobo.141.8">Again, the extra overhead is extremely small when present and not necessarily something we </span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.142.1">need to worry about in most cases. </span><span class="koboSpan" id="kobo.142.2">We will look at the cost of different operations – addition, subtraction, comparison, bit operations, and so on typically take a single clock cycle. </span><span class="koboSpan" id="kobo.142.3">Multiplication operations take longer, and division operations </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">take longest.</span></span></p>
<h2 id="_idParaDest-68"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.144.1">Using casting and conversion operations</span></h2>
<p><span class="koboSpan" id="kobo.145.1">Converting between signed and unsigned integers is free. </span><span class="koboSpan" id="kobo.145.2">Converting integers from a smaller size into a </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.146.1">larger one can take a single clock cycle but sometimes can be optimized to be free. </span><span class="koboSpan" id="kobo.146.2">Converting integer sizes down from a larger size into a smaller one has no </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">additional cost.</span></span></p>
<p><span class="koboSpan" id="kobo.148.1">Conversion between floats, doubles, and long doubles is typically free except under very few conditions. </span><span class="koboSpan" id="kobo.148.2">Conversion of signed and unsigned integers into floats or doubles takes a few clock cycles. </span><span class="koboSpan" id="kobo.148.3">Conversion from unsigned integers can take longer than </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">signed integers.</span></span></p>
<p><span class="koboSpan" id="kobo.150.1">Conversion from floating-point values into integers can be extremely expensive – 50 to 100 clock cycles or more. </span><span class="koboSpan" id="kobo.150.2">If these conversions are on the critical path, it is common for low-latency application developers to try and make these more efficient by enabling special instruction sets, avoiding or refactoring these conversions, if possible, using special assembly language rounding implementations, and </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.152.1">Converting pointers from one type into another type is completely free; whether the conversions are safe or not is the developer’s responsibility. </span><span class="koboSpan" id="kobo.152.2">Type-casting a pointer to an object to a pointer to a different object violates the strict aliasing rule stating that </span><em class="italic"><span class="koboSpan" id="kobo.153.1">two pointers of different types cannot point to the same memory location</span></em><span class="koboSpan" id="kobo.154.1">, which really means that it is possible the compiler might not use the same register to store the two different pointers, even though they point to the same address. </span><span class="koboSpan" id="kobo.154.2">Remember that the CPU registers are the fastest form of storage available to the processor but are extremely limited in storage capacity. </span><span class="koboSpan" id="kobo.154.3">So, when an extra register gets used to store the same variable, it is an inefficient use of the registers and negatively impacts </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">performance overall.</span></span></p>
<p><span class="koboSpan" id="kobo.156.1">An example of type-casting a pointer to be a different object is presented here. </span><span class="koboSpan" id="kobo.156.2">This example uses a conversion from </span><strong class="source-inline"><span class="koboSpan" id="kobo.157.1">double *</span></strong><span class="koboSpan" id="kobo.158.1"> into </span><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">uint64_t *</span></strong><span class="koboSpan" id="kobo.160.1"> and modifies the sign bit using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.161.1">uint64_t</span></strong><span class="koboSpan" id="kobo.162.1"> pointer. </span><span class="koboSpan" id="kobo.162.2">This is nothing more than a convoluted and more efficient method </span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.163.1">of achieving </span><strong class="source-inline"><span class="koboSpan" id="kobo.164.1">x = -std::abs(x)</span></strong><span class="koboSpan" id="kobo.165.1"> but demonstrates how this violates the strict aliasing rule (</span><strong class="source-inline"><span class="koboSpan" id="kobo.166.1">strict_alias.cpp</span></strong><span class="koboSpan" id="kobo.167.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.168.1">Chapter3</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.169.1">on GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.170.1">
#include &lt;cstdio&gt;
#include &lt;cstdint&gt;
int main() {
  double x = 100;
  const auto orig_x = x;
  auto x_as_ui = (uint64_t *) (&amp;x);
  *x_as_ui |= 0x8000000000000000;
  printf(“orig_x:%0.2f x:%0.2f &amp;x:%p &amp;x_as_ui:%p\n”,
       orig_x, x, &amp;x, x_as_ui);
}</span></pre>
<p><span class="koboSpan" id="kobo.171.1">It yields something </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.173.1">
orig_x:100.00 x:-100.00 &amp;x:0x7fff1e6b00d0 &amp;x_as_ui:0x7fff1e6b00d0</span></pre>
<p><span class="koboSpan" id="kobo.174.1">Using modern C++ casting operations, </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1">const_cast</span></strong><span class="koboSpan" id="kobo.176.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.177.1">static_cast</span></strong><span class="koboSpan" id="kobo.178.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.179.1">reinterpret_cast</span></strong><span class="koboSpan" id="kobo.180.1"> do not incur any additional overhead when used. </span><span class="koboSpan" id="kobo.180.2">However, when it comes to </span><strong class="source-inline"><span class="koboSpan" id="kobo.181.1">dynamic_cast</span></strong><span class="koboSpan" id="kobo.182.1">, which converts an object of a certain class into an object of a different class, this can be expensive at runtime. </span><strong class="source-inline"><span class="koboSpan" id="kobo.183.1">dynamic_cast</span></strong><span class="koboSpan" id="kobo.184.1"> checks whether the conversion is valid using </span><strong class="bold"><span class="koboSpan" id="kobo.185.1">Run-Time Type Information</span></strong><span class="koboSpan" id="kobo.186.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.187.1">RTTI</span></strong><span class="koboSpan" id="kobo.188.1">), which is slow and possibly throws </span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.189.1">an exception if the conversion is invalid – this makes it safer but </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">increases latency.</span></span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.191.1">Optimizing numerical operations</span></h2>
<p><span class="koboSpan" id="kobo.192.1">Typically, double-precision </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.193.1">calculations take about the same time as single-precision operations. </span><span class="koboSpan" id="kobo.193.2">In general, for integers and floating values, additions </span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.194.1">are fast, multiplications are slightly more expensive than additions, and division is quite a bit more expensive than multiplication. </span><span class="koboSpan" id="kobo.194.2">Integer multiplications take around 5 clock cycles and floating-point multiplications take around 8 clock cycles. </span><span class="koboSpan" id="kobo.194.3">Integer additions take a single clock cycle on most processors and floating-point additions take around 2-5 clock cycles. </span><span class="koboSpan" id="kobo.194.4">Floating-point divisions and integer divisions both take about the same amount of time around 20-80 clock cycles, depending on the processor and depending on whether it has special floating-point operations </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">or not.</span></span></p>
<p><span class="koboSpan" id="kobo.196.1">Compilers will try to rewrite and reduce expressions wherever possible to prefer faster operations such as rewriting divisions to be multiplications by reciprocals. </span><span class="koboSpan" id="kobo.196.2">Multiplication and division by values that are powers of 2 are significantly faster because the compiler rewrites them to be bit-shift operations, which are much faster. </span><span class="koboSpan" id="kobo.196.3">There is additional overhead when the compiler uses this optimization since it must handle signs and rounding errors. </span><span class="koboSpan" id="kobo.196.4">Obviously, this only applies when the expressions involve values that can be determined to be powers of 2 at compile time. </span><span class="koboSpan" id="kobo.196.5">When dealing with multi-dimensional arrays, for instance, the compiler converts multiplications into bitwise shift operations </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">wherever possible.</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">Mixing single- and double-precision operations in the same expression and expressions involving floating and integer values should be avoided because they implicitly force type conversions. </span><span class="koboSpan" id="kobo.198.2">We saw before that type conversions are not always free, so these expressions can take longer to compute than we would guess. </span><span class="koboSpan" id="kobo.198.3">For instance, when mixing single- and double-precision values in an expression, the single-precision values must first be converted into double-precision values, which can consume a few clock cycles before the expression is computed. </span><span class="koboSpan" id="kobo.198.4">Similarly, when mixing integers and floating-point values in an expression, either the floating-point value has to be converted into an integer or the integer must be converted into a floating-point value, which adds a few clock cycles to the final </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">calculation time.</span></span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.200.1">Optimizing boolean and bitwise operations</span></h2>
<p><span class="koboSpan" id="kobo.201.1">Boolean operations </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.202.1">such as </span><strong class="bold"><span class="koboSpan" id="kobo.203.1">logical AND</span></strong><span class="koboSpan" id="kobo.204.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">&amp;&amp;</span></strong><span class="koboSpan" id="kobo.206.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.207.1">logical OR</span></strong><span class="koboSpan" id="kobo.208.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.209.1">||</span></strong><span class="koboSpan" id="kobo.210.1">) are evaluated such that for </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1">&amp;&amp;</span></strong><span class="koboSpan" id="kobo.212.1">, if the first </span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.213.1">operand is false, then the second one is not evaluated, and, for </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">||</span></strong><span class="koboSpan" id="kobo.215.1">, if the first </span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.216.1">operand is true, then the second one is not </span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.217.1">evaluated. </span><span class="koboSpan" id="kobo.217.2">A simple optimization technique is to </span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.218.1">order the operands of </span><strong class="source-inline"><span class="koboSpan" id="kobo.219.1">&amp;&amp;</span></strong><span class="koboSpan" id="kobo.220.1"> in order from lowest to highest probability of being evaluated </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">to true.</span></span></p>
<p><span class="koboSpan" id="kobo.222.1">Similarly, for </span><strong class="source-inline"><span class="koboSpan" id="kobo.223.1">||</span></strong><span class="koboSpan" id="kobo.224.1">, ordering </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.225.1">the operands from highest to lowest probability of being true is best. </span><span class="koboSpan" id="kobo.225.2">This technique is referred to as </span><strong class="bold"><span class="koboSpan" id="kobo.226.1">short-circuiting</span></strong><span class="koboSpan" id="kobo.227.1"> the boolean operations </span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.228.1">and it not only reduces the number of times these operands are evaluated </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.229.1">but also improves branch prediction. </span><span class="koboSpan" id="kobo.229.2">This technique cannot be used if the order of the </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.230.1">operands is important to the program, for instance, if we </span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.231.1">require that for an </span><strong class="source-inline"><span class="koboSpan" id="kobo.232.1">&amp;&amp;</span></strong><span class="koboSpan" id="kobo.233.1"> boolean operation, the second operand should not be evaluated if the first one is false. </span><span class="koboSpan" id="kobo.233.2">Or for an </span><strong class="source-inline"><span class="koboSpan" id="kobo.234.1">||</span></strong><span class="koboSpan" id="kobo.235.1"> boolean operation, the second operand should not be evaluated if the first one is true, and </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.237.1">Another aspect of using boolean variables is understanding the way they are stored. </span><span class="koboSpan" id="kobo.237.2">Boolean variables are stored as 8 bits and not a single bit, as might match our intuition from the way they are used. </span><span class="koboSpan" id="kobo.237.3">What this means is that operations involving boolean values have to be implemented such that any 8-bit values other than 0 are treated as 1, which leads to implementations with branches in them with comparisons against 0. </span><span class="koboSpan" id="kobo.237.4">For example, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.238.1">c = a &amp;&amp; b;</span></strong><span class="koboSpan" id="kobo.239.1"> expression is implemented </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.241.1">
if(a != 0) {
 if(b != 0) {
   c = true;
 } else {
   c = false;
 }
} else {
 c = false;
}</span></pre>
<p><span class="koboSpan" id="kobo.242.1">If there was a guarantee that </span><strong class="source-inline"><span class="koboSpan" id="kobo.243.1">a</span></strong><span class="koboSpan" id="kobo.244.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.245.1">b</span></strong><span class="koboSpan" id="kobo.246.1"> could not have values other than 0 or 1, then </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">c = a &amp;&amp; b;</span></strong><span class="koboSpan" id="kobo.248.1"> would simply be </span><strong class="source-inline"><span class="koboSpan" id="kobo.249.1">c = a &amp; b;</span></strong><span class="koboSpan" id="kobo.250.1">, which is super-fast and avoids branching and </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">branching-related overheads.</span></span></p>
<p><span class="koboSpan" id="kobo.252.1">Bitwise operations can also help speed up other cases of boolean expressions by treating each bit of an integer as a single boolean variable and then rewriting expressions involving comparisons of multiple booleans with bit-masking operations. </span><span class="koboSpan" id="kobo.252.2">For instance, take an expression such as this, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.253.1">market_state</span></strong><span class="koboSpan" id="kobo.254.1"> is </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">uint64_t</span></strong><span class="koboSpan" id="kobo.256.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.257.1">PreOpen</span></strong><span class="koboSpan" id="kobo.258.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.259.1">Opening</span></strong><span class="koboSpan" id="kobo.260.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.261.1">Trading</span></strong><span class="koboSpan" id="kobo.262.1"> are enum values that reflect different </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">market states:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.264.1">
if(market_state == PreOpen ||
   market_state == Opening ||
   market_state == Trading) {
  // do something...
</span><span class="koboSpan" id="kobo.264.2">}</span></pre>
<p><span class="koboSpan" id="kobo.265.1">It can be rewritten </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.267.1">
if(market_state &amp; (PreOpen | Opening | Trading)) {
  // do something...
</span><span class="koboSpan" id="kobo.267.2">}</span></pre>
<p><span class="koboSpan" id="kobo.268.1">If the enum values are </span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.269.1">chosen such that each bit in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1">market_state</span></strong><span class="koboSpan" id="kobo.271.1"> variable </span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.272.1">represents a state of true </span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.273.1">or false, one choice would be for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.274.1">PreOpen</span></strong><span class="koboSpan" id="kobo.275.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1">Opening</span></strong><span class="koboSpan" id="kobo.277.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.278.1">Trading</span></strong><span class="koboSpan" id="kobo.279.1"> enums to </span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.280.1">be set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">0x001</span></strong><span class="koboSpan" id="kobo.282.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.283.1">0x010</span></strong><span class="koboSpan" id="kobo.284.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">0x100</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">.</span></span></p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.288.1">Initializing, destroying, copying, and moving objects</span></h2>
<p><span class="koboSpan" id="kobo.289.1">Constructors </span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.290.1">and destructors </span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.291.1">for developer-defined classes should be kept as light and efficient as possible since they can be </span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.292.1">called without the developer </span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.293.1">expecting it. </span><span class="koboSpan" id="kobo.293.2">Keeping these methods super-simple and small also allows the compiler to </span><em class="italic"><span class="koboSpan" id="kobo.294.1">inline</span></em><span class="koboSpan" id="kobo.295.1"> these methods to improve performance. </span><span class="koboSpan" id="kobo.295.2">The same applies to copy and move constructors, which should be kept simple, with using move constructors preferred over using copy </span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.296.1">constructors </span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.297.1">wherever possible. </span><span class="koboSpan" id="kobo.297.2">In </span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.298.1">many cases </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.299.1">where high levels of optimization are required, the developer can delete the default constructor and the copy constructor to make sure unnecessary or unexpected copies of their objects are not </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">being made.</span></span></p>
<h2 id="_idParaDest-72"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.301.1">Using references and pointers</span></h2>
<p><span class="koboSpan" id="kobo.302.1">A lot of C++ features are built around implicitly accessing class members through the </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1">this</span></strong><span class="koboSpan" id="kobo.304.1"> pointer, so </span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.305.1">access through </span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.306.1">references and pointers occurs very frequently regardless of whether the developer explicitly does so or not. </span><span class="koboSpan" id="kobo.306.2">Accessing objects through pointers and references is mostly as efficient as directly accessing the objects. </span><span class="koboSpan" id="kobo.306.3">This is because most modern processors have support to efficiently fetch the pointer values and dereference them. </span><span class="koboSpan" id="kobo.306.4">The big disadvantage of using references and pointers is that they take up an extra register for the pointer themselves and the other one consists of the extra dereference instructions to access the variable pointed to by the </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">pointer value.</span></span></p>
<p><span class="koboSpan" id="kobo.308.1">Pointer arithmetic is just as fast as integer arithmetic except computing the differences between pointers requires a division by the size of the object, which can potentially be very slow. </span><span class="koboSpan" id="kobo.308.2">This is not necessarily a problem if the size of the type of object is a multiple of 2, which is quite often the case with primitive types and </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">optimized structures.</span></span></p>
<p><span class="koboSpan" id="kobo.310.1">Smart pointers are an important feature of modern C++ that offers safety, life cycle management, automatic memory management, and clear ownership control for dynamically allocated </span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.311.1">objects. </span><span class="koboSpan" id="kobo.311.2">Smart pointers such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.312.1">std::unique_ptr</span></strong><span class="koboSpan" id="kobo.313.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.314.1">std::shared_ptr</span></strong><span class="koboSpan" id="kobo.315.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.316.1">std::weak_ptr</span></strong><span class="koboSpan" id="kobo.317.1"> use the </span><strong class="bold"><span class="koboSpan" id="kobo.318.1">Resource Acquisition is Initialization</span></strong><span class="koboSpan" id="kobo.319.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.320.1">RAII</span></strong><span class="koboSpan" id="kobo.321.1">) C++ paradigm. </span><span class="koboSpan" id="kobo.321.2">There is an extra cost associated with </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">std::shared_ptr</span></strong><span class="koboSpan" id="kobo.323.1"> due to the reference counting overhead but generally, smart pointers are expected to add very little overhead to the entire program unless there are a lot </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">of them.</span></span></p>
<p><span class="koboSpan" id="kobo.325.1">Another important aspect of using pointers is that it can prevent compiler optimizations due to </span><strong class="bold"><span class="koboSpan" id="kobo.326.1">Pointer Aliasing</span></strong><span class="koboSpan" id="kobo.327.1">. </span><span class="koboSpan" id="kobo.327.2">This is because, while it may be obvious to the user, at compile time, the compiler </span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.328.1">cannot guarantee that two pointer variables in the code will never point to the same memory address. </span><span class="koboSpan" id="kobo.328.2">Under those theoretical possible cases of pointer aliasing, some compiler optimizations would change the outcome of code; hence, those optimizations are disabled. </span><span class="koboSpan" id="kobo.328.3">For instance, the following code would prevent the compiler from applying loop-invariant code motion. </span><span class="koboSpan" id="kobo.328.4">This is despite there being no overlap between pointers </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">a[0]</span></strong><span class="koboSpan" id="kobo.330.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">a[n-1]</span></strong><span class="koboSpan" id="kobo.332.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">b</span></strong><span class="koboSpan" id="kobo.334.1">. </span><span class="koboSpan" id="kobo.334.2">That means that this optimization is valid because </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">*b</span></strong><span class="koboSpan" id="kobo.336.1"> is a constant for the entire loop and can be </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">computed once:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.338.1">
void func(int* a, int* b, int n) {
  for(int i = 0; i &lt; n; ++i) {
    a[i] = *b;
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.339.1">There are really two options for instructing the compiler to assume no pointer aliasing in cases where the developer is confident that there is no behavior that is dependent on the side effects </span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.340.1">of pointer aliasing. </span><span class="koboSpan" id="kobo.340.2">Use </span><strong class="source-inline"><span class="koboSpan" id="kobo.341.1">__restrict__</span></strong><span class="koboSpan" id="kobo.342.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">__restrict</span></strong><span class="koboSpan" id="kobo.344.1">, a similar specifier keyword, for your compiler </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.345.1">on the function arguments or functions to specify no aliasing on the pointers. </span><span class="koboSpan" id="kobo.345.2">However, this is a hint, and the compiler does not guarantee that this will make a difference. </span><span class="koboSpan" id="kobo.345.3">The other option is to specify the </span><strong class="source-inline"><span class="koboSpan" id="kobo.346.1">-fstrict-aliasing</span></strong><span class="koboSpan" id="kobo.347.1"> compiler option to assume no pointer aliasing globally. </span><span class="koboSpan" id="kobo.347.2">The following code block demonstrates the use of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">restrict</span></strong><span class="koboSpan" id="kobo.349.1"> specifier for the preceding </span><strong class="source-inline"><span class="koboSpan" id="kobo.350.1">func()</span></strong><span class="koboSpan" id="kobo.351.1"> function (</span><strong class="source-inline"><span class="koboSpan" id="kobo.352.1">pointer_alias.cpp</span></strong><span class="koboSpan" id="kobo.353.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.354.1">Chapter3</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.355.1">on GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.356.1">
void func(int *__restrict a, int *__restrict b, int n) {
  for (int i = 0; i &lt; n; ++i) {
    a[i] = *b;
  }
}</span></pre>
<h2 id="_idParaDest-73"><a id="_idTextAnchor075"/><span class="koboSpan" id="kobo.357.1">Optimizing jumping and branching</span></h2>
<p><span class="koboSpan" id="kobo.358.1">In modern processor pipelines, instructions and data are fetched and decoded in stages. </span><span class="koboSpan" id="kobo.358.2">When there </span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.359.1">is a branch instruction, the processor tries to predict which of the branches will be taken and fetches and decodes instructions from that branch. </span><span class="koboSpan" id="kobo.359.2">However, when the processor has mispredicted the branch taken, it takes 10 or more clock cycles before it detects the misprediction. </span><span class="koboSpan" id="kobo.359.3">After that, it must spend a bunch of clock cycles fetching the instructions and data from the correct branch and evaluate it. </span><span class="koboSpan" id="kobo.359.4">The key takeaway here is that a branch misprediction wastes many clock cycles every time </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">it happens.</span></span></p>
<p><span class="koboSpan" id="kobo.361.1">Let us discuss some of the most used forms of jumps and branches </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">in C++:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.363.1">if-else</span></strong><span class="koboSpan" id="kobo.364.1"> branching is the most common thing that comes to mind when discussing branching. </span><span class="koboSpan" id="kobo.364.2">Long chains of </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1">if-else</span></strong><span class="koboSpan" id="kobo.366.1"> conditionals are best avoided, if possible, because it is difficult to predict these correctly as they grow. </span><span class="koboSpan" id="kobo.366.2">Keeping the number of conditions small and trying to structure them so they are more predictable is the way to </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">optimize them.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.368.1">for</span></strong><span class="koboSpan" id="kobo.369.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.370.1">while</span></strong><span class="koboSpan" id="kobo.371.1"> loops are also types of branching that are typically predicted well if the loop count is relatively small. </span><span class="koboSpan" id="kobo.371.2">This, of course, gets complicated with nested loops and loops containing hard-to-predict </span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">exit conditions.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.373.1">switch</span></strong><span class="koboSpan" id="kobo.374.1"> statements are branches with multiple jump targets, so they can be very difficult to predict. </span><span class="koboSpan" id="kobo.374.2">When label values are widely spread out, the compiler must use </span><strong class="source-inline"><span class="koboSpan" id="kobo.375.1">switch</span></strong><span class="koboSpan" id="kobo.376.1"> statements as a long sequence of </span><strong class="source-inline"><span class="koboSpan" id="kobo.377.1">if-else</span></strong><span class="koboSpan" id="kobo.378.1"> branching trees. </span><span class="koboSpan" id="kobo.378.2">An optimization technique that works well with </span><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">switch</span></strong><span class="koboSpan" id="kobo.380.1"> statements is to assign case label values that increment by one and are arranged in ascending order because there is a very good chance they will get implemented as jump tables, which is significantly </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">more efficient.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.382.1">Replacing branching with table lookups containing different output values in the source code is a good optimization wherever possible. </span><span class="koboSpan" id="kobo.382.2">We can also create a table of function pointers indexed by jump conditions but beware that function pointers are not necessarily much more efficient than the </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">branching itself.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.384.1">Loop unrolling</span></strong><span class="koboSpan" id="kobo.385.1"> can also help with minimizing branching if there are branches within a loop that are difficult </span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.386.1">to predict and can lead to a lot of branch mispredictions. </span><span class="koboSpan" id="kobo.386.2">We will discuss loop unrolling in detail later, but for now, let us briefly introduce the idea. </span><span class="koboSpan" id="kobo.386.3">Loop unrolling duplicates the body of the loop multiple times in order to avoid the checks and branching that determine whether a loop should continue. </span><span class="koboSpan" id="kobo.386.4">The compiler will attempt to unroll loops if possible, but it is often best if the developer does it themself. </span><span class="koboSpan" id="kobo.386.5">For example, consider a simple loop such as this with a low loop counter (</span><strong class="source-inline"><span class="koboSpan" id="kobo.387.1">loop_unroll.cpp</span></strong><span class="koboSpan" id="kobo.388.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.389.1">Chapter3</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.390.1">on GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.391.1">
   int a[5]; a[0] = 0;
    for(int i = 1; i &lt; 5; ++i)
      a[i] = a[i-1] + 1;</span></pre>
<p><span class="koboSpan" id="kobo.392.1">The compiler can unroll the loop into the following code shown here. </span><span class="koboSpan" id="kobo.392.2">Note that it is more than likely </span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.393.1">that for such a simple example, the compiler will use additional optimizations and reduce this loop even further. </span><span class="koboSpan" id="kobo.393.2">But for now, we limit ourselves to only present the impact of </span><span class="No-Break"><span class="koboSpan" id="kobo.394.1">loop unrolling:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.395.1">
    int a[5];
    a[0] = 0;
    a[1] = a[0] + 1; a[2] = a[1] + 1;
    a[3] = a[2] + 1; a[4] = a[3] + 1;</span></pre>
<p><span class="koboSpan" id="kobo.396.1">Compile-time branching using an </span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1">if constexpr (condition-expression) {}</span></strong><span class="koboSpan" id="kobo.398.1"> format can obviously help a lot by moving the overhead of branching to compile time, but this requires that </span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">condition-expression</span></strong><span class="koboSpan" id="kobo.400.1"> be something that can be evaluated at compile time. </span><span class="koboSpan" id="kobo.400.2">This is </span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.401.1">technically part of the </span><strong class="bold"><span class="koboSpan" id="kobo.402.1">Compile time Polymorphism</span></strong><span class="koboSpan" id="kobo.403.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.404.1">Template Metaprogramming</span></strong><span class="koboSpan" id="kobo.405.1"> paradigm, which we will </span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.406.1">discuss more in the </span><em class="italic"><span class="koboSpan" id="kobo.407.1">Using compile-time polymorphism</span></em><span class="koboSpan" id="kobo.408.1"> sub-section in </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">this section.</span></span></p>
<p><span class="koboSpan" id="kobo.410.1">It is possible to provide the compiler with branch prediction hints in the source code since the developer has a better idea of the expected use cases. </span><span class="koboSpan" id="kobo.410.2">These do not make a significant difference overall since modern processors are good at learning which branches are most likely to be taken after a few iterations through the branches. </span><span class="koboSpan" id="kobo.410.3">For GNU C++, these are traditionally implemented as follows </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">__builtin_expect</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.413.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.414.1">
#define LIKELY_CONDITION(x) __builtin_expect(!!(x), 1)
#define UNLIKELY_CONDITION (x) __builtin_expect(!!(x), 0)</span></pre>
<p><span class="koboSpan" id="kobo.415.1">For C++ 20, these </span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.416.1">are standardized as the </span><strong class="source-inline"><span class="koboSpan" id="kobo.417.1">[[likely]]</span></strong><span class="koboSpan" id="kobo.418.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.419.1">[[</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.420.1">unlikely]]</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.421.1"> attributes.</span></span></p>
<h2 id="_idParaDest-74"><a id="_idTextAnchor076"/><span class="koboSpan" id="kobo.422.1">Calling functions efficiently</span></h2>
<p><span class="koboSpan" id="kobo.423.1">There are numerous overheads associated with calling functions – the overhead of fetching the </span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.424.1">function address and jumping to it, passing the parameters to it and returning the results, setting up the stack frame, saving and restoring registers, exception handling, possible latency in the code cache misses, and </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.426.1">When breaking up the code base into functions, some general things to consider to maximize the performance would be </span><span class="No-Break"><span class="koboSpan" id="kobo.427.1">the following.</span></span></p>
<h3><span class="koboSpan" id="kobo.428.1">Thinking before creating an excessive number of functions</span></h3>
<p><span class="koboSpan" id="kobo.429.1">Functions should </span><a id="_idIndexMarker428"/><span class="koboSpan" id="kobo.430.1">only be created if there is enough re-usability to justify them. </span><span class="koboSpan" id="kobo.430.2">The criteria for creating functions should be logical program flow and re-usability and not the length of code because, as we saw, calling functions is not free, and creating excessive functions is not a </span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">good idea.</span></span></p>
<h3><span class="koboSpan" id="kobo.432.1">Grouping related functions together</span></h3>
<p><span class="koboSpan" id="kobo.433.1">Class member and non-class member functions typically get assigned memory addresses in the order in which they are created, so it is generally a good idea to group together performance-critical functions that call each other frequently or operate on the same datasets. </span><span class="koboSpan" id="kobo.433.2">This facilitates better code and data </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">cache performance.</span></span></p>
<h3><span class="koboSpan" id="kobo.435.1">Link Time Optimization (LTO) or Whole Program Optimization (WPO)</span></h3>
<p><span class="koboSpan" id="kobo.436.1">When writing </span><a id="_idIndexMarker429"/><span class="koboSpan" id="kobo.437.1">performance-critical functions, it is important to place </span><a id="_idIndexMarker430"/><span class="koboSpan" id="kobo.438.1">them in the same module where they are used if possible. </span><span class="koboSpan" id="kobo.438.2">Doing so unlocks a lot of compiler optimizations, the most important of which is the ability to inline the </span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">function call.</span></span></p>
<p><span class="koboSpan" id="kobo.440.1">Using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.441.1">static</span></strong><span class="koboSpan" id="kobo.442.1"> keyword to </span><a id="_idIndexMarker431"/><span class="koboSpan" id="kobo.443.1">declare a function does the equivalent </span><a id="_idIndexMarker432"/><span class="koboSpan" id="kobo.444.1">of putting it in an </span><strong class="bold"><span class="koboSpan" id="kobo.445.1">anonymous namespace</span></strong><span class="koboSpan" id="kobo.446.1">, which makes it local to the translation unit it is used in. </span><span class="koboSpan" id="kobo.446.2">Specifying the </span><strong class="source-inline"><span class="koboSpan" id="kobo.447.1">inline</span></strong><span class="koboSpan" id="kobo.448.1"> keyword achieves this as well, but </span><a id="_idIndexMarker433"/><span class="koboSpan" id="kobo.449.1">we will explore that in the </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">next section.</span></span></p>
<p><span class="koboSpan" id="kobo.451.1">Specifying WPO </span><a id="_idIndexMarker434"/><span class="koboSpan" id="kobo.452.1">and LTO parameters for the compiler instructs it to treat the </span><a id="_idIndexMarker435"/><span class="koboSpan" id="kobo.453.1">entire code base as a single module and enable compiler optimizations across modules. </span><span class="koboSpan" id="kobo.453.2">Without enabling these </span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.454.1">compiler options, optimizations occur across functions in the same module but not between modules which can be quite sub-optimal for large code bases which typically have a lot of source files </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">and modules.</span></span></p>
<h3><span class="koboSpan" id="kobo.456.1">Macros, inline functions, and template metaprogramming</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.457.1">Macro expressions</span></strong><span class="koboSpan" id="kobo.458.1"> are a pre-processor directive and are expanded even before compilation begins. </span><span class="koboSpan" id="kobo.458.2">This eliminates </span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.459.1">the overhead associated with calling and returning from functions at runtime. </span><span class="koboSpan" id="kobo.459.2">Macros have several disadvantages though, such as namespace collision, cryptic compilation errors, unnecessary evaluation of conditions and expressions, and </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.461.1">Inlined functions, whether they are part of a class or not, are similar to macros but solve a lot of the problems </span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.462.1">associated with macros. </span><span class="koboSpan" id="kobo.462.2">Inlined functions are expanded at their usage during compilation and link times and eliminate the overhead associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">function calls.</span></span></p>
<p><span class="koboSpan" id="kobo.464.1">Using template metaprogramming, it is possible to move a lot of the computation load from runtime to </span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.465.1">compile time. </span><span class="koboSpan" id="kobo.465.2">This involves using partial and full template specialization and recursive loop templates. </span><span class="koboSpan" id="kobo.465.3">However, template metaprogramming can be clumsy and difficult to use, compile, and debug and should only really be used where the pe</span><a id="_idTextAnchor077"/><span class="koboSpan" id="kobo.466.1">rformance improvements justify the increased development discomfort. </span><span class="koboSpan" id="kobo.466.2">We will explore templates and template </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">metaprogramming shortly.</span></span></p>
<h3><span class="koboSpan" id="kobo.468.1">Avoiding function pointers</span></h3>
<p><span class="koboSpan" id="kobo.469.1">Calling a function through a function pointer has a larger overhead than directly calling the function. </span><span class="koboSpan" id="kobo.469.2">For one, if the pointer changes, then the compiler cannot predict which function will be called and cannot pre-fetch the instructions and data. </span><span class="koboSpan" id="kobo.469.3">Additionally, this also prevents a lot of compiler optimizations since these cannot be inlined at </span><span class="No-Break"><span class="koboSpan" id="kobo.470.1">compile time.</span></span></p>
<p><span class="koboSpan" id="kobo.471.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.472.1">std::function</span></strong><span class="koboSpan" id="kobo.473.1"> is a much more powerful construct available in modern C++ but should be used only if necessary since there is potential for misuse and extra overhead of a few clock cycles compared to direct inlined functions. </span><strong class="source-inline"><span class="koboSpan" id="kobo.474.1">std::bind</span></strong><span class="koboSpan" id="kobo.475.1"> is another construct to be very careful about when using and should also only be used if absolutely necessary. </span><span class="koboSpan" id="kobo.475.2">If </span><strong class="source-inline"><span class="koboSpan" id="kobo.476.1">std::function</span></strong><span class="koboSpan" id="kobo.477.1"> must be used, try to see whether you can use a lambda expression instead of </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">std::bind</span></strong><span class="koboSpan" id="kobo.479.1"> since that is typically a few clock cycles faster to invoke. </span><span class="koboSpan" id="kobo.479.2">Overall, be careful when using </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">std::function</span></strong><span class="koboSpan" id="kobo.481.1"> and/or </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">std::bind</span></strong><span class="koboSpan" id="kobo.483.1"> since a lot of developers are surprised that these constructs can perform virtual function calls and invoke dynamic memory allocations under </span><span class="No-Break"><span class="koboSpan" id="kobo.484.1">the hood.</span></span></p>
<h3><span class="koboSpan" id="kobo.485.1">Passing function parameters by reference or pointers</span></h3>
<p><span class="koboSpan" id="kobo.486.1">For primitive types, passing parameters by value is super-efficient. </span><span class="koboSpan" id="kobo.486.2">For composite types that are function parameters, the preferred way of passing them would be const references. </span><span class="koboSpan" id="kobo.486.3">The </span><strong class="bold"><span class="koboSpan" id="kobo.487.1">constness</span></strong><span class="koboSpan" id="kobo.488.1"> means that the object cannot be modified and allows the compiler to apply optimizations </span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.489.1">based on that and the reference allows the compiler to possibly inline the object itself. </span><span class="koboSpan" id="kobo.489.2">If the function needs to modify the object passed to it, then obviously a non-const reference or pointer is the way </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">to go.</span></span></p>
<h3><span class="koboSpan" id="kobo.491.1">Returning simple types from functions</span></h3>
<p><span class="koboSpan" id="kobo.492.1">Functions that return primitive types are very efficient. </span><span class="koboSpan" id="kobo.492.2">Returning composite types is much more inefficient and can lead to a couple of copies being created in some cases, which is quite sub-optimal especially if these are large and/or have slow copy constructors and assignment </span><a id="_idIndexMarker441"/><span class="koboSpan" id="kobo.493.1">operators. </span><span class="koboSpan" id="kobo.493.2">When the compiler can apply </span><strong class="bold"><span class="koboSpan" id="kobo.494.1">Return Value Optimization</span></strong><span class="koboSpan" id="kobo.495.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.496.1">RVO</span></strong><span class="koboSpan" id="kobo.497.1">), it can eliminate the temporary copy created and just write the result to the caller’s object directly. </span><span class="koboSpan" id="kobo.497.2">The optimal way to return a composite type is to have the caller create an object of that type and pass it to the function using a reference or a pointer for the function </span><span class="No-Break"><span class="koboSpan" id="kobo.498.1">to modify.</span></span></p>
<p><span class="koboSpan" id="kobo.499.1">Let us look at an example to explain what happens with RVO; let us say we have the following function definition and call to the function (</span><strong class="source-inline"><span class="koboSpan" id="kobo.500.1">rvo.cpp</span></strong><span class="koboSpan" id="kobo.501.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.502.1">Chapter3</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.503.1">on GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.504.1">
#include &lt;iostream&gt;
struct LargeClass {
  int i;
  char c;
  double d;
};
auto rvoExample(int i, char c, double d) {
  return LargeClass{i, c, d};
}
int main() {
  LargeClass lc_obj = rvoExample(10, ‘c’, 3.14);
}</span></pre>
<p><span class="koboSpan" id="kobo.505.1">With RVO, instead of creating a temporary </span><strong class="source-inline"><span class="koboSpan" id="kobo.506.1">LargeClass</span></strong><span class="koboSpan" id="kobo.507.1"> object inside </span><strong class="source-inline"><span class="koboSpan" id="kobo.508.1">rvoExample()</span></strong><span class="koboSpan" id="kobo.509.1"> and then copying it into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.510.1">LargeClass lc_obj</span></strong><span class="koboSpan" id="kobo.511.1"> object in </span><strong class="source-inline"><span class="koboSpan" id="kobo.512.1">main()</span></strong><span class="koboSpan" id="kobo.513.1">, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.514.1">rvoExample()</span></strong><span class="koboSpan" id="kobo.515.1"> function can directly update </span><strong class="source-inline"><span class="koboSpan" id="kobo.516.1">lc_obj</span></strong><span class="koboSpan" id="kobo.517.1"> and avoid the temporary object </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">and copy.</span></span></p>
<h3><span class="koboSpan" id="kobo.519.1">Avoiding recursive functions or replacing them with a loop</span></h3>
<p><span class="koboSpan" id="kobo.520.1">Recursive functions are inefficient because of the overhead of calling themselves repeatedly. </span><span class="koboSpan" id="kobo.520.2">Additionally, recursive functions can go very deep in the stack and take up a lot of stack space, and, in </span><a id="_idIndexMarker442"/><span class="koboSpan" id="kobo.521.1">worst-case scenarios, even cause a stack overflow. </span><span class="koboSpan" id="kobo.521.2">This causes a lot of cache misses due to the new memory areas and makes predicting the return address difficult and inefficient. </span><span class="koboSpan" id="kobo.521.3">In such cases, replacing recursive functions with a loop is significantly more efficient since it avoids a lot of the cache performance issues that recursive </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">functions encounter.</span></span></p>
<h2 id="_idParaDest-75"><a id="_idTextAnchor078"/><span class="koboSpan" id="kobo.523.1">Using bitfields</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.524.1">Bitfields</span></strong><span class="koboSpan" id="kobo.525.1"> are just structs where the developer controls the number of bits assigned to each member. </span><span class="koboSpan" id="kobo.525.2">This </span><a id="_idIndexMarker443"/><span class="koboSpan" id="kobo.526.1">makes the data as compact as possible and greatly improves </span><a id="_idIndexMarker444"/><span class="koboSpan" id="kobo.527.1">cache performance for many objects. </span><span class="koboSpan" id="kobo.527.2">Bitfield members are also usually modified using bitmask operations, which are very efficient, as we have seen before. </span><span class="koboSpan" id="kobo.527.3">Accessing the members of bitfields is </span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.528.1">less efficient than accessing the members of a regular structure, so it is important to carefully </span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.529.1">assess whether using bitfields and improving the cache </span><strong class="bold"><span class="koboSpan" id="kobo.530.1">performance</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.531.1">is worthwhile.</span></span></p>
<h2 id="_idParaDest-76"><a id="_idTextAnchor079"/><span class="koboSpan" id="kobo.532.1">Using runtime polymorphism</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.533.1">Runtime polymorphism</span></strong><span class="koboSpan" id="kobo.534.1"> is an elegant solution when the member function that needs to be called will be </span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.535.1">determined at runtime instead of compile </span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.536.1">time. </span><strong class="source-inline"><span class="koboSpan" id="kobo.537.1">Virtual</span></strong><span class="koboSpan" id="kobo.538.1"> functions are the key to implementing runtime polymorphism, but they have an additional overhead compared to non-virtual </span><span class="No-Break"><span class="koboSpan" id="kobo.539.1">function calls.</span></span></p>
<p><span class="koboSpan" id="kobo.540.1">Usually, the compiler cannot determine at compile time which implementation of a virtual function will be called. </span><span class="koboSpan" id="kobo.540.2">At runtime, this causes many branch mispredictions unless the same version of the virtual function gets called most of the time. </span><span class="koboSpan" id="kobo.540.3">It is possible for the compiler to determine the virtual function implementation called at compile time using </span><strong class="bold"><span class="koboSpan" id="kobo.541.1">devirtualization</span></strong><span class="koboSpan" id="kobo.542.1">, but this is not possible in many cases. </span><span class="koboSpan" id="kobo.542.2">The primary problem with </span><strong class="source-inline"><span class="koboSpan" id="kobo.543.1">virtual</span></strong><span class="koboSpan" id="kobo.544.1"> functions is </span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.545.1">that the compiler cannot apply many of the compile-time optimizations in the presence of </span><strong class="source-inline"><span class="koboSpan" id="kobo.546.1">virtual</span></strong><span class="koboSpan" id="kobo.547.1"> functions, the most important one </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">being inlining.</span></span></p>
<p><span class="koboSpan" id="kobo.549.1">Inheritance in C++ is another important OOP concept but be careful when the inheritance structure gets too complicated since there are many subtle inefficiencies that can be introduced. </span><span class="koboSpan" id="kobo.549.2">Child classes inherit every single data member from their parent class, so the size of the child classes can become quite large and lead to poor </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">cache performance.</span></span></p>
<p><span class="koboSpan" id="kobo.551.1">In general, instead of inheriting from multiple parent classes, we can consider using the </span><strong class="bold"><span class="koboSpan" id="kobo.552.1">Composition</span></strong><span class="koboSpan" id="kobo.553.1"> paradigm, where the </span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.554.1">child class has members of different parent class types instead of inheriting from them. </span><span class="koboSpan" id="kobo.554.2">This avoids complications related to accessing child class objects using different parent class pointers, offsets of the data members and methods in the child classes, and so on. </span><span class="koboSpan" id="kobo.554.3">The following example (</span><strong class="source-inline"><span class="koboSpan" id="kobo.555.1">composition.cpp</span></strong><span class="koboSpan" id="kobo.556.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.557.1">Chapter3</span></strong><span class="koboSpan" id="kobo.558.1"> on GitHub) builds </span><strong class="source-inline"><span class="koboSpan" id="kobo.559.1">OrderBook</span></strong><span class="koboSpan" id="kobo.560.1">, which basically holds a vector of </span><strong class="source-inline"><span class="koboSpan" id="kobo.561.1">Order</span></strong><span class="koboSpan" id="kobo.562.1"> objects, in two different ways. </span><span class="koboSpan" id="kobo.562.2">The benefit (if used properly) of the inheritance model is that it now inherits all the methods that </span><strong class="source-inline"><span class="koboSpan" id="kobo.563.1">std::vector</span></strong><span class="koboSpan" id="kobo.564.1"> provides while the composition model would need to implement them. </span><span class="koboSpan" id="kobo.564.2">In this example, we demonstrate this by implementing a </span><strong class="source-inline"><span class="koboSpan" id="kobo.565.1">size()</span></strong><span class="koboSpan" id="kobo.566.1"> method in </span><strong class="source-inline"><span class="koboSpan" id="kobo.567.1">CompositionOrderBook</span></strong><span class="koboSpan" id="kobo.568.1">, which calls the </span><strong class="source-inline"><span class="koboSpan" id="kobo.569.1">size()</span></strong><span class="koboSpan" id="kobo.570.1"> method on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">std::vector</span></strong><span class="koboSpan" id="kobo.572.1"> object, while </span><strong class="source-inline"><span class="koboSpan" id="kobo.573.1">InheritanceOrderBook</span></strong><span class="koboSpan" id="kobo.574.1"> inherits it directly </span><span class="No-Break"><span class="koboSpan" id="kobo.575.1">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.576.1">std::vector</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.578.1">
#include &lt;cstdio&gt;
#include &lt;vector&gt;
struct Order { int id; double price; };
class InheritanceOrderBook : public std::vector&lt;Order&gt; { };
class CompositionOrderBook {
  std::vector&lt;Order&gt; orders_;
public:
  auto size() const noexcept {
    return orders_.size();
  }
};
int main() {
  InheritanceOrderBook i_book;
  CompositionOrderBook c_book;
  printf(“InheritanceOrderBook::size():%lu Composi
       tionOrderBook:%lu\n”, i_book.size(), c_book.size());
}</span></pre>
<p><span class="koboSpan" id="kobo.579.1">C++ </span><strong class="bold"><span class="koboSpan" id="kobo.580.1">RTTI</span></strong><span class="koboSpan" id="kobo.581.1"> adds a </span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.582.1">bunch of extra metadata to each class object to extract and use additional information at runtime. </span><span class="koboSpan" id="kobo.582.2">This makes all instances of these objects inefficient, and it is best to turn off RTTI support at the compiler level for low-latency applications. </span><span class="koboSpan" id="kobo.582.3">If the developer needs to attach specific metadata to specific classes or objects, it is best to customize </span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.583.1">the implementation itself instead of adding overhead to the entire application. </span><strong class="source-inline"><span class="koboSpan" id="kobo.584.1">dynamic_cast</span></strong><span class="koboSpan" id="kobo.585.1">, as we discussed before, usually uses the RTTI information to perform the cast and should also </span><span class="No-Break"><span class="koboSpan" id="kobo.586.1">be avoided.</span></span></p>
<h2 id="_idParaDest-77"><a id="_idTextAnchor080"/><span class="koboSpan" id="kobo.587.1">Using compile-time polymorphism</span></h2>
<p><span class="koboSpan" id="kobo.588.1">Let us discuss an alternative to using runtime polymorphism, which is to use templates to achieve compile-time </span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.589.1">polymorphism. </span><span class="koboSpan" id="kobo.589.2">Templates are </span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.590.1">similar to macros, meaning they are expanded before compilation, and because of this, not only is the runtime overhead eliminated but it also unlocks additional compiler optimization opportunities. </span><span class="koboSpan" id="kobo.590.2">Te</span><a id="_idTextAnchor081"/><span class="koboSpan" id="kobo.591.1">mplates make the compiler machine code super-efficient but they come at the cost of additional source code complexity, as well as larger </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">executable sizes.</span></span></p>
<p><span class="koboSpan" id="kobo.593.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.594.1">Curiously Recurring Template Pattern</span></strong><span class="koboSpan" id="kobo.595.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.596.1">CRTP</span></strong><span class="koboSpan" id="kobo.597.1">) facilitates compile-time polymorphism. </span><span class="koboSpan" id="kobo.597.2">Note that the syntax </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.598.1">here is more complicated than using runtime polymorphism using </span><strong class="source-inline"><span class="koboSpan" id="kobo.599.1">virtual</span></strong><span class="koboSpan" id="kobo.600.1"> functions and the base class and derived class relationships are similar but slightly different using the </span><em class="italic"><span class="koboSpan" id="kobo.601.1">CRTP</span></em><span class="koboSpan" id="kobo.602.1">. </span><span class="koboSpan" id="kobo.602.2">A simple example of converting runtime polymorphism into compile-time polymorphism is shown here. </span><span class="koboSpan" id="kobo.602.3">In both cases, the derived classes, </span><strong class="source-inline"><span class="koboSpan" id="kobo.603.1">SpecificRuntimeExample</span></strong><span class="koboSpan" id="kobo.604.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.605.1">SpecificCRTPExample</span></strong><span class="koboSpan" id="kobo.606.1">, override the </span><strong class="source-inline"><span class="koboSpan" id="kobo.607.1">placeOrder()</span></strong><span class="koboSpan" id="kobo.608.1"> method. </span><span class="koboSpan" id="kobo.608.2">The code discussed in this sub-section is</span><a id="_idTextAnchor082"/><span class="koboSpan" id="kobo.609.1"> in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.610.1">crtp.cpp</span></strong><span class="koboSpan" id="kobo.611.1"> file in the GitHub repo for this book under the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">Chapter3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.613.1"> directory.</span></span></p>
<h3><span class="koboSpan" id="kobo.614.1">Runtime polymorphism using virtual functions</span></h3>
<p><span class="koboSpan" id="kobo.615.1">Here, we have an </span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.616.1">example of implementing runtime polymorphism where </span><strong class="source-inline"><span class="koboSpan" id="kobo.617.1">SpecificRuntimeExample</span></strong><span class="koboSpan" id="kobo.618.1"> derives </span><strong class="source-inline"><span class="koboSpan" id="kobo.619.1">RuntimeExample</span></strong><span class="koboSpan" id="kobo.620.1"> and overrides the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.621.1">placeOrder()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.622.1"> method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.623.1">
#include &lt;cstdio&gt;
class RuntimeExample {
public:
  virtual void placeOrder() {
    printf(“RuntimeExample::placeOrder()\n”);
  }
};
class SpecificRuntimeExample : public RuntimeExample {
public:
  void placeOrder() override {
    printf(“SpecificRuntimeExample::placeOrder()\n”);
  }
};</span></pre>
<h3><span class="koboSpan" id="kobo.624.1">Compile-time polymorphism using the CRTP</span></h3>
<p><span class="koboSpan" id="kobo.625.1">Now we implement similar functionality as discussed in the previous section, but instead of using </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.626.1">runtime polymorphism, we use compile-time polymorphism. </span><span class="koboSpan" id="kobo.626.2">Here, we use the CRTP pattern and </span><strong class="source-inline"><span class="koboSpan" id="kobo.627.1">SpecificCRTPExample</span></strong><span class="koboSpan" id="kobo.628.1"> specializes/implements the </span><strong class="source-inline"><span class="koboSpan" id="kobo.629.1">CRTPExample</span></strong><span class="koboSpan" id="kobo.630.1"> interface and has a different implementation of </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">placeOrder()</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.632.1">via </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">actualPlaceOrder()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.634.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.635.1">
template &lt;typename actual_type&gt;
class CRTPExample {
public:
  void placeOrder() {
    static_cast&lt;actual_type*&gt;(this)-&gt;actualPlaceOrder();
  }
  void actualPlaceOrder() {
    printf(“CRTPExample::actualPlaceOrder()\n”);
  }
};
class SpecificCRTPExample : public CRTPExample&lt;Specific
     CRTPExample&gt; {
public:
  void actualPlaceOrder() {
    printf(“SpecificCRTPExample::actualPlaceOrder()\n”);
  }
};</span></pre>
<h3><span class="koboSpan" id="kobo.636.1">Invoking polymorphic methods in the two cases</span></h3>
<p><span class="koboSpan" id="kobo.637.1">Finally, in the </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.638.1">following snippet presented, we show how we would create </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">SpecificRuntimeExample</span></strong><span class="koboSpan" id="kobo.640.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1">SpecificCRTPExample</span></strong><span class="koboSpan" id="kobo.642.1"> objects. </span><span class="koboSpan" id="kobo.642.2">We then invoke runtime and compile-time polymorphism respectively using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.643.1">placeOrder()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.644.1"> method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.645.1">
int main(int, char **) {
  RuntimeExample* runtime_example = new SpecificRuntimeEx
       ample();
  runtime_example-&gt;placeOrder();
  CRTPExample&lt;SpecificCRTPExample&gt; crtp_example;
  crtp_example.placeOrder();
  return 0;
}</span></pre>
<p><span class="koboSpan" id="kobo.646.1">Running this yields the following output, the first line using runtime polymorphism and the second line using compile </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1">time polymorphism:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.648.1">
SpecificRuntimeExample::placeOrder()
SpecificCRTPExample::actualPlaceOrder()</span></pre>
<h2 id="_idParaDest-78"><a id="_idTextAnchor083"/><span class="koboSpan" id="kobo.649.1">Using additional compile-time processing</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.650.1">Template metaprogramming</span></strong><span class="koboSpan" id="kobo.651.1"> is a more general term that means writing code that itself yields </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.652.1">more code. </span><span class="koboSpan" id="kobo.652.2">The benefit here is also to move computations </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.653.1">from runtime to compile time and maximize compiler optimization opportunities and runtime performance. </span><span class="koboSpan" id="kobo.653.2">It is possible to write almost anything with template metaprogramming, but it can get extremely complicated and difficult to understand, maintain, and debug, lead to very long compilation times, and increase the binary size to a very </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">large size.</span></span></p>
<h2 id="_idParaDest-79"><a id="_idTextAnchor084"/><span class="koboSpan" id="kobo.655.1">Handling exceptions</span></h2>
<p><span class="koboSpan" id="kobo.656.1">The C++ exception handling system is designed to detect unexpected error conditions at runtime and either gracefully recover or shut down from that point. </span><span class="koboSpan" id="kobo.656.2">When it comes to low-latency </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.657.1">applications, it is important to evaluate the use of exception handling since while it is true that exception handling incurs the largest latencies during these rare error cases, there can still be some overhead even when exceptions are not raised. </span><span class="koboSpan" id="kobo.657.2">There is some bookkeeping overhead related to the logic used to recover gracefully when exceptions are raised under various scenarios. </span><span class="koboSpan" id="kobo.657.3">With nested functions, exceptions need to be propagated all the way up to the top-most caller function and each stack frame needs to be cleaned up. </span><span class="koboSpan" id="kobo.657.4">This is known as </span><strong class="bold"><span class="koboSpan" id="kobo.658.1">stack unwinding</span></strong><span class="koboSpan" id="kobo.659.1"> and requires the exception handler to track all the </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.660.1">information it needs to walk backward during </span><span class="No-Break"><span class="koboSpan" id="kobo.661.1">an exception.</span></span></p>
<p><span class="koboSpan" id="kobo.662.1">For low-latency applications, exceptions are either disabled per function using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.663.1">throw()</span></strong><span class="koboSpan" id="kobo.664.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">noexcept</span></strong><span class="koboSpan" id="kobo.666.1"> specifications or disabled across the entire program using compiler flags. </span><span class="koboSpan" id="kobo.666.2">This allows the compiler to assume that some or all methods will not throw an exception and hence the processor does not have to worry about saving and tracking recovery information. </span><span class="koboSpan" id="kobo.666.3">Note that using </span><strong class="source-inline"><span class="koboSpan" id="kobo.667.1">noexcept</span></strong><span class="koboSpan" id="kobo.668.1"> or disabling the C++ exception handling system is not without some disadvantages. </span><span class="koboSpan" id="kobo.668.2">For one, usually, the C++ exception handling system does not typically add a lot of extra overhead unless an exception is thrown, so this decision must be made with careful consideration. </span><span class="koboSpan" id="kobo.668.3">Another point is that if a method marked as </span><strong class="source-inline"><span class="koboSpan" id="kobo.669.1">noexcept</span></strong><span class="koboSpan" id="kobo.670.1"> throws an exception for some reason, the exception can no longer be propagated up the stack and instead the program is terminated right there. </span><span class="koboSpan" id="kobo.670.2">What this means is that disabling the C++ exception handling system either partially or fully makes handling failures and exceptions harder and completely the developer’s responsibility. </span><span class="koboSpan" id="kobo.670.3">Usually, what this means is that the developer will still need to make sure that exceptional error conditions are not encountered or handled elsewhere, but the point is that now the developer has explicit control over this and can move it out </span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.671.1">of the critical hot path. </span><span class="koboSpan" id="kobo.671.2">For this reason, it is common that during the development and testing phases, the C++ exception handling system is not disabled, but only during the very last optimization steps do we consider removing </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">exception handling.</span></span></p>
<h2 id="_idParaDest-80"><a id="_idTextAnchor085"/><span class="koboSpan" id="kobo.673.1">Accessing cache and memory</span></h2>
<p><span class="koboSpan" id="kobo.674.1">We have frequently referred to cache performance while discussing different uses of C++ features since </span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.675.1">accessing the main memory is significantly slower than the clock cycles used to execute CPU instructions or access registers or cache storage. </span><span class="koboSpan" id="kobo.675.2">Here are some general points to keep in mind when trying to optimize cache and </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">memory access.</span></span></p>
<h3><span class="koboSpan" id="kobo.677.1">Aligning data</span></h3>
<p><span class="koboSpan" id="kobo.678.1">Variables that are aligned, in that they are placed at memory locations that are multiples of the size </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.679.1">of the variable, are accessed most efficiently. </span><span class="koboSpan" id="kobo.679.2">The term </span><strong class="bold"><span class="koboSpan" id="kobo.680.1">word size</span></strong><span class="koboSpan" id="kobo.681.1"> for processors describes the number of bits read by and processed by processors, which for modern processors is </span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.682.1">either 32-bits or 64-bits. </span><span class="koboSpan" id="kobo.682.2">This is because the processor can read a variable from memory up to the word size in a single read operation. </span><span class="koboSpan" id="kobo.682.3">If the variable is aligned in memory, then the processor does not have to do any extra work to get it into the required register to </span><span class="No-Break"><span class="koboSpan" id="kobo.683.1">be processed.</span></span></p>
<p><span class="koboSpan" id="kobo.684.1">For these reasons, aligned variables are more efficient to handle, and the compiler will take care of automatically aligning variables. </span><span class="koboSpan" id="kobo.684.2">This includes adding padding in between member variables in a class or a struct to keep those variables aligned. </span><span class="koboSpan" id="kobo.684.3">When adding member variables to structures where we expect to have a lot of objects, it is important to consider the extra padding added carefully because the size of the struct will be larger than expected. </span><span class="koboSpan" id="kobo.684.4">The extra space in each instance of this struct’s or class’s objects means that they can have worse cache performance if there are a lot of them. </span><span class="koboSpan" id="kobo.684.5">The recommended approach here would be to reorder the members of the struct so that minimal extra padding is added to keep the </span><span class="No-Break"><span class="koboSpan" id="kobo.685.1">members aligned.</span></span></p>
<p><span class="koboSpan" id="kobo.686.1">We will see an example that orders the same members inside a structure in three different ways – one where there is a lot of additional padding added to keep each variable aligned, another where the developer reorders the member variables to minimize space waste due to compiler-added padding, and, finally, where we use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.687.1">pack()</span></strong><span class="koboSpan" id="kobo.688.1"> pragma to eliminate </span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.689.1">all padding. </span><span class="koboSpan" id="kobo.689.2">This code is available in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.690.1">Chapter3/alignment.cpp</span></strong><span class="koboSpan" id="kobo.691.1"> file in the GitHub repository for </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">this book:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.693.1">
#include &lt;cstdio&gt;
#include &lt;cstdint&gt;
#include &lt;cstddef&gt;
struct PoorlyAlignedData {
  char c;
  uint16_t u;
  double d;
  int16_t i;
};
struct WellAlignedData {
  double d;
  uint16_t u;
  int16_t i;
  char c;
};
#pragma pack(push, 1)
struct PackedData {
  double d;
  uint16_t u;
  int16_t i;
  char c;
};
#pragma pack(pop)
int main() {
  printf(“PoorlyAlignedData c:%lu u:%lu d:%lu i:%lu
       size:%lu\n”,
         offsetof(struct PoorlyAlignedData,c), offsetof
              (struct PoorlyAlignedData,u), offsetof(struct
              PoorlyAlignedData,d), offsetof(struct PoorlyA
              lignedData,i), sizeof(PoorlyAlignedData));
  printf(“WellAlignedData d:%lu u:%lu i:%lu c:%lu
       size:%lu\n”,
         offsetof(struct WellAlignedData,d), offsetof
              (struct WellAlignedData,u), offsetof(struct
              WellAlignedData,i), offsetof(struct WellAligned
              Data,c), sizeof(WellAlignedData));
  printf(“PackedData d:%lu u:%lu i:%lu c:%lu size:%lu\n”,
         offsetof(struct PackedData,d), offsetof(struct
              PackedData,u), offsetof(struct PackedData,i),
              offsetof(struct PackedData,c), sizeof
              (PackedData));
}</span></pre>
<p><span class="koboSpan" id="kobo.694.1">This code outputs the following on my system, displaying the offsets of the different data members </span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.695.1">in each of the three designs of the same structure. </span><span class="koboSpan" id="kobo.695.2">Note that the first version has an extra 11 bytes of padding, the second one only has an extra 3 bytes of padding due to the reordering, and the last version has no </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">extra padding:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.697.1">
PoorlyAlignedData c:0 u:2 d:8 i:16 size:24
WellAlignedData d:0 u:8 i:10 c:12 size:16
PackedData d:0 u:8 i:10 c:12 size:13</span></pre>
<h3><span class="koboSpan" id="kobo.698.1">Accessing data</span></h3>
<p><span class="koboSpan" id="kobo.699.1">Cache-friendly data access (read and/or write) is when the data is accessed sequentially or somewhat </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.700.1">sequentially. </span><span class="koboSpan" id="kobo.700.2">If the data is accessed backward, it is less efficient than this, and cache performance is worse if the data is accessed randomly. </span><span class="koboSpan" id="kobo.700.3">This is something to consider, especially when accessing multi-dimensional arrays of objects and/or objects residing in a container with a non-trivial underlying storage of </span><span class="No-Break"><span class="koboSpan" id="kobo.701.1">the objects.</span></span></p>
<p><span class="koboSpan" id="kobo.702.1">For instance, accessing elements in an array is significantly more efficient than accessing elements in a linked list, tree, or hash-map container because of the contiguous memory storage versus random memory storage locations. </span><span class="koboSpan" id="kobo.702.2">From the perspective of algorithmic complexity, searching linearly in an array is less efficient than using a hash map since the array search has </span><strong class="source-inline"><span class="koboSpan" id="kobo.703.1">O(n)</span></strong><span class="koboSpan" id="kobo.704.1"> and the hash map has </span><strong class="source-inline"><span class="koboSpan" id="kobo.705.1">O(1)</span></strong><span class="koboSpan" id="kobo.706.1"> theoretical algorithmic complexity.  </span><span class="koboSpan" id="kobo.706.2">However, if the number of elements is small enough, then using the array still yields better performance, a large reason being due to cache performance and </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1">algorithm overhead.</span></span></p>
<h3><span class="koboSpan" id="kobo.708.1">Using large data structures</span></h3>
<p><span class="koboSpan" id="kobo.709.1">When dealing with large multi-dimensional matrix datasets, for instance, with linear algebra </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.710.1">operations, cache access performance dominates the performance of the operation. </span><span class="koboSpan" id="kobo.710.2">Often, the actual algorithm implementation for matrix operations is different from that used in classic texts to reorder the matrix access operations for cache performance. </span><span class="koboSpan" id="kobo.710.3">The best approach here is to measure the performance of different algorithms and access patterns and find the one that performs best under different matrix dimensions, cache contention conditions, and </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">so on.</span></span></p>
<h3><span class="koboSpan" id="kobo.712.1">Grouping variables together</span></h3>
<p><span class="koboSpan" id="kobo.713.1">When designing </span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.714.1">classes and method or non-method functions, grouping variables that are accessed together greatly improves cache performance by reducing the number of cache misses. </span><span class="koboSpan" id="kobo.714.2">We discussed that preferring local variables over global, static, and dynamically allocated memory leads </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.715.1">to better </span><span class="No-Break"><span class="koboSpan" id="kobo.716.1">cache performance.</span></span></p>
<h3><span class="koboSpan" id="kobo.717.1">Grouping functions together</span></h3>
<p><span class="koboSpan" id="kobo.718.1">Grouping class member functions and non-member functions together so that functions that are used </span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.719.1">together are close together in memory also leads to better cache performance. </span><span class="koboSpan" id="kobo.719.2">This is because functions are placed in memory addresses depending on where they are in the developer’s source code and functions next to each other get assigned addresses close to </span><span class="No-Break"><span class="koboSpan" id="kobo.720.1">each other.</span></span></p>
<h2 id="_idParaDest-81"><a id="_idTextAnchor086"/><span class="koboSpan" id="kobo.721.1">Dynamically allocating memory</span></h2>
<p><span class="koboSpan" id="kobo.722.1">Dynamically allocated memory has several good use cases, specifically when the size of containers is not </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.723.1">known at compile time and when they can grow or shrink in size during the application instance’s life cycle. </span><span class="koboSpan" id="kobo.723.2">Dynamically allocated memory is also important for objects that are</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.724.1"> very large and take up a lot of stack space. </span><span class="koboSpan" id="kobo.724.2">Dynamically allocated memory can have a place in low-latency applications if allocation and deallocation are not done on the critical path and an allocated block of memory is used so that the cache performance is </span><span class="No-Break"><span class="koboSpan" id="kobo.725.1">not hurt.</span></span></p>
<p><span class="koboSpan" id="kobo.726.1">A disadvantage of dynamically allocated memory is that the process of allocating and deallocating memory blocks is </span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.727.1">awfully slow. </span><span class="koboSpan" id="kobo.727.2">The repeated allocation and deallocation of memory blocks of varied sizes fragments the heap, that is, it creates free memory blocks of different sizes interspersed with allocated </span><span class="No-Break"><span class="koboSpan" id="kobo.728.1">memory blocks.</span></span></p>
<p><span class="koboSpan" id="kobo.729.1">A fragmented heap makes the allocation and deallocation process even slower. </span><span class="koboSpan" id="kobo.729.2">Allocated memory blocks might not be optimally aligned unless the developer is careful about it. </span><span class="koboSpan" id="kobo.729.3">Dynamically allocated memory accessed through pointers causes pointer aliasing and prevents compiler optimizations, as we have seen before. </span><span class="koboSpan" id="kobo.729.4">There are other disadvantages of dynamically allocated memory, but these are the biggest ones for low-latency applications. </span><span class="koboSpan" id="kobo.729.5">Hence, it is best to avoid dynamically allocated memory completely when it comes to low-latency applications, or at the very least use it carefully </span><span class="No-Break"><span class="koboSpan" id="kobo.730.1">and sparingly.</span></span></p>
<h2 id="_idParaDest-82"><a id="_idTextAnchor087"/><span class="koboSpan" id="kobo.731.1">Multi-threading</span></h2>
<p><span class="koboSpan" id="kobo.732.1">If low-latency applications use multi-threading, the threads and the interactions between these threads should be designed carefully. </span><span class="koboSpan" id="kobo.732.2">Starting and stopping threads takes time, so it is best to avoid launching new threads when they are needed and instead use a thread pool of worker </span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.733.1">threads. </span><span class="koboSpan" id="kobo.733.2">Task switching or context switching is when one thread is paused or blocked, and another thread starts executing in its place. </span><span class="koboSpan" id="kobo.733.3">Context switching is very expensive since it requires the OS to save the state of the current thread, load the state of the next thread, start the processing, and so on, and is usually accompanied by memory reads and writes, cache misses, instruction pipeline stalls, and </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.735.1">Synchronization using locks and mutexes between threads is also expensive and involves additional checks around concurrent access and context-switching overhead. </span><span class="koboSpan" id="kobo.735.2">When multiple threads access shared resources, they need to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.736.1">volatile</span></strong><span class="koboSpan" id="kobo.737.1"> keyword and that also prevents several compiler optimizations. </span><span class="koboSpan" id="kobo.737.2">Additionally, different threads can compete for the same cache lines and invalidate each other’s caches and this contention leads to terrible cache performance. </span><span class="koboSpan" id="kobo.737.3">Each thread gets its own stack, so it’s best to keep the shared data to a minimum and allocate variables locally on the </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">thread’s stack.</span></span></p>
<h1 id="_idParaDest-83"><a id="_idTextAnchor088"/><span class="koboSpan" id="kobo.739.1">Maximizing C++ compiler optimization parameters</span></h1>
<p><span class="koboSpan" id="kobo.740.1">In this last section, we will understand how advanced and amazing modern C++ compilers are at </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.741.1">optimizing the C++ code that the developers write. </span><span class="koboSpan" id="kobo.741.2">We will understand how compilers optimize the C++ code during the compilation, linking, and optimization stages to generate the most efficient machine code possible. </span><span class="koboSpan" id="kobo.741.3">We will understand how compilers optimize high-level C++ code and when they fail to do the best job. </span><span class="koboSpan" id="kobo.741.4">We will follow that up with a discussion on what the application developer can do to aid the compilers in their optimization task. </span><span class="koboSpan" id="kobo.741.5">Finally, we will look at different options available in modern C++ compilers </span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.742.1">by looking specifically at the </span><strong class="bold"><span class="koboSpan" id="kobo.743.1">GNU compiler</span></strong><span class="koboSpan" id="kobo.744.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.745.1">GCC</span></strong><span class="koboSpan" id="kobo.746.1">). </span><span class="koboSpan" id="kobo.746.2">Let us start by understanding how compilers optimize our </span><span class="No-Break"><span class="koboSpan" id="kobo.747.1">C++ program.</span></span></p>
<h2 id="_idParaDest-84"><a id="_idTextAnchor089"/><span class="koboSpan" id="kobo.748.1">Understanding how compilers optimize</span></h2>
<p><span class="koboSpan" id="kobo.749.1">In this sub-section, we will understand the different compiler optimization techniques that the compiler employs during its many passes over the high-level C++ code. </span><span class="koboSpan" id="kobo.749.2">The compiler typically first performs local optimizations and then tries to globally optimize these smaller code sections. </span><span class="koboSpan" id="kobo.749.3">It does so over several passes through the translated machine code during the pre-processing, compilation, linking, and optimization stages. </span><span class="koboSpan" id="kobo.749.4">Broadly, most compiler optimization techniques have some common themes, some of which overlap and some of which conflict with each other, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.750.1">at next.</span></span></p>
<h3><span class="koboSpan" id="kobo.751.1">Optimizing the common cases</span></h3>
<p><span class="koboSpan" id="kobo.752.1">This concept applies to software development too and helps the compiler optimize the code better. </span><span class="koboSpan" id="kobo.752.2">If the </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.753.1">compiler can understand which code paths the program execution will spend most of its time in, it can optimize the common path to be faster even if it slows down the paths that are rarely taken. </span><span class="koboSpan" id="kobo.753.2">This results in better performance overall, but typically this is harder for the compiler to achieve at compilation time since it is not obvious which code paths are expected to be more likely unless the developer adds directives to specify this. </span><span class="koboSpan" id="kobo.753.3">We will discuss the hints that a developer can provide to the compiler to help specify which code paths are expected to be more likely </span><span class="No-Break"><span class="koboSpan" id="kobo.754.1">during runtime.</span></span></p>
<h3><span class="koboSpan" id="kobo.755.1">Minimizing branching</span></h3>
<p><span class="koboSpan" id="kobo.756.1">Modern processors typically prefetch data and instructions before they are required so that the processors can execute instructions as quickly as possible. </span><span class="koboSpan" id="kobo.756.2">However, when there are jumps and </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.757.1">branches (conditional and unconditional), the processor cannot know which instructions and data will be needed ahead of time with 100% certainty. </span><span class="koboSpan" id="kobo.757.2">What this means is that sometimes the processor incorrectly predicts the branch taken and thus the instructions and data prefetched are incorrect. </span><span class="koboSpan" id="kobo.757.3">When this happens, there is an extra penalty incurred since now the processor must remove the instructions and data that were fetched incorrectly and replace them with the correct instructions and data and then execute them after that. </span><span class="koboSpan" id="kobo.757.4">Techniques such as loop unrolling, inlining, and branch prediction hints help reduce branching and the misprediction of branching and improve performance. </span><span class="koboSpan" id="kobo.757.5">We will explore these concepts in more detail later in </span><span class="No-Break"><span class="koboSpan" id="kobo.758.1">this section.</span></span></p>
<p><span class="koboSpan" id="kobo.759.1">There are several cases in which a developer can refactor code in such a way that they avoid branching and achieve the same behavior. </span><span class="koboSpan" id="kobo.759.2">Sometimes, these optimization opportunities are only available to the developer, who understands the code and behavior at a deeper level than the compiler. </span><span class="koboSpan" id="kobo.759.3">A very simple example of how to convert a code block that uses branching and transform it to avoid branching is presented next. </span><span class="koboSpan" id="kobo.759.4">Here we have an enumeration to track side for an execution and we track the last bought/sold quantity, as well as updating </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.760.1">the position in two different ways. </span><span class="koboSpan" id="kobo.760.2">The first way uses a branch on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.761.1">fill_side</span></strong><span class="koboSpan" id="kobo.762.1"> variable and the second method avoids that branching by assuming that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.763.1">fill_side</span></strong><span class="koboSpan" id="kobo.764.1"> variable can only have </span><strong class="source-inline"><span class="koboSpan" id="kobo.765.1">BUY</span></strong><span class="koboSpan" id="kobo.766.1">/</span><strong class="source-inline"><span class="koboSpan" id="kobo.767.1">SELL</span></strong><span class="koboSpan" id="kobo.768.1"> values and can be cast to integers to be indexed into an array. </span><span class="koboSpan" id="kobo.768.2">This code can be found in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.769.1">Chapter3/branch.cpp</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.770.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.771.1">
#include &lt;cstdio&gt;
#include &lt;cstdint&gt;
#include &lt;cstdlib&gt;
enum class Side : int16_t { BUY = 1, SELL = -1 };
int main() {
  const auto fill_side = (rand() % 2 ? </span><span class="koboSpan" id="kobo.771.2">Side::BUY : Side
       ::SELL);
  const int fill_qty = 10;
  printf(“fill_side:%s fill_qty:%d.\n”, (fill_side == Side
       ::BUY ? </span><span class="koboSpan" id="kobo.771.3">“BUY” : (fill_side == Side::SELL ? </span><span class="koboSpan" id="kobo.771.4">“SELL” :
         “INVALID”)), fill_qty);
  { // with branching
    int last_buy_qty = 0, last_sell_qty = 0, position = 0;
    if (fill_side == Side::BUY) {
      position += fill_qty; last_buy_qty = fill_qty;
    } else if (fill_side == Side::SELL) {
      position -= fill_qty; last_sell_qty = fill_qty; }
    printf(“With branching - position:%d last-buy:%d last-
         sell:%d.\n”, position, last_buy_qty,
           last_sell_qty);
  }
  { // without branching
    int last_qty[3] = {0, 0, 0}, position = 0;
    auto sideToInt = [](Side side) noexcept { return
         static_cast&lt;int16_t&gt;(side); };
    const auto int_fill_side = sideToInt(fill_side);
    position += int_fill_side * fill_qty;
    last_qty[int_fill_side + 1] = fill_qty;
    printf(“Without branching - position:%d last-buy:%d
         last-sell:%d.\n”, position, last_qty[sideToInt
           (Side::BUY) + 1], last_qty[side
             ToInt(Side::SELL)+
             1]);
  }
}</span></pre>
<p><span class="koboSpan" id="kobo.772.1">And both the </span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.773.1">branching and branchless implementations compute the </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">same values:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.775.1">
fill_side:BUY fill_qty:10.
</span><span class="koboSpan" id="kobo.775.2">With branching - position:10 last-buy:10 last-sell:0.
</span><span class="koboSpan" id="kobo.775.3">Without branching - position:10 last-buy:10 last-sell:0.</span></pre>
<h3><span class="koboSpan" id="kobo.776.1">Reordering and scheduling instructions</span></h3>
<p><span class="koboSpan" id="kobo.777.1">The compiler can take advantage of advanced processors by re-ordering instructions in such a way that </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.778.1">parallel processing </span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.779.1">can happen at the instruction, memory, and thread levels. </span><span class="koboSpan" id="kobo.779.2">The compiler can detect dependencies between code blocks and re-order them so that the program still works correctly but executes faster by executing instructions and processing data in parallel at the processor level. </span><span class="koboSpan" id="kobo.779.3">Modern processors can reorder instructions even without the compiler doing so, but it helps if the compiler can make it easier for the processors to do so as well. </span><span class="koboSpan" id="kobo.779.4">The main objective here is to prevent stalls and bubbles in modern processors, which have multiple pipelined processors, by choosing and ordering instructions in such a way as to preserve the original </span><span class="No-Break"><span class="koboSpan" id="kobo.780.1">logical flow.</span></span></p>
<p><span class="koboSpan" id="kobo.781.1">A simple example of how an expression can be reordered to take advantage of parallelism is shown here. </span><span class="koboSpan" id="kobo.781.2">Note that this is somewhat hypothetical since the actual implementation of this will vary greatly depending on the processor and </span><span class="No-Break"><span class="koboSpan" id="kobo.782.1">the compiler:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.783.1">
x = a + b + c + d + e + f;</span></pre>
<p><span class="koboSpan" id="kobo.784.1">As it is written, this expression has a data dependency and would be executed sequentially, roughly as follows, and cost 5 </span><span class="No-Break"><span class="koboSpan" id="kobo.785.1">clock cycles:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.786.1">
x = a + b;
x = x + c;
x = x + d;
x = x +e;
x = x + f;</span></pre>
<p><span class="koboSpan" id="kobo.787.1">It can be re-ordered into the following instructions, and assuming the advanced processor can perform two additions at a time, can be reduced to three clock cycles. </span><span class="koboSpan" id="kobo.787.2">This is because two operations such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.788.1">x = a + b;</span></strong><span class="koboSpan" id="kobo.789.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.790.1">p = c +d;</span></strong><span class="koboSpan" id="kobo.791.1"> can be performed in parallel since they are independent of </span><span class="No-Break"><span class="koboSpan" id="kobo.792.1">each other:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.793.1">
x = a + b; p = c + d;
q = e + f; x = x + p;
x = x + q;</span></pre>
<h3><span class="koboSpan" id="kobo.794.1">Using special instructions depending on the architecture</span></h3>
<p><span class="koboSpan" id="kobo.795.1">During the compilation process, the compiler can choose which CPU instructions to use to implement </span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.796.1">the high-level program logic. </span><span class="koboSpan" id="kobo.796.2">When the compiler generates an executable for a specific architecture, it can use special instructions that the architecture supports. </span><span class="koboSpan" id="kobo.796.3">This means there is an opportunity to generate even more efficient instruction sequences, which leverage the special instructions that the architecture provides. </span><span class="koboSpan" id="kobo.796.4">We will look at how to specify this in the </span><em class="italic"><span class="koboSpan" id="kobo.797.1">Learning about compiler optimization </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.798.1">flags</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.799.1"> section.</span></span></p>
<h3><span class="koboSpan" id="kobo.800.1">Vectorization</span></h3>
<p><span class="koboSpan" id="kobo.801.1">Modern processors can use vector registers to perform multiple calculations on multiple pieces of </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.802.1">data in parallel. </span><span class="koboSpan" id="kobo.802.2">For instance, the SSE2 instruction set has 128-bit vector registers, which can be used to perform multiple operations on multiple integers or floating values depending on the size of these types. </span><span class="koboSpan" id="kobo.802.3">Extending this further, the AVX2 instruction set, for example, has 256-bit vector registers and can support a higher degree of vectorized operations. </span><span class="koboSpan" id="kobo.802.4">This optimization can be technically considered as part of the discussion in the </span><em class="italic"><span class="koboSpan" id="kobo.803.1">Using special instructions depending on the architecture</span></em><span class="koboSpan" id="kobo.804.1"> section </span><span class="No-Break"><span class="koboSpan" id="kobo.805.1">from before.</span></span></p>
<p><span class="koboSpan" id="kobo.806.1">To understand vectorization even better, let us present the following very simple example of a loop that operates on two arrays and stores the result in another array (</span><strong class="source-inline"><span class="koboSpan" id="kobo.807.1">vector.cpp</span></strong><span class="koboSpan" id="kobo.808.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.809.1">Chapter3</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.810.1">in GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.811.1">
  const size_t size = 1024;
  float x[size], a[size], b[size];
  for (size_t i = 0; i &lt; size; ++i) {
    x[i] = a[i] + b[i];
  }</span></pre>
<p><span class="koboSpan" id="kobo.812.1">For architectures that support special vector registers such as the SSE2 instruction set we discussed before, it can hold 4 4-byte float values simultaneously and perform 4 additions at a time. </span><span class="koboSpan" id="kobo.812.2">In this case, the compiler can leverage the vectorization optimization technique and re-write </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.813.1">this as the following with loop unrolling to use the SSE2 </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">instruction set:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.815.1">
  for (size_t i = 0; i &lt; size; i += 4) {
    x[i] = a[i] + b[i];
    x[i + 1] = a[i + 1] + b[i + 1];
    x[i + 2] = a[i + 2] + b[i + 2];
    x[i + 3] = a[i + 3] + b[i + 3];</span></pre>
<h3><span class="koboSpan" id="kobo.816.1">Strength reduction</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.817.1">Strength reduction</span></strong><span class="koboSpan" id="kobo.818.1"> is a term used to describe compiler optimizations where complex operations that are </span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.819.1">quite expensive are replaced by instructions that are simpler </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.820.1">and cheaper to improve performance. </span><span class="koboSpan" id="kobo.820.2">A classic example is one in which the compiler replaces operations involving division by some value with multiplication by the reciprocal of that value. </span><span class="koboSpan" id="kobo.820.3">Another example would be replacing multiplication by a loop index with an </span><span class="No-Break"><span class="koboSpan" id="kobo.821.1">addition operation.</span></span></p>
<p><span class="koboSpan" id="kobo.822.1">The simplest example we could think of is presented here, where we try to convert a price from its double notation into its integer notation by dividing the floating value by its minimum valid price increment. </span><span class="koboSpan" id="kobo.822.2">The variant that demonstrates the strength reduction that a compiler would perform is a simple multiplication instead of a division. </span><span class="koboSpan" id="kobo.822.3">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.823.1">inv_min_price_increment = 1 / min_price_increment;</span></strong><span class="koboSpan" id="kobo.824.1"> is a </span><strong class="source-inline"><span class="koboSpan" id="kobo.825.1">constexpr</span></strong><span class="koboSpan" id="kobo.826.1"> expression, so it is not evaluated at runtime. </span><span class="koboSpan" id="kobo.826.2">This code is available in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.827.1">Chapter3/strength.cpp</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.828.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.829.1">
#include &lt;cstdint&gt;
int main() {
  const auto price = 10.125; // prices are like: 10.125,
       10.130, 10.135...
</span><span class="koboSpan" id="kobo.829.2">  constexpr auto min_price_increment = 0.005;
  [[maybe_unused]] int64_t int_price = 0;
  // no strength reduction
  int_price = price / min_price_increment;
  // strength reduction
  constexpr auto inv_min_price_increment = 1 /
       min_price_increment;
  int_price = price * inv_min_price_increment;
}</span></pre>
<h3><span class="koboSpan" id="kobo.830.1">Inlining</span></h3>
<p><span class="koboSpan" id="kobo.831.1">Calling functions is expensive, </span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.832.1">as we have already seen before. </span><span class="koboSpan" id="kobo.832.2">There are </span><span class="No-Break"><span class="koboSpan" id="kobo.833.1">several steps:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.834.1">Saving the current state of variables </span><span class="No-Break"><span class="koboSpan" id="kobo.835.1">and execution</span></span></li>
<li><span class="koboSpan" id="kobo.836.1">Loading the variables and instructions from the function </span><span class="No-Break"><span class="koboSpan" id="kobo.837.1">being called</span></span></li>
<li><span class="koboSpan" id="kobo.838.1">Executing them and possibly returning back values and resuming execution after the </span><span class="No-Break"><span class="koboSpan" id="kobo.839.1">function call</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.840.1">The compiler tries to replace a call to a function with the body of the function where possible to remove this overhead associated with calling functions and optimize performance. </span><span class="koboSpan" id="kobo.840.2">Not only that but now that it has replaced a call to a function with the actual body of the function, that opens room for more optimizations since the compiler can inspect this new larger </span><span class="No-Break"><span class="koboSpan" id="kobo.841.1">code block.</span></span></p>
<h3><span class="koboSpan" id="kobo.842.1">Constant folding and constant propagation</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.843.1">Constant folding</span></strong><span class="koboSpan" id="kobo.844.1"> is a no-brainer optimization technique and applies when there are expressions whose </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.845.1">output can be computed entirely at compile time that do not depend </span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.846.1">on runtime branches or variables. </span><span class="koboSpan" id="kobo.846.2">Then, the compiler computes these expressions at compile time and replaces the evaluation of these expressions with the compile-time constant </span><span class="No-Break"><span class="koboSpan" id="kobo.847.1">output value.</span></span></p>
<p><span class="koboSpan" id="kobo.848.1">A similar and closely related compiler optimization tracks values in the code that are known to be compile-time constants and tries to propagate those constant values and unlock additional optimization opportunities. </span><span class="koboSpan" id="kobo.848.2">This optimization technique is known as </span><strong class="bold"><span class="koboSpan" id="kobo.849.1">constant propagation</span></strong><span class="koboSpan" id="kobo.850.1">. </span><span class="koboSpan" id="kobo.850.2">An example </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.851.1">would be loop unrolling if the </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.852.1">compiler can determine the starting value, incremental value, or stopping value of the </span><span class="No-Break"><span class="koboSpan" id="kobo.853.1">loop iterator.</span></span></p>
<h3><span class="koboSpan" id="kobo.854.1">Dead Code Elimination (DCE)</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.855.1">DCE</span></strong><span class="koboSpan" id="kobo.856.1"> applies when the compiler can detect code blocks that have no impact on the program behavior. </span><span class="koboSpan" id="kobo.856.2">This can </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.857.1">be due to code blocks that are never needed or </span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.858.1">code blocks where the calculations do not end up being used or affect the outcome. </span><span class="koboSpan" id="kobo.858.2">Once the compiler detects such </span><em class="italic"><span class="koboSpan" id="kobo.859.1">dead</span></em><span class="koboSpan" id="kobo.860.1"> code blocks, it can remove them and boost program performance. </span><span class="koboSpan" id="kobo.860.2">Modern compilers emit warnings when the outcome of running some code ends up not being used to help developers find such cases, but the compiler cannot detect all of these cases at compile time and there are still opportunities for DOE once it is translated into machine </span><span class="No-Break"><span class="koboSpan" id="kobo.861.1">code instructions.</span></span></p>
<h3><span class="koboSpan" id="kobo.862.1">Common Subexpression Elimination (CSE)</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.863.1">CSE</span></strong><span class="koboSpan" id="kobo.864.1"> is a specific optimization technique where the compiler finds duplicated sets of instructions or </span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.865.1">calculations. </span><span class="koboSpan" id="kobo.865.2">Here, the compiler restructures </span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.866.1">the code to remove this redundancy by computing the result only once and then using the value where it </span><span class="No-Break"><span class="koboSpan" id="kobo.867.1">is required.</span></span></p>
<h3><span class="koboSpan" id="kobo.868.1">Peephole optimizations</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.869.1">Peephole optimization</span></strong><span class="koboSpan" id="kobo.870.1"> is a relatively generic compiler optimization term that refers to a compiler optimization </span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.871.1">technique where the compiler tries to search for </span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.872.1">local optimizations in short sequences of instructions. </span><span class="koboSpan" id="kobo.872.2">We use the term local because the compiler does not necessarily try to understand the entire program and optimize it globally. </span><span class="koboSpan" id="kobo.872.3">Of course, however, by repeatedly and iteratively performing peephole optimizations, the compiler can achieve a decent degree of optimization at a </span><span class="No-Break"><span class="koboSpan" id="kobo.873.1">global scale.</span></span></p>
<h3><span class="koboSpan" id="kobo.874.1">Tail call optimization</span></h3>
<p><span class="koboSpan" id="kobo.875.1">We know that function calls are not cheap because they have overhead associated with passing parameters and results and affect the cache performance and processor pipeline. </span><strong class="bold"><span class="koboSpan" id="kobo.876.1">Tail call optimization</span></strong><span class="koboSpan" id="kobo.877.1"> refers to compiler optimization techniques in which recursive function calls are </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.878.1">replaced by loops. </span><span class="koboSpan" id="kobo.878.2">This has obvious performance </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.879.1">benefits such as eliminating function call overheads and stack operations and avoids possible stack overflow cases. </span><span class="koboSpan" id="kobo.879.2">The following simple example of a recursive factorial implementation. </span><span class="koboSpan" id="kobo.879.3">For now, you can ignore the </span><strong class="source-inline"><span class="koboSpan" id="kobo.880.1">__attribute__ ((noinline))</span></strong><span class="koboSpan" id="kobo.881.1"> attribute, which is there to explicitly prevent the compiler from inlining the </span><strong class="source-inline"><span class="koboSpan" id="kobo.882.1">factorial()</span></strong><span class="koboSpan" id="kobo.883.1"> function directly into </span><strong class="source-inline"><span class="koboSpan" id="kobo.884.1">main()</span></strong><span class="koboSpan" id="kobo.885.1">. </span><span class="koboSpan" id="kobo.885.2">You can find this example in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.886.1">Chapter3/tail_call.cpp</span></strong><span class="koboSpan" id="kobo.887.1"> source file </span><span class="No-Break"><span class="koboSpan" id="kobo.888.1">on GitHub:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.889.1">
auto __attribute__ ((noinline)) factorial(unsigned n) -&gt;
     unsigned {
  return (n ? </span><span class="koboSpan" id="kobo.889.2">n * factorial(n - 1) : 1);
}
int main() {
  [[maybe_unused]] volatile auto res = factorial(100);
}</span></pre>
<p><span class="koboSpan" id="kobo.890.1">For this implementation, we would expect that in the machine code for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.891.1">factorial()</span></strong><span class="koboSpan" id="kobo.892.1"> function, we would find a call to itself, but when compiled with optimization turned on, the compiler performs tail call optimization and implements the </span><strong class="source-inline"><span class="koboSpan" id="kobo.893.1">factorial()</span></strong><span class="koboSpan" id="kobo.894.1"> function as a loop and not a recursion. </span><span class="koboSpan" id="kobo.894.2">To observe that machine code, you can compile this code with something </span><span class="No-Break"><span class="koboSpan" id="kobo.895.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.896.1">
g++ -S -Wall -O3 tail_call.cpp ; cat tail_call.s</span></pre>
<p><span class="koboSpan" id="kobo.897.1">And in that </span><strong class="source-inline"><span class="koboSpan" id="kobo.898.1">tail_call.s</span></strong><span class="koboSpan" id="kobo.899.1"> file, you will see the call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.900.1">factorial()</span></strong><span class="koboSpan" id="kobo.901.1"> in </span><strong class="source-inline"><span class="koboSpan" id="kobo.902.1">main()</span></strong><span class="koboSpan" id="kobo.903.1"> to be something like the following example. </span><span class="koboSpan" id="kobo.903.2">If this is your first time looking at assembly code, then let us quickly describe the instructions you </span><span class="No-Break"><span class="koboSpan" id="kobo.904.1">will encounter.</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.905.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.906.1">movl</span></strong><span class="koboSpan" id="kobo.907.1"> instruction moves a value into a register (100 in the </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">following block)</span></span></li>
<li><span class="koboSpan" id="kobo.909.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.910.1">call</span></strong><span class="koboSpan" id="kobo.911.1"> instruction calls a function (</span><strong class="source-inline"><span class="koboSpan" id="kobo.912.1">factorial()</span></strong><span class="koboSpan" id="kobo.913.1"> with name mangling (step where the C++ compiler changes the function names in intermediate code) and the parameter is passed in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.914.1">edi</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.915.1"> register)</span></span></li>
<li><span class="koboSpan" id="kobo.916.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.917.1">testl</span></strong><span class="koboSpan" id="kobo.918.1"> instruction compares two registers and sets the zero flag if </span><span class="No-Break"><span class="koboSpan" id="kobo.919.1">they’re equal</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.920.1">je</span></strong><span class="koboSpan" id="kobo.921.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.922.1">jne</span></strong><span class="koboSpan" id="kobo.923.1"> check </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.924.1">whether the </span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.925.1"> zero flag is set and jump to the specified memory address if it is (</span><strong class="source-inline"><span class="koboSpan" id="kobo.926.1">je</span></strong><span class="koboSpan" id="kobo.927.1">) or jump to the specified memory address if it is </span><span class="No-Break"><span class="koboSpan" id="kobo.928.1">not (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.929.1">jne</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.931.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.932.1">ret</span></strong><span class="koboSpan" id="kobo.933.1"> instruction returns from the function and the return value is in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.934.1">eax</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.935.1"> register:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.936.1">
main:</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.937.1">
.LFB1</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.938.1">
    Movl    $100, %edi</span></pre><pre class="source-code"><span class="koboSpan" id="kobo.939.1">
    Call    _Z9factorialj</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.940.1">When you look at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.941.1">factorial()</span></strong><span class="koboSpan" id="kobo.942.1"> function itself, you will find a loop (the </span><strong class="source-inline"><span class="koboSpan" id="kobo.943.1">je</span></strong><span class="koboSpan" id="kobo.944.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.945.1">jne</span></strong><span class="koboSpan" id="kobo.946.1"> instructions) instead of an additional </span><strong class="source-inline"><span class="koboSpan" id="kobo.947.1">call</span></strong><span class="koboSpan" id="kobo.948.1"> instruction </span><span class="No-Break"><span class="koboSpan" id="kobo.949.1">to itself:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.950.1">
_Z9factorialj:
.LFB0:
    Movl    $1, %eax
    testl    %edi, %edi
    je    .L4
.L3:
    Imull    %edi, %eax
    subl    $1, %edi
    jne    .L3
    ret
.L4:
    ret</span></pre>
<h3><span class="koboSpan" id="kobo.951.1">Loop unrolling</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.952.1">Loop unrolling</span></strong><span class="koboSpan" id="kobo.953.1"> duplicates the body of the loop multiple times. </span><span class="koboSpan" id="kobo.953.2">Sometimes, it is not possible for the compiler to know at compile time how many times the loop will be executed – in which case, it </span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.954.1">will partially unroll the loop. </span><span class="koboSpan" id="kobo.954.2">For loops where the loop </span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.955.1">body is small and/or where it can be determined that the number of times that the loop will execute is low, the compiler can completely unroll the loop. </span><span class="koboSpan" id="kobo.955.2">This avoids the need for checking the loop counters and the overhead associated with conditional branching or looping. </span><span class="koboSpan" id="kobo.955.3">This is like function inlining where the call to the function is replaced by the body of the function. </span><span class="koboSpan" id="kobo.955.4">For loop unrolling, the entire loop is rolled out and replaces the conditional </span><span class="No-Break"><span class="koboSpan" id="kobo.956.1">loop body.</span></span></p>
<h3><span class="koboSpan" id="kobo.957.1">Additional loop optimizations</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.958.1">Loop unrolling</span></strong><span class="koboSpan" id="kobo.959.1"> is the primary loop-related optimization technique employed by compilers but there are additional </span><span class="No-Break"><span class="koboSpan" id="kobo.960.1">loop optimizations:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.961.1">Loop fission</span></strong><span class="koboSpan" id="kobo.962.1"> breaks a </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.963.1">loop down into multiple loops operating on smaller sets of data to improve cache </span><span class="No-Break"><span class="koboSpan" id="kobo.964.1">reference locality.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.965.1">Loop fusion</span></strong><span class="koboSpan" id="kobo.966.1"> does the </span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.967.1">opposite, where if two adjacent loops are executed the same number of times, they can be merged into one to reduce the </span><span class="No-Break"><span class="koboSpan" id="kobo.968.1">loop overhead.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.969.1">Loop inversion</span></strong><span class="koboSpan" id="kobo.970.1"> is a technique where a </span><strong class="source-inline"><span class="koboSpan" id="kobo.971.1">while</span></strong><span class="koboSpan" id="kobo.972.1"> loop is transformed into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.973.1">do-while</span></strong><span class="koboSpan" id="kobo.974.1"> loop inside </span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.975.1">a conditional </span><strong class="source-inline"><span class="koboSpan" id="kobo.976.1">if</span></strong><span class="koboSpan" id="kobo.977.1"> statement. </span><span class="koboSpan" id="kobo.977.2">This reduces the total number of jumps by two when the loop is executed and is typically applied to loops that are expected to execute at </span><span class="No-Break"><span class="koboSpan" id="kobo.978.1">least once.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.979.1">Loop interchange</span></strong><span class="koboSpan" id="kobo.980.1"> exchanges </span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.981.1">inner loops and outer loops especially when doing so leads to better cache reference locality – for example, in the cases of iterating over an array where accessing memory contiguously makes a huge </span><span class="No-Break"><span class="koboSpan" id="kobo.982.1">performance difference.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.983.1">Register variables</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.984.1">Registers</span></strong><span class="koboSpan" id="kobo.985.1"> are internal processor memory and are the fastest form of storage available for the processor on account </span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.986.1">of being the closest to them. </span><span class="koboSpan" id="kobo.986.2">Because of this, the compiler tries to store variables that have the highest number of accesses in the registers. </span><span class="koboSpan" id="kobo.986.3">Registers, however, </span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.987.1">are limited, so the compiler needs to choose </span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.988.1">the variables to store effectively, and the effectiveness of this choice can make a significant difference to performance. </span><span class="koboSpan" id="kobo.988.2">The compiler typically picks variables such as local variables, loop counter and iterator variables, function parameters, commonly used expressions, or </span><strong class="bold"><span class="koboSpan" id="kobo.989.1">induction variables</span></strong><span class="koboSpan" id="kobo.990.1"> (variables that change by fixed amounts on each loop iteration). </span><span class="koboSpan" id="kobo.990.2">There are some limitations to what the compiler can place in registers such </span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.991.1">as variables whose address needs to be taken via pointers or references that need to reside in the </span><span class="No-Break"><span class="koboSpan" id="kobo.992.1">main memory.</span></span></p>
<p><span class="koboSpan" id="kobo.993.1">Now, we present a very simple example of how a compiler will transform a loop expression using induction variables. </span><span class="koboSpan" id="kobo.993.2">See the following code (</span><strong class="source-inline"><span class="koboSpan" id="kobo.994.1">Chapter3/induction.cpp</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.995.1">on GitHub):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.996.1">
  for(auto i = 0; i &lt; 100; ++i)
    a[i] = i * 10 + 12;
gets transformed into something of the form presented below
     and avoids the multiplication in the loop and replaces
     it
       with an induction variable based addition.
</span><span class="koboSpan" id="kobo.996.2">  int temp = 12;
  for(auto i = 0; i &lt; 100; ++i) {
    a[i] = temp;
    temp += 10;
  }</span></pre>
<h3><span class="koboSpan" id="kobo.997.1">Live range analysis</span></h3>
<p><span class="koboSpan" id="kobo.998.1">The term </span><strong class="bold"><span class="koboSpan" id="kobo.999.1">live range</span></strong><span class="koboSpan" id="kobo.1000.1"> describes the code block within which a variable is active or used. </span><span class="koboSpan" id="kobo.1000.2">If there are multiple </span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.1001.1">variables in the same code block with overlapping live ranges, then</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.1002.1"> each variable needs a different storage location. </span><span class="koboSpan" id="kobo.1002.2">However, if there are variables with live ranges that do not overlap, then </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.1003.1">the compiler can use the same register for multiple variables in each </span><span class="No-Break"><span class="koboSpan" id="kobo.1004.1">live range.</span></span></p>
<h3><span class="koboSpan" id="kobo.1005.1">Rematerialization</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.1006.1">Rematerialization</span></strong><span class="koboSpan" id="kobo.1007.1"> is a compiler technique where the compiler chooses to re-calculate a value (assuming the calculation is trivial) instead of accessing the memory location that contains the value </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.1008.1">of this calculation already. </span><span class="koboSpan" id="kobo.1008.2">The output value of this recalculation </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.1009.1">must be stored in registers, so this technique works in tandem with </span><em class="italic"><span class="koboSpan" id="kobo.1010.1">register allocation techniques</span></em><span class="koboSpan" id="kobo.1011.1">. </span><span class="koboSpan" id="kobo.1011.2">The main objective here is to avoid accessing the caches and main memory, which are slower to access than accessing the register storage. </span><span class="koboSpan" id="kobo.1011.3">This, of course, depends on making sure that the recalculation takes less time than a cache or </span><span class="No-Break"><span class="koboSpan" id="kobo.1012.1">memory access.</span></span></p>
<h3><span class="koboSpan" id="kobo.1013.1">Algebraic reductions</span></h3>
<p><span class="koboSpan" id="kobo.1014.1">The compiler can find expressions that can be further reduced and simplified using algebraic laws. </span><span class="koboSpan" id="kobo.1014.2">While </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.1015.1">software developers do not unnecessarily complicate expressions, there are cases where simpler forms of expressions exist compared to what the developer originally wrote in C++. </span><span class="koboSpan" id="kobo.1015.2">Opportunities for algebraic reductions also show up as the compiler optimizes code iteratively due to inlining, macro expansions, constant folding, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1016.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.1017.1">Something to note here is that compilers do not typically apply algebraic reductions to floating-point operations because, in C++, floating-point operations are not safe to reduce due to precision issues. </span><span class="koboSpan" id="kobo.1017.2">Flags need to be turned on to force the compiler to perform unsafe floating-point algebraic reductions, but it would be preferable for developers to reduce them explicitly </span><span class="No-Break"><span class="koboSpan" id="kobo.1018.1">and correctly.</span></span></p>
<p><span class="koboSpan" id="kobo.1019.1">The simplest example we can think of here is where a compiler might rewrite </span><span class="No-Break"><span class="koboSpan" id="kobo.1020.1">this expression:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1021.1">
if(!a &amp;&amp; !b) {}</span></pre>
<p><span class="koboSpan" id="kobo.1022.1">Here, it uses two operations instead of three previously </span><span class="No-Break"><span class="koboSpan" id="kobo.1023.1">like so:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1024.1">
if(!(a || b)) {}</span></pre>
<h3><span class="koboSpan" id="kobo.1025.1">Induction variable analysis</span></h3>
<p><span class="koboSpan" id="kobo.1026.1">The idea behind </span><strong class="bold"><span class="koboSpan" id="kobo.1027.1">induction variable</span></strong><span class="koboSpan" id="kobo.1028.1">-related compiler optimization techniques is that an expression that is a </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.1029.1">linear function of the loop counter variable can be reduced </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.1030.1">into an expression that is a simple addition to a previous value. </span><span class="koboSpan" id="kobo.1030.2">The simplest possible example would be calculating the address of elements in an array where the next element is at a memory location equal to the current element’s location plus the size of the object type. </span><span class="koboSpan" id="kobo.1030.3">This is just a simple example since in modern compilers and processors, there </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.1031.1">are special instructions to calculate addresses of array elements and induction is not really used there, but induction variable-based optimizations are still performed for other </span><span class="No-Break"><span class="koboSpan" id="kobo.1032.1">loop expressions.</span></span></p>
<h3><span class="koboSpan" id="kobo.1033.1">Loop invariant code movement</span></h3>
<p><span class="koboSpan" id="kobo.1034.1">When the compiler can ascertain that some code and instructions within a loop are constant for the entire </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.1035.1">duration of the loop, that expression can be moved out of the loop. </span><span class="koboSpan" id="kobo.1035.2">If there are expressions within the loop that conditionally yield one value or the other depending on branching conditions, those can also be moved out of the loop. </span><span class="koboSpan" id="kobo.1035.3">Also, if there are expressions executed on each branch within a loop, these can be moved out of the branches and possibly the loop. </span><span class="koboSpan" id="kobo.1035.4">There are many such optimization possibilities, but the fundamental idea is that code that does not need to be executed on each loop iteration or can be evaluated once before the loop falls under the umbrella of loop invariant code refactoring. </span><span class="koboSpan" id="kobo.1035.5">Here is a hypothetical example of how loop invariant code movement implemented by the compiler would work. </span><span class="koboSpan" id="kobo.1035.6">The first block is what the developer originally wrote, but the compiler can understand that the call to </span><strong class="source-inline"><span class="koboSpan" id="kobo.1036.1">doSomething()</span></strong><span class="koboSpan" id="kobo.1037.1"> and the expression involving the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1038.1">b</span></strong><span class="koboSpan" id="kobo.1039.1"> variable are loop invariants and only need to be computed once. </span><span class="koboSpan" id="kobo.1039.2">You will find this code in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1040.1">Chapter3/loop_invariant.cpp</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1041.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1042.1">
#include &lt;cstdlib&gt;
int main() {
  auto doSomething = [](double r) noexcept { return 3.14 *
       r * r; };
  [[maybe_unused]] int a[100], b = rand();
  // original
  for(auto i = 0; i &lt; 100; ++i)
    a[i] = (doSomething(50) + b * 2) + 1;
  // loop invariant code movement
  auto temp = (doSomething(50) + b * 2) + 1;
  for(auto i = 0; i &lt; 100; ++i)
    a[i] = temp;
}</span></pre>
<h3><span class="koboSpan" id="kobo.1043.1">Static Single Assignment (SSA)-based optimizations</span></h3>
<p><span class="koboSpan" id="kobo.1044.1">SSA is a transformed form of the original program where instructions are re-ordered such that every variable is </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.1045.1">assigned in a </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.1046.1">single place. </span><span class="koboSpan" id="kobo.1046.2">After this transformation, the compiler can apply many additional optimizations, leveraging the property that every variable is assigned in only a </span><span class="No-Break"><span class="koboSpan" id="kobo.1047.1">single place.</span></span></p>
<h3><span class="koboSpan" id="kobo.1048.1">Devirtualization</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.1049.1">Devirtualization</span></strong><span class="koboSpan" id="kobo.1050.1"> is a compiler </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.1051.1">optimization technique, especially for C++, that tries to avoid </span><strong class="bold"><span class="koboSpan" id="kobo.1052.1">Virtual Table</span></strong><span class="koboSpan" id="kobo.1053.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1054.1">vtable</span></strong><span class="koboSpan" id="kobo.1055.1">) lookups when calling virtual functions. </span><span class="koboSpan" id="kobo.1055.2">This optimization </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.1056.1">technique boils down to the compiler figuring </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.1057.1">out the correct method to call at compile time. </span><span class="koboSpan" id="kobo.1057.2">This can happen even when using virtual functions because in some cases, the object type is known at compile time, such as when there is only a single implementation of pure </span><span class="No-Break"><span class="koboSpan" id="kobo.1058.1">virtual functions.</span></span></p>
<p><span class="koboSpan" id="kobo.1059.1">Another case is where the compiler can determine that only a single derived class is created and used in some contexts or code branches, and it can replace the indirect functional call using vtable to be a direct call to the correct derived </span><span class="No-Break"><span class="koboSpan" id="kobo.1060.1">type’s method.</span></span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor090"/><span class="koboSpan" id="kobo.1061.1">Understanding when compilers fail to optimize</span></h2>
<p><span class="koboSpan" id="kobo.1062.1">In this section, we will discuss the different scenarios under which a compiler cannot apply some of the optimization techniques we discussed in the previous section. </span><span class="koboSpan" id="kobo.1062.2">Understanding when compilers fail to optimize will help us develop C++ code that avoids these failures so that the code can be highly optimized by the compiler to yield highly efficient </span><span class="No-Break"><span class="koboSpan" id="kobo.1063.1">machine code.</span></span></p>
<h3><span class="koboSpan" id="kobo.1064.1">Failure to optimize across modules</span></h3>
<p><span class="koboSpan" id="kobo.1065.1">When the compiler </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.1066.1">compiles the entire program, it compiles modules independently of each other on a file-by-file basis. </span><span class="koboSpan" id="kobo.1066.2">So, the compiler does not have information about functions in a module other than the one it is currently compiling. </span><span class="koboSpan" id="kobo.1066.3">This prevents it from being able to optimize functions across modules and a lot of the techniques we saw cannot be applied since the compiler does not understand the whole program. </span><span class="koboSpan" id="kobo.1066.4">Modern compilers solve such issues by using </span><strong class="bold"><span class="koboSpan" id="kobo.1067.1">LTO</span></strong><span class="koboSpan" id="kobo.1068.1">, where, after the individual modules are compiled, the linker treats the different modules as if they were part of the same translation unit at compile time. </span><span class="koboSpan" id="kobo.1068.2">This activates all the optimizations we have discussed so far, so it is important to enable LTO when trying to optimize the </span><span class="No-Break"><span class="koboSpan" id="kobo.1069.1">entire application.</span></span></p>
<h3><span class="koboSpan" id="kobo.1070.1">Dynamic memory allocation</span></h3>
<p><span class="koboSpan" id="kobo.1071.1">We already know that dynamic memory allocation is slow at runtime and introduces non-deterministic latency into your applications. </span><span class="koboSpan" id="kobo.1071.2">They also have another side effect and that is </span><strong class="bold"><span class="koboSpan" id="kobo.1072.1">pointer aliasing</span></strong><span class="koboSpan" id="kobo.1073.1"> in the pointers that point to these dynamically allocated memory blocks. </span><span class="koboSpan" id="kobo.1073.2">We will look at pointer aliasing in more detail next, but with dynamically allocated memory blocks, the compiler cannot ascertain that the pointers will necessarily point to different and non-overlapping memory areas, even though for the programmer it might seem obvious. </span><span class="koboSpan" id="kobo.1073.3">This prevents various compiler optimizations that depend on aligning data or assuming alignment, as well as pointer aliasing-related inefficiencies, which we will see next. </span><span class="koboSpan" id="kobo.1073.4">Local storage and declarations are also more cache-efficient because the memory space gets reused frequently as new functions are called and local objects are created. </span><span class="koboSpan" id="kobo.1073.5">Dynamically allocated memory blocks can be randomly scattered in memory and yield poor </span><span class="No-Break"><span class="koboSpan" id="kobo.1074.1">cache performance.</span></span></p>
<h3><span class="koboSpan" id="kobo.1075.1">Pointer aliasing</span></h3>
<p><span class="koboSpan" id="kobo.1076.1">When accessing variables through pointers or references, while it might be obvious to the developer which pointers point to different and non-overlapping memory locations, the compiler cannot be 100% sure. </span><span class="koboSpan" id="kobo.1076.2">To put it another way, the compiler cannot guarantee that a pointer is not pointing to another variable in the code block or different pointers are not pointing to overlapping memory locations. </span><span class="koboSpan" id="kobo.1076.3">Since the compiler must assume this possibility, this prevents a lot of the compiler optimizations we discussed before since they can no longer be applied safely. </span><span class="koboSpan" id="kobo.1076.4">There are ways to specify which pointers the compiler can safely assume are not aliases in C++ code. </span><span class="koboSpan" id="kobo.1076.5">Another way would be to instruct the compiler to assume no pointer aliasing across the entire code, but that would require the developer to analyze all pointers and references and make sure there is never any aliasing, which is not trivial to do. </span><span class="koboSpan" id="kobo.1076.6">Finally, the last option is to optimize the code explicitly keeping these hindrances to compiler optimizations in mind, which is not </span><span class="No-Break"><span class="koboSpan" id="kobo.1077.1">trivial either.</span></span></p>
<p><span class="koboSpan" id="kobo.1078.1">Our advice on dealing with pointer aliasing would be to do </span><span class="No-Break"><span class="koboSpan" id="kobo.1079.1">the following:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1080.1">Use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1081.1">__restrict</span></strong><span class="koboSpan" id="kobo.1082.1"> keyword in the function declarations when passing pointers to functions to instruct the compiler to assume no pointer aliasing for the pointers marked with </span><span class="No-Break"><span class="koboSpan" id="kobo.1083.1">that specifier</span></span></li>
<li><span class="koboSpan" id="kobo.1084.1">If additional optimization is required, we recommend explicitly optimizing code paths, being aware of pointer </span><span class="No-Break"><span class="koboSpan" id="kobo.1085.1">aliasing considerations</span></span></li>
<li><span class="koboSpan" id="kobo.1086.1">Finally, if additional </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.1087.1">optimizations are still required, we can instruct the compiler to assume no pointer aliasing across the entire code base, but this is a dangerous option and should only be used as a </span><span class="No-Break"><span class="koboSpan" id="kobo.1088.1">last resort</span></span></li>
</ol>
<h3><span class="koboSpan" id="kobo.1089.1">Floating-point induction variables</span></h3>
<p><span class="koboSpan" id="kobo.1090.1">Compilers typically do not use induction variable optimizations for floating-point expressions and variables. </span><span class="koboSpan" id="kobo.1090.2">This is because of the rounding errors and issues with precision that we have discussed before. </span><span class="koboSpan" id="kobo.1090.3">This prevents compiler optimizations when dealing with floating-point expressions and values. </span><span class="koboSpan" id="kobo.1090.4">There are compiler options that can enable unsafe floating-point optimizations, but the developer must make sure to check each expression and formulate them in such a way that these precision issues due to compiler optimizations do not have unintended side effects. </span><span class="koboSpan" id="kobo.1090.5">This is not a trivial task; hence, developers should be careful to either optimize floating-point expressions explicitly or analyze side effects from unsafe </span><span class="No-Break"><span class="koboSpan" id="kobo.1091.1">compiler optimizations.</span></span></p>
<h3><span class="koboSpan" id="kobo.1092.1">Virtual functions and function pointers</span></h3>
<p><span class="koboSpan" id="kobo.1093.1">We have already </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.1094.1">discussed that when it comes to virtual functions and function pointers, the compiler cannot perform optimizations at compile time since in many cases it is not possible for the compiler to determine which method will be called </span><span class="No-Break"><span class="koboSpan" id="kobo.1095.1">at runtime.</span></span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor091"/><span class="koboSpan" id="kobo.1096.1">Learning about compiler optimization flags</span></h2>
<p><span class="koboSpan" id="kobo.1097.1">So far, we have discussed the different optimization techniques that the compiler uses, as well as the different cases where the compiler fails to optimize our C++ code. </span><span class="koboSpan" id="kobo.1097.2">There are two fundamental </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.1098.1">keys to generating optimized low-latency code. </span><span class="koboSpan" id="kobo.1098.2">The first is to write efficient C++ code and optimize manually in cases where the compiler might not be able to do so. </span><span class="koboSpan" id="kobo.1098.3">Secondly, you can provide the compiler with as much visibility and information as possible so it can make the correct and best optimization decisions. </span><span class="koboSpan" id="kobo.1098.4">We can convey our intent to the compiler through the compiler flags we use to </span><span class="No-Break"><span class="koboSpan" id="kobo.1099.1">configure it.</span></span></p>
<p><span class="koboSpan" id="kobo.1100.1">In this section, we will learn about the compiler flags for the GCC since that is the compiler we will use in this book. </span><span class="koboSpan" id="kobo.1100.2">However, most modern compilers have flags to configure optimizations like the ones we will discuss in </span><span class="No-Break"><span class="koboSpan" id="kobo.1101.1">this section.</span></span></p>
<h3><span class="koboSpan" id="kobo.1102.1">Approaching compiler optimization flags</span></h3>
<p><span class="koboSpan" id="kobo.1103.1">At a high level, the general </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.1104.1">approach toward GCC compiler optimization flags is </span><span class="No-Break"><span class="koboSpan" id="kobo.1105.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1106.1">The highest optimization level is typically preferred so </span><strong class="source-inline"><span class="koboSpan" id="kobo.1107.1">–O3</span></strong><span class="koboSpan" id="kobo.1108.1"> is a good starting point and enables a lot of optimizations, which we will </span><span class="No-Break"><span class="koboSpan" id="kobo.1109.1">see shortly.</span></span></li>
<li><span class="koboSpan" id="kobo.1110.1">Measuring the performance of the application in practice is the best way to measure and optimize the most critical code paths. </span><span class="koboSpan" id="kobo.1110.2">GCC itself can perform </span><strong class="bold"><span class="koboSpan" id="kobo.1111.1">Profile-Guided Optimization</span></strong><span class="koboSpan" id="kobo.1112.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1113.1">PGO</span></strong><span class="koboSpan" id="kobo.1114.1">) when the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1115.1">-fprofile-generate</span></strong><span class="koboSpan" id="kobo.1116.1"> option is enabled. </span><span class="koboSpan" id="kobo.1116.2">The </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.1117.1">compiler determines the flow of the program and counts how many times each function and code branch is executed to find optimizations for the critical </span><span class="No-Break"><span class="koboSpan" id="kobo.1118.1">code paths.</span></span></li>
<li><span class="koboSpan" id="kobo.1119.1">Enabling </span><strong class="bold"><span class="koboSpan" id="kobo.1120.1">LTO</span></strong><span class="koboSpan" id="kobo.1121.1"> is a good practice for building the lowest latency machine code due to the reasons we have discussed before and the inability of the compiler to optimize across modules without this. </span><span class="koboSpan" id="kobo.1121.2">For GCC, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1122.1">–flto</span></strong><span class="koboSpan" id="kobo.1123.1"> parameter enables LTO for our applications. </span><span class="koboSpan" id="kobo.1123.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.1124.1">-fwhole-program</span></strong><span class="koboSpan" id="kobo.1125.1"> option enables </span><strong class="bold"><span class="koboSpan" id="kobo.1126.1">WPO</span></strong><span class="koboSpan" id="kobo.1127.1"> to enable inter-procedural optimizations, treating the entire code base as a </span><span class="No-Break"><span class="koboSpan" id="kobo.1128.1">whole program.</span></span></li>
<li><span class="koboSpan" id="kobo.1129.1">Allowing the compiler to generate a build for a specific architecture where the application will run is a good idea. </span><span class="koboSpan" id="kobo.1129.2">This lets the compiler use special instruction sets specific to that architecture and maximize optimization opportunities. </span><span class="koboSpan" id="kobo.1129.3">For GCC, this is enabled using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1130.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1131.1">march</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1132.1"> parameter.</span></span></li>
<li><span class="koboSpan" id="kobo.1133.1">It is recommended to disable </span><strong class="bold"><span class="koboSpan" id="kobo.1134.1">RTTI</span></strong><span class="koboSpan" id="kobo.1135.1"> because RTTI depends on figuring out the type of an object at runtime. </span><span class="koboSpan" id="kobo.1135.2">For GCC, this is achieved using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1136.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1137.1">no-rtti</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1138.1"> parameter.</span></span></li>
<li><span class="koboSpan" id="kobo.1139.1">It is possible to instruct the GCC compiler to enable fast floating-point value optimizations and even enable unsafe floating-point optimizations. </span><span class="koboSpan" id="kobo.1139.2">GCC has the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1140.1">-ffp-model=fast</span></strong><span class="koboSpan" id="kobo.1141.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1142.1">-funsafe-math-optimizations</span></strong><span class="koboSpan" id="kobo.1143.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1144.1">-ffinite-math-only</span></strong><span class="koboSpan" id="kobo.1145.1"> options to enable these unsafe floating-point optimizations. </span><span class="koboSpan" id="kobo.1145.2">When using these flags, it is important that the developer carefully thinks about the order of operations and the precision resulting from these operations. </span><span class="koboSpan" id="kobo.1145.3">When using a parameter such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.1146.1">-ffinite-math-only</span></strong><span class="koboSpan" id="kobo.1147.1">, make sure that all floating-point variables and expressions are finite because this optimization depends on that property. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1148.1">-fno-trapping-math</span></strong><span class="koboSpan" id="kobo.1149.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1150.1">-fno-math-errno</span></strong><span class="koboSpan" id="kobo.1151.1"> allow the compiler to </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.1152.1">vectorize loops containing floating-point operations by assuming that there will be no reliance on exception handling or the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1153.1">errno</span></strong><span class="koboSpan" id="kobo.1154.1"> global variable for </span><span class="No-Break"><span class="koboSpan" id="kobo.1155.1">error signaling.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.1156.1">Understanding the details of GCC optimization flags</span></h3>
<p><span class="koboSpan" id="kobo.1157.1">In this section, we </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.1158.1">will provide additional details on </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.1159.1">the GCC optimization flags available. </span><span class="koboSpan" id="kobo.1159.2">The complete list of optimization flags available is exceptionally large and out of the scope of this book. </span><span class="koboSpan" id="kobo.1159.3">First, we will describe what turning on the higher-level optimization directives, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1160.1">–O1</span></strong><span class="koboSpan" id="kobo.1161.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1162.1">–O2</span></strong><span class="koboSpan" id="kobo.1163.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1164.1">–O3</span></strong><span class="koboSpan" id="kobo.1165.1">, enables in GCC, and we encourage interested readers to learn about each one of these in greater detail from the </span><span class="No-Break"><span class="koboSpan" id="kobo.1166.1">GCC manual.</span></span></p>
<h4><span class="koboSpan" id="kobo.1167.1">Optimization level -O1</span></h4>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1168.1">–O1</span></strong><span class="koboSpan" id="kobo.1169.1"> is the first level of </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.1170.1">optimization and enables the following flags presented in the following table. </span><span class="koboSpan" id="kobo.1170.2">At this level, the compiler tries to reduce the code size and execution time without incurring a very large increase in compilation, linking, and optimization times. </span><span class="koboSpan" id="kobo.1170.3">These are the most important levels of optimization and provide tremendous optimization opportunities based on the ones we discussed in this chapter. </span><span class="koboSpan" id="kobo.1170.4">We will discuss a few of the </span><span class="No-Break"><span class="koboSpan" id="kobo.1171.1">flags next.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1172.1">-fdce</span></strong><span class="koboSpan" id="kobo.1173.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1174.1">–fdse</span></strong><span class="koboSpan" id="kobo.1175.1"> perform </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.1176.1">DCE and </span><strong class="bold"><span class="koboSpan" id="kobo.1177.1">Dead Store </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1178.1">Elimination</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1179.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1180.1">DSE</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1181.1">).</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1182.1">-fdelayed-branch</span></strong><span class="koboSpan" id="kobo.1183.1"> is supported on many architectures and tries to reorder instructions to try and maximize the throughput of the pipeline after delayed </span><span class="No-Break"><span class="koboSpan" id="kobo.1184.1">branch instructions.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1185.1">-fguess-branch-probability</span></strong><span class="koboSpan" id="kobo.1186.1"> tries to guess branch probabilities based on heuristics for branches that the developer has not provided </span><span class="No-Break"><span class="koboSpan" id="kobo.1187.1">any hints.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1188.1">-fif-conversion</span></strong><span class="koboSpan" id="kobo.1189.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1190.1">-fif-conversion2</span></strong><span class="koboSpan" id="kobo.1191.1"> try to eliminate branching by changing them into branchless equivalents using tricks similar to what we discussed in </span><span class="No-Break"><span class="koboSpan" id="kobo.1192.1">this chapter.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1193.1">-fmove-loop-invariants</span></strong><span class="koboSpan" id="kobo.1194.1"> enables loop invariant code </span><span class="No-Break"><span class="koboSpan" id="kobo.1195.1">movement optimization.</span></span></p>
<p><span class="koboSpan" id="kobo.1196.1">If you are interested, you </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.1197.1">should investigate the details of these flags since discussing every parameter is outside the scope of </span><span class="No-Break"><span class="koboSpan" id="kobo.1198.1">this book.</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1199.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1200.1">fauto-inc-dec</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1201.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1202.1">fshrink-wrap</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1203.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1204.1">fbranch-count-reg</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1205.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1206.1">fshrink-wrap-separate</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1207.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1208.1">fcombine-stack-adjustments</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1209.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1210.1">fsplit-wide-types</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1211.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1212.1">fcompare-elim</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1213.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1214.1">fssa-backprop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1215.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1216.1">fcprop-registers</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1217.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1218.1">fssa-phiopt</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1219.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1220.1">fdce</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1221.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1222.1">ftree-bit-ccp</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1223.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1224.1">fdefer-pop</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1225.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1226.1">ftree-ccp</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1227.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1228.1">fdelayed-branch</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1229.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1230.1">ftree-ch</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1231.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1232.1">fdse</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1233.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1234.1">ftree-coalesce-vars</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1235.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1236.1">fforward-propagate</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1237.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1238.1">ftree-copy-prop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1239.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1240.1">fguess-branch-probability</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1241.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1242.1">ftree-dce</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1243.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1244.1">fif-conversion</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1245.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1246.1">ftree-dominator-opts</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1247.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1248.1">fif-conversion2</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1249.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1250.1">ftree-dse</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1251.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1252.1">finline-functions-called-once</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1253.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1254.1">ftree-forwprop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1255.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1256.1">fipa-modref</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1257.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1258.1">ftree-fre</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1259.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1260.1">fipa-profile</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1261.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1262.1">ftree-phiprop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1263.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1264.1">fipa-pure-const</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1265.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1266.1">ftree-pta</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1267.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1268.1">fipa-reference</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1269.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1270.1">ftree-scev-cprop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1271.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1272.1">fipa-reference-addressable</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1273.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1274.1">ftree-sink</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1275.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1276.1">fmerge-constants162</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1277.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1278.1">ftree-slsr</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1279.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1280.1">fmove-loop-invariants</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1281.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1282.1">ftree-sra</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1283.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1284.1">fmove-loop-stores</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1285.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1286.1">ftree-ter</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1287.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1288.1">fomit-frame-pointer</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1289.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1290.1">funit-at-a-time</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1291.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1292.1">freorder-blocks</span></strong></span></p>
</td>
<td class="No-Table-Style"/>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1293.1">Table 3.1 – GCC optimization flags enabled when -O1 is enabled</span></p>
<h4><span class="koboSpan" id="kobo.1294.1">Optimization level -O2</span></h4>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1295.1">-O2</span></strong><span class="koboSpan" id="kobo.1296.1"> is the next optimization level and at this level, GCC will perform a lot more optimizations and will </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.1297.1">lead to longer compilation and linking times. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1298.1">-O2</span></strong><span class="koboSpan" id="kobo.1299.1"> adds the flags in the following table in addition to the flags enabled by </span><strong class="source-inline"><span class="koboSpan" id="kobo.1300.1">–O1</span></strong><span class="koboSpan" id="kobo.1301.1">. </span><span class="koboSpan" id="kobo.1301.2">We will quickly discuss a few of these flags and leave a detailed discussion of each flag up to interested readers </span><span class="No-Break"><span class="koboSpan" id="kobo.1302.1">to pursue.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1303.1">-falign-functions</span></strong><span class="koboSpan" id="kobo.1304.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1305.1">-falign-labels</span></strong><span class="koboSpan" id="kobo.1306.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1307.1">-falign-loops</span></strong><span class="koboSpan" id="kobo.1308.1"> align the starting address of functions, jump targets, and loop locations so that the processor can access them as efficiently as possible. </span><span class="koboSpan" id="kobo.1308.2">The principles we discussed on optimal data alignment in this chapter apply to the instruction addresses </span><span class="No-Break"><span class="koboSpan" id="kobo.1309.1">as well.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1310.1">-fdelete-null-pointer-checks</span></strong><span class="koboSpan" id="kobo.1311.1"> lets the program assume that dereferencing null pointers is not safe and leverages that assumption to perform constant folding, eliminate null pointer checks, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1312.1">so on.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1313.1">-fdevirtualize</span></strong><span class="koboSpan" id="kobo.1314.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1315.1">-fdevirtualize-speculatively</span></strong><span class="koboSpan" id="kobo.1316.1"> attempt to convert virtual function </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.1317.1">calls into direct function calls wherever possible. </span><span class="koboSpan" id="kobo.1317.2">This, in turn, can lead to even more optimization due </span><span class="No-Break"><span class="koboSpan" id="kobo.1318.1">to inlining.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1319.1">-fgcse</span></strong><span class="koboSpan" id="kobo.1320.1"> enables </span><strong class="bold"><span class="koboSpan" id="kobo.1321.1">Global Common Subexpression Elimination</span></strong><span class="koboSpan" id="kobo.1322.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1323.1">GCSE</span></strong><span class="koboSpan" id="kobo.1324.1">) and </span><span class="No-Break"><span class="koboSpan" id="kobo.1325.1">constant </span></span><span class="No-Break"><a id="_idIndexMarker545"/></span><span class="No-Break"><span class="koboSpan" id="kobo.1326.1">propagation.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1327.1">-finline-functions</span></strong><span class="koboSpan" id="kobo.1328.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1329.1">-finline-functions-called-once</span></strong><span class="koboSpan" id="kobo.1330.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1331.1">-findirect-inlining</span></strong><span class="koboSpan" id="kobo.1332.1"> increase the aggressiveness of the compiler in its attempts to inline functions and look for indirect inline opportunities due to previous </span><span class="No-Break"><span class="koboSpan" id="kobo.1333.1">optimization passes.</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1334.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1335.1">falign-functions -falign-jumps</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1336.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1337.1">foptimize-sibling-calls</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1338.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1339.1">falign-labels -falign-loops</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1340.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1341.1">foptimize-strlen</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1342.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1343.1">fcaller-saves</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1344.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1345.1">fpartial-inlining</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1346.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1347.1">fcode-hoisting</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1348.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1349.1">fpeephole2</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1350.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1351.1">fcrossjumping</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1352.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1353.1">freorder-blocks-algorithm=stc</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1354.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1355.1">fcse-follow-jumps -fcse-skip-blocks</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1356.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1357.1">freorder-blocks-and-partition -freorder-functions</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1358.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1359.1">fdelete-null-pointer-checks</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1360.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1361.1">frerun-cse-after-loop</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1362.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1363.1">fdevirtualize -fdevirtualize-speculatively</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1364.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1365.1">fschedule-insns -fschedule-insns2</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1366.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1367.1">fexpensive-optimizations</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1368.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1369.1">fsched-interblock -fsched-spec</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1370.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1371.1">ffinite-loops</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1372.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1373.1">fstore-merging</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1374.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1375.1">fgcse -fgcse-lm</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1376.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1377.1">fstrict-aliasing</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1378.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1379.1">fhoist-adjacent-loads</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1380.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1381.1">fthread-jumps</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1382.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1383.1">finline-functions</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1384.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1385.1">ftree-builtin-call-dce</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1386.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1387.1">finline-small-functions</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1388.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1389.1">ftree-loop-vectorize</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1390.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1391.1">findirect-inlining</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1392.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1393.1">ftree-pre</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1394.1">-fipa-bit-cp -</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1395.1">fipa-cp -fipa-icf</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1396.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1397.1">ftree-slp-vectorize</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1398.1">-fipa-ra -</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1399.1">fipa-sra -fipa-vrp</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1400.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1401.1">ftree-switch-conversion -ftree-tail-merge</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1402.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1403.1">fisolate-erroneous-paths-dereference</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1404.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1405.1">ftree-vrp</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1406.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1407.1">flra-remat</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1408.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1409.1">fvect-cost-model=very-cheap</span></strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1410.1">Table 3.2 – GCC optimization flags enabled in addition to the ones from -O1 when -O2 is enabled</span></p>
<h4><span class="koboSpan" id="kobo.1411.1">Optimization level –O3</span></h4>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1412.1">–O3</span></strong><span class="koboSpan" id="kobo.1413.1"> is the most aggressive optimization option in GCC and it will optimize even when it leads to larger </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.1414.1">executable sizes as long as the program performs better. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1415.1">-O3</span></strong><span class="koboSpan" id="kobo.1416.1"> enables the following flags presented in the next table beyond </span><strong class="source-inline"><span class="koboSpan" id="kobo.1417.1">–O2</span></strong><span class="koboSpan" id="kobo.1418.1">. </span><span class="koboSpan" id="kobo.1418.2">We quickly discuss a few important ones first and then provide the </span><span class="No-Break"><span class="koboSpan" id="kobo.1419.1">complete list.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1420.1">-fipa-cp-clone</span></strong><span class="koboSpan" id="kobo.1421.1"> creates function clones to make interprocedural constant propagation and other forms of optimization stronger by trading execution speed at the cost of higher </span><span class="No-Break"><span class="koboSpan" id="kobo.1422.1">executable sizes.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1423.1">-fsplit-loops</span></strong><span class="koboSpan" id="kobo.1424.1"> attempts to split a loop if it can avoid branching within the loop by having the loop for one side and then the other side – for instance, in a case where we check the side of execution in a trading algorithm within a loop and execute two different code blocks within </span><span class="No-Break"><span class="koboSpan" id="kobo.1425.1">the loop.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1426.1">-funswitch-loops</span></strong><span class="koboSpan" id="kobo.1427.1"> moves loop invariant branches out of the loop to </span><span class="No-Break"><span class="koboSpan" id="kobo.1428.1">minimize branching.</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1429.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1430.1">fgcse-after-reload</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1431.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1432.1">fsplit-paths</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1433.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1434.1">fipa-cp-clone -floop-interchange</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1435.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1436.1">ftree-loop-distribution</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1437.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1438.1">floop-unroll-and-jam</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1439.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1440.1">ftree-partial-pre</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1441.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1442.1">fpeel-loops</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1443.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1444.1">funswitch-loops</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1445.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1446.1">fpredictive-commoning</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1447.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1448.1">fvect-cost-model=dynamic</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1449.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1450.1">fsplit-loops</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1451.1">-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1452.1">fversion-loops-for-strides</span></strong></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1453.1">Table 3.3 – GCC optimization flags enabled in addition to the ones from -O2 when -O3 is enabled</span></p>
<p><span class="koboSpan" id="kobo.1454.1">We will discuss </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.1455.1">some additional compiler optimization flags we have found useful when it comes to optimizing </span><span class="No-Break"><span class="koboSpan" id="kobo.1456.1">low-latency applications.</span></span></p>
<h4><span class="koboSpan" id="kobo.1457.1">Static linkage</span></h4>
<p><span class="koboSpan" id="kobo.1458.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.1459.1">–l library</span></strong><span class="koboSpan" id="kobo.1460.1"> option is passed to the linker to specify which library to link the executables with. </span><span class="koboSpan" id="kobo.1460.2">However, if </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.1461.1">the linker finds a static library </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.1462.1">that has a name such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.1463.1">liblibrary.a</span></strong><span class="koboSpan" id="kobo.1464.1"> and a shared library that has a name such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.1465.1">liblibrary.so</span></strong><span class="koboSpan" id="kobo.1466.1">, then we must specify the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1467.1">–static</span></strong><span class="koboSpan" id="kobo.1468.1"> parameter to prevent linking with shared libraries and opt for the static library instead. </span><span class="koboSpan" id="kobo.1468.2">We have discussed before why static linkage is preferred over shared library linkage for </span><span class="No-Break"><span class="koboSpan" id="kobo.1469.1">low-latency applications.</span></span></p>
<h4><span class="koboSpan" id="kobo.1470.1">Target architecture</span></h4>
<p><span class="koboSpan" id="kobo.1471.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.1472.1">–march</span></strong><span class="koboSpan" id="kobo.1473.1"> parameter is used to specify the target architecture for which the compiler should build the final </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.1474.1">executable binary. </span><span class="koboSpan" id="kobo.1474.2">For example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1475.1">–march=native</span></strong><span class="koboSpan" id="kobo.1476.1"> specifies that the compiler should build the executable for the </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.1477.1">architecture that it is being built on. </span><span class="koboSpan" id="kobo.1477.2">We reiterate here that when the compiler knows the target architecture that the application is being built to run on, it can leverage information about that architecture, such as extended instruction sets and so on, to </span><span class="No-Break"><span class="koboSpan" id="kobo.1478.1">improve optimization.</span></span></p>
<h4><span class="koboSpan" id="kobo.1479.1">Warnings</span></h4>
<p><span class="koboSpan" id="kobo.1480.1">The</span><strong class="source-inline"><span class="koboSpan" id="kobo.1481.1">–Wall</span></strong><span class="koboSpan" id="kobo.1482.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1483.1">–Wextra</span></strong><span class="koboSpan" id="kobo.1484.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1485.1">–Wpendantic</span></strong><span class="koboSpan" id="kobo.1486.1"> parameters control the number of warnings that are </span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.1487.1">generated by the compiler when it detects a </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.1488.1">variety of different cases that are not </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.1489.1">technically errors but could be unsafe. </span><span class="koboSpan" id="kobo.1489.2">It is advisable to turn these on for most applications because they detect potential bugs and typos in developers’ code. </span><span class="koboSpan" id="kobo.1489.3">While these do not directly affect the compiler’s ability to optimize the application, sometimes, the warnings force developers to inspect cases of ambiguity or sub-optimal code, such as unexpected or implicit type conversions, which can be inefficient. </span><span class="koboSpan" id="kobo.1489.4">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.1490.1">–Werror</span></strong><span class="koboSpan" id="kobo.1491.1"> parameter turns these warnings into errors and </span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.1492.1">will force the developer to inspect and fix each case that generates a compiler warning before compilation </span><span class="No-Break"><span class="koboSpan" id="kobo.1493.1">can succeed.</span></span></p>
<h4><span class="koboSpan" id="kobo.1494.1">Unsafe fast math</span></h4>
<p><span class="koboSpan" id="kobo.1495.1">This category of compiler optimization flags should not be enabled without a lot of consideration and due </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.1496.1">diligence. </span><span class="koboSpan" id="kobo.1496.2">In C++, the compiler cannot apply a lot of floating-point optimizations that depend on properties such as floating-point operations yielding valid values, floating-point expressions being associative, and so on. </span><span class="koboSpan" id="kobo.1496.3">To recap, this is because of the way floating-point values are represented in hardware, and a lot of these optimizations can lead to precision loss and different (and possibly incorrect) results. </span><span class="koboSpan" id="kobo.1496.4">Enabling the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1497.1">–ffast-math</span></strong><span class="koboSpan" id="kobo.1498.1"> parameter in turn enables the </span><span class="No-Break"><span class="koboSpan" id="kobo.1499.1">following parameters:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1500.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1501.1">fno-math-errno</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1502.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1503.1">funsafe-math-optimizations</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1504.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1505.1">ffinite-math-only</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1506.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1507.1">fno-rounding-math</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1508.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1509.1">fno-signaling-nans</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1510.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1511.1">fcx-limited-range</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.1512.1">–</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1513.1">fexcess-precision=fast</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1514.1">These parameters will allow the compiler to apply optimizations to floating-point expressions even </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.1515.1">if they are unsafe. </span><span class="koboSpan" id="kobo.1515.2">These are not automatically enabled in any of the three optimization levels because they are unsafe and should only be enabled if the developer is confident that there are no errors or side effects that show up because </span><span class="No-Break"><span class="koboSpan" id="kobo.1516.1">of these.</span></span></p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor092"/><span class="koboSpan" id="kobo.1517.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1518.1">In this chapter, first, we discussed general advice that applies to developing low-latency applications in any programming language. </span><span class="koboSpan" id="kobo.1518.2">We discussed the ideal software engineering approach when it comes to these applications and how to think about, design, develop, and evaluate building blocks such as the data structures and algorithms </span><span class="No-Break"><span class="koboSpan" id="kobo.1519.1">to use.</span></span></p>
<p><span class="koboSpan" id="kobo.1520.1">We emphasized that when it comes to low-latency application development specifically, the depth of knowledge on topics such as processor architecture, cache and memory layout and access, how the C++ programming language works under the hood, and how the compiler works to optimize your code will dictate your success. </span><span class="koboSpan" id="kobo.1520.2">Measuring and improving performance is also a critical component for low-latency applications but we will dive into those details at the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.1521.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.1522.1">We spent a lot of time discussing different C++ principles, constructs, and features with the objective of understanding how they are implemented at a lower level. </span><span class="koboSpan" id="kobo.1522.2">The goal here was to unlearn sub-optimal practices and emphasize some of the ideal aspects of using C++ for low-latency </span><span class="No-Break"><span class="koboSpan" id="kobo.1523.1">application development.</span></span></p>
<p><span class="koboSpan" id="kobo.1524.1">In the remainder of this book, as we build our low-latency electronic trading exchange ecosystem (collection of applications that interact with each other), we will reinforce and build on these ideas we discussed here as we avoid certain C++ features and use </span><span class="No-Break"><span class="koboSpan" id="kobo.1525.1">others instead.</span></span></p>
<p><span class="koboSpan" id="kobo.1526.1">In the last section of this chapter, we discussed many aspects of the C++ compiler in detail. </span><span class="koboSpan" id="kobo.1526.2">We tried to build an understanding of how compilers optimize developers’ high-level code, as in, what techniques they have at their disposal. </span><span class="koboSpan" id="kobo.1526.3">We also investigated scenarios in which the compiler fails to optimize a developer’s code. </span><span class="koboSpan" id="kobo.1526.4">The goal there was for you to understand how to use a compiler to your advantage when trying to output the most optimal machine code possible and help the compiler help you avoid conditions where the compiler fails to optimize. </span><span class="koboSpan" id="kobo.1526.5">Finally, we looked at the different compiler optimization flags available for the GNU GCC compiler, which is what we will use in the rest of </span><span class="No-Break"><span class="koboSpan" id="kobo.1527.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.1528.1">We will put our theoretical knowledge into practice in the next chapter where we jump into implementing some common building blocks of low-latency applications in C++. </span><span class="koboSpan" id="kobo.1528.2">We will keep our goal of building these components to be low-latency and highly performant. </span><span class="koboSpan" id="kobo.1528.3">We will carefully use the principles and techniques we discussed in this chapter to build these high-performance components. </span><span class="koboSpan" id="kobo.1528.4">In later chapters, we will use these components to build an electronic </span><span class="No-Break"><span class="koboSpan" id="kobo.1529.1">trading ecosystem.</span></span></p>
</div>
</body></html>