- en: 5 Working with Geometry Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Join our book community on Discord
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](img/file40.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/unitydev](https://packt.link/unitydev)'
  prefs: []
  type: TYPE_NORMAL
- en: Previously, we tried different ad hoc approaches to storing and handling 3D
    geometry data in our graphical applications. The mesh data layout for vertex and
    index buffers was hardcoded in each of our demo apps. This way it was easier to
    focus on other important parts of the graphics pipeline. As we go into the territory
    of more complex graphics applications, we require additional control over the
    storage of different 3D meshes in system memory and GPU buffers. However, our
    focus still remains on guiding you through the main principles and practices rather
    than on pure efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn how to store and handle mesh geometry data in
    a more organized way. We will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating level-of-detail meshes using MeshOptimizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing programmable vertex pulling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rendering instanced geometry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing instanced meshes with compute shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an infinite grid GLSL shader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating tessellation into the graphics pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizing the mesh data storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing automatic geometry conversion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indirect rendering in Vulkan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating textures in Vulkan using compute shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing computed meshes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To run the code from this chapter on your Linux or Windows PC, you’ll require
    a GPU with up-to-date drivers that support Vulkan 1.3\. The source code can be
    downloaded from [https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook](https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook).
  prefs: []
  type: TYPE_NORMAL
- en: To run the demo applications from this chapter, you are advised to download
    and unpack the entire Amazon Lumberyard Bistro dataset from the McGuire Computer
    Graphics Archive [http://casual-effects.com/data/index.xhtml](http://casual-effects.com/data/index.xhtml).
    You can do it automatically by running the `deploy_deps.py` script.
  prefs: []
  type: TYPE_NORMAL
- en: Generating level-of-detail meshes using MeshOptimizer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started with geometry manipulations, let’s implement a mesh geometry
    simplification demo using the MeshOptimizer library that, besides mesh optimizations,
    can generate simplified meshes for real-time discrete **level-of-detail** (**LOD**)
    algorithms we might want to use later. Simplification is an efficient way to improve
    rendering performance.
  prefs: []
  type: TYPE_NORMAL
- en: For GPUs to render a mesh efficiently, all vertices in the vertex buffer should
    be unique and without duplicates. Solving this problem efficiently can be a complicated
    and computationally intensive task in any modern 3D content pipeline. MeshOptimizer
    is an open-source C++ library developed by Arseny Kapoulkine, which provides algorithms
    to help optimize meshes for modern GPU vertex and index processing pipelines.
    It can reindex an existing index buffer or generate an entirely new set of indices
    from an unindexed vertex buffer.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s learn how to optimize and generate simplified meshes with MeshOptimizer.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is recommended that you revisit *Chapter 3*, *Working with Vulkan Objects*.
    The complete source code for this recipe can be found in `Chapter05/01_MeshOptimizer`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`MeshOptimizer` can generate all necessary LOD meshes for a specified set of
    indices and vertices. Once we have our loaded mesh with `Assimp`, we can pass
    it to `MeshOptimizer`. Here’s how to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s load a mesh from a `.gltf` file using `Assimp`. For this demo, we need
    only vertex positions and indices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The LOD meshes are represented as a collection of indices that construct a
    new simplified mesh from the same vertices that are used for the original mesh.
    This way we have to store only one set of vertices and can render corresponding
    LODs just by switching index buffers data. As done previously, we store all indices
    as unsigned 32-bit integers for simplicity. Now we should generate a remap table
    for our existing vertex and index data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The MeshOptimizer documentation ([https://github.com/zeux/meshoptimizer](https://github.com/zeux/meshoptimizer))
    tells us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“…the remap table is generated based on binary equivalence of the input vertices,
    so the resulting mesh will be rendered in the same way.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The returned `vertexCount` value corresponds to the number of unique vertices
    that have remained after remapping. Let’s allocate space and generate new vertex
    and index buffers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we can use other `MeshOptimizer` algorithms to optimize these buffers even
    further. The official documentation is pretty straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we want to render a mesh, the GPU has to transform each vertex via a vertex
    shader. GPUs can reuse transformed vertices by means of a small built-in cache,
    usually storing between 16 and 32 vertices inside it. In order to use this small
    cache effectively, we need to reorder the triangles to maximize the locality of
    vertex references. How to do this with `MeshOptimizer` in place is shown next.
    Pay attention to how only the indices data is being touched here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Transformed vertices form triangles that are sent for rasterization to generate
    fragments. Usually, each fragment is run through a depth test first, and fragments
    that pass the depth test get the fragment shader executed to compute the final
    color. As fragment shaders get more and more expensive, it becomes increasingly
    important to reduce the number of fragment shader invocations. This can be achieved
    by reducing pixel overdraw in a mesh, and, in general, it requires the use of
    view-dependent algorithms. However, `MeshOptimizer` implements heuristics to reorder
    triangles and minimize overdraw from all directions. We can use it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The last parameter, `1.05`, is the threshold that determines how much the algorithm
    can compromise the vertex cache hit ratio. We use the recommended default value
    from the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have optimized the mesh to reduce pixel overdraw, the vertex buffer
    access pattern can still be optimized for memory efficiency. The GPU has to fetch
    specified vertex attributes from the vertex buffer and pass this data into the
    vertex shader. To speed up this fetch, a memory cache is used, which means optimizing
    the locality of vertex buffer access is very important. We can use MeshOptimizer
    to optimize our index and vertex buffers for vertex fetch efficiency, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This function will reorder vertices in the vertex buffer and regenerate indices
    to match the new contents of the vertex buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we will do in this recipe is simplify the mesh. MeshOptimizer
    can generate a new index buffer that uses existing vertices from the vertex buffer
    with a reduced number of triangles. This new index buffer can be used to render
    LOD meshes. The following code snippet shows you how to do this using the default
    threshold and target error values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s take a look at how rendering of the LOD meshes works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to render the mesh and its lower-level LOD, we need to store a vertex
    buffer and two index buffers – one for the mesh and one for the LOD:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the vertex buffer for storing vertex positions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We use two index buffers to store both sets of indices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The rendering part is trivial, and the graphics pipeline setup is skipped here
    for the sake of brevity. We render the main mesh using the first index buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we render the LOD mesh using the second index buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here’s a screenshot from the running demo application.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1: A mesh with a discrete LOD](img/file31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: A mesh with a discrete LOD'
  prefs: []
  type: TYPE_NORMAL
- en: Try changing the `threshold` parameter in the code to generate meshes with different
    LOD.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `MeshOptimizer` library contains many other useful algorithms, such as triangle
    strip generation, index and vertex buffer compression, and mesh animation data
    compression. All of these algorithms might be very useful for your geometry preprocessing
    stage depending on the kind of graphics software you are writing. Check out the
    official documentation and the releases page to get the latest features at [https://github.com/zeux/meshoptimizer](https://github.com/zeux/meshoptimizer).
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 9*, *Advanced Rendering Techniques and Optimization*, we will learn
    how to render LODs in a GPU-friendly and performant way.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing programmable vertex pulling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of **programmable vertex pulling** (**PVP**) was proposed in an
    article called *Introducing the Programmable Vertex Pulling Rendering Pipeline*
    by Daniel Rákos, published in the amazing book *OpenGL Insights* in 2012\. That
    article goes deep into the architecture of GPUs of that time and why it was beneficial
    to use this data storage approach. Initially, the idea of vertex pulling was to
    store vertex data inside one-dimensional buffer textures and, instead of setting
    up standard vertex input bindings. Then read the data using `texelFetch()` and
    GLSL `samplerBuffer` in the vertex shader. The built-in OpenGL GLSL `gl_VertexID`
    variable was used as an index to calculate texture coordinates for texel fetching.
    The reason for this trick was that because developers were hitting CPU limits
    with many draw calls, it was beneficial to combine multiple meshes inside a single
    buffer and render them in a single draw call without rebinding any vertex arrays
    or buffer objects to improve the batching of draw calls.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, buffer textures are no longer required and the vertex data can be
    fetched directly from storage or uniform buffers using offsets calculated via
    the built-in Vulkan GLSL `gl_VertexIndex` variable.
  prefs: []
  type: TYPE_NORMAL
- en: This technique opens up possibilities for merge-instancing, where many small
    meshes can be merged into a bigger one to be handled as a part of the same batch.
    We will extensively use this technique in our examples starting from *Chapter
    7*, *Graphics Rendering Pipeline*.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will use storage buffers to implement a similar technique
    with Vulkan 1.3 and *LightweightVK*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The complete source code for this recipe can be found in the source code bundle
    under the name `Chapter05/02_VertexPulling`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s render the rubber duck 3D model `data/rubber_duck/scene.gltf` from the
    previous recipe. However, this time, instead of using vertex attributes, we will
    be using the programmable vertex-pulling technique. The idea is to allocate two
    buffers, one buffer for indices and another storage buffer for the vertex data,
    and access them in the vertex shader to fetch vertex positions. This is how we
    can do it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we load the 3D model via `Assimp`, as in the previous recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert per-vertex data into a format suitable for our GLSL shaders. We are
    going to use `vec3` for positions and `vec2` for texture coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'For simplicity, we store indices as unsigned 32-bit integers. In real-world
    applications, consider using 16-bit indices for small meshes and be capable of
    switching between them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the index and vertex data are ready, we can upload them into the Vulkan
    buffers. We should create two buffers, one for the vertices and one for the indices.
    Not that here, despite calling it a vertex buffer, we set the usage flag to `lvk::BufferUsageBits_Storage`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create a render pipeline for our mesh. We will look into the shader
    code in a few moments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s load a texture for our mesh and create a proper depth state:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Before we can proceed with the actual rendering, we should pass the texture
    ID and storage buffer address to our GLSL shader. We can do it using Vulkan push
    constants. Model-view-projection matrix calculations are reused from the previous
    recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now, the mesh rendering can done as follows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The rest of the C++ code can be found in `Chapter05/02_VertexPulling/src/main.cpp`.
    Now, we have to look into the GLSL vertex shader to understand how to read the
    vertex data from buffers. The vertex shader can be found in `Chapter05/02_VertexPulling/src/main.vert`:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we have some declarations shared between all shaders. The reason for
    this sharing is that our fragment shader needs to access push constants to retrieve
    the texture ID. Note that the `Vertex` structure does not use `vec2` and `vec3`
    member fields to maintain tight padding and prevent any GPU alignment issues.
    This structure reflects how our C++ code writes vertex data into the buffer. The
    buffer holds an unbounded array `in_Vertices[]`. Each element corresponds to exactly
    one vertex.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Let’s introduce two accessor functions to make the shader code more readable.
    The assemble `vec3` and `vec2` values are from the raw float values in the storage
    buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The rest of the shader is trivial. The previously mentioned functions are used
    to load the vertex positions and texture coordinates, which are passed further
    into the graphics pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s it for the PVP part. The fragment shader applies the texture and uses
    the barycentric coordinates trick for wireframe rendering as was described in
    the previous chapter. The resulting output from the program should look like the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2: Textured mesh rendering using PVP](img/file32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: Textured mesh rendering using PVP'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PVP is a complex topic and has different performance implications. There is
    an open-source project that does an in-depth analysis and run-time metrics of
    PVP performance based on different vertex data layouts and access methods, such
    as storing data as an array of structures or a structure of arrays, reading data
    as multiple floats or a single vector type, and so on. Check it out at [https://github.com/nlguillemot/ProgrammablePulling](https://github.com/nlguillemot/ProgrammablePulling).
    It should become one of your go-to tools when designing PVP pipelines in your
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Rendering instanced geometry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common task in geometry rendering is drawing multiple meshes that share the
    same geometry but have different transformations and materials. This can lead
    to additional CPU overhead in generating all the necessary commands to instruct
    the GPU to draw each mesh individually. It occurs even though the Vulkan API already
    has significantly lower CPU overhead. One possible solution to this problem, provided
    by modern graphics APIs such as Vulkan, is instanced rendering. API draw commands
    can take a number of instances as a parameter and a vertex shader has access to
    the current instance number `gl_InstanceIndex`. Combined with the PVP approach
    demonstrated in the previous recipe, this technique can become incredibly flexible.
    Indeed, `gl_InstanceIndex` can be used to read all necessary material properties,
    transforms, and other data from buffers. Let’s take a look at a basic instanced
    geometry demo to learn how to do it in Vulkan.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Make sure to read the previous recipe, *Implementing programmable vertex pulling*,
    to understand the notion of generating vertices data inside vertex shaders. The
    source code for this recipe can be found in `Chapter05/03_MillionCubes`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To demonstrate how instanced rendering can work, let’s render 1 million colored
    rotating cubes. Each cube should have its own distinct rotation angle around its
    diagonal and should be textured with an overlay of one of a few different colors.
    Let’s take a look at the C++ code in `03_MillionCubes/src/main.cpp`:'
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s generate a procedural texture for our cubes. An XOR pattern texture
    looks quite interesting. It is generated by XOR-ing the `x` and `y` coordinates
    of the current texel and then applying the result to all three BGR channels by
    bitshifts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Let’s create `vec3` positions and `float` initial rotation angles for 1 million
    cubes. We can organize this data into `vec4` containers and store them in an immutable
    storage buffer. The GLSL shader code will then perform calculations based on the
    elapsed time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We skip the traditional framebuffer and pipeline creation code and jump straight
    into the main rendering loop. The camera motion is hardcoded so it moves back
    and forth through the swarm of the cubes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We pass all the necessary data to shaders using push constants. Our vertex shader
    is going to need the current time to do the calculations based on the initial
    cube positions and rotations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Rendering is started via `vkCmdDraw()`, which hides inside `cmdDraw()`. The
    first parameter is the number of vertices we need to generate a cube using triangle
    primitives. We will look at how it is handled in the vertex shader in a moment.
    The second parameter, `kNumCubes`, is the number of instances to be rendered.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s take a look at the GLSL code to understand how this instancing demo
    works under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our vertex shader starts by declaring the same `PerFrameData` structure as in
    our C++ code mentioned above. The shader outputs per-vertex color and texture
    coordinates. The storage buffer contains positions and initial angles for all
    the cubes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As you may have noticed, the C++ code in the *How to do it…* section did not
    provide any index data to shaders. Instead, we a going to generate vertex data
    in the vertex shader. Let’s declare indices mapping right here. We need indices
    to construct `6` cube faces using triangles. Two triangles per face gives `6`
    points per face and `36` indices in total. That is the number passed to `vkCmdDraw()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here are the per-instance colors for our cubes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As there are no translation and rotation matrices passed to the vertex shader,
    we have to generate everything ourselves right here. Here’s a GLSL function to
    apply a translation by a vector `v` to the current transformation `m`. This function
    is a counterpart to the C++ function `glm::translate()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Rotations are handled in a similar way. This is an analogue of `glm::rotate()`
    ported to GLSL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: With this extensive arsenal at our disposal, we can now write the `main()` function
    of our vertex shader. The built-in `gl_InstanceIndex` variable is used to index
    the storage buffer and retrieve positions and angles. Then, a model matrix for
    the current cube is computed using the `rotate()` and `translate()` helper functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The built-in `gl_VertexIndex` variable ranges from `0` to `35`, helping us extract
    the specific index for `8` of our vertices. Then we use this simple binary formula
    to generate `vec3` positions for each of those `8` vertices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Remap the `0...1` vertex coordinates into the `-1…+1` coordinates and scale
    by the desired `edge` length:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The UV coordinates are selected on a per-face basis, and the colors are per
    instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s all the magic that happens in the vertex shader. The fragment shader
    is pretty trivial and short:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The running demo should look as in the following screenshot. You are flying
    through a swarm of 1 million cubes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3: One million cubes using instanced rendering](img/file33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: One million cubes using instanced rendering'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While this example is self-contained and very fast compared to non-instanced
    rendering, it can be made even faster if the indices are moved out of the vertex
    shader and stored in a dedicated index buffer to take advantage of the hardware
    vertex cache and model matrices are calculated per-instance and not per-vertex.
    We will cover this in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s extend this instancing example a bit further and draw some meshes
    using real mesh data.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing instanced meshes with compute shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the last recipe, we learned the fundamentals of instanced rendering. Although
    that approach covers various aspects of rendering geometry instances, such as
    handling model matrices and materials, it’s not yet a practical implementation.
    Let’s expand on that example and demonstrate how to render instanced meshes loaded
    from a `.gltf` file.
  prefs: []
  type: TYPE_NORMAL
- en: To add a bit more complexity to this example, we’ll enhance it by precalculating
    per-instance model matrices using a compute shader.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Make sure you read the previous recipe, *Rendering instanced geometry*. The
    source code for this recipe can be found in `Chapter05/04_InstancedMeshes`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s skim the C++ code to understand the big picture
  prefs: []
  type: TYPE_NORMAL
- en: First, we generate random positions and initial rotation angles for our meshes.
    We use 32,000 meshes because our GPU cannot handle 1 million meshes with this
    naïve brute-force approach. Pushing it to 1 million meshes is possible, and we
    will show some tricks to approach that number in *Chapter 11*, *Advanced Rendering
    Techniques and Optimizations*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The center points and angles are loaded into a storage buffer in exactly the
    same way as in the previous recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: To store model matrices for our instances, we’ll require two buffers. We’ll
    alternate between them in a round-robin fashion during even and odd frames to
    prevent unnecessary synchronization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The rubber duck 3D model is loaded from `.gltf` the following way. This time,
    besides vertex positions and texture coordinates, we require normal vectors to
    do some improvized lighting. We are going to need it when we render so many meshes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The mesh data is uploaded into index and vertex buffers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Let’s load the texture and create compute and rendering pipelines. The compute
    shader will generate model matrices for our instances based on the elapsed time,
    following the approach used in the vertex shader in the previous recipe, *Rendering
    instanced meshes*. However, this time, we’ll do it on a per-instance basis instead
    of per vertex.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The main loop goes like this. We use the `frameId` counter to facilitate the
    switching of buffers containing model matrices between even and odd frames.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'For convenience, push constants are shared between compute and rendering pipelines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Dispatch the compute shader. Each local workgroup handles 32 meshes – a common
    portable baseline supported by many GPUs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: After the compute shader has finished updating model matrices, we can start
    rendering. Note that we have a non-empty dependencies parameter here, which refers
    to the buffer with model matrices. This is necessary to make sure a proper Vulkan
    buffer memory barrier is issued by *LightweightVK* to prevent race conditions
    between the compute shader and the vertex shader.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s look at the barrier. The source and destination stages, respectively,
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'And:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The underlying Vulkan barrier looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The rest of the rendering code is pretty standard. The *LightweightVK* draw
    call command, `cmdDrawIndexed()`, takes the number of indices in our mesh and
    the number of instances `kNumMeshes`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s delve into the GLSL implementation details to understand how it works
    internally.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first part is the compute shader, which prepares data for rendering. Let’s
    take a look at `Chapter05/04_InstancedMeshes/src/main.comp`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The compute shader processes 32 meshes in one local workgroup. Push constants
    are shared between the compute shader and the graphics pipeline. They are declared
    in an include file, `Chapter05/04_InstancedMeshes/src/common.sp`. We provide that
    file here for your convenience:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The matrices buffer reference declaration is not shared. Here, in the compute
    shader, it is declared as `writeonly`, while the vertex shader will declare it
    as `readonly`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Helper functions `translate()` and `rotate()` mimic the `glm::translate()` and
    `glm::rotate()` C++ functions in GLSL. They are reused from the previous recipe,
    *Rendering instanced geometry*, in their entirety. As they are quite long, we
    will not duplicate them here.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The `main()` function reads a `vec4` value containing the center point and initial
    angle, and calculates a model matrix. This is exactly the same computation we
    did in the vertex shader in the previous recipe. The model matrix is then stored
    in a storage buffer referenced by `bufMatricesId`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: As we moved most of the calculations into the compute shader, the shaders for
    the rendering pipeline became significantly shorter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader uses the same shared declarations for push constants and
    buffer references:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex data contains normal vectors, as was declared in the C++ code earlier
    in this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex data is retrieved from the “vertex” storage buffer, and the model
    matrix is obtained from the matrices buffer, which was updated by the compute
    shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can calculate the value of `gl_Position` and pass the normal vector
    and texture coordinates to our fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader is quite straightforward. We perform some improvized diffuse
    lighting calculations to enhance the distinctiveness of the meshes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: The running demo application should render a swarm of rotating rubber ducks,
    as shown in the following screenshot, while the camera flies through them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4: A swarm of rotating rubber ducks using instanced rendering](img/file34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: A swarm of rotating rubber ducks using instanced rendering'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you may have noticed, this demo utilizes only `32,768` instances compared
    to `1` million instances in the previous recipe. The reason for this difference
    is that the cube used in the previous example had only `36` indices, while the
    rubber duck model in this case has `33,216`, which is almost 1,000 times more.
  prefs: []
  type: TYPE_NORMAL
- en: The naive brute force approach won’t suffice for this dataset. We need to employ
    additional tricks to render `1` million duckies, such as culling and GPU-level-of-detail
    management. We’ll delve into some of these topics in *Chapter 11*, *Advanced Rendering
    Techniques and Optimizations*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s switch gears and learn how to render some debug grid geometry before
    proceeding with examples of more complex mesh rendering.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an infinite grid GLSL shader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous recipes of this chapter, we learned how to approach geometry
    rendering. To debug our applications, it is useful to have a visible representation
    of the coordinate system so that a viewer can quickly infer the camera orientation
    and position just by looking at a rendered image. A natural way to represent a
    coordinate system in the image is to render an infinite grid where the grid plane
    is aligned with one of the coordinate planes. Let’s learn how to implement a decent-looking
    grid in GLSL.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full C++ source code for this recipe can be found in `Chapter05/05_Grid`.
    The corresponding GLSL shaders will be reused in subsequent recipes, so they are
    located in the shared data folder in the `data/shaders/Grid.vert` and `data/shaders/Grid.frag`
    files.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To parametrize our grid, we should introduce some constants. They can be found
    and tweaked in the `data/shaders/GridParameters.h` GLSL include file. Let’s take
    a look inside:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we need to define the size of our grid extents in the world coordinates.
    That is how far from the camera the grid is visible:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The size of one grid cell is specified in the same units as the grid size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Let’s define the colors of the grid lines. We will use two different colors,
    one for regular thin lines and the other for thick lines, which are rendered in
    every tenth line. Since we render everything against a white background, we are
    good with black and 50% gray.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Our grid implementation will change the number of rendered lines based on the
    grid LOD. We will switch LOD when the number of pixels between two adjacent grid
    cell lines drops below this value, as calculated in the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Let’s take a look at a simple vertex shader we use to generate and transform
    grid vertices. It takes in the current model-view-projection matrix, the current
    camera position, and the grid origin. The origin is in world space and can be
    used to move the grid around.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The built-in `gl_VertexIndex` variable is used to access hardcoded quad indices
    and vertices `pos[]`. The `-1…+1` points are scaled by the desired grid size.
    The resulting vertex position is translated by the 2D camera in the horizontal
    plane and, then, by the 3D origin position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader is somewhat more complex. It will calculate a programmatic
    texture that looks like a grid. The grid lines are rendered based on how fast
    the `uv` coordinates change in the screen space to avoid the Moiré pattern, hence
    we are going to need screen space derivatives. The screen space derivative of
    a variable in your shader measures how much that variable changes from one pixel
    to the next. The GLSL function `dFdx()` represents the horizontal change, while
    `dFdy()` represents the vertical change. It measures how fast a GLSL variable
    changes as you move across the screen, approximating its partial derivatives in
    calculus terms. This approximation is due to relying on discrete samples at each
    fragment, rather than doing a mathematical evaluation of the change:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we introduce a bunch of GLSL helper functions to aid our calculations.
    They can be found in `data/shaders/GridCalculation.h`. The function names `satf()`
    and `satv()` stand for saturate-float and saturate-vector respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look into the `gridColor()` function, which is invoked from `main()`,
    and start by calculating the screen space length of the derivatives of the `uv`
    coordinates we previously generated in the vertex shader. We use built-in `dFdx()`
    and `dFdy()` functions to calculate the required derivatives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Knowing the derivatives, the current LOD of our grid can be calculated in the
    following way. The `gridMinPixelsBetweenCells` value controls how fast we want
    our LOD to increase. In this case, it is the minimum number of pixels between
    two adjacent cell lines of the grid:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Besides the LOD value, we are going to need a fading factor to render smooth
    transitions between the adjacent levels. It can be obtained by taking a fractional
    part of the floating point LOD level. The logarithm base `10` is used to ensure
    each LOD covers `pow(10, lodLevel)` more cells than the previous size.
  prefs: []
  type: TYPE_NORMAL
- en: 'The LOD levels are blended with each other. To render them, we have to calculate
    the cell size for each LOD. Here, instead of calculating `pow()` three times,
    which is done purely for the sake of explanation, we can calculate it only for
    `lod0` and multiply each subsequent LOD cell size by `10.0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'To be able to draw anti-aliased lines using alpha transparency, we need to
    increase the screen coverage of our lines. Let’s make sure each line covers up
    to `4` pixels. Shift grid coordinates to the centers of anti-aliased lines for
    subsequent alpha calculations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we should get coverage alpha value corresponding to each calculated LOD
    level. To do that, we calculate absolute distances to cell line centers for each
    LOD and pick the maximum coordinate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Non-zero alpha values represent non-empty transition areas of the grid. Let’s
    blend between them using two colors to handle LOD transitions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Last but not least, make the grid disappear when it is far away from the camera.
    Use the `gridSize` value to calculate the opacity falloff:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can blend between the LOD level alpha values and scale the result with
    the opacity falloff factor. The resulting pixel color value can be stored in the
    framebuffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The abovementioned shaders in `data/shaders/GridCalculation.h` should be rendered
    using the following render pipeline state, which is created in `Chapter05/05_Grid/src/main.cpp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The C++ rendering code in the same file looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out the complete `Chapter05/05_Grid` for a self-contained demo app. The
    camera can be controlled with the WASD keys and a mouse. The resulting image should
    look like in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5: GLSL grid](img/file35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: GLSL grid'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Besides considering only the distance to the camera to calculate the antialiasing
    falloff factor, we can use the angle between the viewing vector and the grid line.
    This will make the overall look and feel of the grid more visually pleasing and
    can be an interesting improvement if you want to implement a grid not only as
    an internal debugging tool but also as a part of a customer-facing product, like
    an editor.
  prefs: []
  type: TYPE_NORMAL
- en: This implementation was inspired by the *Our Machinery* blog. Unfortunately,
    it is not available anymore. However, there are some other advanced materials
    available on the internet showing how to render a more complex grid suitable for
    customer-facing rendering. Make sure you read the blog post *The Best Darn Grid
    Shader (Yet)* by Ben Golus [https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f9278b9d8](https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f9278b9d8),
    which takes grid rendering a lot further.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to the next recipe, we want to mention that grid rendering
    is quite handy, and we’ve included it in most of our subsequent demo applications.
    You can use the `VulkanApp::drawGrid()` function to render this grid anywhere
    you want.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating tessellation into the graphics pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s switch gears and learn how to integrate hardware tessellation into the
    Vulkan graphics rendering pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware tessellation is implemented as a set of two new shader stage types
    in the graphics pipeline. The first shader stage is called the **tessellation
    control shader**, and the second stage is called the **tessellation evaluation
    shader**. The tessellation control shader operates on a set of vertices, which
    are called control points and define a geometric surface called a patch. The shader
    can manipulate the control points and calculate the required tessellation level.
    The tessellation evaluation shader can access the barycentric coordinates of the
    tessellated triangles and can use them to interpolate any required per-vertex
    attributes such as texture coordinates and colors. Let’s go through the code to
    see how these new shader stages can be used to triangulate a mesh depending on
    the distance to the camera.
  prefs: []
  type: TYPE_NORMAL
- en: Using tessellation shaders for hardware tessellation might not be as efficient
    on modern GPUs as using mesh shaders. Regrettably, as of the time this book was
    written, there is no standardized API for mesh shaders in core Vulkan. So, for
    now, let’s stick with the old tessellation approach.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The complete source code for this recipe is located in `Chapter05/06_Tessellation`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What we want to do now is write shaders that will calculate per-vertex tessellation
    levels based on the distance to the camera. This way, we can render more geometrical
    details in the areas that are closer to the viewer. To do that, we should start
    with the `Chapter05/06_Tessellation/src/main.vert` vertex shader, which will compute
    the world positions of vertices and pass them down to the tessellation control
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our per-frame data consist of the usual view and projection matrices, together
    with the current camera position in the world space, and the tessellation scaling
    factor, which is user-controllable and comes from an ImGui widget. This data does
    not fit into `128` bytes of push constants, so we put everything into a buffer.
    Geometry is accessed using the PVP technique and stored in the following format
    using `vec3` for vertex positions and `vec2` for texture coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s write some helper functions to access vertex positions and texture coordinates
    using the traditional GLSL data types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex shader outputs UV texture coordinates and per-vertex world positions.
    The actual calculation is done as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can go further to the next shader stage and take a look at the tessellation
    control shader `Chapter05/06_Tessellation/src/main.tesc`:'
  prefs: []
  type: TYPE_NORMAL
- en: The shader operates on a group of `3` vertices that correspond to a single triangle
    in the input data. The `uv_in` and `worldPos_in` variables correspond to the ones
    in the vertex shader. Note how here we have arrays instead of single solitary
    values. The `PerFrameData` structure should be exactly the same for all shader
    stages in this example and comes from `common.sp`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s describe the input and output data structures that correspond to each
    individual vertex. Besides the required vertex position, we store `vec2` texture
    coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The `getTessLevel()` function calculates the desired tessellation level based
    on the distance of two adjacent vertices from the camera. The hardcoded distance
    values that are used to switch the levels are scaled using the `tessellationScale`
    uniform coming from the UI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'The `main()` function is straightforward. It passes the positions and UV coordinates
    as-is and then calculates the distance from each vertex in the triangle to the
    camera:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on these distances, we can calculate the required inner and outer tessellation
    levels in the following way. The inner tessellation level defines how the inner
    part of a triangle is subdivided into smaller triangles. The outer level defines
    how the outer edges of the triangle are subdivided so that they can be correctly
    connected to adjacent triangles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at the tessellation evaluation shader `Chapter05/06_Tessellation/src/main.tese`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should specify triangles as the input. The `equal_spacing` spacing mode
    tells Vulkan that the tessellation level `n` should be clamped to the range `0...64`
    and rounded to the nearest integer. After that, the corresponding edge should
    be divided into `n` equal segments. When the tessellation primitive generator
    produces triangles, the orientation of triangles can be specified by an input
    layout declaration using the identifiers `cw` and `ccw`. We use the counter-clockwise
    orientation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'These two helper functions are useful for interpolating between the `vec2`
    and `vec4` attribute values at the corners of the original triangle using barycentric
    coordinates of the current vertex. The built-in `gl_TessCoord` variable contains
    the required barycentric coordinates, `0…1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The actual interpolation code in `main()` is straightforward and can be written
    in the following way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The next stage of our hardware tessellation graphics pipeline is the geometry
    shader `Chapter05/06_Tessellation/src/main.geom`. We use it to generate barycentric
    coordinates for all the small tessellated triangles. It is used to render a nice
    antialiased wireframe overlay on top of our colored mesh, as we did earlier in
    this chapter in the *Generating LODs using MeshOptimizer* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The geometry shader consumes triangles generated by the hardware tessellator
    and outputs triangle strips, each consisting of a single triangle:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Barycentric coordinates are assigned per vertex using these hardcoded constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The final stage of this rendering pipeline is the fragment shader `Chapter05/06_Tessellation/src/main.frag`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We take in the barycentric coordinates from the geometry shader and use them
    to calculate a wireframe overlay covering our mesh:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'A helper function returns the blending factor based on the distance to the
    edge and the desired thickness of the wireframe contour. Essentially, when one
    of the `3` barycentric coordinate values is close to `0`, it indicates that the
    current fragment is near one of the triangle’s edges. The distance to zero controls
    the visible thickness of a rendered edge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s sample the texture using the provided UV values and call it a day:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The GLSL shader part of our Vulkan hardware tessellation pipeline is over,
    and it is time to look into the C++ code. The source code is located in the `Chapter05/06_Tessellation/src/main.cpp`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The shaders for the tessellated mesh rendering are loaded the following way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create a corresponding rendering pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The `data/rubber_duck/scene.gltf` mesh loading code is identical to that from
    the previous recipes, so we’ll skip it here. What’s more important is how we render
    the mesh and ImGui widget to control the tessellation scale factor. Let’s take
    a look at the body of the rendering loop:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we calculate model-view-projection matrices for our mesh:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Per-frame data is uploaded into a buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Push constants are used to pass an address of the buffer into shaders. Then
    we can render the mesh using our tessellation pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'We add a grid on top, as was described earlier in this chapter in the *Implementing
    an infinite grid GLSL shader* recipe. The origin is used to place the grid just
    under the duck model. Inside our frame rendering loop, we can access all the ImGui
    rendering functionality as usual. Here, we just render a single slider containing
    a floating-point value for the tessellation scale factor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a screenshot from the running demo application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6: Tessellated duck](img/file36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: Tessellated duck'
  prefs: []
  type: TYPE_NORMAL
- en: Note how the different tessellation level varies based on the distance to the
    camera. Try playing with the control slider to emphasize the effect.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This recipe can be used as a cornerstone of hardware mesh tessellation techniques
    in your Vulkan applications. One natural step forward would be to apply a displacement
    map to the fine-grained tessellated vertices using the direction of normal vectors.
    Check out this page for inspiration: [https://www.geeks3d.com/20100804/test-opengl-4-tessellation-with-displacement-mapping](https://www.geeks3d.com/20100804/test-opengl-4-tessellation-with-displacement-mapping).
    For those who want to go serious on adaptive tessellation of subdivision surfaces,
    there is a chapter in the *GPU Gems 2* book covering this advanced topic in great
    detail. It is now available online at [https://developer.nvidia.com/gpugems/gpugems2/part-i-geometric-complexity/chapter-7-adaptive-tessellation-subdivision-surfaces](https://developer.nvidia.com/gpugems/gpugems2/part-i-geometric-complexity/chapter-7-adaptive-tessellation-subdivision-surfaces).'
  prefs: []
  type: TYPE_NORMAL
- en: Organizing mesh data storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapters, we used fixed hardcoded vertex formats for our meshes,
    which changed between demos, and also implicitly included the material description.
    For example, a hardcoded texture was used to provide color information. A triangle
    mesh is defined by indices and vertices. Each vertex is defined as a set of attributes
    with distinct data formats corresponding to the `lvk::VertexInput` vertex input
    description. All auxiliary physical properties of an object, such as collision
    detection data, mass, and moments of inertia, can be represented by a mesh, while
    other information, such as surface material properties, can be stored outside
    of the mesh as external metadata. It’s worth noting that small 3D models, like
    the rubber duck we used before, can be loaded pretty quickly. However, larger
    and more intricate real-world 3D models, especially when using transmission formats
    like `.gltf`, may take several minutes to load. Using a run-time mesh format can
    address this issue by eliminating any parsing and replacing it with flat buffer
    loading, which matches internal rendering data structures. This involves employing
    fast functions like `fread()` and similar mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s define a unified mesh storage format covering all the use cases for the
    remaining part of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This recipe describes the basic data structures we will use to store mesh data
    throughout the rest of this book. The full corresponding source code is located
    in the header file `shared/Scene/VtxData.h`. Make sure you’ve read *Chapter 2*,
    *Getting Started with Vulkan* before going forward.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A vector of homogeneous **vertex attributes** stored contiguously is called
    a **vertex stream**. Examples of such attributes are vertex positions, texture
    coordinates, and normal vectors, each of the three representing one attribute.
    Each stream must have a format. Vertex positions are `vec3`, texture coordinates
    can be `vec2`, normal vectors can use the packed format `Int_2_10_10_10_REV`,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s define a **LOD** as an index buffer of reduced size that uses existing
    vertices and hence can be used directly for rendering with the original vertex
    buffer. We learned how to create LODs earlier in this chapter in the *Generating
    LODs using MeshOptimizer* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: We define a **mesh** as a collection of all vertex data streams and a collection
    of all index buffers, one for each LOD. The number of elements in each vertex
    data stream is the same and is called the “vertex count”, which we will encounter
    in the instructions below. To make things a bit simpler, we always use 32-bit
    offsets and indices for our data.
  prefs: []
  type: TYPE_NORMAL
- en: All the vertex data streams and LOD index buffers are packed into a single blob.
    This allows us to load the data in a single `fread()` call or even use memory
    mapping to allow direct data access. This simple vertex data representation also
    enables direct upload of meshes into the GPU. What makes it particularly interesting
    is the ability to merge data for multiple meshes into a single file. Alternatively,
    this can be achieved by consolidating the data into two large buffers — one for
    indices and the other for vertex attributes. This will come in very handy later
    when we learn how to implement a LOD switching technique on GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we will deal only with geometrical data. The LOD creation process
    is covered in the recipe *Generating LODs using MeshOptimizer* and the material
    data export process is covered in the subsequent chapters. Let’s take a look at
    `shared/Scene/VtxData.h` and declare the main data structures for our mesh:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to define an individual mesh description. We deliberately avoid
    using pointers, which hide memory allocations and prohibit simple saving and loading
    of the data. We store offsets to individual data streams and LOD index buffers,
    which are equivalent to pointers, but are more flexible and, most importantly,
    more GPU-friendly. All the offsets in the `Mesh` structure are given relative
    to the beginning of the data block. Let’s declare our main data structure for
    a mesh. It contains the number of LODs and vertex data streams. The LOD count,
    where the original mesh counts as one of the LODs, must be strictly less than
    `kMaxLODs`, because we do not store LOD index buffer sizes but calculate them
    from offsets. To calculate these sizes, we store one extra empty LOD level at
    the end. The number of vertex data streams is stored directly with no modifications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The `vertexCount` field contains the total number of vertices in this mesh.
    This number is described the content of the vertex buffer and can be greater than
    the number of vertices on any individual level of detail. We postpone the question
    of material data storage to the next chapters. To do this in an elegant manner,
    let’s introduce a level of indirection. The `materialID` field contains an abstract
    identifier that allows us to reference any material data stored elsewhere:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'Each mesh can potentially be displayed at different LODs. The file contains
    all indices for all levels of detail and offsets for the beginning of each LOD
    are stored in the `lodOffset` array. This array contains one extra item at the
    end, which serves as a marker to calculate the size of the last LOD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of storing the number of indices of each LOD, we define a little helper
    function to calculate that number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'As you might have noticed, the `Mesh` structure is just a sort of index into
    other buffers containing data, such as index and vertex buffers. Let’s take a
    look at that data container:'
  prefs: []
  type: TYPE_NORMAL
- en: The format of the vertex streams is described by the structure `lvk::VertexInput`.
    We already used it in *Chapter 2*, *Getting Started with Vulkan*. This form of
    vertex stream description allows very flexible storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: The actual index and vertex buffer data are stored in these containers. They
    can accommodate multiple meshes. We use only 32-bit indices in our book for the
    sake of simplicity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Another `std::vector` stores each individual mesh description:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: For completeness, we’ll also store a bounding box for each mesh right here.
    Bounding boxes are extremely useful for culling, and having them precalculated
    can significantly speed up the loading process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '**Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For this book, we are solely focusing on tightly-packed (non-interleaved) vertex
    attribute streams. However, it is not difficult to extend the proposed schema
    to support interleaved data storage by making use of the stride parameter in `lvk::VertexInput::VertexInputBinding`.
    One major drawback is that such data reorganization would require us to change
    all the vertex pulling code in shaders. If you are developing production code,
    measure which storage format works faster on your target hardware before committing
    to one particular approach.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Before we can store these mesh data structures in a file, we need some sort
    of a file header:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure data integrity and to check the validity of the header, a magic hexadecimal
    value of `0x12345678` is stored in the first 4 bytes of the header:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'The number of individual `Mesh` descriptors in this file is stored in the `meshCount`
    field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'The last two member fields store the sizes of index and vertex data in bytes,
    respectively. These values come in handy when checking the integrity of a mesh
    file as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: The file continues with the list of `Mesh` structures. After the header and
    a list of individual mesh descriptors, we store a large index and vertex data
    block, which can be loaded all at once.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s go through the pseudocode from `shared/Scene/VtxData.cpp` for loading
    such a file is just a few `fread()` calls that look as follows. Error checks are
    omitted from the book text but are present in the actual code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we read the file header with the mesh count. Error checks are skipped
    here in the book but are present in the bundled source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'Having read the header, we resize the mesh descriptors array and read in all
    `Mesh` descriptions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we read the main geometry data blocks for this mesh, which contain the
    actual index and vertex data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, index and vertex buffers can be combined into a single large
    byte buffer. We leave this as an exercise for our readers.
  prefs: []
  type: TYPE_NORMAL
- en: Later on, the `indexData` and `vertexData` containers can be directly uploaded
    to the GPU. We’ll revisit this idea in the subsequent recipes in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Although you can see the result of this code in the demo app `Chapter05/07_MeshRenderer`
    for this chapter, there are some additional functionalities that need to be implemented.
    Let’s cover a few more topics before we can run and witness the demo.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This geometry data format is pretty simple and straightforward for the purpose
    of storing static mesh data. If the meshes may be changed, reloaded, or loaded
    asynchronously, we may store separate meshes in dedicated files.
  prefs: []
  type: TYPE_NORMAL
- en: Since it is impossible to predict all the use cases and since this book is all
    about the rendering and not some general gaming engine creation, it is up to the
    reader to make decisions on adding extra features such as mesh skinning or others.
    One simple example of such a decision is the addition of material data directly
    into the mesh file. Technically, all we need to do is add a `materialCount` field
    to `MeshFileHeader` and store a list of material descriptions right after the
    list of meshes. Even such a simple thing immediately raises more questions. Should
    we pack texture data in the same file? If yes, how complex should the texture
    format be? What material model should we use? And so on, and so forth. For now,
    we just leave mesh geometry data separated from material descriptions. We will
    come back to materials in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing automatic geometry conversion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapters, we learned how to use the `Assimp` library to load
    and render 3D models stored in different file formats. In real-world graphics
    applications, the process of loading a model can be tedious and multistage. Besides
    just loading, we might want to optimize a mesh in some specific way, such as optimizing
    geometry and computing multiple LOD meshes. This process might become slow for
    sizable meshes, so it makes perfect sense to preprocess meshes offline, before
    an application starts, and load them later in the app as described in the previous
    recipe, *Organizing mesh data storage*. Let’s learn how to implement a simple
    framework for automatic geometry preprocessing and conversion.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous edition of this book, we created a standalone tool for geometry
    conversion that needs to be executed before subsequent demo apps can load the
    converted data. It turned out to be a significant oversight on our part because
    many readers dove straight into running the demo apps and then reported issues
    when things didn’t work out of the box as they expected. Here, we have rectified
    that mistake. If an app requires converted data and cannot find it, it triggers
    all the necessary code to load the data from storage assets and convert it into
    our run-time format.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The source code for our geometry conversion framework is in `Chapter05/07_MeshRenderer`.
    Low-level loader functions are defined in `shared/Scene/VtxData.cpp`. The entire
    demo application is covered by multiple recipes from this chapter, including *Organizing
    mesh data storage*, *Implementing automatic geometry conversion*, and *Indirect
    rendering in Vulkan*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let us see how the `Assimp` library is used to export the mesh data and save
    it into the binary file using the data structures defined in the *Organizing mesh
    data storage* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by exploring a function called `convertAIMesh()`, which converts the
    `Assimp` mesh representation into our run-time format and appends it to the referenced
    `MeshData` parameter. Global index and vertex offsets are updated as well. The
    function is quite lengthy, but we will explore it in full detail here. Error checks
    are omitted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'The actual mesh geometry data are stored in two following arrays. We cannot
    output converted meshes one by one, at least not in a single-pass tool, because
    we do not know the total size of data in advance, so we allocate in-memory storage
    for all the data and then write these data blobs into the output file. We also
    need a reference to the global vertex buffer, where we would append new vertices
    from this `aiMesh`. The `outLods` container is for per-LOD index buffers. Then
    we just go through all vertices of `aiMesh` and convert them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: For this recipe, we assume there is a single LOD and that all the vertex data
    is stored as a continuous data stream. In other words, we have an interleaved
    storage of the data. We also ignore all the material information and deal exclusively
    with the index and vertex data for now.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: Once we have the stream data for the vertex, we can output it into the vertex
    buffer. The position `v` is stored as `vec3`. The texture coordinates `uv` are
    stored as half-float `vec2` to save some space. The normal vector is converted
    into `2_10_10_10_REV`, which has the size of `uint32_t` – not bad for `3` floats.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`put()` is a templated function, which mem-copies the value from its second
    argument into a vector of `uint8_t`:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Describe the vertex streams for our demo: positions, texture coordinates, and
    normal vectors. The stride comes from the size of `vec3` positions, half-float
    `vec2` texture coordinates packed into `uint32_t`, and `2_10_10_10_REV` normals
    packed into `uint32_t`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'Go through all faces and create an index buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: If no LOD calculation is required, we can just store `srcIndices` as LOD 0\.
    Otherwise, we call the processLods() function, which calculates LOD levels for
    this mesh, as described in the *Generating LODs using MeshOptimizer* recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: Before updating the `indexOffset` and `vertexOffset` parameters, let’s store
    their values in the resulting `Mesh` structure. Their values represent where all
    the previous index and vertex data ended before we started converting this `aiMesh`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'Stream out all the indices for all the LOD levels one after another:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'After processing the input mesh, we increment offset counters for indices and
    the current starting vertex:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'Processing a 3D asset file by Assimp comprises loading the scene and converting
    each mesh into the internal format. Let’s take a look at the `loadMeshFile()`
    function to see how to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: The list of flags for the `aiImportFile()` function includes options that allow
    further usage of imported data without any extra processing on our side. For example,
    all the transformation hierarchies are flattened, and the resulting transformation
    matrices are applied to mesh vertices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'After importing an Assimp scene, we resize the mesh descriptor container accordingly
    and call `convertAIMesh()` for each mesh in the scene. The `indexOffset` and `vertexOffset`
    offsets are accumulated incrementally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'In the end, we precalculate axis-aligned bounding boxes for our mesh data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: Although loading and preprocessing of data should be customizable to accommodate
    needs of each individual demo app, saving is pretty much standard because `MeshData`
    contains all the information we need. As such, the saving function `saveMeshData()`
    is defined in `shared/Scene/VtxData.cpp`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Saving converted meshes into our file format is the reverse process of reading
    meshes from the file described in the *Organizing mesh data storage* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we fill the file header structure using the mesh number and offsets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'We calculate byte sizes of index and vertex data buffers and store them in
    the header:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the sizes are known, we save the header and the list of mesh descriptions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: After the header and other metadata, two blobs with index and vertex data are
    stored.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: Let’s put all this code to work in our demo app.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The mesh conversion framework is a part of our demo app. Let’s take a look
    at that part in the `Chapter05/07_MeshRenderer/src/main.cpp` file:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we check if there’s any valid cached mesh data available. The `isMeshDataValid()`
    function checks if the specified cached mesh file exists and does some routine
    sanity checks on the data sizes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we use the `isMeshDataValid()` function to load the Lumberyard Bistro
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: 'If the data is already precached, we just load it using the `loadMeshData()`
    described earlier in this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: The output mesh data is saved into the file `.cache/ch05_bistro.meshes`. Let’s
    go through the rest of this chapter to learn how to render this mesh with Vulkan.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect rendering in Vulkan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Indirect rendering is the process of issuing drawing commands to the graphics
    API, where most of the parameters to those commands come from GPU buffers. It
    is a part of many modern GPU usage paradigms and exists in all contemporary rendering
    APIs in some form. For example, we can do indirect rendering with Vulkan using
    the `vkCmdDraw*Indirect*()` family of functions. Instead of dealing with low-level
    Vulkan here, let’s get more technical and learn how to combine indirect rendering
    in Vulkan with the mesh data format we introduced in the *Organizing mesh data
    storage* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the earlier recipes, we covered building a mesh preprocessing pipeline and
    converting 3D meshes from transmission formats such as `.gltf2` into our run-time
    mesh data format. To wrap up this chapter, let’s demonstrate how to render this
    data. To delve into something new, let’s explore how to achieve this using the
    indirect rendering technique.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have defined the mesh data structures, we also need to render them.
    To do so, we allocate GPU buffers for vertex and index data using the previously
    described functions, upload all the data to the GPU, and finally, render all the
    meshes.
  prefs: []
  type: TYPE_NORMAL
- en: The whole point of the previously defined `Mesh` data structure is the ability
    to render multiple meshes in a single Vulkan command. Since version 1.0 of the
    API, Vulkan supports the technique of indirect rendering. This means we do not
    need to issue the `vkCmdDraw()` command for each and every mesh. Instead, we create
    a GPU buffer and fill it with an array of `VkDrawIndirectCommand` structures,
    then fill these structures with appropriate offsets into our index and vertex
    data buffers, and finally emit a single `vkCmdDrawIndirect()` call. The `Mesh`
    structure described in the *Organizing mesh data storage* recipe contains the
    data required to fill in `VkDrawIndirectCommand`.
  prefs: []
  type: TYPE_NORMAL
- en: The full source code for this recipe is located in `Chapter05/07_MeshRenderer`.
    It is recommended to revisit the *Organizing mesh data storage* and *Implementing
    automatic geometry conversion* recipes before reading further.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s implement a simple helper class called `VKMesh` to render our mesh using
    *LightweightVK*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We need three buffers, an index buffer, a vertex buffer, and an indirect buffer,
    as well as three shaders and a rendering pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: 'The constructor accepts references to `MeshFileHeader` and `MeshData`, which
    we loaded in the previous recipe, *Implemented automatic geometry conversion*.
    The data buffers are used as-is and uploaded directly into the respective Vulkan
    buffers. The number of indices is inferred from the indices buffer size, assuming
    indices are stored as 32-bit unsigned integers. The depth format specification
    is required to create a corresponding rendering pipeline right here in this class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: 'Create vertex and index buffers and upload the data into them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'Allocate the data storage for our indirect buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: Store the number of draw commands at the very beginning of the indirect buffer.
    This approach is not used in this demo but can be useful for GPU-driven rendering
    when the GPU calculates the number of draw commands and stores it in a buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: Fill in the content of our indirect commands buffer. Each command corresponds
    to a single `Mesh` structure. The indirect buffer should be allocated with the
    `BufferUsageBits_Indirect` usage flag.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '`DrawIndexedIndirectCommand` is just our mirror-image of `VkDrawIndexedIndirectCommand`
    to prevent including Vulkan headers into our app. While this might be an exaggeration
    for a Vulkan book, this type of separation might be useful in real-world apps
    considering this data structure is compatible in Vulkan, Metal, and OpenGL.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`struct DrawIndexedIndirectCommand { uint32_t count; uint32_t instanceCount;
    uint32_t firstIndex; uint32_t baseVertex; uint32_t baseInstance;};`'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'The rendering pipeline is created using a set of vertex, geometry, and fragment
    shaders. The geometry shader is used for barycentric coordinates generation to
    render beautiful wireframes. The vertex stream descriptions from `meshData.streams`
    can be used directly to initialize the pipeline’s vertex input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'The `draw()` method fills in a corresponding Vulkan command buffer to render
    the entire mesh. Note how `cmdDrawIndexedIndirect()` skips the first 32 bits of
    the indirect buffer where the number of commands is located. We will put that
    number to use in *Chapter 11*, *Advanced Rendering Techniques and Optimizations*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: 'This class is used as follows after the Bistro mesh is loaded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'This completes the description of our initialization process. Now, let’s turn
    to the GLSL source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The vertex shader `Chapter05/07_MeshRenderer/src/main.vert` is quite simple.
    We do not use programmable vertex fetching here for the sake of simplicity. Only
    standard per-vertex attributes are used to simplify the example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'The geometry shader, `Chapter05/07_MeshRenderer/src/main.geom`, provides the
    necessary barycentric coordinates, as described earlier in this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader, `Chapter05/07_MeshRenderer/src/main.frag`, calculates
    some improvized lighting and applies a wireframe outline based on the barycentric
    coordinates generated by the geometry shader, as described in the *Integrating
    tessellation into the graphics pipeline* recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: 'The final C++ rendering code snippet is straightforward because all the heavy
    lifting is already done inside the `VKMesh` helper class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: 'The running application will render the following image, if the image is loaded
    with the Lumberyard Bistro mesh:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7: Amazon Lumberyard Bistro mesh geometry loaded and rendered](img/file37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7: Amazon Lumberyard Bistro mesh geometry loaded and rendered'
  prefs: []
  type: TYPE_NORMAL
- en: Generating textures in Vulkan using compute shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned how to use basic compute shaders earlier in this chapter, in the
    *Implementing instanced meshes with compute shaders* recipe. It is time to go
    through a few examples of how to use them. Let’s start with some basic procedural
    texture generation. In this recipe, we implement a small program to display animated
    textures whose texel values are calculated in real time inside our custom compute
    shader. To add even more value to this recipe, we will port a GLSL shader from
    [https://www.shadertoy.com](https://www.shadertoy.com) to our Vulkan compute shader.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The compute pipeline creation code and Vulkan application initialization are
    the same as in the *Implementing instanced meshes with compute shaders* recipe.
    Make sure you read it before proceeding further. To use and display the generated
    texture, we need a textured full-screen quad renderer. Its GLSL source code can
    be found in `data/shaders/Quad.vert` and `data/shaders/Quad.frag`. However, the
    geometry used is actually a triangle covering the entire screen. We will not focus
    on its internals here because at this point, it should be easy for you to render
    a full-screen quad on your own using the material from the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The original shader, “Industrial Complex,” that we are going to use here to
    generate a Vulkan texture was created by Gary “Shane” Warne ([rhomboid.com](https://www.rhomboid.com))
    and can be downloaded from ShaderToy: [https://www.shadertoy.com/view/MtdSWS](https://www.shadertoy.com/view/MtdSWS).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start by discussing the process of writing a texture-generating GLSL
    compute shader. The simplest shader to generate an RGBA image without using any
    input data outputs an image by using the `gl_GlobalInvocationID` built-in variable
    to calculate which pixel to output. This maps directly to how ShaderToy shaders
    operate, thus we can transform them into a compute shader just by adding some
    input and output parameters and layout modifiers that are specific to compute
    shaders and Vulkan. Let’s take a look at a minimalistic compute shader that creates
    a red-green gradient texture:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As in all other compute shaders, one mandatory line at the beginning tells
    the driver how to distribute the workload on the GPU. In our case, we are processing
    tiles of 16x16 pixels – the local workgroup size, 16x16, is supported on many
    GPUs, and we will use it for compatibility purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'The only buffer binding that we need to specify is the output image. This is
    the first time we have used the image type `image2D` in this book. Here, it means
    that the array `kTextures2DOut` contains an array of 2D images whose elements
    are nothing but pixels of a texture. The `writeonly` layout qualifier instructs
    the compiler to assume we will not read from this image in the shader. The binding
    is updated from the C++ code in the *Using Vulkan descriptor indexing* recipe
    in *Chapter 2, Getting Started with Vulkan*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'The GLSL compute shading language provides a set of helper functions to retrieve
    various image attributes. We use the built-in `imageSize()` function to determine
    the size of an image in pixels, and the image ID is loaded from push constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'The built-in `gl_GlobalInvocationID` variable tells us which global element
    of our compute grid we are processing. To convert its value into 2D image coordinates,
    we divide it by the image dimensions. As we are dealing with 2D textures, only
    `x` and `y` components matter. The calling code from the C++ side executes the
    `vkCmdDispatch()` function and passes the output image size as the X and Y numbers
    of local workgroups:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: 'The actual real work we do in this shader is to call the `imageStore()` GLSL
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: Now, this example is rather limited, and all you get is a red-and-green gradient
    image. Let’s change it a little bit to use the actual shader code from ShaderToy.
    The compute shader that renders a Vulkan version of the “Industrial Complex” shader
    from ShaderToy, available via the following URL [https://shadertoy.com/view/MtdSWS](https://shadertoy.com/view/MtdSWS),
    can be found in the `Chapter05/08_ComputeTexture/src/main.comp` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s copy the entire original ShaderToy GLSL code into our new compute
    shader. There is a function called `mainImage()` in there, which is declared as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: 'We should replace it with a function that returns a `vec4` color instead of
    storing it in the output parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: Don’t forget to add an appropriate `return` statement at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s change the `main()` function of our compute shader to invoke `mainImage()`
    properly and do 5x5 accumulative antialiasing. It is a pretty neat trick:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: There is still one issue that needs to be resolved before we can run this code.
    The ShaderToy code uses two custom input variables, `iTime` for the elapsed time
    and `iResolution`, which contains the size of the resulting image. To prevent
    any search and replace in the original GLSL code, we mimic these variables, one
    as a push constant and the other with a hardcoded value for simplicity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '**Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The GLSL `imageSize()` function can be used to obtain the `iResolution` value
    based on the actual size of our texture. We leave it as an exercise to the reader.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The C++ code is rather short and consists of creating a texture and invoking
    the previously mentioned compute shader, inserting a Vulkan pipeline barrier,
    and rendering a textured full-screen quad:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A texture is created using the `TextureUsageBits_Storage` usage flag to make
    it accessible to compute shaders:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute and rendering pipelines are created the following way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: 'When doing rendering, we provide the texture ID to both shaders and the current
    time to the compute shader using push constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: A pipeline barrier that ensures that the compute shader finishes before texture
    sampling happens is created by LightweightVK when we specify a required texture
    dependency. Take a look at `lvk::CommandBuffer::transitionToShaderReadOnly()`
    for the low-level image barrier code. As our fullscreen shader uses a triangle
    covering the entire screen, draw 3 vertices of that triangle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: 'The running application should render the following image, which is similar
    to the output of [https://www.shadertoy.com/view/MtdSWS](https://www.shadertoy.com/view/MtdSWS):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8: Using compute shaders to generate textures](img/file38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: Using compute shaders to generate textures'
  prefs: []
  type: TYPE_NORMAL
- en: In the next recipe, we will continue learning the Vulkan compute pipeline and
    implement a mesh generation compute shader.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing computed meshes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the *Generating textures in Vulkan using compute shaders* recipe, we learned
    how to write pixel data into textures from compute shaders. We are going to need
    that data in the next chapter to implement a BRDF precomputation tool for our
    physically-based rendering pipeline. But before that, let’s learn a few simple
    and interesting ways to use compute shaders in Vulkan and combine this feature
    with mesh geometry generation on the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to run a compute shader to create the triangulated geometry of
    a 3D torus knot shape with different `P` and `Q` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A torus knot is a special kind of knot that lies on the surface of an unknotted
    torus in 3D space. Each torus knot is specified by a pair of coprime integers,
    p and q. To find out more, check out the Wikipedia page: [https://en.wikipedia.org/wiki/Torus_knot](https://en.wikipedia.org/wiki/Torus_knot).'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: A compute shader generates vertex data, including positions, texture coordinates,
    and normal vectors. This data is stored in a buffer and later utilized as a vertex
    buffer to render a mesh in a graphics pipeline. To make the results more visually
    pleasing, we will implement real-time morphing between two different torus knots
    that is controllable from an ImGui widget. Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The source code for this example is located in `Chapter05/09_ComputeMesh`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The application consists of multiple parts: the C++ part (which drives the
    UI and Vulkan commands), the mesh generation compute shader, the texture generations
    compute shader, and a rendering pipeline with simple vertex and fragment shaders.
    The C++ part in `Chapter05/09_ComputeMesh/src/main.cpp` is quite short, so let’s
    tackle it first:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We store a queue of P-Q pairs, which defines the order of morphing. The queue
    always has at least two elements, which define the current and the next torus
    knot. We also store a floating point value, `g_MorphCoef`, which is the morphing
    factor `0...1` between the two adjacent P-Q pairs in the queue. The mesh is regenerated
    in every frame, and the morphing coefficient is increased until it reaches `1.0`.
    At this point, we will either stop morphing or, if there are more than two elements
    in the queue, remove the top element from it, reset `g_MorphCoef` to `zero`, and
    repeat. The `g_AnimationSpeed` value defines how fast one torus knot mesh morphs
    into another. The `g_UseColoredMesh` Boolean flag is used to switch between colored
    and textured shading of the mesh:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'Two global constants define the tessellation level of a torus knot. Feel free
    to play around with them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: 'Regardless of the `P` and `Q` parameter values, we have a single order in which
    we should traverse vertices to produce torus knot triangles. The `generateIndices()`
    function prepares index buffer data for this purpose. Here, `6` is the number
    of indices generated for each rectangular grid element consisting of `2` triangles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, our C++ code operates an ImGui UI for selecting a configuration
    of a torus knot and managing various parameters. This offers insights into the
    code’s flow, so let’s examine it more closely:'
  prefs: []
  type: TYPE_NORMAL
- en: Each torus knot is specified by a pair of coprime integers, `P` and `Q`. Here,
    we have preselected a few pairs that produce visually interesting results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: We can control the morphing animation speed. That is how fast one mesh morphs
    into another. We can also switch between colored and textured shading of the mesh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: When we click a button with a different set of `P`-`Q` parameters, we don’t
    regenerate the mesh right away. Instead, we let any ongoing animations complete
    by adding a new pair to a queue. In the main loop, after the current morphing
    animation concludes, we remove the front element from the queue and initiate the
    animation again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: 'The content of the morph queue is printed here for you. The current `P`-`Q`
    pair is marked with `“<---”`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: 'If we apply an animated texture for shading the mesh, let’s also showcase it
    using `ImGui::Image()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s examine the C++ code that’s responsible for creating buffers and
    populating them with initial data:'
  prefs: []
  type: TYPE_NORMAL
- en: The indices are immutable and are generated using the previously mentioned `generateIndices()`
    function. The vertex buffer size is calculated based on `12` `float` elements
    per vertex. That is `vec4` positions, `vec4` texture coordinates, and `vec4` normal
    vectors. This padding is used to simplify the compute shader that writes to the
    vertex buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: Let’s create a texture that will be generated by a compute shader. This is similar
    to the previous recipe, *Generating textures in Vulkan using compute shaders*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex buffer should be created with the `BufferUsageBits_Storage` flag
    to allow vertex shader usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: 'We create two compute pipelines: one for mesh generation and another for texture
    generation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: Shader modules are loaded as usual. The geometry shader generates barycentric
    coordinates for wireframe outlines. Wireframe outline rendering will be enabled
    if you set `kNumU` and `kNumV` to `64` or lower values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: 'For vertex input, we employ `vec4` to simplify padding concerns—or, to be more
    precise, to eliminate them entirely:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: 'The same shader code is specialized for textures and colored shading using
    specialization constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: 'The final segment of the C++ code is the rendering loop. Let’s explore how
    to populate a command buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to access the current `P`-`Q` pair from the morph queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: The number of parameters for the shaders is larger than usual, precisely `128`
    bytes. Push constants are shared across all shaders, compute, and graphics, for
    convenience purposes and to simplify the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: 'When we dispatch the mesh generation compute shader, we need to specify proper
    memory barriers to make sure the previous frame has finished rendering:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: Do the same for the texture generation shader. We must ensure the texture regeneration
    is properly synchronized with rendering by issuing a Vulkan image layout transition
    with appropriate pipeline stages and masks. This is done by `LightweightVK` inside
    `lvk::CommandBuffer::cmdDispatchThreadGroups()` using a few empirical rules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: When we start rendering, it’s essential to specify both dependencies—the texture
    and the vertex buffer. The choice of the rendering pipeline depends on whether
    we aim to render a colored or textured mesh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: The `renderGUI()` function renders the ImGui UI, as described earlier in this
    recipe. In this case, we pass our generated texture to it for presentation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: That covers the C++ part. Now, let’s delve into the GLSL shaders to understand
    how the whole demo works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start with the compute shader, `Chapter05/09_ComputeMesh/src/main_mesh.comp`,
    which is responsible for generating vertex data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The push constants are declared in `Chapter05/09_ComputeMesh/src/common.sp`.
    They are shared between all shaders, and we paste them here for convenience:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: This is the structure containing per-vertex data that we aim to generate and
    write into a buffer referenced by `VertexBuffer`, which is stored in `pc.bufferId`
    a few lines above the buffer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: 'The heart of our mesh generation algorithm is the `torusKnot()` function, which
    uses the following parametrization to triangulate a torus knot [https://en.wikipedia.org/wiki/Torus_knot](https://en.wikipedia.org/wiki/Torus_knot):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: 'The `torusKnot()` function is rather long and is implemented directly from
    the previously mentioned parametrization. Feel free to play with the `baseRadius`,
    `segmentRadius`, and `tubeRadius` values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: 'We are running this compute shader in each frame, so, instead of generating
    a static set of vertices, we can actually pre-transform them to make the mesh
    look like it is rotating. Here is a couple of helper functions to compute the
    appropriate rotation matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the previously mentioned helpers, the `main()` function of our compute
    shader is now straightforward, and the only interesting thing worth mentioning
    here is the real-time morphing that blends two torus knots with different `P`
    and `Q` parameters. This is pretty easy because the total number of vertices always
    remains the same:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: 'Two sets of UV coordinates for parametrization need to be computed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the model matrix for our mesh by combining two rotation matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute two vertex positions for two different torus knots defined by the two
    sets of `P`-`Q` parameters: `P1`-`Q1` and `P2`-`Q2`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a linear blend between them using the `pc.morph` coefficient. We only
    need to blend the position and the normal vector. While normal vectors can be
    interpolated more gracefully, we leave that as another exercise for our readers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: 'Fill in the resulting `VertexData` structure and store it in the output vertex
    buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex shader looks as follows. Just note that the vertex attributes have
    proper types here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: 'The geometry shader is trivial because the only thing it does is generate barycentric
    coordinates as described in *Integrating tessellation into the graphics pipeline*.
    So, let’s jump straight to the fragment shader, `Chapter05/09_ComputeMesh/src/main.frag`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The specialization constant is used to switch between the colored and textured
    versions of the shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: 'Edge factor calculation for wireframe outlines as described in the *Integrating
    tessellation into the graphics pipeline* recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: 'A function to calculate an RGB color for our mesh based on a floating point
    “hue” value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: For high values of `numU` and `numV`, the tessellation level is so dense that
    no distinct wireframe edges are visible—everything collapses into a black Moiré
    mess. We disable wireframe overlays for values greater than `64`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: Last but not least, there’s a compute shader responsible for generating an animated
    texture. You can find it in `Chapter05/09_ComputeMesh/src/main_texture.comp`,
    and the idea is identical to the approach described in the previous recipe, *Generating
    textures in Vulkan using compute shaders*. We do not copy and paste that shader
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The demo application will produce a variety of torus knots similar to the one
    in the following screenshot. Each time you select a new pair of `P`-`Q` parameters
    from the UI, the morphing animation will kick in and transform one knot into another.
    Checking the *Use colored mesh* box will apply colors to the mesh instead of a
    computed texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9: Computed mesh with real-time animation](img/file39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: Computed mesh with real-time animation'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Refer to the Wikipedia page [https://en.wikipedia.org/wiki/Torus_knot](https://en.wikipedia.org/wiki/Torus_knot)
    for additional explanation of the math details. Try setting the values of `kNumU`
    and `kNumV` to `32` while checking “Use colored mesh”.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the initial recipe that involves an explicit synchronization process
    between two independent compute shaders and a rendering pass. The *LightweightVK*
    implementation aims to make this synchronization as seamless as possible through
    explicit dependency specification. In more complex real-world 3D applications,
    more fine-grained synchronization mechanisms would be desirable. Refer to the
    guide on Vulkan synchronization from Khronos for valuable insights on how to handle
    it effectively: [https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples](https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples).'
  prefs: []
  type: TYPE_NORMAL
