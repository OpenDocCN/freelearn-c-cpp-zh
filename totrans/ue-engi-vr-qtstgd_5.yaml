- en: Creating Optimized Game Art for VR in UE4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Server 17* has come a long way. We have brought the game from a simple puzzle
    idea to a working game prototype. At this stage, we have a sample level, custom
    gameplay, and custom interfaces. We have built interaction systems that can be
    expanded to add even more game mechanics. However, the game is not much to look
    at, is it? Our lighting is basic. We are still using the default textures for
    many things. There is nothing wrong with it, since this is still a game prototype,
    but if we want to be able to present this to anyone beyond family and friends,
    it is going to need a bit of sprucing up.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating 3D game art for VR is not like creating game art for other titles.
    Though we use many of the same programs, VR requires us to be conservative with
    our art. The performance requirements of VR demand that we keep polygon counts
    low, use tricks to eliminate the use of advanced lighting techniques, and rethink
    our approach to art. Fake everything you can, and treat your game art as if it
    is the late, 90s.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Performance is key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artistic limitations in VR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance-boosting techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring ingame performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance is key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Again and again, we have touched on the theme of performance in VR. We talked
    about it first when we discussed VR sickness in [Chapter 1](926e8e71-f556-43b2-b4f8-47dc017c7a38.xhtml),
    *Introducing VR Technology in Unreal Engine 4*. We touched on it again in [Chapter
    3](ec4818ac-6582-4488-ba15-e48ef829466f.xhtml),Â *Exploring Riveting Gameplay in
    Virtual Reality*, when we programmed the interaction systems that make our game
    work. So, why do we keep talking about it? Performance is central to enjoying
    a VR experience. Having high-end visuals helps our players become immersed in
    our digital environments, while keeping steady frame rates is the best way to
    maximize player comfort and reduce VR sickness. So, how do we balance both of
    these needs?
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to talk about performance regarding to 3D game
    art, lighting, and visual effects. In VR, managing your assets and detail level
    becomes a balancing act. How do we provide the visuals required to engage our
    players while keeping framerates at 90 FPS or above to keep them comfortable?
    The simple answer is understanding and careful planning. With the right planning
    and a few tricks, we can keep our FPS high, and deliver the experience our players
    demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start us off, let''s discuss the important points of how VR renders the
    elements we place on the screen. Each object we create and add to our environment
    needs to go through the process of being drawn to the screen. The more detailed
    the object (as measured by the polygon count or the triangle count), the more
    processing it takes. Processing takes time. We also have to be aware of draw calls.
    Each time we update the screen, the object needs to be drawn again along with
    each material that it uses. We could describe this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Draw Calls = Number of Meshes on screen * Number of Materials per Mesh*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also have to remember that VR headsets render to two screens (one per eye).
    So the number of draw calls is actually doubled! This is where planning can help.
    Here are some helpful do''s and don''ts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Do''s**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plan our environment so we can minimize the number of meshes on the screen.
    Make sure that each mesh has a purpose and adds something to the level by being
    there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize the number of materials that are on each object. It is possible to
    create one large material that can be used with several different meshes. However,
    keeping the number of materials per object as low as possible works as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Don''ts**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Place meshes just to fill space. This makes the level feel cluttered and busy.
    This also increases the number of draw calls per frame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depend on advanced rendering techniques to display meshes and effects. Features
    such as transparency, screen-space reflections, and normal maps do not work well
    in VR. Either they are too resource intensive or do not display correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a couple of the ways knowledge and planning can help with performance.
    By understanding the demands of VR and planning our approach to the art, we can
    do our best to minimize draw calls.
  prefs: []
  type: TYPE_NORMAL
- en: Artistic limitations in VR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a basic understanding, it''s time to get specific. How do
    the limitations we face in VR affect each of the following categories of game
    art?:'
  prefs: []
  type: TYPE_NORMAL
- en: Static and skeletal meshes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Materials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual effects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each category represents different limitations that need to be considered when
    creating the visuals for our game.
  prefs: []
  type: TYPE_NORMAL
- en: Static and skeletal mesh limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by taking a look at static and skeletal meshes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a5a44b03-4c2d-4305-9cbc-8a2823bd12cd.png)'
  prefs: []
  type: TYPE_IMG
- en: The static mesh editor in Unreal 4
  prefs: []
  type: TYPE_NORMAL
- en: Static and skeletal meshes represent the majority of the art that goes into
    creating a game in Unreal Engine 4\. These are your 3D models and tend to be sorted
    into groups such as environment, character, weapon, vehicle, and so on. Back in
    the late '90s when computer resources were more limited, artists had to work within
    strict limits when it came to polygon or triangle counts, but those limits are
    a thing of the past. Modern game hardware can push millions of triangles to the
    screen with no problems. However, with the performance needs of VR being so high,
    it is time to create our models like it's 1999!
  prefs: []
  type: TYPE_NORMAL
- en: For some of us older folks, we are able to remember what those limitations were
    like. For others of us (younger readers), we need a bit of a refresher on what
    that means. Today's standards for triangle counts are quite high. A first-person
    weapon can be 30,000 triangles or more. It is not uncommon for characters to have
    a triangle count of up to 120,000 triangles. However, every bit of extra detail
    can impact performance. Without normal maps to help us fake detail and decrease
    these numbers, how can we maintain the level of detail that we need for a high-end
    environment? A common practice is to delete the polygons on objects in places
    that the player won't see. How can we do that when the player can see all around
    our objects?
  prefs: []
  type: TYPE_NORMAL
- en: Material limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, let''s discuss materials:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f601798a-ccfc-4bb2-88fe-8827484bc665.png)'
  prefs: []
  type: TYPE_IMG
- en: A glimpse of the material editor
  prefs: []
  type: TYPE_NORMAL
- en: The complexity and number of a scene's materials is often the major reason for
    poor performance in VR. Each material that we apply to a mesh adds a draw call
    to our game, forcing the computer to work harder each frame. This can result in
    slower performance and not being able to hit our 90 FPS target. There is also
    the issue of transparency and reflections. Transparent and translucent materials
    are a fantastic effect. However, they are costly in VR, as the material has to
    be reevaluated and redrawn every frame. Reflections are another great effect that
    helps a world feel more realistic and immersive. Yet, these are also very resource
    intensive and require complex calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Lighting limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s now time to look at lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30f3667d-19fc-41f6-a60e-bae31151b78f.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of lighting in UE4
  prefs: []
  type: TYPE_NORMAL
- en: Many modern games make use of dynamic light sources to provide players with
    a living world. Shadows move as the sun marches across the sky. NPCs cast shadows
    as they move under street lamps. This type of lighting and shadow help us feel
    grounded in the world and are an essential part of any game. However, dynamic
    lighting is very expensive to calculate for every frame. So, how can we use shadows
    to keep the realism in our virtual worlds?
  prefs: []
  type: TYPE_NORMAL
- en: Visual Effects (VFX) limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lastly, we come to visual effects:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2497210e-43fc-4798-a5e0-20fde43adcda.png)'
  prefs: []
  type: TYPE_IMG
- en: Unreal Engine 4 Cascade VFX editor
  prefs: []
  type: TYPE_NORMAL
- en: The right visual effects bring a punch and excitement to many different kinds
    of games. They are essential in action games. They bring a sense of impact to
    sports games. They even add to the realism and feel of simulations. Yet, much
    like dynamic lighting, they are costly when it comes to performance. The limitations
    on translucent and transparent materials apply here. Making some techniques such
    as the use of SubUV textures (laying out the frames of an animated particle in
    a grid) ineffective. Many particles also contain dynamic light sources.
  prefs: []
  type: TYPE_NORMAL
- en: Performance-boosting techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the player''s comfort to consider andÂ all of these limitations, how are
    designers creating amazing 3D worlds for VR users to step into? The answer can
    be summed up in the phase *fake it till you make it*. The technology behind VR
    is rapidly evolving. New techniques for dealing with the issues we''ve mentioned
    are being built into the next generation of game engines. However, for now, there
    are some best practices currently being used by artists in the industry today
    to deliver amazing visuals, such as the showdown demo from Epic Games:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b29d208-bebe-4a58-b174-372d85025d83.png)'
  prefs: []
  type: TYPE_IMG
- en: The showdown demo from Epic Games
  prefs: []
  type: TYPE_NORMAL
- en: These guys were able to render this amazing scene at 90 FPS. There is transparency,
    lighting, and visual effects. The models used are from various other UE4 demos
    and are not reduced in quality. Here is just some of how they did it.
  prefs: []
  type: TYPE_NORMAL
- en: Static and skeletal mesh techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The best way to maximize the success of your VR environment in terms of performance
    is to approach the scene with a plan and be as conservative as possible. Since
    the player has the opportunity to scrutinize and interact with the environment
    more than in a traditional game, VR-ready assets need to be scaled for users of
    anÂ average height. Meshes must also be manifold. This means ensuring that the
    object is complete and there are no missing polygons in the mesh, since the player
    can usually view the object from any angle. Here is an example of a DJ deck that
    was created for *Tribe XR*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72096641-4865-40cc-9d57-e1786f96f1af.png)'
  prefs: []
  type: TYPE_IMG
- en: Pioneer CDJ used in Tribe XR open in Autodesk Maya. This mesh is only 2,001
    triangles
  prefs: []
  type: TYPE_NORMAL
- en: In their game *Tribe XR*, the team planned and focused their VR DJing experience
    to fit in one room so that they could maximize the ability to create an immersive
    Sci-Fi environment. Inspired by games such as *Overwatch* and *Team Fortress 2*,
    the lounge they have created has just enough meshes in it to give it that lived-in
    feel. Each one is placed with purpose to create a relaxed and believable atmosphere.
    The meshes they used have low polygon/triangle counts, and UV maps are optimized
    to reduce redundant draw calls. The result is a smooth VR experience that keeps
    framerates high and players absorbed in the music.
  prefs: []
  type: TYPE_NORMAL
- en: Standard methods of game optimization, such as the use of **Level of Detail**
    (**LOD**) meshes, is still viable in VR and should still be considered.
  prefs: []
  type: TYPE_NORMAL
- en: Material techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned previously, materials for VR should be planned and designed to
    minimize the number of draw calls that are required in every frame. Each mesh
    should incorporate the minimum number of materials to reduce these draw calls.
    In the showdown demo, Epic Games created many purpose-built props, though some
    were taken from previous demos, such as the Samaritan demo. The meshes constructed
    for VR all follow a similar pattern. All are optimized with low triangle counts,
    and most utilize only one material.
  prefs: []
  type: TYPE_NORMAL
- en: 'The translucency/transparency is kept to a minimum and only used in a handful
    of locations, such as the glass in vehicles. The glass in the surrounding buildings
    has been faked through the texture images that are used. In places where translucency
    is needed, the DitherTemporalAA material node can be used to make opacity-masked
    objects look like translucent ones. Here is one example using a rocket smoke trail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/735777df-dc38-4795-a1d7-644117502651.png)'
  prefs: []
  type: TYPE_IMG
- en: The RocketTrail material from the showdown demo
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, using theÂ DitherTemporalAAÂ node helps eliminate pixel overdraw,
    and this improves performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have a powerful tool in helping us fine-tune the materials in our
    scenes: the Shader Complexity view. Accessed through the View Mode drop-down menu
    in the viewport, this view shades the scene in greens and reds, with green being
    less complex and red being more complex. Let''s look at this screenshot from the
    showdown demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25782631-9279-43b8-9f99-62362e425c13.png)'
  prefs: []
  type: TYPE_IMG
- en: The showdown demo with Shader Complexity enabled
  prefs: []
  type: TYPE_NORMAL
- en: Most of the scene is overlayed in green, showing us that there is a minimum
    number of shader instructions for most objects in the level. Where we see red
    is the transparent windshield glass and the shaders used on the characters that
    were taken from the infiltrator demo (these are not optimized for VR).
  prefs: []
  type: TYPE_NORMAL
- en: Lighting techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lighting a level is one of the most resource intensive processes that happens
    every frame update. When dynamic lights move, it changes shadows, reflections,
    and scattered light, which all have to be recalculated and redrawn. To compensate
    for this, Unreal Engine 4 gives the option to bake lightmaps for each object.
    This creates static lighting by baking the lighting data into a lightmap on each
    object. Lightmaps can't be as realistic as dynamic lighting, but the performance
    difference is very dramatic. That isn't to say that dynamic lighting doesn't have
    a place in VR projects. Dynamic lights may still be used in limited numbers, and
    they should never touch one another. If the scene you are creating is an outdoor
    scene, try setting your directional light (sun or moon) to dynamic, and then use
    cascading shadow maps with the simplest settings you can.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the problem with using static lighting is the loss of shadows for
    your dynamic objects. Things such as the player, enemies, and interactive objects
    just seem to float within your virtual space, without a shadow to ground them.
    This gives the space a somewhat-unnatural look. To fix this, we can use a technique
    that can create a fake blob shadow. We can see it here in the showdown demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1eea53e5-378b-44e2-8486-404ef0da696c.png)'
  prefs: []
  type: TYPE_IMG
- en: A static mesh with a fake blob shadow
  prefs: []
  type: TYPE_NORMAL
- en: Finally, reflections can go a long way to giving an area a feeling of complexity
    and realism. However, real-time reflections use a significant amount of resources
    and are not well-suited to VR games. In the spirit of *fake it till you make it*,Â the
    designers at Epic Games created the reflection-capture actor. These actors grab
    reflections from within their areas of influence and encode them into static cube
    maps. These cube maps can then be used by materials to create and fine-tune reflections
    in the level. Since these cube maps are created before the game begins, they have
    very little impact on the level of performance.
  prefs: []
  type: TYPE_NORMAL
- en: Visual effects techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you''ve done much game development work, whether it is two or three dimensional,
    then you are aware of the traditional SubUV technique for creating particle effects.
    This technique involves creating a sprite sheet that represents a particle, such
    as fire or smoke, and having the game engine animate through the cells. This creates
    an animated particle that looks three dimensional but is actually a 2D texture.
    Here is an example of smoke:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bf52efb-b5f4-4a65-9b10-6ad912934437.png)'
  prefs: []
  type: TYPE_IMG
- en: Smoke particle created with the SubUV technique
  prefs: []
  type: TYPE_NORMAL
- en: 'Your first thought might be that this type of particle would be ideal for VR
    since we are projecting a smoke particle with a 2D texture. However, since the
    technique depends on transparency, creating this particle in VR would be tough
    on our performance. We would also need to consider that players in VR can view
    the particles from many different angles. Because of this, particles created using
    the SubUV technique end up looking flat and uninteresting. Designers can work
    around these issues by focusing on using small meshes as particles and creating
    effects that are close to the camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/93d9392a-24c2-4e7d-b154-d44759f89199.png)'
  prefs: []
  type: TYPE_IMG
- en: A VR-friendly particle open in Cascade
  prefs: []
  type: TYPE_NORMAL
- en: In the showdown demo, smoke is used at several points in the level, such as
    part of the vehicle explosion that flips the car. To minimize the impact on performance,
    the designers created an animated smoke material that they were able to place
    on to a 3D ribbon mesh, which is then emitted along with several different types
    of concrete chunks as part of the effect. When the demo is viewed with the Shader
    Complexity view enabled, these smoke effects are shown with a green tint, meaning
    that they are optimized and have little impact on the framerate. This also allowed
    the designers to deploy these effects near or directly in front of the cameraâsomething
    that can be done well with SubUV particles.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring ingame performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over and over again, I have mentioned-performance as the most important consideration
    for a VR game. Yet, we have not talked about how to measure performance inside
    Unreal Engine 4 so that we can know whether we are optimizing well or not. Let's
    take a look at the tools we have available.
  prefs: []
  type: TYPE_NORMAL
- en: 'UE4 has an amazing number of performance profiling tools available as part
    of the game engine, more than I could discuss in this one-quick-start guide. However,
    I do want to discuss a couple that are relevant to our discussion: the Stat commands
    and the GPU Visualizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cffc171d-ccae-4367-b1e5-e05d05dcd02e.png)'
  prefs: []
  type: TYPE_IMG
- en: Stat command statistics
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several Stat commands that can be useful for us to determine our
    performance. They are accessed byÂ  opening Accessing the console with the tilde
    key and typing in the following commands (they are not case-sensitive):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stat FPS**: This command brings up the current framerate and the time it
    takes to render a frame in milliseconds. Remember that our target goal for HTC
    Vive and Oculus Rift is 90 FPS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stat Unit**: Displays in milliseconds the time per frame spent on rendering
    the frame, game calculations, draw calls, and GPU calculation time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stat SceneRendering**: Displays general render time statistics. When performance
    starts to drop, this panel can show us the culprit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These statistics can help us understand whether our game is CPU bound or GPU
    bound. Being CPU bound means that our game has too many complex calculations and
    performance is currently being bottlenecked by the CPU. When our game is GPU bound,
    it means that we have too many draw calls, lights, or complex visuals, and our
    performance is being constrained by the graphics processor.
  prefs: []
  type: TYPE_NORMAL
- en: Another simple method of determining whether we are CPU or GPU bound is to lower
    the graphics quality of the game and take a look at the effects on our framerate.
    If there is no change to the current FPS, then we are bound to the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other tool we have is the GPU Visualizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/59bf5795-5d0c-4c6f-8d87-7c766568b987.png)'
  prefs: []
  type: TYPE_IMG
- en: The GPU Visualizer
  prefs: []
  type: TYPE_NORMAL
- en: This is a visual interface that allows us to see the GPU cost of the render
    passes used to draw each frame. Though it may look complicated at first, this
    interface can show us which visual element or feature is causing the largest drop
    in performance, as indicated by the feature taking the largest number of milliseconds
    to render. With that knowledge, we can optimize the specific feature or remove
    it entirely. For more information on this subject, please refer to the *Performance
    and Profiling* section of the Unreal Engine 4 documentation located atÂ [https://docs.unrealengine.com/en-us/Engine/Performance.](https://docs.unrealengine.com/en-us/Engine/Performance)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned several of the known causes of performance issues
    in VR games related to static and skeletal meshes, materials, lighting, and visual
    effects. After discussing the causes, we explored several different solutions
    using some examples from the DJ simulation *Tribe XR* and Epic Games own the cinematic
    VR demo showdown. Lastly, we discussed methods for profiling our own game performance
    to determine whether our game is being limited by the CPU or GPU, and how we can
    use that data to adjust and optimize our application for maximum player comfort.
  prefs: []
  type: TYPE_NORMAL
- en: In the final chapter, we will discuss the importance of game testing in the
    user experience design process and how to collect that data to make further design
    decisions. We will also learn how to finalize our game through the cooking process
    and prepare it for distribution. Finally, we will discuss the importance of everything
    we learned, how to proceed with the game prototype that we created, and look at
    further resources for continuing to develop VR applications.
  prefs: []
  type: TYPE_NORMAL
