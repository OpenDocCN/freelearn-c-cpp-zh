<html><head></head><body>
        

                            
                    <h1 class="header-title">Shadows</h1>
                
            
            
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Rendering shadows with shadow maps</li>
<li>Anti-aliasing shadow edges with PCF</li>
<li>Creating soft shadow edges with random sampling</li>
<li>Creating shadows using shadow volumes and the geometry shader</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction</h1>
                
            
            
                
<p>Shadows add a great deal of realism to a scene. Without shadows, it can be easy to misjudge the relative location of objects, and the lighting can appear unrealistic, as light rays seem to pass right through objects.</p>
<p>Shadows are important visual cues for realistic scenes, but can be challenging to produce in an efficient manner in interactive applications. One of the most popular techniques for creating shadows in real-time graphics is the <strong>shadow mapping</strong> algorithm (also called <strong>depth shadows</strong>). In this chapter, we'll look at several recipes surrounding the shadow mapping algorithm. We'll start with the basic algorithm, and discuss it in detail in the first recipe. Then, we'll look at a couple of techniques for improving the look of the shadows produced by the basic algorithm.</p>
<p>We'll also look at an alternative technique for shadows called shadow volumes. Shadow volumes produce near perfect hard-edged shadows, but are not well-suited for creating shadows with soft edges.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Rendering shadows with shadow maps</h1>
                
            
            
                
<p>One of the most common and popular techniques for producing shadows is called shadow mapping. In its basic form, the algorithm involves two passes. In the first pass, the scene is rendered from the point of view of the light source. The depth information from this pass is saved into a texture called the <strong>shadow map</strong>. This map will help provide information about the visibility of objects from the light's perspective. In other words, the shadow map stores the distance (actually the pseudo-depth) from the light to whatever the light can <em>see</em>. Anything that is closer to the light than the corresponding depth stored in the map is lit; anything else must be in shadow.</p>
<p>In the second pass, the scene is rendered normally, but each fragment's depth (from the light's perspective) is first tested against the shadow map to determine whether or not the fragment is in shadow. The fragment is then shaded differently depending on the result of this test. If the fragment is in shadow, it is shaded with ambient lighting only; otherwise, it is shaded normally.</p>
<p>The following image shows an example of shadows produced by the basic shadow mapping technique:</p>
<div><img src="img/3c6d91b7-0823-4486-8d2f-2c5e8f64e576.png" style="width:26.25em;height:13.25em;"/></div>
<p>Let's look at each step of the algorithm in detail.</p>
<p>The first step is the creation of the shadow map. We set up our view matrix so that we are rendering the scene as if the camera is located at the position of the light source, and is oriented toward the shadow-casting objects. We set up a projection matrix so that the view frustum encloses all objects that may cast shadows as well as the area where the shadows will appear. We then render the scene normally and store the information from the depth buffer in a texture. This texture is called the shadow map (or simply depth map). We can think of it (roughly) as a set of distances from the light source to various surface locations.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Technically, these are depth values, not distances. A depth value is not a true distance (from the origin), but can be roughly treated as such for the purposes of depth testing.</p>
<p>The following diagrams represent an example of the basic shadow mapping setup. The left diagram shows the light's position and its associated perspective frustum. The right-hand diagram shows the corresponding shadow map. The greyscale intensities in the shadow map correspond to the depth values (darker is closer):</p>
<div><img src="img/f91f2ae7-7bcf-48f0-befc-e97486ac7fd0.png" style="width:28.08em;height:11.25em;"/></div>
<p>Once we have created the shadow map and stored the map in a texture, we render the scene again from the point of view of the camera. This time, we use a fragment shader that shades each fragment based on the result of a depth test with the shadow map. The position of the fragment is first converted into the coordinate system of the light source and projected using the light source's projection matrix. The result is then biased (in order to get valid texture coordinates) and tested against the shadow map. If the depth of the fragment is greater than the depth stored in the shadow map, then there must be some surface that is between the fragment and the light source. Therefore, the fragment is in shadow and is shaded using ambient lighting only. Otherwise, the fragment must have a clear view to the light source, and so it is shaded normally.</p>
<p>The key aspect here is the conversion of the fragment's 3D coordinates to the coordinates appropriate for a lookup into the shadow map. As the shadow map is just a 2D texture, we need coordinates that range from zero to one for points that lie within the light's frustum. The light's view matrix will transform points in world coordinates to points within the light's coordinate system. The light's projection matrix will transform points that are within the light's frustum to <strong>homogeneous clip coordinates</strong>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>These are called clip coordinates because the built-in clipping functionality takes place when the position is defined in these coordinates. Points within the perspective (or orthographic) frustum are transformed by the projection matrix to the (homogeneous) space that is contained within a cube centered at the origin, with each side of length two. This space is called the <strong>canonical viewing volume</strong>. The term <em>homogeneous</em> means that these coordinates should not necessarily be considered to be true Cartesian positions until they are divided by their fourth coordinate. For full details about homogeneous coordinates, refer to your favorite textbook on computer graphics.</p>
<p>The <em>x</em> and <em>y</em> components of the position in clip coordinates are roughly what we need to access the shadow map. The <em>z</em> coordinate contains the depth information that we can use to compare with the shadow map. However, before we can use these values we need to do two things. First, we need to bias them so that they range from zero to one (instead of -1 to 1), and second, we need to apply <strong>perspective division</strong> (more on this later).</p>
<p>To convert the value from clip coordinates to a range appropriate for use with a shadow map, we need the <em>x</em>, <em>y</em>, and <em>z</em> coordinates to range from zero to one (for points within the light's view frustum). The depth that is stored in an OpenGL depth buffer (and also our shadow map) is simply a fixed or floating-point value between zero and one (typically). A value of zero corresponds to the near plane of the perspective frustum, and a value of one corresponds to points on the far plane. Therefore, if we are to use our <em>z</em> coordinate to accurately compare with this depth buffer, we need to scale and translate it appropriately.</p>
<p>In clip coordinates (after perspective division) the <em>z</em> coordinate ranges from -1 to 1. It is the viewport transformation that (among other things) converts the depth to a range between zero and one. Incidentally, if so desired, we can configure the viewport transformation to use some other range for the depth values (say between 0 and 100) via the <kbd>glDepthRange</kbd> function.</p>
<p>Of course, the <em>x</em> and <em>y</em> components also need to be biased between zero and one because that is the appropriate range for texture access.</p>
<p>We can use the following <em>bias</em> matrix to alter our clip coordinates:</p>
<div><img class="fm-editor-equation" src="img/cb0a3687-846f-48d0-a82c-6b548e4dbe12.png" style="width:12.17em;height:5.42em;"/></div>
<p>This matrix will scale and translate our coordinates such that the <em>x</em>, <em>y</em>, and <em>z</em> components range from 0 to 1 (after perspective division) for points within the light's frustum. Now, combining the bias matrix with the light's view (<em>V<sub>l</sub></em>) and projection (<em>P<sub>l</sub></em>) matrices, we have the following equation for converting positions in world coordinates (<em>W</em>) to homogeneous positions that can be used for shadow map access (<em>Q</em>):</p>
<div><img class="fm-editor-equation" src="img/97d4d43c-131d-4406-a214-876f578d281b.png" style="width:6.75em;height:1.08em;"/></div>
<p>Finally, before we can use the value of <em>Q</em> directly, we need to divide by the fourth (<em>w</em>) component. This step is sometimes called <strong>perspective division</strong>. This converts the position from a homogeneous value to a true Cartesian position, and is always required when using a perspective projection matrix.</p>
<p>Perspective division is automatically done by the OpenGL pipeline prior to rasterization. However, since we're working with a value that is not transformed by the pipeline, we need to perform the division manually.</p>
<p>In the following equation, we'll define a shadow matrix (<em>S</em>) that also includes the model matrix (<em>M</em>), so that we can convert directly from the object coordinates (<em>C</em>) (note that <em>W = MC</em>, because the model matrix takes object coordinates as world coordinates):</p>
<div><img class="fm-editor-equation" src="img/1b9188be-2e6b-4bf2-a040-51a3eca1a4df.png" style="width:4.08em;height:1.17em;"/></div>
<p>Here, <em>S</em> is the shadow matrix, the product of the model matrix with all of the preceding matrices:</p>
<div><img class="fm-editor-equation" src="img/676b10b2-95f4-4f7c-a759-6d3249439466.png" style="width:7.50em;height:1.25em;"/></div>
<p>In this recipe, in order to keep things simple and clear, we'll cover only the basic shadow mapping algorithm, without any of the usual improvements. We'll build upon this basic algorithm in the following recipes. Before we get into the code, we should note that the results will likely be less than satisfying. This is because the basic shadow mapping algorithm suffers from significant aliasing artifacts. Nevertheless, it is still an effective technique when combined with one of many techniques for anti-aliasing. We'll look at some of those techniques in the recipes that follow.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>The position should be supplied in vertex attribute zero and the normal in vertex attribute one. Uniform variables for the ADS shading model should be declared and assigned, as well as uniforms for the standard transformation matrices. The <kbd>ShadowMatrix</kbd> variable should be set to the matrix for converting from object coordinates to shadow map coordinates (<em>S</em> in the preceding equation).</p>
<p>The uniform variable <kbd>ShadowMap</kbd> is a handle to the shadow map texture, and should be assigned to texture unit zero.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>To create an OpenGL application that creates shadows using the shadow mapping technique, perform the following steps. We'll start by setting up a <strong>framebuffer object</strong> (<strong>FBO</strong>) to contain the shadow map texture, and then move on to the required shader code:</p>
<ol>
<li>In the main OpenGL program, set up an FBO with a depth buffer only. Declare a <kbd>GLuint</kbd> variable named <kbd>shadowFBO</kbd> to store the handle to this <kbd>framebuffer</kbd>. The depth buffer storage should be a texture object. You can use something similar to the following code to accomplish this:</li>
</ol>
<pre style="padding-left: 60px">GLfloat border[]={1.0f,0.0f,0.0f,0.0f}; 
 
//The shadowmap texture 
GLuint depthTex; 
glGenTextures(1,&amp;depthTex); 
glBindTexture(GL_TEXTURE_2D,depthTex); 
glTexStorage2D(GL_TEXTURE_2D, 1, GL_DEPTH_COMPONENT24, 
               shadowMapWidth, shadowMapHeight); 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER, 
                GL_NEAREST); 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER, 
                GL_NEAREST); 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_WRAP_S, 
                GL_CLAMP_TO_BORDER); 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_WRAP_T, 
                GL_CLAMP_TO_BORDER); 
glTexParameterfv(GL_TEXTURE_2D,GL_TEXTURE_BORDER_COLOR, 
                 border); 
 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_COMPARE_MODE, 
                GL_COMPARE_REF_TO_TEXTURE); 
glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_COMPARE_FUNC, 
                GL_LESS); 
 
//Assign the shadow map to texture unit 0 
glActiveTexture(GL_TEXTURE0); 
glBindTexture(GL_TEXTURE_2D,depthTex); 
 
//Create and set up the FBO 
glGenFramebuffers(1,&amp;shadowFBO); 
glBindFramebuffer(GL_FRAMEBUFFER,shadowFBO); 
glFramebufferTexture2D(GL_FRAMEBUFFER,GL_DEPTH_ATTACHMENT, 
                       GL_TEXTURE_2D,depthTex,0); 
GLenum drawBuffers[]={GL_NONE}; 
glDrawBuffers(1,drawBuffers); 
// Revert to the default framebuffer for now 
glBindFramebuffer(GL_FRAMEBUFFER,0); </pre>
<ol start="2">
<li>Use the following code for the vertex shader:</li>
</ol>
<pre style="padding-left: 60px">layout (location=0) in vec3 VertexPosition; 
layout (location=1) in vec3 VertexNormal; 
 
out vec3 Normal;     
out vec3 Position;    
 
// Coordinate to be used for shadow map lookup 
out vec4 ShadowCoord; 
 
uniform mat4 ModelViewMatrix; 
uniform mat3 NormalMatrix; 
uniform mat4 MVP; 
uniform mat4 ShadowMatrix; 
 
void main() {
    Position = (ModelViewMatrix *  
                vec4(VertexPosition,1.0)).xyz; 
    Normal = normalize( NormalMatrix * VertexNormal ); 
 
    // ShadowMatrix converts from modeling coordinates 
    // to shadow map coordinates. 
    ShadowCoord =ShadowMatrix * vec4(VertexPosition,1.0); 
 
    gl_Position = MVP * vec4(VertexPosition,1.0); 
}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="3">
<li>Use the following code for the fragment shader:</li>
</ol>
<pre style="padding-left: 60px">// Declare any uniforms needed for your shading model 
uniform sampler2DShadow ShadowMap; 
 
in vec3 Position; 
in vec3 Normal; 
in vec4 ShadowCoord; 
 
layout (location = 0) out vec4 FragColor; 
 
vec3 diffAndSpec() {
   // Compute only the diffuse and specular components of 
   // the shading model. 
} 
 
subroutine void RenderPassType(); 
subroutine uniform RenderPassType RenderPass; 
 
subroutine (RenderPassType) 
void shadeWithShadow() {
  vec3 ambient = ...; // compute ambient component here 
  vec3 diffSpec = diffAndSpec(); 
 
  // Do the shadow-map look-up 
  float shadow = textureProj(ShadowMap, ShadowCoord); 
 
  // If the fragment is in shadow, use ambient light only. 
  FragColor = vec4(diffSpec * shadow + ambient, 1.0); 
} 
subroutine (RenderPassType) 
void recordDepth() {
    // Do nothing, depth will be written automatically 
} 
 
void main() { 
  // This will call either shadeWithShadow or recordDepth 
  RenderPass(); 
} </pre>
<p>Within the main OpenGL program, perform the following steps when rendering. For pass one:</p>
<ol>
<li>Set the viewport, view, and projection matrices to those that are appropriate for the light source.</li>
<li>Bind to the <kbd>framebuffer</kbd> containing the shadow map (<kbd>shadowFBO</kbd>).</li>
<li>Clear the depth buffer.</li>
</ol>
<ol start="4">
<li>Select the subroutine <kbd>recordDepth</kbd> function.</li>
<li>Enable front-face culling.</li>
<li>Draw the scene.</li>
</ol>
<p>For pass two:</p>
<ol>
<li>Select the viewport, view, and projection matrices appropriate for the scene.</li>
<li>Bind to the default framebuffer.</li>
<li>Disable culling (or switch to back-face culling).</li>
<li>Select the subroutine function <kbd>shadeWithShadow</kbd> function.</li>
<li>Draw the scene.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The first block of the preceding code demonstrates how to create an FBO for our shadow map texture. The FBO contains only a single texture connected to its depth buffer attachment. The first few lines of code create the shadow map texture. The texture is allocated using the <kbd>glTexStorage2D</kbd> function with an internal format of <kbd>GL_DEPTH_COMPONENT24</kbd>.</p>
<p>We use <kbd>GL_NEAREST</kbd> for <kbd>GL_TEXTURE_MAG_FILTER</kbd> and <kbd>GL_TEXTURE_MIN_FILTER</kbd> here, although <kbd>GL_LINEAR</kbd> could also be used, and might provide slightly better-looking results. We use <kbd>GL_NEAREST</kbd> here so that we can see the aliasing artifacts clearly, and the performance will be slightly better.</p>
<p>Next, the <kbd>GL_TEXTURE_WRAP_*</kbd> modes are set to <kbd>GL_CLAMP_TO_BORDER</kbd>. When a fragment is found to lie completely outside of the shadow map (outside of the light's frustum), then the texture coordinates for that fragment will be greater than one or less than zero. When that happens, we need to make sure that those points are not treated as being in shadow. When <kbd>GL_CLAMP_TO_BORDER</kbd> is used, the value that is returned from a texture lookup (for coordinates outside the 0–1 range) will be the border value. The default border value is <kbd>(0,0,0,0)</kbd>. When the texture contains depth components, the first component is treated as the depth value. A value of zero will not work for us here because a depth of zero corresponds to points on the near plane. Therefore, all points outside of the light's frustum will be treated as being in shadow! Instead, we set the border color to <kbd>(1,0,0,0)</kbd> using the <kbd>glTexParameterfv</kbd> function, which corresponds to the maximum possible depth.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The next two calls to <kbd>glTexParameteri</kbd> affect settings that are specific to depth textures. The first call sets <kbd>GL_TEXTURE_COMPARE_MODE</kbd> to <kbd>GL_COMPARE_REF_TO_TEXTURE</kbd>. When this setting is enabled, the result of a texture access is the result of a comparison, rather than a color value retrieved from the texture. The third component of the texture coordinate (the <kbd>p</kbd> component) is compared against the value in the texture at location <kbd>(s,t)</kbd>. The result of the comparison is returned as a single floating-point value. The comparison function that is used is determined by the value of <kbd>GL_TEXTURE_COMPARE_FUNC</kbd>, which is set on the next line. In this case, we set it to <kbd>GL_LESS</kbd>, which means that the result will be <kbd>1.0</kbd> if the <kbd>p</kbd> value of the texture coordinate is less than the value stored at <kbd>(s,t)</kbd>. (Other options include <kbd>GL_LEQUAL</kbd>, <kbd>GL_ALWAYS</kbd>, <kbd>GL_GEQUAL</kbd>, and so on.)</p>
<p>The next few lines create and set up the FBO. The shadow map texture is attached to the FBO as the depth attachment with the <kbd>glFramebufferTexture2D</kbd> function. For more details about FBOs, check out the <em>Rendering to a texture</em> recipe in <a href="a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml">Chapter 5</a>, <em>Using Textures</em>.</p>
<p>The vertex shader is fairly simple. It converts the vertex position and normal-to-camera coordinates and passes them along to the fragment shader via the output variables <kbd>Position</kbd> and <kbd>Normal</kbd>. The vertex position is also converted into shadow map coordinates using <kbd>ShadowMatrix</kbd>. This is the matrix <em>S</em> that we referred to in the previous section. It converts a position from object coordinates to shadow coordinates. The result is sent to the fragment shader via the <kbd>ShadowCoord</kbd> output variable.</p>
<p>As usual, the position is also converted to clip coordinates and assigned to the built-in <kbd>gl_Position</kbd> output variable.</p>
<p>In the fragment shader, we provide different functionality for each pass. In the main function, we call <kbd>RenderPass</kbd>, which is a subroutine uniform that will call either <kbd>recordDepth</kbd> or <kbd>shadeWithShadow</kbd>. For the first pass (shadow map generation), the <kbd>recordDepth</kbd> subroutine function is executed. This function does nothing at all! This is because we only need to write the depth to the depth buffer. OpenGL will do this automatically (assuming that <kbd>gl_Position</kbd> was set correctly by the vertex shader), so there is nothing for the fragment shader to do.</p>
<p>During the second pass, the <kbd>shadeWithShadow</kbd> function is executed. We compute the ambient component of the shading model and store the result in the <kbd>ambient</kbd> variable.  We then compute the diffuse and specular components and store those in the <kbd>diffuseAndSpec</kbd> variable.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The next step is the key to the shadow mapping algorithm. We use the built-in <kbd>textureProj</kbd> texture access function to access the <kbd>ShadowMap</kbd> shadow map texture. Before using the texture coordinate to access the texture, the <kbd>textureProj</kbd> function will divide the first three components of the texture coordinate by the fourth component. Remember that this is exactly what is needed to convert the homogeneous position (<kbd>ShadowCoord</kbd>) to a true Cartesian position.</p>
<p>After this perspective division, the <kbd>textureProj</kbd> function will use the result to access the texture. As this texture's sampler type is <kbd>sampler2DShadow</kbd>, it is treated as a texture containing depth values, and rather than returning a value from the texture, it returns the result of a comparison. The first two components of <kbd>ShadowCoord</kbd> are used to access a depth value within the texture. That value is then compared against the value of the third component of <kbd>ShadowCoord</kbd>.</p>
<p>We need to use <kbd>vec3</kbd> as the lookup coordinate when using a sampler of type <kbd>sampler2DShadow</kbd>,  because we need a 2D position and a depth.</p>
<p>When <kbd>GL_NEAREST</kbd> is the interpolation mode (as it is in our case) the result will be <kbd>1.0</kbd>, or <kbd>0.0</kbd>. As we set the comparison function to <kbd>GL_LESS</kbd>, this will return <kbd>1.0</kbd>, but only if the value of the third component of <kbd>ShadowCoord</kbd> is less than the value within the depth texture at the sampled location. This result is then stored in the <kbd>shadow</kbd> variable. Finally, we assign a value to the output variable <kbd>FragColor</kbd>. The result of the shadow map comparison (<kbd>shadow</kbd>) is multiplied by the diffuse and specular components, and the result is added to the ambient component. If <kbd>shadow</kbd> is <kbd>0.0</kbd>, that means that the comparison failed, meaning that there is something between the fragment and the light source. Therefore, the fragment is only shaded with ambient light. Otherwise, <kbd>shadow</kbd> is <kbd>1.0</kbd>, and the fragment is shaded with all three shading components.</p>
<p>When rendering the shadow map, note that we culled the front faces. This is to avoid the z-fighting that can occur when front faces are included in the shadow map. Note that this only works if our mesh is completely closed. If back faces are exposed, you may need to use another technique (that uses <kbd>glPolygonOffset</kbd>) to avoid this. I'll talk a bit more about this in the next section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>There's a number of challenging issues with the shadow mapping technique. Let's look at just a few of the most immediate ones.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Aliasing</h1>
                
            
            
                
<p>As mentioned earlier, this algorithm often suffers from severe aliasing artifacts at the shadow's edges. This is due to the fact that the shadow map is essentially projected onto the scene when the depth comparison is made. If the projection causes the map to be magnified, aliasing artifacts appear.</p>
<p>The following image shows the aliasing of the shadow's edges:</p>
<div><img src="img/02d5a3b1-f57a-44dc-8ec5-1197aa9b5ebd.png" style="width:18.33em;height:11.25em;"/></div>
<p>The easiest solution is to simply increase the size of the shadow map. However, that may not be possible due to memory, CPU speed, or other constraints. There is a large number of techniques for improving the quality of the shadows produced by the shadow mapping algorithm such as resolution-matched shadow maps, cascaded shadow maps, variance shadow maps, perspective shadow maps, and many others. In the following recipes, we'll look at some ways to help you soften and anti-alias the edges of the shadows.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Rendering back faces only for the shadow map</h1>
                
            
            
                
<p>When creating the shadow map, we only rendered back faces. This is because if we were to render front faces, points on certain faces would have nearly the same depth as the shadow map's depth, which can cause fluctuations between light and shadow across faces that should be completely lit. The following image shows an example of this effect:</p>
<div><img src="img/16614eca-2d0c-45b2-9682-01c270fa13c1.png" style="width:21.75em;height:12.50em;"/></div>
<p>Since the majority of faces that cause this issue are those that are facing the light source, we avoid much of the problem by only rendering back faces during the shadow map pass. This, of course, will only work correctly if your meshes are completely closed. If that is not the case, <kbd>glPolygonOffset</kbd> can be used to help the situation by offsetting the depth of the geometry from that in the shadow map. In fact, even when back faces are only rendered when generating the shadow map, similar artifacts can appear on faces that are facing away from the light (back faces in the shadow map, but the front from the camera's perspective). Therefore, it is quite often the case that a combination of front-face culling and <kbd>glPolygonOffset</kbd> is used when generating the shadow map.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter08/sceneshadowmap.cpp</kbd> file in the example code</li>
<li>The <em>Rendering to a texture</em> recipe in <a href="a5d0db76-6dbb-470d-8685-42ab8ae077b1.xhtml">Chapter 5</a>, <em>Using Textures</em></li>
<li>The <em>Anti-aliasing shadow edges with PCF</em> recipe</li>
<li>The <em>Creating soft shadow edges with random sampling</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Anti-aliasing shadow edges with PCF</h1>
                
            
            
                
<p>One of the simplest and most common techniques for dealing with the aliasing of shadow edges is called <strong>percentage-closer filtering</strong> (<strong>PCF</strong>). The name comes from the concept of sampling the area around the fragment and determining the percentage of the area that is closer to the light source (in shadow). The percentage is then used to scale the amount of shading (diffuse and specular) that the fragment receives. The overall effect is a blurring of the shadow's edges.</p>
<p>The basic technique was first published by Reeves et al. in a 1987 paper (<em>SIGGRAPH Proceedings, Volume 21, Number 4, July 1987</em>). The concept involves transforming the fragment's extents into shadow space, sampling several locations within that region, and computing the percent that is closer than the depth of the fragment. The result is then used to attenuate the shading. If the size of this filter region is increased, it can have the effect of blurring the shadow's edges.</p>
<p>A common variant of the PCF algorithm involves just sampling a constant number of nearby texels within the shadow map. The percent of those texels that are closer to the light is used to attenuate the shading. This has the effect of blurring the shadow's edges. While the result may not be physically accurate, the result is not objectionable to the eye.</p>
<p>The following images show shadows rendered with PCF (right) and without PCF (left). Note that the shadows in the right-hand image have fuzzier edges and the aliasing is less visible:</p>
<div><img src="img/b5003004-02d5-4e85-9264-0528fc960458.png" style="width:36.83em;height:13.92em;"/></div>
<p>In this recipe, we'll use the latter technique, and sample a constant number of texels around the fragment's position in the shadow map. We'll calculate an average of the resulting comparisons and use that result to scale the diffuse and specular components.</p>
<p>We'll make use of OpenGL's built-in support for PCF by using linear filtering on the depth texture. When linear filtering is used with this kind of texture, the hardware can automatically sample four nearby texels (execute four depth comparisons) and average the results (the details of this are implementation dependent). Therefore, when linear filtering is enabled, the result of the <kbd>textureProj</kbd> function can be somewhere between 0.0 and 1.0.</p>
<p>We'll also make use of the built-in functions for texture accesses with offsets. OpenGL provides the <kbd>textureProjOffset</kbd> texture access function, which has a third parameter (the offset) that is added to the texel coordinates before the lookup/comparison.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Start with the shaders and FBO presented in the previous <em>Rendering shadows with shadow maps</em> recipe. We'll just make a few minor changes to the code presented there.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>To add the PCF technique to the shadow mapping algorithm, use the following steps:</p>
<ol>
<li>When setting up the FBO for the shadow map, make sure to use linear filtering on the depth texture. Replace the corresponding lines with the following code:</li>
</ol>
<pre style="padding-left: 60px">glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,  
                GL_LINEAR); 
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,      
                GL_LINEAR); </pre>
<ol start="2">
<li>Use the following code for the <kbd>shadeWithShadow</kbd> function within the fragment shader:</li>
</ol>
<pre style="padding-left: 60px">subroutine (RenderPassType) 
void shadeWithShadow() {
  vec3 ambient = vec3(0.2); 
  vec3 diffSpec = diffAndSpec(); 
 
  // The sum of the comparisons with nearby texels 
  float sum = 0; 
 
  // Sum contributions from texels around ShadowCoord 
  sum += textureProjOffset(ShadowMap, ShadowCoord,  
                           ivec2(-1,-1)); 
  sum += textureProjOffset(ShadowMap, ShadowCoord,  
                           ivec2(-1,1)); 
  sum += textureProjOffset(ShadowMap, ShadowCoord,  
                           ivec2(1,1)); 
  sum += textureProjOffset(ShadowMap, ShadowCoord,  
                           ivec2(1,-1)); 
  float shadow = sum * 0.25; 
 
  FragColor = vec4(ambient + diffSpec * shadow,1.0); 
} </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The first step enables linear filtering on the shadow map texture. When this is enabled, the OpenGL driver can repeat the depth comparison on the four nearby texels within the texture. The results of the four comparisons will be averaged and returned.</p>
<p class="mce-root"/>
<p>Within the fragment shader, we use the <kbd>textureProjOffset</kbd> function to sample the four texels (diagonally) surrounding the texel nearest to <kbd>ShadowCoord</kbd>. The third argument is the offset. It is added to the texel's coordinates (not the texture coordinates) before the lookup takes place.</p>
<p>As linear filtering is enabled, each lookup will sample an additional four texels, for a total of 16 texels. The results are then averaged together and stored within the variable shadow.</p>
<p>As before, the value of <kbd>shadow</kbd> is used to attenuate the diffuse and specular components of the lighting model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>An excellent survey of the PCF technique was written by Fabio Pellacini of Pixar, and can be found in Chapter 11, <em>Shadow Map Anti-aliasing</em>, of <em>GPU Gems</em>, edited by Randima Fernando, Addison-Wesley Professional, 2004. If more details are desired, I highly recommend reading this short, but informative, chapter.</p>
<p>Because of its simplicity and efficiency, the PCF technique is an extremely common method for anti-aliasing the edges of shadows produced by shadow mapping. Since it has the effect of blurring the edges, it can also be used to simulate soft shadows. However, the number of samples must be increased with the size of the blurred edge (the penumbra) to avoid certain artifacts. This can, of course, be a computational roadblock. In the next recipe, we'll look at a technique for producing soft shadows by randomly sampling a larger region.</p>
<p>A penumbra is the region of a shadow where only a portion of the light source is obscured.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter08/scenepcf.cpp</kbd> file in the example code</li>
<li>The <em>Rendering shadows with shadow maps</em> recipe</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating soft shadow edges with random sampling</h1>
                
            
            
                
<p>The basic shadow mapping algorithm combined with PCF can produce shadows with soft edges. However, if we desire blurred edges that are substantially wide (to approximate true soft shadows), then a large number of samples is required. Additionally, there is a good deal of wasted effort when shading fragments that are in the center of large shadows, or completely outside of the shadow. For those fragments, all of the nearby shadow map texels will evaluate to the same value. Therefore, the work of accessing and averaging those texels is essentially a wasted effort.</p>
<p>The technique presented in this recipe is based on a chapter published in <em>GPU Gems 2</em>, edited by Matt Pharr and Randima Fernando, Addison-Wesley Professional, 2005. (Chapter 17 by Yury Uralsky.) It provides an approach that can address both of the preceding issues to create shadows with soft edges of various widths, while avoiding unnecessary texture accesses in areas inside and outside of the shadow.</p>
<p>The basic idea is as follows:</p>
<ul>
<li>Instead of sampling texels around the fragment's position (in shadow map space) using a constant set of offsets, we use a random, circular pattern of offsets</li>
<li>In addition, we sample only the outer edges of the circle first in order to determine whether or not the fragment is in an area that is completely inside or outside of the shadow</li>
</ul>
<p>The following diagram is a visualization of a possible set of shadow map samples. The center of the crosshairs is the fragment's location in the shadow map, and each <strong>x</strong> is a sample. The samples are distributed randomly within a circular grid around the fragment's location (one sample per grid cell):</p>
<div><img src="img/aacb7906-d478-45ac-8d1d-d0ba4ac6ff0b.png" style="width:11.42em;height:12.42em;"/></div>
<p class="chapter-content">Additionally, we vary the sample locations through a set of precomputed sample patterns. We compute random sample offsets and store them in a texture prior to rendering. Then, in the fragment shader, the samples are determined by first accessing the offset texture to grab a set of offsets and using them to vary the fragment's position in the shadow map. The results are then averaged together in a similar manner to the basic PCF algorithm. The following diagram shows the difference between shadows using the PCF algorithm (left), and the random sampling technique described in this recipe (right):</p>
<div><div><img src="img/1dbf1617-75c9-4c89-913f-2150b9de348a.png" style="width:38.58em;height:14.58em;"/></div>
</div>
<p class="mce-root">We'll store the offsets in a three-dimensional texture (<em>n</em> x <em>n</em> x <em>d</em>). The first two dimensions are of arbitrary size, and the third dimension contains the offsets. Each (<em>s</em>,<em>t</em>) location contains a list (size <em>d</em>) of random offsets packed into an RGBA color. Each RGBA color in the texture contains two 2D offsets. The <em>R</em> and <em>G</em> channels contain the first offset, and the <em>B</em> and <em>A</em> channels contain the second. Therefore, each (<em>s</em>,<em>t</em>) location contains a total of <em>2*d</em> offsets.</p>
<p class="mce-root">For example, location (1, 1, 3) contains the sixth and seventh offset at location (1,1). The entire set of values at a given (<em>s</em>,<em>t</em>) comprise a full set of offsets. We'll rotate through the texture based on the fragment's screen coordinates. The location within the offset texture will be determined by taking the remainder of the screen coordinates divided by the texture's size. For example, if the fragment's coordinates are (10.0,10.0) and the texture's size is (4,4), then we use the set of offsets located in the offset texture at location (2,2).</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">Start with the code presented in the <em>Rendering shadows with shadow maps</em> recipe. There are three additional uniforms that need to be set. They are as follows:</p>
<ul>
<li><kbd>OffsetTexSize</kbd>: This gives the width, height, and depth of the offset texture. Note that the depth is same as the number of samples per fragment divided by two.</li>
<li><kbd>OffsetTex</kbd>: This is a handle to the texture unit containing the offset texture.</li>
<li><kbd>Radius</kbd>: This is the blur radius in pixels divided by the size of the shadow map texture (assuming a square shadow map). This could be considered as the softness of the shadow.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">To modify the shadow mapping algorithm and to use this random sampling technique, perform the following steps. We'll build the offset texture within the main OpenGL program, and make use of it within the fragment shader:</p>
<ol>
<li>Use the following code within the main OpenGL program to create the offset texture. This only needs to be executed once during the program's initialization:</li>
</ol>
<pre style="padding-left: 60px">void buildOffsetTex(int size, int samplesU, int samplesV) {
  int samples = samplesU * samplesV; 
  int bufSize = size * size * samples * 2; 
  float *data = new float[bufSize]; 
 
  for( int i = 0; i&lt; size; i++ ) { 
    for(int j = 0; j &lt; size; j++ ) { 
      for( int k = 0; k &lt; samples; k += 2 ) { 
        int x1,y1,x2,y2; 
        x1 = k % (samplesU); 
        y1 = (samples - 1 - k) / samplesU; 
        x2 = (k+1) % samplesU; 
        y2 = (samples - 1 - k - 1) / samplesU; 
 
        glm::vec4 v; 
        // Center on grid and jitter 
        v.x = (x1 + 0.5f) + jitter(); 
        v.y = (y1 + 0.5f) + jitter(); 
        v.z = (x2 + 0.5f) + jitter(); 
        v.w = (y2 + 0.5f) + jitter(); 
        // Scale between 0 and 1 
        v.x /= samplesU; 
        v.y /= samplesV; 
        v.z /= samplesU; 
        v.w /= samplesV; 
        // Warp to disk 
        int cell = ((k/2) * size * size + j *  
                    size + i) * 4; 
        data[cell+0] = glm::sqrt(v.y) * glm::cos(glm::two_pi&lt;float&gt;<br/>        ()*v.x); 
        data[cell+1] = glm::sqrt(v.y) * glm::sin(glm::two_pi&lt;float&gt;<br/>        ()*v.x); 
        data[cell+2] = glm::sqrt(v.w) * glm::cos(glm::two_pi&lt;float&gt;<br/>        ()*v.z); 
        data[cell+3] = glm::sqrt(v.w) * glm::sin(glm::two_pi&lt;float&gt;<br/>        ()*v.z); 
      } 
    } 
  } 
 
  glActiveTexture(GL_TEXTURE1); 
  GLuint texID; 
  glGenTextures(1, &amp;texID); 
 
  glBindTexture(GL_TEXTURE_3D, texID); 
  glTexStorage3D(GL_TEXTURE_3D, 1, GL_RGBA32F, size, size, 
                 samples/2); 
  glTexSubImage3D(GL_TEXTURE_3D, 0, 0, 0, 0, size, size,  
                 samples/2, GL_RGBA, GL_FLOAT, data); 
  glTexParameteri(GL_TEXTURE_3D, GL_TEXTURE_MAG_FILTER,  
                    GL_NEAREST); 
  glTexParameteri(GL_TEXTURE_3D, GL_TEXTURE_MIN_FILTER,  
                    GL_NEAREST); 
 
  delete [] data; 
} 
 
// Return random float between -0.5 and 0.5 
float jitter() { <br/>  static std::default_random_engine generator;<br/>  static std::uniform_real_distribution&lt;float&gt; distrib(-0.5f, 0.5f); <br/>  return distrib(generator); <br/>}</pre>
<ol start="2">
<li>Add the following uniform variables to the fragment shader:</li>
</ol>
<pre style="padding-left: 60px">uniform sampler3D OffsetTex; 
uniform vec3 OffsetTexSize; // (width, height, depth) 
uniform float Radius;</pre>
<ol start="3">
<li>Use the following code for the <kbd>shadeWithShadow</kbd> function in the fragment shader:</li>
</ol>
<pre style="padding-left: 60px">subroutine (RenderPassType) 
void shadeWithShadow() {
  vec3 ambient = vec3(0.2); 
  vec3 diffSpec = diffAndSpec(); 
 
  ivec3 offsetCoord; 
  offsetCoord.xy = ivec2( mod( gl_FragCoord.xy,  
                         OffsetTexSize.xy ) ); 
 
  float sum = 0.0; 
  int samplesDiv2 = int(OffsetTexSize.z); 
  vec4 sc = ShadowCoord; 
 
  for( int i = 0 ; i&lt; 4; i++ ) { 
    offsetCoord.z = i; 
    vec4 offsets = texelFetch(OffsetTex,offsetCoord,0) *  
                       Radius * ShadowCoord.w; 
 
    sc.xy = ShadowCoord.xy + offsets.xy; 
    sum += textureProj(ShadowMap, sc); 
    sc.xy = ShadowCoord.xy + offsets.zw; 
    sum += textureProj(ShadowMap, sc); 
  } 
  float shadow = sum / 8.0; 
 
  if( shadow != 1.0 &amp;&amp; shadow != 0.0 ) { 
    for( int i = 4; i&lt; samplesDiv2; i++ ) { 
      offsetCoord.z = i; 
      vec4 offsets =  
        texelFetch(OffsetTex, offsetCoord,0) * 
                   Radius * ShadowCoord.w; 
 
      sc.xy = ShadowCoord.xy + offsets.xy; 
      sum += textureProj(ShadowMap, sc); 
      sc.xy = ShadowCoord.xy + offsets.zw; 
      sum += textureProj(ShadowMap, sc); 
    } 
    shadow = sum / float(samplesDiv2 * 2.0); 
  } 
  FragColor = vec4(diffSpec * shadow + ambient, 1.0); 
}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">The <kbd>buildOffsetTex</kbd> function creates our three-dimensional texture of random offsets. The first parameter, <kbd>texSize</kbd>, defines the width and height of the texture. To create the preceding images, I used a value of <kbd>8</kbd>. The second and third parameters, <kbd>samplesU</kbd> and <kbd>samplesV</kbd>, define the number of samples in the <kbd>u</kbd> and <kbd>v</kbd> directions. I used a value of <kbd>4</kbd> and <kbd>8</kbd>, respectively, for a total of 32 samples. The <kbd>u</kbd> and <kbd>v</kbd> directions are arbitrary axes that are used to define a grid of offsets. To understand this, take a look at the following diagram:</p>
<div><img src="img/66af00d9-05d0-4218-ba1a-fdcea2dc58b4.png" style="width:38.25em;height:15.92em;"/></div>
<p class="chapter-content">The offsets are initially defined to be centered on a grid of size <kbd>samplesU</kbd> x <kbd>samplesV</kbd> (4 x 4 in the preceding diagram). The coordinates of the offsets are scaled such that the entire grid fits in the unit cube (side length <kbd>1</kbd>) with the origin in the lower-left corner. Then, each sample is randomly jittered from its position to a random location inside the grid cell. Finally, the jittered offsets are warped so that they surround the origin and lie within the circular grid shown on the right.</p>
<p class="chapter-content">The last step can be accomplished by using the <em>v</em> coordinate as the distance from the origin and the <em>u</em> coordinate as the angle scaled from 0 to 360. The following equations should do the trick:</p>
<div><img class="fm-editor-equation" src="img/66de6b0d-9548-4a3f-b258-1e7ce97c2ffd.png" style="width:11.08em;height:3.67em;"/></div>
<p class="chapter-content">Here, <em>w</em> is the warped coordinate. What we are left with is a set of offsets around the origin that are a maximum distance of 1.0 from the origin. Additionally, we generate the data such that the first samples are the ones around the outer edge of the circle, moving inside toward the center. This will help us avoid taking too many samples when we are working completely inside or outside of the shadow.</p>
<p class="mce-root"/>
<p class="chapter-content">Of course, we also pack the samples in such a way that a single texel contains two samples. This is not strictly necessary, but is done to conserve memory space. However, it does make the code a bit more complex.</p>
<p class="chapter-content">Within the fragment shader, we start by computing the ambient component of the shading model separately from the diffuse and specular components. We access the offset texture at a location based on the fragment's screen coordinates (<kbd>gl_FragCoord</kbd>). We do so by taking the modulus of the fragment's position and the size of the offset texture. The result is stored in the first two components of <kbd>offsetCoord</kbd>. This will give us a different set of offsets for each nearby pixel. The third component of <kbd>offsetCoord</kbd> will be used to access a pair of samples. The number of samples is the depth of the texture divided by two. This is stored in <kbd>samplesDiv2</kbd>. We access the sample using the <kbd>texelFetch</kbd> function. This function allows us to access a texel using the integer texel coordinates rather than the usual normalized texture coordinates in the range 0-1.</p>
<p class="chapter-content">The offset is retrieved and multiplied by <kbd>Radius</kbd> and the <em>w</em> component of <kbd>ShadowCoord</kbd>. Multiplying by <kbd>Radius</kbd> simply scales the offsets so that they range from <kbd>0.0</kbd> to <kbd>Radius</kbd>.  Typically, we want the radius to represent a small region in texel space, so a value like <kbd>5/width</kbd> (where <kbd>width</kbd> is the width of the shadow map) would be appropriate. We multiply by the <em>w</em> component because <kbd>ShadowCoord</kbd> is still a homogeneous coordinate, and our goal is to use offsets to translate the <kbd>ShadowCoord</kbd>. In order to do so properly, we need to multiply the offset by the <em>w</em> component. Another way of thinking of this is that the w component will be cancelled when perspective division takes place.</p>
<p class="chapter-content">Next, we use offsets to translate <kbd>ShadowCoord</kbd> and access the shadow map to do the depth comparison using <kbd>textureProj</kbd>. We do so for each of the two samples stored in the texel, once for the first two components of offsets and again for the last two. The result is added to <kbd>sum</kbd>.</p>
<p class="chapter-content">The first loop repeats this for the first eight samples. If the first eight samples are all <kbd>0.0</kbd> or <kbd>1.0</kbd>, then we assume that all of the samples will be the same (the sample area is completely in or out of the shadow). In that case, we skip the evaluation of the rest of the samples. Otherwise, we evaluate the following samples and compute the overall average. Finally, the resulting average (shadow) is used to attenuate the diffuse and specular components of the lighting model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">The use of a small texture containing a set of random offsets helps to blur the edges of the shadow better than what we might achieve with the standard PCF technique that uses a constant set of offsets. However, artifacts can still appear as repeated patterns within the shadow edges because the texture is finite and offsets are repeated every few pixels. We could improve this by also using a random rotation of the offsets within the fragment shader, or simply compute the offsets randomly within the shader.</p>
<p class="chapter-content">It should also be noted that this blurring of the edges may not be desired for all shadow edges. For example, edges that are directly adjacent to the occluder, that is, creating the shadow, should not be blurred. These may not always be visible, but can become so in certain situations, such as when the occluder is a narrow object. The effect is to make the object appear as if it is hovering above the surface. Unfortunately, there isn't an easy fix for this one.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter08/scenejitter.cpp</kbd> file in the example code</li>
<li>The <em>Rendering shadows with shadow maps</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating shadows using shadow volumes and the geometry shader</h1>
                
            
            
                
<p class="mce-root">As we discovered in the previous recipes, one of the main problems with shadow maps is aliasing. The problem essentially boils down to the fact that we are sampling the shadow map(s) at a different frequency (resolution) than we are using when rendering the scene. To minimize the aliasing we can blur the shadow edges (as in the previous recipes), or try to sample the shadow map at a frequency that is closer to the corresponding resolution in projected screen space. There are many techniques that help with the latter; for more details, I recommend the book <em>Real-Time Shadows</em>.</p>
<p class="chapter-content">An alternate technique for shadow generation is called <strong>shadow volumes</strong>. The shadow volume method completely avoids the aliasing problem that plagues shadow maps. With shadow volumes, you get pixel-perfect hard shadows, without the aliasing artifacts of shadow maps. The following image shows a scene with shadows that are produced using the shadow volume technique:</p>
<div><img src="img/e9d2530d-a853-430f-ad8a-8e635e0c5f2e.png" style="width:29.42em;height:16.92em;"/></div>
<p class="chapter-content">The shadow volume technique works by making use of the stencil buffer to mask out areas that are in shadow. We do this by drawing the boundaries of the actual shadow volumes (more on this next). A shadow volume is the region of space where the light source is occluded by an object. For example, the following diagram shows a representation of the shadow volumes of a triangle (left) and a sphere (right):</p>
<div><img src="img/5e741657-e602-4eb8-b108-75800559aae7.png" style="width:26.67em;height:9.75em;"/></div>
<p class="chapter-content">The boundaries of a shadow volume are made up of quads formed by extending the edges of the object away from the light source. For a single triangle, the boundaries would consist of three quads, extended from each edge, and triangular caps on each end. One cap is the triangle itself and the other is placed at some distance from the light source. For an object that consists of many triangles, such as the preceding sphere, the volume can be defined by the so-called <strong>silhouette edges</strong>. These are edges that are on or near the boundary between the shadow volume and the portion of the object that is lit. In general, a silhouette edge borders a triangle that faces the light and another triangle that faces away from the light. To draw the shadow volume, one would find all of the silhouette edges and draw extended quads for each edge. The caps of the volume could be determined by making a closed polygon (or triangle fan) that includes all the points on the silhouette edges, and similarly on the far end of the volume.</p>
<p class="chapter-content">The shadow volume technique works in the following way. Imagine a ray that originates at the camera position and extends through a pixel on the near plane. Suppose that we follow that ray and keep track of a counter that is incremented every time that it enters a shadow volume and decremented each time that it exits a shadow volume. If we stop counting when we hit a surface, that point on the surface is occluded (in shadow) if our count is non-zero, otherwise, the surface is lit by the light source. The following diagram shows an example of this idea:</p>
<div><img src="img/46a5d757-ce83-47af-a0a9-d9af7a12d099.png" style="width:23.42em;height:17.42em;"/></div>
<p class="chapter-content">The roughly horizontal line represents a surface that is receiving a shadow. The numbers represent the counter for each camera ray. For example, the rightmost ray with value <strong>+1</strong> has that value because the ray entered two volumes and exited one along the way from the camera to the surface: <em>1 + 1 - 1 = 1</em>. The rightmost ray has a value of <strong>0</strong> at the surface because it entered and exited both shadow volumes: <em>1 + 1 - 1 - 1 = 0</em>.</p>
<p class="chapter-content">This all sounds fine in theory, but how can we trace rays in OpenGL? The good news is that we don't have to. The stencil buffer provides just what we need. With the stencil buffer, we can increment/decrement a counter for each pixel based on whether a front or back face is rendered into that pixel. So, we can draw the boundaries of all of the shadow volumes, then for each pixel, increment the stencil buffer's counter when a front face is rendered to that pixel and decrement when it is a back face.</p>
<p class="chapter-content">The key here is to realize that each pixel in the rendered figure represents an eye-ray (as in the preceding diagram). So, for a given pixel, the value in the stencil buffer is the value that we would get if we actually traced a ray through that pixel. The depth test helps to stop tracing when we reach a surface.</p>
<p>This is just a quick introduction to shadow volumes; a full discussion is beyond the scope of this book. For more detail, a great resource is <em>Real-Time Shadows</em> by Eisemann et al.</p>
<p class="mce-root">In this recipe, we'll draw our shadow volumes with the help of the geometry shader. Rather than computing the shadow volumes on the CPU side, we'll render the geometry normally, and have the geometry shader produce the shadow volumes. In the <em>Drawing silhouette lines using the geometry shader</em> recipe in <a href="fab663d4-e210-417c-aa3b-2c4c307ec913.xhtml">Chapter 7</a>, <em>Using Geometry and Tessellation Shaders</em>, we saw how the geometry shader can be provided with adjacency information for each triangle. With adjacency information, we can determine whether a triangle has a silhouette edge. If the triangle faces the light, and a neighboring triangle faces away from the light, then the shared edge can be considered a silhouette edge, and used to create a polygon for the shadow volume.</p>
<p class="mce-root">The entire process is done in three passes. They are as follows:</p>
<ol>
<li>Render the scene normally, but write the shaded color to two separate buffers. We'll store the ambient component in one and the diffuse and specular components in another.</li>
<li>Set up the stencil buffer so that the stencil test always passes, and front faces cause an increment and back faces cause a decrement. Make the depth buffer read-only, and render only the shadow-casting objects. In this pass, the geometry shader will produce the shadow volumes, and only the shadow volumes will be rendered to the fragment shader.</li>
<li>Set up the stencil buffer so that the test succeeds when the value is equal to zero. Draw a screen-filling quad, and combine the values of the two buffers from step one when the stencil test succeeds.</li>
</ol>
<p class="mce-root">That's the high-level view, and there are many details. Let's go through them in the next sections.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p class="mce-root">We'll start by creating our buffers. We'll use a framebuffer object with a depth attachment and two color attachments. The ambient component can be stored in a renderbuffer (as opposed to a texture) because we'll blit (a fast copy) it over to the default framebuffer rather than reading from it as a texture. The <em>diffuse + specular</em> component will be stored in a texture.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">Create the ambient buffer (<kbd>ambBuf</kbd>), a depth buffer (<kbd>depthBuf</kbd>), and a texture (<kbd>diffSpecTex</kbd>), then set up the FBO:</p>
<pre>glGenFramebuffers(1, &amp;colorDepthFBO); 
glBindFramebuffer(GL_FRAMEBUFFER, colorDepthFBO); 
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT,  
                          GL_RENDERBUFFER, depthBuf); 
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,  
                          GL_RENDERBUFFER, ambBuf); 
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1,  
                       GL_TEXTURE_2D, diffSpecTex, 0); </pre>
<p class="mce-root">Set up the draw buffers so that we can write to the color attachments:</p>
<pre>GLenum drawBuffers[] = {GL_COLOR_ATTACHMENT0,  
                        GL_COLOR_ATTACHMENT1}; 
glDrawBuffers(2, drawBuffers); </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p class="mce-root">For the first pass, enable the framebuffer object that we set up earlier, and render the scene normally. In the fragment shader, send the ambient component and the <em>diffuse + specular</em> component to separate outputs:</p>
<pre>layout( location = 0 ) out vec4 Ambient; 
layout( location = 1 ) out vec4 DiffSpec; 
 
void shade( ) {
  // Compute the shading model, and separate out the ambient 
  // component. 
  Ambient = ...;   // Ambient 
  DiffSpec = ...;  // Diffuse + specular 
} 
void main() { shade(); } </pre>
<p class="mce-root">In the second pass, we'll render our shadow volumes. We want to set up the stencil buffer so that the test always succeeds, and that front faces cause an increment, and back faces cause a decrement:</p>
<pre>glClear(GL_STENCIL_BUFFER_BIT); 
glEnable(GL_STENCIL_TEST); 
glStencilFunc(GL_ALWAYS, 0, 0xffff); 
glStencilOpSeparate(GL_FRONT, GL_KEEP, GL_KEEP, GL_INCR_WRAP); 
glStencilOpSeparate(GL_BACK, GL_KEEP, GL_KEEP, GL_DECR_WRAP);</pre>
<p class="mce-root"/>
<p class="mce-root">Also in this pass, we want to use the depth buffer from the first pass, but we want to use the default frame buffer, so we need to copy the depth buffer over from the FBO used in the first pass. We'll also copy over the color data, which should contain the ambient component:</p>
<pre>glBindFramebuffer(GL_READ_FRAMEBUFFER, colorDepthFBO);  
glBindFramebuffer(GL_DRAW_FRAMEBUFFER,0); 
glBlitFramebuffer(0,0,width,height,0,0,width,height, 
           GL_DEPTH_BUFFER_BIT|GL_COLOR_BUFFER_BIT, GL_NEAREST); </pre>
<p class="mce-root">We don't want to write to the depth buffer or the color buffer in this pass, since our only goal is to update the stencil buffer, so we'll disable writing for those buffers:</p>
<pre>glColorMask(GL_FALSE, GL_FALSE, GL_FALSE, GL_FALSE);  
glDepthMask(GL_FALSE); </pre>
<p class="mce-root">Next, we render the shadow-casting objects with adjacency information. In the geometry shader, we determine the silhouette edges and output only quads that define the shadow volume boundaries:</p>
<pre>layout( triangles_adjacency ) in; 
layout( triangle_strip, max_vertices = 18 ) out; 
 
in vec3 VPosition[]; 
in vec3 VNormal[]; 
 
uniform vec4 LightPosition;  // Light position (eye coords) 
uniform mat4 ProjMatrix;     // Proj. matrix (infinite far plane) 
 
bool facesLight( vec3 a, vec3 b, vec3 c ) {
  vec3 n = cross( b - a, c - a ); 
  vec3 da = LightPosition.xyz - a; 
  vec3 db = LightPosition.xyz - b; 
  vec3 dc = LightPosition.xyz - c; 
  return dot(n, da) &gt; 0 || dot(n, db) &gt; 0 || dot(n, dc) &gt; 0;  
} 
 
void emitEdgeQuad( vec3 a, vec3 b ) { 
  gl_Position = ProjMatrix * vec4(a, 1); 
  EmitVertex();   
  gl_Position = ProjMatrix * vec4(a - LightPosition.xyz, 0); 
  EmitVertex(); 
  gl_Position = ProjMatrix * vec4(b, 1); 
  EmitVertex(); 
  gl_Position = ProjMatrix * vec4(b - LightPosition.xyz, 0); 
  EmitVertex(); 
  EndPrimitive(); 
} 
 
void main() {
  if( facesLight(VPosition[0], VPosition[2], VPosition[4]) ) { 
    if( ! facesLight(VPosition[0],VPosition[1],VPosition[2]) )  
       emitEdgeQuad(VPosition[0],VPosition[2]); 
    if( ! facesLight(VPosition[2],VPosition[3],VPosition[4]) )  
       emitEdgeQuad(VPosition[2],VPosition[4]); 
    if( ! facesLight(VPosition[4],VPosition[5],VPosition[0]) )  
       emitEdgeQuad(VPosition[4],VPosition[0]); 
  } 
} </pre>
<p class="mce-root">In the third pass, we'll set up our stencil buffer so that the test passes only when the value in the buffer is equal to zero:</p>
<pre>glStencilFunc(GL_EQUAL, 0, 0xffff); 
glStencilOp(GL_KEEP, GL_KEEP, GL_KEEP); </pre>
<p class="mce-root">We want to enable blending so that our ambient component is combined with <em>diffuse + specular</em> when the stencil test succeeds:</p>
<pre>glEnable(GL_BLEND);           
glBlendFunc(GL_ONE,GL_ONE); </pre>
<p class="mce-root">In this pass, we just draw a screen-filling quad, and output the <em>diffuse + specular</em> value. If the stencil test succeeds, the value will be combined with the ambient component, which is already in the buffer (we copied it over earlier using <kbd>glBlitFramebuffer</kbd>):</p>
<pre>layout(binding = 0) uniform sampler2D DiffSpecTex; 
layout(location = 0) out vec4 FragColor; 
 
void main() { 
  vec4 diffSpec = texelFetch(DiffSpecTex, ivec2(gl_FragCoord), 0); 
  FragColor = vec4(diffSpec.xyz, 1); 
} </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p class="mce-root">The first pass is fairly straightforward. We draw the entire scene normally, except we separate the ambient color from the diffuse and specular color, and send the results to different buffers.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">The second pass is the core of the algorithm. Here, we render only the objects that cast shadows and let the geometry shader produce the shadow volumes. Thanks to the geometry shader, we don't actually end up rendering the shadow-casting objects at all, only the shadow volumes. However, before this pass, we need to do a bit of setup. We set up the stencil test so that it increments when a front face is rendered and decrements for back faces using <kbd>glStencilOpSeparate</kbd>, and the stencil test is configured to always succeed using <kbd>glStencilFunc</kbd>. We also use <kbd>glBlitFramebuffer</kbd> to copy over the depth buffer and (ambient) color buffer from the FBO used in the first pass. Since we want to only render shadow volumes that are not obscured by geometry, we make the depth buffer read-only using <kbd>glDepthMask</kbd>. Lastly, we disable writing to the color buffer using <kbd>glColorMask</kbd> because we don't want to mistakenly overwrite anything in this pass.</p>
<p class="mce-root">The geometry shader does the work of producing the silhouette shadow volumes. Since we are rendering using adjacency information (see the <em>Drawing silhouette lines using the geometry shader</em> recipe in <a href="fab663d4-e210-417c-aa3b-2c4c307ec913.xhtml">Chapter 7</a>, <em>Using Geometry and Tessellation Shaders</em>), the geometry shader has access to six vertices that define the current triangle being rendered and the three neighboring triangles. The vertices are numbered from 0 to 5, and are available via the input array named <kbd>VPosition</kbd> in this example. Vertices 0, 2, and 4 define the current triangle and the others define the adjacent triangles, as shown in the following diagram:</p>
<div><img src="img/a1daffb5-c408-48ab-9418-1ce337807843.png" style="width:13.33em;height:11.75em;"/></div>
<p class="mce-root">The geometry shader starts by testing the main triangle (<strong>0</strong>, <strong>2</strong>, <strong>4</strong>) to see if it faces the light source. We do so by computing the normal to the triangle (<kbd>n</kbd>) and the vector from each vertex to the light source. Then, we compute the dot product of n and each of the three light source direction vectors (<kbd>da</kbd>, <kbd>db</kbd>, and <kbd>dc</kbd>). If any of the three are positive, then the triangle faces the light source. If we find that triangle (<strong>0</strong>, <strong>2</strong>, <strong>4</strong>) faces the light, then we test each neighboring triangle in the same way. If a neighboring triangle does not face the light source, then the edge between them is a silhouette edge and can be used as an edge of a face of the shadow volume.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">We create a shadow volume face in the <kbd>emitEdgeQuad</kbd> function. The points <kbd>a</kbd> and <kbd>b</kbd> define the silhouette edge, one edge of the shadow volume face. The other two vertices of the face are determined by extending <kbd>a</kbd> and <kbd>b</kbd> away from the light source. Here, we use a mathematical trick that is enabled by homogeneous coordinates. We extend the face out to infinity by using a zero in the <kbd>w</kbd> coordinate of the extended vertices. This effectively defines a homogeneous vector, sometimes called a point at infinity. The <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd> coordinates define a vector in the direction away from the light source, and the <kbd>w</kbd> value is set to <kbd>0</kbd>. The end result is that we get a quad that extends out to infinity, away from the light source.</p>
<p>This will only work properly if we use a modified projection matrix that can take into account points defined in this way. Essentially, we want a projection matrix with a far plane set at infinity. GLM provides just such a projection matrix via the <kbd>infinitePerspective</kbd> function.</p>
<p class="mce-root">We don't worry about drawing the caps of the shadow volume here. We don't need a cap at the far end, because we've used the homogeneous trick described earlier, and the object itself will serve as the cap on the near end.</p>
<p class="mce-root">In the third and final pass, we reset our stencil test to pass when the value in the stencil buffer is equal to zero using <kbd>glStencilFunc</kbd>. Here, we want to sum the ambient with the <em>diffuse + specular</em> color when the stencil test succeeds, so we enable blending, and set the source and destination blend functions to <kbd>GL_ONE</kbd>. We render just a single screen-filling quad, and output the value from the texture that contains our <em>diffuse + specular</em> color. The stencil test will take care of discarding fragments that are in shadow, and OpenGL's blending support will blend the output with the ambient color for fragments that pass the test. (Remember that we copied over the ambient color using <kbd>glBlitFramebuffer</kbd> earlier.)</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p class="mce-root">The technique described here is often referred to as the <strong>z-pass</strong> technique. It has one fatal flaw. If the camera is located within a shadow volume, this technique breaks down because the counts in the stencil buffer will be off by at least one. A common solution is to basically invert the problem and trace a ray from infinity toward the view point. This is called the <strong>z-fail</strong> technique or <strong>Carmack's reverse</strong>.</p>
<p>The <em>fail</em> and <em>pass</em> here refer to whether or not we are counting when the depth test passes or fails.</p>
<p class="mce-root"/>
<p class="mce-root">Care must be taken when using z-fail because it is important to draw the caps of the shadow volumes. However, the technique is very similar to z-pass. Instead of incrementing/decrementing when the depth test passes, we do so when the depth test fails. This effectively <em>traces </em>a ray from infinity back toward the view point.</p>
<p class="mce-root">I should also note that the preceding code is not robust enough to degenerate triangles (triangles that have sides that are nearly parallel), or non-closed meshes. One might need to take care in such situations. For example, to better deal with degenerate triangles, we could use another technique for determining the normal to the triangle. We could also add additional code to handle edges of meshes, or simply always use closed meshes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter08/sceneshadowvolume.cpp</kbd> file in the example code</li>
<li>The <em>Drawing silhouette lines </em><em>using the geometry shader</em> recipe in <a href="fab663d4-e210-417c-aa3b-2c4c307ec913.xhtml">Chapter 7</a>, <em>Using Geometry and Tessellation Shaders</em></li>
</ul>


            

            
        
    </body></html>