- en: The Basics of GLSL Shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Diffuse and per-vertex shading with a single point light source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the Phong reflection model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using functions in shaders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing two-sided shading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing flat shading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using subroutines to select shader functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discarding fragments to create a perforated look
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shaders were first added into OpenGL in version 2.0, introducing programmability
    into the formerly fixed-function OpenGL pipeline. Shaders give us the power to
    implement custom rendering algorithms and provide us with a greater degree of
    flexibility in the implementation of those techniques. With shaders, we can run
    custom code directly on the GPU, providing us with the opportunity to leverage
    the high degree of parallelism available with modern GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Shaders are implemented using the **OpenGL Shading Language** (**GLSL**). GLSL
    is syntactically similar to C, which should make it easier for experienced OpenGL
    programmers to learn. Due to the nature of this text, I won't present a thorough
    introduction to GLSL here. Instead, if you're new to GLSL, reading through these
    recipes should help you to learn the language through example. If you are already
    comfortable with GLSL, but don't have experience with version 4.x, you'll see
    how to implement these techniques by utilizing the newer API. However, before
    we jump into GLSL programming, let's take a quick look at how vertex and fragment
    shaders fit within the OpenGL pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex and fragment shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In OpenGL Version 4.3 and above, there are six shader stages/types: vertex,
    geometry, tessellation control, tessellation evaluation, fragment, and compute.
    In this chapter, we''ll focus only on the vertex and fragment stages. In [Chapter
    7](fab663d4-e210-417c-aa3b-2c4c307ec913.xhtml), *Using Geometry and Tessellation
    Shaders*, I''ll provide some recipes for working with the geometry and tessellation
    shaders, and in [Chapter 11](d67e01c8-8212-4d49-937f-6b1c62a57744.xhtml), *Using
    Compute Shaders*, I''ll focus specifically on compute shaders.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Shaders are fundamental parts of the modern OpenGL pipeline. The following
    block diagram shows a simplified view of the OpenGL pipeline with only the vertex
    and fragment shaders installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b21bf23-b73d-4288-a641-55bfea8b9842.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Vertex data is sent down the pipeline and arrives at the vertex shader via
    shader input variables. The vertex shader''s input variables correspond to the
    vertex attributes (refer to the *Sending data to a shader using vertex attributes
    and vertex buffer objects* recipe in [Chapter 2](15752c1f-eee7-4117-9632-f08f84a9405d.xhtml),
    *Working with GLSL Programs*). In general, a shader receives its input via programmer-defined
    input variables, and the data for those variables comes either from the main OpenGL
    application or previous pipeline stages (other shaders). For example, a fragment
    shader''s input variables might be fed from the output variables of the vertex
    shader. Data can also be provided to any shader stage using uniform variables
    (refer to the *Sending data to a shader using uniform variables* recipe in [Chapter
    2](15752c1f-eee7-4117-9632-f08f84a9405d.xhtml), *Working with GLSL Programs*).
    These are used for information that changes less often than vertex attributes
    (for example, matrices, light position, and other settings). The following diagram
    shows a simplified view of the relationships between input and output variables
    when there are two shaders active (vertex and fragment):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ae9550c-eb4e-4582-877f-c31256676587.png)'
  prefs: []
  type: TYPE_IMG
- en: The vertex shader is executed once for each vertex, in parallel. The data corresponding
    to the position of the vertex must be transformed into clip space coordinates
    and assigned to the output variable `gl_Position` before the vertex shader finishes
    execution. The vertex shader can send other information down the pipeline using
    shader output variables. For example, the vertex shader might also compute the
    color associated with the vertex. That color would be passed to later stages via
    an appropriate output variable.
  prefs: []
  type: TYPE_NORMAL
- en: Between the vertex and fragment shader, vertices are assembled into primitives,
    clipping takes place, and the viewport transformation is applied (among other
    operations). The rasterization process then takes place and the polygon is filled
    (if necessary). The fragment shader is executed once for each fragment of the
    polygon being rendered (typically in parallel). Data provided from the vertex
    shader is (by default) interpolated in a perspective correct manner, and provided
    to the fragment shader via shader input variables. The fragment shader determines
    the appropriate color for the pixel and sends it to the frame buffer using output
    variables. The depth information is handled automatically, but can be modified
    by the fragment shader if desired.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the basics first
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Programmable shaders give us tremendous power and flexibility. A good place
    to start is to learn how to implement a simple, common reflection model known
    as the **Phong reflection model**. It is a good basis for building upon.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll look at the basic techniques for implementing the Phong
    model. We'll modify it in a few simple ways, including two-sided rendering and
    flat shading. Along the way, we'll also see some examples of other GLSL features
    such as functions, subroutines, and the `discard` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Diffuse and per-vertex shading with a single point light source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before learning the full Phong reflection model, we''ll start with just one
    part: diffuse reflection. It is a simple reflection model that makes the assumption
    that the surface exhibits purely diffuse reflection. That is to say that the surface
    appears to scatter light in all directions equally, regardless of direction.'
  prefs: []
  type: TYPE_NORMAL
- en: Incoming light strikes the surface and penetrates slightly before being reradiated
    in all directions. Of course, the incoming light interacts with the surface before
    it is scattered, causing some wavelengths to be fully or partially absorbed and
    others to be scattered. A typical example of a diffuse surface is a surface that
    has been painted with a matte paint. The surface has a dull look with no shine
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows a torus rendered with diffuse shading:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/477790cd-0263-4bb5-9123-a9770f48abb9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The mathematical model for diffuse reflection involves two vectors: the direction
    from the surface point to the light source (**s**), and the normal vector at the
    surface point (**n**). The vectors are represented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b05ab82-3db9-46b0-a1a9-f0aacd3c81ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The amount of incoming light (or radiance) per unit area that strikes a surface
    is dependent on the orientation of the surface with respect to the light source.
    The physics of the situation tells us that the amount of radiation per unit area
    is maximal when the light arrives along the direction of the normal vector, and
    zero when the light is perpendicular to the normal vector. In between, it is proportional
    to the cosine of the angle between the direction towards the light source and
    the normal vector. So, since the dot product is proportional to the cosine of
    the angle between two vectors, we can express the amount of radiation striking
    the surface as the product of the light intensity and the dot product of *s* and
    *n*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b6b510f6-32fc-4f53-a48e-2fb4c995e299.png)'
  prefs: []
  type: TYPE_IMG
- en: '*L[d]* is the intensity of the light source, and the vectors **s** and **n**
    are assumed to be normalized.'
  prefs: []
  type: TYPE_NORMAL
- en: The dot product of two unit vectors is equal to the cosine of the angle between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As stated previously, some of the incoming light is absorbed before it is reemitted.
    We can model this interaction by using a reflection coefficient (*K[d]*), which
    represents the fraction of the incoming light that is scattered. This is sometimes
    called the **diffuse reflectivity**, or the diffuse reflection coefficient. The
    diffuse reflectivity becomes a scaling factor, so the intensity of the outgoing
    light can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42dcb457-527b-4407-b8ec-d1f7538bd691.png)'
  prefs: []
  type: TYPE_IMG
- en: Because this model depends only on the direction towards the light source and
    the normal to the surface, not on the direction towards the viewer, we have a
    model that represents uniform (omnidirectional) scattering.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll evaluate this equation at each vertex in the vertex shader
    and interpolate the resulting color across the face. We'll use uniform variables
    for the *K[d]* and *L[d]* terms as well as the light position.
  prefs: []
  type: TYPE_NORMAL
- en: In this and the following recipes, light intensities and material reflectivity
    coefficients are represented by three-component (RGB) vectors. Therefore, the
    equations should be treated as component-wise operations, applied to each of the
    three components separately. Luckily, the GLSL will make this nearly transparent
    because the necessary operators operate component-wise on vector variables.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start with an OpenGL application that provides the vertex position in attribute
    location 0, and the vertex normal in attribute location 1 (refer to the *Sending
    data to a shader using vertex attributes and vertex buffer objects* recipe in
    [Chapter 2](15752c1f-eee7-4117-9632-f08f84a9405d.xhtml), *Working with GLSL Programs*).
    The OpenGL application should also provide the standard transformation matrices
    (projection, modelview, and normal) via uniform variables.
  prefs: []
  type: TYPE_NORMAL
- en: The light position (in camera coordinates), `Kd`, and `Ld` should also be provided
    by the OpenGL application via uniform variables. Note that `Kd` and `Ld` are of
    type `vec3`. We can use `vec3` to store an RGB color as well as a vector or point.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader pair that implements diffuse shading, take the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader computes the diffuse reflection equation and sends the result
    to the fragment shader via the output variable `LightIntensity`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader simply applies the color to the fragment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Compile and link both shaders within the OpenGL application and install the
    shader program prior to rendering. See [Chapter 1](3b817a9a-28a1-4be7-936c-b982b4dfacdf.xhtml),
    *Getting Started with GLSL*, for details about compiling, linking, and installing
    shaders.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader does all of the work in this example. The diffuse reflection
    is computed in camera coordinates by first transforming the normal vector using
    the normal matrix, normalizing, and storing the result in `tnorm`. Note that the
    normalization here may not be necessary if your normal vectors are already normalized
    and the normal matrix does not do any scaling.
  prefs: []
  type: TYPE_NORMAL
- en: The normal matrix is the inverse transpose of the upper-left 3x3 portion of
    the model-view matrix. We use the inverse transpose because normal vectors transform
    differently than the vertex position. For a more thorough discussion of the normal
    matrix, and the reasons why, see any introductory computer graphics textbook (a
    good choice would be *Computer Graphics with OpenGL* by Hearn and Baker). If your
    model-view matrix does not include any nonuniform scaling, then one can use the
    upper-left 3 x 3 of the model-view matrix in place of the normal matrix to transform
    your normal vectors. However, if your model-view matrix does include (uniform)
    scaling, you'll still need to (re)normalize your normal vectors after transforming
    them.
  prefs: []
  type: TYPE_NORMAL
- en: The next step converts the vertex position to camera coordinates by transforming
    it with the model-view matrix. Then, we compute the direction toward the light
    source by subtracting the vertex position from the light position and storing
    the result in `s`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we compute the scattered light intensity using the equation described
    previously and store the result in the output variable `LightIntensity`. Note
    the use of the `max` function here. If the dot product is less than zero, then
    the angle between the normal vector and the light direction is greater than 90
    degrees. This means that the incoming light is coming from inside the surface.
    Since such a situation would mean that no radiation reaches the surface, and the
    dot product would produce negative values, we use a value of `0.0`. However, you
    may decide that you want to properly light both sides of your surface, in which
    case the normal vector needs to be reversed for those situations where the light
    is striking the back side of the surface (refer to the *Implementing two-sided
    shading* recipe in this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we convert the vertex position to clip space coordinates by multiplying
    it with the model-view projection matrix, (which is *projection * view * model*)
    and store the result in the built-in output variable `gl_Position`.
  prefs: []
  type: TYPE_NORMAL
- en: The subsequent stage of the OpenGL pipeline expects that the vertex position
    will be provided in clip space coordinates in the output variable `gl_Position`.
    This variable does not directly correspond to any input variable in the fragment
    shader, but is used by the OpenGL pipeline in the primitive assembly, clipping,
    and rasterization stages that follow the vertex shader. It is important that we
    always provide a valid value for this variable.
  prefs: []
  type: TYPE_NORMAL
- en: Since `LightIntensity` is an output variable from the vertex shader, its value
    is interpolated across the face and passed into the fragment shader. The fragment
    shader then simply assigns the value to the output fragment.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Diffuse shading is a technique that models only a very limited range of surfaces.
    It is best used for surfaces that have a *matte* appearance. Additionally, with
    the technique used previously, the dark areas may look a bit too dark. In fact,
    those areas that are not directly illuminated are completely black. In real scenes,
    there is typically some light that has been reflected about the room that brightens
    these surfaces. In the following recipes, we'll look at ways to model more surface
    types, as well as providing some light for those dark parts of the surface.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/scenediffuse.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Sending data to a shader using uniform variables* recipe in [Chapter 2](15752c1f-eee7-4117-9632-f08f84a9405d.xhtml),
    *Working with GLSL Programs*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Compiling a shader* recipe in [Chapter 1](3b817a9a-28a1-4be7-936c-b982b4dfacdf.xhtml),
    *Getting Started with GLSL*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Linking a shader program* recipe in [Chapter 1](3b817a9a-28a1-4be7-936c-b982b4dfacdf.xhtml),
    *Getting Started with GLSL*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Sending data to a shader using vertex attributes and vertex buffer objects*
    recipe in [Chapter 2](15752c1f-eee7-4117-9632-f08f84a9405d.xhtml), *Working with
    GLSL Programs*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the Phong reflection model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll implement the well-known Phong reflection model. The
    OpenGL fixed-function pipeline''s default shading technique was very similar to
    the one presented here.  It models the light-surface interaction as a combination
    of three components: ambient, diffuse, and specular. The **ambient** component
    is intended to model light that has been reflected so many times that it appears
    to be emanating uniformly from all directions. The **diffuse** component was discussed
    in the previous recipe, and represents omnidirectional reflection. The **specular**
    component models the shininess of the surface and represents glossy reflection
    around a preferred direction. Combining these three components together can model
    a nice (but limited) variety of surface types. This shading model is called the
    **Phong reflection model** (or **Phong shading model**), after graphics researcher Bui
    Tuong Phong.'
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a torus rendered with the Phong shading model is shown in the
    following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3dd29349-b614-4337-845e-045460c4dbad.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Phong model is implemented as the sum of three components: ambient, diffuse,
    and specular. The ambient component represents light that illuminates all surfaces
    equally and reflects equally in all directions. It is used to help brighten some
    of the darker areas within a scene. Since it does not depend on the incoming or
    outgoing directions of the light, it can be modeled simply by multiplying the
    light source intensity (*L[a]*) by the surface reflectivity (*K[a]*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a820503-2e84-49ca-a4cc-4808a8eaa91a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The diffuse component models a rough surface that scatters light in all directions
    (see* Diffuse and per-vertex shading with a single point light source* recipe
    in this chapter). The diffuse contribution is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9d6c8dd-395b-403e-8d6f-f9cf54ab9556.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The specular component is used for modeling the shininess of a surface. When
    a surface has a glossy shine to it, the light is reflected off of the surface,
    scattered around some preferred direction. We model this so that the reflected
    light is strongest in the direction of perfect (mirror-like) reflection. The physics
    of the situation tells us that for perfect reflection, the angle of incidence
    is the same as the angle of reflection and that the vectors are coplanar with
    the surface normal, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a401c95-2047-452b-828a-d3693931d9ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding diagram, **r** represents the direction of pure reflection
    corresponding to the incoming light vector (**-s**), and **n** is the surface
    normal. We can compute **r** by using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/034eb641-c42d-438b-beb0-8b4d18f2a215.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To model specular reflection, we need to compute the following (normalized)
    vectors: the direction toward the light source (**s**), the vector of perfect
    reflection (**r**), the vector toward the viewer (**v**), and the surface normal
    (**n**). These vectors are represented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/81a67689-22a4-41fc-9ecd-5451330197cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We would like the reflection to be maximal when the viewer is aligned with
    the vector **r**, and to fall off quickly as the viewer moves farther away from
    alignment with **r**. This can be modeled using the cosine of the angle between
    **v** and **r** raised to some power (**f**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4cb2ff7c-8609-4f5c-87c8-2f9c94d4d970.png)'
  prefs: []
  type: TYPE_IMG
- en: (Recall that the dot product is proportional to the cosine of the angle between
    the vectors involved.) The larger the power, the faster the value drops toward
    zero as the angle between **v** and **r** increases. Again, similar to the other
    components, we also introduce a specular light intensity term (*L[s]*) and reflectivity
    term (*K[s]*). It is common to set the *K[s]* term to some grayscale value (for
    example, (0.8, 0.8, 0.8)), since glossy reflection is not (generally) wavelength
    dependent.
  prefs: []
  type: TYPE_NORMAL
- en: The specular component creates **specular highlights** (bright spots) that are
    typical of glossy surfaces. The larger the power of *f* in the equation, the smaller
    the specular highlight and the shinier the surface. The value for *f* is typically
    chosen to be somewhere between 1 and 200.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting all of this together by simply summing the three terms, we have the
    following shading equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb91f8d1-8b54-4c2c-93fe-df8b866a44d1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following code, we'll evaluate this equation in the vertex shader, and
    interpolate the color across the polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the OpenGL application, provide the vertex position in location 0 and the
    vertex normal in location 1\. The light position and the other configurable terms
    for our lighting equation are uniform variables in the vertex shader and their
    values must be set from the OpenGL application.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader pair that implements the Phong reflection model, take the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader computes the Phong reflection model at the vertex position
    and sends the result to the fragment shader:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader simply applies the color to the fragment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Compile and link both shaders within the OpenGL application, and install the
    shader program prior to rendering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex shader computes the shading equation in eye coordinates. It begins
    by transforming the vertex normal into camera coordinates and normalizing, then
    storing the result in `n`. The vertex position is also transformed into camera
    coordinates and stored in `camCoords`.
  prefs: []
  type: TYPE_NORMAL
- en: The ambient component is computed and stored in the variable `ambient`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we compute the normalized direction towards the light source (`s`). This
    is done by subtracting the vertex position in camera coordinates from the light
    position and normalizing the result.
  prefs: []
  type: TYPE_NORMAL
- en: The dot product of `s` and `n` is computed next. As in the preceding recipe,
    we use the built-in function `max` to limit the range of values to between zero
    and one. The result is stored in the variable named `sDotN`, and is used to compute
    the diffuse component. The resulting value for the diffuse component is stored
    in the variable `diffuse`.
  prefs: []
  type: TYPE_NORMAL
- en: Before computing the specular component, we check the value of `sDotN`. If `sDotN` is
    zero, then there is no light reaching the surface, so there is no point in computing
    the specular component, as its value must be zero. Otherwise, if `sDotN` is greater
    than zero, we compute the specular component using the equation presented earlier.
  prefs: []
  type: TYPE_NORMAL
- en: If we did not check `sDotN` before computing the specular component, it is possible
    that some specular highlights could appear on faces that are facing away from
    the light source. This is clearly an unrealistic and undesirable result. Another
    way to solve this problem is to multiply both the specular and diffuse components
    by `sDotN` (instead of only the diffuse component as we are doing now). This is
    actually somewhat more physically accurate, but is not part of the traditional
    Phong model.
  prefs: []
  type: TYPE_NORMAL
- en: The direction toward the viewer (`v`) is the negation of the position (normalized)
    because in camera coordinates the viewer is at the origin.
  prefs: []
  type: TYPE_NORMAL
- en: We compute the direction of pure reflection by calling the GLSL built-in function
    `reflect`, which reflects the first argument about the second. We don't need to
    normalize the result because the two vectors involved are already normalized.
  prefs: []
  type: TYPE_NORMAL
- en: When computing the specular component, we use the built-in function `max` to
    limit the range of values of the dot product to between zero and one, and the
    function `pow` raises the dot product to the power of the `Shininess` exponent
    (corresponding to *f* in our lighting equation).
  prefs: []
  type: TYPE_NORMAL
- en: The sum of the three components is then stored in the output variable `LightIntensity`.
    This value will be associated with the vertex and passed down the pipeline. Before
    reaching the fragment shader, its value will be interpolated in a perspective
    correct manner across the face of the polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the vertex shader transforms the position into clip coordinates, and
    assigns the result to the built-in output variable `gl_Position` (refer to the
    D*iffuse and per-vertex shading with a single point light source* recipe in this
    chapter).
  prefs: []
  type: TYPE_NORMAL
- en: The fragment shader simply applies the interpolated value of `LightIntensity`
    to the output fragment by storing it in the shader output variable `FragColor`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Phong reflection model works quite well, but has some drawbacks. A slight
    change to the model, introduced by James Blinn, is more commonly used in practice.
    The Blinn-Phong model replaces the vector of pure reflection with the so-called
    *halfway vector*, and produces specular highlights that have been shown to be
    more realistic. This model is discussed in *The Blinn-Phong reflection model* recipe
    in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting and Shading*.
  prefs: []
  type: TYPE_NORMAL
- en: Using a nonlocal viewer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can avoid the extra normalization needed to compute the vector towards the
    viewer (`v`) by using a so-called **nonlocal viewer**. Instead of computing the
    direction toward the origin, we simply use the constant vector (0, 0, 1) for all
    vertices. Of course, it is not accurate, but in practice the visual results are
    very similar, often visually indistinguishable, saving us one normalization.
  prefs: []
  type: TYPE_NORMAL
- en: Per-vertex versus per-fragment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the shading equation is computed within the vertex shader, we refer to
    this as **per-vertex shading**. Per-vertex shading is also called **Gouraud shading**.
    One of the disadvantages of this is that specular highlights can be warped or
    lost, due to the fact that the shading equation is not evaluated at each point
    across the face.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a specular highlight that should appear in the middle of a polygon
    might not appear at all when per-vertex shading is used, because of the fact that
    the shading equation is only computed at the vertices where the specular component
    is near zero. In the *Using per-fragment shading for improved realism* recipe
    of [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting and Shading*,
    we'll look at the changes needed to move the shading computation into the fragment
    shader, producing more realistic results.
  prefs: []
  type: TYPE_NORMAL
- en: Directional lights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can also avoid the need to compute a light direction (`s`) for each vertex
    if we assume a directional light. A **directional light source** is one that has
    no position, only a direction. Instead of computing the direction towards the
    source for each vertex, a constant vector is used, which represents the direction
    towards the remote light source. This is a good way to model lighting from distant
    sources such as sunlight. We'll look at an example of this in the *Shading with
    a directional light source* recipe of [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml),
    *Lighting and Shading*.
  prefs: []
  type: TYPE_NORMAL
- en: Light attenuation with distance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might think that this shading model is missing one important component.
    It doesn't take into account the effect of the distance to the light source. In
    fact, it is known that the intensity of radiation from a source falls off in proportion
    to the inverse square of the distance from the source. So why not include this
    in our model?
  prefs: []
  type: TYPE_NORMAL
- en: It would be fairly simple to do so, however, the visual results are often less
    than appealing. It tends to exaggerate the distance effects and create unrealistic-looking
    images. Remember, our equation is just an approximation of the physics involved
    and is not a truly realistic model, so it is not surprising that adding a term
    based on a strict physical law produces unrealistic results.
  prefs: []
  type: TYPE_NORMAL
- en: In the OpenGL fixed-function pipeline, it was possible to turn on distance attenuation
    using the `glLight` function. If desired, it would be straightforward to add a
    few uniform variables to our shader to produce the same effect.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/scenephong.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Shading with a directional light source* recipe in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml),
    **Lighting and Shading**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Using per-fragment shading for improved realism* recipe in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml),
    *Lighting and Shading*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Using the Blinn-Phong model* recipe in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting
    and Shading*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using functions in shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The GLSL supports functions that are syntactically similar to C functions. However,
    the calling conventions are somewhat different. In the following example, we'll
    revisit the Phong shader using functions to help provide abstractions for the
    major steps.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with previous recipes, provide the vertex position at attribute location
    0 and the vertex normal at attribute location 1\. Uniform variables for all of
    the Phong coefficients should be set from the OpenGL side, as well as the light
    position and the standard matrices.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The vertex shader is nearly identical to the one from the previous recipe,
    except that the Phong model is evaluated within a function, and we add another
    function to convert the position and the normal to camera coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The fragment shader has no changes from the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In GLSL functions, the parameter evaluation strategy is **call by value-return** (also
    called **call by copy-restore** or **call by value-result**). Parameter variables
    can be qualified with `in`, `out`, or `inout`. Arguments corresponding to input
    parameters (those qualified with `in` or `inout`) are copied into the parameter
    variable at call time, and output parameters (those qualified with `out` or `inout`)
    are copied back to the corresponding argument before the function returns. If
    a parameter variable does not have any of the three qualifiers, the default qualifier
    is `in`.
  prefs: []
  type: TYPE_NORMAL
- en: We've created two functions in the vertex shader. The first, named `getCamSpace`,
    transforms the vertex position and vertex normal into camera coordinates, and
    returns them via output parameters. In the `main` function, we create two uninitialized
    variables (`camNorm` and `camPosition`) to store the results, and then call the
    function with the variables as the function's arguments. The function stores the
    results into the parameter variables (`n` and `position`) which are copied into
    the arguments before the function returns.
  prefs: []
  type: TYPE_NORMAL
- en: The second function, `phongModel`, uses only input parameters. The function
    receives the eye-space position and normal, and computes the result of the Phong
    reflection model. The result is returned by the function and stored in the shader
    output variable `LightIntensity`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since it makes no sense to read from an output parameter variable, output parameters
    should only be written to within the function. Their value is undefined.
  prefs: []
  type: TYPE_NORMAL
- en: Within a function, writing to an input-only parameter (qualified with `in`)
    is allowed. The function's copy of the argument is modified, and changes are not
    reflected in the argument.
  prefs: []
  type: TYPE_NORMAL
- en: The const qualifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The additional qualifier `const` can be used with input-only parameters (not
    with `out` or `inout`). This qualifier makes the input parameter read-only, so
    it cannot be written to within the function.
  prefs: []
  type: TYPE_NORMAL
- en: Function overloading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functions can be overloaded by creating multiple functions with the same name,
    but with a different number and/or type of parameters. As with many languages,
    two overloaded functions may not differ in return type only.
  prefs: []
  type: TYPE_NORMAL
- en: Passing arrays or structures to a function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It should be noted that when passing arrays or structures to functions, they
    are passed by value. If a large array or structure is passed, it can incur a large
    copy operation, which may not be desired. It would be a better choice to declare
    these variables in the global scope.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/shader/function.vert.glsl` and `chapter03/shader/function.frag.glsl` files
    in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Implementing the Phong reflection model* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing two-sided shading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When rendering a mesh that is completely closed, the back faces of polygons
    are hidden. However, if a mesh contains holes, it might be the case that the back
    faces would become visible. In this case, the polygons may be shaded incorrectly
    due to the fact that the normal vector is pointing in the wrong direction. To
    properly shade those back faces, one needs to invert the normal vector and compute
    the lighting equations based on the inverted normal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows a teapot with the lid removed. On the left, the Phong
    model is used. On the right, the Phong model is augmented with the two-sided rendering
    technique discussed in this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f09a8b43-dc22-49e7-8435-999064553601.png)'
  prefs: []
  type: TYPE_IMG
- en: In this recipe, we'll look at an example that uses the Phong model discussed
    in the previous recipes, augmented with the ability to correctly shade back faces.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex position should be provided in attribute location 0 and the vertex
    normal in attribute location 1\. As in the previous examples, the lighting parameters
    must be provided to the shader via uniform variables.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To implement a shader pair that uses the Phong reflection model with two-sided
    lighting, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader is similar to the one in the previous recipe, except that
    it computes the Phong equation twice. First, without any change to the normal
    vector, and again with the normal inverted. The results are stored in output variables
    `FrontColor` and `BackColor`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The fragment shader chooses which color to use based on the value of the built-in `gl_FrontFacing` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the vertex shader, we compute the lighting equation using both the vertex
    normal and the inverted version, and pass each color to the fragment shader. The
    fragment shader chooses and applies the appropriate color depending on the orientation
    of the face.
  prefs: []
  type: TYPE_NORMAL
- en: The evaluation of the reflection model is placed within a function named `phongModel`.
    The function is called twice, first using the normal vector (transformed into
    camera coordinates), and second using the inverted normal vector. The combined
    results are stored in `FrontColor` and `BackColor`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few aspects of the shading model that are independent of the orientation
    of the normal vector (such as the ambient component). One could optimize this
    code by rewriting it so that the redundant calculations are only done once. However,
    in this recipe, we compute the entire shading model twice in the interest of making
    things clear and readable.
  prefs: []
  type: TYPE_NORMAL
- en: In the fragment shader, we determine which color to apply based on the value
    of the built-in variable `gl_FrontFacing`.  This is a Boolean value that indicates
    whether the fragment is part of a front- or back-facing polygon. Note that this
    determination is based on the **winding** of the polygon, and not the normal vector.
    (A polygon is said to have counterclockwise winding if the vertices are specified
    in counterclockwise order, as viewed from the front side of the polygon.) By default,
    when rendering, if the order of the vertices appear on the screen in a counterclockwise
    order, it indicates a front-facing polygon, however, we can change this by calling
    `glFrontFace` from the OpenGL program.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the vertex shader, we determine the front side of the polygon by the direction
    of the normal vector, and in the fragment shader, the determination is based on
    the polygon's winding. For this to work properly, the normal vector must be defined
    appropriately for the face determined by the setting of `glFrontFace`.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative choice for this recipe would be to determine whether the face
    being shaded is a front or back face first in the vertex shader, and send only
    a single result to the fragment shader. One way to do this would be to compute
    the dot product between a vector pointing towards the camera (the origin in camera
    coordinates), and the normal. If the dot product is negative, then the normal
    must be pointing away from the viewer, meaning that the viewer is seeing the back
    side of the face.
  prefs: []
  type: TYPE_NORMAL
- en: 'In which case, we invert the normal. Specifically, we could change the main
    function in the vertex shader as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we only need a single output variable to send to the fragment
    shader (`Color`, in the preceding code), and the fragment shader simply applies
    the color to the fragment. In this version, there's no need to check the value
    of `gl_FrontFacing` in the fragment shader.
  prefs: []
  type: TYPE_NORMAL
- en: In this version, the only thing that is used to determine whether or not it
    is a front face is the normal vector. The polygon winding is not used. If the
    normals at the vertices of a polygon are not parallel (which is often the case
    for curved shapes), then it may be the case that some vertices are treated as
    *front* and others are treated as *back*. This has the potential of producing
    unwanted artifacts as the color is blended across the face. It would be better
    to compute all of the reflection model in the fragment shader, as is common practice
    these days. See the *Using per-fragment shading for improved realism* recipe in [Chapter
    4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting and Shading*, for details
    about per-fragment shading.
  prefs: []
  type: TYPE_NORMAL
- en: Using two-sided rendering for debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It can sometimes be useful to visually determine which faces are front-facing
    and which are back-facing (based on winding). For example, when working with arbitrary
    meshes, polygons may not be specified using the appropriate winding. As another
    example, when developing a mesh procedurally, it can sometimes be helpful to determine
    which faces have proper winding in order to help with debugging. We can easily
    tweak our fragment shader to help us solve these kinds of problems by mixing a
    solid color with all back (or front) faces. For example, we could change the `else`
    clause within our fragment shader to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This would mix a solid red color with all back faces, helping them stand out,
    as shown in the following image. In the image, back faces are mixed with 70 percent
    red, as shown in the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b57cf931-dad2-40a2-97fb-df90eeb9a5e6.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/scenetwoside.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Implementing the Phong reflection model* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using per-fragment shading for improved realism* in [Chapter 4](343fbd70-0012-4449-afe6-a724b330b441.xhtml), *Lighting
    and Shading*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing flat shading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Per-vertex shading involves computation of the shading model at each vertex
    and associating the result (a color) with that vertex. The colors are then interpolated
    across the face of the polygon to produce a smooth shading effect. This is also
    referred to as **Gouraud shading**. In earlier versions of OpenGL, this per-vertex
    shading with color interpolation was the default shading technique.
  prefs: []
  type: TYPE_NORMAL
- en: It is sometimes desirable to use a single color for each polygon so that there
    is no variation of color across the face of the polygon, causing each polygon
    to have a flat appearance. This can be useful in situations where the shape of
    the object warrants such a technique, perhaps because the faces really are intended
    to look flat, or to help visualize the locations of the polygons in a complex
    mesh. Using a single color for each polygon is commonly called **flat shading**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows a mesh rendered with the Phong reflection model.
    On the left, Gouraud shading is used. On the right, flat shading is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0316c524-3878-496c-9a90-008e3f9963f3.png)'
  prefs: []
  type: TYPE_IMG
- en: In earlier versions of OpenGL, flat shading was enabled by calling the function
    `glShadeModel` with the argument `GL_FLAT`, in which case the computed color of
    the last vertex of each polygon was used across the entire face.
  prefs: []
  type: TYPE_NORMAL
- en: In OpenGL 4, flat shading is facilitated by the interpolation qualifiers available
    for shader input/output variables.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To modify the Phong reflection model to use flat shading, take the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the same vertex shader as in the Phong example provided earlier. Change
    the output variable `LightIntensity` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the corresponding variable in the fragment shader to use the `flat`
    qualifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Compile and link both shaders within the OpenGL application, and install the
    shader program prior to rendering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Flat shading is enabled by qualifying the vertex output variable (and its corresponding
    fragment input variable) with the `flat` qualifier. This qualifier indicates that
    no interpolation of the value is to be done before it reaches the fragment shader.
    The value presented to the fragment shader will be the one corresponding to the
    result of the invocation of the vertex shader for either the first or last vertex
    of the polygon. This vertex is called the **provoking vertex**, and can be configured
    using the OpenGL function `glProvokingVertex`. For example, the following call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Indicates that the first vertex should be used as the value for the flat-shaded
    variable. The `GL_LAST_VERTEX_CONVENTION` argument indicates that the last vertex
    should be used. The default value is `GL_LAST_VERTEX_CONVENTION`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/sceneflat.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Implementing the Phong reflection model* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using subroutines to select shader functionality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In GLSL, a subroutine is a mechanism for binding a function call to one of a
    set of possible function definitions based on the value of a variable. In many
    ways, it is similar to function pointers in C. A uniform variable serves as the
    pointer and is used to invoke the function. The value of this variable can be
    set from the OpenGL side, thereby binding it to one of a few possible definitions.
    The subroutine's function definitions need not have the same name, but must have
    the same number and type of parameters and the same return type.
  prefs: []
  type: TYPE_NORMAL
- en: Subroutines therefore provide a way to select alternative implementations at
    runtime without swapping shader programs and/or recompiling, or using the `if`
    statements along with a uniform variable. For example, a single shader could be
    written to provide several shading algorithms intended for use on different objects
    within the scene. When rendering the scene, rather than swapping shader programs
    or using a conditional statement, we can simply change the subroutine's uniform
    variable to choose the appropriate shading algorithm as each object is rendered.
  prefs: []
  type: TYPE_NORMAL
- en: Since performance is crucial in shader programs, avoiding a conditional statement
    or a shader swap may be valuable. With subroutines, we can implement the functionality
    of a conditional statement or shader swap without the computational overhead.
    However, modern drivers do a good job of handling conditionals, so the benefits of
    subroutines over conditionals is not always clear-cut. Depending on the condition,
    conditional statements based on uniform variables can be as efficient as subroutines.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we'll demonstrate the use of subroutines by rendering a teapot
    twice. The first teapot will be rendered with the full Phong reflection model
    described earlier. The second teapot will be rendered with diffuse shading only.
    A subroutine uniform will be used to choose between the two shading techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '**Subroutines are not supported in SPIR-V**. Therefore, their use should probably
    be avoided. Since SPIR-V is evidently the future of shaders in OpenGL, subroutines
    should be considered deprecated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following image, we can see an example of a rendering that was created
    using subroutines. The teapot on the left is rendered with the full Phong reflection model,
    and the teapot on the right is rendered with diffuse shading only. A subroutine
    is used to switch between shader functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0c7d649-c7a9-4d04-9e24-6581420ee598.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with the previous recipes, provide the vertex position at attribute location
    0 and the vertex normal at attribute location 1\. Uniform variables for all of
    the Phong coefficients should be set from the OpenGL side, as well as the light
    position and the standard matrices.
  prefs: []
  type: TYPE_NORMAL
- en: We'll assume that, in the OpenGL application, the `programHandle` variable contains
    the handle to the shader program object.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that uses a subroutine to switch between pure-diffuse
    and Phong, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the vertex shader with a subroutine uniform variable, and two functions
    of the subroutine type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The fragment shader is the same as the one in* The Phong reflection model* recipe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the OpenGL application, compile and link the shaders into a shader program,
    and install the program into the OpenGL pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Within the render function of the OpenGL application, use the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, the subroutine is defined within the vertex shader. The first
    step involves declaring the subroutine type, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This defines a new subroutine type with the name `shadeModelType`. The syntax
    is very similar to a function prototype, in that it defines a name, a parameter
    list, and a return type. As with function prototypes, the parameter names are
    optional.
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating the new subroutine type, we declare a uniform variable of that
    type named `shadeModel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This variable serves as our function pointer and will be assigned to one of
    the two possible functions in the OpenGL application.
  prefs: []
  type: TYPE_NORMAL
- en: 'We declare two functions to be part of the subroutine by prefixing their definition
    with the subroutine qualifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that the function matches the subroutine type, and therefore
    its header must match the one in the subroutine type definition. We use this prefix
    for the definition of the functions `phongModel` and `diffuseOnly`. The `diffuseOnly`
    function computes the diffuse shading equation, and the `phongModel` function
    computes the complete Phong reflection equation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We call one of the two subroutine functions by utilizing the subroutine uniform
    `shadeModel` within the main function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Again, this call will be bound to one of the two functions depending on the
    value of the subroutine uniform `shadeModel`, which we will set within the OpenGL
    application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the render function of the OpenGL application, we assign a value to
    the subroutine uniform with the following two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we query for the index of each subroutine function using `glGetSubroutineIndex`.
    The first argument is the program handle. The second is the shader stage. In this
    case, the subroutine is defined within the vertex shader, so we use `GL_VERTEX_SHADER`
    here. The third argument is the name of the subroutine. We query for each function
    individually and store the indexes in the variables `phongIndex` and `diffuseIndex`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Second, we select the appropriate subroutine function. To do so, we need to
    set the value of the subroutine uniform `shadeModel` by calling `glUniformSubroutinesuiv`.
    This function is designed for setting multiple subroutine uniforms at once. In
    our case, of course, we are setting only a single uniform. The first argument
    is the shader stage (`GL_VERTEX_SHADER`), the second is the number of uniforms
    being set, and the third is a pointer to an array of subroutine function indexes.
    Since we are setting a single uniform, we simply provide the address of the `GLuint`
    variable containing the index, rather than a true array of values. Of course,
    we would use an array if multiple uniforms were being set. In general, the array
    of values provided as the third argument is assigned to subroutine uniform variables
    in the following way. The i^(th) element of the array is assigned to the subroutine
    uniform variable with index i. Since we have provided only a single value, we
    are setting the subroutine uniform at index zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You may be wondering, "How do we know that our subroutine uniform is located
    at index zero? We didn't query for the index before calling `glUniformSubroutinesuiv`!"
    The reason that this code works is that we are relying on the fact that OpenGL
    will always number the indexes of the subroutines consecutively starting at zero.
    If we had multiple subroutine uniforms, we could (and should) query for their
    indexes using `glGetSubroutineUniformLocation`, and then order our array appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: '`glUniformSubroutinesuiv` requires us to set `all` subroutine uniform variables
    at once, in a single call. This is so that they can be validated by OpenGL in
    a single burst.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unfortunately, subroutine bindings get reset when a shader program is unbound
    (switched out) from the pipeline by calling `glUseProgram` or another technique.
    This requires us to call `glUniformSubroutinsuiv` each time that we activate a
    shader program.
  prefs: []
  type: TYPE_NORMAL
- en: 'A subroutine function defined in a shader can match more than one subroutine
    type. The subroutine qualifier can contain a comma-separated list of subroutine
    types. For example, if a subroutine matched the types `type1` and `type2`, we
    could use the following qualifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This would allow us to use subroutine uniforms of differing types to refer to
    the same subroutine function.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/scenesubroutine.cpp` file in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*T**he Phong reflection model* recipe'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Diffuse and per-vertex shading with a single point light source* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discarding fragments to create a perforated look
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fragment shaders can make use of the `discard` keyword to *throw away* fragments.
    Use of this keyword causes the fragment shader to stop execution, without writing
    anything (including depth) to the output buffer. This provides a way to create
    holes in polygons without using blending. In fact, since fragments are completely
    discarded, there is no dependence on the order in which objects are drawn, saving
    us the trouble of doing any depth sorting that might have been necessary if blending
    was used.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll draw a teapot, and use the `discard` keyword to remove
    fragments selectively, based on texture coordinates. The result will look like
    the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/600677f4-55bc-481a-9449-b37c1b2bb767.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vertex position, normal, and texture coordinates must be provided to the
    vertex shader from the OpenGL application. The position should be provided at
    location 0, the normal at location 1, and the texture coordinates at location
    2\. As in the previous examples, the lighting parameters must be set from the
    OpenGL application via the appropriate uniform variables.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a shader program that discards fragments based on a square lattice
    (as in the preceding image):'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the vertex shader, we use two-sided lighting, and include the texture coordinate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In the fragment shader, discard the fragment based on a certain condition by
    using the `discard` keyword:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Compile and link both shaders within the OpenGL application, and install the
    shader program prior to rendering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we will be discarding some parts of the teapot, we will be able to see
    through the teapot to the other side. This will cause the back sides of some polygons
    to become visible. Therefore, we need to compute the lighting equation appropriately
    for both sides of each face. We'll use the same technique presented earlier in
    the two-sided shading recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The vertex shader is essentially the same as in the two-sided shading recipe,
    with the main difference being the addition of the texture coordinate. To manage
    the texture coordinate, we have an additional input variable, `VertexTexCoord`,
    that corresponds to attribute location 2\. The value of this input variable is
    passed directly on to the fragment shader unchanged via the output variable `TexCoord`.
    The Phong reflection model is calculated twice, once using the given normal vector,
    storing the result in `FrontColor`, and again using the reversed normal, storing
    that result in `BackColor`.
  prefs: []
  type: TYPE_NORMAL
- en: In the fragment shader, we calculate whether or not the fragment should be discarded
    based on a simple technique designed to produce the lattice-like pattern shown
    in the preceding image. We first scale the texture coordinate by the arbitrary
    scaling factor `scale`. This corresponds to the number of lattice rectangles per
    unit (scaled) texture coordinate. We then compute the fractional part of each
    component of the scaled texture coordinate using the built-in function `fract`.
    Each component is compared to 0.2 using the built-in the `greaterThan` function, and
    the result is stored in the Boolean vector `toDiscard`. The `greaterThan` function
    compares the two vectors component-wise, and stores the Boolean results in the
    corresponding components of the return value.
  prefs: []
  type: TYPE_NORMAL
- en: If both components of the vector `toDiscard` are true, then the fragment lies
    within the inside of each lattice frame, and therefore we wish to discard this
    fragment. We can use the built-in function `all` to help with this check. The
    function `all` will return true if all of the components of the parameter vector
    are true. If the function returns true, we execute the `discard` statement to
    reject the fragment.
  prefs: []
  type: TYPE_NORMAL
- en: In the `else` branch, we color the fragment based on the orientation of the
    polygon, as in the *Implementing two-sided shading* recipe presented earlier.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `chapter03/scenediscard.cpp` recipe in the example code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Implementing two-sided shading* recipe in this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
