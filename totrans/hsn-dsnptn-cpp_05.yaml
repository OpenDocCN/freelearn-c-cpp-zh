- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Comprehensive Look at RAII
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Resource management is probably the second most frequent thing a program does,
    after computing. But just because it’s frequently done does not mean it’s visible—some
    languages hide most, or all, resource management from the user. And just because
    it is hidden, does not mean it’s not there.
  prefs: []
  type: TYPE_NORMAL
- en: Every program needs to use some memory, and memory is a resource. A program
    would be of no use if it never interacted with the outside world in some way,
    at least to print the result, and input and output channels (files, sockets, and
    so on) are resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will start by answering the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is considered a resource in a C++ program?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the key concerns for managing resources in C++?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we will introduce **Resource Acquisition is Initialization** (**RAII**)
    and explain how it helps in efficient resource management in C++ by answering
    these questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the standard approach for managing resources in C++ (RAII)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does RAII solve the problems of resource management?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will end the chapter with a discussion about the implications and possible
    concerns of using RAII by providing the answers to these questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the precautions that must be taken when writing RAII objects?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the consequences of using RAII for resource management?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C++, with its zero-overhead abstraction philosophy, does not hide resources
    or their management at the core language level. But we would do well to not confuse
    hiding resources with managing them.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some useful links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Test unit testing framework: [https://github.com/google/googletest](https://github.com/google/googletest)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Benchmark library: [https://github.com/google/benchmark](https://github.com/google/benchmark)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example code: [https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter05](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter05)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource management in C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every program operates on resources and needs to manage them. The most commonly
    used resource is memory, of course. Hence, you often read about **memory** **management**
    in C++. But really, resources can be just about anything. Many programs exist
    specifically to manage real, tangible physical resources, or the more ephemeral
    (but no less valuable) digital ones. Money in bank accounts, airline seats, car
    parts and assembled cars, or even crates of milk—in today’s world, if it is something
    that needs to be counted and tracked, there is a piece of software somewhere that
    is doing it. But even in a program that does pure computations, there may be varied
    and complex resources, unless the program also eschews abstractions and operates
    at the level of bare numbers. For example, a physics simulation program may have
    particles as resources.
  prefs: []
  type: TYPE_NORMAL
- en: All of these resources have one thing in common—they need to be accounted for.
    They should not vanish without a trace, and a program should not just make up
    resources that don’t really exist. Often, a specific instance of a resource is
    needed—you would not want someone else’s purchase to be debited from your bank
    account; the specific instance of the resource matters. Thus, the most important
    consideration when evaluating different approaches to resource management is correctness—how
    well does the design ensure that resources are managed properly, how easy is it
    to make a mistake, and how hard would it be to find such a mistake? It should
    come as no surprise, then, that we use a testing framework to present the coding
    examples of resource management in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the microbenchmark library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our case, we are interested in the efficiency of memory allocations and
    small fragments of code that may contain such allocations. The appropriate tool
    for measuring the performance of small fragments of code is a microbenchmark.
    There are many microbenchmark libraries and tools out there; in this book, we
    will use the Google Benchmark library. To follow along with the examples in this
    chapter, you must first download and install the library (follow the instructions
    in the `Readme.md` file). Then you can compile and run the examples. You can build
    the sample files included with the library to see how to build a benchmark on
    your particular system; you can also use the example benchmark from this chapter’s
    repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the call to `DoNotOptimize()`: it’s a special function that doesn’t generate
    any code but tricks the compiler into thinking that its argument is necessary
    and cannot be optimized away. Without this, the compiler will probably figure
    out that the entire benchmark loop has no observable effect and can be optimized
    to nothing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On a Linux machine, the command to build and run a benchmark program called
    `01_benchmark.C` might look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, `$CXX` is your C++ compiler, such as `g++` or `clang++`, and `$GBENCH_DIR`
    is the directory where the benchmark is installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding example should print something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Figure_5.1_B19262.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On this particular machine, a single iteration (one pair of calls to `malloc()`
    and `free()`) takes 6.37 nanoseconds, which translates into 157 million memory
    allocations per second.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes we have to benchmark very short operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We may be reasonably concerned about the overhead of the benchmark loop itself.
    In such cases, we can execute multiple copies of the benchmarked operation within
    the body of the loop. We can even get the C++ preprocessor to make copies for
    us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The time of a “*single*” iteration now includes 32 iterations, so it is much
    easier to use the items per second value. Remember to include repeat count in
    the number of items processed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Figure_5.2_B19262.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Writing fast programs is all well and good, but they have to be correct first.
    To that end, we need to write tests, so we also need a testing framework.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Google Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will be testing very small fragments of code for correctness. On the one
    hand, this is simply because each fragment illustrates a specific concept or idea.
    On the other hand, even in a large-scale software system, resource management
    is done by small building blocks of code. They may combine to form a quite complex
    resource manager, but each block performs a specific function and is testable.
    The appropriate testing system for this situation is a unit testing framework.
    There are many such frameworks to choose from; in this book, we will use the Google
    Test unit testing framework. To follow along with the examples in this chapter,
    you must first download and install the framework (follow the instructions in
    the `README` file). Once installed, you can compile and run the examples. You
    can build the sample tests included with the library to see how to build and link
    with Google Test on your particular system; you can also use the example from
    this chapter’s repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'On a Linux machine, the command to build and run a `02_test.C` test might look
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `$CXX` is your C++ compiler, such as `g++` or `clang++`, and `$GTEST_DIR`
    is the directory where Google Test is installed. If all tests pass, you should
    get this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Writing good tests is an art. We have to identify the aspects of our code that
    need to be validated and come up with ways to observe these aspects. In this chapter,
    we are interested in resource management, so let us see how we can test the utilization
    and release of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Counting resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A unit testing framework, such as Google Test, allows us to execute some code
    and verify that the results are what they should be. The results that we can look
    at include any variable or expression that we can access from the test program.
    That definition does not extend, for example, to the amount of memory that is
    currently in use. So, if we want to verify that resources are not disappearing,
    we have to count them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following simple test fixture, we use a special resource class instead
    of, say, the `int` keyword. This class is instrumented to count how many objects
    of this type have been created, and how many are currently alive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can test that our program manages resources correctly, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In Google Test, every test is implemented as a **test fixture**. There are
    several types; the simplest one is a standalone test function, such as the one
    we use here. Running this simple test program tells us that the test has passed,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The expected results are verified using one of the `EXPECT_*` macros and any
    test failures will be reported. This test verifies that, after creating and deleting
    an instance of the type `object_counter`, there are no such objects left, and
    that exactly one was constructed.
  prefs: []
  type: TYPE_NORMAL
- en: Dangers of manual resource management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C++ allows us to manage resources almost at the hardware level, and someone,
    somewhere, must indeed manage them at this level. The latter is actually true
    for every language, even the high-level ones that do not expose such details to
    the programmers. But *somewhere* does not have to be in your program! Before we
    learn the C++ solutions and tools for resource management, let’s first understand
    the problems that arise from not using any such tools.
  prefs: []
  type: TYPE_NORMAL
- en: Manual resource management is error-prone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first and most obvious danger of managing every resource manually, with
    explicit calls to acquire and release each one, is that it is easy to forget the
    latter. For example, see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now leaking a resource (the `object_counter` objects, in this case).
    If we did this in a unit test, it would fail, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the failing tests, and the location of the failures, as reported
    by the unit test framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In a real program, finding such errors is much harder. Memory debuggers and
    sanitizers can help with memory leaks, but they require that the program actually
    execute the buggy code, so they depend on the test coverage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resource leaks can be much subtler and harder to find, too. Consider this
    code, where we did not forget to release the resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'During subsequent maintenance, a possible failure condition was discovered,
    and the appropriate test was added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This change introduced a subtle bug—now, resources are leaked only if the intermediate
    computation has failed and triggered the early return. If the failure is rare
    enough, this mistake may escape all tests, even if the testing process employs
    regular memory sanitizer runs. This mistake is also all too easy to make since
    the edit could be made in a place far removed from both the construction and deletion
    of the object, and nothing in the immediate context gives the programmer a hint
    that a resource needs to be released.
  prefs: []
  type: TYPE_NORMAL
- en: 'The alternative to leaking a resource, in this case, is to release it. Note
    that this leads to some code duplication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'As with any code duplication, there comes the danger of code divergence. Let’s
    say that the next round of code enhancements required more than one `object_counter`,
    and an array of them is now allocated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If we change `new` to the `new` array, we must change `delete` as well; the
    thought goes, there is probably one at the end of the function. Who knew that
    there was one more in the middle? Even if the programmer had not forgotten about
    the resources, manual resource management gets disproportionately more error-prone
    as the program becomes more complex. And not all resources are as forgiving as
    a counter object. Consider the following code that performs some concurrent computation,
    and must acquire and release mutex locks. Note the very words **acquire** and
    **release**, the common terminology for locks, suggest that locks are treated
    as a kind of resource (the resource here is exclusive access to the data protected
    by the lock):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This code has both duplication and divergence. It also has a bug—see if you
    can find it (hint—count how many times `m3` is unlocked, versus how many `return`
    statements there are after it’s locked). As the resources become more numerous
    and complex to manage, such bugs are going to creep up more often.
  prefs: []
  type: TYPE_NORMAL
- en: Resource management and exception safety
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember the code at the beginning of the previous section—the one we said
    is correct, where we did not forget to release the resource? Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'I have bad news for you—this code probably wasn’t correct either. If any of
    the many more lines of code can throw an exception, then `delete p` is never going
    to be executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This looks very similar to the early `return` problem, only worse—the exception
    can be thrown by any code that the `process()` function calls. The exception can
    even be added later to some code that the `process()` function calls, without
    any changes in the function itself. It used to work fine, then one day it does
    not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unless we change our approach to resource management, the only solution is
    to use the `try …` `catch` blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The obvious problem here is code duplication again, as well as the proliferation
    of the `try … catch` blocks literally everywhere. Worse than that, this approach
    does not scale should we need to manage multiple resources, or even just manage
    anything more complex than a single acquisition with a corresponding release:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can’t even decide whether the catch block should release the mutex or
    not—it depends on whether the exception was thrown before or after the `unlock()`
    operation that happens in the normal, non-exceptional control flow. Also, the
    `object_counter` constructor could throw an exception (not the simple one we had
    so far, but a more complex one that ours could evolve into). That would happen
    outside of the `try … catch` block, and the mutex would never get unlocked.
  prefs: []
  type: TYPE_NORMAL
- en: It should be clear to us by now that we need an entirely different solution
    for the resource management problem, not some patchwork. In the next section,
    we will discuss the pattern that became the golden standard of resource management
    in C++.
  prefs: []
  type: TYPE_NORMAL
- en: The RAII idiom
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen in the previous section how ad hoc attempts to manage resources
    become unreliable, then error-prone, and eventually fail. What we need is to make
    sure that resource acquisition is always paired up with resource release, and
    that these two actions happen before and after the section of code that uses the
    resource respectively. In C++, this kind of bracketing of a code sequence by a
    pair of actions is known as the Execute Around design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: For more information, see the article *C++ Patterns – Executing Around Sequences*
    by Kevlin Henney, available at [http://www.two-sdg.demon.co.uk/curbralan/papers/europlop/ExecutingAroundSequences.pdf](http://www.two-sdg.demon.co.uk/curbralan/papers/europlop/ExecutingAroundSequences.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: When specifically applied to resource management, this pattern is much more
    widely known as **Resource Acquisition is** **Initialization** (**RAII**).
  prefs: []
  type: TYPE_NORMAL
- en: RAII in a nutshell
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The basic idea behind RAII is very simple—there is one kind of function in C++
    that is guaranteed to be called automatically, and that is the destructor of an
    object created on the stack, or the destructor of an object that is a data member
    of another object (in the latter case, the guarantee holds only if the containing
    class itself is destroyed). If we could hook up the release of the resource to
    the destructor of such an object, then the release could not be forgotten or skipped.
    It stands to reason that if releasing the resource is handled by the destructor,
    acquiring it should be handled by the constructor during the initialization of
    the object. Hence the full meaning of RAII as introduced in the title of this
    chapter—*A Comprehensive Look* *at RAII*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how this works in the simplest case of memory allocation, via `operator
    new`. First, we need a class that can be initialized from a pointer to the newly
    allocated object, and whose destructor will delete that object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it is very easy to make sure that deletion is never omitted, and we can
    verify that it works as expected with a test that uses `object_counter`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that in C++17, the class template type is deduced from the constructor
    and we can simply write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The RAII resource release happens when the owning object is destroyed for any
    reason; thus, the cleanup after an exception is thrown and automatically taken
    care of:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, we probably want to use the new object for more than just creating
    and deleting it, so it would be nice to have access to the pointer stored inside
    the RAII object. There is no reason to grant such access in any way other than
    the standard pointer syntax, which makes our RAII object a kind of pointer itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This pointer can be used to automatically delete, at the end of the scope,
    the object that it points to (hence the name):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The destructor is called when the scope containing the `scoped_ptr` object
    is exited. It does not matter how it is exited—an early `return` from a function,
    a `break` or `continue` statement in the loop, or an exception being thrown are
    all handled in exactly the same way, and without leaks. We can verify this with
    tests, of course:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'All tests pass, confirming that there is no leak:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we can use a scoped pointer as a data member in another class—a
    class that has secondary storage and must release it upon destruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This way, we don’t have to delete the object manually in the destructor of class
    `A`, and, in fact, if every data member of class `A` takes care of itself in a
    similar fashion, class `A` may not even need an explicit destructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyone familiar with C++11 should recognize our `scoped_ptr` as a very rudimentary
    version of `std::unique_ptr`, which can be used for the same purpose. As you might
    expect, the standard unique pointer’s implementation has a lot more to it, and
    for good reasons. We will review some of these reasons later in this chapter,
    but, to be clear: you should use `std::unique_ptr` in your code and the only reason
    we implemented our own `scoped_ptr` here is to understand how an RAII pointer
    works.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One last issue to consider is that of performance. C++ strives for zero-overhead
    abstractions whenever possible. In this case, we are wrapping a raw pointer into
    a smart pointer object. However, the compiler does not need to generate any additional
    machine instructions; the wrapper only forces the compiler to generate the code
    that, in a correct program, it would have done anyway. We can confirm with a simple
    benchmark that both the construction/deletion and the dereference of our `scoped_ptr`
    (or `std::unique_ptr`, for that matter) take exactly the same time as the corresponding
    operations on a raw pointer. For example, the following microbenchmark (using
    the Google benchmark library) compares the performance of all three pointer types
    for dereferencing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The benchmark shows that the smart pointers indeed incur no overhead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We have covered in enough detail the applications of RAII for managing memory.
    But there are other resources that a C++ program needs to manage and keep track
    of, so we have to expand our view of RAII now.
  prefs: []
  type: TYPE_NORMAL
- en: RAII for other resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The name, RAII, refers to *resources* and not *memory*, and indeed the same
    approach is applicable to other resources. For each resource type, we need a special
    object, although generic programming and lambda expressions may help us to write
    less code (we will learn more about this in [*Chapter 11*](B19262_11.xhtml#_idTextAnchor509),
    *ScopeGuard*). The resource is acquired in the constructor and released in the
    destructor. Note that there are two slightly different flavors of RAII. The first
    option is the one we have already seen—the actual acquisition of the resource
    is at initialization, but outside of the constructor of the RAII object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The constructor merely captures the handle (such as a pointer) that resulted
    from this acquisition. This was the case with the `scoped_ptr` object that we
    just saw—memory allocation and object construction were both done outside of the
    constructor of the `scoped_ptr` object, but still during its initialization. The
    second option is for the constructor of the RAII object to actually acquire the
    resource. Let’s see how this works, with the example of an RAII object that manages
    mutex locks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the constructor of the `mutex_guard` class itself acquires the resource;
    in this case, exclusive access to the shared data protected by the mutex. The
    destructor releases that resource. Again, this pattern completely removes the
    possibility of *leaking* a lock (that is, exiting a scope without releasing the
    lock), for example, when an exception is thrown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In this test, we check whether the mutex is locked or not by calling `std::mutex::try_lock()`—we
    cannot call `lock()` if the mutex is already locked, as it will deadlock. By calling
    `try_lock()`, we can check the state of the mutex without the risk of deadlock
    (but remember to unlock the mutex if `try_lock()` succeeds since we’re using `try_lock()`
    just to test and don’t want to lock the mutex again).
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, the standard provides an RAII object for mutex locking, `std::lock_guard`.
    It is used in a similar manner but can be applied to any mutex type that has the
    `lock()` and `unlock()` member functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In C++17, we have a similar RAII object for locking multiple mutexes – `std::scoped_lock`.
    In addition to the RAII release, it offers a deadlock avoidance algorithm when
    locking several mutexes at once. Of course, there are many more kinds of resources
    that a C++ program may have to manage, so we often end up writing our own RAII
    objects. Sometimes, the standard helps out, such as the addition of `std::jthread`
    in C++20 (a thread is also a resource, and “*releasing*” it usually means joining
    the thread, which is what `std::jthread` does in its destructor). With the wide
    variety of resources that can be managed with RAII techniques, sometimes we have
    needs that go beyond automatically releasing resources at the end of the scope.
  prefs: []
  type: TYPE_NORMAL
- en: Releasing early
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The scope of a function or a loop body does not always match the desired duration
    of the holding of the resource. If we do not want to acquire the resource at the
    very beginning of the scope, this is easy—the RAII object can be created anywhere,
    not just at the beginning of the scope. Resources are not acquired until the RAII
    object is constructed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the release still happens at the end of the function body scope. What
    if we only want to lock a short portion of code inside the function? The simplest
    answer is to create an additional scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: It may be surprising if you have never seen it before, but in C++, any sequence
    of statements can be enclosed in the curly braces, as `{ ... }`. Doing so creates
    a new scope with its own local variables. Unlike the curly braces that come after
    loops or conditional statements, the only purpose of this scope is to control
    the lifetime of these local variables. A program that uses RAII extensively often
    has many such scopes, enclosing variables with different lifetimes that are shorter
    than the overall function or loop body. This practice also improves readability
    by making it clear that some variables will not be used after a certain point,
    so the reader does not need to scan the rest of the code looking for possible
    references to these variables. Also, the user cannot accidentally add such a reference
    by mistake if the intent is to *expire* a variable and never use it again.
  prefs: []
  type: TYPE_NORMAL
- en: 'And what if a resource may be released early, but only if certain conditions
    are met? One possibility is, again, to contain the use of the resource in a scope,
    and exit that scope when the resource is no longer needed. It would be convenient
    to be able to use `break` to get out of a scope. A common way to do just that
    is to write a *do* *once* loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'However, this approach does not always work (we may want to release the resources,
    but not other local variables we defined in the same scope), and the readability
    of the code suffers as the control flow gets more complex. Resist the impulse
    to accomplish this by allocating the RAII object dynamically, with `operator new`!
    This completely defeats the whole point of RAII, since you now must remember to
    invoke `operator delete`. We can enhance our resource-managing objects by adding
    a client-triggered release, in addition to the automatic release by the destructor.
    We just have to make sure that the same resource is not released twice. Consider
    the following example, using `scoped_ptr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'After calling `reset()`, the object managed by the `scoped_ptr` object is deleted,
    and the pointer data member of the `scoped_ptr` object is reset to null. Note
    that we did not need to add a condition check to the destructor, because calling
    delete on a null pointer is allowed by the standard—it does nothing. The resource
    is released only once, either explicitly by the `reset()` call, or implicitly
    at the end of the scope containing the `scoped_ptr` object. As we already noted,
    you do not need to write your own `scoped_ptr` except to learn how RAII pointers
    work: `std::unique_ptr` can be reset too.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `mutex_guard` class, we can’t deduce from just the lock whether an
    early release was called or not, and we need an additional data member to keep
    track of that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can verify that the mutex is released only once, at the right time,
    with this test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The standard `std::unique_ptr` pointer supports `reset()`, whereas `std::lock_guard`
    does not, so if you need to release a mutex early, you need to use a different
    standard RAII object, `std::unique_lock`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: For other resources, you may have to write your own RAII object, which is usually
    a pretty simple class, but finish reading this chapter before you start writing,
    as there are a few *gotchas* to keep in mind.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the `reset()` method of `std::unique_ptr` actually does more than
    just delete the object prematurely. It can also be used to **reset** the pointer
    by making it point to a new object while the old one is deleted. It works something
    like this (the actual implementation in the standard is a bit more complex, because
    of the additional functionality the unique pointer has):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Note that this code breaks if a scoped pointer is reset to itself (for example,
    if `reset()` is called with the same value as that stored in `p_`). We could check
    for this condition and do nothing; it is worth noting that the standard does not
    require such a check for `std::unique_ptr`.
  prefs: []
  type: TYPE_NORMAL
- en: Careful implementation of Resource Acquisition is Initialization objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is obviously very important that the resource management objects do not mismanage
    the resources they are entrusted to guard. Unfortunately, the simple RAII objects
    we have been writing so far have several glaring holes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first problem arises when someone tries to copy these objects. Each of
    the RAII objects we have considered in this chapter is responsible for managing
    a unique instance of its resource, and yet, nothing prevents us from copying this
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This code invokes the default copy constructor, which simply copies the bits
    inside the object; in our case, the pointer is copied to the `object_counter`.
    Now we have two RAII objects that both control the same resource. Two destructors
    will be called, eventually, and both will attempt to delete the same object. The
    second deletion is undefined behavior (if we are very fortunate, the program will
    crash at that point).
  prefs: []
  type: TYPE_NORMAL
- en: 'Assignment of RAII objects is similarly problematic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The default assignment operator also copies the bits of the object. Again, we
    have two RAII objects that will delete the same managed object. Equally troublesome
    are the facts that we have no RAII objects that manage the second `object_counter`,
    the old pointer inside `p1` is gone, and there is no other reference to this object,
    so we have no way to delete it.
  prefs: []
  type: TYPE_NORMAL
- en: The `mutex_guard` does no better—an attempt to copy it results in two mutex
    guards that will unlock the same mutex. The second unlock will be done on a mutex
    that is not locked (at least not by the calling thread), which, according to the
    standard, is undefined behavior. Assignment of the `mutex_guard` object is not
    possible, though, because the default assignment operator is not generated for
    objects with reference data members.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have probably noticed, the problem is created by the **default**
    copy constructor and default assignment operator. Does it mean that we should
    have implemented our own? What would they do? Only one destructor should be called
    for each object that was constructed; a mutex can only be unlocked once after
    it was locked. This suggests that an RAII object should not be copied at all,
    and we should disallow both copying and assignment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: There are some RAII objects that can be copied. These are reference-counted
    resource management objects; they keep track of how many copies of the RAII object
    exist for the same instance of the managed resource. The last of the RAII objects
    has to release the resource when it is deleted. We discuss shared management of
    resources in more detail in [*Chapter 3*](B19262_03.xhtml#_idTextAnchor110), *Memory*
    *and Ownership*.
  prefs: []
  type: TYPE_NORMAL
- en: A different set of considerations exist for move constructor and assignment.
    Moving the object does not violate the assumption that there is only one RAII
    object that owns a particular resource. It merely changes which RAII object that
    is. In many cases, such as mutex guards, it does not make sense to move an RAII
    object (indeed, the standard does not make `std::lock_guard` or `std::scoped_lock`
    movable, but `std::unique_lock` is movable and can be used to transfer ownership
    of a mutex). Moving a unique pointer is possible and makes sense in some contexts,
    which we also explore in [*Chapter 3*](B19262_03.xhtml#_idTextAnchor110), *Memory*
    *and Ownership*.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, for a scoped pointer, moving would be undesirable, as it allows the
    extension of the lifetime of the managed object beyond the scope where it was
    created. Note that we do not need to delete the move constructor or move assignment
    operators if we already deleted the copying ones (although doing so does no harm).
    On the other hand, `std::unique_ptr` is a movable object, which means using it
    as a scope-guarding smart pointer does not offer the same protection because the
    resource could be moved out. However, if you need a scoped pointer, there is a
    very simple way to make `std::unique_ptr` do this job perfectly—all you have to
    do is to declare a `const` `std::unique_ptr` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, we have protected our RAII objects against duplicating or losing resources.
    But there is one more kind of resource management mistake that we have not yet
    considered. It seems obvious that a resource should be released in a way that
    matches its acquisition. And yet, nothing protects our `scoped_ptr` object from
    such a mismatch between construction and deletion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The problem here is that we have allocated multiple objects using an array version
    of `operator new`; it should be deleted with the array version of `operator delete`
    - `delete [] p_` must be called inside the `scoped_ptr` destructor, instead of
    `delete p_` that we have there now.
  prefs: []
  type: TYPE_NORMAL
- en: More generally, an RAII object that accepts a resource handle during initialization,
    instead of acquiring the resource itself (like the `mutex_guard` does) must somehow
    ensure that the resource is released in the right way that matches the way it
    was acquired. Obviously, this is not possible, in general. In fact, it is impossible
    to do automatically, even for the simple case of a mismatched `new` array and
    the `delete` scalar (`std::unique_ptr` does no better than our `scoped_ptr` here,
    although facilities such as `std::make_unique` make writing such code less error-prone).
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, either the RAII class is designed to release resources in one particular
    way, or the caller must specify how the resource must be released. The former
    is certainly easier, and in many cases is quite sufficient. In particular, if
    the RAII class also acquires a resource, such as our `mutex_guard`, it certainly
    knows how to release it. Even for the `scoped_ptr`, it would not be too hard to
    create two versions, `scoped_ptr` and `scoped_array`; the second one is for objects
    allocated by the `operator new` array. The standard handles it by specializing
    the unique pointer for arrays: you can write `std::unique_ptr<int[]>` and the
    array `delete` will be used (it is still up to the programmer to make sure that
    arrays allocated by `new[]` are owned by the correct instantiation of the pointer).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A more general version of an RAII class is parameterized not just by the resource
    type, but also by a callable object used to release this type, usually known as
    the deleter. The deleter can be a function pointer, a member function pointer,
    or an object with `operator()` defined—basically, anything that can be called
    like a function. Note that the deleter has to be passed to the RAII object in
    its constructor, and stored inside the RAII object, which makes the object larger.
    Also, the type of the deleter is a template parameter of the RAII class, unless
    it is erased from the RAII type (this will be covered in [*Chapter 6*](B19262_06.xhtml#_idTextAnchor266),
    *Understanding Type Erasure*). The standard gives us examples of both: `std::unique_ptr`
    has the deleter template parameter, while `std::shared_ptr` uses type erasure.'
  prefs: []
  type: TYPE_NORMAL
- en: Downsides of RAII
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Honestly, there aren’t any significant downsides to RAII. It is by far the most
    widely used idiom for resource management in C++. The only issue of significance
    to be aware of has to do with exceptions. Releasing a resource can fail, like
    anything else. The usual way in C++ to signal a failure is to throw an exception.
    When that is undesirable, we fall back on returning error codes from functions.
    With RAII, we can do neither of these things.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is easy to understand why error codes are not an option—the destructor does
    not return anything. Also, we cannot write the error code into some status data
    member of the object, since the object is being destroyed and its data members
    are gone, as are the other local variables from the scope containing the RAII
    object. The only way to save an error code for future examination would be to
    write it into some sort of a global status variable, or at least a variable from
    the containing scope. This is possible in a bind, but such a solution is very
    inelegant and error-prone. This is exactly the problem that C++ was trying to
    solve when exceptions were introduced: manually-propagated error codes are error-prone
    and unreliable.'
  prefs: []
  type: TYPE_NORMAL
- en: So, if the exceptions are the answer to error reporting in C++, why not use
    them here? The usual answer is *that the destructors in C++ cannot throw*. This
    captures the gist of it, but the real restriction is a bit more nuanced. First
    of all, prior to C++11, the destructors technically could throw, but the exception
    would propagate and (hopefully) eventually get caught and processed. In C++11,
    all destructors are, by default, `noexcept`, unless explicitly specified as `noexcept(false)`.
    If a `noexcept` function throws, the program immediately terminates.
  prefs: []
  type: TYPE_NORMAL
- en: So indeed, in C++11, destructors cannot throw unless you specifically allow
    them to do so. But what’s wrong with throwing an exception in the destructor?
    If the destructor is executed because the object was deleted, or because the control
    reached the end of the scope for a stack object, then nothing is wrong. The *wrong*
    happens if the control did not reach the end of the scope normally and the destructor
    is executed because an exception was already thrown. In C++, two exceptions cannot
    propagate at the same time. If this happens, the program will immediately terminate
    (note that a destructor can throw and catch an exception, there is no problem
    with that, as long as that exception does not propagate out of the destructor).
    Of course, when writing a program, there is no way to know when some function
    called from something in a particular scope, could throw. If the resource release
    throws and the RAII object allows that exception to propagate out of its destructor,
    the program is going to terminate if that destructor was called during exception
    handling. The only safe way is never to allow exceptions to propagate from a destructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'This does not mean that the function that releases the resource itself cannot
    throw, but, if it does, an RAII destructor has to catch that exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This still leaves us with no way to signal that an error happened during resource
    release—an exception was thrown, and we had to catch it and not let it escape.
  prefs: []
  type: TYPE_NORMAL
- en: 'How much of a problem is this? Not that much, really. First of all, releasing
    memory—the most frequently managed resource—does not throw an exception. Usually,
    the memory is released not as just memory, but by deleting an object. But remember
    that the destructors should not throw an exception in order that the entire process
    of releasing memory by deleting an object doesn’t throw an exception either. At
    this point, the reader might, in search of a counter-example, look up in the standard
    what happens if unlocking a mutex fails (that would force the destructor of `std::lock_guard`
    to deal with the error). The answer is both surprising and enlightening—unlocking
    a mutex cannot throw, but if it fails, undefined behavior results instead. This
    is no accident; the mutex was intended to work with an RAII object. Such is, in
    general, the C++ approach to releasing the resources: an exception should not
    be thrown if the release fails, or at least not allowed to propagate. It can be
    caught and logged, for example, but the calling program will, in general, remain
    unaware of the failure, possibly at the cost of undefined behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: RAII is a really successful technique that has evolved very little even as the
    language changes significantly from pre-C++11 all the way to C++20 (aside from
    minor syntactic conveniences such as constructor argument deduction). That is
    because it really doesn’t have any downsides of note. But, as the language gets
    new capabilities, sometimes we find ways to improve even the best and most established
    patterns, and here is one of those cases.
  prefs: []
  type: TYPE_NORMAL
- en: Very modern RAII
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we really want to be picky, we can make another complaint about RAII; realistically,
    this is only a downside when the acquisition or release code is long and complex.
    The acquisition and release are done in the constructor and the destructor of
    an RAII object, respectively, and this code can be quite removed from the place
    in the code where the resource is acquired (so we have to jump around the program
    a bit to figure out what it does).
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, if the resource handling requires a lot of state (such as the appropriate
    actions depending on several factors and conditions), we have to capture all this
    state in the RAII object. An example that truly challenges the readability of
    RAII would also be completely unreadable on a book page, so we will have to condense
    it. Let us say that we want to have an RAII lock guard that performs several actions
    when locking and unlocking the mutex, and even the way it handles the resource
    depends on some external parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is how this guard object might be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we perform only one possible action in addition to locking and unlocking
    – we can optionally log these events; you can already see that the implementations
    of the constructor and the destructor, the two sections of code that must be closely
    matched, are somewhat separated from each other. Also, tracking the state (do
    we need to log the events? Are we running in a multi-threaded or single-threaded
    context?) is becoming somewhat verbose. Again, you have to remember that this
    is a simplified example: in a real program, this is still a fine RAII object.
    But, if the code gets even longer, you may wish for a better way.'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the better way is borrowed from Python (specifically, from the
    `contextmanager` decorator). This technique used coroutines and, thus, requires
    C++20 (so we managed to couple one of the oldest tools in C++ with the most cutting-edge
    one). The detailed explanation of the coroutines in general and the C++ coroutine
    machinery in particular lies outside of the scope of this book (you can find it,
    for example, in my book “*The Art of Writing Efficient* *Programs*”, ([https://www.packtpub.com/product/the-art-of-writing-efficient-programs/9781800208117](https://www.packtpub.com/product/the-art-of-writing-efficient-programs/9781800208117))).
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, it is sufficient to remember two things:'
  prefs: []
  type: TYPE_NORMAL
- en: First, C++ coroutines are, essentially, regular functions except they suspend
    themselves at any time and return the control to the caller. The caller can resume
    the coroutine, and it continues to execute from the suspension point as if nothing
    happened.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, C++ coroutines require a lot of standard boilerplate code. In the example
    that follows, we will highlight the important fragments; you can safely assume
    that the rest of the code is required by the standard to make the coroutine machinery
    work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us first see what the code for a lock guard looks like with this new coroutine-based
    RAII approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Instead of the `lock_guard` object, we have the `make_guard` function. This
    function is a coroutine; you can tell because it has the `co_yield` operator –
    this is one of several ways C++ coroutines return values to the caller. The code
    before `co_yield` is resource acquisition, it is executed when the resource is
    acquired and is equivalent to the constructor of our `lock_guard` object. The
    code after `co_yield` is the same as the destructor of `lock_guard`. Arguably,
    this is easier to read and maintain (at least after you stop staring at the coroutine
    syntax) because all the code is in the same place you can think of `co_yield`
    as a placeholder for the work the caller is going to do while owning the resource
    (the mutex, in our case). Also, there are no class members and member initialization
    to write – the function parameters are accessible throughout the execution of
    the coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The coroutine returns an object of type `co_resource<std::mutex>`: that is
    our modern RAII type is implemented as the `co_resource` class template; it is
    implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the object that owns the resource, but you don’t see the resource or
    its type `T` directly: it is hidden inside the coroutine handle `coro_`. This
    handle acts like a pointer to the state of the coroutine. If you focus on the
    handle as a resource for the moment, we have a fairly routine resource-owning
    object. It acquires the resource in the constructor and maintains the exclusive
    ownership: the handle is destroyed in the destructor of the `co_resource` object
    unless the ownership is transferred via move, and copying the resource is not
    allowed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This resource-owning object is going to be returned by a coroutine function;
    every such object must contain a nested type named `promise_type`. Often, it is
    a nested class, but it can also be a separate type (in this example, we made it
    such largely to avoid a single very long code fragment). The standard imposes
    several requirements on the interface of the promise type, and here is the type
    that meets these requirements for our purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Our promise type contains a pointer to the value returned by the coroutine.
    How does the value get there? When the coroutine returns the result via `co_yield`,
    the member function `yield_value()` is called (the compiler generates this call).
    The value returned by `co_yield` is passed to this function, which, in turn, captures
    its address (the lifetime of the value is the same as that of the coroutine itself).
    The other important member function of the promise type is `get_return_object()`:
    it is invoked by the compiler to return the `co_resource` object itself to the
    caller of the `make_guard()` coroutine. Note that it does not return a `co_resource`
    object, but a handle that is implicitly convertible to `co_resource` (it has an
    implicit constructor from `handle_type`). The rest of the `promise_type` interface
    is, for our purposes, the boilerplate code required by the standard.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the `co_resource` RAII works: first, we call the function `make_guard()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'From the caller’s point of view, it starts executing like any other function,
    although the internal details are quite different. All the code we wrote before
    `co_yield` is executed, then the coroutine is suspended and the `co_resource<std::mutex>`
    object is constructed and returned to the caller, where it is moved into a stack
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The execution proceeds as usual, protected by the locked mutex. At the end of
    the scope, the object `lg` is destroyed; this happens no matter whether we exit
    the scope normally or by throwing an exception. In the destructor of the `co_resource`
    object, the coroutine is resumed via the call to the member function `resume()`
    of the coroutine handle `coro_`. This causes the coroutine to resume execution
    right after the point where stopped before, so the control jumps to the next line
    after `co_yield`. The resource release code we wrote there is executed, and the
    coroutine exits through the bottom of the scope, now for the last time. The destructor
    of `co_resource` has some cleanup to do, but, otherwise, we are (mostly) done.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few things we have left out to avoid overly extending the example.
    First of all, as written, the `co_resource` template does not work if the resource
    type `T` is a reference. This may be perfectly acceptable: handling references
    by RAII is not that common. In this case, a static assert or a concept check is
    sufficient. Otherwise, we have to carefully handle dependent types inside the
    template. Second, the implicit requirement on the coroutine such as `make_guard()`
    is that it returns a value via `co_yield` exactly once (you can have more than
    one `co_yield` in the body of the coroutine, but only one can be executed for
    a particular call). To make the code robust, we have to verify that this requirement
    has been met using run-time asserts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have the acquisition and release code right next to each other and we
    don’t need to convert function arguments into data members like we did when constructors
    and destructors handled RAII. The only thing that might make it even better would
    be if we didn’t have to write a separate `make_guard()` function, at least in
    cases where we have only one call to it. Turns out that we can combine coroutines
    and lambdas to just such a result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Here the coroutine is the `operator()` of a lambda expression; note that we
    have to specify the return type explicitly. The lambda is invoked immediately;
    and; as usual in such cases, the use of captures or parameters boils down to what
    is more convenient in each case.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the coroutine-based RAII resource management, we were able to keep all
    the relevant code portions very close to each other. Of course, there is a price:
    launching, suspending, and resuming coroutines takes time (and a bit of memory).
    The basic RAII object is always going to be faster, so don’t try to replace `std::unique_pointer`
    with a `co_resource` class. But keep in mind that our original dissatisfaction
    with RAII started with the observation that when the code executed for the acquisition
    or release of resources is long, complex, and uses a lot of state variables, an
    RAII class might be hard to read. It is likely that in such cases the overhead
    of the coroutines is less important (we should also point out that the “scope
    guard” pattern described later in [*Chapter 11*](B19262_11.xhtml#_idTextAnchor509),
    *ScopeGuard*, addresses some of the same concerns and sometimes is a better option).'
  prefs: []
  type: TYPE_NORMAL
- en: The RAII techniques we have learned are some of the most enduring C++ patterns;
    they were in use from the first day of C++ and continue to evolve and benefit
    from the latest language features. Throughout this book, we will casually and
    without a second thought use classes such as `std::unique_ptr` or `std::lock_guard`.
    For now, we leave you with these final thoughts.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After this chapter, you should be well aware of the dangers of an ad-hoc approach
    to resource management. Fortunately, we have learned the most widely used idiom
    for resource management in C++; the RAII idiom. With this idiom, each resource
    is owned by an object. Constructing (or initializing) the object acquires the
    resource, and deleting the object releases it. We saw how using RAII addresses
    the problems of resource management, such as leaking resources, accidentally sharing
    resources, and releasing resources incorrectly. We have also learned the basics
    of writing exception-safe code, at least as far as the leaking or otherwise mishandling
    of resources is concerned. Writing RAII objects is simple enough, but there are
    several caveats to keep in mind. Finally, we reviewed the complications that arise
    when error handling has to be combined with RAII.
  prefs: []
  type: TYPE_NORMAL
- en: 'RAII is a resource management idiom, but it can also be viewed as an abstraction
    technique: the complex resources are hidden behind simple resource handles. The
    next chapter introduces another kind of abstraction idiom, type erasure: instead
    of complex objects, we will now hide complex types.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the resources that a program can manage?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main considerations when managing resources in a C++ program?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is RAII?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does RAII address the problem of leaking resources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does RAII address the problem of dangling resource handles?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What RAII objects are provided by the C++ standard library?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What precautions must be taken when writing RAII objects?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens if releasing a resource fails?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/application-development/expert-c-programming](https://www.packtpub.com/application-development/expert-c-programming)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/application-development/c-data-structures-and-algorithms](https://www.packtpub.com/application-development/c-data-structures-and-algorithms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/application-development/rapid-c-video](https://www.packtpub.com/application-development/rapid-c-video)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
