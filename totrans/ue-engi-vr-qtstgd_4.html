<html><head></head><body><div><h1 class="header-title">User Interface and User Experience inside VR</h1>
                
            
            
                
<p>Thinking about our users and building our game systems with them in mind is just a small part of the overall process we need to go through to ensure that our game is an enjoyable experience for the widest range of players. <strong>Human-Centered Design</strong> (<strong>HCD</strong>) is just the first step in the greater design process called <strong>User Experience</strong> (<strong>UX</strong>) design. When we think about the whole user experience, we are really looking at not only the people who are using our game, but also at what we can do to improve how they use it. By thinking through the lens of UX, we hope to build a game that addresses all of the player's needs, is easy to use, and that the player never wants to put down.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>What is UX design?</li>
<li>The seven aspects of UX</li>
<li>User interfaces in VR</li>
<li>Designing the UI for <em>Server 17</em></li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">What is UX design?</h1>
                
            
            
                
<p>The term UX design is not a new term, even though its use has become more popular in recent years. Coined by Don Norman during his time at Apple, it is an umbrella term for the many ways in which people interact with machines. It also refers to the idea of seeing things from the user's perspective. In the game industry, UX tends to go hand in hand with user interface design since players often interact with a piece of software purely through its interface. Yet the development of virtual reality and its ability to give players a large amount of choice in how they interact with a game world has led companies to rethink how they view this field. How do you think about the user experience in a game when the player can interact with the world without a traditional UI? This is where the UX designer really comes into their own.</p>
<p>A UX designer is a designer who is responsible for the look, feel, and usability of the product. Yet, even this definition is lacking since, until recently, UX design in video games pretty much meant focusing on the user interface. In virtual reality development, UX design covers several more topics, such as story experience, control schemes, player safety, accessibility, and more. A UX designer should be concerned with seven different aspects of the game. The game needs to have the following characteristics:</p>
<ul>
<li><strong>Useful</strong>: Does the game provide the user with the experience they are looking for? There is no reason to bring a game or product to market if it isn't useful to someone. In UX design, we use the Discovery and Empathy stages of HCD to discover how useful what we are designing will be for our users.</li>
<li><strong>Usable</strong>: Can the user achieve their objectives while using the product? A game cannot be successful if it is difficult to play or understand. There are many factors that contribute to a video game's usability, such as the controls, character animation, difficulty, and more.</li>
<li><strong>Accessible</strong>: Accessibility continues to be an important part of user experience design. Users with different ability levels should be able to play your game, and the experience you offer should be accessible to anyone. When we sit down and design for accessibility, we often find that we improve the experience for everyone. Several organizations have released developer resources to help bring more accessible games to market, such as <a href="https://accessible.games/">https://accessible.games/</a> and <a href="http://gameaccessibilityguidelines.com/">http://gameaccessibilityguidelines.com/</a>.</li>
</ul>
<ul>
<li><strong>Desirable</strong>: Desirability refers to the marketing, branding, and aesthetic of a game or franchise. When we design for desirability, we want to create an image or emotional attachment that players want. The goal is to create a game experience that players will brag about and create a desire for that game in their friends.</li>
<li><strong>Findable</strong>: Findability refers to how easy a game is to find and purchase, but it also refers to how easy it is to find experiences contained within it the game. Imagine that a player purchases the latest arena shooter. They are excited to play with their friends, so they load the game, but can't seem to find the play button or the options to customize the controls. They search through countless menus that allow them to make a character and tweak the sound, but just can't get to the point where they can play with their buddies. Finally, they just give up and drop the controller. As developers, the last thing we want to is waste our players' time and cause them frustration. This is why findability is so important.</li>
<li><strong>Valuable</strong>: Players often find value based on factors such as online capabilities, hours of gameplay, announced features, and difficulty. The more value the player sees in the game, the more likely they are to purchase it. Terefore, the main goal of us designers is to have players see the value in our games and purchase them so that we can continue to design and create more experiences. </li>
<li><strong>Credible</strong>: This is the players' ability to trust the developer to deliver the experience and features they have been promised. Credibility is an important commodity in the game industry, and one that we have seen publishers/developers take for granted in recent years. We only have one chance for our game to make a good first impression, and most players never give a product a second chance. This is especially important for smaller independent developers who rely on reputation and word of mouth to sell their games.</li>
</ul>
<p>Together, these seven aspects of game design create the basis for a way to think about the user experience. When we design games with our players' needs, goals, and overall experience in mind, we create products that are fun, memorable, and successful in the marketplace. With this idea in mind, let's move on to creating the next portion of <em>Server 17</em>: the user interface elements that will be critical for controlling the experience and for conveying necessary information to the player.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">User interfaces in VR</h1>
                
            
            
                
<p>As we have seen, interaction in VR goes beyond what we are used to in traditional applications and video games. The player has near total immersion in the game world and can reach out and touch many of the objects they wish to interact with. This ability to interact directly with the environment opens many avenues for interface design while also presenting several challenges. One such challenge is that HUD elements that are displayed along the edges of a screen appear distorted and out of position in VR. Such elements can also break the immersion of the VR experience, depending on the story and setting. To solve the interface problem, most VR developers have moved away from these interfaces in favor of using information elements embedded within the game world. These can be broken down into the following three categories:</p>
<ul>
<li>Diagetic</li>
<li>Spatial</li>
<li>Meta</li>
</ul>
<p>Let's take a look at diagetic interfaces, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7066e1e6-1815-4cb2-a3e9-3062b080572a.png" style="width:26.58em;height:12.83em;" width="1950" height="935"/></p>
<p>The Server 17 level clock </p>
<p>Diagetic interface elements exist within the game world and provide the player with information directly from the environment. The map the player carries in <em>Minecraft</em> or <em>Firewatch,</em> the energy bars built into the suit of Isaac Clarke in <em>Dead Space</em>, and the watch that the player refers to in the <em>Metro</em> games are all examples of information being provided to the player by contextual clues inside the environment. Diagetic interfaces are preferred in virtual reality as they promote immersion and do not create any ill effects for the player.</p>
<p>Next up are spatial interfaces, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/490564ad-6e47-4930-bc02-b0fd2b764187.png" style="width:27.00em;height:15.25em;" width="1300" height="731"/></p>
<p>Spatial interface elements in Tribe XR</p>
<p>Sometimes the best way to provide information to the player is to have it floating right in front of their face. Spatial interface elements float at designated world coordinates in the game world, waiting for the player to read or interact with them. We see these interfaces in many current VR titles—for example, the song menu in <em>Beat Saber,</em> the track selection interface in <em>Tribe XR,</em> and the ammo counters in <em>Robo Recall</em>. Spatial interface elements perform well in virtual reality as they blend in with the virtual world and often mimic traditional UI elements that players are used to using.</p>
<p>Finally, we have meta interfaces:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/57241460-c0fd-48fd-96e3-5aac07e5f805.png" style="width:20.58em;height:20.42em;" width="1100" height="1088"/></p>
<p>Interface elements in <em>Robo Recall</em></p>
<p>Meta interface elements are defined as two-dimensional elements that are displayed as an overlay on the player's vision, but that are not persistent like a standard interface. These are often used to convey temporary information, such as damage, without a more permanent presence on the screen. The most common use of this type of interface is a blood splatter or red tinted vision to display damage in games such as <em>Gorn</em> and <em>Robo Recall</em>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Designing the UI elements for Server 17</h1>
                
            
            
                
<p>Taking what we now know about user experience and interfaces, let's apply that knowledge to creating some UI elements for <em>Server 17</em>. For our first-time VR user, our interface elements should probably be diagetic for both ease of use and to preserve immersion in our Sci-Fi environment. We need to display our level timer so that the player knows how much time they have left. We also might need to rethink how the tools station is used to streamline the station interface. As always, remember to test with your user group along the way along the way and remember that you are designing the game to maximize their enjoyment!</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Displaying the level timer</h1>
                
            
            
                
<p>Let's start by designing the level timer, as shown in the following diagram:</p>
<div><img src="img/66937198-9e35-4a40-8f10-8e5809738feb.png" style="width:23.92em;height:13.42em;" width="1319" height="741"/></div>
<p>Level timer wireframe created using a basic UI wireframe software</p>
<p>To keep the timer as simple as possible, we need to create something that is easily seen from anywhere in the level and does not take the player out of the experience. First, our timer should be digital to fit the Sci-Fi setting of our game. Second, it should be located in a place that the player finds natural to look at and can be easily found anywhere in the level. Finally, it should be able to display minutes and seconds, rather than just seconds, to fit the player's expectation of what a timer is. This is what I think would make a good solution. </p>
<p>Creating a diagetic timer element will preserve the Sci-Fi experience for the player, as well as create something that is easy to read. We can locate our widget above the puzzle itself and allow it to rotate to always face the player. This will meet all of our criteria and create something that is fun and fits with our theme.</p>
<p>Our timer solution will consist of two different parts. The first is an <strong>Unreal Motion Graphics</strong> (<strong>UMG</strong>) widget scripted to calculate the level time. The second piece will be a class blueprint that displays our 2D widget in our 3D level.</p>
<p>When preparing for this book, I was asked by several people to discuss the difference between 2D and 3D interface assets in VR. 2D interface elements work in virtual reality as long as they exist as spatial or diagetic components. 3D pieces, such as the button and tool station we developed in the last chapter, work as well, specifically because they are diagetic in nature. The most important consideration should always be your players and their expectations. Research and testing will always help you design the best solution.</p>
<p>We will start by creating the UMG widget, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b820f9ed-369c-4071-89eb-6159c698528b.png" style="width:64.83em;height:34.83em;" width="1950" height="1048"/></p>
<p>The UMG widget canvas</p>
<p>To create a UMG widget, go through the following steps:</p>
<ol>
<li>Right-click in the Content Browser, mouse over the User Interface option, and select Widget Blueprint. Name the new widget <kbd>LevelTimer</kbd>. Double-click the new blueprint to open it.</li>
<li> Our design consists of two text components, one a label and one that is updated every frame to display the time. Create the first one by using the Palette panel to find the Text component and dragging it on to the Canvas Panel. </li>
<li>In the Details panel, change the name to <kbd>TraceLabel</kbd>.</li>
<li>In the Slot section of the Details panel, click the Anchors drop-down menu and choose the center option. This will keep it centered within our class blueprint.</li>
<li>Change the Position X value to -150 and the Position Y value to -125.</li>
<li>Change the Size X value to 300 and the Size Y value to 100.</li>
<li>In the Appearance section of the Details panel, change the color of the text to something bright. I went with a green color, but feel free to change it to whatever you might like.</li>
<li>In the Font portion of the Appearance section, change the Size value to 48.</li>
<li>Finally, change the Justification option to center.</li>
<li>With our font option set, we can now update the text. In the Content section of the Details panel, change the Text value to <kbd>TRACE ACTIVE</kbd>.</li>
<li>Create the second Text component and name it <kbd>TimerDisplay</kbd>.</li>
<li>Just like before, click the Anchors drop-down menu and change it to the center option.</li>
<li>Change the Position X value to -150 and the Position Y value to -50.</li>
<li>Change the Size X value to 300 and the Size Y value to 100.</li>
<li>In the Appearance section of the Details panel, change the color to the same value that you used in step 7.</li>
<li>In the Font portion of the Appearance section, change the Size value to 48.</li>
<li>Change the Justification to center.</li>
</ol>
<ol start="18">
<li>In the content section of the panel, change the Text value to "MM:SS".</li>
<li>Now we need to program the Text value to update and display the time remaining in our level. To do this we will create a bit of programming called a Bind. Click the Bind drop-down list to the right of the Text value and choose Create Binding, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/8828118d-6dc4-4e72-8f98-9d0e660849aa.png" width="1950" height="372"/></p>
<p>Display Level Time binding</p>
<ol start="20">
<li>Let's start with a bit of housekeeping. In the Functions section of the My Blueprint panel, right-click on the name of our binding and choose the Rename option. Change the name to Display Level Time.</li>
<li>This binding needs to be able to take the level time that is measured in seconds, convert it to minutes and seconds, and then display it as a string. The first step will be to create a new float variable that will hold our level time. Over in the Variables section of the My Blueprint panel, create a new float variable and name it Level Time. </li>
<li>Drag a copy of our new variable into the blueprint, and choose Get from the menu. From here, we will delve a bit into Unreal's timespan system. We will use a node called Time Seconds to String to convert our seconds that are stored in Level Time to a string that is in the m<em>inutes:seconds:milliseconds</em> format. From there, we can convert the new string into text and feed it into our text component. Right-click and search for the Time Seconds to String node and connect Level Time to the In Seconds input.</li>
</ol>
<ol start="23">
<li>From there, plug the output from Time Seconds to String into the Return input and Unreal will create the translate node for us, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/9af03543-6f9c-476b-8ec8-95ec18934eb6.png" style="width:78.58em;height:40.42em;" width="1950" height="1002"/></p>
<p>Event graph for level timer widget</p>
<ol start="24">
<li>Now to finish the setup for our timer. We will need to cast to <kbd>S17GameState</kbd> to retrieve the value of GameTime and that as our value for the Level Time. This allows us to change the value in one place and have it affect the timer automatically. Click over to the Event Graph for our widget and drag an execute line off the Event Construct node. Search for Cast To S17GameState.</li>
<li>Let's set up the cast. Drag a connection from the Object input, and search for the Get Game State node. With this defined, we can now pretend to be the Game State and retrieve the value of GameTime. Drag a connection from the <kbd>S17GameState</kbd> output and search for the Get Game Time node.</li>
<li>Lastly, we need to store the value of GameTime inside our Level Time node. Drag a copy of the Level Time variable into the blueprint and choose the set option, Connect this to the execute output from our cast node and connect the output from getting the value of GameTime into the float input for Level Time.</li>
</ol>
<ol start="27">
<li>To finally make our timer work, every tick we will quickly calculate the new time for Level Time. Combined with our Bind function, this will display the current remaining level time in our widget. Grab a copy of the Level Time variable and drag it into our blueprint. Choose Get from the menu and position it near the Event Tick node.</li>
<li>Drag another copy of the Level Time into the blueprint, only this time, choose Set from the menu. Connect this to the execute output from Event Tick.</li>
<li>Math time! We will use the In Delta Seconds output from Event Tick to calculate the time remaining in the level by subtracting it from the current value of Level Time. Drag a line off from the get Level Time node and search for <kbd>Float-Float</kbd>. Make sure the first value in this new node is Level Time and connect the In Delta Second output to the second input. Connect the output of this node to the float input on the set Level Time. </li>
</ol>
<p>With our timer functionality all set up, all that remains to do is display it in the level. To do this, we will make use of a class blueprint that contains a <kbd>Widget</kbd> component. This component allows us to display a 2D interface element in 3D space by projecting the widget on-to a plane. We can then position this plane over the puzzle and program it to always rotate to face the player. In this way, we can guarantee that the player can always see our countdown clock.</p>
<p>Start by creating a new Class Blueprint extended from Actor and name it <kbd>3dLevelTimer</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/aa2b415c-5c85-400e-98a7-0c68a910defc.png" width="1950" height="753"/></p>
<p>3dLevelTimer function</p>
<p>Let's add the Widget component by going through the following steps:</p>
<ol>
<li>In the Viewport section of our blueprint, click the Add Component button and search for the Widget component. Add it to the blueprint and name it Display Widget.</li>
<li>Click on the new Display Widget in the Components panel. In the Details panel, find the Widget Class option in the User Interface section of the menu. Click the drop-down menu and select the Level Timer widget we created earlier.</li>
<li>Next, we will create a new function to handle the rotation of the widget. In the Functions section of the My Blueprints panel, click the + function button. Name the new function Update Rotation.</li>
<li>The purpose of the Update Rotation function is to find the location of the player's camera and rotate the widget around to face it so that our player can always look and see how much time is left. Start the function by dragging a line from the start node and searching for the IsValid node. We only want the widget to worry about rotating if the player is in the level.</li>
<li>From IsValid, drag a line from the IsValid output, and search for the SetWorldRotation node that references the Display Widget. Right-click on the New Rotation input and split the struct pin. We will need this for later.</li>
<li>Going back to the IsValid node, we still need to find the Input Object. Drag a line off the input, and search for the Get Player Camera Manager node. This node will provide the input for IsValid, as well as the node we will create in the next step.</li>
<li>Dragging another connection from the Get Player Camera Manager node, search for Get Camera Location. This will be the start location for finding our look at rotation.</li>
<li>From the Return Value of Get Camera Location, drag a line and create a Find Look At Rotation node. To get the Target for our new node, we will need to drag a reference to our Display Widget into the blueprint from the Components panel. From this, create a Get World Location node and connect its output to the Target input on Find Look At Rotation.</li>
<li>Almost there! Right-click on the Return Value pin from the Find Look At Rotation node and split the struct. We only need to work with the Yaw value. If we work with the Yaw as it is, our widget will be rotated backwards. We can correct this with a little bit of math. Drag a connection from the Return Value Z output and create a Float+Float node. Set the second value to <kbd>180</kbd>. Plug the output into the New Rotation Z input on the Set World Rotation node.</li>
<li>Time to add the new function to the Event Graph. Drag a copy of the UpdateRotation function into the blueprint and connect it to a copy of the Event Tick node. We are ready to test!</li>
</ol>
<p>Programming complete! Drag a copy of the <kbd>3dLevelTimer</kbd> into your test level, and position it above the puzzle. Now test the new feature on yourself, as well as on your potential users. Pay attention to their feedback and adjust the size, color, and location of the timer as needed.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Redesigning the tool experience</h1>
                
            
            
                
<p>Having applied user experience design principles to our level timer, let's go back and take a look at the Tools Station we created in the last chapter. When testing with my users, I discovered that it was not intuitive for the player to have to head for a tool station every time they wanted to rotate the puzzle, especially within a timed experience. When we receive feedback like this, there is only one solution: redesign! Let's look at the following diagram:</p>
<div><img src="img/9a5cbf13-6473-4b3d-ba9f-ba0e3c03306a.png" style="width:23.17em;height:30.08em;" width="1025" height="1331"/></div>
<p>New tools menu wireframe</p>
<p class="mce-root">After a couple of rounds of testing and interviews with my players, it became clear that having to go back to the tool station to rotate the puzzle (and use other future tools) was adding a step where there didn't need to be one. The tool station itself was a neat idea, but it didn't bring any additional value to the game experience. In fact, it made the experience less usable. The new goal will be to redesign the station as a tool menu that will be connected to the player's controller. This menu could be opened at any time or location and used in the same manner as the tool station, without having to move.</p>
<p>It will need to be built in two parts, similar to the level timer. The first will be a 2D widget that will contain all the functionality. The second will be a 3D widget that we can display whenever a button on the controller is pressed. We can see this setup in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e8e10ee5-d9ba-4aad-8dc2-feff45a5fa7e.png" width="1950" height="847"/></p>
<p>The completed ToolsWidget interface</p>
<p>Start by creating a new blueprint widget and naming it <kbd>ToolsWidget</kbd>:</p>
<ol>
<li>Right-click in the Content Browser and create a new blueprint widget named <kbd>ToolsWidget</kbd>. Double-click the blueprint to open the UMG editor.</li>
<li>This time when we make our widget, we are going to take a more organized approach. Start by searching the Palette for the Image component. Drag it on to the Canvas Panel and change the Anchors option in the Details panel to the center. Change its name to <kbd>Background</kbd>. This will give our menu a nice background color.</li>
</ol>
<ol start="3">
<li>Change the Position X and Position Y values to <kbd>-62.5</kbd>.</li>
<li>Change the Size X and Size Y values to <kbd>125</kbd>.</li>
<li>Time to choose the color. Choose your new color with the Color and Opacity option. Setting your Alpha value to <kbd>0.5</kbd> gives it a nice Sci-Fi technology feel.</li>
<li>Now we are going to create a Vertical Box component and add it to the Canvas panel. Don't forget to change its Anchors option to center.</li>
<li>Like the Background, change the Position X and Position Y values to <kbd>-62.5</kbd>, as well as the Size X and Size Y values to <kbd>125</kbd>.</li>
<li>The Vertical Box organizes every component we place in it equally throughout the vertical space. We will use this to keep our buttons perfectly distributed in the menu. Start by dragging a Text component into the Vertical Box. Change the Horizontal Alignment to center and the Font Size to <kbd>14</kbd>. Set the Text to say Tools Menu.</li>
<li>Now we are going to add a few buttons. Two will be used to rotate the puzzle left and right. We will also build two buttons that can be used to program additional tools in the future. Head to the Palette and search for the Button component. Drag two copies into the Vertical Box. In the Details panel, change the Padding value of both buttons to <kbd>5</kbd>.</li>
<li>Name the first button <kbd>Tools1_BTN</kbd> and the second button <kbd>Tools2_BTN</kbd>.</li>
<li>Each button now needs a text label. Use the Palette to find the Text component and drag one on to each of our buttons. For each one, change the Font Size to <kbd>10</kbd>. Change the Text to Tool 1 and Tool 2.</li>
<li>Now we will use a Horizontal Box to organize our rotation buttons. Use the search box in the Palette panel to find the Horizontal Box and drag a copy into our Vertical Box. In the Details panel, set the Size option to Fill.</li>
<li>Drag two copies of the Button component into the Horizontal Box. Name the first button <kbd>Left_BTN</kbd> and the second <kbd>Right_BTN</kbd>. Set the Padding to <kbd>5</kbd> and Size option to Fill.</li>
<li>Add a label to each button. Drag a Text component on to the left button. Set the Font Size to <kbd>10</kbd> and change the Text value to <kbd>&lt;---</kbd>.</li>
<li>Do the same for the right button, but set the Text value to <kbd>---&gt;</kbd>. </li>
</ol>
<p>We now have a nice basic interface that is ready to be programmed. The plan is to program the left and right puzzle rotation buttons in a similar fashion to the tool station we created earlier. The additional tool buttons that we created will be left without functionality for the time being. Time to take a look at the code, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/fc5d3ec1-9845-4a7f-a602-b7e6c57dac9c.png" width="1950" height="1079"/></p>
<p>ToolsWidget programming blueprint</p>
<p>To be able to rotate our puzzle, we first need to find a reference to it by going through the following steps:</p>
<ol>
<li>We need to be able to find the puzzle that is in our level as soon as the interface is created. To do this, we will use the Event Construct node. Head over to the Graph, and create one using the Palette panel, if there isn't one already there.</li>
<li>To find the puzzle, we are going to use a node called Get All Actors of Class. This node is able to find every copy of a specific class inside your level and dump it into a temporary array. Drag an execute line from Event Construct and drop it. Search for Get All Actors of Class, and set the Actor Class option to PuzzleCubeTest.</li>
</ol>
<ol start="3">
<li>The Out Actors output gives us an array containing any instances of PuzzleCubeTest. In this case, there is only one. To access it, we will use the Get (a copy) node. Drag a line from the Out Actors output, and create one using the menu. The node will access index 0, the first slot in the array, which should contain our one and only reference to PuzzleCubeTest.</li>
<li>Drag a line from the output of the Get node and choose Promote to Variable from the menu. This will place our puzzle reference in a variable we can use. Name the new variable ActivePuzzle. Connect the execute output from the event to the Set node that was created for our new variable.</li>
<li>With our puzzle reference in place, it is now time to create the rotation. Just like when we created our 3D button, we will use the In Delta Time output from the node to control our rotation. Create an Event Tick node if there is not one already in the blueprint.</li>
<li>Since we have to check for a button press for both the left and right button, we will need to use a Sequence node. Drag a line from the execute output of the Event Tick node, and create the Sequence node.</li>
<li>The Then 0 branch will handle the Left button, and we will use the same technique we used when we created the original rotation code. Drag a line off the Then 0 output, and create a Gate node.</li>
<li>Now we need a pressed and a released event to control the opening and closing of the gate. Head over to the Variables section of the My Blueprints panel and click on Left_BTN. Scroll to the bottom of the Details panel and click the + button next to the On Pressed and On Released options. Connect the On Pressed event to the Open input on the gate. Finally, connect the On Released event to the Close input.</li>
<li>We need to program the actual rotation using the AddActorLocalRotation node. Drag a line from the Exit output of the gate, and create the node. For the Target, head over to the Variables section and grab the Active Puzzle variable. Bring it into the blueprint and select Get from the menu. Plug it into the Target input on AddActorLocalRotation.</li>
<li>To get our Delta Rotation, we will multiply the change in time by a rotation speed. Create a new Float variable and name it Rotation Speed. Bring it into the blueprint and choose the Get option. Drag a line from its output, and create a Make Rotator node. Lastly, move the connection from the X input to the Z input.</li>
</ol>
<ol start="11">
<li>Drag from the output of Make Rotator and connect a Scale Rotator node. This node takes a rotator and multiplies it by a float value. Connect the float input to the In Delta Seconds output from Event Tick.</li>
</ol>
<ol start="12">
<li>Finally, connect the output of the Scale Rotator to the Delta Rotation input for AddActorLocalRotation, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/be612489-1035-4223-af8c-2bca2df87f43.png" width="1950" height="880"/></p>
<p>ToolsWidget puzzle rotation code</p>
<ol start="13">
<li>Repeat the steps from step 7 to step 12 for the Then 1 branch to program the right button, but this time add a <kbd>Float * Float</kbd> node between the Rotation Speed and the Make Rotator node. Set the second value to -1 to change the direction of the rotation.</li>
</ol>
<p>With the tools widget built and programmed, it's time to build the 3D widget to display it inside the level. We are going to use the same process we used to display the timer widget in the level, but this time, we will attach the 3D widget to the motion controller to give the feel of a wrist-mounted display, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a7778402-ac38-48b4-9587-0c1e7a03d959.png" style="width:20.08em;height:20.17em;" width="1050" height="1050"/></p>
<p>The ToolsWidget in action, mounted to the player's wrist</p>
<p>Right-click in the Content Browser and create a new Class Blueprint based on the Actor. Name it <kbd>3dToolsWidget</kbd>, double-click to open it, then go through the following steps:</p>
<ol>
<li>In the Components panel, use the Add Component button to add a Widget component to the Viewport.</li>
<li>In the Details panel, rename this to <kbd>ToolsWidget</kbd>.</li>
<li>In the User Interface section of Details, click on the Widget Class drop-down menu, and choose our <kbd>ToolsWidget</kbd> interface.</li>
<li>Set the X and Y values for the Draw Size to <kbd>125</kbd>.</li>
<li>Time to add the interface to our <kbd>Server17PlayerPawn</kbd>. Find the player pawn in the Content Browser and double-click it to open it.  </li>
<li>Let's add the interface to the motion controller. Click the Add Component button and search for the Child Actor component. Name it <kbd>ChildActor_ToolsWidget</kbd> and make it a child of <kbd>MotionController_L</kbd> in the hierarchy.</li>
<li>In the Details panel, set the Child Actor Class option to <kbd>3dToolsWidget</kbd>.</li>
<li>In the Viewport, use the move and rotate tools to position the widget at the left wrist, similar to a wristwatch. If you prefer to type the values in yourself, set the location values to <em>X=5</em>, <em>Y=-5</em>, and <em>Z=0</em>. For the rotation values, use <em>X=180</em>, <em>Y=0</em>, and <em>Z=-90</em>.</li>
<li>Since our interface display is quite large on the player's wrist, change the Scale values to <em>0.2</em>.</li>
</ol>
<p>By default, motion controllers do not have a way to interact with 2D interface elements since they were originally designed for mouse interaction. To add this functionality, we need to use a Widget Interaction component. This component was designed by Epic Games to be the bridge between VR controllers and traditional interfaces, and just takes a little setup to use. Start by adding a Widget Interaction component to the <kbd>Server17PlayerPawn</kbd>, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/49ffdb9c-bd53-4bef-ac5a-aa79d9c555ac.png" width="1950" height="1190"/></p>
<p>Widget Interaction component</p>
<p>We will add one of these components to each motion controller:</p>
<ol>
<li>In the Components panel, use the Add Component button to add two copies of the Widget Interaction component. Make one a child of MotionController_L and name it Widget Interaction L. Make the other a child of MotionController_R and name it Widget Interaction R. This will give the functionality to both hands.</li>
</ol>
<ol start="2">
<li>The Widget Interaction component allows us to simulate a mouse pointer. We can also simulate a mouse click with just a little bit of code. Head over to the Event Graph for our player pawn and locate our trigger code. We can add the functionality on the end of the existing sequence. Drag an execute line from from the end of the left trigger sequence, drop it, and search for the Press Pointer Key (Widget Interaction L) node. Use the Key drop-down list to choose the Left Mouse Button.</li>
<li>Drag a line from the output from the reference to Widget Interaction L that we just created, and search for the Release Pointer key node. Set the Key drop-down menu to Left Mouse Button, and connect an execute line back to the End Drag node.</li>
<li>Repeat the process for Widget Interaction R to give the same functionality to our right trigger.</li>
</ol>
<p>At this point, we can test our interface. Make sure that the rotate functionality is working and that the position at the left wrist is correct. There is one more bit of programming to do to finish this menu. Let's make it so that the menu can be toggled on and off using the menu button on the motion controller. This way, a player can hide it if they are not using it. To do this, we will need to use the MotionController (L) Shoulder event, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/35d13d92-8bb2-4de1-9587-1c7de716d6c6.png" width="1950" height="704"/></p>
<p>ToolsWidget toggle code</p>
<p>Start by creating the event node by going through the following steps:</p>
<ol>
<li>Right-click in the Event Graph for <kbd>Server17PlayerPawn</kbd> , and search for the MotionController (L) Shoulder event. Create it and position it near the rest of our button code.</li>
<li>Drag an execution line from the Pressed output and drop it. Search for the Toggle Visibility (ChildActor_ToolsWidget) and place it in the blueprint.</li>
<li>Go back to the Viewport for our player pawn, and click on the ChildActor_ToolsWidget. In the Details panel, turn off the Visibility option.</li>
</ol>
<p>And done! We have now constructed two different interface elements that make more use of 2D menu components, and we have learned how to display them in a 3D space. We have programmed them to interact with the world and added the ability to simulate mouse interaction to our motion controllers so that we can use them. Just think of all the great interactive menus you could now create for your virtual reality experiences, using either 3D objects or 2D interfaces!</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p class="mce-root">In this chapter, we learned about user experience and how HCD is just one small part of this much larger field. We explored the field of UX design and how VR has caused it to expand beyond traditional interface interactions. We also learned about the seven aspects of user experience that are important. From there, we took a look at the different types of user interfaces and learned what works best in virtual reality. Finally, we applied our new knowledge of user experience and VR-ready interfaces to design and create the interface widgets for our level.</p>
<p>In the next chapter, we will discuss how to create eye-popping visual elements for virtual reality games. Like gameplay elements and user interfaces, art for VR games has different requirements than art created for traditional video games. Optimization is key to keeping performance high and our player comfortable. We will look at some techniques for creating our lighting and visual effects, as well as what is needed to make the most of our static meshes and materials. </p>


            

            
        
    </div>



  </body></html>