<html><head></head><body>
		<div><h1 id="_idParaDest-121"><em class="italic"><a id="_idTextAnchor127"/>Chapter 9</em>: Working with PassManager and AnalysisManager</h1>
			<p>In the previous section of this book, <em class="italic">Frontend Development</em>, we began with an introduction to the internals of Clang, which is LLVM's official frontend for the C family of programming languages. We went through various projects, involving skills and knowledge, that can help you to deal with problems that are tightly coupled with source code. </p>
			<p>In this part of the book, we will be working with <strong class="bold">LLVM IR</strong> – a target-independent <strong class="bold">intermediate representation</strong> (<strong class="bold">IR</strong>) for compiler optimization and code generation. Compared to Clang's <strong class="bold">Abstract Syntax Tree</strong> (<strong class="bold">AST</strong>), LLVM IR provides a different level of abstraction by encapsulating extra execution details to enable more powerful program analyses and transformations. In addition to the design of LLVM IR, there is a mature ecosystem around this IR format, which provides countless resources, such as libraries, tools, and algorithm implementations. We will cover a variety of topics in LLVM IR, including the most common LLVM Pass development, using and writing program analysis, and the best practices and tips for working with LLVM IR APIs. Additionally, we will review more advanced skills such as <strong class="bold">Program Guided Optimization</strong> (<strong class="bold">PGO</strong>) and sanitizer development.</p>
			<p>In this chapter, we are going to talk about writing a transformation <strong class="bold">Pass</strong> and program analysis for the new <strong class="bold">PassManager</strong>. LLVM Pass is one of the most fundamental, and crucial, concepts within the entire project. It allows developers to encapsulate program processing logic into a modular unit that can be freely composed with other Passes by the <strong class="bold">PassManager</strong>, depending on the situation. In terms of the design of the Pass infrastructure, LLVM has actually gone through an overhaul of both PassManager and AnalysisManager to improve their runtime performance and optimization quality. The new PassManager uses a quite different interface for its enclosing Passes. This new interface, however, is not backward-compatible to the legacy one, meaning you cannot run legacy Passes in the new PassManager and vice versa. What is worse, there aren't many learning resources online that talk about this new interface, even though, now, they are enabled, by default, in both LLVM and Clang. The content of this chapter will fill this gap and provide you with an up-to-date guide to this crucial subsystem in LLVM.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Writing an LLVM Pass for the new PassManager</li>
				<li>Working with the new AnalysisManager</li>
				<li>Learning instrumentations in the new PassManager</li>
			</ul>
			<p>With the knowledge learned from this chapter, you should be able to write an LLVM Pass, using the new Pass infrastructure, to transform or even optimize your input code. You can also further improve the quality of your Pass by leveraging the analysis data provided by LLVM's program analysis framework.</p>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor128"/>Technical requirements</h1>
			<p>In this chapter, we will, primarily, use a command-line utility, called <code>opt</code>, to test our Passes. You can build it using a command like this:</p>
			<pre>$ ninja opt</pre>
			<p>The code example for this chapter can be found at <a href="https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter09">https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter09</a>.</p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor129"/>Writing an LLVM Pass for the new PassManager</h1>
			<p>A <strong class="bold">Pass in LLVM</strong> is the<a id="_idIndexMarker411"/> basic unit that is required to<a id="_idIndexMarker412"/> perform certain actions against LLVM IR. It is<a id="_idIndexMarker413"/> similar to a single production step in a factory, where the products that need to be processed are LLVM IR and the factory workers are the Passes. In the same way that a normal factory usually has multiple manufacturing steps, LLVM also consists of multiple Passes that are executed in sequential<a id="_idIndexMarker414"/> order, called the <strong class="bold">Pass pipeline</strong>. <em class="italic">Figure 9.1</em> shows an example of the Pass pipeline:</p>
			<div><div><img src="img/Figure_9.1_B14590.jpg" alt="Figure 9.1 – An example of the LLVM Pass pipeline and its intermediate results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – An example of the LLVM Pass pipeline and its intermediate results</p>
			<p>In the preceding <a id="_idIndexMarker415"/>diagram, multiple Passes are arranged in a <a id="_idIndexMarker416"/>straight line. The LLVM IR for the <code>foo</code> function is processed by one Pass after another. <code>foo</code> and replaces an arithmetic multiplication (<code>mul</code>) by 2 with left shifting (<code>shl</code>) by 1, which is considered easier than multiplication in most hardware architectures. In addition, this figure also illustrates that the <strong class="bold">code generation</strong> steps are modeled as Passes. Code generation in LLVM transforms LLVM IR, which is target independent, into assembly code for certain hardware architecture (for example, <strong class="bold">x86_64</strong> in <em class="italic">Figure 9.1</em>). Each detailed procedure, such as the register allocation, instruction selection, or instruction scheduling, is encapsulated into a single Pass and is executed in a certain order.</p>
			<p class="callout-heading">Code generation Passes</p>
			<p class="callout">Passes for code generation have a different API than normal LLVM IR Passes. Additionally, during the code generation phase, LLVM IR is actually converted into another kind<a id="_idIndexMarker417"/> of IR, called <strong class="bold">Machine IR</strong> (<strong class="bold">MIR</strong>). However, in this chapter, we will only be covering LLVM IR and its Passes.</p>
			<p>This Pass pipeline is conceptually managed <a id="_idIndexMarker418"/>by an infrastructure called <strong class="bold">PassManager</strong>. PassManager owns the plan – their execution order, for example – to run these Passes. Conventionally, we actually use the terms <em class="italic">Pass pipeline</em> and <em class="italic">PassManager</em> interchangeably since they have nearly identical missions. In the <em class="italic">Learning instrumentations in the new PassManager</em> section, we will go into more detail about the pipeline itself and discuss how to customize the execution order of these enclosing Passes.</p>
			<p>Code transformations in modern compilers can be complex. Because of this, multiple transformation Passes might need the same set of program information, which is called <strong class="bold">analysis</strong> in LLVM, in <a id="_idIndexMarker419"/>order to do their work. Furthermore, to achieve maximum efficiency, LLVM also <em class="italic">caches</em> this analysis data so that it can be reused if possible. However, since a transformation Pass might change the IR, some cached analysis data, which was previously collected, might be outdated after running that Pass. To solve these challenges, in addition to PassManager, LLVM has also created <strong class="bold">AnalysisManager</strong> to manage everything related to program analysis. We will go deeper into AnalysisManager in the <em class="italic">Working with the new AnalysisManager</em> section.</p>
			<p>As mentioned in the<a id="_idIndexMarker420"/> introduction of this chapter, LLVM has <a id="_idIndexMarker421"/>gone through a series of overhauls on its Pass and PassManager (and AnalysisManager) infrastructure. The new infrastructure runs faster and generates results with better quality. Nevertheless, the new Pass differs in many places from the old one; we will briefly explain these differences along the way. However, aside from that, we will only be discussing the new Pass infrastructure, by default, for the rest of the chapter.</p>
			<p>In this section, we will show you how to develop a simple Pass for the new PassManager. As usual, we will begin with a description of the sample project we are about to use. Then, we will show you the steps to create a Pass that can be dynamically loaded from a plugin into the Pass pipeline, which was mentioned earlier, using the <code>opt</code> utility.</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor130"/>Project overview</h2>
			<p>In this section, the sample <a id="_idIndexMarker422"/>project we are using is called <code>noalias</code> attribute to every function parameter that has a pointer type. Effectively, it adds a <code>restrict</code> keyword to the function parameters in C code. First, let's explain what the <code>restrict</code> keyword does.</p>
			<p class="callout-heading">The restrict keyword in C and C++</p>
			<p class="callout">The <code>restrict</code> keyword was introduced in C99. However, it doesn't have a counterpart in C++. Nevertheless, mainstream compilers such as Clang, GCC, and MSVS all support the same functionality in C++. For example, in Clang and GCC, you can use <code>__restrict__</code> or <code>__restrict</code> in C++ code and it has the same effect as <code>restrict</code> in C.</p>
			<p>The <code>restrict</code> keyword can also be used alongside pointer type variables in C. In the most common cases, it is used with pointer type function parameters. The following is an example:</p>
			<pre>int foo(int* <strong class="bold">restrict</strong> x, int* <strong class="bold">restrict</strong> y) {
  *x = *y + 1;
  return *y;
}</pre>
			<p>Essentially, this<a id="_idIndexMarker423"/> additional attribute tells the compiler that argument <code>x</code> will never point to the <em class="italic">same memory region</em> as argument <code>y</code>. In other words, programmers can use this keyword to <em class="italic">persuade</em> the compilers that they will <em class="italic">never</em> call the <code>foo</code> function, as follows:</p>
			<pre>…
// Programmers will NEVER write the following code
int main() {
  int V = 1;
  return <strong class="bold">foo(&amp;V, &amp;V)</strong>;
}</pre>
			<p>The rationale behind this is that if the compiler knows that two pointers – in this case, the two pointer arguments – will never point to the same memory region, it can do more <em class="italic">aggressive</em> optimizations. To give you a more concrete understanding of this, if you compare the assembly code of the <code>foo</code> function with and without the <code>restrict</code> keyword, the latter version takes five instructions to execute (on x86_64):</p>
			<pre>foo:                                    
     mov   eax, dword ptr [rsi]
     add   eax, 1
     mov   dword ptr [rdi], eax
     mov   eax, dword ptr [rsi]
     ret</pre>
			<p>The version with the <code>restrict</code> keyword added only takes four instructions:</p>
			<pre>foo:                                    
     mov   eax, dword ptr [rsi]
     lea   ecx, [rax + 1]
     mov   dword ptr [rdi], ecx
     ret</pre>
			<p>Although the<a id="_idIndexMarker424"/> difference here seems subtle, in the version without <code>restrict</code>, the compiler needs to insert an extra memory load to assure that the last argument <code>*y</code> (in the original C code) always reads the latest value. This extra cost might gradually accumulate in a more complex code base and, eventually, create a performance bottleneck.</p>
			<p>Now, you have learned how <code>restrict</code> works and its importance for ensuring good performance. In LLVM IR, there is also a corresponding directive to model the <code>restrict</code> keyword: the <code>noalias</code> attribute. This attribute is attached to the pointer function parameters if hints such as <code>restrict</code> have been given by programmers in the original source code. For example, the <code>foo</code> function (with the <code>restrict</code> keywords) can be translated into the following LLVM IR:</p>
			<pre>define i32 @foo(i32* <strong class="bold">noalias</strong> %0, i32* <strong class="bold">noalias</strong> %1) {
  %3 = load i32, i32* %1
  %4 = add i32 %3, 1
  store i32 %4, i32* %0
  ret i32 %3
}</pre>
			<p>Furthermore, we can also generate the LLVM IR code of the <code>foo</code> function <em class="italic">without</em> <code>restrict</code> in C code, as follows:</p>
			<pre>define i32 @foo(i32* %0, i32* %1) {
  %3 = load i32, i32* %1
  %4 = add i32 %3, 1
  store i32 %4, i32* %0
  <strong class="bold">%5 = load i32, i32* %1</strong>
  ret i32 <strong class="bold">%5</strong>
}</pre>
			<p>Here, you will find that there is an extra memory load (as shown in the highlighted instruction of the preceding snippet), which is similar to what happened to the assembly examples from earlier. That is, LLVM is unable to perform more aggressive optimization to remove that memory load since it's not sure whether those pointers overlap each other.</p>
			<p>In this section, we<a id="_idIndexMarker425"/> are going to write a Pass to add a <code>noalias</code> attribute to every pointer argument of a function. The Pass will be built as a plugin, and once it's loaded into <code>opt</code>, users can use the <code>--passes</code> argument to explicitly trigger <code>StrictOpt</code>, as follows:</p>
			<pre>$ opt <strong class="bold">--load-pass-plugin=StrictOpt.so</strong> \
      <strong class="bold">--passes="function(strict-opt)"</strong> \
      -S -o – test.ll</pre>
			<p>Alternatively, we can make <code>StrictOpt</code> run before other optimizations if the optimization level is greater or equal to <code>-O3</code>. The following is an example:</p>
			<pre>$ opt <strong class="bold">-O3</strong> <strong class="bold">--enable-new-pm</strong> \
      <strong class="bold">--load-pass-plugin=StrictOpt.so</strong> \
      -S -o – test.ll</pre>
			<p>We will show you how to switch between these two modes shortly.</p>
			<p class="callout-heading">A demo-only Pass</p>
			<p class="callout">Note that <code>StrictOpt</code> is merely a demo-only Pass, and adding <code>noalias</code> to every pointer function argument is absolutely <em class="italic">not</em> the thing you should do in real-world use cases. This is because it<a id="_idIndexMarker426"/> might break the <strong class="bold">correctness</strong> of the target program.</p>
			<p>In the next section, we will show you detailed steps of how to create this Pass.</p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor131"/>Writing the StrictOpt Pass</h2>
			<p>The following<a id="_idIndexMarker427"/> instructions will take you through the process of developing the core Pass logic before covering how to register <code>StrictOpt</code> into the Pass pipeline dynamically:</p>
			<ol>
				<li>We only have two source files this time: <code>StrictOpt.h</code> and <code>StrictOpt.cpp</code>. In the former file, we place the skeleton of the <code>StrictOpt</code> Pass:<pre>#include "llvm/IR/PassManager.h"
struct StrictOpt : public <code>Function</code> IR unit. The <code>run</code> method is the primary entry point for this Pass, which we are going to fill in later. It takes two arguments: a <code>Function</code> class that we will work on and a <code>FunctionAnalysisManager</code> class that can give you analysis data. It returns a <code>PreservedAnalyses</code> instance, which tells PassManager (and AnalysisManager) what analysis data was <em class="italic">invalidated</em> by this Pass.</p><p>If you have prior experience in writing LLVM Pass for the <em class="italic">legacy</em> PassManager, you might find several differences between the legacy Pass and the new Pass:</p><p>a) The Pass class no longer derives from one of the <code>FunctionPass</code>, <code>ModulePass</code>, or <code>LoopPass</code>. Instead, the Passes running on different IR units are all deriving from <code>PassInfoMixin&lt;YOUR_PASS&gt;</code>. In fact, deriving from <code>PassInfoMixin</code> is <em class="italic">not</em> even a requirement for a functional Pass anymore – we will leave this as an exercise for you.</p><p>b) Instead of <em class="italic">overriding</em> methods, such as <code>runOnFunction</code> or <code>runOnModule</code>, you will define a normal class member method, <code>run</code> (be aware that <code>run</code> does <em class="italic">not</em> have an <code>override</code> keyword that follows), which operates on the desired IR unit.</p><p>Overall, the new Pass has a cleaner interface compared to the legacy one. This difference also allows the new PassManager to have less overhead runtime.</p></li>
				<li>To implement <a id="_idIndexMarker428"/>the skeleton from the previous step, we are heading to <code>StrictOpt.cpp</code>. In this file, first, we create the following method definition:<pre>#include "StrictOpt.h"
using namespace llvm;
PreservedAnalyses StrictOpt::run(Function &amp;F,
                          FunctionAnalysisManager &amp;FAM) {
  return PreservedAnalyses::all(); // Just a placeholder
}</pre><p>The returned <code>PreservedAnalyses::all()</code> instance is just a placeholder that will be removed later.</p></li>
				<li>Now, we are finally creating the code to add a <code>noalias</code> attribute to the pointer function arguments. The logic is simple: for each <code>Argument</code> instance in a <code>Function</code> class, attach <code>noalias</code> if it fulfills the criteria:<pre>// Inside StrictOpt::run…
bool Modified = false;
for (auto &amp;Arg : F.<code>args()</code> method of the <code>Function</code> class will return a range of <code>Argument</code> instances representing all of the formal parameters. We check each of their types to make <a id="_idIndexMarker429"/>sure there isn't an existing <code>noalias</code> attribute (which is represented by the <code>Attribute::NoAlias</code> enum). If everything looks good, we use <code>addAttr</code> to attach <code>noalias</code>. </p><p>Here, the <code>Modified</code> flag here records whether any of the arguments were modified in this function. We will use this flag shortly.</p></li>
				<li>Certain analysis data might become outdated after a transformation Pass since the latter might change the program's IR. Therefore, when writing a Pass, we need to return a <code>PreservedAnalyses</code> instance to show which analysis was affected and should be subject to recalculation. While there are many analyses available in LLVM, we don't need to enumerate each of them. Instead, there are some handy utility functions to create <code>PreservedAnalyses</code> instances, representing <em class="italic">all analyses</em> or <em class="italic">none of the analyses</em>, such that we only need to subtract or add (un) affected analysis from it. Here is what we do in <code>StrictOpt</code>:<pre>#include "llvm/Analysis/AliasAnalysis.h"
…
// Inside StrictOpt::run…
auto PA = <code>PreservedAnalyses</code> instance, <code>PA</code>, which represents <em class="italic">all analyses</em>. Then, if the <code>Function</code> class we are working on here has been modified, we <em class="italic">discard</em> the <code>AAManager</code> analysis via the <code>abandon</code> method. <code>AAManager</code> represents<a id="_idIndexMarker430"/> the <code>noalias</code> attribute we are discussing here has strong relations with this analysis since they're working on a nearly identical <a id="_idIndexMarker431"/>problem. Therefore, if any new <code>noalias</code> attribute was generated, all the cached alias analysis data would be outdated. This is why we invalidate it using <code>abandon</code>.</p><p>Note that you can always return a <code>PreservedAnalyses::none()</code> instance, which tells AnalysisManager to mark <em class="italic">every</em> analysis as outdated if you are not sure what analyses have been affected. This comes at a cost, of course, since AnalysisManager then needs to spend extra effort to recalculate the analyses that might contain expensive computations.</p></li>
				<li>The core logic of <code>StrictOpt</code> is essentially finished. Now, we are going to show you how to dynamically register the Pass into the pipeline. In <code>StrictOpt.cpp</code>, we create a special global function, called <code>llvmGetPassPluginInfo</code>, with an outline like this:<pre>extern "C" ::llvm::<code>PassPluginLibraryInfo</code> instance, which contains various pieces<code>LLVM_PLUGIN_API_VERSION</code>) and the Pass name (<code>StrictOpt</code>). One of its most important fields is a lambda function that takes a single <code>PassBuilder&amp;</code> argument. In that particular function, we are going to insert our <code>StrictOpt</code> into a proper position within the Pass pipeline.</p><p><code>PassBuilder</code>, as its name suggests, is an entity LLVM that is used to build the Pass pipeline. In addition to its primary job, which involves configuring the pipeline according <a id="_idIndexMarker432"/>to the optimization level, it also allows developers to insert Passes into some of the places in the pipeline. Furthermore, to increase its flexibility, <code>PassBuilder</code> allows you to specify a <em class="italic">textual</em> description of the pipeline you want to run by using the <code>--passes</code> argument on <code>opt</code>, as we have seen previously. For instance, the following command<a id="_idIndexMarker433"/> will run <code>InstCombine</code>, <code>PromoteMemToReg</code>, and <code>SROA</code> (<code>opt</code> will run our Pass if <code>strict-opt</code> appears in the <code>--passes</code> argument, as follows:</p><pre>$ opt <code>registerPipelineParsingCallback</code> method in <code>PassBuilder</code>:</p><pre>…
[](PassBuilder &amp;PB) {
  using PipelineElement = typename PassBuilder::PipelineElement;
  PB.<code>registerPipelineParsingCallback</code> method takes another lambda callback <a id="_idIndexMarker434"/>as the argument. This callback is invoked whenever <code>PassBuilder</code> encounters an unrecognized Pass name while parsing the textual pipeline representation. Therefore, in our implementation, we simply insert our <code>StrictOpt</code> pass into the pipeline via <code>FunctionPassManager::addPass</code> when the unrecognized Pass name, that is, the <code>Name</code> parameter, is <code>strict-opt</code>.</p></li>
				<li>Alternatively, we also want to trigger our <code>StrictOpt</code> at the beginning of the Pass pipeline without using the textual pipeline description, as we described in the <em class="italic">Project overview</em> section. This means that the Pass will be run before other Passes after it is loaded into <code>opt</code> using the following command:<pre>$ opt -O2 --enable-new-pm \
      <code>--enable-new-pm</code> flag in the preceding command forced <code>opt</code> to use the new PassManager since it's still using the legacy one by default. We haven't used this flag before because <code>--passes</code> implicitly enables the new PassManager under the hood.)</p><p>To do this, instead of using <code>PassBuilder::registerPipelineParsingCallback</code> to register a custom (pipeline) parser callback, we are going to use <code>registerPipelineStartEPCallback</code> to handle this. Here is the alternative <a id="_idIndexMarker435"/>version of the code snippet from the previous step:</p><pre>…
[](PassBuilder &amp;PB) {
  using OptimizationLevel
    = typename PassBuilder::OptimizationLevel;
  PB.<strong class="bold">registerPipelineStartEPCallback</strong>(
    [](<strong class="bold">ModulePassManager &amp;MPM</strong>, <strong class="bold">OptimizationLevel OL</strong>) {
      if (OL.getSpeedupLevel() &gt;= 2) {
        MPM.addPass(
         <strong class="bold">createModuleToFunctionPassAdaptor</strong>(StrictOpt()));
      }
    });
}</pre></li>
			</ol>
			<p>There are several things worth noting in the preceding snippet:</p>
			<ul>
				<li>The <code>registerPipelineStartEPCallback</code> method we are using here registers a<a id="_idIndexMarker436"/> callback that can customize certain places in the Pass pipeline, called <strong class="bold">extension points</strong> (<strong class="bold">EPs</strong>). The EP we are going to customize here is one of the earliest points in the pipeline.</li>
				<li>In comparison to the lambda callback we saw in <code>registerPipelineParsingCallback</code>, the lambda callback for <code>registerPipelineStartEPCallback</code> only provides <code>ModulePassManager</code>, rather than <code>FunctionPassManager</code>, to insert our <code>StrictOpt</code> Pass, which is a function Pass. We are using <code>ModuleToFunctionPassAdapter</code> to overcome this issue.<p><code>ModuleToFunctionPassAdapter</code> is a module Pass that can run a given function Pass over a module's enclosing functions. It is suitable for running a function Pass in contexts where only <code>ModulePassManager</code> is available, such as in this<a id="_idIndexMarker437"/> scenario. The <code>createModuleToFunctionPassAdaptor</code> function highlighted in the preceding code is used to create a new <code>ModuleToFunctionPassAdapter</code> instance from a specific function Pass.</p></li>
				<li>Finally, in this version, we are only enabling <code>StrictOpt</code> when the optimization level is greater or equal to <code>-O2</code>. Therefore, we leverage the <code>OptimizationLevel</code> argument passing into the lambda callback to determine whether we want to insert <code>StrictOpt</code> into the pipeline or not.<p>With these Pass registration steps, we have also learned how to trigger our <code>StrictOpt</code> without explicitly specifying the textual Pass pipeline.</p></li>
			</ul>
			<p>To summarize, in this section, we learned the essentials of the LLVM Pass and Pass pipeline. Through the <code>StrictOpt</code> project, we have learned how to develop a Pass – which is also encapsulated as a plugin – for the new PassManager and how to dynamically register it against the Pass pipeline in <code>opt</code> in two different ways: first, by triggering the Pass explicitly via a textual description, and second, by running it at a certain time point (EP) in the pipeline. We also learned how to invalidate analyses depending on the changes made in the Pass. These skills can help you develop high-quality and modern LLVM Passes to process IR in a composable fashion with maximum flexibility. In the next section, we will dive into the program analysis infrastructure of LLVM. This greatly improves the capability of normal LLVM transformation Passes.</p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor132"/>Working with the new AnalysisManager</h1>
			<p>Modern compiler<a id="_idIndexMarker438"/> optimizations can be complex. They usually require lots of information from the target program in order to make correct decisions and optimal transformations. For example, in the <em class="italic">Writing an LLVM Pass for the new PassManager</em> section, LLVM used the <code>noalias</code> attribute to calculate memory aliasing information, which might eventually be used to remove redundant memory loads. </p>
			<p>Some of this<a id="_idIndexMarker439"/> information – called <strong class="bold">analysis</strong>, in LLVM – is expensive to evaluate. In addition, a single analysis might also depend on other analyses. Therefore, LLVM creates an <strong class="bold">AnalysisManager</strong> component<a id="_idIndexMarker440"/> to handle all tasks related to program analysis in LLVM. In this section, we are going to show you how to use AnalysisManager in your own Passes for the sake of writing more powerful and sophisticated program transformations or analyses. We will also use a sample project, <strong class="bold">HaltAnalyzer</strong>, to drive<a id="_idIndexMarker441"/> our tutorial here. The next section will provide you with an overview of HaltAnalyzer before moving on to the detailed development steps.</p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor133"/>Overview of the project</h2>
			<p>HaltAnalyzer is set<a id="_idIndexMarker442"/> up in a scenario where target programs are using a special function, <code>my_halt</code>, that terminates the program execution when it is called. The <code>my_halt</code> function is similar to the <code>std::terminate</code> function, or the <code>assert</code> function when its sanity check fails.</p>
			<p>The job of HaltAnalyzer is to analyze the program to find basic blocks that are <em class="italic">guaranteed to be unreachable</em> because of the <code>my_halt</code> function. To be more specific, let's take the following C code as an example:</p>
			<pre>int foo(int x, int y) {
  if (x &lt; 43) {
    my_halt();
    <strong class="bold">if (y &gt; 45)</strong>
      <strong class="bold">return x + 1;</strong>
    <strong class="bold">else {</strong>
      <strong class="bold">bar();</strong>
      <strong class="bold">return x;</strong>
    <strong class="bold">}</strong>
  } else {
    return y;
  }
}</pre>
			<p>Because <code>my_halt</code> was called at the beginning of the true block for the <code>if (x &lt; 43)</code> statement, the code highlighted in the preceding snippet will never be executed (that is, <code>my_halt</code> stopped all of the program executions before even getting to those lines). </p>
			<p>HaltAnalyzer should identify these basic blocks and print out warning messages to <code>stderr</code>. Just like the sample project from the previous section, HaltAnalyzer is also a function Pass wrapped inside a plugin. Therefore, if we use the preceding snippet as the input to our HaltAnalyzer<a id="_idIndexMarker443"/> Pass, it should print out the following messages:</p>
			<pre>$ opt --enable-new-pm --load-pass-plugin ./HaltAnalyzer.so \
      --disable-output ./test.ll
[WARNING] <strong class="bold">Unreachable BB: label %if.else</strong>
[WARNING] <strong class="bold">Unreachable BB: label %if.then2</strong>
<strong class="bold">$</strong></pre>
			<p>The <code>%if.else</code> and <code>%if.then2</code> strings are just names for the basic blocks in the <code>if (y &gt; 45)</code> statement (you might see different names on your side). Another thing worth noting is the <code>--disable-output</code> command-line flag. By default, the <code>opt</code> utility will print out the binary form of LLVM IR (that is, the LLVM bitcode) anyway unless users redirect the output to other places via the <code>-o</code> flag. Using the aforementioned flag is merely to tell <code>opt</code> not to do that since we are not interested in the final content of LLVM IR (because we are not going to modify it) this time.</p>
			<p>Although the algorithm of HaltAnalyzer seems pretty simple, writing it from scratch might be a pain. That's why we are leveraging one of the analyses provided by LLVM: the<strong class="bold"> Dominator Tree (DT)</strong>. The concept of <strong class="bold">Control Flow Graph</strong> (<strong class="bold">CFG</strong>) domination has<a id="_idIndexMarker444"/> been <a id="_idIndexMarker445"/>taught in most entry-level compiler classes, so we are not going to explain it in depth here. Simply speaking, if we say a basic block <em class="italic">dominates</em> another block, every execution flow that arrives at the latter is guaranteed to go through the former first. A DT is one of the most important and commonly used analyses in LLVM; most control flow-related transformations cannot live without it.</p>
			<p>Putting this idea into <a id="_idIndexMarker446"/>HaltAnalyzer, we are simply looking for all of the basic blocks that are dominated by the basic blocks that contain a function call to <code>my_halt</code> (we are excluding the basic blocks that contain the <code>my_halt</code> call sites from the warning messages). In the next section, we will show you detailed instructions on how to write HaltAnalyzer.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor134"/>Writing the HaltAnalyzer Pass</h2>
			<p>In this project, we <a id="_idIndexMarker447"/>will only create a single source file, <code>HaltAnalyzer.cpp</code>. Most of the infrastructure, including <code>CMakeListst.txt</code>, can be reused from the <code>StrictOpt</code> project in the previous section:</p>
			<ol>
				<li value="1">Inside <code>HaltAnalyzer.cpp</code>, first, we create the following Pass skeleton:<pre>class HaltAnalyzer : public PassInfoMixin&lt;HaltAnalyzer&gt; {
  static constexpr const char* HaltFuncName = "my_halt";
  // All the call sites to "my_halt"
  SmallVector&lt;Instruction*, 2&gt; <code>run</code> method that we saw in the previous section, we are creating an additional method, <code>findHaltCalls</code>, which will collect all of the <code>Instruction</code> calls to <code>my_halt</code> in the current function and store them inside the <code>Calls</code> vector.</p></li>
				<li>Let's implement <code>findHaltCalls</code> first:<pre>void HaltAnalyzer::findHaltCalls(Function &amp;F) {
  Calls.clear();
  for (auto &amp;I : <code>llvm::instructions</code> to iterate through every <code>Instruction</code> call in the current function and check them one by one. If the <code>Instruction</code> call is a <code>CallInst</code> – representing a typical function call site – and the callee name is <code>my_halt</code>, we will push it into the <code>Calls</code> vector for later use.</p><p class="callout-heading">Function name mangling</p><p class="callout">Be aware that when a line of C++ code is compiled into LLVM IR or native code, the name of any symbol – including the function name – will be different from what you saw in the original source code. For example, a simple function that has the name of <em class="italic">foo</em> and takes no argument <a id="_idIndexMarker449"/>might have <em class="italic">_Z3foov</em> as its name in LLVM IR. We call such a transformation in C++ <strong class="bold">name mangling</strong>. Different platforms also adopt different name mangling schemes. For example, in Visual Studio, the same function name becomes <em class="italic">?foo@@YAHH@Z</em> in LLVM IR.</p></li>
				<li>Now, let's go back to the <code>HaltAnalyzer::run</code> method. There are two things we are going to do. We will collect the call sites to <code>my_halt</code> via <code>findHaltCalls</code>, which we just wrote, and then retrieve the DT analysis data:<pre>#include "llvm/IR/Dominators.h"
…
PreservedAnalyses
HaltAnalyzer::run(Function &amp;F, <code>FunctionAnalysisManager</code> type argument to retrieve specific analysis data (in this case, <code>DominatorTree</code>) for a specific <code>Function</code> class.</p><p>Although, so far, we have (kind of) used the words <em class="italic">analysis</em> and <em class="italic">analysis data</em> interchangeably, in a real LLVM implementation, they are actually two different entities. Take the DT that we are using here as an example:</p><p>a) <code>Function</code>. In other words, it is the one that <em class="italic">performs</em> the analysis.</p><p>b) <code>DominatorTreeAnalysis</code>. This is just static data that will be cached by AnalysisManager until it is invalidated.</p><p>Furthermore, LLVM asks every analysis to clarify its affiliated result type via the <code>Result</code> member type. For example, <code>DominatorTreeAnalysis::Result</code> is equal to <code>DominatorTree</code>.</p><p>To make this even more formal, to associate the analysis data of an analysis class, <code>T</code>, with a <code>Function</code> variable, <code>F</code>, we can use the following snippet:</p><pre>// `FAM` is a FunctionAnalysisManager
typename <strong class="bold">T::Result</strong> &amp;Data = FAM.getResult&lt;<strong class="bold">T</strong>&gt;(F);</pre></li>
				<li>After we retrieve <code>DominatorTree</code>, it's time to find all of the basic blocks dominated by<a id="_idIndexMarker452"/> the <code>Instruction</code> call sites that we collected earlier:<pre>PreservedAnalyses
HaltAnalyzer::run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {
  …
  SmallVector&lt;BasicBlock*, 4&gt; DomBBs;
  for (auto *I : Calls) {
    auto *BB = I-&gt;getParent();
    DomBBs.clear();
    DT.<code>DominatorTree::getDescendants</code> method, we can retrieve all of the basic blocks dominated by a <code>my_halt</code> call site. Note that the results from <code>getDescendants</code> will also contain the block you put into the query (in this case, the block containing the <code>my_halt</code> call sites), so we need to exclude it before printing the basic block name using the <code>BasicBlock::printAsOperand</code> method.</p><p>With the ending<a id="_idIndexMarker453"/> of the returning <code>PreservedAnalyses::all()</code>, which tells AnalysisManager that this Pass does not invalidate any analysis since we don't modify the IR at all, we will wrap up the <code>HaltAnalyzer::run</code> method here.</p></li>
				<li>Finally, we need to dynamically insert our HaltAnalyzer Pass into the Pass pipeline. We are using the same method that we did in the last section, by implementing the <code>llvmGetPassPluginInfo</code> function and using <code>PassBuilder</code> to put our Pass at one of the EPs in the pipeline:<pre>extern "C" ::llvm::PassPluginLibraryInfo LLVM_ATTRIBUTE_WEAK
llvmGetPassPluginInfo() {
  return {
    LLVM_PLUGIN_API_VERSION, "HaltAnalyzer", "v0.1",
    [](PassBuilder &amp;PB) {
      using OptimizationLevel
        = typename PassBuilder::OptimizationLevel;
      PB.<code>StrictOpt</code> in the previous section, we are using <code>registerOptimizerLastEPCallback</code> to insert HaltAnalyzer <em class="italic">after</em> all of the other optimization Passes. The rationale behind this is that some optimizations<a id="_idIndexMarker454"/> might move basic blocks around, so prompting warnings too early might not be very useful. Nevertheless, we are still leveraging <code>ModuletoFunctionPassAdaptor</code> to wrap around our Pass; this is because <code>registerOptimizerLastEPCallback</code> only provides <code>ModulePassManager</code> for us to add our Pass, which is a function Pass.</p></li>
			</ol>
			<p>These are all the necessary steps to implement our HaltAnalyzer. Now you have learned how to use LLVM's program analysis infrastructure to obtain more information about the target program in an LLVM Pass. These skills can provide you with more insight into IR when you are developing a Pass. In addition, this infrastructure allows you to reuse high-quality, off-the-shelf program analysis algorithms from LLVM instead of recreating the wheels by yourself. To browse all of the available analyses provided by LLVM, the <code>llvm/include/llvm/Analysis</code> folder in the source tree is a good starting point. Most of the header files within this folder are standalone analysis data files that you can use.</p>
			<p>In the final section of this chapter, we will show you some diagnosis techniques that are useful for debugging an LLVM Pass.</p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor135"/>Learning instrumentations in the new PassManager</h1>
			<p>PassManager <a id="_idIndexMarker455"/>and AnalysisManager in LLVM are complicated pieces of software. They manage interactions between hundreds of Passes and analyses, and it can be a challenge when we try to diagnose a problem caused by them. In addition, it's really common for a compiler engineer to fix crashes in the compiler or <strong class="bold">miscompilation </strong>bugs. In <a id="_idIndexMarker456"/>those scenarios, useful instrumentation tools that provide insights to Passes and the Pass pipeline can greatly improve the productivity of fixing those problems. Fortunately, LLVM has already provided many of those tools.</p>
			<p class="callout-heading">Miscompilation</p>
			<p class="callout"><strong class="bold">Miscompilation</strong> bugs usually refer <a id="_idIndexMarker457"/>to logical issues in the <strong class="bold">compiled program</strong>, which were introduced by compilers. For example, an overly aggressive compiler optimization removes certain loops that shouldn't be removed, causing the compiled software to malfunction, or mistakenly reorder memory barriers and create <em class="italic">race conditions</em> in the generated code.</p>
			<p>We will introduce a single tool at a time in each of the following sections. Here is the list of them:</p>
			<ul>
				<li>Printing Pass pipeline details</li>
				<li>Printing changes to the IR after each Pass</li>
				<li>Bisecting the Pass pipeline</li>
			</ul>
			<p>These tools can interact purely in the command-line interface of <code>opt</code>. In fact, you can also create <em class="italic">your own</em> instrumentation tools (without even changing the LLVM source tree!); we will leave this as an exercise for you.</p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor136"/>Printing Pass pipeline details</h2>
			<p>There are<a id="_idIndexMarker458"/> many different <code>-O1</code>, <code>-O2</code>, or <code>-Oz</code> flags we are familiar with when using <code>clang</code> (or <code>opt</code>). Each optimization level is running a <em class="italic">different set of Passes</em> and arranging them in <em class="italic">different orders</em>. In some cases, this might greatly affect the generated code, in terms of performance or correctness. Therefore, sometimes, it's crucial to know these configurations in order to gain a clear understanding of the problems we are going to deal with.</p>
			<p>To print out all the Passes and the order they are currently running in inside <code>opt</code>, we can use the <code>--debug-pass-manager</code> flag. For instance, given the following C code, <code>test.c</code>, we will see the following:</p>
			<pre>int bar(int x) {
  int y = x;
  return y * 4;
}
int foo(int z) {
  return z + z * 2;
}</pre>
			<p>We first<a id="_idIndexMarker460"/> generate the<a id="_idIndexMarker461"/> IR for it using the following command:</p>
			<pre>$ clang -O0 -Xclang -disable-O0-optnone -emit-llvm -S test.c</pre>
			<p class="callout-heading">The -disable-O0-optnone flag</p>
			<p class="callout">By default, <code>clang</code> will attach a special attribute, <code>optnone</code>, to each function under the <code>-O0</code> optimization level. This attribute will prevent any further optimization on the attached functions. Here, the <code>-disable-O0-optnone</code> (frontend) flag is preventing <code>clang</code> from attaching to this attribute.</p>
			<p>Then, we use the following command to print out all of the Passes running under the optimization level of <code>-O2</code>:</p>
			<pre>$ opt <strong class="bold">-O2</strong> --disable-output <strong class="bold">--debug-pass-manager</strong> test.ll
Starting <strong class="bold">llvm::Module pass manager</strong> run.
…
Running pass: Annotation2MetadataPass on ./test.ll
Running pass: ForceFunctionAttrsPass on ./test.ll
…
Starting <strong class="bold">llvm::Function pass manager</strong> run.
Running pass: SimplifyCFGPass on <strong class="bold">bar</strong>
Running pass: SROA on <strong class="bold">bar</strong>
<strong class="bold">Running analysis</strong>: DominatorTreeAnalysis on <strong class="bold">bar</strong>
Running pass: EarlyCSEPass on <strong class="bold">bar</strong>
…
Finished llvm::Function pass manager run.
…
Starting <strong class="bold">llvm::Function pass manager</strong> run.
Running pass: SimplifyCFGPass on <strong class="bold">foo</strong>
…
Finished llvm::Function pass manager run.
<strong class="bold">Invalidating analysis</strong>: VerifierAnalysis on ./test.ll
…
$</pre>
			<p>The preceding <a id="_idIndexMarker462"/>command-line<a id="_idIndexMarker463"/> output tells us that <code>opt</code> first runs a set of <em class="italic">module-level</em> optimizations; the ordering of those Passes (for example, <code>Annotation2MetadataPass</code> and <code>ForceFunctionAttrsPass</code>) are also listed. After that, a sequence of <em class="italic">function-level</em> optimizations is performed on the <code>bar</code> function (for example, <code>SROA</code>) before running those optimizations on the <code>foo</code> function. Furthermore, it also shows the analyses used in the pipeline (for example, <code>DominatorTreeAnalysis</code>), as well as prompting us with a message regarding they became invalidated (by a certain Pass).</p>
			<p>To sum up, <code>--debug-pass-manager</code> is a useful tool to peek into the Passes and their ordering run by the Pass pipeline at a certain optimization level. Knowing this information<a id="_idIndexMarker464"/> can give you a <a id="_idIndexMarker465"/>big picture of how Passes and analyses interact with the input IR.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor137"/>Printing changes to the IR after each Pass</h2>
			<p>To understand <a id="_idIndexMarker466"/>the<a id="_idIndexMarker467"/> effects of a particular transformation Pass on your target program, one of the most straightforward ways is to compare the IR before and after it is processed by that Pass. To be more specific, in most cases, we are interested in the <em class="italic">changes</em> made by a particular transformation Pass. For instance, if LLVM mistakenly removes a loop that it shouldn't do, we want to know <em class="italic">what</em> Pass did that, and <em class="italic">when</em> the removal happened in the Pass pipeline.</p>
			<p>By using the <code>--print-changed</code> flag (and some other supported flags that we will introduce shortly) with <code>opt</code>, we can print out the IR after each Pass if it was ever modified by that Pass. Using the <code>test.c</code> (and its IR file, <code>test.ll</code>) example code from the previous paragraph, we can use the following command to print changes, if there are any, made by each Pass:</p>
			<pre>$ opt -O2 --disable-output <strong class="bold">--print-changed</strong> ./test.ll
*** <strong class="bold">IR Dump At Start</strong>: ***
...
define dso_local i32 @<strong class="bold">bar</strong>(i32 %x) #0 {
entry:
  %x.addr = alloca i32, align 4
  %y = alloca i32, align 4
  …
  %1 = load i32, i32* %y, align 4
  %mul = mul nsw i32 %1, 4
  ret i32 %mul
}
...
*** IR Dump After <strong class="bold">VerifierPass</strong> (module) <strong class="bold">omitted because no change</strong> ***
…
...
*** IR Dump After <strong class="bold">SROA</strong> *** (function: <strong class="bold">bar</strong>)
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @bar(i32 %x) #0 {
entry:
  %mul = mul nsw i32 %x, 4
  ret i32 %mul
}
...
$</pre>
			<p>Here, we<a id="_idIndexMarker468"/> have only <a id="_idIndexMarker469"/>shown a small amount of output. However, in the highlighted part of the snippet, we can see that this tool will first print out the original IR (<code>IR Dump At Start</code>), then show the IR after it is processed by each Pass. For example, the preceding snippet shows that the <code>bar</code> function has become much shorter after the SROA Pass. If a Pass didn't modify the IR at all, it will omit the IR dump to reduce the amount of noise.</p>
			<p>Sometimes, we are only interested in the changes that have happened on a <em class="italic">particular set of functions</em>, say, the <code>foo</code> function, in this case. Instead of printing the <em class="italic">change log</em> of the entire module, we can add the <code>--filter-print-funcs=&lt;function names&gt;</code> flag to only print IR changes for a subset of functions. For example, to only print IR changes for the <code>foo</code> function, you can use the following command:</p>
			<pre>$ opt -O2 --disable-output \
          <strong class="bold">--print-changed</strong> <strong class="bold">--filter-print-funcs=foo</strong> ./test.ll</pre>
			<p>Just like <code>--filter-print-funcs</code>, sometimes, we only want to see changes made by a <em class="italic">particular set of Passes</em>, say, the SROA and <code>InstCombine</code> Passes. In that case, we can add the <code>--filter-passes=&lt;Pass names&gt;</code> flag. For example, to view only the content that is relevant to SROA and <code>InstCombine</code>, we can use the following command:</p>
			<pre>$ opt -O2 --disable-output \
          <strong class="bold">--print-changed</strong> \
          <strong class="bold">--filter-passes=SROA,InstCombinePass</strong> ./test.ll</pre>
			<p>Now you have learned how to print the IR differences among all the Passes in the pipeline, with<a id="_idIndexMarker470"/> additional <a id="_idIndexMarker471"/>filters that can further focus on a specific function or Pass. In other words, this tool can help you to easily observe the <em class="italic">progression</em> of changes throughout the Pass pipeline and quickly spot any traces that you might be interested in. In the next section, we will learn how to debug problems raised in the code optimization by <em class="italic">bisecting</em> the Pass pipeline.</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor138"/>Bisecting the Pass pipeline</h2>
			<p>In the previous <a id="_idIndexMarker472"/>section, we<a id="_idIndexMarker473"/> introduced the <code>--print-changed</code> flag, which prints out the <em class="italic">IR change log</em> throughout the Pass pipeline. We also mentioned that it is useful to call out changes that we are interested in; for instance, an invalid code transformation that caused miscompilation bugs. Alternatively, we can also <code>--opt-bisect-limit=&lt;N&gt;</code> flag in <code>opt</code> bisects the Pass pipeline by <em class="italic">disabling</em> all Passes except the first <code>N</code> ones. The following command shows an example of this:</p>
			<pre>$ opt -O2 <strong class="bold">--opt-bisect-limit=5</strong> -S <strong class="bold">-o –</strong> test.ll
BISECT: running pass (1) Annotation2MetadataPass on module (./test.ll)
BISECT: running pass (2) ForceFunctionAttrsPass on module (./test.ll)
BISECT: running pass (3) InferFunctionAttrsPass on module (./test.ll)
BISECT: running pass (4) SimplifyCFGPass on function (bar)
BISECT: <strong class="bold">running pass (5) SROA on function (bar)</strong>
BISECT: NOT running pass (6) EarlyCSEPass on function (bar)
BISECT: NOT running pass (7) LowerExpectIntrinsicPass on function (bar)
BISECT: NOT running pass (8) SimplifyCFGPass on function (foo)
BISECT: <strong class="bold">NOT running pass (9) SROA on function (foo)</strong>
BISECT: NOT running pass (10) EarlyCSEPass on function (foo)
...
define dso_local i32 @<strong class="bold">bar</strong>(i32 %x) #0 {
entry:
  %mul = mul nsw i32 %x, 4
  ret i32 %mul
}
define dso_local i32 @<strong class="bold">foo</strong>(i32 %y) #0 {
entry:
  %y.addr = alloca i32, align 4
  store i32 %y, i32* %y.addr, align 4
  %0 = load i32, i32* %y.addr, align 4
  %1 = load i32, i32* %y.addr, align 4
  %mul = mul nsw i32 %1, 2
  %add = add nsw i32 %0, %mul
  ret i32 %add
}
$</pre>
			<p>(Note that this is different from examples shown in the previous sections; the preceding command has printed both messages from <code>--opt-bisect-limit</code> and the final textual IR.)</p>
			<p>Since we implemented the <code>--opt-bisect-limit=5</code> flag, the Pass pipeline only ran the first five Passes. As you can see from the diagnostic messages, SROA was applied on <code>bar</code> but not the <code>foo</code> function, leaving the final IR of <code>foo</code> less optimal.</p>
			<p>By changing the number that follows <code>--opt-bisect-limit</code>, we can adjust the cut point until certain code changes appear or a certain bug is triggered (for example, a crash). This is particularly useful as an <em class="italic">early filtering step</em> to narrow down the original problem to a smaller range of Passes in the pipeline. Furthermore, since it uses a numeric value as the parameter, this feature fits perfectly to automating environments such as automatic crash reporting tools or performance regression tracking tools.</p>
			<p>In this section, we <a id="_idIndexMarker474"/>introduced several<a id="_idIndexMarker475"/> useful instrumentation tools in <code>opt</code> for debugging and diagnosing the Pass pipeline. These tools can greatly improve your productivity when it comes to fixing problems, such as compiler crashes, performance regressions (on the target program), and miscompilation bugs.</p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor139"/>Summary</h1>
			<p>In this chapter, we learned how to write an LLVM Pass for the new PassManager and how to use program analysis data within a Pass via the AnalysisManager. We also learned how to leverage various instrumentation tools to improve the development experiences while working with the Pass pipeline. With the skills gained from this chapter, you can now write a Pass to process LLVM IR, which can be used to transform or even optimize a program.</p>
			<p>These topics are some of the most fundamental and crucial skills to learn before starting on any IR level transformation or analysis task. If you have been working with the legacy PassManager, these skills can also help you to migrate your code to the new PassManager system, which has now been enabled by default.</p>
			<p>In the next chapter, we will show you various tips along with the best practices that you should know when using the APIs of LLVM IR.</p>
			<h1 id="_idParaDest-134"><a id="_idTextAnchor140"/>Questions</h1>
			<ol>
				<li value="1">In the <code>StrictOpt</code> example of the <em class="italic">Writing an LLVM Pass for the new PassManager</em> section, how can you write a Pass without deriving the <code>PassInfoMixin</code> class?</li>
				<li>How can you develop a custom instrumentation for the new PassManager? Additionally, how can you do this without modifying the LLVM source tree? (Hint: think about the Pass plugin that we learned about in this chapter.)</li>
			</ol>
		</div>
	</body></html>