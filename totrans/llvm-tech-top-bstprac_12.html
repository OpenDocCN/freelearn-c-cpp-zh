<html><head></head><body>
		<div id="_idContainer028">
			<h1 id="_idParaDest-121"><em class="italic"><a id="_idTextAnchor127"/>Chapter 9</em>: Working with PassManager and AnalysisManager</h1>
			<p>In the previous section of this book, <em class="italic">Frontend Development</em>, we began with an introduction to the internals of Clang, which is LLVM's official frontend for the C family of programming languages. We went through various projects, involving skills and knowledge, that can help you to deal with problems that are tightly coupled with source code. </p>
			<p>In this part of the book, we will be working with <strong class="bold">LLVM IR</strong> – a target-independent <strong class="bold">intermediate representation</strong> (<strong class="bold">IR</strong>) for compiler optimization and code generation. Compared to Clang's <strong class="bold">Abstract Syntax Tree</strong> (<strong class="bold">AST</strong>), LLVM IR provides a different level of abstraction by encapsulating extra execution details to enable more powerful program analyses and transformations. In addition to the design of LLVM IR, there is a mature ecosystem around this IR format, which provides countless resources, such as libraries, tools, and algorithm implementations. We will cover a variety of topics in LLVM IR, including the most common LLVM Pass development, using and writing program analysis, and the best practices and tips for working with LLVM IR APIs. Additionally, we will review more advanced skills such as <strong class="bold">Program Guided Optimization</strong> (<strong class="bold">PGO</strong>) and sanitizer development.</p>
			<p>In this chapter, we are going to talk about writing a transformation <strong class="bold">Pass</strong> and program analysis for the new <strong class="bold">PassManager</strong>. LLVM Pass is one of the most fundamental, and crucial, concepts within the entire project. It allows developers to encapsulate program processing logic into a modular unit that can be freely composed with other Passes by the <strong class="bold">PassManager</strong>, depending on the situation. In terms of the design of the Pass infrastructure, LLVM has actually gone through an overhaul of both PassManager and AnalysisManager to improve their runtime performance and optimization quality. The new PassManager uses a quite different interface for its enclosing Passes. This new interface, however, is not backward-compatible to the legacy one, meaning you cannot run legacy Passes in the new PassManager and vice versa. What is worse, there aren't many learning resources online that talk about this new interface, even though, now, they are enabled, by default, in both LLVM and Clang. The content of this chapter will fill this gap and provide you with an up-to-date guide to this crucial subsystem in LLVM.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Writing an LLVM Pass for the new PassManager</li>
				<li>Working with the new AnalysisManager</li>
				<li>Learning instrumentations in the new PassManager</li>
			</ul>
			<p>With the knowledge learned from this chapter, you should be able to write an LLVM Pass, using the new Pass infrastructure, to transform or even optimize your input code. You can also further improve the quality of your Pass by leveraging the analysis data provided by LLVM's program analysis framework.</p>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor128"/>Technical requirements</h1>
			<p>In this chapter, we will, primarily, use a command-line utility, called <strong class="source-inline">opt</strong>, to test our Passes. You can build it using a command like this:</p>
			<p class="source-code">$ ninja opt</p>
			<p>The code example for this chapter can be found at <a href="https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter09">https://github.com/PacktPublishing/LLVM-Techniques-Tips-and-Best-Practices-Clang-and-Middle-End-Libraries/tree/main/Chapter09</a>.</p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor129"/>Writing an LLVM Pass for the new PassManager</h1>
			<p>A <strong class="bold">Pass in LLVM</strong> is the<a id="_idIndexMarker411"/> basic unit that is required to<a id="_idIndexMarker412"/> perform certain actions against LLVM IR. It is<a id="_idIndexMarker413"/> similar to a single production step in a factory, where the products that need to be processed are LLVM IR and the factory workers are the Passes. In the same way that a normal factory usually has multiple manufacturing steps, LLVM also consists of multiple Passes that are executed in sequential<a id="_idIndexMarker414"/> order, called the <strong class="bold">Pass pipeline</strong>. <em class="italic">Figure 9.1</em> shows an example of the Pass pipeline:</p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/Figure_9.1_B14590.jpg" alt="Figure 9.1 – An example of the LLVM Pass pipeline and its intermediate results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – An example of the LLVM Pass pipeline and its intermediate results</p>
			<p>In the preceding <a id="_idIndexMarker415"/>diagram, multiple Passes are arranged in a <a id="_idIndexMarker416"/>straight line. The LLVM IR for the <strong class="source-inline">foo</strong> function is processed by one Pass after another. <strong class="bold">Pass B</strong>, for instance, performs code optimization on <strong class="source-inline">foo</strong> and replaces an arithmetic multiplication (<strong class="source-inline">mul</strong>) by 2 with left shifting (<strong class="source-inline">shl</strong>) by 1, which is considered easier than multiplication in most hardware architectures. In addition, this figure also illustrates that the <strong class="bold">code generation</strong> steps are modeled as Passes. Code generation in LLVM transforms LLVM IR, which is target independent, into assembly code for certain hardware architecture (for example, <strong class="bold">x86_64</strong> in <em class="italic">Figure 9.1</em>). Each detailed procedure, such as the register allocation, instruction selection, or instruction scheduling, is encapsulated into a single Pass and is executed in a certain order.</p>
			<p class="callout-heading">Code generation Passes</p>
			<p class="callout">Passes for code generation have a different API than normal LLVM IR Passes. Additionally, during the code generation phase, LLVM IR is actually converted into another kind<a id="_idIndexMarker417"/> of IR, called <strong class="bold">Machine IR</strong> (<strong class="bold">MIR</strong>). However, in this chapter, we will only be covering LLVM IR and its Passes.</p>
			<p>This Pass pipeline is conceptually managed <a id="_idIndexMarker418"/>by an infrastructure called <strong class="bold">PassManager</strong>. PassManager owns the plan – their execution order, for example – to run these Passes. Conventionally, we actually use the terms <em class="italic">Pass pipeline</em> and <em class="italic">PassManager</em> interchangeably since they have nearly identical missions. In the <em class="italic">Learning instrumentations in the new PassManager</em> section, we will go into more detail about the pipeline itself and discuss how to customize the execution order of these enclosing Passes.</p>
			<p>Code transformations in modern compilers can be complex. Because of this, multiple transformation Passes might need the same set of program information, which is called <strong class="bold">analysis</strong> in LLVM, in <a id="_idIndexMarker419"/>order to do their work. Furthermore, to achieve maximum efficiency, LLVM also <em class="italic">caches</em> this analysis data so that it can be reused if possible. However, since a transformation Pass might change the IR, some cached analysis data, which was previously collected, might be outdated after running that Pass. To solve these challenges, in addition to PassManager, LLVM has also created <strong class="bold">AnalysisManager</strong> to manage everything related to program analysis. We will go deeper into AnalysisManager in the <em class="italic">Working with the new AnalysisManager</em> section.</p>
			<p>As mentioned in the<a id="_idIndexMarker420"/> introduction of this chapter, LLVM has <a id="_idIndexMarker421"/>gone through a series of overhauls on its Pass and PassManager (and AnalysisManager) infrastructure. The new infrastructure runs faster and generates results with better quality. Nevertheless, the new Pass differs in many places from the old one; we will briefly explain these differences along the way. However, aside from that, we will only be discussing the new Pass infrastructure, by default, for the rest of the chapter.</p>
			<p>In this section, we will show you how to develop a simple Pass for the new PassManager. As usual, we will begin with a description of the sample project we are about to use. Then, we will show you the steps to create a Pass that can be dynamically loaded from a plugin into the Pass pipeline, which was mentioned earlier, using the <strong class="source-inline">opt</strong> utility.</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor130"/>Project overview</h2>
			<p>In this section, the sample <a id="_idIndexMarker422"/>project we are using is called <strong class="bold">StrictOpt</strong>. It is a Pass and Pass plugin that adds a <strong class="source-inline">noalias</strong> attribute to every function parameter that has a pointer type. Effectively, it adds a <strong class="source-inline">restrict</strong> keyword to the function parameters in C code. First, let's explain what the <strong class="source-inline">restrict</strong> keyword does.</p>
			<p class="callout-heading">The restrict keyword in C and C++</p>
			<p class="callout">The <strong class="source-inline">restrict</strong> keyword was introduced in C99. However, it doesn't have a counterpart in C++. Nevertheless, mainstream compilers such as Clang, GCC, and MSVS all support the same functionality in C++. For example, in Clang and GCC, you can use <strong class="source-inline">__restrict__</strong> or <strong class="source-inline">__restrict</strong> in C++ code and it has the same effect as <strong class="source-inline">restrict</strong> in C.</p>
			<p>The <strong class="source-inline">restrict</strong> keyword can also be used alongside pointer type variables in C. In the most common cases, it is used with pointer type function parameters. The following is an example:</p>
			<p class="source-code">int foo(int* <strong class="bold">restrict</strong> x, int* <strong class="bold">restrict</strong> y) {</p>
			<p class="source-code">  *x = *y + 1;</p>
			<p class="source-code">  return *y;</p>
			<p class="source-code">}</p>
			<p>Essentially, this<a id="_idIndexMarker423"/> additional attribute tells the compiler that argument <strong class="source-inline">x</strong> will never point to the <em class="italic">same memory region</em> as argument <strong class="source-inline">y</strong>. In other words, programmers can use this keyword to <em class="italic">persuade</em> the compilers that they will <em class="italic">never</em> call the <strong class="source-inline">foo</strong> function, as follows:</p>
			<p class="source-code">…</p>
			<p class="source-code">// Programmers will NEVER write the following code</p>
			<p class="source-code">int main() {</p>
			<p class="source-code">  int V = 1;</p>
			<p class="source-code">  return <strong class="bold">foo(&amp;V, &amp;V)</strong>;</p>
			<p class="source-code">}</p>
			<p>The rationale behind this is that if the compiler knows that two pointers – in this case, the two pointer arguments – will never point to the same memory region, it can do more <em class="italic">aggressive</em> optimizations. To give you a more concrete understanding of this, if you compare the assembly code of the <strong class="source-inline">foo</strong> function with and without the <strong class="source-inline">restrict</strong> keyword, the latter version takes five instructions to execute (on x86_64):</p>
			<p class="source-code">foo:                                    </p>
			<p class="source-code">     mov   eax, dword ptr [rsi]</p>
			<p class="source-code">     add   eax, 1</p>
			<p class="source-code">     mov   dword ptr [rdi], eax</p>
			<p class="source-code">     mov   eax, dword ptr [rsi]</p>
			<p class="source-code">     ret</p>
			<p>The version with the <strong class="source-inline">restrict</strong> keyword added only takes four instructions:</p>
			<p class="source-code">foo:                                    </p>
			<p class="source-code">     mov   eax, dword ptr [rsi]</p>
			<p class="source-code">     lea   ecx, [rax + 1]</p>
			<p class="source-code">     mov   dword ptr [rdi], ecx</p>
			<p class="source-code">     ret</p>
			<p>Although the<a id="_idIndexMarker424"/> difference here seems subtle, in the version without <strong class="source-inline">restrict</strong>, the compiler needs to insert an extra memory load to assure that the last argument <strong class="source-inline">*y</strong> (in the original C code) always reads the latest value. This extra cost might gradually accumulate in a more complex code base and, eventually, create a performance bottleneck.</p>
			<p>Now, you have learned how <strong class="source-inline">restrict</strong> works and its importance for ensuring good performance. In LLVM IR, there is also a corresponding directive to model the <strong class="source-inline">restrict</strong> keyword: the <strong class="source-inline">noalias</strong> attribute. This attribute is attached to the pointer function parameters if hints such as <strong class="source-inline">restrict</strong> have been given by programmers in the original source code. For example, the <strong class="source-inline">foo</strong> function (with the <strong class="source-inline">restrict</strong> keywords) can be translated into the following LLVM IR:</p>
			<p class="source-code">define i32 @foo(i32* <strong class="bold">noalias</strong> %0, i32* <strong class="bold">noalias</strong> %1) {</p>
			<p class="source-code">  %3 = load i32, i32* %1</p>
			<p class="source-code">  %4 = add i32 %3, 1</p>
			<p class="source-code">  store i32 %4, i32* %0</p>
			<p class="source-code">  ret i32 %3</p>
			<p class="source-code">}</p>
			<p>Furthermore, we can also generate the LLVM IR code of the <strong class="source-inline">foo</strong> function <em class="italic">without</em> <strong class="source-inline">restrict</strong> in C code, as follows:</p>
			<p class="source-code">define i32 @foo(i32* %0, i32* %1) {</p>
			<p class="source-code">  %3 = load i32, i32* %1</p>
			<p class="source-code">  %4 = add i32 %3, 1</p>
			<p class="source-code">  store i32 %4, i32* %0</p>
			<p class="source-code">  <strong class="bold">%5 = load i32, i32* %1</strong></p>
			<p class="source-code">  ret i32 <strong class="bold">%5</strong></p>
			<p class="source-code">}</p>
			<p>Here, you will find that there is an extra memory load (as shown in the highlighted instruction of the preceding snippet), which is similar to what happened to the assembly examples from earlier. That is, LLVM is unable to perform more aggressive optimization to remove that memory load since it's not sure whether those pointers overlap each other.</p>
			<p>In this section, we<a id="_idIndexMarker425"/> are going to write a Pass to add a <strong class="source-inline">noalias</strong> attribute to every pointer argument of a function. The Pass will be built as a plugin, and once it's loaded into <strong class="source-inline">opt</strong>, users can use the <strong class="source-inline">--passes</strong> argument to explicitly trigger <strong class="source-inline">StrictOpt</strong>, as follows:</p>
			<p class="source-code">$ opt <strong class="bold">--load-pass-plugin=StrictOpt.so</strong> \</p>
			<p class="source-code">      <strong class="bold">--passes="function(strict-opt)"</strong> \</p>
			<p class="source-code">      -S -o – test.ll</p>
			<p>Alternatively, we can make <strong class="source-inline">StrictOpt</strong> run before other optimizations if the optimization level is greater or equal to <strong class="source-inline">-O3</strong>. The following is an example:</p>
			<p class="source-code">$ opt <strong class="bold">-O3</strong> <strong class="bold">--enable-new-pm</strong> \</p>
			<p class="source-code">      <strong class="bold">--load-pass-plugin=StrictOpt.so</strong> \</p>
			<p class="source-code">      -S -o – test.ll</p>
			<p>We will show you how to switch between these two modes shortly.</p>
			<p class="callout-heading">A demo-only Pass</p>
			<p class="callout">Note that <strong class="source-inline">StrictOpt</strong> is merely a demo-only Pass, and adding <strong class="source-inline">noalias</strong> to every pointer function argument is absolutely <em class="italic">not</em> the thing you should do in real-world use cases. This is because it<a id="_idIndexMarker426"/> might break the <strong class="bold">correctness</strong> of the target program.</p>
			<p>In the next section, we will show you detailed steps of how to create this Pass.</p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor131"/>Writing the StrictOpt Pass</h2>
			<p>The following<a id="_idIndexMarker427"/> instructions will take you through the process of developing the core Pass logic before covering how to register <strong class="source-inline">StrictOpt</strong> into the Pass pipeline dynamically:</p>
			<ol>
				<li>We only have two source files this time: <strong class="source-inline">StrictOpt.h</strong> and <strong class="source-inline">StrictOpt.cpp</strong>. In the former file, we place the skeleton of the <strong class="source-inline">StrictOpt</strong> Pass:<p class="source-code">#include "llvm/IR/PassManager.h"</p><p class="source-code">struct StrictOpt : public <strong class="bold">PassInfoMixin&lt;StrictOpt&gt;</strong> {</p><p class="source-code">  PreservedAnalyses <strong class="bold">run</strong>(Function &amp;F,</p><p class="source-code">                        FunctionAnalysisManager &amp;FAM);</p><p class="source-code">};</p><p>The Pass we are writing here is a <em class="italic">function Pass</em>; namely, it runs on the <strong class="source-inline">Function</strong> IR unit. The <strong class="source-inline">run</strong> method is the primary entry point for this Pass, which we are going to fill in later. It takes two arguments: a <strong class="source-inline">Function</strong> class that we will work on and a <strong class="source-inline">FunctionAnalysisManager</strong> class that can give you analysis data. It returns a <strong class="source-inline">PreservedAnalyses</strong> instance, which tells PassManager (and AnalysisManager) what analysis data was <em class="italic">invalidated</em> by this Pass.</p><p>If you have prior experience in writing LLVM Pass for the <em class="italic">legacy</em> PassManager, you might find several differences between the legacy Pass and the new Pass:</p><p>a) The Pass class no longer derives from one of the <strong class="source-inline">FunctionPass</strong>, <strong class="source-inline">ModulePass</strong>, or <strong class="source-inline">LoopPass</strong>. Instead, the Passes running on different IR units are all deriving from <strong class="source-inline">PassInfoMixin&lt;YOUR_PASS&gt;</strong>. In fact, deriving from <strong class="source-inline">PassInfoMixin</strong> is <em class="italic">not</em> even a requirement for a functional Pass anymore – we will leave this as an exercise for you.</p><p>b) Instead of <em class="italic">overriding</em> methods, such as <strong class="source-inline">runOnFunction</strong> or <strong class="source-inline">runOnModule</strong>, you will define a normal class member method, <strong class="source-inline">run</strong> (be aware that <strong class="source-inline">run</strong> does <em class="italic">not</em> have an <strong class="source-inline">override</strong> keyword that follows), which operates on the desired IR unit.</p><p>Overall, the new Pass has a cleaner interface compared to the legacy one. This difference also allows the new PassManager to have less overhead runtime.</p></li>
				<li>To implement <a id="_idIndexMarker428"/>the skeleton from the previous step, we are heading to <strong class="source-inline">StrictOpt.cpp</strong>. In this file, first, we create the following method definition:<p class="source-code">#include "StrictOpt.h"</p><p class="source-code">using namespace llvm;</p><p class="source-code">PreservedAnalyses StrictOpt::run(Function &amp;F,</p><p class="source-code">                          FunctionAnalysisManager &amp;FAM) {</p><p class="source-code">  return PreservedAnalyses::all(); // Just a placeholder</p><p class="source-code">}</p><p>The returned <strong class="source-inline">PreservedAnalyses::all()</strong> instance is just a placeholder that will be removed later.</p></li>
				<li>Now, we are finally creating the code to add a <strong class="source-inline">noalias</strong> attribute to the pointer function arguments. The logic is simple: for each <strong class="source-inline">Argument</strong> instance in a <strong class="source-inline">Function</strong> class, attach <strong class="source-inline">noalias</strong> if it fulfills the criteria:<p class="source-code">// Inside StrictOpt::run…</p><p class="source-code">bool Modified = false;</p><p class="source-code">for (auto &amp;Arg : F.<strong class="bold">args</strong>()) {</p><p class="source-code">  if (Arg.getType()-&gt;<strong class="bold">isPointerTy</strong>() &amp;&amp;</p><p class="source-code">      !Arg.<strong class="bold">hasAttribute</strong>(Attribute::NoAlias)) {</p><p class="source-code">    Arg.<strong class="bold">addAttr</strong>(<strong class="bold">Attribute::NoAlias</strong>);</p><p class="source-code">    Modified |= true;</p><p class="source-code">  }</p><p class="source-code">}</p><p>The <strong class="source-inline">args()</strong> method of the <strong class="source-inline">Function</strong> class will return a range of <strong class="source-inline">Argument</strong> instances representing all of the formal parameters. We check each of their types to make <a id="_idIndexMarker429"/>sure there isn't an existing <strong class="source-inline">noalias</strong> attribute (which is represented by the <strong class="source-inline">Attribute::NoAlias</strong> enum). If everything looks good, we use <strong class="source-inline">addAttr</strong> to attach <strong class="source-inline">noalias</strong>. </p><p>Here, the <strong class="source-inline">Modified</strong> flag here records whether any of the arguments were modified in this function. We will use this flag shortly.</p></li>
				<li>Certain analysis data might become outdated after a transformation Pass since the latter might change the program's IR. Therefore, when writing a Pass, we need to return a <strong class="source-inline">PreservedAnalyses</strong> instance to show which analysis was affected and should be subject to recalculation. While there are many analyses available in LLVM, we don't need to enumerate each of them. Instead, there are some handy utility functions to create <strong class="source-inline">PreservedAnalyses</strong> instances, representing <em class="italic">all analyses</em> or <em class="italic">none of the analyses</em>, such that we only need to subtract or add (un) affected analysis from it. Here is what we do in <strong class="source-inline">StrictOpt</strong>:<p class="source-code">#include "llvm/Analysis/AliasAnalysis.h"</p><p class="source-code">…</p><p class="source-code">// Inside StrictOpt::run…</p><p class="source-code">auto PA = <strong class="bold">PreservedAnalyses::all</strong>();</p><p class="source-code">if (Modified)</p><p class="source-code">  PA.<strong class="bold">abandon</strong>&lt;<strong class="bold">AAManager</strong>&gt;();</p><p class="source-code">return PA;</p><p>Here, we first create a <strong class="source-inline">PreservedAnalyses</strong> instance, <strong class="source-inline">PA</strong>, which represents <em class="italic">all analyses</em>. Then, if the <strong class="source-inline">Function</strong> class we are working on here has been modified, we <em class="italic">discard</em> the <strong class="source-inline">AAManager</strong> analysis via the <strong class="source-inline">abandon</strong> method. <strong class="source-inline">AAManager</strong> represents<a id="_idIndexMarker430"/> the <strong class="bold">alias analysis</strong> in LLVM. </p><p>Without going into the details of this, the alias analysis asks whether two pointers point to the same memory region, or whether the memory regions they are pointing to overlap with each other. The <strong class="source-inline">noalias</strong> attribute we are discussing here has strong relations with this analysis since they're working on a nearly identical <a id="_idIndexMarker431"/>problem. Therefore, if any new <strong class="source-inline">noalias</strong> attribute was generated, all the cached alias analysis data would be outdated. This is why we invalidate it using <strong class="source-inline">abandon</strong>.</p><p>Note that you can always return a <strong class="source-inline">PreservedAnalyses::none()</strong> instance, which tells AnalysisManager to mark <em class="italic">every</em> analysis as outdated if you are not sure what analyses have been affected. This comes at a cost, of course, since AnalysisManager then needs to spend extra effort to recalculate the analyses that might contain expensive computations.</p></li>
				<li>The core logic of <strong class="source-inline">StrictOpt</strong> is essentially finished. Now, we are going to show you how to dynamically register the Pass into the pipeline. In <strong class="source-inline">StrictOpt.cpp</strong>, we create a special global function, called <strong class="source-inline">llvmGetPassPluginInfo</strong>, with an outline like this:<p class="source-code">extern "C" ::llvm::<strong class="bold">PassPluginLibraryInfo</strong> LLVM_ATTRIBUTE_WEAK</p><p class="source-code"><strong class="bold">llvmGetPassPluginInfo</strong>() {</p><p class="source-code">  return {</p><p class="source-code">    LLVM_PLUGIN_API_VERSION, "StrictOpt", "v0.1",</p><p class="source-code">    <strong class="bold">[](PassBuilder &amp;PB) {…}</strong></p><p class="source-code">  };</p><p class="source-code">}</p><p>This function returns a <strong class="source-inline">PassPluginLibraryInfo</strong> instance, which contains various pieces<strong class="bold"> </strong>of information such as the plugin API version (<strong class="source-inline">LLVM_PLUGIN_API_VERSION</strong>) and the Pass name (<strong class="source-inline">StrictOpt</strong>). One of its most important fields is a lambda function that takes a single <strong class="source-inline">PassBuilder&amp;</strong> argument. In that particular function, we are going to insert our <strong class="source-inline">StrictOpt</strong> into a proper position within the Pass pipeline.</p><p><strong class="source-inline">PassBuilder</strong>, as its name suggests, is an entity LLVM that is used to build the Pass pipeline. In addition to its primary job, which involves configuring the pipeline according <a id="_idIndexMarker432"/>to the optimization level, it also allows developers to insert Passes into some of the places in the pipeline. Furthermore, to increase its flexibility, <strong class="source-inline">PassBuilder</strong> allows you to specify a <em class="italic">textual</em> description of the pipeline you want to run by using the <strong class="source-inline">--passes</strong> argument on <strong class="source-inline">opt</strong>, as we have seen previously. For instance, the following command<a id="_idIndexMarker433"/> will run <strong class="source-inline">InstCombine</strong>, <strong class="source-inline">PromoteMemToReg</strong>, and <strong class="source-inline">SROA</strong> (<strong class="bold">SROA</strong>: <strong class="bold">Scalar Replacement of Aggregates</strong>) in sequential order:</p><p class="source-code">$ opt <strong class="bold">--passes="instcombine,mem2reg,sroa"</strong> test.ll -S -o –</p><p>What we are going to do in this step is ensure that after the plugin has been loaded, <strong class="source-inline">opt</strong> will run our Pass if <strong class="source-inline">strict-opt</strong> appears in the <strong class="source-inline">--passes</strong> argument, as follows:</p><p class="source-code">$ opt <strong class="bold">--passes="strict-opt"</strong> test.ll -S -o –</p><p>To do this, we leverage the <strong class="source-inline">registerPipelineParsingCallback</strong> method in <strong class="source-inline">PassBuilder</strong>:</p><p class="source-code">…</p><p class="source-code">[](PassBuilder &amp;PB) {</p><p class="source-code">  using PipelineElement = typename PassBuilder::PipelineElement;</p><p class="source-code">  PB.<strong class="bold">registerPipelineParsingCallback</strong>(</p><p class="source-code">    <strong class="bold">[](StringRef Name,</strong></p><p class="source-code">       <strong class="bold">FunctionPassManager &amp;FPM, ArrayRef&lt;PipelineElement&gt;){</strong></p><p class="source-code">      if (Name == "strict-opt") {</p><p class="source-code">        FPM.<strong class="bold">addPass</strong>(StrictOpt());</p><p class="source-code">        return true;</p><p class="source-code">      }</p><p class="source-code">      return false;</p><p class="source-code">    <strong class="bold">}</strong>);</p><p class="source-code">}</p><p>The <strong class="source-inline">registerPipelineParsingCallback</strong> method takes another lambda callback <a id="_idIndexMarker434"/>as the argument. This callback is invoked whenever <strong class="source-inline">PassBuilder</strong> encounters an unrecognized Pass name while parsing the textual pipeline representation. Therefore, in our implementation, we simply insert our <strong class="source-inline">StrictOpt</strong> pass into the pipeline via <strong class="source-inline">FunctionPassManager::addPass</strong> when the unrecognized Pass name, that is, the <strong class="source-inline">Name</strong> parameter, is <strong class="source-inline">strict-opt</strong>.</p></li>
				<li>Alternatively, we also want to trigger our <strong class="source-inline">StrictOpt</strong> at the beginning of the Pass pipeline without using the textual pipeline description, as we described in the <em class="italic">Project overview</em> section. This means that the Pass will be run before other Passes after it is loaded into <strong class="source-inline">opt</strong> using the following command:<p class="source-code">$ opt -O2 --enable-new-pm \</p><p class="source-code">      <strong class="bold">--load-pass-plugin=StrictOpt.so</strong> test.ll -S -o –</p><p>(The <strong class="source-inline">--enable-new-pm</strong> flag in the preceding command forced <strong class="source-inline">opt</strong> to use the new PassManager since it's still using the legacy one by default. We haven't used this flag before because <strong class="source-inline">--passes</strong> implicitly enables the new PassManager under the hood.)</p><p>To do this, instead of using <strong class="source-inline">PassBuilder::registerPipelineParsingCallback</strong> to register a custom (pipeline) parser callback, we are going to use <strong class="source-inline">registerPipelineStartEPCallback</strong> to handle this. Here is the alternative <a id="_idIndexMarker435"/>version of the code snippet from the previous step:</p><p class="source-code">…</p><p class="source-code">[](PassBuilder &amp;PB) {</p><p class="source-code">  using OptimizationLevel</p><p class="source-code">    = typename PassBuilder::OptimizationLevel;</p><p class="source-code">  PB.<strong class="bold">registerPipelineStartEPCallback</strong>(</p><p class="source-code">    [](<strong class="bold">ModulePassManager &amp;MPM</strong>, <strong class="bold">OptimizationLevel OL</strong>) {</p><p class="source-code">      if (OL.getSpeedupLevel() &gt;= 2) {</p><p class="source-code">        MPM.addPass(</p><p class="source-code">         <strong class="bold">createModuleToFunctionPassAdaptor</strong>(StrictOpt()));</p><p class="source-code">      }</p><p class="source-code">    });</p><p class="source-code">}</p></li>
			</ol>
			<p>There are several things worth noting in the preceding snippet:</p>
			<ul>
				<li>The <strong class="source-inline">registerPipelineStartEPCallback</strong> method we are using here registers a<a id="_idIndexMarker436"/> callback that can customize certain places in the Pass pipeline, called <strong class="bold">extension points</strong> (<strong class="bold">EPs</strong>). The EP we are going to customize here is one of the earliest points in the pipeline.</li>
				<li>In comparison to the lambda callback we saw in <strong class="source-inline">registerPipelineParsingCallback</strong>, the lambda callback for <strong class="source-inline">registerPipelineStartEPCallback</strong> only provides <strong class="source-inline">ModulePassManager</strong>, rather than <strong class="source-inline">FunctionPassManager</strong>, to insert our <strong class="source-inline">StrictOpt</strong> Pass, which is a function Pass. We are using <strong class="source-inline">ModuleToFunctionPassAdapter</strong> to overcome this issue.<p><strong class="source-inline">ModuleToFunctionPassAdapter</strong> is a module Pass that can run a given function Pass over a module's enclosing functions. It is suitable for running a function Pass in contexts where only <strong class="source-inline">ModulePassManager</strong> is available, such as in this<a id="_idIndexMarker437"/> scenario. The <strong class="source-inline">createModuleToFunctionPassAdaptor</strong> function highlighted in the preceding code is used to create a new <strong class="source-inline">ModuleToFunctionPassAdapter</strong> instance from a specific function Pass.</p></li>
				<li>Finally, in this version, we are only enabling <strong class="source-inline">StrictOpt</strong> when the optimization level is greater or equal to <strong class="source-inline">-O2</strong>. Therefore, we leverage the <strong class="source-inline">OptimizationLevel</strong> argument passing into the lambda callback to determine whether we want to insert <strong class="source-inline">StrictOpt</strong> into the pipeline or not.<p>With these Pass registration steps, we have also learned how to trigger our <strong class="source-inline">StrictOpt</strong> without explicitly specifying the textual Pass pipeline.</p></li>
			</ul>
			<p>To summarize, in this section, we learned the essentials of the LLVM Pass and Pass pipeline. Through the <strong class="source-inline">StrictOpt</strong> project, we have learned how to develop a Pass – which is also encapsulated as a plugin – for the new PassManager and how to dynamically register it against the Pass pipeline in <strong class="source-inline">opt</strong> in two different ways: first, by triggering the Pass explicitly via a textual description, and second, by running it at a certain time point (EP) in the pipeline. We also learned how to invalidate analyses depending on the changes made in the Pass. These skills can help you develop high-quality and modern LLVM Passes to process IR in a composable fashion with maximum flexibility. In the next section, we will dive into the program analysis infrastructure of LLVM. This greatly improves the capability of normal LLVM transformation Passes.</p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor132"/>Working with the new AnalysisManager</h1>
			<p>Modern compiler<a id="_idIndexMarker438"/> optimizations can be complex. They usually require lots of information from the target program in order to make correct decisions and optimal transformations. For example, in the <em class="italic">Writing an LLVM Pass for the new PassManager</em> section, LLVM used the <strong class="source-inline">noalias</strong> attribute to calculate memory aliasing information, which might eventually be used to remove redundant memory loads. </p>
			<p>Some of this<a id="_idIndexMarker439"/> information – called <strong class="bold">analysis</strong>, in LLVM – is expensive to evaluate. In addition, a single analysis might also depend on other analyses. Therefore, LLVM creates an <strong class="bold">AnalysisManager</strong> component<a id="_idIndexMarker440"/> to handle all tasks related to program analysis in LLVM. In this section, we are going to show you how to use AnalysisManager in your own Passes for the sake of writing more powerful and sophisticated program transformations or analyses. We will also use a sample project, <strong class="bold">HaltAnalyzer</strong>, to drive<a id="_idIndexMarker441"/> our tutorial here. The next section will provide you with an overview of HaltAnalyzer before moving on to the detailed development steps.</p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor133"/>Overview of the project</h2>
			<p>HaltAnalyzer is set<a id="_idIndexMarker442"/> up in a scenario where target programs are using a special function, <strong class="source-inline">my_halt</strong>, that terminates the program execution when it is called. The <strong class="source-inline">my_halt</strong> function is similar to the <strong class="source-inline">std::terminate</strong> function, or the <strong class="source-inline">assert</strong> function when its sanity check fails.</p>
			<p>The job of HaltAnalyzer is to analyze the program to find basic blocks that are <em class="italic">guaranteed to be unreachable</em> because of the <strong class="source-inline">my_halt</strong> function. To be more specific, let's take the following C code as an example:</p>
			<p class="source-code">int foo(int x, int y) {</p>
			<p class="source-code">  if (x &lt; 43) {</p>
			<p class="source-code">    my_halt();</p>
			<p class="source-code">    <strong class="bold">if (y &gt; 45)</strong></p>
			<p class="source-code">      <strong class="bold">return x + 1;</strong></p>
			<p class="source-code">    <strong class="bold">else {</strong></p>
			<p class="source-code">      <strong class="bold">bar();</strong></p>
			<p class="source-code">      <strong class="bold">return x;</strong></p>
			<p class="source-code">    <strong class="bold">}</strong></p>
			<p class="source-code">  } else {</p>
			<p class="source-code">    return y;</p>
			<p class="source-code">  }</p>
			<p class="source-code">}</p>
			<p>Because <strong class="source-inline">my_halt</strong> was called at the beginning of the true block for the <strong class="source-inline">if (x &lt; 43)</strong> statement, the code highlighted in the preceding snippet will never be executed (that is, <strong class="source-inline">my_halt</strong> stopped all of the program executions before even getting to those lines). </p>
			<p>HaltAnalyzer should identify these basic blocks and print out warning messages to <strong class="source-inline">stderr</strong>. Just like the sample project from the previous section, HaltAnalyzer is also a function Pass wrapped inside a plugin. Therefore, if we use the preceding snippet as the input to our HaltAnalyzer<a id="_idIndexMarker443"/> Pass, it should print out the following messages:</p>
			<p class="source-code">$ opt --enable-new-pm --load-pass-plugin ./HaltAnalyzer.so \</p>
			<p class="source-code">      --disable-output ./test.ll</p>
			<p class="source-code">[WARNING] <strong class="bold">Unreachable BB: label %if.else</strong></p>
			<p class="source-code">[WARNING] <strong class="bold">Unreachable BB: label %if.then2</strong></p>
			<p class="source-code"><strong class="bold">$</strong></p>
			<p>The <strong class="source-inline">%if.else</strong> and <strong class="source-inline">%if.then2</strong> strings are just names for the basic blocks in the <strong class="source-inline">if (y &gt; 45)</strong> statement (you might see different names on your side). Another thing worth noting is the <strong class="source-inline">--disable-output</strong> command-line flag. By default, the <strong class="source-inline">opt</strong> utility will print out the binary form of LLVM IR (that is, the LLVM bitcode) anyway unless users redirect the output to other places via the <strong class="source-inline">-o</strong> flag. Using the aforementioned flag is merely to tell <strong class="source-inline">opt</strong> not to do that since we are not interested in the final content of LLVM IR (because we are not going to modify it) this time.</p>
			<p>Although the algorithm of HaltAnalyzer seems pretty simple, writing it from scratch might be a pain. That's why we are leveraging one of the analyses provided by LLVM: the<strong class="bold"> Dominator Tree (DT)</strong>. The concept of <strong class="bold">Control Flow Graph</strong> (<strong class="bold">CFG</strong>) domination has<a id="_idIndexMarker444"/> been <a id="_idIndexMarker445"/>taught in most entry-level compiler classes, so we are not going to explain it in depth here. Simply speaking, if we say a basic block <em class="italic">dominates</em> another block, every execution flow that arrives at the latter is guaranteed to go through the former first. A DT is one of the most important and commonly used analyses in LLVM; most control flow-related transformations cannot live without it.</p>
			<p>Putting this idea into <a id="_idIndexMarker446"/>HaltAnalyzer, we are simply looking for all of the basic blocks that are dominated by the basic blocks that contain a function call to <strong class="source-inline">my_halt</strong> (we are excluding the basic blocks that contain the <strong class="source-inline">my_halt</strong> call sites from the warning messages). In the next section, we will show you detailed instructions on how to write HaltAnalyzer.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor134"/>Writing the HaltAnalyzer Pass</h2>
			<p>In this project, we <a id="_idIndexMarker447"/>will only create a single source file, <strong class="source-inline">HaltAnalyzer.cpp</strong>. Most of the infrastructure, including <strong class="source-inline">CMakeListst.txt</strong>, can be reused from the <strong class="source-inline">StrictOpt</strong> project in the previous section:</p>
			<ol>
				<li value="1">Inside <strong class="source-inline">HaltAnalyzer.cpp</strong>, first, we create the following Pass skeleton:<p class="source-code">class HaltAnalyzer : public PassInfoMixin&lt;HaltAnalyzer&gt; {</p><p class="source-code">  static constexpr const char* HaltFuncName = "my_halt";</p><p class="source-code">  // All the call sites to "my_halt"</p><p class="source-code">  SmallVector&lt;Instruction*, 2&gt; <strong class="bold">Calls</strong>;</p><p class="source-code">  void <strong class="bold">findHaltCalls</strong>(Function &amp;F);</p><p class="source-code">public:</p><p class="source-code">  PreservedAnalyses run(Function &amp;F,</p><p class="source-code">                        FunctionAnalysisManager &amp;FAM);</p><p class="source-code">};</p><p>In addition to the <strong class="source-inline">run</strong> method that we saw in the previous section, we are creating an additional method, <strong class="source-inline">findHaltCalls</strong>, which will collect all of the <strong class="source-inline">Instruction</strong> calls to <strong class="source-inline">my_halt</strong> in the current function and store them inside the <strong class="source-inline">Calls</strong> vector.</p></li>
				<li>Let's implement <strong class="source-inline">findHaltCalls</strong> first:<p class="source-code">void HaltAnalyzer::findHaltCalls(Function &amp;F) {</p><p class="source-code">  Calls.clear();</p><p class="source-code">  for (auto &amp;I : <strong class="bold">instructions</strong>(F)) {</p><p class="source-code">    if (auto *CI = dyn_cast&lt;CallInst&gt;(&amp;I)) {</p><p class="source-code">      if (CI-&gt;<strong class="bold">getCalledFunction</strong>()-&gt;getName() ==           <strong class="bold">HaltFuncName</strong>)</p><p class="source-code">        Calls.push_back(&amp;I);</p><p class="source-code">    }</p><p class="source-code">  }</p><p class="source-code">}</p><p>This method <a id="_idIndexMarker448"/>uses <strong class="source-inline">llvm::instructions</strong> to iterate through every <strong class="source-inline">Instruction</strong> call in the current function and check them one by one. If the <strong class="source-inline">Instruction</strong> call is a <strong class="source-inline">CallInst</strong> – representing a typical function call site – and the callee name is <strong class="source-inline">my_halt</strong>, we will push it into the <strong class="source-inline">Calls</strong> vector for later use.</p><p class="callout-heading">Function name mangling</p><p class="callout">Be aware that when a line of C++ code is compiled into LLVM IR or native code, the name of any symbol – including the function name – will be different from what you saw in the original source code. For example, a simple function that has the name of <em class="italic">foo</em> and takes no argument <a id="_idIndexMarker449"/>might have <em class="italic">_Z3foov</em> as its name in LLVM IR. We call such a transformation in C++ <strong class="bold">name mangling</strong>. Different platforms also adopt different name mangling schemes. For example, in Visual Studio, the same function name becomes <em class="italic">?foo@@YAHH@Z</em> in LLVM IR.</p></li>
				<li>Now, let's go back to the <strong class="source-inline">HaltAnalyzer::run</strong> method. There are two things we are going to do. We will collect the call sites to <strong class="source-inline">my_halt</strong> via <strong class="source-inline">findHaltCalls</strong>, which we just wrote, and then retrieve the DT analysis data:<p class="source-code">#include "llvm/IR/Dominators.h"</p><p class="source-code">…</p><p class="source-code">PreservedAnalyses</p><p class="source-code">HaltAnalyzer::run(Function &amp;F, <strong class="bold">FunctionAnalysisManager &amp;FAM</strong>) {</p><p class="source-code">  findHaltCalls(F);</p><p class="source-code">  <strong class="bold">DominatorTree &amp;DT = FAM.    getResult&lt;DominatorTreeAnalysis&gt;(F);</strong></p><p class="source-code">  …</p><p class="source-code">}</p><p>The highlighted <a id="_idIndexMarker450"/>line in the preceding snippet is the main character of this section. It shows us how to leverage the provided <strong class="source-inline">FunctionAnalysisManager</strong> type argument to retrieve specific analysis data (in this case, <strong class="source-inline">DominatorTree</strong>) for a specific <strong class="source-inline">Function</strong> class.</p><p>Although, so far, we have (kind of) used the words <em class="italic">analysis</em> and <em class="italic">analysis data</em> interchangeably, in a real LLVM implementation, they are actually two different entities. Take the DT that we are using here as an example:</p><p>a) <strong class="bold">DominatorTreeAnalysis</strong> is a C++ class that evaluates dominating relationships from <a id="_idIndexMarker451"/>the given <strong class="source-inline">Function</strong>. In other words, it is the one that <em class="italic">performs</em> the analysis.</p><p>b) <strong class="bold">DominatorTree</strong> is a C++ class that represents the <em class="italic">result</em> generated from <strong class="source-inline">DominatorTreeAnalysis</strong>. This is just static data that will be cached by AnalysisManager until it is invalidated.</p><p>Furthermore, LLVM asks every analysis to clarify its affiliated result type via the <strong class="source-inline">Result</strong> member type. For example, <strong class="source-inline">DominatorTreeAnalysis::Result</strong> is equal to <strong class="source-inline">DominatorTree</strong>.</p><p>To make this even more formal, to associate the analysis data of an analysis class, <strong class="source-inline">T</strong>, with a <strong class="source-inline">Function</strong> variable, <strong class="source-inline">F</strong>, we can use the following snippet:</p><p class="source-code">// `FAM` is a FunctionAnalysisManager</p><p class="source-code">typename <strong class="bold">T::Result</strong> &amp;Data = FAM.getResult&lt;<strong class="bold">T</strong>&gt;(F);</p></li>
				<li>After we retrieve <strong class="source-inline">DominatorTree</strong>, it's time to find all of the basic blocks dominated by<a id="_idIndexMarker452"/> the <strong class="source-inline">Instruction</strong> call sites that we collected earlier:<p class="source-code">PreservedAnalyses</p><p class="source-code">HaltAnalyzer::run(Function &amp;F, FunctionAnalysisManager &amp;FAM) {</p><p class="source-code">  …</p><p class="source-code">  SmallVector&lt;BasicBlock*, 4&gt; DomBBs;</p><p class="source-code">  for (auto *I : Calls) {</p><p class="source-code">    auto *BB = I-&gt;getParent();</p><p class="source-code">    DomBBs.clear();</p><p class="source-code">    DT.<strong class="bold">getDescendants</strong>(BB, <strong class="bold">DomBBs</strong>);</p><p class="source-code">    for (auto *DomBB : DomBBs) {</p><p class="source-code">    // excluding the block containing `my_halt` call site</p><p class="source-code">      if (DomBB != BB) {</p><p class="source-code">        DomBB-&gt;<strong class="bold">printAsOperand</strong>(</p><p class="source-code">               errs() &lt;&lt; "[WARNING] Unreachable BB: ");</p><p class="source-code">        errs() &lt;&lt; "\n";</p><p class="source-code">      }</p><p class="source-code">    }</p><p class="source-code">  }</p><p class="source-code">  return PreservedAnalyses::all();</p><p class="source-code">}</p><p>By using the <strong class="source-inline">DominatorTree::getDescendants</strong> method, we can retrieve all of the basic blocks dominated by a <strong class="source-inline">my_halt</strong> call site. Note that the results from <strong class="source-inline">getDescendants</strong> will also contain the block you put into the query (in this case, the block containing the <strong class="source-inline">my_halt</strong> call sites), so we need to exclude it before printing the basic block name using the <strong class="source-inline">BasicBlock::printAsOperand</strong> method.</p><p>With the ending<a id="_idIndexMarker453"/> of the returning <strong class="source-inline">PreservedAnalyses::all()</strong>, which tells AnalysisManager that this Pass does not invalidate any analysis since we don't modify the IR at all, we will wrap up the <strong class="source-inline">HaltAnalyzer::run</strong> method here.</p></li>
				<li>Finally, we need to dynamically insert our HaltAnalyzer Pass into the Pass pipeline. We are using the same method that we did in the last section, by implementing the <strong class="source-inline">llvmGetPassPluginInfo</strong> function and using <strong class="source-inline">PassBuilder</strong> to put our Pass at one of the EPs in the pipeline:<p class="source-code">extern "C" ::llvm::PassPluginLibraryInfo LLVM_ATTRIBUTE_WEAK</p><p class="source-code">llvmGetPassPluginInfo() {</p><p class="source-code">  return {</p><p class="source-code">    LLVM_PLUGIN_API_VERSION, "HaltAnalyzer", "v0.1",</p><p class="source-code">    [](PassBuilder &amp;PB) {</p><p class="source-code">      using OptimizationLevel</p><p class="source-code">        = typename PassBuilder::OptimizationLevel;</p><p class="source-code">      PB.<strong class="bold">registerOptimizerLastEPCallback</strong>(</p><p class="source-code">        [](ModulePassManager &amp;MPM, OptimizationLevel OL) {</p><p class="source-code">          MPM.addPass(<strong class="bold">createModuleToFunctionPassAdaptor            </strong>(HaltAnalyzer()));</p><p class="source-code">        });</p><p class="source-code">    }</p><p class="source-code">  };</p><p class="source-code">}</p><p>In comparison to <strong class="source-inline">StrictOpt</strong> in the previous section, we are using <strong class="source-inline">registerOptimizerLastEPCallback</strong> to insert HaltAnalyzer <em class="italic">after</em> all of the other optimization Passes. The rationale behind this is that some optimizations<a id="_idIndexMarker454"/> might move basic blocks around, so prompting warnings too early might not be very useful. Nevertheless, we are still leveraging <strong class="source-inline">ModuletoFunctionPassAdaptor</strong> to wrap around our Pass; this is because <strong class="source-inline">registerOptimizerLastEPCallback</strong> only provides <strong class="source-inline">ModulePassManager</strong> for us to add our Pass, which is a function Pass.</p></li>
			</ol>
			<p>These are all the necessary steps to implement our HaltAnalyzer. Now you have learned how to use LLVM's program analysis infrastructure to obtain more information about the target program in an LLVM Pass. These skills can provide you with more insight into IR when you are developing a Pass. In addition, this infrastructure allows you to reuse high-quality, off-the-shelf program analysis algorithms from LLVM instead of recreating the wheels by yourself. To browse all of the available analyses provided by LLVM, the <strong class="source-inline">llvm/include/llvm/Analysis</strong> folder in the source tree is a good starting point. Most of the header files within this folder are standalone analysis data files that you can use.</p>
			<p>In the final section of this chapter, we will show you some diagnosis techniques that are useful for debugging an LLVM Pass.</p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor135"/>Learning instrumentations in the new PassManager</h1>
			<p>PassManager <a id="_idIndexMarker455"/>and AnalysisManager in LLVM are complicated pieces of software. They manage interactions between hundreds of Passes and analyses, and it can be a challenge when we try to diagnose a problem caused by them. In addition, it's really common for a compiler engineer to fix crashes in the compiler or <strong class="bold">miscompilation </strong>bugs. In <a id="_idIndexMarker456"/>those scenarios, useful instrumentation tools that provide insights to Passes and the Pass pipeline can greatly improve the productivity of fixing those problems. Fortunately, LLVM has already provided many of those tools.</p>
			<p class="callout-heading">Miscompilation</p>
			<p class="callout"><strong class="bold">Miscompilation</strong> bugs usually refer <a id="_idIndexMarker457"/>to logical issues in the <strong class="bold">compiled program</strong>, which were introduced by compilers. For example, an overly aggressive compiler optimization removes certain loops that shouldn't be removed, causing the compiled software to malfunction, or mistakenly reorder memory barriers and create <em class="italic">race conditions</em> in the generated code.</p>
			<p>We will introduce a single tool at a time in each of the following sections. Here is the list of them:</p>
			<ul>
				<li>Printing Pass pipeline details</li>
				<li>Printing changes to the IR after each Pass</li>
				<li>Bisecting the Pass pipeline</li>
			</ul>
			<p>These tools can interact purely in the command-line interface of <strong class="source-inline">opt</strong>. In fact, you can also create <em class="italic">your own</em> instrumentation tools (without even changing the LLVM source tree!); we will leave this as an exercise for you.</p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor136"/>Printing Pass pipeline details</h2>
			<p>There are<a id="_idIndexMarker458"/> many different <strong class="bold">optimization levels</strong> in<a id="_idIndexMarker459"/> LLVM, that is, the <strong class="source-inline">-O1</strong>, <strong class="source-inline">-O2</strong>, or <strong class="source-inline">-Oz</strong> flags we are familiar with when using <strong class="source-inline">clang</strong> (or <strong class="source-inline">opt</strong>). Each optimization level is running a <em class="italic">different set of Passes</em> and arranging them in <em class="italic">different orders</em>. In some cases, this might greatly affect the generated code, in terms of performance or correctness. Therefore, sometimes, it's crucial to know these configurations in order to gain a clear understanding of the problems we are going to deal with.</p>
			<p>To print out all the Passes and the order they are currently running in inside <strong class="source-inline">opt</strong>, we can use the <strong class="source-inline">--debug-pass-manager</strong> flag. For instance, given the following C code, <strong class="source-inline">test.c</strong>, we will see the following:</p>
			<p class="source-code">int bar(int x) {</p>
			<p class="source-code">  int y = x;</p>
			<p class="source-code">  return y * 4;</p>
			<p class="source-code">}</p>
			<p class="source-code">int foo(int z) {</p>
			<p class="source-code">  return z + z * 2;</p>
			<p class="source-code">}</p>
			<p>We first<a id="_idIndexMarker460"/> generate the<a id="_idIndexMarker461"/> IR for it using the following command:</p>
			<p class="source-code">$ clang -O0 -Xclang -disable-O0-optnone -emit-llvm -S test.c</p>
			<p class="callout-heading">The -disable-O0-optnone flag</p>
			<p class="callout">By default, <strong class="source-inline">clang</strong> will attach a special attribute, <strong class="source-inline">optnone</strong>, to each function under the <strong class="source-inline">-O0</strong> optimization level. This attribute will prevent any further optimization on the attached functions. Here, the <strong class="source-inline">-disable-O0-optnone</strong> (frontend) flag is preventing <strong class="source-inline">clang</strong> from attaching to this attribute.</p>
			<p>Then, we use the following command to print out all of the Passes running under the optimization level of <strong class="source-inline">-O2</strong>:</p>
			<p class="source-code">$ opt <strong class="bold">-O2</strong> --disable-output <strong class="bold">--debug-pass-manager</strong> test.ll</p>
			<p class="source-code">Starting <strong class="bold">llvm::Module pass manager</strong> run.</p>
			<p class="source-code">…</p>
			<p class="source-code">Running pass: Annotation2MetadataPass on ./test.ll</p>
			<p class="source-code">Running pass: ForceFunctionAttrsPass on ./test.ll</p>
			<p class="source-code">…</p>
			<p class="source-code">Starting <strong class="bold">llvm::Function pass manager</strong> run.</p>
			<p class="source-code">Running pass: SimplifyCFGPass on <strong class="bold">bar</strong></p>
			<p class="source-code">Running pass: SROA on <strong class="bold">bar</strong></p>
			<p class="source-code"><strong class="bold">Running analysis</strong>: DominatorTreeAnalysis on <strong class="bold">bar</strong></p>
			<p class="source-code">Running pass: EarlyCSEPass on <strong class="bold">bar</strong></p>
			<p class="source-code">…</p>
			<p class="source-code">Finished llvm::Function pass manager run.</p>
			<p class="source-code">…</p>
			<p class="source-code">Starting <strong class="bold">llvm::Function pass manager</strong> run.</p>
			<p class="source-code">Running pass: SimplifyCFGPass on <strong class="bold">foo</strong></p>
			<p class="source-code">…</p>
			<p class="source-code">Finished llvm::Function pass manager run.</p>
			<p class="source-code"><strong class="bold">Invalidating analysis</strong>: VerifierAnalysis on ./test.ll</p>
			<p class="source-code">…</p>
			<p class="source-code">$</p>
			<p>The preceding <a id="_idIndexMarker462"/>command-line<a id="_idIndexMarker463"/> output tells us that <strong class="source-inline">opt</strong> first runs a set of <em class="italic">module-level</em> optimizations; the ordering of those Passes (for example, <strong class="source-inline">Annotation2MetadataPass</strong> and <strong class="source-inline">ForceFunctionAttrsPass</strong>) are also listed. After that, a sequence of <em class="italic">function-level</em> optimizations is performed on the <strong class="source-inline">bar</strong> function (for example, <strong class="source-inline">SROA</strong>) before running those optimizations on the <strong class="source-inline">foo</strong> function. Furthermore, it also shows the analyses used in the pipeline (for example, <strong class="source-inline">DominatorTreeAnalysis</strong>), as well as prompting us with a message regarding they became invalidated (by a certain Pass).</p>
			<p>To sum up, <strong class="source-inline">--debug-pass-manager</strong> is a useful tool to peek into the Passes and their ordering run by the Pass pipeline at a certain optimization level. Knowing this information<a id="_idIndexMarker464"/> can give you a <a id="_idIndexMarker465"/>big picture of how Passes and analyses interact with the input IR.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor137"/>Printing changes to the IR after each Pass</h2>
			<p>To understand <a id="_idIndexMarker466"/>the<a id="_idIndexMarker467"/> effects of a particular transformation Pass on your target program, one of the most straightforward ways is to compare the IR before and after it is processed by that Pass. To be more specific, in most cases, we are interested in the <em class="italic">changes</em> made by a particular transformation Pass. For instance, if LLVM mistakenly removes a loop that it shouldn't do, we want to know <em class="italic">what</em> Pass did that, and <em class="italic">when</em> the removal happened in the Pass pipeline.</p>
			<p>By using the <strong class="source-inline">--print-changed</strong> flag (and some other supported flags that we will introduce shortly) with <strong class="source-inline">opt</strong>, we can print out the IR after each Pass if it was ever modified by that Pass. Using the <strong class="source-inline">test.c</strong> (and its IR file, <strong class="source-inline">test.ll</strong>) example code from the previous paragraph, we can use the following command to print changes, if there are any, made by each Pass:</p>
			<p class="source-code">$ opt -O2 --disable-output <strong class="bold">--print-changed</strong> ./test.ll</p>
			<p class="source-code">*** <strong class="bold">IR Dump At Start</strong>: ***</p>
			<p class="source-code">...</p>
			<p class="source-code">define dso_local i32 @<strong class="bold">bar</strong>(i32 %x) #0 {</p>
			<p class="source-code">entry:</p>
			<p class="source-code">  %x.addr = alloca i32, align 4</p>
			<p class="source-code">  %y = alloca i32, align 4</p>
			<p class="source-code">  …</p>
			<p class="source-code">  %1 = load i32, i32* %y, align 4</p>
			<p class="source-code">  %mul = mul nsw i32 %1, 4</p>
			<p class="source-code">  ret i32 %mul</p>
			<p class="source-code">}</p>
			<p class="source-code">...</p>
			<p class="source-code">*** IR Dump After <strong class="bold">VerifierPass</strong> (module) <strong class="bold">omitted because no change</strong> ***</p>
			<p class="source-code">…</p>
			<p class="source-code">...</p>
			<p class="source-code">*** IR Dump After <strong class="bold">SROA</strong> *** (function: <strong class="bold">bar</strong>)</p>
			<p class="source-code">; Function Attrs: noinline nounwind uwtable</p>
			<p class="source-code">define dso_local i32 @bar(i32 %x) #0 {</p>
			<p class="source-code">entry:</p>
			<p class="source-code">  %mul = mul nsw i32 %x, 4</p>
			<p class="source-code">  ret i32 %mul</p>
			<p class="source-code">}</p>
			<p class="source-code">...</p>
			<p class="source-code">$</p>
			<p>Here, we<a id="_idIndexMarker468"/> have only <a id="_idIndexMarker469"/>shown a small amount of output. However, in the highlighted part of the snippet, we can see that this tool will first print out the original IR (<strong class="source-inline">IR Dump At Start</strong>), then show the IR after it is processed by each Pass. For example, the preceding snippet shows that the <strong class="source-inline">bar</strong> function has become much shorter after the SROA Pass. If a Pass didn't modify the IR at all, it will omit the IR dump to reduce the amount of noise.</p>
			<p>Sometimes, we are only interested in the changes that have happened on a <em class="italic">particular set of functions</em>, say, the <strong class="source-inline">foo</strong> function, in this case. Instead of printing the <em class="italic">change log</em> of the entire module, we can add the <strong class="source-inline">--filter-print-funcs=&lt;function names&gt;</strong> flag to only print IR changes for a subset of functions. For example, to only print IR changes for the <strong class="source-inline">foo</strong> function, you can use the following command:</p>
			<p class="source-code">$ opt -O2 --disable-output \</p>
			<p class="source-code">          <strong class="bold">--print-changed</strong> <strong class="bold">--filter-print-funcs=foo</strong> ./test.ll</p>
			<p>Just like <strong class="source-inline">--filter-print-funcs</strong>, sometimes, we only want to see changes made by a <em class="italic">particular set of Passes</em>, say, the SROA and <strong class="source-inline">InstCombine</strong> Passes. In that case, we can add the <strong class="source-inline">--filter-passes=&lt;Pass names&gt;</strong> flag. For example, to view only the content that is relevant to SROA and <strong class="source-inline">InstCombine</strong>, we can use the following command:</p>
			<p class="source-code">$ opt -O2 --disable-output \</p>
			<p class="source-code">          <strong class="bold">--print-changed</strong> \</p>
			<p class="source-code">          <strong class="bold">--filter-passes=SROA,InstCombinePass</strong> ./test.ll</p>
			<p>Now you have learned how to print the IR differences among all the Passes in the pipeline, with<a id="_idIndexMarker470"/> additional <a id="_idIndexMarker471"/>filters that can further focus on a specific function or Pass. In other words, this tool can help you to easily observe the <em class="italic">progression</em> of changes throughout the Pass pipeline and quickly spot any traces that you might be interested in. In the next section, we will learn how to debug problems raised in the code optimization by <em class="italic">bisecting</em> the Pass pipeline.</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor138"/>Bisecting the Pass pipeline</h2>
			<p>In the previous <a id="_idIndexMarker472"/>section, we<a id="_idIndexMarker473"/> introduced the <strong class="source-inline">--print-changed</strong> flag, which prints out the <em class="italic">IR change log</em> throughout the Pass pipeline. We also mentioned that it is useful to call out changes that we are interested in; for instance, an invalid code transformation that caused miscompilation bugs. Alternatively, we can also <strong class="bold">bisect</strong> the Pass pipeline to achieve a similar goal. To be more specific, the <strong class="source-inline">--opt-bisect-limit=&lt;N&gt;</strong> flag in <strong class="source-inline">opt</strong> bisects the Pass pipeline by <em class="italic">disabling</em> all Passes except the first <strong class="source-inline">N</strong> ones. The following command shows an example of this:</p>
			<p class="source-code">$ opt -O2 <strong class="bold">--opt-bisect-limit=5</strong> -S <strong class="bold">-o –</strong> test.ll</p>
			<p class="source-code">BISECT: running pass (1) Annotation2MetadataPass on module (./test.ll)</p>
			<p class="source-code">BISECT: running pass (2) ForceFunctionAttrsPass on module (./test.ll)</p>
			<p class="source-code">BISECT: running pass (3) InferFunctionAttrsPass on module (./test.ll)</p>
			<p class="source-code">BISECT: running pass (4) SimplifyCFGPass on function (bar)</p>
			<p class="source-code">BISECT: <strong class="bold">running pass (5) SROA on function (bar)</strong></p>
			<p class="source-code">BISECT: NOT running pass (6) EarlyCSEPass on function (bar)</p>
			<p class="source-code">BISECT: NOT running pass (7) LowerExpectIntrinsicPass on function (bar)</p>
			<p class="source-code">BISECT: NOT running pass (8) SimplifyCFGPass on function (foo)</p>
			<p class="source-code">BISECT: <strong class="bold">NOT running pass (9) SROA on function (foo)</strong></p>
			<p class="source-code">BISECT: NOT running pass (10) EarlyCSEPass on function (foo)</p>
			<p class="source-code">...</p>
			<p class="source-code">define dso_local i32 @<strong class="bold">bar</strong>(i32 %x) #0 {</p>
			<p class="source-code">entry:</p>
			<p class="source-code">  %mul = mul nsw i32 %x, 4</p>
			<p class="source-code">  ret i32 %mul</p>
			<p class="source-code">}</p>
			<p class="source-code">define dso_local i32 @<strong class="bold">foo</strong>(i32 %y) #0 {</p>
			<p class="source-code">entry:</p>
			<p class="source-code">  %y.addr = alloca i32, align 4</p>
			<p class="source-code">  store i32 %y, i32* %y.addr, align 4</p>
			<p class="source-code">  %0 = load i32, i32* %y.addr, align 4</p>
			<p class="source-code">  %1 = load i32, i32* %y.addr, align 4</p>
			<p class="source-code">  %mul = mul nsw i32 %1, 2</p>
			<p class="source-code">  %add = add nsw i32 %0, %mul</p>
			<p class="source-code">  ret i32 %add</p>
			<p class="source-code">}</p>
			<p class="source-code">$</p>
			<p>(Note that this is different from examples shown in the previous sections; the preceding command has printed both messages from <strong class="source-inline">--opt-bisect-limit</strong> and the final textual IR.)</p>
			<p>Since we implemented the <strong class="source-inline">--opt-bisect-limit=5</strong> flag, the Pass pipeline only ran the first five Passes. As you can see from the diagnostic messages, SROA was applied on <strong class="source-inline">bar</strong> but not the <strong class="source-inline">foo</strong> function, leaving the final IR of <strong class="source-inline">foo</strong> less optimal.</p>
			<p>By changing the number that follows <strong class="source-inline">--opt-bisect-limit</strong>, we can adjust the cut point until certain code changes appear or a certain bug is triggered (for example, a crash). This is particularly useful as an <em class="italic">early filtering step</em> to narrow down the original problem to a smaller range of Passes in the pipeline. Furthermore, since it uses a numeric value as the parameter, this feature fits perfectly to automating environments such as automatic crash reporting tools or performance regression tracking tools.</p>
			<p>In this section, we <a id="_idIndexMarker474"/>introduced several<a id="_idIndexMarker475"/> useful instrumentation tools in <strong class="source-inline">opt</strong> for debugging and diagnosing the Pass pipeline. These tools can greatly improve your productivity when it comes to fixing problems, such as compiler crashes, performance regressions (on the target program), and miscompilation bugs.</p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor139"/>Summary</h1>
			<p>In this chapter, we learned how to write an LLVM Pass for the new PassManager and how to use program analysis data within a Pass via the AnalysisManager. We also learned how to leverage various instrumentation tools to improve the development experiences while working with the Pass pipeline. With the skills gained from this chapter, you can now write a Pass to process LLVM IR, which can be used to transform or even optimize a program.</p>
			<p>These topics are some of the most fundamental and crucial skills to learn before starting on any IR level transformation or analysis task. If you have been working with the legacy PassManager, these skills can also help you to migrate your code to the new PassManager system, which has now been enabled by default.</p>
			<p>In the next chapter, we will show you various tips along with the best practices that you should know when using the APIs of LLVM IR.</p>
			<h1 id="_idParaDest-134"><a id="_idTextAnchor140"/>Questions</h1>
			<ol>
				<li value="1">In the <strong class="source-inline">StrictOpt</strong> example of the <em class="italic">Writing an LLVM Pass for the new PassManager</em> section, how can you write a Pass without deriving the <strong class="source-inline">PassInfoMixin</strong> class?</li>
				<li>How can you develop a custom instrumentation for the new PassManager? Additionally, how can you do this without modifying the LLVM source tree? (Hint: think about the Pass plugin that we learned about in this chapter.)</li>
			</ol>
		</div>
	</body></html>