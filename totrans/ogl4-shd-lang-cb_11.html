<html><head></head><body>
        

                            
                    <h1 class="header-title">Using Compute Shaders</h1>
                
            
            
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Implementing a particle simulation with the compute shader</li>
<li>Creating a fractal texture using the compute shader</li>
<li>Using the compute shader for cloth simulation</li>
<li>Implementing an edge detection filter with the compute shader</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction</h1>
                
            
            
                
<p><strong>Compute shaders</strong> were introduced into OpenGL with version 4.3. A compute shader is a shader stage that can be used for arbitrary computation. It provides the ability to leverage the GPU and its inherent parallelism for general computing tasks that might have previously been implemented in serial on the CPU. The compute shader is most useful for tasks that are not directly related to rendering, such as physical simulation.</p>
<p>Although APIs such as OpenCL and CUDA are already available for general purpose computation on the GPU, they are completely separate from OpenGL. Compute shaders are integrated directly within OpenGL, and therefore are more suitable for general computing tasks that are more closely related to graphics rendering.</p>
<p>The compute shader is not a traditional shader stage in the same sense as the fragment or vertex shader. It is not executed in response to rendering commands. In fact, when a compute shader is linked with a vertex, fragment, or other shader stages, it is effectively inert when drawing commands are executed. The only way to execute the compute shader is via the OpenGL <kbd>glDispatchCompute</kbd> or <kbd>glDispatchComputeIndirect</kbd> command.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Compute shaders do not have any direct user-defined inputs and no outputs at all. Shaders get its work by fetching data directly from memory using image-access functions such as the image load/store operations, or via shader storage buffer objects. Similarly, it provides its results by writing to the same or other objects. The only non-user-defined inputs to a compute shader are a set of variables that determine where the shader invocation is within its <em>space</em> of execution.</p>
<p>The number of invocations of the compute shader is completely user defined. It is not tied in any way to the number of vertices or fragments being rendered. We specify the number of invocations by defining the number of work groups, and the number of invocations within each work group.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Compute space and work groups</h1>
                
            
            
                
<p>The number of invocations of a compute shader is governed by the user-defined compute space. This space is divided into a number of work groups. Each work group is then broken down into a number of invocations. We think of this in terms of the global compute space (all shader invocations) and the local work group space (the invocations within a particular work group). The compute space can be defined as a one-, two-, or three-dimensional space.</p>
<p>Technically, it is always defined as a three-dimensional space, but any of the three dimensions can be defined with a size of one (1), which effectively removes that dimension.</p>
<p>For example, a one-dimensional compute space with five work groups and three invocations per work group could be represented as the following diagram. The thicker lines represent the work groups, and the thinner lines represent the invocations within each work group:</p>
<div><img src="img/76d4aaa8-3781-48d8-adc3-e2440c174a9a.png" style="width:32.92em;height:3.33em;"/></div>
<p>In this case, we have <em>5 * 3 = 15</em> shader invocations. The grey shaded invocation is in work group <strong>2</strong>, and within that work group is invocation <strong>1</strong> (the invocations are indexed starting at <strong>0</strong>). We can also refer to that invocation with a global index of 7 by indexing the total number of invocations starting at zero. The global index determines an invocation's location within the global compute space, rather than just within the work group.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>It is determined by taking the product of work group (<strong>2</strong>) and index the number of invocations per work group (<strong>3</strong>), plus the local invocation index (<strong>1</strong>) that is <em>2 * 3 + 1 = 7</em>. The <strong>global index</strong> is simply the index of each invocation in the global compute space, starting at zero on the left and counting from there.</p>
<p>The following diagram shows a representation of a two-dimensional compute space where the space is divided into 20 work groups, four in the <em>x</em> direction and five in the <em>y</em> direction. Each work group is then divided into nine invocations, three in the <em>x</em> direction and three in the <em>y</em> direction:</p>
<div><img src="img/9eb7b3f7-073b-42b8-beb7-1c1c5b0612af.png" style="width:24.42em;height:14.50em;"/></div>
<p>The cell that is shaded in gray represents invocation (0, 1) within the work group (2, 0). The total number of compute shader invocations in this example is then <em>20 * 9 = 180</em>. The global index of this shaded invocation is (6, 1). As with the one-dimensional case, we can think of this index as a global compute space (without the work groups), and it can be computed (for each dimension) by the number of invocations per work group times the work group index, plus the local invocation index. For the <em>x</em> dimension, this would be <em>3 * 2 + 0 = 6</em>, and for the <em>y</em> dimension it is <em>3 * 0 + 1 = 1</em>.</p>
<p>The same idea can extend in a straightforward manner to a three-dimensional compute space. In general, we choose the dimensionality based on the data to be processed. For example, if I'm working on the physics of a particle simulation, I would just have a list of particles to process, so a one-dimensional compute space might make sense. On the other hand, if I'm processing a cloth simulation, the data will have a grid structure, so a two-dimensional compute space would be appropriate.</p>
<p>There are limits to the total number of work groups and local shader invocations. These can be queried (via <kbd>glGetInteger*</kbd>) using the <kbd>GL_MAX_COMPUTE_WORK_GROUP_COUNT</kbd>, <kbd>GL_MAX_COMPUTE_WORK_GROUP_SIZE</kbd>, and <kbd>GL_MAX_COMPUTE_WORK_GROUP_INVOCATIONS </kbd>parameters.</p>
<p class="mce-root"/>
<p>The order of execution of the work groups and thereby the individual shader invocations is unspecified and the system can execute them in any order. Therefore, we shouldn't rely on any particular ordering of the work groups. Local invocations within a particular work group will be executed in parallel (if possible). Therefore, any communication between invocations should be done with great care. Invocations within a work group can communicate via shared local data, but invocations should not (in general) communicate with invocations in other work groups without the consideration of the various pitfalls involved such as deadlock and data races. In fact, those can also be issues for local shared data within a work group as well, and care must be taken to avoid these problems. In general, for reasons of efficiency, it is best to only attempt communication within a work group. As with any kind of parallel programming, "there be dragons here."</p>
<p>OpenGL provides a number of atomic operations and memory barriers that can help with the communication between invocations. We'll see some examples in the recipes that follow.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Executing the compute shader</h1>
                
            
            
                
<p>When we execute the compute shader, we define the compute space. The number of work groups are determined by the parameters to <kbd>glDispatchCompute</kbd>. For example, to execute the compute shader with a two-dimensional compute space with <kbd>4</kbd> work groups in the <em>x</em> dimension and <kbd>5</kbd> work groups in the <em>y</em> dimension (matching the preceding diagram), we'd use the following call:</p>
<pre>glDispatchCompute( 4, 5, 1 ); </pre>
<p>The number of local invocations within each work group is not specified on the OpenGL side. Instead, it is specified within the compute shader itself with a layout specifier. For example, here, we specify nine local invocations per work group, <kbd>3</kbd> in the <em>x</em> direction and <kbd>3</kbd> in the <em>y</em> direction:</p>
<pre>layout (local_size_x = 3, local_size_y = 3) in; </pre>
<p>The size in the <em>z</em> dimension can be left out (the default is one).</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>When a particular invocation of the compute shader is executing, it usually needs to determine where it is within the global compute space. GLSL provides a number of built-in input variables that help with this. Most of them are listed in the following table:</p>
<table border="1" class="table" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Variable</strong></p>
</td>
<td>
<p><strong>Type</strong></p>
</td>
<td>
<p><strong>Meaning</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>gl_WorkGroupSize</kbd></p>
</td>
<td>
<p><kbd>uvec3</kbd></p>
</td>
<td>
<p>The number of invocations per work group in each dimension—the same as what is defined in the layout specifier.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>gl_NumWorkGroups</kbd></p>
</td>
<td>
<p><kbd>uvec3</kbd></p>
</td>
<td>
<p>The total number of work groups in each dimension.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>gl_WorkGroupID</kbd></p>
</td>
<td>
<p><kbd>uvec3</kbd></p>
</td>
<td>
<p>The index of the current work group for this shader invocation.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>gl_LocalInvocationID</kbd></p>
</td>
<td>
<p><kbd>uvec3</kbd></p>
</td>
<td>
<p>The index of the current invocation within the current work group.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>gl_GlobalInvocationID</kbd></p>
</td>
<td>
<p><kbd>uvec3</kbd></p>
</td>
<td>
<p>The index of the current invocation within the global compute space.</p>
</td>
</tr>
</tbody>
</table>
<div><p> </p>
<p>The last one in the preceding table, <kbd>gl_GlobalInvocationID</kbd>, is computed in the following way (each operation is component-wise):</p>
<pre>gl_WorkGroupID * gl_WorkGroupSize + gl_LocalInvocationID </pre>
<p>This helps us to locate the current invocation within the global compute space (refer to the preceding examples).</p>
<p>GLSL also defines <kbd>gl_LocalInvocationIndex</kbd>, which is a flattened form of <kbd>gl_LocalInvocationID</kbd>. It can help when multidimensional data is provided in a linear buffer, but is not used in any of the examples that follow.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing a particle simulation with the compute shader</h1>
                
            
            
                
<p>In this recipe, we'll implement a simple particle simulation. We'll have the compute shader handle the physics computations and update the particle positions directly. Then, we'll just render the particles as points. Without the compute shader, we'd need to update the positions on the CPU by stepping through the array of particles and updating each position in a serial fashion, or by making use of transform feedback, as shown in the <em>Creating a particle system using transform feedback</em> recipe in <a href="5e6b75a0-9f0c-4798-bc37-b5d34b53ef4a.xhtml">Chapter 9</a>, <em>Using Noise in Shaders</em>.</p>
<p>Doing such animations with vertex shaders is sometimes counterintuitive and requires some additional work (such as transform feedback setup). With the compute shader, we can do the particle physics in parallel on the GPU, and customize our compute space to get the most "bang for the buck" out of our GPU.</p>
<p>The following image shows our particle simulation running with one million particles. Each particle is rendered as a 1 x 1 point. The particles are partially transparent, and the particle attractors are rendered as small 5 x 5 squares (barely visible):</p>
<div><img src="img/9f182425-bc66-4943-a13d-2dfff2ed8b51.png" style="width:20.17em;height:15.08em;"/></div>
<p>These simulations can create beautiful, abstract figures, and are a lot of fun to produce.</p>
<p>For our simulation, we'll define a set of attractors (two in this case, but you can create more), which I'll call the <strong>black holes</strong>. They will be the only objects that affect our particles and they'll apply a force on each particle that is inversely proportional to the distance between the particle and the black hole. More formally, the force on each particle will be determined by the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/267ba104-508c-4177-ad32-043acae98a17.png" style="width:10.17em;height:4.42em;"/></p>
<p><em>N</em> is the number of black holes (attractors), <em>r<sub>i</sub></em> is the vector between the <em>i</em><sup>th</sup> attractor and the particle (determined by the position of the attractor minus the particle position), and <em>G<sub>i</sub></em> is the strength of the <em>i</em><sup>th</sup> attractor.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To implement the simulation, we compute the force on each particle and then update the position by integrating the Newtonian equations of motion. There are a number of well-studied numerical techniques for integrating the equations of motion. For this simulation, the simple Euler method is sufficient. With the Euler method, the position of the particle at time <em>t + Δt</em> is given by the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/1b1a4e59-6e5f-44cd-a3c3-ec3d262ceb1e.png" style="width:20.67em;height:2.58em;"/></p>
<p><em>P</em> is the position of the particle, <em>v</em> is the velocity, and <em>a</em> is the acceleration. Similarly, the updated velocity is determined by the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/9cde8466-8277-4e9e-a6e7-8abf54393bbf.png" style="width:14.33em;height:1.50em;"/></p>
<p>These equations are derived from a Taylor expansion of the position function about time <em>t</em>. The result is dependent upon the size of the time step (<em>Δt</em>), and is more accurate when the time step is very small.</p>
<p>The acceleration is directly proportional to the force on the particle, so by calculating the force on the particle (using the preceding equation), we essentially have a value for the acceleration. To simulate the particle's motion, we track its position and velocity, determine the force on the particle due to the black holes, and then update the position and velocity using the equations.</p>
<p>We'll use the compute shader to implement the physics here. Since we're just working with a list of particles, we'll use a one-dimensional compute space, and work groups of about 1,000 particles each. Each invocation of the compute shader will be responsible for updating the position of a single particle.</p>
<p>We'll use shader storage buffer objects to track the positions and velocities, and when rendering the particles themselves, we can just render directly from the position buffer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>On the OpenGL side, we need a buffer for the position of the particles and a buffer for the velocity. Create a buffer containing the initial positions of the particles and a buffer with zeroes for the initial velocities. We'll use four component positions and velocities for this example in order to avoid issues with data layouts. For example, to create the buffer for the positions, we might do something as follows:</p>
<pre>vector&lt;GLfloat&gt; initPos; 
 
... // Set initial positions 
 
GLuint bufSize = totalParticles * 4 * sizeof(GLfloat); 
 
GLuint posBuf; 
glGenBuffers(1, &amp;posBuf); 
glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, posBuf); 
glBufferData(GL_SHADER_STORAGE_BUFFER, bufSize, &amp;initPos[0], 
               GL_DYNAMIC_DRAW); </pre>
<p>Use a similar process for the velocity data, but bind it to index one of the <kbd>GL_SHADER_STORAGE_BUFFER</kbd> binding location:</p>
<pre>glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 1, velBuf); </pre>
<p>Set up a vertex array object that uses the same position buffer as its data source for the vertex position.</p>
<p>To render the points, set up a vertex and fragment shader pair that just produces a solid color. Enable blending and set up a standard blending function.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>Perform the following steps:</p>
<ol>
<li>We'll use the compute shader for updating the positions of the particles:</li>
</ol>
<pre style="padding-left: 60px">layout( local_size_x = 1000 ) in; 
 
uniform float Gravity1 = 1000.0; 
uniform vec3 BlackHolePos1; 
uniform float Gravity2 = 1000.0; 
uniform vec3 BlackHolePos2; 
 
uniform float ParticleInvMass = 1.0 / 0.1; 
uniform float DeltaT = 0.0005; 
 
layout(std430, binding=0) buffer Pos { 
  vec4 Position[]; 
}; 
layout(std430, binding=1) buffer Vel { 
  vec4 Velocity[]; 
}; 
 
void main() { 
  uint idx = gl_GlobalInvocationID.x; 
 
  vec3 p = Position[idx].xyz; 
  vec3 v = Velocity[idx].xyz; 
 
  // Force from black hole #1 
  vec3 d = BlackHolePos1 - p; 
  vec3 force = (Gravity1 / length(d)) * normalize(d); 
   
  // Force from black hole #2 
  d = BlackHolePos2 - p; 
  force += (Gravity2 / length(d)) * normalize(d); 
 
  // Apply simple Euler integrator 
  vec3 a = force * ParticleInvMass; 
  Position[idx] = vec4( 
        p + v * DeltaT + 0.5 * a * DeltaT * DeltaT, 1.0); 
  Velocity[idx] = vec4( v + a * DeltaT, 0.0); 
} </pre>
<ol start="2">
<li>In the render routine, invoke the compute shader to update the particle positions:</li>
</ol>
<pre style="padding-left: 60px">glDispatchCompute(totalParticles / 1000, 1, 1); </pre>
<ol start="3">
<li>Then, make sure that all data has been written out to the buffer by invoking a memory barrier:</li>
</ol>
<pre style="padding-left: 60px">glMemoryBarrier( GL_SHADER_STORAGE_BARRIER_BIT ); </pre>
<ol start="4">
<li>Finally, render the particles using data in the position buffer.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>The compute shader starts by defining the number of invocations per work group using the layout specifier:</p>
<pre>layout( local_size_x = 1000 ) in; </pre>
<p>This specifies <kbd>1000</kbd> invocations per work group in the <em>x</em> dimension. You can choose a value for this that makes the most sense for the hardware you're running. Just make sure to adjust the number of work groups appropriately. The default size for each dimension is one so we don't need to specify the size of the <em>y</em> and <em>z</em> directions.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Then, we have a set of uniform variables that define the simulation parameters. <kbd>Gravity1</kbd> and <kbd>Gravity2</kbd> are the strengths of the two black holes (<kbd>G</kbd>, in the preceding equation), and <kbd>BlackHolePos1</kbd> and <kbd>BlackHolePos2</kbd> are their positions. <kbd>ParticleInvMass</kbd> is the inverse of the mass of each particle, which is used to convert force to acceleration. Finally, <kbd>DeltaT</kbd> is the time-step size, which is used in the Euler method for the integration of the equations of motion.</p>
<p>The buffers for position and velocity are declared next. Note that the binding values here match those that we used on the OpenGL side when initializing the buffers.</p>
<p>Within the main function, we start by determining the index of the particle for which this invocation is responsible for. Since we're working with a linear list of particles, and the number<br/>
of particles is the same as the number of shader invocations, what we want is the index within the global range of invocations. This index is available via the built-in<br/>
<kbd>gl_GlobalInvocationID.x</kbd> input variable. We use the global index here because it is the index within the entire buffer that we need, not the index within our work group, which would only reference a portion of the entire array.</p>
<p>Next, we retrieve the position and velocity from their buffers, and compute the force due to each black hole, storing the sum in the <kbd>force</kbd> variable. Then, we convert the force to acceleration and update the particle's position and velocity using the Euler method. We write to the same location from which we read previously. Since invocations do not share data, this is safe.</p>
<p>In the render routine, we invoke the compute shader (step <em>2</em> in the <em>How to do it... </em>section), defining the number of work groups per dimension. In the compute shader, we specified a work group size of <kbd>1000</kbd>. Since we want one invocation per particle, we divide the total number of particles by <kbd>1000</kbd> to determine the number of work groups.</p>
<p>Finally, in step <em>3</em>, before rendering the particles, we need to invoke a memory barrier to ensure that all compute shader writes have fully executed.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter11/sceneparticles.cpp</kbd> file in the example code.</li>
<li>Refer to <a href="5e6b75a0-9f0c-4798-bc37-b5d34b53ef4a.xhtml">Chapter 9</a>, <em>Using Noise in Shaders</em>, for other particle simulations. Most of these have been implemented using transform feedback, but could instead be implemented using the compute shader.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a fractal texture using the compute shader</h1>
                
            
            
                
<p>The Mandelbrot set is based on iterations of the following complex polynomial:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/4a042f57-0298-4f05-af19-f4767eca21ac.png" style="width:9.08em;height:1.83em;"/></p>
<p><em>z</em> and <em>c</em> are complex numbers. Starting with the value <em>z = 0 + 0i</em>, we apply the iteration repeatedly until a maximum number of iterations is reached or the value of <em>z</em> exceeds a specified maximum. For a given value of <em>c</em>, if the iteration remains stable (<em>z</em> doesn't increase above the maximum) the point is inside the Mandelbrot set and we color the position corresponding to <em>c</em> black. Otherwise, we color the point based on the number of iterations it took for the value to exceed the maximum.</p>
<p>In the following image, the image of the Mandelbrot set is applied as a texture to a cube:</p>
<div><img src="img/4b5984d3-0446-42fb-9653-fc62fdba21de.png" style="width:17.08em;height:14.92em;"/></div>
<p>We'll use the compute shader to evaluate the Mandelbrot set. Since this is another image-based technique, we'll use a two-dimensional compute space with one compute shader invocation per pixel. Each invocation can work independently, and doesn't need to share any data with other invocations.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Create a texture to store the results of our fractal calculation. The image should be bound to the image texture unit <kbd>0</kbd> using <kbd>glBindImageTexture</kbd>:</p>
<pre>GLuint imgTex; 
glGenTextures(1, &amp;imgTex); 
glActiveTexture(GL_TEXTURE0); 
glBindTexture(GL_TEXTURE_2D, imgTex); 
glTexStorage2D(GL_TEXTURE_2D, 1, GL_RGBA8, 256, 256);  <br/>glBindImageTexture(0, imgTex, 0, GL_FALSE, 0, GL_READ_WRITE,  
                   GL_RGBA8); </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>Perform the following steps:</p>
<ol>
<li>In the compute shader, we start by defining the number of shader invocations per work group:</li>
</ol>
<pre style="padding-left: 60px">layout( local_size_x = 32, local_size_y = 32 ) in; </pre>
<ol start="2">
<li>Next, we declare the output image as well as some other uniform variables:</li>
</ol>
<pre style="padding-left: 60px">layout( binding = 0, rgba8) uniform image2D ColorImg; 
#define MAX_ITERATIONS 100 
uniform vec4 CompWindow; 
uniform uint Width = 256; 
uniform uint Height = 256; </pre>
<ol start="3">
<li>We define a function to compute the number of iterations for a given position on the complex plane:</li>
</ol>
<pre style="padding-left: 60px">uint mandelbrot( vec2 c ) { 
  vec2 z = vec2(0.0,0.0); 
  uint i = 0; 
  while(i &lt; MAX_ITERATIONS &amp;&amp; (z.x*z.x + z.y*z.y) &lt; 4.0) { 
    z = vec2( z.x*z.x-z.y*z.y+c.x, 2 * z.x*z.y + c.y );  
    i++; 
  } 
  return i; 
} </pre>
<ol start="4">
<li>In the main function, we start by computing the size of a pixel in the complex space:</li>
</ol>
<pre style="padding-left: 60px">void main() { 
  float dx = (CompWindow.z - CompWindow.x) / Width;  
  float dy = (CompWindow.w - CompWindow.y) / Height;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>Then, we determine the value of <kbd>c</kbd> for this invocation:</li>
</ol>
<pre style="padding-left: 60px">  vec2 c = vec2(  
      dx * gl_GlobalInvocationID.x + CompWindow.x, 
      dy * gl_GlobalInvocationID.y + CompWindow.y); </pre>
<ol start="6">
<li>Next, we call the <kbd>mandelbrot</kbd> function and determine the color based on the number of iterations:</li>
</ol>
<pre style="padding-left: 60px">  uint i = mandelbrot(c);  
  vec4 color = vec4(0.0,0.5,0.5,1); 
  if( i &lt; MAX_ITERATIONS ) { 
    if( i &lt; 5 )  
         color = vec4(float(i)/5.0,0,0,1); 
    else if( i &lt; 10 )  
         color = vec4((float(i)-5.0)/5.0,1,0,1); 
    else if( i &lt; 15 )  
         color = vec4(1,0,(float(i)-10.0)/5.0,1); 
    else color = vec4(0,0,1,0); 
  } 
  else 
    color = vec4(0,0,0,1); </pre>
<ol start="7">
<li>We then write the color to the output image:</li>
</ol>
<pre style="padding-left: 60px">  imageStore(ColorImg,  
             ivec2(gl_GlobalInvocationID.xy), color);  
} </pre>
<ol start="8">
<li>Within the render function of the OpenGL program, we execute the compute shader with one invocation per texel, and call <kbd>glMemoryBarrier</kbd>:</li>
</ol>
<pre style="padding-left: 60px">glDispatchCompute(256/32, 256/32, 1); 
glMemoryBarrier( GL_SHADER_IMAGE_ACCESS_BARRIER_BIT ); </pre>
<ol start="9">
<li>Then, we render the scene, applying the texture to the appropriate objects.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>In step 2, the <kbd>ColorImg</kbd> uniform variable is the output image. It is defined to be located at the image texture unit <kbd>0</kbd> (via the <kbd>binding</kbd> layout option). Also note that the format is <kbd>rgb8</kbd>, which must be the same as what is used in the <kbd>glTexStorage2D</kbd> call when creating the texture.</p>
<p class="mce-root"/>
<p><kbd>MAX_ITERATIONS</kbd> is the maximum number of iterations of the complex polynomial mentioned earlier. <kbd>CompWindow</kbd> is the region of complex space with which we are working on. The first two components <kbd>CompWindow.xy</kbd> are the real and imaginary parts of the lower-left corner of the window, and <kbd>CompWindow.zw</kbd> is the upper right corner. <kbd>Width</kbd> and <kbd>Height</kbd> define the size of the texture image.</p>
<p>The <kbd>mandelbrot</kbd> function (step 3) takes a value for <kbd>c</kbd> as the parameter, and repeatedly iterates the complex function until either a maximum number of iterations is reached, or the absolute value of <kbd>z</kbd> becomes greater than <kbd>2</kbd>. Note that here, we avoid computing the square root and just compare the absolute value squared with <kbd>4</kbd>. The function returns the total number of iterations.</p>
<p>Within the main function (step 4), we start by computing the size of a pixel within the complex window (<kbd>dx</kbd>, <kbd>dy</kbd>). This is just the size of the window divided by the number of texels in each dimension.</p>
<p>The compute shader invocation is responsible for the texel located at <kbd>gl_GlobalInvocationID.xy</kbd>. We compute the point on the complex plane that corresponds to this texel next. For the <em>x</em> position (real axis), we take the size of the texel in that direction (<kbd>dx</kbd>) times <kbd>gl_GlobalInvocationID.x</kbd> (which gives us the distance from the left edge of the window), plus the position of the left edge of the window (<kbd>CompWindow.x</kbd>). A similar calculation is done for the y position (imaginary axis).</p>
<p>In step 6, we call the <kbd>mandelbrot</kbd> function with the value for <kbd>c</kbd> that was just determined, and determine a color based on the number of iterations returned.</p>
<p>In step 7, we apply the color to the output image at <kbd>gl_GlobalInvocationID.xy</kbd> using <kbd>imageStore</kbd>.</p>
<p>In the OpenGL render function (step 8), we dispatch the compute shader with enough invocations so that there is one invocation per texel. The <kbd>glMemoryBarrier</kbd> call assures that all writes to the output image are complete before continuing.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>Prior to the advent of the compute shader, we might have chosen to do this using the fragment shader. However, the compute shader gives us a bit more flexibility in defining how the work is allocated on the GPU. We can also gain memory efficiency by avoiding the overhead of a complete FBO for the purposes of a single texture.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter11/scenemandelbrot.cpp</kbd> file in the example code</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the compute shader for cloth simulation</h1>
                
            
            
                
<p>The compute shader is well-suited for harnessing the GPU for physical simulation. Cloth simulation is a prime example. In this recipe, we'll implement a simple particle-spring-based cloth simulation using the compute shader. The following is an image of the simulation of a cloth hanging by five pins (you'll have to imagine it animating):</p>
<div><img src="img/49737ff4-333c-43cc-a4d7-0fcd197f0d1d.png" style="width:16.75em;height:14.67em;"/></div>
<p>A common way to represent cloth is with a particle-spring lattice. The cloth is composed of a 2D grid of point masses, each connected to its eight neighboring masses with idealized springs. The following diagram represents one of the point masses (center) connected to its neighboring masses. The lines represent the springs. The dark lines are the horizontal/vertical springs and the dashed lines are the diagonal springs:</p>
<div><img src="img/f16c5ecd-b843-4421-9401-0ec1bb8d1fe4.png" style="width:9.75em;height:10.17em;"/></div>
<p>The total force on a particle is the sum of the forces produced by the eight springs to which it is connected. The force for a single spring is given by the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/91f33d6d-afec-42fc-9255-69d96af6732c.png" style="width:9.92em;height:2.67em;"/></p>
<p><em>K</em> is the stiffness of the spring, <em>R</em> is the rest-length of the spring (the length where the spring applies zero force), and <em>r</em> is the vector between the neighboring particle and the particle (the neighbor's position minus the particle's position).</p>
<p>Similar to the previous recipe, the process is simply to compute the total force on each particle and then integrate Newton's equations of motion using our favorite integration. Again, we'll use the Euler method for this example. For details on the Euler method, refer to the previous <em>Implementing a particle simulation with the compute shader </em>recipe.</p>
<p>This particle-spring lattice is obviously a two-dimensional structure, so it makes sense to map it to a two-dimensional compute space. We'll define rectangular work groups and use one shader invocation per particle. Each invocation needs to read the positions of its eight neighbors, compute the force on the particle, and update the particle's position and velocity.</p>
<p>Note that, in this case, each invocation needs to read the positions of the neighboring particles. Those neighboring particles will be updated by other shader invocations. Since we can't rely on any execution order for the shader invocations, we can't read and write directly to the same buffer. If we were to do so, we wouldn't know for sure whether we were reading the original positions of the neighbors or their updated positions. To avoid this problem, we'll use pairs of buffers. For each simulation step, one buffer will be designated for reading and the other for writing, then we'll swap them for the next step, and repeat.</p>
<p>It might be possible to read/write to the same buffer with careful use of local shared memory; however, there is still the issue of the particles along the edges of the work group. Their neighbor's positions are managed by another work group, and again, we have the same problem.</p>
<p>This simulation tends to be quite sensitive to numerical noise, so we need to use a very small integration time step. A value of around <kbd>0.000005</kbd> works well. Additionally, the simulation looks better when we apply a damping force to simulate air resistance. A good way to simulate air resistance is to add a force that is proportional to and in the opposite direction to the velocity, as in the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b4b10f92-db5d-47fb-8084-9d301c77303f.png" style="width:4.67em;height:1.00em;"/></p>
<p class="mce-root"/>
<p><em>D</em> is the strength of the damping force and <em>v</em> is the velocity of the particle.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Start by setting up two buffers for the particle position and two for the particle velocity. We'll bind them to the <kbd>GL_SHADER_STORAGE_BUFFER</kbd> indexed binding point at indices <kbd>0</kbd> and <kbd>1</kbd> for the position buffers and <kbd>2</kbd> and <kbd>3</kbd> for the velocity buffers. The data layout in these buffers is important. We'll lay out the particle positions/velocities in row-major order starting at the lower left and proceeding to the upper right of the lattice.</p>
<p>We'll also set up a vertex array object for drawing the cloth using the particle positions as triangle vertices. We may also need buffers for normal vectors and texture coordinates. For brevity, I'll omit them from this discussion, but the example code for this book includes them.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>Perform the following steps:</p>
<ol>
<li>In the compute shader, we start by defining the number of invocations per work group:</li>
</ol>
<pre style="padding-left: 60px">layout( local_size_x = 10, local_size_y = 10 ) in; </pre>
<ol start="2">
<li>Then, we define a set of uniform variables for the simulation parameters:</li>
</ol>
<pre style="padding-left: 60px">uniform vec3 Gravity = vec3(0,-10,0); 
uniform float ParticleMass = 0.1; 
uniform float ParticleInvMass = 1.0 / 0.1; 
uniform float SpringK = 2000.0; 
uniform float RestLengthHoriz; 
uniform float RestLengthVert; 
uniform float RestLengthDiag; 
uniform float DeltaT = 0.000005; 
uniform float DampingConst = 0.1; </pre>
<ol start="3">
<li>Next, declare the shader storage buffer pairs for the position and velocity:</li>
</ol>
<pre style="padding-left: 60px">layout(std430, binding=0) buffer PosIn { 
  vec4 PositionIn[]; 
}; 
layout(std430, binding=1) buffer PosOut { 
  vec4 PositionOut[]; 
}; 
layout(std430, binding=2) buffer VelIn { 
  vec4 VelocityIn[]; 
}; 
layout(std430, binding=3) buffer VelOut { 
  vec4 VelocityOut[]; 
}; </pre>
<ol start="4">
<li>In the main function, we get the position of the particle for which this invocation<br/>
is responsible for:</li>
</ol>
<pre style="padding-left: 60px">void main() { 
  uvec3 nParticles = gl_NumWorkGroups * gl_WorkGroupSize; 
  uint idx = gl_GlobalInvocationID.y * nParticles.x +  
             gl_GlobalInvocationID.x; 
 
  vec3 p = vec3(PositionIn[idx]); 
  vec3 v = vec3(VelocityIn[idx]), r; </pre>
<ol start="5">
<li>Initialize our force with the force due to gravity:</li>
</ol>
<pre style="padding-left: 60px">  vec3 force = Gravity * ParticleMass; </pre>
<ol start="6">
<li>Add the force due to the particle before this one:</li>
</ol>
<pre style="padding-left: 60px">  if( gl_GlobalInvocationID.y &lt; nParticles.y - 1 ) { 
    r = PositionIn[idx + nParticles.x].xyz - p; 
    force += normalize(r)*SpringK*(length(r) -  
                                 RestLengthVert); 
  }  </pre>
<ol start="7">
<li>Repeat the preceding steps for the following particles and to the left and right. Then, add the force due to the particle that is diagonally above and to the left:</li>
</ol>
<pre style="padding-left: 60px">  if( gl_GlobalInvocationID.x &gt; 0 &amp;&amp;  
      gl_GlobalInvocationID.y &lt; nParticles.y - 1 ) { 
    r = PositionIn[idx + nParticles.x - 1].xyz - p; 
    force += normalize(r)*SpringK*(length(r) -  
                                 RestLengthDiag); 
  } </pre>
<ol start="8">
<li>Repeat the preceding steps for the other three diagonally connected particles. Then, add the damping force:</li>
</ol>
<pre style="padding-left: 60px">  force += -DampingConst * v;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="9">
<li>Next, we integrate the equations of motion using the Euler method:</li>
</ol>
<pre style="padding-left: 60px">  vec3 a = force * ParticleInvMass; 
  PositionOut[idx] = vec4( 
      p + v * DeltaT + 0.5 * a * DeltaT * DeltaT, 1.0); 
  VelocityOut[idx] = vec4( v + a * DeltaT, 0.0); </pre>
<ol start="10">
<li>Finally, we pin some of the top verts so that they do not move:</li>
</ol>
<pre style="padding-left: 60px">  if( gl_GlobalInvocationID.y == nParticles.y - 1 &amp;&amp;  
      (gl_GlobalInvocationID.x == 0 ||  
       gl_GlobalInvocationID.x == nParticles.x / 4 || 
       gl_GlobalInvocationID.x == nParticles.x * 2 / 4 || 
       gl_GlobalInvocationID.x == nParticles.x * 3 / 4 || 
       gl_GlobalInvocationID.x == nParticles.x - 1)) { 
    PositionOut[idx] = vec4(p, 1.0); 
    VelocityOut[idx] = vec4(0,0,0,0); 
  } 
} </pre>
<ol start="11">
<li>Within the OpenGL render function, we invoke the compute shader so that each work group is responsible for 100 particles. Since the time step size is so small, we need to execute the process many times (<kbd>1000</kbd>), each time swapping the input and output buffers:</li>
</ol>
<pre style="padding-left: 60px">for( int i = 0; i &lt; 1000; i++ ) { 
  glDispatchCompute(nParticles.x/10, nParticles.y/10, 1); 
  glMemoryBarrier( GL_SHADER_STORAGE_BARRIER_BIT ); 
 
  // Swap buffers 
  readBuf = 1 - readBuf; 
 
  glBindBufferBase(GL_SHADER_STORAGE_BUFFER,0, 
                    posBufs[readBuf]); 
  glBindBufferBase(GL_SHADER_STORAGE_BUFFER,1, 
                   posBufs[1-readBuf]); 
  glBindBufferBase(GL_SHADER_STORAGE_BUFFER,2, 
                   velBufs[readBuf]); 
  glBindBufferBase(GL_SHADER_STORAGE_BUFFER,3, 
                   velBufs[1-readBuf]); 
} </pre>
<ol start="12">
<li>Finally, we render the cloth using the position data from the position buffer.</li>
</ol>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>We use <kbd>100</kbd> invocations per work group, <kbd>10</kbd> in each dimension. The first statement in the compute shader defines the number of invocations per work group:</p>
<pre>layout( local_size_x = 10, local_size_y = 10 ) in; </pre>
<p>The uniform variables that follow define the constants in the force equations and the rest the lengths for each of the horizontal, vertical, and diagonal springs. The time step size is <kbd>DeltaT</kbd>. The position and velocity buffers are declared next. We define the position buffers at binding indexes <kbd>0</kbd> and <kbd>1</kbd>, and the velocity buffers at indexes <kbd>2</kbd> and <kbd>3</kbd>.</p>
<p>In the main function (step 4), we start by determining the number of particles in each dimension. This is going to be the same as the number of work groups times the work group size. Next, we determine the index of the particle for which this invocation is responsible for. Since the particles are organized in the buffers in row-major order, we compute the index by the global invocation ID in the <em>y</em> direction times the number of particles in the <em>x</em> dimension, plus the global invocation ID in the <em>x</em> direction.</p>
<p>In step 5, we initialize our force with the gravitational force, <kbd>Gravity</kbd> times the mass of a particle (<kbd>ParticleMass</kbd>). Note that it's not really necessary here to multiply by the mass since all particles have the same mass. We could just pre-multiply the mass into the gravitational constant.</p>
<p>In steps 6 and 7, we add the force on this particle due to each of the eight neighboring particles connected by virtual springs. For each spring, we add the force due to that spring. However, we first need to check to see if we are on the edge of the lattice. If we are, there may not be a neighboring particle (see the following diagram).</p>
<p>For example, in the preceding code, when computing the force due to the preceding spring/particle, we verify that <kbd>gl_GlobalInvocationID.y</kbd> is less than the number of particles in the <em>y</em> dimension minus one. If that is true, there must be a particle above this one. Otherwise, the current particle is on the top edge of the lattice and there is no neighboring particle above it. (Essentially, <kbd>gl_GlobalInvocationID</kbd> contains the particle's location in the overall lattice.) We can do a similar test for the other three horizontal/vertical directions. When computing the force for the diagonally connected particles, we need to check that we're not on a horizontal and a vertical edge. For example, in the preceding code, we're looking for the particle that is above and to the left, so we check that <kbd>gl_GlobalInvocationID.x</kbd> is greater than zero (not on the left edge), and that <kbd>gl_GlobalInvocationID.y</kbd> is less than the number of particles in the y direction minus one (not on the top edge):</p>
<div><img src="img/bb92f5f0-56e7-447f-a321-ca314767ae5d.png" style="width:21.33em;height:13.17em;"/></div>
<p>Once we verify that the neighboring particle exists, we compute the force due to the spring connected to that particle and add it to the total force. We organized our particles in row-major order in the buffer. Therefore, to access the position of the neighboring particle, we take the index of the current particle and add/subtract the number of particles in the <em>x</em> direction to move vertically, and/or add/subtract one to move horizontally.</p>
<p>In step 8, we apply the damping force that simulates air resistance by adding to the total force <kbd>DampingConst</kbd> times the velocity. The minus sign here assures that the force is in the opposite direction of the velocity.</p>
<p>In step 9, we apply the Euler method to update the position and velocity based on the force. We multiply the force by the inverse of the particle mass to get the acceleration, then store the results of the Euler integration into the corresponding positions in the output buffers.</p>
<p>Finally, in step 10, we reset the position of the particle if it is located at one of the five pin positions at the top of the cloth.</p>
<p>Within the OpenGL render function (step 11), we invoke the compute shader multiple times, switching the input/output buffers after each invocation. After calling <kbd>glDispatchCompute</kbd>, we issue a <kbd>glMemoryBarrier</kbd> call to make sure that all shader writes have completed before swapping the buffers. Once that is complete, we go ahead and render the cloth using the positions from the shader storage buffer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>For rendering, it is useful to have normal vectors. One option is to create another compute shader to recalculate the normal vectors after the positions are updated. For example, we might execute the preceding compute shader 1,000 times, dispatch the other compute shader once to update the normals, and then render the cloth.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Additionally, we may be able to achieve better performance with the use of local shared data within the work group. In the preceding implementation, the position of each particle is read a maximum of eight times. Each read can be costly in terms of execution time. It is faster to read from memory that is closer to the GPU. One way to achieve this is to read data into local shared memory once, and then read from the shared memory for subsequent reads. In the next recipe, we'll see an example of how this is done. It would be straightforward to update this recipe in a similar way.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter11/scenecloth.cpp</kbd> file in the example code</li>
<li>The <em>Implementing an edge detection filter with the compute shader</em> recipe</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing an edge detection filter with the compute shader</h1>
                
            
            
                
<p>In the <em>Applying an edge detection filter</em> recipe in <a href="827d2689-d7e7-4188-a7bc-2eb4d813e88d.xhtml">Chapter 6</a>, <em>Image Processing and Screen Space Techniques</em>, we saw an example of how to implement edge detection using the fragment shader. The fragment shader is well-suited for many image-processing operations, because we can trigger the execution of the fragment shader for each pixel by rendering a screen-filling quad. Since image processing filters are often applied to the result of a render, we can render to a texture, then invoke the fragment shader for each screen pixel (by rendering a quad), and each fragment shader invocation is then responsible for processing a single pixel. Each invocation might need to read from several locations in the (rendered) image texture, and a texel might be read multiple times from different invocations.</p>
<p>This works well for many situations, but the fragment shader was not designed for image processing. With the compute shader, we can have more fine-grained control over the distribution of shader invocations, and we can make use of local shared memory to gain a bit more efficiency with data reads.</p>
<p>In this example, we'll re-implement the edge detection filter using the compute shader. We'll make use of local (work group) shared memory to gain additional speed. Since this local memory is closer to the GPU, memory access is faster than it would be when reading directly from the shader storage buffers (or textures).</p>
<p>As with the previous recipe, we'll implement this using the Sobel operator, which is made up of two 3 x 3 filter kernels which is, shown as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/14262d3a-5189-4b11-a0ce-31960810877c.png" style="width:17.75em;height:3.67em;"/></p>
<p>For details on the Sobel operator, refer to <a href="827d2689-d7e7-4188-a7bc-2eb4d813e88d.xhtml">Chapter 6</a>, <em>Image Processing and Screen Space Techniques</em>. The key point here is that in order to compute the result for a given pixel, we need to read the values of the eight neighboring pixels. This means that the value of each pixel needs to be fetched up to eight times (when processing the neighbors of that pixel). To gain some additional speed, we'll copy the needed data into local shared memory so that, within a work group, we can read from the shared memory rather than fetching it from the shader storage buffer.</p>
<p>Work group shared memory is generally faster to access than texture or shader storage memory.</p>
<p>In this example, we'll use one compute shader invocation per pixel, and a 2D work group size of 25 x 25. Before computing the Sobel operator, we'll copy the corresponding pixel values into local shared memory for the work group. For each pixel, in order to compute the filter, we need to read the values of the eight neighboring pixels. In order to do so for the pixels on the edge of the work group, we need to include in our local memory an extra strip of pixels outside the edges of the work group. Therefore, for a work group size of 25 x 25, we'll need a storage size of 27 x 27.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Start by setting up for rendering to a <strong>framebuffer object</strong> (<strong>FBO</strong>) with a color texture attached; we'll render the raw pre-filtered image to this texture. Create a second texture to receive the output from the edge-detection filter. Bind this latter texture to unit <kbd>0</kbd>. We'll use this as the output from the compute shader. Bind the FBO texture to image texture unit <kbd>0</kbd>, and the second texture to image texture unit <kbd>1</kbd> using <kbd>glBindImageTexture</kbd>.</p>
<p>Next, set up a vertex/fragment shader pair for rendering directly to the FBO, and for rendering a full-screen texture.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<p>Perform the following steps:</p>
<ol>
<li>In the compute shader, as usual, we start by defining the number of shader invocations per work group:</li>
</ol>
<pre style="padding-left: 60px">layout (local_size_x = 25, local_size_y = 25) in; </pre>
<ol start="2">
<li>Next, we declare uniform variables for our input and output images and for the edge detection threshold. The input image is the rendered image from the FBO, and the output image will be the result of the edge detection filter:</li>
</ol>
<pre style="padding-left: 60px">uniform float EdgeThreshold = 0.1; 
layout(binding=0, rgba8) uniform image2D InputImg; 
layout(binding=1, rgba8) uniform image2D OutputImg; </pre>
<ol start="3">
<li>Then, we declare our work group's shared memory, which is an array of size 27 x 27:</li>
</ol>
<pre style="padding-left: 60px">shared float 
     localData[gl_WorkGroupSize.x+2][gl_WorkGroupSize.y+2]; </pre>
<ol start="4">
<li>We also define a function for computing the luminance of a pixel called <kbd>luminance</kbd>. Since the same function was used in several previous recipes, this need not be repeated here.</li>
<li>Next, we define a function that applies the Sobel filter to the pixel that corresponds to this shader invocation. It reads directly from the local shared data:</li>
</ol>
<pre style="padding-left: 60px">void applyFilter() 
{ 
  uvec2 p = gl_LocalInvocationID.xy + uvec2(1,1); 
 
  float sx = localData[p.x-1][p.y-1] +  
            2*localData[p.x-1][p.y] + 
            localData[p.x-1][p.y+1] - 
           (localData[p.x+1][p.y-1] +  
            2 * localData[p.x+1][p.y] +  
            localData[p.x+1][p.y+1]); 
  float sy = localData[p.x-1][p.y+1] +  
             2*localData[p.x][p.y+1] +  
             localData[p.x+1][p.y+1] -  
            (localData[p.x-1][p.y-1] +  
             2 * localData[p.x][p.y-1] +  
             localData[p.x+1][p.y-1]); 
  float g = sx * sx + sy * sy; 
 
  if( g &gt; EdgeThreshold ) 
    imageStore(OutputImg,  
       ivec2(gl_GlobalInvocationID.xy), vec4(1.0)); 
  else 
    imageStore(OutputImg,  
       ivec2(gl_GlobalInvocationID.xy), vec4(0,0,0,1)); 
} </pre>
<ol start="6">
<li>In the main function, we start by copying the luminance for this pixel into the shared memory array:</li>
</ol>
<pre style="padding-left: 60px">void main() 
{ 
  localData 
   [gl_LocalInvocationID.x+1][gl_LocalInvocationID.y+1] =  
   luminance(imageLoad(InputImg,  
             ivec2(gl_GlobalInvocationID.xy)).rgb); </pre>
<ol start="7">
<li>If we're on the edge of the work group, we need to copy one or more additional pixels into the shared memory array in order to fill out the pixels around the edge. So, we need to determine whether or not we're on the edge of the work group (by examining <kbd>gl_LocalInvocationID</kbd>), and then determine which pixels we're responsible for copying. This is not complex, but is fairly involved and lengthy, due to the fact that we also must determine whether or not that external pixel actually exists. For example, if this work group is on the edge of the global image, then some of the edge pixels don't exist (are outside of the image). Due to its length, I won't include that code here. For full details, grab the code for this book from the GitHub site.</li>
<li>Once we've copied the data for which this shader invocation is responsible, we need to wait for other invocations to do the same, so here we invoke a barrier. Then, we call our <kbd>applyFilter</kbd> function to compute the filter and write the results to the output image:</li>
</ol>
<pre style="padding-left: 60px">  barrier(); 
 
  // Apply the filter using local memory 
  applyFilter(); 
}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="9">
<li>In the OpenGL render function, we start by rendering the scene to the FBO, then dispatch the compute shader, and wait for it to finish all of its writes to the output image:</li>
</ol>
<pre style="padding-left: 60px">glDispatchCompute(width/25, height/25, 1); 
glMemoryBarrier(GL_SHADER_IMAGE_ACCESS_BARRIER_BIT); </pre>
<ol start="10">
<li>Finally, we render the output image to the screen via a full-screen quad.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>In step 1, we specify 625 shader invocations per work group, 25 in each dimension. Depending on the system on which the code is running, this could be changed to better match the hardware available.</p>
<p>The uniform <kbd>image2D</kbd> variables (step 2) are the input and output images. Note the binding locations indicated in the layout qualifier. These correspond to the image units specified in the <kbd>glBindImageTexture</kbd> call within the main OpenGL program. The input image should contain the rendered scene, and corresponds to the image texture bound to the FBO. The output image will receive the result of the filter. Also note the use of <kbd>rgb8</kbd> as the format. This must be the same as the format used when creating the image using <kbd>glTexStorage2D</kbd>.</p>
<p>The <kbd>localData</kbd> array is declared in step 3 with the shared qualifier. This is our work group's local shared memory. The size is 27 x 27 in order to include an extra strip, one pixel wide along the edges. We store the luminance of all of the pixels in the work group here, plus the luminance for a strip of surrounding pixels of width one.</p>
<p>The <kbd>applyFilter</kbd> function (step 5) is where the Sobel operator is computed using the data in <kbd>localData</kbd>. It is fairly straightforward, except for an offset that needs to be applied due to the extra strip around the edges. The luminance of the pixel that this invocation is responsible for is located at:</p>
<pre>p = gl_LocalInvocationID.xy + uvec2(1,1); </pre>
<p>Without the extra strip of pixels, we could just use <kbd>gl_LocalInvocationID</kbd>, but here we need to add an offset of one in each dimension.</p>
<p>The next few statements just compute the Sobel operator, and determine the magnitude of the gradient, stored in <kbd>g</kbd>. This is done by reading the luminance of the eight nearby pixels, reading from the <kbd>localData</kbd> shared array.</p>
<p>At the end of the <kbd>applyFilter</kbd> function, we write to <kbd>OutputImg</kbd> as the result of the filter. This is either (1,1,1,1) or (0,0,0,1), depending on whether <kbd>g</kbd> is above the threshold or not. Note that here, we use <kbd>gl_GlobalInvocationID</kbd> as the location in the output image. The global ID is appropriate for determining the location within the global image, while the local ID tells us where we are within the local work group, and is more appropriate for access to the local shared array.</p>
<p>In the main function (step 6), we compute the luminance of the pixel corresponding to this invocation (at <kbd>gl_GlobalInvocationID</kbd>) and store it in the local shared memory (<kbd>localData</kbd>) at <kbd>gl_LocalInvocationID + 1</kbd>. Again, the <kbd>+ 1</kbd> is due to the additional space for the edge pixels.</p>
<p>The next step (step 7) is to copy the edge pixels. We only do so if this invocation is on the edge of the work group. Additionally, we need to determine if the edge pixels actually exist or not. For details on this, refer to the code that accompanies this book.</p>
<p>In step 8, we call the GLSL barrier function. This synchronizes all shader invocations within the work group to this point in the code, assuring that all writes to the local shared data have completed. Without calling the barrier function, there's no guarantee that all shader invocations will have finished writing to <kbd>localData</kbd>, and therefore the data might be incomplete. It is interesting (and instructive) to remove this call and observe the results.</p>
<p>Finally, we call <kbd>applyFilter</kbd> to compute the Sobel operator and write to the output image.</p>
<p>Within the OpenGL render function, we dispatch the compute shader so that there are enough work groups to cover the image. Since the work group size is 25 x 25, we invoke <em>width/25</em> work groups in the <em>x</em> dimension and <em>height/25</em> in the <em>y</em>. The result is one shader invocation per pixel in the input/output image.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">There's more...</h1>
                
            
            
                
<p>This is a straightforward example of the use of local shared memory. It is only slightly complicated by the fact that we need to deal with the extra row/column of pixels. In general, however, local shared data can be used for any type of communication between invocations within a work group. In this case, the data is not used for communication, but is instead used to increase efficiency by decreasing the global number of reads from the image.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Note that there are (sometimes stringent) limits on the size of shared memory. We can use <kbd>GL_MAX_COMPUTE_SHARED_MEMORY_SIZE</kbd> (via <kbd>glGetInteger*</kbd>) to query the maximum size available on the current hardware. The minimum required by the OpenGL specification is 32 KB.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">See also</h1>
                
            
            
                
<ul>
<li>The <kbd>chapter11/sceneedge.cpp</kbd> file in the example code</li>
<li>The <em>Applying an edge detection filter</em> recipe in <a href="827d2689-d7e7-4188-a7bc-2eb4d813e88d.xhtml">Chapter 6</a>, <em>Image Processing and Screen Space Techniques</em></li>
</ul>


            

            
        
    </body></html>