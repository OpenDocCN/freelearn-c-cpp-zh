- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring Testing Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing the code is an important part of software development. Although there
    is no support for testing in the C++ standard, there are a large variety of frameworks
    for unit testing C++ code. The purpose of this chapter is to get you started with
    several modern and widely used testing frameworks that enable you to write portable
    testing code. The frameworks that will be covered in this chapter are **Boost.Test**,
    **Google Test**, and **Catch2**.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter includes the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Boost.Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Boost.Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Boost.Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using test fixtures with Boost.Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Boost.Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Google Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Google Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Google Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using test fixtures with Google Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Google Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Catch2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Catch2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Catch2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Catch2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These three frameworks were chosen due to their wide use, rich capabilities,
    the ease with which they can be used to write and execute tests, their extensibility,
    and their customization. The following table shows a short comparison of the features
    of these three libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **Boost.Test** | **Google Test** | **Catch2 (v3)** |'
  prefs: []
  type: TYPE_TB
- en: '| Easy to install | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Header-only | Yes | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| Compiled library | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Easy to write tests | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Automatic test registration | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Supports test suites | Yes | Yes | No (indirectly with tags) |'
  prefs: []
  type: TYPE_TB
- en: '| Supports fixtures | Yes (setup/teardown) | Yes (setup/teardown) | Yes (multiple
    ways) |'
  prefs: []
  type: TYPE_TB
- en: '| Rich set of asserts | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Non-fatal asserts | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Multiple output formats | Yes (includes HRF, XML) | Yes (includes HRF, XML)
    | Yes (includes HRF, XML) |'
  prefs: []
  type: TYPE_TB
- en: '| Filtering of test execution | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| License | Boost | Apache 2.0 | Boost |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.1: Comparison of features for Boost.Test, Google Test, and Catch2'
  prefs: []
  type: TYPE_NORMAL
- en: All these features will be discussed in detail for each framework. This chapter
    has a symmetric structure, with 4 5 recipes dedicated to each testing framework.
    The first framework to look at is Boost.Test.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Boost.Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Boost.Test** is one of the oldest and most popular C++ testing frameworks.
    It provides an easy-to-use set of APIs for writing tests and organizing them into
    test cases and test suites. It has good support for asserting, exception handling,
    fixtures, and other important features required for a testing framework.'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the next few recipes, we will explore the most important features
    it has that enable you to write unit tests. In this recipe, we will see how to
    install the framework and create a simple test project.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Boost.Test framework has a macro-based API. Although you only need to use
    the supplied macros for writing tests, a good understanding of macros is recommended
    if you want to use the framework well.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to set up your environment to use Boost.Test, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the latest version of the Boost library from [http://www.boost.org/](http://www.boost.org/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unzip the content of the archive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the library using the provided tools and scripts in order to use either
    the static or shared library variant. This step is not necessary if you plan to
    use the header-only version of the library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On Linux systems, the library can also be installed using package management
    tools. For instance, on Ubuntu, you can use **app-get** to install the libboost-test-dev
    package containing the Boost.Test library as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It is recommended that you consult the online documentation of the library for
    installation steps on various systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create your first test program using the header-only variant of the Boost.Test
    library, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new, empty C++ project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do the necessary setup specific to the development environment you are using
    to make the Boost `main` folder available to the project for including header
    files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a new source file to the project with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you want to link against the shared library version, then also define the
    `BOOST_TEST_DYN_LINK` macro.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build and run the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Boost.Test library can be downloaded, along with other Boost libraries,
    from [http://www.boost.org/](http://www.boost.org/). In this edition of the book,
    I used version 1.83, but the features discussed in these recipes will probably
    be available for many future versions. The `Test` library comes in three variants:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single header**: This enables you to write test programs without building
    the library; you just need to include a single header. Its limitation is that
    you can only have a single translation unit for the module; however, you can still
    split the module into multiple header files so that you can separate different
    test suites into different files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static library**: This enables you to split a module across different translation
    units, but the library needs to be built first as a static library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shared library**: This enables the same scenario as that of the static library.
    However, it has the advantage that, for programs with many test modules, this
    library is linked only once, and not once for each module, resulting in a smaller
    binary size. However, in this case, the shared library must be available at runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For simplicity, we will use the single-header variant in this book. In the case
    of static and shared library variants, you’d need to build the library. The downloaded
    archive contains scripts for building the library. However, the exact steps vary,
    depending on the platform and the compiler; they will not be covered here but
    are available online.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several terms and concepts that you need to understand in order to
    use the library:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Test module** is a program that performs tests. There are two types of modules:
    **single-file** (when you use the single-header variant) and **multifile** (when
    you use either the static or shared variant).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test assertion** is a condition that is checked by a test module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test case** is a group of one or more test assertions that is independently
    executed and monitored by a test module so that if it fails or leaks uncaught
    exceptions, the execution of other tests will not be stopped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test suite** is a collection of one or more test cases or test suites.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test unit** is either a test case or a test suite.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test tree** is a hierarchical structure of test units. In this structure,
    test cases are leaves and test suites are non-leaves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test runner** is a component that, given a test tree, performs the necessary
    initialization, execution of tests, and results reporting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test report** is the report produced by the test runner from executing the
    tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test log** is the recording of all the events that occur during the execution
    of the test module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test setup** is the part of the test module responsible for the initialization
    of the framework, construction of the test tree, and individual test case setups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test cleanup** is a part of the test module responsible for cleanup operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test fixture** is a pair of setup and cleanup operations that are invoked
    for multiple test units in order to avoid repetitive code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these concepts defined, it is possible to explain the sample code listed
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#define BOOST_TEST_MODULE My first test module` defines a stub for module
    initialization and sets a name for the main test suite. This must be defined before
    you include any library header.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`#include <boost/test/included/unit_test.hpp>` includes the single-header library,
    which includes all the other necessary headers.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`BOOST_AUTO_TEST_CASE(first_test_function)` declares a test case without parameters
    (`first_test_function`) and automatically registers it to be included in the test
    tree as part of the enclosing test suite. In this example, the test suite is the
    main test suite defined by `BOOST_TEST_MODULE`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`BOOST_TEST(true);` performs a test assertion.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output of executing this test module is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you don’t want the library to generate the `main()` function but want to
    write it yourself, then you need to define a couple more macros – `BOOST_TEST_NO_MAIN`
    and `BOOST_TEST_ALTERNATIVE_INIT_API` – before you include any of the library
    headers. Then, in the `main()` function that you supply, invoke the default test
    runner called `unit_test_main()` by providing the default initialization function
    called `init_unit_test()` as an argument, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to customize the initialization function of the test runner.
    In this case, you must remove the definition of the `BOOST_TEST_MODULE` macro
    and instead write an initialization function that takes no arguments and returns
    a `bool` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to customize the initialization function without writing the
    `main()` function yourself. In this case, the `BOOST_TEST_NO_MAIN` macro should
    not be defined and the initialization function should be called `init_unit_test()`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Boost.Test*, to see how to create test suites
    and test cases using the single-header version of the Boost.Test library, as well
    as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Boost.Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The library provides both an automatic and manual way of registering test cases
    and test suites to be executed by the test runner. Automatic registration is the
    simplest way because it enables you to construct a test tree just by declaring
    test units. In this recipe, we will see how to create test suites and test cases
    using the single-header version of the library, as well as how to run tests.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To exemplify the creation of test suites and test cases, we will use the following
    class, which represents a three-dimensional point. This implementation contains
    methods for accessing the properties of a point, comparison operators, a stream
    output operator, and a method for modifying the position of a point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Before you go any further, notice that the test cases in this recipe contain
    erroneous tests on purpose so that they produce failures.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following macros to create test units:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a test suite, use `BOOST_AUTO_TEST_SUITE(name)` and `BOOST_AUTO_TEST_SUITE_END()`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create a test case, use `BOOST_AUTO_TEST_CASE(name)`. Test cases are defined
    between `BOOST_AUTO_TEST_SUITE(name)` and `BOOST_AUTO_TEST_SUITE_END()`, as shown
    in the following code snippet:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create a nested test suite, define a test suite inside another test suite:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To add decorators to a test unit, add an additional parameter to the test unit’s
    macros. Decorators could include description, label, precondition, dependency,
    fixture, and so on. Refer to the following code snippet, which illustrates this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute the tests, do the following (notice that the command line is Windows-specific,
    but it should be trivial to replace that with the one specific to Linux or macOS):'
  prefs: []
  type: TYPE_NORMAL
- en: 'To execute the entire test tree, run the program (the test module) without
    any parameters:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute a single test suite, run the program with the argument `run_test`,
    specifying the path of the test suite:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute a single test case, run the program with the argument `run_test`,
    specifying the path of the test case:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute a collection of test suites and test cases defined under the same
    label, run the program with the argument `run_test`, specifying the label name
    prefixed with `@`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A test tree is a hierarchy of test cases and test suites, which also includes
    the fixtures and additional dependencies. A test suite can contain one or more
    test cases and other nested test suites as well. Test suites are similar to namespaces
    in the sense that they can be stopped and restarted multiple times in the same
    file or in different files. Automatic registration of test suites is done with
    the macros `BOOST_AUTO_TEST_SUITE`, which requires a name, and `BOOST_AUTO_TEST_SUITE_END`.
    Automatic registration of test cases is done with `BOOST_AUTO_TEST_CASE`. Test
    units (whether they’re cases or suites) become members of the closest test suite.
    Test units defined at the file scope level become members of the master test suite
    - the implicit test suite created with the `BOOST_TEST_MODULE` declaration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both test suites and test cases can be decorated with a series of attributes
    that affect how test units will be processed during the execution of the test
    module. The currently supported decorators are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`depends_on`: This indicates a dependency between the current test unit and
    a designated test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`description`: This provides a semantic description of a test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`enabled` / `disabled`: These set the default run status of a test unit to
    either `true` or `false`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`enable_if<bool>`: This sets the default run status of a test unit to either
    `true` or `false`, depending on the evaluation of a compile-time expression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expected_failures`: This indicates the expected failures for a test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fixture`: This specifies a pair of functions (startup and cleanup) to be called
    before and after the execution of a test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label`: With this, you can associate a test unit with a label. The same label
    can be used for multiple test units, and a test unit can have multiple labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`precondition`: This associates a predicate with a test unit, which is used
    at runtime to determine the run status of the test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeout`: Specifies a timeout for a unit test, in wall-clock time. If the
    test lasts longer than the specified timeout, the test fails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tolerance`: This decorator specifies the default comparison tolerance for
    the floating-point type FTP in the decorated test unit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the execution of a test case results in an unhandled exception, the framework
    will catch the exception and terminate the execution of the test case with a failure.
    However, the framework provides several macros to test whether a particular piece
    of code raises, or does not raise, exceptions. For more information, see the next
    recipe, *Asserting with Boost.Test*.
  prefs: []
  type: TYPE_NORMAL
- en: The test units that compose the module’s test tree can be executed entirely
    or partially. In both cases, to execute the test units, execute the (binary) program,
    which represents the test module. To execute only some of the test units, use
    the `--run_test` command-line option (or `--t` if you want to use a shorter name).
    This option allows you to filter the test units and specify either a path or a
    label. A path consists of a sequence of test suite and/or test case names, such
    as `test_construction` or `test_operations`/`test_methods`/`test_offset`. A label
    is a name defined with the `label` decorator and is prefixed with `@` for the
    `run_test` parameter. This parameter is repeatable, which means you can specify
    multiple filters on it.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Getting started with Boost.Test*, to learn how to install the Boost.Test framework
    and how to create a simple test project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Boost.Test*, to explore the rich set of assertion macros from
    the Boost.Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Boost.Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A test case contains one or more tests. The Boost.Test library provides a series
    of APIs in the form of macros to write tests. In the previous recipe, you learned
    a bit about the `BOOST_TEST` macro, which is the most important and widely used
    macro in the library. In this recipe, we will discuss how the `BOOST_TEST` macro
    can be used in further detail.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should now be familiar with writing test suites and test cases, a topic
    we covered in the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following list shows some of the most commonly used APIs for performing
    tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BOOST_TEST`, in its plain form, is used for most tests:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_TEST`, along with the `tolerance()` manipulator, is used to indicate
    the tolerance of floating-point comparisons:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_TEST`, along with the `per_element()` manipulator, is used to perform
    an element-wise comparison of containers (even of different types):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_TEST`, along with the ternary operator and compound statements using
    the logical `||` or `&&`, requires an extra set of parentheses:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_ERROR` is used to unconditionally fail a test and produce a message
    in the report. This is equivalent to `BOOST_TEST(false, message)`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_TEST_WARN` is used to produce a warning in the report in case a test
    is failing, without increasing the number of encountered errors and stopping the
    execution of the test case:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_TEST_REQUIRE` is used to ensure that test case pre-conditions are met;
    the execution of the test case is stopped otherwise:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_FAIL` is used to unconditionally stop the execution of the test case,
    increase the number of encountered errors, and produce a message in the report.
    This is equivalent to `BOOST_TEST_REQUIRE(false, message)`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`BOOST_IS_DEFINED` is used to check whether a particular preprocessor symbol
    is defined at runtime. It is used together with `BOOST_TEST` to perform validation
    and logging:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The library defines a variety of macros and manipulators for performing test
    assertions. The most commonly used one is `BOOST_TEST`. This macro simply evaluates
    an expression; if it fails, it increases the error count but continues the execution
    of the test case. It has three variants actually:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BOOST_TEST_CHECK` is the same as `BOOST_TEST` and is used to perform checks,
    as described in the previous section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BOOST_TEST_WARN` is used for assertions meant to provide information, without
    increasing the error count and stopping the execution of the test case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BOOST_TEST_REQUIRE` is intended to ensure that pre-conditions that are required
    for test cases to continue execution are met. Upon failure, this macro increases
    the error count and stops the execution of the test case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general form of the test macro is `BOOST_TEST(statement)`. This macro provides
    rich and flexible reporting capabilities. By default, it shows not only the statement
    but also the value of the operands, to enable quick identification of the failure’s
    cause.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the user could provide an alternative failure description; in this
    scenario, the message is logged in the test report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This macro also allows you to control the comparison process with special support
    for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is a floating-point comparison, where tolerance can be defined to
    test equality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Secondly, it supports a container’s comparison using several methods: default
    comparison (using the overloaded operator ==), per-element comparison, and lexicographic
    comparison (using the lexicographical order). Per-element comparison enables the
    comparison of different types of containers (such as vector and list) in the order
    given by the forward iterators of the container; it also takes into account the
    size of the container (meaning that it first tests the sizes and, only if they
    are equal, continues with the comparison of the elements).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, it supports bitwise comparison of the operands. Upon failure, the framework
    reports the index of the bit where the comparison failed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `BOOST_TEST` macro does have some limitations. It cannot be used with compound
    statements that use a comma, because such statements would be intercepted and
    handled by the preprocessor or the ternary operator, and compound statements using
    the logical operators `||` and `&&`. The latter cases have a workaround: a second
    pair of parentheses, as in `BOOST_TEST((statement))`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Several macros are available for testing whether a particular exception is
    raised during the evaluation of an expression. In the following list, `<level>`
    is either `CHECK`, `WARN`, or `REQUIRE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BOOST_<level>_NO_THROW(expr)` checks whether an exception is raised from the
    `expr` expression. Any exception raised during the evaluation of `expr` is caught
    by this assertion and is not propagated to the test body. If any exception occurs,
    the assertion fails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BOOST_<level>_THROW(expr, exception_type)` checks whether an exception of
    `exception_type` is raised from the `expr` expression. If the expression `expr`
    does not raise any exception, then the assertion fails. Exceptions of types other
    than `exception_type` are not caught by this assertion and can be propagated to
    the test body. Uncaught exceptions in a test case are caught by the execution
    monitor, but they result in failed test cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BOOST_<level>_EXCEPTION(expr, exception_type, predicate)` checks whether an
    exception of `exception_type` is raised from the `expr` expression. If so, it
    passes the expression to the predicate for further examination. If no exception
    is raised or an exception of a type different than `exception_type` is raised,
    then the assertion behaves like `BOOST_<level>_THROW`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This recipe discussed only the most common APIs for testing and their typical
    usage. However, the library provides many more APIs. For further reference, check
    the online documentation. For version 1.83, refer to [https://www.boost.org/doc/libs/1_83_0/libs/test/doc/html/index.html](https://www.boost.org/doc/libs/1_83_0/libs/test/doc/html/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Boost.Test*, to see how to create test suites
    and test cases using the single-header version of the Boost.Test library, as well
    as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using fixtures in Boost.Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The larger a test module is and the more similar the test cases are, the more
    likely it is to have test cases that require the same setup, cleanup, and maybe
    the same data. A component that contains these is called a **test fixture** or
    **test context**. Fixtures are important to establish a well-defined environment
    for running tests so that the results are repeatable. Examples can include copying
    a specific set of files to some location before executing the tests and deleting
    them after, or loading data from a particular data source.
  prefs: []
  type: TYPE_NORMAL
- en: Boost.Test provides several ways to define test fixtures for a test case, test
    suite, or module (globally). In this recipe, we will look at how fixtures work.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The examples in this recipe use the following classes and functions for specifying
    test unit fixtures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The first two are classes whose constructors represent the setup function and
    the destructors represent the teardown function. At the end of the sample, there
    is a pair of functions, `fixture_setup()` and `fixture_cleanup()`, that represent
    functions for a test’s setup and cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following methods to define test fixtures for one or multiple test
    units:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To define a fixture for a particular test case, use the `BOOST_FIXTURE_TEST_CASE`
    macro:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To define a fixture for all the test cases in a test suite, use `BOOST_FIXTURE_TEST_SUITE`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To define a fixture for all the test units in a test suite, except for one
    or several test units, use `BOOST_FIXTURE_TEST_SUITE`. You can overwrite it to
    a particular test unit with `BOOST_FIXTURE_TEST_CASE` for a test case and `BOOST_FIXTURE_TEST_SUITE`
    for a nested test suite:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To define more than a single fixture for a test case or test suite, use `boost::unit_test::fixture`
    with the `BOOST_AUTO_TEST_SUITE` and `BOOST_AUTO_TEST_CASE` macros:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To use free functions as setup and teardown operations in the case of a fixture,
    use `boost::unit_test::fixture`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To define a fixture for the module, use `BOOST_GLOBAL_FIXTURE`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The library supports a couple of fixture models:'
  prefs: []
  type: TYPE_NORMAL
- en: A **class model**, where the constructor acts as the setup function and the
    destructor as the cleanup function. An extended model allows the constructor to
    have one parameter. In the preceding example, `standard_fixture` implemented the
    first model and `extended_fixture` implemented the second model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A **pair of free functions**: one that defines the setup and the other, which
    is optional, that implements the cleanup code. In the preceding example, we came
    across these when discussing `fixture_setup()` and `fixture_cleanup()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fixtures implemented as classes can also have data members, and these members
    are made available to the test unit. If a fixture is defined for a test suite,
    it is available implicitly to all the test units that are grouped under this test
    suite. However, it is possible that test units contained in such a test suite
    could redefine the fixture. In this case, the fixture defined in the closest scope
    is the one available to the test unit.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to define multiple fixtures for a test unit. However, this is
    done with the `boost::unit_test::fixture()` decorator, not with macros. The test
    suite and test case are defined, in this case, with the `BOOST_TEST_SUITE`/`BOOST_AUTO_TEST_SUITE`
    and `BOOST_TEST_CASE`/`BOOST_AUTO_TEST_CASE` macros. Multiple `fixture()` decorators
    can be composed together with `operator *`, as seen in the previous section. The
    purpose of this decorator is to define a setup and a teardown function to be called
    before and after the execution of the test unit. It comes in several forms, either
    with a pair of functions or with a class where the constructor and destructor
    play the role of the setup/teardown functions. A drawback, or perhaps misleading
    part, of using the fixture decorator with a class that contains member data is
    that these members will not be available for the test units.
  prefs: []
  type: TYPE_NORMAL
- en: A new fixture object is constructed for each test case when it is executed,
    and the object is destroyed at the end of the test case.
  prefs: []
  type: TYPE_NORMAL
- en: The fixture state is not shared among different test cases. Therefore, the constructor
    and destructor are called once for each test case. You must make sure these special
    functions do not contain code that is supposed to be executed only once per module.
    If this is the case, you should set a global fixture for the entire module.
  prefs: []
  type: TYPE_NORMAL
- en: 'A global fixture uses the generic test class model (the model with the default
    constructor); you can define any number of global fixtures (allowing you to organize
    setup and cleanup by category, if necessary). Global fixtures are defined with
    the `BOOST_GLOBAL_FIXTURE` macro, and they have to be defined at the test file
    scope (not inside any test unit). Their purpose is to define setup and teardown
    functions, represented by the constructor and destructor of a class. If the class
    also defines other members, such as data, these are not available in the test
    units:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Boost.Test*, to see how to create test suites
    and test cases using the single-header version of the Boost.Test library, as well
    as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Boost.Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The framework provides us with the ability to customize what is shown in the
    test log and test report and then format the results. Currently, there are two
    that are supported: a **human-readable format** (or **HRF**) and XML (also with
    a JUNIT format for the test log). However, it is possible to create and add your
    own format.'
  prefs: []
  type: TYPE_NORMAL
- en: A human-readable format is any form of encoding data that can be naturally read
    by humans. Text, whether encoded as ASCII or Unicode, is used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration of what is shown in the output can be done both at runtime,
    through command-line switches, and at compile time, through various APIs. During
    the execution of the tests, the framework collects all the events in a log. At
    the end, it produces a report that represents a summary of the execution with
    different levels of detail. In the case of a failure, the report contains detailed
    information about the location and the cause, including actual and expected values.
    This helps developers quickly identify the error. In this recipe, we will see
    how to control what is written in the log and the report and in which format;
    we do this using the command-line options at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the examples presented in this recipe, we will use the following test module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The next section presents how to control the test log and the test report’s
    output through command-line options.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To control the test log’s output, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Use either the `--log_format=<format>` or `-f <format>` command-line option
    to specify the log format. The possible formats are `HRF` (the default value),
    `XML`, and `JUNIT`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use either the `--log_level=<level>` or `-l <level>` command-line option to
    specify the log level. The possible log levels include `error` (default for HRF
    and XML), `warning`, `all`, and `success` (the default for JUNIT).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use either the `--log_sink=<stream or file name>` or `-k <stream or file name>`
    command-line option to specify the location where the framework should write the
    test log. The possible options are `stdout` (default for HRF and XML), `stderr`,
    or an arbitrary filename (default for JUNIT).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To control the test report’s output, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Use either the `--report_format=<format>` or `-m <format>` command-line option
    to specify the report format. The possible formats are `HRF` (the default value)
    and `XML`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use either the `--report_level=<format>` or `-r <format>` command-line option
    to specify the report level. The possible formats are `confirm` (the default value),
    `no` (for no report), `short`, and `detailed`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use either the `--report_sink=<stream or file name>` or `-e <stream or file
    name>` command-line option to specify the location where the framework should
    write the report log. The possible options are `stderr` (the default value), `stdout`,
    or an arbitrary filename.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you run the test module from a console/terminal, you see both the test
    log and test report, with the test report following the test log. For the test
    module shown earlier, the default output is as follows. The first three lines
    represent the test log, while the last line represents the test report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The content of both the test log and test report can be made available in several
    formats. The default is HRF; however, the framework also supports XML, and for
    the test log, the JUNIT format. This is a format intended for automated tools,
    such as continuous build or integration tools. Apart from these options, you can
    implement your own format for the test log by implementing your own class derived
    from `boost::unit_test::unit_test_log_formatter`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how to format the test log (the first example)
    and the test report (the second example) using XML (each highlighted in bold):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The log or report level represents the verbosity of the output. The possible
    values of the verbosity level of a log are shown in the following table, ordered
    from the lowest to the highest level. A higher level in the table includes all
    the messages of the levels above it:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Level** | **Messages that are reported** |'
  prefs: []
  type: TYPE_TB
- en: '| `nothing` | Nothing is logged. |'
  prefs: []
  type: TYPE_TB
- en: '| `fatal_error` | System or user fatal errors and all the messages describing
    failed assertions at the `REQUIRE` level (such as `BOOST_TEST_REQUIRE` and `BOOST_REQUIRE_`).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `system_error` | System non-fatal errors. |'
  prefs: []
  type: TYPE_TB
- en: '| `cpp_exception` | Uncaught C++ exceptions. |'
  prefs: []
  type: TYPE_TB
- en: '| `error` | Failed assertion at the `CHECK` level (`BOOST_TEST` and `BOOST_CHECK_`).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `warning` | Failed assertion at the `WARN` level (`BOOST_TEST_WARN` and `BOOST_WARN_`).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `message` | Messages generated by `BOOST_TEST_MESSAGE`. |'
  prefs: []
  type: TYPE_TB
- en: '| `test_suite` | Notification at the start and finish states of each test unit.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `all` / `success` | All the messages, including passed assertions. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.2: Possible values for the verbosity level of logs'
  prefs: []
  type: TYPE_NORMAL
- en: 'The available formats of the test report are described in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Level** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `no` | No report is produced. |'
  prefs: []
  type: TYPE_TB
- en: '| `confirm` | **Passing test**:*** No errors detected.**Skipped test**:***
    The <name> test suite was skipped; see the standard output for details.**Aborted
    test**:*** The <name> test suite was aborted; see the standard output for details.**Failed
    test without failed assertions**:*** Errors were detected in the <name> test suite;
    see the standard output for details.**Failed test**:*** N failures are detected
    in the <name> test suite.**Failed test with some failures expected**:*** N failures
    are detected (M failures are expected) in the <name> test suite. |'
  prefs: []
  type: TYPE_TB
- en: '| `detailed` | Results are reported in a hierarchical fashion (each test unit
    is reported as part of the parent test unit), but only relevant information appears.
    Test cases that do not have failing assertions do not produce entries in the report.The
    test case/suite <name> has passed/was skipped/was aborted/has failed with:N assertions
    out of M passedN assertions out of M failedN warnings out of M failedX failures
    expected |'
  prefs: []
  type: TYPE_TB
- en: '| `short` | Similar to `detailed`, but this reports information only to the
    master test suite. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.3: Available formats for a test report'
  prefs: []
  type: TYPE_NORMAL
- en: The standard output stream (`stdout`) is the default location where the test
    log is written, and the standard error stream (`stderr`) is the default location
    of the test report. However, both the test log and test report can be redirected
    to another stream or file.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these options, it is possible to specify a separate file for
    reporting memory leaks using the `--report_memory_leaks_to=<file name>` command-line
    option. If this option is not present and memory leaks are detected, they are
    reported to the standard error stream.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to the options discussed in this recipe, the framework provides
    additional compile-time APIs for controlling the output. For a comprehensive description
    of these APIs, as well as the features described in this recipe, check the framework
    documentation at [https://www.boost.org/doc/libs/1_83_0/libs/test/doc/html/index.html](https://www.boost.org/doc/libs/1_83_0/libs/test/doc/html/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Boost.Test*, to see how to create test suites
    and test cases using the single-header version of the Boost.Test library, as well
    as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Boost.Test*, to explore the rich set of assertion macros from
    the Boost.Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Google Test** is one of the most widely used testing frameworks for C++.
    The **Chromium** projects and the **LLVM** compiler are among the projects that
    are using it for unit testing. Google Test enables developers to write unit tests
    on multiple platforms using multiple compilers. Google Test is a portable, lightweight
    framework that has a simple yet comprehensive API for writing tests using asserts;
    here, tests are grouped into test suites and test suites into test programs.'
  prefs: []
  type: TYPE_NORMAL
- en: The framework provides useful features, such as repeating a test a number of
    times and breaking a test to invoke the debugger at the first failure. Its assertions
    work regardless of whether exceptions are enabled or not. The next recipe will
    cover the most important features of the framework. This recipe will show you
    how to install the framework and set up your first testing project.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Google Test framework, just like Boost.Test, has a macro-based API. Although
    you only need to use the supplied macros for writing tests, a good understanding
    of macros is recommended in order to use the framework well.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to set up your environment to use Google Test, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Clone or download the Git repository from [https://github.com/google/googletest](https://github.com/google/googletest).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you selected to download it, once you’ve done so, unzip the content of the
    archive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the framework using the provided build scripts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To create your first test program using Google Test, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new empty C++ project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do the necessary setup specific to the development environment you are using
    to make the framework’s headers folder (called `include`) available to the project
    for including header files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Link the project to the `gtest` shared library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a new source file to the project with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Build and run the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Google Test framework provides a simple and easy-to-use set of macros for
    creating tests and writing assertions. The structure of the test is also simplified
    compared to other testing frameworks, such as Boost.Test. Tests are grouped into
    test suites and test suites into test programs.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to mention several aspects related to terminology. Traditionally,
    Google Test did not use the term **test suite**. A **test case** in Google Test
    was basically a test suite and equivalent to the test suites in Boost.Test. On
    the other hand, a **test function** was equivalent to a test case. Because this
    has led to confusion, Google Test has adhered to the common terminology, used
    by the **International Software Testing Qualifications Board** (**ISTQB**), of
    test cases and test suites and has started to replace this throughout its code
    and documentation. In this book, we will use these terms.
  prefs: []
  type: TYPE_NORMAL
- en: The framework provides a rich set of assertions, both fatal and non-fatal, great
    support for exception handling, and the ability to customize the way tests are
    executed and how the output should be generated. However, unlike with the Boost.Test
    library, the test suites in Google Test cannot contain other test suites, but
    only test functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation for the framework is available on the project’s page at GitHub.
    For this edition of this book, I used Google Test framework version 1.14, but
    the code presented here works with previous versions of the framework and is expected
    to also work with future versions of the framework. The sample code shown in the
    *How to do it…* section contains the following parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#include <gtest/gtest.h>` includes the main header of the framework.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`TEST(FirstTestSuite, FirstTest)` declares a test called `FirstTest` as part
    of a test suite called `FirstTestSuite`. These names must be valid C++ identifiers
    but are not allowed to contain underscores. The actual name of a test function
    is composed through concatenation with an underscore from the name of the test
    suite and the test name. For our example, the name is `FirstTestSuite_FirstTest`.
    Tests from different test suites may have the same individual name. A test function
    has no arguments and returns `void`. Multiple tests can be grouped with the same
    test suite.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ASSERT_TRUE(a > 0);` is an assertion macro that yields a fatal error and returns
    from the current function in case the condition evaluates to `false`. The framework
    defines many more assertion macros, which we will see in the *Asserting with Google
    Test* recipe.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`testing::InitGoogleTest(&argc, argv);` initializes the framework and must
    be called before `RUN_ALL_TESTS()`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`return RUN_ALL_TESTS();` automatically detects and calls all the tests defined
    with either the `TEST()` or `TEST_F()` macro. The return value returned from the
    macro is used as the return value of the `main()` function. This is important
    because the automated testing service determines the result of a test program
    according to the value returned from the `main()` function, not the output printed
    to the `stdout` or `stderr` streams. The `RUN_ALL_TESTS()` macro must be called
    only once; calling it multiple times is not supported because it conflicts with
    some advanced features of the framework.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Executing this test program will provide the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: For many test programs, the content of the `main()` function is identical to
    the one shown in this recipe, in the example from the *How to do it...* section.
    To avoid writing such a `main()` function, the framework provides a basic implementation
    that you can use by linking your program with the `gtest_main` shared library.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Google Test framework can also be used with other testing frameworks. You
    can write tests using another testing framework, such as Boost.Test or CppUnit,
    and use the Google Test assertion macros. To do so, set the `throw_on_failure`
    flag, either from the code or command line, with the `--gtest_throw_on_failure`
    argument. Alternatively, use the `GTEST_THROW_ON_FAILURE` environment variable
    and initialize the framework, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: When you enable the `throw_on_failure` option, assertions that fail will print
    an error message and throw an exception, which will be caught by the host testing
    framework and treated as a failure. If exceptions are not enabled, then a failed
    Google Test assertion will tell your program to exit with a non-zero code, which
    again will be treated as a failure by the host testing framework.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Google Test*, to see how to create tests and
    test suites using the Google Test library, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Google Test*, to explore the various assertion macros from
    the Google Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we had a glimpse of what it takes to write simple tests
    with the Google Test framework. Multiple tests can be grouped into a test suite
    and one or more test suites grouped into a test program. In this recipe, we will
    see how to create and run tests.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the sample code in this recipe, we’ll use the `point3d` class we discussed
    in the *Writing and invoking tests with Boost.Test* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following macros to create tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TEST(TestSuiteName, TestName)` defines a test called `TestName` as part of
    a test suite called `TestSuiteName`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`TEST_F(TestSuiteWithFixture, TestName)` defines a test called `TestName` as
    part of a test suite, using a fixture called `TestSuiteWithFixture`. You’ll find
    details about how this works in the *Using test fixtures with Google Test* recipe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To execute the tests, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `RUN_ALL_TESTS()` macro to run all the tests defined in the test program.
    This must be called only once from the `main()` function after the framework has
    been initialized.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `--gtest_filter=<filter>` command-line option to filter the tests to
    run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `--gtest_repeat=<count>` command-line option to repeat the selected
    tests the specified number of times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `--gtest_break_on_failure` command-line option to attach the debugger
    to debug the test program when the first test fails.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several macros available for defining tests (as part of a test case).
    The most common ones are `TEST` and `TEST_F`. The latter is used with fixtures,
    which will be discussed in detail in the *Using test fixtures with Google Test*
    recipe. Other macros for defining tests are `TYPED_TEST` for writing typed tests
    and `TYPED_TEST_P` for writing type-parameterized tests. However, these are more
    advanced topics and are beyond the scope of this book. The `TEST` and `TEST_F`
    macros take two arguments: the first is the name of the test suite and the second
    is the name of the test. These two arguments form the full name of a test, and
    they must be valid C++ identifiers; they should not contain underscores, though.
    Different test suites can contain tests with the same name (because the full name
    is still unique). Both macros automatically register the tests with the framework;
    therefore, no explicit input is required from the user to do this.'
  prefs: []
  type: TYPE_NORMAL
- en: A test can either fail or succeed. A test fails if an assertion fails or an
    uncaught exception occurs. Except for these two instances, the test always succeeds.
  prefs: []
  type: TYPE_NORMAL
- en: 'To invoke the test, call `RUN_ALL_TESTS()`. However, you can do this only once
    in a test program and only after the framework has been initialized with a call
    to `testing::InitGoogleTest()`. This macro runs all the tests in the test program.
    However, it is possible that you select only some tests to run. You can do this
    either by setting up an environment variable called `GTEST_FILTER` with the appropriate
    filter or by passing the filter as a command-line argument with the `--gtest_filter`
    flag. If either of these two are present, the framework only runs the tests whose
    full name matches the filter. The filter may include wildcards: `*` to match any
    string and the `?` symbol to match any character. Negative patterns (what should
    be omitted) are introduced with a hyphen (`-`). The following are examples of
    filters:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Filter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=*` | Run all the tests |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=TestConstruction.*` | Run all the tests from the test suite
    called `TestConstruction` |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=TestOperations.*-TestOperations.TestLess` | Run all the tests
    from the test suite called `TestOperations`, except for a test called `TestLess`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=*Operations*:*Construction*` | Run all the tests whose full
    names contain either `Operations` or `Construction` |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=Test?` | Run all tests whose names have 5 characters and
    start with `Test`, such as `TestA`, `Test0`, or `Test_`. |'
  prefs: []
  type: TYPE_TB
- en: '| `--gtest_filter=Test??` | Run all tests whose names have 6 characters and
    start with `Test`, such as `TestAB`, `Test00`, or `Test_Z`. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.4: Examples of filters'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following listing is the output of a test program containing the tests
    shown earlier when invoked with the command-line argument `--gtest_filter=TestConstruction.*-TestConstruction.TestConstructor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'It is possible for you to disable some of the tests by prefixing either the
    name of a test with `DISABLED_` or the name of a test suite with the same identifier,
    in which case all the tests in the test suite will be disabled. This is exemplified
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: None of these tests will be executed. However, you will receive a report in
    the output stating that you have a number of disabled tests.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that this feature is only meant for temporarily disabling tests.
    This is useful when you need to perform some code changes that make tests fail
    and you don’t have time to fix them right away. Therefore, this feature should
    be used judiciously.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Getting started with Google Test*, to learn how to install the Google Test
    framework and how to create a simple test project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Google Test*, to explore the various assertion macros from
    the Google Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using test fixtures with Google Test*, to learn how to define test fixtures
    when using the Google Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Google Test framework provides a rich set of both fatal and non-fatal assertion
    macros, which resemble function calls, to verify the tested code. When these assertions
    fail, the framework displays the source file, line number, and relevant error
    message (including custom error messages) to help developers quickly identify
    the failed code. We have already seen some simple examples of how to use the `ASSERT_TRUE`
    macro; in this recipe, we will look at other available macros.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following macros to verify the tested code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `ASSERT_TRUE(condition)` or `EXPECT_TRUE(condition)` to check whether the
    condition is `true`, and `ASSERT_FALSE(condition)` or `EXPECT_FALSE(condition)`
    to check whether the condition is `false`, as shown in the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `ASSERT_XX(val1, val2)` or `EXPECT_XX(val1, val2)` to compare two values,
    where `XX` is one of the following: `EQ(val1 == val2)`, `NE(val1 != val2)`, `LT(val1
    < val2)`, `LE(val1 <= val2)`, `GT(val1 > val2)`, or `GE(val1 >= val2)`. This is
    illustrated in the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `ASSERT_STRXX(str1, str2)` or `EXPECT_STRXX(str1, str2)` to compare two
    null-terminated strings, where `XX` is one of the following: `EQ` (the strings
    have the same content), `NE` (the strings don’t have the same content), `CASEEQ`
    (the strings have the same content with the case ignored), and `CASENE` (the strings
    don’t have the same content with the case ignored). This is illustrated in the
    following code snippet:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `ASSERT_FLOAT_EQ(val1, val2)` or `EXPECT_FLOAT_EQ(val1, val2)` to check
    whether two `float` values are almost equal, and `ASSERT_DOUBLE_EQ(val1, val2)`
    or `EXPECT_DOUBLE_EQ(val1, val2)` to check whether two `double` values are almost
    equal; they should differ by at most 4 **ULP** (**units in the last place**).
    Use `ASSERT_NEAR(val1, val2, abserr)` to check whether the difference between
    the two values is not greater than the specified absolute value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `ASSERT_THROW(statement, exception_type)` or `EXPECT_THROW(statement, exception_type)`
    to check whether the statement throws an exception of the specified type, `ASSERT_ANY_THROW(statement)`
    or `EXPECT_ANY_THROW(statement)` to check whether the statement throws an exception
    of any type, and `ASSERT_NO_THROW(statement)` or `EXPECT_NO_THROW(statement)`
    to check whether the statement throws any exception:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `ASSERT_PRED1(pred, val)` or `EXPECT_PRED1(pred, val)` to check whether
    `pred(val)` returns `true`, `ASSERT_PRED2(pred, val1, val2)` or `EXPECT_PRED2(pred,
    val1, val2)` to check whether `pred(val1, val2)` returns `true`, and so on; use
    this for *n*-ary predicate functions or functors:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use `ASSERT_HRESULT_SUCCEEDED(expr)` or `EXPECT_HRESULT_SUCCEEDED(expr)` to
    check whether `expr` is a success `HRESULT`, and `ASSERT_HRESULT_FAILED(expr)`
    or `EXPECT_HRESULT_FAILED(expr)` to check whether `expr` is a failure `HRESULT`.
    These assertions are intended to be used on Windows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use `FAIL()` to generate a fatal failure and `ADD_FAILURE()` or `ADD_FAILURE_AT(filename,
    line)` to generate non-fatal failures:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All these asserts are available in two versions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ASSERT_*`: This generates fatal failures, preventing further execution of
    the current test function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EXPECT_*`: This generates non-fatal failures, which means that the execution
    of the test function continues, even if the assertion fails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `EXPECT_*` assertion if not meeting the condition is not a critical
    error or if you want the test function to continue, in order to get as many error
    messages as possible. In other cases, use the `ASSERT_*` version of the test assertions.
  prefs: []
  type: TYPE_NORMAL
- en: You will find details about the assertions presented here in the framework’s
    online documentation, which is available on GitHub at [https://github.com/google/googletest](https://github.com/google/googletest);
    this is where the project is located. A special note on floating-point comparison
    is, however, necessary. Due to round-offs (fractional parts cannot be represented
    as a finite sum of the inverse powers of two), floating-point values do not match
    exactly. Therefore, a comparison should be done within a relative error bound.
    The macros `ASSERT_EQ`/`EXPECT_EQ` are not suitable for comparing floating points,
    and the framework provides another set of assertions. `ASSERT_FLOAT_EQ`/`ASSERT_DOUBLE_EQ`
    and `EXPECT_FLOAT_EQ`/`EXPECT_DOUBLE_EQ` perform a comparison with a default error
    of 4 ULP.
  prefs: []
  type: TYPE_NORMAL
- en: 'ULP is a unit of measurement for the spacing between floating-point numbers,
    that is, the value the least significant digit represents if it is 1\. For more
    information on this, read the *Comparing Floating Point Numbers, 2012 Edition*
    article by Bruce Dawson: [https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/).'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Google Test*, to see how to create tests and
    test suites using the Google Test library, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using test fixtures with Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The framework provides support for using fixtures as reusable components for
    all the tests that are part of a test suite. It also provides support for setting
    up the global environment in which the tests will run. In this recipe, you will
    find stepwise instructions on how to define and use test fixtures, as well as
    to set up the test environment.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should now be familiar with writing and invoking tests using the Google
    Test framework, a topic that was covered earlier in this chapter, specifically
    in the *Writing and invoking tests with Google Test* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create and use a test fixture, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class derived from the `testing::Test` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the constructor to initialize the fixture and the destructor to clean it
    up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Alternatively, you can override the virtual methods `SetUp()` and `TearDown()`
    for the same purpose.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add member data and functions to the class to make them available to the tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `TEST_F` macro to define tests using fixtures, and specify the fixture
    class name as the test suite name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To customize the setup of the environment for running tests, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a class derived from `testing::Environment`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Override the virtual methods `SetUp()` and `TearDown()` to perform setup and
    cleanup operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Register the environment with a call to `testing::AddGlobalTestEnvironment()`
    before calling `RUN_ALL_TESTS()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Text fixtures enable users to share data configurations between multiple tests.
    Fixture objects are not shared between tests. A different fixture object is created
    for each test that is associated with the text function. The following operations
    are performed by the framework for each test coming from a fixture:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new fixture object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call its `SetUp()` virtual method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call the fixture’s `TearDown()` virtual method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Destroy the fixture object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can set up and clean the fixture objects in two ways: by using the constructor
    and destructor, or by using the `SetUp()` and `TearDown()` virtual methods. In
    most cases, the former way is preferred. The use of virtual methods is suitable
    in several cases, though:'
  prefs: []
  type: TYPE_NORMAL
- en: When the teardown operation throws an exception, as exceptions are not allowed
    to leave destructors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are required to use assertion macros during cleanup and you use the `--gtest_throw_on_failure`
    flag, which determines the macros to be thrown upon a failure occurring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to call virtual methods (which might be overridden in a derived
    class), as virtual calls should not be invoked from the constructor or destructor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tests that use fixtures must be defined using the `TEST_F` macro (where `_F`
    stands for fixture). Trying to declare them using the `TEST` macro will generate
    compiler errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The environments in which tests are run can also be customized. The mechanism
    is similar to test fixtures: you derive from the base `testing::Environment` class
    and override the `SetUp()` and `TearDown()` virtual functions. Instances of these
    derived environment classes must be registered with the framework with a call
    to `testing::AddGlobalTestEnvironment()`; however, this has to be done before
    you run the tests. You can register as many instances as you want, in which case
    the `SetUp()` method is called for the objects in the order they were registered
    and the `TearDown()` method is called in reverse order. You must pass dynamically
    instantiated objects to this function. The framework takes ownership of the objects
    and deletes them before the program terminates; therefore, do not delete them
    yourself.'
  prefs: []
  type: TYPE_NORMAL
- en: Environment objects are not available to the tests, nor intended to provide
    data to the tests. Their purpose is to customize the global environment for running
    the tests.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Google Test*, to see how to create tests and
    test suites using the Google Test library, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Google Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, the output of a Google Test program goes to the standard stream,
    printed in a human-readable format. The framework provides several options for
    customizing the output, including printing XML to a disk file in a JUNIT-based
    format. This recipe will explore the options available to control the output.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the purpose of this recipe, let’s consider the following test program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Its output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: We will use this simple testing program to demonstrate the various options we
    can use to control the program’s output, which are exemplified in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To control the output of a test program, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `--gtest_output` command-line option or the `GTEST_OUTPUT` environment
    variable with the `xml:filepath` string to specify the location of a file where
    the XML report is to be written:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `--gtest_color` command-line option or the `GTEST_COLOR` environment
    variable and specify either `auto`, `yes`, or `no` to indicate whether the report
    should be printed to a terminal using colors or not:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `--gtest_print_time` command-line option or the `GTEST_PRINT_TIME`
    environment variable with the value `0` to suppress the printing time each test
    takes to execute:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generating a report in an XML format does not affect the human-readable report
    printed to the terminal. The output path can indicate either a file, a directory
    (in which case a file with the name of the executable is created – if it already
    exists from a previous run, it creates a file with a new name by suffixing it
    with a number), or nothing, in which case the report is written to a file called
    `test_detail.xml` in the current directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The XML report format is based on the JUNITReport Ant task and contains the
    following main elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<testsuites>`: This is the root element and it corresponds to the entire test
    program.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<testsuite>`: This corresponds to a test suite.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<testcase>`: This corresponds to a test function, as Google Test functions
    are equivalent to test cases in other frameworks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, the framework reports the time it takes for each test to execute.
    This feature can be suppressed using the `--gtest_print_time` command-line option
    or the `GTEST_PRINT_TIME` environment variable, as shown earlier.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Google Test*, to see how to create tests and
    test suites using the Google Test library, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using test fixtures with Google Test*, to learn how to define test fixtures
    when using the Google Test library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Catch2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Catch2** is a multiparadigm testing framework for C++ and Objective-C. The
    name Catch2 follows on from Catch, the first version of the framework, which stands
    for **C++ Automated Test Cases in Headers**. It enables developers to write tests
    using either the traditional style of test functions grouped in test cases or
    the **behavior-driven development**(**BDD**) style with *given-when-then* sections.
    Tests are self-registered and the framework provides several assertion macros;
    out of these, two are used the most: one fatal (namely, `REQUIRE`) and one non-fatal
    (namely, `CHECK`). They perform expression decomposition of both the left-hand
    and right-hand side values, which are logged in case of failure. Unlike its first
    version, Catch2 no longer supports C++03\. The current version of Catch2 is v3,
    which has some significant changes when compared to Catch2 v2, such as the library
    is no longer a single-header library but works as a regular library (that needs
    to be compiled), and requires a C++14 compiler.'
  prefs: []
  type: TYPE_NORMAL
- en: For the remaining recipes of this chapter, we will learn how to write unit tests
    using Catch2 version 3.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Catch2 test framework has a macro-based API. Although you only need to use
    the supplied macros for writing tests, a good understanding of macros is recommended
    if you want to use the framework well.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to set up your environment to use the Catch2 testing framework, do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Clone or download the Git repository from [https://github.com/catchorg/Catch2](https://github.com/catchorg/Catch2).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you’ve downloaded the repository, unzip the content of the archive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To use the v3 version of Catch 2, you have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Use library merged (amalgamated) header and source files in your test project.
    These files are called `catch_amalgamated.hpp` and `catch_amalgamated.cpp`. They
    are located in the `extras` folder of the Catch2 library, and you can copy them
    into your test project if you want. The advantage of this is that you don’t have
    to deal with CMake scripts, at the expense of increased build times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use CMake to add Catch2 as a static library for your project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create your first test program using Catch2 and its amalgamated files, do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new empty C++ project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the `catch_amalgamated.hpp` and `catch_amalgamated.cpp` files from the
    `extras` folder of the Catch2 library to your test project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `catch_amalgamated.cpp` source file to your project, to be compiled
    along with your other source files (containing tests).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a new source file to the project with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Build and run the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To create your first test program with Catch2 using the CMake integration,
    do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a console/command prompt and change the directory to the location of the
    cloned/unzipped Catch2 files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Build the library using the commands shown below. On a Unix system, run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'On a Windows system, execute the following commands from a command prompt running
    with administrative privileges:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a new folder (called `Test`) for a C++ testing project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a new source file (called `main.cpp`) to this folder with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a new `CMakeLists.txt` CMake file to the `Test` folder with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run `cmake.exe` to generate/build your project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are different ways to set up your project using CMake. In this recipe,
    I provided a minimal example that works, which you can also find with the source
    files from the GitHub repo. Readers experienced with CMake may find better approaches
    than the one provided here. You can learn more about CMake from online resources.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Catch2 enables developers to write test cases as self-registered functions;
    it can even provide a default implementation for the `main()` function so that
    you can focus on testing code and writing less setup code. Test cases are divided
    into sections that are run in isolation. The framework does not adhere to the
    style of the **setup-test-teardown** architecture. Instead, the test case sections
    (or rather the innermost ones, since sections can be nested) are the units of
    testing that are executed, along with their enclosing sections. This makes the
    need for fixtures obsolete because data and setup and teardown code can be reused
    on multiple levels.
  prefs: []
  type: TYPE_NORMAL
- en: Test cases and sections are identified using strings, not identifiers (as in
    most testing frameworks). Test cases can also be tagged so that tests can be executed
    or listed based on tags. Test results are printed in a textual human-readable
    format; however, they can also be exported to XML, using either a Catch2-specific
    schema or a JUNIT ANT schema for easy integration with continuous delivery systems.
    The execution of the tests can be parameterized to break upon failure (on Windows
    and macOS) so that you can attach a debugger and inspect the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'The framework is easy to install and use. There are two alternatives, as seen
    in the *How to do it…* section:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the amalgamated files `catch_amalgamated.hpp` and `catch_amalgamated_cpp`.
    These are a merging of all the header and source files. The advantage of using
    them is that you do not have to worry about building the Catch2 library. You only
    have to copy these files to your desired location (typically inside your project),
    include the `catch_amalgamated`.hpp header in your files that contain tests, and
    build `catch_amalgamated.cpp` alongside the rest of your source files. The disadvantage
    of using this approach is increased build times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Catch2 as a static library. This requires you to build the library before
    using it. You can either add the header and `lib` files explicitly to your project,
    or you can use CMake for this purpose. This approach provides the advantage of
    reduced build times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The sample code shown in the previous section has the following parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#include "catch_amalgamated.hpp"` includes the amalgamated header of the library
    that is a merging of all the library headers. On the other hand, if you’re using
    the build version, you only need to include the particular headers that you need,
    such as `<catch2/catch_test_macros.hpp>`. You can include `<cathc2/catch_all.hpp>`
    but this will include all the library headers, which is not advisable. In general,
    you should only include the headers that you need.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`TEST_CASE("first_test_case", "[learn][catch]")` defines a test case called
    `first_test_case`, which has two associated tags: `learn` and `catch`. Tags are
    used to select either running or just listing test cases. Multiple test cases
    can be tagged with the same tags.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`SECTION("first_test_function")` defines a section, that is, a test function,
    called `first_test_function`, as part of the outer test case.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`REQUIRE(i == 42);` is an assertion that tells the test to fail if the condition
    is not satisfied.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output of running this program is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned previously, the framework enables us to write tests using the
    BDD style with *give-when-then* sections. This was made possible using several
    aliases: `SCENARIO` for `TEST_CASE` and `GIVE`, `WHEN`, `AND_WHEN`, `THEN`, and
    `AND_THEN` for `SECTION`. Using this style, we can rewrite the test shown earlier,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'When executed successfully, the program prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'However, upon failure (let’s suppose we got the wrong condition: `i == 0`),
    the expression that failed, as well as the values on the left-hand and right-hand
    sides, are printed in the output, as shown in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The output presented here, as well as in other snippets throughout the following
    recipes, has been slightly trimmed or compressed from the actual console output
    to make it easier to list within the pages of this book.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Catch2*, to see how to create tests with the
    Catch2 library, either using the traditional style based on test cases or the
    BDD style with scenarios, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Catch2*, to explore the various assertion macros from the Catch2
    library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing and invoking tests with Catch2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Catch2 framework enables you to write tests using either the traditional
    style of test cases and test functions or the BDD style with scenarios and *given-when-then*
    sections. Tests are defined as separate sections of a test case and can be nested
    as deep as you want. Whichever style you prefer, tests are defined with only two
    base macros. This recipe will show what these macros are and how they work.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To write tests using the traditional style, with test cases and test functions,
    do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `TEST_CASE` macro to define a test case with a name (as a string),
    and optionally, a list of its associated tags:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `SECTION` macro to define a test function inside a test case, with
    the name as a string:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define nested sections if you want to reuse the setup and teardown code or
    organize your tests in a hierarchical structure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To write tests using the BDD style, do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define scenarios using the `SCENARIO` macro, specifying a name for it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define nested sections inside the scenario using the `GIVEN`, `WHEN`, and `THEN`
    macros, specifying a name for each of them:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute the tests, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: To execute all the tests from your program (except hidden ones), run the test
    program without any command-line arguments (from the ones described in the following
    code).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To execute only a specific set of test cases, provide a filter as a command-line
    argument. This can contain test case names, wildcards, tag names, and tag expressions:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To execute only a particular section (or set of sections), use the command-line
    argument `--section` or `-c` with the section name (can be used multiple times
    for multiple sections):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To specify the order in which test cases should be run, use the command-line
    argument `--order` with one of the following values: `decl` (for the order of
    declaration), `lex` (for lexicographic ordering by name), or `rand` (for a random
    order determined with `std::random_shuffle()`). Here’s an illustration of this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Test cases are self-registered and do not require any additional work from the
    developer to set the test program, other than defining the test cases and test
    functions. Test functions are defined as sections of test cases (using the `SECTION`
    macro), and they can be nested.
  prefs: []
  type: TYPE_NORMAL
- en: There is no limit to the depth of section nesting. Test cases and test functions,
    which, from here on, will be referred to as sections, form a tree structure, with
    the test cases on the root nodes and the most inner sections as leaves. When the
    test program runs, it is the leaf sections that are executed. Each leaf section
    is executed in isolation from the other leaf sections. However, the execution
    path starts at the root test case and continues downward, toward the innermost
    section. All of the code that’s encountered on the path is executed entirely for
    each run. This means that when multiple sections share common code (from a parent
    section or the test case), the same code is executed once for each section, without
    any data being shared between executions. This has the effect that it eliminates
    the need for a special fixture approach on the one hand. On the other hand, it
    enables multiple fixtures for each section (everything that is encountered up
    in the path), a feature that many testing frameworks lack.
  prefs: []
  type: TYPE_NORMAL
- en: 'The BDD style of writing test cases is powered by the same two macros, namely,
    `TEST_CASE` and `SECTION`, and the ability to test sections. In fact, the macro
    `SCENARIO` is a redefinition of `TEST_CASE`, and `GIVEN`, `WHEN`, `AND_WHEN`,
    `THEN`, and `AND_THEN` are redefinitions of `SECTION`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: When you execute a test program, all defined tests are run. This, however, excludes
    hidden tests, which are specified either using a name that starts with `./` or
    a tag that starts with a period. It is possible to force the running of hidden
    tests too by providing the command-line argument `[.]` or `[hide]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to filter the test cases to execute. This can be done using
    either the name or the tags. The following table displays some of the possible
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Argument** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `"test construction"` | The test case called `test construction` |'
  prefs: []
  type: TYPE_TB
- en: '| `test*` | All test cases that start with `test` |'
  prefs: []
  type: TYPE_TB
- en: '| `~"test construction"` | All test cases, except the one called `test construction`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `~*equal*` | All test cases, except those that contain the word `equal` |'
  prefs: []
  type: TYPE_TB
- en: '| `a* ~ab* abc` | All tests that start with `a`, except those that start with
    `ab`, except `abc`, which is included |'
  prefs: []
  type: TYPE_TB
- en: '| `[modify]` | All test cases tagged with `[modify]` |'
  prefs: []
  type: TYPE_TB
- en: '| `[modify],[compare][op]` | All test cases that are tagged with either `[modify]`
    or both `[compare]` and `[op]` |'
  prefs: []
  type: TYPE_TB
- en: '| `-#sourcefile` | All tests from the `sourcefile.cpp` file |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.5: Examples of filters for the test cases to be executed'
  prefs: []
  type: TYPE_NORMAL
- en: The execution of particular test functions is also possible by specifying one
    or more section names with the command-line argument `--section` or `-c`. However,
    wildcards are not supported for this option. If you specify a section to run,
    be aware that the entire test path from the root test case to the selected section
    will be executed. Moreover, if you do not specify a test case or a set of test
    cases first, then all the test cases will be executed, though only the matching
    sections within them.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Getting started with Catch2*, to learn how to install the Catch2 framework
    and how to create a simple test project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asserting with Catch2*, to explore the various assertion macros from the Catch2
    library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserting with Catch2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unlike other testing frameworks, Catch2 does not provide a large set of assertion
    macros. It has two main macros: `REQUIRE`, which produces a fatal error, stopping
    the execution of the test case upon failure, and `CHECK`, which produces a non-fatal
    error upon failure, continuing the execution of the test case. Several additional
    macros are defined; in this recipe, we will see how to put them to work.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should now be familiar with writing test cases and test functions using
    Catch2, a topic we covered in the previous recipe, *Writing and invoking tests
    with Catch2*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following list contains the available options for asserting with the Catch2
    framework:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `CHECK(expr)` to check whether `expr` evaluates to `true`, continuing the
    execution in case of failure, and `REQUIRE(expr)` to make sure that `expr` evaluates
    to `true`, stopping the execution of the test in case of failure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `CHECK_FALSE(expr)` and `REQUIRE_FALSE(expr)` to make sure that `expr`
    evaluates to `false` and produces either a non-fatal or fatal error in case of
    failure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use floating-point matchers, `WithinAbs`, `WithinRel`, and `WithinUPL`, to
    compare floating-point numbers (this is preferred over the obsolete `Approx` class):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `CHECK_NOTHROW(expr)`/`REQUIRE_NOTHROW(expr)` to verify that `expr` does
    not throw any error, `CHECK_THROWS(expr)`/`REQUIRE_THROWS(expr)` to verify that
    `expr` does throw an error of any type, `CHECK_THROWS_AS(expr, exctype)`/`REQUIRE_THROWS_AS(expr,
    exctype)` to verify that `expr` throws an exception of the type `exctype`, or
    `CHECK_THROWS_WITH(expression, string or string matcher)`/`REQUIRE_THROWS_WITH(expression,
    string or string matcher)` to verify that `expr` throws an expression whose description
    matches the specified string:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `CHECK_THAT(value, matcher expression)`/`REQUIRE_THAT(expr, matcher expression)`
    to check whether the given matcher expression evaluates to `true` for the specified
    value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use `FAIL(message)` to report `message` and fail the test case, `WARN(message)`
    to log the message without stopping the execution of the test case, and `INFO(message)`
    to log the message to a buffer and only report it with the next assertion that
    would fail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `REQUIRE`/`CATCH` family of macros decompose the expression into its left-
    and right-hand side terms and, upon failure, report the location of the failure
    (source file and line), the expression, and the values on the left- and right-hand
    sides:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'However, these macros do not support complex expressions composed using logical
    operators, such as `&&` and `||`. The following example is an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'The solution for this is to create a variable to hold the result of the expression
    evaluation and use it in the assertion macros. In this case, however, the ability
    to print the expansion of the elements of the expression is lost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative is to use another set of parentheses. However, this too stops
    the decomposition from working:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Two sets of assertions, namely `CHECK_THAT`/`REQUIRE_THAT` and `CHECK_THROWS_WITH`/`REQUIRE_THROWS_WITH`,
    work with matchers. Matchers are extensible and composable components that perform
    value matching. The framework provides several matchers, including for:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Strings: `StartsWith`, `EndsWith`, `ContainsSubstring`, `Equals`, and `Matches`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::vector`: `Contains`, `VectorContains`, `Equals`, `UnorderedEquals`, and
    `Approx`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Floating-point values: `WithinAbs`, `WithinULP`, `WithinRel`, and `IsNaN`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Range-like types (included from version 3.0.1): `IsEmpty`, `SizeIs`, `Contains`,
    `AllMatch`, `AnyMatch`, `NoneMatch`, `AllTrue`, `AnyTrue`, `NoneTrue`, `RangeEquals`,
    `UnorderedRangeEquals`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exceptions: `Message` and `MessageMatches`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference between `Contains()` and `VectorContains()` is that `Contains()`
    searches for a vector in another vector and `VectorContains()` searches for a
    single element inside a vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the previous list, there are several matchers that target floating-point
    numbers. These matchers are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`WithinAbs()`: Creates a matcher that accepts a floating-point number that
    is less than or equal to a target number with a specified margin (a percentage
    given as a number between 0 and 1):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`WithinRel()`: Creates a matcher that accepts a floating-point number that
    is approximatively equal to a target with a given tolerance:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`WithinULP()`: Creates a matcher that accepts a floating-point number that
    is no more than the given ULP away from the target:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'These matchers can also be combined together, as exemplified below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: An obsolete way of comparing floating-point numbers is represented by the class
    called `Approx`, in the `Catch` namespace. This class overloads the equality/inequality
    and comparison operators with values through which a `double` value can be constructed.
    The margin by which the two values can either differ or be considered equal can
    be specified as a percentage of the given value. This is set using the member
    function `epsilon()`. The value must be between 0 and 1 (for example, the value
    of 0.05 is 5 percent). The default value of epsilon is set to `std::numeric_limits<float>::epsilon()*100`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create your own matchers, either to extend the existing framework capabilities
    or to work with your own types. There are two ways to create custom matches: the
    old v2 way, and the new v3 way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a custom matcher the old way, there are two things that are necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A matcher class derived from `Catch::MatcherBase<T>`, where `T` is the type
    being compared. There are two virtual functions that must be overridden: `match()`,
    which takes a value to match and returns a Boolean indicating whether the match
    was successful, and `describe()`, which takes no arguments but returns a string
    describing the matcher.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A builder function that is called from the test code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following example defines a matcher for the `point3d` class, which we have
    seen throughout this chapter, to check whether a given 3D point lies on a line
    in the three-dimensional space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a custom matcher the new way, you need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A matcher class derived from `Catch::Matchers::MatcherGenericBase`. This class
    has to implement two methods: `bool match(…) const`, which performs the matching,
    and an overriding of the virtual function `string describe() const`, which takes
    no arguments but returns a string describing the matcher. Although these are very
    similar to the functions used in the old style, there is a key difference: the
    `match()` function has no requirements on the way its argument is passed. This
    means it can take an argument by value or mutating reference. In addition, it
    can also be a function template. The advantage is that it enables writing more
    complex matchers, such as matchers that can compare range-like types.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A builder function that is called from the test code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The same matcher that compares `point3d` values written in the new style looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The following test case contains an example of how to use this custom matcher:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: This test ensures that the point `{2,2,2}` lies on the line defined by the points
    `{0,0,0}` and `{3,3,3}` by using the `IsOnTheLine()` custom matcher implemented
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Catch2*, to see how to create tests with the
    Catch2 library, either using the traditional style based on test cases or the
    BDD style with scenarios, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling output with Catch2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with other testing frameworks discussed in this book, Catch2 reports the
    results of a test program’s execution in a human-readable format to the `stdout`
    standard stream. Additional options are supported, such as reporting using XML
    format or writing to a file. In this recipe, we will look at the main options
    available for controlling the output when using Catch2.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To exemplify the way the test program’s execution output could be modified,
    use the following test cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of running these two test cases is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: In the following section, we’ll explore some of the various options for controlling
    the output of a Catch2 test program.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To control the output of a test program when using Catch2, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the command-line argument `-r` or `--reporter <reporter>` to specify the
    reporter used to format and structure the results. The default options supplied
    with the framework are `console`, `compact`, `xml`, and `junit`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the command-line argument `-s` or `--success` to display the results of
    successful test cases too:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the command-line argument `-o` or `--out <filename>` to send all of the
    output to a file instead of the standard stream:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the command-line argument `-d` or `--durations <yes/no>` to display the
    time that it takes each test case to execute:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Apart from the human-readable format used, by default, for reporting the results
    of the test program execution, the Catch2 framework supports two XML formats:'
  prefs: []
  type: TYPE_NORMAL
- en: A Catch2-specific XML format (specified with `-r xml`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A JUNIT-like XML format, following the structure of the JUNIT ANT task (specified
    with `-r junit`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The former reporter streams the XML content as unit tests are executed and results
    are available. It can be used as input to an XSLT transformation to generate an
    HTML report for the instance. The latter reporter needs to gather all of the program
    execution data in order to structure the report before printing it. The JUNIT
    XML format is useful for being consumed by third-party tools, such as a continuous
    integration server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several additional reporters are provided in standalone headers. They need
    to be included in the source code of the test program (all the headers of the
    additional reporters have the name format as `catch_reporter_*.hpp`). These additional
    available reporters are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TeamCity** reporter (specified with `-r teamcity`), which writes TeamCity
    service messages to the standard output stream. It is suitable only for integration
    with TeamCity. It is a streamed reporter; data is written as it is available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automake** reporter (specified with `-r automake`), which writes the meta
    tags expected by `automake` via `make check`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Anything Protocol** (or **TAP**, for short) reporter (specified with
    `-r tap`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SonarQube** reporter (specified with `-r sonarqube`), which writes using
    the SonarQube generic test data XML format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following example shows how to include the TeamCity header file in order
    to produce the report using the TeamCity reporter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'The default target of the test report is the standard stream `stdout` (even
    data written explicitly to `stderr` ends up being redirected to `stdout`). However,
    it is possible that the output is written to a file instead. These formatting
    options can be combined. Take a look at the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: This command specifies that the report should use the JUNIT XML format and be
    saved to a file called `test_report.xml`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Getting started with Catch2*, to learn how to install the Catch2 framework
    and how to create a simple test project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Writing and invoking tests with Catch2*, to see how to create tests with the
    Catch2 library, either using the traditional style based on test cases or the
    BDD style with scenarios, as well as how to run tests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.gg/7xRaTCeEhx](Chapter_11.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code2659294082093549796.png)'
  prefs: []
  type: TYPE_IMG
