<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-227"><a id="_idTextAnchor264"/>5</h1>
<h1 id="_idParaDest-228"><a id="_idTextAnchor265"/>Deciphering Order-Independent Transparency</h1>
<p>Rendering transparent objects isn’t always easy. While opaque objects can be rendered in any order, transparent objects need to be rendered from farthest to nearest relative to the camera, which implies an extra sorting step before performing the actual rendering. This depth sorting ensures that more distant objects are blended into the frame buffer first, followed by nearer objects, allowing for accurate composition of transparent layers.</p>
<p>Sorting can become computationally expensive and error-prone, especially when dealing with complex scenes, intersecting objects, or real-time rendering scenarios. Additionally, sorting fails to solve the problem of cyclic overlaps, where multiple objects interpenetrate in such a way that no single depth-sorting order can accurately represent their visual appearance.</p>
<p>Order-independent transparency techniques try to solve these problems by accumulating transparency information in a way that doesn’t depend on the order in which objects are processed. This chapter delves into the complexities and challenges of rendering transparent objects, a task that requires precision and careful execution. In contrast to opaque objects, which can be rendered in any order, transparent objects necessitate rendering based on their depth in relation to the camera, from the farthest to the nearest. This involves an additional sorting step, which, while ensuring accurate composition of transparent layers, can prove to be computationally intensive and prone to errors.</p>
<p>In this chapter we’re going to cover the following main topics:</p>
<ul>
<li>Implementing Depth-Peeling</li>
<li>Implementing Dual Depth-Peeling</li>
<li>Implementing Linked-List Order-Independent Transparency</li>
<li>Implementing Weighted Order-Independent Transparency</li>
</ul>
<h1 id="_idParaDest-229"><a id="_idTextAnchor266"/>Technical requirements</h1>
<p>For this chapter, you will need to make sure you have VS 2022 installed along with the Vulkan SDK. Basic familiarity with the C++ programming language and an understanding of OpenGL or any other graphics API will be useful. Please revisit <a href="B18491_01.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a><em class="italic">, Vulkan Core Concepts</em>, under the <em class="italic">Technical requirements </em>section for details on setting up and building executables for this chapter. All recipes for this chapter are encapsulated in a single executable and can be launched using <code>Chapter05_Transparency.exe</code> executable.</p>
<h1 id="_idParaDest-230"><a id="_idTextAnchor267"/>Implementing Depth-Peeling</h1>
<p><strong class="bold">Depth Peeling</strong> was introduced in 2001 by Cass Everitt as a solution to<a id="_idIndexMarker413"/> render semi-transparent geometry without the need to sort the geometry from back-to-front. The technique consists of rendering the scene multiple times (passes). At each pass, only the nearest fragments to the camera are rendered and their depth is collected to be used on the next pass. On each pass, except for the first pass, fragments closer than the ones in the depth pass collected in the previous iteration are discarded. This process <em class="italic">peels</em> the scene into consecutive layers, from front to back. At the end of the process, all layers are blended into one final image, which is then blended once more with the background.</p>
<h2 id="_idParaDest-231"><a id="_idTextAnchor268"/>Getting ready</h2>
<p>In the repository mentioned in <em class="italic">Technical requirements</em>, the Depth Peeling algorithm is implemented by the <code>DepthPeeling</code> class, located in <code>source/enginecore/passes/DepthPeeling.hpp</code> and <code>cpp</code> files. In this recipe, you will learn how to peel away or progressively remove layers of transparent objects in your rendering process. This technique ensures accurate rendering by handling each layer individually from the farthest to the nearest, thus improving the overall visual quality of scenes with complex overlapping transparencies.</p>
<p>The algorithm consists of rendering the scene repeatedly, storing the depth map at the end of each pass. The fragments nearest to the camera are blended with the previous pass (or an empty framebuffer for the first pass). The current pass fragment depth is discarded if it is smaller than the depth from the last pass, as summarized in <em class="italic">Figure 5</em><em class="italic">.1</em>:</p>
<div><div><img alt="Figure 5.1 –Depth Peeling algorithm with 3 planes" src="img/B18491_05_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 –Depth Peeling algorithm with 3 planes</p>
<p>We’ve provided a foundational understanding of this technique in the preceding section. Moving forward, we will delve deeper, guiding you through a detailed, step-by-step process on how to practically implement this technique using Vulkan.</p>
<h2 id="_idParaDest-232"><a id="_idTextAnchor269"/>How to do it…</h2>
<p>The algorithm uses<a id="_idIndexMarker414"/> two sets of depth maps and two sets of color attachments to perform a ping-pong operation between passes. The depth map obtained during one pass is used as a reference depth map on the next, while a second depth map is then used as a depth attachment. The same thing is done with two color attachments: one is used to store the blending of the current pass, while the other is used as the reference, generated in the previous pass. The subsequent steps will guide you through the actual execution of these operations. With the help of a detailed diagram provided below, you will be able to visualize and better understand the intricate workings of this algorithm.</p>
<p><em class="italic">Figure 5</em><em class="italic">.2</em> effectively illustrates the described process, aiding in your comprehension and application of this intricate technique:</p>
<div><div><img alt="Figure 5.2 – Depth peeling algorithm" src="img/B18491_05_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Depth peeling algorithm</p>
<p>Now we will go<a id="_idIndexMarker415"/> through steps on how to perform this recipe.</p>
<ol>
<li>The algorithm is performed by the <code>DepthPeeling::draw</code> method, which starts by clearing the depth map 1 and both color attachments:<pre class="source-code">
void DepthPeeling::draw(
    VkCommandBuffer commandBuffer, int index,
    const std::vector&lt;
        std::shared_ptr&lt;VulkanCore::Buffer&gt;&gt;
        &amp;buffers,
    uint32_t numMeshes) {
  {
    // Clear Depth 1
    vkCmdClearDepthStencilImage(
        commandBuffer,
        depthTextures_[1]-&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        &amp;clearDepth, 1, &amp;range);
  }
  {
    // Clear color attachments
    vkCmdClearColorImage(
        commandBuffer,
        colorTextures_[0]-&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        &amp;clearColor, 1, &amp;range);
    vkCmdClearColorImage(
        commandBuffer,
        colorTextures_[1]-&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        &amp;clearColor, 1, &amp;range);
  }</pre></li> <li>Both the color<a id="_idIndexMarker416"/> and depth attachments start with the color and depth attachments with index equal to 0:<pre class="source-code">
  VulkanCore::DynamicRendering::
      AttachmentDescription colorAttachmentDesc{
          .imageView =
              colorTextures_[0]-&gt;vkImageView(),
          .imageLayout =
              VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
          .attachmentLoadOp =
              VK_ATTACHMENT_LOAD_OP_LOAD,
          .attachmentStoreOp =
              VK_ATTACHMENT_STORE_OP_STORE,
          .clearValue = clearValues[0],
      };
  VulkanCore::DynamicRendering::
      AttachmentDescription depthAttachmentDesc{
          .imageView =
              depthTextures_[0]-&gt;vkImageView(),
          .imageLayout =
              VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL,
          .attachmentLoadOp =
              VK_ATTACHMENT_LOAD_OP_CLEAR,
          .attachmentStoreOp =
              VK_ATTACHMENT_STORE_OP_STORE,
          .clearValue = clearValues[1],
      };</pre></li> <li>The algorithm<a id="_idIndexMarker417"/> repeats a number of times, equal to the number of passes. Care must be taken to transition each attachment to the correct layout, obeying the ping-ponging mechanism: a texture used as a color attachment before needs to be transitioned to a texture that will be read <a id="_idIndexMarker418"/>by a shader and vice-versa:<pre class="source-code">
  for (uint32_t currentPeel = 0;
       currentPeel &lt; numPeels_; ++currentPeel) {
    colorTextures_[currentPeel % 2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
    colorTextures_[(currentPeel + 1) % 2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
    depthTextures_[currentPeel % 2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL);
    depthTextures_[(currentPeel + 1) % 2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
    colorAttachmentDesc.imageView =
        colorTextures_[currentPeel % 2]
            -&gt;vkImageView();
    depthAttachmentDesc.imageView =
        depthTextures_[currentPeel % 2]
            -&gt;vkImageView();</pre></li> <li>Then we begin the <a id="_idIndexMarker419"/>render pass, issue the draw call, and end the pass:<pre class="source-code">
    VulkanCore::DynamicRendering::beginRenderingCmd(
        commandBuffer,
        colorTextures_[currentPeel % 2]
            -&gt;vkImage(),
        0,
        {{0, 0},
         {colorTextures_[currentPeel % 2]
              -&gt;vkExtents()
              .width,
          colorTextures_[currentPeel % 2]
              -&gt;vkExtents()
              .height}},
        1, 0, {colorAttachmentDesc},
        &amp;depthAttachmentDesc, nullptr,
        colorTextures_[currentPeel % 2]
            -&gt;vkLayout(),
        VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
    vkCmdSetViewport(commandBuffer, 0, 1,
                     &amp;viewport_);
    vkCmdSetScissor(commandBuffer, 0, 1,
                    &amp;scissor_);
    pipeline_-&gt;bind(commandBuffer);
    ... // Perform the draw call
    VulkanCore::DynamicRendering::endRenderingCmd(
        commandBuffer,
        colorTextures_[currentPeel % 2]
            -&gt;vkImage(),
        VK_IMAGE_LAYOUT_UNDEFINED,
        VK_IMAGE_LAYOUT_UNDEFINED);</pre></li> <li>The images are transitioned to the correct layout by the render pass, so all we need to do is copy <a id="_idIndexMarker420"/>the result of the current pass into the other texture that will be used as the color attachment during the next pass:<pre class="source-code">
    vkCmdBlitImage(
        commandBuffer,
        colorTextures_[currentPeel % 2]
            -&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
        colorTextures_[(currentPeel + 1) % 2]
            -&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1,
        &amp;region, VK_FILTER_NEAREST);</pre></li> <li>The vertex fragment is not special for depth peeling, but the fragment shader must discard fragments that are closer to the camera than the fragments collected in the previous pass. The fragment shader also performs the blending into the current<a id="_idIndexMarker421"/> attachment:<pre class="source-code">
#version 460
layout(set = 1,
       binding = 0) uniform ObjectProperties {
  vec4 color;
  mat4 model;
}objectProperties;
layout(set = 2,
       binding = 0) uniform sampler2D depth;
layout(set = 2, binding = 2) uniform sampler2D
    temporaryColor;
layout(location = 0) out vec4 outColor;
void main() {
  float fragDepth = gl_FragCoord.z;
  float peelDepth =
      texture(depth, gl_FragCoord.xy /
                         textureSize(depth, 0))
          .r;
  if (fragDepth &lt;= peelDepth) {
    discard;
  }
  vec4 tmpColor =
      texture(temporaryColor,
              gl_FragCoord.xy /
                  textureSize(temporaryColor, 0));
  vec3 mulTmpColor = tmpColor.xyz * tmpColor.a;
  vec3 mulObjProp = objectProperties.color.xyz *
                    (1.0 - tmpColor.a);
  outColor = vec4(
      tmpColor.a * (objectProperties.color.a *
                    objectProperties.color.rgb) +
          tmpColor.rgb,
      (1 - objectProperties.color.a) *
          tmpColor.a);
}</pre><p class="list-inset">The blending <a id="_idIndexMarker422"/>equation is a special one, used for front-to-back compositing, as described by Louis Bavoil and Kevin Myers in 2008 in their <em class="italic">Order Independent Transparency with Dual Depth Peeling</em> paper. The blending equation is:</p><p class="list-inset">C dst = A dst(A src C src)+ C dst</p><p class="list-inset">A dst = (1 − A src) A dst</p></li> </ol>
<p>In the following recipe, we will explore how to enhance the depth-peeling technique, making it more efficient.</p>
<h1 id="_idParaDest-233"><a id="_idTextAnchor270"/>Implementing Dual Depth-Peeling</h1>
<p>One of the main <a id="_idIndexMarker423"/>drawbacks of the Depth Peeling algorithm is that it requires multiple passes, each of which may consist of rasterizing the entire scene. The <strong class="bold">Dual Depth-Peeling</strong> algorithm extends the original Depth Peeling algorithm by peeling two layers at the same time, almost effectively cutting the number of passes by half. In this recipe, we will focus on implementing the Dual Depth-Peeling algorithm. We will address one of the key limitations of the Depth Peeling algorithm, namely its requirement for multiple passes which may involve rasterizing the entire scene. You’ll learn how the Dual Depth-Peeling algorithm improves upon the original by peeling two layers concurrently, thus potentially reducing the number of passes by nearly half. This insight will empower you to handle complex scenes with greater efficiency and speed.</p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor271"/>Getting ready</h2>
<p>In the repository, the Depth Peeling algorithm is implemented by the <code>DualDepthPeeling</code> class, located in <code>source/enginecore/passes/DualDepthPeeling.hpp</code> and <code>cpp</code> files.</p>
<p>Before we begin, we need to set the <code>VkPhysicalDeviceFeatures::independentBlend</code> property to true. This property allows us to use different blending equations for each attachment associated with a graphics pipeline.</p>
<p>On each pass, a depth map with two components, R and G (in the code we use the <code>VK_FORMAT_R32G32_SFLOAT</code> format), is used to store both the front and the back peels simultaneously. The blend equation used with the map is <code>VK_BLEND_OP_MAX</code>. When storing the current fragment’s depth, we encode it as <code>vec2(-depth, depth)</code>. The R component stores the negative depth of the front peel, while the G component stores the actual depth of the back peel, The <code>Max</code> blending equation ensures that we only store the nearest front peel by negating it. The back peels are guaranteed to always be the farthest because they are stored as positive depths.</p>
<p>The front peel is blended with the modified blend equation:</p>
<p>C dst = A dst(A src C src)+ C dst</p>
<p>A dst = (1 − A src) A dst</p>
<p>While the back peel is blended with the regular back-to-front blend equation</p>
<p>C dst = A src C src + (1 − A src) C dst</p>
<p>With the preparatory steps outlined, you are now ready to delve into the implementation of the Dual Depth-Peeling algorithm. In the next section, we will guide you through the step-by-step process of executing this algorithm, using the insights and techniques discussed above.</p>
<h2 id="_idParaDest-235"><a id="_idTextAnchor272"/>How to do it…</h2>
<p>The algorithm in Vulkan consists of using 2 color attachments, one for the front peel and one for the back peel. It also uses 2 depth buffers with the same format. One is used for the even numbered <a id="_idIndexMarker424"/>passes, while the other for the odd even passes.</p>
<ol>
<li>We start by specifying the blend operations for each attachment:<pre class="source-code">
const VkPipelineColorBlendAttachmentState
    depthBlendState = {
    .blendEnable = true,
    .srcColorBlendFactor =
        VK_BLEND_FACTOR_SRC_ALPHA,
    .dstColorBlendFactor =
        VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
    .colorBlendOp = VK_BLEND_OP_MAX,
    .srcAlphaBlendFactor =
        VK_BLEND_FACTOR_SRC_ALPHA,
    .dstAlphaBlendFactor =
        VK_BLEND_FACTOR_DST_ALPHA,
    .alphaBlendOp = VK_BLEND_OP_MAX,
    .colorWriteMask =
        VK_COLOR_COMPONENT_R_BIT |
        VK_COLOR_COMPONENT_G_BIT |
        VK_COLOR_COMPONENT_B_BIT |
        VK_COLOR_COMPONENT_A_BIT,
};
const VkPipelineColorBlendAttachmentState
    frontBlendState = {
    // front color attachment
    .blendEnable = true,
    .srcColorBlendFactor =
        VK_BLEND_FACTOR_DST_ALPHA,
    .dstColorBlendFactor =
        VK_BLEND_FACTOR_ONE,
    .colorBlendOp = VK_BLEND_OP_ADD,
    .srcAlphaBlendFactor =
        VK_BLEND_FACTOR_ZERO,
    .dstAlphaBlendFactor =
        VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
    .alphaBlendOp = VK_BLEND_OP_ADD,
    .colorWriteMask =
        VK_COLOR_COMPONENT_R_BIT |
        VK_COLOR_COMPONENT_G_BIT |
        VK_COLOR_COMPONENT_B_BIT |
        VK_COLOR_COMPONENT_A_BIT,
};
const VkPipelineColorBlendAttachmentState
    backBlendState = {
    // back color attachment
    .blendEnable = true,
    .srcColorBlendFactor =
        VK_BLEND_FACTOR_SRC_ALPHA,
    .dstColorBlendFactor =
        VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
    .colorBlendOp = VK_BLEND_OP_ADD,
    .srcAlphaBlendFactor =
        VK_BLEND_FACTOR_ZERO,
    .dstAlphaBlendFactor =
        VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
    .alphaBlendOp = VK_BLEND_OP_ADD,
    .colorWriteMask =
        VK_COLOR_COMPONENT_R_BIT |
        VK_COLOR_COMPONENT_G_BIT |
        VK_COLOR_COMPONENT_B_BIT |
        VK_COLOR_COMPONENT_A_BIT,
};</pre><p class="list-inset">These instances <a id="_idIndexMarker425"/>of the <code>VkPipelineColorBlendAttachmentState</code> structure are added to the <code>VkPipelineColorBlendStateCreateInfo</code> structure when creating a graphics pipeline and are provided in the order the attachments will be set in the framebuffers.</p></li> <li>The algorithm, implemented by <code>DualDepthPeeling::draw</code> method, starts by clearing the depth buffers and the color attachments:<pre class="source-code">
void DualDepthPeeling::draw(
    VkCommandBuffer commandBuffer, int index,
    const std::vector&lt;
        std::shared_ptr&lt;VulkanCore::Buffer&gt;&gt;
        &amp;buffers,
    uint32_t numMeshes) {
  // Clear Depth 0
  {
    vkCmdClearColorImage(
        commandBuffer,
        depthMinMaxTextures_[0]-&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        &amp;clearColor, 1, &amp;range);
  }
  // Clear Depth 1
  {
    vkCmdClearColorImage(
        commandBuffer,
        depthMinMaxTextures_[1]-&gt;vkImage(),
        VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        &amp;clearColor, 1, &amp;range);
  }
  // Clear color attachments
  {
    for (uint32_t i = 0;
         i &lt; colorTextures_.size(); ++i) {
      vkCmdClearColorImage(
          commandBuffer,
          colorTextures_[i]-&gt;vkImage(),
          VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
          &amp;clearColor, 1, &amp;range);
    }
  }</pre></li> <li>The depth textures are then transitioned for the first pass:<pre class="source-code">
  depthMinMaxTextures_[0]-&gt;transitionImageLayout(
      commandBuffer,
      VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
  depthMinMaxTextures_[1]-&gt;transitionImageLayout(
      commandBuffer,
      VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);</pre></li> <li>Both the front <a id="_idIndexMarker426"/>and back textures are bound as attachments and are loaded and stored for each pass. One of the depth textures is also bound as an attachment and is cleared to <code>(-99,999; 99,999)</code> and stored after each pass. The other depth texture is bound as a texture for read by the fragment shader:<pre class="source-code">
  VulkanCore::DynamicRendering::AttachmentDescription
      colorAttachmentDesc_Front{
          .imageView = colorTextures_[0]
                           -&gt;vkImageView(),
          .imageLayout =
              VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
          .attachmentLoadOp =
              VK_ATTACHMENT_LOAD_OP_LOAD,
          .attachmentStoreOp =
              VK_ATTACHMENT_STORE_OP_STORE,
      };
  VulkanCore::DynamicRendering::AttachmentDescription
      colorAttachmentDesc_Back{
          .imageView = colorTextures_[1]
                           -&gt;vkImageView(),
          .imageLayout =
              VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
          .attachmentLoadOp =
              VK_ATTACHMENT_LOAD_OP_LOAD,
          .attachmentStoreOp =
              VK_ATTACHMENT_STORE_OP_STORE,
      };
  const VkClearValue clearDepthMinMax = {
      .color = {-99999.0f, -99999.0f, 0.0f,
                0.0f},
  };
  VulkanCore::DynamicRendering::AttachmentDescription
      depthMinMaxAttachmentDesc{
          .imageView =
              depthMinMaxTextures_[0]
                  -&gt;vkImageView(),
          .imageLayout =
              VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
          .attachmentLoadOp =
              VK_ATTACHMENT_LOAD_OP_CLEAR,
          .attachmentStoreOp =
              VK_ATTACHMENT_STORE_OP_STORE,
          .clearValue = clearDepthMinMax,
      };</pre></li> <li>For each pass we <a id="_idIndexMarker427"/>start by transitioning the color and depth attachments to the correct layouts:<pre class="source-code">
  for (uint32_t currentPeel = 0;
       currentPeel &lt; numPeels_;
       ++currentPeel) {
    const uint32_t readIdx = currentPeel % 2;
    colorTextures_[0]-&gt;transitionImageLayout(
        commandBuffer,
        VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
    colorTextures_[1]-&gt;transitionImageLayout(
        commandBuffer,
        VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
    depthMinMaxTextures_[currentPeel % 2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
    depthMinMaxTextures_[(currentPeel + 1) %
                         2]
        -&gt;transitionImageLayout(
            commandBuffer,
            VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
    depthMinMaxAttachmentDesc.imageView =
        depthMinMaxTextures_[readIdx]
            -&gt;vkImageView();</pre></li> <li>The attachments are provided for the render pass using dynamic rendering, the scene is<a id="_idIndexMarker428"/> rendered, and the pass is completed:<pre class="source-code">
    VulkanCore::DynamicRendering::
        beginRenderingCmd(
            commandBuffer,
            colorTextures_[0]-&gt;vkImage(), 0,
            {{0, 0},
             {colorTextures_[0]
                  -&gt;vkExtents()
                  .width,
              colorTextures_[0]
                  -&gt;vkExtents()
                  .height}},
            1, 0,
            {depthMinMaxAttachmentDesc,
             colorAttachmentDesc_Front,
             colorAttachmentDesc_Back},
            &amp;depthAttachmentDesc, nullptr,
            colorTextures_[0]-&gt;vkLayout(),
            VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);
    vkCmdSetViewport(commandBuffer, 0, 1,
                     &amp;viewport_);
    vkCmdSetScissor(commandBuffer, 0, 1,
                    &amp;scissor_);
    pipeline_-&gt;bind(commandBuffer);
    // Draw geometry
    VulkanCore::DynamicRendering::
        endRenderingCmd(
            commandBuffer,
            colorTextures_[0]-&gt;vkImage(),
            VK_IMAGE_LAYOUT_UNDEFINED,
            VK_IMAGE_LAYOUT_UNDEFINED);
  }</pre></li> <li>Once all the passes<a id="_idIndexMarker429"/> are completed, one last step remains which is consists of blending the last front and back peels. The front peel is provided as a color attachment and as a texture for the shader, while the back color is only provided as a texture for reading by the shader.<pre class="source-code">
  {
    VulkanCore::DynamicRendering::
        beginRenderingCmd(...);
    vkCmdSetViewport(commandBuffer, 0, 1,
                     &amp;viewport_);
    vkCmdSetScissor(commandBuffer, 0, 1,
                    &amp;scissor_);
    pipelineFinal_-&gt;bind(commandBuffer);
    vkCmdDraw(commandBuffer, 4, 1, 0, 0);
    VulkanCore::DynamicRendering::
        endRenderingCmd(...);
  }
}</pre><p class="list-inset">This last pass consists of drawing a rectangle the size of the viewport and used solely for blending the two peels</p></li> <li>The main dual <a id="_idIndexMarker430"/>depth peeling fragment shader reads the depth value of the fragment output from the previous pass, decodes it, and decided whether the fragment should be discarded or not:<pre class="source-code">
#version 460
const float MAX_DEPTH = 99999.0;
void main() {
  float fragDepth = gl_FragCoord.z;
  vec2 lastDepth =
      texture(depth,
              gl_FragCoord.xy /
                  textureSize(depth, 0)).rg;
  depthMinMax.rg = vec2(-MAX_DEPTH);
  frontColorOut = vec4(0.0f);
  backColorOut = vec4(0.0f);
  float nearestDepth = -lastDepth.x;
  float furthestDepth = lastDepth.y;
  float alphaMultiplier = 1.0 - lastFrontColor.a;
  if (fragDepth &lt; nearestDepth ||
      fragDepth &gt; furthestDepth) {
    return;
  }
  if (fragDepth &gt; nearestDepth &amp;&amp;
      fragDepth &lt; furthestDepth) {
    depthMinMax = vec2(-fragDepth, fragDepth);
    return;
  }
  vec4 color = objectProperties.color;
  if (fragDepth == nearestDepth) {
    frontColorOut = vec4(
        color.rgb * color.a, color.a);
  } else {
    backColorOut = color;
  }
}</pre></li> <li>The final pass, where the front <a id="_idIndexMarker431"/>and back peels are blended, uses a simple fragment shader:<pre class="source-code">
#version 460
layout(set = 0, binding = 0)
    uniform sampler2D front;
layout(set = 0, binding = 1)
    uniform sampler2D back;
layout(location = 0) in vec2
    fragTexCoord;
layout(location = 0) out vec4 outColor;
void main() {
  const vec4 frontColor =
      texture(front, fragTexCoord);
  const vec4 backColor =
      texture(back, fragTexCoord);
  outColor =
      vec4(((backColor)*frontColor.a +
            frontColor)
               .rgb,
           (1.0 - backColor.a) *
               frontColor.a);
}</pre></li> </ol>
<p>Having delved into the <a id="_idIndexMarker432"/>intricacies of the Dual Depth-Peeling algorithm, we will now shift our focus to another advanced technique in the next recipe.</p>
<h1 id="_idParaDest-236"><a id="_idTextAnchor273"/>Implementing Linked-List Order-Independent Transparency</h1>
<p><strong class="bold">Order Independent Transparency</strong> uses a per pixel linked list to handle transparency, it <a id="_idIndexMarker433"/>makes use of data structures, specifically linked lists, to store fragments for each pixel. Each node of the list contains information about a fragment’s color and depth value, and the nodes are connected in a way that follows the order of fragments arrival, thus making sorting unnecessary.</p>
<p>This approach effectively eliminates overdrawing, and artifacts associated with depth sorting. By focusing on the depth value of each fragment, the approach provides a more accurate, visually pleasing representation of transparent objects. In this recipe, we will delve into the detailed process of implementing<a id="_idIndexMarker434"/> the Linked-List <strong class="bold">Order-Independent Transparency</strong> (<strong class="bold">OIT</strong>) technique. You’ll learn how this technique leverages per pixel linked lists to efficiently manage transparency, eliminating the issues of overdrawing and depth sorting artifacts.</p>
<h2 id="_idParaDest-237"><a id="_idTextAnchor274"/>Getting ready</h2>
<p>In the repository, the Linked list algorithm is implemented by the <code>OitLinkedListPass</code> class, located in <code>source/enginecore/passes/</code> <code>OitLinkedListPass.hpp</code> and <code>cpp</code> files. The corresponding shaders are <code>source/enginecore/resources/shaders/OitLinkedListBuildPass.frag</code> and <code>source/enginecore/resources/shaders/ OITLinkedListCompositePass.frag</code></p>
<p>The algorithm begins by initializing an empty list for each pixel, and as the scene is rendered, it adds nodes to the list in the order in which they are processed. This is done in a two-pass rendering stage. In the first pass, also known as the build pass, each fragment’s depth, color, and next-node pointer are written into a buffer. The second pass, also known as resolve or composite pass, goes through the list from back-to-front for each pixel and blends the colors based on depth values, resulting in the final pixel color.</p>
<h2 id="_idParaDest-238"><a id="_idTextAnchor275"/>How to do it…</h2>
<p>To implement a per pixel linked list, we need to maintain various buffers.</p>
<ol>
<li>The <code>OitLinkedListPass::init</code> method is tasked with initializing a variety of resources. It establishes both the Build pass and the Composite pass pipelines. Furthermore, it arranges the necessary resources for the Build pass pipeline. The code snippet below highlights some key resources configured during the initialization phase.<ol><li class="Alphabets"><code>atomicCounterBuffer_</code>: This buffer is created to hold an atomic counter. The counter is used to allocate slots in the linked list buffer for storing new fragments.</li><li class="Alphabets"><code>linkedListBuffer_</code>: This is the main buffer that holds the linked lists of fragments for each pixel. Each pixel can have multiple fragments, and each fragment is <a id="_idIndexMarker435"/>represented as a <code>Node</code> in the linked list. The size of this buffer is determined by the number of pixels in the swapchain’s extent (its width and height), the number of slots per pixel, and the size of the Node structure.</li><li class="Alphabets"><code>linkedListHeadPtrTexture_</code>: This buffer stores the head pointers for the linked lists of each pixel. A head pointer points to the first Node of a linked list. This buffer is created as a 2D texture (image) because it needs to store a pointer for each pixel in the swapchain’s extents. The format <code>VK_FORMAT_R32_UINT</code> indicates that each element in the texture is a 32-bit unsigned integer, which is suitable for representing a pointer.</li></ol><pre class="source-code">
atomicCounterBuffer_ = context-&gt;createBuffer(
    sizeof(AtomicCounter), ...);
auto bufferSize = width * height *
                  slotsPerPixel *
                  sizeof(Node);
linkedListBuffer_ = context_-&gt;createBuffer(
    bufferSize, ...);
linkedListHeadPtrTexture_ =
    context-&gt;createTexture(...);</pre></li> <li>The actual magic of the algorithm happens during the <code>draw</code> function. As a first step, we are setting the pixels in <code>linkedListHeadPtrTexture_</code> to zero with <code>vkCmdClearColorImage</code> function, and filling the <code>linkedListBuffer_</code> and <code>atomicCounterBuffer_</code> with zeros using <code>vkCmdFillBuffer</code>, just<a id="_idIndexMarker436"/> to reset everything to null state before we begin writing to it.<pre class="source-code">
vkCmdClearColorImage(
    commandBuffer,
    linkedListHeadPtrTexture_
        -&gt;vkImage(),
    VK_IMAGE_LAYOUT_GENERAL,
    &amp;clearColor, 1, &amp;auxClearRanges);
vkCmdFillBuffer(
    commandBuffer,
    linkedListBuffer_-&gt;vkBuffer(), 0,
    VK_WHOLE_SIZE, 0);
vkCmdFillBuffer(
    commandBuffer,
    atomicCounterBuffer_-&gt;vkBuffer(), 0,
    VK_WHOLE_SIZE, 0);</pre></li> <li>The next step is to set up correct memory barriers. These barriers ensure that all clear operations finish before the shader starts reading from or writing to the buffers. The first <a id="_idIndexMarker437"/>barrier is a memory barrier:<pre class="source-code">
const VkPipelineStageFlags
    srcStageFlags =
        VK_PIPELINE_STAGE_TRANSFER_BIT;
const VkPipelineStageFlags dstStageFlags =
    VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
{
  const VkMemoryBarrier barrier = {
      .sType =
          VK_STRUCTURE_TYPE_MEMORY_BARRIER,
      .srcAccessMask =
          VK_ACCESS_TRANSFER_WRITE_BIT,
      .dstAccessMask =
          VK_ACCESS_SHADER_READ_BIT |
          VK_ACCESS_SHADER_WRITE_BIT,
  };
  vkCmdPipelineBarrier(
      commandBuffer, srcStageFlags,
      dstStageFlags,
      0,
      1, &amp;barrier,
      0, VK_NULL_HANDLE,
      0, VK_NULL_HANDLE);</pre></li> <li>The other two barriers are buffer barriers, one for the linked list buffer and one for the atomic <a id="_idIndexMarker438"/>counter buffer:<pre class="source-code">
  const VkBufferMemoryBarrier bufferBarriers[2] = {
      {
          .sType =
              VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER,
          .srcAccessMask =
              VK_ACCESS_TRANSFER_WRITE_BIT,
          .dstAccessMask =
              VK_ACCESS_SHADER_READ_BIT |
              VK_ACCESS_SHADER_WRITE_BIT,
          .buffer = linkedListBuffer_-&gt;vkBuffer(),
          .size = linkedListBuffer_-&gt;size(),
      },
      {
          .sType =
              VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER,
          .srcAccessMask =
              VK_ACCESS_TRANSFER_WRITE_BIT,
          .dstAccessMask =
              VK_ACCESS_SHADER_READ_BIT |
              VK_ACCESS_SHADER_WRITE_BIT,
          .buffer = atomicCounterBuffer_-&gt;vkBuffer(),
          .size = atomicCounterBuffer_-&gt;size(),
      },
  };
  vkCmdPipelineBarrier(
      commandBuffer, srcStageFlags,
      dstStageFlags, 0, 0, nullptr, 2,
      &amp;bufferBarriers[0], 0, nullptr);
}</pre></li> <li>In the next step descriptor sets are bound, updated, and the vertex and index buffers are bound to <a id="_idIndexMarker439"/>the pipeline. Then the indexed draw command is issued for each mesh.<pre class="source-code">
pipeline_-&gt;bind(commandBuffer);
for (uint32_t meshIdx = 0;
     meshIdx &lt; numMeshes; ++meshIdx) {
  // ...
  vkCmdDrawIndexed(commandBuffer,
                   vertexCount, 1, 0, 0,
                   0);
}</pre></li> <li>The vertex fragment is not special, but the fragment shader must maintain a linked list along with head pointer. Below we present the code breakdown for <code>OitLinkedListBuildPass.frag</code> which is responsible for the build pass of the linked list OIT algorithm:<ol><li class="Alphabets">We start by defining a Node struct, which represents a node in a linked list for handling transparency. It contains the color and the index of the previous node. Afterwards, we declare several uniform and buffer variables, used for object properties, an atomic counter, a linked list of nodes, and an image for head <a id="_idIndexMarker440"/>pointers.</li></ol><pre class="source-code">
struct Node {
  vec4 color;
  uint previousIndex;
  float depth;
  uint padding1; // add 4 byte padding
                 // for alignment
  uint padding2; // add 4 byte padding
                 // for alignment
};
layout(set = 1, binding = 0) uniform
    ObjectProperties {
  vec4 color;
  mat4 model;
}
objectProperties;
layout(set = 2, binding = 0) buffer
    AtomicCounter {
  uint counter;
};
layout(set = 2,
       binding = 1) buffer LinkedList {
  Node transparencyList[];
}
transparencyLinkedList;
layout(set = 2, binding = 2,
       r32ui) uniform coherent uimage2D
    headPointers;</pre><ol><li class="Alphabets" value="2">The main function performs an atomic add operation on the atomic counter to get a unique index for each fragment. After calculating the size of the image and ensuring the new node index doesn’t exceed the maximum size of the linked list, it performs an atomic exchange operation to insert the new node at the<a id="_idIndexMarker441"/> beginning of the linked list. Finally, it sets the properties of the new node in the linked list.</li></ol><pre class="source-code">void main() {
  // Set the output color to transparent
  outputColor = vec4(0.0);
  // Atomic operation to get unique
  // index for each fragment, don't
  // return 0 since that will be used as
  // ll terminator
  uint newNodeIndex =
      atomicAdd(counter, 1) + 1;
  ivec2 size = imageSize(headPointers);
  // max size of linked list * width *
  // height
  if (newNodeIndex &gt;
      (10 * size.x * size.y) - 1) {
    return;
  }
  // Atomic operation to insert the new
  // node at the beginning of the linked
  // list
  uint oldHeadIndex =
      imageAtomicExchange(
          headPointers,
          ivec2(gl_FragCoord.xy),
          newNodeIndex);
  transparencyLinkedList
      .transparencyList[newNodeIndex]
      .previousIndex = oldHeadIndex;
  transparencyLinkedList
      .transparencyList[newNodeIndex]
      .color = objectProperties.color;
  transparencyLinkedList
      .transparencyList[newNodeIndex]
      .depth = gl_FragCoord.z;
  transparencyLinkedList
      .transparencyList[newNodeIndex]
      .padding1 = 0;
  transparencyLinkedList
      .transparencyList[newNodeIndex]
      .padding2 = 0;
}</pre></li> <li>The next and final step is to draw a full screen quad. Before performing the full screen quad pass, we set up memory and buffer barriers to ensure synchronization for the <code>linkedListBuffer_</code> and the <code>linkedListHeadPtrTexture_</code> since these resources are used during the composite pass.</li>
<li>Lastly, the composite pass fragment shader starts by first getting the head of the linked list for <a id="_idIndexMarker442"/>the current pixel. The list is stored in a buffer, and each pixel corresponds to the first node of a linked list of all fragments that affect that pixel. An array to temporarily store the nodes for sorting is created. We then iterate over the linked list, retrieving each node and storing it in the temporary array. It continues until it reaches the end of the list (denoted by <code>nodeIndex</code> being 0) or when it has retrieved 20 nodes:<pre class="source-code">
void main() {
  outputColor = vec4(0.0);
  // Get the head of the linked list for
  // the current pixel
  uint nodeIndex = imageLoad(headPointers,
                ivec2(gl_FragCoord.xy)).x;
  // Create a temporary array to store
  // the nodes for sorting
  Node nodes[20]; // Assuming a maximum
                  // of 20 overlapping
                  // fragments
  int numNodes = 0;
  // Iterate over the linked list
  while (nodeIndex != 0 &amp;&amp;
         numNodes &lt; 20) {
    nodes[numNodes] = transparencyLinkedList.transparencyList[nodeIndex];
    nodeIndex = nodes[numNodes].previousIndex;
    numNodes++;
  }</pre></li> <li>The nodes in the array are sorted in descending order based on their depth values using a simple bubble sort algorithm. This ensures that the nodes closest to the camera <a id="_idIndexMarker443"/>are blended last:<pre class="source-code">
  for (int i = 0; i &lt; numNodes; i++) {
    for (int j = i + 1; j &lt; numNodes; j++) {
      if (nodes[j].depth &gt; nodes[i].depth) {
        Node temp = nodes[i];
        nodes[i] = nodes[j];
        nodes[j] = temp;
      }
    }
  }</pre></li> <li>Finally, the colors of each node are blended from back to front using the mix function:<pre class="source-code">
  // Blend the colors from back to front
  for (int i = 0; i &lt; numNodes; i++) {
    outputColor = mix(outputColor, nodes[i].color,
            nodes[i].color.a);
  }
}</pre></li> </ol>
<p>This algorithm gives a very good result and is an excellent option if you value correctness. It’s a bit slower than the one presented in the next recipe, but it is by far the most intuitive<a id="_idIndexMarker444"/> algorithm amongst all the different algorithms we discussed in this chapter.</p>
<h2 id="_idParaDest-239"><a id="_idTextAnchor276"/>There’s more…</h2>
<p>We would like to note an additional technique, known as <strong class="bold">Tail Blending</strong>, that can be effectively <a id="_idIndexMarker445"/>combined with the technique discussed above. One of the limitations of our approach is the maximum number of fragments that can be accommodated for each pixel, which is typically dictated by the anticipated depth complexity of the scene and the memory available. In more intricate scenes with numerous overlapping transparent objects, the fragment count for a pixel may surpass this limit. That’s when Tail Blending becomes handy. When a linked list reaches its capacity, any extra fragments are directly blended with the color of the last node in the list, also known as the <em class="italic">tail</em>, hence the term <em class="italic">Tail Blending</em>. The benefit of tail blending is its ability to process scenes with extremely high depth complexity without the need to expand the maximum length of the linked list, thereby conserving memory. However, a potential drawback is that it might yield less precise results since blending is order-dependent and the fragments blended with the tail aren’t arranged in relation to the other fragments in the list.</p>
<h2 id="_idParaDest-240"><a id="_idTextAnchor277"/>See also</h2>
<p>Please see the following link on:</p>
<ul>
<li>Exploring and Expanding the Continuum of OIT Algorithms: <a href="http://cwyman.org/papers/hpg16_oitContinuum.pdf">http://cwyman.org/papers/hpg16_oitContinuum.pdf</a></li>
</ul>
<h1 id="_idParaDest-241"><a id="_idTextAnchor278"/>Implementing Weighted Order-Independent Transparency</h1>
<p><strong class="bold">Weighted Order-Independent Transparency</strong> (<strong class="bold">WOIT</strong>) uses a different idea to tackle <a id="_idIndexMarker446"/>transparency, by using the concept of weighted averages rather than using data structures like linked lists or layers like depth peeling.</p>
<p>This method doesn’t require sorting or linked lists or multiple passes, reducing the overhead associated with those operations. The final color is calculated by normalizing the color buffer with the weight buffer, which provides an aggregate view of the colors and their weights. Although it may not be as accurate as per-pixel linked lists in complex scenarios, WOIT offers a performance-efficient solution for handling transparency in scenes with lower depth complexity. In this recipe, you will gain an understanding of the WOIT technique. We will explore how this method employs weighted averages to handle transparency, eschewing the need for data structures like linked lists or multiple passes, thereby reducing associated overhead.</p>
<h2 id="_idParaDest-242"><a id="_idTextAnchor279"/>Getting ready</h2>
<p>In the repository, the WOIT algorithm is implemented by the <code>OitWeightedPass</code> class, located in source <code>/enginecore/passes/</code> <code>OitWeightedPass.hpp</code> and <code>cpp</code> files. The corresponding shaders are <code>source/enginecore/resources/shaders/OitWeighted.frag</code> and <code>source/enginecore/resources/shaders/ OITWeightedComposite.frag</code></p>
<p>The WOIT algorithm begins by initializing two empty buffers for each pixel, one for accumulating color and the other for accumulating weights. As the scene is rendered, the algorithm processes each transparent fragment and updates these buffers in a single rendering pass. During this pass, each fragment’s color is multiplied by its alpha value (the weight) and added to the color buffer, while the alpha value itself is added to the weight buffer. This process continues for all fragments, accumulating and blending their contributions based on their opacity. Once all fragments are processed, a final composite step is performed where the accumulated color in the color buffer is divided by the total weight in the weight buffer. This results in the final pixel color, providing a composite view of all transparent fragments based on their weights.</p>
<h2 id="_idParaDest-243"><a id="_idTextAnchor280"/>How to do it…</h2>
<p>The following steps provides a guide on implementing the WOIT technique using the Vulkan API.</p>
<ol>
<li>The <code>OitWeightedPass::init</code> method is tasked with initializing a variety of resources. It establishes both the Accumulation pass and the Composite pass pipelines. Furthermore, it arranges the necessary resources for the accumulation pass pipeline.<p class="list-inset">The <code>colorTexture_</code> uses the <code>VK_FORMAT_R16G16B16A16_SFLOAT</code> format. This format represents 4 channels (R, G, B, A) of 16-bit floating point numbers, providing high precision for color representation. It’s important for the color buffer to have a high precision format because during the accumulation<a id="_idIndexMarker447"/> pass, colors from various fragments are added together:</p><pre class="source-code">
colorTexture_ =
      context-&gt;createTexture(VK_IMAGE_TYPE_2D, VK_FORMAT_R16G16B16A16_SFLOAT ...</pre></li> <li>The <code>alphaTexture</code>_ uses the <code>VK_FORMAT_R16_SFLOAT</code> format, which is a single 16-bit floating point number. This is adequate because we’re only storing the alpha (opacity) value:<pre class="source-code">
alphaTexture_ =
      context-&gt;createTexture(VK_IMAGE_TYPE_2D, VK_FORMAT_R16_SFLOAT ...</pre></li> <li>Since WOIT depends upon blending, it’s important to set up blending attachments correctly. The pipeline descriptor <code>gpDesc</code> below is created with two <code>VkPipelineColorBlendAttachmentState</code> structures, one for each attachment. For the first blend attachment (corresponding to the color texture), the blend factors are set to <code>VK_BLEND_FACTOR_ONE</code> for both the source and destination, and the blend operation is <code>VK_BLEND_OP_ADD</code>. This effectively implements additive blending, where the new fragment’s color is added to the existing color in the color buffer.<pre class="source-code">
const VulkanCore::Pipeline::
  GraphicsPipelineDescriptor gpDesc = {
    .blendAttachmentStates_ = {
      VkPipelineColorBlendAttachmentState{
        .blendEnable = VK_TRUE,
        .srcColorBlendFactor =
          VK_BLEND_FACTOR_ONE,
        .dstColorBlendFactor =
          VK_BLEND_FACTOR_ONE,
        .colorBlendOp = VK_BLEND_OP_ADD,
        .srcAlphaBlendFactor =
          VK_BLEND_FACTOR_ONE,
        .dstAlphaBlendFactor =
          VK_BLEND_FACTOR_ONE,
        .alphaBlendOp = VK_BLEND_OP_ADD,
        .colorWriteMask =
          VK_COLOR_COMPONENT_R_BIT |
          VK_COLOR_COMPONENT_G_BIT |
          VK_COLOR_COMPONENT_B_BIT |
          VK_COLOR_COMPONENT_A_BIT,
      },</pre></li> <li>For the second blend <a id="_idIndexMarker448"/>attachment (corresponding to the alpha texture), the source alpha blend factor is <code>VK_BLEND_FACTOR_ZERO</code>, and the destination alpha blend factor is <code>VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR</code>. This configuration ensures that the new fragment’s alpha (or weight) is accumulated in the alpha buffer:<pre class="source-code">
         VkPipelineColorBlendAttachmentState{
          .blendEnable = VK_TRUE,
          .srcColorBlendFactor =
            VK_BLEND_FACTOR_ZERO,
          .dstColorBlendFactor =
            VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR,
          .colorBlendOp = VK_BLEND_OP_ADD,
          .srcAlphaBlendFactor =
            VK_BLEND_FACTOR_ZERO,
          .dstAlphaBlendFactor =
            VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
          .alphaBlendOp = VK_BLEND_OP_ADD,
          .colorWriteMask =
            VK_COLOR_COMPONENT_R_BIT |
            VK_COLOR_COMPONENT_G_BIT |
            VK_COLOR_COMPONENT_B_BIT |
            VK_COLOR_COMPONENT_A_BIT,
        },
      },
};</pre></li> <li>Next, we need to <a id="_idIndexMarker449"/>initialize the composite pipeline. This could be implemented as a Vulkan subpass, but for simplicity we have kept it as a separate pass. The composite pipeline is created with <code>VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA</code> as <code>srcColorBlendFactor</code> and <code>VK_BLEND_FACTOR_SRC_ALPHA</code> as <code>dstColorBlendFactor</code>.<p class="list-inset">This configuration causes the incoming fragment’s color and alpha values to be blended with the current color and alpha in the frame buffer, with the incoming fragment’s alpha value controlling how much of the incoming color overwrites the existing color.</p></li>
<li>The draw function is where the actual rendering occurs, the implementation is straightforward and uses <code>vkCmdDrawIndexed</code> to draw multiple meshes. Below we present the fragment shader used during this step. In this fragment shader, the view-space depth is scaled to provide depth weight; closer fragments are assigned larger weights. Then, the maximum color component multiplied by alpha is calculated to weigh vibrant pixels more. The calculated color weight is ensured to be no more than 1.0 and compared with the alpha to take the maximum value. The depth weight is then calculated and clamped within a specific range. The final weight is the product of color and depth weights. The color is then premultiplied by its alpha value to prevent over-saturation during<a id="_idIndexMarker450"/> blending. This shader outputs the weighted color and the original alpha of the fragment.<pre class="source-code">
void main() {
  const float scaledDepth =
      -(inViewSpaceDepth * 3.0) / 200;
  float maxColorComponent =
      max(max(objectProperties.color.r,
              objectProperties.color.g),
          objectProperties.color.b);
  float weightedColor =
      maxColorComponent *
      objectProperties.color.a;
  float weightedColorAlpha =
      max(min(1.0, weightedColor),
          objectProperties.color.a);
  float depthWeight =
      0.03 /
      (1e-5 + pow(scaledDepth, 4.0));
  depthWeight =
      clamp(depthWeight, 0.01, 4000);
  const float weight =
      weightedColorAlpha * depthWeight;
  outputColor =
      vec4(objectProperties.color.rgb *
               objectProperties.color.a,
           objectProperties.color.a) *
      weight;
  outputAlpha =
      objectProperties.color.a;
}</pre></li> <li>The final step is <a id="_idIndexMarker451"/>drawing a full screen quad using composite pipeline, it reads the accumulated color and alpha from two textures (<code>colorData</code> and <code>alphaData</code>) for the current fragment. The accumulated color (<code>accumulateColor</code>) is the sum of the product of color, alpha, and weight for each fragment from the previous step. The alpha value (alpha) is the original alpha value of the fragment. In the output color (<code>outColor</code>), the RGB components of the accumulated color are divided by the accumulated alpha value to normalize them, with a minimum limit of 0.0001 to prevent division by zero. This is because the accumulated color was premultiplied by the alpha value (and weight) in the previous steps.<pre class="source-code">
void main() {
  vec4 accumulateColor =
      texture(colorData, fragTexCoord);
  float alpha =
      texture(alphaData, fragTexCoord)
          .r;
  outColor = vec4(
      accumulateColor.rgb /
          max(accumulateColor.a, .0001),
      alpha);
}</pre></li> </ol>
<p>This technique is faster than the linked-list one presented in recipe <em class="italic">Implementing Linked-List Order-Independent Transparency</em>, but it has its drawbacks, such as the weighting function <a id="_idIndexMarker452"/>which is prone to add artifacts to the result if not well designed and tested.</p>
<h2 id="_idParaDest-244"><a id="_idTextAnchor281"/>There’s more…</h2>
<p>In this chapter, we have explored various techniques for handling transparency. The following table highlights<a id="_idIndexMarker453"/> the advantages and disadvantages of each method:</p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-2">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">Technique</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><strong class="bold">Memory</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><strong class="bold">Performance</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><strong class="bold">Physically correct</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p>Linked list OIT</p>
</td>
<td class="No-Table-Style T---Body">
<p>High, depends upon scene complexity as well as maintained LinkedList size</p>
</td>
<td class="No-Table-Style T---Body">
<p>Moderate speed, only requires two passes</p>
</td>
<td class="No-Table-Style T---Body">
<p>Highly accurate, handles complex overlapping geometry very well</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p>Dual Depth Peeling OIT</p>
</td>
<td class="No-Table-Style T---Body">
<p>Moderate, requires storage of two depth buffer</p>
</td>
<td class="No-Table-Style T---Body">
<p>Slower, since it requires multiple passes</p>
</td>
<td class="No-Table-Style T---Body">
<p>Moderate accuracy, struggles with highly complex scene.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p>WOIT</p>
</td>
<td class="No-Table-Style T---Body">
<p>Low, only needs to store weights &amp; colors for each fragment.</p>
</td>
<td class="No-Table-Style T---Body">
<p>Fast, since only single pass is required</p>
</td>
<td class="No-Table-Style T---Body">
<p>Low accuracy, requires careful weight management that can depend upon scene.</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 5.1 – Comparison of various techniques</p>
<p>We hope <em class="italic">Table 5.1</em> will help <a id="_idIndexMarker454"/>you decide which technique to use based upon your use case.</p>
<h2 id="_idParaDest-245"><a id="_idTextAnchor282"/>See also</h2>
<p>Please see following<a id="_idIndexMarker455"/> link for more details on WOIT:</p>
<ul>
<li>WOIT: https://jcgt.org/published/0002/02/09/</li>
</ul>
</div>
</body></html>