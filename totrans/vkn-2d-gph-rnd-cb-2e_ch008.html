<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>Advanced PBR extensions</title>


</head>
<body>
<div><h1 data-number="8">7 Advanced PBR extensions</h1>

<h2 data-number="8.1">Join our book community on Discord</h2>
<p>
<img height="301" src="img/file40.png" style="width:15rem" width="301"/>
</p>
<p><a href="https://packt.link/unitydev">https://packt.link/unitydev</a></p>
<p>In this chapter, we will delve into advanced glTF PBR extensions that build upon the base metallic-roughness model. While the base metallic-roughness model provides a starting point, it falls short of capturing the full spectrum of real-life materials. To address this, glTF incorporates additional material layers, each with specific parameters that define their unique behaviors. Our goal here is to guide you through implementing these layers from the ground up. We will introduce the concept of layers, break down some mathematical principles behind them, and then show you how to integrate each layer into the GLSL shader code.</p>
<p>Most of the C++ code provided in this chapter is applicable across all the recipes we will cover here and throughout the rest of our book.</p>
<p>In this chapter, you will learn the following recipes:</p>
<ul>
<li>Introduction to glTF PBR extensions</li>
<li>Implementing the <code>KHR_materials_clearcoat</code> extension</li>
<li>Implementing the <code>KHR_materials_sheen</code> extension</li>
<li>Implementing the <code>KHR_materials_transmission</code> extension</li>
<li>Implementing the <code>KHR_materials_volume</code> extension</li>
<li>Implementing the <code>KHR_materials_ior</code> extension</li>
<li>Implementing the <code>KHR_materials_specular</code> extension</li>
<li>Implementing the <code>KHR_materials_emissive_strength</code> extension</li>
<li>Extending analytical lights support with <code>KHR_lights_punctual</code></li>
</ul>
<blockquote>
<p>Our GLSL shaders code is based on the official Khronos Sample Viewer and serves as an example implementation of these extensions.</p>
</blockquote>


<h2 data-number="8.2">Introduction to glTF PBR extensions</h2>
<p>In this recipe, we will explore the design approach for PBR Material extensions, offering plenty of context to help you implement various glTF PBR extensions. The actual code will be shared in subsequent recipes, with the chapter structure following the sequence in which Khronos developed these PBR extensions.</p>
<p>PBR specifications evolve rapidly, and the reader should be aware that some extensions may become deprecated or obsolete by the time of reading.</p>

<h3 data-number="8.2.1">Getting ready</h3>
<p>We assume our readers have some basic understanding of linear algebra and calculus. It is recommended to have the glTF 2.0 list of ratified extensions specification at hand which can be found at <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md</a>.</p>


<h3 data-number="8.2.2">How is the glTF 2.0 PBR model designed?</h3>
<p>In the previous chapter, we explored the core Metallic-Roughness PBR model. This model is great for depicting many types of metallic and non-metallic materials, but the real world is much more complex.</p>
<p>To better capture that complexity, Khronos decided not to simply extend the Metallic-Roughness model. Instead, they introduced a layered approach, much like the layers of an onion. This method lets you gradually add complexity to the PBR material, similar to how layers are built up in Adobe Standard Surface <a href="https://github.com/Autodesk/standard-surfacehttps://github.com/Autodesk/standard-surface">https://github.com/Autodesk/standard-surfacehttps://github.com/Autodesk/standard-surface</a>.</p>
<p><strong>Layering</strong> mimics real-world material structures by stacking multiple layers, each with its own light-interacting properties. To maintain physical accuracy, the first layer, called the base layer, should be either fully opaque (like metallic surfaces) or completely transparent (like glass or skin). After that, additional layers, known as dielectric slabs, can be added on top of that one by one.</p>
<p>When light hits the boundary between two layers, it can reflect and bounce back in the opposite direction. However, our main concern here is the light that continues to move through the material stack. As this light passes through the lower layers, it may be absorbed by the material.</p>
<p>The mixing operation provides a unique method for material modeling. You can think of it as a statistically weighted blend of two different materials, where you combine a certain percentage of material <code>A</code> with a certain percentage of material <code>B</code>. While this technique is great for creating new materials, it is important to remember that not all combinations are physically realistic. For example, mixing oil and water wouldn’t produce a believable material.</p>
<p>When the mixing operation is done as a linear interpolation, it naturally follows the principle of energy conservation. This means that the total energy within the resulting material stays the same, consistent with the basic laws of physics.</p>
<figure>
<img alt="Figure 7.1: glTF PBR layering and mixing" height="957" src="img/file51.png" width="957"/><figcaption aria-hidden="true">Figure 7.1: glTF PBR layering and mixing</figcaption>
</figure>
<p>In the following recipes, we will dive into several advanced material layers: specular retro-reflection (sheen), coating specular reflection, and diffuse transmission. We will also explore how these layers can be combined to create a broader range of material appearances.</p>


<h3 data-number="8.2.3">Getting ready</h3>
<p>This chapter uses a single glTF viewer sample code for all the recipes. The <code>main.cpp</code> file varies across recipes in only two ways: they use different model files to demonstrate the specific glTF PBR extensions covered and the initial camera positions are adjusted to showcase the models attractively.</p>
<p>The source code for the glTF Viewer itself resides in the file <code>shared/UtilsGLTF.cpp</code>. The corresponding GLSL vertex and fragment shaders are located in the <code>data/shaders/gltf/</code> folder.</p>
<blockquote>
<p>The structure of these GLSL shaders differs from those covered in the previous chapter. We will explore the specific implementation differences in each of the individual recipes.</p>
</blockquote>


<h3 data-number="8.2.4">How to do it…</h3>
<p>Let’s go over the main differences between our glTF Viewer implementation from the previous chapter and the newly proposed unified version.</p>
<ol>
<li>We refactored the code and introduced a very basic structure in <code>shared/UtilsGLTF.h</code> to store all the necessary application data. This chapter will explain all the struct member fields.</li>
</ol>
<div><pre><code>struct GLTFContext {
  explicit GLTFContext(VulkanApp&amp; app_)
  : app(app_)
  , samplers(app_.ctx_)
  , envMapTextures(app_.ctx_) {}
  GLTFDataHolder glTFDataholder;
  MaterialsPerFrame matPerFrame;
  GLTFGlobalSamplers samplers;
  EnvironmentMapTextures envMapTextures;
  GLTFFrameData frameData;
  std::vector&lt;GLTFTransforms&gt; transforms;
  std::vector&lt;GLTFNode&gt; nodesStorage;
  std::vector&lt;GLTFMesh&gt; meshesStorage;
  std::vector&lt;uint32_t&gt; opaqueNodes;
  std::vector&lt;uint32_t&gt; transmissionNodes;
  std::vector&lt;uint32_t&gt; transparentNodes;
  lvk::Holder&lt;lvk::BufferHandle&gt; envBuffer;
  lvk::Holder&lt;lvk::BufferHandle&gt; perFrameBuffer;
  lvk::Holder&lt;lvk::BufferHandle&gt; transformBuffer;
  lvk::Holder&lt;lvk::RenderPipelineHandle&gt; pipelineSolid;
  lvk::Holder&lt;lvk::RenderPipelineHandle&gt; pipelineTransparent;
  lvk::Holder&lt;lvk::ShaderModuleHandle&gt; vert;
  lvk::Holder&lt;lvk::ShaderModuleHandle&gt; frag;
  lvk::Holder&lt;lvk::BufferHandle&gt; vertexBuffer;
  lvk::Holder&lt;lvk::BufferHandle&gt; indexBuffer;
  lvk::Holder&lt;lvk::BufferHandle&gt; matBuffer;
  lvk::Holder&lt;lvk::TextureHandle&gt; offscreenTex[3] = {};
  uint32_t currentOffscreenTex = 0;
  GLTFNodeRef root;
  VulkanApp&amp; app;
  bool volumetricMaterial = false;
  bool isScreenCopyRequired() const {
    return volumetricMaterial;
  }
};</code></pre>
</div>
<ol>
<li>Let’s introduce a very basic loading and rendering API for it. The <code>rebuildRenderList</code> argument signals that model-to-world transformations of glTF nodes should be rebuilt:</li>
</ol>
<div><pre><code>void loadglTF(GLTFContext&amp; context,
  const char* gltfName, const char* glTFDataPath);
void renderglTF(GLTFContext&amp; context,
  const mat4&amp; model, const mat4&amp; view, const mat4&amp; proj,
  bool rebuildRenderList = false);</code></pre>
</div>
<ol>
<li>We expanded the GPU data structures to include the required material properties and added a new <code>enum</code> called <code>MaterialType</code>, which allows us to provide the material ID as needed. The previous <em>Chapter 6, Physically Based Rendering Using the glTF 2.0 Shading Model</em> covered the old materials: unlit, metallic-roughness, and specular-glossiness. New materials will be covered here in this chapter in the subsequent recipes.</li>
</ol>
<div><pre><code>enum MaterialType : uint32_t {
  MaterialType_Invalid            = 0,
  MaterialType_Unlit              = 0xF,
  MaterialType_MetallicRoughness  = 0x1,
  MaterialType_SpecularGlossiness = 0x2,
  MaterialType_Sheen              = 0x4,
  MaterialType_ClearCoat          = 0x8,
  MaterialType_Specular           = 0x10,
  MaterialType_Transmission       = 0x20,
  MaterialType_Volume             = 0x40,
};</code></pre>
</div>
<ol>
<li>We’ve added <code>3</code> different vector containers to keep lists of the glTF nodes: opaque, transparent and transmission. Here is the function <code>buildTransformsList()</code> to build node transformations and collect other nodes data:</li>
</ol>
<div><pre><code>void buildTransformsList(GLTFContext&amp; gltf) {
  gltf.transforms.clear();
  gltf.opaqueNodes.clear();
  gltf.transmissionNodes.clear();
  gltf.transparentNodes.clear();</code></pre>
</div>
<ol>
<li>The body of our recursive traversal function is declared as a local C++ lambda. It collects all the transforms into <code>gltf.transforms</code> and adds opaque, transparent, and transmissive nodes to their corresponding containers:</li>
</ol>
<div><pre><code>  std::function&lt;void(GLTFNodeRef gltfNode)&gt; traverseTree =
    [&amp;]([&amp;](GLTFNodeRef nodeRef) {
      const GLTFNode&amp; node = gltf.nodesStorage[nodeRef];
      for (GLTFNodeRef meshId : node.meshes) {
        const GLTFMesh&amp; mesh = gltf.meshesStorage[meshId];
        gltf.transforms.push_back({
          .model = node.transform,
          .matId = mesh.matIdx,
          .nodeRef = nodeRef,
          .meshRef = meshId,
          .sortingType = mesh.sortingType });</code></pre>
</div>
<ol>
<li>Push the index of the transform that was just added to <code>gltf.transforms</code> in the code block above.</li>
</ol>
<div><pre><code>        uint32_t lastTransformIndex = gltf.transforms.size() – 1;
        if (mesh.sortingType == SortingType_Transparent) {
          gltf.transparentNodes.push_back(lastTransformIndex);
        } else if (mesh.sortingType==SortingType_Transmission) {
          gltf.transmissionNodes.push_back(lastTransformIndex);
        } else {
          gltf.opaqueNodes.push_back(lastTransformIndex );
        }
      }
      for (GLTFNodeRef child : node.children)
        traverseTree(child);
    };</code></pre>
</div>
<ol>
<li>Invoke the lambda to traverse the entire tree of glTF nodes starting from the root and store all the resulting transformations in a buffer:</li>
</ol>
<div><pre><code>  traverseTree(gltf.root);
  gltf.transformBuffer = gltf.app.ctx_-&gt;createBuffer({
    .usage     = lvk::BufferUsageBits_Uniform,
    .storage   = lvk::StorageType_HostVisible,
    .size      = gltf.transforms.size() * sizeof(GLTFTransforms),
    .data      = &amp;gltf.transforms[0],
    .debugName = “Per Frame data” });
};</code></pre>
</div>
<ol>
<li>Let’s add a node-sorting function to correctly render glTF nodes in the right order to support transparency. We’re using a very simple algorithm that sorts nodes based on the distance from the camera to the node’s center. To properly render transparent nodes, they should be rendered last, from back to front.</li>
</ol>
<div><pre><code>void sortTransparentNodes(
  GLTFContext&amp; gltf, const vec3&amp; cameraPos) {
  std::sort(
    gltf.transparentNodes.begin(),
    gltf.transparentNodes.end(),
    [&amp;](uint32_t a, uint32_t b) {
      float sqrDistA = glm::length2(
        cameraPos-vec3(gltf.transforms[a].model[3]));
      float sqrDistB = glm::length2(
        cameraPos-vec3(gltf.transforms[b].model[3]));
      return sqrDistA &lt; sqrDistB;
  });
}</code></pre>
</div>
<ol>
<li>Now we have to change the actual rendering function <code>renderGLTF()</code> to accommodate all the changes mentioned above.</li>
<li>First, we have to update the transforms list and sort glTF nodes based on the distance to the current camera.</li>
</ol>
<div><pre><code>void renderGLTF(GLTFContext&amp; gltf,
  const mat4&amp; model, const mat4&amp; view, const mat4&amp; proj,
  bool rebuildRenderList)
{
  auto&amp; ctx = gltf.app.ctx_;
  const vec4 camPos = glm::inverse(view)[3];
  if (rebuildRenderList || gltf.transforms.empty()) {
    buildTransformsList(gltf);
  }
  sortTransparentNodes(gltf, camPos);</code></pre>
</div>
<ol>
<li>Store per-frame camera parameters and prepare push constants with all necessary buffers and textures:</li>
</ol>
<div><pre><code>  gltf.frameData = {
    .model     = model,
    .view      = view,
    .proj      = proj,
    .cameraPos = camPos,
  };
  struct PushConstants {
    uint64_t draw;
    uint64_t materials;
    uint64_t environments;
    uint64_t transforms;
    uint32_t envId;
    uint32_t transmissionFramebuffer;
    uint32_t transmissionFramebufferSampler;
  } pushConstants = {
    .draw         = ctx-&gt;gpuAddress(gltf.perFrameBuffer),
    .materials    = ctx-&gt;gpuAddress(gltf.matBuffer),
    .environments = ctx-&gt;gpuAddress(gltf.envBuffer),
    .transforms   = ctx-&gt;gpuAddress(gltf.transformBuffer),
    .envId        = 0,
    .transmissionFramebuffer = 0,
    .transmissionFramebufferSampler =
      gltf.samplers.clamp.index(),
  };
  ctx-&gt;upload(
    gltf.perFrameBuffer, &amp;gltf.frameData, sizeof(GLTFFrameData));
  …</code></pre>
</div>
<ol>
<li>Let’s render all opaque nodes. For this pass, no transmission framebuffer is required:</li>
</ol>
<div><pre><code>  const lvk::RenderPass renderPass = {
    .color = { { .loadOp = lvk::LoadOp_Clear,
                 .clearColor = { 1.0f, 1.0f, 1.0f, 1.0f } } },
    .depth = { .loadOp = lvk::LoadOp_Clear, .clearDepth = 1.0f },
  };
  const lvk::Framebuffer framebuffer = {
    .color        = { {
     .texture = screenCopy ?
       gltf.offscreenTex[gltf.currentOffscreenTex] : 
       ctx-&gt;getCurrentSwapchainTexture() } },
    .depthStencil = { .texture = gltf.app.getDepthTexture() },
  };
  buf.cmdBeginRendering(renderPass, framebuffer);
  buf.cmdBindVertexBuffer(0, gltf.vertexBuffer, 0);
  buf.cmdBindIndexBuffer(
    gltf.indexBuffer, lvk::IndexFormat_UI32);
  buf.cmdBindDepthState({ .compareOp = lvk::CompareOp_Less,
                          .isDepthWriteEnabled = true });
  buf.cmdBindRenderPipeline(gltf.pipelineSolid);
  buf.cmdPushConstants(pushConstants);
  for (uint32_t transformId : gltf.opaqueNodes) {
    GLTFTransforms transform = gltf.transforms[transformId];
    buf.cmdPushDebugGroupLabel(
      gltf.nodesStorage[transform.nodeRef].name.c_str(),
      0xff0000ff);
    const GLTFMesh submesh =
      gltf.meshesStorage[transform.meshRef];</code></pre>
</div>
<ol>
<li><p>We use the built-in GLSL variable <code>gl_BaseInstance</code> to pass the value of <code>transformId</code> into shaders. This way, we do not have to update push constants per each draw call. This is the most efficient way to do it.</p>
<blockquote>
<p>The <code>firstInstance</code> parameter of <code>vkCmdDrawIndexed()</code> is assigned to the built-in GLSL variable <code>gl_BaseInstance</code>. This allows you to pass an arbitrary per-draw-call <code>uint32_t</code> value into vertex shaders without involving any buffers or push constants. This is a very fast technique and should be used whenever possible.</p>
</blockquote>
<pre><code>vkCmdDrawIndexed(VkCommandBuffer commandBuffer,
                 uint32_t        indexCount,    
                 uint32_t        instanceCount, 
                 uint32_t        firstIndex,
                 int32_t         vertexOffset,
                 uint32_t        firstInstance);</code></pre></li>
</ol>
<div><pre><code>    buf.cmdDrawIndexed(submesh.indexCount, 1,
      submesh.indexOffset, submesh.vertexOffset, transformId);
    buf.cmdPopDebugGroupLabel();
  }
  buf.cmdEndRendering();
  …</code></pre>
</div>
<ol>
<li>Now, we should render transparent nodes on top of opaque ones. Some transparent nodes may require a screen copy to render various effects, such as volume or index-of-refraction. Here’s a very simple way to obtain it:</li>
</ol>
<div><pre><code>  if (screenCopy) {
    buf.cmdCopyImage(
      gltf.offscreenTex[gltf.currentOffscreenTex],
      ctx-&gt;getCurrentSwapchainTexture(),
      ctx-&gt;getDimensions(ctx-&gt;getCurrentSwapchainTexture()));
    buf.cmdGenerateMipmap(
      gltf.offscreenTex[gltf.currentOffscreenTex]);
    pushConstants.transmissionFramebuffer =
      gltf.offscreenTex[gltf.currentOffscreenTex].index();
    buf.cmdPushConstants(pushConstants);
  }</code></pre>
</div>
<ol>
<li>As we start the next render pass and use the offscreen texture, we have to synchronize it properly:</li>
</ol>
<div><pre><code>  buf.cmdBeginRendering(renderPass, framebuffer, {
    .textures = { lvk::TextureHandle(
      gltf.offscreenTex[gltf.currentOffscreenTex]) } });
  buf.cmdBindVertexBuffer(0, gltf.vertexBuffer, 0);
  buf.cmdBindIndexBuffer(
    gltf.indexBuffer, lvk::IndexFormat_UI32);
  buf.cmdBindDepthState({ .compareOp = lvk::CompareOp_Less,
                          .isDepthWriteEnabled = true });</code></pre>
</div>
<ol>
<li>Now we render transmission nodes:</li>
</ol>
<div><pre><code>  buf.cmdBindRenderPipeline(gltf.pipelineSolid);
  for (uint32_t transformId : gltf.transmissionNodes) {
    const GLTFTransforms transform =
      gltf.transforms[transformId];
    buf.cmdPushDebugGroupLabel(
      gltf.nodesStorage[transform.nodeRef].name.c_str(),
      0x00FF00ff);
    const GLTFMesh submesh =
      gltf.meshesStorage[transform.meshRef];
    buf.cmdDrawIndexed(submesh.indexCount, 1,
      submesh.indexOffset, submesh.vertexOffset, transformId);
    buf.cmdPopDebugGroupLabel();
  }</code></pre>
</div>
<ol>
<li>Transparent nodes come last. The same <code>gl_BaseInstance</code> trick is used to pass the value of <code>transformId</code> for each glTF mesh:</li>
</ol>
<div><pre><code>  buf.cmdBindRenderPipeline(gltf.pipelineTransparent);
  for (uint32_t transformId : gltf.transparentNodes) {
    const GLTFTransforms transform =
      gltf.transforms[transformId];
    buf.cmdPushDebugGroupLabel(
      gltf.nodesStorage[transform.nodeRef].name.c_str(),
      0x00FF00ff);
    const GLTFMesh submesh =
      gltf.meshesStorage[transform.meshRef];
    buf.cmdDrawIndexed(submesh.indexCount, 1,
      submesh.indexOffset, submesh.vertexOffset, transformId);
    buf.cmdPopDebugGroupLabel();
  }</code></pre>
</div>
<ol>
<li>Once the command buffer is filled, we can submit it and use another offscreen texture in a round-robin manner.</li>
</ol>
<div><pre><code>  buf.cmdEndRendering();
  ctx-&gt;submit(buf, ctx-&gt;getCurrentSwapchainTexture());
  gltf.currentOffscreenTex = (gltf.currentOffscreenTex + 1) %
    LVK_ARRAY_NUM_ELEMENTS(gltf.offscreenTex);</code></pre>
</div>
<p>This was a complete overview of our generic glTF rendering code. The real magic happens inside the GLSL shaders. In the next recipes, we will go through the shaders step by step to learn how to implement different glTF material extensions.</p>


<h3 data-number="8.2.5">There’s more...</h3>
<p>The Khronos <em>3D Formats Working Group</em> is constantly working to improve PBR material capabilities by introducing new extension specifications. To stay up to date with the status of approved extensions, you can visit the Khronos GitHub page: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/README.md</a></p>



<h2 data-number="8.3">Implementing the KHR_materials_clearcoat extension</h2>
<p>The <strong>KHR_materials_clearcoat</strong> extension improves glTF’s core <strong>physically based rendering</strong> (<strong>PBR</strong>) model by adding a clear, reflective layer on top of another material or surface. This layer reflects light both from itself and the layers underneath. Examples of this effect include the glossy finish on car paint or the shine of a well-polished shoe.</p>
<p>Here is a link to the Khronos glTF PBR extension: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_clearcoat/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_clearcoat/README.md</a></p>

<h3 data-number="8.3.1">Clearcoat parameters</h3>
<p>The following parameters are provided by the <code>KHR_materials_clearcoat</code> extension:</p>
<p><em>clearcoatFactor / clearcoatTexure</em>: This parameter indicates the intensity of the coating. It can be set using a scalar factor or a texture. A value of <code>0</code> means no coating, while a value of <code>1</code> indicates the presence of the coating. In-between values should be used only along the boundary between coated and uncoated areas.</p>
<p><em>clearcoatNormalTexture:</em> This parameter allows a normal map to be applied to the coating layer, introducing variations and details to the coating surface.</p>
<p><em>clearcoatRoughnessFactor / clearcoatRoughnessTexture:</em> This parameter indicates the coating roughness. It can be set as a roughness scalar factor or a roughness texture. It works similarly to the roughness parameter of a base material but is applied to the coating layer.</p>


<h3 data-number="8.3.2">Specular BRDF for the clearcoat layer</h3>
<p>The specular BRDF for the clearcoat layer uses the specular term from the glTF 2.0 Metallic-Roughness material. However, to maintain energy conservation within the material when using a simple layering function, a slight adjustment is applied.</p>
<p>The microfacet Fresnel term is calculated using the <code>NdotV</code> term instead of the <code>VdotH</code> term, effectively ignoring the microscopic surface orientation within the clearcoat layer. This simplification is justified because clearcoat layers usually have very low roughness, meaning the microfacets are mostly aligned with the normal direction. As a result, <code>NdotV</code> becomes approximately equivalent to <code>NdotL</code>. This approach ensures energy conservation within the material through a simple layering function and keeps computations efficient by omitting the <code>VdotH</code> term.</p>
<blockquote>
<p>As explained in the previous chapter <em>Physically Based Rendering Using the glTF 2.0 Shading Model</em>, <code>N</code> represents the normal vector at the surface point, <code>V</code> is the vector pointing from the surface to the viewer, <code>L</code> is the vector pointing from the surface point to the light source, and <code>H</code> is the half-vector that lies exactly between the directions of the light source <code>L</code> and the viewer <code>V</code>.</p>
</blockquote>
<p>The provided implementation of the <code>clearcoat</code> layer within the BRDF framework makes certain assumptions that neglect some real-world material properties. Here’s a breakdown of these limitations:</p>
<ul>
<li><strong>Infinitely Thin Layer</strong>: The clearcoat layer is treated as infinitely thin, disregarding its actual thickness.</li>
<li><strong>Neglecting Refraction</strong>: Refraction, bending of light as it passes through the clearcoat layer, is not taken into account.</li>
<li><strong>Independent Fresnel Terms</strong>: The refractive indices of the clearcoat and base layers are treated as independent, with their Fresnel terms calculated separately, without accounting for any interaction between them.</li>
<li><strong>Omitted Scattering</strong>: The current model does not account for light scattering between the clearcoat layer and the base layer.</li>
<li><strong>Diffraction Ignored:</strong> Diffraction effects, the slight bending of light around the edges of microscopic facets, are not taken into account.</li>
</ul>
<p>Despite these limitations, the clearcoat BRDF is a valuable tool for simulating clear coat effects in material modeling. It strikes a good balance between computational efficiency and producing visually plausible results, especially for clearcoat layers with low roughness.</p>
<blockquote>
<p>Important notice</p>
<blockquote>
<p>The clearcoat extension is designed to work with glTF’s core PBR shading model and is not compatible with other shading models like Unlit or Specular-glossiness. However, it can still be used alongside other PBR parameters, such as emissive materials, where the emitted light is influenced by the clearcoat layer.</p>
</blockquote>
</blockquote>


<h3 data-number="8.3.3">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/01_Clearcoat/</code>.</p>


<h3 data-number="8.3.4">How to do it…</h3>
<p>Let’s take a look at the C++ code in <code>Chapter07/01_Clearcoat/src/main.cpp</code>.</p>
<ol>
<li>First, let’s load a <code>.gltf</code> file using our new glTF API:</li>
</ol>
<div><pre><code>  VulkanApp app({
      .initialCameraPos    = vec3(0.0f, -0.2f, -1.5f),
      .initialCameraTarget = vec3(0.0f, -0.5f, 0.0f),
  });
  GLTFContext gltf(app);
  loadGLTF(gltf,
    “deps/src/glTF-Sample-Assets/Models/ClearcoatWicker/
      glTF/ClearcoatWicker.gltf”,
    “deps/src/glTF-Sample-Assets/Models/ClearcoatWicker/glTF/”);</code></pre>
</div>
<ol>
<li>Then we render it using the <code>renderGLTF()</code> function described in the previous recipe <em>Introduction to glTF PBR extensions</em>:</li>
</ol>
<div><pre><code>  const mat4 t = glm::translate(mat4(1.0f), vec3(0, -1, 0));
  app.run([&amp;](uint32_t width, uint32_t height,
              float aspectRatio, float deltaSeconds) {
    const mat4 m = t * glm::rotate(
      mat4(1.0f),  (float)glfwGetTime(), vec3(0.0f, 1.0f, 0.0f));
    const mat4 v = app.camera_.getViewMatrix();
    const mat4 p = glm::perspective(
      45.0f, aspectRatio, 0.01f, 100.0f);
    renderGLTF(gltf, m, v, p);
  });</code></pre>
</div>
<p>To load clearcoat parameters from a <code>.gltf</code> file, we have to introduce some changes to our GLTF material loader. Let’s take a look at the steps required to do it.</p>
<ol>
<li>First, we should add some new member fields to the <code>GLTFMaterialDataGPU</code> structure in the file <code>shared/UtilsGLTF.h</code> to store scalar values and corresponding textures:</li>
</ol>
<div><pre><code>struct GLTFMaterialDataGPU {
  …
  vec4 clearcoatTransmissionThickness = vec4(1, 1, 1, 1);
  uint32_t clearCoatTexture                 = 0;
  uint32_t clearCoatTextureSampler          = 0;
  uint32_t clearCoatTextureUV               = 0;
  uint32_t clearCoatRoughnessTexture        = 0;
  uint32_t clearCoatRoughnessTextureSampler = 0;
  uint32_t clearCoatRoughnessTextureUV      = 0;
  uint32_t clearCoatNormalTexture           = 0;
  uint32_t clearCoatNormalTextureSampler    = 0;
  uint32_t clearCoatNormalTextureUV         = 0;
  …
}</code></pre>
</div>
<ol>
<li>Let’s load textures and properties using the Assimp library in <code>shared/UtilsGLTF.cpp</code>. Here we emphasize only the properties related to the clearcoat extension:</li>
</ol>
<div><pre><code>GLTFMaterialDataGPU setupglTFMaterialData(
  const std::unique_ptr&lt;lvk::IContext&gt;&amp; ctx,
  const GLTFGlobalSamplers&amp; samplers,
  const aiMaterial* mtlDescriptor,
  const char* assetFolder,
  GLTFDataHolder&amp; glTFDataholder,
  bool&amp; useVolumetric)
{
  …
  // clearcoat
  loadMaterialTexture(mtlDescriptor, aiTextureType_CLEARCOAT,
    assetFolder, mat.clearCoatTexture, ctx, true, 0);
  loadMaterialTexture(mtlDescriptor, aiTextureType_CLEARCOAT,
    assetFolder, mat.clearCoatRoughnessTexture, ctx, false, 1);
  loadMaterialTexture(mtlDescriptor, aiTextureType_CLEARCOAT,
    assetFolder, mat.clearCoatNormalTexture, ctx, false, 2);
  …
  bool useClearCoat = !mat.clearCoatTexture.empty() ||
                      !mat.clearCoatRoughnessTexture.empty() ||
                      !mat.clearCoatNormalTexture.empty();
  ai_real clearcoatFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_CLEARCOAT_FACTOR,
    clearcoatFactor) == AI_SUCCESS) {
    res.clearcoatTransmissionThickness.x = clearcoatFactor;
    useClearCoat = true;
  }
  ai_real clearcoatRoughnessFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_CLEARCOAT_ROUGHNESS_FACTOR,
    clearcoatRoughnessFactor) == AI_SUCCESS) {
    res.clearcoatTransmissionThickness.y =
      clearcoatRoughnessFactor;
    useClearCoat = true;
  }
  if (assignUVandSampler(
        samplers, mtlDescriptor, aiTextureType_CLEARCOAT,
        res.clearCoatTextureUV,
        res.clearCoatNormalTextureSampler, 0)) {
    useClearCoat = true;
  }
  if (assignUVandSampler(
        samplers, mtlDescriptor, aiTextureType_CLEARCOAT,
        res.clearCoatRoughnessTextureUV, 
        res.clearCoatRoughnessTextureSampler, 1)) {
    useClearCoat = true;
  }
  if (assignUVandSampler(
        samplers, mtlDescriptor, aiTextureType_CLEARCOAT,
        res.clearCoatNormalTextureUV,
        res.clearCoatNormalTextureSampler, 2)) {
    useClearCoat = true;
  }
  if (useClearCoat) 
    res.materialTypeFlags |= MaterialType_ClearCoat;</code></pre>
</div>
<blockquote>
<p>Please note that we only set the <code>MaterialType_ClearCoat</code> flag if the checks pass and the extension is present in the <code>.gltf</code> file. While it’s technically possible to enable the clearcoat layer all the time — since the default settings effectively disable it — doing so is highly inefficient. The clearcoat layer adds secondary BRDF sampling, which is computationally expensive. It is better to use only the expensive features that are actually needed!</p>
</blockquote>
<p>That’s it for the C++ changes. Now, let’s look at the GLSL shader changes, where the actual rendering work takes place:</p>
<ol>
<li>Similar to the C++ changes for new parameters, we added GLSL utility functions to read clearcoat data from textures and input buffers in <code>data/shaders/gltf/inputs.frag</code>. The clearcoat factor and roughness are packed into a texture as <code>r</code> and <code>g</code> channels respectively:</li>
</ol>
<div><pre><code>float getClearcoatFactor(InputAttributes tc,
                         MetallicRoughnessDataGPU mat)
{
  return textureBindless2D(mat.clearCoatTexture,
    mat.clearCoatTextureSampler,
    tc.uv[mat.clearCoatTextureUV]
  ).r * mat.clearcoatTransmissionThickness.x;
}
float getClearcoatRoughnessFactor(InputAttributes tc,
                                  MetallicRoughnessDataGPU mat)
{
  return textureBindless2D(mat.clearCoatRoughnessTexture,
    mat.clearCoatRoughnessTextureSampler,
    tc.uv[mat.clearCoatRoughnessTextureUV]
  ).g * mat.clearcoatTransmissionThickness.y;
}</code></pre>
</div>
<ol>
<li>We calculate the clearcoat contribution as described in the beginning of this recipe. We use the GGX BRDF to perform an additional lookup and provide clearcoat roughness, reflectance <code>clearcoatF0</code>, and normal as inputs in <code>data/shaders/gltf/main.frag</code>. Please note that we use the IOR parameter, which will be covered later in the recipe <em>Implementing the IOR extension</em>:</li>
</ol>
<div><pre><code>  vec3 clearCoatContrib = vec3(0);
  if (isClearCoat) {
    pbrInputs.clearcoatFactor = getClearcoatFactor(tc, mat);
    pbrInputs.clearcoatRoughness =
      clamp(getClearcoatRoughnessFactor(tc, mat), 0.0, 1.0);
    pbrInputs.clearcoatF0 = vec3(pow((pbrInputs.ior - 1.0) /
                            (pbrInputs.ior + 1.0), 2.0));
    pbrInputs.clearcoatF90 = vec3(1.0);
    if (mat.clearCoatNormalTextureUV &gt; -1) {
      pbrInputs.clearcoatNormal = mat3(
        pbrInputs.t, pbrInputs.b, pbrInputs.ng) *
        sampleClearcoatNormal(tc, mat).rgb;
    } else {
      pbrInputs.clearcoatNormal = pbrInputs.ng;
    }
    clearCoatContrib = getIBLRadianceGGX(
      pbrInputs.clearcoatNormal, pbrInputs.v,
      pbrInputs.clearcoatRoughness,
      pbrInputs.clearcoatF0, 1.0, envMap);
  }</code></pre>
</div>
<ol>
<li>We calculate the Fresnel term for the clearcoat layer using a similar approach. We apply the Schlick approximation, but with input data specific to the clearcoat:</li>
</ol>
<div><pre><code>  vec3 clearcoatFresnel = vec3(0);
  if (isClearCoat) {
    clearcoatFresnel = F_Schlick(
      pbrInputs.clearcoatF0,
      pbrInputs.clearcoatF90,
      clampedDot(pbrInputs.clearcoatNormal, pbrInputs.v));
  }</code></pre>
</div>
<ol>
<li>Finally, at the very end of the fragment shader <code>data/shaders/gltf/main.frag</code>, we apply the clearcoat contribution on top of all layers, including emissive ones! Note the <code>sheenColor</code> value here, which will be covered in the next recipe <em>Implementing the sheen material extension</em>.</li>
</ol>
<div><pre><code>  vec3 color =
    specularColor + diffuseColor + emissiveColor + sheenColor;
  color = color *
    (1.0 - pbrInputs.clearcoatFactor * clearcoatFresnel) +
    clearCoatContrib;</code></pre>
</div>
<p>This concludes all the necessary GLSL changes to implement the clearcoat extension. The demo app should look like the screenshot below:</p>
<figure>
<img alt="Figure 7.2: glTF PBR KHR_materials_clearcoat example" height="832" src="img/file52.png" width="1427"/><figcaption aria-hidden="true">Figure 7.2: glTF PBR KHR_materials_clearcoat example</figcaption>
</figure>
<p>Notice the glossy layer on top of the ball—this is the clearcoat! Congratulations, we’ve completed our first advanced PBR extension.</p>


<h3 data-number="8.3.5">There’s more...</h3>
<p>The Khronos glTF extensions repository includes a comprehensive list of references for clearcoat materials: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_clearcoat/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_clearcoat/README.md</a></p>



<h2 data-number="8.4">Implementing the KHR_materials_sheen extension</h2>
<p>The <code>KHR_materials_sheen</code> extension improves the glTF 2.0 Metallic-Roughness material by adding a layer that simulates the sheen effect found on fabrics like satin or brushed metals. This enhancement creates more realistic and visually appealing sheen highlights.</p>
<p><strong>Sheen BRDF</strong> sits on top of the glTF 2.0 Metallic-Roughness material. If the previous extension <code>KHR_materials_clearcoat</code> is also active, it is layered on top of the sheen effect.</p>
<p>The <code>sheenColorFactor</code> property controls the base intensity of the sheen effect, independent of the viewing angle. A value of <code>0</code> disables <strong>sheen</strong> entirely.</p>

<h3 data-number="8.4.1">Sheen parameters</h3>
<p><em>sheenColorTexture / sheenColorFactor</em>: If the texture is defined, the sheen color is calculated by multiplying <code>sheenColorFactor</code> and the texture’s RGB value.</p>
<p><em>sheenRoughnessTexture / sheenRoughnessFactor:</em> If defined, the sheen roughness is calculated by multiplying with the texture’s alpha channel value.</p>
<p>If no textures are specified, <code>sheenColorFactor</code> directly controls the sheen color, and <code>sheenRoughnessFactor</code> directly controls sheen roughness.</p>


<h3 data-number="8.4.2">Simulating the sheen effect</h3>
<p>The <strong>sheen BRDF</strong> simulates how light scatters off velvet-like materials. It models how light bounces off tiny fibers that are oriented perpendicular to the surface. Sheen roughness controls how much these fibers deviate from that direction:</p>
<ul>
<li>Lower sheen roughness: the fibers are more aligned, creating a sharper sheen highlight when light grazes the surface.</li>
<li>Higher sheen roughness: the fibers are more scattered, leading to a softer sheen highlight.</li>
</ul>
<p>The sheen BRDF is mathematically based on an exponentiated sinusoidal distribution, derived from the microfacet theory (Conty &amp; Kulla, 2017 <a href="https://blog.selfshadow.com/publications/s2017-shading-course/#course_content">https://blog.selfshadow.com/publications/s2017-shading-course/#course_content</a>). The roughness is mapped using <code>r=sheenRoughness^2</code> for a more intuitive understanding of roughness changes.</p>
<p>Sheen roughness operates independently of the material’s base roughness. This makes it possible for a material to have a rough surface texture (high base roughness) while still displaying a sharp sheen effect (low sheen roughness).</p>
<p>Not all incoming light interacts with the microfibers. Some light may directly reach the base layer or bounce between the fibers before doing so. The behavior of this light is governed by the underlying glTF 2.0 PBR Metallic-Roughness material properties.</p>


<h3 data-number="8.4.3">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/02_Sheen/</code>.</p>


<h3 data-number="8.4.4">How to do it…</h3>
<p>Similar to the previous recipe <em>Implementing the clear coat material extension</em>, we introduce a bunch of new material parameters . Let’s take a look at the C++ code.</p>
<ol>
<li>Let’s load a <code>.gltf</code> file to demonstrate the effect <code>Chapter07/02_Sheen/src/main.cpp</code>:</li>
</ol>
<div><pre><code>  GLTFContext gltf(app);
  loadGLTF(gltf,
    “deps/src/glTF-Sample-Assets/Models/
      SheenChair/glTF/SheenChair.gltf”,
    “deps/src/glTF-Sample-Assets/Models/SheenChair/glTF/”);</code></pre>
</div>
<ol>
<li>In the file <code>shared/UtilsGLTF.h</code>, we added new member fields to the <code>GLTFMaterialDataGPU</code> structure in:</li>
</ol>
<div><pre><code>struct GLTFMaterialDataGPU {
  …
  vec4 sheenFactors       = vec4(1.0f, 1.0f, 1.0f, 1.0f);
  uint32_t sheenColorTexture            = 0;
  uint32_t sheenColorTextureSampler     = 0;
  uint32_t sheenColorTextureUV          = 0;
  uint32_t sheenRoughnessTexture        = 0;
  uint32_t sheenRoughnessTextureSampler = 0;
  uint32_t sheenRoughnessTextureUV      = 0;</code></pre>
</div>
<ol>
<li>Let’s load new parameters via Assimp in <code>shared/UtilsGLTF.cpp</code> and store them into the sheen material. The sheen color texture is <code>sRGB</code> and has the index <code>0</code> and the roughness texture has the index of <code>1</code>:</li>
</ol>
<div><pre><code>  loadMaterialTexture(mtlDescriptor, aiTextureType_SHEEN,
    assetFolder, mat.sheenColorTexture, ctx, true, 0);
  loadMaterialTexture(mtlDescriptor, aiTextureType_SHEEN,
    assetFolder, mat.sheenRoughnessTexture, ctx, false, 1);
  bool useSheen = !mat.sheenColorTexture.empty() ||
                  !mat.sheenRoughnessTexture.empty();
  aiColor4D sheenColorFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_SHEEN_COLOR_FACTOR,
      sheenColorFactor) == AI_SUCCESS) {
    res.sheenFactors = vec4(sheenColorFactor.r,
                            sheenColorFactor.g,
                            sheenColorFactor.b,
                            sheenColorFactor.a);
    useSheen      = true;
  }
  ai_real sheenRoughnessFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_SHEEN_ROUGHNESS_FACTOR,
      sheenRoughnessFactor) == AI_SUCCESS) {
    res.sheenFactors.w = sheenRoughnessFactor;
    useSheen = true;
  }
  if (assignUVandSampler(samplers, mtlDescriptor,
      aiTextureType_SHEEN, res.sheenColorTextureUV,
      res.sheenColorTextureSampler, 0)) {
    useSheen = true;
  }
  if (assignUVandSampler(samplers, mtlDescriptor,
      aiTextureType_SHEEN, res.sheenRoughnessTextureUV,
      res.sheenRoughnessTextureSampler, 1)) {
    useSheen = true;
  }
  if (useSheen) res.materialTypeFlags |= MaterialType_Sheen;
  …</code></pre>
</div>
<p>As you can see, we follow the same pattern as with the clearcoat extension and set the flag <code>MaterialType_Sheen</code> only when we use this extension. This is it for the main C++ code.</p>
<p>The Sheen extension needs a different BRDF function, which was discussed in the recipe <em>Precomputing BRDF look-up tables</em> of the previous <em>Chapter 6, Physically Based Rendering Using the glTF 2.0 Shading Model</em>. We recommend reviewing that recipe to refresh your understanding of how precomputed BRDF LUTs work and revisiting the implementation details.</p>
<p>Now let’s take a look at the GLSL shader code changes which follow a similar pattern:</p>
<ol>
<li>Let’s introduce some utility functions in <code>data/shaders/gltf/inputs.frag</code>. We can simplify these functions by pre-multiplying textures values by sheen factors. In the C++ code, we set <code>sheenColorTexture</code> and <code>sheenRoughnessTexture</code> to use a white 1x1 texture in case when no texture data is provided in the <code>.gltf</code> asset. In this case, it is always correct to multiply these values by identity factors. We still perform a texture lookup for this small texture, but the overhead is minimal. These small textures should always fit into the GPU’s fastest cache:</li>
</ol>
<div><pre><code>vec4 getSheenColorFactor(InputAttributes tc,
  MetallicRoughnessDataGPU mat) {
  return vec4(mat.sheenFactors.xyz, 1.0f) *
    textureBindless2D(mat.sheenColorTexture,
                      mat.sheenColorTextureSampler,
                      tc.uv[mat.sheenColorTextureUV]);
}
float getSheenRoughnessFactor(InputAttributes tc,
  MetallicRoughnessDataGPU mat) {
  return mat.sheenFactors.a * textureBindless2D(
    mat.sheenRoughnessTexture,
    mat.sheenRoughnessTextureSampler,
    tc.uv[mat.sheenRoughnessTextureUV]).a;
}</code></pre>
</div>
<ol>
<li>The GLSL code of the sheen extension is scattered between the main fragment shader <code>data/shaders/gltf/main.frag</code> and the PBR module <code>data/shaders/gltf/PBR.sp</code>. In <code>main.frag</code>, we apply sheen parameters:</li>
</ol>
<div><pre><code>  …
  if (isSheen) {
    pbrInputs.sheenColorFactor =
      getSheenColorFactor(tc, mat).rgb;
    pbrInputs.sheenRoughnessFactor =
      getSheenRoughnessFactor(tc, mat);
  }
  …</code></pre>
</div>
<p>In the next step during IBL calculations, we accumulate the sheen contribution calculated using the Charlie distribution:</p>
<div><pre><code>  vec3 sheenColor = vec3(0);
  if (isSheen) {
    sheenColor += getIBLRadianceCharlie(pbrInputs, envMap);
  }</code></pre>
</div>
<ol>
<li>Let’s take a look at the implementation of <code>getIBLRadianceCharlie()</code> in the file <code>data/shaders/gltf/PBR.sp</code>. This function is similar to <code>getIBLRadianceGGX()</code> used for metallic-roughness, but is much simpler. The Sheen extension provides its own roughness value, so no perceptual adjustments are needed. All we have to do here is to multiply <code>sheenRoughnessFactor</code> by the total number of mip-levels <code>mipCount</code> to determine the correct mip-level, sample the precalculated environment map, and then multiply it by the <code>BRDF</code> and <code>sheenColor</code>.</li>
</ol>
<div><pre><code>vec3 getIBLRadianceCharlie(PBRInfo pbrInputs,
  EnvironmentMapDataGPU envMap) {
  float sheenRoughness = pbrInputs.sheenRoughnessFactor;
  vec3 sheenColor = pbrInputs.sheenColorFactor;
  float mipCount = float(sampleEnvMapQueryLevels(envMap));
  float lod = sheenRoughness * float(mipCount - 1);
  vec3 reflection =
    normalize(reflect(-pbrInputs.v, pbrInputs.n));
  vec2 brdfSamplePoint = clamp(vec2(pbrInputs.NdotV,
    sheenRoughness), vec2(0.0, 0.0), vec2(1.0, 1.0));
  float brdf = sampleBRDF_LUT(brdfSamplePoint, envMap).b;
  vec3 sheenSample = sampleCharlieEnvMapLod(
    reflection.xyz, lod, envMap).rgb;
  return sheenSample * sheenColor * brdf;
}</code></pre>
</div>
<ol>
<li>Let’s go back to <code>data/shaders/gltf/main.frag</code>. We modify the sheen contribution based on the value of <code>occlusionStrength</code>. Light’s The l sheen calculation <code>lights_sheen</code> will be covered in the last recipe <em>Extend analytical lights support</em> in this chapter. For now, assume it is just zero.</li>
</ol>
<div><pre><code>  vec3 lights_sheen = vec3(0);
  sheenColor = lights_sheen +
    mix(sheenColor, sheenColor * occlusion, occlusionStrength);</code></pre>
</div>
<p>This is all the additional code required to implement the Sheen extension. The running demo app should look as in the following screenshot:</p>
<figure>
<img alt="Figure 7.3: glTF PBR KHR_materials_sheen example" height="832" src="img/file53.png" width="1427"/><figcaption aria-hidden="true">Figure 7.3: glTF PBR KHR_materials_sheen example</figcaption>
</figure>


<h3 data-number="8.4.5">There’s more...</h3>
<p>The Khronos glTF extensions repository has a comprehensive list of references to sheen materials: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_sheen/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_sheen/README.md</a>.</p>



<h2 data-number="8.5">Implementing the KHR_materials_transmission extension</h2>
<p>The glTF 2.0 core specification uses a basic method for handling transparency called <strong>alpha-as-coverage</strong>. While this approach works well for simple materials like gauze or burlap, it doesn’t do a good job of representing more complex transparent materials like glass or plastic. These materials involve complicated light interactions—such as reflection, refraction, absorption, and scattering—that alpha-as-coverage can’t accurately simulate on its own.</p>
<p>Alpha-as-coverage basically decides if a surface is there or not. A value of <code>0</code> means nothing is visible, while a value of <code>1</code> means the surface is solid. This method works well for materials with holes or gaps that let light pass through without actually entering the material. However, for materials like glass, light interacts with the surface in more complex ways—like reflecting, refracting, or even being absorbed. Alpha-as-coverage can’t handle these kinds of interactions. Additionally, it affects how intense reflections are, making more transparent materials have weaker reflections. This is the opposite of what happens with real-world transparent materials, which often have strong reflections even when they’re see-through.</p>
<p>To overcome the limitations of alpha-as-coverage, the <code>KHR_materials_transmission</code> extension offers a more realistic way to render transparent materials in glTF. It allows for the simulation of materials that absorb, reflect, and transmit light depending on the angle of incidence and the light’s wavelength. This extension is especially useful for accurately representing thin-surface materials like plastic and glass.</p>
<p>The <code>KHR_materials_transmission</code> extension targets the simplest cases of optical transparency: infinitely thin materials without refraction, scattering, or dispersion. This simplification enables efficient calculations of refraction and absorption.</p>

<h3 data-number="8.5.1">Transmission parameters</h3>
<p>The <code>KHR_materials_transmission </code>extension adds new properties to define material’s transmission characteristics:</p>
<p><em>transmissionFactor</em>: A scalar value between <code>0</code> and <code>1</code> that represents the material’s overall opacity. A value of <code>0</code> means the material is fully opaque, while a value of <code>1</code> means it is completely transparent.</p>
<p><em>transmissionFilter</em>: A color value that alters the color of the light passing through the material.</p>


<h3 data-number="8.5.2">Transmission BTDF</h3>
<p>The <code>KHR_materials_transmission</code> extension introduces a specular <strong>BTDF</strong> (Bidirectional Transmission Distribution Function) based on the microfacet model. It uses the same <strong>Trowbridge-Reitz</strong> distribution as the specular <strong>BRDF</strong> (Bidirectional Reflectance Distribution Function) but samples along the view vector instead of the reflection direction. This method simulates how microfacets act like tiny prisms, blurring the transmitted light.</p>
<p>The transmission process is modeled as two back-to-back surfaces, representing a thin material. This approach simplifies the process by avoiding the complexities of average refraction and instead focusing on refraction at the microfacet level. The roughness parameter affects both reflection and transmission since the microfacet distribution impacts both sides of the surface. Let’s take a look at how to implement this glTF extension.</p>


<h3 data-number="8.5.3">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/03_Transmission/</code>.</p>


<h3 data-number="8.5.4">How to do it…</h3>
<p>This is the most complex extension discussed in this chapter, requiring changes to the C++ code to handle the complexities of transparency rendering. In addition to updating the C++ rendering code, we need to implement a specular BTDF in the GLSL shader code and incorporate the blending of two layers to accurately represent a thin material.</p>
<p>Let’s start with C++ changes.</p>
<ol>
<li>First, we should load a corresponding <code>.gltf</code> sample model in <code>Chapter07/03_Transmission/src/main.cpp</code>:</li>
</ol>
<div><pre><code>  GLTFContext gltf(app);
  loadGLTF(gltf, “deps/src/glTF-Sample-Assets/Models/
      TransmissionRoughnessTest/glTF/
      TransmissionRoughnessTest.gltf”,
    “deps/src/glTF-Sample-Assets/Models/
      TransmissionRoughnessTest/glTF/”);</code></pre>
</div>
<ol>
<li>The parameters parsing is in <code>shared/UtilsGLTF.cpp</code> and quite simple:</li>
</ol>
<div><pre><code>  loadMaterialTexture(mtlDescriptor, aiTextureType_TRANSMISSION,
    assetFolder, mat.transmissionTexture, ctx, true, 0);
  …
  bool useTransmission = !mat.transmissionTexture.empty();
  ai_real transmissionFactor = 0.0f;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_TRANSMISSION_FACTOR,
      transmissionFactor) == AI_SUCCESS) {
    res.clearcoatTransmissionThickness.z = transmissionFactor;
    useTransmission = true;
  }
  if (useTransmission) {
    res.materialTypeFlags |= MaterialType_Transmission;
    useVolumetric = true;
  }
  assignUVandSampler(samplers, mtlDescriptor,
    aiTextureType_TRANSMISSION, res.transmissionTextureUV,
    res.transmissionTextureSampler, 0);</code></pre>
</div>
<p>Significant changes have been made to the rendering function <code>renderGLTF()</code>. We touched on some of these in the first recipe <em>Introduction to glTF PBR extensions</em>. Now, let’s take a closer look at these changes. To effectively render transparent and transmission surfaces, we need to follow these steps:</p>
<ol>
<li><p>Prepare lists of completely opaque, transmission, and transparent nodes, because these should be rendered in a particular order: opaque nodes first, then transmission, and then transparent.</p>
<blockquote>
<p>Keep in mind that rendering transmission nodes doesn’t automatically make them transparent! Instead, we need to use the result from rendering opaque nodes. To do this, we must create a copy of the rendered surface and use it as input for the transmission nodes.</p>
</blockquote></li>
<li>Pre-allocate an offscreen texture to store the rendered opaque nodes:</li>
</ol>
<div><pre><code>  if (gltf.offscreenTex[0].empty() || isSizeChanged) {
    const lvk::Dimensions res =
      ctx-&gt;getDimensions(ctx-&gt;getCurrentSwapchainTexture());
    for (Holder&lt;TextureHandle&gt;&amp; holder : gltf.offscreenTex) {
      holder = ctx-&gt;createTexture({
          .type         = lvk::TextureType_2D,
          .format       = ctx-&gt;getSwapchainFormat(),
          .dimensions   = {res.width, res.height},
          .usage        = lvk::TextureUsageBits_Attachment |
                          lvk::TextureUsageBits_Sampled,
          .numMipLevels = lvk::calcNumMipLevels(res.width,
                                                res.height),
          .debugName    = “offscreenTex” });
    }
  }</code></pre>
</div>
<ol>
<li>Create a screen copy when necessary and pass its handle as <code>transmissionFramebuffer:</code></li>
</ol>
<div><pre><code>  const bool screenCopy = gltf.isScreenCopyRequired();
  if (screenCopy) {
    buf.cmdCopyImage(
      gltf.offscreenTex[gltf.currentOffscreenTex],],
      ctx-&gt;getCurrentSwapchainTexture(),
      ctx-&gt;getDimensions(ctx-&gt;getCurrentSwapchainTexture()));
    buf.cmdGenerateMipmap(
      gltf.offscreenTex[gltf.currentOffscreenTex]);
    pushConstants.transmissionFramebuffer =
      gltf.offscreenTex[gltf.currentOffscreenTex].index();
    buf.cmdPushConstants(pushConstants);
  }</code></pre>
</div>
<ol>
<li>Now we can render transmission nodes using the screen copy as input. It’s important to note that we’re not using alpha blending for this pass. The nodes are still rendered as opaque, and we simulate transparency by sampling the screen copy. We also specify a texture dependency for LightweightVK here to ensure the correct Vulkan barriers are applied:</li>
</ol>
<div><pre><code>  buf.cmdBeginRendering(renderPass, framebuffer, { .textures = {
      lvk::TextureHandle(
        gltf.offscreenTex[gltf.currentOffscreenTex]) } });
  buf.cmdBindVertexBuffer(0, gltf.vertexBuffer, 0);
  buf.cmdBindIndexBuffer(
    gltf.indexBuffer, lvk::IndexFormat_UI32);
  buf.cmdBindDepthState({ .compareOp = lvk::CompareOp_Less,
                          .isDepthWriteEnabled = true });
  buf.cmdBindRenderPipeline(gltf.pipelineSolid);
  for (uint32_t transformId : gltf.transmissionNodes) {
    const GLTFTransforms transform =
      gltf.transforms[transformId];
    const GLTFMesh submesh =
      gltf.meshesStorage[transform.meshRef];
    buf.cmdDrawIndexed(submesh.indexCount, 1,
      submesh.indexOffset, submesh.vertexOffset, transformId);
  }</code></pre>
</div>
<ol>
<li>The next step is to render all transparent nodes in back-to-front order. We did not change push constants and these transparent nodes use the same offscreen texture as input:</li>
</ol>
<div><pre><code>  buf.cmdBindRenderPipeline(gltf.pipelineTransparent);
  for (uint32_t transformId : gltf.transparentNodes) {
    const GLTFTransforms transform =
      gltf.transforms[transformId];
     
    const GLTFMesh submesh =
      gltf.meshesStorage[transform.meshRef];
    buf.cmdDrawIndexed(submesh.indexCount, 1,
      submesh.indexOffset, submesh.vertexOffset, transformId);
  }}</code></pre>
</div>
<p>This is it for the C++ changes. Let’s take a look at the GLSL shader changes now.</p>
<ol>
<li>First, we introduce a utility function in <code>data/shaders/gltf/inputs.frag</code> to read material inputs. The transmission factor is stored in the <code>r</code> channel of the texture:</li>
</ol>
<div><pre><code>float getTransmissionFactor(InputAttributes tc,
  MetallicRoughnessDataGPU mat) {
  return mat.clearcoatTransmissionThickness.z
         textureBindless2D(mat.transmissionTexture,
           mat.transmissionTextureSampler,
           tc.uv[mat.transmissionTextureUV]
         ).r;
}</code></pre>
</div>
<ol>
<li>Then, we populate inputs in <code>data/shaders/gltf/main.frag</code> if the transmission extension is enabled for this material:</li>
</ol>
<div><pre><code>  if (isTransmission) {
    pbrInputs.transmissionFactor =
      getTransmissionFactor(tc, mat);
  }</code></pre>
</div>
<ol>
<li>We calculate the transmission contribution. The volumetric part will be covered in detail in our next recipe for the <code>KHR_materials_volume</code> extension <em>Implementing the volume extension</em>. In a pure transmission implementation without the volume extension, the transmission part would be similar to GGX/Lambertian, but instead of using the reflection vector, we use the dot product <code>NdotV</code>. Implementing just the transmission extension without volume support is not practical, as the volume extension offers greater flexibility to represent effects like refraction, absorption, or scattering without adding excessive complexity on top of transmission:</li>
</ol>
<div><pre><code>  vec3 transmission = vec3(0,0,0);
  if (isTransmission) {
    transmission += getIBLVolumeRefraction(
      pbrInputs.n,
      pbrInputs.v,
      pbrInputs.perceptualRoughness,
      pbrInputs.diffuseColor,
      pbrInputs.reflectance0,
      pbrInputs.reflectance90,
      worldPos, getModel(), getViewProjection(),
      pbrInputs.ior,
      pbrInputs.thickness,
      pbrInputs.attenuation.rgb,
      pbrInputs.attenuation.a);
  }</code></pre>
</div>
<ol>
<li>Finally, we add the calculated transmission value to the diffuse contribution scaled by <code>transmissionFactor</code>:</li>
</ol>
<div><pre><code>  if (isTransmission) {
    diffuseColor = mix(diffuseColor, transmission,
                       pbrInputs.transmissionFactor);
  }</code></pre>
</div>
<p>The resulting rendered 3D model should look as in the following screenshot:</p>
<figure>
<img alt="Figure 7.4: glTF PBR KHR_materials_transmission example" height="1590" src="img/file54.png" width="2726"/><figcaption aria-hidden="true">Figure 7.4: glTF PBR KHR_materials_transmission example</figcaption>
</figure>


<h3 data-number="8.5.5">There is more…</h3>
<p>Rendering transparent objects efficiently and accurately in real-time is challenging, particularly when dealing with overlapping transparent polygons. Issues such as order-dependent transparency and the need for separate blending operations for absorption and reflections add to the complexity. We will address some of these issues in <em>Chapter 11, Advanced Rendering Techniques and Optimizations</em>.</p>
<p>The Khronos extensions repository provides comprehensive reference materials for the transmission extension: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_transmission/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_transmission/README.md</a>.</p>



<h2 data-number="8.6">Implementing the KHR_materials_volume extension</h2>
<p>The <code>KHR_materials_volume</code> extension adds volumetric effects to the glTF 2.0 ecosystem, enabling the creation of materials with depth and internal structure. It’s crucial for accurately rendering materials such as smoke, fog, clouds, and translucent objects.</p>
<p>Volumetric effects are different from surface-based materials. While surface-based materials focus on how light interacts with a surface, volumetric materials describe how light moves through a medium. This includes simulating how light scatters and gets absorbed as it passes through the volume.</p>
<p>To create realistic volumetric effects, the <code>KHR_materials_volume</code> extension needs to work alongside other extensions that define light interactions with the material’s surface. The <code>KHR_materials_transmission</code> extension is key here, as it lets light rays pass through the surface and enter the volume. Once inside, the light’s interaction with the material is no longer affected by the surface properties. Instead, the light travels through the volume, undergoing refraction and attenuation. When it exits the volume, its direction is determined by the angle at which it leaves the volume boundary.</p>
<p>Let’s explore how to add this extension to our glTF renderer.</p>

<h3 data-number="8.6.1">Volumetric parameters</h3>
<p>The <code>KHR_materials_volume</code> extension defines the following parameters to describe a volumetric material:</p>
<ul>
<li><strong>thicknessFactor</strong>: A scalar floating-point value that represents the base thickness of the volume. This value is multiplied by the thickness texture value (if available) to determine the final thickness at any point on the surface.</li>
<li><strong>attenuationDistance</strong>: A floating-point value that indicates the distance over which the volume’s density decreases. This parameter controls how quickly the volume’s opacity fades as light passes through it.</li>
<li><strong>attenuationColo</strong><em>r</em>: A color value representing the base color of the volume’s attenuation. This color influences how light is absorbed as it travels through the volume.</li>
<li><strong>thicknessTexture</strong>: An optional texture that adds extra detail about the volume’s thickness. The values in the texture are multiplied by the <code>thicknessFactor</code> to determine the final thickness at each point on the surface.</li>
</ul>
<p>Here’s how these parameters work together:</p>
<ul>
<li><strong>Thickness</strong>: The <code>thicknessFactor</code> and <code>thicknessTexture</code> are multiplied to define the volume’s depth. A higher thickness value results in a thicker volume.</li>
<li><strong>Attenuation</strong>: The <code>attenuationDistance</code> and <code>attenuationColor</code> control how light is absorbed as it travels through the volume. A smaller value of <code>attenuationDistance</code> leads to quicker attenuation. The value of <code>attenuationColor</code> determines the color change due to absorption.</li>
</ul>
<blockquote>
<p>The <code>KHR_materials_volume</code> extension currently assumes a homogeneous volume, where the material properties are uniform throughout. Future extensions may add support for heterogeneous volumes with varying properties.</p>
</blockquote>


<h3 data-number="8.6.2">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/04_Volume/</code>. Please review the previous recipe <em>Implementing the transmission extension</em>, where we covered the transmission and volumetric C++ rendering flow.</p>


<h3 data-number="8.6.3">How to do it…</h3>
<p>This extension requires only a handful of changes across our existing C++ and GLSL shader code. This extension requires <code>KHR_materials_transmission</code> support and works only in conjunction with it.</p>
<p>Let’s explore how to create advanced volumetric effects such as refraction, absorption, or scattering, starting with the C++.++. code</p>
<ol>
<li>First, we load a corresponding <code>.gltf</code> model in <code>Chapter07/04_Volume/main.cpp</code>:</li>
</ol>
<div><pre><code>  GLTFContext gltf(app);
  loadGLTF(gltf, “deps/src/glTF-Sample-Assets/Models/
    DragonAttenuation/glTF/DragonAttenuation.gltf”,
   “deps/src/glTF-Sample-Assets/Models/DragonAttenuation/glTF/”);</code></pre>
</div>
<ol>
<li>Parsing the volume parameters using Assimp in <code>shared/UtilsGLTF.cpp</code>:</li>
</ol>
<div><pre><code>  …
  loadMaterialTexture(mtlDescriptor, aiTextureType_TRANSMISSION,
    assetFolder, mat.thicknessTexture, ctx, true, 1);
  bool useVolume = !mat.thicknessTexture.empty();
  ai_real thicknessFactor = 0.0f;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_VOLUME_THICKNESS_FACTOR,
      thicknessFactor) == AI_SUCCESS) {
    res.clearcoatTransmissionThickness.w = thicknessFactor;
    useVolume = true;
  }
  ai_real attenuationDistance = 0.0f;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_VOLUME_ATTENUATION_DISTANCE,
      attenuationDistance) == AI_SUCCESS) {
    res.attenuation.w = attenuationDistance;
    useVolume =      true;
  }
  aiColor4D volumeAttnuationColorvolumeAttnuationColore;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_VOLUME_ATTENUATION_COLOR,
      volumeAttnuationColorvolumeAttnuationColore)==AI_SUCCESS) {
    res.attenuation.x =
      volumeAttnuationColorvolumeAttnuationColore.r;
    res.attenuation.y =
      volumeAttnuationColorvolumeAttnuationColore.g;
    res.attenuation.z =
      volumeAttnuationColorvolumeAttnuationColore.b;
    useVolume = true;
  }
  if (useVolume) {
    res.materialTypeFlags |= MaterialType_Transmission |
                             MaterialType_Volume;
    useVolumetric = true;
  }
  assignUVandSampler(samplers, mtlDescriptor,
    aiTextureType_TRANSMISSION, res.thicknessTextureUV,
    res.thicknessTextureSampler, 1);
  …</code></pre>
</div>
<p>Most of the magic is hidden in GLSL shaders. Let’s step inside <code>data/shaders/gltf/PBR.sp</code> and check important helper functions.</p>
<ol>
<li>The function <code>getVolumeTransmissionRay()</code> calculates the direction of refracted light <code>refractionVector</code> and uses the <code>modelScale</code> factor to get an actual lookup vector inside a volume. Note that the <code>thickness</code> factor is designed to be normalized to the actual scale of the mesh.</li>
</ol>
<div><pre><code>vec3 getVolumeTransmissionRay(
  vec3 n, vec3 v, float thickness, float ior, mat4 modelMatrix)
{
  vec3 refractionVector = refract(-v, n, 1.0 / ior);</code></pre>
</div>
<ol>
<li>Compute rotation-independent scaling of the model matrix. The <code>thickness</code> factor is specified in local space:</li>
</ol>
<div><pre><code>  vec3 modelScale = vec3(length(modelMatrix[0].xyz),
                         length(modelMatrix[1].xyz),
                         length(modelMatrix[2].xyz));
  return
    normalize(refractionVector) * thickness * modelScale.xyz;
}</code></pre>
</div>
<p>Another helper function is <code>getIBLVolumeRefraction()</code>. This function has several important steps:</p>
<ol>
<li>The first step is to get a transmission ray <code>transmissionRay</code> and calculate the final refraction position:</li>
</ol>
<div><pre><code>vec3 getIBLVolumeRefraction(vec3 n, vec3 v,
  float perceptualRoughness, vec3 baseColor, vec3 f0, vec3 f90,
  vec3 position, mat4 modelMatrix, mat4 viewProjMatrix,
  float ior, float thickness, vec3 attenuationColor,
  float attenuationDistance)
{
  vec3 transmissionRay =
    getVolumeTransmissionRay(n, v, thickness, ior, modelMatrix);
  vec3 refractedRayExit = position + transmissionRay;</code></pre>
</div>
<ol>
<li>We project the refracted vector onto the framebuffer and map it to normalized device coordinates to sample the color of the pixel where the refracted ray hits the framebuffer. The refracted framebuffer coordinates should be transformed from the <code>-1...+1</code> range into <code>0...1</code> and then flipped vertically:</li>
</ol>
<div><pre><code>  vec4 ndcPos = viewProjMatrix * vec4(refractedRayExit, 1.0);
  vec2 refractionCoords = ndcPos.xy / ndcPos.w;
  refractionCoords += 1.0;
  refractionCoords /= 2.0;
  refractionCoords.y = 1.0 - refractionCoords.y;
  vec3 transmittedLight = getTransmissionSample(
    refractionCoords, perceptualRoughness, ior);</code></pre>
</div>
<ol>
<li>After that, we apply volume attenuation and sample GGX BRDF to get the specular component and modulate it by <code>baseColor</code> and <code>attenuatedColor</code>:</li>
</ol>
<div><pre><code>  vec3 attenuatedColor = applyVolumeAttenuation(
    transmittedLight,
    length(transmissionRay), attenuationColor,
    attenuationDistance);
  float NdotV = clampedDot(n, v);
  vec2 brdfSamplePoint = clamp(vec2(NdotV, perceptualRoughness),
    vec2(0.0, 0.0), vec2(1.0, 1.0));
  vec2 brdf = sampleBRDF_LUT(brdfSamplePoint,
    getEnvironmentMap(getEnvironmentId())).rg;
  vec3 specularColor = f0 * brdf.x + f90 * brdf.y;
  return (1.0 - specularColor) * attenuatedColor * baseColor;
}</code></pre>
</div>
<ol>
<li>Here’s the function <code>getTransmissionSample()</code>. We use a copy of the framebuffer as we explained in the previous recipe <em>Implementing the transmission extension</em>:</li>
</ol>
<div><pre><code>vec3 getTransmissionSample(
  vec2 fragCoord, float roughness, float ior)
{
  const ivec2 size =
    textureBindlessSize2D(perFrame.transmissionFramebuffer);
  const vec2 uv = fragCoord;
  float framebufferLod =
    log2(float(size.x)) * applyIorToRoughness(roughness, ior);
  vec3 transmittedLight = textureBindless2DLod(
    perFrame.transmissionFramebuffer,
    perFrame.transmissionFramebufferSampler,
    uv, framebufferLod).rgb;
  return transmittedLight;
}</code></pre>
</div>
<ol>
<li>The helper function <code>applyVolumeAttenuation()</code> looks as follows. The attenuation distance of <code>0</code> means the transmitted color is not attenuated at all. Light attenuation is computed using Beer-Lambert law <a href="https://en.wikipedia.org/wiki/Beer%E2%80%93Lambert_law">https://en.wikipedia.org/wiki/Beer%E2%80%93Lambert_law</a>:</li>
</ol>
<div><pre><code>vec3 applyVolumeAttenuation(vec3 radiance,
  float transmissionDistance, vec3 attenuationColor,
  float attenuationDistance)
{
  if (attenuationDistance == 0.0) return radiance;
  vec3 attenuationCoefficient =
    -log(attenuationColor) / attenuationDistance;
  vec3 transmittance =
    exp(-attenuationCoefficient * transmissionDistance);
  return transmittance * radiance;
}</code></pre>
</div>
<ol>
<li>Now we can go back to <code>data/shaders/gltf/main.frag</code> and use <code>getIBLVolumeRefraction()</code>, together with other helper functions as described in the previous recipe <em>Implementing the transmission extension</em>:</li>
</ol>
<div><pre><code>  …
  vec3 transmission = vec3(0,0,0);
  if (isTransmission) {
    transmission += getIBLVolumeRefraction(
      pbrInputs.n, pbrInputs.v,
      pbrInputs.perceptualRoughness,
      pbrInputs.diffuseColor, pbrInputs.reflectance0,
      pbrInputs.reflectance90,
      worldPos, getModel(), getViewProjection(),
      pbrInputs.ior, pbrInputs.thickness,
      pbrInputs.attenuation.rgb, pbrInputs.attenuation.w);
  }</code></pre>
</div>
<p>The resulting demo application should render a translucent dragon, similar to the screenshot below. You can move the camera around the dragon to observe how light interacts with the volume from different angles. This will allow you to see how the light passes through the medium and interacts with the volumetric material.</p>
<figure>
<img height="1587" src="img/file55.png" width="2721"/>
</figure>
Figure 7.5: glTF PBR KHR_materials_volume example
<p>After we explored a range of complex PBR glTF extensions, it is time to switch gears. Let’s take a look at something a bit more straightforward: implementing the <strong>Index-of-Refraction</strong> extension. This simpler extension is a great way to continue building your understanding while giving you a break from the more complex topics we have covered.</p>


<h3 data-number="8.6.4">There is more…</h3>
<p>An alternative way to implement this extension could involve volume ray-casting or ray-tracing. We leave that as an exercise for our readers.</p>
<p>The Khronos extensions repository provides comprehensive reference materials for this extension: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_volume/README.md#overview">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_volume/README.md#overview</a>.</p>



<h2 data-number="8.7">Implementing the KHR_materials_ior extension</h2>
<p>The <code>KHR_materials_ior</code> extension for glTF 2.0 adds the concept of <strong>Index-of-Refraction</strong> (<strong>IOR</strong>) to materials, allowing for more accurate and realistic simulations of transparent objects. IOR is a key material property that dictates how light bends when it passes through a substance <a href="https://en.wikipedia.org/wiki/Refractive_index">https://en.wikipedia.org/wiki/Refractive_index</a>.</p>
<p>The <strong>IOR</strong> is a dimensionless number that shows the ratio of the speed of light in a vacuum to its speed in a particular medium. Different materials have different IOR values, which influence how light bends when it enters or exits the material. A higher IOR means more refraction. For instance, the IOR of air is nearly <code>1</code>, water has an IOR of about <code>1.33</code>, and glass has an IOR of around <code>1.5</code>.</p>

<h3 data-number="8.7.1">IOR parameters</h3>
<p>The <code>KHR_materials_ior</code> extension adds a single property to the glTF material definition:</p>
<p><em>ior</em>: A floating-point value representing the index-of-refraction of the material.</p>
<p>This value is used in conjunction with the <code>KHR_materials_transmission</code> extension to calculate the refraction direction of light rays when passing through the material.</p>


<h3 data-number="8.7.2">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/05_IOR/</code>. Check out the recipe <em>Implementing the transmission extension</em> to recap how <code>KHR_materials_transmission</code> is implemented.</p>


<h3 data-number="8.7.3">How to do it…</h3>
<p>This extension requires only a handful of changes across C++ and GLSL shader code. Let’s start with C++.</p>
<ol>
<li>In <code>Chapter07/05_IOR/main.cpp</code>, load a corresponding <code>.gltf</code> model:</li>
</ol>
<div><pre><code>  GLTFContext gltf(app);
  loadGLTF(gltf,
    “deps/src/glTF-Sample-Assets/Models/
      MosquitoInAmber/glTF/MosquitoInAmber.gltf”,
    “deps/src/glTF-Sample-Assets/Models/MosquitoInAmber/glTF/”);</code></pre>
</div>
<ol>
<li>Here is the code in <code>shared/UtilsGLTF.cpp</code> for parsing the IOR material parameter with Assimp. You will notice that we don’t set any material flag, it’s not needed. IOR is just a value and does not alter the functionality of shaders.</li>
</ol>
<div><pre><code>ai_real ior;
if (mtlDescriptor-&gt;Get(AI_MATKEY_REFRACTI, ior) == AI_SUCCESS) {
  res.ior = ior;
}</code></pre>
</div>
<p>Here goes the GLSL shader code. We need to modify a couple lines:</p>
<ol>
<li>The first line is in the PBR module <code>data/shaders/gltf/PBR.sp</code> in the function <code>calculatePBRInputsMetallicRoughness()</code>. The default index of refraction value, <code>ior = 1.5</code>, results in the <code>f0</code> term being calculated as <code>0.04</code>:</li>
</ol>
<div><pre><code>PBRInfo calculatePBRInputsMetallicRoughness(InputAttributes tc,
  vec4 albedo, vec4 mrSample, MetallicRoughnessDataGPU mat) {
  PBRInfo pbrInputs;
  …
  vec3 f0 = isSpecularGlossiness ?
    getSpecularFactor(mat) * mrSample.rgb :
    vec3(pow((pbrInputs.ior - 1)/( pbrInputs.ior + 1), 2));</code></pre>
</div>
<p>The second line is in <code>data/shaders/gltf/main.frag</code> and modifies the clearcoat reflectance value:</p>
<div><pre><code>  if (isClearCoat) {
    …
    pbrInputs.clearcoatF0 = vec3(
      pow((pbrInputs.ior - 1.0) / (pbrInputs.ior + 1.0), 2.0));
    …
  }</code></pre>
</div>
<p>That’s it! The application should now render a mosquito encased in a piece of amber, as shown in the following screenshot:</p>
<figure>
<img alt="Figure 7.6: glTF PBR KHR_materials_ior example" height="1582" src="img/file56.png" width="2733"/><figcaption aria-hidden="true">Figure 7.6: glTF PBR KHR_materials_ior example</figcaption>
</figure>


<h3 data-number="8.7.4">There is more…</h3>
<p>The official extension specification includes a normative section that explains how this glTF extension <code>KHR_material_ior</code> interacts with other extensions: <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_ior/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_ior/README.md</a>.</p>



<h2 data-number="8.8">Implementing the KHR_materials_specular extension</h2>
<p>In the previous chapter, we discussed the <strong>Specular-Glossiness</strong> PBR model. One of its main issues is the lack of compatibility with most other extensions. This is because it introduces non-physically based material properties, including an unclear distinction between dielectrics and metals in specular-glossiness mode, which makes it impossible to combine with the metallic-roughness model or other extension properties.</p>
<p>As an alternative, Khronos proposed the <code>KHR_materials_specular</code> extension, which addresses these issues and offers the functionality of <code>KHR_materials_pbrSpecularGlossiness</code> without compromising the physical accuracy of the <strong>Metallic-Roughness</strong> PBR model. This makes it compatible with most glTF PBR extensions. At the time of writing, the <code>KHR_materials_specular</code> extension is only incompatible with the <code>KHR_materials_pbrSpecularGlossiness</code> and <code>KHR_materials_unlit</code> extensions.</p>
<p>The <code>KHR_materials_specular</code> extension allows for more precise control over specular reflections in glTF materials. While the core glTF specification includes a basic specular BRDF, this extension introduces additional parameters to better fine-tune the appearance of specular highlights.</p>

<h3 data-number="8.8.1">Specular parameters</h3>
<p>The <code>KHR_materials_specular</code> extension introduces several parameters to enhance specular reflections:</p>
<ul>
<li><strong>specularFactor/specularTexture</strong>: A scalar value that scales the overall intensity of the specular reflection.</li>
<li><strong>specularColorFactor/specularColorTexture</strong>: A color value that modifies the color of the specular reflection.</li>
</ul>


<h3 data-number="8.8.2">Specular-Glossiness conversion</h3>
<p>You can convert <strong>Specular-Glossiness</strong> materials to the <strong>Metallic-Roughness</strong> workflow using the <code>KHR_materials_ior</code> extension described in the previous recipe <em>Implementing the index-of-refraction extension</em>. By setting the <code>IOR</code> parameter to <code>0</code>, the material is treated as a dielectric with the maximum specular reflection. The <code>IOR</code> parameter controls the upper limit of the specular reflection’s strength, and setting it to <code>0</code> maximizes this strength, allowing full control over specular reflection through the <code>specularColorFactor</code>. This method eliminates the need to classify materials as either dielectric or metallic. It’s important to note that materials using the <code>KHR_materials_volume</code> extension are incompatible with this conversion due to their non-zero <code>IOR</code> value. For new materials, it’s often better to use the <strong>Metallic-Roughness</strong> model directly.</p>


<h3 data-number="8.8.3">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/06_Specular/</code>. Reread two previous recipes <em>Implementing the index-of-refraction extension</em> and <em>Implementing the volume extension</em> as this extension interacts with them.</p>


<h3 data-number="8.8.4">How to do it…</h3>
<p>This extension doesn’t require any major changes to the C++ code, aside from reading the additional material properties via Assimp:</p>
<ol>
<li>Let’s load a new <code>.gltf</code> model in <code>Chapter07/06_Specular/src/main.cpp</code>:</li>
</ol>
<div><pre><code>  VulkanApp app({
      .initialCameraPos    = vec3(0.0f, -0.5f, -1.0f),
      .initialCameraTarget = vec3(0.0f, -1.0f, 0.0f),
  });
  GLTFContext gltf(app);
  loadGLTF(gltf, “deps/src/glTF-Sample-Assets/Models/
    SpecularSilkPouf/glTF/SpecularSilkPouf.gltf”,
    “deps/src/glTF-Sample-Assets/Models/SpecularSilkPouf/glTF/”);</code></pre>
</div>
<ol>
<li>To make this example more interesting, we added rotation to our 3D model:</li>
</ol>
<div><pre><code>  const bool rotateModel = true;
  const mat4 t = glm::translate(mat4(1.0f), vec3(0, -1, 0));
  app.run([&amp;](uint32_t width, uint32_t height,
    float aspectRatio, float deltaSeconds)
  {
    const mat4 m = t * glm::rotate(mat4(1.0f),
      rotateModel ? (float)glfwGetTime() : 0.0f,
      vec3(0.0f, 1.0f, 0.0f));
    const mat4 p =
      glm::perspective(45.0f, aspectRatio, 0.01f, 100.0f);
    renderGLTF(gltf, m, app.camera_.getViewMatrix(), p);
  });</code></pre>
</div>
<ol>
<li>Now, let’s load material properties in <code>shared/UtilsGLTF.cpp</code>:</li>
</ol>
<div><pre><code>  loadMaterialTexture(mtlDescriptor, aiTextureType_SPECULAR,
    assetFolder, mat.specularTexture, ctx, true, 0);
  loadMaterialTexture(mtlDescriptor, aiTextureType_SPECULAR,
    assetFolder, mat.specularColorTexture, ctx, true, 1);…
  bool useSpecular = !mat.specularColorTexture.empty() ||
                     !mat.specularTexture.empty();
  ai_real specularFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_SPECULAR_FACTOR,
      specularFactor) == AI_SUCCESS) {
    res.specularFactors.w = specularFactor;
    useSpecular           = true;
  }
  assignUVandSampler(samplers, mtlDescriptor,
    aiTextureType_SPECULAR, res.specularTextureUV,
    res.specularTextureSampler, 0);
  aiColor4D specularColorFactor;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_COLOR_SPECULAR,
      specularColorFactor) == AI_SUCCESS) {
    res.specularFactors = vec4(specularColorFactor.r,
                               specularColorFactor.g,
                               specularColorFactor.b,
                               res.specularFactors.w);
    useSpecular = true;
  }
  assignUVandSampler(samplers, mtlDescriptor,
    aiTextureType_SPECULAR, res.specularColorTextureUV,
    res.specularColorTextureSampler, 1);
  if (useSpecular)
    res.materialTypeFlags |= MaterialType_Specular;
}</code></pre>
</div>
<p>GLSL shader changes are a bit more complex. The <code>specularColor</code> parameter introduces color variations into the specular reflection. It is integrated into the Fresnel term, influencing the specular reflectance at different viewing angles. At normal incidence, the specular color directly scales the base reflectance (<code>F0</code>), while at grazing angles, the reflectance approaches <code>1.0</code> regardless of the specular color. To maintain energy conservation, the maximum component of the specular color is used to calculate the scaling factor for the Fresnel term, preventing excessive energy in the specular reflection.</p>
<ol>
<li>First, we introduce some utility functions in <code>data/shaders/gltf/inputs.frag</code>:</li>
</ol>
<div><pre><code>vec3 getSpecularColorFactor(InputAttributes tc,
  MetallicRoughnessDataGPU mat) {
  return mat.specularFactors.rgb *
    textureBindless2D(mat.specularColorTexture,
                      mat.specularColorTextureSampler,
                      tc.uv[mat.specularColorTextureUV]).rgb;
}
float getSpecularFactor(InputAttributes tc,
  MetallicRoughnessDataGPU mat) {
  return mat.specularFactors.a *
    textureBindless2D(mat.specularTexture,
                      mat.specularTextureSampler,
                      tc.uv[mat.specularTextureUV]).a;
}</code></pre>
</div>
<ol>
<li>We add a new field <code>specularWeight</code> to the <code>PBRInfo</code> structure in <code>data/shaders/gltf/PBR.sp</code>.</li>
</ol>
<div><pre><code>struct PBRInfo {
  …
  float specularWeight;
};</code></pre>
</div>
<ol>
<li>We modify the method for obtaining the <code>F0</code> reflectance and populate the <code>specularWeigthspecularWeigthh</code> field in the <code>calculatePBRInputsMetallicRoughness()</code> function:</li>
</ol>
<div><pre><code>PBRInfo calculatePBRInputsMetallicRoughness(InputAttributes tc,
  vec4 albedo, vec4 mrSample, MetallicRoughnessDataGPU mat) { 
  …
  if (isSpecular) {
    vec3 dielectricSpecularF0 =
      min(f0 *       getSpecularColorFactor(tc, mat), vec3(1.0));
    f0 = mix(dielectricSpecularF0, pbrInputs.baseColor.rgb,
             metallic);
    pbrInputs.specularWeight = getSpecularFactor(tc, mat);
  }
  …
  vec3 specularColor = isSpecularGlossiness ? f0 :
    mix(f0, pbrInputs.baseColor.rgb, metallic);
  float reflectance = max(
    max(specularColor.r, specularColor.g), specularColor.b);
  …</code></pre>
</div>
<ol>
<li>Now we can use these parameters in <code>data/shaders/gltf/main.frag</code> to calculate the specular and diffuse components of the IBL contribution:</li>
</ol>
<div><pre><code>  vec3 specularColor = getIBLRadianceContributionGGX(
    pbrInputs, pbrInputs.specularWeight, envMap);
  vec3 diffuseColor = getIBLRadianceLambertian(pbrInputs.NdotV,
    n, pbrInputs.perceptualRoughness, pbrInputs.diffuseColor,
    pbrInputs.reflectance0, pbrInputs.specularWeight, envMap);</code></pre>
</div>
<ol>
<li>Here is how the specular contribution is calculated. Please note that we multiply by <code>specularWeight</code> at the end of the function <code>getIBLRadianceContributionGGX()</code>:</li>
</ol>
<div><pre><code>vec3 getIBLRadianceContributionGGX(PBRInfo pbrInputs,
  float specularWeight, EnvironmentMapDataGPU envMap) {
  vec3 n = pbrInputs.n;
  vec3 v = pbrInputs.v;
  vec3 reflection = normalize(reflect(-v, n));
  float mipCount = float(sampleEnvMapQueryLevels(envMap));
  float lod = pbrInputs.perceptualRoughness * (mipCount - 1);
  vec2 brdfSamplePoint = clamp(
    vec2(pbrInputs.NdotV, pbrInputs.perceptualRoughness),
    vec2(0.0, 0.0), vec2(1.0, 1.0));
  vec3 brdf = sampleBRDF_LUT(brdfSamplePoint, envMap).rgb;
  vec3 specularLight =
    sampleEnvMapLod(reflection.xyz, lod, envMap).rgb;
  vec3 Fr = max(vec3(1.0 - pbrInputs.perceptualRoughness),
                pbrInputs.reflectance0) - pbrInputs.reflectance0;
  vec3 k_S =
    pbrInputs.reflectance0 + Fr * pow(1.0-pbrInputs.NdotV, 5.0);
  vec3 FssEss = k_S * brdf.x + brdf.y;
  return specularWeight * specularLight * FssEss;
}</code></pre>
</div>
<ol>
<li>The diffuse contribution looks like this. Note that we scale the Fresnel term and replace it with a <code>vec3</code> RGB value to incorporate the <code>specularColor</code> contribution into <code>F0</code>:</li>
</ol>
<div><pre><code>vec3 getIBLRadianceLambertian(float NdotV, vec3 n,
  float roughness, vec3 diffuseColor, vec3 F0,
  float specularWeight, EnvironmentMapDataGPU envMap) {
  vec2 brdfSamplePoint =
    clamp(vec2(NdotV, roughness), vec2(0., 0.), vec2(1., 1.));
  vec2 f_ab = sampleBRDF_LUT(brdfSamplePoint, envMap).rg;
  vec3 irradiance = sampleEnvMapIrradiance(n.xyz, envMap).rgb;
  vec3 Fr = max(vec3(1.0 - roughness), F0) - F0;
  vec3 k_S = F0 + Fr * pow(1.0 - NdotV, 5.0);
  vec3 FssEss = specularWeight * k_S * f_ab.x + f_ab.y;
  float Ems = (1.0 - (f_ab.x + f_ab.y));
  vec3 F_avg = specularWeight * (F0 + (1.0 - F0) / 21.0);
  vec3 FmsEms = Ems * FssEss * F_avg / (1.0 - F_avg * Ems);
  vec3 k_D = diffuseColor * (1.0 - FssEss + FmsEms);
  return (FmsEms + k_D) * irradiance;
}</code></pre>
</div>
<p>Those are all the changes required to implement the <code>KHR_materials_specular</code> extension in our glTF renderer. The demo application should render a rotating torus as in the following screenshot:</p>
<figure>
<img alt="Figure 7.7: glTF PBR KHR_materials_specular example" height="1576" src="img/file57.png" width="2719"/><figcaption aria-hidden="true">Figure 7.7: glTF PBR KHR_materials_specular example</figcaption>
</figure>
<p>For further details on the motivation behind this approach, please refer to the Khronos specification <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_specular/README.md#implementation">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_specular/README.md#implementation</a>.</p>


<h3 data-number="8.8.5">There is more…</h3>
<p>The Khronos extension page <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_specular/README.md">https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_specular/README.md</a> provides comprehensive information on various aspects of the extension. It includes detailed explanations of the BRDF and additional insights into converting between different PBR models.</p>



<h2 data-number="8.9">Implementing the KHR_materials_emissive_strength extension</h2>
<p>The metallic-roughness core model supports light emission, but before the introduction of the <code>KHR_materials_emissive_strength</code> extension, it was difficult to control the intensity of a material’s light emission. This made it challenging to create realistic glowing objects or materials that function as light sources in a scene.</p>
<p>The <code>KHR_materials_emissive_strength</code> extension overcomes this limitation by introducing a new property called <em>emissiveStrength</em>. This property allows for precise control over the intensity of a material’s emitted light. With values ranging from <code>0.0</code> for no emission to higher values for increased intensity, artists and designers gain more control over the lighting in their scenes.</p>

<h3 data-number="8.9.1">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/07_EmissiveStrength/</code>.</p>


<h3 data-number="8.9.2">How to do it…</h3>
<p>This extension is one of the simplest to implement. All it requires is loading an intensity value and applying it to the existing emissive value. Essentially, you only need to take the <code>emissiveStrength</code> property from Assimp, which determines how intense the material’s emitted light should be, and multiply it by the emissive color.</p>
<ol>
<li>Let’s load a new 3D model in <code>Chapter07/07_EmissiveStrength/src/main.cpp</code> to demonstrate this extension.</li>
</ol>
<div><pre><code>  VulkanApp app({
    .initialCameraPos    = vec3(0.0f, 5.0f, -10.0f),
  });
  GLTFContext gltf(app);
  loadGLTF(gltf, “deps/src/glTF-Sample-Assets/Models/
      EmissiveStrengthTest/glTF/EmissiveStrengthTest.gltf”,
    “deps/src/glTF-Sample-Assets/Models/
      EmissiveStrengthTest/glTF/”);</code></pre>
</div>
<ol>
<li>Here’s the C++ code in <code>shared/UtilsGLTF.cpp</code> to retrieve the material properties from Assimp:</li>
</ol>
<div><pre><code>  if (mtlDescriptor-&gt;Get(AI_MATKEY_COLOR_EMISSIVE,
     aiColor) == AI_SUCCESS) {
    res.emissiveFactorAlphaCutoff = vec4(aiColor.r,
                                         aiColor.g,
                                         aiColor.b, 0.5f);
  }
  assignUVandSampler(samplers, mtlDescriptor,
    aiTextureType_EMISSIVE,
    res.emissiveTextureUV,
    res.emissiveTextureSampler);
  ai_real emissiveStrength = 1.0f;
  if (mtlDescriptor-&gt;Get(AI_MATKEY_EMISSIVE_INTENSITY,
     emissiveStrength) == AI_SUCCESS) {
    res.emissiveFactorAlphaCutoff *= vec4(
      emissiveStrength, emissiveStrength, emissiveStrength, 1.0);
  }</code></pre>
</div>
<p>The resulting demo app should render a set of five glowing cubes, as shown in the following screenshot:</p>
<figure>
<img alt="Figure 7.8: glTF PBR KHR_materials_emissive_strength example" height="1583" src="img/file58.png" width="2726"/><figcaption aria-hidden="true">Figure 7.8: glTF PBR KHR_materials_emissive_strength example</figcaption>
</figure>
<p>Now, let’s jump to the final recipe of this chapter, where we will dive into implementing support for glTF analytical lights.</p>



<h2 data-number="8.10">Extend analytical lights support with KHR_lights_punctual</h2>
<p>This is the final recipe in this chapter, and we will add support for analytical light sources to our glTF viewer. In the next chapter, we will cover the <code>KHR_lights_punctual</code> extension, which will allow us to load lighting information directly from glTF assets. In this recipe, we will only be dealing with shader changes.</p>
<p>In the context of glTF PBR, the terms “analytical” and “punctual” lights are often used interchangeably to describe the same type of light source:</p>
<ul>
<li><strong>Analytical light</strong>: This refers to light sources defined by mathematical equations, enabling precise calculations of its effect on lighting.</li>
<li><strong>Punctual light</strong>: This describes light sources that are infinitely small points that emit light in specific directions and intensities.</li>
</ul>
<p>We will explore these concepts in more detail in the next chapter. In this recipe, fFor simplicity, we’ll use both terms interchangeably.</p>

<h3 data-number="8.10.1">Image-Based Lighting vs Punctual lights</h3>
<p>Let’s refresh the difference between Image-Based (IBL) and punctual lights.</p>
<p>IBL simulates indirect lighting from the environment using a pre-computed environment map. In glTF PBR, this environment map is filtered based on roughness and normal direction to approximate incoming radiance. The reflected light is calculated using <strong>BRDF</strong> (<strong>Bidirectional Reflectance Distribution Function</strong>) based on the surface material properties, with integration performed over the hemisphere to account for light coming from all directions. Punctual lights, on the other hand, represent specific light sources like point, spot, and directional lights. For each surface point, the direction and distance to the light are calculated, with attenuation applied based on how far the light source is. Shadows are also considered to check if the light reaches the surface. The BRDF is then used to calculate the reflected light based on the light direction, surface normal, and material properties. This method is more computationally expensive than IBL since it requires calculating lighting for each individual light source.</p>
<p>Let’s take a look at how to add glTF punctual lights to our viewer.</p>


<h3 data-number="8.10.2">Getting ready</h3>
<p>The source code for this recipe can be found in <code>Chapter07/08_AnalyticalLight</code>.</p>


<h3 data-number="8.10.3">How to do it…</h3>
<p>C++ code changes are pretty small and straightforward. We introduce additional structures to provide light information data.</p>
<ol>
<li>First, let’s load a corresponding <code>.gltf</code> model in <code>Chapter07/08_AnalyticalLight/src/main.cpp</code>.</li>
</ol>
<div><pre><code>  VulkanApp app({
    .initialCameraPos    = vec3(0.0f, 3.5f, -5.0f),
    .initialCameraTarget = vec3(0.0f, 2.0f, 0.0f),
  });
  GLTFContext gltf(app);
  loadGLTF(gltf, “deps/src/glTF-Sample-Assets/Models/
      LightsPunctualLamp/glTF/LightsPunctualLamp.gltf”,
    “deps/src/glTF-Sample-Assets/Models/
      LightsPunctualLamp/glTF/”);</code></pre>
</div>
<ol>
<li>Declare an enumeration for different light types in <code>shared/UtilsGLTF.h</code>:</li>
</ol>
<div><pre><code>enum LightType : uint32_t {
  LightType_Directional = 0,
  LightType_Point       = 1,
  LightType_Spot        = 2,
};</code></pre>
</div>
<ol>
<li>Here’s a structure called <code>LightDataGPU</code> to store light information in GPU buffers. It has default values defining a dummy directional light:</li>
</ol>
<div><pre><code>struct LightDataGPU {
  vec3 direction     = vec3(0, 0, 1);
  float range        = 10000.0;
  vec3 color         = vec3(1, 1, 1);
  float intensity    = 1.0;
  vec3 position      = vec3(0, 0, -5);
  float innerConeCos = 0.0;
  float outerConeCos = 0.78;
  LightType type     = LightType_Directional;
  int padding[2];
};
struct EnvironmentsPerFrame {
  EnvironmentMapDataGPU environments[kMaxEnvironments];
  LightDataGPU lights[kMaxLights];
  uint32_t lightCount;
};</code></pre>
</div>
<ol>
<li>We set the light sources in <code>shared/UtilsGLTF.cpp</code> as a part of our per-frame constants:</li>
</ol>
<div><pre><code>const EnvironmentsPerFrame envPerFrame = {
  .environments = { {
      …
    } },
  .lights     = { LightDataGPU() },
  .lightCount = 1,
};</code></pre>
</div>
<p>The changes to the GLSL shader code are substantial. We need to reimplement the specular and diffuse contributions for Metallic-Roughness and other extensions, applying these calculations for each light source individually. In this recipe, we will not go too deep into the implementation details, but we strongly recommend reviewing the actual shaders and the reference materials provided in the comments to fully understand this topic. Here’s a brief glimpse of the changes.</p>
<ol>
<li>Let’s introduce a couple of utility functions in <code>data/shaders/gltf/inputs.frag</code> to conveniently access the light data:</li>
</ol>
<div><pre><code>uint getLightsCount() {
  return perFrame.environments.lightsCount;
}
Light getLight(uint i) {
  return perFrame.environments.lights[i];
}</code></pre>
</div>
<ol>
<li>In <code>data/shaders/gltf/main.frag</code>, we introduce accumulation variables for each individual contribution component:</li>
</ol>
<div><pre><code>  vec3 lights_diffuse      = vec3(0);
  vec3 lights_specular     = vec3(0);
  vec3 lights_sheen        = vec3(0);
  vec3 lights_clearcoat    = vec3(0);
  vec3 lights_transmission = vec3(0);
  float albedoSheenScaling = 1.0;</code></pre>
</div>
<ol>
<li>We iterate over all light sources, calculating the necessary terms for each one and checking if the light source is visible from the rendering point. Then we calculate the light intensity:</li>
</ol>
<div><pre><code>  for (int i = 0; i &lt; getLightsCount(); ++i) {
    Light light = getLight(i);
    vec3 l = normalize(pointToLight);
    vec3 h = normalize(l + v);
    float NdotL = clampedDot(n, l);
    float NdotV = clampedDot(n, v);
    float NdotH = clampedDot(n, h);
    float LdotH = clampedDot(l, h);
    float VdotH = clampedDot(v, h);
    if (NdotL &gt; 0.0 || NdotV &gt; 0.0) {
      vec3 intensity = getLightIntensity(light, pointToLight);</code></pre>
</div>
<blockquote>
<p>Evaluating all lights for every object can be quite costly. Alternatives like clustered or deferred shading can help improve performance in this situation.</p>
</blockquote>
<ol>
<li>Then we calculate diffuse and specular contributions for this light:</li>
</ol>
<div><pre><code>      lights_diffuse += intensity * NdotL *
        getBRDFLambertian(pbrInputs.reflectance0,
          pbrInputs.reflectance90, pbrInputs.diffuseColor,
          pbrInputs.specularWeight, VdotH);
      lights_specular += intensity * NdotL *
        getBRDFSpecularGGX(pbrInputs.reflectance0,
          pbrInputs.reflectance90, pbrInputs.alphaRoughness,
          pbrInputs.specularWeight, VdotH, NdotL, NdotV, NdotH);</code></pre>
</div>
<ol>
<li>The sheen contribution is now calculated as follows:</li>
</ol>
<div><pre><code>      if (isSheen) {
        lights_sheen += intensity *
          getPunctualRadianceSheen(pbrInputs.sheenColorFactor,
            pbrInputs.sheenRoughnessFactor, NdotL, NdotV, NdotH);
        albedoSheenScaling =
          min(1.0 - max3(pbrInputs.sheenColorFactor) *
            albedoSheenScalingFactor(NdotV,
            pbrInputs.sheenRoughnessFactor),
          1.0 - max3(pbrInputs.sheenColorFactor) *
          albedoSheenScalingFactor(NdotL,
            pbrInputs.sheenRoughnessFactor));
      }</code></pre>
</div>
<ol>
<li>The new clearcoat contribution is calculated in a similar way. Transmission and volume contributions are skipped here for the sake of brevity:</li>
</ol>
<div><pre><code>      if (isClearCoat) {
        lights_clearcoat += intensity *
          getPunctualRadianceClearCoat(
            pbrInputs.clearcoatNormal, v, l, h, VdotH,
        pbrInputs.clearcoatF0, pbrInputs.clearcoatF90,
          pbrInputs.clearcoatRoughness);
      }
      … // transmission &amp; volume effects are skipped for brevity
    }
  }</code></pre>
</div>
<ol>
<li>We used a helper function <code>getLightIntensity()</code> which is declared in <code>data/shaders/gltf/PBR.sp</code>:</li>
</ol>
<div><pre><code>vec3 getLightIntensity(Light light, vec3 pointToLight) {
  float rangeAttenuation = 1.0;
  float spotAttenuation = 1.0;
  if (light.type != LightType_Directional) {
    rangeAttenuation =
      getRangeAttenuation(light.range, length(pointToLight));
  }
  if (light.type == LightType_Spot) {
    spotAttenuation = getSpotAttenuation(pointToLight,
      light.direction, light.outerConeCos, light.innerConeCos);
  }
  return rangeAttenuation * spotAttenuation *
    light.intensity * light.color;
}</code></pre>
</div>
<p>Other helper functions, such as <code>getBRDFLambertian()</code>, <code>getBRDFSpecularGGX()</code>, <code>getBRDFSpecularSheen()</code>, <code>getPunctualRadianceSheen()</code>, and many others mentioned in the GLSL code earlier, are defined in <code>data/shaders/gltf/PBR.sp</code>. These functions contain the math for calculating the specific terms. For brevity, we do not include them here.</p>
<p>The running application should render a mesh illuminated by an analytical directional light, as shown in the screenshot below:</p>
<figure>
<img alt="Figure 7.9: Analytical lights example" height="1564" src="img/file59.png" width="2721"/><figcaption aria-hidden="true">Figure 7.9: Analytical lights example</figcaption>
</figure>
<p>With this example, we wrap up our chapter on advanced glTF PBR extensions. We have delved into complex topics and extended our understanding of how to work with various lighting models and extensions. In the next chapter, <em>Graphics Rendering Pipeline</em>, we will shift our focus to the broader organization of 3D scenes. We will explore various data structures and strategies needed to efficiently manage and render multiple 3D models. This will involve a detailed look at how to structure and optimize data for rendering, ensuring smooth and effective visualization of complex scenes.</p>



</div></body>
</html>