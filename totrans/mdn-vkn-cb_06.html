<html><head></head><body>
<div id="_idContainer055">
<h1 class="chapter-number" id="_idParaDest-246"><a id="_idTextAnchor283"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-247"><a id="_idTextAnchor284"/><span class="koboSpan" id="kobo.2.1">Anti-Aliasing Techniques</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Anti-aliasing can be achieved in many ways, the most common being the one usually provided by the graphics API. </span><span class="koboSpan" id="kobo.3.2">In this chapter, we start by looking at how to enable and use the anti-aliasing provided by Vulkan, going over a multitude of other techniques that are more suitable for other use cases that require better anti-aliasing or that need a different algorithm altogether, such as temporal anti-aliasing. </span><span class="koboSpan" id="kobo.3.3">In this chapter, we will guide you through various anti-aliasing techniques, starting from enabling and using the one provided by Vulkan to exploring other more advanced and suitable methods for different use cases. </span><span class="koboSpan" id="kobo.3.4">The goal is to empower you with the knowledge and skills to choose and implement the most appropriate anti-aliasing technique for your specific needs, thereby </span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.4.1">improving the visual quality of your </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">rendered </span></span><span class="No-Break"><a id="_idIndexMarker457"/></span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">graphics.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In this </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.8.1">chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">following recipes:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.10.1">Enabling </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.11.1">and using </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">Vulkan’s MSAA</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.13.1">Applying FXAA</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.14.1">Utilizing TAA</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.15.1">Applying DLSS</span></span></li>
</ul>
<h1 id="_idParaDest-248"><a id="_idTextAnchor285"/><span class="koboSpan" id="kobo.16.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.17.1">For this chapter, you will need to make sure you have VS 2022 installed along with the Vulkan SDK. </span><span class="koboSpan" id="kobo.17.2">Basic familiarity with the C++ programming language and an understanding of OpenGL or any other graphics API will be useful. </span><span class="koboSpan" id="kobo.17.3">Please revisit </span><a href="B18491_01.xhtml#_idTextAnchor019"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.18.1">Chapter 1</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.19.1">, Vulkan Core Concepts</span></em><span class="koboSpan" id="kobo.20.1">, under the </span><em class="italic"><span class="koboSpan" id="kobo.21.1">Technical requirements</span></em><span class="koboSpan" id="kobo.22.1"> section for details on setting up and building executables for this chapter. </span><span class="koboSpan" id="kobo.22.2">This chapter has multiple recipes, which can be launched using the </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">following executables:</span></span></p>
<ol>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.24.1">Chapter06_MSAA.exe</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.25.1">Chapter06_FXAA.exe</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.26.1">Chapter06_TAA.exe</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.27.1">Chapter06_DLSS.exe</span></strong></span></li>
</ol>
<h1 id="_idParaDest-249"><a id="_idTextAnchor286"/><span class="koboSpan" id="kobo.28.1">Enabling and using Vulkan’s MSAA</span></h1>
<p><span class="koboSpan" id="kobo.29.1">MSAA is an </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.30.1">anti-aliasing technique that is used to reduce the jagged edges that can appear on curved lines and diagonal edges. </span><span class="koboSpan" id="kobo.30.2">Here’s an overview of how </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">it works:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.32.1">Multiple samples</span></strong><span class="koboSpan" id="kobo.33.1">: Instead of sampling a pixel once (like in regular rendering), MSAA takes multiple samples within each pixel. </span><span class="koboSpan" id="kobo.33.2">For example, 4 x MSAA needs 4 samples while 8 x MSAA needs 8 samples. </span><span class="koboSpan" id="kobo.33.3">The fragment shader runs for each one of the samples, and their output is stored for processing in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.34.1">step 3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.36.1">Edge detection</span></strong><span class="koboSpan" id="kobo.37.1">: MSAA only multi-samples pixels that are at the edges of geometry. </span><span class="koboSpan" id="kobo.37.2">This makes it more performance-efficient compared to techniques such as super-sampling, which samples the entire image at a </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">higher resolution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.39.1">Combining samples</span></strong><span class="koboSpan" id="kobo.40.1">: Once the samples are taken, they are averaged (or resolved) into a single-color value for the pixel. </span><span class="koboSpan" id="kobo.40.2">If some of the samples are within an object and some are outside it, the final pixel color will be a blend, creating a smoother transition and thereby reducing the appearance of </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">jagged edges.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.42.1">In this recipe, we will describe what steps you need to take to enable MSAA in Vulkan, as it is provided by </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">the API.</span></span></p>
<h2 id="_idParaDest-250"><a id="_idTextAnchor287"/><span class="koboSpan" id="kobo.44.1">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.45.1">Enabling MSAA </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.46.1">in Vulkan requires changes to multiple locations in the source code. </span><span class="koboSpan" id="kobo.46.2">The following are high-level steps to </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">implement MSAA:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.48.1">First, you need to ensure that the system supports MSAA. </span><span class="koboSpan" id="kobo.48.2">Additionally, you need to determine the maximum number of samples per pixel that </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">are supported.</span></span></li>
<li><span class="koboSpan" id="kobo.50.1">Textures need to be created with the number of samples </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">they support.</span></span></li>
<li><span class="koboSpan" id="kobo.52.1">Additional textures need to be created to serve as the output after combining the samples (also referred to as </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">resolve attachments).</span></span></li>
<li><span class="koboSpan" id="kobo.54.1">Render passes need to specify the number of samples per attachment and provide extra information about the </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">resolve attachments.</span></span></li>
<li><span class="koboSpan" id="kobo.56.1">Finally, framebuffers need to refer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">resolve attachments.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.58.1">Rendering with MSAA involves images with sample counts greater than 1. </span><span class="koboSpan" id="kobo.58.2">However, these multi-sampled images cannot be presented directly using </span><strong class="source-inline"><span class="koboSpan" id="kobo.59.1">VK_IMAGE_LAYOUT_PRESENT_SRC_KHR</span></strong><span class="koboSpan" id="kobo.60.1">. </span><span class="koboSpan" id="kobo.60.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.61.1">VK_IMAGE_LAYOUT_PRESENT_SRC_KHR</span></strong><span class="koboSpan" id="kobo.62.1"> layout is designed for single-sampled images that are ready for presentation, with one color value per pixel. </span><span class="koboSpan" id="kobo.62.2">That’s why a </span><em class="italic"><span class="koboSpan" id="kobo.63.1">resolve</span></em><span class="koboSpan" id="kobo.64.1"> operation is needed to convert the multi-sampled image into a single-sampled image. </span><span class="koboSpan" id="kobo.64.2">The final </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.65.1">anti-aliased output, which is suitable for presentation, needs to be written to another image with a sample count of </span><strong class="source-inline"><span class="koboSpan" id="kobo.66.1">VK_SAMPLE_COUNT_1_BIT</span></strong><span class="koboSpan" id="kobo.67.1">. </span><span class="koboSpan" id="kobo.67.2">This implies that every color attachment with a sample count greater than 1 requires an associated attachment with a sample count equal to </span><strong class="source-inline"><span class="koboSpan" id="kobo.68.1">VK_SAMPLE_COUNT_1_BIT</span></strong><span class="koboSpan" id="kobo.69.1">. </span><span class="koboSpan" id="kobo.69.2">These additional attachments, known as resolve attachments, are used to store the final anti-aliased output. </span><span class="koboSpan" id="kobo.69.3">During the resolve operation, the values from the multi-samples are combined and written into the </span><em class="italic"><span class="koboSpan" id="kobo.70.1">resolve</span></em><span class="koboSpan" id="kobo.71.1"> attachment, creating the final single-sample image that can </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">be presented.</span></span></p>
<h2 id="_idParaDest-251"><a id="_idTextAnchor288"/><span class="koboSpan" id="kobo.73.1">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.74.1">Enabling MSAA in Vulkan is not difficult but needs changes in multiple parts of the code. </span><span class="koboSpan" id="kobo.74.2">Here’s a step-by-step guide on how to </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">do it:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.76.1">In the following code block, we deal with </span><strong class="source-inline"><span class="koboSpan" id="kobo.77.1">VkPhysicalDeviceProperties</span></strong><span class="koboSpan" id="kobo.78.1"> objects, specifically focusing on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">framebufferColorSampleCounts</span></strong><span class="koboSpan" id="kobo.80.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.81.1">framebufferDepthSampleCounts</span></strong><span class="koboSpan" id="kobo.82.1"> properties. </span><span class="koboSpan" id="kobo.82.2">These properties help us determine the maximum number of samples per pixel supported for color and depth respectively. </span><span class="koboSpan" id="kobo.82.3">This capability is hardware-dependent, which makes it necessary to check it first before usage. </span><span class="koboSpan" id="kobo.82.4">The maximum supported value is found in </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">the following:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.84.1">
VkPhysicalDeviceProperties::limits::framebufferColorSampleCounts
VkPhysicalDeviceProperties::limits::framebufferDepthSampleCounts</span></pre></li> <li><span class="koboSpan" id="kobo.85.1">The maximum number of samples is provided as a bit field of type </span><strong class="source-inline"><span class="koboSpan" id="kobo.86.1">VkSampleCountFlagBits</span></strong><span class="koboSpan" id="kobo.87.1">, with flags such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.88.1">VK_SAMPLE_COUNT_1_BIT</span></strong><span class="koboSpan" id="kobo.89.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1">VK_SAMPLE_COUNT_2_BIT</span></strong><span class="koboSpan" id="kobo.91.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.92.1">VK_SAMPLE_COUNT_4_BIT</span></strong><span class="koboSpan" id="kobo.93.1">, and so on, up </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.95.1">VK_SAMPLE_COUNT_64_BIT</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.97.1">During image creation, the number of samples that a texture supports must be specified. </span><span class="koboSpan" id="kobo.97.2">This is done by setting the </span><strong class="source-inline"><span class="koboSpan" id="kobo.98.1">samples</span></strong><span class="koboSpan" id="kobo.99.1"> member of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.100.1">VkImageCreateInfo</span></strong><span class="koboSpan" id="kobo.101.1"> structure, which is of type </span><strong class="source-inline"><span class="koboSpan" id="kobo.102.1">VkSampleCountFlagBits</span></strong><span class="koboSpan" id="kobo.103.1">, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">the following:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.105.1">
VkImageCreateInfo newTexture = {
  ...
</span><span class="koboSpan" id="kobo.105.2">  .samples = VK_SAMPLE_COUNT_8_BIT,
};</span></pre></li> <li><span class="koboSpan" id="kobo.106.1">While </span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.107.1">creating a render pass, the attachment descriptions must indicate the sample count by setting the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.108.1">VkAttachmentDescription::samples</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.109.1"> field:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.110.1">
VkAttachmentDescription attachment = {
  ...
</span><span class="koboSpan" id="kobo.110.2">  .samples = VK_SAMPLE_COUNT_8_BIT,
};</span></pre></li> <li><span class="koboSpan" id="kobo.111.1">An instance of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.112.1">VkAttachmentDescription</span></strong><span class="koboSpan" id="kobo.113.1"> structure needs to be added to the render pass’s list of attachments, </span><strong class="source-inline"><span class="koboSpan" id="kobo.114.1">VkSubpassDescription::pColorAttachments</span></strong><span class="koboSpan" id="kobo.115.1">, for each resolve attachment in the render pass. </span><span class="koboSpan" id="kobo.115.2">The resolve attachments must have their samples field set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.116.1">VK_SAMPLE_COUNT_1_BIT</span></strong><span class="koboSpan" id="kobo.117.1">, as the resolution of the multi-sampled image results in a single sample per pixel. </span><span class="koboSpan" id="kobo.117.2">This is because the multiple samples from the multi-sampled image are resolved into one final color value for that pixel. </span><span class="koboSpan" id="kobo.117.3">Here is how you can create and configure such a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.118.1">VkAttachmentDescription</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.119.1"> instance:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.120.1">
VkAttachmentDescription resolveAttachment = {
  ...
</span><span class="koboSpan" id="kobo.120.2">  .samples = VK_SAMPLE_COUNT_1_BIT,
}</span></pre></li> <li><span class="koboSpan" id="kobo.121.1">An instance </span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.122.1">of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.123.1">VkAttachmentReference</span></strong><span class="koboSpan" id="kobo.124.1"> structure must be created to reference this </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">resolve attachment:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.126.1">
VkAttachmentReference resolveAttachmentRef{
  .attachment = </span><strong class="bold"><span class="koboSpan" id="kobo.127.1">&lt;index of resolve texture in the attachmentDescriptor vector&gt;</span></strong><span class="koboSpan" id="kobo.128.1">,
  .layout =
      VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
}</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.129.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.130.1">VkAttachmentReference::attachment</span></strong><span class="koboSpan" id="kobo.131.1"> field is an integer that points to the resolve attachment at the corresponding index of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.132.1">VkRenderPassCreateInfo::pAttachments</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.133.1"> array.</span></span></p></li> <li><span class="koboSpan" id="kobo.134.1">Finally, the list of attachment references that describe the resolve attachments is added to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.135.1">VkSubpassDescription::pResolveAttachments</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.136.1"> field.</span></span><p class="list-inset"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.137.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.138.1">.1</span></em><span class="koboSpan" id="kobo.139.1"> illustrates how each component is set up and how they are referenced by a render pass and subpass description structures. </span><span class="koboSpan" id="kobo.139.2">The depth/stencil attachment must have the same sample count as the color attachments, and the number of resolve attachments must be equal to the number of </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">color attachments.</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer051">
<span class="koboSpan" id="kobo.141.1"><img alt="Figure 6.1 – Render pass configuration" src="image/B18491_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.142.1">Figure 6.1 – Render pass configuration</span></p>
<p><span class="koboSpan" id="kobo.143.1">In the </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.144.1">preceding diagram, we showcased the configuration of texture sample count and its reference by both the render pass and subpass description structures. </span><span class="koboSpan" id="kobo.144.2">This arrangement is crucial for enabling MSAA </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">in Vulkan.</span></span></p>
<h1 id="_idParaDest-252"><a id="_idTextAnchor289"/><span class="koboSpan" id="kobo.146.1">Applying FXAA</span></h1>
<p><span class="koboSpan" id="kobo.147.1">FXAA is a screen-space anti-aliasing technique that can be implemented as an extra full-screen post-process pass. </span><span class="koboSpan" id="kobo.147.2">FXAA works by identifying edges in the image and then smoothing </span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.148.1">them to reduce the appearance of aliasing. </span><span class="koboSpan" id="kobo.148.2">Without the need for any additional information from the scene, FXAA can be easily integrated into existing code. </span><span class="koboSpan" id="kobo.148.3">It’s also fast because it processes only the final rendered image pixels and some of their neighbors. </span><span class="koboSpan" id="kobo.148.4">In this recipe, you will learn about the FXAA technique. </span><span class="koboSpan" id="kobo.148.5">You will understand how it functions as a screen-space anti-aliasing method, how it can be applied through a post-process pass, and why it is a beneficial tool due to its ease of integration and speed. </span><span class="koboSpan" id="kobo.148.6">Note that FXAA is generally applied before gamma correction or any sRGB conversion. </span><span class="koboSpan" id="kobo.148.7">The reason for this is that FXAA works best on linear RGB data. </span><span class="koboSpan" id="kobo.148.8">If you apply FXAA after gamma correction or sRGB conversion, it may result in incorrect edge detection and thus less </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">effective anti-aliasing.</span></span></p>
<h2 id="_idParaDest-253"><a id="_idTextAnchor290"/><span class="koboSpan" id="kobo.150.1">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.151.1">The FXAA algorithm is implemented in our repository by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.152.1">FXAAPass</span></strong><span class="koboSpan" id="kobo.153.1"> class, found in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.154.1">source/enginecore/passes/FXAA.cpp</span></strong><span class="koboSpan" id="kobo.155.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.156.1">FXAA.hpp</span></strong><span class="koboSpan" id="kobo.157.1"> files. </span><span class="koboSpan" id="kobo.157.2">The shader used by the pass is located </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">at </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">source/enginecore/resources/shaders/fxaa.frag</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">.</span></span></p>
<h2 id="_idParaDest-254"><a id="_idTextAnchor291"/><span class="koboSpan" id="kobo.161.1">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.162.1">The algorithm can be implemented entirely in a fragment shader that uses the final render </span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.163.1">image as input. </span><span class="koboSpan" id="kobo.163.2">The shader also needs the size of the viewport, which can be provided as a </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">push constant:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.165.1">The shader is simple in terms of input and output and only needs an input texture and the size of the viewport </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">for processing:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.167.1">
#version 460
layout(push_constant) uniform Viewport {
  uvec2 size;
}
ViewportSize;
layout(set = 0, binding = 0) uniform sampler2D
    inputTexture;
layout(location = 0) out vec4 outColor;</span></pre></li> <li><span class="koboSpan" id="kobo.168.1">The FXAA algorithm operates on the luminance of the pixels, so we need a function to convert RGB values </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">to luminance:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.170.1">
float rgb2luma(vec3 rgb) {
  return dot(rgb, vec3(0.299, 0.587, 0.114));
}</span></pre></li> <li><span class="koboSpan" id="kobo.171.1">Here are some constants for the </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">edge-detection part:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.173.1">
const float EDGE_THRESHOLD_MIN = (1.0 / 16.0);
const float EDGE_THRESHOLD_MAX = (1.0 / 8.0);
const float PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING =
    (3.0 / 4.0);
const float MIN_PIXEL_ALIASING_REQUIRED =
    (1.0 / 8.0);
const float NUM_LOOP_FOR_EDGE_DETECTION = 1;</span></pre></li> <li><span class="koboSpan" id="kobo.174.1">To simplify the code, we’ll use an array to store the luminance and RGB values for the </span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.175.1">neighboring pixels. </span><span class="koboSpan" id="kobo.175.2">We’ll also use constants to help refer to elements of the vector without using </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">just integers:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.177.1">
const int Center      = 0;
const int Top         = 1;
const int Bottom      = 2;
const int Left        = 3;
const int Right       = 4;
const int TopRight    = 5;
const int BottomRight = 6;
const int TopLeft     = 7;
const int BottomLeft  = 8;
vec2 offsets[] = {
    vec2( 0, 0), vec2( 0, -1), vec2( 0,  1),
    vec2(-1, 0), vec2( 1,  0), vec2( 1, -1),
    vec2( 1, 1), vec2(-1, -1), vec2(-1,  1)};</span></pre></li> <li><span class="koboSpan" id="kobo.178.1">The algorithm is encapsulated in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.179.1">applyFXAA</span></strong><span class="koboSpan" id="kobo.180.1"> function that takes the screen coordinates in pixels, the rendered image to be processed, and the size of </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">the viewport:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.182.1">
vec4 applyFXAA(vec2 screenCoord,
               sampler2D inputTexture,
               uvec2 viewportSize) {</span></pre></li> <li><span class="koboSpan" id="kobo.183.1">The first </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.184.1">step is to compute the luminance and the RGB values of all eight neighboring pixels, as well as the range between the lowest and the highest luminance. </span><span class="koboSpan" id="kobo.184.2">If the value is below a certain threshold, we don’t perform the anti-aliasing. </span><span class="koboSpan" id="kobo.184.3">The </span><strong class="bold"><span class="koboSpan" id="kobo.185.1">threshold</span></strong><span class="koboSpan" id="kobo.186.1"> is used to determine whether a pixel is on an edge; its value represents the minimum difference in luminance that must exist between a pixel and its neighbors for that pixel to be considered part of </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">an edge:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.188.1">
  const vec2 viewportSizeInverse = vec2(
      1.0 / viewportSize.x, 1.0 / viewportSize.y);
  const vec2 texCoord =
      screenCoord * viewportSizeInverse;
  float minLuma = 100000000;
  float maxLuma = 0;
  float lumas[9];
  vec3 rgb[9];
  vec3 rgbSum = vec3(0, 0, 0);
  for (int i = 0; i &lt; 9; ++i) {
    rgb[i] =
        texture(inputTexture,
                texCoord +
                    offsets[i] *
                        viewportSizeInverse)
            .rgb;
    rgbSum += rgb[i];
    lumas[i] = rgb2luma(rgb[i]);
    if (i &lt; 5) {
      minLuma = min(lumas[i], minLuma);
      maxLuma = max(lumas[i], maxLuma);
    }
  }
  const float rangeLuma = maxLuma - minLuma;
  if (rangeLuma &lt;
      max(EDGE_THRESHOLD_MIN,
          EDGE_THRESHOLD_MAX * maxLuma)) {
    return vec4(rgb[Center], 1.0);
  }</span></pre></li> <li><span class="koboSpan" id="kobo.189.1">The difference between the average luminance of all neighboring pixels and the center </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.190.1">pixels tells us whether we need to perform the anti-aliasing algorithm and the amount of blending required. </span><span class="koboSpan" id="kobo.190.2">It also clamps the blend amount between 0 and </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING</span></strong><span class="koboSpan" id="kobo.192.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">reduce blurring:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.194.1">
  const float lumaTopBottom =
      lumas[Top] + lumas[Bottom];
  const float lumaLeftRight =
      lumas[Left] + lumas[Right];
  const float lumaTopCorners =
      lumas[TopLeft] + lumas[TopRight];
  const float lumaBottomCorners =
      lumas[BottomLeft] + lumas[BottomRight];
  const float lumaLeftCorners =
      lumas[TopLeft] + lumas[BottomLeft];
  const float lumaRightCorners =
      lumas[TopRight] + lumas[BottomRight];
  const float lumaTBLR =
      lumaTopBottom + lumaLeftRight;
  const float averageLumaTBLR = (lumaTBLR) / 4.0;
  const float lumaSubRange =
      abs(averageLumaTBLR - lumas[Center]);
  float pixelblendAmount =
      max(0.0, (lumaSubRange / rangeLuma) -
                   MIN_PIXEL_ALIASING_REQUIRED);
  pixelblendAmount = min(
      PIXEL_BLEND_LIMIT_TO_REDUCE_BLURRING,
      pixelblendAmount *
          (1.0 /
           (1.0 - MIN_PIXEL_ALIASING_REQUIRED)));</span></pre></li> <li><span class="koboSpan" id="kobo.195.1">The next step consists of determining whether the edge is more vertical than horizontal </span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.196.1">and initializing the variables that will be used to find the edge endpoints, with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.197.1">findEndPointPosition</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.198.1"> function:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.199.1">
  const vec3 averageRGBNeighbor =
      rgbSum * (1.0 / 9.0);
  const float verticalEdgeRow1 =
      abs(-2.0 * lumas[Top] + lumaTopCorners);
  const float verticalEdgeRow2 =
      abs(-2.0 * lumas[Center] + lumaLeftRight);
  const float verticalEdgeRow3 = abs(
      -2.0 * lumas[Bottom] + lumaBottomCorners);
  const float verticalEdge =
      (verticalEdgeRow1 + verticalEdgeRow2 * 2.0 +
       verticalEdgeRow3) /
      12.0;
  const float horizontalEdgeCol1 =
      abs(-2.0 * lumas[Left] + lumaLeftCorners);
  const float horizontalEdgeCol2 =
      abs(-2.0 * lumas[Center] + lumaTopBottom);
  const float horizontalEdgeCol3 =
      abs(-2.0 * lumas[Right] + lumaRightCorners);
  const float horizontalEdge =
      (horizontalEdgeCol1 +
       horizontalEdgeCol2 * 2.0 +
       horizontalEdgeCol3) /
      12.0;
  const bool isHorizontal =
      horizontalEdge &gt;= verticalEdge;
  const float luma1 =
      isHorizontal ? </span><span class="koboSpan" id="kobo.199.2">lumas[Top] : lumas[Left];
  const float luma2 =
      isHorizontal ? </span><span class="koboSpan" id="kobo.199.3">lumas[Bottom] : lumas[Right];
  const bool is1Steepest =
      abs(lumas[Center] - luma1) &gt;=
      abs(lumas[Center] - luma2);
  float stepLength =
      isHorizontal ? </span><span class="koboSpan" id="kobo.199.4">-screenCoordToTextureCoord.y
                   : -screenCoordToTextureCoord.x;
  float lumaHighContrastPixel;
  if (is1Steepest) {
    lumaHighContrastPixel = luma1;
  } else {
    lumaHighContrastPixel = luma2;
    // Also reverse the direction:
    stepLength = -stepLength;
  }
  vec2 outPosToFetchTexelForEdgeAntiAliasing;
  vec3 rgbEdgeAntiAliasingPixel = rgb[Center];</span></pre></li> <li><span class="koboSpan" id="kobo.200.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.201.1">findEndPointPosition</span></strong><span class="koboSpan" id="kobo.202.1"> function returns </span><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">1</span></strong><span class="koboSpan" id="kobo.204.1"> if it deems antialiasing is needed and </span><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">0</span></strong><span class="koboSpan" id="kobo.206.1"> otherwise. </span><span class="koboSpan" id="kobo.206.2">It also returns the coordinate of the texel that will be blended with the pixel being anti-aliased. </span><span class="koboSpan" id="kobo.206.3">We will investigate the </span><strong class="source-inline"><span class="koboSpan" id="kobo.207.1">findEndPointPosition</span></strong><span class="koboSpan" id="kobo.208.1"> function in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.209.1">step 11</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.211.1">
  const float res = findEndPointPosition(
      inputTexture, texCoord,
      lumas[Center], lumaHighContrastPixel,
      stepLength, screenCoordToTextureCoord,
      isHorizontal,
      outPosToFetchTexelForEdgeAntiAliasing);</span></pre></li> <li><span class="koboSpan" id="kobo.212.1">If the </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.213.1">return value is </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">1.0</span></strong><span class="koboSpan" id="kobo.215.1">, we perform the antialiasing by blending the original pixel’s color with the color from the texel at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1">outPosToFetchTexelForEdgeAntiAliasing</span></strong><span class="koboSpan" id="kobo.217.1"> coordinate. </span><span class="koboSpan" id="kobo.217.2">The blending factor to use (</span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">pixelblendAmount</span></strong><span class="koboSpan" id="kobo.219.1">) was computed previously, in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.220.1">step 7</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.222.1">
  if (res == 1.0) {
    rgbEdgeAntiAliasingPixel =
        texture(
            inputTexture,
            outPosToFetchTexelForEdgeAntiAliasing)
            .rgb;
  }
  return vec4(mix(rgbEdgeAntiAliasingPixel,
                  averageRGBNeighbor,
                  pixelblendAmount),
              1.0);
}</span></pre></li> <li><span class="koboSpan" id="kobo.223.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.224.1">findEndPointPosition</span></strong><span class="koboSpan" id="kobo.225.1"> function performs an important task – it traverses the image in search of edge endpoints, moving in both directions from the central pixel that’s being processed. </span><span class="koboSpan" id="kobo.225.2">To accomplish this, it requires several pieces of information. </span><span class="koboSpan" id="kobo.225.3">First, it needs the texture that’s being processed, which is the image that the function will traverse. </span><span class="koboSpan" id="kobo.225.4">Next, it requires the coordinate of the pixel being processed, which serves as the starting point for the function’s traversal. </span><span class="koboSpan" id="kobo.225.5">The function also needs to know the luminance, or brightness, of the pixel. </span><span class="koboSpan" id="kobo.225.6">In addition, it must be aware of the luminance of the highest contrast pixel, an element that is determined based on whether the edge being examined </span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.226.1">is more horizontal or more vertical. </span><span class="koboSpan" id="kobo.226.2">Another crucial piece of information is the step length, which, like the luminance of the highest contrast pixel, is also dependent on the angle of the edge. </span><span class="koboSpan" id="kobo.226.3">The function needs the length of one pixel in texture coordinates for accurate image traversal. </span><span class="koboSpan" id="kobo.226.4">Finally, it requires a flag that indicates whether the edge is more horizontal or more vertical to correctly understand the edge’s orientation. </span><span class="koboSpan" id="kobo.226.5">It returns </span><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">1</span></strong><span class="koboSpan" id="kobo.228.1"> if it deems anti-aliasing needs to be performed and </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1">0</span></strong><span class="koboSpan" id="kobo.230.1"> otherwise. </span><span class="koboSpan" id="kobo.230.2">It also returns the coordinate of the pixel that contains the RGB value to be used for </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">the anti-aliasing:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.232.1">
float findEndPointPosition(
    sampler2D inputTexture,
    vec2 textureCoordMiddle, float lumaMiddle,
    float lumaHighContrastPixel, float stepLength,
    vec2 screenCoordToTextureCoord,
    bool isHorizontal,
    out vec2
        outPosToFetchTexelForEdgeAntiAliasing) {</span></pre></li> <li><span class="koboSpan" id="kobo.233.1">Depending on whether the edge is horizontal or not, the function initializes the direction </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.234.1">and position of the </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">high-contrast pixel:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.236.1">
  vec2 textureCoordOfHighContrastPixel =
      textureCoordMiddle;
  // Direction of the edge
  vec2 edgeDir;
  if (isHorizontal) {
    textureCoordOfHighContrastPixel.y =
        textureCoordMiddle.y + stepLength;
    textureCoordOfHighContrastPixel.x =
        textureCoordMiddle.x;
    edgeDir.x = screenCoordToTextureCoord.x;
    edgeDir.y = 0.0;
  } else {
    textureCoordOfHighContrastPixel.x =
        textureCoordMiddle.x + stepLength;
    textureCoordOfHighContrastPixel.y =
        textureCoordMiddle.y;
    edgeDir.y = screenCoordToTextureCoord.y;
    edgeDir.x = 0.0;
  }</span></pre></li> <li><span class="koboSpan" id="kobo.237.1">Before we proceed to start looking for the edge endpoints, we need to set up some variables used in </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">the loop:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.239.1">
  // Prepare for the search loop:
  float lumaHighContrastPixelNegDir;
  float lumaHighContrastPixelPosDir;
  float lumaMiddlePixelNegDir;
  float lumaMiddlePixelPosDir;
  bool doneGoingThroughNegDir = false;
  bool doneGoingThroughPosDir = false;
  vec2 posHighContrastNegDir =
      textureCoordOfHighContrastPixel - edgeDir;
  vec2 posHighContrastPosDir =
      textureCoordOfHighContrastPixel + edgeDir;
  vec2 posMiddleNegDir =
      textureCoordMiddle - edgeDir;
  vec2 posMiddlePosDir =
      textureCoordMiddle + edgeDir;</span></pre></li> <li><span class="koboSpan" id="kobo.240.1">The loop iterates a maximum of </span><strong class="source-inline"><span class="koboSpan" id="kobo.241.1">NUM_LOOP_FOR_EDGE_DETECTION</span></strong><span class="koboSpan" id="kobo.242.1"> times. </span><span class="koboSpan" id="kobo.242.2">It checks </span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.243.1">for edges by looking at the luminance differences in both the positive and negative directions from the middle pixel. </span><span class="koboSpan" id="kobo.243.2">The edge is detected when the luminance difference between two consecutive points in one direction exceeds a threshold (we will look at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">processDirection</span></strong><span class="koboSpan" id="kobo.245.1"> function in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.246.1">step 20</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">):</span></span><pre class="source-code"><span class="koboSpan" id="kobo.248.1">
    for (int i = 0; i &lt; NUM_LOOP_FOR_EDGE_DETECTION;
       ++i) {
    // Negative direction processing
    if (!doneGoingThroughNegDir) {
      processDirection(doneGoingThroughNegDir,
                       posHighContrastNegDir,
                       posMiddleNegDir, -edgeDir,
                       lumaHighContrastPixel,
                       lumaMiddle);
    }
    // Positive direction processing
    if (!doneGoingThroughPosDir) {
      processDirection(doneGoingThroughPosDir,
                       posHighContrastPosDir,
                       posMiddlePosDir, edgeDir,
                       lumaHighContrastPixel,
                       lumaMiddle);
    }
    // If both directions are done, exit the loop
    if (doneGoingThroughNegDir &amp;&amp;
        doneGoingThroughPosDir) {
      break;
    }
  }</span></pre></li> <li><span class="koboSpan" id="kobo.249.1">The function </span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.250.1">now calculates the distances from the middle pixel to the detected edge endpoints, in both the negative and </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">positive directions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.252.1">
  float dstNeg;
  float dstPos;
  if (isHorizontal) {
    dstNeg =
        textureCoordMiddle.x - posMiddleNegDir.x;
    dstPos =
        posMiddlePosDir.x - textureCoordMiddle.x;
  } else {
    dstNeg =
        textureCoordMiddle.y - posMiddleNegDir.y;
    dstPos =
        posMiddlePosDir.y - textureCoordMiddle.y;
  }</span></pre></li> <li><span class="koboSpan" id="kobo.253.1">It also </span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.254.1">checks which endpoint is closer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">middle pixel:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.256.1">
  bool isMiddlePixelCloserToNeg = dstNeg &lt; dstPos;
  float dst = min(dstNeg, dstPos);
  float lumaEndPointOfPixelCloserToMiddle =
      isMiddlePixelCloserToNeg
          ? </span><span class="koboSpan" id="kobo.256.2">lumaMiddlePixelNegDir
          : lumaMiddlePixelPosDir;</span></pre></li> <li><span class="koboSpan" id="kobo.257.1">Anti-aliasing is deemed necessary, based on the luminance difference between the endpoint that is closer to the middle pixel and the middle </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">pixel itself:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.259.1">
  bool edgeAARequired =
      abs(lumaEndPointOfPixelCloserToMiddle -
          lumaHighContrastPixel) &lt;
      abs(lumaEndPointOfPixelCloserToMiddle -
          lumaMiddle);</span></pre></li> <li><span class="koboSpan" id="kobo.260.1">Using the </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.261.1">distances to the edge endpoints, the following code snippet calculates the pixel offset that is required </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">for anti-aliasing:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.263.1">
  float negInverseEndPointsLength =
      -1.0 / (dstNeg + dstPos);
  float pixelOffset =
      dst * negInverseEndPointsLength + 0.5;
  outPosToFetchTexelForEdgeAntiAliasing =
      textureCoordMiddle;
  if (isHorizontal) {
    outPosToFetchTexelForEdgeAntiAliasing.y +=
        pixelOffset * stepLength;
  } else {
    outPosToFetchTexelForEdgeAntiAliasing.x +=
        pixelOffset * stepLength;
  }</span></pre></li> <li><span class="koboSpan" id="kobo.264.1">The function returns </span><strong class="source-inline"><span class="koboSpan" id="kobo.265.1">1.0</span></strong><span class="koboSpan" id="kobo.266.1"> if edge anti-aliasing is required and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.267.1">0.0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.268.1"> otherwise:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.269.1">
  return edgeAARequired ? </span><span class="koboSpan" id="kobo.269.2">1.0 : 0.0;
}</span></pre></li> <li><span class="koboSpan" id="kobo.270.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.271.1">processDirection</span></strong><span class="koboSpan" id="kobo.272.1"> inspects the luma values of pixels in a certain direction (given by </span><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">edgeIncrement</span></strong><span class="koboSpan" id="kobo.274.1">) to check for high contrast or edges. </span><span class="koboSpan" id="kobo.274.2">It will continue to inspect positions in this direction until a certain contrast condition is met. </span><span class="koboSpan" id="kobo.274.3">Once the condition is met, it will set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">doneGoingThroughDir</span></strong><span class="koboSpan" id="kobo.276.1"> flag to </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">true</span></strong><span class="koboSpan" id="kobo.278.1">, signaling </span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.279.1">that it’s done processing in </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">this direction:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.281.1">
void processDirection(inout bool doneGoingThroughDir,
                      inout vec2 posHighContrast,
                      inout vec2 posMiddle,
                      float edgeIncrement,
                      float lumaHighContrastPixel,
                      float lumaMiddle) {
  float lumaHighContrastPixelDir = rgb2luma(
      texture(inputTexture, posHighContrast).rgb);
  float lumaMiddlePixelDir = rgb2luma(
      texture(inputTexture, posMiddle).rgb);
  doneGoingThroughDir =
      abs(lumaHighContrastPixelDir -
          lumaHighContrastPixel) &gt;
          abs(lumaHighContrastPixelDir -
              lumaMiddle) ||
      abs(lumaMiddlePixelDir - lumaMiddle) &gt;
          abs(lumaMiddlePixelDir -
              lumaHighContrastPixel);
  // Update position for next iteration if not
  // done
  if (!doneGoingThroughDir) {
    posHighContrast += edgeIncrement;
    posMiddle += edgeIncrement;
  }
}</span></pre></li> <li><span class="koboSpan" id="kobo.282.1">The </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.283.1">fragment code calls </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1">applyFXAA</span></strong><span class="koboSpan" id="kobo.285.1">, which returns the new color to output from </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">the shader:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.287.1">
void main() {
  outColor =
      applyFXAA(gl_FragCoord.xy, inputTexture,
                ViewportSize.size);
}</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.288.1">And there you have it – the recipe for applying FXAA, a powerful tool for smoothing out jaggies in your graphics. </span><span class="koboSpan" id="kobo.288.2">As we wrap this up, remember that the beauty of FXAA lies not just in its ability to enhance visual output but also in its flexibility and ease of integration into </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">existing systems.</span></span></p>
<h1 id="_idParaDest-255"><a id="_idTextAnchor292"/><span class="koboSpan" id="kobo.290.1">Utilizing TAA</span></h1>
<p><span class="koboSpan" id="kobo.291.1">Unlike the previously discussed anti-aliasing methods, which only consider spatial information, TAA is based on temporal information – that is, it utilizes both the current and previous </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.292.1">frames to smooth out these aliasing artifacts. </span><span class="koboSpan" id="kobo.292.2">The reason aliasing artifacts happens is because of insufficient samples; TAA solves this by sampling data over the frame sequence, significantly reducing the pressure on a </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">single frame.</span></span></p>
<p><span class="koboSpan" id="kobo.294.1">The basic idea is to apply subpixel jittering – that is, slightly shift the projection matrix of the camera for each new frame. </span><span class="koboSpan" id="kobo.294.2">This results in slightly different viewpoints for each frame, giving us more information about the scene than a static viewpoint would. </span><span class="koboSpan" id="kobo.294.3">When sampling textures during rendering, the resulting color value can be different due to the jitter. </span><span class="koboSpan" id="kobo.294.4">This creates a different aliasing pattern per frame, which, when accumulated over time, averages out and reduces the visible aliasing in the scene. </span><span class="koboSpan" id="kobo.294.5">This is demonstrated in the following screenshot in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.295.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.296.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<span class="koboSpan" id="kobo.298.1"><img alt="Figure 6.2 – A temporal anti-aliasing overview" src="image/B18491_06_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.299.1">Figure 6.2 – A temporal anti-aliasing overview</span></p>
<p><span class="koboSpan" id="kobo.300.1">The concept outlined here performs exceptionally well for static scenes. </span><span class="koboSpan" id="kobo.300.2">However, in scenarios </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.301.1">where either the objects or the camera is in motion, consecutive frames can exhibit substantial differences. </span><span class="koboSpan" id="kobo.301.2">This can lead to a visual artifact where moving objects appear to leave behind a series of their </span><em class="italic"><span class="koboSpan" id="kobo.302.1">ghosts</span></em><span class="koboSpan" id="kobo.303.1">, creating what is </span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.304.1">known as the </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.305.1">ghosting</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.306.1"> effect.</span></span></p>
<p><span class="koboSpan" id="kobo.307.1">To get rid of ghosting, we use </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.308.1">what is commonly called a </span><strong class="bold"><span class="koboSpan" id="kobo.309.1">velocity</span></strong><span class="koboSpan" id="kobo.310.1"> buffer, and the motion in the scene is captured using motion vectors. </span><span class="koboSpan" id="kobo.310.2">For each pixel, a motion vector is calculated that represents how much a pixel has moved compared to the previous frame. </span><span class="koboSpan" id="kobo.310.3">The result is a velocity buffer that stores these motion vectors. </span><span class="koboSpan" id="kobo.310.4">The previously rendered frame is then re-projected onto the current frame using the velocity buffer. </span><span class="koboSpan" id="kobo.310.5">This means that for each pixel, the color of the corresponding pixel in the previous frame is looked up using the motion vector. </span><span class="koboSpan" id="kobo.310.6">This color is then blended with the current color of the pixel, which results in a smoothing of the colors </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">over time.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.312.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.313.1">.3</span></em><span class="koboSpan" id="kobo.314.1"> shows a high-level overview of the </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">TAA algorithm:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<span class="koboSpan" id="kobo.316.1"><img alt="Figure 6.3 – A TAA frame overview" src="image/B18491_06_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.317.1">Figure 6.3 – A TAA frame overview</span></p>
<p><span class="koboSpan" id="kobo.318.1">In this recipe, you will learn how to implement TAA, an advanced technique that can significantly reduce flickering and provide smoother visuals in your graphics. </span><span class="koboSpan" id="kobo.318.2">You’ll understand the intricacies of TAA and how to adeptly integrate it into your code, adding another powerful tool to your graphics </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">rendering toolbox.</span></span></p>
<h2 id="_idParaDest-256"><a id="_idTextAnchor293"/><span class="koboSpan" id="kobo.320.1">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.321.1">In the repository, the TAA algorithm is implemented by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">TAAComputePass</span></strong><span class="koboSpan" id="kobo.323.1"> class, located in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.324.1">source/enginecore/passes/TAAComputePass.hpp</span></strong><span class="koboSpan" id="kobo.325.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.326.1">cpp</span></strong><span class="koboSpan" id="kobo.327.1"> files. </span><span class="koboSpan" id="kobo.327.2">The shaders </span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.328.1">are implemented using a compute shader, located in </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">source/enginecore/resources/shaders/taaresolve.comp</span></strong><span class="koboSpan" id="kobo.330.1"> and</span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1"> source/enginecore/resources/shaders/taahistorycopyandsharpen.comp</span></strong><span class="koboSpan" id="kobo.332.1">. </span><span class="koboSpan" id="kobo.332.2">TAA example can be launched by running the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">Chapter06_TAA</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.334.1"> executable.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.335.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.336.1">.4</span></em><span class="koboSpan" id="kobo.337.1"> illustrates the flow of the </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">TAA algorithm:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer054">
<span class="koboSpan" id="kobo.339.1"><img alt="Figure 6.4 – A TAA algorithm in a deferred renderer" src="image/B18491_06_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.340.1">Figure 6.4 – A TAA algorithm in a deferred renderer</span></p>
<p><span class="koboSpan" id="kobo.341.1">TAA is implemented as a two-step </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">compute shader:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.343.1">The first step is the TAA resolve shader, which takes </span><strong class="source-inline"><span class="koboSpan" id="kobo.344.1">ColorTexture</span></strong><span class="koboSpan" id="kobo.345.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.346.1">DepthTexture</span></strong><span class="koboSpan" id="kobo.347.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">HistoryTexture</span></strong><span class="koboSpan" id="kobo.349.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.350.1">VelocityTexture</span></strong><span class="koboSpan" id="kobo.351.1"> as input and writes to an intermediate image. </span><span class="koboSpan" id="kobo.351.2">The velocity, color, and depth texture are produced from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.352.1">Gbuffer</span></strong><span class="koboSpan" id="kobo.353.1"> pass in the given example; however, conceptually, the same could be produced in forward rendering </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">as well.</span></span></li>
<li><span class="koboSpan" id="kobo.355.1">The second </span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.356.1">step is running a compute shader that is responsible for </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">the following:</span></span><ol><li class="Alphabets"><span class="koboSpan" id="kobo.358.1">Copying the results of the previously produced intermediate texture into a </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">history texture.</span></span></li><li class="Alphabets"><span class="koboSpan" id="kobo.360.1">Refining these intermediate results, we don’t need to generate an additional texture to store the refined results, instead, we can utilize the provided </span><strong class="source-inline"><span class="koboSpan" id="kobo.361.1">ColorTexture</span></strong><span class="koboSpan" id="kobo.362.1"> in the TAA resolve shader. </span><span class="koboSpan" id="kobo.362.2">This is the same </span><strong class="source-inline"><span class="koboSpan" id="kobo.363.1">ColorTexture</span></strong><span class="koboSpan" id="kobo.364.1"> that eventually gets displayed. </span><span class="koboSpan" id="kobo.364.2">A known downside of TAA is the potential of causing a minor blur in the image. </span><span class="koboSpan" id="kobo.364.3">To mitigate this, a sharpening filter is applied post-TAA. </span><span class="koboSpan" id="kobo.364.4">This sharpening phase is designed to intensify the edges and intricate details in the image, thereby reinstating some of the sharpness that might have been compromised during the TAA </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">resolve process.</span></span></li></ol></li>
</ol>
<h2 id="_idParaDest-257"><a id="_idTextAnchor294"/><span class="koboSpan" id="kobo.366.1">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.367.1">To implement TAA, we first need to construct a jitter matrix. </span><span class="koboSpan" id="kobo.367.2">This matrix will be used in tandem with the </span><strong class="bold"><span class="koboSpan" id="kobo.368.1">Model-View-Projection</span></strong><span class="koboSpan" id="kobo.369.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.370.1">MVP</span></strong><span class="koboSpan" id="kobo.371.1">) matrix during the rendering process. </span><span class="koboSpan" id="kobo.371.2">Furthermore, we will </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.372.1">need color, depth, and velocity buffers. </span><span class="koboSpan" id="kobo.372.2">Conveniently, these buffers are already generated as part of the G-buffer pipeline, which we implemented in </span><a href="B18491_04.xhtml#_idTextAnchor241"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.373.1">Chapter 4</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.374.1">, Exploring Techniques for Lighting, Shading, and Shadows</span></em><span class="koboSpan" id="kobo.375.1"> in the </span><em class="italic"><span class="koboSpan" id="kobo.376.1">Implementing the G-buffer for deferred </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.377.1">rendering</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.378.1"> recipe:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.379.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.380.1">TAAComputePass::init</span></strong><span class="koboSpan" id="kobo.381.1"> method is in charge of initializing various resources. </span><span class="koboSpan" id="kobo.381.2">It establishes two pipelines – one for resolving to an output color, and another for transferring the output color into a history texture and enhancing the output </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">color’s sharpness.</span></span></li>
<li><span class="koboSpan" id="kobo.383.1">The majority of work happens in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1">TAAComputePass::doAA</span></strong><span class="koboSpan" id="kobo.385.1"> function. </span><span class="koboSpan" id="kobo.385.2">This function simply operates the resolve compute pipeline, followed by the pipeline that handles the copying of the history texture and the sharpening of the output color. </span><span class="koboSpan" id="kobo.385.3">We’ve highlighted key components of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.386.1">doAA</span></strong><span class="koboSpan" id="kobo.387.1"> function as follows, omitting </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.388.1">less critical parts to </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">avoid verbosity:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.390.1">
void TAAComputePass::doAA(VkCommandBuffer cmd,
                          int frameIndex,
                          int isCamMoving) {
  pipeline_-&gt;bind(cmd);
  outColorTexture_-&gt;transitionImageLayout(
      cmd, VK_IMAGE_LAYOUT_GENERAL);
  historyTexture_-&gt;transitionImageLayout(
      cmd, VK_IMAGE_LAYOUT_GENERAL);
  vkCmdDispatch(…);
  VkImageMemoryBarrier barriers[2] = {
      {
        …
  };
  vkCmdPipelineBarrier(
      cmd, VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,
      VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT, 0, 0,
      nullptr, 0, nullptr, 2, barriers);
  colorTexture_-&gt;transitionImageLayout(
      cmd, VK_IMAGE_LAYOUT_GENERAL);
  sharpenPipeline_-&gt;bind(cmd);
  vkCmdDispatch(…);
  colorTexture_-&gt;transitionImageLayout(
      cmd,
      VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
  outColorTexture_-&gt;transitionImageLayout(
      cmd,
      VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);
}</span></pre></li> <li><span class="koboSpan" id="kobo.391.1">The actual </span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.392.1">magic happens in the two compute shaders; specifically, the resolve shader is the most important. </span><span class="koboSpan" id="kobo.392.2">The resolve shader is implemented in </span><strong class="source-inline"><span class="koboSpan" id="kobo.393.1">taaresolve.comp</span></strong><span class="koboSpan" id="kobo.394.1">. </span><span class="koboSpan" id="kobo.394.2">Let’s look at how the </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">shaders work.</span></span></li>
<li><span class="koboSpan" id="kobo.396.1">First, we will expand on some auxiliary functions. </span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1">catmullRomTextureFiltering</span></strong><span class="koboSpan" id="kobo.398.1"> helps smooth out the temporal aliasing by blending the colors of pixels between frames, using Catmull-Rom interpolation. </span><span class="koboSpan" id="kobo.398.2">Catmull-Rom interpolation is a form of cubic interpolation that provides a smoother appearance than linear interpolation. </span><span class="koboSpan" id="kobo.398.3">The function uses the Catmull-Rom weights (</span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">w0, w1, w2, w3</span></strong><span class="koboSpan" id="kobo.400.1">) to calculate the weight for the center (</span><strong class="source-inline"><span class="koboSpan" id="kobo.401.1">w12</span></strong><span class="koboSpan" id="kobo.402.1">) and the offset from the center (</span><strong class="source-inline"><span class="koboSpan" id="kobo.403.1">offset12</span></strong><span class="koboSpan" id="kobo.404.1">). </span><span class="koboSpan" id="kobo.404.2">Then, the function calculates three new texture positions (</span><strong class="source-inline"><span class="koboSpan" id="kobo.405.1">texPos0</span></strong><span class="koboSpan" id="kobo.406.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.407.1">texPos3</span></strong><span class="koboSpan" id="kobo.408.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.409.1">texPos12</span></strong><span class="koboSpan" id="kobo.410.1">) and adjusts these positions to match the texture resolution. </span><span class="koboSpan" id="kobo.410.2">The function then uses these weights and texture positions to calculate the resulting pixel color, by accessing the history buffer texture at the specific positions, multiplying the retrieved color by the respective weights, and summing </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">them together.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.412.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">varianceClampColor</span></strong><span class="koboSpan" id="kobo.414.1"> function is used in anti-aliasing TAA to deal with issues of ghosting and blurring that can occur, due to the temporal reprojection of color data. </span><span class="koboSpan" id="kobo.414.2">The function works by limiting the color value of a given pixel, based on the color variance of its surrounding pixels. </span><span class="koboSpan" id="kobo.414.3">It loops over a 3x3 neighborhood around the current pixel. </span><span class="koboSpan" id="kobo.414.4">For each neighboring pixel, the function retrieves its color data (</span><strong class="source-inline"><span class="koboSpan" id="kobo.415.1">neighColor</span></strong><span class="koboSpan" id="kobo.416.1">) and calculates a weight (</span><strong class="source-inline"><span class="koboSpan" id="kobo.417.1">w</span></strong><span class="koboSpan" id="kobo.418.1">), based on the Euclidean distance from the current pixel. </span><span class="koboSpan" id="kobo.418.2">This weight is designed to give closer pixels more influence over the final </span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">color result.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.420.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">calculateBlendFactor</span></strong><span class="koboSpan" id="kobo.422.1"> function is responsible for performing calculations to determine the blend factor of a pixel, based on its velocity and luminance. </span><span class="koboSpan" id="kobo.422.2">Firstly, the pixel movement is calculated on two levels, the overall motion and the tiny subpixel motion, resulting in values called </span><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">subpixelMotion</span></strong><span class="koboSpan" id="kobo.424.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.425.1">dynamicBlendFactor</span></strong><span class="koboSpan" id="kobo.426.1"> respectively. </span><span class="koboSpan" id="kobo.426.2">Then, to adjust the pixel’s brightness or luminance, the difference between the current color and </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.427.1">the previous frame color is determined. </span><span class="koboSpan" id="kobo.427.2">This entire process enhances the realism of the pixel’s movement and color changes over time, significantly improving the overall image quality when there’s movement of objects or camera. </span><span class="koboSpan" id="kobo.427.3">The implementation of </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">catmullRomTextureFiltering</span></strong><span class="koboSpan" id="kobo.429.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">varianceClampColor</span></strong><span class="koboSpan" id="kobo.431.1"> are very verbose; we suggest looking at </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1">taaresolve.comp</span></strong><span class="koboSpan" id="kobo.433.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">implementation details.</span></span></p></li>
<li><span class="koboSpan" id="kobo.435.1">Next, we present the </span><strong class="source-inline"><span class="koboSpan" id="kobo.436.1">main</span></strong><span class="koboSpan" id="kobo.437.1"> function; this helps to produce a smoother, more stable image by reducing flickering and ghosting artifacts that can occur, due to the rapid movement of the camera or objects in a scene. </span><span class="koboSpan" id="kobo.437.2">The following sub-steps will walk you through the specifics of </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">its implementation:</span></span><ol><li class="Alphabets"><span class="koboSpan" id="kobo.439.1">Calculate the closest depth and corresponding velocity around the </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">current pixel:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.441.1">
void main() {
  vec2 velocity;
  const float closestDepth =
      closestVelocityAndDepth(velocity);</span></pre><ol><li class="Alphabets" value="2"><span class="koboSpan" id="kobo.442.1">Reproject the current pixel position to its position in the previous frame using the </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">calculated velocity:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.444.1">  vec2 reprojectedUV = uv - velocity;</span></pre><ol><li class="Alphabets" value="3"><span class="koboSpan" id="kobo.445.1">Calculate </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1">velocityLerp</span></strong><span class="koboSpan" id="kobo.447.1"> using the history buffer at the reprojected location. </span><span class="koboSpan" id="kobo.447.2">Note the use of </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1">taaConstData.isFirstFrame</span></strong><span class="koboSpan" id="kobo.449.1">, which helps to determine whether we are dealing with the first frame of the sequence or not. </span><span class="koboSpan" id="kobo.449.2">If it is the first frame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.450.1">velocityLerp</span></strong><span class="koboSpan" id="kobo.451.1"> is simply initialized to </span><strong class="source-inline"><span class="koboSpan" id="kobo.452.1">0.0f</span></strong><span class="koboSpan" id="kobo.453.1">. </span><span class="koboSpan" id="kobo.453.2">In the context of camera cuts or teleports (i.e., a sudden change from one perspective to another), the first frame assumption is also applicable. </span><span class="koboSpan" id="kobo.453.3">Whenever these events occur, the scene changes dramatically from one frame to another. </span><span class="koboSpan" id="kobo.453.4">In such cases, it’s beneficial to treat the frame right after the cut </span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.454.1">or teleport as a first frame. </span><span class="koboSpan" id="kobo.454.2">This is because the data from the previous frame is no longer a good reference for the current frame, due to the drastic changes in </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">scene content:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.456.1">  float velocityLerp =
      (taaConstData.isFirstFrame != 0)
          ? </span><span class="koboSpan" id="kobo.456.2">texture(inHistoryBuffer,
                    reprojectedUV)
                .w
          : 0.0f;</span></pre><ol><li class="Alphabets" value="4"><span class="koboSpan" id="kobo.457.1">Load the current frame color (</span><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">colorIn</span></strong><span class="koboSpan" id="kobo.459.1">) and calculate </span><strong class="source-inline"><span class="koboSpan" id="kobo.460.1">colorHistory</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.461.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.462.1">catmullRomTextureFiltering</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.464.1">  vec3 colorIn = getColorData(
      ivec2(gl_GlobalInvocationID.xy));
  vec3 colorHistory = catmullRomTextureFiltering(
      reprojectedUV, vec2(workSize));</span></pre><ol><li class="Alphabets" value="5"><span class="koboSpan" id="kobo.465.1">Define two constants, </span><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">boxSizeWhenMoving</span></strong><span class="koboSpan" id="kobo.467.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.468.1">boxSizeWhenStationary</span></strong><span class="koboSpan" id="kobo.469.1">. </span><span class="koboSpan" id="kobo.469.2">We determine value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.470.1">boxSize</span></strong><span class="koboSpan" id="kobo.471.1"> based on whether the camera is moving or not and is interpolated between the stationary and moving values, based </span><span class="No-Break"><span class="koboSpan" id="kobo.472.1">on </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.473.1">velocityLerp</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.475.1">  const float boxSizeWhenMoving = 2000.0f;
  const float boxSizeWhenStationary = 100.0f;
  float boxSize =
      (taaConstData.isCameraMoving == 0)
          ? </span><span class="koboSpan" id="kobo.475.2">boxSizeWhenStationary
          : mix(boxSizeWhenStationary,
                boxSizeWhenMoving, velocityLerp);
  boxSize = mix(
      0.5f, boxSize,
      noGeometry ? </span><span class="koboSpan" id="kobo.475.3">0.0f
                 : smoothstep(0.02f, 0.0f,
                              length(velocity)));</span></pre><ol><li class="Alphabets" value="6"><span class="koboSpan" id="kobo.476.1">Historical </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.477.1">color (</span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">colorHistory</span></strong><span class="koboSpan" id="kobo.479.1">) is then clamped using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">varianceClampColor</span></strong><span class="koboSpan" id="kobo.481.1"> function to ensure that the color is within a certain range, based on the variance of </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">surrounding pixels:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.483.1">  vec3 clampHistory =
      varianceClampColor(colorHistory, boxSize);</span></pre><ol><li class="Alphabets" value="7"><span class="koboSpan" id="kobo.484.1">Calculate </span><strong class="source-inline"><span class="koboSpan" id="kobo.485.1">blendFactor</span></strong><span class="koboSpan" id="kobo.486.1">, which determines how much of the current color and the historical color should be used to get the </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1">final color:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.488.1">  float blendFactor = calculateBlendFactor(
      closestDepth, velocity, noGeometry,
      workSize, colorIn, clampHistory,
      velocityLerp);</span></pre><ol><li class="Alphabets" value="8"><span class="koboSpan" id="kobo.489.1">Compute the final color (</span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1">colorResolve</span></strong><span class="koboSpan" id="kobo.491.1">) as a mix of the clamped historical color and the current color, based on </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1">blendFactor</span></strong><span class="koboSpan" id="kobo.493.1">; also, store </span><strong class="source-inline"><span class="koboSpan" id="kobo.494.1">velocityLerp</span></strong><span class="koboSpan" id="kobo.495.1"> in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.496.1">alpha</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.497.1"> channel:</span></span></li></ol><pre class="source-code"><span class="koboSpan" id="kobo.498.1">  vec3 colorResolve =
      mix(clampHistory, colorIn, blendFactor);
  imageStore(outColorImage,
             ivec2(gl_GlobalInvocationID.xy),
             vec4(colorResolve, velocityLerp));
}</span></pre></li> <li><span class="koboSpan" id="kobo.499.1">Next, we will show how </span><strong class="source-inline"><span class="koboSpan" id="kobo.500.1">taahistorycopyandsharpen.comp</span></strong><span class="koboSpan" id="kobo.501.1"> works; this shader is </span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.502.1">responsible for copying the data into history texture, as well as sharpening the results produced by </span><em class="italic"><span class="koboSpan" id="kobo.503.1">step 5</span></em><span class="koboSpan" id="kobo.504.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.505.1">taaresolve.comp</span></strong><span class="koboSpan" id="kobo.506.1">). </span><span class="koboSpan" id="kobo.506.2">The main function is presented as follows, and the code is simple – it first copies </span><strong class="source-inline"><span class="koboSpan" id="kobo.507.1">incolor</span></strong><span class="koboSpan" id="kobo.508.1"> (which is the image produced by previous </span><em class="italic"><span class="koboSpan" id="kobo.509.1">step 5</span></em><span class="koboSpan" id="kobo.510.1">) into the history texture. </span><span class="koboSpan" id="kobo.510.2">Then, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">sharpen</span></strong><span class="koboSpan" id="kobo.512.1"> method is called. </span><span class="koboSpan" id="kobo.512.2">This method works by first loading pixel colors from the center and four directly adjacent locations (top, left, right, and bottom). </span><span class="koboSpan" id="kobo.512.3">It then uses an unsharp masking technique, which involves subtracting a blurred or </span><em class="italic"><span class="koboSpan" id="kobo.513.1">unsharp</span></em><span class="koboSpan" id="kobo.514.1"> version of the image from the original image to create a mask that represents the detail of the image. </span><span class="koboSpan" id="kobo.514.2">The function applies this mask to enhance the original image, making it appear sharper. </span><span class="koboSpan" id="kobo.514.3">The final color produced by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.515.1">sharpen</span></strong><span class="koboSpan" id="kobo.516.1"> method is stored in </span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">outColorImage</span></strong><span class="koboSpan" id="kobo.518.1">, which is finally copied to the swapchain image. </span><span class="koboSpan" id="kobo.518.2">For the sake of brevity, we’re not detailing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">sharpen</span></strong><span class="koboSpan" id="kobo.520.1"> function here. </span><span class="koboSpan" id="kobo.520.2">However, you can review its implementation in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.521.1">taahistorycopyandsharpen.comp</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.522.1"> file:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.523.1">
void main() {
  vec4 incolor = imageLoad(inColorImage, ivec2(gl_GlobalInvocationID.xy));
  imageStore(outHistory, ivec2(gl_GlobalInvocationID.xy), incolor);
  vec3 color = sharpen();
  imageStore(outColorImage, ivec2(gl_GlobalInvocationID.xy), vec4(color, 1.0f));
}</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.524.1">Despite its </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.525.1">widespread use and numerous benefits, TAA isn’t without </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">its shortcomings:</span></span></p><ul><li><span class="koboSpan" id="kobo.527.1">When object motion uncovers new areas on a screen, these areas are either not present in the history buffer or are inaccurately depicted by the motion vectors. </span><span class="koboSpan" id="kobo.527.2">Additionally, camera rotation and reverse translation can lead to extensive uncovered areas at the </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">screen’s edges.</span></span></li><li><span class="koboSpan" id="kobo.529.1">Features with subpixel dimensions, such as wires, may be missed by a consecutive frame, leading to their absence in motion vectors in the subsequent frame. </span><span class="koboSpan" id="kobo.529.2">Transparent surfaces can generate pixels where the motion vectors from opaque objects don’t align with the overall movement of the objects depicted. </span><span class="koboSpan" id="kobo.529.3">Lastly, shadows and reflections don’t follow the direction of the motion vectors of the surfaces </span><span class="No-Break"><span class="koboSpan" id="kobo.530.1">they shade.</span></span></li></ul></li> </ol>
<p><span class="koboSpan" id="kobo.531.1">When TAA doesn’t work properly, it either results in ghosting (a blurring effect caused by integrating incorrect values) or it exposes the original aliasing, leading to jagged edges, flickering, </span><span class="No-Break"><span class="koboSpan" id="kobo.532.1">and noise.</span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.533.1">See also</span></span></p>
<p><span class="koboSpan" id="kobo.534.1">For further reading and a deeper understanding of TAA, consider exploring the following resources. </span><span class="koboSpan" id="kobo.534.2">These references will provide you with more detailed information, practical applications, and insights into the </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">latest advancements:</span></span></p>
<ul>
<li><a href="https://research.nvidia.com/publication/2019-03_improving-temporal-antialiasing-adaptive-ray-tracing"><span class="No-Break"><span class="koboSpan" id="kobo.536.1">https://research.nvidia.com/publication/2019-03_improving-temporal-antialiasing-adaptive-ray-tracing</span></span></a></li>
<li><a href="https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/temporal-anti-aliasing"><span class="No-Break"><span class="koboSpan" id="kobo.537.1">https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/temporal-anti-aliasing</span></span></a></li>
</ul>
<h1 id="_idParaDest-258"><a id="_idTextAnchor295"/><span class="koboSpan" id="kobo.538.1">Applying DLSS</span></h1>
<p><span class="koboSpan" id="kobo.539.1">DLSS is an AI-powered technology developed by NVIDIA for their RTX series of graphics cards. </span><span class="koboSpan" id="kobo.539.2">DLSS uses </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.540.1">the power of machine learning and AI to increase the resolution of rendered frames by intelligently upscaling lower resolution images in real time. </span><span class="koboSpan" id="kobo.540.2">This results in a high-quality, high-resolution image that requires less computational power to produce. </span><span class="koboSpan" id="kobo.540.3">We can also use DLSS to render frames at a lower base resolution and then use AI to upscale the image to a </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">higher resolution.</span></span></p>
<p><span class="koboSpan" id="kobo.542.1">Note that to use DLSS, you must have an NVIDIA RTX series </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">graphics card.</span></span></p>
<p><span class="koboSpan" id="kobo.544.1">In this recipe, you’ll learn how to apply DLSS, an innovative technique for enhancing the resolution of rendered frames in real time. </span><span class="koboSpan" id="kobo.544.2">You will gain an understanding of how DLSS leverages machine learning and AI to upscale lower-resolution images intelligently, thereby achieving superior image quality with less </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">computational power.</span></span></p>
<h2 id="_idParaDest-259"><a id="_idTextAnchor296"/><span class="koboSpan" id="kobo.546.1">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.547.1">In the repository, DLSS is implemented by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">DLSS</span></strong><span class="koboSpan" id="kobo.549.1"> class, located in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.550.1">source/enginecore/DLSS.hpp</span></strong><span class="koboSpan" id="kobo.551.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.552.1">cpp</span></strong><span class="koboSpan" id="kobo.553.1"> files. </span><span class="koboSpan" id="kobo.553.2">The DLSS example can be launched by running the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.554.1">chapter06_DLSS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.555.1"> executable.</span></span></p>
<p><span class="koboSpan" id="kobo.556.1">DLSS also requires color, depth and velocity textures, the same textures that were used by the </span><span class="No-Break"><span class="koboSpan" id="kobo.557.1">TAA algorithm.</span></span></p>
<h2 id="_idParaDest-260"><a id="_idTextAnchor297"/><span class="koboSpan" id="kobo.558.1">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.559.1">The DLSS is integrated using the </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">following steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.561.1">First, we need to query the device and instance extensions that are required for DLSS; these extensions need to be enabled before Vulkan is initialized. </span><span class="koboSpan" id="kobo.561.2">NVIDIA’s DLSS SDK provides </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">NVSDK_NGX_VULKAN_RequiredExtensions</span></strong><span class="koboSpan" id="kobo.563.1">, which needs to be used to query extensions. </span><span class="koboSpan" id="kobo.563.2">The following code block presents a static function that can append extensions required by DLSS; this needs to be called before initializing the </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">Vulkan device:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.565.1">
void DLSS::requiredExtensions(std::vector&lt;std::string&gt;&amp; instanceExtensions,
                              std::vector&lt;std::string&gt;&amp; deviceExtensions) {
  unsigned int instanceExtCount;
  const char** instanceExt;
  unsigned int deviceExtCount;
  const char** deviceExt;
  auto result = NVSDK_NGX_VULKAN_RequiredExtensions(
      &amp;instanceExtCount, &amp;instanceExt, &amp;deviceExtCount, &amp;deviceExt);
  for (int i = 0; i &lt; instanceExtCount; ++i) {
    if (std::find(instanceExtensions.begin(), instanceExtensions.end(),
                  instanceExt[i]) == instanceExtensions.end()) {
      instanceExtensions.push_back(instanceExt[i]);
    }
  }
  for (int i = 0; i &lt; deviceExtCount; ++i) {
    if (std::find(deviceExtensions.begin(), deviceExtensions.end(),
                  deviceExt[i]) == deviceExtensions.end()) {
      deviceExtensions.push_back(deviceExt[i]);
      if (deviceExtensions.back() ==
          "VK_EXT_buffer_device_address") {  // we are using 1.3, this extension
                                             // has been promoted
        deviceExtensions.pop_back();
      }
    }
  }
}</span></pre></li> <li><span class="koboSpan" id="kobo.566.1">Next, we will look at </span><strong class="source-inline"><span class="koboSpan" id="kobo.567.1">DLSS init</span></strong><span class="koboSpan" id="kobo.568.1"> method. </span><span class="koboSpan" id="kobo.568.2">This method is responsible for initializing </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.569.1">the DLSS feature provided by the NVSDK. </span><span class="koboSpan" id="kobo.569.2">It takes the current width and height of the viewport, an upscale factor, and a reference to a </span><strong class="source-inline"><span class="koboSpan" id="kobo.570.1">CommandQueueManager</span></strong><span class="koboSpan" id="kobo.571.1"> object. </span><span class="koboSpan" id="kobo.571.2">The function first sets the upscale factor and then determines the optimal settings for DLSS, based on the current viewport size and desired quality level. </span><span class="koboSpan" id="kobo.571.3">It then configures DLSS features such as motion vector resolution, frame sharpening, and others based on specific flags. </span><span class="koboSpan" id="kobo.571.4">Finally, it creates the DLSS feature and submits the command to the Vulkan </span><span class="No-Break"><span class="koboSpan" id="kobo.572.1">command buffer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.573.1">
void DLSS::init(int currentWidth, int currentHeight, float upScaleFactor, VulkanCore::CommandQueueManager&amp; commandQueueManager) {
  NVSDK_NGX_Result result = NGX_DLSS_GET_OPTIMAL_SETTINGS(paramsDLSS_, currentWidth, currentHeight, dlssQuality, &amp;optimalRenderWidth, &amp;optimalRenderHeight, &amp;minRenderWidth, &amp;minRenderHeight, &amp;maxRenderWidth, &amp;maxRenderHeight, &amp;recommendedSharpness);
  int dlssCreateFeatureFlags = NVSDK_NGX_DLSS_Feature_Flags_None;
  dlssCreateFeatureFlags |= NVSDK_NGX_DLSS_Feature_Flags_MVLowRes;
  dlssCreateFeatureFlags |= NVSDK_NGX_DLSS_Feature_Flags_DoSharpening;
  NVSDK_NGX_DLSS_Create_Params dlssCreateParams{
      .Feature =
          {
              .InWidth = unsigned int(currentWidth),
              .InHeight = unsigned int(currentHeight),
              .InTargetWidth = unsigned int(currentWidth * upScaleFactor),
              .InTargetHeight = unsigned int(currentHeight * upScaleFactor),
              .InPerfQualityValue = NVSDK_NGX_PerfQuality_Value_MaxQuality,
          },
      .InFeatureCreateFlags = dlssCreateFeatureFlags,
  };
  auto commmandBuffer = commandQueueManager.getCmdBufferToBegin();
  constexpr unsigned int creationNodeMask = 1;
  constexpr unsigned int visibilityNodeMask = 1;
  NVSDK_NGX_Result createDlssResult = NGX_VULKAN_CREATE_DLSS_EXT(commmandBuffer, creationNodeMask, visibilityNodeMask, &amp;dlssFeatureHandle_, paramsDLSS_, &amp;dlssCreateParams);
  ASSERT(createDlssResult == NVSDK_NGX_Result_Success, "Failed to create NVSDK NGX DLSS feature");
  commandQueueManager.endCmdBuffer(commmandBuffer);
  VkSubmitInfo submitInfo{
      .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
      .commandBufferCount = 1,
      .pCommandBuffers = &amp;commmandBuffer,
  };
  commandQueueManager.submit(&amp;submitInfo);
  commandQueueManager.waitUntilSubmitIsComplete();
}</span></pre></li> <li><span class="koboSpan" id="kobo.574.1">The next step is to call DLSS’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.575.1">render</span></strong><span class="koboSpan" id="kobo.576.1"> method, which is responsible for applying DLSS </span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.577.1">to the provided input textures to enhance the image quality. </span><span class="koboSpan" id="kobo.577.2">It takes a Vulkan command buffer and several texture objects as inputs – color, depth, motion vector, and output color texture, along with a 2D vector for the camera jitter. </span><span class="koboSpan" id="kobo.577.3">Firstly, we create resources for each of the input textures using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.578.1">NVSDK_NGX_Create_ImageView_Resource_VK</span></strong><span class="koboSpan" id="kobo.579.1"> function; afterward, we transition the layout of the output color texture to </span><strong class="source-inline"><span class="koboSpan" id="kobo.580.1">VK_IMAGE_LAYOUT_GENERAL</span></strong><span class="koboSpan" id="kobo.581.1"> to prepare it for writing. </span><span class="koboSpan" id="kobo.581.2">Next, this function sets up the parameters for the DLSS evaluation, including input color and output resources, sharpness level, depth resource, motion vector resource, and camera jitter offsets. </span><span class="koboSpan" id="kobo.581.3">The last part is to call </span><strong class="source-inline"><span class="koboSpan" id="kobo.582.1">NGX_VULKAN_EVALUATE_DLSS_EXT</span></strong><span class="koboSpan" id="kobo.583.1"> to apply DLSS to the images, which enhances the image quality, based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.584.1">parameters provided:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.585.1">
void DLSS::render(VkCommandBuffer commandBuffer, VulkanCore::Texture&amp; inColorTexture, VulkanCore::Texture&amp; inDepthTexture, VulkanCore::Texture&amp; inMotionVectorTexture, VulkanCore::Texture&amp; outColorTexture, glm::vec2 cameraJitter) {
  NVSDK_NGX_Resource_VK inColorResource = NVSDK_NGX_Create_ImageView_Resource_VK(
          inColorTexture.vkImageView(), inColorTexture.vkImage(),
          {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}, VK_FORMAT_UNDEFINED,
          inColorTexture.vkExtents().width, inColorTexture.vkExtents().height,
          true);
  NVSDK_NGX_Resource_VK outColorResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);
  NVSDK_NGX_Resource_VK depthResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);
  NVSDK_NGX_Resource_VK motionVectorResource = NVSDK_NGX_Create_ImageView_Resource_VK(…);
  outColorTexture.transitionImageLayout(commandBuffer, VK_IMAGE_LAYOUT_GENERAL);
  NVSDK_NGX_VK_DLSS_Eval_Params evalParams = {
      .Feature =
          {
              .pInColor = &amp;inColorResource,
              .pInOutput = &amp;outColorResource,
              .InSharpness = 1.0,
          },
      .pInDepth = &amp;depthResource,
      .pInMotionVectors = &amp;motionVectorResource,
      .InJitterOffsetX = cameraJitter.x,
      .InJitterOffsetY = cameraJitter.y,
      .InRenderSubrectDimensions =
          {
              .Width =
                  static_cast&lt;unsigned int&gt;(inColorTexture.vkExtents().width),
              .Height =
                  static_cast&lt;unsigned int&gt;(inColorTexture.vkExtents().height),
          },
      .InReset = 0,
      .InMVScaleX = -1.0f * inColorResource.Resource.ImageViewInfo.Width,
      .InMVScaleY = -1.0f * inColorResource.Resource.ImageViewInfo.Height,
      .pInExposureTexture = nullptr,
  };
  NVSDK_NGX_Result result = NGX_VULKAN_EVALUATE_DLSS_EXT(commandBuffer, dlssFeatureHandle_, paramsDLSS_, &amp;evalParams);
  ASSERT(result == NVSDK_NGX_Result_Success, "Failed to evaluate DLSS feature");
  if (result != NVSDK_NGX_Result_Success) {
    auto store = GetNGXResultAsString(result);
  }
}</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.586.1">In the </span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.587.1">next section, we present valuable links for further reading and deeper understanding of </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">the topic.</span></span></p>
<h2 id="_idParaDest-261"><a id="_idTextAnchor298"/><span class="koboSpan" id="kobo.589.1">See also</span></h2>
<p><span class="koboSpan" id="kobo.590.1">For more in-depth knowledge and practical insights on DLSS, the following resource will </span><span class="No-Break"><span class="koboSpan" id="kobo.591.1">prove invaluable:</span></span></p>
<ul>
<li><a href="https://github.com/NVIDIA/DLSS/blob/main/doc/DLSS_Programming_Guide_Release.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.592.1">https://github.com/NVIDIA/DLSS/blob/main/doc/DLSS_Programming_Guide_Release.pdf</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.593.1">In this chapter, we started with Vulkan’s MSAA. </span><span class="koboSpan" id="kobo.593.2">This is a method used to combat the spatial aliasing of high-contrast edges, often seen as jagged or staircase lines in the rendered image. </span><span class="koboSpan" id="kobo.593.3">We discussed the process of enabling MSAA in Vulkan, which involves configuring the multi-sample state during pipeline creation and allocating a separate multi-sample image. </span><span class="koboSpan" id="kobo.593.4">We also covered how MSAA operates by averaging the color of multiple sample points, reducing the jagged appearance, and providing a smoother, more natural look to </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">the edges.</span></span></p>
<p><span class="koboSpan" id="kobo.595.1">Then, we addressed FXAA. </span><span class="koboSpan" id="kobo.595.2">This technique is a screen-space, post-processing method, meaning that </span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.596.1">it works directly on the final image. </span><span class="koboSpan" id="kobo.596.2">Its primary advantage is its speed and simplicity, offering a good trade-off between performance and quality. </span><span class="koboSpan" id="kobo.596.3">FXAA smooths edges by finding high-contrast pixels and blending them with their surroundings. </span><span class="koboSpan" id="kobo.596.4">Despite being an approximation, FXAA can often provide a significant improvement in perceived image quality, particularly in scenes with many </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">high-contrast edges.</span></span></p>
<p><span class="koboSpan" id="kobo.598.1">The third technique we discussed was TAA. </span><span class="koboSpan" id="kobo.598.2">This method uses the concept of temporal reprojection, where it leverages information from previous frames to minimize aliasing artifacts in the current frame. </span><span class="koboSpan" id="kobo.598.3">We covered how TAA operates by accumulating samples over multiple frames and applying a filter to reduce the temporal aliasing effects, such as crawling and flickering. </span><span class="koboSpan" id="kobo.598.4">When implemented correctly, TAA can offer superior results over purely spatial techniques, particularly in scenes with high levels of motion </span><span class="No-Break"><span class="koboSpan" id="kobo.599.1">and detail.</span></span></p>
<p><span class="koboSpan" id="kobo.600.1">Lastly, we explored the cutting-edge technique of DLSS. </span><span class="koboSpan" id="kobo.600.2">Powered by AI, DLSS is a proprietary technology developed by NVIDIA. </span><span class="koboSpan" id="kobo.600.3">It works by training a deep learning model to predict high-resolution images from lower-resolution inputs. </span><span class="koboSpan" id="kobo.600.4">The trained model is then used to upscale images in real time. </span><span class="koboSpan" id="kobo.600.5">We also talked about how DLSS can maintain or even improve visual fidelity while significantly </span><span class="No-Break"><span class="koboSpan" id="kobo.601.1">boosting performance.</span></span></p>
<p><span class="koboSpan" id="kobo.602.1">This chapter provided a comprehensive overview of various anti-aliasing techniques, each with its strengths and use cases. </span><span class="koboSpan" id="kobo.602.2">By understanding these methods, you can make informed choices on which technique to implement, based on the specific needs of your </span><span class="No-Break"><span class="koboSpan" id="kobo.603.1">Vulkan applications.</span></span></p>
</div>
</body></html>