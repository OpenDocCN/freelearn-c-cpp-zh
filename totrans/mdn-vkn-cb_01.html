<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-20"><a id="_idTextAnchor019"/>1</h1>
<h1 id="_idParaDest-21"><a id="_idTextAnchor020"/>Vulkan Core Concepts</h1>
<p>Our goal for this chapter is to implement a simple program that displays a shaded triangle on screen, with the triangle’s vertices and attributes being sourced directly from the shaders. In the process of implementing the code to render this triangle, we will cover most of Vulkan’s fundamental objects, the ones you need to create a very simple application. Although the code required for this minimal example is extensive, the majority of it can be reused and tweaked for other applications. By the end of the chapter, you will know how to bootstrap communication with the driver, how to create and manage basic Vulkan objects, and how to issue rendering commands to the GPU.</p>
<p>In this chapter, following a brief introduction to the Vulkan API, we will cover the following recipes:</p>
<ul>
<li>Calling API functions</li>
<li>Learning about Vulkan objects</li>
<li>Using Volk to load Vulkan functions and extensions</li>
<li>Using Vulkan extensions correctly</li>
<li>Using the Validation Layer for error checking</li>
<li>Enumerating available instance layers</li>
<li>Enumerating available instance extensions</li>
<li>Initializing the Vulkan instance</li>
<li>Creating a surface</li>
<li>Enumerating Vulkan physical devices</li>
<li>Caching the properties of queue families</li>
<li>Enumerating physical device extensions</li>
<li>Reserving queue families</li>
<li>Creating a Vulkan logical device</li>
<li>Retrieving the queue object handle</li>
<li>Creating a command pool</li>
<li>Allocating, recording, and submitting commands</li>
<li>Reusing command buffers</li>
<li>Creating render passes</li>
<li>Creating framebuffers</li>
<li>Creating image views</li>
<li>The Vulkan graphics pipeline</li>
<li>Compiling <a id="_idIndexMarker000"/>shaders to SPIR-V</li>
<li>Dynamic states</li>
<li>Creating a graphics pipeline</li>
<li>Swapchain</li>
<li>Understanding synchronization in the swapchain – fences and semaphores</li>
<li>Populating submission information for presentation</li>
<li>Presenting images</li>
<li>Rendering a triangle</li>
</ul>
<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>Technical requirements</h1>
<p>To successfully run the code featured in this and rest of chapters, your system must meet the following requirements:</p>
<p>A Windows computer equipped with a GPU that supports Vulkan 1.3. We recommend having a machine with at least 16 GB of RAM and a modern graphics card. The code for various chapters was tested with GTX 1080, GTX 1060, RTX 3050, and RTX 4060. Please note that <a href="B18491_07.xhtml#_idTextAnchor299"><em class="italic">Chapter 7</em></a><em class="italic">, Ray Tracing and Hybrid Rendering</em>, requires RTX 3050/4060 series card since it demonstrates use of ray tracing.</p>
<p>To get started, follow these steps:</p>
<ol>
<li>Download and Install Vulkan SDK 1.3.268: Visit the LunarG website at <a href="https://sdk.lunarg.com/sdk/download/1.3.268.0/windows/VulkanSDK-1.3.268.0-Installer.exe">https://sdk.lunarg.com/sdk/download/1.3.268.0/windows/VulkanSDK-1.3.268.0-Installer.exe</a> and download the Vulkan SDK 1.3.268 installer. Run the installer to complete the installation process.</li>
<li>Install Python 3.12: Download the latest version of Python 3.12 from the official Python website and follow the installation instructions provided.</li>
<li>Clone the Repository: Ensure you have Git installed on your computer. If not, download and install Git from <a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a>. Once Git is installed, open a command prompt or terminal and execute git clone <a href="https://github.com/PacktPublishing/The-Modern-Vulkan-Cookbook">https://github.com/PacktPublishing/The-Modern-Vulkan-Cookbook</a> to clone the repository.</li>
<li>Open the Project in Visual Studio 2022: Launch Visual Studio 2022. Navigate to <strong class="bold">File</strong> | <strong class="bold">Open</strong> | <strong class="bold">Folder</strong> and select the folder where you cloned the repository. This action will load the project into Visual Studio.</li>
<li>Build the Project: Within Visual Studio, you can choose to build the project for debugging or release. For learning purposes and when making changes to the code, it’s recommended to use the <strong class="bold">Debug</strong> build configuration. This allows you to step through the code and understand its execution flow. For simply running the executables, you can use the <strong class="bold">Release</strong> build configuration.</li>
</ol>
<p>The project is structured to facilitate easy navigation and understanding of the code examples provided in each chapter. Here’s a detailed guide on how to locate and work with the code:</p>
<p>The project is organized into several key directories, each serving a specific purpose:</p>
<ul>
<li><code>source/chapterX</code>: This directory contains the main source code for each chapter. Replace X with the chapter number you are working on. For example, the source code for this chapter is located in <code>source/chapter1</code>.</li>
<li><code>source/vulkancore</code>: This directory is dedicated to the Vulkan specific code and components. It includes utilities, wrappers, and other Vulkan related functionalities that are used throughout the project.</li>
<li><code>source/enginecore</code>: This directory houses the core engine components that are shared across multiple chapters. These components provide foundational functionality that is reused in various parts of the project.</li>
</ul>
<p>The recipe for this chapter can be run by launching <code>Chapter01_Traingle.exe</code> executable.</p>
<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>Getting to know the Vulkan API</h1>
<p>The Vulkan API, introduced in 2016 by the Khronos Group, is a low-overhead, cross-platform <a id="_idIndexMarker001"/>computing API that is the successor to OpenGL and its variants (WebGL and OpenGL ES). In fact, Vulkan was called <strong class="bold">Next Generation OpenGL</strong> (or <strong class="bold">glNext</strong>) before it <a id="_idIndexMarker002"/>was officially named Vulkan. OpenGL has been around since 1992 and it was the de facto introductory graphics API everyone learned (and learns still today). Allied with its simplicity, OpenGL is ubiquitous even today.</p>
<p>So, how is Vulkan different from OpenGL? It starts with its complexity. Vulkan is intended to provide application authors more control over the graphics hardware so that they can implement a solution that caters to their needs. Applications can implement solutions as simple as they want or as complex as they need. In practice, this means that the application is now responsible for controlling the hardware, making it more complex. The drivers, on the other hand, became simpler. For instance, if an application is really concerned about resource management, it can implement its own resource management algorithms and not rely on the driver’s implementation.</p>
<p>In short, Vulkan offers more fine-grained control over the GPU compared to OpenGL due to its <em class="italic">lower-level</em> nature. It empowers applications to handle tasks that were traditionally managed by graphics drivers, such as initiating communication between the application and the hardware. However, this increased control comes with added complexity. Vulkan abstracts a large part of the GPU-specific implementation, allowing the same code to run on a wide range of GPUs. While it is possible to use device-specific extensions to maximize the computation potential of a particular GPU, these are not necessities but optional choices to optimize performance. In both desktop and mobile environments, managing this complexity to make optimal use of the GPU can be challenging due to the vast array of possibilities.</p>
<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/>Calling API functions</h1>
<p>Due to the <a id="_idIndexMarker003"/>many knobs Vulkan provides to control every little thing that the hardware can do, Vulkan tends to be more verbose than OpenGL. Since the control of every single aspect of the rendering process is now exposed to the application, there is simply more information that needs to be communicated with the graphics driver (mind you, the graphics driver still exists; it’s just simpler than it used to be).</p>
<p>The most prominent pattern used by the Vulkan API is structure-as-parameter. It is used for creating and allocating objects, querying their capabilities and information, describing layouts, and much more. In this pattern, instead of passing all possible values for the creation of an object as parameters of a function, you must stick all that information in a structure provided by the Vulkan SDK and then pass that structure as a parameter to the function.</p>
<p>In this recipe, you will learn how Vulkan functions are expected to be called and how to check their return value.</p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Getting ready</h2>
<p>Creating objects <a id="_idIndexMarker004"/>in Vulkan requires you to fill an instance of a special structure (there’s one for each object you would like to create) and pass it to the creation function, which takes a pointer to a variable that will store the object’s handle upon return. Most functions in the API return a result that can be used to detect errors, and it’s usually a very good idea to do so to catch errors as soon as possible.</p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>How to do it…</h2>
<p>This recipe will show how to create a Vulkan sampler (<code>VkSampler</code>) by calling the <code>vkCreateSampler</code> function and how you can create a macro that can be used to check the return value of Vulkan function calls without repeating the same code over and over again.</p>
<ol>
<li>The following code demonstrates how to create a <code>VkSampler</code> sampler, a Vulkan object that dictates how a texture is sampled in a shader.</li>
<li>Before calling the <code>vkCreateSampler</code> function that creates the sampler, you need to fill a structure called <code>VkSamplerCreateInfo</code> with all the parameters you’d like the new sampler to have.<p class="list-inset">In the example, we are setting its minification and magnification filter types, how the texture coordinates are treated before sampling the texture, and everything else that Vulkan allows to be controlled in an object of this type:</p><pre class="source-code">
VkDevice device;
const VkSamplerCreateInfo samplerInfo = {
      .sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO,
      .magFilter = VK_FILTER_LINEAR,
      .minFilter = VK_FILTER_LINEAR,
      .addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT,
      .addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT,
      .addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT,
      .mipLodBias = 0,
      .anisotropyEnable = VK_FALSE,
      .minLod = 0,
      .maxLod = maxLod,
  };
VkSampler sampler = VK_NULL_HANDLE;
const VkResult result = vkCreateSampler(device, &amp;samplerInfo, nullptr, &amp;sampler);
assert(result == VK_SUCCESS);
VkStructureType</strong> declared by the Vulkan SDK. If you use the wrong value for <code>sType</code>, you won’t get a compilation error, and maybe not even a runtime error. Maybe not even an error at all! Well, at least not while running it on your development machine. As soon as someone else tries your code on their device, then it could crash. Luckily, there is a mechanism that helps us detect this kind of mistake at runtime. It’s called the Validation Layer, and we’re going to talk more about it in this chapter.</pre><p class="list-inset">The last thing to notice about the listing is that while creating objects in Vulkan, the handle to the object is not returned from the function but is stored in a pointer <a id="_idIndexMarker006"/>passed to the function. In our preceding example, the handle to the new sampler will be stored in the variable sampler (the last parameter to the <code>vkCreateSampler</code> function). That’s why we’re passing the address of the local variable to the function.</p><p class="list-inset">The reason for that is that most functions in the API return a result denoting whether the operation was successful or not. In most cases, checking the return value, of type <code>VkResult</code>, against <code>VK_SUCCESS</code> is fine (and displaying a message on screen or terminating), but in a few cases, the result may not represent an irrecoverable error but a situation that needs to be rectified before we can continue.</p></li> <li>This pattern is so common that we use a simple utility macro that checks the return value. If the result is anything different than <code>VK_SUCCESS</code>, it prints a message, along with the stringified error code, and asserts. Check it out:<pre class="source-code">
#define VK_CHECK(func)                                \
  {                                                   \
    const VkResult result = func;                     \
    if (result != VK_SUCCESS) {                       \
      std::cerr &lt;&lt; "Error calling function " &lt;&lt; #func \
                &lt;&lt; " at " &lt;&lt; __FILE__ &lt;&lt; ":"          \
                &lt;&lt; __LINE__ &lt;&lt; ". Result is "         \
                &lt;&lt; string_VkResult(result)            \
                &lt;&lt; std::endl;                         \
      assert(false);                                  \
    }                                                 \
  }</pre></li> </ol>
<p>Vulkan objects <a id="_idIndexMarker007"/>are created almost always the same way: by providing their attributes in a structure, calling a <code>create</code> function, and providing a pointer to store the handle to the newly created object. Most functions return a <code>VkResult</code> value that can be used to check whether the function succeeded or not.</p>
<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>Learning about Vulkan objects</h1>
<p>The Vulkan API is extensive and many times larger than OpenGL (in any way you’d like to measure). Nonetheless, only a handful of very important objects are necessary to write many types <a id="_idIndexMarker008"/>of applications. As mentioned at the beginning of this chapter, the Vulkan API was leveled against the most demanding applications, those that need to control every single minute detail of the hardware to extract the maximum performance. But most applications don’t need all that flexibility and can get by with just the <em class="italic">basics</em>.</p>
<p>In this recipe, you will learn what Vulkan objects are and how they relate to each other.</p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Getting ready</h2>
<p>Objects in <a id="_idIndexMarker009"/>Vulkan are opaque handles, and their types begin with the letters <code>Vk</code>. A Vulkan instance is called <code>VkInstance</code>, a Vulkan device is called <code>VkDevice</code>, and so on. Some objects need an instance of other objects to be created or allocated from. This dependency creates an implicit logical sequence as to object creation. A Vulkan physical device, <code>VkPhysicalDevice</code>, which represents a GPU on the <a id="_idIndexMarker010"/>system, can only be created if a Vulkan instance, <code>VkInstance</code>, already exists. The next section will present a diagram that may be helpful in understanding Vulkan’s capabilities and <em class="italic">when</em> objects may be created.</p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>How to do it…</h2>
<p><em class="italic">Figure 1</em><em class="italic">.1</em> is a summary of what we consider the most important objects in Vulkan; the ones that we cover in this book and that will satisfy most graphics applications. They are also the bare minimum for a simple – but flexible – pr<a id="_idTextAnchor029"/>ogram.</p>
<div><div><img alt="Figure 1.1 – Object dependency in Vulkan" src="img/B18491_01_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Object dependency in Vulkan</p>
<ol>
<li>In the preceding diagram, each node is a Vulkan object with its name on the top half and its <a id="_idIndexMarker011"/>Vulkan type in the bottom half. The diagram also encodes the dependency between the objects, explicit and implicit. The arrows connecting objects denote what an object needs to be created (besides their parameters, which are not depicted there).</li>
<li>Solid arrows are explicit dependencies: an object needs a reference to all objects pointed by the arrows leaving its node. For example, a device needs a reference to a physical device to be created; a buffer view needs a reference to a buffer and the device. Dashed arrows indicate implicit dependencies: a queue object needs a reference to a device, but it doesn’t explicitly need a reference to a physical device, only a queue index to a family of queues, which is obtained from a physical device. It doesn’t need a physical device, but it needs something that is provided by one.</li>
<li>Solid lines with an open arrow at the end denote objects that are allocated from others, generally a pool of those types of objects. A command buffer isn’t created; it is allocated from a command pool (which in turn needs to be created at some point).</li>
<li>This diagram is useful for the beginner because it helps visualize multiple dependencies <a id="_idIndexMarker012"/>that aren’t exactly obvious. The descriptor set is one of those objects: to obtain one, you need a reference to a descriptor set layout. They are not created by the application; they are allocated from a descriptor pool. Finally, a descriptor set references buffers, image views, and samplers. They are not required, and that’s why that type of relation in the diagram represents an optional reference. We’ll talk more about descriptor sets in <a href="B18491_02.xhtml#_idTextAnchor126"><em class="italic">Chapter 2</em></a><em class="italic">, Working with </em><em class="italic">Modern Vulkan.</em></li>
</ol>
<p>In the remainder of this chapter and the next chapter, we will cover the creation of all objects in the diagram in the order that they would usually be implemented. That means starting at the top with the Vulkan instance and moving downward, fulfilling the dependencies represented in the diagram.</p>
<h1 id="_idParaDest-30"><a id="_idTextAnchor030"/>Using Volk to load Vulkan functions and extensions</h1>
<p>Volk <a id="_idIndexMarker013"/>is an open source library created by Arseny Kapoulkine that provides simple <a id="_idIndexMarker014"/>cross-platform support for loading Vulkan <a id="_idIndexMarker015"/>functions. The library provides several <a id="_idIndexMarker016"/>key features, the most important ones being <a id="_idIndexMarker017"/>automatically loading Vulkan’s function pointers and providing cross-platform support.</p>
<p>In this recipe, you will learn how to use Volk to load Vulkan functions and their extensions.</p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor031"/>Getting ready</h2>
<p>Download <a id="_idIndexMarker018"/>Volk from <a href="https://github.com/zeux/volk">https://github.com/zeux/volk</a> and add <code>volk.c</code> to your project and enable the preprocessor defines for your platform, <code>VK_USE_PLATFORM_WIN32_KHR</code>, <code>VK_USE_PLATFORM_XLIB_KHR</code>, <code>VK_USE_PLATFORM_MACOS_MVK</code>, and so on, before including <code>volk.h</code>.</p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor032"/>How to do it…</h2>
<p>Volk <a id="_idIndexMarker019"/>automatically loads Vulkan’s function pointers, so you <a id="_idIndexMarker020"/>don’t have to manually handle <a id="_idIndexMarker021"/>the details of loading them and checking <a id="_idIndexMarker022"/>for available extensions. If you use Volk in your application, do not link against the static version of the Vulkan library (<code>VKstatic.1.lib</code> on Windows) or load the shared library directly (such as <code>vulkan-1.dll</code> on Windows). Volk will do that for you.</p>
<ol>
<li>Call <code>volkInitialize()</code> during the application’s startup process, before any other Vulkan functions are used.</li>
<li>Call <code>volkLoadInstance</code> after the creation of the Vulkan instance. It replaces global function pointers with functions retrieved with <code>vkGetInstanceProcAddr</code>.</li>
<li>Call <code>volkLoadDevice</code> after the creation of the Vulkan logical device. It replaces global function pointers with functions retrieved with <code>vkGetDeviceProcAddr</code>.</li>
</ol>
<h1 id="_idParaDest-33"><a id="_idTextAnchor033"/>Using Vulkan extensions correctly</h1>
<p>Vulkan relies <a id="_idIndexMarker023"/>heavily on extensions. Extensions are functions and types that are part of the <em class="italic">Vulkan Specification</em>; they are provided in addition to the core API but aren’t guaranteed to exist for a particular version of the API. Either they are experimental or vendor- and card-specific and are not guaranteed to be present, either at compile time or runtime. Official extensions are registered with the Khronos Group and are part of the spec, so you can find their documentation there.</p>
<p>Extensions may be introduced to a <em class="italic">Vulkan Specification</em> version and later promoted to the core set of functionalities on a newer version. Or not at all! The functionality to present rendering results to a surface (such as a window on a GUI), for example, is still an extension <a id="_idIndexMarker024"/>even in Vulkan 1.3 (the most recent version as of the writing of this book). If you are curious, here’s a link to it, the <code>VK_KHR_surface</code> device extension:  <a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_surface.html">https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_surface.html</a>.</p>
<p><em class="italic">Figure 1</em><em class="italic">.2</em> offers a high-level over<a id="_idTextAnchor034"/>view of the process:</p>
<div><div><img alt="Figure 1.2 – Vulkan extensions" src="img/B18491_01_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Vulkan extensions</p>
<p>Vulkan version 1.1, for example, contains its core functionality – functions and types present in that version – plus extensions. Some, all, or none of those extensions may be promoted to the core set of functionalities in Vulkan 1.2. Some might be considered deprecated and removed. The same thing happens when the specification is updated to version 1.3: some, all, or none of those extensions may be promoted from version 1.2 to the new version, and some might be deprecated.</p>
<p>In this recipe, we will present the right way to deal with extensions during compile time and during runtime.</p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor035"/>Getting ready</h2>
<p>There are two types of extensions in Vulkan: instance- and device-level extensions. Before using <a id="_idIndexMarker025"/>an extension, you need to check if it is available during compile time and only add code that uses the extension if the extension is available. Generally speaking, you don’t need to check extensions at runtime. You also need to request the instance or device to enable the extensions by providing the name of the extension as a string.</p>
<h2 id="_idParaDest-35"><a id="_idTextAnchor036"/>How to do it…</h2>
<p>In addition to an extension being present at compile time, you need to enable it at the right level (instance or device) and check if it has been enabled just before using it at runtime.</p>
<ol>
<li>The pattern of checking whether a particular extension can be used at compile time and runtime is shown next:<pre class="source-code">
bool isEnabledForDevice(VkDevice device,
                        const std::string &amp;extName) {
  // std::unordered_map&lt;std::string&gt; deviceExtensions;
  return deviceExtensions.contains(extName);
}
  VkDevice device;  // Valid Vulkan Device
#if defined(VK_KHR_win32_surface)
  // VK_KHR_WIN32_SURFACE_EXTENSION_NAME is defined as the string
  // "VK_KHR_win32_surface"
  if (isEnabledForDevice(device, VK_KHR_WIN32_SURFACE_EXTENSION_NAME)) {
    // VkWin32SurfaceCreateInfoKHR struct is available, as well as the
    // vkCreateWin32SurfaceKHR() function
    VkWin32SurfaceCreateInfoKHR surfaceInfo;
  }
#endif</pre></li> <li>Besides new functions and types, the Vulkan SDK offers macros for each extension. Those <a id="_idIndexMarker026"/>macros can be used to check whether they are present, their name, and version. In the preceding listing, a <code>VK_KHR_win32_surface</code> macro is defined and set to <code>1</code> if the extension is available. The <code>VK_KHR_WIN32_SURFACE_EXTENSION_NAME</code> macro defines a <code>const char *</code> as the name of the extension (in this case, it is <code>VK_KHR_win32_surface</code>) and a <code>VK_KHR_WIN32_SURFACE_SPEC_VERSION</code> macro, defined as an integer, that specifies its version number.</li>
<li>Before creating an instance of <code>VkWin32SurfaceCreateInfoKHR</code>, we check if the <code>VK_KHR_win32_surface</code> device extension is present and enabled. The code is guarded by an <code>+#if+</code> directive, and if the extension is present, we proceed to check if it’s enabled at runtime using the <code>VK_KHR_WIN32_SURFACE_EXTENSION_NAME</code> macro.</li>
</ol>
<p>This check is especially important if you are writing cross-platform code. While it may seem obvious that some extensions should be available, they may not be available for all platforms or graphics cards you are planning to support.</p>
<h1 id="_idParaDest-36"><a id="_idTextAnchor037"/>Using the Validation Layer for error checking</h1>
<p>In the spirit of a high-performant, low-overhead API, Vulkan does not perform error-checking <a id="_idIndexMarker027"/>by default. Doing so would incur a performance penalty, which may be unacceptable for some applications. On the other hand, due to Vulkan’s complexity, it is very easy for the application to make mistakes.</p>
<p>To help <a id="_idIndexMarker028"/>application authors detect errors, Vulkan provides layers, which can be enabled during development and later disabled for shipping. That combination isn’t mandatory, as developers don’t have to enable error-detecting layers for testing nor disable them for shipping, although that is the most common scenario.</p>
<p>In this recipe, we will introduce what Vulkan layers are and how their messages are presented, as well as offer tips on how to learn more about the meaning of those messages.</p>
<h2 id="_idParaDest-37"><a id="_idTextAnchor038"/>Getting ready</h2>
<p>Layers are provided with the Vulkan SDK, so if you are using Vulkan, chances are you also have access to layers by default.</p>
<h2 id="_idParaDest-38"><a id="_idTextAnchor039"/>How to do it…</h2>
<p>Layers are implementations of Vulkan functions that can be inserted in the call chain, intercepting entry points into the API. Those implementations can then perform error checking, performance measurements, or even detect possible optimizations.</p>
<p>The Vulkan SDK provides <a id="_idIndexMarker029"/>a few layers that are <strong class="bold">Plug and Play</strong> (<strong class="bold">PnP</strong>). The only work you need to do is find which layers are present and enable them for the Vulkan instance. After that, at runtime, layers should start doing their jobs as soon as you start calling Vulkan functions.</p>
<ol>
<li>The most important layer available in the SDK is the Validation Layer. This layer will validate all Vulkan function calls and their parameters. It also maintains an internal state – which Vulkan does not – to ensure that your application is not missing a synchronization step or using the wrong layouts for images.</li>
<li>As an example, the following message shows a real message displayed by the Validation Layer. Although somewhat cryptic, the message is very useful: it starts by displaying the error ID (<code>VUID-VkSamplerCreateInfo-sType-sType</code>), which you can use to search for it on the web; it also displays the device <a id="_idIndexMarker030"/>associated with the error; and finally, it displays the message ID and text, which informs us, in this example, that <a id="_idIndexMarker031"/>the structure we used to create a sampler (<code>VkSamplerCreateInfo</code>) needs to have its <code>sType</code> member equal to <code>VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO</code>:<pre class="source-code">
VUID-VkSamplerCreateInfo-sType-sType(ERROR / SPEC): msgNum: -129708450 - Validation Error: [ VUID-VkSamplerCreateInfo-sType-sType ] Object 0: handle = 0x1fbd501b6e0, name = Device, type = VK_OBJECT_TYPE_DEVICE; | MessageID = 0xf844ce5e | vkCreateSampler: parameter pCreateInfo-&gt;sType must be VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO. The Vulkan spec states: sType must be VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO (https://vulkan.lunarg.com/doc/view/1.3.236.0/windows/1.3-extensions/vkspec.html#VUID-VkSamplerCreateInfo-sType-sType)
    Objects: 1
        [0] 0x1fbd501b6e0, type: 3, name: Device</pre></li> </ol>
<p>Even the most experienced graphics programmers will face Validation Layer errors. Getting used to how they look and how to figure out what they mean is the first step in writing a Vulkan application that is Validation Layer error-free.</p>
<h1 id="_idParaDest-39"><a id="_idTextAnchor040"/>Enumerating available instance layers</h1>
<p>Enabling an <a id="_idIndexMarker032"/>instance layer is as easy as providing its name as a <code>const char *</code> to the instance creation function. Unfortunately, not all layers exist in all implementations, and we need to check the available ones before trying to enable them.</p>
<p>In this recipe, you will learn how to enumerate the available instance layers and how to transform them into strings so that they are easier to manage.</p>
<h2 id="_idParaDest-40"><a id="_idTextAnchor041"/>Getting ready</h2>
<p>The code snippets shown in this section are part of our <code>Context</code> class.. It encapsulates most of the initialization and object creation functions.</p>
<h2 id="_idParaDest-41"><a id="_idTextAnchor042"/>How to do it…</h2>
<p>Checking the <a id="_idIndexMarker033"/>available extensions is easy to do:</p>
<ol>
<li>First, you need to query the number of extensions using the <code>vkEnumerateInstanceLayerProperties</code> function, create an array of <code>VkLayerProperties</code> big enough to store all extensions, and request their data by issuing a call to the same function again, like this:<pre class="source-code">
uint32_t instanceLayerCount{0};
VK_CHECK(vkEnumerateInstanceLayerProperties(
    &amp;instanceLayerCount, nullptr));
std::vector&lt;VkLayerProperties&gt; layers(
    instanceLayerCount);
VK_CHECK(vkEnumerateInstanceLayerProperties(
    &amp;instanceLayerCount, layers.data()));</pre><p class="list-inset">The second call to <code>vkEnumerateInstanceLayerProperties</code> will store all available layers in the <code>layers</code> vector, which then can be used for querying, diagnostics, and so on.</p></li> <li>With that information in hand, it’s always a good idea to verify whether the layers you are trying to enable are available. Since the instance creation function accepts the name of the layers in <code>const char *</code> format, we need to convert the extension names to strings:<pre class="source-code">
std::vector&lt;std::string&gt; availableLayers;
std::transform(
    layers.begin(), layers.end(),
    std::back_inserter(availableLayers),
    [](const VkLayerProperties&amp; properties) {
      return properties.layerName;
    });</pre></li> <li>Finally, the requested layers need to be filtered according to the available ones. With two <a id="_idIndexMarker034"/>vectors of strings, one for the available layers and one for the requested layers, we can use the following utility function to perform filtering:<pre class="source-code">
std::unordered_set&lt;std::string&gt; filterExtensions(
    std::vector&lt;std::string&gt; availableExtensions,
    std::vector&lt;std::string&gt; requestedExtensions) {
  std::sort(availableExtensions.begin(),
            availableExtensions.end());
  std::sort(requestedExtensions.begin(),
            requestedExtensions.end());
  std::vector&lt;std::string&gt; result;
  std::set_intersection(
      availableExtensions.begin(),
      availableExtensions.end(),
      requestedExtensions.begin(),
      requestedExtensions.end(),
      std::back_inserter(result));
  return std::unordered_set&lt;std::string&gt;(
      result.begin(), result.end());
}</pre></li> </ol>
<p>This function is very handy because instance layers and instance and device extensions are all referred <a id="_idIndexMarker035"/>to by their names as <code>const char*</code>. This function can be applied to filter all layers and extensions you need in Vulkan.</p>
<h1 id="_idParaDest-42"><a id="_idTextAnchor043"/>Enumerating available instance extensions</h1>
<p>The same process of filtering requested layers against available ones should be repeated for instance extensions.</p>
<p>In this <a id="_idIndexMarker036"/>recipe, you will learn how to obtain available instance extensions, how to store them as strings, and how to convert them to pointers to characters so that they can be passed to the Vulkan API.</p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor044"/>Getting ready</h2>
<p>The process is very similar to the one described in the previous recipe, which also includes a utility function to perform an intersection of the available layers and the requested ones.</p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor045"/>How to do it…</h2>
<p>Obtaining a list of extensions is as easy as obtaining the available layers.</p>
<ol>
<li>First, call <code>vkEnumerateInstanceExtensionProperties</code> twice, once to determine how many extensions are available and then one more time to fetch the extens<a id="_idTextAnchor046"/>ions:<pre class="source-code">
uint32_t extensionsCount{0};
vkEnumerateInstanceExtensionProperties(
    nullptr, &amp;extensionsCount, nullptr);
std::vector&lt;VkExtensionProperties&gt;
    extensionProperties(extensionsCount);
vkEnumerateInstanceExtensionProperties(
    nullptr, &amp;extensionsCount,
    extensionProperties.data());
std::vector&lt;std::string&gt; availableExtensions;
std::transform(
    extensionProperties.begin(),
    extensionProperties.end(),
    std::back_inserter(availableExtensions),
    [](const VkExtensionProperties&amp; properties) {
      return properties.extensionName;
    });</pre></li> <li>Finally, we can filter the requested layers and extensions using the list of available <a id="_idIndexMarker037"/>layers and extensions from the previous steps. Notice that we are requesting the Validation Layer and guarding all extensions with a conditional preprocessor block:<pre class="source-code">
const std::vector&lt;std::string&gt;
    requestedInstanceLayers = {
        "VK_LAYER_KHRONOS_validation"};
const std::vector&lt;std::string&gt;
    requestedInstanceExtensions = {
#if defined(VK_KHR_win32_surface)
      VK_KHR_WIN32_SURFACE_EXTENSION_NAME,
#endif
#if defined(VK_EXT_debug_utils),
      VK_EXT_DEBUG_UTILS_EXTENSION_NAME,
#endif
#if defined(VK_KHR_surface)
      VK_KHR_SURFACE_EXTENSION_NAME,
#endif
    };
const auto enabledInstanceLayers =
    filterExtensions(availableLayers,
                      requestedInstanceLayers);
const auto enabledInstanceExtensions =
    filterExtensions(availableExtensions,
                      requestedInstanceExtensions);</pre></li> <li>To pass the <a id="_idIndexMarker038"/>vectors of strings to the API, we need to convert them to vectors of <code>const char*</code> because the API only accepts <code>const char*</code> parameters. We also need to perform the same conversion for the vector of instance layers (which is omitted here for brevity):<pre class="source-code">
std::vector&lt;const char*&gt; instanceExtensions(
    enabledInstanceExtensions.size());
std::transform(enabledInstanceExtensions.begin(),
                enabledInstanceExtensions.end(),
                instanceExtensions.begin(),
                std::mem_fn(&amp;std::string::c_str));</pre></li> </ol>
<p class="callout-heading">Important note</p>
<p class="callout">The <code>instanceExtensions</code> vector must <em class="italic">not</em> outlive the <code>enabledInstanceExtensions</code> vector. As <code>instanceExtensions</code> contains pointers to the strings in <code>enabledInstanceExtensions</code>, once the latter is destroyed, the pointers in <code>instanceExtensions</code> would all be dangling.</p>
<h1 id="_idParaDest-45"><a id="_idTextAnchor047"/>Initializing the Vulkan instance</h1>
<p>To start using Vulkan, we need to create a Vulkan instance. One can think of a Vulkan instance as <a id="_idIndexMarker039"/>a way of initializing the Vulkan library. To create one, you need to provide a set of required and optional information such as application name, engine name, version, and a list of desired layers and extensions.</p>
<p>In this recipe, you will learn how to create a Vulkan instance.</p>
<h2 id="_idParaDest-46"><a id="_idTextAnchor048"/>Getting ready</h2>
<p>Instantiating the <code>VkApplicationInfo</code> structure used to create an instance requires the version of the application and the Vulkan API version. The former can be created using the <code>VK_MAKE_VERSION</code> macro, while the latter can be provided as one of the preprocessor definitions available in the SDK.</p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor049"/>How to do it…</h2>
<p>With all of those in hand, all we need to do is create a Vulkan instance:</p>
<ol>
<li>Create an instance of the <code>VkApplicationInfo</code> structure first:<pre class="source-code">
const VkApplicationInfo applicationInfo_ = {
    .sType = VK_STRUCTURE_TYPE_APPLICATION_INFO,
    .pApplicationName = "Essential Graphics With Vulkan",
    .applicationVersion = VK_MAKE_VERSION(1, 0, 0),
    .apiVersion = VK_API_VERSION_1_3,
};</pre></li> <li>You will also need an instance of the <code>VkInstanceCreateInfo</code> structure with the requested instance layers and extensions. Then, call <code>vkCreateInstance</code>:<pre class="source-code">
const VkInstanceCreateInfo instanceInfo = {
    .sType =
        VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO,
    .pApplicationInfo = &amp;applicationInfo_,
    .enabledLayerCount = static_cast&lt;uint32_t&gt;(
        requestedLayers.size()),
    .ppEnabledLayerNames = requestedLayers.data(),
    .enabledExtensionCount = static_cast&lt;uint32_t&gt;(
        instanceExtensions.size()),
    .ppEnabledExtensionNames =  instanceExtensions.data(),
};
VkInstanc<a id="_idTextAnchor050"/>e instance_{VK_NULL_HANDLE};
VK_CHECK(vkCreateInstance(&amp;instanceInfo, nullptr,
                          &amp;instance_));</pre></li> </ol>
<p>Once the <a id="_idIndexMarker040"/>Vulkan instance has been created, you should keep it stored safely, as it will need to be destroyed before your application exits.</p>
<h1 id="_idParaDest-48"><a id="_idTextAnchor051"/>Creating a surface</h1>
<p>Just as in OpenGL, presenting the final render output to the screen needs support from the windowing system and is platform-dependent. For this reason, the Vulkan Core API does not <a id="_idIndexMarker041"/>contain functions to render the final image to the screen. Those functions and types are extensions. For this recipe, we’ll use the <code>VK_KHR_surface</code> and <code>VK_KHR_swapchain</code> extensions. We will cover only the Windows case here and use the <code>VK_KHR_win32_surface</code> extension.</p>
<p>In this recipe, you will learn how to create a surface for presenting the final output of your rendering.</p>
<h2 id="_idParaDest-49"><a id="_idTextAnchor052"/>Getting ready</h2>
<p>The first step in the process of rendering an image onto the screen starts with the creation of a <code>VkSurfaceKHR</code> object. Since this object is needed while reserving queues from a physical device, this step is done after the instance has been created but before the physical devices are enumerated and before the device is created, as the device needs information about which queue families we will use.</p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor053"/>How to do it…</h2>
<p>Creating a <code>VkSurfaceKHR</code> object is simple but needs support from the windowing system.</p>
<ol>
<li>On Windows, you need an instance handle  to the executable a (<code>HINSTANCE)</code> and a window handle (<code>HWND</code>) for where to present the image. We’re using GLFW, so the <a id="_idIndexMarker042"/>window used by the <code>VkWin32SurfaceCreateInfoKHR</code> structure can be obtained with <code>glfwGetWin32Window(GLFWwindow*)</code>. The handle to the <code>VkSurfaceKHR</code> object is stored in <code>Context::surface_</code>:<pre class="source-code">
const auto window = glfwGetWin32Window(glfwWindow);
#if defined(VK_USE_PLATFORM_WIN32_KHR) &amp;&amp; \
    defined(VK_KHR_win32_surface)
    if (enabledInstanceExtensions_.contains(
            VK_KHR_WIN32_SURFACE_EXTENSION_NAME)) {
      if (window != nullptr) {
        const VkWin32SurfaceCreateInfoKHR ci = {
            .sType =
                VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR,
            .hinstance = GetModuleHandle(NULL),
            .hwnd = (HWND)window,
        };
        VK_CHECK(vkCreateWin32SurfaceKHR(
            instance_, &amp;ci, nullptr, &amp;surface_));
      }
    }
#endif</pre></li> </ol>
<p>The surface <a id="_idIndexMarker043"/>creation varies slightly between platforms, but the process is very similar.</p>
<h1 id="_idParaDest-51"><a id="_idTextAnchor054"/>Enumerating Vulkan physical devices</h1>
<p>Before we can create a device in Vulkan, we need to select a suitable physical device, as a system may <a id="_idIndexMarker044"/>have multiple Vulkan-capable GPUs and we want to choose one with the capabilities required by our application. To do this, we need to enumerate all available physical devices on the system. This can be achieved by calling the <code>vkEnumeratePhysicalDevices</code> function, which returns a list of all physical devices on the system that support the Vulkan API. Once we have the list of physical devices, we can inspect their properties and features using the <code>vkGetPhysicalDeviceProperties</code> and <code>vkGetPhysicalDeviceFeatures</code> functions to determine if they have the required capabilities. Finally, we can choose the most suitable physical device and use it to create a logical device through the <code>vkCreateDevice</code> function.</p>
<p>In this recipe, you will learn how to enumerate all Vulkan-capable devices present in the system so that you can choose one that best fits your needs.</p>
<h2 id="_idParaDest-52"><a id="_idTextAnchor055"/>Getting ready</h2>
<p>In our code, we encapsulate a physical device in a class called <code>VulkanCore::PhysicalDevice</code>, which retrieves a physical device’s properties and stores them for later use.</p>
<p>Also, make sure to check out the <code>Context::choosePhysicalDevice()</code> method if you’d like to use a better heuristic to choose one physical device on systems that have multiple devices that support Vulkan.</p>
<h2 id="_idParaDest-53"><a id="_idTextAnchor056"/>How to do it…</h2>
<p>Enumerating physical devices employs the same pattern used throughout the API, which requires <a id="_idIndexMarker045"/>us to first request the number of items available and then fetch and store them into a vector:</p>
<ol>
<li><code>vkEnumeratePhysicalDevices</code> is called twice, first to query how many objects are available, and a second time to fetch the handles to <code>VkPhysicalDevice</code> objects:<pre class="source-code">
std::vector&lt;PhysicalDevice&gt;
Context::enumeratePhysicalDevices(
    const std::vector&lt;std::string&gt;&amp;
        requestedExtensions) const {
  uint32_t deviceCount{0};
  VK_CHECK(vkEnumeratePhysicalDevices(
      instance_, &amp;deviceCount, nullptr));
  ASSERT(deviceCount &gt; 0,
          "No Vulkan devices found");
  std::vector&lt;VkPhysicalDevice&gt; devices(
      deviceCount);
  VK_CHECK(vkEnumeratePhysicalDevices(
      instance_, &amp;deviceCount, devices.data()));
  std::vector&lt;PhysicalDevice&gt; physicalDevices;
  for (const auto device : devices) {
    physicalDevices.emplace_back(PhysicalDevice(
        device, surface_, requestedExtensions,
        printEnumerations_));
  }
  return physicalDevices;
}</pre></li> </ol>
<p>This method <a id="_idIndexMarker046"/>returns a vector of <code>PhysicalDevice</code> objects. In the code, this list is passed to the <code>Context::choosePhysicalDevice()</code> helper method, which can be used to select an appropriate physical device based on the requested extensions and other GPU capabilities you may need. For the sake of simplicity, we always choose the first physical device from the list.</p>
<h1 id="_idParaDest-54"><a id="_idTextAnchor057"/>Caching the properties of queue families</h1>
<p>In Vulkan, a physical device can have one or more queue families, where each queue family <a id="_idIndexMarker047"/>represents a set of command queues that share certain properties, such as capabilities or usage. <em class="italic">Figure 1</em><em class="italic">.3</em> depicts a f<a id="_idTextAnchor058"/>ictional set of families and their queues:</p>
<div><div><img alt="Figure 1.3 – Queue families and their queues" src="img/B18491_01_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Queue families and their queues</p>
<p>Each queue family supports a specific set of operations and commands that can be executed in parallel. For example, there may be a graphics queue family, a compute queue family, and a transfer queue family, each optimized for different types of operations.</p>
<p>In this recipe, you will learn how to retrieve the properties of a queue family and where they are stored in the code in the repository.</p>
<h2 id="_idParaDest-55"><a id="_idTextAnchor059"/>Getting ready</h2>
<p>In the repository provided with this book, queue families and their properties are stored and managed by the <code>VulkanCore::PhysicalDevice</code> class.</p>
<h2 id="_idParaDest-56"><a id="_idTextAnchor060"/>How to do it…</h2>
<p>Each queue family has its own set of properties, such as the number of queues, the type of operations <a id="_idIndexMarker048"/>it can perform, and the priority of the queues. When creating a logical device, we must specify which queue families and how many queues of each type we want to use.</p>
<ol>
<li>To query the queue families available and their properties, use the <code>vkGetPhysicalDeviceQueueFamilyProperties</code> function:<pre class="source-code">
uint32_t queueFamilyCount{0};
vkGetPhysicalDeviceQueueFamilyProperties(
    physicalDevice_, &amp;queueFamilyCount, nullptr);
queueFamilyProperties_.resize(queueFamilyCount);
vkGetPhysicalDeviceQueueFamilyProperties(
    physicalDevice_, &amp;queueFamilyCount,
    queueFamilyProperties_.data());</pre></li> </ol>
<p>The properties of the families are stored in <code>std::vector&lt;VkQueueFamilyProperties&gt; PhysicalDevice::queueFamilyProperties_</code>.</p>
<h1 id="_idParaDest-57"><a id="_idTextAnchor061"/>Enumerating physical device extensions</h1>
<p>Physical device <a id="_idIndexMarker049"/>extensions must be explicitly enabled by the application and may only be available on specific physical devices or device drivers. It’s important to check for the availability of required extensions and to gracefully handle situations where extensions are not supported.</p>
<p>In this recipe, you will learn how to enumerate all physical device extensions and how to convert and store them to strings for later use.</p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor062"/>Getting ready</h2>
<p>Enumerating physical device extensions is managed by the <code>VulkanCore::PhysicalDevice</code> class.</p>
<h2 id="_idParaDest-59"><a id="_idTextAnchor063"/>How to do it…</h2>
<p>Obtaining all <a id="_idIndexMarker050"/>physical device extensions for a physical device is simple. Here, we also provide code to store them as strings so that they are easier to work with.</p>
<ol>
<li>Enumerating all physical device extensions is done by using the <code>vkEnumerateDeviceExtensionProperties</code> function. The result is an array of <code>VkExtensionProperties</code>. This structure contains information such as the extension name, version, and a brief description of the extension’s purpose:<pre class="source-code">
uint32_t propertyCount{0};
VK_CHECK(vkEnumerateDeviceExtensionProperties(
    physicalDevice_, nullptr, &amp;propertyCount,
    nullptr));
std::vector&lt;VkExtensionProperties&gt; properties(
    propertyCount);
VK_CHECK(vkEnumerateDeviceExtensionProperties(
    physicalDevice_, nullptr, &amp;propertyCount,
    properties.data()));</pre></li> <li>Convert the extension’s name to <code>std::string</code>:<pre class="source-code">
std::transform(
    properties.begin(), properties.end(),
    std::back_inserter(extensions_),
    [](const VkExtensionProperties&amp; property) {
      return std::string(property.extensionName);
    });</pre></li> <li>This array <a id="_idIndexMarker051"/>is processed so that we end up with only the names of the extensions as strings. Further processing filters the requested extensions against the available ones using our <code>filterExtensions</code> utility function and stores them in <code>std::unordered_set&lt;std::string&gt;  </code><code>PhysicalDevice::enabledExtensions_</code>:<pre class="source-code">
enabledExtensions_ = util::filterExtensions(
    extensions_, requestedExtensions);</pre></li> </ol>
<p>In summary, mastering the enumeration of physical device extensions is an important aspect of Vulkan. It ensures optimal utilization of your device’s capabilities.</p>
<h1 id="_idParaDest-60"><a id="_idTextAnchor064"/>Reserving queue families</h1>
<p>In Vulkan, a queue family is a group of one or more queues that share common properties, such as the type of operations they can perform. When creating a Vulkan device, we must <a id="_idIndexMarker052"/>specify which queue families we want to use and how many queues of each family we need.</p>
<p>For rendering and presentation, we typically need at least one graphics queue family, which is responsible for executing graphics commands. Additionally, we may require a compute queue family for executing compute workloads and a transfer queue family for handling data transfers.</p>
<p>In this recipe, you will learn how to find queue families based on their properties and how to select a queue family that supports presentation, which can be used to present the final render output on the screen.</p>
<h2 id="_idParaDest-61"><a id="_idTextAnchor065"/>Getting ready</h2>
<p>In the repository, reserving queues is encapsulated by the <code>VulkanCore::PhysicalDevice</code> class.</p>
<h2 id="_idParaDest-62"><a id="_idTextAnchor066"/>How to do it…</h2>
<p>One additional step necessary before creating a Vulkan device is to gather the indices to the queue families we’d like to use. For that, we created a <code>PhysicalDevice::reserveQueues()</code> method in the <code>PhysicalDevice</code> class to handle the process, which takes the type of queues we’d like to reserve as a parameter. It also <a id="_idIndexMarker053"/>takes a handle to a Vulkan surface (<code>VkSurfaceKHR</code>), which we will use later to verify whether a queue supports presentation, necessary to display the final render on the screen.</p>
<ol>
<li>We iterate over the queue families properties, stored in <code>queueFamilyProperties_</code>, and store the index to the queue family index if its type has been requested:<pre class="source-code">
uint32_t graphicsFamilyIndex{UINT32_MAX};
uint32_t presentationFamilyIndex{UINT32_MAX};
for (uint32_t queu<a id="_idTextAnchor067"/>eFamilyIndex = 0;
      queueFamilyIndex &lt;
          queueFamilyProperties_.size() &amp;&amp;
      requestedQueueTypes != 0;
      ++queueFamilyIndex) {
  if (graphicsFamilyIndex == UINT32_MAX &amp;&amp;
      (queueFamilyProperties_[queueFamilyIndex]
            .queueFlags &amp;
        VK_QUEUE_GRAPHICS_BIT)) {
    graphicsFamilyIndex = queueFamilyIndex;
  }</pre></li> <li>To detect if a queue family supports presentation, we use the <code>vkGetPhysicalDeviceSurfaceSupportKHR</code> function, guarded by the preprocessor macros:<pre class="source-code">
#if defined(VK_KHR_surface)
  if (enabledInstanceExtensions_.contains(
          VK_KHR_SURFACE_EXTENSION_NAME)) {
    if (presentationFamilyIndex == UINT32_MAX &amp;&amp;
        surface != VK_NULL_HANDLE) {
      VkBool32 supportsPresent{VK_FALSE};
      vkGetPhysicalDeviceSurfaceSupportKHR(
          physicalDevice_, queueFamilyIndex,
          surface, &amp;supportsPresent);
      if (supportsPresent == VK_TRUE) {
        presentationFamilyIndex = queueFamilyIndex;
      }
    }
  }
#endif
}</pre></li> </ol>
<p>The indices <a id="_idIndexMarker054"/>of other types of queue families may be obtained in a similar manner.</p>
<h1 id="_idParaDest-63"><a id="_idTextAnchor068"/>Creating a Vulkan logical device</h1>
<p>A Vulkan device <a id="_idIndexMarker055"/>is a logical representation of a physical GPU. It’s an object that is associated with a selected physical device (an existing GPU in the system) and is used to perform all graphics and compute operations. The device also provides access to physical GPU capabilities through queues. Queues are used to submit commands to the GPU, such as draw calls or memory transfers. The device also provides access to other Vulkan objects, such as pipelines, buffers, and images.</p>
<p>In this recipe, you will learn how to create a Vulkan logical device.</p>
<h2 id="_idParaDest-64"><a id="_idTextAnchor069"/>Getting ready</h2>
<p>The code in <a id="_idIndexMarker056"/>this recipe is available as part of the <code>VulkanCore::Context</code> class in the repository. The <code>Context</code> class represents a Vulkan logical device.</p>
<h2 id="_idParaDest-65"><a id="_idTextAnchor070"/>How to do it…</h2>
<p>To create a Vulkan device, we need to provide a physical device and the indices of the queue families we want to use. Using this information, we can create a vector of <code>VkDeviceQueueCreateInfo</code> structures, which determines the number of queues we want to use from each family and their respective priorities.</p>
<ol>
<li>The most common use case for creating a device is to use one queue per family and set its priority to <code>1</code>:<pre class="source-code">
auto physicalDevice_ = enumeratePhysicalDevices(
    requestedExtensions)[0];
// Retrieves a vector of (queue family indices and
// their number)
const vector&lt;uint32_t&gt; familyIndices =
    physicalDevice_.reservedFamilies();
std::vector&lt;VkDeviceQueueCreateInfo&gt;
    queueCreateInfos;
float priority{1.0f};
for (const auto&amp; queueFamilyIndex :
      familyIndices) {
  queueCreateInfos.emplace_back(
      VkDeviceQueueCreateInfo{
          .sType =
              VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
          .queueFamilyIndex = queueFamilyIndex,
          .queueCount = 1,
          .pQueuePriorities = &amp;priority,
      });
  ++index;
}</pre></li> <li>The list of <a id="_idIndexMarker057"/>requested device extensions is converted from strings to <code>const char*</code>, filtered against the available extensions, and added to the <code>VkDeviceCreateInfo</code> structure, along with the index of the families we’d like to use and the layers we’d like to enable:<pre class="source-code">
std::vector&lt;const char*&gt; deviceExtensions(
    physicalDevice_.enabledExtensions().size());
std::transform(
    physicalDevice_.enabledExtensions().begin(),
    physicalDevice_.enabledExtensions().end(),
    deviceExtensions.begin(),
    std::mem_fn(&amp;std::string::c_str));
const VkDeviceCreateInfo dci = {
    .sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO,
    .queueCreateInfoCount = static_cast&lt;uint32_t&gt;(
        queueCreateInfos.size()),
    .pQueueCreateInfos = queueCreateInfos.data(),
    .enabledLayerCount = static_cast&lt;uint32_t&gt;(
        requestedLayers.size()),
    .ppEnabledLayerNames = requestedLayers.data(),
    .enabledExtensionCount = static_cast&lt;uint32_t&gt;(
        deviceExtensions.size()),
    .ppEnabledExtensionNames =
        deviceExtensions.data(),
};
VK_CHECK(vkCreateDevice(
    physicalDevice_.vkPhysicalDevice(), &amp;dci,
    nullptr, &amp;device_));</pre></li> </ol>
<p>A Vulkan device <a id="_idIndexMarker058"/>is one of the most important objects you need, as it’s needed to create almost every other Vulkan object there is.</p>
<h1 id="_idParaDest-66"><a id="_idTextAnchor071"/>Retrieving the queue object handle</h1>
<p>Once the <a id="_idIndexMarker059"/>logical device has been created, we need to obtain the handle to queues. That is accomplished with the <code>vkGetDeviceQueue</code> function. This handle will be used to submit command buffers for processing on the GPU.</p>
<p>In this recipe, you will learn how to obtain the handle to a Vulkan queue.</p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor072"/>Getting ready</h2>
<p>In the repository, all queues are retrieved and stored by the <code>VulkanCore::Context</code> class. That class maintains a list for each type of queue: graphics, compute, transfer, and sparse, along with a special queue for presentation.</p>
<h2 id="_idParaDest-68"><a id="_idTextAnchor073"/>How to do it…</h2>
<p>To retrieve <a id="_idIndexMarker060"/>the handle to a queue, just call the <code>vkGetDeviceQueue</code> function with the queue family index and the queue index:</p>
<pre class="source-code">
VkQueue queue{VK_NULL_HANDLE};
uint32_t queueFamilyIndex; // valid queue family
vkGetDeviceQueue(device, queueFamilyIndex, 0, &amp;queue);</pre> <p>Knowing which queue families are available is not enough. Once we determine which queues are available and the queues we need, we request the handle to one of the queues from the family using the API presented in this recipe.</p>
<h1 id="_idParaDest-69"><a id="_idTextAnchor074"/>Creating a command pool</h1>
<p><strong class="bold">Command buffers</strong> provide the <a id="_idIndexMarker061"/>ability to record graphics and compute commands, while command queues allow those buffers to be submitted to the hardware. Commands recorded in the command buffers are then executed by the GPU.</p>
<p>Each queue is <a id="_idIndexMarker062"/>associated with a specific queue family, which defines the capabilities of the queue. For example, a queue family may only support graphics operations, or it may support both graphics and compute operations. The number of families and their capabilities can be retrieved using the <code>vkGetPhysicalDeviceQueueFamilyProperties</code> function, discussed in the <em class="italic">Caching the properties of queue families</em> recipe. A queue family may contain one or more queues.</p>
<p>Command buffers are containers for the actual commands that are executed by the GPU. To record commands, you allocate a command buffer, then use the <code>vkCmd*</code> family of functions to record the commands into them. Once the commands have been recorded, the command buffer can be submitted to a command queue for execution.</p>
<p>Command buffers are allocated from a command pool, which in turn is created from a device and is associated with a specific queue family.</p>
<p>In this recipe, you will learn how to create a command pool.</p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor075"/>Getting ready</h2>
<p>Command pools and allocating and submitting command buffers is managed by the <code>VulkanCore:: </code><code>CommandQueueManager</code> class.</p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor076"/>How to do it…</h2>
<p>Creating a <a id="_idIndexMarker063"/>command pool is easy. All you need is the queue family index and a creation flag. The <code>VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT</code> flag is enough for our purposes.</p>
<p>To create a command pool, use the <code>vkCreateCommandPool</code> function. The <code>VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT</code> flag means that each command buffer allocated from this pool may be reset individually or implicitly by calling <code>vkCmdBeginCommandBuffer</code>:</p>
<pre class="source-code">
uint32_t queueFamilyIndex; // Valid queue family index
const VkCommandPoolCreateInfo commandPoolInfo = {
    .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
    .flags =
      VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT,
    .queueFamilyIndex = queueFamilyIndex,
};
VkCommandPool commandPool{VK_NULL_HANDLE};
VK_CHECK(
    vkCreateCommandPool(device, &amp;commandPoolInfo,
                        nullptr, &amp;commandPool));</pre> <p>With a command pool object, you can start allocating command buffers for recording commands.</p>
<h1 id="_idParaDest-72"><a id="_idTextAnchor077"/>Allocating, recording, and submitting commands</h1>
<p>Command buffers are allocated from command pools using the <code>vkAllocateCommandBuffers</code> function. Command buffers must be initialized with the <code>vkBeginCommandBuffer</code> function before being recorded into the buffer and prepared <a id="_idIndexMarker064"/>for submission with <code>vkEndCommandBuffer</code>. Commands are <a id="_idIndexMarker065"/>recorded into the buffer between those function calls <a id="_idIndexMarker066"/>and are executed only after the command buffer is submitted to the device with <code>vkQueueSubmit</code>.</p>
<p>In this recipe, you will learn how to allocate command buffers, how to record commands in the command buffer, and how to submit them for execution on the GPU.</p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor078"/>Getting ready</h2>
<p>Command buffers are allocated from the <code>VulkanCore::CommandQueueManager</code> class and submitted using the same class. <code>VulkanCore::CommandQueueManager</code> provides basic functions to maintain a set of command buffers for processing.</p>
<h2 id="_idParaDest-74"><a id="_idTextAnchor079"/>How to do it…</h2>
<p>A command buffer’s life cycle starts with its allocation from a command pool. Once it has started, commands can be recorded into it. Before submission, you need to explicitly message them that recording has ended. They can then be submitted for execution:</p>
<ol>
<li>To allocate command buffers, you call <code>vkAllocateCommandBuffers</code>, passing in the command pool, the number of buffers you want to allocate, and a pointer to a structure that specifies the properties of the command buffers:<pre class="source-code">
const VkCommandBufferAllocateInfo commandBufferInfo = {
        .sType =
            VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
        .commandPool = commandPool_,
        .level = VK_COMMAND_BUFFER_LEVEL_PRIMARY,
        .commandBufferCount = 1,
    };
    VkCommandBuffer cmdBuffer{VK_NULL_HANDLE};
    VK_CHECK(vkAllocateCommandBuffers(
        device, &amp;commandBufferInfo, &amp;cmdBuffer));</pre></li> <li>After successfully <a id="_idIndexMarker067"/>allocating a command buffer, the recording <a id="_idIndexMarker068"/>of Vulkan commands can begin. The recording <a id="_idIndexMarker069"/>process is initiated through a call to the <code>vkBeginCommandBuffer</code> function, with parameters including the command buffer and a pointer to a structure that defines recording properties. Once recording is completed, the <code>vkEndCommandBuffer</code> function is called to finalize the process:<pre class="source-code">
const VkCommandBufferBeginInfo info = {
      .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
      .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT,
};
VK_CHECK(vkBeginCommandBuffer(cmdBuffer, &amp;info));</pre><p class="list-inset">Here are some examples of commonly used commands that can be recorded in a Vulkan command buffer:</p><ul><li><code>vkCmdBindPipeline</code>: Binds a pipeline to the command buffer. This command sets the current pipeline state for subsequent draw calls.</li><li><code>vkCmdBindDescriptorSets</code>: Binds descriptor sets to the command buffer. Descriptor sets hold references to buffer and image resources that can be used by shaders.</li><li><code>vkCmdBindVertexBuffers</code>: Binds vertex buffers to the command buffer. Vertex buffers contain the vertex data for a mesh.</li><li><code>vkCmdDraw</code>: Executes a draw call, which processes vertices and rasterizes the resulting pixels.</li><li><code>vkCmdDispatch</code>: Executes a compute shader.</li><li><code>vkCmdCopyBuffer</code>: Copies data from one buffer to another.</li><li><code>vkCmdCopyImage</code>: Copies data from one image to another.</li></ul></li> <li>Once you <a id="_idIndexMarker070"/>are done recording commands, you must call <code>vkEndCommandBuffer</code>:<pre class="source-code">
VK_CHECK(vkEndCommandBuffer(cmdBuffer));</pre></li> <li>Once a <a id="_idIndexMarker071"/>command buffer has been recorded, it still lives in your <a id="_idIndexMarker072"/>application and needs to be submitted to the GPU for processing. That is accomplished by the <code>vkQueueSubmit</code> function:<pre class="source-code">
VkDevice device;  // Valid Vulkan Device
VkQueue queue;  // Valid Vulkan Queue
VkFence fence{VK_NULL_HANDLE};
const VkFenceCreateInfo fenceInfo = {
    .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
    .flags = VK_FENCE_CREATE_SIGNALED_BIT,
};
VK_CHECK(vkCreateFence(device, &amp;fenceInfo, nullptr,
                        &amp;fence));
const VkSubmitInfo submitInfo = {
    .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
    .commandBufferCount = 1,
    .pCommandBuffers = cmdBuffer,
};
VK_CHECK(
    vkQueueSubmit(queue, 1, submitInfo, fence));</pre></li> </ol>
<p>In the <a id="_idIndexMarker073"/>preceding code, the fence is a specific Vulkan object that facilitates synchronization between the GPU and the CPU. The <code>vkQueueSubmit</code> function is <a id="_idIndexMarker074"/>an asynchronous operation that does not block the application. Therefore, once a command buffer is submitted, we can only determine whether it <a id="_idIndexMarker075"/>has been processed by checking the status of the fence using functions such as <code>vkGetFenceStatus</code> or <code>vkWaitForFences</code>. See the <em class="italic">Understanding synchronization in the swapchain – fences and semaphores</em> recipe to understand how fences can be used to synchronize your application and the execution of commands submitted to the GPU.</p>
<h1 id="_idParaDest-75"><a id="_idTextAnchor080"/>Reusing command buffers</h1>
<p>Command buffers <a id="_idIndexMarker076"/>can be recorded once and submitted multiple times. They can also be used once and reset before the next use or just recorded, submitted, and discarded.</p>
<p>In this recipe, you will learn how to reuse a command buffer without creating a race condition between your application and the GPU.</p>
<h2 id="_idParaDest-76"><a id="_idTextAnchor081"/>Getting ready</h2>
<p>The code provided in <code>VulkanCore::CommandQueueManager</code> doesn’t synchronize command buffers but provides functions to help you do so, such as <code>goToNextCmdBuffer</code>, <code>waitUntilSubmitIsComplete</code>, and <code>waitUntilAllSubmitsAreComplete</code>.</p>
<h2 id="_idParaDest-77"><a id="_idTextAnchor082"/>How to do it…</h2>
<p>Using command buffers can be accomplished in two ways:</p>
<ol>
<li>Create a command buffer and reuse it indefinitely. In this case, once the command buffer is submitted, you must wait for it to be processed before starting to <a id="_idIndexMarker077"/>record new commands. One way to guarantee that the buffer has finished being processed is by checking the status of the fences associated with it. If the fence is to be reused, you need to reset its state as well:<pre class="source-code">
VkDevice device; // Valid Vulkan Device
VK_CHECK(vkWaitForFences(device, 1, &amp;fences, true,
                         UINT32_MAX));
VK_CHECK(vkResetFences(device, 1, &amp;fences));</pre><p class="list-inset"><em class="italic">Figure 1</em><em class="italic">.4</em> shows the case where the command buffer submitted for processing is reused immediately after being submitted for processing on the GPU. Without any form of synchronization, reusing the command buffer wil<a id="_idTextAnchor083"/>l result in a race condition, as it may be still processing in the GPU:</p></li> </ol>
<div><div><img alt="Figure 1.4 – Recording and submitting command buffers without using fences" src="img/B18491_01_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Recording and submitting command buffers without using fences</p>
<p class="list-inset">By using fences, as depicted in <em class="italic">Figure 1</em><em class="italic">.5</em>, it’s possible to prevent a race condition by checking the state of the fence associated with a command buffer before reusing it. If the fence has been signaled, no wait is necessary, but if the fence has <a id="_idIndexMarker078"/>not been signaled before reusing a command buf<a id="_idTextAnchor084"/>fer, the application must wait for it to be signaled before continuing:</p>
<div><div><img alt="Figure 1.5 – Recording and submitting command buffers using fences" src="img/B18491_01_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – Recording and submitting command buffers using fences</p>
<ol>
<li value="2">Allocate command buffers as needed. This is the easiest approach. Whenever you need to record and submit commands, just allocate a new command buffer from the pool, record commands, submit it, and forget about it. In this case, you need to pass the <code>VK_COMMAND_POOL_CREATE_TRANSIENT_BIT</code> flag when creating the command pool. You might still need a fence associated with the buffer if you need to track the state of resources used by the commands in that buffer.</li>
</ol>
<p>Limiting the number of command buffers your application uses is a good practice that can help reduce the amount of memory your program needs.</p>
<h1 id="_idParaDest-78"><a id="_idTextAnchor085"/>Creating render passes</h1>
<p>A render pass <a id="_idIndexMarker079"/>object represents a series of rendering operations that read from and write to images. It’s a high-level abstraction that helps the GPU optimize the rendering process. An attachment in Vulkan is a reference to an image that is used as a target during a render pass. Attachments can be color attachments (for storing color information) or depth or stencil attachments (for storing depth/stencil information).<a id="_idTextAnchor086"/> <em class="italic">Figure 1</em><em class="italic">.6</em> shows an overview of what a render pass object consists of:</p>
<div><div><img alt="Figure 1.6 – Render pass and framebuffer composition" src="img/B18491_01_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6 – Render pass and framebuffer composition</p>
<p>The <code>VkAttachmentDescription</code> structure is used when creating a render pass in Vulkan to define the properties of each attachment. The <code>initialLayout</code> and <code>finalLayout</code> fields play a crucial role in optimizing the usage of attachments and layout transitions <a id="_idIndexMarker080"/>during the render pass execution. By setting the initial and final layouts correctly, you can avoid using additional pipeline barriers to transition image layouts, as these transitions are automatically managed by the render pass execution. For example, if you can have a color attachment that is initially in the <code>VK_IMAGE_LAYOUT_UNDEFINED</code> layout and should transition to the <code>VK_IMAGE_LAYOUT_PRESENT_SRC_KHR</code> layout at the end of the render pass, you can set the <code>initialLayout</code> and <code>finalLayout</code> fields accordingly. This eliminates the need for an explicit pipeline barrier to handle the transition, as the render pass will automatically perform the layout transition as part of its execution.</p>
<p>A subpass is a part of a render pass that performs a specific rendering operation. Attachments are loaded for each subpass, read and/or written to, and finally stored at the end of the subpass. Load and store operations define whether an attachment’s contents should be loaded, cleared, or not cared about (which means the driver/hardware is free to choose what to do – or what not to do) while being loaded and whether they should be stored or not cared about when stored at the end of the pass. They have a significant impact on performance, especially on mobile GPUs. For mobile GPUs, minimizing the number of load/store operations can lead to significant performance improvements. By using <code>VK_ATTACHMENT_LOAD_OP_DONT_CARE</code> and <code>VK_ATTACHMENT_STORE_OP_DONT_CARE</code> when possible, we can avoid unnecessary memory bandwidth usage, which is a common bottleneck on mobile devices.</p>
<p>A subpass dependency describes the order in which subpasses should be executed and the synchronization <a id="_idIndexMarker081"/>required between them. On mobile GPUs, using multiple subpasses can help reduce memory bandwidth usage by keeping intermediate data in on-chip memory (tile-based rendering). This avoids the need to write and read back data from the main memory, which can be expensive in terms of power consumption and performance.</p>
<p>Vulkan also supports render pass compatibility, which allows a framebuffer created for one render pass to be used with another compatible render pass, enhancing resource utilization and performance. Compatibility requires matching attachment counts, formats, load/store operations, sample counts, and compatible layouts; however, subpass structures can differ.</p>
<p>In this recipe, you will learn how to create render passes.</p>
<h2 id="_idParaDest-79"><a id="_idTextAnchor087"/>Getting ready</h2>
<p>The creation of a render pass isn’t complicated but requires an assortment of information that is easier to manage if encapsulated in its own class. This way, the destructor of the class can take care of destroying the object at the right time, without us having to add code to deal with its destruction.</p>
<p>Render passes are wrapped by the <code>VulkanCore::RenderPass</code> class in the code provided with the book.</p>
<h2 id="_idParaDest-80"><a id="_idTextAnchor088"/>How to do it…</h2>
<p>Creating a render pass needs a list of all attachments that will be used in that pass, along with their load and store operations and the final layout desired for each one of the attachments. A render pass must be associated with a type of pipeline (graphics, compute, and so on), so the constructor also takes a value of type <code>VkPipelineBindPoint</code>.</p>
<p>The following code sample shows one of the constructors of the <code>VulkanCore::RenderPass</code> class. Be aware that we have not yet introduced Vulkan images (which are encapsulated in the <code>Texture</code> class in the code). We will discuss images in more detail in <a href="B18491_02.xhtml#_idTextAnchor126"><em class="italic">Chapter 2</em></a><em class="italic">, Working with Modern Vulkan,</em> in the <em class="italic">Creating images (</em><em class="italic">textures)</em> recipe.</p>
<ol>
<li>The constructor iterates over all attachments that will be used in the render pass and creates a <code>VkAttachmentDescription</code> structure for each one. This structure contains basic information that is extracted from the attachments themselves (such as format and initial layout), but it also records what to do with each <a id="_idIndexMarker082"/>attachment when it is loaded and stored. While iterating over all the attachments used in the render pass, we create two other auxiliary variables: one list with the indices of attachments that are of type color (<code>colorAttachmentReferences</code>) and a variable that stores the index of the attachment that is depth and/or stencil (<code>depthStencilAttachmentReference</code>), since render passes only support one depth/stencil attachment:<pre class="source-code">
RenderPass::RenderPass(
    const Context&amp; context,
    const std::vector&lt;std::shared_ptr&lt;Texture&gt;&gt;
        attachments,
    const std::vector&lt;VkAttachmentLoadOp&gt;&amp; loadOp,
    const std::vector&lt;VkAttachmentStoreOp&gt;&amp; storeOp,
    const std::vector&lt;VkImageLayout&gt;&amp; layout,
    VkPipelineBindPoint bindPoint,
    const std::string&amp; name)
    : device_{context.device()} {
  ASSERT(attachments.size() == loadOp.size() &amp;&amp;
             attachments.size() == storeOp.size() &amp;&amp;
             attachments.size() == layout.size(),
         "The sizes of the attachments and their load "
         "and store operations and final layouts "
         "must match");
  std::vector&lt;VkAttachmentDescription&gt;
      attachmentDescriptors;
  std::vector&lt;VkAttachmentReference&gt;
      colorAttachmentReferences;
  std::optional&lt;VkAttachmentReference&gt;
      depthStencilAttachmentReference;</pre></li> <li>For each <a id="_idIndexMarker083"/>attachment, create a <code>VkAttachmentDescription</code> structure and append it to the <code>attachmentDescriptors</code> vector:<pre class="source-code">
  for (uint32_t index = 0; index &lt; attachments.size();
       ++index) {
    attachmentDescriptors.emplace_back(
        VkAttachmentDescription{
            .format = attachments[index]-&gt;vkFormat(),
            .samples = VK_SAMPLE_COUNT_1_BIT,
            .loadOp =
                attachments[index]-&gt;isStencil()
                    ? VK_ATTACHMENT_LOAD_OP_DONT_CARE
                    : loadOp[index],
            .storeOp =
                attachments[index]-&gt;isStencil()
                    ? VK_ATTACHMENT_STORE_OP_DONT_CARE
                    : storeOp[index],
            .stencilLoadOp =
                attachments[index]-&gt;isStencil()
                    ? loadOp[index]
                    : VK_ATTACHMENT_LOAD_OP_DONT_CARE,
            .stencilStoreOp =
                attachments[index]-&gt;isStencil()
                    ? storeOp[index]
                    : VK_ATTACHMENT_STORE_OP_DONT_CARE,
            .initialLayout =
                attachments[index]-&gt;vkLayout(),
            .finalLayout = layout[index],
        });</pre></li> <li>If the <a id="_idIndexMarker084"/>attachment is a depth or a stencil texture, create a <code>VkAttachmentReference</code> structure for it and store it in the <code>depthStencilAttachmentReference</code> auxiliary variable. Otherwise, the attachment is a color attachment, and we create and store a <code>VkAttachmentReference</code> structure to the <code>colorAttachmentReferences</code> vector:<pre class="source-code">
    if (attachments[index]-&gt;isStencil() ||
        attachments[index]-&gt;isDepth()) {
      depthStencilAttachmentReference =
          VkAttachmentReference{
              .attachment = index,
              .layout =
                  VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL,
          };
    } else {
      colorAttachmentReferences.emplace_back(
          VkAttachmentReference{
              .attachment = index,
              .layout =
                  VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
          });
    }
  }</pre></li> <li>The <code>RenderPass</code> class only creates one subpass, which stores the color attachment <a id="_idIndexMarker085"/>references and the depth/stencil attachment reference:<pre class="source-code">
  const VkSubpassDescription spd = {
      .pipelineBindPoint =
          VK_PIPELINE_BIND_POINT_GRAPHICS,
      .colorAttachmentCount = static_cast&lt;uint32_t&gt;(
          colorAttachmentReferences.size()),
      .pColorAttachments =
          colorAttachmentReferences.data(),
      .pDepthStencilAttachment =
          depthStencilAttachmentReference.has_value()
              ? &amp;depthStencilAttachmentReference
                     .value()
              : nullptr,
  };</pre></li> <li>The only subpass we <a id="_idIndexMarker086"/>use for this recipe depends on an external subpass (since there’s only one subpass, it must depend on an external one):<pre class="source-code">
  const VkSubpassDependency subpassDependency = {
      .srcSubpass = VK_SUBPASS_EXTERNAL,
      .srcStageMask =
          VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT |
          VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT,
      .dstStageMask =
          VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT |
          VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT,
      .dstAccessMask =
          VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT |
          VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT,
  };</pre></li> <li>Lastly, all this information is stored in a structure of type <code>VkRenderPassCreateInfo</code>, which is passed, along with the device, to create a render pass with <code>vkCreateRenderPass</code>. The handle is stored in the <code>RenderPass::renderPass_</code> member variable:<pre class="source-code">
  const VkRenderPassCreateInfo rpci = {
      .sType =
          VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO,
      .attachmentCount = static_cast&lt;uint32_t&gt;(
          attachmentDescriptors.size()),
      .pAttachments = attachmentDescriptors.data(),
      .subpassCount = 1,
      .pSubpasses = &amp;spd,
      .dependencyCount = 1,
      .pDependencies = &amp;subpassDependency,
  };
  VK_CHECK(vkCreateRenderPass(device_, &amp;rpci, nullptr,
                              &amp;renderPass_));
  context.setVkObjectname(renderPass_,
                          VK_OBJECT_TYPE_RENDER_PASS,
                          "Render pass: " + name);
}</pre></li> <li>Destroying the <a id="_idIndexMarker087"/>render pass happens in the destructor, by calling the <code>vkDestroyRenderPass</code> function:<pre class="source-code">
RenderPass::~RenderPass() {
  vkDestroyRenderPass(device_, renderPass_, nullptr);
}</pre></li> </ol>
<p>Render passes store information on <em class="italic">what to do</em> with attachments (loaded, cleared, stored) and describe subpass dependencies. They also describe which attachments are resolve attachments (see the <em class="italic">Enabling and using Vulkan’s MSAA</em> recipe in <a href="B18491_06.xhtml#_idTextAnchor283"><em class="italic">Chapter 6</em></a><em class="italic">, Anti-Aliasing Techniques</em>, to know more about resolve attachments and how they are used to implement MSAA in Vulkan).</p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor089"/>Creating framebuffers</h1>
<p>While the render pass object contains information about what to do with each attachment <a id="_idIndexMarker088"/>and their initial and final layouts, a framebuffer contains actual references to the attachments used in the render pass, which are provided in the form of <code>VkImageViews</code>.</p>
<p>In this recipe, you will learn how to create a framebuffer object.</p>
<h2 id="_idParaDest-82"><a id="_idTextAnchor090"/>Getting ready</h2>
<p>In the repository, Vulkan framebuffers are encapsulated by the <code>VulkanCore::Framebuffer</code> class.</p>
<h2 id="_idParaDest-83"><a id="_idTextAnchor091"/>How to do it…</h2>
<p>Framebuffers refer to attachments (it answers the question “Which attachments will we be using for this render pass?”).</p>
<ol>
<li>The references are image views and are passed as a list, along with the handle of the render pass, to the <code>vkCreateFramebuffer</code> framebuffer creation function:<pre class="source-code">
uint32_t width, height; // Width and height of attachments
VkDevice device; // Valid Vulkan Device
std::vector&lt;VkImageView&gt; imageViews; // Valid Image Views
const VkFramebufferCreateInfo framebufferInfo = {
    .sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO,
    .renderPass = renderPass,
    .attachmentCount =
        static_cast&lt;uint32_t&gt;(attachments.size()),
    .pAttachments = imageViews.data(),
    .width = attachments[0]-&gt;vkExtents().width,
    .height = attachments[0]-&gt;vkExtents().height,
    .layers = 1,
};
VK_CHECK(
    vkCreateFramebuffer(device_, &amp;framebufferInfo,
                        nullptr, &amp;framebuffer_));</pre></li> </ol>
<p>Creating <a id="_idIndexMarker089"/>framebuffers is straightforward, and they are not strictly necessary anymore if you use dynamic rendering.</p>
<h1 id="_idParaDest-84"><a id="_idTextAnchor092"/>Creating image views</h1>
<p>In Vulkan, an image view is a way to specify how an image should be interpreted and accessed by the GPU. It provides a view into an image’s memory and defines its format, dimensions, and data layout.</p>
<p>An image view <a id="_idIndexMarker090"/>can be thought of as a window into an image’s memory that describes how the image should be accessed. It allows the image to be used in a variety of ways, such as a source or destination for rendering commands, or as a texture in a shader.</p>
<p>Image views are created by specifying the image they will be associated with, along with a set of parameters that define the image’s format, aspect ratio, and range. Once created, an image view can be bound to a pipeline or shader to be used in rendering or other operations. They are represented by the <code>VkImage</code> type.</p>
<p>In this recipe, you will learn how to create image views.</p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor093"/>Getting ready</h2>
<p>In the repository, image views are stored by the <code>VulkanCore::Texture</code> class and don’t have a dedicated wrapper.</p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor094"/>How to do it…</h2>
<p>Before creating <a id="_idIndexMarker091"/>an image view, you need the handle a Vulkan image object:</p>
<ol>
<li>Creating an image view is simple; all you need is the handle to a Vulkan image object (<code>VkImage</code>) and a few parameters that dictate how to access the underlying image:<pre class="source-code">
VkImage image; // Valid VkImage
const VkImageAspectFlags aspectMask =
    isDepth() ? VK_IMAGE_ASPECT_DEPTH_BIT
              : VK_IMAGE_ASPECT_COLOR_BIT;
const VkImageViewCreateInfo imageViewInfo = {
    .sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,
    .image = image_,
    .viewType = viewType,
    .format = format,
    .components =
        {
            .r = VK_COMPONENT_SWIZZLE_IDENTITY,
            .g = VK_COMPONENT_SWIZZLE_IDENTITY,
            .b = VK_COMPONENT_SWIZZLE_IDENTITY,
            .a = VK_COMPONENT_SWIZZLE_IDENTITY,
        },
    .subresourceRange = {
        .aspectMask = aspectMask,
        .baseMipLevel = 0,
        .levelCount = numMipLevels,
        .baseArrayLayer = 0,
        .layerCount = layers,
    }};
VK_CHECK(vkCreateImageView(context_.device(),
                            &amp;imageViewInfo, nullptr,
                            &amp;imageView_));</pre></li> </ol>
<p>Image views <a id="_idIndexMarker092"/>can span an entire image (mip levels and layers), just one element (mip level or layer), or even just a portion of the image.</p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor095"/>The Vulkan graphics pipeline</h1>
<p>The graphics pipeline is a crucial concept that describes the process of rendering graphics in <a id="_idIndexMarker093"/>a Vulkan application. The pipeline consists of a series of stages, each with a specific purpose, that take raw data and transform it into a fully rendered image on the screen. While some stages of the pipeline are more obvious, such as the viewport or rasterization, other stages such as the shader stage, vertex input, and dynamic states are less apparent but equally important. In the following recipes, we will explore some of the less obvious stages of the pipeline and explain their importance in the rendering process. <em class="italic">Figure 1</em><em class="italic">.7</em> shows an overview of all str<a id="_idTextAnchor096"/>uctures you may need to populate to create a graphics pipeline and their properties:</p>
<div><div><img alt="Figure 1.7 – Vulkan graphics pipeline" src="img/B18491_01_07.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.7 – Vulkan graphics pipeline</p>
<p>In this recipe, you will learn a little more about pipelines in Vulkan and their most important characteristics.</p>
<h2 id="_idParaDest-88"><a id="_idTextAnchor097"/>How to do it...</h2>
<p>Here are the <a id="_idIndexMarker094"/>most important characteristics of pipelines in Vulkan:</p>
<ol>
<li>In Vulkan, graphics pipelines are mostly immutable objects, meaning that once they are created, they cannot be modified except in certain instances. This is why it is necessary to create a new pipeline with a different topology if you wish to reuse a pipeline to draw different shapes. However, some pipeline properties can be changed dynamically at runtime, such as the viewport and scissor rectangles, which are referred to as dynamic states.</li>
<li>One important exception to the pipeline stages that won’t be covered in this book is the vertex input state. Although it is not entirely straightforward to create, we will <a id="_idIndexMarker095"/>not discuss it here since we exclusively utilize the <strong class="bold">Programmable Vertex Pulling</strong> (<strong class="bold">PVP</strong>) method to access indices and vertices at the vertex shader stage. For additional information about PVP, please refer to the  <em class="italic">Implementing Programmable Vertex Pulling and Multi-Draw Indirect</em> recipe in <a href="B18491_02.xhtml#_idTextAnchor126"><em class="italic">Chapter 2</em></a><em class="italic">, Working with </em><em class="italic">Modern Vulkan.</em></li>
<li>Similarly, the pipeline layout, a property of the graphics pipeline (and not a stage), is a data structure that outlines the anticipated layout of resources utilized by the shaders, including their location, quantity, and type, as well as pertinent details regarding push constants. Since this chapter does not provide any resources to the shaders, the pipeline layout is initialized with default values. Descriptor sets and push constants will be covered in <a href="B18491_02.xhtml#_idTextAnchor126"><em class="italic">Chapter 2</em></a><em class="italic">, Working with </em><em class="italic">Modern Vulkan.</em></li>
</ol>
<h1 id="_idParaDest-89"><a id="_idTextAnchor098"/>Compiling shaders to SPIR-V</h1>
<p>In contrast to OpenGL, which typically compiles shaders from high-level languages into binary <a id="_idIndexMarker096"/>format during runtime, Vulkan only supports an intermediate <a id="_idIndexMarker097"/>representation called SPIR-V. SPIR-V is a <a id="_idIndexMarker098"/>cross-platform, low-level intermediate representation that can be produced from various shading languages.</p>
<p>In this recipe, you will learn how to compile GLSL to SPIR-V using the <code>glslang</code> library.</p>
<h2 id="_idParaDest-90"><a id="_idTextAnchor099"/>Getting ready</h2>
<p>In this recipe, we use a third-party library that compiles GLSL code into SPIR-V at runtime <a id="_idIndexMarker099"/>called <code>glslang</code>. It can be downloaded from <a href="https://github.com/KhronosGroup/glslang.git">https://github.com/KhronosGroup/glslang.git</a>.</p>
<p>In our code, we provide the <code>VulkanCore::ShaderModule</code> class that encapsulates shaders. It provides the <code>ShaderModule::glslToSpirv</code> method (and overloads) that compiles shader source code from GLSL to SPIR-V.</p>
<h2 id="_idParaDest-91"><a id="_idTextAnchor100"/>How to do it…</h2>
<p>The steps presented here are part of the <code>ShaderModule::glslToSpirv()</code> method. Here’s how it works:</p>
<ol>
<li>The <code>glslang</code> library needs to be initialized once by calling <code>glslang::InitializeProcess()</code>, so its initialization is guarded by a static Boolean variable:<pre class="source-code">
std::vector&lt;char&gt; ShaderModule::glslToSpirv(
    const std::vector&lt;char&gt;&amp; data,
    EShLanguage shaderStage,
    const std::string&amp; shaderDir,
    const char* entryPoint) {
  static bool glslangInitialized = false;
  if (!glslangInitialized) {
    glslang::InitializeProcess();
    glslangInitialized = true;
  }</pre></li> <li>The <code>TShader</code> object is instantiated by a function to contain shaders and various other parameters that are necessary for generating SPIR-V bytecode. These <a id="_idIndexMarker100"/>parameters include the input client and GLSL <a id="_idIndexMarker101"/>versions, as well as entry points into the shaders:<pre class="source-code">
  glslang::TShader tshader(shaderStage);
  const char* glslCStr = data.data();
  tshader.setStrings(&amp;glslCStr, 1);
  glslang::EshTargetClientVersion clientVersion =
      glslang::EShTargetVulkan_1_3;
  glslang::EShTargetLanguageVersion langVersion =
      glslang::EShTargetSpv_1_3;
  tshader.setEnvInput(glslang::EShSourceGlsl,
                      shaderStage,
                      glslang::EShClientVulkan, 460);
  tshader.setEnvClient(glslang::EShClientVulkan,
                       clientVersion);
  tshader.setEnvTarget(glslang::EShTargetSpv,
                       langVersion);
  tshader.setEntryPoint(entryPoint);
  tshader.setSourceEntryPoint(entryPoint);</pre></li> <li>Afterward, we collect constraints on resources that are typically available for shaders <a id="_idIndexMarker102"/>in the system, such as the maximum <a id="_idIndexMarker103"/>number of textures or vertex attributes, and establish messages that the compiler should present. Lastly, we compile the shader into SPIR-V and verify the result:<pre class="source-code">
  const TBuiltInResource* resources =
      GetDefaultResources();
  const EShMessages messages =
      static_cast&lt;EShMessages&gt;(
          EShMsgDefault | EShMsgSpvRules |
          EShMsgVulkanRules | EShMsgDebugInfo |
          EShMsgReadHlsl);
  CustomIncluder includer(shaderDir);
  std::string preprocessedGLSL;
  if (!tshader.preprocess(
          resources, 460, ENoProfile, false, false,
          messages, &amp;preprocessedGLSL, includer)) {
    std::cout &lt;&lt; "Preprocessing failed for shader: "
              &lt;&lt; std::endl;
    printShader(data);
    std::cout &lt;&lt; std::endl;
    std::cout &lt;&lt; tshader.getInfoLog() &lt;&lt; std::endl;
    std::cout &lt;&lt; tshader.getInfoDebugLog()
              &lt;&lt; std::endl;
    ASSERT(false, "includes are forbidden");
    return std::vector&lt;char&gt;();
  }</pre></li> <li>In the last phase, linking options are established for both debug and release builds. In debug builds, regular debugging information is enabled while optimizations <a id="_idIndexMarker104"/>and debug information stripping <a id="_idIndexMarker105"/>are disabled. Conversely, in release builds, the optimizer is enabled, which may result in the removal of unused shader variables, including structure members. However, because discrepancies in structure sizes may cause problems if the same optimizations are not applied to the C++ code, optimizations are also disabled in release builds:<pre class="source-code">
  glslang::SpvOptions options;
#ifdef _DEBUG
  tshader.setDebugInfo(true);
  options.generateDebugInfo = true;
  options.disableOptimizer = true;
  options.optimizeSize = false;
  options.stripDebugInfo = false;
  options.emitNonSemanticShaderDebugSource = true;
#else
  options.disableOptimizer = true;  // Special care!
  options.optimizeSize = true;
  options.stripDebugInfo = true;
#endif
  glslang::TProgram program;
  program.addShader(&amp;tshader);
  if (!program.link(messages)) {
    std::cout &lt;&lt; "Parsing failed for shader "
              &lt;&lt; std::endl;
    std::cout &lt;&lt; program.getInfoLog() &lt;&lt; std::endl;
    std::cout &lt;&lt; program.getInfoDebugLog()
              &lt;&lt; std::endl;
    ASSERT(false, "link failed");
  }
  std::vector&lt;uint32_t&gt; spirvData;
  spv::SpvBuildLogger spvLogger;
  glslang::GlslangToSpv(
       program.getIntermediate(shaderStage), spirvData,
      &amp;spvLogger, &amp;options);
  std::vector&lt;char&gt; byteCode;
  byteCode.resize(spirvData.size() *
                  (sizeof(uint32_t) / sizeof(char)));
  std::memcpy(byteCode.data(), spirvData.data(),
              byteCode.size());
  return byteCode;
}</pre></li> </ol>
<p>For truly <a id="_idIndexMarker106"/>performant applications, shaders are not compiled from <a id="_idIndexMarker107"/>GLSL at runtime. They are compiled at build time and loaded from disk in the SPIR-V format when the application starts.</p>
<h1 id="_idParaDest-92"><a id="_idTextAnchor101"/>Dynamic states</h1>
<p>While <strong class="bold">pipeline state objects</strong> (<strong class="bold">PSOs</strong>) include immutable states, such as shader programs and <a id="_idIndexMarker108"/>vertex input bindings, some properties of a pipeline state can be changed dynamically at draw time using dynamic state objects. This <a id="_idIndexMarker109"/>feature provides greater flexibility and can minimize the necessity to recreate pipelines. Dynamic state objects can be used to change properties such as viewport and scissor rectangles, line width, blend constants, and stencil reference values. However, not all properties of a pipeline can be changed dynamically, and the use of dynamic states can have a small performance overhead.</p>
<p>Without using dynamic states, the application has a few alternatives available:</p>
<ol>
<li>Create pipelines during the application startup. If you are aware of which pipelines will be required, they can be created beforehand at the expense of a higher startup cost.</li>
<li>Utilize pipeline caches. The graphics driver features a built-in mechanism for pipeline caching that can automatically generate a cache for you.</li>
</ol>
<p>Several parameters, such as the viewport, line width, and depth bias, can be dynamically modified. While some dynamic states were included in Vulkan 1.0, others were added as extensions or included as part of Vulkan 1.3. If a parameter is marked as dynamic (using the appropriate structure), its value is ignored during pipeline creation.</p>
<p>In this recipe, you will learn about dynamic states, which allow some pipeline parameters to be dynamically set after a pipeline has been created.</p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor102"/>Getting ready</h2>
<p>Dynamic states are created using the <code>VkPipelineDynamicStateCreateInfo</code> structure. An instance of this structure is filled with states you would like to be dynamic and is later plugged into the creation of a pipeline, which we’ll cover in the next recipe.</p>
<h2 id="_idParaDest-94"><a id="_idTextAnchor103"/>How to do it…</h2>
<p>To allow <a id="_idIndexMarker110"/>parameters to be dynamically set, we need to create an instance of the <code>VkPipelineDynamicStateCreateInfo</code> structure.</p>
<ol>
<li>The next code fragment shows how to enable the dynamic state for the viewport parameter:<pre class="source-code">
const std::array&lt;VkDynamicState, 1&gt; dynamicStates = {
    VK_DYNAMIC_STATE_VIEWPORT,
};
const VkPipelineDynamicStateCreateInfo dynamicState = {
    .sType =
      VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO,
    .dynamicStateCount =
        static_cast&lt;uint32_t&gt;(dynamicStates.size()),
    .pDynamicStates = dynamicStates.data(),
};
dynamicStates</strong> array contains only the <code>VK_DYNAMIC_STATE_VIEWPORT</code> value, but it may contain a much larger set of values from <code>VkDynamicState</code>.</pre></li> </ol>
<p>The previously created instance will be used in the next recipe.</p>
<h1 id="_idParaDest-95"><a id="_idTextAnchor104"/>Creating a graphics pipeline</h1>
<p>Once all <a id="_idIndexMarker111"/>the required states and pipeline properties have been gathered and instantiated, creating a graphics pipeline in Vulkan is a straightforward process. This involves populating the <code>VkGraphicsPipelineCreateInfo</code> structure and calling <code>vkCreateGraphicsPipelines</code>.</p>
<p>In this recipe, you will learn how to create a graphics pipeline object in Vulkan.</p>
<h2 id="_idParaDest-96"><a id="_idTextAnchor105"/>Getting ready</h2>
<p>For more information, please refer to the constructor of the <code>VulkanCore::Pipeline</code> class in the repository.</p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor106"/>How to do it…</h2>
<p>Populating the structures referenced by <code>VkGraphicsPipelineCreateInfo</code> is not complicated, but a tedious task.</p>
<ol>
<li>Once all structures of all states have been instantiated, all we need to do is create an instance of <code>VkGraphicsPipelineCreateInfo</code> and call <code>vkCreateGraphicsPipelines</code>:<pre class="source-code">
const VkGraphicsPipelineCreateInfo pipelineInfo = {
    .sType=VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO,
    .stageCount = uint32_t(shaderStages.size()),
    .pStages = shaderStages.data(),
    .pVertexInputState = &amp;vinfo,
    .pInputAssemblyState = &amp;inputAssembly,
    .pViewportState = &amp;viewportState,
    .pRasterizationState = &amp;rasterizer,
    .pMultisampleState = &amp;multisampling,
    .pDepthStencilState = &amp;depthStencilState, // Optional
    .pColorBlendState = &amp;colorBlending,
    .pDynamicState = &amp;dynamicState,
    .layout = layout,
    .renderPass = renderPass,
    .basePipelineHandle = VK_NULL_HANDLE, // Optional
    .basePipelineIndex = -1,  // Optional
};
VkPipeline gfxPipeline = VK_NULL_HANDLE;
VK_CHECK(vkCreateGraphicsPipelines(
    device_, VK_NULL_HANDLE, 1, &amp;pipelineInfo,
    nullptr, &amp;gfxPipeline));</pre></li> </ol>
<p>Creating a <a id="_idIndexMarker112"/>graphics pipeline is an expensive operation. One way to avoid the penalty of creating pipelines is to cache them and reuse them the next time your application runs.</p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor107"/>Swapchain</h1>
<p>A swapchain in Vulkan <a id="_idIndexMarker113"/>mimics the functionality of double and triple buffering from OpenGL but with a more explicit role for the application in managing swapchain buffers. This approach provides better control over the configuration, synchronization, and presentation of images.</p>
<p>A Vulkan swapchain is a collection of images associated with a surface (<code>VkSurfaceKHR</code>) that are used to display rendering outputs in a window. Even though it is a key part of the Vulkan API, the functions and types used to create and manage a swapchain are part of the <code>VK_KHR_swapchain</code> extension.</p>
<p>The number of images in a swapchain object must be determined during its construction but must fall between the minimum (<code>minImageCount</code>) and maximum (<code>maxImageCount</code>) possible values provided by the device. Those values can be retrieved from the <code>VkSurfaceCapabilitiesKHR</code> structure of the Vulkan physical device.</p>
<p>Swapchain <a id="_idIndexMarker114"/>images (<code>VkImage</code>) are created and owned by the swapchain object and, as a result, their memory isn’t provided or allocated by the application. Image views (<code>VkImageView</code>) are not created by the swapchain object and thus must be created separately.</p>
<p>In this recipe, you will learn how to create, manage, and destroy swapchain images.</p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor108"/>Getting ready</h2>
<p>The swapchain is managed by the <code>VulkanCore::Swapchain</code> class in the code.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor109"/>How to do it…</h2>
<p>The swapchain extension provides a set of functions and types to create, manage, and destroy swapchains. Some key functions and types include the following:</p>
<ol>
<li><code>vkCreateSwapchainKHR</code>: This function is used to create a swapchain. You need to provide a <code>VkSwapchainCreateInfoKHR</code> structure that contains details about the surface, the number of images, their format, dimensions, usage flags, and other swapchain properties.</li>
<li><code>vkGetSwapchainImagesKHR</code>: After creating a swapchain, this function is used to retrieve handles to the images in the swapchain. You can then create image views and framebuffers for rendering and presentation.</li>
<li><code>vkAcquireNextImageKHR</code>: This function is used to acquire an available image from the swapchain for rendering. It also requires providing a semaphore or fence to signal when the image is ready for rendering.</li>
<li><code>vkQueuePresentKHR</code>: Once rendering is complete, this function is used to submit the swapchain image for presentation on the display device.</li>
<li><code>vkDestroySwapchainKHR</code>: This function is responsible for destroying the swapchain and cleaning up resources associated with it.</li>
</ol>
<h1 id="_idParaDest-101"><a id="_idTextAnchor110"/>Understanding synchronization in the swapchain – fences and semaphores</h1>
<p>The application and the GPU processes run in parallel; unless specified otherwise, the command <a id="_idIndexMarker115"/>buffers and their commands also run in parallel on the GPU. To enforce an order between the CPU and the GPU, and between command <a id="_idIndexMarker116"/>buffers being processed in the GPU, Vulkan provides two mechanisms: <strong class="bold">fences</strong> and <strong class="bold">semaphores</strong>. Fences are used to synchronize <a id="_idIndexMarker117"/>work between <a id="_idIndexMarker118"/>the GPU and the CPU, while semaphores are used to synchronize workloads executed in the GPU.</p>
<p>In this recipe, you will learn about fences and semaphores: why they are necessary, how they are used (and when), and how to use semaphores with a swapchain.</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor111"/>Getting ready</h2>
<p>Examples of semaphores can be found in the <code>VulkanCore::Swapchain</code> class, while examples of fences can be found in the <code>VulkanCore::CommandQueueManager</code> class.</p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor112"/>How to do it…</h2>
<p>Fences and semaphores have different uses. Let’s explore each one of those elements and how to use semaphores with swapchains.</p>
<ol>
<li><em class="italic">Figure 1</em><em class="italic">.8</em> shows how an application, running on the CPU, may submit commands to the GPU and proceed with its work right after submission (without synchronization). This may be intended, but if you wish to wait for commands on the GPU to finish being processed before continuing, you may use a fence to signal when work on the GPU has been complete<a id="_idTextAnchor113"/>d. Once commands on the GPU are finished processing, the fence is signaled, and the application may proceed:</li>
</ol>
<div><div><img alt="Figure 1.8 – Command buffer recording and execution on the device without synchronization" src="img/B18491_01_08.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.8 – Command buffer recording and execution on the device without synchronization</p>
<ol>
<li value="2">Semaphores <a id="_idIndexMarker119"/>work in a similar manner but are used <a id="_idIndexMarker120"/>between commands or jobs running on the GPU. <em class="italic">Figure 1</em><em class="italic">.10</em> illustrates using a semaphore to synchronize commands being processed on the GPU. The application is responsible for creating semaphores and adding dependencies between command buffers and semaphores itself before submitting the buffers for processing. Once a task is processed on the GPU, the semaphore is signaled, and the next task can continue. This enforces an ordering between commands:</li>
</ol>
<div><div><img alt="Figure 1.9 – Fences" src="img/B18491_01_09.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.9 – Fences</p>
<p class="list-inset">The process of acquiring an image, rendering, and presenting are all asynchronous and need to be synchronized. In this recipe, we will use two semaphores <a id="_idIndexMarker121"/>for the synchronization: <code>imageAvaila<a id="_idTextAnchor114"/>ble</code> and <code>imageRendered</code>. <em class="italic">Figure 1</em><em class="italic">.10</em> illustrates how semaphores <a id="_idIndexMarker122"/>affect the execution of commands on the device:</p>
<div><div><img alt="Figure 1.10 – Semaphores" src="img/B18491_01_10.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.10 – Semaphores</p>
<p class="list-inset"><code>imageAvailable_</code> is signaled once the image acquired is available, prompting the command queue that will render into the image to start processing. Once the command buffer finishes, it signals the other semaphore, <code>imageRendered</code>, which in turn allows the presentat<a id="_idTextAnchor115"/>ion of that image to start. <em class="italic">Figure 1</em><em class="italic">.11</em> demonstrates how synchronization is implemented using two semaphores:</p>
<div><div><img alt="Figure 1.11 – Synchronization of the swapchain" src="img/B18491_01_11.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.11 – Synchronization of the swapchain</p>
<p>Fences and <a id="_idIndexMarker123"/>semaphores aren’t difficult to understand, but they <a id="_idIndexMarker124"/>are crucial for synchronization in Vulkan. Make sure you understand how they are used before continuing.</p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor116"/>Populating submission information for presentation</h1>
<p>Submitting a command buffer requires an instance of the <code>VkSubmitInfo</code> structure, which allows <a id="_idIndexMarker125"/>specifying semaphores for waiting (to start processing) and signaling (once the command buffer finishes executing). Those semaphores are optional and usually not needed. But when submitting a command buffer for presenting images onto the screen, those semaphores allow Vulkan to synchronize the execution of the buffer with the presentation engine.</p>
<p>In this recipe, you will learn how to submit a command buffer for processing by the GPU after it has been recorded.</p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor117"/>Getting ready</h2>
<p>The <code>VulkanCore::Swapchain</code> class in the repository provides a utility function to fill the <code>VkSubmitInfo</code> structure for you since the semaphores used to synchronize the execution with the presentation engine are stored in the swapchain. If no semaphores are needed in the structure, the <code>waitForImageAvailable</code> and the <code>signalImagePresented</code> parameters should be set to <code>false</code>.</p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor118"/>How to do it…</h2>
<p>The synchronization information used to submit command buffers that need to be synchronized <a id="_idIndexMarker126"/>with the presentation engine is provided by an instance of the <code>VkSubmitInfo</code> structure and contains references to the semaphores that will be used for synchronization in the device. It also contains the command buffer that will be submitted.</p>
<ol>
<li>The fence is associated with the command buffer and is not a specific one for synchronizing the swapchain:<pre class="source-code">
const VkSubmitInfo submitInfo = {
    .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
    .waitSemaphoreCount = 1,
    .pWaitSemaphores = &amp;imageAvailable,
    .pWaitDstStageMask = submitStageMask,
    .commandBufferCount = 1,
    .pCommandBuffers = buffer,
    .signalSemaphoreCount = 1,
    .pSignalSemaphores = &amp;imagePresented,
};
VK_CHECK(vkQueueSubmit(queue_, 1, &amp;submitInfo, fence));</pre></li> </ol>
<p>Once a command buffer has been submitted for processing, it’s up to the driver and the GPU to execute the commands recorded there. The only way to know whether the command buffer has finished processing is by checking the fence provided to <code>vkQueueSubmit</code>.</p>
<h1 id="_idParaDest-107"><a id="_idTextAnchor119"/>Presenting images</h1>
<p>Presenting an <a id="_idIndexMarker127"/>image onto the screen isn’t automatic in Vulkan. You need to call the <code>vkQueuePresentKHR</code> function along with an instance of the <code>VkPresentInfoKHR</code> structure.</p>
<p>In this recipe, you will learn how to queue an image for presentation once it has finished rendering.</p>
<h2 id="_idParaDest-108"><a id="_idTextAnchor120"/>Getting ready</h2>
<p>The presentation in our code is done in the <code>VulkanCore::Swapchain::present()</code> method.</p>
<h2 id="_idParaDest-109"><a id="_idTextAnchor121"/>How to do it…</h2>
<p>Requesting an acquired image to be presented is done by calling <code>vkQueuePresentKHR</code>.</p>
<p>This time, we need to provide the <code>imageRendered</code> semaphore, which indicates when the rendering process has finished using the image:</p>
<pre class="source-code">
const VkPresentInfoKHR presentInfo{
    .sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR,
    .waitSemaphoreCount = 1,
    .pWaitSemaphores = &amp;imageRendered_,
    .swapchainCount = 1,
    .pSwapchains = &amp;swapchain_,
    .pImageIndices = &amp;imageIndex_,
};
VK_CHECK(vkQueuePresentKHR(presentQueue_, &amp;presentInfo));</pre> <p>The image won’t be presented right away once <code>VkQueuePresentKHR</code> is called. This call merely sets up the synchronization mechanism so that Vulkan knows when the image can be sent for display.</p>
<h1 id="_idParaDest-110"><a id="_idTextAnchor122"/>Rendering a triangle</h1>
<p>Now that we’ve learned about all basic Vulkan objects and how they work, we can finally create a <a id="_idIndexMarker128"/>small example application that displays a static shaded triangle on the screen.</p>
<p>In this recipe, we will present a full example that renders a static triangle on the screen. The vertex data and attributes are statically provided in the vertex shader.</p>
<h2 id="_idParaDest-111"><a id="_idTextAnchor123"/>Getting ready</h2>
<p>The code in this recipe can be found in the repository in <code>source/chapter1/main.cpp</code>. The vertex and fragment shaders are located in <code>source/chapter1/resources/shaders</code>, in the <code>triangle.vert</code> and <code>triangle.frag</code> files.</p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor124"/>How to do it…</h2>
<p>The code presented here is an unabridged version of the code in the repository.</p>
<ol>
<li>For this recipe, we will use two shaders: <code>triangle.vert</code> and <code>triangle.frag</code>. The vertex shader does not accept any inputs, as all the data it needs is defined right there in the shader itself as two arrays: one for vertex data (<code>positions</code>) and the other for color data (<code>colors</code>).<p class="list-inset">Both sets of data are sent to the output as-is without any transformations, as they are already in their respective output spaces (screen space for the position data and the output color space for the color data). The position is output through the built-in <code>gl_VertexIndex</code> variable, while the color is written to the <code>outColor</code> variable at location <code>0</code>:</p><pre class="source-code">
#version 460
layout(location = 0) out vec4 outColor;
vec2 positions[3] = vec2[](
    vec2(0.0, -0.5),
    vec2(0.5, 0.5),
    vec2(-0.5, 0.5)
);
vec3 colors[3] = vec3[](
    vec3(1.0, 0.0, 0.0),
    vec3(0.0, 1.0, 0.0),
    vec3(0.0, 0.0, 1.0)
);
void main() {
   gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0);
   outColor = vec4(colors[gl_VertexIndex], 1.0);
}</pre></li> <li>The fragment <a id="_idIndexMarker129"/>shader accepts the color data from the vertex stage and directly outputs it as the fragment color through the <code>outColor</code> variable at location <code>0</code>:<pre class="source-code">
#version 460
layout(location = 0) in vec4 inColor;
layout(location = 0) out vec4 outColor;
void main() {
    outColor = inColor;
}</pre><p class="list-inset">We only need one render pass that will output the render result to a framebuffer with only one attachment, color attachment 0. The color attachment’s load operation is <em class="italic">clear</em> as we will clear it for rendering, whereas the store operation is <em class="italic">store</em> as we want the output to be recorded into the attachment. The output will go straight into the swapchain, so the acquired swapchain image is <a id="_idIndexMarker130"/>the color attachment 0. Since each render pass outputs directly onto the swapchain image, and a framebuffer is associated with an attachment and is immutable, we need the number of framebuffers to match the number of swapchain images. Each framebuffer will be associated with one swapchain image as the color attachment 0. The shaders don’t need access to external buffers, such as vertex and index, or textures.</p></li> <li>The first step is to initialize a window and create a context with the features we will use by default in this book. For more details, please refer to the <code>VulkanCore::VulkanFeatureChain</code> class in the repo. The context, which encapsulates the instance and the physical and logical devices, is initialized with a few useful extensions, one graphics queue, and the default features:<pre class="source-code">
int main(int argc, char** argv) {
  initWindow(&amp;window_);
  // Create Context
  VulkanCore::VulkanFeatureChain featureChain;
  VulkanCore::Context::createDefaultFeatureChain(
      featureChain);
  VulkanCore::Context context(
      (void*)glfwGetWin32Window(window_),
      {},  // layers
      {
          VK_KHR_WIN32_SURFACE_EXTENSION_NAME,
          VK_KHR_SURFACE_EXTENSION_NAME,
          VK_KHR_GET_PHYSICAL_DEVICE_PROPERTIES_2_EXTENSION_NAME,
      },  // instance extensions
      {VK_KHR_SWAPCHAIN_EXTENSION_NAME},  // device
                                          // extensions
      VK_QUEUE_GRAPHICS_BIT,  // request a graphics
                              // queue only
      featureChain, true);</pre></li> <li>The swapchain is initialized with a common format and color space, along with the extensions <a id="_idIndexMarker131"/>from the physical device. In this example, we <a id="_idIndexMarker132"/>use the <strong class="bold">First In First Out</strong> (<strong class="bold">FIFO</strong>) presentation mode because it’s the only mode that is supported by default:<pre class="source-code">
  // Create Swapchain
  const VkExtent2D extents = context.physicalDevice()
                                 .surfaceCapabilities()
                                 .minImageExtent;
  context.createSwapchain(
      VK_FORMAT_B8G8R8A8_UNORM,
      VK_COLORSPACE_SRGB_NONLINEAR_KHR,
      VK_PRESENT_MODE_FIFO_KHR, extents);
  const VkRect2D renderArea = {
      .offset = {.x = 0, .y = 0}, .extent = extents};</pre></li> <li>Both shaders are initialized from the resources in the repo, along with a vector of framebuffers. The <a id="_idIndexMarker133"/>number of framebuffers matches the number of swapchain images, as we’ll need one framebuffer for each acquired image later:<pre class="source-code">
  // Create Shader Modules
  const auto shadersPath =
      std::filesystem::current_path() /
      "resources/shaders";
  const auto vertexShaderPath =
      shadersPath / "triangle.vert";
  const auto fragShaderPath =
      shadersPath / "triangle.frag";
  const auto vertexShader = context.createShaderModule(
      vertexShaderPath.string(),
      VK_SHADER_STAGE_VERTEX_BIT);
  const auto fragShader = context.createShaderModule(
      fragShaderPath.string(),
      VK_SHADER_STAGE_FRAGMENT_BIT);
  // Create Framebuffers
  std::vector&lt;std::shared_ptr&lt;VulkanCore::Framebuffer&gt;&gt;
      swapchain_framebuffers(
          context.swapchain()-&gt;numberImages());</pre></li> <li>We only need one render pass with one subpass. A render pass isn’t associated with any resources. It only specifies the load and store operations of each framebuffer’s color attachment and their use by the subpasses. For this reason, we don’t need multiple render passes, like framebuffers do. One is enough, and it is reused for all swapchain images. The final layout of the color attachment 0, the swapchain image, is <code>VK_IMAGE_LAYOUT_PRESENT_SRC_KHR</code>, as it will be presented:<pre class="source-code">
  // Create Render Pass
  std::shared_ptr&lt;VulkanCore::RenderPass&gt; renderPass =
      context.createRenderPass(
          {context.swapchain()-&gt;texture(0)},
          {VK_ATTACHMENT_LOAD_OP_CLEAR},
          {VK_ATTACHMENT_STORE_OP_STORE},
          {VK_IMAGE_LAYOUT_PRESENT_SRC_KHR},
          VK_PIPELINE_BIND_POINT_GRAPHICS);</pre><p class="list-inset">Finally, we create a pipeline that contains mostly the default parameters. Besides the two <a id="_idIndexMarker134"/>shaders compiled before, we set the viewport to be the size of the output and disable depth testing. We then create a Command Queue Manager instance to manage the command buffers and their fences:</p><pre class="source-code">  // Create Graphics Pipeline
  auto pipeline = context.createGraphicsPipeline(
      VulkanCore::Pipeline::GraphicsPipelineDescriptor{
          .vertexShader_ = vertexShader,
          .fragmentShader_ = fragShader,
          .viewport = context.swapchain()-&gt;extent(),
          .depthTestEnable = false,
      },
      renderPass-&gt;vkRenderPass());
  // Create Command Queue Manager
  auto commandMgr = context.createGraphicsCommandQueue(
      context.swapchain()-&gt;numberImages(),
      context.swapchain()-&gt;numberImages());
  // FPS Counter
  EngineCore::FPSCounter fps(glfwGetTime());</pre></li> <li>The main render loop executes until the <code>GLFW</code> window is closed. On each iteration, we first <a id="_idIndexMarker135"/>acquire a swapchain image and its index. If a framebuffer for this swapchain image doesn’t exist yet, we create one. We then obtain a command buffer for rendering:<pre class="source-code">
  // Main Render Loop
  while (!glfwWindowShouldClose(window_)) {
    fps.update(glfwGetTime());
    const auto texture =
        context.swapchain()-&gt;acquireImage();
    const auto swapchainImageIndex =
        context.swapchain()-&gt;currentImageIndex();
    // Create the framebuffer the first time we get
    // here, once for each swapchain image
    if (swapchain_framebuffers[swapchainImageIndex] ==
        nullptr) {
      swapchain_framebuffers[swapchainImageIndex] =
          context.createFramebuffer(
              renderPass-&gt;vkRenderPass(), {texture},
              nullptr, nullptr);
    }
    auto commandBuffer =
        commandMgr.getCmdBufferToBegin();</pre></li> <li>Before starting rendering, we begin the render pass by providing a clear color (black), and the <a id="_idIndexMarker136"/>render pass and framebuffer handles. We then bind the pipeline to the current command buffer, and we are ready to start rendering:<pre class="source-code">
    // Begin Render Pass
    constexpr VkClearValue clearColor{0.0f, 0.0f, 0.0f,
                                      0.0f};
    const VkRenderPassBeginInfo renderpassInfo = {
        .sType =
            VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO,
        .renderPass = renderPass-&gt;vkRenderPass(),
        .framebuffer =
            swapchain_framebuffers[swapchainImageIndex]
                -&gt;vkFramebuffer(),
        .renderArea = renderArea,
        .clearValueCount = 1,
        .pClearValues = &amp;clearColor,
    };
    vkCmdBeginRenderPass(commandBuffer,
                         &amp;renderpassInfo,
                         VK_SUBPASS_CONTENTS_INLINE);
    pipeline-&gt;bind(commandBuffer);</pre></li> <li>Finally, we issue the draw call with three vertices and one instance. This call will invoke the vertex <a id="_idIndexMarker137"/>shader three times (one for each vertex), instantiating the <code>gl_VertexIndex</code> variable in the shader to 0, 1, and 2. We use this variable to index into the position and color arrays in the shader itself. We then submit the command buffer and present the swapchain image:<pre class="source-code">
    vkCmdDraw(commandBuffer, 3, 1, 0, 0);
    vkCmdEndRenderPass(commandBuffer);
    commandMgr.endCmdBuffer(commandBuffer);
    constexpr VkPipelineStageFlags flags =
        VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
    const auto submitInfo =
        context.swapchain()-&gt;createSubmitInfo(
            &amp;commandBuffer, &amp;flags);
    commandMgr.submit(&amp;submitInfo);
    commandMgr.goToNextCmdBuffer();
    // Present render output to the screen
    context.swapchain()-&gt;present();
    glfwPollEvents();
    // Increment frame number
    fps.incFrame();
  }</pre></li> <li>After the render loop ends, and before exiting the program, we wait for all queues to <a id="_idIndexMarker138"/>finish processing before destroying all Vulkan objects in the opposite order in which they were created:<pre class="source-code">
  commandMgr.waitUntilAllSubmitsAreComplete<a id="_idTextAnchor125"/>();
  glfwDestroyWindow(window_);
  glfwTerminate();
  return 0;
}</pre><p class="list-inset">The result of this recipe should look like <em class="italic">Figure 1</em><em class="italic">.12</em>:</p></li> </ol>
<div><div><img alt="Figure 1.12 – Recipe result" src="img/B18491_01_12.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.12 – Recipe result</p>
<p>Vulkan is <a id="_idIndexMarker139"/>verbose and, as mentioned before, provides many ways to customize your graphics application. A simple example such as this needed around 1,000 lines of code! But there is no reason for panic. Most of that code can be reused (and will be reused) for the remainder of the book to explain all techniques and recipes in the text.</p>
</div>
</body></html>