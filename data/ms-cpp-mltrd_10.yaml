- en: Multithreading with GPGPU
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPGPU进行多线程处理
- en: A fairly recent development has been to use video cards (GPUs) for general purpose
    computing (GPGPU). Using frameworks such as CUDA and OpenCL, it is possible to
    speed up, for example, the processing of large datasets in parallel in medical,
    military, and scientific applications. In this chapter, we will look at how this
    is done with C++ and OpenCL, and how to integrate such a feature into a multithreaded
    application in C++.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的一个发展是使用视频卡（GPU）进行通用计算（GPGPU）。使用诸如CUDA和OpenCL之类的框架，可以加速例如在医疗、军事和科学应用中并行处理大型数据集的处理。在本章中，我们将看看如何使用C++和OpenCL来实现这一点，以及如何将这样的功能集成到C++中的多线程应用程序中。
- en: 'Topics in this chapter include:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题包括：
- en: Integrating OpenCL into a C++ based application
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将OpenCL集成到基于C++的应用程序中
- en: The challenges of using OpenCL in a multithreaded fashion
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多线程中使用OpenCL的挑战
- en: The impact of latency and scheduling on multithreaded performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟和调度对多线程性能的影响
- en: The GPGPU processing model
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPGPU处理模型
- en: In [Chapter 9](part0187.html#5IAP60-1ab5991b318547348fc444437bdacb24), *Multithreading
    with Distributed Computing*, we looked at running the same task across a number
    of compute nodes in a cluster system. The main goal of such a setup is to process
    data in a highly parallel fashion, theoretically speeding up said processing relative
    to a single system with fewer CPU cores.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](part0187.html#5IAP60-1ab5991b318547348fc444437bdacb24)中，*使用分布式计算进行多线程处理*，我们看到在集群系统中跨多个计算节点运行相同的任务。这样设置的主要目标是以高度并行的方式处理数据，从理论上讲，相对于具有较少CPU核心的单个系统，可以加快处理速度。
- en: '**GPGPU** (**General Purpose Computing on Graphics Processing Units**) is in
    some ways similar to this, but with one major difference: while a compute cluster
    with only regular CPUs is good at scalar tasks--meaning performing one task on
    one single set of data (SISD)--GPUs are vector processors that excel at SIMD (Single
    Input, Multiple Data) tasks.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPGPU**（图形处理单元上的通用计算）在某些方面与此类似，但有一个主要区别：虽然只有常规CPU的计算集群擅长标量任务--即在一组数据上执行一个任务（SISD）--GPU是擅长SIMD（单输入，多数据）任务的矢量处理器。'
- en: 'Essentially, this means that one can send a large dataset to a GPU, along with
    a single task description, and the GPU will proceed to execute that same task
    on parts of that data in parallel on its hundreds or thousands of cores. One can
    thus regard a GPU as a very specialized kind of cluster:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这意味着一个人可以将大型数据集发送到GPU，以及单个任务描述，GPU将继续在其数百或数千个核上并行执行该数据的部分相同任务。因此，人们可以将GPU视为一种非常专业化的集群：
- en: '![](img/00026.jpeg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00026.jpeg)'
- en: Implementations
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施
- en: When the concept of GPGPU was first coined (around 2001), the most common way
    to write GPGPU programs was using GLSL (OpenGL Shading Language) and similar shader
    languages. Since these shader languages were already aimed at the processing of
    SIMD tasks (image and scene data), adapting them for more generic tasks was fairly
    straightforward.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当GPGPU的概念首次被提出（大约在2001年左右），编写GPGPU程序的最常见方式是使用GLSL（OpenGL着色语言）和类似的着色器语言。由于这些着色器语言已经针对SIMD任务（图像和场景数据）进行了优化，因此将它们调整为更通用的任务相对比较简单。
- en: 'Since that time, a number of more specialized implementations have appeared:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时起，出现了许多更专业的实现：
- en: '| **Name** | **Since** | **Owner** | **Notes** |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **自** | **所有者** | **备注** |'
- en: '| CUDA | 2006 | NVidia | This is proprietary and only runs on NVidia GPUs |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| CUDA | 2006 | NVidia | 这是专有的，仅在NVidia GPU上运行 |'
- en: '| Close to Metal | 2006 | ATi/AMD | This was abandoned in favor of OpenCL |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| Close to Metal | 2006 | ATi/AMD | 这被放弃，支持OpenCL |'
- en: '| DirectCompute | 2008 | Microsoft | This is released with DX11, runs on DX10
    GPUs, and is limited to Windows platforms |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| DirectCompute | 2008 | Microsoft | 这是随DX11发布的，可以在DX10 GPU上运行，仅限于Windows平台
    |'
- en: '| OpenCL | 2009 | Khronos Group | This is open standard and available across
    AMD, Intel, and NVidia GPUs on all mainstream platforms, as well as mobile platforms
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| OpenCL | 2009 | Khronos Group | 这是开放标准，适用于所有主流平台上的AMD、Intel和NVidia GPU，以及移动平台
    |'
- en: OpenCL
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL
- en: Of the various current GPGPU implementations, OpenCL is by far the most interesting
    GPGPU API due to the absence of limitations. It is available for virtually all
    mainstream GPUs and platforms, even enjoying support on select mobile platforms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种当前的GPGPU实现中，由于没有限制，OpenCL是迄今为止最有趣的GPGPU API。它适用于几乎所有主流GPU和平台，甚至在某些移动平台上也得到支持。
- en: Another distinguishing feature of OpenCL is that it's not limited to just GPGPU
    either. As part of its name (Open Computing Language), it abstracts a system into
    the so-called *compute devices*, each with their own capabilities. GPGPU is the
    most common application, but this feature makes it fairly easy to test implementations
    on a CPU first, for easy debugging.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL的另一个显着特点是它不仅限于GPGPU。作为其名称的一部分（开放计算语言），它将系统抽象为所谓的*计算设备*，每个设备都有自己的功能。GPGPU是最常见的应用，但这个特性使得在CPU上首先进行测试实现变得相当容易，以便进行简单的调试。
- en: One possible disadvantage of OpenCL is that it employs a high level of abstraction
    for memory and hardware details, which can negatively affect performance, even
    as it increases the portability of the code.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL的一个可能的缺点是它对内存和硬件细节采用了高度抽象，这可能会对性能产生负面影响，尽管它增加了代码的可移植性。
- en: In the rest of this chapter, we will focus on OpenCL.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将专注于OpenCL。
- en: Common OpenCL applications
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的OpenCL应用
- en: 'Many programs incorporate OpenCL-based code in order to speed up operations.
    These include programs aimed at graphics processing, as well as 3D modelling and
    CAD, audio and video processing. Some examples are:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 许多程序包括基于OpenCL的代码，以加快操作。这些包括旨在进行图形处理的程序，以及3D建模和CAD、音频和视频处理。一些例子包括：
- en: Adobe Photoshop
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adobe Photoshop
- en: GIMP
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GIMP
- en: ImageMagick
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageMagick
- en: Autodesk Maya
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Autodesk Maya
- en: Blender
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blender
- en: Handbrake
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Handbrake
- en: Vegas Pro
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vegas Pro
- en: OpenCV
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV
- en: Libav
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Libav
- en: Final Cut Pro
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Final Cut Pro
- en: FFmpeg
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FFmpeg
- en: Further acceleration of certain operations is found in office applications including
    LibreOffice Calc and Microsoft Excel.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在办公应用程序中，包括LibreOffice Calc和Microsoft Excel中，还发现了某些操作的进一步加速。
- en: Perhaps more importantly, OpenCL is also commonly used for scientific computing
    and cryptography, including BOINC and GROMACS as well as many other libraries
    and programs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 也许更重要的是，OpenCL通常用于科学计算和密码学，包括BOINC和GROMACS以及许多其他库和程序。
- en: OpenCL versions
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL版本
- en: Since the release of the OpenCL specification on December 8, 2008, there have
    so far been five updates, bringing it up to version 2.2\. Important changes with
    these releases are mentioned next.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自2008年12月8日发布OpenCL规范以来，迄今已经有五次更新，将其升级到2.2版本。这些更新中的重要变化如下。
- en: OpenCL 1.0
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 1.0
- en: The first public release was released by Apple as part of the macOS X Snow Leopard
    release on August 28, 2009.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首次公开发布是由苹果作为macOS X Snow Leopard发布的一部分于2009年8月28日发布。
- en: Together with this release, AMD announced that it would support OpenCL and retire
    its own Close to Metal (CtM) framework. NVidia, RapidMind, and IBM also added
    support for OpenCL to their own frameworks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，AMD宣布将支持OpenCL并淘汰其自己的Close to Metal（CtM）框架。 NVidia，RapidMind和IBM还为其自己的框架添加了对OpenCL的支持。
- en: OpenCL 1.1
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 1.1
- en: 'The OpenCL 1.1 specification was ratified by the Khronos Group on June 14,
    2010\. It adds additional functionality for parallel programming and performance,
    including the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 1.1规范于2010年6月14日由Khronos Group批准。它为并行编程和性能增加了额外的功能，包括以下内容：
- en: New data types including 3-component vectors and additional image formats
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括3组分向量和额外的图像格式在内的新数据类型
- en: Handling commands from multiple host threads and processing buffers across multiple
    devices
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理来自多个主机线程的命令，并在多个设备上处理缓冲区
- en: Operations on regions of a buffer including reading, writing, and copying of
    the 1D, 2D, or 3D rectangular regions
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对缓冲区的区域进行操作，包括读取、写入和复制1D、2D或3D矩形区域
- en: Enhanced use of events to drive and control command execution
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增强事件的使用来驱动和控制命令执行
- en: Additional OpenCL built-in C functions, such as integer clamp, shuffle, and
    asynchronous-strided (not contiguous, but with gaps between the data) copies
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的OpenCL内置C函数，如整数夹紧、洗牌和异步步进（不连续，但数据之间有间隙）复制
- en: Improved OpenGL interoperability through efficient sharing of images and buffers
    by linking OpenCL and OpenGL events
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过有效共享图像和缓冲区来改进OpenGL互操作性，通过链接OpenCL和OpenGL事件
- en: OpenCL 1.2
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 1.2
- en: 'The OpenCL 1.2 version was released on November 15, 2011\. Its most significant
    features include the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 1.2版本于2011年11月15日发布。其最重要的功能包括以下内容：
- en: '**Device partitioning:** This enables applications to partition a device into
    sub-devices to directly control work assignment to particular compute units, reserve
    a part of the device for use for high priority/latency-sensitive tasks, or effectively
    use shared hardware resources such as a cache.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备分区：**这使应用程序能够将设备分成子设备，直接控制对特定计算单元的工作分配，为高优先级/延迟敏感任务保留设备的一部分，或有效地使用共享硬件资源，如缓存。'
- en: '**Separate compilation and linking of objects**: This provides the capabilities
    and flexibility of traditional compilers enabling the creation of libraries of
    OpenCL programs for other programs to link to.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象的分离编译和链接：**这提供了传统编译器的功能和灵活性，使得可以创建OpenCL程序的库，供其他程序链接。'
- en: '**Enhanced image support**: This **i**ncludes added support for 1D images and
    1D & 2D image arrays. Also, the OpenGL sharing extension now enables an OpenCL
    image to be created from OpenGL 1D textures and 1D & 2D texture arrays.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强的图像支持：**这包括对1D图像和1D和2D图像数组的增强支持。此外，OpenGL共享扩展现在可以从OpenGL 1D纹理和1D和2D纹理数组创建OpenCL图像。'
- en: '**Built-in kernels:** This represents the capabilities of specialized or non-programmable
    hardware and associated firmware, such as video encoder/decoders and digital signal
    processors, enabling these custom devices to be driven from and integrated closely
    with the OpenCL framework.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内置内核：**这代表了专门或不可编程硬件及相关固件的功能，如视频编码器/解码器和数字信号处理器，使得这些定制设备可以从OpenCL框架中驱动并与之紧密集成。'
- en: '**DX9 Media Surface Sharing**: This enables efficient sharing between OpenCL
    and DirectX 9 or DXVA media surfaces.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DX9媒体表面共享：**这使得OpenCL和DirectX 9或DXVA媒体表面之间的有效共享成为可能。'
- en: '**DX11 Surface Sharing**: For seamless sharing between OpenCL and DirectX 11
    surfaces.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DX11表面共享：**实现OpenCL和DirectX 11表面之间的无缝共享。'
- en: OpenCL 2.0
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 2.0
- en: 'The OpenCL2.0 version was released on November 18, 2013\. This release has
    the following significant changes or additions:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL2.0版本于2013年11月18日发布。此版本具有以下重大变化或增加：
- en: '**Shared Virtual Memory**: Host and device kernels can directly share complex,
    pointer-containing data structures such as trees and linked lists, providing significant
    programming flexibility and eliminating costly data transfers between host and
    devices.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享虚拟内存：**主机和设备内核可以直接共享复杂的、包含指针的数据结构，如树和链表，提供了重要的编程灵活性，并消除了主机和设备之间昂贵的数据传输。'
- en: '**Dynamic Parallelism**: Device kernels can enqueue kernels to the same device
    with no host interaction, enabling flexible work scheduling paradigms and avoiding
    the need to transfer execution control and data between the device and host, often
    significantly offloading host processor bottlenecks.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态并行性：**设备内核可以在没有主机交互的情况下将内核排队到同一设备，从而实现灵活的工作调度范例，并避免在设备和主机之间传输执行控制和数据，通常显著减轻主机处理器瓶颈。'
- en: '**Generic Address Space**: Functions can be written without specifying a named
    address space for arguments, especially useful for those arguments that are declared
    to be a pointer to a type, eliminating the need for multiple functions to be written
    for each named address space used in an application.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用地址空间：**函数可以在不指定参数的命名地址空间的情况下编写，特别适用于声明为指向类型的指针的参数，消除了需要为应用程序中使用的每个命名地址空间编写多个函数的需要。'
- en: '**Images**: Improved image support including sRGB images and 3D image writes,
    the ability for kernels to read from and write to the same image, and the creation
    of OpenCL images from a mip-mapped or a multi-sampled OpenGL texture for improved
    OpenGL interop.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：改进的图像支持，包括sRGB图像和3D图像写入，内核可以从同一图像读取和写入，以及从mip-mapped或多采样OpenGL纹理创建OpenCL图像以改进OpenGL互操作性。'
- en: '**C11 Atomics**: A subset of C11 atomics and synchronization operations to
    enable assignments in one work-item to be visible to other work-items in a work-group,
    across work-groups executing on a device or for sharing data between the OpenCL
    device and host.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C11原子操作**：C11原子操作和同步操作的子集，可以使一个工作项中的赋值对设备上执行的其他工作项或在设备和主机之间共享数据的工作组可见。'
- en: '**Pipes**: Pipes are memory objects that store data organized as a FIFO and
    OpenCL 2.0 provides built-in functions for kernels to read from or write to a
    pipe, providing straightforward programming of pipe data structures that can be
    highly optimized by OpenCL implementers.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：管道是以FIFO形式存储数据的内存对象，OpenCL 2.0提供了内核读取或写入管道的内置函数，可以直接编程管道数据结构，这可以由OpenCL实现者进行高度优化。'
- en: '**Android Installable Client Driver Extension**: Enables OpenCL implementations
    to be discovered and loaded as a shared object on Android systems.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Android可安装客户端驱动扩展**：使得可以在Android系统上发现和加载OpenCL实现作为共享对象。'
- en: OpenCL 2.1
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 2.1
- en: The OpenCL 2.1 revision to the 2.0 standard was released on November 16, 2015\.
    The most notable thing about this release was the introduction of the OpenCL C++
    kernel language, such as how the OpenCL language originally was based on C with
    extensions, the C++ version is based on a subset of C++14, with backwards compatibility
    for the C kernel language.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 2.1标准于2015年11月16日发布，这个版本最显著的特点是引入了OpenCL C++内核语言，就像OpenCL语言最初是基于带有扩展的C一样，C++版本是基于C++14的子集，同时向后兼容C内核语言。
- en: 'Updates to the OpenCL API include the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL API的更新包括以下内容：
- en: '**Subgroups**: These enable finer grain control of hardware threading, are
    now in core, together with additional subgroup query operations for increased
    flexibility'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子组**：这些使得对硬件线程的更精细控制现在已经成为核心，还有额外的子组查询操作，以增加灵活性。'
- en: '**Copying of kernel objects and states**: clCloneKernel enables copying of
    kernel objects and state for safe implementation of copy constructors in wrapper
    classes'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内核对象和状态的复制**：clCloneKernel可以复制内核对象和状态，以安全地实现包装类中的复制构造函数'
- en: '**Low-latency device timer queries**: These allow for alignment of profiling
    data between device and host code'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低延迟设备定时器查询**：这允许在设备和主机代码之间对齐分析数据'
- en: '**Intermediate SPIR-V code for the runtime**:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行时的中间SPIR-V代码**：'
- en: A bi-directional translator between LLVM to SPIR-V to enable flexible use of
    both intermediate languages in tool chains.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLVM到SPIR-V之间的双向翻译器，以便在工具链中灵活使用这两种中间语言。
- en: An OpenCL C to LLVM compiler that generates SPIR-V through the above translator.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过上述翻译生成SPIR-V的OpenCL C到LLVM编译器。
- en: A SPIR-V assembler and disassembler.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SPIR-V汇编器和反汇编器。
- en: Standard Portable Intermediate Representation (SPIR) and its successor, SPIR-V,
    are a way to provide device-independent binaries for use across OpenCL devices.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 标准可移植中间表示（SPIR）及其后继者SPIR-V，是为了在OpenCL设备上提供设备无关的二进制文件的一种方式。
- en: OpenCL 2.2
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL 2.2
- en: 'On May 16, 2017, what is now the current release of OpenCL was released. According
    to the Khronos Group, it includes the following changes:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年5月16日，现在的OpenCL版本发布。根据Khronos Group的说法，它包括以下更改：
- en: OpenCL 2.2 brings the OpenCL C++ kernel language into the core specification
    for significantly enhanced parallel programming productivity
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCL 2.2将OpenCL C++内核语言纳入核心规范，显著增强了并行编程的生产力
- en: The OpenCL C++ kernel language is a static subset of the C++14 standard and
    includes classes, templates, Lambda expressions, function overloads, and many
    other constructs for generic and meta-programming
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCL C++内核语言是C++14标准的静态子集，包括类、模板、Lambda表达式、函数重载和许多其他用于通用和元编程的构造
- en: Leverages the new Khronos SPIR-V 1.1 intermediate language that fully supports
    the OpenCL C++ kernel language
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用全面支持OpenCL C++内核语言的新Khronos SPIR-V 1.1中间语言
- en: OpenCL library functions can now take advantage of the C++ language to provide
    increased safety and reduced undefined behavior while accessing features such
    as atomics, iterators, images, samplers, pipes, and device queue built-in types
    and address spaces
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCL库函数现在可以利用C++语言来提供更高的安全性和减少未定义行为，同时访问原子操作、迭代器、图像、采样器、管道和设备队列内置类型和地址空间
- en: Pipe storage is a new device-side type in OpenCL 2.2 that is useful for FPGA
    implementations by making the connectivity size and type known at compile time
    and enabling efficient device-scope communication between kernels
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道存储是OpenCL 2.2中的一种新的设备端类型，对于FPGA实现非常有用，因为它可以在编译时知道连接大小和类型，并能够在内核之间实现高效的设备范围通信
- en: 'OpenCL 2.2 also includes features for enhanced optimization of generated code:
    Applications can provide the value of specialization constant at SPIR-V compilation
    time, a new query can detect non-trivial constructors and destructors of program-scope
    global objects, and user callbacks can be set at program release time'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCL 2.2还包括增强生成代码的功能：应用程序可以在SPIR-V编译时提供特化常量的值，新的查询可以检测程序范围全局对象的非平凡构造函数和析构函数，用户回调可以在程序释放时设置
- en: Runs on any OpenCL 2.0-capable hardware (only driver update required)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可在任何支持OpenCL 2.0的硬件上运行（只需要更新驱动程序）
- en: Setting up a development environment
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置开发环境
- en: Regardless of which platform and GPU you have, the most important part of doing
    OpenCL development is to obtain the OpenCL runtime for one's GPU from its manufacturer.
    Here, AMD, Intel, and NVidia all provide an SDK for all mainstream platforms.
    For NVidia, OpenCL support is included in the CUDA SDK.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪个平台和GPU，进行OpenCL开发最重要的部分是从制造商那里获取适用于自己GPU的OpenCL运行时。在这里，AMD、Intel和Nvidia都为所有主流平台提供SDK。对于Nvidia，OpenCL支持包含在CUDA
    SDK中。
- en: Along with the GPU vendor's SDK, one can also find details on their website
    on which GPUs are supported by this SDK.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了GPU供应商的SDK之外，人们还可以在他们的网站上找到有关该SDK支持哪些GPU的详细信息。
- en: Linux
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Linux
- en: After installing the vendor's GPGPU SDK using the provided instructions, we
    still need to download the OpenCL headers. Unlike the shared library and runtime
    file provided by the vendor, these headers are generic and will work with any
    OpenCL implementation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在按照提供的说明安装供应商的GPGPU SDK后，我们仍然需要下载OpenCL头文件。与供应商提供的共享库和运行时文件不同，这些头文件是通用的，可以与任何OpenCL实现一起使用。
- en: 'For Debian-based distributions, simply execute the following command line:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于Debian的发行版，只需执行以下命令行：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For other distributions, the package may be called the same, or something different.
    Consult the manual for one's distribution on how to find out the package name.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他发行版，软件包可能被称为相同的名称，或者是不同的名称。请查阅发行版的手册，了解如何找到软件包的名称。
- en: After installing the SDK and OpenCL headers, we are ready to compile our first
    OpenCL applications.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 安装SDK和OpenCL头文件后，我们就可以编译我们的第一个OpenCL应用程序了。
- en: Windows
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Windows
- en: On Windows, we can choose between developing with Visual Studio (Visual C++)
    or with the Windows port of GCC (MinGW). To stay consistent with the Linux version,
    we will be using MinGW along with MSYS2\. This means that we'll have the same
    compiler toolchain and same Bash shell and utilities, along with the Pacman package
    manager.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，我们可以选择使用Visual Studio（Visual C++）或Windows版的GCC（MinGW）进行开发。为了与Linux版本保持一致，我们将使用MinGW以及MSYS2。这意味着我们将拥有相同的编译器工具链、相同的Bash
    shell和实用程序，以及Pacman软件包管理器。
- en: 'After installing the vendor''s GPGPU SDK, as described previously, simply execute
    the following command line in an MSYS2 shell in order to install the OpenCL headers:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装供应商的GPGPU SDK后，如前所述，只需在MSYS2 shell中执行以下命令行，即可安装OpenCL头文件：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Or, execute the following command line when using the 32-bit version of MinGW:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在使用32位MinGW版本时，执行以下命令行：
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With this, the OpenCL headers are in place. We now just have to make sure that
    the MinGW linker can find OpenCL library. With the NVidia CUDA SDK, you can use
    the `CUDA_PATH` environment variable for this, or browse the install location
    of the SDK and copy the appropriate OpenCL LIB file from there to the MinGW lib
    folder, making sure not to mix the 32-bit and 64-bit files.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，OpenCL头文件就位了。现在我们只需要确保MinGW链接器可以找到OpenCL库。使用NVidia CUDA SDK，您可以使用`CUDA_PATH`环境变量，或浏览SDK的安装位置，并将适当的OpenCL
    LIB文件从那里复制到MinGW lib文件夹中，确保不要混淆32位和64位文件。
- en: With the shared library now also in place, we can compile the OpenCL applications.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在共享库也已经就位，我们可以编译OpenCL应用程序。
- en: OS X/MacOS
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OS X/MacOS
- en: Starting with OS X 10.7, an OpenCL runtime is provided with the OS. After installing
    XCode for the development headers and libraries, one can immediately start with
    OpenCL development.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从OS X 10.7开始，OS中提供了OpenCL运行时。安装XCode以获取开发头文件和库后，就可以立即开始OpenCL开发。
- en: A basic OpenCL application
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个基本的OpenCL应用程序
- en: A common example of a GPGPU application is one which calculates the Fast Fourier
    Transform (FFT). This algorithm is commonly used for audio processing and similar,
    allowing you to transform, for example, from the time domain to the frequency
    domain for analysis purposes.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的GPGPU应用程序的例子是计算快速傅里叶变换（FFT）。这个算法通常用于音频处理等领域，允许您将例如从时域到频域进行转换，以进行分析。
- en: What it does is apply a divide and conquer approach to a dataset, in order to
    calculate the DFT (Discrete Fourier Transform). It does this by splitting the
    input sequence into a fixed, small number of smaller subsequences, computing their
    DFT, and assembling these outputs in order to compose the final sequence.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 它的作用是对数据集应用分治法，以计算DFT（离散傅里叶变换）。它通过将输入序列分成固定的小数量的较小子序列，计算它们的DFT，并组装这些输出，以组成最终序列。
- en: 'This is fairly advanced mathematics, but suffice it to say that what makes
    it so ideal for GPGPU is that it''s a highly-parallel algorithm, employing the
    subdivision of data in order to speed up the calculating of the DFT, as visualized
    in this graphic:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相当高级的数学，但可以说它之所以非常适合GPGPU，是因为它是一个高度并行的算法，采用数据的分割来加速DFT的计算，如图所示：
- en: '![](img/00027.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00027.jpeg)'
- en: 'Each OpenCL application consists of at least two parts: the C++ code that sets
    up and configures the OpenCL instance, and the actual OpenCL code, also known
    as a kernel, such as this one based on the FFT demonstration example from Wikipedia:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 每个OpenCL应用程序至少由两部分组成：设置和配置OpenCL实例的C++代码，以及实际的OpenCL代码，也称为内核，例如基于维基百科FFT演示示例的这个。
- en: '[PRE3]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This OpenCL kernel shows that, like the GLSL shader language, OpenCL's kernel
    language is essentially C with a number of extensions. Although one could use
    the OpenCL C++ kernel language, this one is only available since OpenCL 2.1 (2015),
    and as a result, support and examples for it are less common than the C kernel
    language.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个OpenCL内核表明，与GLSL着色器语言一样，OpenCL的内核语言本质上是C语言，具有许多扩展。虽然可以使用OpenCL C++内核语言，但这个语言仅在OpenCL
    2.1（2015年）之后才可用，因此对它的支持和示例比C内核语言更少。
- en: 'Next is the C++ application, using which, we run the preceding OpenCL kernel:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是C++应用程序，使用它，我们运行前面的OpenCL内核：
- en: '[PRE4]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we can see here, there''s only one header we have to include in order to
    gain access to the OpenCL functions. We also specify the name of the file that
    contains the source for our OpenCL kernel. Since each OpenCL device is likely
    a different architecture, the kernel is compiled for the target device when we
    load it:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，我们只需要包含一个头文件，就可以访问OpenCL函数。我们还要指定包含我们OpenCL内核源代码的文件的名称。由于每个OpenCL设备可能是不同的架构，当我们加载内核时，内核会被编译为目标设备：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we have to obtain a list of OpenCL devices we can use, filtering it by
    GPUs:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须获取可以使用的OpenCL设备列表，并通过GPU进行过滤：
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We then create an OpenCL `context` using the GPU devices we found. The context
    manages the resources on a range of devices:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用找到的GPU设备创建一个OpenCL“context”。上下文管理一系列设备上的资源：
- en: '[PRE7]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, we will create the command queue that will contain the commands to
    be executed on the OpenCL devices:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将创建包含要在OpenCL设备上执行的命令的命令队列：
- en: '[PRE8]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In order to communicate with devices, we need to allocate buffer objects that
    will contain the data we will copy to their memory. Here, we will allocate two
    buffers, one to read and one to write:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与设备通信，我们需要分配缓冲区对象，这些对象将包含我们将复制到它们的内存中的数据。在这里，我们将分配两个缓冲区，一个用于读取，一个用于写入：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We have now got the data on the device, but still need to load the kernel on
    it. For this, we will create a kernel using the OpenCL kernel source we looked
    at earlier, using the filename we defined earlier:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据放在设备上，但仍需要在设备上加载内核。为此，我们将使用前面查看的OpenCL内核源代码创建一个内核，使用我们之前定义的文件名：
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we will compile the source as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将按以下方式编译源代码：
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, we will create the actual kernel from the binary we created:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将从我们创建的二进制文件中创建实际的内核：
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In order to pass arguments to our kernel, we have to set them here. Here, we
    will add pointers to our buffers and dimensions of the work size as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将参数传递给我们的内核，我们必须在这里设置它们。在这里，我们将添加指向我们缓冲区的指针和工作大小的维度：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now we can set the work item dimensions and execute the kernel. Here, we will
    use a kernel execution method that allows us to define the size of the work group:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以设置工作项维度并执行内核。在这里，我们将使用一种内核执行方法，允许我们定义工作组的大小：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After executing the kernel, we wish to read back the resulting information.
    For this, we tell OpenCL to copy the assigned write buffer we passed as a kernel
    argument into a newly assigned buffer. We are now free to use the data in this
    buffer as we see fit.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 执行内核后，我们希望读取生成的信息。为此，我们告诉OpenCL将分配的写缓冲区复制到新分配的缓冲区中。现在我们可以自由地使用这个缓冲区中的数据。
- en: 'However, in this example, we will not use the data:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这个例子中，我们不会使用这些数据：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Finally, we free the resources we allocated and exit.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们释放分配的资源并退出。
- en: GPU memory management
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU内存管理
- en: When using a CPU, one has to deal with a number of memory hierarchies, in the
    form of the main memory (slowest), to CPU caches (faster), and CPU registers (fastest).
    A GPU is much the same, in that, one has to deal with a memory hierarchy that
    can significantly impact the speed of one's applications.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用CPU时，我们必须处理多层内存层次结构，从主内存（最慢）到CPU缓存（更快），再到CPU寄存器（最快）。GPU也是如此，我们必须处理一个可能会显著影响应用程序速度的内存层次结构。
- en: Fastest on a GPU is also the register (or private) memory, of which we have
    quite a bit more than on the average CPU. After this, we get local memory, which
    is a memory shared by a number of processing elements. Slowest on the GPU itself
    is the memory data cache, also called texture memory. This is a memory on the
    card that is usually referred to as Video RAM (VRAM) and uses a high-bandwidth,
    but a relatively high-latency memory such as GDDR5.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU上最快的也是寄存器（或私有）内存，我们拥有的比平均CPU多得多。之后是本地内存，这是一种由多个处理单元共享的内存。GPU本身上最慢的是内存数据缓存，也称为纹理内存。这是卡上的一个内存，通常被称为视频RAM（VRAM），使用高带宽，但相对高延迟的内存，比如GDDR5。
- en: The absolute slowest is using the host system's memory (system RAM), as this
    has to travel across the PCIe bus and through various other subsystems in order
    to transfer any data. Relative to on-device memory systems, host-device communication
    is best called 'glacial'.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对最慢的是使用主机系统的内存（系统RAM），因为这需要通过PCIe总线和其他各种子系统传输数据。相对于设备内存系统，主机设备通信最好称为“冰川”。
- en: 'For AMD, Nvidia, and similar dedicated GPU devices, the memory architecture
    can be visualized like this:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AMD、Nvidia和类似的专用GPU设备，内存架构可以像这样进行可视化：
- en: '![](img/00028.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00028.jpeg)'
- en: Because of this memory layout, it is advisable to transfer any data in large
    blocks, and to use asynchronous transfers if possible. Ideally, the kernel would
    run on the GPU core and have the data streamed to it to avoid any latencies.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种内存布局，建议以大块传输任何数据，并在可能的情况下使用异步传输。理想情况下，内核将在GPU核心上运行，并将数据流式传输到它，以避免任何延迟。
- en: GPGPU and multithreading
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPGPU和多线程
- en: 'Combining multithreaded code with GPGPU can be much easier than trying to manage
    a parallel application running on an MPI cluster. This is mostly due to the following
    workflow:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 将多线程代码与GPGPU结合使用要比尝试管理在MPI集群上运行的并行应用程序容易得多。这主要是由于以下工作流程：
- en: 'Prepare data: Readying the data which we want to process, such as a large set
    of images, or a single large image, by sending it to the GPU''s memory.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据：准备要处理的数据，比如大量的图像或单个大图像，将其发送到GPU的内存中。
- en: 'Prepare kernel: Loading the OpenCL kernel file and compiling it into an OpenCL
    kernel.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备内核：加载OpenCL内核文件并将其编译为OpenCL内核。
- en: 'Execute kernel: Send the kernel to the GPU and instruct it to start processing
    data.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行内核：将内核发送到GPU并指示它开始处理数据。
- en: 'Read data: Once we know the processing has finished, or a specific intermediate
    state has been reached, we will read a buffer we passed along as an argument with
    the OpenCL kernel in order to obtain our result(s).'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取数据：一旦我们知道处理已经完成，或者已经达到特定的中间状态，我们将读取我们作为OpenCL内核参数传递的缓冲区，以获取我们的结果。
- en: As this is an asynchronous process, one can treat this as a fire-and-forget
    operation, merely having a single thread dedicated to monitoring the process of
    the active kernels.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个异步过程，可以将其视为一种“发射并忘记”的操作，只需有一个专用线程来监视活动内核的过程。
- en: The biggest challenge in terms of multithreading and GPGPU applications lies
    not with the host-based application, but with the GPGPU kernel or shader program
    running on the GPU, as it has to coordinate memory management and processing between
    both local and distant processing units, determine which memory systems to use
    depending on the type of data without causing problems elsewhere in the processing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程和GPGPU应用方面最大的挑战不在于基于主机的应用程序，而是在于运行在GPU上的GPGPU内核或着色器程序，因为它必须在本地和远程处理单元之间协调内存管理和处理，确定根据数据类型使用哪种内存系统，而不会在处理其他地方引起问题。
- en: This is a delicate process involving a lot of trial and error, profiling and
    optimizations. One memory copy optimization or use of an asynchronous operation
    instead of a synchronous one may cut processing time from many hours to just a
    couple. A good understanding of the memory systems is crucial to preventing data
    starvation and similar issues.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个需要大量试错、分析和优化的细致过程。一个内存复制优化或使用异步操作而不是同步操作可能会将处理时间从几个小时减少到几分钟。对内存系统的良好理解对于防止数据饥饿和类似问题至关重要。
- en: Since GPGPU is generally used to accelerate tasks of significant duration (minutes
    to hours, or longer), it is probably best regarded from a multithreading perspective
    as a common worker thread, albeit with a few important complications, mostly in
    the form of latency.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPGPU通常用于加速持续时间显著的任务（几分钟到几小时甚至更长），因此最好从多线程的角度来看待它，尽管存在一些重要的复杂性，主要是延迟的形式。
- en: Latency
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 延迟
- en: As we touched upon in the earlier section on GPU memory management, it is highly
    preferable to use the memory closest to the GPU's processing units first, as they
    are the fastest. Fastest here mostly means that they have less latency, meaning
    the time taken to request information from the memory and receiving the response.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在早期关于GPU内存管理的部分中提到的，最好首先使用最接近GPU处理单元的内存，因为它们是最快的。这里的最快主要意味着它们具有较低的延迟，意味着从内存请求信息到接收响应所花费的时间。
- en: 'The exact latency will differ per GPU, but as an example, for Nvidia''s Kepler
    (Tesla K20) architecture, one can expect a latency of:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 确切的延迟会因GPU而异，但以Nvidia的Kepler（Tesla K20）架构为例，可以期望延迟为：
- en: '**Global** memory: 450 cycles.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局**内存：450个周期。'
- en: '**Constant** memory cache: 45 – 125 cycles.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常量**内存缓存：45-125个周期。'
- en: '**Local** (**shared**) memory: 45 cycles.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地**（**共享**）内存：45个周期。'
- en: These measurements are all on the CPU itself. For the PCIe bus one would have
    to expect something on the order of multiple milliseconds per transfer once one
    starts to transfer multi-megabyte buffers. To fill for example the GPU's memory
    with a gigabyte-sized buffer could take a considerable amount of time.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测量都是在CPU本身上进行的。对于PCIe总线，一旦开始传输多兆字节的缓冲区，一个传输可能需要几毫秒的时间。例如，填充GPU的内存以千兆字节大小的缓冲区可能需要相当长的时间。
- en: For a simple round-trip over the PCIe bus one would measure the latency in microseconds,
    which for a GPU core running at 1+ GHz would seem like an eternity. This basically
    defines why communication between the host and GPU should be absolutely minimal
    and highly optimized.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过PCIe总线的简单往返，延迟可以用微秒来衡量，对于以1+ GHz运行的GPU核心来说，似乎是一段漫长的时间。这基本上定义了为什么主机和GPU之间的通信应该绝对最小化并且高度优化。
- en: Potential issues
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 潜在问题
- en: A common mistake with GPGPU applications is reading the result buffer before
    the processing has finished. After transferring the buffer to the device and executing
    the kernel, one has to insert synchronization points to signal the host that it
    has finished processing. These generally should be implemented using asynchronous
    methods.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: GPGPU应用的一个常见错误是在处理完成之前读取结果缓冲区。在将缓冲区传输到设备并执行内核之后，必须插入同步点以通知主机处理已经完成。这些通常应该使用异步方法实现。
- en: As we just covered in the section on latency, it's important to keep in mind
    the potentially very large delays between a request and response, depending on
    the memory sub-system or bus. Failure to do so may cause weird glitches, freezes
    and crashes, as well as data corruption and an application which will seemingly
    wait forever.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在延迟部分中所介绍的，重要的是要记住请求和响应之间可能存在非常大的延迟，这取决于内存子系统或总线。不这样做可能会导致奇怪的故障、冻结和崩溃，以及数据损坏和似乎永远等待的应用程序。
- en: It is crucial to profile a GPGPU application to get a good idea of what the
    GPU utilization is, and whether the process flow is anywhere near being optimal.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPGPU应用进行分析是至关重要的，以便了解GPU利用率如何，以及流程是否接近最佳状态。
- en: Debugging GPGPU applications
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试GPGPU应用
- en: The biggest challenge with GPGPU applications is that of debugging a kernel.
    CUDA comes with a simulator for this reason, which allows one to run and debug
    a kernel on a CPU. OpenCL allows one to run a kernel on a CPU without modification,
    although this may not get the exact same behavior (and bugs) as when run on a
    specific GPU device.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: GPGPU应用的最大挑战是调试内核。CUDA出于这个原因带有一个模拟器，它允许在CPU上运行和调试内核。OpenCL允许在CPU上运行内核而无需修改，尽管这可能不会得到与在特定GPU设备上运行时相同的行为（和错误）。
- en: A slightly more advanced method involves the use of a dedicated debugger such
    as Nvidia's Nsight, which comes in versions both for Visual Studio ([https://developer.nvidia.com/nvidia-nsight-visual-studio-edition](https://developer.nvidia.com/nvidia-nsight-visual-studio-edition))
    and Eclipse ([https://developer.nvidia.com/nsight-eclipse-edition](https://developer.nvidia.com/nsight-eclipse-edition)).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一个稍微更高级的方法涉及使用专用调试器，例如Nvidia的Nsight，它有适用于Visual Studio（[https://developer.nvidia.com/nvidia-nsight-visual-studio-edition](https://developer.nvidia.com/nvidia-nsight-visual-studio-edition)）和Eclipse（[https://developer.nvidia.com/nsight-eclipse-edition](https://developer.nvidia.com/nsight-eclipse-edition)）的版本。
- en: 'According to the marketing blurb on the Nsight website:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Nsight网站上的营销宣传：
- en: NVIDIA Nsight Visual Studio Edition brings GPU computing into Microsoft Visual
    Studio (including multiple instances of VS2017). This application development
    environment for GPUs allows you to build, debug, profile and trace heterogeneous
    compute, graphics, and virtual reality applications built with CUDA C/C++, OpenCL,
    DirectCompute, Direct3D, Vulkan API, OpenGL, OpenVR, and the Oculus SDK.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA Nsight Visual Studio Edition将GPU计算引入了Microsoft Visual Studio（包括VS2017的多个实例）。这个GPU的应用程序开发环境允许您构建、调试、分析和跟踪使用CUDA
    C/C++、OpenCL、DirectCompute、Direct3D、Vulkan API、OpenGL、OpenVR和Oculus SDK构建的异构计算、图形和虚拟现实应用程序。
- en: 'The following screenshot shows an active CUDA debug session:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了一个活跃的CUDA调试会话：
- en: '![](img/00029.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00029.jpeg)'
- en: A big advantage of such a debugger tool is that it allows one to monitor, profile
    and optimize one's GPGPU application by identifying bottlenecks and potential
    problems.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这样一个调试工具的一个很大的优势是，它允许用户通过识别瓶颈和潜在问题来监视、分析和优化自己的GPGPU应用程序。
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at how to integrate GPGPU processing into a C++ application
    in the form of OpenCL. We also looked at the GPU memory hierarchy and how this
    impacts performance, especially in terms of host-device communication.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看了如何将GPGPU处理集成到C++应用程序中，以OpenCL的形式。我们还研究了GPU内存层次结构以及这如何影响性能，特别是在主机设备通信方面。
- en: You should now be familiar with GPGPU implementations and concepts, along with
    how to create an OpenCL application, and how to compile and run it. How to avoid
    common mistakes should also be known.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该熟悉GPGPU的实现和概念，以及如何创建一个OpenCL应用程序，以及如何编译和运行它。如何避免常见错误也应该是已知的。
- en: As this is the final chapter of this book, it is hoped that all major questions
    have been answered, and that the preceding chapters, along with this one, have
    been informative and helpful in some fashion.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本书的最后一章，希望所有主要问题都已得到解答，并且前面的章节以及本章在某种程度上都是有益的和有帮助的。
- en: Moving on from this book, the reader may be interested in pursuing any of the
    topics covered in more detail, for which many resources are available both online
    and offline. The topic of multithreading and related areas is very large and touches
    upon many applications, from business to scientific, artistic and personal applications
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从这本书开始，读者可能对更详细地探究其中任何一个主题感兴趣，而在线和离线都有许多资源可用。多线程和相关领域的主题非常广泛，涉及到许多应用，从商业到科学、艺术和个人应用。
- en: The reader may want to set up a Beowulf cluster of tehir own, or focus on GPGPU,
    or combine the two. Maybe there is a complex application they have wanted to write
    for a while, or perhaps just have fun with programming.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可能想要建立自己的Beowulf集群，或者专注于GPGPU，或者将两者结合起来。也许有一个复杂的应用程序他们想要写一段时间了，或者只是想玩编程。
