["```cpp\n1\\. For iteration 1 to N (N: number of unknowns) \n    1.1 Find a row with non-zero pivot\n    1.2 Extract the pivot row\n    1.3 Reduce other rows using pivot row\n2 Computing the solution vector through back substitution\n```", "```cpp\n$ nvcc -o gaussian_sequential.out gaussian_sequential.cu\n$ nvcc -o gaussian_single_gpu.out gaussian_single_gpu.cu\n$ $ time ./gaussian_sequential.out\n$ time ./gaussian_single_gpu.out\n```", "```cpp\nfor( int n = 0; n < N; n++ ){\n// M: number of equations, N: number of unknowns\n    for( int pr = 0; pr < M; pr++ ){\n        // finding the pivot row \n        //if pr satisfies condition for pivot i.e. is non zero \n        break; \n    }\n    for( int r = 0; r < M; r++ ){\n        // reduce all other eligible rows using the pivot row\n        double ratio = AB[r*N+n]/AB[pr*N+n]\n        for( int nn = n; nn < N + 1; nn++ ){\n            AB[r * N + nn] -= (ratio*AB[pr * N + nn]);\n        }\n    }\n}\n```", "```cpp\n$ nvprof --cpu-profiling on ./guassian_sequential.out\n```", "```cpp\n<Copy input augmented matrix AB to GPU>\n...\nfor( int n = 0; n < N; n++ ){\n// M: number of equations, N: number of unknowns\n    findPivotRowAndMultipliers<<<...>>>(); \n    extractPivotRow<<<...>>>(); \n    rowElimination<<<...>>>(); \n\n}\n```", "```cpp\n$ nvcc -o gaussian_multi_gpu_p2p.out gaussian_multi_gpu_p2p.cu\n$ time ./gaussian_multi_gpu_p2p.out\n```", "```cpp\nfor( int i = 0; i < nGPUs; i++ ){   \n    // setup P2P \n    cudaSetDevice(i);   \n    for( int j = 0; j < nGPUs; j++ ) {      \n        if (i == j) continue;      \n        cudaDeviceCanAccessPeer(&canAccessPeer, i, j);\n        if (canAccessPeer)      \n            cudaDeviceEnablePeerAccess(j, 0);    \n    } \n}\n```", "```cpp\nfor( int g = 0; g < nGPUs; g++ ){       \n    cudaSetDevice(g);       \n    //Copy  part \u2018g\u2019 of ABT to GPU \u2018g\u2019; \n}\n```", "```cpp\nfor( int n = 0; n < N; n++ ){        \n    gp = GPU that holds n;        \n    cudaSetDevice(gp);        \n    findPivotRowAndMultipliers<<<...>>>();\n    for( int g = 0; g < nGPUs; g++ ){ \n        if (g == gp) continue;\n        cudaMemcpyPeer(pivotDatag, g, pivotDatagp, gp, numBytes);\n     }  ... \n```", "```cpp\nfor( int n = 0; n < N; n++ ){\n    ...\n    for( int g = 0; g < nGPUs; g++ ){  \n        cudaSetDevice(g); \n        extractPivotRow<<<...>>>(); \n        rowElimination<<<...>>>();   \n    }  \n}  \n```", "```cpp\nfor( int g = 0; g < nGPUs; g++ ){ \n    cudaSetDevice(g);  \n    Copy  part \u2018g\u2019 of reduced ABT from GPU \u2018g\u2019 to Host; \n}\n```", "```cpp\n#include <mpi.h> \nint main(int argc, char *argv[]) {     \n    int rank,size;     \n    /* Initialize the MPI library */     \n    MPI_Init(&argc,&argv);     \n    /* Determine the calling process rank and total number of ranks */\n    MPI_Comm_rank(MPI_COMM_WORLD,&rank);     \n    MPI_Comm_size(MPI_COMM_WORLD,&size);     \n    /* Compute based on process rank */     \n    /* Call MPI routines like MPI_Send, MPI_Recv, ... */     \n    ...     \n    /* Shutdown MPI library */     \n    MPI_Finalize();     \n    return 0; \n}\n```", "```cpp\n$ mpicc -o helloWorldMPI helloWorldMPI.c\n$ mpirun -n 4 --hostfile hostsList ./helloWorldMPI\n```", "```cpp\n //MPI rank 0:Passing s_buf residing in GPU memory \n // requires it to be transferred to CPU memory\ncudaMemcpy(s_buf_h,s_buf_d,size,cudaMemcpyDeviceToHost);\nMPI_Send(s_buf_h,size,MPI_CHAR,1,100,MPI_COMM_WORLD);\n\n//MPI rank 1: r_buf received buffer needs to be \n// transferred to GPU memory before being used in GPU\nMPI_Recv(r_buf_h,size,MPI_CHAR,0,100,MPI_COMM_WORLD, &status);\ncudaMemcpy(r_buf_d,r_buf_h,size,cudaMemcpyHostToDevice);\n```", "```cpp\n//MPI rank 0\nMPI_Send(s_buf_d,size,MPI_CHAR,1,100,MPI_COMM_WORLD);\n\n//MPI rank n-1\nMPI_Recv(r_buf_d,size,MPI_CHAR,0,100,MPI_COMM_WORLD, &status);\n```", "```cpp\n$ ./configure --with-cuda\n```", "```cpp\n$ mpicc-o gaussian_multi_gpu_rdma.out gaussian_multi_gpu_rdma.cu\n$ mpirun -np 8 ./gaussian_multi_gpu_rdma.out\n```", "```cpp\nvoid gaussianEliminationOnGPU() {\n    cudaSetDevice(nodeLocalRank); //Set CUDA Device based on local rank\n    //Copy  chuck of AB Transpose from Host to GPU; \n   for( int n = 0; n < N; n++ ){ \n       prank = MPI rank that holds n; \n       if (myRank == prank) \n           findPivotRowAndMultipliers<<<...>>>(); \n       bCastPivotInfo(); // from prank to other ranks \n       extractPivotRow<<<...>>>(); \n       rowElimination<<<...>>>(); \n   //Copy  myPartOfReducedTransposeAB from GPU to Host;\n}\n```", "```cpp\nMPI_Comm loc_comm;\nMPI_Comm_split_type(MPI_COMM_WORLD, MPI_COMM_TYPE_SHARED, rank, MPI_INFO_NULL, &loc_comm);\nint local_rank = -1;\nMPI_Comm_rank(loc_comm,&local_rank);\nMPI_Comm_free(&loc_comm);\n```", "```cpp\nvoid distributeInputs() {\n    MPI_Scatterv(transposeAB, ..., myPartOfTransposeAB, recvCount, MPI_UNSIGNED, 0, MPI_COMM_WORLD); \n} \n```", "```cpp\nvoid gaussianEliminationOnGPU() { \n    cudaSetDevice(nodeLocalRank);\n     for( int n = 0; n < N; n++ ){ \n        prank = MPI rank that holds n; \n        if (myRank == prank) \n            findPivotRowAndMultipliers<<<...>>>();\n        MPI_Bcast(...); // from prank to other ranks \n        extractPivotRow<<<...>>>(); \n        rowElimination<<<...>>>(); \n}\n```", "```cpp\n$ nvcc --default-stream per-thread -o vector_addition -Xcompiler -fopenmp -lgomp vector_addition.cu\n$ nvcc --default-stream per-thread -o merging_muli_gpu -Xcompiler -fopenmp -lgomp scrImagePgmPpmPackage.cu image_merging.cu\n$ ./vector addition\n$ ./merging_muli_gpu\n```", "```cpp\ncudaMallocHost(&hostInput1, inputLength*sizeof(float));\ncudaMallocHost(&hostInput2, inputLength*sizeof(float));\ncudaMallocHost(&hostOutput, inputLength*sizeof(float));\n```", "```cpp\nfor (i = 0; i < 4; i++) {\n cudaStreamCreateWithFlags(&stream[i],cudaStreamNonBlocking);\n```", "```cpp\nfor (i = 0; i < inputLength; i += Seglen * 4) {\n    for (k = 0; k < 4; k++) {\n        cudaMemcpyAsync(... , cudaMemcpyHostToDevice, stream[k]);\n        cudaMemcpyAsync(... , cudaMemcpyHostToDevice, stream[k]);\n        vecAdd<<<Gridlen, 256, 0, stream[k]>>>(...);\n    }\n}\n```", "```cpp\ncudaGetDeviceCount(&noDevices);\ncudaStream_t *streams;\nstreams = (cudaStream_t*) malloc(sizeof(cudaStream_t) * noDevices);\n```", "```cpp\n#pragma omp parallel num_threads(noDevices)\n{\n     int block = omp_get_thread_num();\n    cudaSetDevice(block);\n    cudaStreamCreate(&streams[block]);\n```", "```cpp\ncudaMemcpyAsync(... cudaMemcpyHostToDevice,streams[block]);\ncudaMemcpyAsync(..., cudaMemcpyHostToDevice, streams[block]);\nmerging_kernel<<<gridDim,blockDim,0,streams[block]>>>(...);\ncudaMemcpyAsync(...,streams[block]); \n```", "```cpp\n$ git clone git://git.openfabrics.org/~grockah/perftest.git\n$ cd perftest \n$ ./autogen.sh \n$ export CUDA_H_PATH=<<Path to cuda.h>> \n$ ./configure \u2013prefix=$HOME/test \n$ make all install\n```", "```cpp\nFor example host to GPU memory (H-G) BW test:\nserver$ ~/test/bin/ib_write_bw -n 1000 -O -a --use_cuda\nclient $ ~/test/bin/ib_write_bw -n 1000 -O -a server.name.org\n\n//GPU to GPU memory (G-G) BW test:\nserver$ ~/test/bin/ib_write_bw -n 1000 -O -a --use_cuda\nclient $ ~/test/bin/ib_write_bw -n 1000 -O -a --use_cuda server.name.org\n```", "```cpp\nncclGroupStart(); \nfor (int i=0; i<ngpus; i++) \n{ \n    ncclAllGather(\u2026, comms[i], streams[i]); \n} \nncclGroupEnd();\n```", "```cpp\ntypedef struct device\n{\n    float *d_send;\n    float *d_recv;\n    cudaStream_t stream;\n} device_t;\n```", "```cpp\ncudaGetDeviceCount(&num_dev);\nncclComm_t *ls_comms = new ncclComm_t[num_dev];\nint *dev_ids = new int[num_dev];\nfor (int i = 0; i < num_dev; i++)\n    dev_ids[i] = i;\n```", "```cpp\nunsigned long long size = 512 * 1024 * 1024; // 2 GB\n\n// allocate device buffers and initialize device handles\ndevice_t *ls_dev = new device_t[num_dev];\nfor (int i = 0; i < num_dev; i++) {\n    cudaSetDevice(i);\n    cudaMalloc((void**)&ls_dev[i].d_send, sizeof(float) * size);\n    cudaMalloc((void**)&ls_dev[i].d_recv, sizeof(float) * size);\n    cudaMemset(ls_dev[i].d_send, 0, sizeof(float) * size);\n    cudaMemset(ls_dev[i].d_recv, 0, sizeof(float) * size);\n    cudaStreamCreate(&ls_dev[i].stream);\n}\n```", "```cpp\nncclCommInitAll(ls_comms, num_dev, dev_ids);\n```", "```cpp\nncclGroupStart();\nfor (int i = 0; i < num_dev; i++) {\n    ncclAllReduce((const void*)ls_dev[i].d_send, \n                  (void*)ls_dev[i].d_recv,\n        test_size, ncclFloat, ncclSum, \n        ls_comms[i], ls_dev[i].stream);\n}\nncclGroupEnd();\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -lnccl -o nccl ./nccl.cu\n```"]