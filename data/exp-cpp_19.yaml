- en: Implementing a Dialog-Based Search Engine
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现基于对话框的搜索引擎
- en: We have come so far in this book! We have learned the fundamentals of C++ application
    development and discussed architecting and designing world-ready applications.
    We also dove into data structures and algorithms, which are at the heart of efficient
    programming. It's now time to leverage all of these skills to design complex software,
    such as a search engine.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们已经走了这么远！我们已经学习了C++应用程序开发的基础知识，并讨论了构建和设计面向全球的应用程序。我们还深入研究了数据结构和算法，这是高效编程的核心。现在是时候利用所有这些技能来设计复杂的软件，比如搜索引擎了。
- en: With the popularity of the internet, search engines have become the most in-demand
    products out there. Most users start their journey through the web from a search
    engine. Various web search services, such as Google, Baidu, Yandex, and so on,
    receive huge amounts of traffic, serving trillions of requests daily. Search engines
    process each request in less than a second. Although they maintain thousands of
    servers to tackle the load, at the heart of their efficient processing are data
    structures and algorithms, data architecture strategies, and caching.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着互联网的普及，搜索引擎已成为最受欢迎的产品。大多数用户从搜索引擎开始他们的网络之旅。各种网络搜索服务，如Google、Baidu、Yandex等，每天接收大量的流量，处理数万亿的请求。搜索引擎在不到一秒的时间内处理每个请求。尽管它们维护了成千上万的服务器来处理负载，但它们高效处理的核心是数据结构和算法、数据架构策略和缓存。
- en: The problem of designing an efficient searching system doesn't just appear in
    web search engines. Local databases, **Customer Relationship Management** (**CRM**)
    systems, accounting software, and others need robust searching functionality.
    In this chapter, we will discover the fundamentals of search engines and discuss
    the algorithms and data structures used to build fast search engines. You will
    learn how web search engines generally work and meet the new data structures used
    in projects requiring high processing capabilities. You will also build the confidence
    to go out there and build your own search engine that will compete with existing
    ones.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 设计高效搜索系统的问题不仅出现在网络搜索引擎中。本地数据库、**客户关系管理**（**CRM**）系统、会计软件等都需要强大的搜索功能。在本章中，我们将了解搜索引擎的基础知识，并讨论用于构建快速搜索引擎的算法和数据结构。您将了解网络搜索引擎的一般工作原理，并了解需要高处理能力的项目中使用的新数据结构。您还将建立信心，去构建自己的搜索引擎，与现有的搜索引擎竞争。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding the structure of a search engine
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解搜索引擎的结构
- en: Understanding and designing an inverted index used to map keywords to documents
    in the search engine
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解和设计用于在搜索引擎中将关键词映射到文档的倒排索引
- en: Designing and building a recommendation engine for users of a search platform
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为搜索平台的用户设计和构建推荐引擎
- en: Using knowledge graphs to design a dialog-based search engine
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用知识图谱设计基于对话框的搜索引擎
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: A `g++` compiler with a `-std=c++2a` option is used to compile the examples
    throughout this chapter. You can find the source files used in this chapter at [https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用`g++`编译器和`-std=c++2a`选项来编译示例。您可以在[https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP)找到本章中使用的源文件。
- en: Understanding the structure of a search engine
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解搜索引擎的结构
- en: Imagine the billions of web pages in the world. Typing a word or phrase into
    a search engine interface returns us a long list of results in less than a second.
    The speed at which a search engine processes so many web pages is miraculous.
    How does it find the correct document so quickly? To answer this question, we
    will do the wisest thing a programmer can do design an engine of our own.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下世界上数十亿的网页。在搜索引擎界面中输入一个单词或短语，不到一秒钟就会返回一个长长的结果列表。搜索引擎如此快速地处理如此多的网页，这是奇迹般的。它是如何如此快速地找到正确的文档的呢？为了回答这个问题，我们将做程序员可以做的最明智的事情，设计我们自己的引擎。
- en: 'The following diagram shows the basic idea behind a search engine:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了搜索引擎背后的基本思想：
- en: '![](img/e863777e-e6a1-428a-9543-34793e6ebfc4.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e863777e-e6a1-428a-9543-34793e6ebfc4.png)'
- en: The **User** types in words using the search engine's **user interface**. The
    **Search engine** scans all the documents, filters them, sorts them by relevance,
    and responds to the user as fast as it can. Our main interest lies in the web
    search engine's implementation. Looking for something will require searching for
    it among billions of documents.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户**使用搜索引擎的**用户界面**输入单词。**搜索引擎**扫描所有文档，对其进行过滤，按相关性对其进行排序，并尽快向用户做出响应。我们主要关注的是网络搜索引擎的实现。寻找某物需要在数十亿的文档中进行搜索。'
- en: Let's try to devise an approach to find the phrase *Hello, world!* from among
    billions of documents (we will refer to web pages as documents for the sake of
    brevity). Scanning each document for the phrase would take a huge amount of time.
    If we consider each document to have at least 500 words, searching for a specific
    word or a combination of words would take a lot of time. It would be more practical
    to scan all the documents beforehand. This scanning process includes building
    an index of each occurrence of words in the documents and storing the information
    in a database, which is also known as **indexing documents**. When the user types
    in a phrase, the search engine will look up the words in its database and respond
    with links to documents that satisfy the query.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试着想出一种方法来从数十亿的文档中找到短语“Hello, world!”（为了简洁起见，我们将网页称为文档）。扫描每个文档以查找该短语将需要大量的时间。如果我们认为每个文档至少有500个单词，搜索特定单词或单词组合将需要很长时间。更实际的方法是事先扫描所有文档。这个扫描过程包括在文档中建立每个单词出现的索引，并将信息存储在数据库中，这也被称为**文档索引**。当用户输入一个短语时，搜索引擎将在其数据库中查找这些单词，并返回满足查询的文档链接。
- en: Before searching the documents, it wouldn't hurt for the engine to validate
    the user's input. It's not uncommon for users to have typos in phrases. Aside
    from typos, the user experience would be a lot better if the engine autocompleted
    words and phrases. For example, while the user is typing *hello*, the engine might
    suggest searching for the phrase *Hello, world!*. Some search engines keep track
    of users, storing information about their recent searches, details of the device
    they're using to make the request, and so on. For example, a user searching *how
    to restart the computer* will get an even better result if the search engine knows
    the operating system of the user. If it's a Linux distribution, the search engine
    will sort the search results so that documents describing the restarting of a
    Linux-based computer appear first.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索文档之前，引擎验证用户输入并不会有害。用户在短语中出现拼写错误并不罕见。除了拼写错误，如果引擎自动完成单词和短语，用户体验会更好。例如，当用户输入“hello”时，引擎可能建议搜索短语“Hello,
    world!”。一些搜索引擎跟踪用户，存储有关其最近搜索、请求设备的详细信息等信息。例如，如果用户搜索“如何重新启动计算机”，如果搜索引擎知道用户的操作系统，结果会更好。如果是Linux发行版，搜索引擎将对搜索结果进行排序，使描述如何重新启动基于Linux的计算机的文档首先出现。
- en: We should also be careful of new documents appearing on the web regularly. A
    background job might analyze the web continuously to find new content. We call
    this job a **crawler**, as it crawls the web and indexes documents. The crawler
    downloads documents in order to parse their contents and build an index. Already-indexed
    documents might get updated, or worse, removed. So, another background job should
    take care of updating existing documents regularly. You might encounter the term
    **spider** for tasks that crawl the web to parse documents.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该注意定期出现在网络上的新文档。后台作业可能会持续分析网络以查找新内容。我们称这个作业为**爬虫**，因为它爬行网络并索引文档。爬虫下载文档以解析其内容并构建索引。已经索引的文档可能会得到更新，或者更糟的是被删除。因此，另一个后台作业应定期更新现有文档。您可能会遇到爬行网络以解析文档的任务术语**蜘蛛**。
- en: 'The following updated diagram illustrates the structure of a search engine
    in a bit more detail:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下面更新的图表更详细地说明了搜索引擎的结构：
- en: '![](img/80b2e7a9-acbb-4672-a83c-d3bce75bde7c.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/80b2e7a9-acbb-4672-a83c-d3bce75bde7c.png)'
- en: 'Searching has a wide range of applications. Imagine the simplest form of searching—finding
    a word in an array:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索具有广泛的应用。想象一下最简单的搜索形式——在数组中查找一个单词：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Although the previous example applies to the simplest search engine, the real
    deal is designing a search engine that scales. You don't want to serve user requests
    by searching through an array of strings. Instead, you should strive to implement
    a scalable search engine that is able to search through millions of documents.
    This requires a lot of thinking and designing because everything matters, from
    the right choice of data structure to efficient algorithms for data processing.
    Let's now discuss the components of a search engine in more detail. We will incorporate
    all of the skills learned from previous chapters to design a good search engine.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的例子适用于最简单的搜索引擎，但真正的问题是设计一个可扩展的搜索引擎。您不希望通过搜索字符串数组来处理用户请求。相反，您应该努力实现一个能够搜索数百万个文档的可扩展搜索引擎。这需要大量的思考和设计，因为一切都很重要，从正确选择的数据结构到高效的数据处理算法。现在让我们更详细地讨论搜索引擎的组件。我们将整合从之前章节学到的所有技能来设计一个好的搜索引擎。
- en: Providing a convenient user interface
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供方便的用户界面
- en: 'It''s crucial to invest time and resources in building a fine-grained user
    interface that will provide an astonishing user experience. The key here is simplicity.
    The simpler the interface, the better its usage. We will use the market-dominant
    Google as an example. It has a simple input field at the center of the page. The
    user types their request in the field and the engine suggests a number of phrases:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建提供令人惊叹的用户体验的细粒度用户界面上投入时间和资源至关重要。关键在于简单。界面越简单，使用起来就越好。我们将以市场主导地位的Google为例。它在页面中央有一个简单的输入字段。用户在字段中输入请求，引擎会建议一些短语：
- en: '![](img/51e853fb-bc2e-4002-b368-fbd3e49d7057.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/51e853fb-bc2e-4002-b368-fbd3e49d7057.png)'
- en: We don't think of users as lazy people, but providing a list of suggestions
    is helpful because sometimes users don't know the exact term they are looking
    for. Let's concentrate on the structure and implementation of the suggestions
    list. After all, we are interested in solving problems rather than designing nice
    user interfaces. We will not discuss user interface design in this chapter; it
    would be better to concentrate on the backend of the search engine. However, there
    is just one thing that we should consider before moving on. The search engine
    that we are implementing here is dialog-based. The user queries the engine and
    can choose from several answers to narrow down the list of results. For example,
    suppose the user queries *a computer* and the search engine asks *a desktop or
    a laptop?*. That cuts down the search results drastically and provides a better
    result for the user. We will use a decision tree to achieve this. But, before
    that, let's understand the complexity of search engines.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不认为用户是懒惰的人，但提供建议列表是有帮助的，因为有时用户不知道他们正在寻找的确切术语。让我们集中精力在建议列表的结构和实施上。毕竟，我们对解决问题感兴趣，而不是设计漂亮的用户界面。我们不会在本章讨论用户界面设计；更好的是集中在搜索引擎的后端。然而，在继续之前，有一件事情我们应该考虑。我们正在实现的搜索引擎是基于对话的。用户查询引擎并可以从几个答案中选择以缩小结果列表。例如，假设用户查询“一台电脑”，搜索引擎会问“台式机还是笔记本？”。这会大大减少搜索结果并为用户提供更好的结果。我们将使用决策树来实现这一点。但在此之前，让我们了解搜索引擎的复杂性。
- en: First of all, there is the problem of **input tokenization**. This relates to
    both document parsing and search-phrase analysis. You might build a great query
    parser that breaks just because the user made a mistake in their query. Let's
    take a look at a couple of approaches to dealing with vague queries.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，存在**输入标记化**的问题。这涉及文档解析和搜索短语分析。您可能构建了一个很好的查询解析器，但由于用户在查询中犯了一个错误，它就会出现问题。让我们来看看处理模糊查询的一些方法。
- en: Dealing with typos in queries
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理查询中的拼写错误
- en: 'It''s not uncommon for users to make typos while typing. While it might seem
    like a simple thing, it can be a real problem for search engine designers. Searching
    through millions of documents might give unexpectedly wrong results if the user
    typed helo worl instead of hello world. You may be familiar with autosuggestions
    provided by a search engine. For example, here''s how the Google Search interface
    looks when we type with mistakes:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在输入时犯错并非罕见。虽然这似乎是一件简单的事情，但对于搜索引擎设计者来说可能会是一个真正的问题。如果用户输入了helo worl而不是hello
    world，那么在数百万份文档中进行搜索可能会产生意外的错误结果。你可能熟悉搜索引擎提供的自动建议。例如，当我们输入错误时，谷歌搜索界面是这样的：
- en: '![](img/3885d527-3de0-4b25-946d-c20714d9eb89.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3885d527-3de0-4b25-946d-c20714d9eb89.png)'
- en: Pay attention to the two lines at the bottom of the screenshot. One of them
    says Showing results for hello world, which suggests that the search engine has
    assumed that the user typed the query with typos and has taken the initiative
    of showing results for the correct query. However, there is still a possibility
    that the user did want to search for the exact words they typed. So, the user
    experience provides the next line as Search instead for helo worl.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意屏幕截图底部的两行。其中一行显示了hello world的搜索结果，这表明搜索引擎假定用户输入的查询存在拼写错误，并主动显示了正确查询的结果。然而，仍然有可能用户确实想要搜索他们输入的确切单词。因此，用户体验提供了下一行，即搜索helo
    worl的结果。
- en: So, when building search engines, we have several problems to solve, starting
    with user requests. First of all, we need to provide a convenient interface for
    users to type in their text. The interface should also interact with them to provide
    better results. This includes providing suggestions based on partially typed words,
    as discussed earlier. Making the search engine interact with the user is another
    improvement in the user interface that we are going to discuss in this chapter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在构建搜索引擎时，我们需要解决几个问题，首先是用户请求。首先，我们需要为用户提供一个方便的界面来输入他们的文本。界面还应该与用户进行交互，以提供更好的结果。这包括根据部分输入的单词提供建议，就像之前讨论的那样。使搜索引擎与用户进行交互是用户界面的另一个改进，我们将在本章中讨论。
- en: 'Next comes a check for typos or incomplete words, which is not an easy task.
    Keeping a list of all the words in a dictionary and comparing the words typed
    by the user might take a while. To solve this problem, using specific data structures
    and algorithms is a must. For example, finding the **Levenshtein distance** between
    words might be helpful when checking for typos in user queries. The Levenshtein distance
    is the number of characters that should be added, removed, or substituted in a
    word for it to be equal to another one. For example, the Levenshtein distance
    between the words *world* and *worl* is 1 because removing the letter *d* from
    *world* or adding *d* to *worl* makes these words equal. The distance between
    the words *coding* and *sitting* is 4 since the following four edits change one
    word into the other:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是检查拼写错误或不完整单词，这并不是一件容易的事。保留字典中所有单词的列表并比较用户输入的单词可能需要一段时间。为了解决这个问题，必须使用特定的数据结构和算法。例如，在检查用户查询中的拼写错误时，找到单词之间的**Levenshtein距离**可能会有所帮助。Levenshtein距离是一个单词需要添加、删除或替换的字符数，使其等于另一个单词。例如，*world*和*worl*之间的Levenshtein距离是1，因为从*world*中删除字母*d*或在*worl*中添加*d*可以使这些单词相等。*coding*和*sitting*之间的距离是4，因为以下四次编辑将一个单词变成另一个单词：
- en: coding -> cod**t**ing (insertion of **t** in the middle)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: coding -> cod**t**ing（在中间插入**t**）
- en: co**d**ting -> co**t**ting (substitution of **t** for **d**)
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: co**d**ting -> co**t**ting（将**t**替换为**d**）
- en: c**o**tting -> c**i**tting  (substitution of **i** for **o**)
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: c**o**tting -> c**i**tting（将**o**替换为**i**）
- en: '**c**itting -> **s**itting (substitution of **s** for **c**)'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**c**itting -> **s**itting（将**c**替换为**s**）'
- en: 'Now, imagine how long processing would take if we were to compare each user
    input with tens of thousands of words to find the closest ones. Another approach
    would be to use a big **trie** (data structure) to discover possible typos beforehand.
    A trie is an ordered search tree where keys are strings. Take a look at the following
    diagram representing a trie:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一下，如果我们要将每个用户输入与成千上万个单词进行比较以找到最接近的单词，处理将需要多长时间。另一种方法是使用一个大的**trie**（数据结构）来预先发现可能的拼写错误。Trie是一个有序搜索树，其中键是字符串。看一下下面表示trie的图表：
- en: '![](img/296999a5-2bd6-4b40-bc87-9fdf30532cc2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/296999a5-2bd6-4b40-bc87-9fdf30532cc2.png)'
- en: 'Each path represents a valid word. For example, the a node points to the n and
    r nodes. Pay attention to the # after n. It tells us that the path up to this
    node represents a word, an. However, it continues to point to d, which is then
    followed by another #, meaning that the path up to this node represents another
    word, and. The same logic applies to the rest of the trie. For example, imagine
    the portion of the trie for the word *world*:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 每条路径代表一个有效的单词。例如，a节点指向n和r节点。注意n后面的#。它告诉我们，直到这个节点的路径代表一个单词，an。然而，它继续指向d，然后是另一个#，意味着直到这个节点的路径代表另一个单词，and。对于trie的其余部分也适用相同的逻辑。例如，想象一下*world*的trie部分：
- en: '![](img/d174ec96-3f73-441a-8f25-6ebd22d5038a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d174ec96-3f73-441a-8f25-6ebd22d5038a.png)'
- en: When the engine encounters *worl*, it goes through the preceding trie. w is
    fine, as is o, and everything else is fine up until the second-to-last character
    in the word, l. In the preceding diagram, there is no terminal node after l, only
    d. That means we are sure that there is no such word as *worl;* so it might be
    *world*. To provide good suggestions and check for typos, we should have a complete
    dictionary of words in the user's language. It gets even harder when you plan
    to support multiple languages. However, while collecting and storing the dictionary
    is arguably an easy task, the harder task is collecting all the documents on the
    web and storing them accordingly to perform a fast search. The tool, program,
    or module of the search engine that collects and parses websites to build the
    search engine database (as discussed previously) is called a crawler. Before looking
    in more depth into the way we will store these website pages, let's take a quick
    look at the functionality of a crawler.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当引擎遇到*worl*时，它会通过前面的trie。w没问题，o也没问题，直到单词的倒数第二个字符l之前的所有字符都没问题。在前面的图表中，l后面没有终端节点，只有d。这意味着我们可以确定没有*worl*这样的单词；所以它可能是*world*。为了提供良好的建议和检查拼写错误，我们应该有用户语言的完整词典。当你计划支持多种语言时，情况会变得更加困难。然而，尽管收集和存储词典可以说是一项简单的任务，更困难的任务是收集所有网页文档并相应地存储以进行快速搜索。搜索引擎收集和解析网站以构建搜索引擎数据库的工具、程序或模块（如前所述）称为爬虫。在更深入地研究我们将如何存储这些网页之前，让我们快速看一下爬虫的功能。
- en: Crawling websites
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爬取网站
- en: Searching through millions of documents each time the user types a query is
    not realistic. Imagine a search engine that parses websites to search for a user
    query right after the user hits the search button on the UI of a system. That
    would take forever to complete. Each request to the website from the search engine
    takes some time. Even if it is less than a millisecond (0.001 seconds), it will
    take a long time to analyze and parse all of the websites while the user waits
    for their query to complete. To make things clearer, let's suppose accessing and
    searching one website takes about 0.5 milliseconds (even then, that's unreasonably
    fast). That means searching through 1 million websites will take around 8 minutes.
    Now imagine you open a Google search and make a query—would you wait for 8 minutes?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每次用户输入查询时搜索数百万个文档是不现实的。想象一下，当用户在系统的UI上点击搜索按钮后，搜索引擎解析网站以搜索用户查询。这将永远无法完成。搜索引擎从网站发送的每个请求都需要一些时间。即使时间少于一毫秒（0.001秒），在用户等待查询完成的同时分析和解析所有网站将需要很长时间。假设访问和搜索一个网站大约需要0.5毫秒（即使如此，这也是不合理的快）。这意味着搜索100万个网站将需要大约8分钟。现在想象一下你打开谷歌搜索并进行查询，你会等待8分钟吗？
- en: The correct approach is to store all the information in the database efficiently
    accessible by the search engine. The crawler downloads website pages and stores
    them as temporary documents until parsing and indexing take place. A complex crawler
    might also parse documents to keep them in a format more convenient for the indexer.
    The important point here is that downloading a web page is not an action that
    happens just once. The contents of a web page might get updated. Also, new pages
    might appear during this time. So, the search engine has to keep its database
    up to date. To achieve this, it schedules the crawler to download pages regularly.
    A smart crawler might compare the differences in the content before passing it
    on to the indexer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的方法是将所有信息高效地存储在数据库中，以便搜索引擎快速访问。爬虫下载网页并将它们存储为临时文档，直到解析和索引完成。复杂的爬虫可能还会解析文档，以便更方便地存储。重要的一点是，下载网页不是一次性的行为。网页的内容可能会更新。此外，在此期间可能会出现新页面。因此，搜索引擎必须保持其数据库的最新状态。为了实现这一点，它安排爬虫定期下载页面。智能的爬虫可能会在将内容传递给索引器之前比较内容的差异。
- en: Usually, the crawler works as a multithreaded application. Developers should
    take care to make crawling as fast as possible because keeping billions of documents
    up to date is not an easy task. As we have already mentioned, the search engine
    doesn't search through documents directly. It performs searches in the so-called
    index file. Although crawling is an interesting coding task, we will mostly concentrate
    on indexing in this chapter. The next section introduces indexing in the search
    engine.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，爬虫作为多线程应用程序运行。开发人员应该尽可能快地进行爬取，因为保持数十亿个文档的最新状态并不是一件容易的事。正如我们已经提到的，搜索引擎不直接搜索文档。它在所谓的索引文件中进行搜索。虽然爬取是一个有趣的编码任务，但在本章中我们将主要集中在索引上。下一节介绍搜索引擎中的索引功能。
- en: Indexing documents
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引文档
- en: 'The key functionality of search engines is indexing. The following diagram
    shows how documents downloaded by the crawler are processed to build the index
    file:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎的关键功能是索引。以下图表显示了爬虫下载的文档如何被处理以构建索引文件：
- en: '![](img/17ba8dc9-5ed9-428a-8b09-0db88bbcb4d4.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17ba8dc9-5ed9-428a-8b09-0db88bbcb4d4.png)'
- en: 'The index is shown as an **inverted index** in the preceding diagram. As you
    can see, the user queries are directed to the inverted index. Although we use
    the terms **index** and **inverted index** interchangeably in this chapter, **inverted
    index** is a more accurate name for it. First, let''s see what the index for the
    search engine is. The whole reason for indexing documents is to provide a fast
    searching functionality. The idea is simple: each time the crawler downloads documents,
    the search engine processes its contents to divide it into words that refer to
    that document. This process is called **tokenization**. Let''s say we have a document
    downloaded from Wikipedia containing the following text (for brevity, we will
    only a part of a paragraph as an example):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，索引显示为**倒排索引**。正如你所看到的，用户查询被引导到倒排索引。虽然在本章中我们在**索引**和**倒排索引**这两个术语之间交替使用，但**倒排索引**是更准确的名称。首先，让我们看看搜索引擎的索引是什么。索引文档的整个目的是提供快速的搜索功能。其思想很简单：每次爬虫下载文档时，搜索引擎会处理其内容，将其分成指向该文档的单词。这个过程称为**标记化**。假设我们从维基百科下载了一个包含以下文本的文档（为了简洁起见，我们只列出了段落的一部分作为示例）：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The search engine divides the preceding document into separate words, as follows
    (only the first few words are shown here for brevity):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎将前面的文档分成单独的单词，如下所示（出于简洁起见，这里只显示了前几个单词）：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After dividing the document into words, the engine assigns an **identifier**
    (**ID**) to each word in the document. Assuming the ID of the preceding document
    is 1, the following table shows that words refer to (occur in) the document with
    ID 1 :'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '将文档分成单词后，引擎为文档中的每个单词分配一个**标识符**（**ID**）。假设前面文档的ID是1，下表显示了单词指向（出现在）ID为1的文档： '
- en: '| In | 1 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| In | 1 |'
- en: '| 1979 | 1 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 1979 | 1 |'
- en: '| Bjarne | 1 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Bjarne | 1 |'
- en: '| Stroustrup | 1 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Stroustrup | 1 |'
- en: '| a | 1 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| a | 1 |'
- en: '| Danish | 1 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Danish | 1 |'
- en: '| computer | 1 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| computer | 1 |'
- en: '| scientist | 1 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| scientist | 1 |'
- en: '| ... |  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| ... |  |'
- en: 'There might be several documents that contain the same words, so the preceding
    table might actually look more like the following one:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有几个文档包含相同的单词，因此前表实际上可能看起来更像以下表：
- en: '| In | 1, 4, 14, 22 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| In | 1, 4, 14, 22 |'
- en: '| 1979 | 1, 99, 455 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 1979 | 1, 99, 455 |'
- en: '| Bjarne | 1, 202, 1314 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Bjarne | 1, 202, 1314 |'
- en: '| Stroustrup | 1, 1314 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Stroustrup | 1, 1314 |'
- en: '| a | 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ... |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| a | 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ... |'
- en: '| Danish | 1, 99, 102, 103 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Danish | 1, 99, 102, 103 |'
- en: '| computer | 1, 4, 5, 6, 24, 38, ... |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: 计算机 | 1, 4, 5, 6, 24, 38, ... |
- en: '| scientist | 1, 38, 101, 3958, ... |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| scientist | 1, 38, 101, 3958, ... |'
- en: 'The following table represents the inverted index. It maps words with the IDs
    of the documents downloaded by the crawler. It now becomes much faster to find
    documents that contain words typed by the user as a query. Now, when the user
    queries the engine by typing *computer*, the result is generated based on the
    ID retrieved from the index, that is, 1, 4, 5, 6, 24, 38, ... in the preceding
    example. Indexing also helps to find results for more complex queries. For example, *computer
    scientist* matches the following documents:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下表表示了倒排索引。它将单词与爬虫下载的文档的ID进行了映射。现在，当用户通过键入*computer*查询引擎时，结果是基于从索引中检索到的ID生成的，即在前面的示例中是1,
    4, 5, 6, 24, 38, ...。索引还有助于找到更复杂查询的结果。例如，*计算机科学家*匹配以下文档：
- en: '| computer | **1**, 4, 5, 6, 24, **38**, ... |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| computer | **1**, 4, 5, 6, 24, **38**, ... |'
- en: '| scientist | **1**, **38**, 101, 3958, ... |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| scientist | **1**, **38**, 101, 3958, ... |'
- en: To respond to the user with the documents that contain both terms, we should
    find the intersection of the referenced documents (see the bold numbers in the
    preceding table), for example, 1 and 38.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回应用户并提供包含两个术语的文档，我们应该找到引用文档的交集（参见前表中的粗体数字），例如，1和38。
- en: Note that the user query is also tokenized before matching it with the index.
    Tokenization usually involves word normalization. If it is not normalized, a *Computer
    Scientist* query wouldn't give any results (note the capital letters in the query).
    Let's learn a bit more about this.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，用户查询在与索引匹配之前也会被标记化。标记化通常涉及单词规范化。如果没有规范化，*计算机科学家*查询将不会返回任何结果（请注意查询中的大写字母）。让我们更多地了解一下这个。
- en: Tokenizing documents
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标记化文档
- en: You might remember the concept of tokenization from [Chapter 1](2297d785-7242-4149-8b31-f9af1fcdd833.xhtml),
    *Building C++ Applications, *where we discussed how a compiler parses the source
    files by tokenizing them into smaller, indivisible units called tokens. A search
    engine parses and tokenizes documents in a similar way.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得[第1章](2297d785-7242-4149-8b31-f9af1fcdd833.xhtml)中的标记化概念，*构建C++应用程序*，我们讨论了编译器如何通过将源文件标记化为更小的、不可分割的单元（称为标记）来解析源文件。搜索引擎以类似的方式解析和标记化文档。
- en: 'We won''t go into too much detail about this but you should consider that the
    document is processed in a way that means tokens (the indivisible terms bearing
    meaning in terms of search engine context) are normalized. For example, all of
    the words we are looking at are lowercase. So, the index table should look like
    the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讨论这个，但你应该考虑文档是以一种方式处理的，这意味着标记（在搜索引擎上下文中具有意义的不可分割的术语）是规范化的。例如，我们正在查看的所有单词都是小写的。因此，索引表应该如下所示：
- en: '| in | 1, 4, 14, 22 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| in | 1, 4, 14, 22 |'
- en: '| 1979 | 1, 99, 455 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: 1979 | 1, 99, 455 |
- en: '| bjarne | 1, 202, 1314 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| bjarne | 1, 202, 1314 |'
- en: '| stroustrup | 1, 1314 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| stroustrup | 1, 1314 |'
- en: '| a | 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ... |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| a | 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ... |'
- en: '| danish | 1, 99, 102, 103 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| danish | 1, 99, 102, 103 |'
- en: '| computer | 1, 4, 5, 6, 24, 38, ... |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| computer | 1, 4, 5, 6, 24, 38, ... |'
- en: '| scientist | 1, 38, 101, 3958, ... |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| scientist | 1, 38, 101, 3958, ... |'
- en: As C++ programmers, you might feel uncomfortable with seeing bjarne or stroustrup
    in lowercase. However, as we are matching the user input with the inverted index
    keys, we should consider that the user input might not have the form that we expect
    it to have. So, we need to apply the same rules to the user input so that it matches
    that of the inverted index.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作为C++程序员，看到bjarne或stroustrup变成小写可能会让您感到不舒服。然而，由于我们正在将用户输入与倒排索引键进行匹配，我们应该考虑用户输入可能不具有我们期望的形式。因此，我们需要对用户输入应用相同的规则，以使其与倒排索引的形式匹配。
- en: 'Next, pay attention to a. Without exaggeration, that''s a word that appears
    in every document. Other examples of this are the words *the*, *an*, *in*, and
    so on. We refer to them as **stop words**; they are filtered out before the actual
    processing. Usually, search engines ignore them, so the inverted index updates
    to the following form:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，注意a。毫不夸张地说，这是每个文档中都出现的一个词。其他类似的例子是*the*，*an*，*in*等词。我们称它们为**停用词**；它们在实际处理之前被过滤掉。通常，搜索引擎会忽略它们，因此倒排索引更新为以下形式：
- en: '| 1979 | 1, 99, 455 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 1979 | 1, 99, 455 |'
- en: '| bjarne | 1, 202, 1314 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| bjarne | 1, 202, 1314 |'
- en: '| stroustrup | 1, 1314 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| stroustrup | 1, 1314 |'
- en: '| danish | 1, 99, 102, 103 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| danish | 1, 99, 102, 103 |'
- en: '| computer | 1, 4, 5, 6, 24, 38, ... |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| computer | 1, 4, 5, 6, 24, 38, ... |'
- en: '| scientist | 1, 38, 101, 3958, ... |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| scientist | 1, 38, 101, 3958, ... |'
- en: You should note that normalization is not just making words lowercase. It also
    involves changing words to their normal forms.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该注意，规范化不仅仅是将单词变成小写。它还涉及将单词转换为它们的正常形式。
- en: Normalizing a word to its root form (or to its word stem) is also called **stemming**.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 将单词规范化为其根形式（或其词干）也称为**词干提取**。
- en: 'Take a look at the following sentence from the document we used as an example
    at the beginning of the section:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下我们在本节开头使用的文档中的以下句子：
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'creating, originated, and Stroustrup''s are normalized, so the inverted index
    will have the following form:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: creating，originated和Stroustrup's已经被规范化，因此倒排索引将具有以下形式：
- en: '| motivation | 1 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| motivation | 1 |'
- en: '| **create** | 1 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| **create** | 1 |'
- en: '| new | 1 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| new | 1 |'
- en: '| language | 1 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| language | 1 |'
- en: '| **originate** | 1 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **originate** | 1 |'
- en: '| **stroustrup** | 1 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| **stroustrup** | 1 |'
- en: '| experience | 1 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| experience | 1 |'
- en: '| programming | 1 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| programming | 1 |'
- en: '| phd | 1 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| phd | 1 |'
- en: '| thesis | 1 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| thesis | 1 |'
- en: Also, note that we have ignored the stop words and didn't include *the* in the
    preceding table.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，我们已经忽略了停用词，并且在前面的表中没有包括*the*。
- en: Tokenization is the first step in index creation. Besides that, we are free
    to process the input in any way that makes searching better, as shown in the next
    section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化是索引创建的第一步。除此之外，我们可以以任何使搜索更好的方式处理输入，如下一节所示。
- en: Sorting the results
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对结果进行排序
- en: Relevance is one of the most important features of search engines. Responding
    with documents that match the user input is not enough. We should rank them in
    a way that means the most relevant documents appear first.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性是搜索引擎最重要的特性之一。仅仅返回与用户输入匹配的文档是不够的。我们应该以一种方式对它们进行排名，以便最相关的文档首先出现。
- en: 'One strategy is recording the number of occurrences of each word in a document.
    For example, a document describing a computer might contain several occurrences
    of the word *computer*, and if the user searches for *a computer*, the results
    will display the document that contains the most occurrences of *computer* first.
    Here''s an example index table:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一种策略是记录文档中每个单词的出现次数。例如，描述计算机的文档可能包含单词*computer*的多次出现，如果用户搜索*a computer*，结果将显示包含最多*computer*出现次数的文档。以下是一个示例索引表：
- en: '| computer | 1{18}, 4{13}, 899{3} |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| computer | 1{18}, 4{13}, 899{3} |'
- en: '| map | 4{9}, 1342{4}, 1343{2} |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| map | 4{9}, 1342{4}, 1343{2} |'
- en: '| world | 12{1} |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| world | 12{1} |'
- en: The values in curly braces define the number of occurrences of each word in
    the document.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 花括号中的值定义了文档中每个单词的出现次数。
- en: There are numerous factors that we can consider when presenting search results
    to a user. Some search engines store user-related information in order to respond
    with personalized results. Even the program that the user uses to access the search
    engine (usually a web browser) might change the results of search platforms. For
    example, a user searching for *reinstalling the operating system* on a Linux OS
    gets results that contain *reinstalling Ubuntu* at the top of the list because
    the browser provided the search engine with the OS type and version information.
    However, taking into account privacy concerns, there are search engines that completely
    eliminate the use of personalized user data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当向用户呈现搜索结果时，我们可以考虑许多因素。一些搜索引擎会存储与用户相关的信息，以便返回个性化的结果。甚至用户用于访问搜索引擎的程序（通常是网络浏览器）也可能改变搜索平台的结果。例如，Linux操作系统上搜索*重新安装操作系统*的用户会得到包含*重新安装Ubuntu*的结果，因为浏览器提供了操作系统类型和版本信息。然而，考虑到隐私问题，有些搜索引擎完全消除了个性化用户数据的使用。
- en: Another property of a document is the date it was updated. Fresh content always
    has a higher priority. So, when returning a list of documents to the user, we
    might also reorder them in the order that their content was updated. Concern about
    the relevant ranking of documents brings us to the next section, where we will
    discuss recommendation engines.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的另一个属性是更新日期。新鲜内容始终具有更高的优先级。因此，当向用户返回文档列表时，我们可能还会按其内容更新的顺序重新排列它们。对文档的相关排名的担忧将我们带到下一节，我们将在那里讨论推荐引擎。
- en: Building a recommendation engine
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建推荐引擎
- en: We introduced **Artificial Intelligence** (**AI**) along with **machine learning**
    (**ML**) in the previous chapter. A recommendation engine could be treated as
    an AI-driven solution or a simple collection of conditional statements. Building
    a system that takes in user data and returns the options that best satisfy that
    input is a complex task. Incorporating ML into such a task might sound quite reasonable.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章介绍了**人工智能**（**AI**）和**机器学习**（**ML**）。推荐引擎可以被视为一个AI驱动的解决方案，或者一个简单的条件语句集合。构建一个接收用户数据并返回最满足该输入的选项的系统是一个复杂的任务。将ML纳入这样的任务中可能听起来相当合理。
- en: However, you should take into account the fact that a recommendation engine
    might comprise a list of rules by which data is processed before being output
    to the end user. Recommendation engines can run in both expected and unexpected
    places. For example, when browsing products on Amazon, a recommendation engine
    suggests products to us based on the product that we are currently viewing. Movie
    databases suggest new movies based on the movies we have previously watched or
    rated. It might seem unexpected to many but a recommendation engine also runs
    behind search engines.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你应该考虑到推荐引擎可能包括一系列规则，这些规则在输出给最终用户之前对数据进行处理。推荐引擎可以在预期和意想不到的地方运行。例如，在亚马逊浏览产品时，推荐引擎会根据我们当前查看的产品向我们推荐产品。电影数据库会根据我们之前观看或评分的电影向我们推荐新电影。对许多人来说，这可能看起来出乎意料，但推荐引擎也在搜索引擎背后运行。
- en: You may be familiar with the way some e-commerce platforms suggest products.
    Most of the time, the suggestions pane is titled something similar to *Customers
    who bought this, also bought...*. Recall cluster analysis, which we introduced
    in the previous chapter. Now, if we try to understand how these suggestions work
    under the hood, we will likely discover some clustering algorithms.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能熟悉一些电子商务平台推荐产品的方式。大多数情况下，建议窗格的标题类似于“购买此产品的顾客还购买了...”。回想一下我们在上一章介绍的聚类分析。现在，如果我们试图了解这些建议是如何工作的，我们可能会发现一些聚类算法。
- en: 'Let''s take a simpler look at and try to devise some recommendation mechanisms.
    Let''s take, for example, a bookstore website. John buys a book titled *Mastering
    Qt5*, so let''s put that information in the table as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简单地看一下并设想一些推荐机制。比如，一个书店网站。约翰买了一本名为“掌握Qt5”的书，那么我们可以把这个信息放在表格中：
- en: '|  |  Mastering Qt5 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| | 掌握Qt5 |'
- en: '|  John |  yes |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 约翰 | 是 |'
- en: 'Next, John decides to buy a C++ book, *Mastering C++ Programming*. Leia buys
    a book called *Design Patterns***.** Karl buys three books, called *Learning Python*,
    *Mastering Machine Learning*, and *Machine Learning with Python*. The table is
    updated and now looks like this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，约翰决定购买一本C++书籍，*掌握C++编程*。莱娅购买了一本名为*设计模式*的书。卡尔购买了三本书，名为*学习Python*、*掌握机器学习*和*Python机器学习*。表格被更新，现在看起来是这样的：
- en: '|  |  Mastering Qt5 |  Mastering C++ Programming |  Design Patterns | Learning
    Python | Mastering Machine Learning | Machine Learning with Python |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| | 掌握Qt5 | 掌握C++编程 | 设计模式 | 学习Python | 掌握机器学习 | Python机器学习 |'
- en: '|  John |  yes |  yes |  no | no | no | no |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 约翰 | 是 | 是 | 否 | 否 | 否 | 否 |'
- en: '|  Leia |  no |  no |  yes | no | no | no |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 莱娅 | 否 | 否 | 是 | 否 | 否 | 否 |'
- en: '|  Karl |  no |  no |  no |  yes |  yes |  yes |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 卡尔 | 否 | 否 | 否 | 是 | 是 | 是 |'
- en: So, now let's imagine Harut visits the website and buys two of the books listed
    earlier, *Learning Python* and *Machine Learning with Python*. Would it be reasonable
    to recommend the book *Mastering Qt5* to him? We don't think so. But we are aware
    of the books that he bought and we are also aware that one of the other users,
    Karl, bought three books, two of which are the same as the books that Harut bought.
    So, it might be reasonable to recommend *Mastering Machine Learning* to Harut
    by telling him that customers who bought those other two books also bought this
    one. That's a simple example of how a recommendation engine works from a high-level
    perspective.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，让我们想象哈鲁特访问网站并购买了之前列出的两本书，*学习Python*和*Python机器学习*。向他推荐书籍*掌握Qt5*是否合理？我们认为不合理。但我们知道他购买了哪些书，我们也知道另一个用户卡尔购买了三本书，其中两本与哈鲁特购买的书相同。因此，向哈鲁特推荐*掌握机器学习*可能是合理的，告诉他购买这两本书的其他顾客也购买了这本书。这是推荐引擎从高层次的工作原理的一个简单例子。 '
- en: Using a knowledge graph
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用知识图谱
- en: 'Now, let''s get back to our search engine. A user is searching for an eminent
    computer scientist— say, Donald Knuth. They type the name in the search field
    and get results from all over the web that are sorted to provide the best results.
    Let''s, once again, take a look at Google Search. To make the most of the user
    interface, Google shows us some brief information about the search topic. In this
    case, it shows several pictures of the great scientist and some information about
    him to the right side of the web page with the results. Here''s what that section
    looks like:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到我们的搜索引擎。用户正在搜索一位著名的计算机科学家——比如，唐纳德·克努斯。他们在搜索框中输入这个名字，然后从整个网络中得到排序后的最佳结果。再次看看谷歌搜索。为了充分利用用户界面，谷歌向我们展示了一些关于搜索主题的简要信息。在这种情况下，它在网页右侧显示了这位伟大科学家的几张图片和一些关于他的信息。这个部分看起来是这样的：
- en: '![](img/703e4005-d07b-4044-8fdd-c249be7de3e0.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/703e4005-d07b-4044-8fdd-c249be7de3e0.png)'
- en: 'This way, the search engine tries to cover the user''s basic needs to allow
    them to find the information faster without even having to visit any websites.
    What interests us most, in this case, is the suggestion box placed under the preceding
    information box. It is titled People also search for and here''s how it looks:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方式，搜索引擎试图满足用户的基本需求，让他们能够更快地找到信息，甚至无需访问任何网站。在这种情况下，我们最感兴趣的是放置在前面信息框下面的建议框。它的标题是“人们还搜索”，看起来是这样的：
- en: '![](img/97e5ef3e-1898-47e4-8368-92a7fcba26c5.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97e5ef3e-1898-47e4-8368-92a7fcba26c5.png)'
- en: These are recommendations based on the activity of users who searched for, let's
    say, Alan Turing, right after they searched for Donald Knuth. This prompted the
    recommendation engine to come up with the suggestion that if someone new is searching
    for Donald Knuth, they might also be interested in Alan Turing.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是基于搜索Donald Knuth后搜索Alan Turing的用户活动的推荐。这促使推荐引擎提出建议，即如果有人新搜索Donald Knuth，他们可能也对Alan
    Turing感兴趣。
- en: 'We can organize a similar suggestion mechanism through something that Google
    calls a **knowledge graph**. This is a graph consisting of nodes, each of which
    represents some topic, person, movie, or anything else that is searchable. A graph
    data structure is a collection of nodes and edges connecting these nodes, as in
    the following diagram:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过谷歌称之为**知识图谱**的东西来组织类似的建议机制。这是一个由节点组成的图，每个节点代表一些可搜索的主题、人物、电影或其他任何东西。图数据结构是一组节点和连接这些节点的边，就像以下图表中的那样：
- en: '![](img/45cb1241-4a3d-44db-9fde-8bb9a30d3c84.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45cb1241-4a3d-44db-9fde-8bb9a30d3c84.png)'
- en: 'In a knowledge graph, each node represents a single entity. By entity, we mean
    a city, a person, a pet, a book, or almost anything else that you can imagine.
    Now, edges in that graph represent the connections between entities. Each node
    can be connected to another by more than one node. For example, take a look at
    these two nodes:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在知识图谱中，每个节点代表一个单一实体。所谓实体，我们指的是城市、人、宠物、书籍，或者几乎你能想象到的任何其他东西。现在，图中的边代表实体之间的连接。每个节点可以通过多个节点连接到另一个节点。例如，看看这两个节点：
- en: '![](img/ca796132-cf5f-4ed1-b8f0-f703724ac5f5.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca796132-cf5f-4ed1-b8f0-f703724ac5f5.png)'
- en: 'These two nodes only contain text. We might guess that Donald Knuth is a name
    and The Art of Computer Programming is some sort of art. The essence of building
    a knowledge graph is that we can relate each node to another node that represents
    its type. The following diagram expands on the previous graph:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个节点只包含文本。我们可能猜测Donald Knuth是一个名字，而《计算机程序设计艺术》是某种艺术。建立知识图谱的本质是我们可以将每个节点与代表其类型的另一个节点相关联。以下图表扩展了之前的图表：
- en: '![](img/5e6932f4-bec8-455f-8dd5-f15a92aa7946.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e6932f4-bec8-455f-8dd5-f15a92aa7946.png)'
- en: 'Take a look at the two new nodes that we have added. One of them represents
    a **person**, while the other one a **book**. And what is even more exciting is
    that we connected the Donald Knuth node with an edge to the **person** node and
    labeled it as an is a relationship. In the same way, we have connected the **The
    Art of Computer Programming** node to the book node and so we can say that The
    Art of Computer Programmingis a book. Let''s now connect Donald Knuth to the book
    he wrote:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们添加的两个新节点。其中一个代表一个**人**，而另一个代表一本**书**。更令人兴奋的是，我们将Donald Knuth节点与**人**节点连接，并标记为is
    a关系。同样，我们将**《计算机程序设计艺术》**节点连接到书籍节点，因此我们可以说《计算机程序设计艺术》是一本书。现在让我们将Donald Knuth与他写的书连接起来：
- en: '![](img/e68dfd54-f84d-4ee7-89ef-5c187ee45498.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e68dfd54-f84d-4ee7-89ef-5c187ee45498.png)'
- en: So, now we have a complete relationship because we know that Donald Knuth is
    a person who is the author of The Art of Computer Programming, which in turn represents
    a book.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们有了一个完整的关系，因为我们知道Donald Knuth是一位作者《计算机程序设计艺术》的人，而这本书又代表一本书。
- en: 'Let''s add a couple more nodes that represent people. The following graph shows
    how we''ve added the Alan Turing and Peter Weyland nodes:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再添加几个代表人的节点。以下图表显示了我们如何添加了Alan Turing和Peter Weyland节点：
- en: '![](img/d433010e-be15-41f9-9669-d36aefa0590e.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d433010e-be15-41f9-9669-d36aefa0590e.png)'
- en: 'So, both Alan Turing and Peter Weyland are people. Now, if this is a part of
    the search engine knowledge base, then it gives us a good insight into the search
    intent of the user. When we hit the result for Donald Knuth, we know that it is
    about a person. If necessary, we can recommend that the user takes a look at the
    other people that we have accumulated knowledge of in our knowledge graph. Would
    it be reasonable to recommend that the user searching for Donald Knuth also takes
    a look at the Alan Turing and Peter  Weyland pages? Well, here comes the tricky
    part: although both are people, they are not strongly connected. So, we need something
    extra to define the relevancy of the connection between two different people.
    Take a look at the following additions to the graph:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，Alan Turing和Peter Weyland都是人。现在，如果这是搜索引擎知识库的一部分，那么它给了我们对用户搜索意图的很好洞察。当我们点击Donald
    Knuth的结果时，我们知道这是关于一个人的。如果需要，我们可以建议用户查看我们在知识图谱中积累的其他人。是否合理建议搜索Donald Knuth的用户也查看Alan
    Turing和Peter Weyland的页面？这里就有棘手的部分：尽管两者都是人，它们之间并没有强烈的联系。因此，我们需要一些额外的东西来定义两个不同人之间连接的相关性。看看图表的以下添加：
- en: '![](img/9d8c7081-485a-487e-9692-9f9e43c47eb0.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d8c7081-485a-487e-9692-9f9e43c47eb0.png)'
- en: 'It is now clear that Donald Knuth and Alan Turing share the same activity,
    presented as the **Computer Science** node, which represents a **field of study**,
    while Peter Weyland turns out to be a **fictional character.** So, the only thing
    that makes Peter Weyland and Donald Knuth related is that they are both people.
    Take a look at the numbers that we put on the edges leading from the person node
    to the Computer Science node. Let''s say we rate the relationship from **0** to
    **100**, with the latter meaning the relationship is the strongest. So, we put
    99 for both Alan Turing and Donald Knuth. We should have omitted the edge from
    Peter Weyland to Computer Science instead of putting **0**, but we have done this
    on purpose to show the contrast. Those numbers are weights. We add weights to
    the edges to emphasize the connectivity factor; that is, Alan Turing and Donald
    Knuth share the same thing and are strongly related to each other. If we add **Steve
    Jobs** as a new person in the knowledge graph, the graph will look like this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在清楚了，Donald Knuth和Alan Turing共享相同的活动，被表示为“计算机科学”节点，代表了一门研究领域，而Peter Weyland原来是一个虚构的角色。所以，Peter
    Weyland和Donald Knuth相关的唯一一件事就是他们都是人。看一下我们放在从人节点到计算机科学节点的边上的数字。假设我们将关系评分从0到100，后者表示关系最强。所以，我们为Alan
    Turing和Donald Knuth都放了99。我们本应该省略从Peter Weyland到计算机科学的边，而不是放0，但我们故意这样做来显示对比。这些数字是权重。我们给边添加权重以强调连接因素；也就是说，Alan
    Turing和Donald Knuth共享相同的事物，并且彼此之间关系密切。如果我们将Steve Jobs作为知识图中的一个新人物，图将会是这样的：
- en: '![](img/39e8ff27-3843-4762-b607-d5af7f171c25.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39e8ff27-3843-4762-b607-d5af7f171c25.png)'
- en: Take a look at the weights for the edges. Steve Jobs is somehow related to Computer
    Science, but he is mostly related to the **businessman** and **influencer** nodes.
    In the same way, we can now see that Peter Weyland shares more with Steve Jobs
    than with Donald Knuth. Now, it's more informative for a recommendation engine
    to suggest that the user searching for Donald Knuth should also take a look at
    Alan Turing because they are both people and connected to Computer Science with
    equal or near-to-equal weights. That was a great example of incorporating such
    a graph in a search engine. The next thing that we are going to do is introduce
    you to using a similar knowledge graph to build an even smarter framework to provide
    relevant search results. We call this dialog-based searching.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下边的权重。Steve Jobs与计算机科学有一定关系，但他更多地与“商人”和“影响者”节点相关。同样，我们现在可以看到Peter Weyland与Steve
    Jobs的关系比与Donald Knuth的关系更密切。现在，对于推荐引擎来说，建议搜索Donald Knuth的用户也应该看看Alan Turing更具信息量，因为他们都是人，并且与计算机科学的关系权重相等或接近相等。这是一个很好的例子，展示了如何在搜索引擎中整合这样的图。我们接下来要做的是向您介绍使用类似知识图来构建一个更智能的框架，以提供相关的搜索结果。我们称之为基于对话的搜索。
- en: Implementing a dialog-based search engine
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现基于对话的搜索引擎
- en: 'Finally, let''s tackle designing the part of our search engine that will give
    us our fine-grained user interface. As we mentioned at the beginning of the chapter,
    a dialog-based search engine involves building a user interface that asks the
    user questions related to their query. This approach is most applicable in situations
    where we have ambiguous results. For example, a user searching for Donald might
    have in mind one of the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来设计搜索引擎的一部分，这部分将为我们提供精细的用户界面。正如我们在本章开头提到的，基于对话的搜索引擎涉及构建一个用户界面，询问用户与其查询相关的问题。这种方法在我们有模糊的结果的情况下最为适用。例如，搜索Donald的用户可能心里想的是以下之一：
- en: '*Donald Knuth*, the great computer scientist'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*唐纳德·克努斯*，伟大的计算机科学家'
- en: '*Donald Duck*, the cartoon character'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*唐纳德·达克*，卡通人物'
- en: '*Donald Dunn*, the real name of Jared Dunn, the fictional character'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*唐纳德·邓恩*，杰瑞德·邓恩的真名，虚构的角色'
- en: '*Donald Trump*, the businessman and 45^(th) US president'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*唐纳德·特朗普*，商人和第45任美国总统'
- en: The preceding list is just a small example of potential results for the Donald search
    term. Now, what do search engines lacking a dialog-based approach do? They provide
    a list of relevant results for the best match for the user input. For example,
    at the time of writing this book, searching for Donald resulted in a list of websites
    all related to Donald Trump, even though I had Donald Knuth in mind. Here, we
    can see the thin line between the best match and the best match for the user.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的列表只是对Donald搜索词的潜在结果的一个小例子。那么，缺乏基于对话的方法的搜索引擎会怎么做呢？它们会为用户输入的最佳匹配提供相关结果列表。例如，在撰写本书时，搜索Donald会得到一个与Donald
    Trump相关的网站列表，尽管我当时心里想的是Donald Knuth。在这里，我们可以看到最佳匹配和用户最佳匹配之间的微妙差别。
- en: Search engines collect a lot of data to use for personalized search results.
    If the user works in the field of website development, most of their search requests
    will somehow be related to that particular field. This is quite helpful in providing
    a user with better search results. For example, a user that has a big search history,
    consisting mostly of requests related to website development, will get better,
    more focused results when searching for zepelin. The ideal search engine will
    provide websites linking to the Zeplin application for building a web UI, while
    for other users, the engine will provide results with information on the rock
    band named Led Zeppelin.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎收集大量数据用于个性化搜索结果。如果用户从事网站开发领域的工作，他们的大部分搜索请求都会与该特定领域有关。这对于提供用户更好的搜索结果非常有帮助。例如，一个搜索历史记录中大部分请求都与网站开发相关的用户，在搜索zepelin时将会得到更好、更专注的结果。理想的搜索引擎将提供链接到Zeplin应用程序用于构建Web
    UI的网站，而对于其他用户，引擎将提供有关摇滚乐队Led Zeppelin的信息的结果。
- en: 'Designing a dialog-based search engine is the next step in providing the user
    with a better interface. Now, it''s simple enough to build if we already have
    a strong knowledge base. We are going to use the concept of the knowledge graph
    described in the previous section. Let''s suppose when the user types a search
    word we fetch all the matched topics from the knowledge graph and have a list
    of potential hits for the user, as in the following diagram:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 设计基于对话框的搜索引擎是提供用户更好界面的下一步。如果我们已经有了强大的知识库，构建起来就足够简单了。我们将使用前一节中描述的知识图概念。假设当用户输入搜索词时，我们从知识图中获取所有匹配的主题，并为用户提供潜在命中列表，如下图所示：
- en: '![](img/2fcc30b2-7cd7-4d82-bd2b-7d3d5b733845.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fcc30b2-7cd7-4d82-bd2b-7d3d5b733845.png)'
- en: So, it's now much easier for the user to choose a topic and save time on recalling
    the full name. The information from the knowledge graph can be (and for some search
    engines it is) incorporated in automatic suggestions when the user is typing the
    query. Further, we are going to tackle the major components of the search engine.
    Obviously, this chapter cannot cover every aspect of the implementation, but the
    fundamental components we will discuss are enough for you to jump into the design
    and implementation of your own search engine.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，用户现在更容易选择一个主题，并节省回忆完整名称的时间。来自知识图的信息可以（对于一些搜索引擎而言）在用户输入查询时合并到自动建议中。此外，我们将着手处理搜索引擎的主要组件。显然，本章无法涵盖实现的每个方面，但我们将讨论的基本组件足以让您开始设计和实现自己的搜索引擎。
- en: 'We won''t bother with the UI part of the search engine. What concerns us most
    is the backend. When talking about the backend of an application, we usually mean
    the part that is invisible to the user. To be more specific, let''s take a look
    at the following diagram:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会去烦恼搜索引擎的用户界面部分。我们最关心的是后端。当谈论应用程序的后端时，通常指的是用户看不到的部分。更具体地说，让我们看一下下面的图表：
- en: '![](img/1ef212ea-f319-4913-a62e-db2027a3059c.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ef212ea-f319-4913-a62e-db2027a3059c.png)'
- en: 'As you can see, most of the engine lies at the backend. While the UI might
    feel simple, it is an important part of the search system overall. That''s where
    the user starts their journey and the more the UI is designed to offer the best
    possible experience, the less discomfort the user experiences when searching for
    something. We will concentrate on the backend; the following are several major
    modules that we are going to discuss:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，大部分引擎位于后端。虽然用户界面可能感觉简单，但它是整个搜索系统的重要部分。这是用户开始他们旅程的地方，界面设计得越好，用户在搜索时的不适感就越少。我们将集中在后端；以下是我们将讨论的几个主要模块：
- en: '**The query parser**: Analyzes the user query, normalizes words, and gathers
    information for each term in the query to later pass on to the query processor.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询解析器**：分析用户查询，规范化单词，并收集查询中每个术语的信息，以便稍后传递给查询处理器。'
- en: '**The query processor**: Retrieves data associated with the query using the
    index and supplementary databases and constructs the response.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询处理器**：使用索引和辅助数据库检索与查询相关的数据，并构建响应。'
- en: '**The dialog generator**: Provides more options for the user to choose from
    while searching for something. The dialog generator is a supplementary module.
    The user making requests can omit the dialog or use it to further narrow down
    the search results.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话生成器**：为用户在搜索时提供更多选择。对话生成器是一个辅助模块。发出请求的用户可以省略对话，也可以使用它来进一步缩小搜索结果。'
- en: We have skipped some of the components that are common in search engines (such
    as the crawler) and instead we will concentrate on those components that are strongly
    related to the dialog-based search engine. Let's now start with the query parser.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们跳过了一些在搜索引擎中常见的组件（如爬虫），而是集中在与基于对话框的搜索引擎密切相关的组件上。现在让我们从查询解析器开始。
- en: Implementing the query parser
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现查询解析器
- en: 'The query parser does what its name suggests: *parses* the query. As a base
    task for the query parser, we should divide the words by space. For example, the
    user query *zeplin best album* is divided into the following terms: `zeplin`,
    `best`, and `album`. The following class represents the basic query parser:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 查询解析器做的就是其名字所暗示的：*解析*查询。作为查询解析器的基本任务，我们应该通过空格来分隔单词。例如，用户查询*zeplin best album*被分成以下术语：`zeplin`，`best`和`album`。以下类表示基本的查询解析器：
- en: '[PRE4]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Take a look at the preceding `parse()` function. It''s the only public function
    in the class. We will add more private functions that are called from the `parse()`
    function to completely parse the query and get results as a `Query` object. `Query` represents
    a simple struct containing information on the query, as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下前面的`parse()`函数。这是类中唯一的公共函数。我们将添加更多的私有函数，这些函数从`parse()`函数中调用，以完全解析查询并将结果作为`Query`对象返回。`Query`表示一个简单的结构，包含有关查询的信息，如下所示：
- en: '[PRE5]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`raw_query` is the textual representation of the query that the user typed,
    while `normalized_query` is the same query after normalization. For example, if
    the user types *good books, a programmer should read*., `raw_query` is that exact
    text and `normalized_query` is *good books programmer should read*. In the following
    snippets, we don''t use `normalized_query`, but you will need it later when you
    complete the implementation. We also store tokens in the `Token` vector, where `Token`
    is a struct, as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`raw_query`是用户输入的查询的文本表示，而`normalized_query`是规范化后的相同查询。例如，如果用户输入*good books,
    a programmer should read*，`raw_query`就是这个确切的文本，而`normalized_query`是*good books
    programmer should read*。在下面的片段中，我们不使用`normalized_query`，但在完成实现时您将需要它。我们还将标记存储在`Token`向量中，其中`Token`是一个结构，如下所示：'
- en: '[PRE6]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `related` property represents a list of words that are **semantically related**
    to the token. We call two words **semantically related** if they express similar
    meanings conceptually. For example, the words *best* and *good*, or *album* and
    *collection*, can be considered semantically related. You may have guessed the
    purpose of the weight in the hash table value. We use it to store the `Weight`
    of similarity.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`related`属性表示与标记**语义相关**的单词列表。如果两个单词在概念上表达相似的含义，我们称它们为**语义相关**。例如，单词*best*和*good*，或者*album*和*collection*可以被认为是语义相关的。您可能已经猜到了哈希表值中权重的目的。我们使用它来存储相似性的`Weight`。'
- en: The range for the **weight** is something that should be configured during the
    exploitation of the search engine. Let's suppose we chose the range to be between
    0 to 99\. The weight of the similarity of the words *best* and *good* could be
    expressed as a number near to 90, while the weight of the similarity of the words
    *album* and *collection* could deviate from 40 to 70\. Choosing these numbers
    is tricky and they should be tuned in the course of the development and exploitation
    of the engine.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**权重**的范围是在利用搜索引擎的过程中应该进行配置的内容。假设我们选择的范围是从0到99。单词*best*和*good*的相似性权重可以表示为接近90的数字，而单词*album*和*collection*的相似性权重可能在40到70之间偏离。选择这些数字是棘手的，它们应该在引擎的开发和利用过程中进行调整。'
- en: Finally, `dialog_id` of the `Query` struct represents the ID of the generated
    dialog if the user chose a path suggested by the generator. We will come to this
    soon. Let's now move on to finalizing the `parse()` function.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`Query`结构的`dialog_id`表示如果用户选择了生成器建议的路径，则生成的对话的ID。我们很快就会谈到这一点。现在让我们继续完成`parse()`函数。
- en: 'Take a look at the following additions to the `QueryParser` class:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下`QueryParser`类的以下补充内容：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Although the two private functions (`tokenize` and `retrieve_word_relations`)
    are not implemented in the preceding snippet, the basic idea is that they normalize
    and collect information on the search query. Take a look at the preceding code
    before we continue on to implementing the query processor.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的代码片段中的两个私有函数（`tokenize`和`retrieve_word_relations`）没有实现，但基本思想是对搜索查询进行规范化和收集信息。在继续实现查询处理器之前，请查看前面的代码。
- en: Implementing the query processor
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现查询处理器
- en: The query processor carries out the main job of the search engine; that is,
    it retrieves the results from the search index and responds with a relevant list
    of documents according to the search query. In this section, we will also cover
    dialog generation.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 查询处理器执行搜索引擎的主要工作，即从搜索索引中检索结果，并根据搜索查询响应相关的文档列表。在本节中，我们还将涵盖对话生成。
- en: As you have seen in the previous section, the query parser constructs a `Query`
    object that contains tokens and `dialog_id`. We will use both here in the query
    processor.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在前一节中看到的，查询解析器构造了一个包含标记和`dialog_id`的`Query`对象。我们将在查询处理器中使用这两者。
- en: It is recommended to have a separate component for the dialog generator due
    to scalability concerns. For educational purposes, we will keep the implementation
    succinct, but you are free to redesign the dialog-based search engine and complete
    the implementation along with the crawler and other supplementary modules.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可扩展性问题，建议为对话生成器单独设计一个组件。出于教育目的，我们将保持实现简洁，但您可以重新设计基于对话的搜索引擎，并完成与爬虫和其他辅助模块的实现。
- en: 'The tokens in the `Query` object are used to make a request to the search index
    in order to retrieve the set of documents associated with each word. Here''s how
    the corresponding `QueryProcessor` class looks:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`Query`对象中的标记用于向搜索索引发出请求，以检索与每个单词相关联的文档集。以下是相应的`QueryProcessor`类的外观：'
- en: '[PRE8]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Consider the preceding code snippet as an introduction to the implementation.
    We want to express the fundamental idea of the `QueryProcessor` class. It has
    the `process_query()` function that retrieves documents from the index based on
    the tokens inside the query argument. The crucial role here is played by the search
    index. The way we define its construction and the way it stores documents is essential
    in terms of making fast queries. In the meantime, the dialog ID, provided as an
    additional argument, allows the `process_query()` function to request the knowledge
    base (or the knowledge graph) to retrieve more relevant tokens related to the
    query.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码片段视为实现的介绍。我们希望表达`QueryProcessor`类的基本思想。它具有`process_query()`函数，根据查询参数中的标记从索引中检索文档。这里的关键作用由搜索索引发挥。我们定义其构造方式和存储文档的方式对于进行快速查询至关重要。同时，作为附加参数提供的对话ID允许`process_query()`函数请求知识库（或知识图）以检索与查询相关的更多相关标记。
- en: It's also essential to consider that `QueryProcessor` is also responsible for
    producing dialogs (that is, defining a set of paths to offer the user possible
    scenarios for the query). The produced dialogs are sent to the user and, when
    the user makes another query, the used dialog is associated with that query by
    the dialog ID that we have seen already.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 还要考虑到`QueryProcessor`还负责生成对话（即定义一组路径，为用户提供查询的可能场景）。生成的对话将发送给用户，当用户进行另一个查询时，使用的对话将通过我们已经看到的对话ID与该查询相关联。
- en: Although the preceding implementation is mostly introductory (because the real
    size of the code is too big to fit into the chapter), it's a great fundament for
    you to move further in designing and implementing the engine.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的实现大多是介绍性的（因为实际代码的规模太大，无法放入本章），但它是您进一步设计和实现引擎的良好基础。
- en: Summary
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Building a search engine from scratch is a task for seasoned programmers. We
    have touched on many topics in this book and combined most of them in this chapter
    by designing a search engine.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始构建搜索引擎是一项需要经验丰富的程序员来完成的任务。本书涉及了许多主题，并在本章中通过设计搜索引擎将大部分主题结合起来。
- en: We have learned that web search engines are complex systems consisting of several
    components, such as the crawler, the indexer, and user interface. The crawler
    is responsible for regularly checking the web to download web pages for the search
    engine to index. Indexing results in the production of a big data structure called
    an inverted index. An inverted index, or just an index, is a data structure that
    maps words with the documents in which they have occurred.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，网络搜索引擎是由爬虫、索引器和用户界面等多个组件组成的复杂系统。爬虫负责定期检查网络，下载网页供搜索引擎索引。索引会产生一个名为倒排索引的大型数据结构。倒排索引，或者简称索引，是一种将单词与它们出现的文档进行映射的数据结构。
- en: Next, we defined what a recommendation engine is and tried to design a simple
    one for our search engine. The recommendation engine was connected to the dialog-based
    features of the search engine discussed in this chapter. A dialog-based search
    engine aims to provide targeted questions to the user to find out more about what
    the user actually intended to search for.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义了推荐引擎是什么，并尝试为我们的搜索引擎设计一个简单的推荐引擎。推荐引擎与本章讨论的基于对话的搜索引擎功能相连。基于对话的搜索引擎旨在向用户提供有针对性的问题，以更好地了解用户实际想要搜索的内容。
- en: We reached the end of the book by discussing various subjects in computer science
    from a C++ perspective. We started with the details of C++ programs and then briefly
    went through efficient problem-solving using data structures and algorithms. Knowing
    a programming language is not enough to succeed in programming. You need to tackle
    coding problems requiring intensive skills in data structures, algorithms, multithreading,
    and so on. Also, tackling different programming paradigms may greatly enhance
    your view of computer science and allow you to take a fresh look at problem-solving.
    In this book, we have touched on several programming paradigms, such as functional
    programming.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从C++的角度讨论计算机科学的各种主题，我们完成了本书的阅读。我们从C++程序的细节开始，然后简要介绍了使用数据结构和算法进行高效问题解决。了解一种编程语言并不足以在编程中取得成功。您需要解决需要数据结构、算法、多线程等技能的编码问题。此外，解决不同的编程范式可能会极大地增强您对计算机科学的认识，并使您以全新的方式看待问题解决。在本书中，我们涉及了几种编程范式，比如函数式编程。
- en: Finally, as you know by now, software development is not limited to coding only.
    Architecting and designing a project is one of the crucial steps toward successful
    application development. Chapters [10](069ab9af-21a4-4b8c-bc3f-f7bc0d9e4712.xhtml),
    *Designing World-Ready Applications, *to [16](0a4355bb-9bc6-4451-8661-fbf29155cfa2.xhtml),
    *Implementing a Dialog-Based Search*, are mostly related to the approaches to
    and strategies of designing real-world applications. Let this book be your introductory
    guide to the world of programming from a C++ developer's perspective. Develop
    your skills by developing more complex applications and share your knowledge with
    colleagues and those who are just starting their careers. One of the best ways
    to learn something new is by teaching it.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，正如您现在所知，软件开发不仅仅局限于编码。架构和设计项目是成功应用开发的关键步骤之一。第10章，*设计面向全球的应用程序*，到第16章，*实现基于对话的搜索*，大部分与设计现实世界应用程序的方法和策略有关。让本书成为您从C++开发者的角度进入编程世界的入门指南。通过开发更复杂的应用程序来发展您的技能，并与同事和刚刚开始职业生涯的人分享您的知识。学习新知识的最佳方式之一就是教授它。
- en: Questions
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the role of the crawler in a search engine?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 爬虫在搜索引擎中的作用是什么？
- en: Why do we call the search index an inverted index?
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们称搜索索引为倒排索引？
- en: What are the main rules for tokenizing words before indexing them?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 令牌化单词在索引之前的主要规则是什么？
- en: What is the role of recommendation engines?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推荐引擎的作用是什么？
- en: What is a knowledge graph?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知识图是什么？
- en: Further reading
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information, refer to the following book:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，请参考以下书籍：
- en: '*Introduction to Information Retrieval*, *Christopher Manning, et al.*, [https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719/](https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719/)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*信息检索导论*，*Christopher Manning等*，[https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719/](https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719/)'
