- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Unlocking Async Compute
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁异步计算
- en: 'In this chapter, we are going to improve our renderer by allowing compute work
    to be done in parallel with graphics tasks. So far, we have been recording and
    submitting all of our work to a single queue. We can still submit compute tasks
    to this queue to be executed alongside graphics work: in this chapter, for instance,
    we have started using a compute shader for the fullscreen lighting rendering pass.
    We don’t need a separate queue in this case as we want to reduce the amount of
    synchronization between separate queues.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过允许计算工作与图形任务并行执行来改进我们的渲染器。到目前为止，我们一直将所有工作记录并提交给单个队列。我们仍然可以向该队列提交计算任务以与图形工作一起执行：例如，在本章中，我们已经开始使用计算着色器进行全屏光照渲染过程。在这种情况下，我们不需要单独的队列，因为我们想减少不同队列之间的同步量。
- en: However, it might be beneficial to run other compute workloads on a separate
    queue and allow the GPU to fully utilize its compute units. In this chapter, we
    are going to implement a simple cloth simulation using compute shaders that will
    run on a separate compute queue. To unlock this new functionality, we will need
    to make some changes to our engine.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在单独的队列上运行其他计算工作负载可能是有益的，这样可以允许GPU充分利用其计算单元。在本章中，我们将实现一个简单的布料模拟，使用计算着色器在单独的计算队列上运行。为了解锁这一新功能，我们需要对我们的引擎进行一些修改。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Using a single timeline semaphore to avoid multiple fences
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单个时间线信号量来避免多个栅栏
- en: Adding a separate queue for async compute
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为异步计算添加单独的队列
- en: Implementing cloth simulation using async compute
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异步计算实现布料模拟
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter5](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter5)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下URL找到：[https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter5](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter5)
- en: Replacing multiple fences with a single timeline semaphore
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用单个时间线信号量替换多个栅栏
- en: In this section, we are going to explain how fences and semaphores are currently
    used in our renderer and how to reduce the number of objects we must use by taking
    advantage of timeline semaphores.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解释当前如何在我们的渲染器中使用栅栏和信号量，以及如何通过利用时间线信号量来减少我们必须使用的对象数量。
- en: Our engine already supports rendering multiple frames in parallel using fences.
    Fences must be used to ensure the GPU has finished using resources for a given
    frame. This is accomplished by waiting on the CPU before submitting a new batch
    of commands to the GPU.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的引擎已经支持使用栅栏并行渲染多个帧。必须使用栅栏来确保GPU已经完成对给定帧的资源使用。这是通过在提交新一批命令到GPU之前在CPU上等待来实现的。
- en: '![Figure 5.1 – The CPU is working on the current frame while the GPU is rendering
    the previous frame](img/B18395_05_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – CPU正在处理当前帧，而GPU正在渲染上一帧](img/B18395_05_01.jpg)'
- en: Figure 5.1 – The CPU is working on the current frame while the GPU is rendering
    the previous frame
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – CPU正在处理当前帧，而GPU正在渲染上一帧
- en: There is a downside, however; we need to create a fence for each frame in flight.
    This means we will have to manage at least two fences for double buffering and
    three if we want to support triple buffering.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个缺点；我们需要为每个正在飞行的帧创建一个栅栏。这意味着我们将至少需要管理两个栅栏来实现双缓冲，如果我们想支持三缓冲，则需要三个。
- en: We also need multiple semaphores to ensure the GPU waits for certain operations
    to complete before moving on. For instance, we need to signal a semaphore once
    rendering is complete and pass that same semaphore to the present command. This
    is needed to guarantee that rendering is complete before we try to present the
    swap chain image.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要多个信号量来确保GPU在继续之前等待某些操作完成。例如，我们需要在渲染完成后发出一个信号量，并将该信号量传递给显示命令。这是为了保证在我们尝试显示交换链图像之前渲染已完成。
- en: The following diagram illustrates two scenarios; in the first one, no semaphore
    is present, and the swapchain image could be presented to the screen while rendering
    is still in progress.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示说明了两种场景；在第一种场景中，没有信号量，交换链图像可以在渲染仍在进行时显示到屏幕上。
- en: In the second scenario, we have added a semaphore that is signaled in the render
    submission and is waited on before presenting. This ensures the correct behavior
    of the application. If we didn’t have this semaphore, we would risk presenting
    an image that is still being rendered and displaying corrupted data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种场景中，我们添加了一个在渲染提交中信号并在展示之前等待的信号量。这确保了应用程序的正确行为。如果我们没有这个信号量，我们可能会展示仍在渲染的图像，并显示损坏的数据。
- en: '![Figure 5.2 – Two scenarios illustrating the need for a semaphore between
    rendering and presentation](img/B18395_05_02.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2 – 两个场景说明了在渲染和展示之间需要信号量的必要性](img/B18395_05_02.jpg)'
- en: Figure 5.2 – Two scenarios illustrating the need for a semaphore between rendering
    and presentation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 两个场景说明了在渲染和展示之间需要信号量的必要性
- en: The situation worsens when we start to consider multiple queues. In this chapter,
    we are going to add a separate compute queue. This means that we will need to
    add more fences to wait on the CPU for compute work to complete. We will also
    need new semaphores to synchronize the compute and graphics queue to ensure the
    data produced by the compute queue is ready to be used by the graphics queue.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始考虑多个队列时，情况会变得更糟。在本章中，我们将添加一个单独的计算队列。这意味着我们需要添加更多的栅栏来等待CPU完成计算工作。我们还需要新的信号量来同步计算和图形队列，以确保计算队列产生的数据准备好被图形队列使用。
- en: Even if we weren’t using a compute queue, we might want to break our rendering
    work into multiple submissions. Each submission would need its own signal and
    wait for semaphores according to the dependencies of each workload. This can get
    out of hand quickly for large scenes that have tens, possibly hundreds, of submissions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们没有使用计算队列，我们也可能想要将我们的渲染工作分成多个提交。每个提交都需要它自己的信号和等待信号量，根据每个工作负载的依赖关系。对于有数十个甚至数百个提交的大型场景，这可能会迅速失控。
- en: Luckily for us, there is a solution. If we think about it, the fence and the
    semaphore hold the same information; they get signaled once a submission is complete.
    What if there was a way to use a single object both on the CPU and the GPU? This
    exact functionality is provided by a timeline semaphore.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们有一个解决方案。如果我们这么想，栅栏和信号量持有相同的信息；它们在提交完成后被信号。如果有一种方法可以在CPU和GPU上使用单个对象会怎样？这种确切的功能正是由时间线信号量提供的。
- en: As the name suggests, a timeline semaphore holds a monotonically increasing
    value. We can define what value we want the semaphore to be signaled with and
    what value we want to wait for. This object can be waited on by both the GPU and
    the CPU, greatly reducing the number of objects needed to implement correct synchronization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，时间线信号量保持一个单调递增的值。我们可以定义我们希望信号量被信号通知的值和希望等待的值。这个对象可以被GPU和CPU等待，大大减少了实现正确同步所需的对象数量。
- en: We are now going to show how to use timeline semaphores in Vulkan.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将展示如何在Vulkan中使用时间线信号量。
- en: Enabling the timeline semaphore extension
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用时间线信号量扩展
- en: 'The timeline semaphore feature has been promoted to core in Vulkan 1.2\. However,
    it’s not a mandatory extension, so we first need to query for support before using
    it. This is done, as usual, by enumerating the extension the device exposes and
    looking for the extension name:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 时间线信号量功能在Vulkan 1.2中被提升为核心功能。然而，它不是一个强制性的扩展，因此在使用它之前，我们首先需要查询支持。这通常是通过枚举设备暴露的扩展并查找扩展名称来完成的：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If the extension is present, we need to populate an additional structure that
    will be used at device creation, as shown in the following code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果扩展存在，我们需要填充一个额外的结构，该结构将在设备创建时使用，如下面的代码所示：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We also need to add the extension name to the list of enabled extensions:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要将扩展名添加到已启用扩展的列表中：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we use the data we just retrieved when creating the device:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用我们刚刚在创建设备时检索到的数据：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We are now ready to use a timeline semaphore in our code! We will see how to
    create a timeline semaphore in the next section.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好在我们的代码中使用时间线信号量了！我们将在下一节中看到如何创建时间线信号量。
- en: Creating a timeline semaphore
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建时间线信号量
- en: 'Creating a timeline semaphore is quite simple. We start by defining the standard
    creation structure:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建时间线信号量相当简单。我们首先定义标准的创建结构：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then need to pass an extra structure to tell the API that we want to create
    a timeline semaphore:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要传递一个额外的结构来告诉API我们想要创建一个时间线信号量：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is it! We now have a timeline semaphore that can be used in our renderer.
    In the next section, we will look at a few examples of how to use this type of
    semaphore.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们现在有一个可以用于我们的渲染器的时间线信号量。在下一节中，我们将探讨如何使用这种类型的信号量的一些示例。
- en: Waiting for a timeline semaphore on the CPU
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在CPU上等待时间线信号量
- en: 'As mentioned previously, we can wait for a timeline semaphore to be signaled
    on the CPU. The following code does just that:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以在CPU上等待时间线信号量被触发。以下代码正是这样做的：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you probably noticed, it’s possible to wait for multiple semaphores at once
    and specify a different value for each semaphore. This could be useful, for instance,
    when rendering to multiple windows, and each window uses a different semaphore.
    The `VkSemaphoreWaitInfo` structure also has a `flags` field.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，我们可以同时等待多个信号量，并为每个信号量指定不同的值。这在渲染到多个窗口时可能很有用，每个窗口使用不同的信号量。`VkSemaphoreWaitInfo`结构还有一个`flags`字段。
- en: Using the `VK_SEMAPHORE_WAIT_ANY_BIT` value in this field will terminate the
    wait as soon as one of the semaphores reaches the value we are waiting for. Otherwise,
    the wait will terminate only when all semaphores have reached their respective
    value.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在此字段中使用`VK_SEMAPHORE_WAIT_ANY_BIT`值将在任何一个信号量达到我们等待的值时终止等待。否则，只有在所有信号量都达到各自值时，等待才会终止。
- en: The last important aspect of the preceding code is the timeout value. This value
    is specified in nanoseconds. If, after the given time, the wait condition is not
    satisfied, the call will return `VK_TIMEOUT`. We usually set the timeout to infinity,
    as we absolutely need the semaphore to be signaled.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的最后一个重要方面是超时值。这个值以纳秒为单位指定。如果在给定时间内等待条件没有得到满足，调用将返回`VK_TIMEOUT`。我们通常将超时设置为无限，因为我们绝对需要信号量被触发。
- en: However, there is a risk that the wait call might never return, for instance,
    if the combination of wait and signal values leads to a deadlock on the GPU. An
    alternative approach would be to set the timeout to a relatively large value –
    1 second, for example. If the wait is not completed within this time span, there
    is likely an issue with our submission, and we can communicate the error to the
    user.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在一个风险，即等待调用可能永远不会返回，例如，如果等待和信号值的组合导致GPU上的死锁。一种替代方法是设置超时为一个相对较大的值——例如1秒。如果在这个时间间隔内等待未完成，很可能我们的提交存在问题，并且我们可以将错误信息通知用户。
- en: In this section, we have shown how to wait for a timeline semaphore on the CPU.
    In the next section, we are going to cover how to use a timeline semaphore on
    the GPU.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何在CPU上等待时间线信号量。在下一节中，我们将介绍如何在GPU上使用时间线信号量。
- en: Using a timeline semaphore on the GPU
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在GPU上使用时间线信号量
- en: In this section, we are going to show how to update a timeline semaphore value
    and how to wait for a given value on the GPU.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何更新时间线信号量的值，以及如何在GPU上等待特定的值。
- en: Note
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before we begin, we’d like to point out that we are using the `VK_KHR_synchronization2`
    extension. This extension simplifies writing code for barriers and semaphores.
    Please refer to the full code to see how this is implemented using the old APIs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们想指出我们正在使用`VK_KHR_synchronization2`扩展。这个扩展简化了屏障和信号量的代码编写。请参考完整代码，以了解如何使用旧API实现这一点。
- en: 'We start by defining the list of semaphores we want to wait for:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义我们想要等待的信号量列表：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This list can contain both standard semaphores and timeline semaphores. For
    standard semaphores, the `signal` value is ignored.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表可以包含标准信号量和时间线信号量。对于标准信号量，`signal`值被忽略。
- en: 'Similarly, we need to define a list of semaphores to wait on:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们需要定义一个要等待的信号量列表：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As before, we can use different semaphore types and the signal value is ignored
    for standard semaphores. It’s important the signal value for a timeline semaphore
    is always increased. If we were to submit the same value twice or a smaller value,
    we would get a validation error.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以使用不同的信号量类型，对于标准信号量，信号值被忽略。对于时间线信号量，信号值始终需要增加。如果我们提交相同的值两次或更小的值，将会得到一个验证错误。
- en: We also need to be careful with the values we use for waiting and signaling.
    If we were to wait for a value that is set within the same submission, we would
    deadlock the GPU. As a rule of thumb, always try to use a value that is guaranteed
    to have been set by a previous submission. The validation layers will also help
    you catch this type of error.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要小心我们用于等待和发出的值。如果我们等待在同一个提交中设置的值，我们将会使GPU陷入死锁。一般来说，始终尝试使用一个保证已被前一个提交设置的值。验证层也将帮助您捕获此类错误。
- en: 'The last step is to pass the two lists to the submit info structure:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将两个列表传递给提交信息结构：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As you probably noticed, we can now wait for and signal the same timeline semaphore
    in a submission. We also no longer need a fence. This greatly simplifies the code
    and reduces the number of synchronization objects needed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，我们现在可以在提交中等待和发出相同的时间线信号量。我们也不再需要栅栏。这极大地简化了代码并减少了所需的同步对象数量。
- en: In this section, we have shown how to enable the extension to use timeline semaphores
    and how to create and use them to wait on the CPU. Finally, we have shown how
    to wait and signal timeline semaphores on the GPU.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何启用使用时间线信号量的扩展，以及如何创建和使用它们在CPU上等待。最后，我们展示了如何在GPU上等待和发出时间线信号量。
- en: In the next section, we are going to use this newly acquired knowledge to add
    a separate queue for async compute work.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将利用新获得的知识添加一个用于异步计算工作的单独队列。
- en: Adding a separate queue for async compute
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加用于异步计算的单独队列
- en: In this section, we are going to illustrate how to use separate queues for graphics
    and compute work to make full use of our GPU. Modern GPUs have many generic compute
    units that can be used both for graphics and compute work. Depending on the workload
    for a given frame (shader complexity, screen resolution, dependencies between
    rendering passes, and so on), it’s possible that the GPU might not be fully utilized.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将说明如何使用单独的队列进行图形和计算工作，以充分利用我们的GPU。现代GPU拥有许多通用的计算单元，这些单元既可以用于图形工作，也可以用于计算工作。根据给定帧的工作负载（着色器复杂性、屏幕分辨率、渲染过程之间的依赖关系等），GPU可能无法充分利用。
- en: 'Moving some of the computation done on the CPU to the GPU using compute shaders
    can increase performance and lead to better GPU utilization. This is possible
    because the GPU scheduler can determine if any of the compute units are idle and
    assign work to them to overlap existing work:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用计算着色器将一些在CPU上完成的计算移动到GPU上可以提高性能并实现更好的GPU利用率。这是可能的，因为GPU调度器可以确定是否有任何计算单元处于空闲状态，并将工作分配给它们以重叠现有工作：
- en: '![Figure 5.3 – Top: graphics workload is not fully utilizing the GPU; Bottom:
    compute workload can take advantage of unused resources for optimal GPU utilization](img/B18395_05_03.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3 – 顶部：图形工作负载没有充分利用GPU；底部：计算工作负载可以利用未使用的资源以实现最佳的GPU利用率](img/B18395_05_03.jpg)'
- en: 'Figure 5.3 – Top: graphics workload is not fully utilizing the GPU; Bottom:
    compute workload can take advantage of unused resources for optimal GPU utilization'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 顶部：图形工作负载没有充分利用GPU；底部：计算工作负载可以利用未使用的资源以实现最佳的GPU利用率
- en: In the remainder of this section, we are going to demonstrate how to use the
    timeline semaphore introduced in the previous section to synchronize access to
    data between the two queues.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的剩余部分，我们将演示如何使用上一节中引入的时间线信号量来同步两个队列之间的数据访问。
- en: Submitting work on separate queues
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在单独的队列上提交工作
- en: We have already set up multiple queues in [*Chapter 3*](B18395_03.xhtml#_idTextAnchor045),
    *Unlocking Multi-Threading*. We now need to ensure that access to data from two
    queues is correctly synchronized; otherwise, we might access data that is out
    of date or, worse, data that hasn’t been initialized yet.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[*第3章*](B18395_03.xhtml#_idTextAnchor045)中设置了多个队列，*解锁多线程*。现在我们需要确保两个队列之间的数据访问正确同步；否则，我们可能会访问过时或更糟的数据，即尚未初始化的数据。
- en: 'The first step in this process is to create a separate command buffer. A different
    command buffer must be used for compute work, as the same command buffer can’t
    be submitted to different queues. This is easily achieved by requesting a new
    command buffer from our `GpuDevice` implementation:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程的第一个步骤是创建一个单独的命令缓冲区。由于同一个命令缓冲区不能提交到不同的队列，因此必须为计算工作使用不同的命令缓冲区。这可以通过从我们的`GpuDevice`实现请求一个新的命令缓冲区轻松实现：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, we need to create a new timeline semaphore to be used by the compute queue.
    This is the same code we have shown in the previous section, and we won’t be duplicating
    it here.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个新的时间线信号量，该信号量将被计算队列使用。这与我们在上一节中展示的代码相同，我们不会在这里重复。
- en: 'We then need to increment the value of our timeline semaphore with each compute
    submission:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要在每次计算提交时增加我们时间线信号量的值：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This code is similar to the code we showed before in relation to submitting
    timeline semaphores. The main difference is the wait stage, which must now be
    `VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT_KHR`. Now that we have the list of wait
    and signal semaphores, they are ready to be used for our submission:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与我们在提交时间线信号量之前展示的代码类似。主要区别在于等待阶段，现在必须是`VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT_KHR`。现在我们已经有了等待和信号信号量的列表，它们已准备好用于我们的提交：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Again, this should be familiar code. We want to highlight that we only add the
    wait semaphore after the first submission. If we were to wait for the semaphore
    on the first submission, we would deadlock the GPU, as the semaphore will never
    be signaled. Luckily, the validation layers will highlight this problem, and it
    can be easily corrected.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这应该是一个熟悉的代码。我们想强调的是，我们只在第一次提交后添加等待信号量。如果我们要在第一次提交时等待信号量，GPU将会死锁，因为信号量永远不会被触发。幸运的是，验证层会突出显示这个问题，并且可以很容易地纠正。
- en: 'Now that we have submitted our compute workload, we need to make sure the graphics
    queue waits until the data is ready. We can achieve this by adding the compute
    semaphore to the list of wait semaphores when submitting the graphics queue. We
    are going to highlight only the new code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提交了计算工作负载，我们需要确保图形队列等待数据准备就绪。我们可以通过在提交图形队列时将计算信号量添加到等待信号量的列表中来实现这一点。我们将只突出显示新的代码：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The same care must be taken when adding the compute semaphore to the list. We
    want to wait only if at least one compute submission has been performed. For some
    frames, we might not have any compute work pending. We don’t want to wait for
    the compute semaphore in this case, either.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在将计算信号量添加到列表时，必须采取相同的谨慎。我们只想在至少执行了一个计算提交时等待。对于某些帧，我们可能没有任何计算工作待处理。在这种情况下，我们也不希望等待计算信号量。
- en: In our case, we have set the wait stage to `VK_PIPELINE_STAGE_2_VERTEX_ATTRIBUTE_INPUT_BIT_KHR`,
    as we are modifying the vertices of our mesh. This will need adjusting if, for
    instance, you are using the compute queue to update a texture that won’t be used
    until the fragment shader stage. Using the right wait stage is important to obtain
    the best performance.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将等待阶段设置为`VK_PIPELINE_STAGE_2_VERTEX_ATTRIBUTE_INPUT_BIT_KHR`，因为我们正在修改我们的网格的顶点。如果，例如，您正在使用计算队列更新一个直到片段着色器阶段才使用的纹理，这将需要调整。使用正确的等待阶段对于获得最佳性能很重要。
- en: In this section, we have demonstrated how to retrieve a separate queue for compute
    work. We then explained how to use the newly created queue to submit compute work
    and correctly synchronize data access from different queues to ensure correct
    results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何检索用于计算工作的单独队列。然后我们解释了如何使用新创建的队列提交计算工作，并正确同步来自不同队列的数据访问以确保正确的结果。
- en: In the next section, we are going to show a concrete example by implementing
    a simple cloth simulation using compute shaders.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过实现一个简单的布料模拟来展示一个具体的示例，使用的是计算着色器。
- en: Implementing cloth simulation using async compute
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异步计算实现布料模拟
- en: In this section, we are going to implement a simple cloth simulation on the
    GPU as an example use case of a compute workload. We start by explaining why running
    some tasks on the GPU might be beneficial. Next, we provide an overview of compute
    shaders. Finally, we show how to port code from the CPU to the GPU and highlight
    some of the differences between the two platforms.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个简单的布料模拟，作为计算工作负载的示例用例。我们首先解释为什么在某些任务上运行GPU可能是有益的。接下来，我们提供一个计算着色器的概述。最后，我们展示如何将代码从CPU迁移到GPU，并突出两个平台之间的差异。
- en: Benefits of using compute shaders
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用计算着色器的优势
- en: In the past, physics simulations mainly ran on the CPU. GPUs only had enough
    compute capacity for graphics work, and most stages in the pipeline were implemented
    by dedicated hardware blocks that could only perform one task. As GPUs evolved,
    pipeline stages moved to generic compute blocks that could perform different tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，物理模拟主要在CPU上运行。GPU只有足够的计算能力来处理图形工作，并且大多数管道阶段都是由只能执行一个任务的专用硬件块实现的。随着GPU的发展，管道阶段转移到通用的计算块，这些块可以执行不同的任务。
- en: This increase both in flexibility and compute capacity has allowed engine developers
    to move some workloads on the GPU. Aside from raw performance, running some computations
    on the GPU avoids expensive copies from CPU memory to GPU memory. Memory speed
    hasn’t evolved as fast as processor speed, and moving data as little as possible
    between devices is key to application performance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活性和计算能力的增加使得引擎开发者可以将一些工作负载移动到GPU上。除了原始性能之外，在GPU上运行一些计算可以避免从CPU内存到GPU内存的昂贵复制。内存速度没有像处理器速度那样快速发展，尽可能少地在设备之间移动数据是应用程序性能的关键。
- en: In our example, the cloth simulation has to update the position of all vertices
    and copy the updated data to the GPU. Depending on the size of the mesh and the
    number of meshes to update, this could amount to a significant percentage of frame
    time.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，布料模拟必须更新所有顶点的位置并将更新的数据复制到GPU。根据网格的大小和要更新的网格数量，这可能会占帧时间的很大一部分。
- en: These workloads can also scale better on the GPU, as we can update a larger
    number of meshes in parallel.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工作负载在GPU上也可以更好地扩展，因为我们能够并行更新更多的网格。
- en: We are now going to provide an overview of how compute shaders are executed.
    If you are familiar with compute shaders or have worked with CUDA or OpenCL before,
    feel free to skim the next section.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将概述计算着色器是如何执行的。如果你熟悉计算着色器或者之前使用过CUDA或OpenCL，可以自由地浏览下一节。
- en: Compute shaders overview
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算着色器概述
- en: The GPU execution model is called **Single Instruction, Multiple Threads** (**SIMT**).
    It is similar to the **Single Instruction, Multiple Data** (**SIMD**) offered
    by modern CPUs to operate on multiple data entries with a single instruction.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: GPU执行模型被称为**单指令多线程**（**SIMT**）。它与现代CPU提供的**单指令多数据**（**SIMD**）类似，用于使用单个指令操作多个数据条目。
- en: However, GPUs operate on a larger number of data points within a single instruction.
    The other main difference is that each thread on the GPU is more flexible compared
    to a SIMD instruction. GPU architecture is a fascinating topic, but its scope
    is outside this book. We will provide references for further reading at the end
    of the chapter.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPU在单个指令中操作的数据点更多。另一个主要区别是，与SIMD指令相比，GPU上的每个线程都更加灵活。GPU架构是一个迷人的话题，但其范围超出了本书的范围。我们将在本章末尾提供进一步阅读的参考文献。
- en: Note
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: A group of threads has different names depending on the GPU vendor. You might
    see the term warp or wave being mentioned in their documentation. We are going
    to use thread group to avoid confusion.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 线程组在不同的GPU供应商中有不同的名称。你可能会在他们的文档中看到术语warp或wave。我们将使用线程组来避免混淆。
- en: 'Each compute shader invocation can use multiple threads within a compute unit,
    and it’s possible to control how many threads are used. In Vulkan, this is achieved
    with the following directive inside a compute shader:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 每个计算着色器调用可以在计算单元内使用多个线程，并且可以控制使用多少线程。在Vulkan中，这是通过计算着色器内的以下指令实现的：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This defines the local group size; we are going to explain what it does in just
    a moment. For now, the main point is that we are telling the GPU that we want
    to execute 64 threads (8x8). Each GPU has an optimal thread group size. You should
    check the documentation from each vendor and, if possible, adjust the thread group
    size for optimal performance.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这定义了局部组的大小；我们将在稍后解释它是如何工作的。目前，主要点是我们在告诉GPU我们想要执行64个线程（8x8）。每个GPU都有一个最佳线程组大小。你应该检查每个供应商的文档，并在可能的情况下调整线程组大小以获得最佳性能。
- en: 'We also have to define a global group size when invoking a compute shader:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用计算着色器时，我们还需要定义一个全局组大小：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code is taken from our lighting pass implementation. In this case, we want
    to process all the pixels in our render target texture. As you probably noticed,
    we divide the size by 8\. This is needed to ensure we don’t process the same pixel
    multiple times. Let’s walk through an example to clarify how the local and global
    group size works.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码取自我们的光照传递实现。在这种情况下，我们想要处理渲染目标纹理中的所有像素。正如你可能注意到的，我们将其大小除以8。这是确保我们不会多次处理相同像素所必需的。让我们通过一个例子来澄清局部和全局组大小的工作原理。
- en: 'Let’s say our render target is 1280x720\. Multiplying the width by the height
    will give us the total number of pixels in the image. When we define the local
    group size, we determine how many pixels are going to be processed by each shader
    invocation (again, 64 in our case). The number of shader invocations is computed
    as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的渲染目标是1280x720。将宽度乘以高度将给出图像中的总像素数。当我们定义局部组大小时，我们确定每个着色器调用将处理多少像素（在我们的例子中再次是64）。着色器调用的数量计算如下：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `dispatch` command requires three values, though, as both the local and
    global group size are defined as a vector of three values. This is why we divide
    each dimension by `8`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`dispatch`命令需要三个值，因为局部和全局组大小都被定义为三个值的向量。这就是为什么我们将每个维度除以`8`的原因：'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Since we are operating on a 2D texture, we are not modifying the `z` value.
    We can verify that we are processing the right number of pixels with this code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在处理2D纹理，我们不会修改`z`值。我们可以通过以下代码验证我们正在处理正确的像素数量：
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can determine which invocation is being run inside the shader by using this
    variable provided by GLSL:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用GLSL提供的这个变量来确定在着色器内部正在运行哪个调用：
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Each thread will see a unique position value, which we can use to access our
    texture.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程将看到一个独特的位置值，我们可以使用它来访问我们的纹理。
- en: This was only a brief overview of the compute shader execution model. We are
    going to provide more in-depth resources in the *Further* *reading* section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是计算着色器执行模型的简要概述。我们将在*进一步阅读*部分提供更深入的资源。
- en: Now that we have a better understanding of how compute shaders are executed,
    we are going to demonstrate how to convert CPU code to a GPU compute shader.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对计算着色器的执行有了更好的理解，我们将演示如何将CPU代码转换为GPU计算着色器。
- en: Writing compute shaders
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写计算着色器
- en: Writing code for compute shaders is similar to writing vertex or fragment shaders.
    The main difference is that we have more flexibility in compute shaders to define
    which data to access. For instance, in vertex shaders, we usually access a single
    entry in an attribute buffer. The same applies to fragment shaders, where the
    fragment being shaded by a shader invocation is determined by the GPU.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为计算着色器编写代码与编写顶点或片段着色器类似。主要区别在于我们在计算着色器中具有更多的灵活性来定义要访问哪些数据。例如，在顶点着色器中，我们通常访问属性缓冲区中的一个条目。同样适用于片段着色器，其中由着色器调用着色的片段由GPU确定。
- en: 'Because of the added flexibility, we also need to think more carefully about
    our access patterns and synchronization between threads. If, for instance, more
    than one thread has to write to the same memory location, we need to add memory
    barriers to ensure previous writes to that memory have completed and all threads
    see the correct value. In pseudo-code, this translates to this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于增加了灵活性，我们还需要更仔细地考虑我们的访问模式和线程之间的同步。例如，如果有多个线程必须写入相同的内存位置，我们需要添加内存屏障以确保对该内存的先前写入已完成，并且所有线程都看到正确的值。在伪代码中，这转化为以下内容：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: GLSL also provides atomic operations in case the same memory location has to
    be accessed across shader invocations.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在着色器调用之间需要访问相同的内存位置，GLSL还提供了原子操作。
- en: 'With that in mind, let’s have a look at the pseudo-code for the CPU version
    of the cloth simulation:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们看看布料模拟CPU版本的伪代码：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We used a common spring model for the cloth simulation, but its implementation
    is outside the scope of this chapter. We suggest looking at the code for more
    detail, and we also reference the paper we used in the *Further* *reading* section.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为布料模拟使用了常见的弹簧模型，但其实现超出了本章的范围。我们建议查看代码以获取更多细节，并在*进一步阅读*部分引用了我们使用的论文。
- en: As you notice, at the end of the loop, we have to copy the updated vertex, normal,
    and tangent buffers to the GPU. Depending on the number of meshes and their complexity,
    this could be a costly operation. This step could be even more costly if the cloth
    simulation were to rely on data from other systems that run on the GPU.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，在循环的末尾，我们必须将更新的顶点、法线和切线缓冲区复制到GPU上。根据网格的数量和它们的复杂性，这可能是一个昂贵的操作。如果布料模拟依赖于在GPU上运行的其它系统的数据，这一步可能会更加昂贵。
- en: If, for instance, the animation system runs on the GPU while the cloth simulation
    runs on the CPU, we now have two copies to perform, in addition to extra synchronization
    points in the pipeline. For these reasons, it can be beneficial to move the cloth
    simulation to the GPU.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果动画系统在GPU上运行，而布料模拟在CPU上运行，我们现在需要执行两个复制操作，并且在管道中还有额外的同步点。出于这些原因，将布料模拟移动到GPU上可能是有益的。
- en: 'Let’s start by looking at the vertex buffer setup:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看顶点缓冲区的设置：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is the only buffer we needed before. Because we had to update the data
    on the CPU, we could only use a host coherent buffer so that write on the CPU
    would be visible on the CPU. Using this type of buffer has performance implications
    on the GPU, as this type of memory can be slower to access, especially when the
    buffer size is large.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们之前需要的唯一缓冲区。因为我们必须在CPU上更新数据，所以我们只能使用主机一致性的缓冲区，这样CPU上的写入在CPU上才是可见的。使用这种类型的缓冲区对GPU的性能有影响，因为这种内存可能访问速度较慢，尤其是当缓冲区大小很大时。
- en: 'Since we are now going to perform the update on the GPU, we can use a buffer
    that is marked as `device_only`. This is how we create the buffer:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在将在GPU上执行更新，我们可以使用标记为`device_only`的缓冲区。这就是我们创建缓冲区的方式：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we copy the data from the CPU to the GPU only once. After the copy
    is done, we can free the CPU buffer:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们只从CPU复制一次数据到GPU。复制完成后，我们可以释放CPU缓冲区：
- en: '[PRE24]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We have shown an example of the position buffer. All the other buffers (normal,
    tangent, texture coordinates, and indices) are managed in the same way.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了位置缓冲区的示例。所有其他缓冲区（法线、切线、纹理坐标和索引）都以相同的方式进行管理。
- en: 'Now that we have our buffers, we need to create a descriptor set that will
    be used by our compute shader:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的缓冲区，我们需要创建一个将被我们的计算着色器使用的描述符集：
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can match the binding of the preceding buffers with the following shader
    code:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将前一个缓冲区的绑定与以下着色器代码相匹配：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It’s important to notice a couple of points. Because we don’t know the size
    of each buffer at runtime, we have to use separate storage blocks. We can only
    have one runtime array per storage block, and it must be the last member of the
    block.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意几个点。因为我们不知道每个缓冲区在运行时的尺寸，我们必须使用单独的存储块。每个存储块只能有一个运行时数组，并且它必须是块的最后一个成员。
- en: We also have to use float arrays instead of `vec3` arrays; otherwise, each entry
    in the vector would be padded to 16 bytes and the data on the GPU will no longer
    match the data layout on the CPU. We could use `vec4` as type, but we would be
    wasting 4 bytes for each vertex. When you have millions, if not billions, of vertices,
    it adds up!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须使用浮点数组而不是`vec3`数组；否则，向量中的每个条目都会填充到16字节，GPU上的数据将不再与CPU上的数据布局匹配。我们可以使用`vec4`作为类型，但我们会为每个顶点浪费4字节。当你有数百万，甚至数十亿个顶点时，这会累积起来！
- en: Finally, we marked the `IndexData` block as `readonly`. This is because we never
    modify the index buffer in this shader. It’s important to mark each block with
    the right attributes as this will give more opportunities for optimization to
    the shader compiler.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将`IndexData`块标记为`readonly`。这是因为在这个着色器中我们永远不会修改索引缓冲区。标记每个块为正确的属性很重要，因为这会给着色器编译器提供更多的优化机会。
- en: 'We could reduce the number of blocks by arranging our data differently, for
    example:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过不同的数据排列来减少块的数量，例如：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This solution is usually referred to as **Array of Structures** (**AoS**), while
    the code we presented before used **Structure of Arrays** (**SoA**). While the
    AoS solution simplifies the bindings, it also makes it impossible to use each
    array individually. In our depth pass, for instance, we only need the positions.
    For this reason, we preferred the SoA approach.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这种解决方案通常被称为**结构数组**（**AoS**），而之前我们展示的代码使用了**数组结构**（**SoA**）。虽然AoS解决方案简化了绑定，但它也使得无法单独使用每个数组。例如，在我们的深度遍历中，我们只需要位置信息。因此，我们更倾向于使用SoA方法。
- en: We have already shown how to dispatch a compute shader and how to synchronize
    access between the compute and graphics queue, so we won’t repeat that code here.
    We can now move to the shader implementation. We are only going to show the relevant
    section; you can refer to the code for the full listing.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了如何调度计算着色器以及如何同步计算和图形队列之间的访问，所以我们不会在这里重复那段代码。现在我们可以转向着色器实现。我们只将展示相关部分；您可以通过查看代码来获取完整的列表。
- en: 'We start by computing the force applied to each vertex:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算每个顶点所受的力：
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice how we access the `physics_vertices` array each time. In the CPU code,
    we could simply get a reference to the struct, and each field would be updated
    correctly. However, GLSL doesn’t support references, so we need to be really careful
    that we are not writing to a local variable.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们每次是如何访问`physics_vertices`数组的。在CPU代码中，我们可以简单地获取结构体的引用，并且每个字段都会被正确更新。然而，GLSL不支持引用，因此我们需要非常小心，确保我们没有写入局部变量。
- en: 'As in the CPU code, after computing the force vector for each vertex, we need
    to update its position:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与CPU代码一样，在计算每个顶点的力向量之后，我们需要更新其位置：
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Again, notice that we always read from the buffer each time. Finally, we update
    the vertex positions of the mesh:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，我们每次都从缓冲区中读取。最后，我们更新网格的顶点位置：
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Because this is all performed on the GPU, the positions could have been updated
    first by another system, such as animation, but we no longer need costly copy
    operations to and from the GPU.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因为所有这些都是在GPU上执行的，所以位置可能首先由另一个系统（如动画）更新，但我们不再需要昂贵的从GPU到GPU的复制操作。
- en: Before we conclude, we’d like to point out that we have one shader invocation
    per mesh and that performance is achieved by updating the cloth simulation for
    multiple meshes in the same dispatch. Another approach could have been to have
    one dispatch per mesh where each shader invocation updates an individual vertex.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们得出结论之前，我们想指出，我们为每个网格调用一个着色器，并且性能是通过在同一个调度中对多个网格更新布料模拟来实现的。另一种方法可能是为每个网格有一个调度，其中每个着色器调用更新一个单独的顶点。
- en: While technically a valid approach, it requires a lot more synchronization within
    the thread group and across shader invocations. As we mentioned, we first have
    to compute the force for each vertex before updating their position. Another solution
    could be to split the update into two shaders, one that computes the force and
    a second one that updates the positions.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在技术上是一个有效的方法，但它需要在线程组内以及着色器调用之间进行更多的同步。正如我们提到的，我们必须首先计算每个顶点的力，然后才能更新它们的位置。另一个解决方案可能是将更新分成两个着色器，一个用于计算力，另一个用于更新位置。
- en: This still requires pipeline barriers between each shader dispatch. While the
    GPU must guarantee that each command is executed in the same order it has been
    recorded; it doesn’t guarantee the order of completion. For these reasons, we
    have decided to use one thread per mesh.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然需要在每个着色器调度之间使用管道屏障。虽然GPU必须保证每个命令的执行顺序与记录的顺序相同；但它不保证完成的顺序。出于这些原因，我们决定为每个网格使用一个线程。
- en: In this section, we have explained the execution model of compute shaders and
    the benefits of running selected computations on the GPU to improve performance
    and avoid extra memory copies. We then demonstrated how to port code written for
    the CPU to the GPU and some of the aspects we need to pay attention to when working
    with compute shaders.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了计算着色器的执行模型以及在GPU上运行选定的计算以提高性能和避免额外的内存复制的好处。然后我们演示了如何将针对CPU编写的代码移植到GPU上，以及在使用计算着色器时需要注意的一些方面。
- en: We suggest looking at the code for more details. Try to make changes to the
    cloth simulation to implement a different simulation technique or add your own
    compute shaders to the engine!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议查看代码以获取更多细节。尝试对布料模拟进行修改以实现不同的模拟技术，或者向引擎中添加您自己的计算着色器！
- en: Summary
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have built the foundations to support compute shaders in
    our renderer. We started by introducing timeline semaphores and how they can be
    used to replace multiple semaphores and fences. We have shown how to wait for
    a timeline semaphore on the CPU and how a timeline semaphore can be used as part
    of a queue submission, either for it to be signaled or to be waited on.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为我们的渲染器构建了支持计算着色器的基础。我们首先介绍了时间线信号量和它们如何被用来替换多个信号量和栅栏。我们展示了如何在CPU上等待时间线信号量，以及时间线信号量可以作为队列提交的一部分使用，无论是为了发出信号还是等待。
- en: Next, we demonstrated how to use the newly introduced timeline semaphore to
    synchronize execution across the graphics and compute queue.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们演示了如何使用新引入的时间线信号量来同步图形和计算队列之间的执行。
- en: In the last section, we showed an example of how to approach porting code written
    for the CPU to the GPU. We first explained some of the benefits of running computations
    on the GPU. Next, we gave an overview of the execution model for compute shaders
    and the configuration of local and global workgroup sizes. Finally, we gave a
    concrete example of a compute shader for cloth simulation and highlighted the
    main differences with the same code written for the CPU.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们展示了如何将针对CPU编写的代码移植到GPU上的一个示例。我们首先解释了在GPU上运行计算的一些好处。接下来，我们概述了计算着色器的执行模型以及局部和全局工作组大小的配置。最后，我们给出了一个用于布料模拟的计算着色器具体示例，并突出了与为CPU编写的相同代码的主要差异。
- en: In the next chapter, we are going to improve our pipeline by adding mesh shaders,
    and for the devices that don’t support them, we are going to write a compute shader
    alternative.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过添加网格着色器来改进我们的管线，对于不支持这些着色器的设备，我们将编写一个计算着色器替代方案。
- en: Further reading
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Synchronization is likely one of the most complex aspects of Vulkan. We have
    mentioned some of the concepts in this and previous chapters. If you want to improve
    your understanding, we suggest reading the following resources:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 同步可能是Vulkan中最复杂的方面之一。我们在本章和前几章中提到了一些概念。如果您想提高您的理解，我们建议阅读以下资源：
- en: '[https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.xhtml#synchronization](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.xhtml#synchronization)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Vulkan 规范 - 同步](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.xhtml#synchronization)'
- en: '[https://www.khronos.org/blog/understanding-vulkan-synchronization](https://www.khronos.org/blog/understanding-vulkan-synchronization)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Vulkan 同步理解](https://www.khronos.org/blog/understanding-vulkan-synchronization)'
- en: '[https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples](https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Vulkan 同步示例](https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples)'
- en: 'We only touched the surface when it comes to compute shaders. The following
    resources go more in depth and also provide suggestions to get the most out of
    individual devices:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到计算着色器时，我们只是触及了表面。以下资源更深入地探讨了这些内容，并提供了一些针对个别设备的优化建议：
- en: '[https://www.khronos.org/opengl/wiki/Compute_Shader](https://www.khronos.org/opengl/wiki/Compute_Shader)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenGL Compute Shader](https://www.khronos.org/opengl/wiki/Compute_Shader)'
- en: '[https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.xhtml#programming-model](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.xhtml#programming-model)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NVIDIA CUDA 编程指南](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.xhtml#programming-model)'
- en: '[https://github.com/KhronosGroup/OpenCL-Guide/blob/main/chapters/opencl_programming_model.md](https://github.com/KhronosGroup/OpenCL-Guide/blob/main/chapters/opencl_programming_model.md)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCL 编程指南](https://github.com/KhronosGroup/OpenCL-Guide/blob/main/chapters/opencl_programming_model.md)'
- en: 'Real-time cloth simulation for computer graphics has been a subject of study
    for many years. We have based our implementation on this paper: [http://graphics.stanford.edu/courses/cs468-02-winter/Papers/Rigidcloth.pdf](http://graphics.stanford.edu/courses/cs468-02-winter/Papers/Rigidcloth.pdf).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机图形学中的实时布料模拟已经是一个研究了许多年的主题。我们的实现基于这篇论文：[斯坦福大学 Rigidcloth 论文](http://graphics.stanford.edu/courses/cs468-02-winter/Papers/Rigidcloth.pdf)。
- en: 'Another popular approach is presented in this paper: [http://www.cs.cmu.edu/~baraff/papers/sig98.pdf](http://www.cs.cmu.edu/~baraff/papers/sig98.pdf).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，介绍了一种流行的另一种方法：[CMU Baraff 论文](http://www.cs.cmu.edu/~baraff/papers/sig98.pdf)。
- en: 'Finally, this GDC talk gave us the idea of using cloth simulation to demonstrate
    how to use compute shaders:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这次GDC演讲给了我们使用布料模拟来展示如何使用计算着色器的想法：
- en: '[https://www.gdcvault.com/play/1022350/Ubisoft-Cloth-Simulation-Performance-Postmortem](https://www.gdcvault.com/play/1022350/Ubisoft-Cloth-Simulation-Performance-Postmortem)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ubisoft 布料模拟性能分析](https://www.gdcvault.com/play/1022350/Ubisoft-Cloth-Simulation-Performance-Postmortem)'
- en: 'Part 2: GPU-Driven Rendering'
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：GPU驱动渲染
- en: 'Starting with this part, we are going to focus on modern rendering techniques.
    We will cover the following chapters in this section:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 从这部分开始，我们将专注于现代渲染技术。本节将涵盖以下章节：
- en: '[*Chapter 6*](B18395_06.xhtml#_idTextAnchor092)*, GPU-Driven Rendering*'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18395_06.xhtml#_idTextAnchor092)*，GPU驱动渲染*'
- en: '[*Chapter 7*](B18395_07.xhtml#_idTextAnchor105)*, Rendering Many Lights with
    Clustered Deferred Rendering*'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B18395_07.xhtml#_idTextAnchor105)*，使用集群延迟渲染渲染多个光源*'
- en: '[*Chapter 8*](B18395_08.xhtml#_idTextAnchor116)*, Adding Shadows Using Mesh
    Shaders*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B18395_08.xhtml#_idTextAnchor116)*，使用网格着色器添加阴影*'
- en: '[*Chapter 9*](B18395_09.xhtml#_idTextAnchor143)*, Implementing Variable Rate
    Shading*'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18395_09.xhtml#_idTextAnchor143)*，实现可变率着色*'
- en: '[*Chapter 10*](B18395_10.xhtml#_idTextAnchor152)*, Adding Volumetric Fog*'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18395_10.xhtml#_idTextAnchor152)*，添加体积雾*'
