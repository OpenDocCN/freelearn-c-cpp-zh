- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Analyzing and Optimizing the Performance of Our C++ System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析和优化我们的C++系统性能
- en: In this chapter, we will analyze the performance of our electronic trading ecosystem
    based on the measurements we added in the previous chapter, *Adding instrumentation
    and measuring performance*. Using the insights we develop about the performance
    of our trading systems based on this analysis, we will learn what areas to focus
    on in terms of potential performance bottlenecks and what areas we can improve.
    We will discuss tips and techniques for optimizing our C++ trading ecosystem.
    Finally, we will think about the future of our electronic trading ecosystem and
    what enhancements can be made in the future.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将基于上一章中添加的测量结果，即*添加仪表和测量性能*，分析我们电子交易生态系统的性能。通过分析我们基于此分析开发的关于交易系统性能的见解，我们将了解在潜在的性能瓶颈方面应该关注哪些领域，以及我们可以改进哪些领域。我们将讨论优化我们的C++交易生态系统的技巧和技术。最后，我们将思考我们电子交易生态系统的未来，以及未来可以进行的改进。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Analyzing the performance of our trading ecosystem
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析我们交易生态系统的性能
- en: Discussing tips and techniques for optimizing our C++ trading system
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论优化我们的C++交易系统的技巧和技术
- en: Thinking about the future of our trading ecosystem
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思考我们交易生态系统的未来
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the book’s code can be found in the GitHub repository for this book at [https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP](https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP).
    The source code for this chapter is in the `Chapter12` directory in the repository.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有代码都可以在本书的GitHub仓库[https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP](https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP)中找到。本章的源代码位于仓库中的`Chapter12`目录。
- en: Since this is the concluding chapter of this book and we will discuss tips for
    improving the performance of the full electronic trading ecosystem as well as
    future enhancements, we expect you to have gone through all the preceding chapters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是本书的最后一章，我们将讨论提高整个电子交易生态系统性能的技巧以及未来的改进，我们希望您已经阅读了所有前面的章节。
- en: 'The specifications of the environment in which the source code for this book
    was developed are listed as follows. We have presented the details of this environment
    since all the C++ code presented in this book is not necessarily portable and
    might require some minor changes to work in your environment:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书源代码开发环境的规格如下所示。我们展示了这个环境的详细信息，因为本书中展示的所有C++代码可能并不一定可移植，可能需要在您的环境中进行一些小的修改才能工作：
- en: 'OS: `Linux 5.19.0-41-generic #42~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr
    18 17:40:00 UTC 2 x86_64 x86_64` `x86_64 GNU/Linux`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '操作系统：`Linux 5.19.0-41-generic #42~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC 周二 4月
    18 17:40:00 UTC 2 x86_64 x86_64` `x86_64 GNU/Linux`'
- en: 'GCC: `g++ (Ubuntu` `11.3.0-1ubuntu1~22.04.1) 11.3.0`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCC：`g++ (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0`
- en: 'CMake: `cmake` `version 3.23.2`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake：`cmake version 3.23.2`
- en: 'Ninja: `1.10.2`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ninja：`1.10.2`
- en: 'Additionally, for those who are interested in running the *optional* Python
    Jupyter notebook included with this chapter, the following environment was used.
    We will not discuss the installation process for Python, Jupyter, and these libraries
    and assume that you will figure it out on your own:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于那些有兴趣运行本章包含的*可选* Python Jupyter笔记本的用户，以下环境被使用。我们不会讨论Python、Jupyter以及这些库的安装过程，并假设您会自己解决这些问题：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Analyzing the performance of our trading ecosystem
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析我们交易生态系统的性能
- en: Before we analyze the performance of our electronic trading ecosystem, let us
    quickly recap the measurements we added in the previous chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们分析电子交易生态系统的性能之前，让我们快速回顾一下上一章中添加的测量指标。
- en: Revisiting the latencies we measure
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新审视我们测量的延迟
- en: We added two forms of measurement. The first one measures the performance of
    internal components and the second one generates timestamps at key points in our
    entire system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了两种测量形式。第一种测量内部组件的性能，第二种在系统的关键点生成时间戳。
- en: 'The first form, which measures the latencies of internal components, generates
    differences in `RDTSC` values before and after calls to different functions, and
    generates log entries such as the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种形式，它测量内部组件的延迟，在调用不同函数前后生成`RDTSC`值的差异，并生成如下日志条目：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The second form, which measures the latencies at key points in the trading
    ecosystem, generates absolute timestamp values and generates log entries such
    as the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种形式，它测量交易生态系统中关键点的延迟，生成绝对时间戳值，并生成如下日志条目：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, let us move forward and analyze these latency measurements.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续分析这些延迟测量值。
- en: Analyzing the performance
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析性能
- en: 'To analyze these performance metrics, we have built a Python Jupyter notebook,
    which is available at `Chapter12/notebooks/perf_analysis.ipynb`. Note that since
    this is a book about C++ and low-latency applications, we will not discuss the
    source code in this notebook, but instead describe the analysis. Running the notebook
    is optional, so we also included an HTML file with the results of this analysis,
    which is available at `Chapter12/notebooks/perf_analysis.html`. To run this notebook,
    you will first have to launch the `jupyter notebook` server from the `Chapter12`
    root directory (where the log files exist) using the following command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析这些性能指标，我们构建了一个Python Jupyter笔记本，它位于`Chapter12/notebooks/perf_analysis.ipynb`。请注意，由于这是一本关于C++和低延迟应用的书籍，我们不会讨论这个笔记本中的源代码，而是描述分析过程。运行笔记本是可选的，所以我们还包含了一个包含此分析结果的HTML文件，它位于`Chapter12/notebooks/perf_analysis.html`。要运行这个笔记本，你首先必须从`Chapter12`根目录（其中存在日志文件）使用以下命令启动`jupyter
    notebook`服务器：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If your browser does not already launch the web page for this notebook, you
    can copy and paste the URL you receive and navigate to and open the `notebooks/perf_analysis.ipynb`
    notebook. Note that the preceding addresses are just examples for this specific
    run; you will receive a different address, which you should use. Once you open
    the notebook, you can run it using **Cell** | **Run All**, or the closest equivalent
    in your notebook instance, as shown in the following screenshot.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的浏览器还没有打开这个笔记本的网页，你可以复制并粘贴你收到的URL，导航到并打开`notebooks/perf_analysis.ipynb`笔记本。请注意，前面的地址只是这个特定运行的示例；你将收到一个不同的地址，你应该使用。一旦打开笔记本，你可以使用**Cell**
    | **Run All**，或者在你的笔记本实例中显示的最近似等效方式来运行它，如下面的截图所示。
- en: '![Figure 12.1 – Screenshot of the perf_analysis.ipynb notebook](img/B19434_12_001.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – perf_analysis.ipynb笔记本的截图](img/B19434_12_001.jpg)'
- en: Figure 12.1 – Screenshot of the perf_analysis.ipynb notebook
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – perf_analysis.ipynb笔记本的截图
- en: 'Since we will not discuss the details of this notebook, we will briefly describe
    the analysis performed in it. This notebook performs the following steps in the
    order presented here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不会讨论这个笔记本的细节，我们将简要描述其中执行的分析。这个笔记本按照以下顺序执行以下步骤：
- en: First, it looks for the log files generated by running the electronic trading
    ecosystem in the current working directory. Specifically, it looks for log files
    from the trading exchange; in the case of this notebook, we look for log files
    from the trading client with `ClientId=1`.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，它在当前工作目录中查找运行电子交易生态系统的日志文件。具体来说，它查找来自交易交易所的日志文件；在这个笔记本的情况下，我们查找`ClientId=1`的交易客户端的日志文件。
- en: It opens each log file and looks for log entries that contain the `RDTSC` and
    `TTT` tokens in them to find the log entries corresponding to the measurements
    we discussed in the previous chapter and revisited in the preceding sub-section.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它打开每个日志文件，并查找包含`RDTSC`和`TTT`标记的日志条目，以找到与我们在上一章中讨论并在前一小节中回顾的测量值相对应的日志条目。
- en: It then creates two `pandas` `DataFrame` instances containing each of the measurements
    it extracts from the log files.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它创建了两个`pandas` `DataFrame`实例，包含从日志文件中提取的每个测量值。
- en: For the measurement entries corresponding to the measurement of internal functions,
    which are tagged with the `RDTSC` token, we generate a scatter plot of those measurements
    as well as a rolling mean of those plots (to smooth the overall latency measurements).
    One crucial point here is that the measurement values in the log files represent
    the difference in `RDTSC` values, that is, the number of CPU cycles elapsed for
    a function call. In this notebook, we convert the CPU cycles into nanoseconds
    using a constant factor of 2.6 GHz, which is specific to our system and will differ
    based on your hardware; it will need to be adjusted. We will look at a few examples
    of these plots in the next sub-section.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于对应于内部函数测量的测量条目，这些条目被标记为`RDTSC`令牌，我们生成了这些测量的散点图以及这些图的滚动平均值（以平滑整体延迟测量）。这里的一个关键点是，日志文件中的测量值代表`RDTSC`值的差异，即函数调用所经过的CPU周期数。在本笔记本中，我们使用2.6
    GHz的常数因子将CPU周期转换为纳秒，这是针对我们系统的特定值，并且会根据您的硬件而有所不同；它需要调整。我们将在下一小节中查看这些图的一些示例。
- en: For the measurement entries corresponding to the timestamps at key spots in
    our electronic trading ecosystem, which are tagged with the `TTT` token, we also
    generate a scatter plot and a plot of the rolling mean values. The difference
    here is that we display the transit times from one hop to the other. For instance,
    we will plot the time it takes from the hop at `T1_OrderServer_TCP_read` to the
    hop at `T2_OrderServer_LFQueue_write`, from `T2_OrderServer_LFQueue_write` to
    `T3_MatchingEngine_LFQueue_read`, from `T3_MatchingEngine_LFQueue_read` to `T4_MatchingEngine_LFQueue_write`,
    and so forth.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于对应于我们电子交易生态系统关键位置的时间戳的测量条目，这些条目被标记为`TTT`令牌，我们也生成了散点图和滚动平均值图。这里的区别在于我们显示了从一个跳到另一个跳的传输时间。例如，我们将绘制从`T1_OrderServer_TCP_read`跳到`T2_OrderServer_LFQueue_write`跳的时间，从`T2_OrderServer_LFQueue_write`跳到`T3_MatchingEngine_LFQueue_read`跳，从`T3_MatchingEngine_LFQueue_read`跳到`T4_MatchingEngine_LFQueue_write`跳，等等。
- en: Each of these inter-hop transits on the side of the exchange is shown in the
    following diagram.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在交易所侧的跨跳传输在以下图中展示。
- en: '![Figure 12.2 – Flow of data between different hops at the electronic exchange](img/B19434_12_002.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 – 电子交易所不同跳之间的数据流](img/B19434_12_002.jpg)'
- en: Figure 12.2 – Flow of data between different hops at the electronic exchange
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – 电子交易所不同跳之间的数据流
- en: Each of these inter-hop transits on the side of the trading client is shown
    in the following diagram.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在交易客户端侧的跨跳传输在以下图中展示。
- en: '![Figure 12.3 – Flow of data between different hops on the electronic trading
    client](img/B19434_12_003.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图12.3 – 电子交易客户端不同跳之间的数据流](img/B19434_12_003.jpg)'
- en: Figure 12.3 – Flow of data between different hops on the electronic trading
    client
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 – 电子交易客户端不同跳之间的数据流
- en: In the next sub-section, we will observe the distribution of a few of these
    different latency metrics from both groups (`RDTSC` and `TTT`) and see what we
    can learn from them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将观察来自两组（`RDTSC`和`TTT`）的一些不同延迟指标的分布，并看看我们能从中学习到什么。
- en: Understanding the output of our analysis
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解分析输出
- en: In this section, we will present the distribution of the latencies for a subset
    of the measurements we added in the previous chapter and analyzed using the notebook
    presented in the previous sub-section. Our objective here is to gain some insight
    into the performance of different components and sub-components in our ecosystem.
    First, we will start with a few examples of latencies for internal function calls
    in the next sub-section. One thing to note is that for the sake of brevity, we
    will present and discuss a subset of all the performance plots available in the
    Python notebook in this chapter. Also, note that these are not arranged in any
    particular order; we simply picked some of the more interesting ones and left
    all possible plots in the notebook for you to inspect further.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示我们在上一章中添加并使用上一小节中展示的笔记本分析的测量子集的延迟分布。我们的目标是深入了解我们生态系统中不同组件和子组件的性能。首先，我们将在下一小节中从内部函数调用的延迟的几个示例开始。需要注意的是，为了简洁起见，我们将展示和讨论本章Python笔记本中所有性能图的一个子集。另外，请注意，这些图没有按照任何特定的顺序排列；我们只是挑选了一些更有趣的图，并将所有可能的图都留在了笔记本中供您进一步检查。
- en: Observing the latencies for internal function calls
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 观察内部函数调用的延迟
- en: The first performance plot we present in this chapter is the distribution of
    the latency of calling the `Exchange::MEOrderBook::removeOrder()` method in the
    matching engine inside the trading exchange. That is presented as follows, but
    our key takeaway here is that this is a very well-behaved function; that is, the
    minimum and maximum latencies are within a tight range between 0.4 and 3.5 microseconds
    and the mean is relatively stable around the 1-to-1.5-microsecond range. There
    might be the possibility to make this faster, of course, but this seems quite
    well behaved for now and has low-performance latencies; we should evaluate whether
    this method is a bottleneck before trying to optimize it any further.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们首先展示的性能图表是在交易交易所内部匹配引擎中调用`Exchange::MEOrderBook::removeOrder()`方法的延迟分布。它呈现如下，但我们的关键结论是，这是一个表现非常好的函数；也就是说，最小和最大延迟在0.4到3.5微秒的紧密范围内，平均值相对稳定在1到1.5微秒的范围内。当然，有可能使其更快，但现在这似乎表现良好，并且具有低性能延迟；在尝试进一步优化之前，我们应该评估此方法是否是瓶颈。
- en: '![Figure 12.4 – Latency distribution for the removeOrder() method in MEOrderBook
    for the matching engine](img/B19434_12_004.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图12.4 – MEOrderBook中removeOrder()方法在匹配引擎中的延迟分布](img/B19434_12_004.jpg)'
- en: Figure 12.4 – Latency distribution for the removeOrder() method in MEOrderBook
    for the matching engine
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 – MEOrderBook中removeOrder()方法在匹配引擎中的延迟分布
- en: 'The next plot presents the distribution of latencies for the `Exchange::FIFOSequencer::``     sequenceAndPublish()` method. This instance is more interesting because here we
    see that while this method has low average latencies in the 90 microseconds range,
    it experiences many spikes in latencies spiking up to values in the 500 to 1,200
    microseconds range. This behavior will result in jitter in the `OrderServer` component’s
    performance when it comes to processing client order requests and is something
    we might need to investigate.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表展示了`Exchange::FIFOSequencer::sequenceAndPublish()`方法的延迟分布。这个实例更有趣，因为在这里我们看到，尽管这个方法在90微秒范围内具有较低的平均延迟，但它经历了许多延迟峰值，峰值达到500到1,200微秒。这种行为将导致`OrderServer`组件在处理客户端订单请求时的性能出现抖动，这是我们可能需要调查的问题。
- en: '![Figure 12.5 – Latency distribution of the sequenceAndPublish() method in
    FIFOSequencer for the matching engine](img/B19434_12_005.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图12.5 – FIFOSequencer中sequenceAndPublish()方法在匹配引擎中的延迟分布](img/B19434_12_005.jpg)'
- en: Figure 12.5 – Latency distribution of the sequenceAndPublish() method in FIFOSequencer
    for the matching engine
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 – FIFOSequencer中sequenceAndPublish()方法在匹配引擎中的延迟分布
- en: The next plot shows another interesting distribution of latency values for the
    `Trading::PositionKeeper::addFill()` method. In this case, the average performance
    latency remains stable around the 50 microseconds range. However, between **15:28:00**
    and **15:29:00**, there are a few spikes in latency that warrant a closer look.
    The difference here compared to *Figure 12**.4* is that there the spikes were
    distributed evenly, but in this case, there appears to be a small patch of spikes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了`Trading::PositionKeeper::addFill()`方法的另一个有趣的延迟值分布。在这种情况下，平均性能延迟稳定在50微秒左右。然而，在**15:28:00**到**15:29:00**之间，有几个延迟峰值需要进一步观察。与*图12.4*相比，这里的差异在于那里的峰值分布均匀，但在这个案例中，似乎有一个小的峰值区域。
- en: '![Figure 12.6 – Latency distribution of the addFill() method in PositionKeeper
    for the trade engine](img/B19434_12_006.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图12.6 – PositionKeeper中addFill()方法在交易引擎中的延迟分布](img/B19434_12_006.jpg)'
- en: Figure 12.6 – Latency distribution of the addFill() method in PositionKeeper
    for the trade engine
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 – PositionKeeper中addFill()方法在交易引擎中的延迟分布
- en: 'We conclude this sub-section by presenting one more plot, this time of the
    `Trading::``     PositionKeeper::updateBBO()` method, which updates the PnL for open positions.
    This is another well-behaved method with an average performance latency of 10
    microseconds, and there seem to be many measurements close to 0 microseconds,
    which is slightly different from *Figure 12**.3*, where the minimum latency value
    was never remarkably close to 0.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过展示另一个图表来结束本小节，这次是`Trading::PositionKeeper::updateBBO()`方法的图表，它更新了开放头寸的损益。这是一个表现良好的方法，平均性能延迟为10微秒，似乎有很多测量值接近0微秒，这与*图12.3*略有不同，在那里最小延迟值从未显著接近0。
- en: '![Figure 12.7 – Latency distribution of the updateBBO() method in PositionKeeper
    for the trade engine](img/B19434_12_007.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7 – 交易引擎PositionKeeper中updateBBO()方法的延迟分布](img/B19434_12_007.jpg)'
- en: Figure 12.7 – Latency distribution of the updateBBO() method in PositionKeeper
    for the trade engine
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 – 交易引擎PositionKeeper中updateBBO()方法的延迟分布
- en: In the next sub-section, we will look at a few similar examples, but this time
    pertaining to the latencies between the different hops in our ecosystem.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将查看一些类似的例子，但这次是关于我们生态系统中不同跳之间的延迟。
- en: Observing the latencies between hops in the ecosystem
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 观察生态系统中跳之间的延迟
- en: The first plot we will look at is the time difference between when a trading
    client’s `OrderGateway` component writes a client request to the TCP socket (`T12`)
    up to the point when the exchange’s `OrderServer` component reads that client
    request from the TCP socket (`T1`). This represents the network transit time from
    the trading client to the trading exchange on the TCP connection. The average
    latency in this case is around 15 to 20 microseconds and the distribution is evenly
    distributed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的第一个图表是交易客户端的`OrderGateway`组件将客户端请求写入TCP套接字（`T12`）到交易所的`OrderServer`组件从TCP套接字读取该客户端请求（`T1`）的时间差。这代表了TCP连接上从交易客户端到交易交易所的网络传输时间。在这种情况下，平均延迟大约在15到20微秒之间，分布是均匀的。
- en: '![Figure 12.8 – Latency distribution between the T12_OrderGateway_TCP_write
    and T1_OrderServer_TCP_read hops](img/B19434_12_008.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图12.8 – T12_OrderGateway_TCP_write和T1_OrderServer_TCP_read跳之间的延迟分布](img/B19434_12_008.jpg)'
- en: Figure 12.8 – Latency distribution between the T12_OrderGateway_TCP_write and
    T1_OrderServer_TCP_read hops
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 – T12_OrderGateway_TCP_write和T1_OrderServer_TCP_read跳之间的延迟分布
- en: The next plot displays the distribution of the network transit time for the
    market data updates, from when the market data updates are written to the UDP
    socket by `MarketDataPublisher` (`T6`) to when they are read from the UDP socket
    by `MarketDataConsumer` (`T7`). There seems to be a great amount of variance in
    the latencies for this measurement, as the plot shows; however, this has lower
    overall latencies than the TCP path.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了市场数据更新的网络传输时间分布，从市场数据更新由`MarketDataPublisher`（`T6`）写入UDP套接字到由`MarketDataConsumer`（`T7`）从UDP套接字读取它们的时间。如图所示，这个测量的延迟似乎有很大的变化；然而，这个路径的整体延迟比TCP路径要低。
- en: '![Figure 12.9 – Latency distribution between the T6_MarketDataPublisher_UDP_write
    and T7_MarketDataConsumer_UDP_read hops](img/B19434_12_009.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图12.9 – T6_MarketDataPublisher_UDP_write和T7_MarketDataConsumer_UDP_read跳之间的延迟分布](img/B19434_12_009.jpg)'
- en: Figure 12.9 – Latency distribution between the T6_MarketDataPublisher_UDP_write
    and T7_MarketDataConsumer_UDP_read hops
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – T6_MarketDataPublisher_UDP_write和T7_MarketDataConsumer_UDP_read跳之间的延迟分布
- en: The next diagram shows the distribution of latencies measured from `MarketDataConsumer`
    reading a market update from the UDP socket (`T7`) to the time when the market
    update is written to `LFQueue` connected to `TradeEngine` (`T8`). This path experiences
    huge spikes in latencies (up to 2,000 microseconds) compared to its average performance
    of around 100 microseconds, so this is something we need to investigate.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了从`MarketDataConsumer`从UDP套接字（`T7`）读取市场更新到市场更新写入连接到`TradeEngine`的`LFQueue`（`T8`）的时间的延迟分布。与平均性能大约为100微秒相比，这个路径的延迟出现了巨大的峰值（高达2,000微秒），因此这是我们需要调查的。
- en: '![Figure 12.10 – Latency distribution between the T7_MarketDataConsumer_UDP_read
    and T8_MarketDataConsumer_LFQueue_write hops](img/B19434_12_010.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图12.10 – T7_MarketDataConsumer_UDP_read和T8_MarketDataConsumer_LFQueue_write跳之间的延迟分布](img/B19434_12_010.jpg)'
- en: Figure 12.10 – Latency distribution between the T7_MarketDataConsumer_UDP_read
    and T8_MarketDataConsumer_LFQueue_write hops
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 – T7_MarketDataConsumer_UDP_read和T8_MarketDataConsumer_LFQueue_write跳之间的延迟分布
- en: The next plot displays the distribution of the latencies between `MatchingEngine`
    reading a client request from `LFQueue` attached to `OrderServer` (`T3`) and the
    time `MatchingEngine` processes it and writes the client response to `LFQueue`
    back to `OrderServer` (`T4t`). This path also appears to be experiencing large
    latency spikes and should be investigated.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表显示了`MatchingEngine`从连接到`OrderServer`的`LFQueue`（`T3`）读取客户端请求到`MatchingEngine`处理它并将客户端响应写回`LFQueue`到`OrderServer`（`T4t`）之间的延迟分布。这个路径似乎也经历了大的延迟峰值，应该进行调查。
- en: '![Figure 12.11 – Latency distribution between the T3_MatchingEngine_LFQueue_read
    and T4t_MatchingEngine_LFQueue_write hops](img/B19434_12_011.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图12.11 – T3_MatchingEngine_LFQueue_read和T4t_MatchingEngine_LFQueue_write跳数之间的延迟分布](img/B19434_12_011.jpg)'
- en: Figure 12.11 – Latency distribution between the T3_MatchingEngine_LFQueue_read
    and T4t_MatchingEngine_LFQueue_write hops
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 – T3_MatchingEngine_LFQueue_read和T4t_MatchingEngine_LFQueue_write跳数之间的延迟分布
- en: This section was dedicated to the analysis of the different latency measurements
    in our ecosystem. In the next section, we will discuss some tips and techniques
    that we can use to optimize the design and implementation of the different components
    in our electronic trading ecosystem.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节专门用于分析我们生态系统中的不同延迟测量。在下一节中，我们将讨论一些我们可以用来优化我们电子交易生态系统中不同组件的设计和实现的技巧和技术。
- en: Discussing tips and techniques for optimizing our C++ trading system
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论优化我们的C++交易系统的技巧和技术
- en: In this section, we will present a few possible areas where we can optimize
    our C++ trading ecosystem. Note that these are only some examples and a lot more
    is possible, but we will leave you to measure and discover those inefficiencies,
    as well as improve on them. To reiterate what we have mentioned a few times before,
    you should measure the performance of various parts of your system with everything
    we learned in the previous chapter, *Adding instrumentation and measuring performance*.
    You should analyze them using the approach we discussed in this chapter and use
    the C++ discussions we had in the chapter *Exploring C++ Concepts from a Low-Latency
    Application’s Perspective* to improve on them further. Now, let us discuss some
    areas of improvement next. We have tried to arrange these loosely in order from
    least to most effort.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示一些我们可以优化我们的C++交易生态系统的可能区域。请注意，这些只是一些示例，还有很多其他可能性，但我们将让您去衡量和发现这些低效之处，以及进一步改进它们。为了重申我们之前提到过几次的内容，您应该使用我们在上一章“添加仪表和测量性能”中学到的所有知识来衡量您系统各个部分的性能。您应该使用本章中讨论的方法来分析它们，并使用我们在“从低延迟应用程序的角度探索C++概念”这一章节中讨论的C++讨论来进一步改进它们。现在，让我们讨论一些改进的区域。我们试图将这些区域从最少到最多工作量进行排列。
- en: Optimizing the release build
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化发布构建
- en: The first suggestion would be to try and optimize the release build we run for
    our system. Some simple things we can do in the code itself is remove the calls
    to `ASSERT()` from the release binaries. The motivation behind this is to remove
    the extra `if` condition this macro introduces in our code base wherever it gets
    used. However, this can be dangerous since we might allow exceptional conditions
    through. The optimal middle ground is to remove the use of this macro only from
    the critical code path wherever it is safe to do so.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 第一建议是尝试优化我们为系统运行的发布构建。我们可以在代码本身中做的简单事情是，从发布二进制文件中移除对`ASSERT()`的调用。背后的动机是移除这个宏在我们代码库中任何使用的地方引入的额外`if`条件。然而，这可能是危险的，因为我们可能会允许异常条件通过。最佳折衷方案是从安全的地方移除此宏在关键代码路径上的使用。
- en: Another suggestion would be to reduce logging in the release build. We have
    made a decent amount of effort to make logging efficient and low-latency. Additionally,
    it is not wise to eliminate all logging since it makes troubleshooting difficult,
    if not impossible. However, logging is not free, so we should try to reduce logging
    on the critical path for release builds as much as possible.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个建议是减少发布构建中的日志记录。我们已经付出了相当大的努力来使日志记录高效且低延迟。此外，完全消除日志记录是不明智的，因为它会使故障排除变得困难，甚至不可能。然而，日志记录不是免费的，因此我们应该尽可能减少发布构建中的关键路径上的日志记录。
- en: The most common method to perform optimizations, as we suggested here, that
    only apply to release builds is to define the NDEBUG (No Debug) preprocessor flag
    and check for its existence in our code base. If the flag is defined, we build
    a release build and skip non-essential code such as asserts and logging.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在此处所建议的，执行优化的最常见方法，仅适用于发布构建，是定义NDEBUG（无调试）预处理器标志，并在我们的代码库中检查其存在。如果定义了此标志，我们将构建发布版本并跳过非必要代码，例如断言和日志记录。
- en: 'An example of this for the `MemoryPool::deallocate()` method is shown here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了`MemoryPool::deallocate()`方法的示例：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Another example for the `FIFOSequencer::sequenceAndPublish()` method is shown
    here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了`FIFOSequencer::sequenceAndPublish()`方法的另一个示例：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Another thing to think about is whether the actual entries being logged can
    be output in a more optimal method. For instance, `Common:: getCurrentTimeStr()`,
    which gets called in each of our log lines in the current code base state itself,
    is quite expensive. This is because it performs string formatting operations using
    `sprintf()`, which is quite expensive, like most string formatting operations.
    Here, we have another optimization where in release builds, we can output a simple
    integer value representing time, instead of a formatted string, which, while more
    readable, is less efficient.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的问题是，实际记录的条目是否可以以更优的方法输出。例如，`Common::getCurrentTimeStr()`，在当前代码库状态下的每条日志记录中都会被调用，它相当昂贵。这是因为它使用`sprintf()`执行字符串格式化操作，这就像大多数字符串格式化操作一样昂贵。在这里，我们有一个优化，在发布构建中，我们可以输出一个简单的整数来表示时间，而不是格式化的字符串，虽然更易读，但效率更低。
- en: Let us move on to the next possible optimization area – managing thread affinity.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续探讨下一个可能的优化领域——管理线程亲和性。
- en: Setting thread affinity correctly
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正确设置线程亲和性
- en: 'So far, in all the instances of creating and launching threads, we have passed
    the `core_id` parameter to be `-1` in the call to the `Common::createAndStartThread()`
    method; that is, the threads were not pinned to any specific core. This was done
    intentionally since, as we mentioned before, the `exchange_main` application instance
    creates and runs 10 threads and each `trading_main` application instance creates
    and runs 8 threads. Unless you are executing the source code for this book on
    a production-grade trading server, it is unlikely to have too many CPU cores.
    Our system, for example, has only four cores. In practice, however, each of the
    following performance-critical threads would be assigned a CPU core all to themselves.
    We present a sample core assignment next; however, this will change from server
    to server and might also depend on the NUMA architecture – but that is beyond
    the scope of this book. Note that these names refer to the names we passed to
    the method in the `name` string parameter:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在创建和启动线程的所有实例中，我们都在调用`Common::createAndStartThread()`方法时传递了`core_id`参数为`-1`；也就是说，线程没有被固定在任何特定的核心上。这是故意为之，因为我们之前提到过，`exchange_main`应用程序实例创建并运行10个线程，而每个`trading_main`应用程序实例创建并运行8个线程。除非你在生产级交易服务器上执行这本书的源代码，否则不太可能有太多的CPU核心。例如，我们的系统只有四个核心。然而，在实践中，以下性能关键线程将各自分配一个CPU核心。我们接下来将展示一个核心分配的示例；然而，这会因服务器而异，也可能取决于NUMA架构——但这超出了本书的范围。请注意，这些名称指的是我们在`name`字符串参数中传递给方法的名称：
- en: '`core_id`=0 : `Exchange/MarketDataPublisher`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=0 : `Exchange/MarketDataPublisher`'
- en: '`core_id`=1 : `Exchange/MatchingEngine`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=1 : `Exchange/MatchingEngine`'
- en: '`core_id`=2 : `Exchange/OrderServer`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=2 : `Exchange/OrderServer`'
- en: '`core_id`=3 : `Trading/MarketDataConsumer`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=3 : `Trading/MarketDataConsumer`'
- en: '`core_id`=4 : `Trading/OrderGateway`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=4 : `Trading/OrderGateway`'
- en: '`core_id`=5 : `Trading/TradeEngine`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=5 : `Trading/TradeEngine`'
- en: Any additional performance critical threads get assigned the remaining core
    ids in a similar fashion
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何额外的性能关键线程将以类似的方式分配剩余的核心ID
- en: 'The remaining non-critical threads, as well as any Linux processes running
    on the server, would be given a block of CPU cores to be run on without any affinity
    settings. Specifically, in our system, they would be the following non-critical
    threads:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的非关键线程以及服务器上运行的任何Linux进程都将分配一组CPU核心来运行，而不进行任何亲和性设置。具体来说，在我们的系统中，它们将是以下非关键线程：
- en: '`core_id`=-1 : `Exchange/SnapshotSynthesizer`'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Exchange/SnapshotSynthesizer`'
- en: '`core_id`=-1 : `Common/Logger exchange_main.log`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger exchange_main.log`'
- en: '`core_id`=-1 : `Common/Logger exchange_matching_engine.log`'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger exchange_matching_engine.log`'
- en: '`core_id`=-1 : `Common/Logger exchange_market_data_publisher.log`'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger exchange_market_data_publisher.log`'
- en: '`core_id`=-1 : `Common/Logger exchange_snapshot_synthesizer.log`'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger exchange_snapshot_synthesizer.log`'
- en: '`core_id`=-1 : `Common/Logger exchange_order_server.log`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger exchange_order_server.log`'
- en: '`core_id`=-1 : `Common/Logger trading_main_1.log`'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger trading_main_1.log`'
- en: '`core_id`=-1 : `Common/Logger trading_engine_1.log`'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger trading_engine_1.log`'
- en: '`core_id`=-1 : `Common/Logger trading_order_gateway_1.log`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger trading_order_gateway_1.log`'
- en: '`core_id`=-1 : `Common/Logger trading_market_data_con``sumer_1.log`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`core_id`=-1 : `Common/Logger trading_market_data_consumer_1.log`'
- en: Any other non-critical threads would also be assigned core id -1 i.e. these
    threads will not be pinned to any specific CPU code
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何其他非关键线程也会被分配核心ID -1，即这些线程不会被固定在任何一个特定的CPU核心上
- en: 'Note one additional detail: for this setup to be as optimized as possible,
    we need to make sure that the Linux process scheduler does not assign any OS processes
    to the CPU cores being used by the critical threads. This is achieved on Linux
    using the `isolcpus` kernel parameter, which we will not discuss in detail here.
    The `isolcpus` parameter tells the process scheduler which cores to ignore when
    deciding where to schedule a process.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意一个额外的细节：为了使此设置尽可能优化，我们需要确保Linux进程调度器不将任何操作系统进程分配给被关键线程使用的CPU核心。在Linux上，这是通过使用`isolcpus`内核参数实现的，我们在此不详细讨论。`isolcpus`参数告诉进程调度器在决定在哪里调度进程时忽略哪些核心。
- en: Optimizing Logger for strings
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化字符串的Logger
- en: 'There is an opportunity to optimize our `Logger` class to handle parameters
    of the `char*` type better. Remember that our implementation for logging `char*`
    parameters consists of calling the `Logger::pushValue(const char value)` method
    on each of the characters iteratively, as shown:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有机会优化`Logger`类以更好地处理`char*`类型的参数。记住，我们记录`char*`参数的实现是通过迭代地对每个字符调用`Logger::pushValue(const
    char value)`方法，如下所示：
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'One option here is to introduce a new enumeration value to the `LogType` enumeration.
    Let’s call it `STRING`, like so:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的一个选择是向`LogType`枚举中引入一个新的枚举值。让我们称它为`STRING`，如下所示：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We’ll update the `LogElement` type to have a fixed-size `char*` array of *some*
    size, as shown. We are vague on the size of this array on purpose since this is
    pseudo-code and we want to focus more on the design and the idea and less on the
    implementation details:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更新`LogElement`类型，使其具有固定大小的`char*`数组，如下所示。我们故意对数组的尺寸保持模糊，因为这是伪代码，我们更关注设计和想法，而不是实现细节：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then, finally, update `Logger::pushValue(const char *value)` and `Logger::flushQueue()`
    to copy and write the strings in blocks of characters rather than a single character
    at a time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，更新`Logger::pushValue(const char *value)`和`Logger::flushQueue()`，以便以字符块的形式复制和写入字符串，而不是一次写入一个字符。
- en: Eliminating the use of std::function instances
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消除std::function实例的使用
- en: 'In our code base, we used the `std::function<>` function wrapper in a couple
    of places, as listed here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码库中，我们在几个地方使用了`std::function<>`函数包装器，如下所示：
- en: '`Common::McastSocket`:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Common::McastSocket`:'
- en: '[PRE9]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`Common::TCPServer`:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Common::TCPServer`:'
- en: '[PRE10]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`Common::TCPSocket`:'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Common::TCPSocket`:'
- en: '[PRE12]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Trading::TradeEngine`:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Trading::TradeEngine`:'
- en: '[PRE13]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Calling functions through these objects is slower than directly calling functions,
    and these incur similar costs as `virtual` functions. This mechanism of calling
    methods using the `std::function<>` objects can be replaced with templates. To
    refresh your memory on the drawbacks of calling functions indirectly, please revisit
    the chapter *Exploring C++ Concepts from a Low-Latency Application’s Perspective*,
    specifically the *Avoiding function pointers* sub-section of the *Calling functions
    efficiently* section. Additionally, revisit the *Using compile-time polymorphism*
    section in the same chapter, reviewing the discussion on the `std::function<>`
    instances in our code base, but we encourage those who are interested to attempt
    that improvement.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些对象调用函数比直接调用函数慢，并且这些调用会带来与`virtual`函数相似的成本。使用`std::function<>`对象调用方法的这种机制可以用模板来替换。为了刷新您对间接调用函数的缺点，请重新阅读章节*从低延迟应用程序的角度探索C++概念*，特别是*调用函数高效*部分的*避免函数指针*子部分。此外，请重新阅读同一章节中的*使用编译时多态*部分，回顾我们代码库中`std::function<>`实例的讨论，但我们鼓励有兴趣的人尝试进行这种改进。
- en: Inspecting the impact of these optimizations
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查这些优化的影响
- en: We will not be able to investigate every optimization opportunity in detail,
    but before we finish this section, we will discuss the details of two optimizations
    that we discussed in this section. First, let us discuss the implementation and
    impact of the optimization on our `Logger` class for logging strings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法详细调查每一个优化机会，但在完成本节之前，我们将讨论本节中提到的两个优化的细节。首先，让我们讨论对用于记录字符串的`Logger`类的优化实现及其影响。
- en: Benchmarking Logger string optimization
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基准测试Logger字符串优化
- en: 'To implement the Logger string optimization, we will change the `pushValue()`
    method for `char*` arguments as discussed before. For the sake of brevity, we
    will not look at the full class, which we implement in an alternate `OptLogger`
    class available in the `Chapter12/common/opt_logging.h` source file. The most
    important change is shown here, but please refer to the full source file to see
    the other minor changes:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现日志记录器的字符串优化，我们将改变之前讨论过的 `pushValue()` 方法，用于 `char*` 参数。为了简洁起见，我们不会查看完整的类，我们将在
    `Chapter12/common/opt_logging.h` 源文件中实现的备用 `OptLogger` 类中查看。这里显示的是最重要的更改，但请参阅完整的源文件以查看其他一些小的更改：
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To benchmark this and compare it against the original `Logger` implementation,
    we will create a simple standalone binary called `logger_benchmark`. We do this
    so that we can check the performance impact in a controlled environment. Remember
    that running the full trading ecosystem introduces a lot of variance due to the
    number of processes and threads, the network activity, the trading activity, and
    so on, and it can be difficult to properly assess the impact of the `Logger` optimization.
    The source code for this benchmark application can be found in the `Chapter12/benchmarks/logger_benchmark.cpp`
    source file. Let us look at the implementation of this source file quickly before
    looking at the results.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对这个进行基准测试并与原始的 `Logger` 实现进行比较，我们将创建一个简单的独立二进制文件，称为 `logger_benchmark`。我们这样做是为了能够在受控环境中检查性能影响。请记住，运行完整的交易生态系统会引入许多变量，包括进程和线程的数量、网络活动、交易活动等，这可能会很难正确评估
    `Logger` 优化的影响。这个基准测试应用程序的源代码可以在 `Chapter12/benchmarks/logger_benchmark.cpp` 源文件中找到。在查看结果之前，让我们快速查看这个源文件的实现。
- en: 'First, we will include the header files corresponding to the original `Logger`
    and the new `OptLogger` classes:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将包含与原始 `Logger` 和新 `OptLogger` 类对应的头文件：
- en: '[PRE17]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we will define a `random_string()` method, which simply generates random
    strings of a specified length. We will use this to generate random strings for
    the two loggers to log to compare the performance difference when it comes to
    strings. This uses a `charset()` lambda method, which returns a random alphanumeric
    (0-9, a-z, or A-z) character. It then uses the `std::generate_n()` method to generate
    a `std::string` with a length specified in the length argument by calling the
    `charset()` lambda method repeatedly:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个 `random_string()` 方法，它简单地生成指定长度的随机字符串。我们将使用这个方法来生成随机字符串，以便两个日志记录器进行记录，比较字符串方面的性能差异。这使用了
    `charset()` lambda 方法，该方法返回一个随机的字母数字字符（0-9，a-z 或 A-Z）。然后，它使用 `std::generate_n()`
    方法通过重复调用 `charset()` lambda 方法来生成一个长度由长度参数指定的 `std::string`：
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we will define a `benchmarkLogging()` method, which accepts a template
    parameter, `T`, which it expects to be an instance of one of the two loggers we
    are comparing here. It runs a loop 100,000 times and uses the `random_string()`
    method we built previously and the logger’s `log()` method to log 100,000 random
    strings. For each call to the `log()` method, it records and sums up the difference
    in clock cycles, using the `Common::rdtsc()` method we built in the previous chapter.
    Finally, it returns the average clock cycles by dividing the sum of each RDTSC
    difference by the loop count:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个 `benchmarkLogging()` 方法，它接受一个模板参数 `T`，它期望它是一个我们在这里比较的两个日志记录器之一的实例。它运行一个循环
    100,000 次，并使用我们之前构建的 `random_string()` 方法和日志记录器的 `log()` 方法来记录 100,000 个随机字符串。对于
    `log()` 方法的每次调用，它使用我们在上一章中构建的 `Common::rdtsc()` 方法记录并累加时钟周期的差异。最后，它通过将每个 RDTSC
    差异的和除以循环次数来返回平均时钟周期数：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we can finally build the `main()` method, which is quite simple. It creates
    an instance of the old logger – `Common::Logger()` – calls the `benchmarkLogging()`
    method on it, and outputs the average clock cycle count to the screen. Then, it
    does exactly the same thing again, except this time it uses the new logger – `OptCommon::OptLogger()`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们终于可以构建 `main()` 方法了，它相当简单。它创建了一个旧日志记录器的实例 – `Common::Logger()`，然后调用其上的
    `benchmarkLogging()` 方法，并将平均时钟周期数输出到屏幕。然后，它再次执行完全相同的事情，只是这次它使用的是新的日志记录器 – `OptCommon::OptLogger()`：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This binary can be built using the same script as before, that is, by running
    `scripts/build.sh` from the `Chapter12` root directory. To run the binary, you
    can call it directly from the command line, as shown here, and, among other output,
    you will see the following two lines displaying the results of the benchmarking:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个二进制文件可以使用之前的相同脚本构建，即从`Chapter12`根目录运行`scripts/build.sh`。要运行二进制文件，您可以直接从命令行调用它，如下所示，并且，在输出中，您将看到以下两行显示基准测试的结果：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that there will be some variance in the output for each run, and the results
    you get will likely be different due to system-dependent reasons, but amount the
    optimization has sped things up, should be somewhat similar to what we have shown.
    In this case, it seems like our optimization efforts have sped up the `log()`
    method for strings to be roughly 50 times faster. Next, let us look at another
    example of the optimization tips we discussed before, which is optimizing the
    binary for release builds.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每次运行的输出可能会有所不同，您得到的结果可能会因系统依赖性而不同，但优化所加快的速度应该与我们所展示的相似。在这种情况下，我们的优化努力似乎使字符串的`log()`方法加快了大约50倍。接下来，让我们看看我们之前讨论的优化技巧的另一个示例，即优化发布构建的二进制文件。
- en: Benchmarking release build optimization
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基准测试发布构建优化
- en: 'To benchmark an example of leaving out non-essential code from the release
    build, we picked the `MemPool` class. Note that this principle applies to all
    the components we built, but we arbitrarily picked a single one to limit the scope
    of our discussion. Similar to what we did for the `Logger` class, we create a
    new class called `OptMemPool`, which you will find in the `Chapter12/common/opt_mem_pool.h`
    source file. The primary change in this file compared to the `MemPool` class is
    that the calls to `ASSERT()` are only built for non-release builds. This is achieved
    by checking for the `NDEBUG` preprocessor flag, as shown in the following two
    examples. You can check out the full source code in the file we mentioned previously:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了基准测试从发布构建中省略非必要代码的示例，我们选择了`MemPool`类。请注意，这个原则适用于我们构建的所有组件，但我们随意选择了一个来限制我们讨论的范围。类似于我们对`Logger`类所做的那样，我们创建了一个新的类，称为`OptMemPool`，您可以在`Chapter12/common/opt_mem_pool.h`源文件中找到它。与`MemPool`类相比，这个文件的主要变化是，对`ASSERT()`的调用仅针对非发布构建进行编译。这通过检查`NDEBUG`预处理器标志来实现，如下面的两个示例所示。您可以在我们之前提到的文件中查看完整的源代码：
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To benchmark this optimization, we will build a `release_benchmark` binary,
    and the code for that is available in the `Chapter12/benchmarks/release_benchmark.cpp`
    source file. First, let us look at the header files we need to include, most importantly
    the `mem_pool.h` and `opt_mem_pool.h` files. Since memory pools store structures,
    we will use `Exchange::MDPMarketUpdate` as an example, so we include the `market_update.h`
    header file for that as well:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了基准测试这个优化，我们将构建一个`release_benchmark`二进制文件，其代码可在`Chapter12/benchmarks/release_benchmark.cpp`源文件中找到。首先，让我们看看我们需要包含的头文件，最重要的是`mem_pool.h`和`opt_mem_pool.h`文件。由于内存池存储结构，我们将使用`Exchange::MDPMarketUpdate`作为示例，因此我们也包含`market_update.h`头文件：
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Similar to what we did with the `logger_benchmark.cpp` file, we will create
    a `benchmarkMemPool()` method, which accepts a template parameter, `T`, and expects
    it to be one of the two memory pools we are comparing. In this method, we will
    first allocate and save 256 `MDPMarketUpdate` objects from the memory pool, using
    the `allocate()` method. Then, we will deallocate each of these objects and return
    them to the memory pool, using the `deallocate()` method. We will run this loop
    100,000 times to find a reliable average over many iterations. We will measure
    and sum up the clock cycles elapsed for each call to `allocate()` and `deallocate()`
    as we did before with the logger benchmark. Finally, we return the average clock
    cycles by dividing the sum of elapsed clock cycles by the loop count:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们对`logger_benchmark.cpp`文件所做的那样，我们将创建一个`benchmarkMemPool()`方法，它接受一个模板参数`T`，并期望它是我们比较的两个内存池之一。在这个方法中，我们首先使用`allocate()`方法从内存池中分配并保存256个`MDPMarketUpdate`对象。然后，我们将使用`deallocate()`方法释放这些对象并将它们返回到内存池中。我们将运行这个循环100,000次，以在多次迭代中找到一个可靠的平均值。我们将测量并累加每次调用`allocate()`和`deallocate()`所花费的时钟周期，就像我们在日志基准测试中所做的那样。最后，我们将通过将时钟周期总和除以循环计数来返回平均时钟周期：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, we build the `main()` method, which again is quite simple. It calls
    the `benchmarkMemPool()` method twice, once with an object of the `Common::MemPool`
    type and next with an object of the `OptCommon::OptMemPool` type, and outputs
    the average clock cycles elapsed for the `allocate()` and `deallocate()` methods:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们构建了`main()`方法，这同样非常简单。它调用了两次`benchmarkMemPool()`方法，一次是用`Common::MemPool`类型的对象，另一次是用`OptCommon::OptMemPool`类型的对象，并输出了`allocate()`和`deallocate()`方法的平均时钟周期数：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The process to build this benchmark binary remains the same, so we will not
    repeat it. Running the binary will yield something that resembles the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 构建这个基准二进制的过程保持不变，所以我们将不会重复它。运行二进制文件将产生类似于以下内容的结果：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this case, our optimization efforts yielded a speed up of around 7 to 8 times
    for the `allocate()` and `deallocate()` methods.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的优化努力使得`allocate()`和`deallocate()`方法的速度提高了大约7到8倍。
- en: In this section, we presented and explained a subset of optimization areas/ideas
    in our electronic trading ecosystem. The goal here is to get you to understand
    what these optimization areas can look like and how to approach them with the
    goal of optimizing performance. In the next section, we’ll discuss some more future
    improvements and enhancements that can be made to our electronic trading ecosystem.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍并解释了我们电子交易生态系统中的优化领域/想法的一个子集。我们的目标是让你了解这些优化领域可能的样子，以及如何以优化性能为目标来处理它们。在下一节中，我们将讨论一些更多可以对我们电子交易生态系统进行的未来改进和增强。
- en: Thinking about the future of our trading ecosystem
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思考我们交易生态系统的未来
- en: Before we conclude this chapter and this book, we will discuss a few possible
    enhancements to our electronic trading ecosystem. In the previous section, we
    discussed some examples of things that can be optimized for those interested in
    maximizing the performance of the electronic trading system we built in this book.
    In this section, we will discuss some examples of how this ecosystem can be enhanced,
    not necessarily to reduce latency but to make the system more feature-rich and
    add functionality.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束这一章节和这本书之前，我们将讨论一些可能的增强我们的电子交易生态系统的方案。在前一节中，我们讨论了一些可以优化的例子，对于那些希望最大化我们在这本书中构建的电子交易系统性能的人来说。在本节中，我们将讨论一些如何增强这个生态系统的例子，不一定是为了减少延迟，而是为了让系统更加功能丰富并增加功能。
- en: Growing containers dynamically
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动态增长容器
- en: 'We built and used a few containers in this book, as listed here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这本书中构建并使用了一些容器，如下所示：
- en: The lock-free queue – `LFQueue` – which is used in multiple components for various
    object types, such as `MEMarketUpdate`, `MDPMarketUpdate`, `MEClientRequest`,
    and `MEClientResponse`
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无锁队列 - `LFQueue` - 被用于多个组件，用于各种对象类型，例如`MEMarketUpdate`、`MDPMarketUpdate`、`MEClientRequest`和`MEClientResponse`
- en: The memory pool – `MemPool` – which was used for multiple object types, such
    as instances of `MEMarketUpdate`, `MEOrder`, `MEOrdersAtPrice`, `MarketOrder`,
    and `MarketOrdersAtPrice`
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存池 - `MemPool` - 被用于多种对象类型，例如`MEMarketUpdate`、`MEOrder`、`MEOrdersAtPrice`、`MarketOrder`和`MarketOrdersAtPrice`的实例
- en: In all these cases, we assumed a safe maximum size value. In practice, that
    still leaves us open to the possibility that under some circumstances, we might
    exceed these limits and get in trouble. One enhancement we can make to this system
    is to improve our handling of this unlikely edge case.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，我们都假设了一个安全的最大值。在实践中，这仍然使我们面临在某种情况下可能超过这些限制并陷入麻烦的可能性。我们可以对这个系统进行的一个增强是改进我们对这种不太可能边缘情况的处理。
- en: One option would be to fail/exit if we encounter a scenario where `LFQueue`
    is full or `MemPool` is out of memory. Another option would be to fall back to
    dynamic memory allocation or a secondary inefficient container for this unlikely
    event; that is, we will be inefficient and slow in this extremely rare case that
    we run out of memory or space in our containers, but we will continue to function
    until it is resolved. Yet another option is to make these containers flexible
    where they can be grown if needed even though the task of growing these containers
    when needed will be extremely slow, since in practice we do not expect to encounter
    that condition.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一个选择是在遇到`LFQueue`已满或`MemPool`内存不足的场景时失败/退出。另一个选择是在这种不太可能的事件中回退到动态内存分配或一个次级低效的容器；也就是说，在我们耗尽内存或容器空间的情况下，我们将变得低效和缓慢，但我们将继续运行直到问题解决。另一个选择是使这些容器具有灵活性，在需要时可以扩展，尽管在需要时扩展这些容器的任务将非常缓慢，因为在实践中我们并不期望遇到那种情况。
- en: Growing and enhancing the hash maps
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增长和增强哈希映射
- en: In this book, we used `std::array` in many contexts as a hash map by assuming
    a safe upper bound. For instance, by assuming that valid `TickerId` values fall
    in the range of 0 and `ME_MAX_TICKERS`, we used `std::array` instances of size
    `ME_MAX_TICKERS` as hash maps with `TickerId` keys. A similar design was used
    for containers such as `TradeEngineCfgHashMap`, `OrderHashMap`, `ClientOrderHashMap`,
    `OrdersAtPriceHashMap`, `OrderBookHashMap`, `MarketOrderBookHashMap`, and `OMOrderTickerSideHashMap`.
    While in practice, some of these can continue to exist, that is, valid and reasonable
    upper bounds can be decided and used, for some of these, this design will not
    scale up elegantly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们假设一个安全的上限，在许多上下文中使用`std::array`作为哈希映射。例如，通过假设有效的`TickerId`值在0和`ME_MAX_TICKERS`之间，我们使用了大小为`ME_MAX_TICKERS`的`std::array`实例作为以`TickerId`为键的哈希映射。类似的设计也用于`TradeEngineCfgHashMap`、`OrderHashMap`、`ClientOrderHashMap`、`OrdersAtPriceHashMap`、`OrderBookHashMap`、`MarketOrderBookHashMap`和`OMOrderTickerSideHashMap`等容器。虽然在实际应用中，其中一些可以继续存在，也就是说，可以决定并使用有效的合理上限，但对于其中的一些，这种设计将无法优雅地扩展。
- en: There are several different hash map implementations available – `std::unordered_map`,
    `absl::flat_hash_map`, `boost::` hash maps, `emhash7::HashMap`, `folly::AtomicHashmap`,
    `robin_hood::unordered_map`, `tsl::hopscotch_map`, and many more. Additionally,
    it is common to optimize and tweak these containers so that they perform best
    under our specific use cases. We’ll leave those of you who are interested with
    the task of exploring these and deciding which ones can replace the `std::array`-based
    hash maps in our system.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的哈希映射实现有多种——`std::unordered_map`、`absl::flat_hash_map`、`boost::`哈希映射、`emhash7::HashMap`、`folly::AtomicHashmap`、`robin_hood::unordered_map`、`tsl::hopscotch_map`以及更多。此外，通常会对这些容器进行优化和调整，以便在特定的使用场景下表现最佳。我们将把这个任务留给那些对此感兴趣的人，即探索这些实现并决定哪些可以替换我们系统中基于`std::array`的哈希映射。
- en: 'For the sake of demonstrating an example, we will replace the `std::array`-based
    hash maps in the limit order book that the matching engine builds and maintains
    (`MEOrderBook`) with `std::unordered_map` hash maps. We will then benchmark the
    two implementations to see how much of a difference it makes. Following the same
    pattern as we used in the benchmarking we performed earlier in this chapter, we
    will introduce a new `MEOrderBook` class, `UnorderedMapMEOrderBook`, where the
    only difference is the use of the `std::unordered_map` containers instead of the
    `std::array` containers. All the source code for this new class is available in
    the `Chapter12/exchange/matcher/unordered_map_me_order_book.h` and `Chapter12/exchange/matcher/unordered_map_me_order_book.cpp`
    source files. For the sake of brevity, we will not repeat the entire class implementation
    here, but we will discuss the important changes. The first important and obvious
    change is the inclusion of the `unordered_map` header file in the `unordered_map_me_order_book.h`
    header file:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示一个例子，我们将替换掉匹配引擎构建和维护的基于`std::array`的订单簿中的哈希映射（`MEOrderBook`），用`std::unordered_map`哈希映射。然后我们将对这两种实现进行基准测试，看看有多大差别。按照我们在本章前面进行的基准测试所使用的相同模式，我们将引入一个新的`MEOrderBook`类，名为`UnorderedMapMEOrderBook`，其中唯一的区别是使用`std::unordered_map`容器而不是`std::array`容器。这个新类的所有源代码都可在`Chapter12/exchange/matcher/unordered_map_me_order_book.h`和`Chapter12/exchange/matcher/unordered_map_me_order_book.cpp`源文件中找到。为了简洁起见，我们不会在这里重复整个类的实现，但我们将讨论重要的更改。第一个重要且明显的变化是在`unordered_map_me_order_book.h`头文件中包含了`unordered_map`头文件：
- en: '[PRE27]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We change the `cid_oid_to_order_` data member to be `std::unordered_map<ClientId,
    std::unordered_map<OrderId, MEOrder *>>` instead of `ClientOrderHashMap`, which
    is a `typedef` for `std::array<OrderHashMap, ME_MAX_NUM_CLIENTS>`. This data member
    is a hash map from `ClientId` to `OrderId` to `MEOrder` objects. Remember that
    `ClientOrderHashMap` is actually a hash map of hash maps, that is, a `std::array`
    whose elements are also `std::array` objects. The other data member we change
    is the `price_orders_at_price_` member, which we change to `std::unordered_map<Price,
    MEOrdersAtPrice *>` instead of the `OrdersAtPriceHashMap` type. This data member
    is a hash map from `Price` to `MEOrdersAtPrice` objects. If you have forgotten
    what `MEOrder` and `MEOrdersAtPrice` are, please revisit the *Designing the exchange
    order book* sub-section in the *Defining the operations and interactions in our
    matching engine* section of the chapter *Building the C++ Matching Engine*. These
    changes are shown here:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`cid_oid_to_order_`数据成员更改为`std::unordered_map<ClientId, std::unordered_map<OrderId,
    MEOrder *>>`，而不是`ClientOrderHashMap`，它是`std::array<OrderHashMap, ME_MAX_NUM_CLIENTS>`的`typedef`。这个数据成员是一个从`ClientId`到`OrderId`再到`MEOrder`对象的哈希表。记住，`ClientOrderHashMap`实际上是一个哈希表的哈希表，即一个其元素也是`std::array`对象的`std::array`。我们更改的另一个数据成员是`price_orders_at_price_`成员，我们将其更改为`std::unordered_map<Price,
    MEOrdersAtPrice *>`，而不是`OrdersAtPriceHashMap`类型。这个数据成员是一个从`Price`到`MEOrdersAtPrice`对象的哈希表。如果你忘记了`MEOrder`和`MEOrdersAtPrice`是什么，请回顾章节“构建C++撮合引擎”中的“定义撮合引擎中的操作和交互”部分的“设计交易所订单簿”子部分。以下是这些更改的示例：
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We will need to remove the following lines from the destructor since the `fill()`
    method does not apply to `std::unordered_map` objects:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从析构函数中移除以下行，因为`fill()`方法不适用于`std::unordered_map`对象：
- en: '[PRE29]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In terms of accessing these modified containers, we replace the calls to the
    `std::array::at()` method for `cid_oid_to_order_` and `price_orders_at_price_`
    with the `std::unordered_map::operator[]` method. These changes for `cid_oid_to_order_`
    are shown here:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在访问这些修改后的容器方面，我们将对`cid_oid_to_order_`和`price_orders_at_price_`的`std::array::at()`方法调用替换为`std::unordered_map::operator[]`方法。以下是`cid_oid_to_order_`的这些更改：
- en: '[PRE30]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We need to make similar changes in spots where we access the `price_orders_at_price_`
    container, which is shown here:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在访问`price_orders_at_price_`容器的地方进行类似的更改，如下所示：
- en: '[PRE31]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, we present the `hash_benchmark` binary to measure the performance
    differences because of these changes. The source code for this binary can be found
    in the `Chapter12/benchmarks/hash_benchmark.cpp` source file. First, we include
    the header files shown as follows and also define a global `loop_count` variable
    as we have done in our previous benchmarks:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了`hash_benchmark`二进制文件来衡量这些更改带来的性能差异。这个二进制文件的源代码可以在`Chapter12/benchmarks/hash_benchmark.cpp`源文件中找到。首先，我们包含以下头文件，并定义一个全局的`loop_count`变量，就像我们在之前的基准测试中所做的那样：
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As we have done before, we will define a `benchmarkHashMap()` method, which
    accepts a template parameter, `T`, to represent either `MEOrderBook` or `UnorderedMapMEOrderBook`.
    It also accepts a vector of `Exchange::MEClientRequest` messages, which will be
    processed in the benchmark. The actual processing is quite simple. It checks the
    type of `MEClientRequest` and then calls the `add()` method for `ClientRequestType::NEW`
    and the `cancel()` method for `ClientRequestType::CANCEL`. We use `Common::rdtsc()`
    to measure and sum up the clock cycles elapsed for each of these calls and then
    return the average at the end of this method:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所做的那样，我们将定义一个`benchmarkHashMap()`方法，它接受一个模板参数`T`，以表示`MEOrderBook`或`UnorderedMapMEOrderBook`。它还接受一个`Exchange::MEClientRequest`消息的向量，这些消息将在基准测试中处理。实际的处理相当简单。它检查`MEClientRequest`的类型，然后对`ClientRequestType::NEW`调用`add()`方法，对`ClientRequestType::CANCEL`调用`cancel()`方法。我们使用`Common::rdtsc()`来测量并汇总每个这些调用所消耗的时钟周期，然后在方法结束时返回平均值：
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now we can look at the `main()` method. We need `Logger` and a `MatchingEngine`
    object to create the `MEOrderBook` or `UnorderedMapMEOrderBook` object, but to
    create the `MatchingEngine` object, we need three lock-free queues as we have
    seen in the implementation of the `exchange_main` binary. So, we create these
    objects as shown here, even though we are not measuring the performance of any
    of these components:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看看`main()`方法。我们需要`Logger`和`MatchingEngine`对象来创建`MEOrderBook`或`UnorderedMapMEOrderBook`对象，但为了创建`MatchingEngine`对象，我们需要三个无锁队列，正如我们在`exchange_main`二进制文件的实现中所看到的。因此，我们创建了这些对象，即使我们并没有测量这些组件的性能：
- en: '[PRE34]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we will create a vector of 100,000 (`loop_count`) `MEClientRequest` objects,
    which will be composed of new order requests as well as requests to cancel these
    orders. We have seen similar code in the `trading_main` application for the random
    trading algorithm:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个包含100,000个(`loop_count`) `MEClientRequest`对象的向量，这些对象将包括新订单请求以及取消这些订单的请求。我们在`trading_main`应用程序中已经看到了类似的代码，用于随机交易算法：
- en: '[PRE35]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we end the `main()` method by calling the `benchmarkHashMap()` method
    twice – once with an instance of `MEOrderBook` and once with an instance of `UnorderedMapMEOrderBook`,
    as shown:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过调用`benchmarkHashMap()`方法两次来结束`main()`方法 – 一次使用`MEOrderBook`的实例，一次使用`UnorderedMapMEOrderBook`的实例，如下所示：
- en: '[PRE36]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The process to build this application remains the same, which is by calling
    the `scripts/build.sh` script from the `Chapter12` root directory. Running the
    application by calling the `hash_benchmark` binary will yield output like what
    is shown here, with some variance between independent runs and depending on the
    system:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 构建此应用程序的过程保持不变，即通过从`Chapter12`根目录调用`scripts/build.sh`脚本来完成。通过调用`hash_benchmark`二进制文件来运行应用程序，将产生类似于这里所示的结果，独立运行之间存在一些差异，并且取决于系统：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Based on the output of this run, it appears that switching from a `std::array`
    hash map implementation to a `std::unordered_map` hash map implementation adds
    an approximate 6 to 7% extra overhead to the `MEOrderBook` `add()` and `cancel()`
    performance.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这次运行的输出，看起来从`std::array`哈希表实现切换到`std::unordered_map`哈希表实现，为`MEOrderBook`的`add()`和`cancel()`性能增加了大约6到7%的额外开销。
- en: Optimizing snapshot messages
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化快照消息
- en: In our design of the snapshot messages in the `MarketDataPublisher` component
    at the trading exchange, a full cycle of snapshot messages between the `START_SNAPSHOT`
    and `END_SNAPSHOT` messages contains the snapshot for all trading instruments,
    as shown in the following diagram (which we have seen before). In our `SnapshotSynthesizer`,
    this full snapshot for all trading instruments is published once every 60 seconds.
    What this means is that if the order books for each of these trading instruments
    have a lot of orders, then every 60 seconds, there is a huge spike in network
    traffic on the snapshot multicast channels followed by silence in the remaining
    60 seconds.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们为交易交易所的`MarketDataPublisher`组件设计的快照消息中，`START_SNAPSHOT`和`END_SNAPSHOT`消息之间的完整快照周期包含了所有交易工具的快照，如图所示（我们之前已经见过）。在我们的`SnapshotSynthesizer`中，所有交易工具的完整快照每60秒发布一次。这意味着，如果每个这些交易工具的订单簿有很多订单，那么每60秒，快照多播通道上的网络流量会有一个巨大的峰值，随后在剩余的60秒内保持沉默。
- en: '![Figure 12.12 – Current composition of snapshot messages](img/B19434_12_012.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图12.12 – 当前快照消息的组成](img/B19434_12_012.jpg)'
- en: Figure 12.12 – Current composition of snapshot messages
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 – 当前快照消息的组成
- en: It would be an enhancement to this design if we changed this such that these
    snapshots are spaced out more evenly and each snapshot cycle contained the snapshot
    messages corresponding to only one `TickerId`. As a simple example, instead of
    sending a snapshot message cycle for 6 instruments every 60 seconds, we can send
    6 snapshots each containing information for a single instrument, and each of these
    snapshots is spaced out with 10 seconds in between them. This hypothetical proposal
    is represented in the following diagram.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们改变设计，使得这些快照更加均匀地分布，并且每个快照周期只包含对应于单个`TickerId`的快照消息，这将是一个改进。作为一个简单的例子，我们不是每60秒发送6个工具的快照消息周期，而是可以发送包含单个工具信息的6个快照，并且这些快照之间间隔10秒。这个假设性的建议在以下图中表示。
- en: '![Figure 12.13 – A proposal for an optimized snapshot messaging format](img/B19434_12_013.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图12.13 – 优化快照消息格式的建议](img/B19434_12_013.jpg)'
- en: Figure 12.13 – A proposal for an optimized snapshot messaging format
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 – 优化快照消息格式的建议
- en: In this new proposal, as we mentioned, there are fewer spikes in network traffic
    since the full snapshot is distributed over time. This leads to a lower chance
    of dropping packets on the snapshot multicast stream for the `MarketDataConsumer`
    components in the trading client’s systems. This also leads to the client’s system
    synchronizing or catching up with the snapshot stream for each trading instrument
    faster, since it does not need to wait for the full snapshot across all trading
    instruments before it can mark some of the instruments as *recovered*.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新的提案中，正如我们提到的，由于完整快照是分时分布的，因此网络流量峰值较少。这导致在交易客户端系统的`MarketDataConsumer`组件的快照多播流中丢失数据包的可能性降低。这也使得客户端系统更快地同步或赶上每个交易工具的快照流，因为它不需要在标记某些工具为*恢复*之前等待所有交易工具的完整快照。
- en: Adding authentication and rejection messages to the Order protocol
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在订单协议中添加认证和拒绝消息
- en: 'Our electronic trading exchange right now has no concept of user authentication
    and is missing a lot of error checking and handling. By this, we mean that it
    does not check whether clients log in with the correct credentials and are authorized
    to trade the instruments they try to trade. Additionally, if the `ClientId` and
    `TCPSocket` instances do not match or there is a sequence number gap in the `ClientRequest`
    messages that a client sends, we quietly ignore it in `Exchange::OrderServer`.
    This is shown in the following code block from the `exchange/order_server/order_server.h`
    source file, which we have already discussed in detail:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在的电子交易交易所没有用户认证的概念，并且缺少很多错误检查和处理。这意味着它不会检查客户端是否使用正确的凭据登录并且是否有权交易他们试图交易的工具。此外，如果`ClientId`和`TCPSocket`实例不匹配，或者在客户端发送的`ClientRequest`消息中存在序列号差距，我们在`Exchange::OrderServer`中会静默忽略它。这在上面的代码块中显示，该代码块来自`exchange/order_server/order_server.h`源文件，我们已经详细讨论过：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Silently ignoring errors like these is not ideal since the clients are not notified
    about these errors. An enhancement to this workflow would be to add a rejection
    message to the `ClientResponse` message protocol, which the `OrderServer` component
    can use to notify the clients about these errors. This enhancement is in addition
    to the enhancements we suggested to the order protocol to facilitate the authentication
    of the trading clients.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 静默忽略这些错误并不理想，因为客户端没有收到这些错误的通知。对此工作流程的改进是在`ClientResponse`消息协议中添加一个拒绝消息，`OrderServer`组件可以使用它来通知客户端这些错误。此增强是在我们建议改进订单协议以方便交易客户端认证之外进行的。
- en: Supporting modify messages in the Order protocol
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在订单协议中支持修改消息
- en: Our current order protocol for `ClientRequest` messages only supports `ClientRequestType::NEW`
    and `ClientRequestType::CANCEL` requests. An enhancement to this protocol would
    be to add a `ClientRequestType::MODIFY` message type so that client trading systems
    can modify their order’s price or quantity attributes. We would need to update
    the `OrderServer`, `MatchingEngine`, `MEOrderBook`, and other components on the
    exchange’s side and update the `OrderGateway`, `OrderManager`, `MarketMaker`,
    `TradeEngine`, and other components on the trading client’s side.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前对`ClientRequest`消息的订单协议仅支持`ClientRequestType::NEW`和`ClientRequestType::CANCEL`请求。对此协议的改进之一是添加一个`ClientRequestType::MODIFY`消息类型，以便客户端交易系统可以修改其订单的价格或数量属性。我们需要更新交易所侧的`OrderServer`、`MatchingEngine`、`MEOrderBook`和其他组件，以及交易客户端侧的`OrderGateway`、`OrderManager`、`MarketMaker`、`TradeEngine`和其他组件。
- en: Enhancing trade engine components
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强`trade engine`组件
- en: The trade engine has several components that can be improved and/or enhanced.
    In this section, we provide brief descriptions of these improvements for each
    of the components with potential future enhancements.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 交易引擎有几个可以改进和/或增强的组件。在本节中，我们为每个组件提供了简要的改进描述，以及可能的未来增强。
- en: Adding risk metrics to RiskManager
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将风险指标添加到RiskManager
- en: In the chapter *Designing Our Trading Ecosystem*, in the *Understanding the
    risk management systems* section, we described a couple of different risk metrics.
    `RiskManager` was built only with a small subset of those risk metrics and can
    be enhanced by adding additional risk measures, as described in that section.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在第*设计我们的交易生态系统*章的*理解风险管理系统*部分，我们描述了几种不同的风险指标。`RiskManager`仅使用这些风险指标的一小部分构建，可以通过添加额外的风险措施来增强，如该部分所述。
- en: Enhancing OrderManager
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强`OrderManager`
- en: '`OrderManager` was built extremely simply – it supports a maximum of one active
    order on each side, that is, at most one buy order and one sell order. Obviously,
    this is an extremely simplified version and `OrderManager` can be enhanced to
    support much more complex order management.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`OrderManager` 极其简单构建——它支持每侧最多一个活跃订单，也就是说，最多一个买入订单和一个卖出订单。显然，这是一个极其简化的版本，`OrderManager`
    可以增强以支持更复杂的订单管理。'
- en: Enriching FeatureEngine
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 丰富 FeatureEngine
- en: '`FeatureEngine` was set up with two hardcoded features built into it. It can
    be enriched a lot to support complex configurations of features, a library of
    diverse types of features, complex interactions between these features, and so
    on.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`FeatureEngine` 配置了两个硬编码的特征。它可以大量丰富以支持复杂特征配置、多种类型特征的库、这些特征之间的复杂交互等。'
- en: Enhancing the trading algorithms
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升交易算法
- en: '`LiquidityTaker` and `MarketMaker` in this book were also extremely simple
    representations of realistic trading strategies. These can be enhanced/improved
    in many ways – improvements in terms of feature compositions, order management,
    efficient execution, and so on.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的 `LiquidityTaker` 和 `MarketMaker` 也是对现实交易策略的极其简单表示。这些可以在许多方面进行增强/改进——包括特征组合、订单管理、高效执行等方面的改进。
- en: This concludes our discussion of future enhancement possibilities for our electronic
    trading ecosystem.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对电子交易生态系统未来增强可能性的讨论。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The first section of this chapter focused on analyzing the latency metrics we
    added to our electronic trading systems in the previous chapter. We discussed
    a few examples of latency measurements for internal functions, as well as a few
    examples of latency measurements between critical hops in our system. The goal
    was to understand the distribution of latencies in different cases so that you
    understand how to identify and investigate areas of potential problems or optimization
    opportunities.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分专注于分析我们在上一章中添加到电子交易系统中的延迟指标。我们讨论了内部函数的几个延迟测量示例，以及系统关键跳转之间的几个延迟测量示例。目标是了解不同情况下延迟的分布，以便您了解如何识别和调查潜在问题或优化机会的区域。
- en: In the second section of this chapter, we discussed a few tips and techniques
    regarding how to approach potential performance optimization possibilities. We
    presented a few examples of what could be improved and discussed the performance
    problems that exist in the current design and solutions to those problems.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第二部分，我们讨论了一些关于如何接近潜在性能优化可能性的技巧和技术。我们提供了一些可以改进的示例，并讨论了当前设计中的性能问题及其解决方案。
- en: In the concluding section, we described a roadmap for the future of the electronic
    trading ecosystem we built in this book. We discussed several different components,
    sub-components, and workflows that can be enriched to build a more mature electronic
    trading ecosystem.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在结论部分，我们描述了本书中构建的电子交易生态系统的未来路线图。我们讨论了几个可以丰富以构建更成熟电子交易生态系统的不同组件、子组件和工作流程。
- en: The approach and principles we discussed in this book pertaining to latency-sensitive
    applications developed in C++ should guide you on your journey. The full end-to-end
    electronic trading ecosystem we built is a prime example of a low-latency application
    and hopefully provided a good practical example of how to build a low-latency
    application from scratch. Hopefully, this chapter added to the experience by providing
    you with tools to analyze the performance and iteratively improve the system.
    We wish you all the best as you continue your low-latency application development
    journey!
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 本书讨论的关于在 C++ 中开发的对延迟敏感的应用程序的方法和原则应指导您的旅程。我们构建的完整端到端电子交易生态系统是一个低延迟应用的典范，并希望提供了一个从零开始构建低延迟应用的优秀实践示例。希望这一章通过为您提供分析性能和迭代改进系统的工具，增加了您的经验。我们祝愿您在继续您的低延迟应用开发旅程中一切顺利！
