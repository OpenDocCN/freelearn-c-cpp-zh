- en: Concurrency and Multithreading
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发和多线程
- en: Concurrent programming allows the creation of more efficient programs. C++ didn't
    have built-in support for concurrency or multithreading for a long time. Now it
    has full support for concurrent programming, threads, thread synchronization objects,
    and other functionality that we will discuss in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程可以创建更高效的程序。很长一段时间以来，C++没有内置对并发或多线程的支持。现在它完全支持并发编程、线程、线程同步对象以及本章将讨论的其他功能。
- en: Before the language updated for thread support, programmers had to use third-party
    libraries. One of the most popular multithreading solutions was **POSIX** (**Portable
    Operating System Interface**) threads. C++ introduced thread support since C++11\.
    It makes the language even more robust and applicable to wider areas of software
    development. Understanding threads is somewhat crucial for C++ programmers as
    they tend to squeeze every bit of the program to make it run even faster. Threads
    introduce us to a completely different way of making programs faster by running
    functions concurrently. Learning multithreading at a fundamental level is a must
    for every C++ programmer. There are lots of programs where you can't avoid using
    multithreading, such as network applications, games, and GUI applications. This
    chapter will introduce you to concurrency and multithreading fundamentals in C++
    and best practices for concurrent code design.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在语言更新以支持线程之前，程序员必须使用第三方库。最流行的多线程解决方案之一是**POSIX**（**可移植操作系统接口**）线程。自C++11以来，C++引入了线程支持。这使得语言更加健壮，并适用于更广泛的软件开发领域。对于C++程序员来说，理解线程有些关键，因为他们倾向于尽可能地压榨程序的每一点，使其运行得更快。线程向我们介绍了一种完全不同的方式，通过并发运行函数来加速程序。在基本水平上学习多线程对于每个C++程序员来说都是必不可少的。有很多程序在其中无法避免使用多线程，例如网络应用程序、游戏和GUI应用程序。本章将向您介绍C++中的并发和多线程基础知识以及并发代码设计的最佳实践。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding concurrency and multithreading
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解并发和多线程
- en: Working with threads
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程
- en: Managing threads and sharing data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理线程和共享数据
- en: Designing concurrent code
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计并发代码
- en: Using thread pools to avoid thread creation overheads
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程池避免线程创建开销
- en: Getting familiar with coroutines in C++20
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉C++20中的协程
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The g++ compiler with the `-std=c++2a` option is used to compile the examples
    in this chapter. You can find the source files used in this chapter at [https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP)
    .
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用`-std=c++2a`选项的g++编译器来编译示例。您可以在[https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP)找到本章中使用的源文件。
- en: Understanding concurrency and multithreading
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解并发和多线程
- en: The simplest form of running a program involves its instructions being executed
    one by one by the **CPU** (**Central Processing Unit**). As you already know from
    previous chapters, a program consists of several sections, one of them containing
    the instructions of the program. Each instruction is loaded into a CPU register
    for the CPU to decode and execute it. It doesn't actually matter what programming
    paradigm you use to produce an application; the result is always the same—the
    executable file contains machine code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序的最简单形式涉及其指令由**CPU**（**中央处理单元**）逐个执行。正如您已经从之前的章节中了解到的，程序由几个部分组成，其中一个部分包含程序的指令。每个指令都加载到CPU寄存器中，以便CPU解码和执行。实际上，无论您使用何种编程范式来生成应用程序，结果始终是一样的——可执行文件包含机器代码。
- en: 'We mentioned that programming languages such as Java and C# use support environments.
    However, if you cut down the support environment in the middle (usually, the virtual
    machine), the final instructions being executed should have a form and format
    familiar to that particular CPU. It''s obvious to programmers that the order of
    statements run by the CPU is not mixed in any circumstance. For example, we are
    sure and can continue to be so that the following program will output `4`, `"hello"`,
    and `5`, respectively:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到，诸如Java和C#之类的编程语言使用支持环境。然而，如果在中间删减支持环境（通常是虚拟机），那么最终执行的指令应该具有特定CPU熟悉的形式和格式。程序员明显知道，CPU运行的语句顺序在任何情况下都不会混合。例如，我们可以确定并且可以继续确定以下程序将分别输出`4`，`"hello"`和`5`：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can guarantee that the value of the `a` variable will be initialized before
    we print it to the screen. The same way we can guarantee that the `"hello"` string will
    be printed before we decrement the value of `b`, and that the `(b + 1)` sum will
    be calculated before printing the result to the screen. The execution of each
    instruction might involve reading data from or writing to memory.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以保证在将`a`变量打印到屏幕之前，其值将被初始化。同样，我们可以保证在将`"hello"`字符串打印到屏幕之前，我们会减少`b`的值，并且在将`(b
    + 1)`的和打印到屏幕之前，该和将被计算。每条指令的执行可能涉及从内存中读取数据或向内存中写入数据。
- en: 'As introduced in [Chapter 5](2b708ddc-255e-490e-bd4c-e783ccae5f9e.xhtml), *Memory Management
    and Smart Pointers*, the memory hierarchy is sophisticated enough to make our
    understanding of program execution a little bit harder. For example, the `int
    b{a};` line from the previous example assumes that the value of `a` is loaded
    from the memory into a register in the CPU, which then will be used to write into
    the memory location of `b`. The keyword here is the *location* because it carries
    a little bit of special interpretation for us. More specifically, we speak about
    memory location. Concurrency support depends on the memory model of the language,
    that is, a set of guarantees for concurrent access to memory. Although the byte
    is the smallest addressable memory unit, the CPU works with words in data. That
    said, the word is the smallest unit the CPU reads from or writes to memory. For
    example, we consider the following two declarations separate variables:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](2b708ddc-255e-490e-bd4c-e783ccae5f9e.xhtml)中介绍了*内存管理和智能指针*，内存层次结构足够复杂，使我们对程序执行的理解变得更加困难。例如，前面例子中的`int
    b{a};`这一行假设`a`的值从内存加载到CPU的寄存器中，然后将用于写入`b`的内存位置。关键词在于*位置*，因为它对我们来说有一点特殊的解释。更具体地说，我们谈论的是内存位置。并发支持取决于语言的内存模型，即对内存并发访问的一组保证。尽管字节是最小的可寻址内存单元，但CPU处理数据时使用的是字。也就是说，字是CPU从内存读取或写入的最小单位。例如，我们认为以下两个声明是不同的变量：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If those variables are allocated in the same word (considering the word size
    as bigger than the size of a `char`), reading and writing any of the variables
    involves reading the word containing both of them. Concurrent access to the variables
    might lead to unexpected behavior. That''s the issue requiring memory model guarantees. The
    C++ memory model guarantees that two threads can access and update separate memory
    locations without interfering with each other. A memory location is a scalar type.
    A scalar type is an arithmetic type, pointer, enumeration, or `nullptr_t`. The
    largest sequence of adjacent bit-fields of non-zero length is considered a memory
    location too. A classic example would be the following structure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些变量分配在同一个字中（假设字的大小大于`char`的大小），读取和写入任何一个变量都涉及读取包含它们两个的字。对变量的并发访问可能导致意外的行为。这就是需要内存模型保证的问题。C++内存模型保证了两个线程可以访问和更新不相互干扰的内存位置。内存位置是标量类型。标量类型是算术类型、指针、枚举或`nullptr_t`。最大的非零长度相邻位字段序列也被认为是内存位置。一个经典的例子是以下结构：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For the preceding example, two threads accessing the same struct's separate
    memory locations won't interfere with each other. So, what should we consider
    when speaking about concurrency or multithreading?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的例子，两个线程访问同一个结构的不同内存位置不会相互干扰。那么，当谈论并发或多线程时，我们应该考虑什么呢？
- en: 'Concurrency is usually confused with multithreading. They are similar in nature but
    are different concepts in detail. To make things easy, just imagine concurrency
    as two operations whose running times interleave together. Operation `A` runs
    concurrently with operation `B` if their start and end times are interleaved at
    any point, as shown in the following diagram:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 并发通常与多线程混淆。它们在性质上是相似的，但在细节上是不同的概念。为了简化问题，只需想象并发是两个操作的运行时间交错在一起。如果操作`A`与操作`B`同时运行，它们的开始和结束时间在任何时刻都是交错的，如下图所示：
- en: '![](img/5a602270-5f05-4ec9-9d02-5ab13bbf4883.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a602270-5f05-4ec9-9d02-5ab13bbf4883.png)'
- en: 'When two tasks run concurrently, they don''t have to run parallel. Imagine
    the following situation: you are watching TV while surfing the internet. Though
    it''s not a good practice to do so, however, let''s imagine for a moment that
    you have a favorite TV show that you can''t miss and at the same time, your friend
    asked you to do some research on bees. You can''t actually concentrate on both
    tasks; at any fixed moment, your attention is grabbed by either the show you are
    watching or the interesting facts about bees that you are reading in an article
    found on the web. Your attention goes from the show to the bees from time to time.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个任务同时运行时，并不一定要并行运行。想象一下以下情况：你正在看电视，同时上网冲浪。虽然这不是一个好的做法，但是，让我们想象一下，你有一个不能错过的最爱电视节目，同时，你的朋友让你研究一些关于蜜蜂的资料。你实际上无法专注于这两个任务；在任何固定的时刻，你的注意力都会被你正在观看的节目或者你在网上找到的关于蜜蜂的有趣事实所吸引。你的注意力会不时地从节目转移到蜜蜂身上。
- en: 'In terms of concurrency, you are doing two tasks concurrently. Your brain gives
    a time portion to the show: you watch, enjoy, and then switch to the article,
    read a couple of sentences, and switch back to the show. This is a simple example
    of concurrently running tasks. Just because their start and end times interleave
    doesn''t mean they run at the same time. On the other hand, you breathe while
    doing any of the tasks mentioned earlier. Breathing happens in the background;
    your brain doesn''t switch your attention from the show or the article to your
    lungs to inhale or exhale. Breathing while watching the show is an example of
    parallel running tasks. Both examples show us the essence of concurrency.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 就并发而言，你同时进行两个任务。你的大脑给节目一个时间段：你观看，享受，然后切换到文章，读几句话，然后再切换回节目。这是同时运行任务的简单例子。仅仅因为它们的开始和结束时间交错，并不意味着它们同时运行。另一方面，你在做任何前面提到的任务时都在呼吸。呼吸是在后台进行的；你的大脑不会将你的注意力从节目或文章转移到你的肺部来吸气或呼气。在看节目的同时呼吸是并行运行任务的一个例子。这两个例子都向我们展示了并发的本质。
- en: So, what is going on when you run more than one application on your computer?
    Are they running in parallel? It's for sure that they run concurrently, however,
    the actual parallelism depends on your computer's hardware. Most mass-market computers
    consist of a single CPU. As we know from previous chapters, the main job of the
    CPU is running an application's instructions one by one. How would a single CPU
    handle the running of two applications at the same time? To understand that, we
    should learn about processes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当您在计算机上运行多个应用程序时会发生什么？它们是否并行运行？可以肯定的是它们是同时运行的，然而，实际的并行性取决于您计算机的硬件。大多数大众市场计算机都只有一个CPU。正如我们从前面的章节中所知，CPU的主要工作是逐个运行应用程序的指令。单个CPU如何处理同时运行两个应用程序的情况？要理解这一点，我们应该了解进程。
- en: Processes
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程
- en: A process is an image of a program running in the memory. When we start a program,
    the OS reads the content of the program from the hard disk, copies it to the memory,
    and points the CPU to the starting instruction of the program. The process has
    its private virtual address space, stack, and heap. Two processes don't interfere
    with each other in any way. That's a guarantee provided by the OS. That also makes
    a programmer's job very difficult if they aim for **Interprocess Communication**
    (**IPC**). We are not discussing low-level hardware features in this book but
    you should have a general understanding of what is going on when we run a program.
    It really depends on the underlying hardware—more specifically, the kind and structure
    of the CPU. The number of CPUs, number of CPU cores, levels of cache memory, and
    shared cache memory between CPUs or their cores—all of these affect the way the
    OS runs and executes programs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 进程是内存中运行程序的映像。当我们启动一个程序时，操作系统从硬盘读取程序的内容，将其复制到内存中，并将CPU指向程序的起始指令。进程有其私有的虚拟地址空间、堆栈和堆。两个进程不会以任何方式相互干扰。这是操作系统提供的保证。这也使得程序员的工作非常困难，如果他们的目标是**进程间通信**（**IPC**）。我们在本书中不讨论低级硬件特性，但你应该对运行程序时发生的事情有一个基本的了解。这实际上取决于底层硬件，更具体地说，取决于CPU的种类和结构。CPU的数量、CPU核心的数量、缓存内存的级别以及CPU或其核心之间的共享缓存内存——所有这些都会影响操作系统运行和执行程序的方式。
- en: 'The number of CPUs in a computer system defines the number of processes running
    truly in parallel. This is shown in the following diagram:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机系统中的CPU数量定义了真正并行运行的进程数量。这在下图中显示：
- en: '![](img/249ef5f9-c6a5-43bf-bad3-7648ec848c90.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/249ef5f9-c6a5-43bf-bad3-7648ec848c90.png)'
- en: When we speak about multiprocessing, we consider an environment that allows
    several processes to run concurrently. And here comes the tricky part. If the
    processes actually run at the same time, then we say that they run in parallel.
    So, concurrency is not parallelism while parallelism implies concurrency.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论多处理时，我们考虑的是允许多个进程同时运行的环境。这就是棘手的部分。如果进程实际上是同时运行的，那么我们说它们是并行运行的。因此，并发不是并行，而并行意味着并发。
- en: If the system has just one CPU, processes run concurrently but not in parallel.
    The OS manages this with a mechanism called **context switching**. Context switching
    implies freezing the work of the process for a moment, copying all of the register
    values that the process was using at the current time, and storing all of the active
    resources and values of the process. When a process is stopped, another process
    takes on the rights to run. After the specified amount of time provided for this
    second process, the OS starts the context switching for it. Again, it copies all
    of the resources used by the process. Then, the previous process gets started.
    Before starting it, the OS copies back the resources and values to the corresponding
    slots used by the first process and then resumes the execution of this process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统只有一个CPU，进程会同时运行但不是并行的。操作系统通过一种称为**上下文切换**的机制来管理这一点。上下文切换意味着暂停进程的工作一会儿，复制进程在当前时间使用的所有寄存器值，并存储进程的所有活动资源和值。当一个进程停止时，另一个进程获得运行的权利。在为第二个进程提供的指定时间段之后，操作系统开始为其进行上下文切换。同样，它复制进程使用的所有资源。然后，之前的进程开始。在启动它之前，操作系统将资源和值复制回第一个进程使用的相应槽位，然后恢复执行此进程。
- en: 'The interesting thing is that the processes are not even aware of such a thing.
    The described process happens so fast that the user cannot actually notice that
    the programs running in the OS are not actually running at the same time. The
    following illustration depicts two processes run by a single CPU. When one of
    the processes is *active*, the CPU executes its instructions sequentially, storing
    any intermediary data in its registers (you should consider cache memory as in
    the game, too). The other process is *waiting* for the OS to provide its time
    portion to run:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这些过程甚至没有意识到这样的事情。所描述的过程发生得如此之快，以至于用户实际上无法注意到操作系统中运行的程序实际上并不是同时运行的。下图描述了由单个CPU运行的两个进程。当其中一个进程处于*活动*状态时，CPU按顺序执行其指令，将任何中间数据存储在其寄存器中（你也应该考虑缓存内存，就像在游戏中一样）。另一个进程正在*等待*操作系统提供其运行的时间段：
- en: '![](img/a385b09c-4de2-4fd5-8057-8831d0675c61.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a385b09c-4de2-4fd5-8057-8831d0675c61.png)'
- en: 'Running more than one process is a sophisticated job for the OS. It manages
    states of processes, defines which process should take more CPU time than others,
    and so on. Each process gets a fixed time to run before the OS switches to another
    process. This time can be longer for one process and shorter for another. Scheduling
    processes happens using priority tables. The OS provides more time to processes
    with a higher priority, for example, a system process has higher priority than
    user processes. Another example could be that a background task monitoring network
    health has a higher priority than a calculator application. When the provided
    time slice is up, the OS initiates a context switch, that is, it stores the state
    of **Process A** to resume its execution later:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 运行多个进程对操作系统来说是一项复杂的工作。它管理进程的状态，确定哪个进程应该比其他进程占用更多的CPU时间等。每个进程在操作系统切换到另一个进程之前都有固定的运行时间。这个时间对于一个进程可能更长，对于另一个进程可能更短。使用优先级表来调度进程。操作系统为优先级更高的进程提供更多的时间，例如，系统进程的优先级高于用户进程。另一个例子可能是，监控网络健康的后台任务的优先级高于计算器应用程序。当提供的时间片用完时，操作系统会启动上下文切换，即，它会存储**进程A**的状态以便稍后恢复其执行：
- en: '![](img/1d6e1429-9787-443b-9ea6-2a591b51de4c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d6e1429-9787-443b-9ea6-2a591b51de4c.png)'
- en: 'After storing the state, as showing in the following diagram, it switches to
    the next process to execute it:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储状态之后，如下图所示，它切换到下一个进程来执行：
- en: '![](img/9ba4ecae-987c-4b5a-a51c-2790b12a3c5e.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ba4ecae-987c-4b5a-a51c-2790b12a3c5e.png)'
- en: 'Obviously, if **Process B** was running before, its state should be loaded
    back to the CPU. In the same way, when the time slice (or time quantum) is up
    for **Process B**, the OS stores its state and loads the state of **Process A**
    back to the CPU (the state it had before being paused by the OS):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，如果**进程B**之前正在运行，它的状态应该被加载回CPU。同样，当**进程B**的时间片（或时间量子）用完时，操作系统会存储它的状态，并将**进程A**的状态加载回CPU（在被操作系统暂停之前的状态）：
- en: '![](img/ed451d71-cf02-45f6-8929-484ecb4ed453.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed451d71-cf02-45f6-8929-484ecb4ed453.png)'
- en: 'Processes do not share anything in common—or at least they think so. Each running
    process behaves as if it''s alone in the system. It has all of the resources the
    OS can provide. In reality, the OS manages to keep processes unaware of each other,
    hence simulating freedom for each one. Finally, after loading the state of **Process
    A** back, the CPU continues executing its instructions like nothing happened:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 进程之间没有任何共同之处，或者至少它们认为是这样。每个运行的进程都表现得好像它是系统中唯一的。它拥有操作系统可以提供的所有资源。实际上，操作系统设法让进程彼此不知晓，因此为每个进程模拟了自由。最后，在将**进程A**的状态加载回来后，CPU继续执行它的指令，就好像什么都没有发生过：
- en: '![](img/b44e37d7-6d77-4248-ad76-e94dc8ab76f4.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b44e37d7-6d77-4248-ad76-e94dc8ab76f4.png)'
- en: '**Process B** is frozen until a new time slice is available for it to run.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**进程B**被冻结，直到有新的时间片可用于运行它。'
- en: A single CPU running more than one process is similar to a teacher checking
    examination papers of students. The teacher can check only one exam paper at a
    time, though they can introduce some concurrency by checking answers one by one
    for each exam test. First, they check the answer to the first question for one
    student, then switch to the first answer of the test of the second student, and
    then switches back to the first student's second answer and so on. Whenever the
    teacher switch from one exam paper to the other, they note down the number of
    the question where they left off. This way, they will know where to start when
    getting back to the same paper.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个单CPU运行多个进程类似于一位老师检查学生的考卷。老师一次只能检查一份考卷，尽管他们可以通过逐个检查每个考试的答案来引入一些并发性。首先，他们检查一个学生的第一个问题的答案，然后切换到第二个学生的考试的第一个答案，然后再切换回第一个学生的第二个答案，依此类推。每当老师从一份考卷切换到另一份时，他们都会记下他们停下来的问题的编号。这样，当他们回到同一份考卷时，他们就知道从哪里开始。
- en: In the same way, the OS notes down the point of execution of a process before
    pausing it to resume another process. The second process can (and most probably
    will) use the same register set used by the paused process. This forces the OS
    to store register values for the first process somewhere to be recovered later.
    When the OS pauses the second process to resume the first one, it loads already
    saved register values back into corresponding registers. The resumed process won't
    notice any difference and will continue its work like it was never paused.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，操作系统在暂停一个进程以恢复另一个进程之前记录下进程的执行点。第二个进程可以（而且很可能会）使用被暂停进程使用的相同寄存器集。这迫使操作系统将第一个进程的寄存器值存储在某个地方，以便稍后恢复。当操作系统暂停第二个进程以恢复第一个进程时，它会将已保存的寄存器值加载回相应的寄存器中。恢复的进程不会注意到任何差异，并将继续工作，就好像它从未被暂停过一样。
- en: Everything described in the preceding two paragraphs relates to single-CPU systems.
    In the case of multi-CPU systems, each CPU in the system has its own set of registers.
    Also, each CPU can execute program instructions independently of the other CPUs,
    which allows running processes in parallel without pausing and resuming them.
    In the example, a teacher with a couple of assistants is similar to a system with
    three CPUs. Each one of them can check one exam paper; all of them are checking
    three different exam papers at any point in time.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 前两段描述的一切都与单CPU系统有关。在多CPU系统中，系统中的每个CPU都有自己的寄存器集。此外，每个CPU可以独立地执行程序指令，而不受其他CPU的影响，这允许进程并行运行而无需暂停和恢复它们。在这个例子中，一位老师和几个助手类似于一个有三个CPU的系统。他们每个人都可以检查一份考卷；他们在任何时候都在检查三份不同的考卷。
- en: Challenges with processes
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程的挑战
- en: 'Difficulties arise when processes need to contact each other in some way. Let''s
    say a process should calculate something and pass the value to a completely different
    process. There are several methods to achieve IPC—one of them is using a memory
    segment shared between processes. The following diagram depicts two processes
    accessing the shared memory segment:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当进程需要以某种方式相互联系时，困难就会出现。比如，一个进程应该计算某些东西并将值传递给一个完全不同的进程。有几种方法可以实现IPC，其中一种是使用在进程之间共享的内存段。下图描述了两个进程访问共享内存段的情况：
- en: '![](img/ba6aa4ed-83da-4987-b27f-17429fa23ec4.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba6aa4ed-83da-4987-b27f-17429fa23ec4.png)'
- en: One process stores the results of the calculation to a shared segment in the
    memory, and the second process reads it from the segment. In the context of our
    previous example, the teacher and their assistants share their checking results
    in a shared paper. Threads, on the other hand, share address space of the process
    because they run in the context of the process. While a process is a program,
    thread is a function rather than a program. That said, a process must have at
    least one thread , which we call the thread of execution. A thread is the container
    of instructions of a program that are run in the system, while the process encapsulates
    the thread and provides resources for it. Most of our interest lies in threads
    and their orchestration mechanisms. Let's now meet them in person.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个进程将计算结果存储到内存中的共享段中，第二个进程从该段中读取。在我们之前的例子中，老师和他们的助手在共享的纸上分享他们的检查结果。另一方面，线程共享进程的地址空间，因为它们在进程的上下文中运行。虽然进程是一个程序，线程是一个函数而不是一个程序。也就是说，一个进程必须至少有一个线程，我们称之为执行线程。线程是在系统中运行的程序的指令容器，而进程封装了线程并为其提供资源。我们大部分的兴趣都在于线程及其编排机制。现在让我们亲自见见它们。
- en: Threads
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程
- en: A **thread** is a section of code in the scope of a process that can be scheduled
    by the OS scheduler. While a process is the image of the running program, managing
    multi-process projects along with IPC is much harder and sometimes useless compared
    to projects leveraging multithreading. Programs deal with data and, usually, collections
    of data. Accessing, processing, and updating data is done by functions that are
    either the methods of objects or free functions composed together to achieve an
    end result. In most projects, we deal with tens of thousands of functions and
    objects. Each function represents a bunch of instructions wrapped under a sensible
    name used to invoke it by other functions. Multithreading aims to run functions
    concurrently to achieve better performance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 线程是进程范围内可以由操作系统调度的代码部分。虽然进程是运行程序的映像，但与利用多线程的项目相比，管理多进程项目以及IPC要困难得多，有时也是无用的。程序处理数据，通常是数据集合。访问、处理和更新数据是通过函数来完成的，这些函数要么是对象的方法，要么是组合在一起以实现最终结果的自由函数。在大多数项目中，我们处理成千上万个函数和对象。每个函数代表一堆指令，这些指令以一个合理的名称包装起来，用于被其他函数调用。多线程旨在并发运行函数以实现更好的性能。
- en: 'For example, a program that calculates the sum of three different vectors and
    prints them calls the function calculating the sum for the first vector, then
    for the second vector, and finally, for the last one. It all happens sequentially.
    If the processing of a single vector takes A amount of time, then the program
    will run in `3A` time. The following code demonstrates the example:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个计算三个不同向量的和并打印它们的程序调用计算第一个向量的和的函数，然后是第二个向量，最后是最后一个。这一切都是顺序进行的。如果处理单个向量需要A的时间，那么程序将在`3A`的时间内运行。以下代码演示了这个例子：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If there was a way to run the same function for three different vectors simultaneously,
    it would take just A amount of time for the whole program in the preceding example.
    Threads of execution, or just threads, are exact ways of running tasks concurrently.
    By tasks, we usually mean a function, although you should remember `std::packaged_task`
    as well. Again, concurrency shouldn't be confused with parallelism. When we speak
    about threads running concurrently, you should consider the context switching
    discussed previously for the process. Almost the same applies to threads.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一种方法可以同时为三个不同的向量运行相同的函数，那么在前面的例子中整个程序只需要A的时间。执行线程，或者说线程，是并发运行任务的确切方式。通过任务，我们通常指的是一个函数，尽管你也应该记住`std::packaged_task`。再次强调，并发不应与并行混淆。当我们谈论线程并发运行时，你应该考虑之前讨论的进程的上下文切换。几乎同样适用于线程。
- en: '`std::packaged_task` is similar to `std::function`. It wraps a callable object—a
    function, lambda, function object, or bind expression. The difference with `std::packaged_task`
    is that it can be invoked asynchronously. There''s more on that later in this
    chapter.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::packaged_task`类似于`std::function`。它包装了一个可调用对象——函数、lambda、函数对象或绑定表达式。与`std::packaged_task`的区别在于它可以异步调用。本章后面会详细介绍这一点。'
- en: Each process has a single thread of execution, sometimes called the **main thread**.
    A process can have more than one thread, and that's when we call it **multithreading**.
    Threads run in almost the same way the processes. They also have context switching.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每个进程都有一个单一的执行线程，有时被称为**主线程**。一个进程可以有多个线程，这时我们称之为**多线程**。线程几乎以与进程相同的方式运行。它们也有上下文切换。
- en: Threads run separately from each other, but they share most of the resources
    of process because all of the threads belong to the process. The process occupies
    hardware and software resources such as CPU registers and memory segments, including
    its own stack and heap. While a process doesn't share its stack or heap with other
    processes, its threads have to use the same resources that are occupied by the
    process. Everything that happens in a thread's life happens within the process.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 线程彼此独立运行，但因为所有线程都属于同一个进程，它们大部分资源都是共享的。进程占用硬件和软件资源，如CPU寄存器和内存段，包括自己的堆栈和堆。虽然进程不与其他进程共享其堆栈或堆，但其线程必须使用进程占用的相同资源。线程的一切生活都发生在进程内部。
- en: 'However, threads don''t share the stack. Each thread has its portion of the
    stack. The reason behind this segregation relies on the fact that a thread is
    just a function and the function itself should have access to the stack to manage
    the life cycle of its arguments and local variables. When we run the same function
    as two (or more) separately running threads, the runtime should somehow handle
    their boundaries. Although it''s error-prone, you can pass a variable from one
    thread to another (either by value or by reference). Let''s suppose that we started
    three threads running the `process_vector()` function for the three vectors in
    the preceding example. You should imagine that starting a thread means *copying*
    the underlying function somehow (its variables but not the instructions) and running
    it separately from any other thread. In this scenario, the same function will
    be copied as three different images, and each one of them will run independently
    of the others, hence each should have its own stack. On the other hand, the heap
    is shared between threads. So, basically, we arrive at the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，线程不共享堆栈。每个线程都有自己的堆栈部分。这种隔离的原因在于，线程只是一个函数，函数本身应该可以访问堆栈来管理其参数和局部变量的生命周期。当我们将相同的函数作为两个（或更多）分别运行的线程运行时，运行时应该以某种方式处理它们的边界。虽然这很容易出错，但你可以通过值或引用将一个变量从一个线程传递到另一个线程。假设我们启动了三个线程，分别运行上面例子中的三个向量的`process_vector()`函数。你应该想象启动一个线程意味着以某种方式*复制*底层函数（它的变量但不是指令）并将其独立地运行。在这种情况下，相同的函数将被复制为三个不同的图像，并且每个图像都将独立于其他图像运行，因此每个图像都应该有自己的堆栈。另一方面，堆在线程之间是共享的。因此，基本上我们得到了以下结论：
- en: '![](img/2837ebc0-a491-4359-aa66-f0e737feff43.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2837ebc0-a491-4359-aa66-f0e737feff43.png)'
- en: As in the case of processes, threads running concurrently are not necessarily running
    in parallel. Each thread gets a small portion of CPU time to be run and, again,
    there is an overhead regarding the switching from one thread to another. Each
    paused thread's state should be stored somewhere to be recovered later when resuming
    it. The internal structure of the CPU defines whether threads could truly run
    in parallel. The number of CPU cores defines the number of threads that can truly
    run in parallel.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与进程一样，并发运行的线程不一定是并行运行的。每个线程都会获得一小部分CPU时间来运行，而且从一个线程切换到另一个线程也会有开销。每个暂停的线程状态都应该被存储在某个地方，以便在恢复时能够恢复。CPU的内部结构定义了线程是否能够真正并行运行。CPU核心的数量定义了可以真正并行运行的线程数量。
- en: The C++ thread library provides the `hardware_concurrency()` function to find
    out the number of threads that can truly run concurrently. You can refer to this
    number when designing concurrent code.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: C++线程库提供了`hardware_concurrency()`函数，用于查找可以真正并发运行的线程数量。在设计并发代码时，可以参考这个数字。
- en: 'The following diagram depicts two CPUs having four cores each. Each core can
    run a thread independently of the other:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了两个CPU，每个CPU都有四个核心。每个核心可以独立地运行一个线程：
- en: '![](img/82938768-6461-41e2-94dc-454295e6fd96.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82938768-6461-41e2-94dc-454295e6fd96.png)'
- en: 'Not only do two processes run in parallel but also their threads are run in
    parallel using the CPU cores. Now, how will the situation change if we have several
    threads but one single-core CPU? Almost the same as we have illustrated earlier
    for processes. Look at the following diagram—it depicts how the CPU executes **Thread
    1** for some time slice:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅两个进程并行运行，它们的线程也使用CPU核心并行运行。那么，如果我们有几个线程但只有一个单核CPU，情况会如何改变呢？几乎与我们之前为进程所说明的情况相同。看看下面的图表——它描述了CPU如何在某个时间片段内执行**线程1**：
- en: '![](img/43a122ae-5378-4cb0-8770-cfea0b51cad2.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43a122ae-5378-4cb0-8770-cfea0b51cad2.png)'
- en: The currently active **Process A** has two threads that run concurrently. At
    each specified point in time, only one of the threads is executed. When the time
    slice is up for **Thread 1**, **Thread 2** is executed. The difference from the
    model we discussed for processes is that threads share the resources of the process,
    which leads to unnatural behavior if we aren't concerned with concurrent code
    design issues. Let's dive into C++ threading support and find out what issues
    arise when using multithreading.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当前活动的**进程A**有两个同时运行的线程。在每个指定的时间点，只有一个线程被执行。当**线程1**的时间片用完时，**线程2**被执行。与我们讨论过的进程模型的不同之处在于，线程共享进程的资源，如果我们不关心并发代码设计问题，这会导致不自然的行为。让我们深入了解C++线程支持，并找出在使用多线程时会出现什么问题。
- en: Working with threads
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程
- en: 'When the C++ program starts, that is, the `main()` function starts its execution,
    you can create and launch new threads that will run concurrently to the main thread. To
    start a thread in C++, you should declare a thread object and pass it the function
    that you want to run concurrently to the main thread. The following code demonstrates
    the declaration and starting of a thread using `std::thread` defined in `<thread>`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当C++程序启动时，也就是`main()`函数开始执行时，你可以创建并启动新的线程，这些线程将与主线程并发运行。要在C++中启动一个线程，你应该声明一个线程对象，并将要与主线程并发运行的函数传递给它。以下代码演示了使用`<thread>`中定义的`std::thread`声明和启动线程：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'That''s it. We can create a better example to show how two threads work concurrently.
    Let''s say we print numbers in a loop concurrently to see which thread prints
    what:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。我们可以创建一个更好的例子来展示两个线程如何同时工作。假设我们同时在循环中打印数字，看看哪个线程打印了什么：
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding example will print both outputs with the `Main:` and `Background:` prefixes mixed
    together. An excerpt from the output might look like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的例子将打印出带有`Main:`和`Background:`前缀混合在一起的两个输出。输出的摘录可能如下所示：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Whenever the main thread finishes its work (printing to the screen one million
    times), the program wants to finish without waiting for the background thread
    to complete. It leads to program termination. Let's see how we should modify the
    previous example.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当主线程完成其工作（向屏幕打印一百万次）时，程序希望在不等待后台线程完成的情况下结束。这会导致程序终止。让我们看看如何修改之前的例子。
- en: Waiting for threads
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等待线程
- en: 'The `thread` class provides the `join()` function if you want to wait for it
    to finish. Here is a modified version of the previous example that waits for the
    `background` thread:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要等待线程完成，`thread`类提供了`join()`函数。以下是等待`background`线程的修改版本的示例：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As we already discussed previously, the `thread` function is run as a separate
    entity independently from other threads- even the one that started it. It won't
    wait for the thread it has just started, and that's why you should explicitly
    tell the caller function to wait for it to finish. It is necessary to signal that
    the calling thread (the main thread) is waiting for the thread to finish before
    itself.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，`thread`函数作为一个独立的实体运行，独立于其他线程-甚至是启动它的线程。它不会等待它刚刚启动的线程，这就是为什么您应该明确告诉调用函数在自己之前等待它完成。在它完成之前，必须发出信号表明调用线程（主线程）正在等待线程完成。
- en: 'The symmetric opposite of the `join()` function is the `detach()` function.
    The `detach()` function indicates that the caller isn''t interested in waiting
    for the thread to finish. In this case, the thread can have an independent life.
    As shown here (like it''s already 18 years old):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`join()`函数的对称相反是`detach()`函数。`detach()`函数表示调用者对等待线程完成不感兴趣。在这种情况下，线程可以有独立的生命周期。就像这里显示的（就像它已经18岁了）：'
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Although detaching a thread might seem natural, there are plenty of scenarios
    when we need to wait for the thread to finish. For example, we might pass local
    to the caller variables to the running thread. In this case, we can''t let the
    caller detach the thread as the caller might finish its work earlier than the
    thread started in it. Let''s illustrate that for the sake of clarity. **Thread
    1** declares the `loc` variable and passes it to **Thread 2**, which has been
    started from **Thread 1**:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分离线程可能看起来很自然，但有很多情况需要等待线程完成。例如，我们可能会将局部变量传递给正在运行的线程。在这种情况下，我们不能让调用者分离线程，因为调用者可能比线程更早完成其工作。让我们为了清晰起见举个例子。**Thread
    1**声明了`loc`变量并将其传递给了从**Thread 1**启动的**Thread 2**：
- en: '![](img/8bcd907b-742d-4b19-9484-87822f730a68.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8bcd907b-742d-4b19-9484-87822f730a68.png)'
- en: 'Passing the address of `loc` to **Thread 2** is error-prone if **Thread 1**
    doesn''t join it. If **Thread 1** finishes its execution before **Thread 2**,
    then accessing `loc` by its address leads to an undefined behavior:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果**Thread 1**在**Thread 2**之前完成其执行，那么通过地址访问`loc`会导致未定义的行为：
- en: '![](img/58cea33e-6366-4f28-9ac5-84e785da0452.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58cea33e-6366-4f28-9ac5-84e785da0452.png)'
- en: There is no such object anymore, so the best that we can hope for the program
    is to crash. It will lead to unexpected behavior because the running thread won't
    have access to the caller's local variables anymore. You should either join or
    detach a thread.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 不再有这样的对象，因此我们可以希望程序最好崩溃。这将导致意外行为，因为运行线程将不再访问调用者的局部变量。您应该加入或分离线程。
- en: 'We can pass any callable object to `std::thread`. The following example shows
    passing a lambda expression to the thread:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将任何可调用对象传递给`std::thread`。以下示例显示了将lambda表达式传递给线程：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Furthermore, we can use callable objects as thread arguments. Take a look at
    the following code declaring the `TestTask` class with the overridden `operator()`
    function:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用可调用对象作为线程参数。看一下以下代码，声明了具有重载的`operator()`函数的`TestTask`类：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: One of the advantages of a functor (the `TestTask` class with the overridden
    `operator()` function ) is its ability to store state information. Functors are
    a beautiful implementation of the command design pattern that we will discuss
    in [Chapter 11](0e28887e-1a43-4510-a8ef-b3ad7531868d.xhtml), *Designing a Strategy
    Game Using Design Patterns*. Getting back to the threads, let's move on the a
    new addition in the language that allows for better ways to join threads.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 函数对象（具有重载的`operator()`函数的`TestTask`类）的一个优点是它能够存储状态信息。函数对象是命令设计模式的一个美丽实现，我们将在[第11章](0e28887e-1a43-4510-a8ef-b3ad7531868d.xhtml)中讨论，*使用设计模式设计策略游戏*。回到线程，让我们继续讨论语言中的一个新添加，它允许更好地加入线程的方式。
- en: Using std::jthread
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::jthread
- en: C++20 introduces a joinable thread, `std::jthread`. It provides the same interface
    `std::thread` as provides, so we can replace all threads with jthreads in the
    code. It actually wraps `std::thread`, so basically it delegates down to the wrapped
    thread.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: C++20引入了可加入线程`std::jthread`。它提供了与`std::thread`相同的接口，因此我们可以在代码中用jthreads替换所有线程。它实际上是对`std::thread`的封装，因此基本上是将操作委托给封装的线程。
- en: 'If the version of your compiler doesn''t support `std::jthread`, you are free
    to go with the **RAII** (**Resource Acquisition Is Initialization**) idiom, which
    is perfectly applicable to threads. Take a look at the following code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的编译器版本不支持`std::jthread`，您可以选择使用**RAII**（**资源获取即初始化**）习惯用法，这对线程非常适用。看一下以下代码：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, the preceding code lacks an additional check because a thread passed
    to the RAII class might have been already detached. To see whether the thread
    could be joined, we use the `joinable()` function. This is how we should overwrite
    the `thread_raii` class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，前面的代码缺少了一个额外的检查，因为传递给RAII类的线程可能已经被分离。为了查看线程是否可以加入，我们使用`joinable()`函数。这是我们应该如何重写`thread_raii`类的方式：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The destructor first tests whether the thread is joinable before calling the
    `join()` function. However, instead of dealing with idioms and being concerned
    about whether the thread has been joined already before joining it, we prefer
    using `std::jthread`. Here''s how we can do that using the `TestTask` function
    declared previously:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`join()`函数之前，析构函数首先测试线程是否可加入。但是，与其处理习惯用法并担心线程在加入之前是否已经加入，我们更喜欢使用`std::jthread`。以下是如何使用先前声明的`TestTask`函数来做到这一点：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'That''s it—there''s no need to call `jt.join()`, and a new cooperative interruptible
    feature out of the box that we use by incorporating jthread. We say that jthread
    is cooperative interruptible because it provides the `request_stop()` function
    ,which does what its name says—requests the thread to stop. Although that request
    fulfillment is implementation-defined, it''s a nice way not to wait for the thread
    forever. Recall the example with the thread printing numbers in an infinite loop.
    We modified the main thread to wait for it, and that leads to waiting for it forever.
    Here''s how we can modify the thread using `std::jthread` to leverage the `request_stop()`
    function:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样——不需要调用`jt.join()`，并且我们使用`std::jthread`内置的新的协作可中断功能。我们说`jthread`是协作可中断的，因为它提供了`request_stop()`函数，它做了它的名字所说的事情——请求线程停止。尽管请求的实现是定义的，但这是一个不必永远等待线程的好方法。回想一下线程在无限循环中打印数字的例子。我们修改了主线程来等待它，这导致永远等待它。下面是我们如何使用`std::jthread`修改线程以利用`request_stop()`函数：
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `print_numbers_in_background()` function now receives a request and can
    behave accordingly. Now, let's see how to pass arguments to the thread function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`print_numbers_in_background()`函数现在接收到一个请求，并可以相应地行为。现在，让我们看看如何将参数传递给线程函数。'
- en: Passing arguments to the thread function
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将参数传递给线程函数
- en: 'The `std::thread` constructor takes arguments and forwards them to the underlying
    `thread` function. For example, to pass the arguments `4` and `2` to the `foo()`
    function here, we pass the arguments to the `std::thread` constructor:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::thread`构造函数接受参数并将它们转发给底层的`thread`函数。例如，要将参数`4`和`2`传递给`foo()`函数，我们将参数传递给`std::thread`构造函数：'
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The arguments `4` and `2` will be passed as the first and second arguments to
    the `foo()` function.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`4`和`2`参数将作为`foo()`函数的第一个和第二个参数传递。'
- en: 'The following example illustrates the passing of an argument by reference:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例说明了通过引用传递参数：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To understand why we named the function `error_prone`, we should know that the
    thread constructor copies the values passed to it and then passes them to the
    thread function with `rvalue` references. This is done to work with move-only
    types. So it will try to call the `make_changes()` function with `rvalue`, which
    will fail to compile (you can't pass `rvalue` to a function that expects a non-constant
    reference). We need to wrap the arguments that need to be a reference in `std::ref:`
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解为什么我们将函数命名为`error_prone`，我们应该知道线程构造函数会复制传递给它的值，然后使用`rvalue`引用将它们传递给线程函数。这是为了处理仅可移动类型。因此，它将尝试使用`rvalue`调用`make_changes()`函数，这将无法编译通过（不能将`rvalue`传递给期望非常量引用的函数）。我们需要在需要引用的参数中使用`std::ref`进行包装。
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding code emphasizes that the argument should be passed by reference.
    Working with threads requires being a little more attentive because there are
    many ways to get unexpected results or undefined behavior in the program. Let's
    see how we can manage threads to produce safer multithreaded applications.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码强调了参数应该通过引用传递。处理线程需要更加注意，因为程序中有许多方法可以获得意外结果或未定义的行为。让我们看看如何管理线程以生成更安全的多线程应用程序。
- en: Managing threads and sharing data
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理线程和共享数据
- en: As discussed previously, the execution of threads involves pausing and resuming
    some of them if the number of threads exceeds the number of parallel running threads
    supported by the hardware. Besides that, the creation of a thread also has its
    overhead. One of the suggested practices to deal with having many threads in a
    project is using thread pools.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前讨论的，线程的执行涉及暂停和恢复其中一些线程，如果线程数量超过硬件支持的并行运行线程数量。除此之外，线程的创建也有开销。在项目中处理有许多线程的建议做法之一是使用线程池。
- en: 'The idea of a thread pool lies in the concept of caching. We create and keep
    threads in some container to be used later. The container is called a pool. For
    example, the following vector represents a simple thread pool:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 线程池的概念在于缓存的概念。我们创建并保留线程在某个容器中以便以后使用。这个容器称为池。例如，以下向量表示一个简单的线程池：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Whenever we need a new thread, instead of declaring the corresponding `std::thread`
    object, we use one already created in the pool. When we are done with the thread,
    we can push it back to the vector to use it later if necessary. This saves some
    time when working with 10 or more threads. A proper example would be a web server.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们需要一个新线程时，我们不是声明相应的`std::thread`对象，而是使用已在池中创建的线程。当我们完成线程时，我们可以将其推回向量以便以后使用。这在处理10个或更多线程时可以节省一些时间。一个合适的例子是一个Web服务器。
- en: 'A web server is a program that waits for incoming client connections and creates
    a separate connection for each client to be processed independently from others.
    A typical web server usually deals with thousands of clients at the same time.
    Each time a new connection is initiated with some client, the web server creates
    a new thread and handles the client requests. The following pseudo-code demonstrates
    a simple implementation of a web server''s incoming connection management:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Web服务器是一个等待传入客户端连接并为每个客户端创建一个独立连接以独立处理的程序。一个典型的Web服务器通常同时处理数千个客户端。每当与某个客户端启动新连接时，Web服务器都会创建一个新线程并处理客户端请求。以下伪代码演示了Web服务器传入连接管理的简单实现：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When using a thread pool, the preceding code will avoid the creation of a thread
    each time it needs to process a client request. The creation of a new thread requires
    additional and rather expensive work from the OS. To save that time, we use a
    mechanism that omits creating new threads on each request. To make the pool even
    better, let''s replace its container with a queue. Whenever we ask for a thread,
    the pool will return a free thread, and whenever we are done with a thread, we
    push it back to the pool. A simple design of a thread pool would look like the
    following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程池时，前面的代码将避免每次处理客户端请求时都创建一个线程。创建新线程需要操作系统额外且昂贵的工作。为了节省时间，我们使用一种机制，可以在每个请求时省略创建新线程。为了使线程池更好，让我们用队列替换它的容器。每当我们请求一个线程时，线程池将返回一个空闲线程，每当我们完成一个线程时，我们将其推回线程池。线程池的简单设计如下：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The constructor creates and pushes threads to the queue. In the following pseudo-code,
    we replace the direct creation of a thread for client request processing with
    `ThreadPool` ,which we looked at previously:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数创建并将线程推送到队列。在下面的伪代码中，我们用之前介绍的`ThreadPool`替换了直接创建线程来处理客户端请求：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Supposing that the `handle_request()` function pushes the thread back to the
    pool when it's done, the pool behaves as a centralized store for connection threads.
    Though shown in the preceding snippet is far from being ready for production,
    it conveys the basic idea of using thread pools in intensive applications.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 假设`handle_request()`函数在完成时将线程推回线程池，那么线程池就像是连接线程的集中存储。虽然前面的片段远未准备好投入生产，但它传达了在密集应用中使用线程池的基本思想。
- en: Sharing data
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享数据
- en: 'A race condition is something that programmers using multithreading are scared
    of and try to avoid as much as possible. Imagine two functions that work concurrently
    with the same data, as shown here:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争条件是多线程程序员害怕并尽量避免的事情。想象一下两个函数同时处理相同的数据，如下所示：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: A potential race condition is happening because threads `t1` and `t2` are modifying
    the same variable with more than one step. Any operation that is performed in
    a single thread-safe step is called an **atomic operation**. In this case, incrementing
    the value of the variable is not an atomic operation, even if we use the increment
    operator.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 可能发生竞争条件，因为线程`t1`和`t2`正在用多个步骤修改相同的变量。在单个线程安全步骤中执行的任何操作称为**原子操作**。在这种情况下，即使使用增量运算符，增加变量的值也不是原子操作。
- en: Protecting shared data using a mutex
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用互斥锁保护共享数据
- en: 'To protect shared data, objects called **mutexes** are used widely. A mutex
    is an object that controls the running of a thread. Imagine threads as humans
    making a deal about how to work with data one by one. When a thread locks a mutex,
    the other thread waits until it is done with the data and unlocks the mutex. The
    other thread then locks the mutex and starts working with data. The following
    code demonstrates how we can solve the problem of a race condition using a mutex:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保护共享数据，广泛使用称为**互斥锁**的对象。互斥锁是控制线程运行的对象。想象线程就像人类一样，一次处理数据的交易。当一个线程锁定一个互斥锁时，另一个线程会等待，直到它完成数据并解锁互斥锁。然后另一个线程锁定互斥锁并开始处理数据。以下代码演示了如何使用互斥锁解决竞争条件的问题：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: When `t1` starts executing `inc()`, it locks a mutex, which avoids any other
    thread to access the global variable unless the original thread doesn't unlock
    the next thread.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当`t1`开始执行`inc()`时，它锁定一个互斥锁，这样可以避免其他线程访问全局变量，除非原始线程不解锁下一个线程。
- en: 'C++17 introduced a lock guard that allows guarding the mutex in order not to
    forget unlock it:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: C++17引入了锁保护，允许保护互斥锁，以免忘记解锁它：
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It's always better to use language-provided guards if possible.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，最好使用语言提供的保护。
- en: Avoiding deadlocks
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免死锁
- en: New problems arise with mutexes, such as **deadlocks**. A deadlock is a condition
    of  multithreaded code when two or more threads lock a mutex and wait for the
    other to unlock another.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁会带来新的问题，比如**死锁**。死锁是多线程代码的一种情况，当两个或多个线程锁定一个互斥锁并等待另一个解锁时发生。
- en: The common advice to avoid deadlock is to always lock two or more mutexes in
    the same order. C++ provides the `std::lock()` function, which serves the same
    purpose.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 避免死锁的常见建议是始终以相同的顺序锁定两个或多个互斥锁。C++提供了`std::lock()`函数，用于相同的目的。
- en: 'The following code illustrates the `swap` function, which takes two arguments
    of type `X`. We suppose that `X` has a member, `mt` , which is a mutex. The implementation
    of the `swap` function locks the mutex of the left object first, then it locks
    the mutex of the right object:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码说明了`swap`函数，它接受两个类型为`X`的参数。我们假设`X`有一个名为`mt`的成员，它是一个互斥锁。`swap`函数的实现首先锁定左对象的互斥锁，然后锁定右对象的互斥锁：
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: To avoid deadlocks in general, avoid nested locks. That said, don't acquire
    a lock if you are already holding one. If this is not the case, then acquire locks
    in a fixed order. The fixed order will allow you to avoid deadlocks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了一般地避免死锁，避免嵌套锁。也就是说，如果已经持有一个锁，则不要获取另一个锁。如果不是这种情况，则按固定顺序获取锁。固定顺序将允许您避免死锁。
- en: Designing concurrent code
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计并发代码
- en: Project complexity rises drastically when concurrency is introduced. It's much
    easier to deal with sequentially executing synchronous code compared to concurrent
    counterparts. Many systems avoid using multithreading at all by introducing event-driven
    development concepts, such as the event loop. The point of using an event loop
    is to introduce a manageable approach to asynchronous programming. To take the
    concept further, imagine any application providing a **Graphical User Interface**
    (**GUI**). Whenever the user clicks on any GUI component, such as buttons; types
    in fields; or even moves the mouse, the application receives so-called events
    regarding the user action. Whether it's `button_press`, `button_release`, `mouse_move`,
    or any other event, it represents a piece of information to the application to
    react properly. A popular approach is to incorporate an event loop to queue any
    event that occurred during user interaction.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当并发引入时，项目复杂性会急剧上升。与并发对应的同步代码相比，处理顺序执行的同步代码要容易得多。许多系统通过引入事件驱动开发概念（如事件循环）来避免使用多线程。使用事件循环的目的是引入一种可管理的异步编程方法。进一步想象，任何提供图形用户界面（GUI）的应用程序。每当用户点击任何GUI组件，如按钮；在字段中输入；甚至移动鼠标时，应用程序都会接收有关用户操作的所谓事件。无论是`button_press`、`button_release`、`mouse_move`还是其他任何事件，它都代表了应用程序对信息的正确反应。一种流行的方法是将事件循环结合起来，以排队用户交互期间发生的任何事件。
- en: While the application is busy with its current task, the events produced by
    user actions are queued to be processed at some time in the future. The processing
    involves calling handler functions attached to each event. They are called in
    the order they were put into the queue.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序忙于当前任务时，由用户操作产生的事件被排队等待在将来的某个时间进行处理。处理涉及调用附加到每个事件的处理程序函数。它们按照它们被放入队列的顺序进行调用。
- en: 'Introducing multithreading to the project brings additional complexity with
    it. You should now take care of race conditions and proper thread handling, maybe
    even using a thread pool to reuse thread objects. In sequentially executed code,
    you care for the code and only the code. Using multithreading, you now care a
    little bit more about the ways of execution of the very same code. For example,
    a simple design pattern such as the singleton behaves differently in a multithreading
    environment. The classic implementation of a singleton looks like the following:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将多线程引入项目会带来额外的复杂性。现在，您需要关注竞争条件和适当的线程处理，甚至可能使用线程池来重用线程对象。在顺序执行的代码中，您只关心代码。使用多线程，您现在需要更多地关注相同代码的执行方式。例如，一个简单的设计模式，如单例，在多线程环境中的行为会有所不同。单例的经典实现如下：
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following code starts two threads, both using the `MySingleton` class:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码启动了两个线程，都使用了`MySingleton`类：
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Threads `t1` and `t2` both call the `get_instance()` static member function
    of the `MySingleton` class. It''s possible that `t1` and `t2` both pass the check
    for the empty instance and both execute the new operator. Clearly, we have a race
    condition here. The resource, in this case, the class instance, should be protected
    from such a scenario. Here''s an obvious solution using a mutex:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 线程`t1`和`t2`都调用`MySingleton`类的`get_instance()`静态成员函数。可能`t1`和`t2`都通过了对空实例的检查，并且都执行了新操作符。很明显，这里存在竞争条件。在这种情况下，资源（在本例中是类实例）应该受到保护。以下是使用互斥量的明显解决方案：
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Using a mutex will solve the problem, but will make the function work more
    slowly because each time a thread requests an instance, a mutex will be locked
    instead (which involves additional operations by the OS kernel). The proper solution
    would be using the Double-Checked Locking pattern. Its basic idea is this:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用互斥量可以解决问题，但会使函数的工作速度变慢，因为每次线程请求一个实例时，都会锁定一个互斥量（这涉及操作系统内核的额外操作）。正确的解决方案是使用双重检查锁定模式。它的基本思想是这样的：
- en: Lock the mutex after the `instance_` check.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`instance_`检查后锁定互斥量。
- en: Check the `instance_` again after the mutex has been locked because another
    thread might have passed the first check and wait for the mutex to unlock.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在锁定互斥量后再次检查`instance_`，因为另一个线程可能已经通过了第一次检查，并等待互斥量解锁。
- en: 'See the code for details:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有关详细信息，请参阅代码：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Several threads may pass the first check and one of them will lock the mutex.
    Only one thread makes it to the new operator call. However, after unlocking the
    mutex, threads that have passed the first check will try to lock it and create
    the instance. The second check is there to prevent this. The preceding code allows
    us to reduce the performance overhead of the synchronized code. The approach we
    provided here is one of the ways to prepare yourself for concurrent code design.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 几个线程可能通过第一次检查，其中一个线程将锁定互斥量。只有一个线程可以进行新操作符调用。然而，在解锁互斥量后，通过第一次检查的线程将尝试锁定它并创建实例。第二次检查是为了防止这种情况发生。上述代码使我们能够减少同步代码的性能开销。我们提供的方法是为并发代码设计做好准备的一种方式。
- en: Concurrent code design is very much based on the capabilities of the language
    itself. The evolution of C++ is marvelous. In its earliest versions, it didn't
    have built-in support for multithreading. Now, it has a solid thread library and
    the new C++20 standard provides us with even more powerful tools, such as coroutines.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 并发代码设计在很大程度上基于语言本身的能力。C++的发展是非常了不起的。在最早的版本中，它没有内置支持多线程。现在，它有一个稳固的线程库，而新的C++20标准为我们提供了更强大的工具，如协程。
- en: Introducing coroutines
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入协程
- en: We discussed an example of asynchronous code execution when speaking about GUI
    applications. GUI components react to user actions by firing corresponding events,
    which are pushed in the event queue. This queue are then processed one by one
    by invoking attached handler functions. The described process happens in a loop;
    that's why we usually refer to the concept as the event loop.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论GUI应用程序时，我们讨论了异步代码执行的一个例子。GUI组件通过触发相应的事件来对用户操作做出反应，这些事件被推送到事件队列中。然后，这些队列会通过调用附加的处理程序函数逐个进行处理。所描述的过程在一个循环中发生；这就是为什么我们通常将这个概念称为事件循环。
- en: 'Asynchronous systems are really useful in I/O operations because any input
    or output operation blocks the execution at the point of I/O call. For example,
    the following pseudo-code reads a file from a directory and then prints a welcome
    message to the screen:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 异步系统在I/O操作中非常有用，因为任何输入或输出操作都会在I/O调用点阻塞执行。例如，以下伪代码从目录中读取文件，然后在屏幕上打印欢迎消息：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Attached to the synchronous execution pattern, we know that the message Welcome
    to the app! will be printed only after the `read_file()` function finishes executing.
    `process_file_contents()` will be invoked only after `cout` completes. When dealing
    with asynchronous code, all we know about code execution starts to behave like
    something unrecognizable. The following modified version of the preceding example
    uses the `read_file_async()` function to read the file contents asynchronously:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与同步执行模式相结合，我们知道只有在`read_file()`函数执行完成后才会打印出欢迎来到应用程序！`process_file_contents()`将在`cout`完成后调用。处理异步代码时，我们对代码执行的了解开始表现得像是一些无法识别的东西。以下修改版本的前面的例子使用`read_file_async()`函数异步读取文件内容：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Considering `read_file_async()` is an asynchronous function, the message Welcome
    to the app! will be printed sooner than the file contents. The very nature of
    asynchronous execution allows us to invoke functions to be executed in the background,
    which provides us with non-blocking input/output.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到`read_file_async()`是一个异步函数，欢迎来到应用程序！的消息将比文件内容更早打印出来。异步执行的本质允许我们调用要在后台执行的函数，这为我们提供了非阻塞的输入/输出。
- en: 'However, there is a slight change in the way we treat the return value of the
    function. If we deal with an asynchronous function, its return value is considered
    as something called a **promise** or a **promise object**. It''s the way the system
    notifies us when the asynchronous function has completed. The promise object has
    three states:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们对函数的返回值处理方式有一点变化。如果我们处理一个异步函数，它的返回值被视为一种称为**承诺**或**承诺对象**的东西。这是系统在异步函数完成时通知我们的方式。承诺对象有三种状态：
- en: Pending
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挂起
- en: Rejected
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拒绝
- en: Fulfilled
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现
- en: A promise object is said to be fulfilled if the function is done and the result
    is ready to be processed. In the event of an error, the promise object will be
    in the rejected state. If the promise is not rejected nor fulfilled, it is in
    the pending state.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 承诺对象在函数完成并且结果准备好被处理时被认为是已实现的。在发生错误时，承诺对象将处于拒绝状态。如果承诺既没有被拒绝也没有被实现，它就处于挂起状态。
- en: 'C++20 introduced coroutines as an addition to the classic asynchronous functions.
    Coroutines move the background execution of the code to next level; they allow
    a function to be paused and resumed when necessary. Imagine a function that reads
    file contents and stops in the middle, passes the execution context to another
    function, and then resumes the reading of the file to its end. So, before diving
    deeper, consider a coroutine as a function that can be as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: C++20引入了协程作为经典异步函数的补充。协程将代码的后台执行提升到了下一个级别；它们允许函数在必要时暂停和恢复。想象一个读取文件内容并在中途停止的函数，将执行上下文传递给另一个函数，然后恢复文件的读取直到结束。因此，在深入研究之前，将协程视为以下函数：
- en: Started
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始
- en: Paused
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暂停
- en: Resumed
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复
- en: Finished
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成
- en: 'To make a function a coroutine, you would use one of the keywords `co_await`,
    `co_yield`, or `co_return`. `co_await` is a construct telling the code to wait
    for asynchronously executing code. It means the function can be suspended at that
    point and resume its execution when a result is ready. For example, the following
    code requests an image from the network using a socket:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要使函数成为协程，您可以使用关键字`co_await`、`co_yield`或`co_return`之一。`co_await`是一个构造，告诉代码等待异步执行的代码。这意味着函数可以在那一点被暂停，并在结果准备好时恢复执行。例如，以下代码使用套接字从网络请求图像：
- en: '[PRE32]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As the network request operation is also considered as an **input/output**
    operation, it might block the execution of the code. To prevent blocking, we use
    asynchronous calls. The line using `co_await` in the preceding example is a point
    where the function execution could be suspended. In simpler words, when the execution
    reaches the line with `co_await`, the following happens:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络请求操作也被视为**输入/输出**操作，它可能会阻塞代码的执行。为了防止阻塞，我们使用异步调用。在前面的例子中使用`co_await`的行是函数执行可能被暂停的地方。简单来说，当执行到达带有`co_await`的行时，会发生以下情况：
- en: It quits the function for a while (until there isn't ready data).
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它暂时退出函数（直到没有准备好的数据）。
- en: It continues executing from where it was before `process_image()` was called.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它继续执行`process_image()`被调用之前的位置。
- en: It then comes back again to continue executing `process_image()` at the point
    where it left it.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后它再次回来继续执行`process_image()`在它离开的地方。
- en: To achieve this, a coroutine (the `process_image()` function is a coroutine)
    is not handled the way regular functions are handled in C++. One of the interesting
    or even surprising features of coroutines is that they are **stackless.** We know
    that functions can't live without the stack. That's where the function pushes
    its arguments and local variables before even executing its instructions. Coroutines,
    on the other hand, instead of pushing anything to the stack, save their state
    in the heap and recover it when resumed.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，协程（`process_image()`函数是一个协程）在C++中不像处理常规函数那样处理。协程的一个有趣甚至令人惊讶的特性是它们是**无堆栈的。**我们知道函数不能没有堆栈。这是函数在执行指令之前推送其参数和局部变量的地方。另一方面，协程不是将任何东西推送到堆栈，而是将它们的状态保存在堆中，并在恢复时恢复它们。
- en: This is tricky because there are also stackful coroutines. Stackful coroutines,
    also referred to as **fibers**, have a separate stack.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这很棘手，因为还有堆栈式协程。堆栈式协程，也称为**纤程**，有一个单独的堆栈。
- en: Coroutines are connected to callers. In the preceding example, the function
    that call `sprocess_image()` transfers execution to the coroutine and the pause
    by the coroutine (also known as **yielding**) transfers the execution back to
    the caller. As we stated, the heap is used to store the state of the coroutine,
    but the actual function-specific data (arguments, and local variables) are stored
    on the caller's stack. That's it—the coroutine is associated with an object that
    is stored on the caller function's stack. Obviously, the coroutine lives as long
    as its object.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 协程与调用者相连。在前面的例子中，调用`sprocess_image()`的函数将执行转移到协程，协程的暂停（也称为**yielding**）将执行返回给调用者。正如我们所说，堆用于存储协程的状态，但实际的函数特定数据（参数和局部变量）存储在调用者的堆栈上。就是这样——协程与存储在调用函数堆栈上的对象相关联。显然，协程的生存期与其对象一样长。
- en: Coroutines might give a wrong impression of redundant complexity added to the
    language, but their use cases are great in improving applications that use asynchronous
    I/O code (as in the preceding example) or lazy computations. That said, when we
    have to invent new patterns or introduce complexities into projects to handle,
    for instance, lazy computations, we now can improve our experience by using coroutines
    in C++. Please note that asynchronous I/O or lazy computations are just two examples
    of coroutine applications. There are more out there.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 协程可能会给人一种错误的印象，认为它增加了语言的冗余复杂性，但它们的用例在改进使用异步I/O代码（如前面的例子中）或延迟计算的应用程序中非常好。也就是说，当我们不得不发明新的模式或引入复杂性来处理懒惰计算等项目时，现在我们可以通过在C++中使用协程来改善我们的体验。请注意，异步I/O或延迟计算只是协程应用的两个例子。还有更多。
- en: Summary
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've discussed the concept of concurrency and showed the difference
    between parallelism. We learned the difference between a process and a thread,
    the latter being of interest. Multithreading allows us to manage a program to
    be more efficient, though it also brings additional complexity with it. To handle
    data races, we use synchronization primitives such as a mutex. A mutex is a way
    to lock the data used by one thread to avoid invalid behavior produced by simultaneously
    accessing the same data from several threads.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了并发的概念，并展示了并行之间的区别。我们学习了进程和线程之间的区别，后者引起了我们的兴趣。多线程使我们能够更有效地管理程序，尽管它也带来了额外的复杂性。为了处理数据竞争，我们使用诸如互斥锁之类的同步原语。互斥锁是一种锁定一个线程使用的数据的方式，以避免多个线程同时访问相同数据产生的无效行为。
- en: We also covered the idea that an input/output operation is considered blocking
    and asynchronous functions are one of the ways to make it non-blocking. Coroutines
    as a part of the asynchronous execution of code were introduced in C++20.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了输入/输出操作被认为是阻塞的概念，而异步函数是使其非阻塞的方法之一。协程作为代码的异步执行的一部分在C++20中被引入。
- en: We learned how to create and start a thread. More importantly, we learned how
    to manage data between threads. In the next chapter, we will dive into data structures
    that are used in concurrent environments.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何创建和启动线程。更重要的是，我们学习了如何在线程之间管理数据。在下一章中，我们将深入研究在并发环境中使用的数据结构。
- en: Questions
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is concurrency?
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 并发是什么？
- en: What is the difference between concurrency and parallelism?
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 并发和并行之间的区别是什么？
- en: What is a process?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是进程？
- en: What's the difference between a process and a thread?
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进程和线程之间的区别是什么？
- en: Write code to start a thread.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码启动一个线程。
- en: How could you make the singleton pattern thread-safe?
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使单例模式线程安全？
- en: Rewrite the `MySingleton` class to use `std::shared_ptr` for the returned instance.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重写`MySingleton`类，使用`std::shared_ptr`返回实例。
- en: What are coroutines and what is the `co_await` keyword used for?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是协程，`co_await`关键字用于什么？
- en: Further reading
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Anthony Williams, C++ Concurrency in Action*, [https://www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/](https://www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Anthony Williams，《C++并发实战》，[https://www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/](https://www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/)*'
