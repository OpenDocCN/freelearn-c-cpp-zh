- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Turning the Source File into an Abstract Syntax Tree
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将源文件转换为抽象语法树
- en: As we learned in the previous chapter, a compiler is typically divided into
    two parts – the frontend and the backend. In this chapter, we will implement the
    frontend of a programming language – that is, the part that mainly deals with
    the source language. We will learn about the techniques that real-world compilers
    use and apply them to our programming languages.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章所学，编译器通常分为两个部分——前端和后端。在本章中，我们将实现编程语言的前端——即主要处理源语言的部分。我们将了解现实世界编译器使用的技巧，并将它们应用到我们的编程语言中。
- en: Our journey will begin with us defining our programming language’s grammar and
    end with an **abstract syntax tree** (**AST**), which will become the base for
    code generation. You can use this approach for every programming language for
    which you would like to implement a compiler.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的旅程将从定义我们的编程语言的语法开始，并以一个**抽象语法树**（**AST**）结束，它将成为代码生成的基石。你可以使用这种方法为任何你想要实现编译器的编程语言应用。
- en: 'In this chapter, you will learn about the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下内容：
- en: Defining a real programming language, where you will learn about the `tinylang`
    language, which is a subset of a real programming language, and for which you
    will implement a compiler frontend
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个真正的编程语言，你将学习关于`tinylang`语言的知识，它是真实编程语言的一个子集，并且你将为它实现编译器前端
- en: Organizing the directory structure of a compiler project
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织编译器项目的目录结构
- en: Knowing how to handle multiple input files for the compiler
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解如何处理编译器的多个输入文件
- en: The skill of handling user messages and informing them of issues in a pleasant
    manner
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理用户消息并以愉快的方式通知他们问题的技巧
- en: Building the lexer using modular pieces
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模块化组件构建词法分析器
- en: Constructing a recursive descent parser from the rules derived from a grammar
    to perform syntax analysis
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从语法规则中构建递归下降解析器以执行语法分析
- en: Performing semantic analysis by creating an AST and analyzing its characteristics
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过创建AST并分析其特征来执行语义分析
- en: With the skills you’ll acquire in this chapter, you’ll be able to build a compiler
    frontend for any programming language.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章你将获得的技能，你将能够为任何编程语言构建编译器前端。
- en: Defining a real programming language
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义一个真正的编程语言
- en: Real programming brings up more challenges than the simple calc language from
    the previous chapter. To have a look at the details, we will be using a tiny subset
    of *Modula-2* in this and the following chapters. Modula-2 is well-designed and
    optionally supports `tinylang`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 真实编程带来的挑战比上一章的简单calc语言要多。为了查看细节，我们将在这章和下一章中使用*Modula-2*的一个小子集。Modula-2设计良好，并可选择支持`tinylang`。
- en: 'Let’s begin with an example of what a program in `tinylang` looks like. The
    following function computes the greatest common divisor using the *Euclidean algorithm*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`tinylang`程序的一个例子开始。以下函数使用*欧几里得算法*计算最大公约数：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now that we have a feeling for how a program in the language looks, let’s take
    a quick tour of the `tinylang` subset’s grammar as used in this chapter. In the
    next few sections, we’ll use this grammar to derive the lexer and the parser from
    it:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对语言中的程序外观有了感觉，让我们快速浏览一下本章中使用的`tinylang`子集的语法。在接下来的几节中，我们将使用这个语法从中推导出词法分析和解析器：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A compilation unit in Modula-2 begins with the `MODULE` keyword, followed by
    the name of the module. The content of a module can have a list of imported modules,
    declarations, and a block containing statements that run at initialization time:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Modula-2的编译单元以`MODULE`关键字开始，后跟模块的名称。模块的内容可以有一个导入模块的列表、声明和一个包含初始化时运行的语句的块：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'A declaration introduces constants, variables, and procedures. The declaration
    of constants is prefixed with the `CONST` keyword. Similarly, variable declarations
    begin with the `VAR` keyword. The declaration of a constant is very simple:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 声明引入常量、变量和过程。常量的声明以`CONST`关键字为前缀。同样，变量声明以`VAR`关键字开始。常量的声明非常简单：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The identifier is the name of the constant. The value is derived from an expression,
    which must be computable at compile time. The declaration of variables is a bit
    more complex:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符是常量的名称。值是从一个表达式中派生的，该表达式必须在编译时可计算。变量的声明稍微复杂一些：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To be able to declare more than one variable in one go, a list of identifiers
    is used. The type name can potentially come from another module and is prefixed
    by the module name in this case. This is called a **qualified identifier**. A
    procedure requires the most details:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够一次声明多个变量，使用了一个标识符列表。类型名称可能来自另一个模块，在这种情况下，它以模块名称为前缀。这被称为 **有资格的标识符**。过程需要最详细的描述：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code shows how constants, variables, and procedures are declared.
    Procedures can have parameters and a return type. Normal parameters are passed
    as values, and `VAR` parameters are passed by reference. The other part missing
    from the `block` rule is `statementSequence`, which is a list of single statements:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码展示了如何声明常量、变量和过程。过程可以有参数和返回类型。正常参数按值传递，而 `VAR` 参数按引用传递。`block` 规则中缺少的另一部分是
    `statementSequence`，它是一系列单个语句：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A statement is delimited by a semicolon if it is followed by another statement.
    Again, only a subset of the *Modula-2* statements is supported:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个语句后面跟着另一个语句，则该语句由分号分隔。再次强调，仅支持 *Modula-2* 语句的一个子集：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first part of this rule describes an assignment or a procedure call. A
    qualified identifier followed by `:=` is an assignment. If it is followed by `(`,
    then it is a procedure call. The other statements are the usual control statements:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 该规则的第一部分描述了一个赋值或过程调用。一个有资格的标识符后跟 `:=` 是一个赋值。如果它后面跟着 `(`，则它是一个过程调用。其他语句是常见的控制语句：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `IF` statement also has a simplified syntax as it can only have a single
    `ELSE` block. With that statement, we can conditionally guard a statement:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`IF` 语句也有简化的语法，因为它只能有一个 `ELSE` 块。有了这个语句，我们可以有条件地保护一个语句：'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `WHILE` statement describes a loop that’s guarded by a condition. Together
    with the `IF` statement, this enables us to write simple algorithms in `tinylang`.
    Finally, the definition of an expression is missing:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`WHILE` 语句描述了一个由条件保护的循环。与 `IF` 语句一起，这使我们能够在 `tinylang` 中编写简单的算法。最后，缺少的是表达式的定义：'
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The expression syntax is very similar to that of calc in the previous chapter.
    Only the `INTEGER` and `BOOLEAN` data types are supported.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式语法与上一章中的 calc 非常相似。仅支持 `INTEGER` 和 `BOOLEAN` 数据类型。
- en: Additionally, the `identifier` and `integer_literal` tokens are used. An `H`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还使用了 `identifier` 和 `integer_literal` 标记。一个 `H`。
- en: These are already a lot of rules, and we’re only covering a part of Modula-2!
    Nevertheless, it is possible to write small applications in this subset. Let’s
    implement a compiler for `tinylang`!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规则已经很多了，而我们只覆盖了 Modula-2 的一部分！尽管如此，在这个子集中仍然可以编写小型应用程序。让我们来实现一个 `tinylang`
    编译器！
- en: Creating the project layout
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建项目布局
- en: The project layout for `tinylang` follows the approach we laid out in [*Chapter
    1*](B19561_01.xhtml#_idTextAnchor017), *Installing LLVM*. The source code for
    each component is in a subdirectory of the `lib` directory, and the header files
    are in a subdirectory of `include/tinylang`. The subdirectory is named after the
    component. In [*Chapter 1*](B19561_01.xhtml#_idTextAnchor017), *Installing LLVM*,
    we only created the `Basic` component.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`tinylang` 的项目布局遵循我们在 [*第一章*](B19561_01.xhtml#_idTextAnchor017) 中概述的方法，即 *安装
    LLVM*。每个组件的源代码位于 `lib` 目录的子目录中，头文件位于 `include/tinylang` 目录的子目录中。子目录以组件命名。在 [*第一章*](B19561_01.xhtml#_idTextAnchor017)
    中，*安装 LLVM*，我们只创建了 `Basic` 组件。'
- en: 'From the previous chapter, we know that we need to implement a lexer, a parser,
    an AST, and a semantic analyzer. Each is a component of its own, called `Lexer`,
    `Parser`, `AST`, and `Sema`, respectively. The directory layout that will be used
    in this chapter looks like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章，我们知道我们需要实现一个词法分析器、一个解析器、一个抽象语法树（AST）和一个语义分析器。每个都是其自身的组件，分别称为 `Lexer`、`Parser`、`AST`
    和 `Sema`。本章将使用的目录结构如下所示：
- en: '![Figure 3.1 – The directory layout of the tinylang project](img/B19561_03_1.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – `tinylang` 项目的目录结构](img/B19561_03_1.jpg)'
- en: Figure 3.1 – The directory layout of the tinylang project
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – `tinylang` 项目的目录结构
- en: The components have clearly defined dependencies. `Lexer` depends only on `Basic`.
    `Parser` depends on `Basic`, `Lexer`, `AST`, and `Sema`. `Sema` only depends on
    `Basic` and `AST`. The well-defined dependencies help us reuse the components.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 组件有明确定义的依赖关系。`Lexer` 只依赖于 `Basic`。`Parser` 依赖于 `Basic`、`Lexer`、`AST` 和 `Sema`。`Sema`
    只依赖于 `Basic` 和 `AST`。明确的依赖关系有助于我们重用组件。
- en: Let’s have a closer look at the implementation!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看实现过程！
- en: Managing the input files for the compiler
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理编译器的输入文件
- en: A real compiler has to deal with many files. Usually, the developer calls the
    compiler with the name of the main compilation unit. This compilation unit can
    refer to other files – for example, via `#include` directives in C or `import`
    statements in Python or Modula-2\. An imported module can import other modules,
    and so on. All these files must be loaded into memory and run through the analysis
    stages of the compiler. During development, a developer may make syntactical or
    semantical errors. When detected, an error message, including the source line
    and a marker, should be printed. This essential component is not trivial.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个真正的编译器必须处理许多文件。通常，开发者使用主编译单元的名称调用编译器。这个编译单元可以引用其他文件——例如，通过C中的`#include`指令或Python或Modula-2中的`import`语句。一个导入的模块可以导入其他模块，依此类推。所有这些文件都必须加载到内存中，并经过编译器的分析阶段。在开发过程中，开发者可能会犯语法或语义错误。当检测到错误时，应该打印出包括源行和标记的错误消息。这个基本组件并不简单。
- en: 'Luckily, LLVM comes with a solution: the `llvm::SourceMgr` class. A new source
    file is added to `SourceMgr` with a call to the `AddNewSourceBuffer()` method.
    Alternatively, a file can be loaded with a call to the `AddIncludeFile()` method.
    Both methods return an ID to identify the buffer. You can use this ID to retrieve
    a pointer to the memory buffer of the associated file. To define a location in
    the file, you can use the `llvm::SMLoc` class. This class encapsulates a pointer
    to the buffer. Various `PrintMessage()` methods allow you to emit errors and other
    informational messages to the user.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，LLVM提供了一个解决方案：`llvm::SourceMgr`类。通过调用`AddNewSourceBuffer()`方法，可以向`SourceMgr`添加一个新的源文件。或者，可以通过调用`AddIncludeFile()`方法来加载一个文件。这两种方法都返回一个ID来标识缓冲区。你可以使用这个ID来检索关联文件的内存缓冲区的指针。为了在文件中定义一个位置，你可以使用`llvm::SMLoc`类。这个类封装了一个指向缓冲区的指针。各种`PrintMessage()`方法允许你向用户发出错误和其他信息性消息。
- en: Handling messages for the user
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理用户消息
- en: Only a centralized definition of messages is missing. In a large piece of software
    (such as a compiler), you do not want to sprinkle message strings all over the
    place. If there is a request to change messages or translate them into another
    language, then you better have them in a central place!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 只缺少消息的集中定义。在一个大型软件（如编译器）中，你不想将消息字符串散布在各个地方。如果有更改消息或将其翻译成其他语言的需求，那么最好将它们放在一个中心位置！
- en: 'A simple approach is that each message has an ID (an `enum` member), a severity
    level such as `Error` or `Warning`, and a string containing the messages. In your
    code, you only refer to the message ID. The severity level and message string
    are only used when the message is printed. These three items (the ID, the security
    level, and the message) must be managed consistently. The LLVM libraries use the
    preprocessor to solve this. The data is stored in a file with the `.def` suffix
    and is wrapped in a macro name. That file is usually included several times, with
    different definitions for the macro. The definition is in the `include/tinylang/Basic/Diagnostic.def`
    file path and looks as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的方法是，每条消息都有一个ID（一个`enum`成员），一个严重程度级别，如`Error`或`Warning`，以及包含消息的字符串。在你的代码中，你只引用消息ID。严重程度级别和消息字符串仅在打印消息时使用。这三个项目（ID、安全级别和消息）必须一致管理。LLVM库使用预处理器来解决这个问题。数据存储在一个以`.def`后缀结尾的文件中，并包含在一个宏名称中。该文件通常被包含多次，宏有不同的定义。定义在`include/tinylang/Basic/Diagnostic.def`文件路径中，如下所示：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The first macro parameter, `ID`, is the enumeration label, the second parameter,
    `Level`, is the severity, and the third parameter, `Msg`, is the message text.
    With this definition at hand, we can define a `DiagnosticsEngine` class to emit
    error messages. The interface is in the `include/tinylang/Basic/Diagnostic.h`
    file:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个宏参数`ID`是枚举标签，第二个参数`Level`是严重程度，第三个参数`Msg`是消息文本。有了这个定义，我们可以定义一个`DiagnosticsEngine`类来发出错误消息。接口在`include/tinylang/Basic/Diagnostic.h`文件中：
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After including the necessary header files, `Diagnostic.def` can be used to
    define the enumeration. To not pollute the global namespace, a nested namespace
    called `diag` is used:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含必要的头文件后，可以使用`Diagnostic.def`来定义枚举。为了不污染全局命名空间，使用了一个名为`diag`的嵌套命名空间：
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `DiagnosticsEngine` class uses a `SourceMgr` instance to emit the messages
    via the `report()` method. Messages can have parameters. To implement this facility,
    the variadic-format support provided by LLVM is used. The message text and the
    severity level are retrieved with the help of the `static` method. As a bonus,
    the number of emitted error messages is also counted:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`DiagnosticsEngine` 类使用 `SourceMgr` 实例通过 `report()` 方法发出消息。消息可以有参数。为了实现这一功能，使用了
    LLVM 提供的变长格式支持。消息文本和严重程度级别通过 `static` 方法检索。作为额外的好处，发出的错误消息数量也被计数：'
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The message string is returned by `getDiagnosticText()`, while the level is
    returned by `getDiagnosticKind()`. Both methods are later implemented in the `.``cpp`
    file:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 消息字符串由 `getDiagnosticText()` 返回，而级别由 `getDiagnosticKind()` 返回。这两种方法稍后在 `.cpp`
    文件中实现：
- en: '[PRE15]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As messages can have a variable number of parameters, the solution in C++ is
    to use a variadic template. Of course, this is also used by the `formatv()` function
    provided by LLVM. To get the formatted message, we just need to forward the template
    parameters:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于消息可以有可变数量的参数，C++ 中的解决方案是使用变长模板。当然，这也被 LLVM 提供的 `formatv()` 函数所使用。要获取格式化的消息，我们只需要转发模板参数：
- en: '[PRE16]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'With that, we have implemented most of the class. Only `getDiagnosticText()`
    and `getDiagnosticKind()`are missing. They are defined in the `lib/Basic/Diagnostic.cpp`
    file and also make use of the `Diagnostic.def` file:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就实现了大多数类。只有 `getDiagnosticText()` 和 `getDiagnosticKind()` 还缺失。它们在 `lib/Basic/Diagnostic.cpp`
    文件中定义，并也使用了 `Diagnostic.def` 文件：
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As in the header file, the `DIAG` macro is defined to retrieve the desired
    part. Here, we define an array that holds the text messages. Therefore, the `DIAG`
    macro only returns the `Msg` part. We use the same approach for the level:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如同头文件中定义的那样，`DIAG` 宏被用来检索所需的部分。在这里，我们定义了一个数组来存储文本消息。因此，`DIAG` 宏只返回 `Msg` 部分。对于级别，我们采用相同的方法：
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Not surprisingly, both functions simply index the array to return the desired
    data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，这两个函数只是简单地索引数组以返回所需的数据：
- en: '[PRE19]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The combination of the `SourceMgr` and `DiagnosticsEngine` classes provides
    a good basis for the other components. We’ll use them in the lexer first!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`SourceMgr` 类和 `DiagnosticsEngine` 类的组合为其他组件提供了一个良好的基础。我们首先将在词法分析器中使用它们！'
- en: Structuring the lexer
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化词法分析器
- en: As we know from the previous chapter, we need a `Token` class and a `Lexer`
    class. Additionally, a `TokenKind` enumeration is required to give each token
    class a unique number. Having an all-in-one header and implementation file does
    not scale, so let’s move the items. `TokenKind` can be used universally and is
    placed in the `Basic` component. The `Token` and `Lexer` classes belong to the
    `Lexer` component but are placed in different headers and implementation files.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从上一章所知，我们需要一个 `Token` 类和一个 `Lexer` 类。此外，还需要一个 `TokenKind` 枚举来为每个令牌类分配一个唯一的数字。将所有内容放在一个头文件和实现文件中并不易于扩展，因此让我们移动这些项。`TokenKind`
    可以被普遍使用，并放置在 `Basic` 组件中。`Token` 和 `Lexer` 类属于 `Lexer` 组件，但被放置在不同的头文件和实现文件中。
- en: 'There are three different classes of tokens: `CONST` keyword, the`;` delimiter,
    and the `ident` token, respectively, each of which represents identifiers in the
    source. Each token needs a member name for the enumeration. Keywords and punctuators
    have natural display names that can be used for messages.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种不同的令牌类别：`CONST` 关键字、`;` 分隔符和 `ident` 令牌，分别代表源代码中的标识符。每个令牌需要一个枚举成员名称。关键字和标点符号有自然的显示名称，可以用于消息。
- en: Like in many programming languages, the keywords are a subset of the identifiers.
    To classify a token as a keyword, we need a keyword filter, which checks if the
    found identifier is indeed a keyword. This is the same behavior as in C or C++,
    where keywords are also a subset of identifiers. Programming languages evolve
    and new keywords may be introduced. As an example, the original K&R C language
    had no enumerations defined with the `enum` keyword. Due to this, a flag indicating
    the language level of a keyword should be present.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在许多编程语言中一样，关键字是标识符的一个子集。为了将令牌分类为关键字，我们需要一个关键字过滤器，该过滤器检查找到的标识符是否确实是关键字。这与 C
    或 C++ 中的行为相同，其中关键字也是标识符的一个子集。编程语言会不断发展，并且可能会引入新的关键字。例如，原始的 K&R C 语言没有使用 `enum`
    关键字定义枚举。因此，应该有一个标志来指示关键字的语言级别。
- en: 'We collected several pieces of information, all of which belong to a member
    of the `TokenKind` enumeration: the label for the enumeration member, the spelling
    of punctuators, and a flag for keywords. For the diagnostic messages, we centrally
    store the information in a `.def` file called `include/tinylang/Basic/TokenKinds.def`,
    which looks like this. One thing to note is that keywords are prefixed with `kw_`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了几个信息片段，所有这些信息都属于 `TokenKind` 枚举的一个成员：枚举成员的标签、运算符的拼写和关键字标志。对于诊断消息，我们集中存储信息在一个名为
    `include/tinylang/Basic/TokenKinds.def` 的 `.def` 文件中，其外观如下。需要注意的是，关键字前缀为 `kw_`：
- en: '[PRE20]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'With these centralized definitions, it’s easy to create the `TokenKind` enumeration
    in the `include/tinylang/Basic/TokenKinds.h` file. Again, the enumeration is put
    into its own namespace, `tok`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些集中定义，在 `include/tinylang/Basic/TokenKinds.h` 文件中创建 `TokenKind` 枚举变得容易。再次，枚举被放入其自己的命名空间
    `tok` 中：
- en: '[PRE21]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The pattern to fill the array should be familiar by now. The `TOK` macro is
    defined to only return `ID`. As a useful addition, we also define `NUM_TOKENS`
    as the last member of the enumeration, which denotes the number of defined tokens:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 填充数组的模式现在应该已经熟悉了。`TOK` 宏被定义为仅返回 `ID`。作为一个有用的补充，我们还定义了 `NUM_TOKENS` 作为枚举的最后一个成员，它表示定义的标记数量：
- en: '[PRE22]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The implementation file, `lib/Basic/TokenKinds.cpp`, also uses the `.def` file
    to retrieve the names:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实现文件 `lib/Basic/TokenKinds.cpp` 也使用 `.def` 文件来检索名称：
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The textual name of a token is derived from its enumeration label, `ID`. There
    are two particularities:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 标记的文本名称是从其枚举标签 `ID` 派生的。有两个特殊情况：
- en: First, we need to define the `TOK` and `KEYWORD` macros since the default definition
    of `KEYWORD` does not use the `TOK` macro
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们需要定义 `TOK` 和 `KEYWORD` 宏，因为 `KEYWORD` 的默认定义没有使用 `TOK` 宏
- en: 'Second, a `nullptr` value is added at the end of the array, accounting for
    the added `NUM_TOKENS` enumeration member:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二，在数组末尾添加了一个 `nullptr` 值，以考虑添加的 `NUM_TOKENS` 枚举成员：
- en: '[PRE24]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We take a slightly different approach in the `getPunctuatorSpelling()` and
    `getKeywordSpelling()` functions. These functions only return a meaningful value
    for a subset of the enumeration. This can be realized with a `switch` statement,
    returning a `nullptr` value by default:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `getPunctuatorSpelling()` 和 `getKeywordSpelling()` 函数中，我们采取了稍微不同的方法。这些函数只为枚举的子集返回有意义的值。这可以通过
    `switch` 语句实现，默认返回 `nullptr` 值：
- en: '[PRE25]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Tip
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Note how the macros are defined to retrieve the necessary piece of information
    from the file.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意宏是如何定义的，以从文件中检索必要的信息。
- en: 'In the previous chapter, the `Token` class was declared in the same header
    file as the `Lexer` class. To make this more versatile, we will put the `Token`
    class into its own header file in `include/Lexer/Token.h`. As before, `Token`
    stores a pointer to the start of the token, its length, and the token kind, as
    defined previously:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，`Token` 类与 `Lexer` 类在同一个头文件中声明。为了使其更灵活，我们将 `Token` 类放入其自己的头文件 `include/Lexer/Token.h`
    中。像以前一样，`Token` 存储标记开始的指针、其长度和标记类型，如之前定义的：
- en: '[PRE26]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `SMLoc` instance, which denotes the source position in messages, is created
    from the pointer to the token:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表示消息中源位置的 `SMLoc` 实例是从标记的指针创建的：
- en: '[PRE27]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `getIdentifier()` and `getLiteralData()` methods allow access to the text
    of the token for identifiers and literal data. It is not necessary to access the
    text for any other token type as this is implied by the token type:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`getIdentifier()` 和 `getLiteralData()` 方法允许访问标识符和字面数据的标记文本。对于任何其他标记类型，没有必要访问文本，因为这由标记类型隐含：'
- en: '[PRE28]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We declare the `Lexer` class in the `include/Lexer/Lexer.h` header file and
    put the implementation in the `lib/Lexer/lexer.cpp` file. The structure is the
    same as for the calc language from the previous chapter. We need to take a closer
    look at two details here:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `include/Lexer/Lexer.h` 头文件中声明了 `Lexer` 类，并将实现放在 `lib/Lexer/lexer.cpp` 文件中。结构与上一章的
    calc 语言相同。在这里，我们需要仔细查看两个细节：
- en: 'First, some operators share the same prefix – for example, `<` and `<=`. When
    the current character we look at is `<`, then we must check the next character
    before deciding which token we found. Remember that the input needs to end with
    a null byte. Therefore, the next character can always be used if the current character
    is valid:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，一些运算符具有相同的词缀 – 例如，`<` 和 `<=`。当我们查看当前字符时，如果它是 `<`，那么我们必须在决定我们找到了哪个标记之前检查下一个字符。记住，输入需要以空字节结束。因此，如果当前字符有效，则下一个字符总是可以使用的：
- en: '[PRE29]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The other detail is that there are far more keywords now. How can we handle
    this? A simple and fast solution is to populate a hash table with the keywords,
    which are all stored in the `TokenKinds.def` file. This can be done during the
    instantiation of the `Lexer` class. With this approach, it is also possible to
    support different levels of the language as the keywords can be filtered with
    the attached flag. Here, this flexibility is not needed yet. In the header file,
    the keyword filter is defined as follows, using an instance of `llvm::StringMap`
    for the hash table:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个细节是现在有更多的关键字。我们该如何处理这个问题呢？一个简单快捷的解决方案是将关键字填充到一个散列表中，这些关键字都存储在`TokenKinds.def`文件中。这可以在`Lexer`类的实例化过程中完成。采用这种方法，也可以支持语言的不同级别，因为关键字可以通过附加的标志进行过滤。在这里，这种灵活性还不是必需的。在头文件中，关键字过滤器定义如下，使用`llvm::StringMap`实例作为散列表：
- en: '[PRE30]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `getKeyword()` method returns the token kind of the given string, or a
    default value if the string does not represent a keyword:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`getKeyword()`方法返回给定字符串的标记类型，或者如果字符串不表示关键字则返回默认值：'
- en: '[PRE31]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In the implementation file, the keyword table is filled:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在实现文件中，填充关键字表：
- en: '[PRE32]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: With the techniques you’ve just learned about, it’s not difficult to write an
    efficient lexer class. As compilation speed matters, many compilers use a handwritten
    lexer, with one example being clang.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过你刚刚学到的技术，编写一个高效的词法分析器类并不困难。由于编译速度很重要，许多编译器使用手写的词法分析器，其中一个是clang。
- en: Constructing a recursive descent parser
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建递归下降解析器。
- en: 'As shown in the previous chapter, the parser is derived from the grammar. Let’s
    recall all the *construction rules*. For each rule of the grammar, you create
    a method named after the non-terminal on the left-hand side of the rule to parse
    the right-hand side of the rule. Following the definition of the right-hand side,
    you do the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所示，解析器是从语法派生出来的。让我们回顾一下所有的*构建规则*。对于语法的每个规则，你创建一个以规则左侧的非终结符命名的方法来解析规则的右侧。遵循右侧的定义，你做以下操作：
- en: For each non-terminal, the corresponding method is called
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个非终结符，调用相应的对应方法。
- en: Each token is consumed
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个标记都被消耗。
- en: For alternatives and optional or repeating groups, the look-ahead token (the
    next unconsumed token) is examined to decide where to continue
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于可选或重复的组，通过查看前瞻标记（下一个未消耗的标记）来决定继续的位置。
- en: 'Let’s apply these construction rules to the following rule of grammar:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些构建规则应用到以下语法规则中：
- en: '[PRE33]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can easily translate this into the following C++ method:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地将它转换为以下C++方法：
- en: '[PRE34]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The whole grammar of `tinylang` can be turned into C++ in this way. In general,
    you have to be careful to avoid some pitfalls since most grammars that you will
    find on the internet are not suitable for this kind of construction.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将`tinylang`的整个语法以这种方式转换为C++。一般来说，你必须小心避免一些陷阱，因为你在互联网上找到的大多数语法都不适合这种构建。
- en: Grammars and parsers
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 语法和解析器。
- en: 'There are two different types of parsers: top-down parsers and bottom-up parsers.
    Their names are derived from the order in which a rule is handled during parsing.
    The input for a parser is the sequence of tokens generated by the lexer.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种不同的解析器类型：自顶向下的解析器和自底向上的解析器。它们的名称来源于解析过程中处理规则顺序。解析器的输入是由词法分析器生成的标记序列。
- en: A top-down parser expands the leftmost symbol in a rule until a token is matched.
    Parsing is successful if all tokens are consumed and all symbols are expanded.
    This is exactly how the parser for tinylang works.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 自顶向下的解析器会扩展规则中的最左边的符号，直到匹配到一个标记。如果所有标记都被消耗并且所有符号都被扩展，解析就成功了。这正是tinylang解析器的工作方式。
- en: 'A bottom-up parser does the opposite: it looks at the sequence of tokens and
    tries to replace the tokens with a symbol of the grammar. For example, if the
    next tokens are `IF`, `3`, `+`, and `4`, then a bottom-up parser replaces the
    `3 + 4` token with the `expression` symbol, resulting in the `IF` `expression`
    sequence. When all tokens that belong to the `IF` statement are seen, then this
    sequence of tokens and symbols is replaced by the `ifStatement` symbol.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 自底向上的解析器做的是相反的事情：它查看标记序列，并尝试用语法的符号替换标记。例如，如果下一个标记是`IF`、`3`、`+`和`4`，那么自底向上的解析器将`3
    + 4`标记替换为`expression`符号，从而得到`IF` `expression`序列。当看到属于`IF`语句的所有标记时，这个标记和符号序列就被替换为`ifStatement`符号。
- en: The parsing is successful if all tokens are consumed and the only symbol left
    is the start symbol. While top-down parsers can easily be constructed by hand,
    this is not the case for bottom-up parsers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 解析成功是指所有标记都被消耗，并且剩下的唯一符号是起始符号。虽然自顶向下解析器可以很容易地手工构建，但对于自底向上解析器来说并非如此。
- en: A different way to characterize both types of parsers is by which symbols are
    expanded first. Both read the input from left to right, but a top-down parser
    expands the leftmost symbol first while a bottom-up parser expands the rightmost
    symbol. Because of this, a top-down parser is also called an LL parser, while
    a bottom-up parser is called an LR parser.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通过首先扩展哪些符号来描述这两种类型的解析器是另一种方法。两者都是从左到右读取输入，但自顶向下解析器首先扩展最左边的符号，而自底向上解析器首先扩展最右边的符号。因此，自顶向下解析器也被称为
    LL 解析器，而自底向上解析器被称为 LR 解析器。
- en: 'A grammar must have certain properties so that either an LL or an LR parser
    can be derived from it. The grammars are named accordingly: you need an LL grammar
    to construct an LL parser.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 语法必须具有某些属性，以便从中导出 LL 或 LR 解析器。这些语法相应地命名：你需要一个 LL 语法来构建一个 LL 解析器。
- en: 'You can find more details in university textbooks about compiler construction,
    such as Wilhelm, Seidl, and Hack: *Compiler Design. Syntactic and Semantic Analysis*,
    Springer 2013, and Grune and Jacobs: *Parsing Techniques, A practical guide*,
    Springer 2008.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在关于编译器构造的大学教科书中找到更多详细信息，例如 Wilhelm, Seidl, 和 Hack 的 *Compiler Design. Syntactic
    and Semantic Analysis*，Springer 2013，以及 Grune 和 Jacobs 的 *Parsing Techniques,
    A practical guide*，Springer 2008。
- en: 'One issue to look for is left-recursive rules. A rule is called **left-recursive**
    if the right-hand side begins with the same terminal that’s on the left-hand side.
    A typical example can be found in grammars for expressions:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要关注的问题是左递归规则。如果一个规则的右侧以左侧相同的终结符开始，则该规则被称为**左递归**。一个典型的例子可以在表达式语法中找到：
- en: '[PRE35]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'If it’s not already clear from the grammar, then the translation to C++ makes
    it obvious that this results in infinite recursion:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果语法本身没有明确，那么将其翻译成 C++ 就会使这种无限递归的结果变得明显：
- en: '[PRE36]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Left recursion can also occur indirectly and involve more rules, which is much
    more difficult to spot. That’s why an algorithm exists that can detect and eliminate
    left recursion.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 左递归也可以间接发生并涉及更多规则，这要难于发现得多。这就是为什么存在一个算法可以检测并消除左递归。
- en: Note
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Left-recursive rules are only a problem for LL parsers, such as the recursive-descent
    parser for `tinylang`. The reason is that these parsers expand the leftmost symbol
    first. In contrast, if you use a parser generator to generate an LR parser, which
    expands the rightmost symbol first, then you should avoid right-recursive rules.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 左递归规则仅是 LL 解析器的问题，例如 `tinylang` 的递归下降解析器。原因是这些解析器首先扩展最左边的符号。相比之下，如果你使用解析器生成器生成一个
    LR 解析器，它首先扩展最右边的符号，那么你应该避免右递归规则。
- en: 'At each step, the parser decides how to continue by just using the look-ahead
    token. The grammar is said to have conflicts if this decision cannot be made deterministically.
    To illustrate this, have a look at the `using` statement in C#. Like in C++, the
    `using` statement can be used to make a symbol visible in a namespace, such as
    in `using Math;`. It is also possible to define an alias name for the imported
    symbol with `using M = Math;`. In a grammar, this can be expressed as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步中，解析器通过仅使用前瞻标记来决定如何继续。如果这个决定不能确定性地做出，则语法存在冲突。为了说明这一点，看看 C# 中的 `using` 语句。像
    C++ 一样，`using` 语句可以用来在命名空间中使一个符号可见，例如在 `using Math;` 中。也可以使用 `using M = Math;`
    定义导入符号的别名。在语法中，这可以表示如下：
- en: '[PRE37]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'There’s a problem here: after the parser consumes the `using` keyword, the
    look-ahead token is `ident`. However, this information is not enough for us to
    decide if the optional group must be skipped or parsed. This situation always
    arises if the set of tokens, with which the optional group can begin, overlaps
    with the set of tokens that follow the optional group.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个问题：在解析器消耗了 `using` 关键字之后，前瞻标记是 `ident`。然而，这些信息不足以让我们决定是否必须跳过或解析可选组。如果可选组可以开始的标记集与可选组后面的标记集重叠，这种情况总会出现。
- en: 'Let’s rewrite the rule with an alternative instead of an optional group:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用备选方案而不是可选组重写规则：
- en: '[PRE38]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, there is a different conflict: both alternatives begin with the same token.
    Looking only at the look-ahead token, the parser can’t decide which of the alternatives
    is the right one.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，存在一个不同的冲突：两个备选方案以相同的标记开始。仅从前瞻标记来看，解析器无法决定哪个备选方案是正确的。
- en: 'These conflicts are very common. Therefore, it’s good to know how to handle
    them. One approach is to rewrite the grammar in such a way that the conflict disappears.
    In the previous example, both alternatives begin with the same token. This can
    be factored out, resulting in the following rule:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这些冲突非常常见。因此，了解如何处理它们是很好的。一种方法是将语法重写，使得冲突消失。在先前的例子中，两种选择都以相同的令牌开始。这可以被提取出来，得到以下规则：
- en: '[PRE39]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This formulation has no conflict, but it should also be noted that it is less
    expressive. In the two other formulations, it is obvious which `ident` is the
    alias name and which `ident` is the namespace name. In the conflict-free rule,
    the leftmost `ident` changes its role. First, it is the namespace name, but if
    an equals sign follows, then it turns into the alias name.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表述没有冲突，但应该注意的是，它表达性较差。在另外两种表述中，很明显哪个`ident`是别名，哪个`ident`是命名空间名。在无冲突的规则中，最左边的`ident`改变其角色。首先，它是命名空间名，但如果后面跟着一个等号，那么它就变成了别名。
- en: 'The second approach is to add a predicate to distinguish between both cases.
    This predicate, often called a `Token &peek(int n)` that returns the *n*th token
    after the current look-ahead token. Here, the existence of an equals sign can
    be used as an additional predicate in the decision:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是添加一个谓词来区分这两种情况。这个谓词通常被称为`Token &peek(int n)`，它返回当前前瞻令牌之后的第*n*个令牌。在这里，等号的存在可以用作决策中的附加谓词：
- en: '[PRE40]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: A third approach is to use backtracking. For this, you need to save the current
    state. Then, you must try to parse the conflicting group. If this does not succeed,
    then you need to go back to the saved state and try the other path. Here, you
    are searching for the correct rule to apply, which is not as efficient as the
    other methods. Therefore, you should only use this approach as a last resort.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法是使用回溯。为此，你需要保存当前状态。然后，你必须尝试解析冲突组。如果这没有成功，那么你需要回到保存的状态并尝试其他路径。在这里，你正在寻找可以应用的正确规则，这不如其他方法高效。因此，你应该只将这种方法作为最后的手段。
- en: Now, let’s incorporate error recovery. In the previous chapter, I introduced
    the so-called *panic mode* as a technique for error recovery. The basic idea is
    to skip tokens until one is found that is suitable for continuing parsing. For
    example, in `tinylang`, a statement is followed by a semicolon (`:`).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们结合错误恢复。在上一章中，我介绍了所谓的*恐慌模式*作为错误恢复的技术。基本思想是跳过令牌，直到找到一个适合继续解析的令牌。例如，在`tinylang`中，一个语句后面跟着一个分号（`;`）。
- en: If there is a syntax problem in an `IF` statement, then you skip all tokens
    until you find a semicolon. Then, you continue with the next statement. Instead
    of using an ad hoc definition for the token set, it’s better to use a systematic
    approach.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`IF`语句中存在语法问题，那么你会跳过所有令牌，直到找到一个分号。然后，你继续执行下一个语句。而不是使用针对令牌集的特定定义，使用系统性的方法会更好。
- en: For each non-terminal, you compute the set of tokens that can follow the non-terminal
    anywhere (called the `;`, `ELSE`, and `END` tokens can follow. So, you must use
    this set in the error recovery part of `parseStatement()`. This method assumes
    that a syntax error can be handled locally. In general, this is not possible.
    Because the parser skips tokens, so many could be skipped that the end of input
    is reached. At this point, local recovery is not possible.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个非终结符，你计算可以跟随非终结符的令牌集合（称为`;`、`ELSE`和`END`令牌可以跟随。因此，你必须在`parseStatement()`的错误恢复部分使用这个集合。这种方法假设语法错误可以在本地处理。通常情况下，这是不可能的。因为解析器会跳过令牌，所以可能会跳过很多令牌，直到达到输入的末尾。在这个点上，局部恢复是不可能的。
- en: To prevent meaningless error messages, the calling method needs to be informed
    that an error recovery is still not finished. This can be done with `bool`. If
    it returns `true`, this means that error recovery hasn’t finished yet, while `false`
    means that parsing (including a possible error recovery) was successful.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止出现无意义的错误信息，调用方法需要被告知错误恢复尚未完成。这可以通过`bool`来实现。如果它返回`true`，这意味着错误恢复尚未完成，而`false`表示解析（包括可能的错误恢复）已成功。
- en: There are numerous ways to extend this error recovery scheme. Using the `FOLLOW`
    sets of active callers is a popular approach. As a simple example, assume that
    `parseStatement()` was called by `parseStatementSequence()`, which was itself
    called by `parseBlock()` and that from `parseModule()`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以扩展这个错误恢复方案。使用活动调用者的`FOLLOW`集合是一种流行的方法。作为一个简单的例子，假设`parseStatement()`被`parseStatementSequence()`调用，而`parseStatementSequence()`本身又被`parseBlock()`和`parseModule()`调用。
- en: Here, each of the corresponding non-terminals has a `FOLLOW` set. If the parser
    detects a syntax error in `parseStatement()`, then tokens are skipped until the
    token is in at least one of the `FOLLOW` sets of the active callers. If the token
    is in the `FOLLOW` set of the statement, then the error was recovered locally
    and a `false` value is returned to the caller. Otherwise, a `true` value is returned,
    meaning that error recovery must continue. A possible implementation strategy
    for this extension is passing `std::bitset` or `std::tuple` to represent the union
    of the current `FOLLOW` sets to the callee.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个相应的非终结符都有一个`FOLLOW`集合。如果解析器在`parseStatement()`中检测到语法错误，则跳过标记直到标记至少属于活动调用者的一个`FOLLOW`集合。如果标记在语句的`FOLLOW`集合中，则错误被局部恢复，并返回一个`false`值给调用者。否则，返回一个`true`值，意味着错误恢复必须继续。为此扩展的一个可能的实现策略是将`std::bitset`或`std::tuple`传递给被调用者，以表示当前`FOLLOW`集合的并集。
- en: 'One last question is still open: how can we call the error recovery? In the
    previous chapter, `goto` was used to jump to the error recovery block. This works
    but is not a pleasing solution. Given what we discussed earlier, we can skip tokens
    in a separate method. Clang has a method has `skipUntil()` for this purpose; we
    also use this for `tinylang`.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个问题仍然悬而未决：我们如何调用错误恢复？在前一章中，使用了`goto`跳转到错误恢复块。这虽然可行，但不是一个令人满意的解决方案。根据我们之前讨论的内容，我们可以通过一个单独的方法跳过标记。Clang有一个名为`skipUntil()`的方法用于此目的；我们也为`tinylang`使用了这个方法。
- en: 'Because the next step is to add semantic actions to the parser, it would also
    be nice to have a central place to put cleanup code if necessary. A nested function
    would be ideal for this. C++ does not have a nested function. Instead, a Lambda
    function can serve a similar purpose. The `parseIfStatement()` method, which we
    looked at initially, looks as follows when the complete error recovery code is
    added:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 因为下一步是向解析器添加语义动作，所以如果需要的话，有一个中央位置来放置清理代码也会很方便。嵌套函数对于这个目的来说非常理想。C++没有嵌套函数。相反，Lambda函数可以起到类似的作用。当我们最初查看`parseIfStatement()`方法时，添加了完整的错误恢复代码后，它看起来如下所示：
- en: '[PRE41]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Parser and lexer generators
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器和词法分析器生成器
- en: Manually constructing a parser and a lexer can be a tedious task, especially
    if you try to invent a new programming language and change the grammar very often.
    Luckily, some tools automate this task.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 手动构建解析器和词法分析器可能是一项繁琐的任务，尤其是当你试图发明一种新的编程语言并且经常更改语法时。幸运的是，一些工具可以自动化这项任务。
- en: The classic Linux tools are **flex** ([https://github.com/westes/flex](https://github.com/westes/flex))
    and **bison** ([https://www.gnu.org/software/bison/](https://www.gnu.org/software/bison/)).
    flex generates a lexer from a set of regular expressions, while bison generates
    an **LALR(1)** parser from a grammar description. Both tools generate C/C+ source
    code and can be used together.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的Linux工具是**flex**（[https://github.com/westes/flex](https://github.com/westes/flex)）和**bison**（[https://www.gnu.org/software/bison/](https://www.gnu.org/software/bison/)）。flex从一组正则表达式生成词法分析器，而bison从语法描述生成**LALR(1)**解析器。这两个工具都生成C/C+源代码，并且可以一起使用。
- en: Another popular tool is **AntLR** (https://www.antlr.org/). AntLR can generate
    a lexer, a parser, and an AST from a grammar description. The generated parser
    belongs to the **LL(*)** class, which means it is a top-down parser that uses
    a variable number of lookaheads to solve conflicts. The tool is written in Java
    but can generate source code for many popular languages, including C/C++.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个流行的工具是**AntLR**（https://www.antlr.org/）。AntLR可以从语法描述中生成一个词法分析器、一个解析器和AST。生成的解析器属于**LL(*)**类别，这意味着它是一个自顶向下的解析器，使用可变数量的前瞻来解决冲突。这个工具是用Java编写的，但可以生成许多流行语言的源代码，包括C/C++。
- en: All these tools require some library support. If you are looking for a tool
    that generates a self-contained lexer and parser, then **Coco/R** ([https://ssw.jku.at/Research/Projects/Coco/](https://ssw.jku.at/Research/Projects/Coco/))
    may be the tool for you. Coco/R generates a lexer and a recursive-descent parser
    from an **LL(1)** grammar description, similar to the one used in this book. The
    generated files are based on a template file that you can change if needed. The
    tool is written in C# but ports to C++, Java, and other languages.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些工具都需要一些库支持。如果你正在寻找一个可以生成自包含的词法分析器和解析器的工具，那么**Coco/R**（[https://ssw.jku.at/Research/Projects/Coco/](https://ssw.jku.at/Research/Projects/Coco/))可能就是你要找的工具。Coco/R可以从**LL(1)**语法描述生成一个词法分析器和递归下降解析器，类似于本书中使用的那个。生成的文件基于一个模板文件，如果需要可以更改。这个工具是用C#编写的，但可以移植到C++、Java和其他语言。
- en: There are many other tools available, and they vary a lot in terms of the features
    and output languages they support. Of course, when choosing a tool, there are
    also trade-offs to consider. An LALR(1) parser generator such as bison can consume
    a wide range of grammars, and free grammars you can find on the internet are often
    LALR(1) grammars.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多其他工具可供选择，它们在支持的特性和输出语言方面差异很大。当然，在选择工具时，也需要考虑权衡。例如，bison这样的LALR(1)解析器生成器可以消费广泛的语法，你可以在互联网上找到的免费语法通常都是LALR(1)语法。
- en: As a downside, these generators generate a state machine that needs to be interpreted
    at runtime, which can be slower than a recursive descent parser. Error handling
    is also more complicated. bison has basic support for handling syntax errors,
    but the correct use requires a deep understanding of how the parser works. Compared
    to this, AntLR consumes a slightly smaller grammar class but automatically generates
    error handling, and can also generate an AST. So, rewriting grammar so that it
    can be used with AntLR may speed up development later.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 作为缺点，这些生成器生成的状态机需要在运行时进行解释，这可能会比递归下降解析器慢。错误处理也更复杂。bison有处理语法错误的基本支持，但正确使用需要深入理解解析器的工作原理。相比之下，AntLR消耗的语法类略小，但可以自动生成错误处理，还可以生成AST。因此，重写语法以便与AntLR一起使用可能会加快后续的开发速度。
- en: Performing semantic analysis
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行语义分析
- en: The parser we constructed in the previous section only checks the syntax of
    the input. The next step is to add the ability to perform semantic analysis. In
    the calc example in the previous chapter, the parser constructed an AST. In a
    separate phase, the semantic analyzer worked on this tree. This approach can always
    be used. In this section, we will use a slightly different approach and intertwine
    the parser and the semantic analyzer more.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中构建的解析器只检查输入的语法。下一步是添加执行语义分析的能力。在上一章的calc示例中，解析器构建了一个AST。在单独的阶段，语义分析器处理这个树。这种方法始终可以使用。在本节中，我们将使用一种稍微不同的方法，并将解析器和语义分析器更紧密地交织在一起。
- en: 'What does the semantic analyzer need to do? Let’s take a look:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分析器需要做什么？让我们先看看：
- en: For each declaration, the names of variables, objects, and more must be checked
    to ensure they have not been declared elsewhere.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每一次声明，必须检查变量、对象等的名称，以确保它们没有在其他地方声明过。
- en: For each occurrence of a name in an expression or statement, it must be checked
    that the name is declared and that the desired use fits the declaration.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于表达式或语句中名称的每一次出现，都必须检查该名称是否已声明，以及所需的使用是否符合声明。
- en: For each expression, the resulting type must be computed. It is also necessary
    to compute if the expression is constant and if so, which value it has.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个表达式，必须计算其结果类型。还必须计算表达式是否为常量，如果是，它具有哪个值。
- en: For assignment and parameter passing, we must check that the types are compatible.
    Further, we must check that the conditions in `IF` and `WHILE` statements are
    of the `BOOLEAN` type.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于赋值和参数传递，我们必须检查类型是否兼容。此外，我们还必须检查`IF`和`WHILE`语句中的条件是否为`BOOLEAN`类型。
- en: That’s already a lot to check for such a small subset of a programming language!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这样一个小子集的编程语言来说，已经有很多需要检查的内容了！
- en: Handling the scope of names
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理名称的作用域
- en: 'Let’s have a look at the scope of names first. The scope of a name is the range
    where the name is visible. Like C, `tinylang` uses a declare-before-use model.
    For example, the `B` and `X` variables are declared at the module level to be
    of the `INTEGER` type:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 首先看看名称的作用域。名称的作用域是名称可见的范围。像C语言一样，`tinylang`使用声明先于使用模型。例如，`B`和`X`变量在模块级别声明为`INTEGER`类型：
- en: '[PRE42]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Before the declaration, the variables are not known and cannot be used. That’s
    only possible after the declaration. Inside a procedure, more variables can be
    declared:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在声明之前，变量是未知的，不能使用。只有在声明之后才能这样做。在过程内部，可以声明更多变量：
- en: '[PRE43]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Inside the procedure, at the point where the comment is, a use of `B` refers
    to the `B` local variable while a use of `X` refers to the `X` global variable.
    The scope of the local variable, `B`, is `Proc`. If a name cannot be found in
    the current scope, then the search continues in the enclosing scope. Therefore,
    the `X` variable can be used inside the procedure. In `tinylang`, only modules
    and procedures open a new scope. Other language constructs, such as structs and
    classes, usually also open a scope. Predefined entities such as the `INTEGER`
    type and the `TRUE` literal are declared in a global scope, enclosing the scope
    of the module.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在程序内部，在注释所在的位置，对`B`的使用指的是局部变量`B`，而对`X`的使用指的是全局变量`X`。局部变量`B`的作用域是`Proc`。如果当前作用域中找不到名称，则搜索将继续在封装作用域中进行。因此，可以在程序内部使用`X`变量。在`tinylang`中，只有模块和程序会打开新的作用域。其他语言结构，如结构体和类，通常也会打开作用域。预定义实体，如`INTEGER`类型和`TRUE`字面量，是在全局作用域中声明的，包围着模块的作用域。
- en: 'In `tinylang`, only the name is crucial. Therefore, a scope can be implemented
    as a mapping from a name to its declaration. A new name can only be inserted if
    it is not already present. For the lookup, the enclosing or parent scope must
    also be known. The interface (in the `include/tinylang/Sema/Scope.h` file) looks
    as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在`tinylang`中，只有名称是关键的。因此，作用域可以作为一个从名称到其声明的映射来实现。只有当新名称不存在时，才能插入新名称。对于查找，还必须知道封装或父作用域。接口（在`include/tinylang/Sema/Scope.h`文件中）如下所示：
- en: '[PRE44]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The implementation in the `lib/Sema/Scope.cpp` file looks as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`lib/Sema/Scope.cpp`文件中的实现如下：'
- en: '[PRE45]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Please note that the `StringMap::insert()` method does not override an existing
    entry. The `second` member of the resulting `std::pair` indicates if the table
    was updated. This information is returned to the caller.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`StringMap::insert()`方法不会覆盖现有条目。结果`std::pair`的`second`成员指示是否更新了表。此信息返回给调用者。
- en: 'To implement the search for the declaration of a symbol, the `lookup()` method
    searches in the current scope and, if nothing is found, searches the scopes linked
    by the `parent` member:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现符号声明的搜索，`lookup()`方法在当前作用域中搜索，如果没有找到，则搜索通过`parent`成员链接的作用域：
- en: '[PRE46]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The variable declaration is then processed as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 然后按照以下方式处理变量声明：
- en: The current scope is the module scope.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前作用域是模块作用域。
- en: The `INTEGER` type declaration is looked up. It’s an error if no declaration
    is found or if it is not a type declaration.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找`INTEGER`类型声明。如果没有找到声明或它不是一个类型声明，则这是一个错误。
- en: A new AST node called `VariableDeclaration` is instantiated, with the important
    attributes being the name, `B`, and the type.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例化一个新的AST节点，名为`VariableDeclaration`，其中重要的属性是名称`B`和类型。
- en: The name, `B`, is inserted into the current scope, mapping to the declaration
    instance. If the name is already present in the scope, then this is an error.
    The content of the current scope is not changed in this case.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将名称`B`插入到当前作用域中，映射到声明实例。如果该名称已经在作用域中，则这是一个错误。在这种情况下，当前作用域的内容不会改变。
- en: The same is done for the `X` variable.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`X`变量也执行同样的操作。
- en: Two tasks are performed here. As in the calc example, AST nodes are constructed.
    At the same time, attributes of the node, such as the type, are computed. Why
    is this possible?
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这里执行了两个任务。与calc示例一样，构建了AST节点。同时，计算了节点的属性，如类型。为什么这是可能的？
- en: The semantic analyzer can fall back on two different sets of attributes. The
    scope is inherited from the caller. The type declaration can be computed (or synthesized)
    by evaluating the name of the type declaration. The language is designed in such
    a way that these two sets of attributes are sufficient to compute all attributes
    of the AST node.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分析器可以回退到两组不同的属性集。作用域是从调用者继承的。类型声明可以通过评估类型声明的名称来计算（或合成）。语言被设计成这样的方式，这两组属性足以计算AST节点的所有属性。
- en: An important aspect is the *declare-before-use* model. If a language allows
    the use of names before declaration, such as members inside a class in C++, then
    it is not possible to compute all attributes of an AST node at once. In such a
    case, the AST node must be constructed with only partially computed attributes
    or just with plain information (such as in the calc example).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的方面是*声明先于使用*模型。如果一个语言允许在声明之前使用名称，例如C++中的类成员，那么就无法一次性计算AST节点的所有属性。在这种情况下，必须使用仅部分计算属性或仅使用普通信息（如calc示例）来构建AST节点。
- en: The AST must then be visited one or more times to determine the missing information.
    In the case of `tinylang` (and Modula-2), it would be possible to dispense with
    the AST construction – the AST is indirectly represented through the call hierarchy
    of the `parseXXX()` methods. Code generation from an AST is much more common,
    so we construct an AST here, too.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，AST必须被访问一次或多次以确定缺失的信息。在`tinylang`（和Modula-2）的情况下，可能不需要AST构造——AST是通过`parseXXX()`方法的调用层次间接表示的。从AST生成代码更为常见，所以我们在这里也构建了一个AST。
- en: Before we put the pieces together, we need to understand the LLVM style of using
    **runtime type** **information** (**RTTI**).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将这些部分组合在一起之前，我们需要了解LLVM使用**运行时类型信息**（**RTTI**）的风格。
- en: Using an LLVM-style RTTI for the AST
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LLVM风格的RTTI对AST进行操作
- en: Naturally, the AST nodes are a part of a class hierarchy. A declaration always
    has a name. Other attributes depend on what is being declared. If a variable is
    declared, then a type is required. A constant declaration needs a type, a value,
    and so on. Of course, at runtime, you need to find out which kind of declaration
    you are working with. The `dynamic_cast<>` C++ operator could be used for this.
    The problem is that the required RTTI is only available if the C++ class has a
    virtual table attached – that is, it uses virtual functions. Another disadvantage
    is that C++ RTTI is bloated. To avoid these disadvantages, the LLVM developers
    introduced a self-made RTTI style, which is used throughout the LLVM libraries.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，AST节点是类层次结构的一部分。声明总是有一个名称。其他属性取决于正在声明的对象。如果一个变量被声明，则需要一个类型。常量声明需要一个类型、一个值等等。当然，在运行时，你需要找出你正在处理哪种类型的声明。可以使用`dynamic_cast<>`
    C++运算符来完成这个任务。问题是，所需的RTTI仅在C++类附加了虚拟表时才可用——也就是说，它使用了虚拟函数。另一个缺点是C++ RTTI很庞大。为了避免这些缺点，LLVM开发者引入了一种自制的RTTI风格，该风格被用于整个LLVM库中。
- en: 'The (abstract) base class of our hierarchy is `Decl`. To implement the LLVM-style
    RTTI, a public enumeration containing a label for each subclass must be added.
    Also, a private member of this type and a public getter are required. The private
    member is usually called `Kind`. In our case, this looks as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们层次结构的（抽象）基类是`Decl`。为了实现LLVM风格的RTTI，必须添加一个包含每个子类标签的公共枚举。还需要这个类型的私有成员和一个公共获取器。私有成员通常称为`Kind`。在我们的情况下，它看起来如下：
- en: '[PRE47]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Each subclass now needs a special function member called `classof`. The purpose
    of this function is to determine if a given instance is of the requested type.
    For `VariableDeclaration`, it is implemented as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 每个子类现在需要一个特殊的功能成员，称为`classof`。这个函数的目的是确定给定的实例是否为请求的类型。对于`VariableDeclaration`，它的实现如下：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now, you can use the special templates, `llvm::isa<>`, to check if an object
    is of the requested type and `llvm::dyn_cast<>` to dynamically cast the object.
    More templates exist, but these two are the most commonly used ones. For the other
    templates, see [https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates](https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates)
    and for more information about the LLVM style, including more advanced uses, see
    [https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html](https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以使用特殊的模板，`llvm::isa<>`，来检查一个对象是否为请求的类型，以及`llvm::dyn_cast<>`来动态转换对象。更多模板存在，但这两个是最常用的。对于其他模板，请参阅[https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates](https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates)，以及更多关于LLVM风格的详细信息，包括更高级的使用，请参阅[https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html](https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html)。
- en: Creating the semantic analyzer
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建语义分析器
- en: 'Equipped with this knowledge, we can now implement all the parts. First, we
    must create the definition of the AST node for a variable that’s stored in the
    `include/llvm/tinylang/AST/AST.h` file. Besides support for the LLVM-style RTTI,
    the base class stores the name of the declaration, the location of the name, and
    a pointer to the enclosing declaration. The latter is required during code generation
    of nested procedures. The `Decl` base class is declared as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，我们现在可以实施所有部分。首先，我们必须在`include/llvm/tinylang/AST/AST.h`文件中创建AST节点变量的定义。除了支持LLVM风格的RTTI之外，基类存储了声明的名称、名称的位置以及指向封装声明的指针。后者在嵌套过程的代码生成期间是必需的。`Decl`基类声明如下：
- en: '[PRE49]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The declaration for a variable only adds a pointer to the type declaration:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的声明仅添加一个指向类型声明的指针：
- en: '[PRE50]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The method in the parser needs to be extended with a semantic action and variables
    for collected information:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器中的方法需要扩展语义动作和收集信息的变量：
- en: '[PRE51]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '`DeclList` is a list of declarations, `std::vector<Decl*>`, and `IdentList`
    is a list of locations and identifiers, `std::vector<std::pair<SMLoc, StringRef>>`.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeclList` 是一个声明列表，`std::vector<Decl*>`，而 `IdentList` 是一个位置和标识符列表，`std::vector<std::pair<SMLoc,
    StringRef>>`。'
- en: The `parseQualident()` method returns a declaration, which in this case is expected
    to be a type declaration.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`parseQualident()` 方法返回一个声明，在这种情况下，预期是一个类型声明。'
- en: 'The parser class knows an instance of the semantic analyzer class, `Sema`,
    that’s stored in the `Actions` member. A call to `actOnVariableDeclaration()`
    runs the semantic analyzer and the AST construction. The implementation is in
    the `lib/Sema/Sema.cpp` file:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器类知道语义分析器类的实例，`Sema`，它存储在 `Actions` 成员中。对 `actOnVariableDeclaration()` 的调用运行语义分析器和
    AST 构建过程。实现位于 `lib/Sema/Sema.cpp` 文件中：
- en: '[PRE52]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The type declaration is checked with `llvm::dyn_cast<TypeDeclaration>`. If it
    is not a type declaration, then an error message is printed. Otherwise, for each
    name in the `Ids` list, `VariableDeclaration` is instantiated and added to the
    list of declarations. If adding the variable to the current scope fails because
    the name is already declared, then an error message is printed as well.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `llvm::dyn_cast<TypeDeclaration>` 检查类型声明。如果不是类型声明，则打印错误消息。否则，对于 `Ids` 列表中的每个名称，实例化
    `VariableDeclaration` 并将其添加到声明列表中。如果由于名称已声明而无法将变量添加到当前作用域，则也会打印错误消息。
- en: 'Most of the other entities are constructed in the same way – the complexity
    of the semantic analysis is the only difference. More work is required for modules
    and procedures because they open a new scope. Opening a new scope is easy: only
    a new `Scope` object must be instantiated. As soon as the module or procedure
    has been parsed, the scope must be removed.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数其他实体以相同的方式构建——语义分析复杂性是唯一的不同之处。对于模块和过程，需要做更多的工作，因为它们打开了一个新的作用域。打开新的作用域很简单：只需实例化一个新的
    `Scope` 对象。一旦模块或过程被解析，就必须删除该作用域。
- en: 'This must be done reliably because we do not want to add names to the wrong
    scope in case of a syntax error. This is a classic use of the **Resource Acquisition
    Is Initialization** (**RAII**) idiom in C++. Another complication comes from the
    fact that a procedure can recursively call itself. Therefore, the name of the
    procedure must be added to the current scope before it can be used. The semantic
    analyzer has two methods to enter and leave a scope. The scope is associated with
    a declaration:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这必须可靠地完成，因为我们不希望在语法错误的情况下将名称添加到错误的作用域中。这是 C++ 中 **资源获取即初始化（RAII**） 习语的经典用法。另一个复杂之处在于，一个过程可以递归地调用自身。因此，在可以使用之前，必须将过程的名称添加到当前作用域中。语义分析器有两种方法来进入和退出作用域。作用域与一个声明相关联：
- en: '[PRE53]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'A simple helper class is used to implement the RAII idiom:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个简单的辅助类来实现资源获取即初始化（RAII）习语：
- en: '[PRE54]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'When parsing a module or procedure, two interactions occur with the semantic
    analyzer. The first is after the name is parsed. Here, the (almost empty) AST
    node is constructed and a new scope is established:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析模块或过程时，与语义分析器发生两次交互。第一次是在名称解析之后。在这里，构建了一个（几乎为空的）抽象语法树（AST）节点，并建立了一个新的作用域：
- en: '[PRE55]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The semantic analyzer checks the name in the current scope and returns the
    AST node:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分析器检查当前作用域中的名称，并返回 AST 节点：
- en: '[PRE56]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The real work is done after all the declarations and the procedure body have
    been parsed. You only need to check if the name at the end of the procedure declaration
    is equal to the name of the procedure and if the declaration used for the return
    type is a type declaration:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析所有声明和过程体之后，实际的工作才完成。您只需检查过程声明末尾的名称是否等于过程的名称，以及用于返回类型的声明是否是类型声明：
- en: '[PRE57]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Some declarations are inherently present and cannot be defined by the developer.
    This includes the `BOOLEAN` and `INTEGER` types and the `TRUE` and `FALSE` literals.
    These declarations exist in the global scope and must be added programmatically.
    Modula-2 also predefines some procedures, such as `INC` or `DEC`, that can be
    added to the global scope. Given our classes, initializing the global scope is
    simple:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一些声明固有的存在，不能由开发者定义。这包括 `BOOLEAN` 和 `INTEGER` 类型以及 `TRUE` 和 `FALSE` 文本。这些声明存在于全局作用域中，必须通过程序添加。Modula-2
    还预定义了一些过程，如 `INC` 或 `DEC`，可以添加到全局作用域中。考虑到我们的类，初始化全局作用域很简单：
- en: '[PRE58]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'With this scheme, all required calculations for `tinylang` can be done. For
    example, let’s look at how to compute if an expression results in a constant value:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此方案，可以对`tinylang`的所有必需计算进行操作。例如，让我们看看如何计算一个表达式是否得到一个常量值：
- en: We must ensure literal or a reference to a constant declaration is a constant
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们必须确保字面量或常量声明的引用是一个常量
- en: If both sides of an expression are constant, then applying the operator also
    yields a constant
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果表达式的两边都是常量，那么应用运算符也会得到一个常量
- en: These rules are embedded into the semantic analyzer while creating the AST nodes
    for an expression. Likewise, the type and the constant value can be computed.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规则在创建表达式AST节点时嵌入到语义分析器中。同样，类型和常量值也可以计算。
- en: It should be noted that not all kinds are computation can be done in this way.
    For example, to detect the use of uninitialized variables, a method called *symbolic
    interpretation* can be used. In its general form, the method requires a special
    walk order through the AST, which is not possible during construction time. The
    good news is that the presented approach creates a fully decorated AST that is
    ready for code generation. This AST can be used for further analysis, given that
    costly analysis can be turned on or off on demand.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，并非所有类型的计算都可以用这种方式进行。例如，为了检测未初始化变量的使用，可以使用一种称为*符号解释*的方法。在其一般形式中，该方法需要通过AST的特殊遍历顺序，这在构建时是不可能的。好消息是，所提出的方法创建了一个完全装饰的AST，它已准备好用于代码生成。这个AST可以用于进一步分析，前提是昂贵的分析可以根据需要打开或关闭。
- en: 'To play around with the frontend, you also need to update the driver. Since
    the code generation is missing, a correct `tinylang` program produces no output.
    Still, it can be used to explore error recovery and provoke semantic errors:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 为了玩转前端，你还需要更新驱动程序。由于缺少代码生成，正确的`tinylang`程序不会产生输出。尽管如此，它可以用来探索错误恢复并引发语义错误：
- en: '[PRE59]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Congratulations! You’ve finished implementing the frontend for `tinylang`!
    You can use the example program, `Gcd.mod`, provided in the *Defining a real programming
    language* section to run the frontend:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经完成了`tinylang`的前端实现！你可以使用*定义真实编程语言*部分提供的示例程序`Gcd.mod`来运行前端：
- en: '[PRE60]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Of course, this is a valid program, and it looks like nothing happens. Be sure
    to modify the file and provoke some error messages. We’ll continue with the fun
    in the next chapter by adding code generation.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个有效的程序，看起来好像没有发生任何事情。务必修改文件并引发一些错误消息。我们将在下一章中继续添加代码生成，继续这项有趣的旅程。
- en: Summary
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the techniques that a real-world compiler
    uses in the frontend. Starting with the project layout, you created separate libraries
    for the lexer, the parser, and the semantic analyzer. To output messages to the
    user, you extended an existing LLVM class, allowing the messages to be stored
    centrally. The lexer is now separated into several interfaces.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了现实世界编译器在前端使用的技巧。从项目布局开始，你创建了用于词法分析器、解析器和语义分析器的单独库。为了向用户输出消息，你扩展了一个现有的LLVM类，允许消息集中存储。词法分析器现在被分割成几个接口。
- en: Then, you learned how to construct a recursive descent parser from a grammar
    description, looked at what pitfalls to avoid, and learned how to use generators
    to do the job. The semantic analyzer you constructed performs all the semantic
    checks required by the language while being intertwined with the parser and AST
    construction.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你学习了如何从语法描述中构建递归下降解析器，了解了要避免的陷阱，并学习了如何使用生成器来完成这项工作。你构建的语义分析器在解析器和AST构建过程中执行了语言所需的所有语义检查。
- en: The result of your coding effort is a fully decorated AST. You’ll use this in
    the next chapter to generate IR code and, finally, object code.s
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你的编码努力的结果是一个完全装饰的AST。你将在下一章中使用它来生成IR代码，最终生成目标代码。
