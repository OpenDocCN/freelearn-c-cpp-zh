- en: Performance Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能优化
- en: Performance is one of the key drivers for choosing C++ as a programming language
    for a project. The time has come to discuss how we can improve performance when
    we're structuring code in a functional style.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 性能是选择C++作为项目编程语言的关键驱动因素之一。现在是讨论如何在以函数式风格构建代码时改善性能的时候了。
- en: While performance is a huge topic that we obviously can't completely cover in
    one chapter, we will look at key ideas for improving performance, how purely functional
    languages optimize performance, and how to translate these optimizations into
    C++.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然性能是一个庞大的主题，显然我们无法在一个章节中完全覆盖，但我们将探讨改善性能的关键思想，纯函数式语言如何优化性能，以及如何将这些优化转化为C++。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: A process for delivering performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交付性能的流程
- en: How to use parallel/async to improve performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用并行/异步来提高性能
- en: Understanding what tail recursion is and how to activate it
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解什么是尾递归以及如何激活它
- en: How to improve memory consumption when using functional constructs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在使用函数式构造时改善内存消耗
- en: Functional asynchronous code
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能性异步代码
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need a compiler that supports C++ 17\. I used GCC 7.3.0.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个支持C++ 17的编译器。我使用的是GCC 7.3.0。
- en: The code can be found on GitHub at [https:/​/​github.​com/​PacktPublishing/​Hands-​On-​Functional-Programming-​with-​Cpp](https://github.%E2%80%8Bcom/PacktPublishing/Hands-On-Functional-Programming-with-Cpp)
    in the `Chapter10` folder. It includes and uses `doctest`, which is a single-header
    open source unit testing library. You can find it on its GitHub repository at [https:/​/github.​com/​onqtam/​doctest](https://github.%E2%80%8Bcom/onqtam/doctest).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可以在GitHub上找到，位于[https:/​/​github.​com/​PacktPublishing/​Hands-​On-​Functional-Programming-​with-​Cpp](https://github.%E2%80%8Bcom/PacktPublishing/Hands-On-Functional-Programming-with-Cpp)的`Chapter10`文件夹中。它包括并使用`doctest`，这是一个单头文件的开源单元测试库。您可以在其GitHub存储库上找到它，网址为[https:/​/github.​com/​onqtam/​doctest](https://github.%E2%80%8Bcom/onqtam/doctest)。
- en: Performance optimization
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能优化
- en: Talking about performance optimization is like talking about pizza. Some people
    like and search for pizza with pineapple. Others only eat traditional Italian
    pizzas (or from a specific region). Some only eat vegetarian pizza, while others
    like all kinds of pizza. The point is, performance optimization is contextual
    to your code base and your product. What kind of performance are you looking at?
    What is the most valuable part of performance for your users? And what constraints
    do you need to take into account?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 谈论性能优化就像谈论披萨。有些人喜欢和寻找菠萝披萨。其他人只吃传统的意大利披萨（或来自特定地区的披萨）。有些人只吃素食披萨，而其他人喜欢各种披萨。关键是，性能优化是与您的代码库和产品相关的。您正在寻找什么样的性能？对于您的用户来说，性能的最有价值的部分是什么？您需要考虑哪些约束？
- en: 'The customers I work with usually have a few performance requirements, depending
    on the topic:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我与合作的客户通常有一些性能要求，取决于主题：
- en: '*Embedded products* (for example, automotive, energy, or telecommunications)
    often need to work within memory constraints. The stack and the heap are often
    small, thus limiting the number of long-lived variables. The cost of increasing
    memory can be prohibitive (one customer told us they would need more than 10 million
    euros for an extra 1 MB of memory on all of their devices). Therefore, programmers
    need to work around these limitations by avoiding unnecessary memory allocation
    whenever possible. This can include initialization, passing arguments by copy
    (especially larger structures), and avoiding specific algorithms that require
    memory consumption, among others.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*嵌入式产品*（例如汽车、能源或电信）通常需要在内存限制内工作。堆栈和堆通常很小，因此限制了长期存在的变量数量。增加内存的成本可能是禁止性的（一位客户告诉我们，他们需要超过1000万欧元才能在所有设备上增加1MB的额外内存）。因此，程序员需要通过尽可能避免不必要的内存分配来解决这些限制。这可能包括初始化、通过复制传递参数（特别是较大的结构）以及避免需要内存消耗的特定算法，等等。'
- en: '*Engineering applications* (for example computer-aided design or CAD) need
    to use specific algorithms derived from math, physics, and engineering on very
    large datasets and return results as quickly as possible. Processing is usually
    done on modern PCs, so RAM is less of a problem; however, the CPU is. With the
    advent of multi-core CPUs, specialized GPUs that can take over part of the processing
    and cloud technologies that allow the distribution of workloads between multiple
    powerful or specialized servers, the job of developers often becomes optimizing
    for speed in a parallel and asynchronous world.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*工程应用*（例如计算机辅助设计或CAD）需要在非常大的数据集上使用从数学、物理和工程中衍生出的特定算法，并尽快返回结果。处理通常在现代PC上进行，因此RAM不是问题；然而，CPU是问题。随着多核CPU的出现，专用GPU可以接管部分处理工作以及允许在多个强大或专用服务器之间分配工作负载的云技术的出现，开发人员的工作往往变成了在并行和异步世界中优化速度。'
- en: '*Desktop games and game engines* have their own particular concerns. The graphics
    have to look as good as possible to gracefully scale down on middle- or lower-
    end machines and avoid lag. Games usually take over the machine they run on, so
    they only need to fight for resources with the operating system and the system
    applications (such as antiviruses or firewalls). They can also assume a specific
    level of GPU, CPU, and RAM. Optimization becomes about parallelism (since multiple
    cores are expected) and about avoiding waste in order to keep a smooth experience
    throughout the gameplay.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*桌面游戏和游戏引擎*有它们自己特别的关注点。图形必须尽可能好看，以便在中低端机器上优雅地缩放，并避免延迟。游戏通常会占据它们运行的机器，因此它们只需要与操作系统和系统应用程序（如防病毒软件或防火墙）争夺资源。它们还可以假定特定级别的GPU、CPU和RAM。优化变得关于并行性（因为预期有多个核心）以及避免浪费，以保持整个游戏过程中的流畅体验。'
- en: '*Game servers*, however, are a different beast. Services such as Blizzard''s
    Battle.net (the one I''m using a lot as a *Starcraft II* player) are required
    to respond quickly, even under stress. The number of servers used and their power
    doesn''t really matter in the age of cloud computing; we can easily scale them
    up or down. The main concern is responding as quickly as possible to a mostly
    I/O workload.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏服务器*，然而，是一个不同的问题。例如暴雪的战网（我作为*星际争霸II*玩家经常使用的一个）需要快速响应，即使在压力下也是如此。在云计算时代，使用的服务器数量和性能并不重要；我们可以轻松地扩展或缩减它们。主要问题是尽可能快地响应大多数I/O工作负载。'
- en: '*The future is exciting*. The tendency in games is to move processing to the
    servers, thus allowing gamers to play even on lower-end machines. This will open
    up amazing opportunities for future games. (What could you do with 10 GPUs instead
    of one? What about with 100?)But will also lead to the need to optimize the game
    engine for server-side, multi-machine, parallel processing. To move away from
    gaming, the IoT industry opens up even more opportunities for embedded software
    and scalable server-side processing.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*未来令人兴奋*。游戏的趋势是将处理移动到服务器，从而使玩家甚至可以在低端机器上玩游戏。这将为未来的游戏开辟令人惊人的机会。（如果你有10个GPU，你能做什么？如果有100个呢？）但也将导致需要优化游戏引擎以进行服务器端、多机器、并行处理。远离游戏，物联网行业为嵌入式软件和可扩展的服务器端处理提供了更多机会。'
- en: Given all these possibilities, what can we do to deliver performance in a code
    base?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些可能性，我们可以在代码库中做些什么来提供性能？
- en: A process for delivering performance
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供性能的流程
- en: 'As you can see, performance optimization depends a lot on what you''re trying
    to achieve. The next steps can be quickly summarized as such:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，性能优化在很大程度上取决于您要实现的目标。下一步可以快速总结如下：
- en: Define a clear goal for performance, including the metrics and how to measure
    them.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为性能设定明确的目标，包括指标和如何测量它们。
- en: Define a few coding guidelines for performance. Keep them clear and tailored
    to specific parts of the code.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为性能定义一些编码准则。保持它们清晰并针对代码的特定部分进行调整。
- en: Make the code work.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使代码工作。
- en: Measure and improve performance where needed.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在需要的地方测量和改进性能。
- en: Monitor and improve.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控和改进。
- en: Before we look into each of these steps in more detail, it's important to understand
    one important caveat of performance optimization—there are two types of optimization.
    The first comes from clean designs and clean code. For example, by removing certain
    types of similarity from your code, you may end up reducing the size of the executable,
    thus allowing more space for data; the data may end up traveling less through
    the code, thus avoiding unnecessary copies or indirections; or, it will allow
    the compiler to understand the code better and optimize it for you. From my experience,
    refactoring code towards simple design has also often improved performance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更详细地了解这些步骤之前，重要的是要理解性能优化的一个重要警告——有两种优化类型。第一种来自清晰的设计和清晰的代码。例如，通过从代码中删除某些相似性，您可能会减少可执行文件的大小，从而为数据提供更多空间；数据可能会通过代码传输得更少，从而避免不必要的复制或间接；或者，它将允许编译器更好地理解代码并为您进行优化。根据我的经验，将代码重构为简单设计也经常提高了性能。
- en: The second way to improve performance is by using point optimizations. These
    are very specific ways in which we can rewrite a function or a flow that allows
    the code to work faster or with less memory consumption, usually for a specific
    compiler and platform. The resulting code often looks smart but is difficult to
    understand and difficult to change.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 改进性能的第二种方法是使用点优化。这些是非常具体的方式，我们可以重写函数或流程，使代码能够更快地工作或消耗更少的内存，通常适用于特定的编译器和平台。结果代码通常看起来很聪明，但很难理解和更改。
- en: Point optimizations have a natural conflict with writing code that's easy to
    change and maintain. This has famously led to Donald Knuth saying that *premature
    optimization is the root of all evil*. This doesn't mean that we should write
    code that's obviously slow, such as passing large collections by copy. It does
    mean, however, that we should first optimize the design for changeability, then
    measure performance, then optimize it, and only use point optimizations if absolutely
    necessary. Quirks in the platform, a specific compiler version, or libraries that
    are used may require point optimizations from time to time; keep them separate
    and use them scarcely.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 点优化与编写易于更改和维护的代码存在天然冲突。这导致了唐纳德·克努斯说*过早优化是万恶之源*。这并不意味着我们应该编写明显缓慢的代码，比如通过复制大型集合。然而，这意味着我们应该首先优化设计以便更易更改，然后测量性能，然后优化它，并且只在绝对必要时使用点优化。平台的怪癖、特定的编译器版本或使用的库可能需要不时进行点优化；将它们分开并节制使用。
- en: Let's look now into our process for optimizing performance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看我们的性能优化流程。
- en: Define a clear goal for performance, including the metrics and how to measure
    them
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为性能设定明确的目标，包括指标和如何测量它们
- en: If we don't know where we're going, it doesn't matter in which direction we
    go—I'm paraphrasing from Alice in the Wonderland. We should, therefore, know where
    we're going. We need a list of performance metrics that fit the needs of our product.
    In addition, for each of the performance metrics, we need a range that defines
    what is a *good* value for the metric and what is an *acceptable* value. Let's
    look at a few examples.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不知道我们要去哪里，那么我们去哪个方向都无所谓——我是从《爱丽丝梦游仙境》中引用的。因此，我们应该知道我们要去哪里。我们需要一个适合我们产品需求的性能指标列表。此外，对于每个性能指标，我们需要一个定义该指标的*好*值和*可接受*值的范围。让我们看几个例子。
- en: 'If you''re building an *embedded product* for a device with 4 MB of memory,
    you might look at metrics such as:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在为具有4MB内存的设备构建*嵌入式产品*，您可能会关注诸如：
- en: 'Memory consumption:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存消耗：
- en: 'Great: 1-3 MB'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很好：1-3 MB
- en: 'Good: 3-4 MB'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好：3-4 MB
- en: 'Device boot time:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备启动时间：
- en: 'Great: < 1s'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很好：<1秒
- en: 'Good: 1-3s'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好：1-3秒
- en: If you're building a *desktop CAD application* that models the sound waves through
    a building design, other metrics are interesting.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在构建一个*桌面CAD应用程序*，用于模拟建筑设计中的声波，其他指标也很有趣。
- en: 'Computation time for modeling sound waves:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟声波建模的计算时间：
- en: 'For a small room:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个小房间：
- en: 'Great: < 1 min'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很好：<1分钟
- en: 'Good: < 5 min'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好：<5分钟
- en: 'For a medium-sized room:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个中等大小的房间：
- en: 'Great: < 2 min'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很好：<2分钟
- en: 'Good: < 10 min'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好：<10分钟
- en: The numbers here are illustrative only; you'll need to find your own metrics
    for your product.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的数字仅供参考；你需要为你的产品找到自己的度量标准。
- en: Having these metrics and the good/great ranges allows us to measure performance
    after a new feature is added and optimize accordingly. It also allows us to simply
    explain the performance of a product to stakeholders or business people.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些度量标准和好/很好的范围，我们可以在添加新功能后测量性能并进行相应的优化。它还可以让我们向利益相关者或业务人员简单地解释产品的性能。
- en: Define a few coding guidelines for performance—keep them clear and tailored
    to specific parts of the code
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为性能定义一些编码准则-保持清晰，并针对代码的特定部分进行定制
- en: If you ask 50 different C++ programmers about tips to optimize performance,
    you'll soon be overwhelmed with advice. If you start investigating the advice,
    it will turn out that some of it is dated, some of it is very specific, and some
    is great.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你问50个不同的C++程序员关于优化性能的建议，你很快就会被淹没在建议中。如果你开始调查这些建议，结果会发现其中一些已经过时，一些非常具体，一些很好。
- en: It is, therefore, important to have coding guidelines for performance, but there's
    a caveat. C++ code bases tend to be huge because they've been developed over many
    years. If you look critically at your code base, you'll realize that only some
    parts of the code are bottlenecks for performance. To give an example, computing
    a mathematical operation 1 ms faster only makes sense if that operation will be
    called many times; if it's only called once or twice, or very seldom, there's
    no need to optimize it. In fact, the next version of the compiler or CPU will
    probably do a better job than you at optimizing it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对性能有编码准则是很重要的，但有一个警告。C++代码库往往很庞大，因为它们已经发展了很多年。如果你对你的代码库进行批判性审视，你会意识到只有一部分代码是性能瓶颈。举个例子，如果一个数学运算快了1毫秒，只有当这个运算会被多次调用时才有意义；如果它只被调用一两次，或者很少被调用，就没有必要进行优化。事实上，下一个版本的编译器或CPU可能会比你更擅长优化它。
- en: Because of this fact, you should understand which parts of your code are critical
    for the performance criteria that you've defined. Figure out what design fits
    that particular piece of code best; have clear guidelines, and follow them. While
    `const&` is useful everywhere, maybe you could avoid wasting the developer's time
    sorting a very small collection that's only done once.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个事实，你应该了解你的代码的哪些部分对你定义的性能标准至关重要。找出哪种设计最适合这个特定的代码片段；制定清晰的准则，并遵循它们。虽然`const&`在任何地方都很有用，也许你可以避免浪费开发人员的时间对一个只做一次的非常小的集合进行排序。
- en: Make the code work
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让代码工作
- en: With these guidelines in mind, and with a new feature to implement, the first
    step should always be to make the code work. Also, structure it so it's easy to
    change within your constraints. Don't try to optimize for performance here; once
    again, the compiler and the CPU might be smarter than you think and do more work
    than you expect. The only way to know whether that's the case is to measure performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些准则，并有一个新功能要实现，第一步应该始终是让代码工作。此外，结构化使其易于在你的约束条件内进行更改。不要试图在这里优化性能；再次强调，编译器和CPU可能比你想象的更聪明，做的工作也比你期望的多。要知道是否是这种情况，唯一的办法就是测量性能。
- en: Measure and improve performance where needed
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在需要的地方测量和改进性能
- en: Your code works and is structured according to your guidelines and is optimized
    for change. It's time to write down a few hypotheses about optimizing it and then
    test them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你的代码可以按照你的准则工作和结构化，并且为变更进行了优化。现在是时候写下一些关于优化它的假设，然后进行测试了。
- en: Since you have clear metrics for performance, it's relatively easy to verify
    them. Sure, it requires the correct infrastructure and a proper measurement process.
    With these in place, you can measure where you stand against your performance
    metrics.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你对性能有明确的度量标准，验证它们相对容易。当然，这需要正确的基础设施和适当的测量过程。有了这些，你就可以测量你在性能指标上的表现。
- en: Additional hypotheses should be welcome here. Something like—*if we restructure
    this code like this, I expect an improvement in the indicator X*. You can then
    move on and test your hypothesis—start a branch, change the code, build the product,
    take it through the performance metrics measurement process, and see the results.
    Sure, it's more complex than I make it sound—sometimes it may require builds with
    different compilers, with different optimization options, or statistics. All these
    are necessary if you want to make an informed decision. It's better to invest
    some time into metrics over changing the code and making it more difficult to
    understand. Otherwise, you'll end up with a technical debt on which you'll pay
    interest for a long time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里应该欢迎额外的假设。比如- *如果我们像这样重构这段代码，我期望指标X会有所改善*。然后你可以继续测试你的假设-开始一个分支，改变代码，构建产品，经过性能指标测量过程，看看结果。当然，实际情况可能比我说的更复杂-有时可能需要使用不同的编译器进行构建，使用不同的优化选项，或者统计数据。如果你想做出明智的决定，这些都是必要的。投入一些时间来进行度量，而不是改变代码并使其更难理解会更好。否则，你最终会得到一笔技术债务，你将长期支付利息。
- en: However, if you have to do point optimizations, there's no workaround. Just
    make sure to document them in as much detail as possible. Since you've tested
    your hypothesis before, you'll have a lot to write, won't you?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你必须进行点优化，没有变通的办法。只需确保尽可能详细地记录它们。因为你之前已经测试过你的假设，你会有很多东西要写，对吧？
- en: Monitor and improve
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和改进
- en: We started the loop by defining metrics for performance. It's time to close
    it—we need to monitor those metrics (and possibly others) and adjust our intervals
    and coding guidelines based on what we've learned. Performance optimization is
    a continuous process because the target devices evolve as well.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过定义性能指标来开始循环。现在是时候结束了，我们需要监控这些指标（可能还有其他指标），并根据我们所学到的知识调整我们的间隔和编码准则。性能优化是一个持续的过程，因为目标设备也在不断发展。
- en: We've looked at a process for delivering performance, but how does this relate
    to functional programming? Which use cases make functional code structures shine,
    and which don't work so well? It's time to look deeper into our code structures.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过了交付性能的流程，但这与函数式编程有什么关系呢？哪些用例使函数式代码结构发光，哪些又效果不佳？现在是时候深入研究我们的代码结构了。
- en: Parallelism – taking advantage of immutability
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行性-利用不可变性
- en: Writing code that runs in parallel has been the source of much pain in software
    development. It seems like the problems arising from multithreaded, multi-process,
    or multi-server environments are fundamentally difficult to solve. Deadlocks,
    starvation, data races, locks, or debugging multi-threaded code are just a few
    terms that make those of us who've seen them afraid of ever meeting them again.
    However, we have to face parallel code because of multi-core CPUs, GPUs, and multiple
    servers. Can functional programming help with this?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 编写并行运行的代码一直是软件开发中的一大痛点。多线程、多进程或多服务器环境带来的问题似乎根本难以解决。死锁、饥饿、数据竞争、锁或调试多线程代码等术语让我们这些见过它们的人害怕再次遇到它们。然而，由于多核CPU、GPU和多个服务器，我们不得不面对并行代码。函数式编程能帮助解决这个问题吗？
- en: Everyone agrees that this is one of the strong points of functional programming,
    specifically derived from immutability. If your data never changes, there are
    no locks and the synchronization is so simple that it can be generalized. If you
    just use pure functions and functional transformations (barring I/O, of course),
    you get parallelization (almost) for free.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都同意这是函数式编程的一个强项，特别是源自不可变性。如果你的数据从不改变，就不会有锁，同步也会变得非常简单并且可以泛化。如果你只使用纯函数和函数转换（当然除了I/O），你几乎可以免费获得并行化。
- en: 'In fact, the C++ 17 standard includes execution policies for the STL higher-level
    functions, allowing us to change the algorithm from sequential to parallel with
    just one parameter. Let''s check whether all numbers from a vector are greater
    than `5` in parallel. We just need to use `execution::par` as the execution policy
    for `all_of`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，C++ 17标准包括STL高级函数的执行策略，允许我们通过一个参数将算法从顺序改为并行。让我们来检查向量中是否所有数字都大于`5`的并行执行。我们只需要将`execution::par`作为`all_of`的执行策略即可：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can then measure the difference between using the sequential and the parallel
    version of the algorithm with the high-resolution timer from the `chrono` namespace,
    as seen here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`chrono`命名空间的高分辨率计时器来衡量使用顺序和并行版本算法的差异，就像这样：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Normally, I would now show you the difference in execution based on my experiments.
    Unfortunately, in this case, I can''t do this. At the time of writing, the only
    compilers implementing execution policies are MSVC and Intel C++, but neither
    of them met the standard. However, as shown in the following snippet, I wrote
    the code in the `parallelExecution.cpp` source file, allowing you to enable it
    by uncommenting a line when your compiler supports the standard, as shown here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我现在会展示基于我的实验的执行差异。不幸的是，在这种情况下，我不能这样做。在撰写本文时，唯一实现执行策略的编译器是MSVC和英特尔C++，但它们都不符合标准。然而，如下代码段所示，我在`parallelExecution.cpp`源文件中编写了代码，当你的编译器支持标准时，你可以通过取消注释一行来启用它：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The code you will be running when you do this will display the comparative
    duration for running `all_of` sequentially and in parallel, like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将显示顺序和并行运行`all_of`的比较持续时间，就像这样：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: While I would have loved to analyze some execution data here, maybe it's for
    the best that I can't, since the most important message of this chapter is measure,
    measure, measure, and, only then, optimize. Hopefully, you'll do some measuring
    yourself when the time comes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我很想在这里分析一些执行数据，但也许最好的是我不能，因为这一章最重要的信息是要衡量、衡量、衡量，然后再优化。希望在合适的时候你也能进行一些衡量。
- en: The C++ 17 standard supports the execution policies for many STL functions,
    including `sort`, `find`, `copy`, `transform`, and `reduce`. That is, if you're
    chaining these functions and using pure functions, you just need to pass an extra
    parameter to all calls (or `bind` the higher-level functions) to achieve parallel
    execution! I would go as far as to say that this is akin to magic for anyone who
    has tried managing threads by themselves or debugging weird synchronization issues.
    In fact, all the code we wrote for Tic-Tac-Toe and Poker Hands in the previous
    chapters can be easily switched to parallel execution, provided the compiler supports
    the full C++ 17 standard.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: C++ 17标准支持许多STL函数的执行策略，包括`sort`、`find`、`copy`、`transform`和`reduce`。也就是说，如果你在这些函数上进行链式调用并使用纯函数，你只需要为所有调用传递一个额外的参数（或者将高级函数绑定），就可以实现并行执行！我敢说，对于那些尝试自己管理线程或调试奇怪同步问题的人来说，这几乎就像魔法一样。事实上，在前几章中我们为井字棋和扑克牌手写的所有代码都可以很容易地切换到并行执行，只要编译器支持完整的C++
    17标准。
- en: But how does this work? It's fairly easy for `all_of` to run in multiple threads; each
    of them executes the predicate on a specific element from the collection, a Boolean
    value is returned, and the process stops when the first predicate returns `False`.
    This is only possible if the predicate is a pure function; modifying the result
    or the vector in any way will create race conditions. The documentation specifically
    states that the programmer is responsible for keeping the predicate function pure—there
    will be no warning or compilation error. In addition to being pure, your predicate
    must not assume the order in which the elements are treated.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这是如何工作的？对于`all_of`来说，运行在多个线程中是相当容易的；每个线程在集合中的特定元素上执行谓词，返回一个布尔值，并且当第一个谓词返回`False`时，进程停止。只有当谓词是纯函数时才可能发生这种情况；以任何方式修改结果或向量都会创建竞争条件。文档明确指出程序员有责任保持谓词函数的纯净性——不会有警告或编译错误。除了是纯函数外，你的谓词不能假设元素被处理的顺序。
- en: 'In case the parallel execution policy cannot be started (for example, due to
    a lack of resources), the execution will fall back to sequential calls. This is
    a useful thing to remember when measuring performance: if it''s much lower than
    expected, check first whether the program can execute in parallel.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果并行执行策略无法启动（例如，由于资源不足），执行将回退到顺序调用。在测量性能时，这是一个需要记住的有用事情：如果性能远低于预期，请首先检查程序是否可以并行执行。
- en: This option is useful for computation-heavy applications using multiple CPUs.
    If you're interested in its memory hit, you'll have to measure it, since it depends
    on the compiler and the standard library that you use.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项对于使用多个CPU的计算密集型应用程序非常有用。如果你对它的内存消耗感兴趣，你需要测量一下，因为它取决于你使用的编译器和标准库。
- en: Memoization
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记忆化
- en: Pure functions have an interesting property. For the same input values, they
    return the same outputs. This makes them equivalent to a big table of values with
    an output value corresponding to every combination of values for the input arguments.
    Sometimes, it's faster to remember parts of this table rather than doing the computation.
    This technique is called **memoization**.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 纯函数具有一个有趣的特性。对于相同的输入值，它们返回相同的输出。这使它们等同于一个大表格的值，其中每个输入参数的组合都对应一个输出值。有时，记住这个表格的部分比进行计算更快。这种技术称为**记忆化**。
- en: Pure functional programming languages, as well as languages such as Python and
    Groovy, have ways to enable memoization on specific function calls, thus providing
    a high level of control. Unfortunately, C++ doesn't have this facility, so we'll
    have to write it ourselves.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 纯函数式编程语言以及诸如Python和Groovy之类的语言，都有办法在特定函数调用上启用记忆化，从而提供了高度的控制。不幸的是，C++没有这个功能，所以我们必须自己编写它。
- en: Implementing memoization
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现记忆化
- en: 'To start our implementation, we will need a function; ideally, computationally
    expensive. Let''s pick the `power` function. A simple implementation is just a
    wrapper over the standard `pow` function, as shown in the following snippet:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始我们的实现，我们需要一个函数；最好是计算昂贵的。让我们选择`power`函数。一个简单的实现只是标准`pow`函数的包装器，如下面的代码片段所示：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How do we start to implement memoization? Well, at its core, memoization is
    caching. Whenever a function is called for the first time, it runs normally but
    also stores the result in combination with the input values. On subsequent calls,
    the function will search through the map to see if the value is cached and return
    it if so.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何开始实现记忆化？嗯，在其核心，记忆化就是缓存。每当一个函数第一次被调用时，它会正常运行，但同时也将结果与输入值组合存储起来。在后续的调用中，函数将搜索映射以查看值是否被缓存，并在有缓存时返回它。
- en: 'This means that we''ll need a cache that has, as key, the parameters, and,
    as value, the result of the computation. To group the parameters together, we
    can simply use a pair or a tuple:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们需要一个缓存，其键是参数，值是计算结果。为了将参数组合在一起，我们可以简单地使用一对或元组：
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Therefore, the cache will be:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，缓存将是：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s change our `power` function to use this cache. First, we need to look
    in the cache for a result:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们改变我们的`power`函数以使用这个缓存。首先，我们需要在缓存中查找结果：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If nothing is found, we compute the result and store it in the cache. If something
    is found, that''s the value we return:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有找到任何东西，我们计算结果并将其存储在缓存中。如果找到了某些东西，那就是我们要返回的值：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To check that this method is working fine, let''s run some tests:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这种方法是否正常工作，让我们运行一些测试：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Everything works fine. Now let''s compare the two versions of power, with and
    without memoization in the following snippet. The following code shows how we
    can extract a more generic way to memoize functions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都很顺利。现在让我们比较power的两个版本，在下面的代码片段中有和没有记忆化。下面的代码显示了我们如何提取一种更通用的方法来记忆化函数：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The first observation is that we can replace the bold line with a call to the
    original power function, so let''s do that:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个观察是我们可以用原始power函数的调用替换粗体行，所以让我们这样做：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If we pass in the function we need to call during memoization, we obtain a
    more general solution:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们传入我们需要在记忆化期间调用的函数，我们将得到一个更通用的解决方案：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'But wouldn''t it be nice to return a memoized function instead? We can modify
    our `memoize` function to receive a function and return a function that is memoized,
    which receives the same parameters as the initial function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 但是返回一个记忆化的函数不是很好吗？我们可以修改我们的`memoize`函数，使其接收一个函数并返回一个记忆化的函数，该函数接收与初始函数相同的参数：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This change doesn''t work initially—I''m getting a segmentation fault. The
    reason is that we are changing the cache inside the lambda. To make it work, we
    need to make the lambda mutable and capture by value:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个改变最初不起作用——我得到了一个分段错误。原因是我们在lambda内部改变了缓存。为了使它工作，我们需要使lambda可变，并按值捕获：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We now have a function that can memoize any function with two integer parameters.
    It''s easy to make it more generic with the help of a few type arguments. We need
    a type for the return value, a type for the first argument, and a type for the
    second argument:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个可以对任何带有两个整数参数的函数进行记忆化的函数。通过使用一些类型参数，很容易使它更通用。我们需要一个返回值的类型，第一个参数的类型和第二个参数的类型：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We have achieved a memoization function for any function that has two arguments.
    We can do even better. C++ allows us to use templates with an unspecified number
    of type arguments—so-called **variadic templates**. Using their magic, we end
    up with an implementation for memoization that works with any function with any
    number of arguments:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了一个对具有两个参数的任何函数进行记忆化的函数。我们可以做得更好。C++允许我们使用具有未指定数量类型参数的模板，即所谓的**可变参数模板**。通过使用它们的魔力，我们最终得到了一个可以处理任何数量参数的函数的记忆化实现：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This function is helpful for caching any other function; however, there''s
    a catch. We have, until now, used the wrapped implementation of power. The following
    is an example of what it would look like if we wrote our own instead:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数对缓存任何其他函数都有帮助；然而，有一个问题。到目前为止，我们使用了`power`的包装实现。以下是一个示例，如果我们自己编写它会是什么样子：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Memoizing this function will merely cache the final results. However, the function
    is recursive and the call to our `memoize` function will not memoize the intermediate
    results from the recursion. To do so, we need to tell our memoized power function
    not to call the power function but the memoized `power` function.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个函数进行记忆化只会缓存最终结果。然而，这个函数是递归的，我们的`memoize`函数调用不会记忆递归的中间结果。为了做到这一点，我们需要告诉我们的记忆化幂函数不要调用`power`函数，而是调用记忆化的`power`函数。
- en: Unfortunately, there's no easy way to do this. We could pass, as an argument,
    the function to call recursively, but this would change the original function
    signature for implementation reasons. Or we could just rewrite the function to
    take advantage of memoization.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有简单的方法可以做到这一点。我们可以将递归调用的函数作为参数传递，但这会因为实现原因改变原始函数的签名。或者我们可以重写函数以利用记忆化。
- en: Still, we end up with quite a good solution. Let's put it to the test.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们得到了一个相当不错的解决方案。让我们来测试一下。
- en: Using memoization
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用记忆化
- en: 'Let''s use our `measureExecutionTimeForF` function to measure the time it takes
    to make various calls to our `power` function. It''s time to also think about
    the results we expect. We do cache the values of repeated calls, but this requires
    its own processing and memory on every call to the function. So, maybe it will
    help, maybe it won''t. We won''t know until we try it:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用我们的`measureExecutionTimeForF`函数来测量调用我们的`power`函数所需的时间。现在也是时候考虑我们期望的结果了。我们确实缓存了重复调用的值，但这需要在每次调用函数时进行自己的处理和内存。所以，也许它会有所帮助，也许不会。在尝试之前，我们不会知道。
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This code is calling the `power` function with the same values, with the last
    call returning to the first values. It then proceeds to do the same, but after
    creating the memoized version of `power`. Finally, a sanity check—the result of
    the `power` function and the memoized `power` function are compared to ensure
    that we don't have a bug in the `memoize` function.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用相同的值调用`power`函数，最后一次调用返回到第一次调用的值。然后继续做同样的事情，但在创建`power`的记忆化版本之后。最后，一个健全性检查——`power`函数的结果和记忆化的`power`函数的结果进行比较，以确保我们的`memoize`函数没有错误。
- en: 'The question is—has memoization improved the time it takes to execute the last
    call from the series (exactly the same as the first call from the series)? In
    my configuration, the results are mixed, as shown in the following snippet:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是——记忆化是否改善了执行系列中最后一个调用所需的时间（与系列中第一个调用完全相同）？在我的配置中，结果是混合的，如下面的片段所示：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Alternatively, for a better view (calls without memoization are first), there
    is the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，为了更好地查看（首先是没有记忆化的调用），有以下内容：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Overall, the calls with memoization are better, except when we repeat the first
    call. Of course, the results vary when running the test repeatedly, but this shows
    that improving performance is not as easy as just using caching. What happens
    behind the scenes? I think that the most likely explanation is that another caching
    mechanism kicks in—CPU or otherwise.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，使用记忆化的调用更好，除非我们重复第一个调用。当然，重复运行测试时结果会有所不同，但这表明提高性能并不像只是使用缓存那么简单。背后发生了什么？我认为最有可能的解释是另一个缓存机制启动了——CPU或其他机制。
- en: If anything, this proves the importance of measurements. It's not a surprise
    that CPUs and compilers already do a fair share of optimizations, and we can only
    do so much in code.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，这证明了测量的重要性。不出乎意料的是，CPU和编译器已经做了相当多的优化，我们在代码中能做的也有限。
- en: 'What if we try recursive memoization? I rewrote the `power` function to use
    memoization recursively, and it mixes caching with the recursive call. Here''s
    the code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试递归记忆化呢？我重写了`power`函数以递归使用记忆化，并将缓存与递归调用混合在一起。以下是代码：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'When we run it, the results are as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行它时，结果如下：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Alternatively, in a compressed view (calls without memoization are first),
    there is the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，以压缩视图（首先是没有记忆化的调用），有以下内容：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, the time for building the cache is enormous. However, it pays
    off for repeated calls but it still can't beat the CPU and compiler optimizations
    in this case.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，构建缓存的时间是巨大的。然而，对于重复调用来说是值得的，但在这种情况下仍然无法击败CPU和编译器的优化。
- en: 'Does memoization help then? It does when we use a more complex function. Let''s
    next try computing the difference between the factorial of two numbers. We''ll
    use a naive implementation of the factorial, and we''ll try to memoize the factorial
    function first, and then the function computing the difference. For the sake of
    consistency, we''ll use the same pairs of numbers as before. Let''s look at the
    code in the following snippet:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，备忘录有帮助吗？当我们使用更复杂的函数时，它确实有帮助。接下来让我们尝试计算两个数字的阶乘之间的差异。我们将使用阶乘的一个简单实现，并首先尝试对阶乘函数进行备忘录，然后再对计算差异的函数进行备忘录。为了保持一致，我们将使用与之前相同的数字对。让我们看一下以下代码：
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'What are the results? Let''s first see the difference between the normal function,
    and the function using the memoized factorial:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是什么？让我们先看一下普通函数和使用备忘录阶乘函数之间的差异：
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s compare them side by side once again:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次并排比较它们：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Although the result is mixed for the other calls, there''s a ~20% improvement
    with the memoized function over the non-memoized function when hitting the cached
    value. That seems a small improvement since factorial is recursive, so, in theory,
    the memoization should help immensely. However, *we did not memoize the recursion*.
    Instead, the factorial function is still calling the non-memoized version recursively.
    We''ll come back to this later; for now, let''s check what happens when memoizing
    the `factorialDifference` function:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其他调用的结果是混合的，但在命中缓存值时，备忘录函数比非备忘录函数有约20%的改进。这似乎是一个小的改进，因为阶乘是递归的，所以理论上，备忘录应该会有很大的帮助。然而，*我们没有对递归进行备忘录*。相反，阶乘函数仍然递归调用非备忘录版本。我们稍后会回到这个问题；现在，让我们来看一下在备忘录`factorialDifference`函数时会发生什么：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s look at the results side by side:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们并排看一下结果：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The memoized version is twice as fast as the non-memoized one on the cached
    value! This is huge! However, we pay for this improvement with a performance hit
    when we don't have the value cached. Also, something weird is going on at the
    second call; some kind of caching may interfere with our results.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 备忘录版本比非备忘录版本在缓存值上快两倍！这太大了！然而，当我们没有缓存值时，我们会因此而付出性能损失。而且，在第二次调用时出现了一些奇怪的情况；某种缓存可能会干扰我们的结果。
- en: 'Can we make this better by optimizing all the recursions of the factorial function?
    Let''s see. We need to change our factorial function such that the cache applies
    to each call. In order to do this, we''ll need to call the memoized factorial
    function recursively instead of the normal factorial function, as shown in the
    following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能通过优化阶乘函数的所有递归来使其更好吗？让我们看看。我们需要改变我们的阶乘函数，使得缓存适用于每次调用。为了做到这一点，我们需要递归调用备忘录阶乘函数，而不是普通的阶乘函数，如下所示：
- en: '[PRE29]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We use the difference function, which recursively memoizes both calls to the
    factorial:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用差异函数，递归地对阶乘的两次调用进行备忘录：
- en: '[PRE30]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'By running the initial function without memoization and the previous function
    with the same data side by side, I got the following output:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过并排运行初始函数和先前函数的相同数据，我得到了以下输出：
- en: '[PRE31]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can look at this side by side:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以并排看一下：
- en: '[PRE32]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As we can see, the cache is building up, with a massive penalty hit for the
    first large computation; the second call involved 1024! However, the subsequent
    calls are much faster due to the cache hits.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，缓存正在累积，对于第一个大计算来说惩罚很大；第二次调用涉及1024！然而，由于缓存命中，随后的调用速度要快得多。
- en: In conclusion, we can say that memoization is useful for speeding up repeated
    complex computations when enough memory is available. It may require some tweaking
    since the cache size and cache hits depend on how many calls and how many repeated
    calls are made to the function. So, don't take this for granted—measure, measure,
    measure.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们可以说，当有足够的内存可用时，备忘录对于加速重复的复杂计算是有用的。它可能需要一些调整，因为缓存大小和缓存命中取决于对函数的调用次数和重复调用次数。因此，不要认为这是理所当然的——要进行测量，测量，测量。
- en: Tail recursion optimization
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尾递归优化
- en: Recursive algorithms are very common in functional programming. In fact, many
    of our imperative loops can be rewritten as recursive algorithms using pure functions.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 递归算法在函数式编程中非常常见。实际上，我们的命令式循环中的许多循环可以使用纯函数重写为递归算法。
- en: However, recursion is not very popular in imperative programming because it
    has a few issues. First, developers tend to have less practice with recursive
    algorithms compared to imperative loops. Second, the dreaded stack overflow—recursive
    calls are placed to the stack by default and if there are too many iterations,
    the stack overflows with an ugly error.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在命令式编程中，递归并不是很受欢迎，因为它有一些问题。首先，开发人员往往对递归算法的练习比起命令式循环要少。其次，可怕的堆栈溢出——递归调用默认情况下会被放到堆栈上，如果迭代次数太多，堆栈就会溢出并出现一个丑陋的错误。
- en: Fortunately, compilers are smart and can fix this problem for us, while at the
    same time optimizing recursive functions. Enter tail recursion optimization.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，编译器很聪明，可以为我们解决这个问题，同时优化递归函数。进入尾递归优化。
- en: 'Let''s take a look at a simple recursive function. We''ll reuse the factorial
    from the previous section, as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的递归函数。我们将重用前一节中的阶乘，如下所示：
- en: '[PRE33]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Normally, each call would be placed on the stack, so your stack will grow with
    each call. Let''s visualize it:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，每次调用都会被放在堆栈上，因此每次调用堆栈都会增长。让我们来可视化一下：
- en: '[PRE34]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can avoid the stack by rewriting the code. We notice that the recursive
    call comes at the end; we can, therefore, rewrite the function similar to the
    following pseudocode:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过重写代码来避免堆栈。我们注意到递归调用是在最后进行的；因此，我们可以将函数重写为以下伪代码：
- en: '[PRE35]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In a nutshell, this is what the compiler can do for us if we enable the correct
    optimization flag. Not only does this call take less memory and avoid stack overflows—but
    it is also faster.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，如果我们启用正确的优化标志，编译器可以为我们做的事情。这个调用不仅占用更少的内存，避免了堆栈溢出，而且速度更快。
- en: By now, you should know not to trust anyone's claims—including mine—without
    measuring them. So, let's check this hypothesis.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该知道不要相信任何人的说法，包括我的，除非经过测量。所以，让我们验证这个假设。
- en: 'First, we''ll need a test that measures the timing for multiple calls to the
    factorial function. I picked some values to carry out the test:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个测试，用于测量对阶乘函数的多次调用的时间。我选择了一些值来进行测试：
- en: '[PRE36]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Then, we need to compile this function with optimization disabled and enabled.
    The **GNU Compiler Collection** (**GCC**) flag that optimizes tail recursion is
    `-foptimize-sibling-calls`; the name refers to the fact that the flag optimizes
    both sibling calls and tail calls. I will not go into detail about what sibling
    call optimization does; let's just say that it doesn't affect our test in any
    way.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要编译此函数，分别禁用和启用优化。**GNU编译器集合**（**GCC**）优化尾递归的标志是`-foptimize-sibling-calls`；该名称指的是该标志同时优化了兄弟调用和尾调用。我不会详细介绍兄弟调用优化的作用；让我们只说它不会以任何方式影响我们的测试。
- en: 'Time to run the two programs. First, let''s look at the raw output:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这两个程序的时间。首先，让我们看一下原始输出：
- en: 'This is the program without optimization:'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是没有优化的程序：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This is the program with optimization:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是带有优化的程序：
- en: '[PRE38]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s see the results side by side now; the duration without optimization
    is on the left:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们一起看一下结果；没有优化的持续时间在左边：
- en: '[PRE39]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: It seems that the optimization really kicks in for larger values on my machine.
    Once again, this proves the importance of metrics whenever performance matters.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来在我的机器上，优化确实对较大的值起作用。这再次证明了在性能要求时度量的重要性。
- en: In the following sections, we'll experiment with the code in various ways and
    measure the results.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将以各种方式对代码进行实验，并测量结果。
- en: Fully optimized calls
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完全优化的调用
- en: 'Out of curiosity, I''ve decided to run the same program with all of the safe
    optimization flags turned on. In GCC, this option is `-O3`. The results are staggering,
    to say the least:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 出于好奇，我决定运行相同的程序，并打开所有安全优化标志。在GCC中，这个选项是`-O3`。结果令人震惊，至少可以这么说：
- en: '[PRE40]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s compare the results of enabling all of the optimization flags (the second
    value in the next snippet) with the results for just tail recursion optimization:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较启用所有优化标志的结果（下一段代码中的第二个值）与仅尾递归优化的结果：
- en: '[PRE41]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The difference is staggering, as you can see. The conclusion is that, while
    tail recursion optimization is useful, it's even better to have CPU cache hits
    and all the goodies enabled by compilers.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 差异是巨大的，正如你所看到的。结论是，尽管尾递归优化很有用，但启用编译器的CPU缓存命中和所有优化功能会更好。
- en: But we're using an `if` statement; will this work differently when we use the
    `?:` operator?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们使用了`if`语句；当我们使用`?:`运算符时，这会有不同的效果吗？
- en: 'If vs ?:'
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'if vs ?:'
- en: 'For curiosity''s sake, I decided to re-write the code using the `?:` operator
    instead of `if` statements, as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 出于好奇，我决定使用`?:`运算符重写代码，而不是`if`语句，如下所示：
- en: '[PRE42]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'I didn''t know what to expect, and the results were interesting. Let''s look
    at the raw output:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道会有什么结果，结果很有趣。让我们看一下原始输出：
- en: 'Without optimization flags:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有优化标志：
- en: '[PRE43]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'With tail recursion flag turned on:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开尾递归标志：
- en: '[PRE44]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s look at a comparison of the results; the duration without optimization
    comes first:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下结果；没有优化的持续时间首先出现：
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The difference is very great between the two versions, which is something I
    didn't quite expect. As always, this is most likely the result of the GCC compiler,
    and you should test it on your own. However, it seems that this version is better
    for tail optimization with my compiler—an intriguing result to say the least.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 两个版本之间的差异非常大，这是我没有预料到的。像往常一样，这很可能是GCC编译器的结果，你应该自己测试一下。然而，看起来这个版本对于我的编译器来说更适合尾部优化，这是一个非常有趣的结果。
- en: Double recursion
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 双递归
- en: 'Does tail recursion work for double recursion? We need to come up with an example
    that passes recursion from one function to another to check for this. I decided
    to write two functions, `f1` and `f2`, which recursively call each other. `f1`
    multiplies the current parameter with `f2(n - 1 )`, while `f2` adds `f1(n)` to `f1(n-1)`.
    Here''s the code:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 尾递归对双递归有效吗？我们需要想出一个例子，将递归从一个函数传递到另一个函数，以检查这一点。我决定编写两个函数，`f1`和`f2`，它们互相递归调用。`f1`将当前参数与`f2(n
    - 1 )`相乘，而`f2`将`f1(n)`添加到`f1(n-1)`。以下是代码：
- en: '[PRE46]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s check the timing for calls to `f1` with values from `0` to `8`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查对`f1`的调用的时间，值从`0`到`8`：
- en: '[PRE47]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Here''s what we obtain:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的结果：
- en: 'Without tail call optimization:'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有尾调用优化：
- en: '[PRE48]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'With call optimization:'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用调用优化：
- en: '[PRE49]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let''s look at the results side by side; the duration of calls without tail
    optimization is on the left:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一起看一下结果；没有尾优化的调用持续时间在左边：
- en: '[PRE50]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The differences are very great indeed, showing that the code is greatly optimized.
    However, remember that, for GCC, we are using the `-foptimize-sibling-calls` optimization
    flag. This flag carries out two types of optimization: tail calls and sibling
    calls. Sibling calls are calls to functions that have a return type of the same
    size and a parameter list of the same total size, thus allowing the compiler to
    treat them similarly with tail calls. It''s quite possible that, in our case,
    both optimizations are applied.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 差异确实非常大，显示代码得到了很大的优化。但是，请记住，对于GCC，我们使用的是`-foptimize-sibling-calls`优化标志。该标志执行两种优化：尾调用和兄弟调用。兄弟调用是指对返回类型和参数列表总大小相同的函数的调用，因此允许编译器以与尾调用类似的方式处理它们。在我们的情况下，很可能两种优化都被应用了。
- en: Optimizing execution time with asynchronous code
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异步代码优化执行时间
- en: 'When we have multiple threads, we can use two close techniques to optimize
    the execution time: parallel execution and asynchronous execution. We''ve seen
    how parallel execution works in a previous section; what about asynchronous calls?'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有多个线程时，我们可以使用两种近似技术来优化执行时间：并行执行和异步执行。我们已经在前一节中看到了并行执行的工作原理；异步调用呢？
- en: First, let's remind ourselves what asynchronous calls are. We would like to
    make a call, continue normally on the main thread, and get the result back at
    some point in the future. To me, this sounds like a perfect job for functions.
    We just need to call functions, let them execute, and talk to them again after
    a while.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下异步调用是什么。我们希望进行一次调用，然后在主线程上继续正常进行，并在将来的某个时候获得结果。对我来说，这听起来像是函数的完美工作。我们只需要调用函数，让它们执行，然后在一段时间后再与它们交谈。
- en: Since we've talked about the future, let's talk about the `future` construct
    in C++.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经谈到了future，让我们来谈谈C++中的`future`构造。
- en: Futures
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Futures
- en: We've already established that it's ideal to avoid managing threads in a program,
    except when doing very specialized work, but we need parallel execution and often
    need synchronization to obtain a result from another thread. A typical example
    is a long computation that would block the main thread unless we run it in its
    own thread. How do we know when the computation is done and how can we get the
    result of the computation?
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定，在程序中避免管理线程是理想的，除非进行非常专业化的工作，但我们需要并行执行，并且通常需要同步以从另一个线程获取结果。一个典型的例子是一个长时间的计算，它会阻塞主线程，除非我们在自己的线程中运行它。我们如何知道计算何时完成，以及如何获得计算的结果？
- en: 'In 1976–1977, two concepts were proposed in computer science to simplify the
    solution to this problem—futures and promises. While these concepts are often
    used interchangeably in various technologies, in C++ they have specific meanings:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在1976年至1977年，计算机科学中提出了两个概念来简化解决这个问题的方法——futures和promises。虽然这些概念在各种技术中经常可以互换使用，在C++中它们有特定的含义：
- en: A future can retrieve a value from a provider while taking care of synchronization
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个future可以从提供者那里检索一个值，同时进行同步处理
- en: A promise stores a value for the future, offering, in addition, a synchronization
    point
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: promise存储了一个未来的值，并提供了一个同步点
- en: Due to its nature, a `future` object has restrictions in C++. It cannot be copied,
    only moved, and it's only valid when associated with a shared state. This means
    that we can only create a valid future object by calling `async`, `promise.get_future()` or
    `packaged_task.get_future()`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它的性质，`future`对象在C++中有一些限制。它不能被复制，只能被移动，并且只有在与共享状态相关联时才有效。这意味着我们只能通过调用`async`、`promise.get_future()`或`packaged_task.get_future()`来创建一个有效的future对象。
- en: It's also worth mentioning that promises and futures use threading libraries
    in their implementation; therefore, you may need to add a dependency to another
    library. On my system (Ubuntu 18.04, 64 bits), when compiling with g++, I had
    to add a link dependency to the `pthread` library; I expect you'll need the same
    if you're using g++ on a mingw or cygwin configuration.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，promises和futures在它们的实现中使用了线程库；因此，您可能需要添加对另一个库的依赖。在我的系统（Ubuntu 18.04，64位）上，使用g++编译时，我不得不添加一个对`pthread`库的链接依赖；如果您在mingw或cygwin配置上使用g++，我希望您也需要相同的依赖。
- en: 'Let''s first see how we use `future` and `promise` in tandem. First, we''ll
    create a `promise` for a secret message:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看如何在C++中同时使用`future`和`promise`。首先，我们将为一个秘密消息创建一个`promise`：
- en: '[PRE51]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, let''s create a `future` and start a new thread using it. The thread
    will use a lambda that simply prints the secret message:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个`future`并使用它启动一个新的线程。线程将使用一个lambda函数简单地打印出秘密消息：
- en: '[PRE52]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Notice that we need to avoid copying the `future`; in this case, we use a reference
    wrapper over the future.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们需要避免复制`future`；在这种情况下，我们使用一个对`future`的引用包装器。
- en: 'We''ll stick with this thread for now; the next thing is to fulfill the promise,
    that is, to set a value:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们暂时只讨论这个线程；下一步是实现承诺，也就是设置一个值：
- en: '[PRE53]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'In the meantime, the other thread will do some stuff and then will request
    that we keep our promise. Well, not quite; it will ask for the value of the `promise`,
    which blocks it until `join()` is called:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，另一个线程将做一些事情，然后要求我们信守诺言。嗯，不完全是；它将要求`promise`的值，这将阻塞它，直到调用`join()`：
- en: '[PRE54]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: As you may notice, this method sets the responsibility for computing the value
    in the main thread. What if we want it to be on the secondary thread? We just
    need to use `async`.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能注意到的，这种方法将计算值的责任放在了主线程上。如果我们希望它在辅助线程上完成呢？我们只需要使用`async`。
- en: 'Let''s say we''d like to check whether a number is prime. We first write a
    lambda that will check for this in a naive way, for each possible divisor from
    `2` to `x-1`, and check whether `x` is divisible by it. If it''s not divisible
    by any value, it is a prime number:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要检查一个数字是否是质数。我们首先编写一个lambda函数，以一种天真的方式检查这一点，对`2`到`x-1`之间的每个可能的除数进行检查，并检查`x`是否可以被它整除。如果它不能被任何值整除，那么它是一个质数：
- en: '[PRE55]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'A few helping lambdas are used. One for generating a range like this:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了一些辅助的lambda函数。一个用于生成这样的范围：
- en: '[PRE56]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'This is then specialized for generating a range that starts with `2`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这是专门用于生成以`2`开头的范围：
- en: '[PRE57]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Then, a predicate that checks whether two numbers are divisible or not:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一个检查两个数字是否可被整除的谓词：
- en: '[PRE58]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'To run this function in a separate thread from the main one, we need to declare
    a `future` using `async`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要在主线程之外的一个单独线程中运行这个函数，我们需要使用`async`声明一个`future`：
- en: '[PRE59]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The second argument of `async` is the input argument for our function. Multiple
    arguments are allowed.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`async`的第二个参数是我们函数的输入参数。允许多个参数。'
- en: 'Then, we can do other stuff, and finally, ask for the result:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以做其他事情，最后，要求结果：
- en: '[PRE60]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The bold line of code marks the point when the main thread stops to wait for
    a result from the secondary thread.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 粗体代码行标志着主线程停止等待来自辅助线程的结果的点。
- en: 'If you need more than one `future`, you can use them. In the following example,
    we''ll run `is_prime` with four different values in four different threads, as
    shown here:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要多个`future`，您可以使用它们。在下面的示例中，我们将使用四个不同的值在四个不同的线程中运行`is_prime`，如下所示：
- en: '[PRE61]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Functional asynchronous code
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 功能性异步代码
- en: We've seen that the simplest implementation of a thread is a lambda, but we
    can do even more. The last example, which uses multiple threads to run the same
    operation asynchronously on different values, can be turned into a functional
    high-order function.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，线程的最简单实现是一个lambda，但我们可以做得更多。最后一个示例使用多个线程异步地在不同的值上运行相同的操作，可以转换为一个功能高阶函数。
- en: 'But let''s start with a few simple loops. First, we will transform the input
    values and the expected results into vectors:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们从一些简单的循环开始。首先，我们将输入值和预期结果转换为向量：
- en: '[PRE62]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Then, we need a `for` loop to create the futures. It''s important not to call
    the `future()` constructor, because this will fail due to trying to copy the newly
    constructed `future` object into a container. Instead, add the result of `async()`
    directly into the container:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要一个`for`循环来创建futures。重要的是不要调用`future()`构造函数，因为这样做会由于尝试将新构造的`future`对象复制到容器中而失败。相反，将`async()`的结果直接添加到容器中：
- en: '[PRE63]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, we need to get the results back from the threads. Once again, we need
    to avoid copying the `future`, so we will use a reference when iterating:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要从线程中获取结果。再次，我们需要避免复制`future`，因此在迭代时将使用引用：
- en: '[PRE64]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let''s see the whole test:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看整个测试：
- en: '[PRE65]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'It''s quite obvious that we can turn this into a few transform calls. However,
    we need to pay special attention to avoid the copying of futures. First, I created
    a lambda that helps with creating a `future`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，我们可以将这些转换成几个transform调用。然而，我们需要特别注意避免复制futures。首先，我创建了一个帮助创建`future`的lambda：
- en: '[PRE66]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The first `for` loop then turns into a `transformAll` call:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个`for`循环然后变成了一个`transformAll`调用：
- en: '[PRE67]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The second part is trickier than expected. Our implementation of `transformAll`
    doesn''t work, so I will call `transform` inline instead:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分比预期的要棘手。我们的`transformAll`的实现不起作用，所以我将内联调用`transform`：
- en: '[PRE68]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We end up with the following test, which passes:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终得到了以下通过的测试：
- en: '[PRE69]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: I have to be honest with you, this was the most difficult code to implement
    correctly so far. So many things can go wrong when working with futures and it's
    not obvious why. The error messages are quite unhelpful, at least for my version
    of g++. The only way I managed to make this work was by going step by step, as
    I showed you in this section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须对你诚实，这是迄今为止实现起来最困难的代码。在处理futures时，有很多事情可能会出错，而且原因并不明显。错误消息相当没有帮助，至少对于我的g++版本来说是这样。我成功让它工作的唯一方法是一步一步地进行，就像我在本节中向你展示的那样。
- en: However, this code sample show an important fact; with the thoroughly thought
    out and tested use of futures, we can parallelize higher-order functions. It is,
    therefore, a possible solution if you need better performance, can use multiple
    cores, and can't wait for the implementation of a parallel running policy in the
    standard. If only for this, I think my efforts were useful!
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个代码示例展示了一个重要的事实；通过深思熟虑和测试使用futures，我们可以并行化高阶函数。因此，如果您需要更好的性能，可以使用多个核心，并且不能等待标准中并行运行策略的实现，这是一个可能的解决方案。即使只是为了这一点，我认为我的努力是有用的！
- en: Since we're talking about asynchronous calls, we could also do a quick pass
    through the world of reactive programming.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在谈论异步调用，我们也可以快速浏览一下响应式编程的世界。
- en: A taste of reactive programming
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式编程的一点体验
- en: '**Reactive programming** is a paradigm for writing code that focuses on processing
    data streams. Imagine having to analyze a stream of temperature values, values
    coming from sensors mounted on self-driving cars, or share values for specific
    companies. In reactive programming, we receive this continuous stream of data
    and run functions that analyze it. Since new data can arrive unpredictably on
    stream, the programming model has to be asynchronous; that is, the main thread
    is continuously waiting for new data, and, when it arrives, the processing is
    delegated to secondary streams. The results are usually collected asynchronously
    as well—either pushed to the user interface, saved in data stores, or passed to
    other data streams.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**响应式编程**是一种编写代码的范式，专注于处理数据流。想象一下需要分析一系列温度值的数据流，来自安装在自动驾驶汽车上的传感器的值，或者特定公司的股票值。在响应式编程中，我们接收这个连续的数据流并运行分析它的函数。由于新数据可能会不可预测地出现在流中，编程模型必须是异步的；也就是说，主线程不断等待新数据，当数据到达时，处理被委托给次要流。结果通常也是异步收集的——要么推送到用户界面，保存在数据存储中，要么传递给其他数据流。'
- en: We've seen that the main focus of functional programming is on data. Therefore,
    it shouldn't be any surprise that functional programming is a good candidate for
    processing real-time data streams. The composability of higher-order functions
    such as `map`, `reduce`, or `filter`, plus the opportunities for parallel processing,
    make the functional style of design a great solution for reactive programming.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，函数式编程的主要重点是数据。因此，函数式编程是处理实时数据流的良好选择并不足为奇。高阶函数的可组合性，如`map`、`reduce`或`filter`，以及并行处理的机会，使得函数式设计风格成为响应式编程的一个很好的解决方案。
- en: We won't go into much detail about reactive programming. Usually, specific libraries
    or frameworks are used that facilitate the implementation of such data flow processing,
    but with the elements we have up to now, we can write a small-scale example.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讨论响应式编程。通常使用特定的库或框架来简化这种数据流处理的实现，但是根据我们目前拥有的元素，我们可以编写一个小规模的示例。
- en: We need a few things. First, a data stream; second, a main thread that receives
    data and immediately passes it to a processing pipeline; and third, a way to get
    the output.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要几样东西。首先，一个数据流；其次，一个接收数据并立即将其传递到处理管道的主线程；第三，一种获取输出的方式。
- en: For the goal of this example, I will simply use the standard input as an input
    stream. We will input numbers from the keyboard and check whether they are prime
    in a reactive manner, thus keeping the main thread responsive at all times. This
    means we'll use the `async` function to create a `future` for every number we
    read from the keyboard. The output will simply be written to the output stream.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本例的目标，我将简单地使用标准输入作为输入流。我们将从键盘输入数字，并以响应式的方式检查它们是否是质数，从而始终保持主线程的响应。这意味着我们将使用`async`函数为我们从键盘读取的每个数字创建一个`future`。输出将简单地写入输出流。
- en: 'We will use the same `is_prime` function as before, but add another function
    that prints to the standard output whether the value is prime or not:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前相同的`is_prime`函数，但添加另一个函数，它将打印到标准输出该值是否是质数。
- en: '[PRE70]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The `main` function is an infinite cycle that reads data from the input stream
    and starts a `future` every time a new value comes in:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '`main`函数是一个无限循环，它从输入流中读取数据，并在每次输入新值时启动一个`future`：'
- en: '[PRE71]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Running this code with some randomly typed values results in the following
    output:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一些随机输入值运行此代码会产生以下输出：
- en: '[PRE72]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: As you can see, the results are returned as soon as possible, but the program
    allows new data to be introduced at all times.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，结果会尽快返回，但程序允许随时引入新数据。
- en: I have to mention that, in order to avoid infinite cycles every time I compile
    the code for this chapter, the reactive example can be compiled and run with `make
    reactive`. You'll have to stop it with an interrupt since it's an infinite loop.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须提到，为了避免每次编译本章的代码时都出现无限循环，响应式示例可以通过`make reactive`编译和运行。你需要用中断来停止它，因为它是一个无限循环。
- en: This is a basic reactive programming example. It can obviously become more complex
    with higher volumes of data, complex pipelines, and the parallelization of each
    pipeline among others. However, we achieved our goal for this section—to give
    you a taste of reactive programming and how we can use functional constructs and
    asynchronous calls to make it work.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基本的响应式编程示例。显然，它可以随着数据量的增加、复杂的流水线和每个流水线的并行化等变得更加复杂。然而，我们已经实现了本节的目标——让你了解响应式编程以及我们如何使用函数构造和异步调用使其工作。
- en: We've discussed a lot about optimizing execution time, looking at various ways
    that help us accomplish faster performance. It's now time to look at a situation
    where we want to reduce the memory usage of our programs.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了如何优化执行时间，看了各种帮助我们实现更快性能的方法。现在是时候看一个情况，我们想要减少程序的内存使用。
- en: Optimizing memory usage
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化内存使用
- en: 'The method we''ve discussed so far, for structuring code in a functional way,
    involves passing multiple times through a collection that is treated as immutable.
    As a result, this can lead to copies of the collection. Let''s look, for example,
    at a simple code sample that uses `transform` to increment all the elements of
    a vector:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的用于以函数方式构造代码的方法涉及多次通过被视为不可变的集合。因此，这可能会导致集合的复制。例如，让我们看一个简单的代码示例，它使用`transform`来增加向量的所有元素：
- en: '[PRE73]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: This implementation leads to a lot of memory allocations. First, the `manyNumbers` vector
    is copied into `transformAll`. Then, `result.push_back()` is automatically called,
    potentially resulting in memory allocation. Finally, the `result` is returned,
    but the initial `manyNumbers` vector is still allocated.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实现会导致大量的内存分配。首先，`manyNumbers`向量被复制到`transformAll`中。然后，`result.push_back()`会自动调用，可能导致内存分配。最后，`result`被返回，但初始的`manyNumbers`向量仍然被分配。
- en: We can improve some of these problems immediately, but it's also worth discussing
    how they compare with other possible optimizations.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即改进其中一些问题，但讨论它们与其他可能的优化方法的比较也是值得的。
- en: 'In order to carry out the tests, we will need to work with large collections
    and a way to measure the memory allocation for a process. The first part is easy—just
    allocate a lot of 64-bit values (the long, long type on my compiler); enough to
    allocate 1 GB of RAM:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行测试，我们需要处理大量的集合，并找到一种测量进程内存分配的方法。第一部分很容易——只需分配大量64位值（在我的编译器上是长长类型）；足够分配1GB的RAM：
- en: '[PRE74]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The second part is a bit more difficult. Fortunately, on my Ubuntu 18.04 system,
    I can watch the memory for a process in a file in `/proc/PID/status`, in which
    PID is the process identifier. With a bit of Bash magic, I can create a `makefile`
    recipe that outputs memory values taken every 0.1 s into a file, like this:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分有点困难。幸运的是，在我的Ubuntu 18.04系统上，我可以在`/proc/PID/status`文件中监视进程的内存，其中PID是进程标识符。通过一些Bash魔法，我可以创建一个`makefile`配方，将每0.1秒获取的内存值输出到一个文件中，就像这样：
- en: '[PRE75]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: You'll notice the `-DNO_MOVE_ITERATOR` argument; this is a compilation directive
    that allows me to compile the same file for different goals, in order to check
    the memory footprint of multiple solutions. This means that our previous test
    is written within an `#if NO_MOVE_ITERATOR` directive.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到`-DNO_MOVE_ITERATOR`参数；这是一个编译指令，允许我为不同的目标编译相同的文件，以检查多个解决方案的内存占用。这意味着我们之前的测试是在`#if
    NO_MOVE_ITERATOR`指令内编写的。
- en: There's only one caveat—since I used the bash `watch` command to generate the
    output, you will need to press a key after running `make memoryConsumptionNoMoveIterator`,
    as well as for every other memory logs recipe.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 只有一个注意事项——因为我使用了bash `watch`命令来生成输出，你需要在运行`make memoryConsumptionNoMoveIterator`后按下一个键，以及对每个其他内存日志配方也是如此。
- en: 'With this set up, let''s improve `transformAll` to use less memory, and look
    at the output. We need to use reference types and allocate memory for the result
    from the beginning, as shown in the following:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个设置，让我们改进`transformAll`以减少内存使用，并查看输出。我们需要使用引用类型，并从一开始就为结果分配内存，如下所示：
- en: '[PRE76]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: As expected, the result of the improvement is that the maximum allocation starts
    from 0.99 GB, but jumps to 1.96 GB, which is roughly double.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的结果是，改进的结果是最大分配从0.99 GB开始，但跳到1.96 GB，大致翻了一番。
- en: We need to put this value in context. Let's first measure what a simple `for`
    loop can do, and compare the result with the same algorithm implemented with `transform`.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将这个值放在上下文中。让我们先测量一下一个简单的`for`循环能做什么，并将结果与使用`transform`实现的相同算法进行比较。
- en: Measuring memory for a simple for loop
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量简单for循环的内存
- en: 'The solution with a `for` loop is very simple:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`for`循环的解决方案非常简单：
- en: '[PRE77]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: When measuring the memory, there's no surprise—the footprint stays at 0.99 GB
    during the whole process. Can we achieve this result with `transform` as well?
    Well, there's one version of `transform` that can modify the collection in place.
    Let's put it to the test.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量内存时，没有什么意外——整个过程中占用的内存保持在0.99 GB。我们能用`transform`也实现这个结果吗？嗯，有一个版本的`transform`可以就地修改集合。让我们来测试一下。
- en: Measure memory for in-place transform
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量就地transform的内存
- en: 'To use `transform` in place, we need to provide the destination iterator parameter, `source.begin()`, as
    follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 要就地使用`transform`，我们需要提供目标迭代器参数`source.begin()`，如下所示：
- en: '[PRE78]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: According to the documentation, this is supposed to change in the same collection;
    therefore, it shouldn't allocate any more memory. As expected, it has the same
    behavior as a simple `for` loop and the memory footprint stays at 0.99 GB for
    the whole duration of the program.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 根据文档，这应该在同一集合中进行更改；因此，它不应该分配更多的内存。如预期的那样，它具有与简单的`for`循环相同的行为，内存占用在整个程序运行期间保持在0.99
    GB。
- en: 'However, you may notice that we''re not returning the value now to avoid a
    copy. I like transform-to-return values though, and we have another option, using
    move semantics:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您可能会注意到我们现在不返回值以避免复制。我喜欢返回值，但我们还有另一个选择，使用移动语义：
- en: '[PRE79]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'To make the call compile, we need to pass in the type of the source when calling
    `transformAllInPlace`, so our test changes to:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使调用编译通过，我们需要在调用`transformAllInPlace`时传递源的类型，因此我们的测试变成了：
- en: '[PRE80]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Let's measure to see if the move semantics helps in any way. The result is as
    expected; the memory footprint stays at 0.99 GB during the whole runtime.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测量一下移动语义是否有所帮助。结果如预期；内存占用在整个运行时保持在0.99 GB。
- en: This leads to an interesting idea. What if we use move semantics in the call
    to `transform`?
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个有趣的想法。如果我们在调用`transform`时使用移动语义呢？
- en: Transform with the move iterator
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用移动迭代器进行transform
- en: 'We can rewrite our `transform` function to use move iterators as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将我们的`transform`函数重写为使用移动迭代器，如下所示：
- en: '[PRE81]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'In theory, what this should do is move values to the destination rather than
    copying them, thus keeping the memory footprint low. To put it to the test, we
    run the same test while recording the memory:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，这应该是将值移动到目标而不是复制它们，从而保持内存占用低。为了测试一下，我们运行相同的测试并记录内存：
- en: '[PRE82]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The result is unexpected; the memory starts at 0.99 GB, rises to 1.96 GB (probably
    after the `transform` call), and then goes back to 0.99 GB (most likely, the result
    of `source.clear()`). I tried multiple variants to avoid this behavior, but couldn't
    find a solution to keep the memory footprint at 0.99 GB. This appears to be a
    problem with the implementation of move iterators; I advise you to test it on
    your compiler to find out whether it works or not.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 结果出乎意料；内存从0.99 GB开始上升到1.96 GB（可能是在`transform`调用之后），然后又回到0.99 GB（很可能是`source.clear()`的结果）。我尝试了多种变体来避免这种行为，但找不到保持内存占用在0.99
    GB的解决方案。这似乎是移动迭代器实现的问题；我建议您在您的编译器上测试一下它是否有效。
- en: Comparing the solutions
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较解决方案
- en: The solutions using in-place or move semantics, while reducing the memory footprint,
    only work when the source data is not required for additional computations. If
    you plan to reuse the data for other computations, there's no way around preserving
    the initial collection. Moreover, it's unclear whether these calls can run in
    parallel; since g++ doesn't yet implement parallel execution policies I can't
    test them, so I will leave this question as an exercise for the reader.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 使用就地或移动语义的解决方案，虽然减少了内存占用，但只有在不需要源数据进行其他计算时才有效。如果您计划重用数据进行其他计算，那么保留初始集合是不可避免的。此外，不清楚这些调用是否可以并行运行；由于g++尚未实现并行执行策略，我无法测试它们，因此我将把这个问题留给读者作为练习。
- en: But what do functional programming languages do in order to reduce memory footprint?
    The answer is very interesting.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 但是函数式编程语言为了减少内存占用做了什么呢？答案非常有趣。
- en: Immutable data structures
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不可变数据结构
- en: Purely functional programming languages use a combination of immutable data
    structures and garbage collection. Each call to modify a data structure creates,
    what seems to be, a copy of the initial data structure, with only one element
    changed. The initial structure is not affected in any way. However, this is done
    using pointers; basically, the new data structure is the same as the initial one,
    except there is a pointer towards the changed value. When discarding the initial
    collection, the old value is no longer used and the garbage collector automatically
    removes it from memory.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 纯函数式编程语言使用不可变数据结构和垃圾回收的组合。修改数据结构的每次调用都会创建一个似乎是初始数据结构的副本，只有一个元素被改变。初始结构不会受到任何影响。然而，这是使用指针来完成的；基本上，新的数据结构与初始数据结构相同，只是有一个指向改变值的指针。当丢弃初始集合时，旧值不再被使用，垃圾收集器会自动将其从内存中删除。
- en: This mechanism takes full advantage of immutability, allowing optimizations
    that are unavailable to C++. Moreover, the implementation is usually recursive,
    which also takes advantage of tail recursion optimization.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制充分利用了不可变性，允许了C++无法实现的优化。此外，实现通常是递归的，这也利用了尾递归优化。
- en: 'However, it is possible to implement such data structures in C++. An example
    is a library called **immer**, which you can find on GitHub at [https://github.com/arximboldi/immer](https://github.com/arximboldi/immer).
    Immer implements a number of immutable collections. We will look at `immer::vector`;
    every time we call an operation that would normally modify the vector (such as
    `push_back`), `immer::vector` returns a new collection. Each value returned can
    be constant, since it never changes. I wrote a small test using immer 0.5.0 in
    the chapter code, showcasing the usage of `immer::vector`, which you can see in
    the following code:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，可以在C++中实现这样的数据结构。一个例子是一个名为**immer**的库，你可以在GitHub上找到它，网址是[https://github.com/arximboldi/immer](https://github.com/arximboldi/immer)。Immer实现了许多不可变的集合。我们将看看`immer::vector`；每当我们调用通常会修改向量的操作（比如`push_back`）时，`immer::vector`会返回一个新的集合。每个返回的值都可以是常量，因为它永远不会改变。我在本章的代码中使用immer
    0.5.0编写了一个小测试，展示了`immer::vector`的用法，你可以在下面的代码中看到：
- en: '[PRE83]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: I will not go into more detail regarding immutable data structures; however,
    I strongly advise you to take a look at the documentation on the *immer* website
    ([https://sinusoid.es/immer/introduction.html](https://sinusoid.es/immer/introduction.html))
    and play with the library.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会详细介绍不可变数据结构；但是，我强烈建议你查看*immer*网站上的文档（[https://sinusoid.es/immer/introduction.html](https://sinusoid.es/immer/introduction.html)）并尝试使用该库。
- en: Summary
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We''ve seen that performance optimization is a complex topic. As C++ programmers,
    we are primed to require more performance from our code; the question we asked
    in this chapter was: is it possible to optimize code written in a functional style?'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，性能优化是一个复杂的话题。作为C++程序员，我们需要从我们的代码中获得更多的性能；本章中我们提出的问题是：是否可能优化以函数式风格编写的代码？
- en: The answer is—yes, if you measure and if you have a clear goal. Do we need a
    specific computation to finish more quickly? Do we need to reduce the memory footprint?
    What area of the application requires the most performance improvements? How much
    do we want to do weird point optimizations that might need rewriting with the
    next compiler, library, or platform version? These are all questions you need
    to answer before moving on to optimize your code.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是——是的，如果你进行了测量，并且有一个明确的目标。我们需要特定的计算更快完成吗？我们需要减少内存占用吗？应用程序的哪个领域需要最大程度的性能改进？我们想要进行怪异的点优化吗，这可能需要在下一个编译器、库或平台版本中进行重写？这些都是你在优化代码之前需要回答的问题。
- en: However, we have seen that functional programming has a huge benefit when it
    comes to using all the cores on a computer. While we're waiting for the standard
    implementation of parallel execution for higher-order functions, we can take advantage
    of immutability by writing our own parallel algorithms. Recursion is another staple
    of functional programming and we can take advantage of tail recursion optimization
    whenever we use it.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们已经看到，当涉及到利用计算机上的所有核心时，函数式编程有巨大的好处。虽然我们正在等待高阶函数的标准实现并行执行，但我们可以通过编写自己的并行算法来利用不可变性。递归是函数式编程的另一个基本特征，每当使用它时，我们都可以利用尾递归优化。
- en: As for memory consumption, immutable data structures implemented in third-party
    libraries, and carefully optimizing the higher-order functions we're using depending
    on their goal, can help us maintain the simplicity of the code, while the complexity
    happens in specific places in the code. Move semantics can be used when we throw
    away the source collections, but remember to check it works with parallel execution.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 至于内存消耗，实现在第三方库中的不可变数据结构，以及根据目标谨慎优化我们使用的高阶函数，都可以帮助我们保持代码的简单性，而复杂性发生在代码的特定位置。当我们丢弃源集合时，可以使用移动语义，但记得检查它是否适用于并行执行。
- en: Above all, I hope you've learned that measuring is the most important part of
    performance optimization. After all, if you don't know where you are and where
    you need to go, how can you make the trip?
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，我希望你已经了解到，测量是性能优化中最重要的部分。毕竟，如果你不知道自己在哪里，也不知道自己需要去哪里，你怎么能进行旅行呢？
- en: We will continue our journey with functional programming by taking advantage
    of data generators for our tests. It's time to look at property-based testing.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续通过利用数据生成器来进行测试来继续我们的函数式编程之旅。现在是时候看看基于属性的测试了。
