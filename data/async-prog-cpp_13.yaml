- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Improving Asynchronous Software Performance
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高异步软件性能
- en: In this chapter, we’ll introduce the performance aspects of asynchronous code.
    Code performance and optimization is a deep and complex subject, and we can’t
    cover everything in just one chapter. We aim to give you a good introduction to
    the subject with some examples of how to measure performance and optimize your
    code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍异步代码的性能方面。代码性能和优化是一个深奥且复杂的话题，我们无法在一章中涵盖所有内容。我们的目标是给你一个关于这个主题的良好介绍，并提供一些如何测量性能和优化代码的示例。
- en: 'This chapter will cover the following key topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下关键主题：
- en: Performance measurement tools with a focus on multithreaded applications
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于多线程应用程序的性能测量工具
- en: What’s false sharing, how to spot it, and how to fix/improve our code
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是伪共享，如何识别它，以及如何修复/改进我们的代码
- en: An introduction to modern CPUs’ memory cache architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代CPU内存缓存架构简介
- en: A review of the **single-producer-single-consumer** ( **SPSC** ) lock-free queue
    we implemented in [*Chapter 5*](B22219_05.xhtml#_idTextAnchor097)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对我们在[*第五章*](B22219_05.xhtml#_idTextAnchor097)中实现的**单生产者单消费者**（**SPSC**）无锁队列的回顾
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Like in the previous chapters, you’ll need a modern C++ compiler that supports
    C++20. We’ll be using GCC 13 and Clang 18. You’ll also need a PC with an Intel/AMD
    multicore CPU running Linux. For this chapter, we used Ubuntu 24.04 LTS running
    on a workstation with a CPU AMD Ryzen Threadripper Pro 5975WX (32 cores). A CPU
    with 8 cores is ideal but 4 cores is enough to run the examples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所述，你需要一个支持C++20的现代C++编译器。我们将使用GCC 13和Clang 18。你还需要一台运行Linux的Intel/AMD多核CPU的PC。对于本章，我们使用了在具有CPU
    AMD Ryzen Threadripper Pro 5975WX（32核心）的工作站上运行的Ubuntu 24.04 LTS。8核心的CPU是理想的，但4核心足以运行示例。
- en: We’ll also be using the Linux **perf** tool. We’ll explain how to get and install
    these tools later in this book.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用Linux **perf**工具。我们将在本书的后面部分解释如何获取和安装这些工具。
- en: 'The examples for this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)
    .'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例可以在本书的GitHub存储库中找到：[https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)。
- en: Performance measurement tools
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测量工具
- en: To learn about the performance of our applications, we need to be able to measure
    it. If there’s one key takeaway from this chapter, it’s to *never estimate or
    guess your code performance* . To know whether your program meets its performance
    requirements (either latency or throughput), you need to measure, measure, and
    then measure again.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解我们应用程序的性能，我们需要能够对其进行测量。如果从这个章节中有一个关键要点，那就是*永远不要估计或猜测你的代码性能*。要知道你的程序是否满足其性能要求（无论是延迟还是吞吐量），你需要测量，测量，然后再测量。
- en: 'Once you have the data from your performance tests, you’ll know the hotspots
    in your code. Maybe they’re related to memory access patterns or thread contention
    (such as, for example, when multiple threads must wait to acquire a lock to access
    a resource). This is where the second most important takeaway comes into play:
    *set a goal when optimizing your application* . Don’t aim to achieve the best
    performance possible because there always will be room for improvement. The right
    thing to do is to set a clear specification with targets such as maximum processing
    time for a transaction or the number of network packets processed per second.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你从性能测试中获得数据，你就会知道代码中的热点。也许它们与内存访问模式或线程竞争（例如，当多个线程必须等待获取锁以访问资源时）有关。这就是第二个最重要的要点发挥作用的地方：*在优化应用程序时设定目标*。不要试图达到可能的最优性能，因为总有改进的空间。正确的方法是设定一个明确的规范，包括目标，例如事务的最大处理时间或每秒处理的网络数据包数量。
- en: With these two main ideas in mind, let’s start with the different methods we
    can use to measure code performance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这两个主要想法的同时，让我们从我们可以用来测量代码性能的不同方法开始。
- en: In-code profiling
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码内分析
- en: A very simple but useful way to start understanding the performance of our code
    is **in-code profiling** , which consists of adding some extra code to measure
    the execution time of some code sections. This method is good to use as a tool
    while we’re writing the code (of course, we need to have access to the source
    code). This will allow us to find some performance issues in our code, as we’ll
    see later in this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 理解代码性能的一个非常简单但实用的方法是 **代码内分析**，它包括添加一些额外的代码来测量某些代码段的执行时间。这种方法在编写代码时作为一个工具使用是很好的（当然，我们需要访问源代码）。这将使我们能够找到代码中的某些性能问题，正如我们将在本章后面看到的。
- en: We’re going to use **std::chrono** as our initial approach to profiling our
    code.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 **std::chrono** 作为我们分析代码的初始方法。
- en: 'The following code snippet shows how we can use **std::chrono** to do some
    basic profiling of our code:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了我们如何使用 **std::chrono** 对代码进行一些基本的性能分析：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, we get two time samples that call **high_resolution_clock::now()** and
    print the time lapse converted into milliseconds. Depending on the time we estimate
    the processing is going to take, we could use either microseconds or seconds,
    for example. With this simple technique, we can easily get an idea of how long
    the processing takes and we can easily compare different options.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们获取了两个时间样本，它们调用了 **high_resolution_clock::now()** 并打印了转换成毫秒的时间间隔。根据我们估计的处理时间，我们可以使用微秒或秒，例如。使用这种简单技术，我们可以轻松地了解处理所需的时间，并且可以轻松地比较不同的选项。
- en: 'Here, **std::chrono::high_resolution_clock** is the clock type that offers
    the highest precision (smallest tick period provided by the implementation). The
    C++ Standard Library allows it to be an alias of either **std::chrono::system_clock**
    or **std::chrono::steady_clock** . libstdc++ has it aliased to **std::chrono::system_clock**
    , whereas libc++ uses **std::chrono::steady_clock** . For the examples in this
    chapter, we’ve used GCC and libstdc++. The clock resolution is 1 nanosecond:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**std::chrono::high_resolution_clock** 是提供最高精度（实现提供的最小滴答周期）的时钟类型。C++ 标准库允许它成为
    **std::chrono::system_clock** 或 **std::chrono::steady_clock** 的别名。libstdc++ 将其别名为
    **std::chrono::system_clock**，而 libc++ 使用 **std::chrono::steady_clock**。在本章的示例中，我们使用了
    GCC 和 libstdc++。时钟分辨率为 1 纳秒：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let’s see a full example of profiling two of the C++ Standard Library
    algorithms to sort vectors – **std::sort** and **std::stable_sort** :'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一个完整的示例，用于分析 C++ 标准库中的两个排序算法——**std::sort** 和 **std::stable_sort** 的性能：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding code generates a vector of normally distributed random numbers
    and then sorts the vector with both **std::sort()** and **std::stable_sort()**
    . Both functions sort the vector, but **std::sort()** uses a combination of quicksort
    and insertion sort algorithms called introsort, while **std::stable_sort()** uses
    merge sort. The sort is *stable* because equivalent keys have the same order in
    both the original and sorted vectors. For a vector of integers, this isn’t important,
    but if the vector has three elements with the same value, after sorting the vector,
    the numbers will be in the same order.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码生成一个正态分布的随机数向量，然后使用 **std::sort()** 和 **std::stable_sort()** 对向量进行排序。这两个函数都排序向量，但
    **std::sort()** 使用了称为 introsort 的快速排序和插入排序算法的组合，而 **std::stable_sort()** 使用了归并排序。排序是
    *稳定的*，因为在原始和排序后的向量中，等效键具有相同的顺序。对于整数向量来说，这并不重要，但如果向量有三个具有相同值的元素，在排序向量后，数字将保持相同的顺序。
- en: 'After running the code, we get the following output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，我们得到以下输出：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this example, **std::stable_sort()** is slower than **std::sort()** .
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，**std::stable_sort()** 的速度比 **std::sort()** 慢。
- en: In this section, we learned about a simple way to measure the running time of
    sections of our code. This method is intrusive and requires that we modify the
    code; it’s mostly used while we develop our applications. In the next section,
    we’re going to introduce another way to measure execution time called micro-benchmarks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了一种简单的方法来测量代码段运行时间。这种方法是侵入性的，需要我们修改代码；它主要在我们开发应用程序时使用。在下一节中，我们将介绍另一种测量执行时间的方法，称为微基准测试。
- en: Code micro-benchmarks
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码微基准测试
- en: Sometimes, we just want to analyze a small section of code in isolation. We
    may need to run it more than once and then get the average running time or run
    it with different input data. In these cases, we can use a benchmark (also called
    a **micro-benchmark** ) library to do just that – execute small parts of our code
    in different conditions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们只想独立分析一小段代码。我们可能需要多次运行它，然后获取平均运行时间或使用不同的输入数据运行它。在这些情况下，我们可以使用基准测试库（也称为
    **微基准测试**）来完成这项工作——在不同的条件下执行我们代码的小部分。
- en: Micro-benchmarks must be used as a guide. Bear in mind that the code runs in
    isolation, and this can give us very different results when we run all the code
    together due to the many complex interactions among different sections of our
    code. Use them carefully and be aware that micro-benchmarks can be misleading.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 微基准测试必须作为指导。请注意，代码在隔离状态下运行，当我们将所有代码一起运行时，由于代码不同部分之间复杂的交互，这可能会给我们带来非常不同的结果。请谨慎使用，并意识到微基准测试可能会误导。
- en: There are many libraries we can use to benchmark our code. We’ll use *Google
    Benchmark* , a very good and well-known library.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用许多库来基准测试我们的代码。我们将使用 *Google Benchmark*，这是一个非常好且广为人知的库。
- en: 'Let’s start by getting the code and compiling the library. To get the code,
    run the following commands:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从获取代码和编译库开始。要获取代码，请运行以下命令：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once we have the code for both the benchmark and Google Test libraries (the
    latter is required to compile the former), we’ll build it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了基准测试和 Google Test 库的代码（后者是编译前者所必需的），我们就会构建它。
- en: 'Create a directory for the build:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为构建创建一个目录：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With that, we’ve created the build directory inside the benchmark directory.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们在基准测试目录内创建了构建目录。
- en: 'Next, we’ll use CMake to configure the build and create all the necessary information
    for **make** :'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 CMake 来配置构建并创建 **make** 所需的所有必要信息：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, run **make** to build and install the libraries:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，运行 **make** 来构建和安装库：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You also need to add the library to the **CmakeLists.txt** file. We’ve done
    that for you in the code for this book.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要将库添加到 **CmakeLists.txt** 文件中。我们已经在本书的代码中为您完成了这项工作。
- en: Once Google Benchmark has been installed, we can work on an example with a few
    benchmark functions to learn how to use the library for some basic benchmarking.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了 Google Benchmark，我们就可以通过一些基准函数的示例来学习如何使用该库进行一些基本的基准测试。
- en: Note that both **std::chrono** and Google Benchmark aren’t specific tools for
    working with asynchronous/multithreaded code and are more like generic tools.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，**std::chrono** 和 Google Benchmark 都不是专门用于处理异步/多线程代码的工具，它们更像是通用工具。
- en: 'This is our first example of using Google Benchmark:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 Google Benchmark 的第一个示例：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We need to include the library header:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要包含库头文件：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'All benchmark functions have the following signature:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所有基准测试函数都具有以下签名：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is a function with one parameter, **benchmark::State& state** , that returns
    **void** . The **benchmark::State** parameter has a dual purpose:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个具有一个参数的函数，**benchmark::State& state**，它返回 **void**。**benchmark::State**
    参数具有双重用途：
- en: '**Controlling the iteration loop** : The **benchmark::State** object is used
    to control how many times a benchmarked function or piece of code should be executed.
    This helps measure the performance accurately by repeating the test enough times
    to minimize variability and collect meaningful data.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制迭代循环**：**benchmark::State** 对象用于控制被基准测试的函数或代码应该执行多少次。通过重复测试足够多次以最小化变异性并收集有意义的数据，这有助于准确测量性能。'
- en: '**Measuring time and statistics** : The **state** object keeps track of how
    long the benchmarked code takes to run, and it provides mechanisms to report metrics
    such as elapsed time, iterations, and custom counters.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测量时间和统计信息**：**state** 对象跟踪基准测试代码的运行时间，并提供报告指标（如经过时间、迭代次数和自定义计数器）的机制。'
- en: 'We’ve implemented three functions to benchmark adding elements to a **std::vector**
    sequence in different ways: the first function uses **std::vector::push_back**
    , the second uses **std::vector::emplace_back** , and the third uses **std::vector::insert**
    . The first two functions add elements at the end of the vector, while the third
    function adds elements at the beginning of the vector.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了三个函数来以不同的方式基准测试向 **std::vector** 序列添加元素：第一个函数使用 **std::vector::push_back**，第二个使用
    **std::vector::emplace_back**，第三个使用 **std::vector::insert**。前两个函数在向量的末尾添加元素，而第三个函数在向量的开头添加元素。
- en: 'Once we’ve implemented the benchmark functions, we need to tell the library
    that they must be run as a benchmark:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们实现了基准测试函数，我们需要告诉库它们必须作为基准测试运行：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We use the **BENCHMARK** macro to do this. For the benchmarks in this example,
    we set the number of elements to be inserted into the vector in each iteration.
    The range goes from **1** to **1000** and each iteration will insert eight times
    the number of elements of the previous iteration until it reaches the maximum.
    In this case, it will insert 1, 8, 64, 512, and 1,000 elements.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 **BENCHMARK** 宏来完成这项工作。对于本例中的基准测试，我们设置了每次迭代要插入向量中的元素数量。范围从 **1** 到 **1000**，每次迭代将插入前一次迭代元素数量的八倍，直到达到最大值。在这种情况下，它将插入1、8、64、512和1000个元素。
- en: 'When we run our first benchmark program, we get the following output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行第一个基准测试程序时，我们得到以下输出：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'First, the program prints information about the execution of the benchmark:
    the date and time, the name of the executable, and information about the CPU it’s
    running on.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，程序打印出基准测试执行的信息：日期和时间、可执行文件名称以及它所运行的CPU信息。
- en: 'Take a look at the following line:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 看看以下这一行：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This line gives us an estimate of the CPU load: from 0.0 (no load at all or
    very low load) to 1.0 (fully loaded). The three numbers correspond to the CPU
    load for the last 5, 10, and 15 minutes, respectively.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行给出了CPU负载的估计：从0.0（完全没有负载或非常低的负载）到1.0（完全加载）。这三个数字分别对应于过去5、10和15分钟的CPU负载。
- en: 'After printing the CPU load information, the benchmark prints the results of
    each iteration. Here’s an example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在打印CPU负载信息后，基准测试会打印出每次迭代的成果。以下是一个示例：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This means that **BM_vector_push_back** was called 6,021,740 times (the number
    of iterations) while inserting 64 elements into the vector.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 **BM_vector_push_back** 被调用了6,021,740次（迭代次数），在向量的插入过程中插入了64个元素。
- en: 'The **Time** and **CPU** columns give us the average time for each iteration:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间** 和 **CPU** 列给出了每次迭代的平均时间：'
- en: '**Time** : This is the real time that’s elapsed from the beginning to the end
    of each benchmark execution. It includes everything that happens during the benchmark:
    CPU computation, I/O operations, context switches, and more.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间**：这是从基准测试开始到结束所经过的真正时间。它包括基准测试期间发生的所有事情：CPU计算、I/O操作、上下文切换等。'
- en: '**CPU time** : This is the amount of time the CPU spent processing the instructions
    of the benchmark. It can be smaller than or equal to **Time** .'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU时间**：这是CPU处理基准测试指令所花费的时间。它可以小于或等于 **时间**。'
- en: In our benchmark, because the operations are simple, we can see that **Time**
    and **CPU** are mostly the same.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的基准测试中，因为操作很简单，我们可以看到 **时间** 和 **CPU** 大多数情况下是相同的。
- en: 'Looking at the results, we can come to the following conclusions:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看结果，我们可以得出以下结论：
- en: For simple objects such as 32-bit integers, both **push_back** and **emplace_back**
    take the same amount of time.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于简单的对象，例如32位整数，**push_back** 和 **emplace_back** 花费的时间相同。
- en: Here, **insert** takes the same amount of time as **push_back** / **emplace_back**
    for a small number of elements but from 64 elements onwards, it takes considerably
    more time. This is because **insert** must copy all the elements after each insertion
    (we insert the elements at the beginning of the vector).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，对于少量元素，**insert** 与 **push_back** / **emplace_back** 花费的时间相同，但从64个元素开始，它需要更多的时间。这是因为每次插入后，**insert**
    必须复制向量中所有后续的元素（我们在向量的开头插入元素）。
- en: 'The following example also sorts a **std::vector** sequence, but this time,
    we’ll use a micro-benchmark to measure execution time:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例也排序了一个 **std::vector** 序列，但这次，我们将使用微基准测试来测量执行时间：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code generates a vector of random numbers. Here, we run two benchmark
    functions to sort the vector: one using **std::sort** and another using **std::stable_sort**
    . Note that we use two copies of the same vector, so the input is the same for
    both functions.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成一个随机数字的向量。在这里，我们运行两个基准测试函数来排序向量：一个使用 **std::sort**，另一个使用 **std::stable_sort**。请注意，我们使用了同一个向量的两个副本，所以两个函数的输入是相同的。
- en: The following line of code uses the **BENCHMARK_CAPTURE** macro. This macro
    allows us to pass parameters to our benchmark functions – in this case, a reference
    to **std::vector** (we pass by reference to avoid copying the vector and impacting
    the benchmark result).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行使用了 **BENCHMARK_CAPTURE** 宏。这个宏允许我们将参数传递给我们的基准测试函数——在这种情况下，一个对 **std::vector**
    的引用（我们通过引用传递以避免复制向量并影响基准测试结果）。
- en: 'We specify the results to be in milliseconds instead of nanoseconds:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定结果以毫秒为单位而不是纳秒：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here are the results of the benchmark:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是基准测试的结果：
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The results are consistent with the ones we got measuring time using **std::chrono**
    .
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 结果与我们使用 **std::chrono** 测量时间得到的结果一致。
- en: 'For our last Google Benchmark example, we’ll create a thread ( **std::thread**
    ):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们最后的 Google Benchmark 示例，我们将创建一个线程（**std::thread**）：
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This example is simple: **BM_create_terminate_thread** creates a thread (doing
    nothing, just returning 0) and waits for it to end ( **thread.join())** . We run
    **2000** iterations to get an estimation of the time it takes to create a thread.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子很简单：**BM_create_terminate_thread** 创建一个线程（什么都不做，只是返回 0）并等待它结束（**thread.join()**）。我们运行
    **2000** 次迭代以估计创建线程所需的时间。
- en: 'The results are as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In this section, we learned how to use the Google Benchmark library to create
    micro-benchmarks to measure the execution time of some functions. Again, micro-benchmarks
    are just an approximation and due to the isolated nature of the code being benchmarked,
    they may be misleading. Use them carefully.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何使用 Google Benchmark 库创建微基准来测量某些函数的执行时间。再次强调，微基准只是一个近似值，由于被基准测试的代码的隔离性质，它们可能会有误导性。请谨慎使用。
- en: The Linux perf tool
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux 的 **perf** 工具
- en: Using **std::chrono** in our code or a micro-benchmark library such as Google
    Benchmark requires gaining access to the code to be profiled and also being able
    to modify it by either adding extra calls to measure the execution time of code
    sections or running small snippets as micro-benchmark functions.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中使用 **std::chrono** 或像 Google Benchmark 这样的微基准库需要获取要分析代码的访问权限，并且能够通过添加额外的调用来测量代码段的执行时间或运行小的代码片段作为微基准函数来修改它。
- en: With the Linux **perf** tool, we can analyze the execution of a program without
    changing any of its code.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Linux 的 **perf** 工具，我们可以分析程序的执行，而不需要更改其任何代码。
- en: The Linux **perf** tool is a powerful, flexible, and widely used performance
    analysis and profiling utility for Linux systems. It provides detailed insights
    into system performance at the kernel and user space levels.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Linux 的 **perf** 工具是一个强大、灵活且广泛使用的性能分析和分析工具，适用于 Linux 系统。它提供了对内核和用户空间级别的系统性能的详细洞察。
- en: Let’s consider the main uses of **perf** .
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑 **perf** 的主要用途。
- en: First, we have **CPU profiling** . The **perf** tool allows you to capture the
    execution profile of a process, measuring which functions consume most of the
    CPU time. This can be very useful in helping to identify CPU-intensive parts of
    the code and bottlenecks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们有 **CPU 分析**。**perf** 工具允许你捕获进程的执行配置文件，测量哪些函数消耗了最多的 CPU 时间。这可以帮助识别代码中 CPU
    密集的部分和瓶颈。
- en: 'The following command line will run **perf** on the small **13x07-thread_contention**
    program we wrote to illustrate the basics of the tool. The code for this application
    can be found in this book’s GitHub repository:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令行将在我们编写的用于说明工具基本原理的小型 **13x07-thread_contention** 程序上运行 **perf**。此应用程序的代码可以在本书的
    GitHub 仓库中找到：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The **--call-graph** option records the data of the function call hierarchy
    in a file called **perf.data** , while the **dwarf** option instructs **perf**
    to use the dwarf file format to debug symbols (to get the function names).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**--call-graph** 选项将函数调用层次结构的数据记录在名为 **perf.data** 的文件中，而 **dwarf** 选项指示 **perf**
    使用 dwarf 文件格式来调试符号（以获取函数名称）。'
- en: 'After the previous command, we must run the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的命令之后，我们必须运行以下命令：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This will dump the recorded data (including the call stack) into a text file
    called **out.perf** .
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把记录的数据（包括调用栈）输出到名为 **out.perf** 的文本文件中。
- en: 'Now, we need to convert the text file into a picture with the call graph. To
    do this, we can run the following command:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将文本文件转换为带有调用图的图片。为此，我们可以运行以下命令：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This will generate a file called **callgraph.dot** that can be visualized using
    Graphviz.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个名为 **callgraph.dot** 的文件，可以使用 Graphviz 进行可视化。
- en: 'You may need to install **gprof2dot** . For this, you need Python installed
    on your PC. Run the following command to install **gprof2dot** :'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要安装 **gprof2dot**。为此，你需要在你的电脑上安装 Python。运行以下命令来安装 **gprof2dot**：
- en: '[PRE23]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Install Graphviz too. In Ubuntu, you can do this like so:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要安装 Graphviz。在 Ubuntu 上，你可以这样做：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, you can generate the **callgraph.png** picture by running the following
    command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以通过运行以下命令生成 **callgraph.png** 图片：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Another very common way to visualize the call graph of a program is by using
    a flame graph.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种非常常见的可视化程序调用图的方法是使用火焰图。
- en: 'To generate a flame graph, clone the **FlameGraph** repository:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成火焰图，请克隆**FlameGraph**仓库：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the **FlameGraph** folder, you’ll find the scripts to generate the flame
    graphs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在**FlameGraph**文件夹中，您将找到生成火焰图的脚本。
- en: 'Run the following command:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令：
- en: '[PRE27]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This command will collapse the stack traces into a format that can be used
    by the FlameGraph tool. Now, run the following command:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将堆栈跟踪折叠成火焰图工具可以使用的形式。现在，运行以下命令：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You can visualize the flame graph with a web browser:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用网页浏览器可视化火焰图：
- en: "![Figure 13.1: \uFEFFAn overview of a flame graph](img/B22219_13_1.jpg)"
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1：火焰图的概述](img/B22219_13_1.jpg)'
- en: 'Figure 13.1: An overview of a flame graph'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：火焰图的概述
- en: Now, let’s learn how to gather the performance statistics of a program.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何收集程序的性能统计数据。
- en: 'The following command will show the number of instructions that have been executed
    and CPU cycles that were used during the execution of **13x05-sort_perf** . The
    number of instructions per cycle is the average number of instructions the CPU
    executes in each clock cycle. This metric is only useful when we microbenchmark
    or measure short parts of the code. For this example, we can see that the CPU
    is executing one instruction per cycle, which is average for a modern CPU. In
    multithreaded code, we can get a much bigger number due to the parallel nature
    of the execution, but this metric is generally used to measure and optimize code
    executed in a single CPU core. The number must be interpreted as how busy we keep
    the CPU because it depends on many factors, such as the number of memory reads/writes,
    memory access patterns (linear consecutive/no linear), level of branching in the
    code, and so on:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将显示在**13x05-sort_perf**执行期间执行的指令数量和使用的CPU周期。每周期指令数是CPU在每个时钟周期中执行的指令的平均数。此指标仅在微基准测试或测量代码的短部分时才有用。对于此示例，我们可以看到CPU每个周期执行一条指令，这对于现代CPU来说是平均的。在多线程代码中，由于执行的并行性，我们可以得到一个更大的数字，但此指标通常用于测量和优化在单个CPU核心中执行的代码。此数字必须解释为我们如何保持CPU忙碌，因为它取决于许多因素，例如内存读取/写入的数量、内存访问模式（线性连续/非线性）、代码中的分支级别等：
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After running the preceding command, we get the following result:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的命令后，我们得到了以下结果：
- en: '[PRE30]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Running the following command, you can get the list of all the predefined events
    you can analyze with **perf** :'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令，您可以获取所有预定义事件的列表，您可以使用**perf**分析这些事件：
- en: '[PRE31]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let’s do a few more:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再进行几个操作：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The previous command measures the number of branch instructions that have been
    executed. We get the following result:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的命令测量了已执行的分支指令的数量。我们得到了以下结果：
- en: '[PRE33]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we can see that a sixth of the instructions that were executed are branching
    instructions, which is expected in a program that sorts large vectors.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，执行指令中有六分之一是分支指令，这在排序大型向量的程序中是预期的。
- en: As mentioned previously, measuring the level of branching in our code is important,
    especially for short sections of the code (to avoid interactions that can impact
    what’s being measured). A CPU will run instructions much faster if there are no
    branches or there are just a few. The main issue with branches is that the CPU
    may need to rebuild the pipeline and that can be costly, especially if branches
    are in inner/critical loops.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，测量代码中的分支级别很重要，尤其是在代码的短部分（以避免可能影响测量的交互）。如果没有分支或只有很少的分支，CPU将运行指令的速度会更快。分支的主要问题是CPU可能需要重建流水线，这可能会很昂贵，尤其是如果分支在内部/关键循环中。
- en: 'The following command will report the number of L1 cache data accesses (we
    will see the CPU cache in the next section):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将报告L1缓存数据访问的数量（我们将在下一节中看到CPU缓存）：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We get the following result:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下结果：
- en: '[PRE35]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Let’s go back to our lock contention example and gather some useful statistics
    with **perf** .
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的锁竞争示例，并使用**perf**收集一些有用的统计数据。
- en: Another benefit of using **perf** is **CPU migrations** – that is, the number
    of times a thread was moved from one CPU core to another. Thread migration between
    cores can degrade cache performance since threads lose the benefit of cached data
    when moving to a new core (more on caches in the next section).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**perf**的另一个好处是**CPU迁移**——也就是说，线程从一个CPU核心移动到另一个核心的次数。线程在核心之间的迁移可能会降低缓存性能，因为当线程移动到新的核心时，会失去缓存数据的优势（关于缓存的更多内容将在下一节中介绍）。
- en: 'Let’s run the following command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行以下命令：
- en: '[PRE36]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This results in the following output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下输出：
- en: '[PRE37]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s look at another advantage of using **perf** : **context switches** .
    It counts the number of context switches (how many times a thread is swapped out
    and another thread is scheduled) during the execution. High-context switching
    can indicate that too many threads are competing for CPU time, leading to performance
    degradation.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用 **perf** 的另一个优点：**上下文切换**。它计算执行过程中的上下文切换次数（线程被交换出去和另一个线程被调度的次数）。高上下文切换可能表明太多线程正在竞争CPU时间，从而导致性能下降。
- en: 'Let’s run the following command:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行以下命令：
- en: '[PRE38]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This results in the following output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '[PRE39]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: That’s a wrap on this section. Here, we introduced the Linux **perf** tool and
    some of its applications. We’ll study the CPU memory cache and false sharing in
    the next section.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这一节的内容到此结束。在这里，我们介绍了Linux **perf** 工具及其一些应用。我们将在下一节研究CPU内存缓存和假共享。
- en: False sharing
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假共享
- en: In this section, we’ll study a common issue with multithreaded applications
    called **false sharing** .
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究多线程应用程序中一个常见的问题，称为 **假共享**。
- en: We already know that the ideal implementation of a multithreaded application
    is minimizing the data that’s shared among its different threads. Ideally, we
    should share data just for read access because in that case, we don’t need to
    synchronize the threads to access the shared data and thus we don’t need to pay
    the runtime cost and deal with issues such as deadlock and livelock.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道，多线程应用程序的理想实现是尽量减少不同线程之间共享的数据。理想情况下，我们应该只为读取访问共享数据，因为在这种情况下，我们不需要同步线程来访问共享数据，因此我们不需要支付运行时成本，也不需要处理死锁和活锁等问题。
- en: 'Now, let’s consider a simple example: four threads run in parallel, generate
    random numbers, and calculate their sum. Each thread works independently, generating
    random numbers and calculating the sum stored in a variable just written by itself.
    This is the ideal (though for this example, a bit contrived) application, with
    threads working independently without any shared data.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑一个简单的例子：四个线程并行运行，生成随机数，并计算它们的总和。每个线程独立工作，生成随机数并计算存储在它刚刚写入的变量中的总和。这是一个理想的应用（尽管对于这个例子来说有点牵强），线程独立工作，没有任何共享数据。
- en: 'The following code is the full source for the example we’re going to analyze
    in this section. You can refer to it while you read the explanations:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是我们将在本节中分析的示例的完整源代码。在阅读解释时，你可以参考它：
- en: '[PRE40]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If you compile and run the previous code, you’ll get an output similar to the
    following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你编译并运行前面的代码，你会得到类似于以下输出的结果：
- en: '[PRE41]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The program just calls two functions: **sum_random_unaligned** and **sum_random_aligned**
    . Both functions do the same: they create eight threads, and each thread generates
    random numbers and calculates their sum. No data is shared among the threads.
    You can see that the functions are pretty much the same and the main difference
    is that **sum_random_unaligned** uses the following data structure to store the
    sum of the generated random numbers:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 程序仅调用两个函数：**sum_random_unaligned** 和 **sum_random_aligned**。这两个函数做的是同一件事：它们创建八个线程，每个线程生成随机数并计算它们的总和。线程之间没有共享数据。你可以看到这两个函数几乎相同，主要区别在于
    **sum_random_unaligned** 使用以下数据结构来存储生成的随机数的总和：
- en: '[PRE42]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The **sum_random_aligned** function uses a slightly different one:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**sum_random_aligned** 函数使用了一个稍微不同的方法：'
- en: '[PRE43]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The only difference is the use of **alignas(64)** in informing the compiler
    that the data structure instances must be aligned at a 64-byte boundary.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是使用了 **alignas(64)** 来通知编译器，数据结构实例必须在64字节边界上对齐。
- en: We can see that the difference in performance is quite dramatic because the
    threads are performing the same tasks. Just aligning the variables written by
    each thread to a 64-byte boundary greatly improves performance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，性能差异非常明显，因为线程正在执行相同的任务。只需将每个线程写入的变量对齐到64字节边界，就可以大大提高性能。
- en: To understand why this is happening, we need to consider a feature of modern
    CPUs – the memory cache.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么会发生这种情况，我们需要考虑现代CPU的一个特性——内存缓存。
- en: CPU memory cache
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU内存缓存
- en: Modern CPUs are very fast at computing and when we want to achieve maximum performance,
    memory access is the main bottleneck. A good estimate for memory access is about
    150 nanoseconds. In that time, our 3.6 GHz CPU has gone through 540 clock cycles.
    As a rough estimate, if the CPU executes an instruction every two cycles, that’s
    270 instructions. For a normal application, memory access is an issue, even though
    the compiler may reorder the instructions it generates and the CPU may also reorder
    the instructions to optimize memory access and try to run as many instructions
    as possible.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现代CPU在计算方面非常快，当我们想要达到最大性能时，内存访问是主要的瓶颈。内存访问的良好估计约为150纳秒。在这段时间内，我们的3.6 GHz CPU已经通过了540个时钟周期。作为一个粗略估计，如果CPU每两个周期执行一条指令，那么就是270条指令。对于一个普通应用程序，内存访问是一个问题，即使编译器可能会重新排序它生成的指令，CPU也可能重新排序指令以优化内存访问并尽可能多地运行指令。
- en: Therefore, to improve the performance of modern CPUs, we have what’s called
    a **CPU cache** or **memory cache** , which is memory in the chip to store both
    data and instructions. This memory is much faster than RAM and allows the CPU
    to retrieve data much faster, significantly boosting overall performance.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了提高现代CPU的性能，我们有了所谓的**CPU缓存**或**内存缓存**，这是芯片中的内存，用于存储数据和指令。这种内存比RAM快得多，允许CPU更快地检索数据，从而显著提高整体性能。
- en: As an example of a real-life cache, think about a cook. They need some ingredients
    to make lunch for their restaurant clients. Now, imagine that they only buy those
    ingredients when a client comes to the restaurant and orders their food. That
    will be very slow. They can also go to the supermarket and buy ingredients for,
    say, a full day. Now, they can cook for all their clients and serve them their
    meals in a much shorter period.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 作为现实生活中的缓存示例，想想一个厨师。他们需要一些原料来为他们的餐厅客户准备午餐。现在，想象一下，他们只有在客户来到餐厅并点餐时才购买这些原料。这将非常慢。他们也可以去超市购买一天的原料，比如。现在，他们可以为所有客户烹饪，并在更短的时间内为他们提供餐点。
- en: 'CPU caches follow the same concept: when the CPU needs to access a variable,
    say a 4-byte integer, it reads 64 bytes (this size may be different, depending
    on the CPU, but most modern CPUs use that size) of contiguous memory *just in
    case* it may need to access more contiguous data.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: CPU缓存遵循相同的概念：当CPU需要访问一个变量时，比如一个4字节的整数，它会读取64字节（这个大小可能因CPU而异，但大多数现代CPU使用这个大小）的连续内存，*以防万一*它可能需要访问更多的连续数据。
- en: Linear memory data structures such as **std::vector** will perform better from
    a memory access point of view because in these cases, the cache can be a big performance
    improvement. For other types of data structures, such as **std::list** , this
    won’t be the case. Of course, this is just about optimizing cache use.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 线性内存数据结构，如**std::vector**，在内存访问方面将表现得更好，因为这些情况下，缓存可以大幅提高性能。对于其他类型的数据结构，如**std::list**，则不会是这样。当然，这仅仅是关于优化缓存使用。
- en: You may be wondering why if in-CPU cache memory is so good, isn’t all memory
    like that? The answer is cost. Cache memory is very fast (much faster than RAM),
    but it’s also very expensive.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道，如果CPU缓存内存如此之好，为什么所有内存都像那样？答案是成本。缓存内存非常快（比RAM快得多），但它也非常昂贵。
- en: 'Modern CPUs employ a hierarchical cache structure, typically consisting of
    three levels called L1, L2, and L3:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现代CPU采用分层缓存结构，通常由三个级别组成，称为L1、L2和L3：
- en: '**L1 cache** is the smallest and fastest. It’s also the closest to the CPU,
    as well as the most expensive. It’s often split into two parts: an instruction
    cache for storing instructions and a data cache for storing data. The typical
    sizes are 64 Kb split into 32 Kb for instructions and 32 Kb for data. The typical
    access time to the L1 cache is between 1 and 3 nanoseconds.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L1缓存**是最小和最快的。它也是最接近CPU的，同时也是最昂贵的。它通常分为两部分：一个指令缓存用于存储指令，一个数据缓存用于存储数据。典型的大小是64
    Kb，分为32 Kb用于指令和32 Kb用于数据。L1缓存的典型访问时间在1到3纳秒之间。'
- en: '**L2 cache** is larger and slightly slower than L1, but still much faster than
    RAM. Typical L2 cache sizes are between 128 Kb and 512 Kb (the CPU used to run
    the examples in this chapter has 512 Kb of L2 cache per core). Typical access
    times for L2 cache are about 3 to 5 nanoseconds.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L2缓存**比L1大，速度略慢，但仍然比RAM快得多。典型的L2缓存大小在128 Kb到512 Kb之间（本章中使用的CPU每个核心有512 Kb的L2缓存）。典型的L2缓存访问时间约为3到5纳秒。'
- en: '**L3 cache** is the largest and slowest of the three. The L1 and L2 caches
    are per core (each core has its own L1 and L2 cache), but L3 is shared by more
    than one core. Our CPU has 32 Mb of L3 cache shared by each group of eight cores.
    The typical access time is about 10 to 15 nanoseconds.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L3 缓存**是三者中最大且速度最慢的。L1 和 L2 缓存是每个核心的（每个核心都有自己的 L1 和 L2 缓存），但 L3 是多个核心共享的。我们的
    CPU 每组八个核心共享 32 Mb 的 L3 缓存。典型的访问时间大约是 10 到 15 纳秒。'
- en: With that, let’s turn our attention to another important concept related to
    memory cache.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，让我们将注意力转向与内存缓存相关的一个重要概念。
- en: Cache coherency
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存一致性
- en: The CPU doesn’t access RAM directly. This access is always done through the
    cache, and RAM is accessed only if the CPU doesn’t find the data required in the
    cache. In multi-core systems, each core having its own cache means that one piece
    of RAM may be present in the cache of multiple cores at the same time. These copies
    need to be synchronized all the time; otherwise, computation results could be
    incorrect.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 不直接访问 RAM。这种访问总是通过缓存进行的，只有当 CPU 在缓存中找不到所需的数据时才会访问 RAM。在多核系统中，每个核心都有自己的缓存意味着同一块
    RAM 可能同时存在于多个核心的缓存中。这些副本需要始终同步；否则，计算结果可能会不正确。
- en: So far, we’ve seen that each core has its own L1 cache. Let’s go back to our
    example and think about what happens when we run the function using non-aligned
    memory.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到每个核心都有自己的 L1 缓存。让我们回到我们的例子，思考一下当我们使用非对齐内存运行函数时会发生什么。
- en: In this case, each instance of **result_data** is 8 bytes. We create an array
    of 8 instances of **result_data** , one for each thread. The total memory that’s
    occupied will be 64 bytes and all the instances will be contiguous in memory.
    Every time a thread updates the sum of random numbers, it changes the value that’s
    stored in the cache. Remember that the CPU will always read and write 64 bytes
    in one go (something called a **cache line** – you can think of it as the smallest
    memory access unit). All the variables are in the same cache line and even if
    the threads don’t share them (each thread has its own variable – **sum** ), the
    CPU doesn’t know that and needs to make the changes visible for all the cores.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，每个 **result_data** 实例是 8 字节。我们创建了一个包含 8 个 **result_data** 实例的数组，每个线程一个。总共占用的内存将是
    64 字节，所有实例在内存中都是连续的。每次线程更新随机数的总和时，它都会改变存储在缓存中的值。记住，CPU 总是会一次读取和写入 64 字节（这被称为**缓存行**——你可以将其视为最小的内存访问单元）。所有变量都在同一个缓存行中，即使线程没有共享它们（每个线程都有自己的变量——**sum**），CPU
    也不知道这一点，需要使更改对所有核心可见。
- en: Here, we have 8 cores, and each core is running a thread. Each core has loaded
    64 bytes of memory from RAM into the L1 cache. Since the threads only read the
    variables, everything is OK, but as soon as one thread modifies its variable,
    the contents of the cache line are invalidated.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有 8 个核心，每个核心都在运行一个线程。每个核心已经从 RAM 中加载了 64 字节的内存到 L1 缓存中。由于线程只读取变量，所以一切正常，但一旦某个线程修改了它的变量，缓存行的内容就会被无效化。
- en: Now, because the cache line is invalid in the remaining 7 cores, the CPU needs
    to propagate the changes to all the cores. As mentioned previously, even if the
    threads don’t share the variables, the CPU can’t possibly know that, and it updates
    all the cache lines for all the cores to keep the values consistent. This is called
    cache coherency. If the threads shared the variables, it would be incorrect not
    to propagate the changes to all the cores.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于剩余的 7 个核心中的缓存行无效，CPU 需要将更改传播到所有核心。如前所述，即使线程没有共享变量，CPU 也不可能知道这一点，并且需要更新所有核心的所有缓存行以保持值的一致性。这被称为缓存一致性。如果线程共享变量，那么不将更改传播到所有核心是不正确的。
- en: 'In our example, the cache coherency protocol generates quite a lot of traffic
    inside the CPU because all the threads *share the memory region where the variables
    reside* , even though they don’t from the program’s point of view. This is the
    reason we call it false sharing: the variables are shared because of the way the
    cache and the cache coherency protocol work.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，缓存一致性协议在 CPU 内部产生了相当多的流量，因为所有线程都*共享变量所在的内存区域*，尽管从程序的角度来看它们并不共享。这就是我们称之为伪共享的原因：变量之所以共享，是因为缓存和缓存一致性协议的工作方式。
- en: When we align the data to a 64-byte boundary, each instance occupies 64 bytes.
    This guarantees that they are in their own cache line and no cache coherency traffic
    is necessary because in this case, there’s no data sharing. In this second case,
    performance is much better.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将数据对齐到64字节边界时，每个实例占用64字节。这保证了它们位于自己的缓存行中，并且不需要缓存一致性流量，因为在这种情况下，没有数据共享。在这种情况下，性能要好得多。
- en: Let’s use **perf** to confirm that this is really happening.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用**perf**来确认这一点是否真的发生了。
- en: 'First, we run **perf** while executing **sum_random_unaligned** . We want to
    see how many times the program accesses the cache and how many times there’s a
    cache miss. Each time the cache needs to be updated because it contains data that’s
    also in a cache line in another core counts as a cache miss:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在执行**sum_random_unaligned**时运行**perf**。我们想看看程序访问缓存的次数和缓存未命中的次数。每次缓存需要更新，因为它包含的数据也在另一个核心的缓存行中，都算作一次缓存未命中：
- en: '[PRE44]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We obtain these results:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下结果：
- en: '[PRE45]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Most of the cache references are cache misses. This is expected because of false
    sharing.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数缓存引用都是缓存未命中。这是预期的，因为伪共享。
- en: 'Now, if we run **sum_random_aligned** , the results are quite different:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们运行**sum_random_aligned**，结果会有很大不同：
- en: '[PRE46]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The number of both cache references and cache misses is much smaller. This is
    because there’s no need to constantly update the caches in all the cores to keep
    cache coherency.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存引用和缓存未命中的数量都小得多。这是因为不需要不断更新所有核心的缓存以保持缓存一致性。
- en: 'In this section, we saw one of the most common performance issues of multithreaded
    code: false sharing. We saw a function example with and without false sharing
    and the negative impact false sharing has on performance.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了多线程代码中最常见的性能问题之一：伪共享。我们看到了一个带有和没有伪共享的函数示例，以及伪共享对性能的负面影响。
- en: In the next section, we’ll go back to the SPSC lock-free queue we implemented
    in [*Chapter 5*](B22219_05.xhtml#_idTextAnchor097) and improve its performance.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将回到我们在[*第五章*](B22219_05.xhtml#_idTextAnchor097)中实现的SPSC无锁队列，并提高其性能。
- en: SPSC lock-free queue
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SPSC无锁队列
- en: 'In [*Chapter 5*](B22219_05.xhtml#_idTextAnchor097) , we implemented an SPSC
    lock-free queue as an example of how to synchronize access to a data structure
    from two threads without using locks. This queue is accessed by just two threads:
    one producer pushing data to the queue and one consumer popping data from the
    queue. It’s the easiest queue to synchronize.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B22219_05.xhtml#_idTextAnchor097)中，我们实现了一个SPSC无锁队列，作为如何从两个线程同步访问数据结构的示例，而不使用锁。这个队列仅由两个线程访问：一个生产者将数据推送到队列，一个消费者从队列中弹数据。这是最容易同步的队列。
- en: 'We used two atomic variables to represent the head (buffer index to read) and
    tail (buffer index to write) of the queue:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了两个原子变量来表示队列的头部（读取缓冲区索引）和尾部（写入缓冲区索引）：
- en: '[PRE47]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To avoid false sharing, we can change the code to the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免伪共享，我们可以将代码更改为以下内容：
- en: '[PRE48]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: After this change, we can run the code we implemented to measure the number
    of operations per second (push/pop) performed by the producer and consumer threads.
    The code can be found in this book’s GitHub repository.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次更改之后，我们可以运行我们实现的代码来测量生产者和消费者线程每秒执行的操作数（推/弹）。代码可以在本书的GitHub仓库中找到。
- en: 'Now, we can run **perf** :'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行**perf**：
- en: '[PRE49]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We’ll get the following results:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下结果：
- en: '[PRE50]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Here, we can see that the queue is capable of about 100 million operations per
    second. Also, there are roughly 41% cache misses.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到队列每秒能够处理大约1亿次操作。此外，大约有41%的缓存未命中。
- en: Let’s review how the queue works. Here, the producer is the only thread writing
    **tail_** and the consumer is the only thread writing **head_** . Still, both
    threads need to read **tail_** and **head_** . We’ve declared both atomic variables
    as **aligned(64)** so that they’re guaranteed to be in different cache lines and
    there’s no false sharing. However, there is true sharing. True sharing also generates
    cache coherency traffic.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下队列的工作原理。在这里，生产者是唯一写入**tail_**的线程，消费者是唯一写入**head_**的线程。尽管如此，两个线程都需要读取**tail_**和**head_**。我们已经将这两个原子变量声明为**aligned(64)**，以确保它们保证位于不同的缓存行中，从而没有伪共享。然而，存在真正的共享。真正的共享也会生成缓存一致性流量。
- en: True sharing means that both threads have shared access to both variables, even
    if each variable is just written by one thread (and always the same thread). In
    this case, to improve performance, we must reduce sharing, avoiding as much of
    the read access from each thread to both variables as we can. We can’t avoid data
    sharing, but we can reduce it.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 真正的共享意味着两个线程都共享对两个变量的访问权限，即使每个变量只是由一个线程（并且总是同一个线程）写入。在这种情况下，为了提高性能，我们必须减少共享，尽可能避免每个线程对两个变量的读访问。我们无法避免数据共享，但我们可以减少它。
- en: 'Let’s focus on the producer (it’s the same mechanism for the consumer):'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注生产者（对于消费者也是同样的机制）：
- en: '[PRE51]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The **push()** function is only called by the producer.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**push()** 函数只由生产者调用。'
- en: 'Let’s analyze what the function does:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下该函数的功能：
- en: 'It atomically reads the last index where an item was stored in the ring buffer:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它原子地读取环形缓冲区中存储最后一个项目的索引：
- en: '[PRE52]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'It calculates the index where the item will be stored in the ring buffer:'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它计算项目将在环形缓冲区中存储的索引：
- en: '[PRE53]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'It checks whether the ring buffer is full. However, instead of reading **head_**
    , it reads the cached head value:'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它检查环形缓冲区是否已满。然而，它不是读取 **head_** ，而是读取缓存的头部值：
- en: '[PRE54]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Initially, both **cache_head_** and **cache_tail_** are set to zero. As mentioned
    previously, the goal of using these two variables is to minimize cache updates
    between cores. The cache variables technique works like so: every time **push**
    (or **pop** ) is called, we atomically read **tail_** (which is written by the
    same thread, so no cache updates are required) and generate the next index where
    we’ll store the item that’s passed as a parameter to the **push** function. Now,
    instead of using **head_** to check whether the queue is full, we use **cache_head_**
    , which is only accessed by one thread (the producer thread), avoiding any cache
    coherency traffic. If the queue is “full,” then we update **cache_head_** by atomically
    loading **head_** . After this update, we check again. If the second check results
    in the queue being full, then we return **false** .'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 初始时，**cache_head_** 和 **cache_tail_** 都被设置为零。如前所述，使用这两个变量的目的是最小化核心之间的缓存更新。缓存变量技术是这样的：每次调用
    **push**（或 **pop** ）时，我们原子地读取 **tail_**（由同一线程写入，因此不需要缓存更新）并生成下一个存储传递给 **push**
    函数的项目索引。现在，我们不是使用 **head_** 来检查队列是否已满，而是使用 **cache_head_**，它只被一个线程（生产者线程）访问，避免了任何缓存一致性流量。如果队列“已满”，则通过原子加载
    **head_** 来更新 **cache_head_**。在此更新之后，我们再次检查。如果第二次检查的结果是队列已满，则返回 **false**。
- en: The advantage of using these local variables ( **cache_head_** for the producer
    and **cache_tail_** for the consumer) is that they reduce true sharing – that
    is, accessing variables that may be updated in the cache of a different core.
    This will work better when the producer pushes several items in the queue before
    the consumer tries to get them (same for the consumer). Say that the producer
    inserts 10 items in the queue and the consumer tries to get one item. In this
    case, the first check with the cache variable will tell us that the queue is empty
    but after updating with the real value, it will be OK. The consumer can get nine
    more items just by checking whether the queue is empty by only reading the **cache_tail_**
    variable.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这些局部变量（生产者使用 **cache_head_** ，消费者使用 **cache_tail_** ）的优势在于它们减少了真正的共享——也就是说，访问可能在不同核心的缓存中更新的变量。当生产者在消费者尝试获取它们之前在队列中推送多个项目时（消费者也是如此），这将表现得更好。比如说生产者在队列中插入10个项目，而消费者尝试获取一个项目。在这种情况下，使用缓存变量进行的第一次检查将告诉我们队列是空的，但在更新为实际值之后，它将正常工作。消费者只需通过检查队列是否为空（只读取
    **cache_tail_** 变量）就可以获取另外九个项目。
- en: 'If the ring buffer is full, then update **cache_head_** :'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果环形缓冲区已满，则更新 **cache_head_** ：
- en: '[PRE55]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: If the buffer is full (not just that **cache_head_** needs to be updated), then
    return **false** . The producer can’t push a new item to the queue.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果缓冲区已满（不仅仅是 **cache_head_** 需要更新），则返回 **false** 。生产者无法将新项目推送到队列中。
- en: 'If the buffer isn’t full, add the item to the ring buffer and return **true**
    :'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果缓冲区未满，将项目添加到环形缓冲区并返回 **true**：
- en: '[PRE56]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We’ve potentially reduced the number of times the producer thread will access
    **tail_** and hence reduced cache coherency traffic. Think about this case: the
    producer and the consumer use the queue and the producer calls **push()** . When
    **push()** updates **cache_head_** , it may be more than one slot ahead of **tail_**
    , which means we don’t need to read **tail_** .'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能减少了生产者线程访问 **tail_** 的次数，从而减少了缓存一致性流量。考虑以下情况：生产者和消费者使用队列，生产者调用 **push()**。当
    **push()** 更新 **cache_head_** 时，它可能比 **tail_** 前面多一个槽位，这意味着我们不需要读取 **tail_**。
- en: The same principle applies to the consumer and **pop()** .
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的原则也适用于消费者和 **pop()**。
- en: 'Let’s run **perf** again after modifying the code to reduce cache coherency
    traffic:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在修改代码以减少缓存一致性流量后，让我们再次运行 **perf**：
- en: '[PRE57]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Here, we can that performance has improved by about 60% and that there is a
    smaller number of cache references and cache misses.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到性能提高了大约 60%，并且缓存引用和缓存缺失的数量更少。
- en: With that, we’ve learned how reducing access to shared data between two threads
    can improve performance.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们学习了如何通过减少两个线程之间共享数据的访问来提高性能。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we covered three methods you can use to profile your code:
    **std::chrono** , micro-benchmarking with the Google Benchmark library, and the
    Linux **perf** tool.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了你可以用来分析代码的三个方法：**std::chrono**，使用 Google Benchmark 库进行微基准测试，以及 Linux
    的 **perf** 工具。
- en: We also saw how to improve multithreaded programs’ performance by both reducing/eliminating
    false sharing and reducing true sharing, reducing the cache coherency traffic.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何通过减少/消除伪共享和减少真实共享来提高多线程程序的性能，从而减少缓存一致性流量。
- en: This chapter provided a basic introduction to some profiling techniques that
    will be very useful as a starting point for further studies. As we said at the
    beginning of this chapter, performance is a complex subject and deserves its own
    book.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了一些基本的分析技术介绍，这些技术将作为进一步研究的起点非常有用。正如我们在本章开头所说，性能是一个复杂的话题，值得有它自己的书籍。
- en: Further reading
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Fedor G. Pikus, *The Art of Writing Efficient Programs* , First Edition, Packt
    Publishing, 2021.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fedor G. Pikus，*编写高效程序的艺术*，第一版，Packt Publishing，2021。
- en: Ulrich Drepper, *What Every Programmer Should Know About* *Memory* , 2007.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ulrich Drepper，*程序员应了解的内存知识*，2007。
- en: Shivam Kunwar, *Optimizing Multithreading* *Performance* ( [https://www.youtube.com/watch?v=yN7C3SO4Uj8](https://www.youtube.com/watch?v=yN7C3SO4Uj8)
    ).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shivam Kunwar，*优化多线程性能*（[https://www.youtube.com/watch?v=yN7C3SO4Uj8](https://www.youtube.com/watch?v=yN7C3SO4Uj8)）。
