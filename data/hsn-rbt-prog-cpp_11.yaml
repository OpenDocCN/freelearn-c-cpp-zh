- en: Face Detection and Tracking Using the Haar Classifier
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Haar分类器进行面部检测和跟踪
- en: In the previous chapter, we programmed the robot to detect a ball object and
    follow it. In this chapter, we will take our detection skills to the next level
    by detecting and tracking a human face, detecting human eyes, and recognizing
    a smile.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们编程机器人来检测一个球体并跟随它。在本章中，我们将通过检测和跟踪人脸、检测人眼和识别微笑，将我们的检测技能提升到下一个水平。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习以下主题：
- en: Face detection using the Haar cascade
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Haar级联进行面部检测
- en: Detecting the eyes and smile
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测眼睛和微笑
- en: Face-tracking robot
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部跟踪机器人
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will need the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将需要以下内容：
- en: Three LEDs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个LED灯
- en: A **Raspberry Pi** (**RPi**) robot (with the Raspberry Pi camera module connected
    to the RPi)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**树莓派**（RPi）机器人（连接到RPi的树莓派摄像头模块）
- en: The code files for this chapter can be downloaded from [https://github.com/PacktPublishing/Hands-On-Robotics-Programming-with-Cpp/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-Robotics-Programming-with-Cpp/tree/master/Chapter08).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以从[https://github.com/PacktPublishing/Hands-On-Robotics-Programming-with-Cpp/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-Robotics-Programming-with-Cpp/tree/master/Chapter08)下载。
- en: Face detection using the Haar cascade
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Haar级联进行面部检测
- en: Paul Viola and Micheal Jones proposed the Haar feature-based cascade classifier
    in their paper, *Rapid Object Detection using a Boosted Cascade of Simple Features*,
    in 2001\. The Haar feature-based cascade classifier is trained using facial images
    as well as non-facial images. The Haar cascade classifier can not only detect
    a frontal face but can also detect the eyes, mouth, and nose of a person. The
    Haar feature-based classifier is also referred to as the Viola-Jones algorithm.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Paul Viola和Micheal Jones在他们的论文《使用增强级联简单特征的快速目标检测》中于2001年提出了基于Haar特征的级联分类器。Haar特征的级联分类器是使用面部图像以及非面部图像进行训练的。Haar级联分类器不仅可以检测正面人脸，还可以检测人的眼睛、嘴巴和鼻子。Haar特征的分类器也被称为Viola-Jones算法。
- en: Basic working of the Viola-Jones algorithm
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Viola-Jones算法的基本工作
- en: 'So, put simply, the Viola-Jones algorithm used Haar features to detect a face.
    Haar generally consists of two main features: **edge features** and **line features**.
    We will first understand these two features and then we will see how these features
    are used to detect faces:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，简而言之，Viola-Jones算法使用Haar特征来检测人脸。Haar通常包括两个主要特征：**边缘特征**和**线特征**。我们将首先了解这两个特征，然后我们将看到这些特征如何用于检测人脸：
- en: '**Edge features**: This is generally used to detect edges. The edge feature
    consists of white and black pixels. Edge features can be further categorized into
    horizontal edge features and vertical edge features. In the following diagram,
    we can see the vertical edge feature on the left block and the horizontal edge
    feature on the right block:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边缘特征**：通常用于检测边缘。边缘特征由白色和黑色像素组成。边缘特征可以进一步分为水平边缘特征和垂直边缘特征。在下图中，我们可以看到左侧块上的垂直边缘特征和右侧块上的水平边缘特征：'
- en: '![](img/16d96ff3-7843-4623-aece-7785b805f5c7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16d96ff3-7843-4623-aece-7785b805f5c7.png)'
- en: '**Line features**: This is generally used to detect lines. In line features,
    a white pixel is sandwiched between two black pixels, or a black pixel will be
    sandwiched between two white pixels. In the following diagram, you can see the
    two horizontal line features on the left, one below the other, and the vertical
    line features on the right, next to each other:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线特征**：通常用于检测线条。在线特征中，一个白色像素被夹在两个黑色像素之间，或者一个黑色像素被夹在两个白色像素之间。在下图中，您可以看到左侧的两个水平线特征，一个在另一个下方，以及右侧的垂直线特征，相邻在一起：'
- en: '![](img/678d0003-8bce-4105-b5b2-1dfbfeb26524.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/678d0003-8bce-4105-b5b2-1dfbfeb26524.png)'
- en: 'Face detection is always performed on a grayscale image, but this means that
    in a grayscale image, we may not have completely black and white pixels. So, let''s
    refer to white pixels as brighter pixels and black pixels as darker pixels. If
    we look at the following grayscale face picture, the forehead region is lighter
    (brighter pixels) compared to the eyebrow region (darker pixels):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 面部检测始终在灰度图像上执行，但这意味着在灰度图像中，我们可能没有完全黑色和白色的像素。因此，让我们将白色像素称为较亮的像素，黑色像素称为较暗的像素。如果我们看下面的灰度人脸图片，额头区域较亮（较亮的像素）与眉毛区域（较暗的像素）相比：
- en: '![](img/1c6d2bdc-a728-45e0-8594-b7b60f82c44d.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c6d2bdc-a728-45e0-8594-b7b60f82c44d.png)'
- en: 'The area of the nose line is brighter compared to the eye and cheeks regions.
    Similarly, if we look at the mouth region, the upper lip region is darker, the
    teeth region is brighter, and the lower lip region is dark again:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与眼睛和脸颊区域相比，鼻线区域更亮。同样，如果我们看口部区域，上唇区域较暗，牙齿区域较亮，下唇区域再次较暗：
- en: '![](img/086200cb-307d-472a-9aee-79207f357ced.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/086200cb-307d-472a-9aee-79207f357ced.png)'
- en: This is how, by using the edge and line features of the Haar cascade, we can
    detect the most relevant feature points in a human face, such as the eyes, nose,
    and mouth.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是通过使用Haar级联的边缘和线特征，我们可以检测人脸中最相关的特征点，如眼睛、鼻子和嘴巴。
- en: 'OpenCV 4.0 consists of different pre-trained Haar detectors, which can be used
    to detect a human face, including its eyes, nose, smile, and so on. Inside the
    `Opencv-4.0.0` folder, there is a `Data` folder, and inside the `Data` folder,
    you will find the `haarcascades` folder. In this folder, you will find different
    Haar cascade classifiers. For frontal face detection, we will use the`haarcascade_frontalface_alt2.xml`detector. In
    the following screenshot, you can see the path of the `haarcascades` folders,
    with different Haar cascade classifiers present inside:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 4.0包括不同的预训练Haar检测器，可以用于检测人脸，包括眼睛、鼻子、微笑等。在`Opencv-4.0.0`文件夹中，有一个`Data`文件夹，在`Data`文件夹中，您会找到`haarcascades`文件夹。在这个文件夹中，您会找到不同的Haar级联分类器。对于正面人脸检测，我们将使用`haarcascade_frontalface_alt2.xml`检测器。在下面的截图中，您可以看到`haarcascades`文件夹的路径，其中包含不同的Haar级联分类器：
- en: '![](img/7defffc4-3716-40fe-8d85-5d5ed6b368c1.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7defffc4-3716-40fe-8d85-5d5ed6b368c1.png)'
- en: Now that we understand the basics of Viola-Jones features, we will program our
    robot to detect a human face using the Haar cascade.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了Viola-Jones特征的基础知识，我们将编写程序，使我们的机器人使用Haar级联检测人脸。
- en: Face-detection program
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测程序
- en: Let's write a program to detect a human face. I have named this program `FaceDetection.cpp`
    and you can download it from the `Chapter08` folder of this book's GitHub repository.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个程序来检测人脸。我将这个程序命名为`FaceDetection.cpp`，您可以从本书的GitHub存储库的`Chapter08`文件夹中下载。
- en: Since we will be using `haarcascade_frontalface_alt2.xml` to detect faces, please
    make sure that the `FaceDetection.cpp` and `haarcascade_frontalface_alt2.xml` files
    are in the same folder.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将使用`haarcascade_frontalface_alt2.xml`来检测人脸，请确保`FaceDetection.cpp`和`haarcascade_frontalface_alt2.xml`文件在同一个文件夹中。
- en: 'To program face detection, follow these steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要编写人脸检测程序，请按照以下步骤进行：
- en: 'In the `FaceDetection.cpp` program, load the Haar''s pre-trained frontal face
    XML using the `CascadeClassifier` class, as shown in the following code snippet:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`FaceDetection.cpp`程序中，使用`CascadeClassifier`类加载Haar的预训练正面脸XML，如下面的代码片段所示：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Declare two matrix variables, called `videofeed` and `grayfeed`, along with
    a `VideoCapture` variable, called `vid(0)`, to capture footage from the RPi camera:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明两个矩阵变量，称为`videofeed`和`grayfeed`，以及一个名为`vid(0)`的`VideoCapture`变量，以从RPi相机捕获视频：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Inside the `for` loop, read the camera feed. Then, flip the camera feed horizontally.
    Using the `cvtColor` function, we can convert our `videofeed` into `grayscale`.
    If your Pi camera is placed upside-down, set the third parameter inside `flip`
    function to `0`. The `grayscale` output is stored in the `grayfeed` variable.
    The following code shows how to complete this step:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`for`循环内，读取相机视频。然后，水平翻转相机视频。使用`cvtColor`函数，我们可以将我们的`videofeed`转换为`grayscale`。如果您的Pi相机放置颠倒，将`flip`函数内的第三个参数设置为`0`。`grayscale`输出存储在`grayfeed`变量中。以下代码显示了如何完成此步骤：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s perform a histogram equalization to improve the brightness and contrast
    of `videofeed`. Histogram equalization is required because sometimes, in low lighting,
    the camera may not be able to detect the face. To perform histogram equalization,
    we will use the `equalizeHist` function:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们执行直方图均衡化，以改善`videofeed`的亮度和对比度。直方图均衡化是必需的，因为有时在光线较暗时，相机可能无法检测到人脸。为了执行直方图均衡化，我们将使用`equalizeHist`函数：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s detect some faces. For this, the `detectMultiScale` function is used,
    as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检测一些人脸。为此，使用`detectMultiScale`函数，如下所示：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `detectMultiScale` function that''s shown in the preceding code snippet
    consists of the following seven parameters:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中显示的`detectMultiScale`函数由以下七个参数组成：
- en: '`image`: Represents the input video feed. In our case, it is `grayfeed`, as
    we will detect the face from the grayscale video.'
  id: totrans-42
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：表示输入视频源。在我们的情况下，它是`grayfeed`，因为我们将从灰度视频中检测人脸。'
- en: '`object`: Represents the vectors of a rectangle where each rectangle contains
    the detected faces.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`object`：表示矩形的向量，其中每个矩形包含检测到的人脸。'
- en: '`scalefactor`: Specifies how much the image size must be reduced. The ideal
    value of scale factor is between 1.1 and 1.3.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scalefactor`：指定图像大小必须缩小多少。比例因子的理想值在1.1和1.3之间。'
- en: '`flags`: This parameter can be set to `CASCADE_SCALE_IMAGE`, `CASCADE_FIND_BIGGEST_OBJECT`,
    `CASCADE_DO_ROUGH_SEARCH`, or `CASCADE_DO_CANNY_PRUNING`:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：此参数可以设置为`CASCADE_SCALE_IMAGE`、`CASCADE_FIND_BIGGEST_OBJECT`、`CASCADE_DO_ROUGH_SEARCH`或`CASCADE_DO_CANNY_PRUNING`：'
- en: '`CASCADE_SCALE_IMAGE`: This is the most popular flag; it informs the classifier
    that the Haar features for detecting the face are applied to the video or image'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CASCADE_SCALE_IMAGE`：这是最流行的标志；它通知分类器，用于检测人脸的Haar特征应用于视频或图像。'
- en: '`CASCADE_FIND_BIGGEST_OBJECT`: This flag will tell the classifier to find the
    biggest face in the image or video'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CASCADE_FIND_BIGGEST_OBJECT`：此标志将告诉分类器在图像或视频中找到最大的脸'
- en: '`CASCADE_DO_ROUGH_SEARCH`: This flag will stop the classifier once a face is
    detected'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CASCADE_DO_ROUGH_SEARCH`：此标志将在检测到人脸后停止分类器。'
- en: '`CASCADE_DO_CANNY_PRUNNING`: This flag informs the classifier to not detect
    sharp edges, thus increasing the chances of face detection'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CASCADE_DO_CANNY_PRUNNING`：此标志通知分类器不要检测锐利的边缘，从而增加检测到人脸的机会。'
- en: '`min neighbors`: The minimum neighbors parameter affects the quality of the
    detected faces. Higher **min neighbor values** will recognize fewer faces, but
    whatever it detects will definitely be a face. Lower `min neighbors` values may
    recognize multiple faces, but sometimes it may also recognize objects that are
    not faces. The ideal `min neighbors` values for detecting faces is between 3 and
    5.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min neighbors`：最小邻居参数影响检测到的人脸的质量。较高的**最小邻居值**将识别较少的人脸，但无论它检测到什么都一定是人脸。较低的`min
    neighbors`值可能会识别多个人脸，但有时也可能识别不是人脸的对象。检测人脸的理想`min neighbors`值在3和5之间。'
- en: '`min size`: The minimum size parameter will detect the minimum face size. For
    example, if we set the min size to 50 x 50 pixels, the classifier will only detect
    faces that are bigger than 50 x 50 pixels and ignore faces that are lower than
    50 x 50 pixels. Ideally, we can set the min size to 30 x 30 pixels.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min size`：最小尺寸参数将检测最小的人脸尺寸。例如，如果我们将最小尺寸设置为50 x 50像素，分类器将只检测大于50 x 50像素的人脸，忽略小于50
    x 50像素的人脸。理想情况下，我们可以将最小尺寸设置为30 x 30像素。'
- en: '`max size`: The maximum size parameter will detect the maximum face size. For
    example, if we set the max size to 80 x 80 pixels, the classifier will only detect
    faces that are smaller than 80 x 80 pixels. So, if you move too close to the camera
    and your face size exceeds the max size, your face will not be detected by the
    classifier.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max size`：最大尺寸参数将检测最大的人脸尺寸。例如，如果我们将最大尺寸设置为80 x 80像素，分类器将只检测小于80 x 80像素的人脸。因此，如果您离相机太近，您的脸的尺寸超过了最大尺寸，分类器将无法检测到您的脸。'
- en: 'Since the `detectMultiScale` function provides a vector of rectangles as its
    output, we have to declare a vector as the `Rect` type. The variable name as `face`. `scalefactor`
    is set to `1.1`, `min neighbors` is set to `5`, and the minimum scale size is
    set 30 x 30 pixels. The max size is ignored here because if your face size becomes
    bigger than the max size, your face will not be detected. To complete this step,
    use the following code:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于`detectMultiScale`函数提供矩形的向量作为其输出，我们必须声明一个`Rect`类型的向量。变量名为`face`。`scalefactor`设置为`1.1`，`min
    neighbors`设置为`5`，最小比例大小设置为30 x 30像素。最大大小在这里被忽略，因为如果您的脸部尺寸变得大于最大尺寸，您的脸部将无法被检测到。要完成此步骤，请使用以下代码：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After detecting faces, we will create a rectangle around the detected faces
    and display text on the top-left side of the rectangle that states "`Face detected`":'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到脸部后，我们将在检测到的脸部周围创建一个矩形，并在矩形的左上方显示文本，指示“检测到脸部”：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Inside the `for` loop, we are determining how many faces are detected using
    the `face.size()` function. If one is detected, `face.size()` equals `1`, and
    the `for` loop will be satisfied. Inside the `for` loop, we have the rectangle
    and `putText` function.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在`for`循环内，我们使用`face.size()`函数来确定检测到了多少张脸。如果检测到一张脸，`face.size()`等于`1`，`for`循环就会满足条件。在`for`循环内，我们有矩形和`putText`函数。
- en: 'The rectangle function will create a rectangle around the detected face. It
    consists of four parameters:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 矩形函数将在检测到的脸部周围创建一个矩形。它由四个参数组成：
- en: The first parameter represents the image or video feed on which we want to draw
    the rectangle, which in our case is `videofeed`
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数表示我们要在其上绘制矩形的图像或视频源，在我们的例子中是`videofeed`
- en: The second parameter of `face[f]` represents the detected face on which we have
    to draw the rectangle
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`face[f]`的第二个参数表示我们要在其上绘制矩形的检测到的脸部'
- en: The third parameter represents the color of the rectangle (for this example,
    we have set the color to blue)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个参数表示矩形的颜色（在此示例中，我们将颜色设置为蓝色）
- en: The fourth and final parameter represents the thickness of the rectangle
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四个和最后一个参数表示矩形的厚度
- en: 'The `putText` function is used to display text in an image or video feed. It
    consists of seven parameters:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`putText`函数用于在图像或视频源中显示文本。它由七个参数组成：'
- en: The first parameter represents the image or video feed on which we want to draw
    the rectangle.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数表示我们要在其上绘制矩形的图像或视频源。
- en: The second parameter represents the text message that we want to display.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数表示我们要显示的文本消息。
- en: The third parameter represents the point on which we want the text to be displayed.
    The `face[f].x` and `face[f].y` functions represent the top-left point of the
    rectangle, so the text will be displayed on the top-left side of the rectangle.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个参数表示我们希望文本显示的位置。`face[f].x`和`face[f].y`函数表示矩形的左上点，因此文本将显示在矩形的左上方。
- en: The fourth parameter represents the font type, which we have set to `FONT_HERSHEY_PLAIN`.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四个参数表示字体类型，我们设置为`FONT_HERSHEY_PLAIN`。
- en: The fifth parameter represents the font size of the text, which we have set
    to `1`.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五个参数表示文本的字体大小，我们设置为`1`。
- en: The sixth parameter represents the color of the text, which is set to green
    (`Scalar(0,255,0)`).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第六个参数表示文本的颜色，设置为绿色（`Scalar(0,255,0)`）。
- en: The seventh and final parameter represents the thickness of the font, which
    is set to `1.0`.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第七个和最后一个参数表示字体的厚度，设置为`1.0`。
- en: 'Finally, using the `imshow` function, we will view the video feed, along with
    the rectangle and text:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用`imshow`函数，我们将查看视频源，以及矩形和文本：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After using the preceding code, and if you have compiled and built the program,
    you will see that a rectangle has been drawn around the detected face:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述代码后，如果您已经编译和构建了程序，您将看到在检测到的脸部周围画了一个矩形：
- en: '![](img/aefc64d5-2d06-4ce2-babe-78d97c9a2df2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aefc64d5-2d06-4ce2-babe-78d97c9a2df2.png)'
- en: Next, we will detect human eyes as well as recognize a smile. Once the eyes
    and smile have been recognized, we will create circles around them.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将检测人眼并识别微笑。一旦眼睛和微笑被识别出来，我们将在它们周围创建圆圈。
- en: Detecting the eyes and smile
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测眼睛和微笑
- en: The program for detecting the eyes and smile is called `SmilingFace.cpp`, and
    you can download it from the `Chapter08` folder of this book's GitHub repository.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检测眼睛和微笑的程序名为`SmilingFace.cpp`，您可以从本书的GitHub存储库的`Chapter08`文件夹中下载。
- en: Detecting the eyes
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测眼睛
- en: The `SmilingFace.cpp` program is basically an extension of the `FaceDetection.cpp`
    program, meaning that we will first find the region of interest, which is the
    face. Next, using the Haar `CascadeClassifier` for the eyes, we will detect the
    eyes and then draw circles around them.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`SmilingFace.cpp`程序基本上是`FaceDetection.cpp`程序的扩展，这意味着我们将首先找到感兴趣的区域，即脸部。接下来，使用Haar级联分类器检测眼睛，然后在它们周围画圆圈。'
- en: 'Before writing the program, let''s first understand the different eye `CascadeClassifier` that
    are available. OpenCV 4.0 has three main eye cascade classifiers:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写程序之前，让我们首先了解不同的可用的眼睛`CascadeClassifier`。OpenCV 4.0有三个主要的眼睛级联分类器：
- en: '`haarcascade_eye.xml`: This classifier will detect both of the eyes simultaneously'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_eye.xml`：此分类器将同时检测两只眼睛'
- en: '`haarcascade_lefteye_2splits.xml`: This classifier will detect only the left
    eye'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_lefteye_2splits.xml`：此分类器将仅检测左眼'
- en: '`haarcascade_righteye_2splits.xml`: This classifier will detect only the right
    eye'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_righteye_2splits.xml`：此分类器将仅检测右眼'
- en: Depending on your requirements, you can use the `haarcascade_eye` classifier
    to detect both of the eyes, or you can use the `haarcascade_lefteye_2splits` classifier
    to detect only the left eye and the `haarcascade_righteye_2splits` classifier
    to detect only the right eye. In the `SmilingFace.cpp` program, we will first
    test the output with the `haarcascade_eye`classifier and then we will test the
    output with the `haarcascade_lefteye_2splits`and `haarcascade_righteye_2splits`
    classifiers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的要求，您可以使用`haarcascade_eye`分类器来检测两只眼睛，或者您可以使用`haarcascade_lefteye_2splits`分类器仅检测左眼和`haarcascade_righteye_2splits`分类器仅检测右眼。在`SmilingFace.cpp`程序中，我们将首先使用`haarcascade_eye`分类器测试输出，然后我们将使用`haarcascade_lefteye_2splits`和`haarcascade_righteye_2splits`分类器测试输出。
- en: Eye detection using haarcascade_eye
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`haarcascade_eye`进行眼睛检测
- en: 'To test the `haarcascade_eye`output, observe the following steps:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试`haarcascade_eye`的输出，观察以下步骤：
- en: 'Load this classifier inside our program:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的程序中加载这个分类器：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To detect the eyes, we need to find the face region (region of interest) in
    the image (video feed). Inside the face-detection `for` loop, we will create a
    `Mat` variable called `faceroi`. `videofeed(face[f])`, which will find faces in
    `videofeed` and store them inside the `faceroi` variable:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检测眼睛，我们需要在图像（视频源）中找到脸部区域（感兴趣区域）。在脸部检测的`for`循环中，我们将创建一个名为`faceroi`的`Mat`变量。`videofeed(face[f])`，这将在`videofeed`中找到脸部并将它们存储在`faceroi`变量中：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create a vector of the `Rect` type, called `eyes`, and then use the `detectMultiScale`
    function to detect the eye region:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`eyes`的`Rect`类型的向量，然后使用`detectMultiScale`函数来检测眼睛区域：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the `detectMultiScale` function, the first parameter is set to `faceroi`,
    which means that we want to detect the eyes from the face region only and not
    from the entire video feed. The detected eyes will be stored in the eyes variable.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在`detectMultiScale`函数中，第一个参数设置为`faceroi`，这意味着我们只想从脸部区域检测眼睛，而不是从整个视频源检测。检测到的眼睛将存储在eyes变量中。
- en: 'To create circles around the eyes, we will use a `for` loop. Let''s find the
    center of the eyes. To find the center of an eye, we will use the `Point` datatype,
    and the equation inside the `eyecenter` variable will give us the center of the
    eye:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在眼睛周围创建圆圈，我们将使用一个`for`循环。让我们找到眼睛的中心。为了找到眼睛的中心，我们将使用`Point`数据类型，并且`eyecenter`变量中的方程将给出眼睛的中心：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The results of this can be seen here:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这的结果可以在这里看到：
- en: '![](img/7387dccd-ec92-4337-974e-18bc25e312b4.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7387dccd-ec92-4337-974e-18bc25e312b4.png)'
- en: Using the `radius` variable, we have calculated the radius of the circle and
    then used the `circle` function to create red circles around the eyes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`radius`变量，我们计算了圆的半径，然后使用`circle`函数在眼睛周围创建红色的圆圈。
- en: Eye detection using haarcascade_lefteye_2splits and haarcascade_righteye_2splits
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`haarcascade_lefteye_2splits`和`haarcascade_righteye_2splits`进行眼睛检测
- en: After detecting both eyes using the `haarcascade_eye` classifier, let's try
    to detect only the left eye or the right eye by using the `haarcascade_lefteye_2splits`and `haarcascade_righteye_2splits` classifiers,
    respectively.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`haarcascade_eye`分类器检测两只眼睛后，让我们尝试仅使用`haarcascade_lefteye_2splits`和`haarcascade_righteye_2splits`分类器分别检测左眼或右眼。
- en: Detecting the left eye
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测左眼
- en: 'To detect the left eye, perform these steps:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要检测左眼，执行以下步骤：
- en: 'Load the `haarcascade_lefteye_2splits` cascade classifier inside our program:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的程序中加载`haarcascade_lefteye_2splits`级联分类器：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Since we want to detect the left eye in the face region, we will create a `Mat`
    variable called `faceroi` and inside it we will store the face region value:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们想要在脸部区域检测左眼，我们将创建一个名为`faceroi`的`Mat`变量，并在其中存储脸部区域的值：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use the `detectMultiScale` function to create a vector of the `Rect` type called
    `lefteye` to detect the left eye region. The `min neighbors` parameter is set
    to `25` so that the classifier detects only the left eye. If we set `min neighbors`
    lower than 25, the `haarcascade_lefteye_2splits`classifier may also detect the
    right eye, which is not what we want. To complete this step, use the following
    code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`detectMultiScale`函数创建一个名为`lefteye`的`Rect`类型的向量来检测左眼区域。`min neighbors`参数设置为`25`，以便分类器只检测左眼。如果我们将`min
    neighbors`设置为低于25，`haarcascade_lefteye_2splits`分类器也可能检测到右眼，这不是我们想要的。要完成此步骤，请使用以下代码：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '![](img/e234758b-61ca-4ddd-98c5-48e213cb1c1b.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e234758b-61ca-4ddd-98c5-48e213cb1c1b.png)'
- en: The `for` loop code for detecting the left and right eye separately is a part
    of the `SmilingFace.cpp` program, but it is commented. To test the code, first
    comment the `for` loop for detecting both the eyes simultaneously and then uncomment
    the other two `for` loops for detecting the left and right eyes.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 检测左右眼分开的`for`循环代码是`SmilingFace.cpp`程序的一部分，但是被注释掉了。要测试代码，首先注释掉同时检测两只眼睛的`for`循环，然后取消注释检测左眼和右眼的另外两个`for`循环。
- en: Detecting the right eye
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测右眼
- en: 'The programming logic for detecting the right eye is very similar to detecting
    the left eye. The only thing that we have to change is the classifier name and
    some variable names to distinguish the left and right eyes. To detect the right
    eye, perform these steps:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 检测右眼的编程逻辑与检测左眼非常相似。我们唯一需要改变的是分类器名称和一些变量名称，以区分左眼和右眼。要检测右眼，执行以下步骤：
- en: 'Load the `haarcascade_righteye_2splits` cascade classifier:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`haarcascade_righteye_2splits`级联分类器：
- en: '[PRE15]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Inside the face-detection for loop, find the face region. Then, use the `detectMultiScale`
    function to detect the right eye. Use the `circle` function to create a green
    circle around the right eye. To do so, use the following code:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在脸部检测的`for`循环中，找到脸部区域。然后，使用`detectMultiScale`函数来检测右眼。使用`circle`函数在右眼周围创建一个绿色的圆圈。为此，请使用以下代码：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出如下：
- en: '![](img/89315812-5bdc-45ea-937a-11f6569bd558.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89315812-5bdc-45ea-937a-11f6569bd558.png)'
- en: 'If we combine the left- and the right-eye detector code, the final output will
    be as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们结合左眼和右眼的检测器代码，最终输出将如下所示：
- en: '![](img/8edd5a4b-37d9-46c4-aad6-cead16da27a1.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8edd5a4b-37d9-46c4-aad6-cead16da27a1.png)'
- en: As we can see, the left eye in the picture is surrounded by a red circle and
    the right eye is surrounded by a green circle.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，图片中的左眼被红色圆圈包围，右眼被绿色圆圈包围。
- en: Recognizing a smile
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别微笑
- en: 'After detecting the eyes from the face region, let''s write the program to
    recognize a smiling face. The webcam will recognize a smiling face when it detects
    a black-white-black line feature around the mouth, that is, the upper and lower
    lip are generally a bit darker compared to the teeth region:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在从面部区域检测到眼睛后，让我们编写程序来识别笑脸。当网络摄像头检测到嘴巴周围的黑白黑线特征时，即上下嘴唇通常比牙齿区域略暗时，网络摄像头将识别出一个微笑的脸：
- en: '![](img/c969cfe1-1672-4b17-ab75-83ac508ddb17.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c969cfe1-1672-4b17-ab75-83ac508ddb17.png)'
- en: Programming logic for smile recognition
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微笑识别的编程逻辑
- en: 'The programming logic for smile recognition is similar to eye detection, and
    we will also write the smile-recognition program inside the face-detection `for`
    loop. To program smile recognition, follow these steps:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 微笑识别的编程逻辑与眼睛检测类似，我们还将在面部检测的`for`循环内编写微笑识别程序。要编写微笑识别程序，请按照以下步骤进行：
- en: 'Load the smile `CascadeClassifier`:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载微笑`CascadeClassifier`：
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We need to detect the mouth region, which is inside the face region. The face
    region is again our region of interest, and to find the face region from the video
    feed, use will use the following command:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要检测面部区域，它位于面部区域内。面部区域再次是我们的感兴趣区域，为了从视频源中找到面部区域，我们将使用以下命令：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Declare a `smile` variable, which is a vector of the `Rect` type. Then, use
    the `detectMultiScale` function. In the `detectMultiScale` function, `min neighbors`
    is set to `25` so that a circle is created only when a person smiles (if we set
    min neighbor to lower than 25, a circle may be created around the mouth, even
    if the person is not smiling). You can vary the `min neighbors` value between
    25-35\. Next, inside the `for` loop, we have written the program to create a green
    circle around the mouth. To complete this step, use the following code:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明一个`smile`变量，它是`Rect`类型的向量。然后使用`detectMultiScale`函数。在`detectMultiScale`函数中，将`min
    neighbors`设置为`25`，以便只有在人微笑时才创建一个圆圈（如果我们将最小邻居设置为低于25，即使人没有微笑，也可能在嘴周围创建一个圆圈）。您可以在25-35之间变化`min
    neighbors`的值。接下来，在`for`循环内，我们编写了在嘴周围创建绿色圆圈的程序。要完成此步骤，请使用以下代码：
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下：
- en: '![](img/785e0ca6-77a7-4e49-b61f-e4ad84056b2e.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/785e0ca6-77a7-4e49-b61f-e4ad84056b2e.png)'
- en: In the next section, we will turn on different LEDs on the robot when the eyes
    and smile are detected. We will also make our robot follow the detected face when
    the face moves.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，当检测到眼睛和微笑时，我们将打开不同的LED。当面部移动时，我们还将使我们的机器人跟随检测到的面部。
- en: Face-tracking robot
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部跟踪机器人
- en: The program for turning LEDs on/off and tracking a human face is called `Facetrackingrobot.cpp`,
    and you can download it from the `Chapter08` folder of this book's GitHub repository.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 用于打开/关闭LED和跟踪人脸的程序称为`Facetrackingrobot.cpp`，您可以从本书的GitHub存储库的`Chapter08`文件夹中下载。
- en: In the `Facetrackingrobot` program, we will first detect the face, and then
    the left eye, right eye, and smile. Once the eyes and smile are detected, we will
    turn the LEDs on/off. After this, we will create a small dot in the center of
    the face rectangle, and then use this dot as a reference to move our robot.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Facetrackingrobot`程序中，我们将首先检测面部，然后是左眼、右眼和微笑。一旦检测到眼睛和微笑，我们将打开/关闭LED。之后，我们将在面部矩形的中心创建一个小点，然后使用这个点作为移动机器人的参考。
- en: Wiring connections
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接线
- en: 'For the `Facetrackingrobot`program, we will need a minimum of three LEDs: one
    for the left eye, one for the right eye, and one LED for smile recognition. The
    three LEDs are shown in the following diagram:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`Facetrackingrobot`程序，我们至少需要三个LED：一个用于左眼，一个用于右眼，一个用于微笑识别。这三个LED显示在以下图表中：
- en: '![](img/09d4f5e2-8e71-4b59-a306-e0c8e99fa8a1.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09d4f5e2-8e71-4b59-a306-e0c8e99fa8a1.png)'
- en: 'The wiring connections of the LEDs and the robot are as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: LED和机器人的接线如下：
- en: The left LED, which corresponds to the **left eye**, is connected to **wiringPi
    pin 0**
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对应**左眼**的左LED连接到**wiringPi pin 0**
- en: The right LED, which corresponds to the **right eye**, is connected to **wiringPi
    pin 2**
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对应**右眼**的右LED连接到**wiringPi pin 2**
- en: The middle LED, which corresponds to a **smile**, is connected to **wiringPi
    pin 3**
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对应**微笑**的中间LED连接到**wiringPi pin 3**
- en: The **IN1** pin of the motor driver is connected to **wiringPi pin 24**
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电机驱动器的**IN1**引脚连接到**wiringPi pin 24**
- en: The **IN2** pin of the motor driver is connected to **wiringPi pin 27**
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电机驱动器的**IN2**引脚连接到**wiringPi pin 27**
- en: The **IN3** pin of the motor driver is connected to **wiringPi pin 25**
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电机驱动器的**IN3**引脚连接到**wiringPi pin 25**
- en: The **IN4** pin of the motor driver is connected to **wiringPi pin 28**
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电机驱动器的**IN4**引脚连接到**wiringPi pin 28**
- en: 'On my robot, I have taped the left and right LEDs on the top chassis of the
    robot. The third LED (the middle LED) is taped to the bottom chassis of the robot.
    I have used green LEDs for the eyes and a red LED for the smile:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器人上，我已经把左右LED贴在机器人的顶部底盘上。第三个LED（中间LED）贴在机器人的底盘上。我使用绿色LED作为眼睛，红色LED作为微笑：
- en: '![](img/0f5efdb7-3959-47e4-a7e8-cd50dbf74e34.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f5efdb7-3959-47e4-a7e8-cd50dbf74e34.png)'
- en: The programming logic
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程逻辑
- en: 'In the `Facetrackingrobot` program, wiringPi pins 0, 2, and 3 are set as output
    pins:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Facetrackingrobot`程序中，将wiringPi引脚0、2和3设置为输出引脚：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'From the face-detection program, you may have noticed that the face-tracking
    process is very slow. Therefore, when you move your face to the left or right,
    you have to make sure that the motors don''t move too fast. To reduce the speed
    of the motor, we will use the `softPwm.h` library, which we also used in [Chapter
    2](0db97f63-8947-4436-9265-3680d34bece6.xhtml), *Implementing Blink with wiringPi*:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 从面部检测程序中，您可能已经注意到面部跟踪过程非常缓慢。因此，当您将脸部向左或向右移动时，必须确保电机不要移动得太快。为了减慢电机的速度，我们将使用`softPwm.h`库，这也是我们在[第2章](0db97f63-8947-4436-9265-3680d34bece6.xhtml)中使用的*使用wiringPi实现眨眼*：
- en: 'From the `softPwm.h` library, use the `softPwmCreate` function todeclare the
    four motor pins (`24`, `27`, `25`, and `28`):'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`softPwm.h`库中，使用`softPwmCreate`函数声明四个电机引脚（`24`，`27`，`25`和`28`）：
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The first parameter inside the `softPwmCreate` function denotes the wiringPi
    pin of the RPi. The second parameter represents the minimum speed at which we
    can move the motor, and the third parameter represents the maximum speed at which
    we can move the motor.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`softPwmCreate`函数中的第一个参数表示RPi的wiringPi引脚。第二个参数表示我们可以移动电机的最小速度，第三个参数表示我们可以移动电机的最大速度。'
- en: 'Load the face, left eye, right eye, and smile `CascadeClassifiers`:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载面部、左眼、右眼和微笑`CascadeClassifiers`：
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Inside the `for` loop, declare three Boolean variables, called `lefteyedetect`,
    `righteyedetect`, and `isSmiling`. Set all three variables to `false`. Using these
    three variables, we will detect whether the left eye, right eye, and smile are
    detected. Declare the `facex` and `facey` variables, which will be used to find
    the center of the face rectangle. To complete this step, use the following code:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`for`循环内，声明三个布尔变量，称为`lefteyedetect`、`righteyedetect`和`isSmiling`。将这三个变量都设置为`false`。使用这三个变量，我们将检测左眼、右眼和微笑是否被检测到。声明`facex`和`facey`变量，用于找到脸部矩形的中心。要完成此步骤，请使用以下代码：
- en: '[PRE23]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use the `detectMultiScale` function to detect the face and then, inside the
    `for` loop, we will write the program to create a rectangle around the detected
    face:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`detectMultiScale`函数检测面部，然后在`for`循环内编写程序创建检测到的面部周围的矩形：
- en: '[PRE24]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`face[f].x + face[f].width/2` will return the *x* center value of the rectangle
    and `face[f].y + face[f].height/2` will return the *y* center value of the rectangle.
    The *x* center value is stored in the `facex` variable and the *y* center value
    is stored in the `facey` variable.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`face[f].x + face[f].width/2`将返回矩形的*x*中心值，`face[f].y + face[f].height/2`将返回矩形的*y*中心值。
    *x*中心值存储在`facex`变量中，*y*中心值存储在`facey`变量中。'
- en: 'To find the center of the rectangle, provide `facex` and `facey` as input to
    the `Point` variable, called `facecenter`. Inside the circle function, use the
    `facecenter` point variable as an input to create a dot in the center of the face
    rectangle:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供`facex`和`facey`作为`Point`变量的输入，以找到矩形的中心，称为`facecenter`。在圆函数中，使用`facecenter`点变量作为输入，在脸部矩形的中心创建一个点：
- en: '![](img/47290ac4-3a89-450a-8cce-5b2590f4bd7c.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/47290ac4-3a89-450a-8cce-5b2590f4bd7c.png)'
- en: 'When the left eye is detected, we will create a red circle around it and set
    the `lefteyedetect` variable to `true`:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到左眼时，我们将在其周围创建一个红色圆圈，并将`lefteyedetect`变量设置为`true`：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When the right eye is detected, we will create a light blue circle around it
    and set the `righteyedetect` variable to `true`:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到右眼时，我们将在其周围创建一个浅蓝色圆圈，并将`righteyedetect`变量设置为`true`：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When the smile is detected, we will create a green circle around the mouth
    and set `isSmiling` to `true`:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当检测到微笑时，我们将在嘴周围创建一个绿色圆圈，并将`isSmiling`设置为`true`：
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In the following screenshot, you can see a red circle drawn around the left
    eye, a light blue circle drawn around the right eye, a green circle drawn around
    the mouth, and a white dot in the center of the blue rectangle that surrounds
    the face:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，您可以看到左眼周围画了一个红色圆圈，右眼周围画了一个浅蓝色圆圈，嘴周围画了一个绿色圆圈，并且在围绕脸部的蓝色矩形的中心有一个白点：
- en: '![](img/7eeb20e3-f8af-452c-86b4-c69022a3d216.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eeb20e3-f8af-452c-86b4-c69022a3d216.png)'
- en: 'Using three `if` conditions, we will check when the `lefteyedetect`, `righteyedetect`,
    and `isSmiling` variables are `true`, and when they are `true`, we will turn on
    their respective LEDs:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三个`if`条件，我们将检查`lefteyedetect`、`righteyedetect`和`isSmiling`变量何时为`true`，并在它们为`true`时打开它们各自的LED：
- en: 'The `lefteyedetect` variable will be `true` when the left eye is detected.
    When the left eye is detected, we will turn on the left LED on the robot, which
    is connected to wiringPi pin 0, as shown in the following code:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当检测到左眼时，`lefteyedetect`变量将为`true`。当检测到左眼时，我们将打开连接到wiringPi引脚0的机器人上的左LED，如下面的代码所示：
- en: '[PRE28]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `righteyedetect` variable will be `true` when the right eye is detected.
    When the right eye is detected, we will turn on the right LED on the robot, which
    is connected to wiringPi pin 2:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当检测到右眼时，`righteyedetect`变量将为`true`。当检测到右眼时，我们将打开连接到wiringPi引脚2的机器人上的右LED：
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, the `isSmiling`variable will be true when the smile is recognized.
    When the smile is recognized, we will turn on the middle LED, which is connected
    to wiringPi pin 3:'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，当识别到微笑时，`isSmiling`变量将为true。当识别到微笑时，我们将打开连接到wiringPi引脚3的中间LED：
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Next, we will use the white dot (point) on the face rectangle to move the robot
    left and right.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用脸部矩形上的白点（点）将机器人向左和向右移动。
- en: Using the white dot on the face triangle to move the robot
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用脸部三角形上的白点移动机器人
- en: 'Similar to [Chapter 7](b5b2dffa-7833-47cc-98d9-e60e6aba7299.xhtml), *Building
    an Object-Following Robot with OpenCV*, we will divide the camera screen into
    three sections: the left section, the middle section, and the right section. When
    the white dot is in the left or right section, we will turn the robot left or
    right, thus tracking the face. Even though I have not resized `videofeed`, the
    resolution of `videofeed` is set to 640 x 480 (a width of 640 and a height of
    480).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 与[第7章](b5b2dffa-7833-47cc-98d9-e60e6aba7299.xhtml)类似，*使用OpenCV构建一个目标跟踪机器人*，我们将摄像头屏幕分为三个部分：左侧部分、中间部分和右侧部分。当白点位于左侧或右侧部分时，我们将向左或向右转动机器人，从而跟踪脸部。即使我没有调整`videofeed`的大小，`videofeed`的分辨率设置为640
    x 480（宽度为640，高度为480）。
- en: 'You can vary the range as per your requirements, but as shown in the following
    diagram, the left section is set to an x range from 0 to 280, the middle section
    is set to a range of 280-360, and the right section is set to a range of 360 to
    640:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据需要变化范围，但如下图所示，左侧部分设置为x范围从0到280，中间部分设置为280-360的范围，右侧部分设置为360到640的范围：
- en: '![](img/4fd8cbfd-0afb-421f-841d-bc4db4dbab54.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4fd8cbfd-0afb-421f-841d-bc4db4dbab54.png)'
- en: 'When we move our face, the face rectangle will move, and when the face rectangle
    moves, the white dot in the center of the rectangle will also move. When the dot
    moves, there will be changes in the `facex` and `facey` values. When dividing
    the camera screen into three sections, we will use the `facex` variable as a reference,
    and then we will use three if conditions to check which section the white dot
    is in. The code for comparing the `facex` values is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们移动我们的脸时，脸部矩形将移动，当脸部矩形移动时，矩形中心的白点也会移动。当点移动时，`facex`和`facey`的值将发生变化。将摄像头屏幕分为三个部分时，我们将使用`facex`变量作为参考，然后我们将使用三个if条件来检查白点位于哪个部分。用于比较`facex`值的代码如下：
- en: '[PRE31]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: If the first `if` condition is satisfied, this means that the white dot is between
    0 to 280\. In this case, we are printing the `Left` text on `videofeed` and then
    using the `softPwmWrite` function so that the robot will take an axial left turn.
    Inside the `softPwmWrite` function, the first parameter represents the pin number
    and the second parameter represents the speed at which our motor will move. Since
    wiringPi pin 24 is set to 0 (low), and wiringPi pin 27 is set to 30, the left
    motor will move backwards with a speed of 30\. Similarly, since wiringPi pin 25
    is set to 30, and wiringPi pin 28 is set to 0 (low), the right motor will move
    forward with a speed of 30.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果满足第一个`if`条件，这意味着白点位于0到280之间。在这种情况下，我们在`videofeed`上打印`Left`文本，然后使用`softPwmWrite`函数，使机器人进行轴向左转。在`softPwmWrite`函数内，第一个参数代表引脚号，第二个参数代表我们的电机移动的速度。由于wiringPi引脚24设置为0（低），wiringPi引脚27设置为30，左电机将以30的速度向后移动。同样，由于wiringPi引脚25设置为30，wiringPi引脚28设置为0（低），右电机将以30的速度向前移动。
- en: The speed value of 30 is in the range of 0 to 100, which we set in the `softPwmCreate`
    function. You can also vary the speed value.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 30的速度值在0到100的范围内，我们在`softPwmCreate`函数中设置。您也可以改变速度值。
- en: If the white dot is between 360 and 640, the `Right` text will be printed and
    the robot will take an axial right turn at a speed of 30.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果白点位于360到640之间，将打印`Right`文本，并且机器人将以30的速度进行轴向右转。
- en: Finally, when the white dot is between 280 and 360, the `Middle` text will be
    printed and the robot will stop moving.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当白点位于280到360之间时，将打印`Middle`文本，机器人将停止移动。
- en: This is how we can make the robot track a face and follow it.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何让机器人跟踪脸部并跟随它。
- en: Summary
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we used the Haar face classifier to detect a face from a video
    feed and then we drew a rectangle around it. Next, we detected the eyes and smile
    from a given face, and drew circles around the eyes and mouth. After this, using
    our knowledge of face, eye, and smile detection, we turned the LEDs of our robot
    on and off when the eyes and smile were detected. Finally, by creating a white
    dot in the center of the face rectangle, we made the robot follow our face.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用Haar面部分类器从视频源中检测面部，然后在其周围画一个矩形。接下来，我们从给定的面部检测眼睛和微笑，并在眼睛和嘴周围画圈。之后，利用我们对面部、眼睛和微笑检测的知识，当检测到眼睛和微笑时，我们打开和关闭机器人的LED。最后，通过在脸部矩形中心创建一个白点，我们使机器人跟随我们的脸。
- en: In the next chapter, we will learn how to control our robot using our voice.
    We will also create an Android application that will recognize what we are speaking
    about. When the Android application detects certain keywords, the Android smartphone's
    Bluetooth will send bits of data to the Raspberry Pi Bluetooth. Once our robot
    recognizes these keywords, we will use them to move the robot in different directions.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用我们的声音控制机器人。我们还将创建一个Android应用程序，用于识别我们所说的内容。当Android应用程序检测到特定关键词时，Android智能手机的蓝牙将向树莓派蓝牙发送数据位。一旦我们的机器人识别出这些关键词，我们将使用它们来使机器人朝不同方向移动。
- en: Questions
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the name of the classifier that we use to detect faces?
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用于检测面部的分类器的名称是什么？
- en: When we open the mouth, which type of feature is created?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们张开嘴时，会创建哪种类型的特征？
- en: Which cascade can be used to detect only the left eye?
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个级联可以用于仅检测左眼？
- en: When detecting the eyes from the face, what is that region generally referred
    to as?
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从面部检测眼睛时，该区域通常被称为什么？
- en: What is the use of the `equalizeHist` function?
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`equalizeHist`函数的用途是什么？'
