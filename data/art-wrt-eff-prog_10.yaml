- en: '*Chapter 8*: Concurrency in C++'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：C++中的并发'
- en: 'The purpose of this chapter is to describe the features for concurrent programming
    that were added to the language recently: in the C++17 and C++20 standards. While
    it is too early to talk about the best practices in using these features for optimum
    performance, we can describe what they do, as well as the current state of the
    compiler support.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是描述最近添加到语言中的并发编程功能：在C++17和C++20标准中。虽然现在讨论使用这些功能以获得最佳性能的最佳实践还为时过早，但我们可以描述它们的功能，以及编译器支持的当前状态。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introduction of concurrency into the C++ language in C++11
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在C++11中将并发引入C++语言
- en: Parallel STL algorithms in C++17
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++17中的并行STL算法
- en: Coroutines in C++20
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++20中的协程
- en: After reading this chapter, you will know the features that C++ offers to help
    write concurrent programs. The chapter is not meant to be a comprehensive manual
    for C++ concurrency features. Rather, it's an overview of the available language
    facilities, a starting point from which you can further explore the subjects that
    interest you.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，您将了解C++提供的功能，以帮助编写并发程序。本章并不意味着是C++并发功能的全面手册，而是对可用语言设施的概述，作为您进一步探索感兴趣主题的起点。
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: If you want to experiment with the language features offered by the recent C++
    versions, you will need a very modern compiler. For some features, you may also
    need additional tools installed; we will point this out when we describe a specific
    language feature. The code accompanying this chapter can be found at [https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter08](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter08).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想尝试最近C++版本提供的语言功能，您将需要一个非常现代的编译器。对于某些功能，您可能还需要安装其他工具；当我们描述特定的语言功能时，我们会指出这一点。本章附带的代码可以在[https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter08](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter08)找到。
- en: Concurrency support in C++11
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: C++11中的并发支持
- en: Before C++11, the C++ standard made no mention of concurrency. Of course, in
    practice, programmers wrote multi-threaded and distributed programs in C++ long
    before 2011\. What made that possible was the fact that the compiler writers have
    voluntarily adopted additional restrictions and guarantees, usually by way of
    complying with both the C++ standard (for the language) and another standard,
    such as POSIX, for concurrency support.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++11之前，C++标准没有提及并发。当然，在实践中，程序员在2011年之前就已经使用C++编写了多线程和分布式程序。这是可能的原因是编译器编写者自愿采用了额外的限制和保证，通常是通过遵守C++标准（用于语言）和其他标准（如POSIX）来支持并发。
- en: C++11 has changed that by introducing the **C++ memory model**. The memory model
    describes how threads interact through memory. For the first time, the C++ language
    was on a solid foundation about concurrency. The immediate practical impact, however,
    was rather muted since the new C++ memory model was quite similar to the memory
    models already supported by most compiler writers. There were some subtle differences
    between those models, and the new standard finally guaranteed the portable behavior
    of the programs that encounter these dark corners.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: C++11通过引入**C++内存模型**改变了这一点。内存模型描述了线程如何通过内存进行交互。这是C++语言首次在并发方面有了坚实的基础。然而，其直接实际影响相当有限，因为新的C++内存模型与大多数编译器编写者已经支持的内存模型非常相似。这些模型之间存在一些微妙的差异，新标准最终保证了遇到这些黑暗角落的程序的可移植行为。
- en: 'Of more immediate practical use were several language features that directly
    supported multi-threading. First of all, the standard introduced the notion of
    a thread. There were notably few guarantees about the behavior of threads, but
    most implementations simply use the system threads to support C++ threads. This
    is fine at the lowest level of the implementation but insufficient for any but
    the simplest program. For instance, a naïve attempt to create a new thread for
    every independent task the program has to perform is almost guaranteed to fail:
    launching new threads takes time, and very few operating systems can handle millions
    of threads efficiently. On the other hand, for the programmers who implemented
    their thread schedulers, the C++ thread interface does not offer sufficient control
    over thread behavior (most thread attributes are OS-specific).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 更直接的实际用途是几种直接支持多线程的语言特性。首先，标准引入了线程的概念。关于线程行为的保证明显很少，但大多数实现通常使用系统线程来支持C++线程。这在实现的最低级别是可以的，但对于除了最简单的程序之外的任何程序都不够。例如，试图为程序必须执行的每个独立任务创建一个新线程几乎肯定会失败：启动新线程需要时间，很少有操作系统能够有效地处理数百万个线程。另一方面，对于实现其线程调度程序的程序员来说，C++线程接口并不提供足够对线程行为的控制（大多数线程属性是特定于操作系统的）。
- en: 'Next, the standard introduced several synchronization primitives for controlling
    concurrent accesses to memory. The language provides `std::mutex`, which is usually
    implemented using the regular system mutex: on POSIX platforms, this is typically
    the POSIX mutex. The standard provides timed and recursive variants of the mutex
    (again, following POSIX). To simplify exception handling, the locking and unlocking
    of mutexes directly should be avoided in favor of the RAII template `std::lock_guard`.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，标准引入了几种用于控制并发访问内存的同步原语。语言提供了`std::mutex`，通常使用常规系统互斥量实现：在POSIX平台上，这通常是POSIX互斥量。标准提供了互斥量的定时和递归变体（再次遵循POSIX）。为了简化异常处理，应避免直接锁定和解锁互斥量，而应优先使用RAII模板`std::lock_guard`。
- en: For locking multiple mutexes safely, without the risk of a deadlock, the standard
    provides the `std::lock()` function (while it guarantees no deadlocks, the algorithm
    it uses is unspecified, and the performance of specific implementations varies
    widely). The other commonly used synchronization primitive is a condition variable,
    `std::condition_variable`, and the respective waiting and signaling operations.
    This functionality also follows the corresponding POSIX features quite closely.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安全地锁定多个互斥锁，而不会出现死锁的风险，标准提供了`std::lock()`函数（虽然它保证不会出现死锁，但它使用的算法是未指定的，特定实现的性能差异很大）。另一个常用的同步原语是条件变量，`std::condition_variable`，以及相应的等待和信号操作。这个功能也非常接近对应的POSIX特性。
- en: 'Then, there is support for low-level atomic operations: `std::atomic`, atomic
    operations such as compare-and-swap, and memory order specifiers. We have covered
    their behavior and applications in [*Chapter 5*](B16229_05_Epub_AM.xhtml#_idTextAnchor084),
    *Threads, Memory, and Concurrency*, [*Chapter 6*](B16229_06_Epub_AM.xhtml#_idTextAnchor103),
    *Concurrency and Performance*, and [*Chapter 7*](B16229_07_Epub_AM.xhtml#_idTextAnchor117),
    *Data Structures for Concurrency*.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，还有对低级原子操作的支持：`std::atomic`，比如比较和交换，以及内存顺序说明符。我们已经在《第5章》、《线程、内存和并发》、《第6章》、《并发和性能》和《第7章》、《并发数据结构》中介绍了它们的行为和应用。
- en: 'Finally, the language added support for asynchronous execution: where a function
    can be invoked asynchronously (possibly on another thread) using `std::async`.
    While this might enable concurrent programming, in practice, this feature is almost
    entirely useless for high-performance applications. Most implementations will
    either provide very limited parallelism or execute each asynchronous function
    call on its own thread. Most operating systems have a rather high overhead for
    creating and joining threads (the only OS I have seen that makes concurrent programming
    as simple as *fire up a thread for every task, millions of them if you need to*
    was AIX, on every other OS I know this is a recipe for chaos).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该语言增加了对异步执行的支持：可以使用`std::async`异步调用函数（可能在另一个线程上）。虽然这可能会实现并发编程，但实际上，这个特性对于高性能应用几乎是完全无用的。大多数实现要么提供非常有限的并行性，要么在自己的线程上执行每个异步函数调用。大多数操作系统创建和加入线程的开销相当高（我见过的唯一一个使并发编程变得像“为每个任务启动一个线程，如果需要的话，可以有数百万个”简单的操作系统是AIX，在我知道的其他操作系统上，这是一种混乱的做法）。
- en: Overall, we can say that, when it comes to concurrency, C++11 was a major step
    forward conceptually but offered modest immediate practical gains. C++14 improvements
    were focused elsewhere, so nothing of note changed with regard to concurrency.
    Next, we will see what new developments were brought in C++17.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，可以说，就并发而言，C++11在概念上是一个重大的进步，但在实际上提供了适度的即时实际收益。C++14的改进集中在其他地方，因此在并发方面没有什么值得注意的变化。接下来，我们将看看C++17带来了哪些新的发展。
- en: Concurrency support in C++17
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: C++17中的并发支持
- en: C++17 brought with it one major advance and several minor tweaks to concurrency-related
    features. Let us quickly cover the latter first. The `std::lock()` function that
    was introduced in C++11 now has a corresponding RAII object, `std::scoped_lock`.
    A shared mutex, `std::shared_mutex`, otherwise known as a **read-write mutex**,
    was added (again, matching the corresponding POSIX feature). This mutex allows
    multiple threads to proceed as long as they do not need exclusive access to the
    locked resource. Usually, such threads perform read-only operations, while a writer
    thread needs exclusive access, hence the name **read-write lock**. It's a clever
    idea in theory, but most implementations offer dismal performance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: C++17带来了一个重大进步和几个与并发相关的次要调整。让我们先快速介绍后者。在C++11中引入的`std::lock()`函数现在有了相应的RAII对象，`std::scoped_lock`。另外，添加了一个共享互斥锁，`std::shared_mutex`，也称为**读-写互斥锁**（再次匹配相应的POSIX特性）。这个互斥锁允许多个线程继续进行，只要它们不需要对锁定资源进行独占访问。通常，这些线程执行只读操作，而写线程需要独占访问，因此称为**读-写锁**。这在理论上是一个聪明的想法，但大多数实现的性能都很差。
- en: Of note is a new feature that allows portably determining the cache line size
    for L1 cache, `std::hardware_destructive_interference_size`, and `std::hardware_constructive_interference_size`.
    These constants help create cache-optimal data structures that avoid false sharing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是一个新特性，可以可移植地确定L1缓存的缓存行大小，`std::hardware_destructive_interference_size`和`std::hardware_constructive_interference_size`。这些常量有助于创建避免伪共享的缓存最优数据结构。
- en: 'Now we come to the major new feature in C++17 – `std::for_each`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来到了C++17中的主要新特性——`std::for_each`：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In C++17, we can ask the library to do this computation in parallel on all
    available processors:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++17中，我们可以要求库在所有可用的处理器上并行进行这个计算：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The parallel versions of STL algorithms have a new first argument: the execution
    policy. Note that the execution policy is not a single type but rather a template
    parameter. The standard provides several execution policies; the parallel policy
    `std::execution::par` that we used earlier allows the algorithm to execute on
    multiple threads. The number of threads and the way the computations are partitioned
    within threads are unspecified and depend on the implementation. The sequential
    policy `std::execution::seq` executes the algorithm on a single thread, the same
    way it''s executed without any policies (or before C++17).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: STL算法的并行版本有一个新的第一个参数：执行策略。请注意，执行策略不是单一类型，而是一个模板参数。标准提供了几种执行策略；我们之前使用的并行策略`std::execution::par`允许算法在多个线程上执行。线程的数量以及计算在线程内的分区方式是未指定的，取决于实现。顺序策略`std::execution::seq`在单个线程上执行算法，就像没有任何策略（或在C++17之前）执行的方式一样。
- en: 'There is also a parallel unsequenced policy, `std::execution::par_unseq`. The
    difference between the two parallel policies is subtle but important to understand.
    The standard says that the unsequenced policy allows computations to be interleaved
    within a single thread, which allows additional optimizations such as vectorization.
    But an optimizing compiler can use vector instructions like AVX when generating
    machine code, and it''s done without any help from the source C++ code: the compiler
    just finds vectorization opportunities and replaces regular single-word instructions
    with vector ones. So what is different here?'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个并行的无序策略，`std::execution::par_unseq`。两种并行策略之间的区别微妙但很重要。标准规定，无序策略允许计算在单个线程内交错进行，这允许额外的优化，比如矢量化。但是优化编译器可以在生成机器代码时使用矢量指令，比如AVX，并且这是在没有源C++代码的帮助下完成的：编译器只是找到矢量化机会，并用矢量指令替换常规的单字指令。那么这里有什么不同呢？
- en: 'To understand the nature of the unsequenced policies, we have to consider a
    more complex example. Let us say that, instead of simply operating on every element,
    we want to do some computation that uses shared data:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解无序策略的性质，我们必须考虑一个更复杂的例子。假设我们不仅仅是对每个元素进行操作，而是要进行一些使用共享数据的计算：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here we do some computations on each vector element, then accumulate the sum
    of the results. The computations themselves can be done in parallel, but the accumulation
    must be protected by a lock since all threads increment the same shared variable
    `res`. The parallel execution policy is safe to use, thanks to the lock. However,
    we cannot use an unsequenced policy here: if the same thread were to process multiple
    vector elements at the same time (interleaved), it could attempt to acquire the
    same lock multiple times. This is a guaranteed deadlock: if a thread is holding
    the lock and tries to lock it again, the second attempt will block, and the thread
    cannot proceed to the point where it would have unlocked the lock. The standard
    calls code such as our last example **vectorization-unsafe** and states that such
    code should not be used with unsequenced policies.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对每个向量元素进行一些计算，然后累加结果的总和。计算本身可以并行进行，但累加必须受到锁的保护，因为所有线程都会增加相同的共享变量`res`。并行执行策略是安全的，多亏了锁。然而，我们不能在这里使用无序策略：如果同一个线程同时处理多个向量元素（交错），它可能会尝试多次获取相同的锁。这是一个保证的死锁：如果一个线程持有锁并尝试再次锁定它，第二次尝试将被阻塞，线程无法继续到达解锁锁的点。标准称我们最后一个示例的代码为**不安全的矢量化**，并且规定不应该在无序策略下使用这样的代码。
- en: Now that we have seen how parallel algorithms work in theory, how about in practice?
    The short answer is *quite well, with some caveats*. Read on for the long version.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了并行算法在理论上是如何工作的，那么在实践中呢？简短的答案是*相当好，但有一些注意事项*。继续阅读详细版本。
- en: Before you can check out parallel algorithms in practice, you have to do some
    work to prepare your built environment. Usually, to compile C++ programs, you
    just need to install the desired compiler version, such as GCC, and you are ready
    to go. Not so with parallel algorithms. At the time this book is written, the
    installation process is somewhat cumbersome.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中检查并行算法之前，您必须做一些准备工作来准备您的构建环境。通常，要编译C++程序，您只需要安装所需的编译器版本，比如GCC，然后就可以开始了。但是并行算法不是这样。在撰写本书时，安装过程有些繁琐。
- en: 'Recent enough versions of GCC and Clang include parallel STL headers (in some
    installations, Clang requires GCC to be installed because it uses GCC-provided
    parallel STL). The problem appears at the lower level. The runtime threading system
    used by both compilers is Intel **Threading Building Blocks** (**TBB**), which
    comes as a library with its own set of headers. Neither compiler includes TBB
    in its installation. To complicate matters even more, each version of the compiler
    requires the corresponding version of TBB: neither an older nor a more recent
    version will work (the failures can manifest themselves at both compile and link-time).
    To run the programs linked with TBB, you will likely need to add the TBB libraries
    to your library path.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 足够新的GCC和Clang版本包括并行STL头文件（在某些安装中，Clang需要安装GCC，因为它使用由GCC提供的并行STL）。问题出现在更低的层次。这两个编译器使用的运行时线程系统是英特尔**线程构建块**（**TBB**），它作为一个带有自己一套头文件的库提供。两个编译器都没有在其安装中包含TBB。更复杂的是，每个编译器版本都需要相应版本的TBB：旧版本和更近版本都不起作用（失败可能会在编译和链接时都表现出来）。要运行与TBB链接的程序，您可能需要将TBB库添加到库路径中。
- en: Once you have resolved all these problems and configured a working installation
    of the compiler and necessary libraries, using parallel algorithms is no harder
    than using any STL code. So, how well does it scale? We can run some benchmarks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你解决了所有这些问题并配置了编译器和必要库的工作安装，使用并行算法就不比使用任何STL代码更难。那么，它的扩展性如何？我们可以运行一些基准测试。
- en: 'Let us start with `std::for_each` without any locks and with a lot of computations
    for each element (function `work()` is expensive, the exact operations don''t
    really matter for our current focus on scaling):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`std::for_each`开始，没有任何锁，并且对每个元素进行了大量的计算（函数`work()`很昂贵，对于我们目前关注的扩展性来说，确切的操作并不重要）：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the performance of the sequential versus the parallel version running
    on 2 threads:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在2个线程上运行的顺序与并行版本的性能：
- en: '![Figure 8.1 – Benchmark of parallel std::foreach on 2 CPUs'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 - 在2个CPU上并行std::foreach的基准测试'
- en: '](img/Figure_8.1_B16229.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.1_B16229.jpg)'
- en: Figure 8.1 – Benchmark of parallel std::foreach on 2 CPUs
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 - 在2个CPU上并行std::foreach的基准测试
- en: 'The scaling is not bad. Note that the vector size `N` is fairly large, 32K
    elements. The scaling does improve for larger vectors. However, for relatively
    small amounts of data, the performance of parallel algorithms is very poor:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展性并不差。请注意，向量大小`N`相当大，有32K个元素。对于更大的向量，扩展性确实有所提高。但是，对于相对较小的数据量，并行算法的性能非常差：
- en: '![Figure 8.2 – Benchmark of parallel std::foreach for short sequences'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 - 用于短序列的并行std::foreach的基准测试'
- en: '](img/Figure_8.2_B16229.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.2_B16229.jpg)'
- en: Figure 8.2 – Benchmark of parallel std::foreach for short sequences
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2-并行std::foreach进行短序列的基准
- en: The parallel version is slower than the sequential version for vectors of 1024
    elements. The reason is that the execution policy starts all the threads at the
    beginning of each parallel algorithm and joins them at the end. Launching new
    threads takes significant time, so when the computation is short, the overhead
    overwhelms any speedup we can get from parallelism. This is not a requirement
    imposed by the standard, but the way the current implementation of parallel STL
    in GCC and Clang manages its interactions with the TBB system.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于1024个元素的向量，并行版本比顺序版本慢。原因是执行策略在每个并行算法的开始时启动所有线程，并在结束时加入它们。启动新线程需要显着的时间，因此当计算很短时，开销会压倒并行性带来的任何加速。这不是标准强加的要求，而是GCC和Clang当前实现的并行STL与TBB系统交互的方式。
- en: 'Of course, the size for which parallel algorithms improve performance depends
    on the hardware, the compiler and its implementation of parallelism, and the amount
    of computation per element. For example, we can try a very simple per-element
    computation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并行算法改善性能的大小取决于硬件、编译器及其并行实现，以及每个元素的计算量。例如，我们可以尝试一个非常简单的每个元素计算：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now processing the same 32K-element vector shows no benefit of parallelism:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在处理相同的32K元素向量不显示并行性的好处：
- en: '![Figure 8.3 – Benchmark of parallel std::foreach for cheap per-element computations'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.3-并行std::foreach进行廉价的每个元素计算的基准'
- en: '](img/Figure_8.3_B16229.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.3_B16229.jpg)'
- en: Figure 8.3 – Benchmark of parallel std::foreach for cheap per-element computations
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3-并行std::foreach进行廉价的每个元素计算的基准
- en: For much larger vector sizes, the parallel algorithm may get ahead unless memory
    access speed limits the performance of both single- and multi-threaded versions
    (this is a very much memory-bound computation).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更大的向量大小，除非内存访问速度限制了单线程和多线程版本的性能（这是一个非常受内存限制的计算），并行算法可能会领先。
- en: 'Perhaps more impressive is the performance of algorithms that are more difficult
    to parallelize, such as `std::sort`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 也许更令人印象深刻的是更难并行化的算法的性能，比如`std::sort`：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is the output for it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出：
- en: '![Figure 8.4 – Benchmark of parallel std::sort'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.4-并行std::sort的基准'
- en: '](img/Figure_8.4_B16229.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.4_B16229.jpg)'
- en: Figure 8.4 – Benchmark of parallel std::sort
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4-并行std::sort的基准
- en: 'Again, we need a sufficiently large amount of data before the parallel algorithm
    becomes effective (for 1024 elements, single-threaded sort is faster). This is
    quite a remarkable achievement: sort is not the easiest algorithm to parallelize,
    and per-element computations on doubles (comparison and swap) are very cheap.
    Nonetheless, the parallel algorithm shows very good speedup, and it gets better
    if the element comparison is more expensive.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们需要足够大量的数据才能使并行算法变得有效（对于1024个元素，单线程排序更快）。这是一个非常显著的成就：排序不是最容易并行化的算法，而双精度浮点数的每个元素计算（比较和交换）非常便宜。尽管如此，并行算法显示出非常好的加速，并且如果元素比较更昂贵，它会变得更好。
- en: 'You might wonder how parallel STL algorithms interact with your threads, that
    is, what happens if you run two parallel algorithms on two threads simultaneously?
    First of all, like with any code running on multiple threads, you have to ensure
    thread safety (running two sorts on the same container in parallel is a bad idea
    no matter which sort you use). Other than that, you will find that multiple parallel
    algorithms coexist just fine, but you have no control over job scheduling: each
    of them tries to run on all available CPUs, so they compete for the resources.
    Depending on how well each algorithm scales, you may or may not get higher overall
    performance by running several algorithms in parallel.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道并行STL算法如何与您的线程交互，也就是说，如果同时在两个线程上运行两个并行算法会发生什么？首先，与在多个线程上运行的任何代码一样，您必须确保线程安全（在同一容器上并行运行两个排序无论使用哪种排序都是一个坏主意）。除此之外，您会发现多个并行算法可以很好地共存，但您无法控制作业调度：它们中的每一个都会尝试在所有可用的CPU上运行，因此它们会竞争资源。取决于每个算法的扩展性如何，您可能会或可能不会通过并行运行多个算法来获得更高的整体性能。
- en: Overall, we can conclude that the parallel versions of STL algorithms deliver
    very good performance when they operate on large enough data volumes, although
    what is *large enough* depends on the particular computation. Additional libraries
    may be needed to compile and run programs that use parallel algorithms, and configuring
    these libraries may require some effort, as well as experimentation. Also, not
    all STL algorithms have their parallel equivalents (for example, `std::accumulate`
    does not).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们可以得出结论，当它们在足够大的数据量上操作时，STL算法的并行版本提供非常好的性能，尽管“足够大”取决于特定的计算。可能需要额外的库来编译和运行使用并行算法的程序，并且配置这些库可能需要一些努力和实验。此外，并非所有STL算法都有其并行等价物（例如，`std::accumulate`没有）。
- en: ….
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '....'
- en: We are now ready to flip a few more pages on the calendar and jump forward to
    C++20.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备翻动日历上的几页，并跳到C++20。
- en: Concurrency support in C++20
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: C++20中的并发支持
- en: 'C++20 added a few enhancements here and there to the existing concurrency support,
    but we are going to focus on the major new addition: coroutines. Coroutines, in
    general, are functions that can be interrupted and resumed. They are useful in
    several major applications: they can greatly simplify writing event-driven programs,
    they are almost unavoidable for work-stealing thread pools, and they make writing
    asynchronous I/O and other asynchronous code much easier.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: C++20在现有并发支持中增加了一些增强功能，但我们将专注于主要的新添加：协程。协程通常是可以中断和恢复的函数。它们在几个主要应用中非常有用：它们可以极大地简化编写事件驱动程序，对于工作窃取线程池几乎是不可避免的，而且它们使编写异步I/O和其他异步代码变得更加容易。
- en: The foundations of coroutines
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协程的基础
- en: 'There are two styles of coroutines: **stackful** and **stackless**. Stackful
    coroutines are also sometimes called **fibers**; they are similar to functions
    wherein their state is allocated on the stack. Stackless coroutines have no corresponding
    stack allocations, their state is stored on the heap. In general, stackful coroutines
    are more powerful and flexible, but stackless coroutines are significantly more
    efficient.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种风格的协程：**堆栈式**和**无堆栈式**。堆栈式协程有时也被称为**纤程**；它们类似于函数，它们的状态是在堆栈上分配的。无堆栈式协程没有对应的堆栈分配，它们的状态存储在堆上。一般来说，堆栈式协程更强大和灵活，但无堆栈式协程要高效得多。
- en: In this book, we will focus on stackless coroutines since this is what C++20
    supports. This is a sufficiently unusual concept that we need to explain before
    we show C++-specific syntax and examples.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将专注于无堆栈式协程，因为这是C++20支持的。这是一个足够不寻常的概念，我们需要在展示C++特定的语法和示例之前进行解释。
- en: 'A regular C++ function always has a corresponding stack frame. This stack frame
    exists for as long as the function is running, and that is where all the local
    variables and other states are stored. Here is a simple function `f()`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个普通的C++函数总是有一个对应的堆栈帧。这个堆栈帧存在的时间与函数运行的时间一样长，这就是所有局部变量和其他状态存储的地方。这里有一个简单的函数`f()`：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It has a corresponding stack frame. The function `f()` may call another function,
    `g()`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 它有一个对应的堆栈帧。函数`f()`可能调用另一个函数`g()`：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The function `g()` also has a stack frame that exists while the function is
    running.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`g()`在运行时也有一个堆栈帧。
- en: 'Refer to the following figure:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图表：
- en: '![Figure 8.5 – Stack frames of regular functions'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.5 – 普通函数的堆栈帧'
- en: '](img/Figure_8.5_B16229.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.5_B16229.jpg)'
- en: Figure 8.5 – Stack frames of regular functions
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 – 普通函数的堆栈帧
- en: When function `g()` exits, its stack frame is destroyed, and only the frame
    of the function `f()` remains.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当函数`g()`退出时，它的堆栈帧被销毁，只剩下函数`f()`的帧。
- en: 'In contrast, the state of the stackless coroutine is not stored on the stack
    but on the heap: this allocation is called the **activation frame**. The activation
    frame is associated with a coroutine handle, which is an object that acts as a
    smart pointer. Function calls can be made and returned from, but the activation
    frame persists as long as the handle is not destroyed.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，无堆栈式协程的状态不是存储在堆栈上而是存储在堆上：这种分配被称为**激活帧**。激活帧与协程句柄相关联，它是一个充当智能指针的对象。可以进行函数调用和返回，但只要句柄没有被销毁，激活帧就会持续存在。
- en: 'The coroutine also needs stack space, for example, if it calls other functions.
    This space is allocated on the stack of the caller. Here is how it works (the
    real C++ syntax is different, so think of the coroutine-related lines as pseudocode
    for now):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 协程也需要堆栈空间，例如，如果它调用其他函数。这个空间是在调用者的堆栈上分配的。它是如何工作的（真正的C++语法不同，所以现在把与协程相关的行当作伪代码来考虑）：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The corresponding memory allocations are shown in the following figure:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的内存分配如下图所示：
- en: '![Figure 8.6 – Coroutine call'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.6 – 协程调用'
- en: '](img/Figure_8.6_B16229.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.6_B16229.jpg)'
- en: Figure 8.6 – Coroutine call
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 – 协程调用
- en: 'The function `f()` creates a coroutine handle object, which owns the activation
    frame. Then it calls the coroutine function `coro()`. There is some stack allocation
    at this point, in particular, the coroutine stores on the stack the address where
    it would return if it is suspended (remember that coroutines are functions that
    can suspend themselves). The coroutine can call another function `g()`, which
    allocates the stack frame of `g()` on the stack. At this point, the coroutine
    can no longer suspend itself: it is possible to suspend only from the top level
    of the coroutine function. Function `g()` runs the same way no matter who called
    it and eventually returns, which destroys its stack frame. The coroutine can suspend
    itself now, so let us assume that it does.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`f()`创建一个协程句柄对象，它拥有激活帧。然后调用协程函数`coro()`。在这一点上有一些堆栈分配，特别是协程在堆栈上存储它如果被挂起时将返回的地址（记住协程是可以自己挂起的函数）。协程可以调用另一个函数`g()`，它在堆栈上分配`g()`的堆栈帧。在这一点上，协程不能再挂起自己：只能从协程函数的顶层挂起。函数`g()`无论是谁调用它都会以相同的方式运行，并最终返回，销毁它的堆栈帧。现在协程可以挂起自己，所以让我们假设它这样做了。
- en: 'This is the key difference between stackful and stackless coroutines: a stackful
    coroutine can be suspended anywhere, at an arbitrary depth of function calls,
    and will resume from that point. But this flexibility has a high cost in memory
    and especially runtime: stackless coroutines, with their limited state allocations,
    are much more efficient.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是堆栈式和无堆栈式协程之间的关键区别：堆栈式协程可以在任何地方挂起，在任意深度的函数调用中恢复。但是这种灵活性在内存和特别是运行时方面代价很高：无堆栈式协程，由于它们有限的状态分配，要高效得多。
- en: When a coroutine suspends itself, parts of the state that are necessary to resume
    it are stored in the activation frame. The stack frame of the coroutine is then
    destroyed, and the control returns to the caller, to the point where the coroutine
    was called. The same happens if the coroutine runs to completion, but there is
    a way for the caller to find out whether the coroutine is suspended or done.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个协程挂起自己时，为了恢复它所需的状态的一部分被存储在激活帧中。然后协程的堆栈帧被销毁，控制返回给调用者，返回到协程被调用的地方。如果协程运行完成，同样也是这样，但是调用者有办法找出协程是挂起还是完成。
- en: 'The caller continues its execution and may call other functions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 调用者继续执行并可能调用其他函数：
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The memory allocations now look as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在内存分配如下：
- en: '![Figure 8.7 – Coroutine is suspended, execution continues'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.7 – 协程被挂起，执行继续'
- en: '](img/Figure_8.7_B16229.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.7_B16229.jpg)'
- en: Figure 8.7 – Coroutine is suspended, execution continues
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – 协程被挂起，执行继续
- en: 'Note that there is no stack frame corresponding to the coroutine, only the
    heap-allocated activation frame. The coroutine can be resumed as long as the handle
    object is alive. It does not have to be the same function that calls and resumes
    the coroutine; for example, our function `h()` can resume it if it has access
    to the handle:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，协程没有对应于堆栈帧，只有堆分配的激活帧。只要句柄对象存在，协程就可以恢复。不一定是调用和恢复协程的相同函数；例如，如果函数`h()`可以访问句柄，它也可以恢复它：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The coroutine resumes from the point where it was suspended. Its state is restored
    from the activation frame, and any necessary stack allocations will happen as
    usual:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 协程从暂停的地方恢复。它的状态从激活帧中恢复，任何必要的堆栈分配都会像往常一样发生：
- en: '![Figure 8.8 – Coroutine is resumed from a different function'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.8 - 协程从不同的函数中恢复'
- en: '](img/Figure_8.8_B16229.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.8_B16229.jpg)'
- en: Figure 8.8 – Coroutine is resumed from a different function
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 - 协程从不同的函数中恢复
- en: Eventually, the coroutine completes, and the handle is destroyed; this deallocates
    all the memory associated with the coroutine.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，协程完成，并且句柄被销毁；这会释放与协程相关的所有内存。
- en: 'Here is a summary of what is important to know about C++20 coroutines:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于C++20协程的重要知识总结：
- en: 'Coroutines are functions that can suspend themselves. This is different from
    the OS suspending a thread: suspending a coroutine is done explicitly by the programmer
    (cooperative multitasking).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协程是可以自行暂停的函数。这与操作系统暂停线程不同：协程的暂停是由程序员显式完成的（协作式多任务处理）。
- en: Unlike regular functions, which are associated with stack frames, coroutines
    have handle objects. Coroutine state persists as long as the handle is alive.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与关联堆栈帧的常规函数不同，协程具有句柄对象。只要句柄存在，协程状态就会持续存在。
- en: After the coroutine is suspended, the control is returned to the caller, which
    continues to run the same way as if the coroutine had completed.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协程暂停后，控制权返回给调用者，继续以与协程完成相同的方式运行。
- en: The coroutine can be resumed from any location; it does not have to be the caller
    itself. Furthermore, the coroutine can even be resumed from a different thread
    (we will see an example later in this section). The coroutine is resumed from
    the point of suspension and continues to run *as if nothing happened* (but may
    be running on a different thread).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协程可以从任何位置恢复；不一定是调用者本身。此外，协程甚至可以从不同的线程中恢复（我们将在本节后面看到一个示例）。协程从暂停点恢复并继续运行*就好像什么都没发生*（但可能在不同的线程上运行）。
- en: Now let us see how all of this is done in real C++.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看在真正的C++中如何完成所有这些。
- en: Coroutine C++ syntax
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++协程语法
- en: Let us now see the C++ language constructs that are used for programming with
    coroutines.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看用于使用协程编程的C++语言构造。
- en: The first order of business is getting a compiler that supports this feature.
    Both GCC and Clang have coroutine support in their latest versions, but, unfortunately,
    not in the same way. For GCC, you need version 11 or later. For Clang, partial
    support was added in version 10 and was improved in later versions, although it
    still remains "experimental."
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首要任务是获得支持此功能的编译器。GCC和Clang的最新版本都支持协程，但不幸的是，方式不同。对于GCC，需要11版或更高版本。对于Clang，部分支持是在10版中添加的，并在后续版本中得到改进，尽管仍然是“实验性的”。
- en: First of all, in order to compile coroutine code, you need a compiler option
    on the command line (merely enabling C++20 with the `--std=c++20` option is not
    enough). For GCC, the option is `–fcoroutines`. For Clang, the options are `-stdlib=libc++
    -fcoroutines-ts`. No options except `/std:c++20` are needed for the latest Visual
    Studio.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，为了编译协程代码，您需要在命令行上使用编译器选项（仅使用`--std=c++20`选项启用C++20是不够的）。对于GCC，选项是`-fcoroutines`。对于Clang，选项是`-stdlib=libc++
    -fcoroutines-ts`。对于最新的Visual Studio，除了`/std:c++20`之外，不需要任何选项。
- en: Then, you need to include the coroutines header. In GCC and Visual Studio (and
    according to the standard), the header is `#include <coroutine>` and all the classes
    it declares are in namespace `std`. Unfortunately, in Clang, the header is `#include
    <experimental/coroutine>` and the namespace is `std::experimental`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您需要包含协程头文件。在GCC和Visual Studio中（以及根据标准），头文件是`#include <coroutine>`，它声明的所有类都在命名空间`std`中。不幸的是，在Clang中，头文件是`#include
    <experimental/coroutine>`，命名空间是`std::experimental`。
- en: 'There is no special syntax for declaring a coroutine: coroutines are, syntactically,
    just regular C++ functions. What makes them into coroutines is the use of the
    suspend operator `co_await` or its variant, `co_yield`. However, it''s not enough
    to call one of these operators in the body of the function: coroutines in C++
    have strict requirements for their return types. The standard library offers no
    help in declaring these return types and other classes necessary for working with
    coroutines. The language provides only a framework for programming with coroutines.
    As a result, the coroutine code that uses C++20 constructs directly is very verbose,
    repetitive, and contains a lot of boilerplate code. In practice, everybody who
    uses coroutines does so using one of several available coroutine libraries.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 声明协程没有特殊的语法：协程在语法上只是常规的C++函数。使它们成为协程的是使用暂停操作符`co_await`或其变体`co_yield`。然而，在函数体中调用其中一个操作符是不够的：C++中的协程对其返回类型有严格要求。标准库在声明这些返回类型和其他与协程一起工作的类方面没有提供帮助。语言只提供了一个用于使用协程的框架。因此，直接使用C++20构造的协程代码非常冗长、重复，并包含大量样板代码。实际上，所有使用协程的人都是使用几种可用的协程库。
- en: For practical programming, so should you. However, in this book, we show you
    examples written in *bare* C++. We do it because we do not want to direct you
    toward any particular library and because doing so would obscure the understanding
    of what is really going on. The support for coroutines is very recent, and the
    libraries are rapidly evolving; it is unlikely that your library of choice will
    stay the same. We would like you to understand the coroutine code at the C++ level
    instead of at the level of abstractions presented by a particular library. Then
    you should choose a library based on your needs and use its abstractions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际编程，你也应该这样做。然而，在本书中，我们展示的例子是用*纯*的C++编写的。我们这样做是因为我们不想引导你去使用特定的库，而且这样做会使人们对实际发生的事情的理解变得模糊。协程的支持非常新，库正在快速发展；你选择的库可能不会保持不变。我们希望你能理解C++级别的协程代码，而不是特定库提供的抽象级别。然后你可以根据自己的需求选择一个库并使用它的抽象。
- en: 'A thorough description of the syntax constructs related to coroutines would
    be remarkably non-intuitive: it is a framework, not a library. For that reason,
    we do the rest of the presentation using examples. If you really want to know
    all the syntax requirements for coroutines, you have to look up a very recent
    publication (or read the standard). But the examples should give you enough understanding
    of what coroutines can do that you can read the documentation for your favorite
    coroutine library instead and use it in your programs.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 与协程相关的语法构造的彻底描述将非常不直观：它是一个框架，而不是一个库。因此，我们用例子来完成剩下的演示。如果你真的想知道协程的所有语法要求，你必须查阅最近的出版物（或者阅读标准）。但是例子应该给你足够的理解，让你可以查阅你喜欢的协程库的文档，并在你的程序中使用它。
- en: Coroutine examples
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协程示例
- en: The first example is probably the most common use of coroutines in C++ (and
    the one for which the standard provides some explicitly designed syntax). We are
    going to implement a lazy generator. Generators are functions that generate sequences
    of data; every time you call the generator, you get a new element of the sequence.
    A lazy generator is a generator that computes elements on demand, as it is called.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个例子可能是C++中协程最常见的用法（也是标准提供了一些明确设计语法的用法）。我们将实现一个惰性生成器。生成器是生成数据序列的函数；每次调用生成器，都会得到序列的一个新元素。惰性生成器是一个按需计算元素的生成器，当调用时会计算元素。
- en: 'Here is a lazy generator based on C++20 coroutines:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基于C++20协程的惰性生成器：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As promised, this is very low-level C++, you rarely see code like this, but
    it allows us to explain all the steps. First of all, the coroutine `coro()` looks
    like any other function, except for the `co_yield` operator. This operator suspends
    the coroutine and returns the value `i` to the caller. Because the coroutine is
    suspended, not terminated, the operator can be executed multiple times. Just like
    any other function, the coroutine terminates when the control reaches the closing
    brace; at this point, it cannot be resumed. It is possible to exit the coroutine
    at any point by calling operator `co_return` (the regular `return` operator should
    not be used).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正如承诺的那样，这是非常低级的C++，你很少看到这样的代码，但它使我们能够解释所有的步骤。首先，协程`coro()`看起来像任何其他函数，除了`co_yield`操作符。这个操作符暂停协程并将值`i`返回给调用者。因为协程被暂停而不是终止，操作符可以被执行多次。就像任何其他函数一样，当控制流到达闭括号时，协程终止；在这一点上，它不能被恢复。可以通过调用`co_return`操作符（不应该使用常规的`return`操作符）在任何时候退出协程。
- en: 'Second, the return type of the coroutine – `generator` – is a special type
    that we are about to define. It has a lot of requirements on it, which results
    in lengthy boilerplate code (any coroutine library will have such types predefined
    for you). We can already see that `generator` contains a nested data member `h_`;
    that is the coroutine handle. The creation of this handle also creates the activation
    frame. The handle is associated with a `promise` object; this has absolutely nothing
    to do with C++11 `std::promise`. In fact, it is not one of the standard types
    at all: we have to define it according to a set of rules listed in the standard.
    At the end of the execution, the handle is destroyed, which destroys the coroutine
    state as well. The handle is, thus, similar to a pointer.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，协程的返回类型`generator`是一个我们即将定义的特殊类型。它对它有很多要求，这导致了冗长的样板代码（任何协程库都会为你预定义这样的类型）。我们已经可以看到`generator`包含一个嵌套的数据成员`h_`；那就是协程句柄。创建这个句柄也会创建激活帧。句柄与`promise`对象相关联；这与C++11的`std::promise`完全无关。事实上，它根本不是标准类型之一：我们必须根据标准中列出的一组规则来定义它。在执行结束时，句柄被销毁，这也会销毁协程状态。因此，句柄类似于指针。
- en: Finally, the handle is a callable object. Calling it resumes the coroutine,
    which generates the next value and promptly suspends itself again because the
    `co_yield` operator is in the loop.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，句柄是一个可调用对象。调用它会恢复协程，生成下一个值，并立即再次暂停，因为`co_yield`操作符在循环中。
- en: 'All of this is magically tied together by defining the appropriate return type
    for the coroutine. Just like the STL algorithms, the entire system is bound by
    convention: there are expectations on all types involved in this process, and
    something somewhere will not compile if these expectations are not met. Let us
    see the `generator` type now:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是通过定义协程的适当返回类型神奇地联系在一起的。就像STL算法一样，整个系统都受约定束缚：对于这个过程中涉及的所有类型都有期望，如果这些期望没有得到满足，某个地方将无法编译。现在让我们看看`generator`类型：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'First of all, the `return` type does not have to be generated from a template.
    We could have just declared a generator for integers. Usually, it is a template
    parameterized on the type of the elements in the generated sequence. Second, the
    name *generator* is in no way special: you can call this type anything you want
    (most libraries provide a similar template and call it `generator`). On the other
    hand, the nested type `generator::promise_type` *must* be called `promise_type`,
    otherwise, the program will not compile. Often, the nested type itself is called
    something else, and a type alias is used:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`return`类型不必从模板生成。我们可以只声明一个整数的生成器。通常，它是一个模板，参数化为生成序列中元素的类型。其次，名称*generator*在任何方面都不是特殊的：您可以将此类型命名为任何您想要的名称（大多数库提供类似的模板并将其称为`generator`）。另一方面，嵌套类型`generator::promise_type`
    *必须* 被称为`promise_type`，否则程序将无法编译。通常，嵌套类型本身被称为其他名称，并且使用类型别名：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `promise_type` type must be a nested type of the `generator` class (or,
    in general, any type returned by the coroutine). But the `promise` class does
    not have to be a nested class: usually, it is, but it could be declared outside
    as well.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`promise_type`类型必须是`generator`类（或者一般来说，协程返回的任何类型）的嵌套类型。但`promise`类不一定是一个嵌套类：通常是这样，但也可以在外部声明。'
- en: 'What is mandatory is the set of required member functions of the `promise`
    type, including their signatures. Note that some of the member functions are declared
    `noexcept`. This is part of the requirement, too: the program will not compile
    if you omit this specification. Of course, any function that is not required to
    be `noexcept` can be declared as such if it doesn''t throw.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 强制的是`promise`类型的一组必需成员函数，包括它们的签名。请注意，其中一些成员函数声明为`noexcept`。这也是要求的一部分：如果省略了这个规范，程序将无法编译。当然，如果不需要声明为`noexcept`的任何函数不会抛出异常，也可以声明为这样。
- en: The body of these required functions may be more complex for different generators.
    We will describe briefly what each of them does.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这些必需函数的主体对于不同的生成器可能会更复杂。我们将简要描述每个函数的作用。
- en: The first non-empty function, `get_return_object()`, is part of the boilerplate
    code and usually looks exactly like the one earlier; this function constructs
    a new generator from a handle that is, in turn, constructed from a promise object.
    It is called by the compiler to get the result of the coroutine.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个非空函数`get_return_object()`是样板代码的一部分，通常看起来与之前的函数完全相同；此函数从一个句柄构造一个新的生成器，而句柄又是从一个promise对象构造的。编译器调用它来获取协程的结果。
- en: The second non-empty function, `yield_value()`, is invoked every time the operator
    `co_yield` is called; its argument is the `co_yield` value. Storing the value
    in the promise object is how the coroutine usually passes the results to the caller.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个非空函数`yield_value()`在每次调用`co_yield`操作符时被调用；它的参数是`co_yield`的值。将值存储在promise对象中通常是协程将结果传递给调用者的方式。
- en: The `initial_suspend()` function is called by the compiler the first time `co_yield`
    is encountered. The `final_suspend()` function is called after the coroutine produces
    its last result via `co_return`; it cannot be suspended afterward. If the coroutine
    ends without `co_return`, the `return_void()` method is called. Finally, if the
    coroutine throws an exception that escapes from its body, the `unhandled_exception()`
    method is called. You can customize these methods for special handling of each
    of these situations, although this is seldom used.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当编译器第一次遇到`co_yield`时，将调用`initial_suspend()`函数。在协程通过`co_return`产生最后一个结果后，将调用`final_suspend()`函数；之后无法再暂停。如果协程在没有`co_return`的情况下结束，将调用`return_void()`方法。最后，如果协程抛出一个从其主体中逃逸的异常，将调用`unhandled_exception()`方法。您可以自定义这些方法，以便特殊处理每种情况，尽管这很少被使用。
- en: 'Now we see how it all ties together to provide us with a lazy generator. First,
    the coroutine handle is created. In our example, we do not keep the `generator`
    object, only the handle. This is not required: we could have kept the `generator`
    object and destroyed the handle in its destructor. The coroutine runs until it
    hits `co_yield` and suspends itself; the control is returned by the caller while
    the return value of `co_yield` is captured in the promise. The calling program
    retrieves this value and resumes the coroutine by invoking the handle. The coroutine
    picks up from the point where it was suspended and runs until the next `co_yield`.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到了如何将所有这些联系在一起，为我们提供了一个惰性生成器。首先，创建协程句柄。在我们的示例中，我们没有保留`generator`对象，只保留了句柄。这不是必需的：我们可以保留`generator`对象，并在其析构函数中销毁句柄。协程运行直到遇到`co_yield`并暂停；控制权由调用者返回，而`co_yield`的返回值被捕获在promise中。调用程序检索此值，并通过调用句柄恢复协程。协程从被暂停的地方继续运行，直到下一个`co_yield`。
- en: 'Our generator can run forever (or until we reach the maximum integer value
    on our platform, anyway): the sequence never ends. If we needed a sequence of
    finite length, we can execute `co_return` or just exit the loop after the sequence
    is over. Refer to the following code:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的生成器可以永远运行（或者直到在我们的平台上达到最大整数值）：序列永远不会结束。如果我们需要一个有限长度的序列，我们可以执行`co_return`或者在序列结束后退出循环。参考以下代码：
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now we have a sequence of 10 elements. The caller must check the result of the
    handle member function `done()` before trying to resume the coroutine.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个包含10个元素的序列。在尝试恢复协程之前，调用者必须检查句柄成员函数`done()`的结果。
- en: 'We mentioned before that a coroutine can be resumed from anywhere in the code
    (after it was suspended, of course). It can even be resumed from a different thread.
    In this case, the coroutine starts to execute on one thread, is suspended, and
    then runs the rest of its code on another thread. Let us see an example:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到协程可以从代码中的任何位置恢复（当然是在被暂停后）。它甚至可以从不同的线程中恢复。在这种情况下，协程开始在一个线程上执行，被暂停，然后在另一个线程上运行其余的代码。让我们看一个例子：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'First, let us get one detail out of the way: `std::jthread` is a C++20 addition,
    it is just a joinable thread – it is joined in the destructor of the object (almost
    anyone who worked with threads wrote a class for that, but now we have a standard
    one). Now we can move to the important part – the coroutine itself.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解决一个细节：`std::jthread`是C++20的一个补充，它只是一个可连接的线程 - 它在对象的析构函数中连接（几乎所有使用线程的人都写过一个类似的东西，但现在我们有了一个标准的）。现在我们可以转向重要的部分
    - 协程本身。
- en: 'First, let us see the return type of the coroutine:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看协程的返回类型：
- en: '[PRE16]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This is actually the smallest possible return type of a coroutine: it contains
    all the required boilerplate and nothing else. Specifically, the return type is
    a class that defines a nested type `promise_type`. That nested type must define
    several member functions, as shown in this code. Our generator type from the previous
    example has all of that plus some data used to return the results to the caller.
    Of course, the task can also have an internal state as needed.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这是协程的最小可能返回类型：它包含所有必需的样板代码，没有其他内容。具体来说，返回类型是一个定义了嵌套类型`promise_type`的类。该嵌套类型必须定义几个成员函数，如此代码所示。我们在前一个示例中的生成器类型具有所有这些内容以及用于将结果返回给调用者的一些数据。当然，任务也可以根据需要具有内部状态。
- en: 'The second change from the previous example is the way the task is suspended:
    we do it with `co_await` instead of `co_yield`. Operator `co_await` is actually
    the most general way to suspend a coroutine: just like `co_yield`, it suspends
    the function and returns the control to the caller. The difference is in the argument
    type: while `co_yield` returns a result, `co_await`''s argument is an awaiter
    object with very general functionality. There are, again, specific requirements
    on the type of this object. If the requirements are met, the class is called an
    `awaitable`, and an object of this type is a valid awaiter (if not, something
    somewhere will not compile). Here is our `awaitable`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个示例的第二个变化是任务被挂起的方式：我们使用`co_await`而不是`co_yield`。操作符`co_await`实际上是挂起协程的最通用方式：就像`co_yield`一样，它挂起函数并将控制返回给调用者。不同之处在于参数类型：`co_yield`返回一个结果，而`co_await`的参数是具有非常一般功能的等待对象。再次，对这个对象的类型有特定要求。如果满足要求，该类被称为`awaitable`，并且该类型的对象是有效的等待者（如果不满足要求，某处将无法编译）。这是我们的`awaitable`：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The required interface of an `awaitable` is the three methods we see here.
    The first is `await_ready()`: it is called after the coroutine is suspended. If
    it returns `true`, then the result of the coroutine is ready, and it is not really
    necessary to suspend it. In practice, it almost always returns `false`, which
    leads to suspension of the coroutine: the state of the coroutine, such as local
    variables and the suspension point, is stored in the activation frame, and the
    control is returned to the caller or resumer. The second function is `await_resume()`,
    it is called just before the coroutine continues to execute after it is resumed.
    If it returns the result, that is the result of the entire `co_await` operator
    (no result in our example). The most interesting function is `await_suspend()`.
    It is called with the handle of the current coroutine when this coroutine is suspended
    and can have several different return types and values. If it returns `void`,
    as it does in our example, the coroutine is suspended, and the control is returned
    to the caller or resumer. Don''t be fooled by the content of `await_suspend()`
    in our example: it does not resume the coroutine. Instead, it creates a new thread
    that will execute a callable object, and it is this object that resumes the coroutine.
    The coroutine may be resumed after `await_suspend()` is done or while it is still
    running: this example demonstrates the use of coroutines of asynchronous operations.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`awaitable`的必需接口是我们在这里看到的三种方法。第一个是`await_ready()`：在协程挂起后调用它。如果返回`true`，则协程的结果已准备就绪，实际上不需要挂起它。在实践中，它几乎总是返回`false`，这导致协程被挂起：协程的状态（例如局部变量和挂起点）存储在激活帧中，并且控制返回给调用者或恢复者。第二个函数是`await_resume()`，它在协程在恢复后继续执行之前调用。如果它返回结果，那就是整个`co_await`操作符的结果（在我们的示例中没有结果）。最有趣的函数是`await_suspend()`。当此协程被挂起时，它使用当前协程的句柄进行调用，并且可以具有几种不同的返回类型和值。如果它返回`void`，就像我们的示例中一样，协程被挂起，并且控制返回给调用者或恢复者。不要被我们示例中`await_suspend()`的内容所迷惑：它不会恢复协程。相反，它创建一个将执行可调用对象的新线程，而正是这个对象恢复了协程。协程可以在`await_suspend()`完成后或在其仍在运行时恢复：此示例演示了异步操作的协程使用。'
- en: 'Putting all of this together, we get this sequence:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，我们得到以下顺序：
- en: The main thread calls a coroutine.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主线程调用一个协程。
- en: The coroutine is suspended by operator `co_await`. This process involves several
    calls to the member functions of the `awaitable` object, one of which creates
    a new thread whose payload resumes the coroutine (the game with move-assigning
    thread objects is done so we delete the new thread in the main program and avoid
    some nasty race conditions).
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 协程被`co_await`操作符挂起。这个过程涉及对`awaitable`对象的几个成员函数的调用，其中一个创建了一个新线程，其有效负载恢复了协程（通过移动分配线程对象的游戏完成，因此我们在主程序中删除新线程并避免了一些讨厌的竞争条件）。
- en: Control is returned to the caller of the coroutine, so the main thread continues
    to run from the line after the coroutine call. It will block in the destructor
    of the thread object `t` if it gets there before the coroutine completes.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制返回给协程的调用者，因此主线程继续从协程调用后的行继续运行。如果在协程完成之前主线程在对象`t`的析构函数中阻塞，它将在那里。
- en: The coroutine is resumed by the new thread and continues to execute on that
    thread from the line after `co_await`. The `awaitable` object that was constructed
    by `co_await` is destroyed. The coroutine runs to the end, all on the second thread.
    Reaching the end of the coroutine means it's done, just like any other function.
    The thread that runs the coroutine now can be joined. If the main thread was waiting
    for the destructor of thread `t` to complete, it now unblocks and joins the thread
    (if the main thread has not yet reached the destructor, it won't block when it
    does).
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新线程恢复了协程，并从`co_await`后的行继续在该线程上执行。由`co_await`构造的`awaitable`对象被销毁。协程在第二个线程上运行到结束。到达协程的结尾意味着它完成了，就像任何其他函数一样。现在运行协程的线程可以被加入。如果主线程正在等待线程`t`的析构函数完成，现在它将解除阻塞并加入线程（如果主线程尚未达到析构函数，它在达到时不会阻塞）。
- en: 'The sequence is confirmed by the output of our program:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们程序的输出确认了这个顺序：
- en: '[PRE18]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the coroutine `coro()` was running on one thread first, then
    changed to a different thread in the middle of the execution. If it had any local
    variables, they would be preserved through this transition.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，协程`coro()`首先在一个线程上运行，然后在执行过程中切换到另一个线程。如果有任何局部变量，它们将通过这个转换被保留。
- en: 'We mentioned that `co_await` is the general operator for suspending coroutines.
    Indeed, the `co_yield x` operator is equivalent to a particular invocation of
    `co_await` as shown here:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到`co_await`是用于挂起协程的通用操作符。的确，`co_yield x`操作符等同于`co_await`的特定调用，如下所示：
- en: '[PRE19]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here `promise` is the `promise_type` object associated with the current coroutine
    handle. The reason for the separate operator `co_yield` is that accessing your
    own promise from inside the coroutine results in a quite verbose syntax, so the
    standard added a shortcut.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这里`promise`是与当前协程句柄关联的`promise_type`对象。之所以单独使用`co_yield`操作符，是因为在协程内部访问自己的promise会导致非常冗长的语法，因此标准添加了一个快捷方式。
- en: These examples demonstrate the capabilities of coroutines in C++. The situations
    where coroutines are thought to be useful are work stealing (you have seen how
    easy it is to transfer execution of a coroutine to another thread), lazy generators,
    and asynchronous operations (I/O and event handling). Nonetheless, the C++ coroutines
    have not been around long enough for any patterns to emerge, so the community
    is yet to come up with the best practices for using coroutines. Similarly, it
    is too early to talk about the performance of the coroutines; we have to wait
    for the compiler support to mature and for larger-scale applications to be developed.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了C++中协程的能力。协程被认为有用的情况包括工作窃取（您已经看到将协程的执行轻松转移到另一个线程有多容易）、惰性生成器和异步操作（I/O和事件处理）。尽管如此，C++协程还没有存在足够长的时间以形成任何模式，因此社区还没有提出使用协程的最佳实践。同样，现在讨论协程的性能还为时过早；我们必须等待编译器支持成熟和开发更大规模的应用程序。
- en: Overall, after neglecting concurrency for years, the C++ standard is rapidly
    catching up, so let us summarise the recent advances.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，C++标准在多年忽视并发之后，正在迅速赶上，让我们总结一下最近的进展。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: C++11 was the first version of the standard to acknowledge the existence of
    threads. It laid the foundation for documenting the behavior of C++ programs in
    concurrent environments and provided some useful functionality in the standard
    library. Out of this functionality, the basic synchronization primitives and the
    threads themselves are the most useful. Subsequent versions extended and completed
    these features with relatively minor enhancements.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: C++11是标准中首次承认线程存在的版本。它为记录C++程序在并发环境中的行为奠定了基础，并在标准库中提供了一些有用的功能。在这些功能中，基本的同步原语和线程本身是最有用的。随后的版本通过相对较小的增强扩展和完善了这些功能。
- en: C++17 brought a major advancement in the form of parallel STL. The performance
    is, of course, determined by the implementation. The observed performance is quite
    good as long as the data corpus is sufficiently large, even on hard-to-parallelize
    algorithms like search and partition. However, if the sequences of data are too
    short, parallel algorithms actually degrade the performance.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: C++17带来了一个重大进步，即并行STL。性能当然取决于实现。只要数据语料库足够大，即使在像搜索和分区这样难以并行化的算法上，观察到的性能也相当不错。然而，如果数据序列太短，并行算法实际上会降低性能。
- en: C++20 added coroutine support. You have seen how stackless coroutines work,
    in theory and on some basic examples. However, it is too early to talk about the
    performance and best practices for the use of C++20 coroutines.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: C++20增加了对协程的支持。您已经看到了无栈协程的工作原理，在理论上和一些基本示例中。然而，现在讨论C++20协程的性能和最佳实践还为时过早。
- en: This chapter concludes our exploration of concurrency. Next, we go on to learn
    how the use of the C++ language itself influences the performance of our programs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 本章总结了我们对并发性的探索。接下来，我们将学习C++语言本身如何影响程序的性能。
- en: Questions
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why is the foundation of concurrent programming laid in C++11 important?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么C++11中并发编程的基础很重要？
- en: How do we use parallel STL algorithms?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何使用并行STL算法？
- en: What are coroutines?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是协程？
