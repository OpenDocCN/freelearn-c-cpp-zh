- en: CUDA Application Profiling and Debugging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA应用程序分析和调试
- en: CUDA provides many programming tools for developers. These tools are the compilers,
    profilers, the IDE and its plugins, debuggers, and memory checkers. Learning about
    these tools will help you analyze your application and help you accomplish the
    development projects we will be covering. In this chapter, we will cover the basic
    usage of these tools and discuss how to apply these to application development.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA为开发人员提供了许多编程工具。这些工具包括编译器、分析器、IDE及其插件、调试器和内存检查器。了解这些工具将有助于您分析您的应用程序，并帮助您完成我们将要涵盖的开发项目。在本章中，我们将介绍这些工具的基本用法，并讨论如何将它们应用到应用程序开发中。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Profiling focused target ranges in GPU applications
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU应用程序中进行专注的分析目标范围
- en: Visual profiling against the remote machine
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对远程机器的可视化分析
- en: Debugging a CUDA application with CUDA error
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CUDA错误调试CUDA应用程序
- en: Asserting local GPU values using CUDA Assert
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CUDA Assert断言本地GPU值
- en: Debugging a CUDA application with Nsight Visual Studio Edition
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Nsight Visual Studio Edition调试CUDA应用程序
- en: Debugging a CUDA application with Nsight Eclipse Edition
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Nsight Eclipse Edition调试CUDA应用程序
- en: Debugging a CUDA application with CUDA-GDB
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CUDA-GDB调试CUDA应用程序
- en: Runtime validation with CUDA-memcheck
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CUDA-memcheck进行运行时验证
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To complete this chapter, it is recommended that you use an NVIDIA GPU card
    later than the Pascal architecture. In other words, your GPU's compute capability
    should be equal to or greater than 60\. If you are unsure of your GPU's architecture,
    please visit NVIDIA's site, [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus),
    and confirm your GPU's compute capability.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章，建议您使用Pascal架构之后的NVIDIA GPU卡。换句话说，您的GPU的计算能力应该等于或大于60。如果您不确定您的GPU架构，请访问NVIDIA的网站[https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)，并确认您的GPU的计算能力。
- en: The sample code for this chapter has been developed and tested with version
    10.1 of CUDA Toolkit. In general, it is recommended that you use the latest CUDA
    version if applicable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例代码已经使用CUDA Toolkit的10.1版本进行开发和测试。一般来说，如果适用的话，建议您使用最新的CUDA版本。
- en: Profiling focused target ranges in GPU applications
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在GPU应用程序中进行专注的分析目标范围
- en: NVIDIA's Visual Profiler is a handy tool for finding bottlenecks in GPU applications
    and understanding their operations. Although it provides fluent information of
    the application operations, those can be redundant if you just want to focus on
    a specific area of code. In this situation, limiting the range of profiling is
    more productive.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA的Visual Profiler是一个方便的工具，用于找出GPU应用程序中的瓶颈并理解它们的操作。虽然它提供了应用程序操作的流畅信息，但如果您只想专注于特定代码区域，这些信息可能会显得多余。在这种情况下，限制分析范围更加高效。
- en: Profiling targets can be specific code blocks, GPU, and time. Specifying the
    code blocks is called **focused profiling**. This technique is useful when you
    want to focus on profiling on a specific kernel function, or profiling on the
    part of a large GPU application. Targeting GPUs or time will be covered after
    we cover focused profiling.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 分析目标可以是特定的代码块、GPU和时间。指定代码块称为**专注分析**。当您想要专注于特定内核函数的分析，或者在大型GPU应用程序的一部分上进行分析时，这种技术是有用的。在我们介绍专注分析后，将介绍针对GPU或时间的分析目标。
- en: Limiting the profiling target in code
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制代码中的分析目标
- en: 'To benefit from focused profiling, you may want to include the featured header
    file in your source code, as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从专注的分析中受益，您可能希望在源代码中包含特色的头文件，如下所示：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you can specify your targeting range of profiling using `cudaProfilerStart()` and
    `cudaProfilerStop()`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用`cudaProfilerStart()`和`cudaProfilerStop()`来指定您的分析范围：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, you need to profile your application with a specific flag, `--profile-from-start`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要使用特定标志`--profile-from-start`来分析您的应用程序。
- en: This option doesn't let the profiler start profiling until the request arrives. If
    you want to profile your application using NVIDIA Visual Profiler, make sure to
    tick the Start execution with profiling enabled checkbox in the setting view.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项不会让分析器开始分析，直到请求到达。如果您想使用NVIDIA Visual Profiler来分析您的应用程序，请确保在设置视图中勾选“启动时启用分析”复选框。
- en: 'The following steps cover how to control the NVIDIA profiler using some simple
    example code. To make this easier, we will reuse the sample code that we used
    to operate matrix multiplication in [Chapter 3](d2527255-a553-410f-bc03-a0f0c0b50f12.xhtml),
    *CUDA Thread Programming*:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤涵盖了如何使用一些简单的示例代码来控制NVIDIA分析器。为了使这更容易，我们将重用我们在[第3章](d2527255-a553-410f-bc03-a0f0c0b50f12.xhtml)中用于矩阵乘法操作的示例代码，*CUDA线程编程*：
- en: Write a CUDA application with two simple SGEMM CUDA kernel functions. The kernel
    functions are identical but have different names, that is, `sgemm_kernel_A()`
    and `sgemm_kernel_B()`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个CUDA应用程序，其中包含两个简单的SGEMM CUDA内核函数。这两个内核函数是相同的，但名称不同，即`sgemm_kernel_A()`和`sgemm_kernel_B()`。
- en: 'Make two iterative calls, like so:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行两次迭代调用，如下所示：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s compile the code and profile using `nvprof`:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编译代码并使用`nvprof`进行分析：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you open the generated `profile-original.nvvp` file using the Visual Profiler,
    you will have the profiled result, as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用Visual Profiler打开生成的`profile-original.nvvp`文件时，您将得到如下的分析结果：
- en: '![](img/2bdf10e5-d9dc-48b0-b300-bff170a481a5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bdf10e5-d9dc-48b0-b300-bff170a481a5.png)'
- en: This timeline includes whole profiled information from when the application
    started. However, we can say that the profiled result contains unnecessary information
    when we want to optimize our kernel functions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个时间轴包括了应用程序启动时的整个分析信息。然而，当我们想要优化我们的内核函数时，我们可以说分析结果包含了不必要的信息。
- en: 'The following steps cover how to specify the profile focusing area:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤涵盖了如何指定分析专注区域：
- en: 'Place `#include <cuda_profiler_api.h>` on top of the source code to enable
    focused profile APIs. Then, we can embrace the area we are interested in using `cudaProfilerStart()`
    and `cudaProfilerStop()`, as follows:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在源代码顶部放置 `#include <cuda_profiler_api.h>` 以启用专注分析 API。然后，我们可以使用 `cudaProfilerStart()`
    和 `cudaProfilerStop()` 来包含我们感兴趣的区域，如下所示：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Compile your code and view the updated profiled result using the Visual Profiler.
    We have to provide the `--profile-from-start off` option to the profiler, as follows:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译您的代码并使用 Visual Profiler 查看更新后的分析结果。我们必须向分析器提供 `--profile-from-start off` 选项，如下所示：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When you open the newly generated profile result, the profiler only reports
    the specified part of the application, as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当您打开新生成的分析结果时，分析器只会报告应用程序的指定部分，如下所示：
- en: '![](img/9bcc2ff9-c3a3-4af8-b741-593489860e3d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bcc2ff9-c3a3-4af8-b741-593489860e3d.png)'
- en: The profile result is restricted. The preceding screenshot shows the kernel's
    execution from when it started GPU execution. As a result, you can eliminate having
    to profile an application's initialization and other irrelevant operations.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 分析结果受限。上面的屏幕截图显示了内核执行的情况，从开始 GPU 执行时开始。因此，您可以省去对应用程序初始化和其他无关操作进行分析的步骤。
- en: 'In conclusion, the focused profile has several benefits, as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，专注分析有几个好处，如下所示：
- en: It helps you focus on the module you're currently developing.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这有助于您专注于当前正在开发的模块。
- en: 'It lets you remove irrelevant operations from the report in the profiler, for
    example:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以让您在分析报告中删除无关的操作，例如：
- en: An external module's behavior that doesn't have any relation to your code
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与您的代码无关的外部模块行为
- en: Application initialization delay
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序初始化延迟
- en: It helps you save time when it comes to finding the targeting function in the
    timeline view.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间轴视图中查找目标函数时，这有助于节省时间。
- en: Limiting the profiling target with time or GPU
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过时间或 GPU 限制分析目标
- en: 'The NVIDIA profiler has other options that can limit profile targets. You can
    use the following options with focused profiling, too:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 分析器还有其他可以限制分析目标的选项。您也可以使用以下选项进行专注分析：
- en: The `--timeout <second>` option limits application execution time. This option
    is useful when you need to profile an application that has a long execution time
    with iterative operations.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--timeout <second>` 选项限制应用程序的执行时间。当您需要分析执行时间较长的迭代操作的应用程序时，此选项非常有用。'
- en: The `--devices <gpu ids>` option specifies the GPUs to profile. This option
    helps you narrow down GPU kernel operations in a multiple GPU application.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--devices <gpu ids>` 选项指定要进行分析的 GPU。该选项帮助您在多 GPU 应用程序中缩小 GPU 内核操作的范围。'
- en: 'Also, you don''t have to collect all the metrics if you only want to focus
    on a few kernel functions. You can just stipulate your interest to the profiler
    with the `--kernels`, `--event`, and `--metrics` options. You can use those options
    along with other profile options, as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您只想专注于少数内核函数，您不必收集所有指标。您可以使用 `--kernels`、`--event` 和 `--metrics` 选项向分析器指定您的兴趣。您可以将这些选项与其他分析选项一起使用，如下所示：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After importing the collected metrics into the timeline profile result, you
    will find that the targeted kernels only have metrics information.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将收集的指标导入时间轴分析结果后，您会发现目标内核只有指标信息。
- en: There are many other versatile profile features in CPU sampling, such as marking
    profile range, OpenMP and OpenACC profiles, and so on. If you want to take a look
    at the features of the NVIDIA profiler, check out the following profiler introduction
    talk by Jeff Larkin from NVIDIA: [https://www.olcf.ornl.gov/wp-content/uploads/2018/12/summit_workshop_Profilers.pdf](https://www.olcf.ornl.gov/wp-content/uploads/2018/12/summit_workshop_Profilers.pdf).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CPU 抽样中有许多其他多功能的分析特性，例如标记分析范围、OpenMP 和 OpenACC 分析等。如果您想了解 NVIDIA 分析器的功能，请查看
    NVIDIA 的 Jeff Larkin 提供的以下分析器介绍讲座：[https://www.olcf.ornl.gov/wp-content/uploads/2018/12/summit_workshop_Profilers.pdf](https://www.olcf.ornl.gov/wp-content/uploads/2018/12/summit_workshop_Profilers.pdf)。
- en: NVIDIA's official profiler user guide provides details about the NVIDIA profiler's
    functions ([https://docs.nvidia.com/cuda/profiler-users-guide/index.html](https://docs.nvidia.com/cuda/profiler-users-guide/index.html.)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 的官方分析器用户指南提供了有关 NVIDIA 分析器功能的详细信息 ([https://docs.nvidia.com/cuda/profiler-users-guide/index.html](https://docs.nvidia.com/cuda/profiler-users-guide/index.html.)).
- en: Profiling with NVTX
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NVTX 进行分析
- en: With focused profiling, we can profile a limited, specific area by using `cudaProfilerStart()` and `cudaProfilerStop()`.
    However, if we want to analyze functional performance in a complex application,
    it is limited. For this situation, the CUDA profiler provides timeline annotations
    via the **NVIDIA Tools Extension** (**NVTX**).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过专注分析，我们可以使用 `cudaProfilerStart()` 和 `cudaProfilerStop()` 对有限的特定区域进行分析。但是，如果我们想要分析复杂应用程序中的功能性能，这是有限的。对于这种情况，CUDA
    分析器通过 **NVIDIA 工具扩展** (**NVTX**) 提供时间轴注释。
- en: 'Using NVTX, we can annotate the CUDA code. We can use the NVTX API as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NVTX，我们可以对 CUDA 代码进行注释。我们可以使用 NVTX API 如下：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, we can define a range as a group of codes and annotate that
    range manually. Then, the CUDA profiler provides a timeline trace of the annotation
    so that we can measure the execution time of code blocks. One drawback of this
    is that the NVTX APIs are host functions, so we need to synchronize the host and
    GPU if the target code blocks are pure GPU kernel calls.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们可以将一段代码定义为一组代码，并手动注释该范围。然后，CUDA 分析器提供注释的时间轴跟踪，以便我们可以测量代码块的执行时间。这种方法的一个缺点是
    NVTX API 是主机函数，因此如果目标代码块是纯 GPU 内核调用，则需要同步主机和 GPU。
- en: 'To learn more about this, let''s apply this NVTX code to the previous focused
    profiling example. First, we should include an NVTX header file, as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多信息，请将此 NVTX 代码应用于前面的专注分析示例。首先，我们应该包含一个 NVTX 头文件，如下所示：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we will insert `nvtxRangePushA()` and `nvtxRangePop()` into several places,
    as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将在几个地方插入 `nvtxRangePushA()` 和 `nvtxRangePop()`，如下所示：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In the preceding code, we have enlarged the focused profile area to monitor
    the NVTX operation. We also have `Data Transfer`, `Kernel A`, `Kernel B`, and
    `Kernel Execution` as NVTX ranges. NVTX supports multi-level annotations, so the `Kernel
    A` and `Kernel B` ranges will be included in the `Kernel Execution` timeline.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我们已经扩大了关注的配置文件区域，以监视NVTX操作。我们还有`Data Transfer`、`Kernel A`、`Kernel B`和`Kernel
    Execution`作为NVTX范围。NVTX支持多级注释，因此`Kernel A`和`Kernel B`范围将包含在`Kernel Execution`时间轴中。
- en: 'To compile the code, we should provide the `-lnvToolsExt` option to the `nvcc`
    compiler to provide NVTX API''s definition. We can compile the code using the
    following command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译代码，我们应该为`nvcc`编译器提供`-lnvToolsExt`选项来提供NVTX API的定义。我们可以使用以下命令编译代码：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, the NVIDIA profiler can collect NVTX annotations without extra options.
    We can profile the application using the following command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，NVIDIA分析器可以在没有额外选项的情况下收集NVTX注释。我们可以使用以下命令对应用程序进行分析：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following screenshot shows the timeline profiled result. In this screenshot,
    we can see Markers and Ranges colored in green. These green bars have the annotations:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了时间轴分析结果。在这个截图中，我们可以看到用绿色标记的标记和范围。这些绿色条有注释：
- en: '![](img/c6943cf2-08ba-4c8e-974b-03436038efdf.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6943cf2-08ba-4c8e-974b-03436038efdf.png)'
- en: 'The preceding screenshot provides us with the following information:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图为我们提供了以下信息：
- en: We can identify where the memory copy operation has been called following the
    NVTX annotation.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过NVTX注释来确定内存复制操作的位置。
- en: We can divide the functional positions by wrapping the area, for example, `kernel
    A` and `kernel B`.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过包装区域来划分功能位置，例如`kernel A`和`kernel B`。
- en: The NVTX annotation can stack multiple levels of annotations. As we can see, `kernel
    A` and `kernel B` are included in the `kernel execution` annotation.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVTX注释可以堆叠多个级别的注释。正如我们所看到的，`kernel A`和`kernel B`包含在`kernel execution`注释中。
- en: 'The following document not only introduces NVTX but also explains how to use
    different colors using NVTX: [https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx](https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx).
    One of the applications of NVTX is to profile deep learning networks with NVTX
    annotations. This provides insight into network operation bottlenecks. We will
    discuss this in [Chapter 10](d0e9e8ff-bc17-4031-bb0e-1cfd310aff6f.xhtml), *Deep
    Learning Acceleration with CUDA*, of this book.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件不仅介绍了NVTX，还解释了如何使用NVTX来使用不同的颜色：[https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx](https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx)。NVTX的一个应用是使用NVTX注释对深度学习网络进行分析。这提供了对网络操作瓶颈的洞察。我们将在本书的第10章《使用CUDA进行深度学习加速》中讨论这一点。
- en: Visual profiling against the remote machine
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 针对远程机器进行可视化分析
- en: The NVIDIA Visual Profiler also can profile remote applications. This feature
    eases the profiling task when it comes to remote application development, especially
    when you develop your application on the server-side.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA Visual Profiler还可以分析远程应用程序。这个功能在远程应用程序开发时特别方便，尤其是在服务器端开发应用程序时。
- en: 'There are several ways of using visual profilers, as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种使用可视化分析器的方法，如下所示：
- en: Profiling on the host with the host CUDA application
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在主机上进行CUDA应用程序的分析
- en: By collecting profile data using the `nvprof` CLI on the target side, copying
    the file to the host, and opening it using the Visual Profiler
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在目标端使用`nvprof` CLI收集配置文件数据，将文件复制到主机并使用Visual Profiler打开
- en: Profiling the application on the target platform using the host machine
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在目标平台上使用主机机器进行应用程序的分析
- en: Visual profiling directly in the host machine is convenient and can save development
    time. Also, remote profiling provides the same user experience that profiling
    a GPU application on a host machine does. One exception is that we should establish
    a remote connection. Another benefit OS host-managed visual profiling provides
    is that the profiler collects metric information on-demand automatically.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在主机机器上直接进行可视化分析非常方便，可以节省开发时间。此外，远程分析提供了与在主机机器上分析GPU应用程序相同的用户体验。唯一的例外是我们需要建立远程连接。主机管理的可视化分析提供的另一个好处是分析器会自动按需收集度量信息。
- en: 'The NVIDIA profiler communicates with the NVIDIA profiler in the host machine
    and collects profiled data. Therefore, you need to confirm that your host machine
    – desktop or laptop – should connect to the remote machine. The following diagram
    shows the overview of this connection:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA分析器与主机机器中的NVIDIA分析器进行通信并收集分析数据。因此，您需要确认您的主机机器（台式机或笔记本电脑）应连接到远程机器。以下图显示了此连接的概述：
- en: '![](img/5b19fd33-9512-4762-b55b-76746e212d43.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b19fd33-9512-4762-b55b-76746e212d43.png)'
- en: 'Let''s try to profile a GPU application remotely. The following steps cover
    how to profile a remote GPU application in NVIDIA Visual Profiler:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试远程分析GPU应用程序。以下步骤介绍了如何在NVIDIA Visual Profiler中分析远程GPU应用程序：
- en: 'First, go to File | New session. When you click the New Session menu, you will
    see the following dialog window:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，转到文件 | 新建会话。当您单击新建会话菜单时，您将看到以下对话框窗口：
- en: '![](img/98f0371c-d094-481c-a716-ba64d95ddc8c.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98f0371c-d094-481c-a716-ba64d95ddc8c.png)'
- en: 'Then, we need to add a connection, which we do by going to the Manage connection... menu.
    Then, the New Remote Connectiondialog will appear. Add your remote machine information
    by clicking the Add button and putting your remote machine information in the
    appropriate sections. Then, close the dialog by clicking the Finish button. When
    you''re finished, you will see the following output:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要添加一个连接，方法是转到“管理连接...”菜单。然后，将出现“新的远程连接”对话框。通过单击“添加”按钮并在适当的部分输入远程机器信息来添加远程机器信息。然后，通过单击“完成”按钮关闭对话框。完成后，您将看到以下输出：
- en: '![](img/a163c51c-0e85-4386-8545-6527b9445305.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a163c51c-0e85-4386-8545-6527b9445305.png)'
- en: As we discussed previously, the host and remote machine communicate over SSH,
    whose default port number is 22\. If the host machine uses another port for SSH,
    you have to inform it of that port number in the new remote session creation dialog.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，主机和远程机器通过SSH进行通信，其默认端口号为22。如果主机机器使用其他端口进行SSH，您必须在新的远程会话创建对话框中通知它该端口号。
- en: 'Now, we need to set up CUDA Toolkit paths in the remote machine by clicking
    the Manage... button at the right-hand side of Toolkit/Script*. *A good start
    is to use the Detect button. It finds the `nvcc` path and sets up the configuration
    information automatically. If automatic detection failed, you have to input the
    configuration information manually. When you''ve finished with the configuration
    process, click the Finish button, as follows:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要通过单击Toolkit/Script*右侧的“管理...”按钮在远程机器上设置CUDA Toolkit路径。*一个很好的开始是使用“检测”按钮。它会自动查找`nvcc`路径并自动设置配置信息。如果自动检测失败，您必须手动输入配置信息。完成配置过程后，单击“完成”按钮，如下所示：
- en: '![](img/214bb1ee-1f3e-413a-a15a-6ee7ab8ecbc9.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/214bb1ee-1f3e-413a-a15a-6ee7ab8ecbc9.png)'
- en: Specify the GPU application's binary by clicking the Browse button on the right-hand
    side of the File text box. It will ask for your remote machine login password.
    Find your application path and set the application's path. You can also put the
    application's arguments if you need to control the application's behavior. When
    you've finished setting up the application and connection, click the Next button
    to set the profiler's options.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过单击“浏览”按钮在“文件”文本框的右侧指定GPU应用程序的二进制文件。它会要求您的远程机器登录密码。找到应用程序路径并设置应用程序路径。如果需要控制应用程序的行为，还可以输入应用程序的参数。完成应用程序和连接设置后，单击“下一步”按钮设置分析器的选项。
- en: 'Now, we will set up the profiling options. NVIDIA Visual Profiler allows us
    to set the profiler''s options using checkboxes as shown in the following screenshot.
    By clicking Finish, the profiler collects profile data from the application:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将设置分析器选项。NVIDIA Visual Profiler允许我们使用复选框设置分析器的选项，如下面的屏幕截图所示。单击“完成”，分析器将从应用程序收集分析数据：
- en: '![](img/258424fc-ee37-4d52-be8b-9572821710c5.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/258424fc-ee37-4d52-be8b-9572821710c5.png)'
- en: You will see the timelined profiled output, as profiled on the host machine.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在主机机器上看到时间线分析输出。
- en: Finally, analyze the performance of the profiled timeline graph. Click any kernel
    function you want to analyze. Click the Perform Kernel Analysis button; the profiler
    tool will collect the related metrics information. By doing this, you can quickly
    get a report regarding the performance limiters and find the bottlenecks of the
    kernel function.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，分析分析时间线图的性能。单击要分析的任何内核函数。单击“执行内核分析”按钮；分析工具将收集相关的度量信息。通过这样做，您可以快速获得有关性能限制器的报告，并找到内核函数的瓶颈。
- en: Debugging a CUDA application with CUDA error
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CUDA错误调试CUDA应用程序
- en: 'Having dedicated exception checks and checking errors is one of the base features
    that make high-quality software. CUDA functions report the error by returning
    their status for each function call. Not only CUDA APIs, but kernel functions
    and the CUDA library''s API call follow this rule. Therefore, detecting a recurring
    error is the start of identifying errors in CUDA execution. For example, let''s
    assume that we have allocated global memory using the `cudaMalloc()` function,
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 具有专用的异常检查和检查错误是使软件具有高质量的基本特征之一。CUDA函数通过返回每个函数调用的状态来报告错误。不仅如此，CUDA API，而且内核函数和CUDA库的API调用也遵循这个规则。因此，检测到重复错误是识别CUDA执行中错误的开始。例如，假设我们使用`cudaMalloc()`函数分配了全局内存，如下所示：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'What if the global memory has insufficient free space to allocate new memory
    space? In this case, the `cudaMalloc()` function returns an error to report an
    out of memory exception. Errors that are triggered by kernel calls can be captured
    from the flags using `cudaGetLastError()`. This returns the recorded error status
    and resets the flag''s value. However, handle this flag with caution: its return
    doesn''t guarantee that the error occurred at the GPU''s last execution and the
    flag is reset manually.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果全局内存没有足够的空闲空间来分配新的内存空间怎么办？在这种情况下，`cudaMalloc()`函数返回一个错误来报告内存不足异常。通过使用`cudaGetLastError()`可以捕获由内核调用触发的标志。它返回记录的错误状态并重置标志的值。但是要小心处理这个标志：它的返回并不保证错误发生在GPU的最后执行，并且需要手动重置标志。
- en: 'The return from CUDA APIs and the return of the `cudaGetLastError()` function
    are of the `cudaError_t` type. This `cudaError_t` type is a predefined integer
    type, and the application identifies which type of error has occurred. For example,
    this type is defined as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA API的返回值和`cudaGetLastError()`函数的返回值都是`cudaError_t`类型。这种`cudaError_t`类型是预定义的整数类型，应用程序可以识别发生了哪种类型的错误。例如，此类型定义如下：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Memorizing or translating all of these values is impractical. For this purpose,
    the CUDA sample code provides a helper function, `checkCudaError()`, which is
    located in `common/inc/cuda_helper.h`. This function prints out the error message
    when the CUDA function returns errors. Its function definition is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 记住或翻译所有这些值是不切实际的。为此，CUDA示例代码提供了一个辅助函数`checkCudaError()`，它位于`common/inc/cuda_helper.h`中。当CUDA函数返回错误时，此函数打印出错误消息。其函数定义如下：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Since this function is defined as a macro, we can identify the line where the
    error occurred.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此函数被定义为宏，我们可以确定发生错误的行。
- en: There are two ways we can use this function. One is to include the `cuda_helper.h`
    file in the source code. Alternatively, we can copy the function code into somewhere
    in the code.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个函数的两种方式。一种是在源代码中包含`cuda_helper.h`文件。另一种是将函数代码复制到代码中的某个位置。
- en: 'Then, we will embrace all the CUDA API classes with `checkCudaErrors()`, as
    follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用`checkCudaErrors()`包装所有的CUDA API类，如下所示：
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For the kernel function call, we will use the `cudaGetLastError()` function
    to get the kernel call''s error flag, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内核函数调用，我们将使用`cudaGetLastError()`函数来获取内核调用的错误标志，如下所示：
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'However, this code has a problem: the kernel operation is asynchronous with
    the host so that `cudaGetLastError()` can only catch the host side''s return values.
    It is highly possible that the error was triggered somewhere in the application.
    To resolve this situation, you can use any host and device synchronization function;
    for example:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这段代码有一个问题：内核操作与主机异步，所以`cudaGetLastError()`只能捕获主机端的返回值。很可能错误是在应用程序的某个地方触发的。为了解决这种情况，您可以使用任何主机和设备同步函数；例如：
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, let''s test the error detection code by modifying the source code to generate
    an error. For example, you can request `cudaMemcpy` to copy a larger memory space
    than the allocated size. In this case, the application returns an error message,
    as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过修改源代码来测试错误检测代码。例如，您可以请求`cudaMemcpy`复制比分配大小更大的内存空间。在这种情况下，应用程序会返回一个错误消息，如下所示：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Alternatively, you can pass a `NULL` point for the CUDA kernel so that the
    kernel accesses the invalid memory space. In this case, the application reports
    an illegal address error in `cudaDeviceSynchronize()`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以为CUDA内核传递一个`NULL`指针，以便内核访问无效的内存空间。在这种情况下，应用程序会在`cudaDeviceSynchronize()`中报告非法地址错误：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This error checking macro is quite useful because it reports where the error
    occurs in the source code. However, this report has a missing point that its error
    detected position does not match with the real error occurred position.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个错误检查宏非常有用，因为它报告了错误发生的源代码位置。然而，这个报告有一个缺点，就是它检测到的错误位置与实际发生的错误位置不匹配。
- en: 'The error message should report the position where we copying memory that''s
    larger than the allocated memory results in an illegal value error immediately.
    So, the developer can identify the error message right after the kernel call.
    However, this error checking code only works on a host. Therefore, this can confuse
    the GPU operations if they''re not synchronized properly. For example, if we didn''t
    set the synchronization and just checking error, then the `cudaDeviceSynchronize()`
    function can report an error from the wrong place. In this case, we can set `CUDA_LAUNCH_BLOCKING=1`
    environment variable to make all the kernel execution to be synchronized with
    the host:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息应该报告我们复制比分配的内存更大的内存位置导致非法值错误。因此，开发人员可以在内核调用之后立即识别错误消息。然而，这个错误检查代码只在主机上工作。因此，如果GPU操作没有正确同步，这可能会混淆GPU操作。例如，如果我们没有设置同步，只是检查错误，那么`cudaDeviceSynchronize()`函数可能会报告错误的位置。在这种情况下，我们可以设置`CUDA_LAUNCH_BLOCKING=1`环境变量，使所有内核执行与主机同步：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Line `36` at `sgemm.cu` is the `cudaGetLastError()` call, right after the `sgemm`
    kernel call. That's where we place an intended error. We can identify the correct
    error position at runtime.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`sgemm.cu`的第36行是`cudaGetLastError()`调用，在`sgemm`内核调用之后。这就是我们放置一个预期错误的位置。我们可以在运行时确定正确的错误位置。'
- en: 'There are two official documents that can help you learn about the different
    types of CUDA errors:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有两份官方文件可以帮助您了解不同类型的CUDA错误：
- en: '[https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html)'
- en: '`include/driver_types.h` in the CUDA Toolkit root path'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA Toolkit根路径中的`include/driver_types.h`
- en: Asserting local GPU values using CUDA assert
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CUDA assert断言本地GPU值
- en: Even though your GPU application works without any systematic errors, you need
    to check the computed result to make sure that the execution works as it was designed
    to. For this purpose, CUDA provides the `assert` function, which checks whether
    the argument value is zero. If it is, this function raises an error flag so that
    the host can identify that there is an error in the kernel function.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您的GPU应用程序没有任何系统错误，您也需要检查计算结果，以确保执行的结果符合设计要求。为此，CUDA提供了`assert`函数，它检查参数值是否为零。如果是，这个函数会引发一个错误标志，以便主机可以识别内核函数中存在错误。
- en: 'An assertion is used to validate that the operation result is as expected.
    In CUDA programming, the `assert` function can be called from the device code
    and can stop the kernel''s execution when the given argument is zero:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 断言用于验证操作结果是否符合预期。在CUDA编程中，可以从设备代码中调用`assert`函数，并在给定参数为零时停止内核的执行：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This is the declaration of the `assert` function, which is the same as it is
    for C/C++. When the assertion is triggered, the application stops and reports
    its error message. If the application is launched by the debugger, it works as
    a breakpoint so that the developer can debug the given information. For instance,
    the output message looks like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`assert`函数的声明，与C/C++的声明相同。当断言被触发时，应用程序会停止并报告其错误消息。如果应用程序由调试器启动，它会作为断点工作，以便开发人员可以调试给定的信息。例如，输出消息看起来像这样：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Since the output message directs the exact CUDA block and thread index, the
    developer can analyze the directed CUDA thread's execution easily.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输出消息指向了确切的CUDA块和线程索引，开发人员可以轻松分析指定的CUDA线程的执行。
- en: Now, let's apply the assertion and see how it can detect intended errors. We
    will modify the SGEMM operation code that we used in the *Profiling focused target
    ranges in GPU applications* section.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们应用断言并看看它如何检测到预期的错误。我们将修改在*GPU应用程序中的性能优化目标范围*部分中使用的SGEMM操作代码。
- en: 'First, place the assertion code in the middle of a kernel function. We will
    see the effect of the expression, which should be false. The assertion code can
    be written as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在内核函数的中间放置断言代码。我们将看到表达式的效果，它应该是false。断言代码可以编写如下：
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can try other index values or try other possible errors too. Compile the
    code and run it to see the output. The following code shows the output error of
    this modification:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试其他索引值或尝试其他可能的错误。编译代码并运行它以查看输出。以下代码显示了此修改的输出错误：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The error message reports that the assertion triggered the code location, the
    kernel function's name, and GPU's thread index. With this information, we can
    find out where we should start analyzing easily.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息报告了断言触发的代码位置、内核函数的名称和GPU的线程索引。有了这些信息，我们可以很容易地找出应该从哪里开始分析。
- en: Actually, the usage of the `assert` function is the same as the `assert` function
    in normal C/C++ programming. One difference is that the `assert` function works
    in the device code. Therefore, it reports not only the event location and the
    expression, but also shows the block and thread index.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，`assert`函数的使用与普通C/C++编程中的`assert`函数相同。一个区别是`assert`函数在设备代码中起作用。因此，它不仅报告事件位置和表达式，还显示块和线程索引。
- en: However, using assertion has an impact on application performance. Therefore,
    we should only use assertion for debugging purposes. It is recommended to disable
    it when we're running in a production environment. You can disable assertion at
    compile time by adding the `NDEBUG` preprocessed macro before including `assert.h`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用断言会对应用程序性能产生影响。因此，我们应该只在调试目的时使用断言。建议在生产环境中运行时禁用它。您可以通过在包含`assert.h`之前添加`NDEBUG`预处理宏来在编译时禁用断言。
- en: Debugging a CUDA application with Nsight Visual Studio Edition
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nsight Visual Studio Edition调试CUDA应用程序
- en: For Windows application developers, the CUDA Toolkit provides Nsight Visual
    Studio Edition, which enables GPU computing in Visual Studio. This tool works
    as an extension of Visual Studio, but you can build, debug, profile, and trace
    GPU applications along with the host. If your working platform is not Windows,
    the contents in this section won't be applicable, so you can skip it.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Windows应用程序开发人员，CUDA Toolkit提供了Nsight Visual Studio Edition，它可以在Visual Studio中实现GPU计算。这个工具作为Visual
    Studio的扩展工作，但您可以构建、调试、分析和跟踪GPU应用程序以及主机。如果您的工作平台不是Windows，则本节中的内容将不适用，您可以跳过它。
- en: The CUDA debugger allows us to monitor the local values on a GPU kernel for
    each CUDA thread. Like normal host debugging, you can set breakpoints in the kernel
    code and trigger them. You can also place conditions such as other normal breakpoints.
    With this feature, you can trigger breakpoints for a specific CUDA thread index
    and review their local variables.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA调试器允许我们监视每个CUDA线程的GPU内核上的本地值。与普通主机调试一样，您可以在内核代码中设置断点并触发它们。您还可以设置条件，例如其他普通断点。有了这个功能，您可以为特定的CUDA线程索引触发断点并查看它们的本地变量。
- en: This tool can be installed along with the CUDA Toolkit. You can obtain the latest
    version from the website. It is not mandatory, but it is recommended when your
    development environment is using the old CUDA Toolkit on the latest GPU and its
    driver. Visit the NVIDIA Nsight web page ([https://developer.nvidia.com/nsight-visual-studio-edition](https://developer.nvidia.com/nsight-visual-studio-edition))
    to download and install Nsight. You'll need an NVIDIA developer membership to
    obtain the software. You will also need to install the recommended display driver
    version.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具可以与CUDA Toolkit一起安装。您可以从网站上获取最新版本。这不是强制性的，但是当您的开发环境使用旧的CUDA Toolkit和最新的GPU及其驱动程序时，建议使用它。访问NVIDIA
    Nsight网页（[https://developer.nvidia.com/nsight-visual-studio-edition](https://developer.nvidia.com/nsight-visual-studio-edition)）下载并安装Nsight。您需要NVIDIA开发人员会员资格才能获取该软件。您还需要安装推荐的显示驱动程序版本。
- en: 'You can find the CUDA tools by going to Menu | Nsight in the Visual Studio
    menu bar. There are several tools in this menu, some of which are as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过转到Visual Studio菜单栏中的菜单 | Nsight来找到CUDA工具。此菜单中有几个工具，其中一些如下：
- en: '**Graphics debugging**: A debugger for graphics (Direct3D, OpenGL, and Vulkan)
    applications'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形调试**：用于图形（Direct3D、OpenGL和Vulkan）应用程序的调试器'
- en: '**CUDA debugging (Next-Gen)**: A debugger for debugging CPU and GPU code simultaneously
    (Turing, Volta, and Pascal with the latest drivers)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CUDA调试（Next-Gen）**：用于同时调试CPU和GPU代码的调试器（Turing、Volta和Pascal与最新驱动程序）'
- en: '**CUDA debugging (Legacy)**: A debugger for GPU kernels only (Pascal with the
    old drivers, Maxwell, and Kepler)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CUDA调试（传统）**：仅用于GPU内核的调试器（具有旧驱动程序的Pascal、Maxwell和Kepler）'
- en: '**Performance analysis**: For the analysis of the current GPU''s application
    performance'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能分析**：用于分析当前GPU应用程序的性能'
- en: '**CUDA memory checker**: For checking GPU memory violations during runtime
    (as covered in the previous section)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CUDA内存检查器**：用于在运行时检查GPU内存违规（如前一节中介绍的）'
- en: In this section, we will focus on CUDA debugging (Next-Gen). This is because
    the Next-Gen debugger can support the latest architectures, including Turing and
    Volta. The CUDA memory checker will be covered at the end of this chapter.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点放在CUDA调试（Next-Gen）上。这是因为Next-Gen调试器可以支持包括Turing和Volta在内的最新架构。CUDA内存检查器将在本章末尾介绍。
- en: Now, let's configure a sample project and see how we can debug the application
    using Nsight Visual Studio Edition. You may use the default sample code or replace
    the code with the previous CUDA code we covered. You can also use the given sample
    code in the `05_debug/05_debug_with_vs` file. It is some simple SAXPY code.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们配置一个示例项目，并看看我们如何使用Nsight Visual Studio Edition调试应用程序。您可以使用默认的示例代码，或者用我们之前介绍的CUDA代码替换代码。您还可以使用`05_debug/05_debug_with_vs`文件中提供的示例代码。这是一些简单的SAXPY代码。
- en: 'Set the project properties to generate the proper device target code. In the
    project''s property page, you can specify the target code version. List the architecture
    versions you want to use in the CUDA C/C++ | Code Generation text box:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 将项目属性设置为生成适当的设备目标代码。在项目的属性页面中，您可以指定目标代码版本。在CUDA C/C++ | 代码生成文本框中列出您想要在其中使用的架构版本：
- en: '![](img/db945ffd-c8da-46ed-9229-1b098affb0ee.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db945ffd-c8da-46ed-9229-1b098affb0ee.png)'
- en: The preceding screenshot shows the CUDA device code's generation property page.
    You can set several `nvcc` options, such as the target GPU's compute capability,
    register limitations per thread, and CUDA kernel information that's verbose during
    compile time.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图显示了CUDA设备代码生成属性页面。您可以设置几个`nvcc`选项，例如目标GPU的计算能力、每个线程的寄存器限制以及在编译时冗长的CUDA内核信息。
- en: 'Place breakpoints at line 34, where the middle of the kernel function is, and
    at line 75, where we copy data from the host to the device. Then, compile and
    start debugging using one of these methods:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在第34行和第75行设置断点，其中第34行是内核函数的中间位置，第75行是从主机复制数据到设备的位置。然后，使用以下方法之一编译并开始调试：
- en: Navigate to Nsight in the Visual Studio menu bar and click on Start CUDA Debugging
    (Next-Gen).
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Visual Studio菜单栏中导航到Nsight，然后单击“开始CUDA调试（Next-Gen）”。
- en: Right-click on the project in Solution Explorer and choose Debug | Start CUDA
    Debugging (Next-Gen).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“解决方案资源管理器”中右键单击项目，选择“调试|开始CUDA调试（Next-Gen）”。
- en: Go to the Nsight CUDA debugging toolbar and click Start CUDA Debugging (Next-Gen).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转到Nsight CUDA调试工具栏，单击“开始CUDA调试（Next-Gen）”。
- en: Window's firewall may ask if you trust and want to allow the network connection
    of Nsight. This is normal, since Nsight uses the internal network to monitor GPU
    devices. Click *Accept* and continue the debugging. The current Nsight Visual
    Studio Edition provides two types of debugging options. It depends on the target
    GPU architecture version. If your GPU is Volta or Turing, it is recommended to
    use Next-Gen debugging. If your GPU is Pascal, the proper debugger differs, depending
    on the driver version. To clarify, please visit the supported GPU list from NVIDIA: [http://developer.nvidia.com/nsight-visual-studio-edition-supported-gpus-full-list](http://developer.nvidia.com/nsight-visual-studio-edition-supported-gpus-full-list).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Windows防火墙可能会询问您是否信任并允许Nsight的网络连接。这是正常的，因为Nsight使用内部网络来监视GPU设备。单击“接受”并继续调试。当前的Nsight
    Visual Studio Edition提供了两种调试选项。这取决于目标GPU架构版本。如果您的GPU是Volta或Turing，建议使用“Next-Gen”调试。如果您的GPU是Pascal，则适当的调试器取决于驱动程序版本。为了澄清，请访问NVIDIA支持的GPU列表：[http://developer.nvidia.com/nsight-visual-studio-edition-supported-gpus-full-list](http://developer.nvidia.com/nsight-visual-studio-edition-supported-gpus-full-list)。
- en: The application will stop where the application starts. Continue the trace.
    The application will stop at line 75 on the host and line 34 on the device. From
    this, we can learn that the Nsight can trace a GPU application on the host and
    the device simultaneously.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序将在应用程序启动的地方停止。继续跟踪。应用程序将在主机的第75行和设备的第34行停止。从中我们可以了解到，Nsight可以同时跟踪主机和设备上的GPU应用程序。
- en: When the yellow arrow stops in the kernel function, you can review the local
    variables. The thread index is `0` in global indexes. Since CUDA issues multiple
    CUDA warps and CUDA threads in parallel, you can review the other threads' local
    variables by changing `blockIdx` and `threadIdx`. The basic CUDA thread debugging
    control unit is a warp. In other words, you can control the debugger so that it
    traverses active warps. The Nsight debugger provides this feature in the Previous
    Active Warp/Next Active Warp menu in the Nsight menu bar.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当黄色箭头停在内核函数中时，您可以查看局部变量。全局索引中的线程索引为`0`。由于CUDA并行发出多个CUDA warp和CUDA线程，因此您可以通过更改`blockIdx`和`threadIdx`来查看其他线程的局部变量。基本的CUDA线程调试控制单元是warp。换句话说，您可以控制调试器以遍历活动warp。Nsight调试器在Nsight菜单栏中的“上一个活动warp/下一个活动warp”菜单中提供了此功能。
- en: 'The following screenshot shows the Nsight debug controls that appear while
    we''re debugging:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了我们在调试时出现的Nsight调试控件：
- en: '![](img/dcf5eef0-05d5-4e19-8c5b-8ccc28f89508.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dcf5eef0-05d5-4e19-8c5b-8ccc28f89508.png)'
- en: 'If you change the warp, you will find that the local variables that are monitored
    in the Autos panel update the index, along with the warp. For example, the following
    screenshot shows the Autos window, which reports the local variables of the selected
    thread in an active warp, that is, the local variable''s value that''s being monitored
    by the leading thread:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果更改warp，您会发现在“Autos”面板中监视的局部变量会随着warp的变化而更新索引。例如，以下屏幕截图显示了“Autos”窗口，该窗口报告了活动warp中所选线程的局部变量，即正在由主导线程监视的局部变量的值：
- en: '![](img/0989a8ac-17c6-4b59-822b-da1874dd3056.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0989a8ac-17c6-4b59-822b-da1874dd3056.png)'
- en: 'The Autos value is updated following the selected thread changes. The following
    screenshot shows the changes that were made by moving to the next active warp:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 选择的线程更改后，Autos值会更新。以下屏幕截图显示了通过移动到下一个活动warp所做的更改：
- en: '![](img/384f174f-f511-412d-bc3c-8a2a020852fe.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/384f174f-f511-412d-bc3c-8a2a020852fe.png)'
- en: 'The Next-Gen CUDA debugger provides three types of windows—warp info, lanes,
    and GPU registers. The yellow arrow denotes current GPU execution, and its information
    is shown in three aspects:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Next-Gen CUDA调试器提供了三种类型的窗口——warp info、lanes和GPU registers。黄色箭头表示当前的GPU执行，并以三个方面显示其信息：
- en: 'The Warp Info window provides another way we can select an active warp. You
    can open the window from Nsight | Window | Warp Info in the menu bar. The window
    looks as follows:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Warp Info窗口提供了另一种选择活动warp的方法。您可以在菜单栏中从Nsight | Window | Warp Info打开该窗口。窗口如下所示：
- en: '![](img/792d956c-f385-4966-95e6-d0568f22959c.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/792d956c-f385-4966-95e6-d0568f22959c.png)'
- en: 'Each row denotes the active warps in the CUDA grid. The fourth column, Shader
    Info, shows each warp''s block and leading thread index. The fifth column, threads,
    shows the CUDA thread''s status in the warp. The color of the cell represents
    each thread''s status. They are all red since we are watching them at the breakpoints,
    but you will see other colors during the debugging process. The following screenshot
    explains what each color means in terms of thread state:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 每行表示CUDA网格中的活动warp。第四列“Shader Info”显示了每个warp的块和主导线程索引。第五列“threads”显示了warp中CUDA线程的状态。单元格的颜色表示每个线程的状态。由于我们在断点处观察它们，它们都是红色的，但在调试过程中您会看到其他颜色。以下屏幕截图解释了每种颜色在线程状态方面的含义：
- en: '![](img/b3d55d2f-75c5-4ea0-9b0a-66750ca6ef39.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3d55d2f-75c5-4ea0-9b0a-66750ca6ef39.png)'
- en: Double-click any warp to find out how the local variables in the autos window
    are updated.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 双击任何warp，查看autos窗口中的局部变量是如何更新的。
- en: 'The Lanes window allows you to select specific CUDA threads within the selected
    active warp. A lane means a single thread in a warp. You can open the window from
    Nsight | Window | Lanes. By double-clicking one lane, you can find that the local
    variables in the autos window are updated according to the updated index:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lanes窗口允许您在所选活动warp内选择特定的CUDA线程。一个lane指的是warp中的一个线程。您可以从Nsight | Window | Lanes中打开该窗口。通过双击一个lane，您可以发现autos窗口中的局部变量根据更新的索引而更新：
- en: '![](img/36e26550-f466-4939-947b-7577ff253123.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36e26550-f466-4939-947b-7577ff253123.png)'
- en: The lanes winn information in an active warp.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 活动warp中的lanes窗口信息。
- en: The Registers window shows the current state of the GPU registers. They will
    be red if their value is updated.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 寄存器窗口显示了GPU寄存器的当前状态。如果它们的值被更新，它们将变为红色。
- en: If you want to learn how to use Nsight Visual Studio Edition, please read the
    official user guide from NVIDIA. It introduces how to configure a debugging environment,
    how to use it, and many detailed tips for various situations ([https://docs.nvidia.com/nsight-visual-studio-edition/Nsight_Visual_Studio_Edition_User_Guide.htm](https://docs.nvidia.com/nsight-visual-studio-edition/Nsight_Visual_Studio_Edition_User_Guide.htm)).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解如何使用Nsight Visual Studio Edition，请阅读NVIDIA官方用户指南。它介绍了如何配置调试环境，如何使用它，以及各种情况下的详细提示。
    ([https://docs.nvidia.com/nsight-visual-studio-edition/Nsight_Visual_Studio_Edition_User_Guide.htm](https://docs.nvidia.com/nsight-visual-studio-edition/Nsight_Visual_Studio_Edition_User_Guide.htm))。
- en: Debugging a CUDA application with Nsight Eclipse Edition
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nsight Eclipse Edition调试CUDA应用程序
- en: For Linux and OSX platform development, the CUDA Toolkit provides Nsight Eclipse
    Edition. This tool is based on Eclipse, so that developers can easily get used
    to this tool in CUDA C development.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Linux和OSX平台开发，CUDA Toolkit提供了Nsight Eclipse Edition。这个工具基于Eclipse，因此开发人员可以很容易地在CUDA
    C开发中使用这个工具。
- en: Nsight Eclipse Edition was built on top of Eclipse for CUDA application development.
    You can use it to edit, build, debug, and profile your CUDA applications. It makes
    CUDA C/C++ development in Linux and OSX easy. This tool is installed with the
    CUDA Toolkit as a package, so you don't have to install this tool separately.
    However, it is required to configure Java 7 for its operation if you are using
    Linux.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Eclipse Edition是基于Eclipse用于CUDA应用程序开发的。您可以使用它来编辑、构建、调试和分析CUDA应用程序。它使得在Linux和OSX中进行CUDA
    C/C++开发变得简单。这个工具作为CUDA Toolkit的一部分安装，因此您不必单独安装这个工具。但是，如果您使用Linux，需要配置Java 7才能使用它。
- en: Nsight Eclipse Edition was built with Eclipse version 4.4.0 (Luna, released
    in 2014) and was built based on Java 7.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Eclipse Edition是基于Eclipse 4.4.0版本（2014年发布的Luna版本）构建的，并且基于Java 7构建。
- en: Nsight can be executed with the `nsight` command from a Terminal or from the
    X window application list.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight可以通过终端中的`nsight`命令或者X窗口应用程序列表中执行。
- en: Now, let's open Nsight from your Terminal or X window desktop so that we can
    compile and analyze the given example. Either create a new CUDA project or open
    the provided sample project in `05_debug/06_debug_with_eclipse`. If you want to
    create a project, select CUDA C/C++ Project. Empty Project just gives you an empty
    project, while CUDA Runtime Project gives you a project with some sample code
    inside it. If you want to use the sample project, import it using File | Import
    | Existing Projects into Workspace.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从终端或X窗口桌面打开Nsight，以便我们可以编译和分析给定的示例。要么创建一个新的CUDA项目，要么打开`05_debug/06_debug_with_eclipse`中提供的示例项目。如果要创建项目，请选择CUDA
    C/C++项目。空项目只会给您一个空项目，而CUDA Runtime项目会给您一个带有一些示例代码的项目。如果要使用示例项目，请使用文件 | 导入 | 导入现有项目到工作区。
- en: 'Let''s place a breakpoint in the `sgemm` kernel function. Like a normal C/C++
    project in Eclipse, you can build and debug the CUDA application in `nsight`.
    Place a breakpoint at line 23 as a starting point of the kernel function, as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在`sgemm`内核函数中设置一个断点。就像在Eclipse中的普通C/C++项目一样，您可以在`nsight`中构建和调试CUDA应用程序。在内核函数的起始点（第23行）设置一个断点，如下所示：
- en: '![](img/b942282b-f014-4cca-8c91-4cd000f0f6f9.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b942282b-f014-4cca-8c91-4cd000f0f6f9.png)'
- en: A good starting point for kernel function debugging is right after thread index
    calculation. Place a breakpoint to halt the GPU's execution. Now, compile and
    start debugging by clicking the green bug in the menu panel. While the debug window
    switches the debugging perspectives, click continue until you get to the breakpoint
    we have placed.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内核函数调试来说，一个很好的起点是在线程索引计算之后。设置一个断点来暂停GPU的执行。现在，通过单击菜单面板中的绿色bug来编译和开始调试。在调试窗口切换调试透视之时，点击继续，直到达到我们设置的断点。
- en: 'Nsight allows you to monitor local variables and registers in active warps.
    First, it stops the application at the leading CUDA thread (CUDA thread `0`) in
    the CUDA grid. Then, you can move to the other CUDA active warp from the debug
    window and inspect each CUDA thread using the CUDA window, like so:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight允许您监视活动warp中的局部变量和寄存器。首先，它会在CUDA网格中的领先CUDA线程（CUDA线程`0`）处停止应用程序。然后，您可以从调试窗口切换到其他CUDA活动warp，并使用CUDA窗口检查每个CUDA线程，就像这样：
- en: '![](img/85a86088-303b-4e26-9837-80e14a25fc35.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85a86088-303b-4e26-9837-80e14a25fc35.png)'
- en: 'The following screenshot shows the local variable information for a selected
    CUDA thread. Nsight updates those values whenever they are updated:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了所选CUDA线程的局部变量信息。Nsight会在这些值更新时更新它们：
- en: '![](img/9510862e-2a8b-4fec-b0df-5b181ca0f452.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9510862e-2a8b-4fec-b0df-5b181ca0f452.png)'
- en: The preceding screenshot shows the Debug window and CUDA window in Eclipse's
    debug perspective window. The debug window provides CUDA warp selection among
    the active warps on the selected GPU and CUDA windows and enables lane selection
    within the selected active warp.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图显示了Eclipse的调试透视窗口中的Debug窗口和CUDA窗口。调试窗口提供了在所选GPU上的活动warp中进行CUDA warp选择的功能，并且可以在所选活动warp内进行lane选择。
- en: NVIDIA also has an Nsight Eclipse Edition user guide. You can learn more about
    this tool by going to [https://docs.nvidia.com/cuda/nsight-eclipse-edition-getting-started-guide/index.html](https://docs.nvidia.com/cuda/nsight-eclipse-edition-getting-started-guide/index.html).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA还有一个Nsight Eclipse Edition用户指南。您可以通过访问[https://docs.nvidia.com/cuda/nsight-eclipse-edition-getting-started-guide/index.html](https://docs.nvidia.com/cuda/nsight-eclipse-edition-getting-started-guide/index.html)来了解更多关于这个工具的信息。
- en: Debugging a CUDA application with CUDA-GDB
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CUDA-GDB调试CUDA应用程序
- en: The CUDA Toolkit provides CUDA-GDB, which supports CUDA C/C++ debugging for
    programs such as C/C++ GDB. This is useful for directly debugging CUDA C/C++ applications
    where there's no X window environment or remote debugging.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA工具包提供了CUDA-GDB，它支持CUDA C/C++调试，用于诸如C/C++ GDB之类的程序。这对于直接调试没有X窗口环境或远程调试的CUDA
    C/C++应用程序非常有用。
- en: To debug a GPU application, the `Makefile` should include the `-g` debugging
    flag for the host and the `-G` debugging flag for the GPU. Basically, CUDA's GDB
    usage is identical to the host debugging, except there are some extra debugging
    features alongside the CUDA operations. For example, we can set specific CUDA
    threads and CUDA-aware breakpoints.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要调试GPU应用程序，`Makefile`应该包括主机的`-g`调试标志和GPU的`-G`调试标志。基本上，CUDA的GDB用法与主机调试相同，只是在CUDA操作之外还有一些额外的调试功能。例如，我们可以设置特定的CUDA线程和CUDA感知断点。
- en: Breakpoints of CUDA-GDB
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA-GDB的断点
- en: Let's cover how `cuda-gdb` can help us detect errors in code. We will set breakpoints
    in the code and look at the local values on the host and the GPU. For this, move
    your working directory to `05_debug/07_debug_with_gdb directory`. We will check
    the `cuda-gdb` operation by matching it with the appropriate line.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`cuda-gdb`如何帮助我们检测代码中的错误。我们将在代码中设置断点，并查看主机和GPU上的局部值。为此，将工作目录切换到`05_debug/07_debug_with_gdb`目录。我们将通过将其与适当的行匹配来检查`cuda-gdb`的操作。
- en: 'To begin with, let’s compile the source using the following command:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用以下命令编译源代码：
- en: '[PRE25]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, we should execute `cuda-gdb` so that we can debug the application on
    the Terminal, as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们应该执行`cuda-gdb`，这样我们就可以在终端上调试应用程序，如下所示：
- en: '[PRE26]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can place a breakpoint on a specific line in the code, as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在代码的特定行上设置断点，如下所示：
- en: '[PRE27]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Alternatively, we can put a breakpoint on the kernel function''s name, as follows.
    This will trigger the breakpoint at the entry point of the function:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以按照内核函数的名称设置断点，如下所示。这将在函数的入口点触发断点：
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Answer `y` if the `cuda-gdb` warning states that *the breakpoint wants to make
    pending on future shared library load*. You can also have breakpoints on the host
    code.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`cuda-gdb`警告指出*断点希望在未来的共享库加载时挂起*，则回答`y`。您也可以在主机代码上设置断点。
- en: 'One problem with using breakpoints is that the breakpoint will be triggered
    according to how many CUDA threads there are. Therefore, we should provide conditional
    information to have a breakpoint against specific CUDA threads. The conditional
    breakpoint is as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用断点的一个问题是，断点将根据CUDA线程的数量触发。因此，我们应该提供条件信息，以便针对特定的CUDA线程设置断点。条件断点如下：
- en: '[PRE29]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Of course, we can modify the condition of the predefined breakpoint as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以修改预定义断点的条件如下：
- en: '[PRE30]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s execute the sample application using the `run` command. If the application
    meets any breakpoint, CUDA-GDB provides information about it. The following code
    shows the `cuda-gdb` report when the application meets the breakpoint at line
    `21`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`run`命令执行示例应用程序。如果应用程序遇到任何断点，CUDA-GDB将提供有关它的信息。以下代码显示了应用程序在第`21`行遇到断点时`cuda-gdb`的报告：
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now, it's time to use the GDB command to trace the code or monitor the active
    variables. We can trace the kernel function with next (or `n`), step (or `s`),
    continue (or `c`), and finish (or `fin`). However, we should use the `continue`
    command when we get to the end of the kernel code and need to switch the target
    hardware between the host and the device.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候使用GDB命令来跟踪代码或监视活动变量了。我们可以使用next（或`n`）、step（或`s`）、continue（或`c`）和finish（或`fin`）来跟踪内核函数。然而，当我们到达内核代码的末尾并需要在主机和设备之间切换目标硬件时，我们应该使用`continue`命令。
- en: Inspecting variables with CUDA-GDB
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CUDA-GDB检查变量
- en: On the top of the default GDB commands, CUDA-GDB provides debugging features
    that can work with CUDA kernels. Here's what you can do with CUDA-GDB.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 除了默认的GDB命令之外，CUDA-GDB提供了可以与CUDA内核一起使用的调试功能。以下是您可以使用CUDA-GDB做的事情。
- en: Listing kernel functions
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列出内核函数
- en: 'Like a normal function, CUDA-GDB can place breakpoints on the kernel functions.
    Once your application has been stopped by the breakpoint, you can list them as
    follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 与普通函数一样，CUDA-GDB可以在内核函数上设置断点。一旦应用程序被断点停止，您可以列出它们如下：
- en: '[PRE32]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As you can see, the preceding output shows the kernel's configuration information
    and input parameter variables.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，前面的输出显示了内核的配置信息和输入参数变量。
- en: Variables investigation
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量调查
- en: 'CUDA-GDB helps us trace specific CUDA threads by selecting a specific thread
    block index and thread index. With this feature, you can move your current focus
    to the specified thread. In this example, the block size is 16 and the `col` variable
    is defined as a CUDA thread index in the `x` dimension. This following code shows
    how CUDA-GDB reports the selected local variable''s value by changing the thread
    index:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA-GDB帮助我们通过选择特定的线程块索引和线程索引来跟踪特定的CUDA线程。有了这个功能，您可以将当前焦点移动到指定的线程。在这个例子中，块大小为16，`col`变量被定义为`x`维度上的CUDA线程索引。以下代码显示了CUDA-GDB如何通过更改线程索引来报告所选的局部变量的值：
- en: '[PRE33]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Check the current focusing thread information:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 检查当前焦点线程的信息：
- en: '[PRE34]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: With the information at hand, we can trace the CUDA thread.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 有了手头的信息，我们可以追踪CUDA线程。
- en: 'If you want to learn more about CUDA-GDB, please check the user guide documentation
    from NVIDIA: [https://docs.nvidia.com/cuda/cuda-gdb/index.html](https://docs.nvidia.com/cuda/cuda-gdb/index.html).'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解有关CUDA-GDB的更多信息，请查看NVIDIA的用户指南文档：[https://docs.nvidia.com/cuda/cuda-gdb/index.html](https://docs.nvidia.com/cuda/cuda-gdb/index.html)。
- en: Runtime validation with CUDA-memcheck
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CUDA-memcheck进行运行时验证
- en: 'One difficult point of CUDA programming is handling memory space. Since CUDA
    threads operate in parallel, the boundary condition or unexpected indexing operation
    can violate valid memory space. CUDA memcheck is a runtime testing tool that validates
    memory access if any GPU operation exceeds the invalid memory space. This tool
    detects the following memory errors:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA编程的一个困难点是处理内存空间。由于CUDA线程并行操作，边界条件或意外的索引操作可能会违反有效的内存空间。CUDA memcheck是一个运行时测试工具，如果任何GPU操作超出了无效的内存空间，它将验证内存访问。该工具检测以下内存错误：
- en: '| Name | Location | Description | Precise |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 位置 | 描述 | 精确 |'
- en: '| Memory access error | Device | Invalid memory access (out of bound, misaligned)
    | O |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: 内存访问错误 | 设备 | 无效的内存访问（超出边界，未对齐） | O |
- en: '| Hardware exception | Device | Errors from the hardware | X |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 硬件异常 | 设备 | 硬件错误 | X |'
- en: '| Malloc/free errors | Device | Incorrect use of `malloc()`/`free()` in CUDA
    kernels | O |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| Malloc/free错误 | 设备 | 在CUDA内核中不正确使用`malloc()`/`free()` | O |'
- en: '| CUDA API errors | Host | The CUDA API''s error return | O |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| CUDA API错误 | 主机 | CUDA API的错误返回 | O |'
- en: '| cudaMalloc memory leaks | Host | Device memory that''s allocated using `cudaMalloc()`
    did not free by the application | O |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| cudaMalloc内存泄漏 | 主机 | 使用`cudaMalloc()`分配的设备内存未被应用程序释放 | O |'
- en: '| Device heap memory leaks | Device | Allocated device memory using `malloc()`
    in device code is not freed by the application | X |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: 设备堆内存泄漏 | 设备 | 在设备代码中使用`malloc()`分配的设备内存未被应用程序释放 | X |
- en: Precise (O) means that memcheck can specify the crashed line and file. On the
    other hand, imprecise (X) means that the tool can identify the error, but cannot
    specify the error points due to the concurrency status. `cuda-memcheck` does not
    require recompilation for the test. However, if we compile with some extra `nvcc`
    options, we can trace error points. The `nvcc` options including `-lineinfo`,
    which generates line number information, and `-Xcompiler -rdynamic`, which is
    used to retain function symbols.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 精确（O）表示memcheck可以指定崩溃的行和文件。另一方面，不精确（X）表示该工具可以识别错误，但由于并发状态，无法指定错误点。`cuda-memcheck`不需要重新编译进行测试。但是，如果我们使用一些额外的`nvcc`选项进行编译，我们可以跟踪错误点。`nvcc`选项包括生成行号信息的`-lineinfo`和用于保留函数符号的`-Xcompiler
    -rdynamic`。
- en: 'Basically, `cuda-memcheck` is a standalone tool and validates GPU applications
    at runtime. The following command shows its format in standalone mode:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，`cuda-memcheck`是一个独立的工具，可以在运行时验证GPU应用程序。以下命令显示了它在独立模式下的格式：
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This tool can also work with CUDA-GDB and help the developer identify errors
    and debug them. In the CUDA-GDB command line, use the `set cuda memcheck on` command
    to enable memory checks. This way, CUDA-GDB can identify memory-related exceptions.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具也可以与CUDA-GDB一起使用，帮助开发人员识别错误并进行调试。在CUDA-GDB命令行中，使用`set cuda memcheck on`命令启用内存检查。这样，CUDA-GDB可以识别与内存相关的异常。
- en: Detecting memory out of bounds
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测内存越界
- en: 'Now, let''s see how `cuda-memcheck` can detect memory exceptions and work with
    CUDA-GDB. To ease this, we will make some erroneous code and see how `cuda-memcheck`
    reports the result. Let''s begin with some clean code. You can use the given sample
    code in `05_debug/08_cuda_memcheck` for this. Let''s test the code using `cuda-memcheck`
    and validate it:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看`cuda-memcheck`如何检测内存异常并与CUDA-GDB一起工作。为了简化这个过程，我们将编写一些错误的代码，并查看`cuda-memcheck`如何报告结果。让我们从一些干净的代码开始。您可以使用`05_debug/08_cuda_memcheck`中提供的示例代码进行测试。让我们使用`cuda-memcheck`测试代码并验证它：
- en: '[PRE36]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, let''s put some erroneous code into the kernel function, as follows. You
    can put another error if you prefer:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将一些错误的代码放入内核函数中，如下所示。如果您愿意，您也可以放入其他错误：
- en: '[PRE37]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s compile and launch the code. The kernel will return a CUDA error and `checkCudaErrors()` will
    report an error message, as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编译并启动代码。内核将返回一个CUDA错误，`checkCudaErrors()`将报告一个错误消息，如下所示：
- en: '[PRE38]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'However, this information is insufficient if we wish to identify which line
    in the kernel code is the root cause of the problem. Using `cuda-memcheck`, we
    can identify which CUDA thread and memory space triggered the error with a stack
    address:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们希望确定内核代码中的哪一行是问题的根本原因，这些信息是不够的。使用`cuda-memcheck`，我们可以确定哪个CUDA线程和内存空间触发了错误，并给出堆栈地址：
- en: '[PRE39]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/2be60221-e0bb-4993-a55c-d90934c2cd8a.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2be60221-e0bb-4993-a55c-d90934c2cd8a.png)'
- en: The preceding screenshot shows a part of the standalone execution of `cuda-memcheck`,
    which shows all the detected errors from the kernel where the error occurred.
    In this case, `cuda-memcheck` reports that it detected a memory violation error
    at line `27`. By default, `cuda-memcheck` stops the application's execution when
    an error is detected.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图显示了`cuda-memcheck`独立执行的一部分，显示了内核中检测到的所有错误。在这种情况下，`cuda-memcheck`报告检测到在第27行发生的内存违规错误。默认情况下，`cuda-memcheck`在检测到错误时会停止应用程序的执行。
- en: 'In this situation, we can find the root cause easily by inspecting the related
    variables using `cuda-gdb`. To do this, we need to launch the application with
    `cuda-gdb` and enable `cuda-memcheck`, as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以通过检查相关变量来轻松找到根本原因，使用`cuda-gdb`。为此，我们需要使用`cuda-gdb`启动应用程序，并启用`cuda-memcheck`，如下所示：
- en: '[PRE40]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This procedure makes `cuda-gdb` report illegal memory access detection from
    `cuda-memcheck`:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程使`cuda-gdb`从`cuda-memcheck`报告非法内存访问检测：
- en: '![](img/7718fc0f-e576-4c4e-9d31-2a921c5045bf.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7718fc0f-e576-4c4e-9d31-2a921c5045bf.png)'
- en: 'The preceding screenshot shows a report from `cuda-gdb` with `cuda-memcheck`.
    The developer can easily identify that line `27` in `simple_sgemm_oob.cu` triggered
    the reported error. From the given information, we can start to investigate which
    piece of memory accessed the invalid space, as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图显示了`cuda-gdb`与`cuda-memcheck`的报告。开发人员可以轻松地确定`simple_sgemm_oob.cu`中的第27行触发了报告的错误。根据给定的信息，我们可以开始调查哪一块内存访问了无效的空间，如下所示：
- en: '[PRE41]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Without arduous effort, we can determine that accessing `A[row * K + i]` triggers
    an error and that the requested value exceeds the global memory's (`A`) allocated
    space. In this manner, you can narrow down the root cause without much effort.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在不费吹灰之力的情况下，我们可以确定访问`A[row * K + i]`会触发错误，并且请求的值超出了全局内存（`A`）的分配空间。通过这种方式，您可以轻松地缩小根本原因。
- en: Detecting other memory errors
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测其他内存错误
- en: 'The CUDA memcheck tool provides additional software validation features, some
    of which are as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA memcheck工具提供了额外的软件验证功能，其中一些如下：
- en: '| **Name** | **Description** | **Option** |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **描述** | **选项** |'
- en: '| Memory leak | For identifying memory leaks | `--leak-check full` |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 内存泄漏 | 用于识别内存泄漏 | `--leak-check full` |'
- en: '| Race check | For the analysis of the racing hazard of conflicting access
    between multiple threads to the shared memory | `--tool racecheck` |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 竞争检查 | 用于分析多个线程之间对共享内存的冲突访问的竞争危险 | `--tool racecheck` |'
- en: '| Init check | Identifying device global memory access without initialization
    | `--tool initcheck` |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 初始化检查 | 在没有初始化的情况下识别设备全局内存访问 | `--tool initcheck` |'
- en: '| Sync check | Validates the correct use of synchronization primitives such
    as `__syncthreads()`, `__syncwarp()`, and cooperative group APIs | `--tool synccheck`
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 同步检查 | 验证同步原语的正确使用，如`__syncthreads()`，`__syncwarp()`和协作组API | `--tool synccheck`
    |'
- en: These tools assume that the memory accesses are correct or verified and do not
    check for memory errors. Due to this, you need to confirm that no memory errors
    exist in your application. Other useful memcheck options include `--save`, which
    we can use to save the output to a disk, and `--print-level`, which we can use
    to control the output detail level.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具假设内存访问是正确的或经过验证的，并且不检查内存错误。因此，您需要确认您的应用程序中不存在内存错误。其他有用的memcheck选项包括`--save`，我们可以用它来将输出保存到磁盘，以及`--print-level`，我们可以用它来控制输出的详细级别。
- en: NVIDIA provides a user guide for `cuda-memcheck`. This document will help you
    validate your application using a GPU and detect unexpected errors ([https://docs.nvidia.com/cuda/cuda-memcheck/index.html](https://docs.nvidia.com/cuda/cuda-memcheck/index.html)).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA为`cuda-memcheck`提供了用户指南。该文档将帮助您使用GPU验证您的应用程序并检测意外错误 ([https://docs.nvidia.com/cuda/cuda-memcheck/index.html](https://docs.nvidia.com/cuda/cuda-memcheck/index.html))。
- en: Profiling GPU applications with Nsight Systems
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nsight Systems对GPU应用程序进行分析
- en: In this section, we will cover the newly introduced CUDA profiler tools, that
    is, Nsight Systems and Nsight Compute. These profilers support the Volta architecture
    and onwards GPUs. It is major profiler in the Turing architecture GPU. We will
    cover the Nsight Systems first, before covering Nsight Compute in the next section.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍新引入的CUDA分析器工具，即Nsys和Nvprof。这些分析器支持Volta架构及更高版本的GPU。它是图灵架构GPU中的主要分析器。我们将先介绍Nsys，然后在下一节介绍Nvprof。
- en: Nsight Systems ([https://developer.nvidia.com/nsight-systems](https://developer.nvidia.com/nsight-systems))
    is a system-wide performance analysis tool that can visualize operations in the
    timeline and easily find optimization points. In terms of the timeline analysis
    aspects, Nsight Systems provides system-side utilization information so that we
    can analyze the bottleneck points. We can get Nsight Systems from the NVIDIA website,
    but CUDA 10 includes Nsight Systems in the toolkit package by default. All we
    have to do is make sure it is installed correctly.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Systems ([https://developer.nvidia.com/nsight-systems](https://developer.nvidia.com/nsight-systems))是一个系统范围的性能分析工具，可以在时间轴上可视化操作并轻松找到优化点。在时间轴分析方面，Nsight
    Systems提供了系统利用率信息，以便我们可以分析瓶颈点。我们可以从NVIDIA网站获取Nsight Systems，但CUDA 10默认包含了Nsight
    Systems在工具包中。我们只需要确保它安装正确即可。
- en: 'For the CLI, we should set the `PATH` to ease our operation because its path
    is separated with ordinary CUDA binaries. Let''s include that in the `PATH` environment
    variable using the following command:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 对于CLI，我们应该设置`PATH`以便于我们的操作，因为它的路径与普通的CUDA二进制文件分开。我们可以使用以下命令将其包含在`PATH`环境变量中：
- en: '[PRE42]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Nsight Systems provides two interfaces: one for the GUI and one for the CLI.
    On a host machine, we can collect the application''s sampling information by running
    the application via a GUI. On the remote machine, we can collect the profiled
    data via a CLI with the following command:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Nsys提供了两个接口：一个用于GUI，一个用于CLI。在主机上，我们可以通过GUI运行应用程序来收集应用程序的采样信息。在远程机器上，我们可以通过CLI收集分析数据，使用以下命令：
- en: '[PRE43]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This option can be interpreted as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项可以解释如下：
- en: '|  | Option | Switches |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '|  | 选项 | 开关 |'
- en: '| Tracing | `-t`/`--trace` | `cuda`: For tracing CUDA operations,`nvtx`: For
    tracing `nvtx` tags,`cublas`, `cudnn`, `opengl`,`openacc`: For tracing the API
    operation,`osrt`: For tracing OS runtime libraries,`none`: No API trace |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 跟踪 | `-t`/`--trace` | `cuda`: 用于跟踪CUDA操作，`nvtx`: 用于跟踪`nvtx`标签，`cublas`, `cudnn`,
    `opengl`,`openacc`: 用于跟踪API操作，`osrt`: 用于跟踪OS运行时库，`none`: 不进行API跟踪 |'
- en: '| Output file | `-o`/`--output` | Output filename |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 输出文件 | `-o`/`--output` | 输出文件名 |'
- en: '| Show output | `-w`/`--show-`output | `true`/`false`: Prints out the behavior
    of the profiler on the Terminal |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 显示输出 | `-w`/`--show-`output | `true`/`false`: 在终端上打印出分析器的行为 |'
- en: 'For example, we can obtain a profiled file named `sgemm.qdrep` from the `02_nvtx`
    SGEMM application. Let''s compare the profiled output between Nsight Systems and
    the NVIDIA Visual Profiler. We can collect the Nsight System''s profile data with
    the following command:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以从`02_nvtx` SGEMM应用程序中获得一个名为`sgemm.qdrep`的分析文件。让我们比较Nsight Systems和NVIDIA
    Visual Profiler之间的分析输出。我们可以使用以下命令收集Nsys的分析数据：
- en: '[PRE44]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This is the profiled timeline view from Nsight Systems:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这是来自Nsys的分析时间轴视图：
- en: '![](img/56430c7c-9262-4bd9-baac-e5f00e655e18.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56430c7c-9262-4bd9-baac-e5f00e655e18.png)'
- en: 'The following screenshot shows the profiled timeline view from the NVIDIA Visual
    Profiler:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了来自NVIDIA Visual Profiler的分析时间轴视图：
- en: '![](img/52c8ca52-275f-4dd2-a7cc-d17b30f0dfc0.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52c8ca52-275f-4dd2-a7cc-d17b30f0dfc0.png)'
- en: The Visual Profiler shows the operation event blocks, but Night Systems shows
    the system utilization together. Therefore, we can easily see which resource—CPU
    core, GPU, or PCIe bus—has an impact on performance. Also, Nsight Systems provides
    a more interactive profiling experience. When you double-click any function operation,
    the Nsight Systems Viewer expands the timeline to fit the window and helps us
    inspect the operation. In addition, Nsight Systems makes it easy for us to discover
    the number of kernel executions that are occurring under a certain NVTX area.
    In the Visual Profiler timeline view, the kernel executions look like a single
    execution, but Nsight Systems shows the separated execution.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Profiler显示操作事件块，而Nsight Systems同时显示系统利用率。因此，我们可以轻松地看到哪些资源（CPU核心、GPU或PCIe总线）对性能产生影响。此外，Nsight
    Systems提供了更具交互性的性能分析体验。当双击任何函数操作时，Nsight Systems Viewer会展开时间轴以适应窗口，并帮助我们检查操作。此外，Nsight
    Systems使我们能够轻松地发现在某个NVTX区域下发生的内核执行次数。在Visual Profiler时间轴视图中，内核执行看起来像是单个执行，但Nsight
    Systems显示了分离的执行。
- en: Now that we have determined that a function should be optimized, we can move
    on to Nsight Compute, which is another new profiler that inspects the GPU operations
    of the kernel function.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了应该优化的函数，我们可以继续使用Nsight Compute，这是另一个新的性能分析器，用于检查内核函数的GPU操作。
- en: Profiling a kernel with Nsight Compute
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nsight Compute进行内核性能分析
- en: Nsight Compute is a kernel-level profiler for computations. It collects GPU
    metric information and helps us focus on the CUDA kernel's optimization. In other
    words, this tool covers the Visual Profiler's performance analysis features.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Compute是一个用于计算的内核级性能分析器。它收集GPU指标信息，并帮助我们专注于CUDA内核的优化。换句话说，这个工具涵盖了Visual
    Profiler的性能分析功能。
- en: 'Nsight Compute provides two interfaces: the GUI and the CLI. The GUI supports
    the host and the remote application profile, while the CLI works on the target
    machine. However, we can get the profiled data and review the results using the
    GUI.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Compute提供两种接口：GUI和CLI。GUI支持主机和远程应用程序性能分析，而CLI适用于目标机器。然而，我们可以使用GUI获取分析数据并查看结果。
- en: Profiling with the CLI
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CLI进行性能分析
- en: 'For ease of using the Nsight Compute CLI, we need to set the `PATH` environment
    variable for the Nsight Compute path in `/usr/local/cuda-10.1/NsightCompute-2019.3/nv-nsight-cu-cli`.
    Then, we can collect profile data using the following command:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便使用Nsight Compute CLI，我们需要在`/usr/local/cuda-10.1/NsightCompute-2019.3/nv-nsight-cu-cli`中设置`PATH`环境变量。然后，我们可以使用以下命令收集性能分析数据：
- en: '[PRE45]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This command collects GPU execution metric information and saves the data to
    the specified file. If we don't provide an output filename, Nsight Compute reports
    the collected metric reports to the console, which provides a fast metric performance
    report over the console.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令收集GPU执行指标信息，并将数据保存到指定的文件中。如果我们没有提供输出文件名，Nsight Compute将把收集到的指标报告输出到控制台，从而在控制台上提供快速的指标性能报告。
- en: 'Since we can specify the profiling target, we can limit Nsight Compute to collect
    the following information:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可以指定性能分析目标，我们可以限制Nsight Compute收集以下信息：
- en: '`--kernel-regex`: Specifies the kernel to the profile'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--kernel-regex`：指定要进行性能分析的内核'
- en: '`--devices`: Focuses on profiling a specific GPU'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: --设备：专注于对特定GPU进行性能分析
- en: This feature is useful when we have to look at the report on the console.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要在控制台上查看报告时，这个功能非常有用。
- en: Profiling with the GUI
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GUI进行性能分析
- en: 'By opening a new project in Nsight Compute, we can initiate the profile operation.
    The following screenshot shows the profile configuration. For host application
    development, make a connection to the localhost. Alternatively, you can specify
    the target GPU server we want to profile:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在Nsight Compute中打开一个新项目，我们可以启动性能分析操作。以下截图显示了性能分析配置。对于主机应用程序开发，请连接到本地主机。或者，您可以指定要进行性能分析的目标GPU服务器：
- en: '![](img/56cc2622-8952-4b5f-b66b-c9f5ae257f4f.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56cc2622-8952-4b5f-b66b-c9f5ae257f4f.png)'
- en: 'Of course, we can also open the `nsight-cuprof-report` file, which was generated
    with the CLI tool over the target machine. For example, we can make the sgemm
    profiled file with the following command:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可以打开使用CLI工具在目标机器上生成的`nsight-cuprof-report`文件。例如，我们可以使用以下命令创建sgemm性能分析文件：
- en: '[PRE46]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: For OSX users, Nsight Systems will require the target `glib` library for remote
    profiling. In this case, we should copy the library from the Nsight Compute installation
    image. It provides the required libraries as a directory named target and copies
    that directory to the `Applications/NVIDIA Nsight Compute.app/target` directory.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 对于OSX用户，Nsight Systems将需要目标`glib`库进行远程性能分析。在这种情况下，我们应该从Nsight Compute安装映像中复制该库。它将所需的库提供为一个名为target的目录，并将该目录复制到`Applications/NVIDIA
    Nsight Compute.app/target`目录。
- en: 'For the ease of this lab, we will use a reduction sample code from [Chapter
    3](71d77c43-0064-491e-9b43-307a05bd6555.xhtml), *CUDA Thread Programming*. It
    has two parallel reduction implementations with different addressing. You can
    find the code from `03_cuda_thread_programming/05_warp_divergence` directory.
    Click the Launch button when you finish to set the connection and application
    Executable text bar as shown in the connect to progress diagram. Then, put *Ctrl*
    + *I*, *Ctrl* + *K* key to run to next kernel function, and then the profiler
    will stop at `reduction_kernel_1`. Put *Ctrl* + *I*, *Ctrl* + *P* key to profile
    this kernel. Then you''ll get the following output. This picture shows Nsight
    Compute''s GUI-based profiling for the first kernel profiling:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们将使用来自[第3章](71d77c43-0064-491e-9b43-307a05bd6555.xhtml) *CUDA线程编程*的减少示例代码。它有两个不同寻址的并行减少实现。您可以在`03_cuda_thread_programming/05_warp_divergence`目录中找到代码。完成连接和应用程序可执行文本栏的设置后，单击启动按钮。然后，按下*Ctrl*
    + *I*，*Ctrl* + *K*键以运行到下一个内核函数，然后性能分析器将停在`reduction_kernel_1`处。按下*Ctrl* + *I*，*Ctrl*
    + *P*键以对此内核进行性能分析。然后您将得到以下输出。这张图片展示了Nsight Compute基于GUI的第一个内核性能分析：
- en: '![](img/970759b9-b14a-437c-a647-92e4659b6e9a.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/970759b9-b14a-437c-a647-92e4659b6e9a.png)'
- en: Output showing GUI-based profiling (for the first kernel profiling)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 显示基于GUI的配置文件（用于第一个内核配置文件）
- en: It provides interactive profiling and debugging. Using the step control debug
    buttons, we can debug the CUDA API and kernel functions. We can also move to the
    next kernel function or the next profile range using the control button on the
    left side API stream panel. On the right panel, you can get the detail profiled
    information of the kernel.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了交互式配置文件和调试。使用步骤控制调试按钮，我们可以调试CUDA API和内核函数。我们还可以使用左侧API流面板上的控制按钮移动到下一个内核函数或下一个配置文件范围。在右侧面板上，您可以获取内核的详细配置文件信息。
- en: We also can get the profiled result automatically by enabling the auto profile
    with the following procedure—go to the Menu bar and select Profile | Auto Profile.
    Then, proceed with the application. Nsight Systems will profile all the kernel
    functions. Alternatively, you can profile the kernel function manually by clicking
    the Profile Kernel button on the top of the window. When we use the CLI's collected
    profiled results, we will just see profiled data from all the kernel functions.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过启用自动配置文件来自动获取配置文件结果，具体操作如下：转到菜单栏，选择Profile | Auto Profile。然后，继续进行应用程序。Nsight
    Systems将配置所有的内核函数。或者，您可以通过单击窗口顶部的Profile Kernel按钮来手动配置内核函数。当我们使用CLI收集的配置文件结果时，我们将只看到所有内核函数的配置文件数据。
- en: Performance analysis report
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能分析报告
- en: As we could see on the right panel in the interactive profile window, the Nsight
    Compute provides a performance analysis report. From the report, we can identify
    the performance limiters and investigate the underutilized resources. Also, Nsight
    Compute provides optimization recommendations based on resource utilization statistics.
    We can also identify them from direct profile.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在交互式配置文件窗口的右侧面板上，我们可以看到Nsight Compute提供了性能分析报告。从报告中，我们可以确定性能限制因素并调查未充分利用的资源。此外，Nsight
    Compute还根据资源利用统计数据提供优化建议。我们也可以直接从直接配置文件中识别它们。
- en: Also, Nsight Compute provides optimization recommendations by analyzing the
    GPU components utilizations. It finds a bottleneck and suggests a recommended
    investigation to optimize the kernel.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Nsight Compute通过分析GPU组件的利用率提供优化建议。它找到瓶颈并建议进行推荐的调查以优化内核。
- en: 'This report page provides each component''s utilizations such as compute, memory,
    scheduler, instruction, warp, and so on. Furthermore, you can get even more details
    by extending the left top arrow for each component. The following picture shows
    an example report of the Memory Workload Analysis:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 此报告页面提供了每个组件的利用率，如计算、内存、调度器、指令、warp等。此外，您可以通过扩展每个组件的左上箭头来获取更多详细信息。以下图片显示了内存工作负载分析的示例报告：
- en: '![](img/21b05b61-2775-47c0-9f4c-66a009420ec4.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21b05b61-2775-47c0-9f4c-66a009420ec4.png)'
- en: In the Nsight Compute, we can get such detailed information easily. In the previous
    profiler, NVIDIA Profiler, we should execute each analysis to obtain such information.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在Nsight Compute中，我们可以轻松获取这样的详细信息。在以前的分析器NVIDIA Profiler中，我们应该执行每个分析以获取这样的信息。
- en: Baseline compare
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基线比较
- en: 'During the optimization process, we should compare the new result from the
    baseline operation. To make this task easy for us, Nsight Compute provides the baseline
    compare feature. Click the Add baseline button at the top of the performance report
    panel and change it to the other kernel function. Then, we can use the Nsight
    Compute to compare kernel function utilizations. The following screen shows this:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化过程中，我们应该将新结果与基线操作进行比较。为了使这项任务对我们来说更容易，Nsight Compute提供了基线比较功能。单击性能报告面板顶部的Add
    baseline按钮，并将其更改为其他内核函数。然后，我们可以使用Nsight Compute来比较内核函数的利用率。以下屏幕显示了这一点：
- en: '![](img/e2f2eadc-5230-453e-911b-038a21d64ac6.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2f2eadc-5230-453e-911b-038a21d64ac6.png)'
- en: Comparison of kernel function utilizations
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 内核函数利用率的比较
- en: This is useful if we wish to trace our optimization efforts and identify the
    effective components.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望追踪我们的优化工作并确定有效的组件，这将非常有用。
- en: Source view
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源视图
- en: 'Nsight Compute provides various pages that we can investigate. One of its useful
    pages is the Source page. If the CUDA application is built with `-lineinfo` option,
    Nsight Compute can show correlated information with CUDA C/C++ source with CUDA
    SASS code. Then, we can analyze the bottleneck code and investigate how it is
    related to the SASS code level. Also, it provides a Live Registers number so that
    we can investigate the number of required registers in the kernel function. The
    following screenshot shows the Source page:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Compute提供了各种我们可以调查的页面。其中一个有用的页面是Source页面。如果CUDA应用程序是使用`-lineinfo`选项构建的，Nsight
    Compute可以显示与CUDA C/C++源代码相关的信息和CUDA SASS代码。然后，我们可以分析瓶颈代码并调查它与SASS代码级别的关系。此外，它提供了一个Live
    Registers数字，以便我们可以调查内核函数中所需寄存器的数量。以下截图显示了Source页面：
- en: '![](img/69711bc7-a6e5-461d-a97d-bdff04a62418.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69711bc7-a6e5-461d-a97d-bdff04a62418.png)'
- en: If you need to learn more about this feature, you can find the related information
    in this document—[https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page](https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要了解更多关于此功能的信息，您可以在此文档中找到相关信息-[https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page](https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page)。
- en: Nsight Compute provides a CUDA kernel performance analysis centric operation
    that we can use to verify that Night Systems and Nsight Compute have a different
    optimization scope.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Compute提供了一个以CUDA内核性能分析为中心的操作，我们可以用来验证Night Systems和Nsight Compute具有不同的优化范围。
- en: Summary
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have covered how to profile a GPU application and debug
    it. Understanding these CUDA tools will help you develop efficiently and effectively
    as they help you find bottlenecks pragmatically and find errors and bugs in a
    short time.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经介绍了如何配置GPU应用程序并对其进行调试。了解这些CUDA工具将有助于您高效和有效地开发，因为它们可以帮助您找到瓶颈，并在短时间内找到错误和漏洞。
- en: Up until now, we have focused on single GPU application development. However,
    many GPU applications use multiple GPUs to achieve better performance. In the
    next chapter, we will cover how to write code that works on multiple GPUs and
    aim for scalable performance. You will learn what can make an impact on performance
    and how to achieve good performance levels. You will also be able to apply the
    tools that we covered in this chapter on the next chapter's problems to reinforce
    multiple GPU systems and their experiences.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直专注于单个GPU应用程序开发。然而，许多GPU应用程序使用多个GPU来实现更好的性能。在下一章中，我们将介绍如何编写能在多个GPU上运行并且具有可扩展性性能的代码。您将学习什么因素会影响性能以及如何实现良好的性能水平。您还将能够应用本章涵盖的工具来加强多GPU系统及其经验，解决下一章的问题。
