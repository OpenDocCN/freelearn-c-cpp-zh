["```cpp\n__global__ void sgemm_kernel_v2(const float *A, const float *B, float *C,\n    int M, int N, int K, float alpha, float beta) {}\n```", "```cpp\nint bid_x = blockIdx.x * blockDim.x;\nint bid_y = blockIdx.y * blockDim.y;\nint tid_x = threadIdx.x;\nint tid_y = threadIdx.y;\n```", "```cpp\nfloat element_c = 0.f;\n__shared__ float s_tile_A[BLOCK_DIM][BLOCK_DIM];\n__shared__ float s_tile_B[BLOCK_DIM][BLOCK_DIM];\n```", "```cpp\nfor (int k = 0; k < K; k += BLOCK_DIM)\n{\n   ... {step 5 and 6 will cover } ...\n}\n```", "```cpp\n// Get sub-matrix from A\ns_tile_A[tid_y][tid_x] = A[ (bid_y + tid_y) * K + tid_x + k ];\n// Get sub-matrix from B \ns_tile_B[tid_y][tid_x] = B[ k * N + bid_x + tid_x ]; \n\n__syncthreads();\n```", "```cpp\nfor (int e = 0; e < BLOCK_DIM; e++)\n    element_c += s_tile_A[tid_y][e] * s_tile_B[e][tid_x];\n```", "```cpp\nC[(bid_y + tid_y) * N + (bid_x + tid_x)] = \\\n alpha * element_c + beta * C[(bid_y + tid_y) * N + (bid_x + tid_x)];\n```", "```cpp\n$ nvcc -m64 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -o sgemm ./sgemm.cu \n$ nvprof ./sgemm \n\n        Type Time(%)    Time Calls      Avg      Min      Max Name\nGPU activities: 47.79% 9.9691ms     1 9.9691ms 9.9691ms 9.9691ms sgemm_kernel(...)\n 32.52% 6.7845ms     1 6.7845ms 6.7845ms 6.7845ms sgemm_kernel_v2(...)\n```", "```cpp\n Type Time(%)    Time Calls      Avg       Min       Max Name\nGPU activities: 46.52% 8.1985ms     1 8.1985ms  8.1985ms  8.1985ms sgemm_kernel(...)\n 31.24% 5.4787ms     1 5.4787ms  5.4787ms  5.4787ms sgemm_kernel_v2(...)\n```", "```cpp\n__global__ void\nconvolution_kernel_v1(float *d_output, float *d_input, float *d_filter, int num_row, int num_col, int filter_size)\n{\n    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n\n    float result = 0.f;\n    // iterates over the every value in the filter\n    for (int filter_row = -filter_size / 2; \n         filter_row <= filter_size / 2; ++filter_row)\n    {\n        for (int filter_col = -filter_size / 2; \n             filter_col <= filter_size / 2; ++filter_col)\n        {\n            // Find the global position to apply the given filter\n            // clamp to boundary of the source\n            int image_row = min(max(idx_y + filter_row, 0), \n                                static_cast<int>(num_row - 1));\n            int image_col = min(max(idx_x + filter_col, 0), \n                                static_cast<int>(num_col - 1));\n\n            float image_value = static_cast<float>(\n                                d_input[image_row * num_col + \n                                image_col]);\n            float filter_value = d_filter[(filter_row + \n                                           filter_size / 2) * \n                                           filter_size \n                                           + filter_col + \n                                           filter_size / 2];\n\n            result += image_value * filter_value;\n        }\n    }\n\n    d_output[idx_y * num_col + idx_x] = result;\n}\n```", "```cpp\nfor (int row = 0; row <= tile_size / BLOCK_DIM; row++) {\n    for (int col = 0; col <= tile_size / BLOCK_DIM; col++) {\n        ... (filter update operation) ...\n    }\n}\n```", "```cpp\n#define MAX_FILTER_LENGTH 128\n__constant__ float c_filter[MAX_FILTER_LENGTH * MAX_FILTER_LENGTH];\n```", "```cpp\ncudaMemcpyToSymbol(c_filter, h_filter, filter_size * filter_size * sizeof(float));\n```", "```cpp\n__global__ void\nconvolution_kernel_v2(float *d_output, float *d_input, float *d_filter, int num_row, int num_col, int filter_size)\n{\n    int idx_x = blockDim.x * blockIdx.x + threadIdx.x;\n    int idx_y = blockDim.y * blockIdx.y + threadIdx.y;\n\n    float result = 0.f;\n    for (int filter_row = -filter_size / 2; \n         filter_row <= filter_size / 2; ++filter_row)\n    {\n        for (int filter_col = -filter_size / 2; \n             filter_col <= filter_size / 2; ++filter_col)\n        {\n            int image_row = idx_y + filter_row;\n            int image_col = idx_x + filter_col;\n\n            float image_value = (image_row >= 0 \n                                 && image_row < num_row \n                                 && image_col >= 0\n                                 && image_col < num_col) ?\n                                 d_input[image_row * num_col \n                                         + image_col] : 0.f;\n            float filter_value = c_filter[(filter_row \n                                          + filter_size / 2) \n                                          * filter_size \n                                          + filter_col \n                                          + filter_size / 2];\n\n            result += image_value * filter_value;\n        }\n    }\n\n    d_output[idx_y * num_col + idx_x] = result;\n}\n```", "```cpp\n$ nvcc -run -m64 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -o convolution ./convolution.cu\n$ nvprof ./convolution\n           Type Time(%) Time Calls Avg Min Max Name\n 12.85% 442.21us     1 442.21us 442.21us 442.21us convolution_kernel_v1(...)\n 11.97% 412.00us     1 412.00us 412.00us 412.00us convolution_kernel_v2(...)\n```", "```cpp\nint shared_mem_size = (2*filter_size+BLOCK_DIM) * (2*filter_size+BLOCK_DIM) * sizeof(float);\nconvolution_kernel_v3<<<dimGrid, dimBlock, shared_mem_size, 0 >>>(d_output, d_input, d_filter, num_row, num_col, filter_size);\n```", "```cpp\nextern __shared__ float s_input[];\n```", "```cpp\nint pad_size = filter_size / 2;\nint tile_size = BLOCK_DIM + 2 * pad_size;\n```", "```cpp\nfor (int row = 0; row <= tile_size / BLOCK_DIM; row++) {\n    for (int col = 0; col <= tile_size / BLOCK_DIM; col++) {\n        int idx_row = idx_y + BLOCK_DIM * row - pad_size; \n        // input data index row\n        int idx_col = idx_x + BLOCK_DIM * col - pad_size; \n        // input data index column\n        int fid_row = threadIdx.y + BLOCK_DIM * row; \n        // filter index row\n        int fid_col = threadIdx.x + BLOCK_DIM * col; \n        // filter index column\n\n        if (fid_row >= tile_size || fid_col >= tile_size) continue;\n\n        s_input[tile_size * fid_row + fid_col] = \\\n            (idx_row >= 0 && idx_row < num_row && idx_col >= 0 \n                && idx_col < num_col) ? \n                d_input[num_col * idx_row + idx_col] : 0.f;\n    }\n}\n\n__syncthreads();\n```", "```cpp\nfloat result = 0.f;\n    for (int filter_row = -filter_size / 2; \n         filter_row <= filter_size / 2; ++filter_row)\n    {\n        for (int filter_col = -filter_size / 2; \n             filter_col <= filter_size / 2; ++filter_col)\n        {\n            // Find the global position to apply the given filter \n            int image_row = threadIdx.y + pad_size + filter_row;\n            int image_col = threadIdx.x + pad_size + filter_col;\n\n            float image_value = s_input[tile_size \n                                        * image_row + image_col]; \n            float filter_value = c_filter[(filter_row \n                                          + filter_size / 2) \n                                          * filter_size \n                                          + filter_col \n                                          + filter_size / 2];\n\n            result += image_value * filter_value;\n        }\n    }\n```", "```cpp\n$ nvcc -run -m64 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -o convolution ./convolution.cu\n$ nvprof ./convolution\nProcessing Time (1) -> GPU: 0.48 ms\nProcessing Time (2) -> GPU: 0.43 ms\nProcessing Time (3) -> GPU: 0.30 ms\nProcessing Time -> Host: 4104.51 ms\n... (profiler output) ...\n              type Time(%)    Time Calls .    Avg      Min .    Max Name\n   GPU activities: 66.85% 2.3007ms     3 766.91us 1.1840us 2.2979ms [CUDA memcpy HtoD]\n                   12.85% 442.21us     1 442.21us 442.21us 442.21us convolution_kernel_v1()\n                   11.97% 412.00us     1 412.00us 412.00us 412.00us convolution_kernel_v2()\n                    8.33% 286.56us     1 286.56us 286.56us 286.56us convolution_kernel_v3()\n```", "```cpp\n__global__ void\nscan_v1_kernel(float *d_output, float *d_input, int length, int offset) {\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    float element = 0.f;\n    for (int offset = 0; offset < length; offset++) {\n        if (idx - offset >= 0)\n            element += d_input[idx - offset];\n    }\n    d_output[idx] = element;\n}\n```", "```cpp\n__global__ void scan_v2_kernel(float *d_output, float *d_input, int length)\n{\n    ...\n}\n```", "```cpp\nint idx = blockDim.x * blockIdx.x + threadIdx.x;\nint tid = threadIdx.x;\n```", "```cpp\nextern __shared__ float s_buffer[];\ns_buffer[threadIdx.x] = d_input[idx];\ns_buffer[threadIdx.x + BLOCK_DIM] = d_input[idx + BLOCK_DIM];\n```", "```cpp\nint offset = 1;\n```", "```cpp\nwhile (offset < length)\n{\n    __syncthreads();\n    int idx_a = offset * (2 * tid + 1) - 1;\n    int idx_b = offset * (2 * tid + 2) - 1;\n    if (idx_a >= 0 && idx_b < 2 * BLOCK_DIM) {\n        s_buffer[idx_b] += s_buffer[idx_a];\n    }\n    offset <<= 1;\n}\n```", "```cpp\noffset >>= 1;\nwhile (offset > 0) {\n    __syncthreads();\n    int idx_a = offset * (2 * tid + 2) - 1;\n    int idx_b = offset * (2 * tid + 3) - 1;\n    if (idx_a >= 0 && idx_b < 2 * BLOCK_DIM) {\n        s_buffer[idx_b] += s_buffer[idx_a];\n    }\n    offset >>= 1;\n}\n__syncthreads();\n```", "```cpp\nd_output[idx] = s_buffer[tid];\nd_output[idx + BLOCK_DIM] = s_buffer[tid + BLOCK_DIM];\n```", "```cpp\nvoid scan_v2(float *d_output, float *d_input, int length)\n{\n    dim3 dimBlock(BLOCK_DIM);\n    dim3 dimGrid(1);\n    scan_v2_kernel<<<dimGrid, dimBlock, \n                     sizeof(float) * BLOCK_DIM * 2>>>\n                  (d_output, d_input, length);\n    cudaDeviceSynchronize();\n}\n```", "```cpp\n$ nvcc -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -L/usr/local/cuda/lib -o scan ./scan.cu ./scan_v1.cu ./scan_v2.cu\n$ nvprof ./scan\n            Type Time(%)     Time Calls      Avg      Min      Max Name\n GPU activities:  68.96% 22.751us     1 22.751us 22.751us 22.751us scan_v1_kernel(float*, float*, int)\n 12.71% 4.1920us    1 4.1920us 4.1920us 4.1920us scan_v2_kernel(float*, float*, int)\n```", "```cpp\ninput         :: -0.4508 -0.0210 -0.4774  0.2750 ... 0.0398 0.4869\nresult[cpu]   :: -0.4508 -0.4718 -0.9492 -0.6742 ... 0.3091 0.7960\nresult[gpu_v1]:: -0.4508 -0.4718 -0.9492 -0.6742 ... 0.3091 0.7960\nSUCCESS!!\nresult[cpu]   :: -0.4508 -0.4718 -0.9492 -0.6742 ... 0.3091 0.7960\nresult[gpu_v2]:: -0.4508 -0.4718 -0.9492 -0.6742 ... 0.3091 0.7960\nSUCCESS!!\n```", "```cpp\n__global__ void\npredicate_kernel(float *d_predicates, float *d_input, int length)\n{\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (idx >= length) return;\n\n    d_predicates[idx] = d_input[idx] > FLT_ZERO;\n}\n```", "```cpp\n__global__ void\npack_kernel(float *d_output, float *d_input, float *d_predicates, float *d_scanned, int length)\n{\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (idx >= length) return;\n\n    if (d_predicates[idx] != 0.f)\n    {\n        // addressing\n        int address = d_scanned[idx] - 1;\n\n        // gather\n        d_output[address] = d_input[idx];\n    }\n}\n```", "```cpp\n// predicates\npredicate_kernel<<< GRID_DIM, BLOCK_DIM >>>(d_predicates, d_input, length);\n// scan\nscan_v2(d_scanned, d_predicates, length);\n// addressing & gather (pack)\npack_kernel<<< GRID_DIM, BLOCK_DIM >>>(d_output, d_input, d_predicates, d_scanned, length);\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -L/usr/local/cuda/lib -o pack_n_split ./pack_n_split.cu\ninput    :: -0.4508 -0.0210 -0.4774  0.2750 .... 0.0398  0.4869\npack[cpu]::  0.2750  0.3169  0.1248  0.4241 .... 0.3957  0.2958\npack[gpu]::  0.2750  0.3169  0.1248  0.4241 .... 0.3957  0.2958\nSUCCESS!!\n```", "```cpp\n__global__ void\nsplit_kernel(float *d_output, float *d_input, float *d_predicates, float *d_scanned, int length)\n{\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (idx >= length) return;\n\n    if (d_predicates[idx] != 0.f)\n    {\n        // address\n        int address = d_scanned[idx] - 1;\n\n        // split\n        d_output[idx] = d_input[address];\n    }\n}\n```", "```cpp\ncudaMemcpy(d_input, d_output, sizeof(float) * length, cudaMemcpyDeviceToDevice);\n    cudaMemset(d_output, 0, sizeof(float) * length);\n    split_kernel<<<GRID_DIM, BLOCK_DIM>>>(d_output, d_input, d_predicates, d_scanned, length);\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -L/usr/local/cuda/lib -o pack_n_split ./pack_n_split.cu\ninput    :: -0.4508 -0.0210 -0.4774  0.2750 .... 0.0398  0.4869\npack[cpu]::  0.2750  0.3169  0.1248  0.4241 .... 0.3957  0.2958\npack[gpu]::  0.2750  0.3169  0.1248  0.4241 .... 0.3957  0.2958\nSUCCESS!!\nsplit[gpu]   0.0000  0.0000  0.0000  0.2750 .... 0.0398  0.4869\nSUCCESS!!\n```", "```cpp\ndata[i] = 2.0f * (rand() / max) - 1.0f\n```", "```cpp\nfor (int tile = 0; tile < gridDim.x; tile++) {\n... \n__shared__ float3 shared_position[blockDim.x];\nfloat4 temp_position = p[tile * blockDim.x + threadIdx.x];\nshared_position[threadIdx.x] = make_float3(temp_position.x, temp_position.y, temp_position.z);\n__syncthreads();\n...\n}\n```", "```cpp\nfor (int j = 0; j < BLOCK_SIZE; j++) {\n    //Calculate Force\n    __syncthreads();\n}\n```", "```cpp\n$nvcc -run --gpu-architecture=sm_70 -o n-body n_body.cu \n```", "```cpp\n$ nvcc -c scrImagePgmPpmPackage.cpp \n$ nvcc -c image_histogram.cu\n$ nvcc -run -o image_histogram image_histogram.o scrImagePgmPpmPackage.o\n```", "```cpp\n__shared__ unsigned int histo_private[256];\n```", "```cpp\nif(localId <256)\n    histo_private[localId] = 0;\n```", "```cpp\n__syncthreads();\n```", "```cpp\nunsigned char imageData = tex2D<unsigned char>(texObj,(float)(tidX),(float)(tidY));\n```", "```cpp\natomicAdd(&(histo_private[imageData]), 1);\n```", "```cpp\n__syncthreads();\n```", "```cpp\nif(localId <256)\n    imageHistogram[histStartIndex+localId] = histo_private[localId];\n```", "```cpp\ncudaStream_t s;\ncudaStreamCreateWithFlags( &s, cudaStreamNonBlocking );\ncdp_simple_quicksort<<< 1, 1, 0, s >>>(data, left, nright, depth+1);\ncudaStreamDestroy( s );\n```", "```cpp\nint main(int argc, char **argv)\n{ ...\n    cdp_simple_quicksort<<< 1, 1 >>>(data, left, right, 0);\n}\n```", "```cpp\n__global__ void cdp_simple_quicksort( unsigned int *data, int left, int right, int depth )\n{ ...\n\nif( depth >= MAX_DEPTH || right-left <= INSERTION_SORT )\n {\n     selection_sort( data, left, right );\n     return;\n }\n```", "```cpp\n__global__ void cdp_simple_quicksort( unsigned int *data, int left, int right, int depth ) {\n...\nwhile(lptr <= rptr)\n {\n     // Move the left pointer as long as the \n     // pointed element is smaller than the pivot.\n     // Move the right pointer as long as the \n     // pointed element is larger than the pivot.\n     // If the swap points are valid, do the swap!\n\n     // Launch a new block to sort the left part.\n     if(left < (rptr-data))\n     { // Create a new stream for the eft sub array\n        cdp_simple_quicksort<<< 1, 1, 0, s \n                            >>>(data, left, nright, depth+1);\n     }\n    // Launch a new block to sort the right part.\n    if((lptr-data) < right)\n     {//Create stream for the right sub array\n         cdp_simple_quicksort<<< 1, 1, 0, s1 \n                             >>>(data, nleft, right, depth+1);\n     }\n }\n```", "```cpp\n$nvcc -o quick_sort --gpu-architecture=sm_70 -rdc=true quick_sort.cu \n```", "```cpp\n$ nvcc -run -o radix_warp_sort radix_warp_sort.cu\n```", "```cpp\n$ nvcc -run -o radix_thrust_sort thrust_radix_sort.cu \n```", "```cpp\n__shared__ unsigned int s_data[WARP_SIZE*2];\n```", "```cpp\nfor (int i = MIN_BIT_POS; i <= MAX_BIT_POS; i++){ ... }\n```", "```cpp\nunsigned int bit  = data&bit_mask;\n```", "```cpp\nunsigned int active = __activemask();\nunsigned int ones = __ballot_sync(active,bit);\nunsigned int zeroes = ~ones;\n```", "```cpp\nif (!bit) // threads with a zero bit\n // get my position in ping-pong buffer\n pos = __popc(zeroes&thread_mask);\n else // threads with a one bit\n // get my position in ping-pong buffer\n pos = __popc(zeroes)+__popc(ones&thread_mask);\n```", "```cpp\n s_data[pos-1+offset] = data;\n```", "```cpp\nd_data[threadIdx.x] = s_data[threadIdx.x+offset];\n```", "```cpp\n#include <thrust/device_vector.h>\n#include <thrust/sort.h>\n```", "```cpp\n//declare a device vector of size N\nthrust::device_vector<int> keys(N);\n//Generate a random number generator engine\nthrust::default_random_engine r(12);\n//create a distribution engine which will create integer values\nthrust::uniform_int_distribution<int> d(10, 99);\n//Fill the array with randon values\nfor(size_t i = 0; i < v.size(); i++)\n    v[i] = d(r);\n```", "```cpp\nthrust::sort(keys.begin(), keys.end());\n```"]