- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Parallel Programming Paradigms
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行编程范式
- en: Before we dive into **parallel programming** using C++, throughout the first
    two chapters, we will focus on acquiring some foundational knowledge about the
    different approaches to building parallel software and how the software interacts
    with the machine hardware.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入使用C++进行**并行编程**之前，在前两章中，我们将专注于获取有关构建并行软件的不同方法以及软件如何与机器硬件交互的基础知识。
- en: In this chapter, we will introduce parallel programming and the different paradigms
    and models that we can use when developing efficient, responsive, and scalable
    concurrent and asynchronous software.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍并行编程以及我们在开发高效、响应和可扩展的并发和异步软件时可以使用的不同范式和模型。
- en: 'There are many ways to group concepts and methods when classifying the different
    approaches we can take to develop parallel software. As we are focusing on software
    built with C++ in this book, we can divide the different parallel programming
    paradigms as follows: concurrency, asynchronous programming, parallel programming,
    reactive programming, dataflows, multithreading programming, and event-driven
    programming.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在对我们可以采取的不同方法进行分类时，有许多方法可以分组概念和方法。由于我们在这本书中关注使用C++构建的软件，我们可以将不同的并行编程范式分为以下几类：并发、异步编程、并行编程、响应式编程、数据流、多线程编程和事件驱动编程。
- en: Depending on the problem at hand, a specific paradigm could be more suitable
    than others to solve a given scenario. Understanding the different paradigms will
    help us to analyze the problem and narrow down the best solution possible.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 根据手头的问题，一个特定的范式可能比其他范式更适合解决特定场景。了解不同的范式将帮助我们分析问题并缩小最佳解决方案的范围。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: What is parallel programming and why does it matter?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是并行编程，为什么它很重要？
- en: What are the different parallel programming paradigms and why do we need to
    understand them?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的并行编程范式有哪些，为什么我们需要了解它们？
- en: What will you learn in this book?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这本书中你将学到什么？
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: No technical requirements apply for this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有技术要求。
- en: Throughout the book, we will develop different solutions using C++20 and, in
    some examples, C++23. Therefore, we will need to install GCC 14 and Clang 8.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将使用C++20开发不同的解决方案，在某些示例中，我们将使用C++23。因此，我们需要安装GCC 14和Clang 8。
- en: 'All the code blocks shown in this book can be found in the following GitHub
    repository: [https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)
    .'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本书展示的所有代码块都可以在以下GitHub仓库中找到：[https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP](https://github.com/PacktPublishing/Asynchronous-Programming-with-CPP)。
- en: Getting to know classifications, techniques, and models
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解分类、技术和模型
- en: Parallel computing occurs when tasks or computations are done simultaneously,
    with a task being a unit of execution or unit of work in a software application.
    As there are many ways to achieve parallelism, understanding the different approaches
    will be helpful to write efficient parallel algorithms. These approaches are described
    via paradigms and models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当任务或计算同时进行时，发生并行计算，其中任务是一个软件应用程序中的执行单元或工作单元。由于有许多实现并行化的方法，了解不同的方法将有助于编写高效的并行算法。这些方法通过范式和模型进行描述。
- en: But first, let us start by classifying the different parallel computing systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们从分类不同的并行计算系统开始。
- en: Systems classification and techniques
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统分类和技术
- en: 'One of the earliest classifications of parallel computing systems was made
    by Michael J. Flynn in 1966. Flynn’s taxonomy defines the following classification
    based on the **data streams** and number of instructions a parallel computing
    architecture can handle:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 1966年，迈克尔·J·弗林对并行计算系统进行了最早的分类。弗林的分类法根据并行计算架构可以处理的数据流和指令数量定义了以下分类：
- en: '**Single-instruction-single-data (SISD) systems** : Define a sequential program'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单指令单数据（SISD）系统**：定义一个顺序程序'
- en: '**Single-instruction-multiple-data (SIMD) systems** : Where operations are
    done over a large dataset, for example in signal processing of GPU computing'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单指令多数据（SIMD）系统**：在大型数据集上执行操作，例如在信号处理或GPU计算中'
- en: '**Multiple-instructions-single-data (MISD) systems** : Rarely used'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多指令单数据（MISD）系统**：很少使用'
- en: '**Multiple-instructions-multiple-data (MIMD) systems** : The most common parallel
    architectures based in multicore and multi-processor computers'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多指令多数据 (MIMD) 系统**：基于多核和多处理器计算机的最常见的并行架构'
- en: '![Figure 1.1: Flynn’s taxonomy](img/B22219_01_1.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1：弗林分类法](img/B22219_01_1.jpg)'
- en: 'Figure 1.1: Flynn’s taxonomy'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：弗林分类法
- en: This book is not only about building software with C++ but also about keeping
    an eye on how it interacts with the underlying hardware. A more interesting division
    or taxonomy can probably be done at the software level, where we can define the
    techniques. We will learn about these in the subsequent sections.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书不仅关于用 C++ 构建软件，还关注它如何与底层硬件交互。在软件层面可能进行更有趣的划分或分类，在那里我们可以定义技术。我们将在后续章节中学习这些内容。
- en: Data parallelism
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据并行
- en: Many different data units are processed in parallel by the same program or sequence
    of instructions running in different processing units such as CPU or GPU cores.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 许多不同的数据单元由同一程序或指令序列在 CPU 或 GPU 核心等不同的处理单元中并行处理。
- en: '**Data parallelism** is achieved by how many disjoint datasets can be processed
    at the same time by the same operations. Large datasets can be divided into smaller
    and independent data chunks exploiting parallelism.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据并行**是通过同一操作可以同时处理多少个不相交的数据集来实现的。大型数据集可以通过并行性被分割成更小且独立的块。'
- en: This technique is also highly scalable, as adding more processing units allows
    for the processing of a higher volume of data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术也具有高度的可扩展性，因为增加更多的处理单元可以处理更大的数据量。
- en: In this subset, we can include SIMD instruction sets such as SSE, AVX, VMX,
    or NEON, which are accessible via intrinsic functions in C++. Also, libraries
    such as OpenMP and CUDA for NVIDIA GPUs. Some examples of its usage can be found
    in machine learning training and image processing. This technique is related to
    the SIMD taxonomy defined by Flynn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个子集中，我们可以包括如 SSE、AVX、VMX 或 NEON 这样的 SIMD 指令集，这些指令集可以通过 C++ 的内建函数访问。还包括如 OpenMP
    和 CUDA 这样的库，用于 NVIDIA GPU。一些使用示例可以在机器学习训练和图像处理中找到。这种技术与弗林定义的 SIMD 分类法相关。
- en: As usual, there are also some drawbacks. Data must be easily divisible into
    independent chunks. This data division and posterior merging also introduces some
    overhead that can reduce the benefits of parallelization.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，也有一些缺点。数据必须容易分割成独立的块。这种数据分割和后续合并也引入了一些开销，可能会降低并行化的好处。
- en: Task parallelism
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务并行
- en: In computers where each CPU core runs different tasks using processes or threads,
    **task parallelism** can be achieved when these tasks simultaneously receive data,
    process it, and send back the results that they generate via message passing.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 CPU 核心使用进程或线程运行不同任务的计算机中，当这些任务同时接收数据、处理数据并将通过消息传递生成的结果发送回来时，可以实现**任务并行**。
- en: The advantage of task parallelism resides in the ability to design heterogeneous
    and granular tasks that can make better usage of processing resources, being more
    flexible when designing a solution with potentially higher speed-up.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 任务并行的优势在于能够设计出异构和细粒度的任务，这样可以更好地利用处理资源，在设计和解决方案时更加灵活，可能实现更高的加速比。
- en: Due to the possible dependencies between tasks that can be created by the data,
    as well as the different nature of each task, scheduling and coordination are
    more complex than with data parallelism. Also, task creation adds some processing
    overhead.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据可能产生的任务之间的依赖性，以及每个任务的不同性质，调度和协调比数据并行更复杂。此外，任务创建还会增加一些处理开销。
- en: Here we can include Flynn’s MISD and MIMD taxonomies. Some examples can be found
    in a web server request processing system or a user interface events handler.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以包括弗林的 MISD 和 MIMD 分类法。一些示例可以在网络服务器请求处理系统或用户界面事件处理器中找到。
- en: Stream parallelism
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流并行
- en: A continuous sequence of data elements, also known as a **data stream** , can
    be processed concurrently by dividing the computation into various stages processing
    a subset of the data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将计算分割成处理数据子集的各个阶段，可以并行处理数据元素连续序列，也称为**数据流**。
- en: Stages can run concurrently. Some generate the input of other stages, building
    a **pipeline** from stage dependencies. A processing stage can send results to
    the next stage without waiting to receive the entire stream data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段可以并行运行。一些阶段生成其他阶段所需的输入，通过阶段依赖关系构建**管道**。处理阶段可以在不等待接收整个数据流的情况下，将结果发送到下一阶段。
- en: Stream parallel techniques are effective when handling continuous data. They
    are also highly scalable, as they can be scaled by adding more processing units
    to handle the extra input data. Since the stream data is processed as it arrives,
    this means not needing to wait for the entire data stream to be sent, which means
    that memory usage is also reduced.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 流并行技术在处理连续数据时非常有效。它们也非常可扩展，因为可以通过添加更多处理单元来扩展，以处理额外的输入数据。由于流数据在到达时即被处理，这意味着不需要等待整个数据流发送完毕，这也意味着内存使用也得到了减少。
- en: However, as usual, there are some drawbacks. These systems are more complex
    to implement due to their processing logic, error handling, and recovery. As we
    might also need to process the data stream in real time, the hardware could be
    a limitation as well.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，像往常一样，也有一些缺点。由于它们的处理逻辑、错误处理和恢复，这些系统更难实现。我们可能还需要实时处理数据流，因此硬件也可能成为限制因素。
- en: Some examples of these systems include monitoring systems, sensor data processing,
    and audio and video streaming.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统的例子包括监控系统、传感器数据处理以及音频和视频流。
- en: Implicit parallelism
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐式并行性
- en: In this case, the compiler, the runtime, or the hardware takes care of parallelizing
    the execution of the instructions transparently for the programmer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，编译器、运行时或硬件负责为程序员透明地并行化指令的执行。
- en: This makes it easier to write parallel programs but limits the programmer’s
    control over the strategies used, or even makes it more difficult to analyze performance
    or debugging.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得编写并行程序变得更容易，但限制了程序员对所使用策略的控制，甚至使得分析性能或调试变得更加困难。
- en: Now that we have a better understanding of the different parallel systems and
    techniques, it’s time to learn about the different models we can use when designing
    a parallel program.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经更好地理解了不同的并行系统和技术，是时候学习在设计并行程序时可以使用的不同模型了。
- en: Parallel programming models
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行编程模型
- en: A **parallel programming model** is a parallel computer’s architecture used
    to express algorithms and build programs. The more generic the model the more
    valuable it becomes, as it can be used in a broader range of scenarios. In that
    sense, C++ implements a parallel model through a library within the **Standard
    Template Library** ( **STL** ), which can be used to achieve parallel execution
    of programs from sequential applications.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行编程模型**是用于表达算法和构建程序的并行计算机架构。模型越通用，其价值就越大，因为它可以在更广泛的场景中使用。在这方面，C++通过**标准模板库**（**STL**）中的库实现并行模型，可以用于从顺序应用程序中实现程序的并行执行。'
- en: These models describe how the different tasks interact during the program’s
    lifetime to achieve a result from input data. Their main differences are related
    to how the tasks interact with each other and how they process the incoming data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型描述了在程序的生命周期中，不同的任务如何相互作用以从输入数据中获得结果。它们的主要区别在于任务如何相互交互以及它们如何处理传入的数据。
- en: Phase parallel
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阶段并行
- en: In **phase parallel** , also known as the agenda or loosely synchronous paradigm,
    multiple jobs or tasks perform independent computations in parallel. At some point,
    the program needs to perform a synchronous interaction operation using a barrier
    to synchronize the different processes. A barrier is a synchronization mechanism
    that ensures that a group of tasks reach a particular point in their execution
    before any of them can proceed further. The next steps execute other asynchronous
    operations, and so on.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在**阶段并行**，也称为议程或松散同步范式，多个作业或任务并行执行独立的计算。在某个时刻，程序需要使用屏障执行同步交互操作，以同步不同的进程。屏障是一种同步机制，确保在任一任务进一步执行之前，所有任务都达到它们执行中的特定点。接下来的步骤执行其他异步操作，依此类推。
- en: '![Figure 1.2: Phase parallel model](img/B22219_01_2.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：阶段并行模型](img/B22219_01_2.jpg)'
- en: 'Figure 1.2: Phase parallel model'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：阶段并行模型
- en: The advantage of this model is that the interaction between tasks does not overlap
    with computation. On the other hand, it is difficult to reach a balanced workload
    and throughput among all processing units.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型的优势在于任务之间的交互不会与计算重叠。另一方面，很难在所有处理单元之间达到平衡的工作负载和吞吐量。
- en: Divide and conquer
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分而治之
- en: The application using this model uses a main task or job that divides the workload
    among its children, assigning them to smaller tasks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此模型的应用程序使用一个主要任务或作业，将工作负载分配给其子任务，将它们分配给更小的任务。
- en: Child tasks compute the results in parallel and return them to the parent task,
    where the partial results are merged into the final one. Child tasks can also
    subdivide the assigned task into even smaller ones and create their own child
    tasks.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 子任务并行计算结果并将其返回给父任务，在那里部分结果合并成最终结果。子任务还可以将分配的任务进一步细分，并创建自己的子任务。
- en: This model has the same disadvantage as the phase parallel model; it is difficult
    to achieve a good load balance.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型与相位并行模型具有相同的缺点；难以实现良好的负载均衡。
- en: '![Figure 1.3: Divide and conquer model](img/B22219_01_3.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3：分而治之模型](img/B22219_01_3.jpg)'
- en: 'Figure 1.3: Divide and conquer model'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：分而治之模型
- en: In *Figure 1* *.3* , we can see how the main job divides the work among several
    child tasks, and how **Child Task 2** , in turn, subdivides its assigned work
    into two additional tasks.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图1.3*中，我们可以看到主工作如何将工作分配给几个子任务，以及**子任务2**如何将其分配的工作进一步细分为两个额外的任务。
- en: Pipeline
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流水线
- en: Several tasks are interconnected, building a virtual pipeline. In this pipeline,
    the various stages can run simultaneously, overlapping their execution when fed
    with data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 几个任务相互连接，构建一个虚拟流水线。在这个流水线中，各个阶段可以同时运行，在提供数据时重叠执行。
- en: '![Figure 1.4: Pipeline model](img/B22219_01_4.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4：流水线模型](img/B22219_01_4.jpg)'
- en: 'Figure 1.4: Pipeline model'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：流水线模型
- en: In the preceding figure, three tasks interact in a pipeline composed of five
    stages. In each stage, some tasks are running, generating output results that
    are used by other tasks in the next stages.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，三个任务在由五个阶段组成的流水线中交互。在每个阶段，一些任务正在运行，生成输出结果，这些结果被下一阶段的其他任务使用。
- en: Master-slave
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主从
- en: Using the **master-slave model** , also known as **process farm** , a master
    job executes the sequential part of the algorithm and spawns and coordinates slave
    tasks that execute parallel operations in the workload. When a slave task finishes
    its computation, it informs the master job of the result, which might then send
    more data to the slave task to be processed.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**主从模型**，也称为**进程农场**，主工作执行算法的顺序部分，并产生和协调执行工作负载中的并行操作的从任务。当从任务完成其计算时，它会向主工作报告结果，主工作可能会随后发送更多数据给从任务进行处理。
- en: '![Figure 1.5: The master-slave model](img/B22219_01_5.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5：主从模型](img/B22219_01_5.jpg)'
- en: 'Figure 1.5: The master-slave model'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：主从模型
- en: The main disadvantage is that the master can become a bottleneck if it needs
    to deal with too many slaves or when tasks are too small. There is a tradeoff
    when selecting the amount of work to be performed by each task, also known as
    **granularity** . When tasks are small, they are named fine-grained, and when
    they are large, they are coarse-grained.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 主要缺点是，如果主工作需要处理太多的从任务或任务太小，它可能会成为瓶颈。在确定每个任务要执行的工作量时存在权衡，这被称为**粒度**。当任务较小时，它们被称为细粒度，当任务较大时，它们被称为粗粒度。
- en: Work pool
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作池
- en: In the work pool model, a global structure holds a pool of work items to do.
    Then, the main program creates jobs that fetch pieces of work from the pool to
    execute them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作池模型中，一个全局结构持有待完成的工作项池。然后，主程序创建工作，从池中获取工作片段以执行。
- en: These jobs can generate more work units that are inserted into the work pool.
    The parallel program finishes its execution when all work units are completed
    and the pool is thus empty.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工作可以生成更多的工作单元，并将它们插入工作池。当所有工作单元都完成且池为空时，并行程序完成其执行。
- en: '![Figure 1.6: The work pool model](img/B22219_01_6.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6：工作池模型](img/B22219_01_6.jpg)'
- en: 'Figure 1.6: The work pool model'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：工作池模型
- en: This mechanism facilitates load balancing among free processing units.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 该机制有助于在空闲处理单元之间实现负载均衡。
- en: In C++, this pool is usually implemented by using an unordered set, a queue,
    or a priority queue. We will implement some examples in this book.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中，这个池通常通过使用无序集合、队列或优先队列来实现。我们将在本书中实现一些示例。
- en: Now that we have learned about a variety of models that we can use to build
    a parallel system, let’s explore the different parallel programming paradigms
    available to develop software that efficiently runs tasks in parallel.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了可以用来构建并行系统的各种模型，让我们探索可用的不同并行编程范式，以开发能够高效并行运行任务的软件。
- en: Understanding various parallel programming paradigms
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解各种并行编程范式
- en: Now that we have explored some of the different models used for building parallel
    programs, it is time to move to a more abstract classification and learn about
    the fundamental styles or principles of how to code parallel programs by exploring
    the different parallel programming language paradigms.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了构建并行程序所使用的不同模型，是时候转向更抽象的分类，并通过探索不同的并行编程语言范式来了解如何编写并行程序的基本风格或原则。
- en: Synchronous programming
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步编程
- en: A **synchronous programming** language is used to build programs where code
    is executed in a strict sequential order. While one instruction is being executed,
    the program remains blocked until the instruction finishes. In other words, there
    is no multitasking. This makes the code easier to understand and debug.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**同步编程**语言用于构建代码以严格顺序执行的程序。当一条指令正在执行时，程序会保持阻塞，直到指令完成。换句话说，没有多任务处理。这使得代码更容易理解和调试。'
- en: However, this behavior makes the program unresponsive to external events while
    it is blocked while running an instruction and difficult to scale.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种行为使得程序在执行指令时对外部事件无响应，并且难以扩展。
- en: This is the traditional paradigm used by most programming languages such as
    C, Python, or Java.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最多编程语言（如C、Python或Java）使用的传统范式。
- en: This paradigm is especially useful for reactive or embedded systems that need
    to respond in real time and in an ordered way to input events. The processing
    speed must match the one imposed by the environment with strict time bounds.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式特别适用于需要实时且有序响应输入事件的反应式或嵌入式系统。处理速度必须与环境施加的严格时间限制相匹配。
- en: '![Figure 1.7: Asynchronous versus synchronous execution time](img/B22219_01_7.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7：异步与同步执行时间](img/B22219_01_7.jpg)'
- en: 'Figure 1.7: Asynchronous versus synchronous execution time'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：异步与同步执行时间
- en: '*Figure 1* *.7* shows two tasks running in a system. In the synchronous system,
    task A is interrupted by task B and only resumes its execution once task B has
    finished its work. In the asynchronous system, tasks A and B can run simultaneously,
    thus completing both of their work in less time.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.7* 显示了系统中运行的两个任务。在同步系统中，任务A被任务B中断，只有在任务B完成其工作后才会继续执行。在异步系统中，任务A和B可以同时运行，因此可以在更短的时间内完成它们的工作。'
- en: Concurrency programming
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发编程
- en: With **concurrency programming** , more than one task can run at the same time.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在**并发编程**中，可以同时运行多个任务。
- en: Tasks can run independently without waiting for other tasks’ instructions to
    finish. They can also share resources and communicate with each other. Their instructions
    can run asynchronously, meaning that they can be executed in any order without
    affecting the outcome, adding the potential for parallel processing. On the other
    hand, that makes this kind of program more difficult to understand and debug.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以独立运行，无需等待其他任务完成指令。它们还可以共享资源并相互通信。它们的指令可以异步运行，这意味着它们可以按任何顺序执行而不影响结果，增加了并行处理的可能性。另一方面，这也使得这类程序更难以理解和调试。
- en: Concurrency increases the program throughput, as the number of tasks completed
    in a time interval increases with concurrency (see the formula for Gustafson’s
    law in the section *Exploring the metrics to assess parallelism* at the end of
    this chapter). Also, it achieves better input and output responsiveness, as the
    program can perform other tasks during waiting periods.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 并发提高了程序的吞吐量，因为随着并发的增加，在时间间隔内完成的任务数量也增加（参见本章末尾“探索评估并行性的指标”部分中Gustafson定律的公式）。此外，它还实现了更好的输入和输出响应性，因为程序可以在等待期间执行其他任务。
- en: The main problem in concurrent software is achieving correct concurrency control.
    Exceptional care must be taken when coordinating access to shared resources and
    ensuring that the correct sequence of interactions is taking place between the
    different computational executions. Incorrect decisions can lead to race conditions,
    deadlocks, or resource starvation, which are explained in depth in [*Chapter 3*](B22219_03.xhtml#_idTextAnchor051)
    and [*Chapter 4*](B22219_04.xhtml#_idTextAnchor074) . Most of these issues are
    solved by following a consistency or memory model, which defines rules on how
    and in which order operations should be performed when accessing the shared memory.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 并发软件中的主要问题是在正确地实现并发控制。在协调对共享资源的访问并确保不同计算执行之间发生正确的交互顺序时必须格外小心。错误的决定可能导致竞争条件、死锁或资源饥饿，这些内容在[*第3章*](B22219_03.xhtml#_idTextAnchor051)和[*第4章*](B22219_04.xhtml#_idTextAnchor074)中进行了深入解释。大多数这些问题通过遵循一致性或内存模型来解决，该模型定义了在访问共享内存时操作应该如何以及按何种顺序执行。
- en: Designing efficient concurrent algorithms is done by finding techniques to coordinate
    tasks’ execution, data exchange, memory allocations, and scheduling to minimize
    the response time and maximize throughput.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 设计高效的并发算法是通过找到协调任务执行、数据交换、内存分配和调度的技术，以最小化响应时间并最大化吞吐量。
- en: The first academic paper introducing concurrency, *Solution of a Problem in
    Concurrent Programming Control* , was published by Dijkstra in 1965. Mutual exclusion
    was also identified and solved there.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍并发的第一篇学术论文《解决并发程序控制问题》由迪杰斯特拉于1965年发表。互斥性也在此处被识别并解决。
- en: Concurrency can happen at the operating system level in a preemptive way, whereby
    the scheduler switches contexts (switching from one task to another) without interacting
    with the tasks. It can also happen in a non-preemptive or cooperative way, whereby
    the task yields control to the scheduler, which chooses another task to continue
    work.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 并发可以在操作系统级别以抢占式的方式发生，其中调度器切换上下文（从一个任务切换到另一个任务）而不与任务交互。它也可以以非抢占式或协作式的方式发生，其中任务将控制权交给调度器，调度器选择另一个任务继续工作。
- en: The scheduler interrupts the running program by saving its state (memory and
    register contents), then loading the saved state of a resumed program and transferring
    control to it. This is called **context switching** . Depending on the priority
    of a task, the scheduler might allow a high-priority task to use more CPU time
    than a low-priority one.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器通过保存运行程序的状态（内存和寄存器内容）来中断正在运行的程序，然后加载已恢复程序保存的状态并将控制权转交给它。这被称为**上下文切换**。根据任务的优先级，调度器可能允许高优先级任务比低优先级任务使用更多的CPU时间。
- en: Also, some special operating software such as memory protection might use special
    hardware to keep supervisory software undamaged by user-mode program errors.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些特殊的操作系统软件，如内存保护，可能使用特殊的硬件来防止用户模式程序错误损坏监督软件。
- en: This mechanism is not only used in single-core computers but also in multicore
    ones, allowing many more tasks to be executed than the number of available cores.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这种机制不仅用于单核计算机，也用于多核计算机，允许执行比可用核心数更多的任务。
- en: '**Preemptive multitasking** also allows important tasks to be scheduled earlier
    to deal with important external events quickly. These tasks wake up and deal with
    the important work when the operating system sends them a signal that triggers
    an interruption.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**抢占式多任务处理**还允许将重要任务提前调度以快速处理重要外部事件。当操作系统向这些任务发送触发中断的信号时，这些任务会唤醒并处理重要工作。'
- en: Older versions of Mac and Windows operating systems used **non-preemptive multitasking**
    . This is still used today on the RISC operating system. Unix systems started
    to use preemptive multitasking in 1969, being a core feature of all Unix-like
    systems and modern Windows versions from Windows NT **3.1** and Windows 95 onward.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的Mac和Windows操作系统使用**非抢占式多任务处理**。这种技术至今仍在RISC操作系统上使用。Unix系统从1969年开始使用抢占式多任务处理，成为所有Unix-like系统和从Windows
    NT **3.1**和Windows 95开始的现代Windows版本的核心功能。
- en: Early-days CPUs could only run one path of instructions at a given time. Parallelism
    was achieved by switching between instruction streams, giving the illusion of
    parallelism at the software level by seemingly overlapping in execution.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的CPU只能同时运行一条指令路径。通过在指令流之间切换，通过看似重叠的执行来在软件级别产生并行性的错觉，从而实现了并行性。
- en: However, in 2005, Intel® introduced multicore processors, which allowed several
    instruction streams to execute at once at the hardware level. This imposed some
    challenges at the time of writing software, as hardware-level concurrency now
    needed to be addressed and exploited.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 2005 年，英特尔® 推出了多核处理器，这使得在硬件级别上可以同时执行多个指令流。这给编写软件时带来了一些挑战，因为硬件级别的并发现在需要被处理和利用。
- en: C++ has supported concurrent programming since C++11 with the **std::thread**
    library. Earlier versions did not include any specific functionality, so programmers
    relied on platform-specific libraries based on the POSIX threading model in Unix
    systems or on proprietary Microsoft libraries in Windows systems.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: C++ 从 C++11 开始支持并发编程，通过 **std::thread** 库。早期版本没有包括任何特定功能，因此程序员依赖于基于 Unix 系统中
    POSIX 线程模型的平台特定库，或在 Windows 系统上依赖于专有的微软库。
- en: Now that we better understand what concurrency is, we need to distinguish between
    concurrency and parallelism. Concurrency happens when many execution paths can
    run in overlapping time periods with interleaved execution, while parallelism
    happens when these tasks are executed at the same time by different CPU units,
    exploiting available multicore resources.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们更好地理解了并发是什么，我们需要区分并发和并行。并发发生在许多执行路径可以在重叠的时间段内交错执行时，而并行发生在这些任务由不同的 CPU 单元同时执行时，利用可用的多核资源。
- en: '![Figure 1.8: Concurrency versus parallelism](img/B22219_01_8.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8：并发与并行](img/B22219_01_8.jpg)'
- en: 'Figure 1.8: Concurrency versus parallelism'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8：并发与并行
- en: Concurrent programming is considered more general than parallel programming
    as the latter has a predefined communication pattern while the former can involve
    arbitrary and dynamic patterns of communication and interaction between tasks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程被认为比并行编程更通用，因为后者有一个预定义的通信模式，而前者可以涉及任务之间任意和动态的通信和交互模式。
- en: Parallelism can exist without concurrency (without interleaved time periods)
    and concurrency without parallelism (by multitasking by time-sharing on a single-core
    CPU).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 并行可以存在于没有并发（没有交错的时间段）的情况下，也可以在没有并行的情况下存在（通过在单核 CPU 上通过时间共享进行多任务处理）。
- en: Asynchronous programming
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步编程
- en: Asynchronous programming allows some tasks to be scheduled and run in the background
    while continuing to work on the current job without waiting for the scheduled
    tasks to finish. When these tasks are finished, they will report their results
    back to the main job or scheduler.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 异步编程允许一些任务在后台调度和运行，同时继续当前工作，无需等待计划中的任务完成。当这些任务完成后，它们将结果返回给主任务或调度器。
- en: One of the key issues of synchronous applications is that a long operation can
    leave the program unresponsive to further input or processing. Asynchronous programs
    solve this issue by accepting new input while some operations are being executed
    with non-blocking tasks and the system can do more than one task at a time. This
    also allows for better resource utilization.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 同步应用程序的一个关键问题是长时间操作可能会使程序对进一步的输入或处理无响应。异步程序通过接受新的输入来解决此问题，同时一些操作正在通过非阻塞任务执行，系统可以同时执行多个任务。这也允许更好的资源利用。
- en: As the tasks are executed asynchronously and they report results back when they
    finish, this paradigm is especially suitable for event-driven programs. Also,
    it is a paradigm usually used for user interfaces, web servers, network communications,
    or long-running background processing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任务异步执行并在完成时返回结果，这种范式特别适合事件驱动程序。此外，它通常用于用户界面、Web 服务器、网络通信或长时间运行的后台处理。
- en: As hardware has evolved toward multiple processing cores on a single processor
    chip, it has become mandatory to use asynchronous programming to take advantage
    of all the available compute power by running tasks in parallel across the different
    cores.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 随着硬件向单个处理器芯片上的多个处理核心发展，使用异步编程来利用所有可用的计算能力，通过在不同核心上并行运行任务，已经成为强制性的要求。
- en: However, asynchronous programming has its challenges, as we will explore in
    this book. For example, it adds complexity, as the code is not interpreted in
    sequence. This can lead to race conditions. Also, error handling and testing are
    essential to ensure program stability and prevent issues.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，异步编程有其挑战，正如我们将在本书中探讨的那样。例如，它增加了复杂性，因为代码不是按顺序解释的。这可能导致竞争条件。此外，错误处理和测试对于确保程序稳定性和防止问题至关重要。
- en: As we will learn in this book, modern C++ also provides asynchronous mechanisms
    such as coroutines, which are programs that can be suspended and resumed later,
    or futures and promises as a proxy for unknown results in asynchronous programs
    for synchronizing the program execution.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在本书中学到的，现代C++还提供了异步机制，如协程，这些是可以在稍后挂起和恢复的程序，或者将`future`和`promise`作为异步程序中未知结果的代理，以同步程序执行。
- en: Parallel programming
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行编程
- en: With parallel programming, multiple computation tasks can be done simultaneously
    on multiple processing units, either with all of them in the same computer (multicore)
    or on multiple computers (cluster).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用并行编程，可以在多个处理单元上同时执行多个计算任务，这些处理单元可以是同一台计算机上的所有处理单元（多核）或多台计算机（集群）。
- en: 'There are two main approaches:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有两种方法：
- en: '**Shared-memory parallelism** : Tasks can communicate via shared memory, a
    memory space accessible by all processors'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享内存并行性**：任务可以通过共享内存进行通信，这是一个所有处理器都可以访问的内存空间。'
- en: '**Message-passing parallelism** : Each task has its own memory space and uses
    message passing techniques to communicate with others'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消息传递并行性**：每个任务都有自己的内存空间，并使用消息传递技术与其他任务通信。'
- en: As with the previous paradigms, to achieve full potential and avoid bugs or
    issues, parallel computing needs synchronization mechanisms to avoid tasks interfering
    with each other. It also calls for load balancing the workload to reach its full
    potential, as well as reducing overhead when creating and managing tasks. These
    needs increase design, implementation, and debugging complexity.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前的范式一样，为了充分发挥潜力并避免错误或问题，并行计算需要同步机制来避免任务相互干扰。它还要求平衡负载以达到其全部潜力，以及在创建和管理任务时减少开销。这些需求增加了设计、实现和调试的复杂性。
- en: Multithreading programming
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多线程编程
- en: Multithreading programming is a subset of parallel programming wherein a program
    is divided into multiple threads executing independent units within the same process.
    The process, memory space, and resources are shared between threads.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程编程是并行编程的一个子集，其中程序被划分为多个线程，这些线程在同一个进程中执行独立的单元。线程之间共享进程、内存空间和资源。
- en: As we already mentioned, sharing memory needs synchronization mechanisms. On
    the other hand, as there is no need for inter-process communication, resource
    sharing is simplified.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，共享内存需要同步机制。另一方面，由于不需要进程间通信，资源共享简化了。
- en: For example, multithreading programming is usually used to achieve **graphical
    user interface** ( **GUI** ) responsiveness with fluid animations, in web servers
    to handle multiple clients’ requests, or in data processing.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，多线程编程通常用于实现**图形用户界面**（**GUI**）的响应性，流畅的动画，在Web服务器上处理多个客户端请求，或在数据处理中。
- en: Event-driven programming
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件驱动编程
- en: In event-driven programming, the control flow is driven by external events.
    The application detects events in real time and responds to these by invoking
    the appropriate event-handling method or callback.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件驱动编程中，控制流由外部事件驱动。应用程序实时检测事件，并通过调用适当的事件处理方法或回调来对这些事件做出响应。
- en: An event signals an action that needs to be taken. This event is listened to
    by the event loop that continuously listens for incoming events and dispatches
    them to the appropriate callback, which will execute the desired action. As the
    code is only executed when an action occurs, this paradigm improves efficiency
    with resource usage and scalability.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 事件表示需要采取行动的动作。这个事件由事件循环监听，它持续监听传入的事件并将它们调度到适当的回调，该回调将执行所需操作。由于代码仅在发生动作时执行，因此这种范式通过资源使用和可扩展性提高了效率。
- en: Event-driven programming is useful to act on actions happening in user interfaces,
    real-time applications, and network connection listeners.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动编程对于处理用户界面、实时应用程序和网络连接监听器中的动作非常有用。
- en: As with many of the other paradigms, the increased complexity, synchronization,
    and debugging make this paradigm complex to implement and apply.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 就像许多其他范式一样，增加的复杂性、同步和调试使得这种范式在实现和应用上变得复杂。
- en: As C++ is a low-level language, techniques such as callbacks or functors are
    used to write the event handlers.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于C++是一种底层语言，因此使用回调或函数对象等技术来编写事件处理程序。
- en: Reactive programming
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 响应式编程
- en: Reactive programming deals with data streams, which are continuous flows of
    data or values over time. A program is usually built using declarative or functional
    programming, defining a pipeline of operators and transformations applied to the
    stream. These operations happen asynchronously using schedulers and **backpressure**
    handling mechanisms.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 反应式编程处理数据流，这些是随时间连续的数据或值流。程序通常使用声明式或函数式编程构建，定义应用于流的操作符和转换的管道。这些操作通过调度器和**背压**处理机制异步发生。
- en: Backpressure happens when the quantity of data overwhelms the consumers and
    they are not able to process all of it. To avoid a system collapse, a reactive
    system needs to use backpressure strategies to prevent system failures.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据量超过消费者处理能力，他们无法处理所有数据时，就会发生背压现象。为了避免系统崩溃，反应式系统需要使用背压策略来防止系统故障。
- en: 'Some of these strategies include the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略包括以下内容：
- en: Controlling input throughput by requesting the publisher to reduce the rate
    of published events. This can be achieved by following a pull strategy, where
    the publisher sends events only when the consumer requests them, or by limiting
    the number of events sent, creating a limited and controlled push strategy.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过请求发布者降低发布事件的速度来控制输入吞吐量。这可以通过遵循拉取策略实现，即发布者仅在消费者请求时发送事件，或者通过限制发送的事件数量，创建一个有限且可控的推送策略。
- en: Buffering the extra data, which is especially useful when there are data bursts
    or a high-bandwidth transmission over a short period.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存额外的数据，这在数据突发或短时间内高带宽传输时特别有用。
- en: Dropping some events or delaying their publication until the consumers recover
    from the backpressure state.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过丢弃一些事件或延迟它们的发布，直到消费者从背压状态中恢复。
- en: Thus, reactive programs can be **pull-based** or **push-based** . Pull-based
    programs implement the classic case where the events are actively pulled from
    the data source. On the other hand, push-based programs push events through a
    signal network to reach the subscriber. Subscribers react to changes without blocking
    the program, making these systems ideal for rich user interface environments where
    responsiveness is crucial.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，反应式程序可以是**基于拉取**或**基于推送**的。基于拉取的程序实现了从数据源主动拉取事件的经典案例。另一方面，基于推送的程序通过信号网络推送事件以到达订阅者。订阅者对变化做出反应而不阻塞程序，这使得这些系统非常适合对响应性至关重要的丰富用户界面环境。
- en: 'Reactive programming is like an event-driven model where event streams from
    various sources can be transformed, filtered, processed, and so on. Both increase
    code modularity and are suitable for real-time applications. However, there are
    some differences, as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 反应式编程类似于事件驱动模型，其中来自各种来源的事件流可以进行转换、过滤、处理等。两者都增加了代码模块化，并适合实时应用。然而，也有一些不同之处，如下所示：
- en: Reactive programming reacts to event streams, while event-driven programming
    deals with discrete events.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反应式编程对事件流做出反应，而事件驱动编程处理离散事件。
- en: In event-driven programming, an event triggers a callback or event handlers.
    With reactive programming, a pipeline with different transformation operators
    can be created whereby the data stream will flow and modify the events.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件驱动编程中，事件触发回调或事件处理器。在反应式编程中，可以创建一个包含不同转换操作符的管道，其中数据流将流动并修改事件。
- en: Examples of systems and software using reactive programming include the X Windows
    system and libraries such as Qt, WxWidgets, and Gtk+. Reactive programming is
    also used in real-time sensors data processing and dashboards. Additionally, it
    is applied to handling network or file I/O traffic and data processing.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用反应式编程的系统软件的例子包括X窗口系统和Qt、WxWidgets、Gtk+等库。反应式编程也用于实时传感器数据处理和仪表板。此外，它还应用于处理网络或文件I/O流量和数据处理。
- en: To reach full potential, there are some challenges to address when using reactive
    programming. For example, it’s important to debug distributed dataflows and asynchronous
    processes or to optimize performance by fine-tuning the schedulers. Also, the
    use of declarative or functional programming makes developing software by using
    reactive programming techniques a bit more challenging to understand and learn.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用反应式编程时，要充分发挥其潜力，需要解决一些挑战。例如，调试分布式数据流和异步过程或通过微调调度器来优化性能是很重要的。此外，使用声明式或函数式编程使得通过反应式编程技术开发软件理解和学习起来更具挑战性。
- en: Dataflow programming
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据流编程
- en: With **dataflow programming** , a program is designed as a directed graph of
    nodes representing computation units and edges representing the flow of data.
    A node only executes when there is some available data. This paradigm was invented
    by Jack Dennis at MIT in the 1960s.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**数据流编程**，程序被设计为一个有向图，节点代表计算单元，边代表数据流。节点仅在有可用数据时执行。这种范式是在20世纪60年代由麻省理工学院的Jack
    Dennis发明的。
- en: Dataflow programming makes the code and design more readable and clearer, as
    it provides a visual representation of the different computation units and how
    they interact. Also, independent nodes can run in parallel with dataflow programming,
    increasing parallelism and throughput. So, it is like reactive programming but
    offers a graph-based approach and visual aid to modeling systems.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流编程使代码和设计更易于阅读和清晰，因为它提供了不同计算单元及其交互的视觉表示。此外，独立节点可以在数据流编程中并行运行，增加并行性和吞吐量。因此，它类似于响应式编程，但提供了一种基于图的方法和视觉辅助来建模系统。
- en: To implement a dataflow program, we can use a hash table. The key identifies
    a set of inputs and the value describes the task to run. When all inputs for a
    given key are available, the task associated with that key is executed, generating
    additional input values that may trigger tasks for other keys in the hash table.
    In these systems, the scheduler can find opportunities for parallelism by using
    a topological sort on the graph data structure, sorting the different tasks by
    their interdependencies.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现数据流程序，我们可以使用哈希表。键标识一组输入，值描述要运行的任务。当给定键的所有输入都可用时，与该键关联的任务将被执行，生成可能触发哈希表中其他键的任务的额外输入值。在这些系统中，调度器可以通过对图数据结构进行拓扑排序来找到并行机会，按任务之间的相互依赖关系对不同的任务进行排序。
- en: This paradigm is usually used for large-scale data processing pipelines for
    machine learning, real-time analysis from sensors or financial markets data, and
    audio, video, and image processing systems. Examples of software libraries using
    the dataflow paradigm are Apache Spark and TensorFlow. In hardware, we can find
    examples for digital signal processing, network routing, GPU architecture, telemetry,
    and artificial intelligence, among others.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式通常用于机器学习的大规模数据处理管道、来自传感器或金融市场数据的实时分析，以及音频、视频和图像处理系统。使用数据流范式的软件库示例包括Apache
    Spark和TensorFlow。在硬件方面，我们可以找到数字信号处理、网络路由、GPU架构、遥测和人工智能等方面的示例。
- en: A variant of dataflow programming is **incremental computing** , whereby only
    the outputs that depend on changed input data are recomputed. This is like recomputing
    affected cells in an Excel spreadsheet when a cell value changes.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流编程的一种变体是**增量计算**，其中只有依赖于变化输入数据的输出被重新计算。这就像在Excel电子表格中某个单元格值改变时重新计算受影响的单元格一样。
- en: Now that we have learned about the different parallel programming systems, models,
    and paradigms, it’s time to introduce some **metrics** that help measure parallel
    systems’ performance.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了不同的并行编程系统、模型和范式，是时候介绍一些**指标**，这些指标有助于衡量并行系统的性能。
- en: Exploring the metrics to assess parallelism
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索评估并行性的指标
- en: Metrics are measurements that can help us understand how a system is performing
    and to compare different improvement approaches.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是帮助我们了解系统性能并进行不同改进方法比较的测量。
- en: Here are some metrics and formulas commonly used to evaluate parallelism in
    a system.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些常用的指标和公式，用于评估系统中的并行性。
- en: Degree of parallelism
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行度
- en: '**Degree of parallelism** ( **DOP** ) is a metric that indicates the number
    of operations being simultaneously executed by a computer. It is useful to describe
    the performance of parallel programs and multi-processor systems.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行度**（**DOP**）是一个指标，表示计算机同时执行的操作数量。它有助于描述并行程序和多处理器系统的性能。'
- en: When computing the DOP, we can use the maximum number of operations that could
    be done simultaneously, measuring the ideal case scenario without bottlenecks
    or dependencies. Alternatively, we can use either the average number of operations
    or the number of simultaneous operations at a given point in time, reflecting
    the actual DOP achieved by a system. An approximation can be done by using profilers
    and performance analysis tools to measure the number of threads during a particular
    time period.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算DOP时，我们可以使用可以同时进行的最大操作数，衡量没有瓶颈或依赖的理想情况。或者，我们可以使用平均操作数或特定时间点的并发操作数，反映系统实际实现的DOP。可以通过使用分析器和性能分析工具来测量特定时间段内的线程数来进行近似。
- en: That means that the DOP is not a constant; it is a dynamic metric that changes
    during application execution.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着DOP不是一个常数；它是一个动态指标，在应用程序执行过程中会发生变化。
- en: For example, consider a script tool that processes multiple files. These files
    can be processed sequentially or simultaneously, increasing efficiency. If we
    have a machine with **N** cores and we want to process **N** files, we can assign
    a file to each core.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个处理多个文件的脚本工具。这些文件可以依次或同时处理，从而提高效率。如果我们有一台拥有**N**个核心的机器，并且我们想要处理**N**个文件，我们可以将一个文件分配给每个核心。
- en: 'The time to process all files sequentially would be as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 依次处理所有文件所需的时间如下：
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>≅</mml:mo><mml:mi>N</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>≅</mml:mo><mml:mi>N</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/1.png)'
- en: 'And, the time to process them in parallel would be:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这些文件并行所需的时间如下：
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/2.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/2.png)'
- en: Therefore, the DOP is **N** , the number of cores actively processing separate
    files.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，DOP是**N**，即积极处理单独文件的活跃核心数。
- en: There is a theoretical upper bound on the speed-up that parallelization can
    achieve, which is given by **Amdahl’s law** .
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化能够达到的速度提升有一个理论上的上限，这由**阿姆达尔定律**给出。
- en: Amdahl’s law
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阿姆达尔定律
- en: In a parallel system, we could believe that doubling the number of CPU cores
    could make the program run twice as fast, thereby halving the runtime. However,
    the speed-up from parallelization is not linear. After a certain number of cores,
    the runtime is not reduced anymore due to different circumstances such as context
    switching, memory paging, and so on.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个并行系统中，我们可能会认为增加CPU核心的数量可以使程序运行速度加倍，从而将运行时间减半。然而，并行化的速度提升并不是线性的。在达到一定数量的核心后，由于上下文切换、内存分页等因素，运行时间不再减少。
- en: 'The Amdahl’s law formula computes the theoretical maximum speed-up a task can
    perform after parallelization as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律公式计算了并行化后任务可以实现的最高理论速度提升，如下所示：
- en: '![<math  display="block"><mrow><mrow><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mfenced
    open="(" close=")"><mi>s</mi></mfenced><mo>=</mo><mfrac><mi>s</mi><mrow><mi>s</mi><mo>+</mo><mi>p</mi><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mi>s</mi></mrow></mfenced></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi><mo>+</mo><mstyle
    scriptlevel="+1"><mfrac><mi>p</mi><mi>s</mi></mfrac></mstyle></mrow></mfrac></mrow></mrow></math>](img/3.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![<math  display="block"><mrow><mrow><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mfenced
    open="(" close=")"><mi>s</mi></mfenced><mo>=</mo><mfrac><mi>s</mi><mrow><mi>s</mi><mo>+</mo><mi>p</mi><mfenced
    open="(" close=")"><mrow><mn>1</mn><mo>−</mo><mi>s</mi></mrow></mfenced></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi><mo>+</mo><mstyle
    scriptlevel="+1"><mfrac><mi>p</mi><mi>s</mi></mfrac></mstyle></mrow></mfrac></mrow></mrow></math>](img/3.png)'
- en: Here, **s** is the speed-up factor of the improved part and **p** is the fraction
    of the parallelizable part compared to the entire process. Therefore, **1-p**
    represents the ratio of the task not parallelizable (the bottleneck or sequential
    part), while **p/s** represents the speed-up achieved by the parallelizable part.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**s**是改进部分的速度提升因子，**p**是可并行部分相对于整个过程的比率。因此，**1-p**代表任务不可并行（瓶颈或顺序部分）的比率，而**p/s**代表可并行部分实现的速度提升。
- en: That means that the maximum speed-up is limited by the sequential portion of
    the task. The greater the fraction of the parallelizable task ( **p** approaches
    **1** ), the more the maximum speed-up increases up to the speed-up factor ( **s**
    ). On the other hand, when the sequential portion becomes larger ( **p** approaches
    **0** ), **Smax** tends to **1** , meaning that no improvement is possible.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着最大速度提升受限于任务的顺序部分。可并行化任务的比例越大（**p**接近**1**），最大速度提升增加得越多，直到达到速度提升因子（**s**）。另一方面，当顺序部分变得更大（**p**接近**0**）时，**Smax**趋向于**1**，这意味着无法实现改进。
- en: '![Figure 1.9: The speed-up limit by the number of processors and percentage
    of parallelizable parts](img/B22219_01_9.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 1.9：处理器数量和并行化部分百分比的速度提升限制](img/B22219_01_9.jpg)'
- en: 'Figure 1.9: The speed-up limit by the number of processors and percentage of
    parallelizable parts'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9：处理器数量和并行化部分百分比的速度提升限制
- en: The **critical path** in parallel systems is defined by the longest chain of
    dependent calculations. As the critical path is hardly parallelizable, it defines
    the sequential portion and thus the quicker runtime that a program can achieve.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 并行系统中的**关键路径**由依赖计算的最长链定义。由于关键路径几乎无法并行化，它定义了顺序部分，从而定义了程序可以实现的更快的运行时间。
- en: For example, if the sequential part of a process represents 10% of the runtime,
    then the fraction of the parallelizable part is **p=0.9.** In this case, the potential
    speed-up will not exceed 10 times the speed-up, regardless of the number of processors
    available.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一个过程的顺序部分代表运行时间的10%，那么并行化部分的比例是**p=0.9**。在这种情况下，潜在的速度提升不会超过速度提升因子的10倍，无论有多少处理器可用。
- en: Gustafson’s law
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gustafson定律
- en: The Amdahl’s law formula can only be used with fixed-sized problems and increasing
    resources. When using larger datasets, time spent in the parallelizable part grows
    much faster than that in the sequential part. In these cases, the Gustafson’s
    law formula is less pessimistic and more accurate, as it accounts for fixed execution
    time and increasing problem size with additional resources.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Amdahl定律公式只能用于固定大小的问题和增加资源。当使用更大的数据集时，并行化部分花费的时间增长速度远快于顺序部分。在这些情况下，Gustafson定律公式更为乐观且更准确，因为它考虑了固定执行时间和随着额外资源增加的问题规模。
- en: 'The Gustafson’s law formula computes the speed-up gained by using **p** processors
    as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Gustafson定律公式计算使用**p**个处理器获得的速度提升如下：
- en: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mfenced><mml:mo>⋅</mml:mo><mml:mi>p</mml:mi></mml:math>](img/4.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math   display="block"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mfenced><mml:mo>⋅</mml:mo><mml:mi>p</mml:mi></mml:math>](img/4.png)'
- en: Here, **p** is the number of processors and **f** is the fraction of the task
    that remains sequential. Therefore, **(1-f)*p** represents the speed-up achieved
    with the parallelization of the **(1-f)** task distributed across **p** processors,
    and **p** represents the extra work done when increasing resources.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**p**是处理器的数量，**f**是剩余顺序任务的比例。因此，**(1-f)*p**表示通过将**(1-f)**任务分布在**p**个处理器上实现的加速，而**p**表示增加资源时所做的额外工作。
- en: Gustafson’s law formula shows that the speed-up is affected by parallelization
    when lowering **f** and by scalability by increasing **p** .
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Gustafson定律公式表明，当降低**f**时，速度提升受并行化影响，当增加**p**时，受可扩展性影响。
- en: As with Amdahl’s law, Gustafson’s law formula is an approximation that provides
    valuable perspective when measuring improvements in parallel systems. Other factors
    can reduce efficiency such as overhead communication between processors or memory
    and storage limitations.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 与Amdahl定律一样，Gustafson定律公式是一个近似值，当测量并行系统改进时提供了有价值的视角。其他因素可能会降低效率，例如处理器或内存与存储之间的开销通信。
- en: Summary
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the different architectures and models we
    can use to build parallel systems. Then we explored the details of the variety
    of parallel programming paradigms available to develop parallel software and learned
    about their behavior and nuances. Finally, we defined some useful metrics to measure
    the performance of parallel programs.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了我们可以用来构建并行系统的不同架构和模型。然后我们探讨了可用来开发并行软件的各种并行编程范式的细节，并了解了它们的行为和细微差别。最后，我们定义了一些有用的指标来衡量并行程序的性能。
- en: In the next chapter, we will explore the relationship between hardware and software,
    as well as how software maps and interacts with the underlying hardware. We will
    also learn what threads, processes, and services are, how threads are scheduled,
    and how they communicate with each other. Furthermore, we will cover inter-process
    communication and much more.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨硬件和软件之间的关系，以及软件如何映射和与底层硬件交互。我们还将学习线程、进程和服务是什么，线程是如何调度的，以及它们如何相互通信。此外，我们还将涵盖进程间通信等内容。
- en: Further reading
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Topological sorting: [https://en.wikipedia.org/wiki/Topological_sorting](https://en.wikipedia.org/wiki/Topological_sorting)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑排序：[https://zh.wikipedia.org/wiki/拓扑排序](https://zh.wikipedia.org/wiki/拓扑排序)
- en: 'C++ compiler support: [https://en.cppreference.com/w/cpp/compiler_support](https://en.cppreference.com/w/cpp/compiler_support)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++ 编译器支持：[https://zh.cppreference.com/w/cpp/compiler_support](https://zh.cppreference.com/w/cpp/compiler_support)
- en: 'C++20 compiler support: [https://en.cppreference.com/w/cpp/compiler_support/20](https://en.cppreference.com/w/cpp/compiler_support/20)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++20 编译器支持：[https://zh.cppreference.com/w/cpp/compiler_support/20](https://zh.cppreference.com/w/cpp/compiler_support/20)
- en: 'C++23 compiler support: [https://en.cppreference.com/w/cpp/compiler_support/23](https://en.cppreference.com/w/cpp/compiler_support/23)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++23 编译器支持：[https://zh.cppreference.com/w/cpp/compiler_support/23](https://zh.cppreference.com/w/cpp/compiler_support/23)
