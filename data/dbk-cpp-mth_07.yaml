- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: There’s No Simple Way to Do Parallelism and Concurrency in C++
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在C++中实现并行和并发没有简单的方法
- en: '*Unless we rethink OOP* *and FP*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非我们重新思考面向对象编程* *和函数式编程*'
- en: To do parallelism and concurrency in C++, we used to require either separate
    libraries (for example, Boost) or OS primitives. With the introduction of functional
    programming constructs, parallelism and concurrency have become easier, within
    certain constraints.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要在C++中实现并行和并发，我们过去通常需要单独的库（例如，Boost）或操作系统原语。随着函数式编程结构的引入，在一定的约束下，并行和并发变得更加容易。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Defining parallelism and concurrency
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义并行和并发
- en: Common issues with parallelism and concurrency
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行和并发中的常见问题
- en: Functional programming to the rescue!
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数式编程来拯救！
- en: The Actor Model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Actor模型
- en: What we can’t do yet
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们目前还无法做到的事情
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code for this chapter is available on GitHub at [https://github.com/PacktPublishing/Debunking-CPP-Myths](https://github.com/PacktPublishing/Debunking-CPP-Myths)
    , in the **ch7** folder. The code has been compiled with Makefiles using g++ and
    C++ 20. The example regarding the Actor Model uses **C++ Actor Framework** ( **CAF**
    ) ( [https://www.actor-framework.org/](https://www.actor-framework.org/) ) so
    you’ll need to install it before working on it. On Ubuntu, it can be installed
    by running **apt install libcaf-dev** . The CAF version that’s used in the examples
    is the stable Ubuntu version of the library: **0.17** .'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可在GitHub上找到，地址为[https://github.com/PacktPublishing/Debunking-CPP-Myths](https://github.com/PacktPublishing/Debunking-CPP-Myths)，位于**ch7**文件夹中。代码是用g++和C++
    20编译的Makefiles。关于Actor Model的示例使用了**C++ Actor Framework**（**CAF**）（[https://www.actor-framework.org/](https://www.actor-framework.org/)），因此在开始工作之前您需要安装它。在Ubuntu上，可以通过运行**apt
    install libcaf-dev**来安装。示例中使用的CAF版本是稳定的Ubuntu库版本：**0.17**。
- en: Defining parallelism and concurrency
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义并行和并发
- en: 'My first computer was an HC-90, a ZX-80 clone built in Romania. I owned two
    versions: the first required a cassette player to load programs. Despite this
    inconvenience, it had a big advantage over its main competitor at the time, the
    CHIP computer, yet another ZX-80 clone built in Romania. You see, the CHIP computer
    required a cassette to load into its OS, while the HC-90 had enough EPROM memory
    to boot directly into a BASIC interpreter. The second version I owned was much
    better: it had a 5-inch floppy disk reader, which meant that you could load programs
    much faster.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我的第一台电脑是HC-90，这是一款在罗马尼亚制造的ZX-80克隆。我拥有两个版本：第一个版本需要磁带播放器来加载程序。尽管这种不便，但它与当时的主要竞争对手CHIP电脑（又是另一款在罗马尼亚制造的ZX-80克隆）相比有一个很大的优势。您知道，CHIP电脑需要磁带来加载其操作系统，而HC-90有足够的EPROM内存可以直接引导到BASIC解释器。我拥有的第二个版本要好得多：它有一个5英寸软盘驱动器，这意味着您可以更快地加载程序。
- en: 'In both versions, the BASIC interpreter was your interface with the computer,
    and since not many programs were available other than games, I spent some of my
    time in high school writing BASIC programs and playing games. Eventually, I realized
    that I wanted more than BASIC. I played a bit with graphics and sound, but the
    problem was that everything was very slow. This made me learn ZX 80 assembler,
    which was an adventure. It was very easy to make mistakes in assembler, which
    resulted in a reboot and the loss of all work. It wasn’t a sustainable way to
    program, but it made me appreciate the programming luxuries of today much more.
    Imagine this: I can compile and run tests on my programs on my computer and save
    my changes to a source control system.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个版本中，BASIC解释器都是您与计算机的接口，由于除了游戏之外可用的程序不多，我在高中时花了一些时间编写BASIC程序和玩游戏。最终，我意识到我想要的不仅仅是BASIC。我尝试了一些图形和声音，但问题是所有东西都非常慢。这让我学习了ZX
    80汇编器，这是一次冒险。在汇编器中犯错非常容易，这会导致重启并丢失所有工作。这不是一种可持续的编程方式，但它让我更加珍视今天的编程便利。想象一下：我可以在我的电脑上编译和运行程序的测试，并将我的更改保存到源代码控制系统中。
- en: 'I knew back then that I wanted the graphics and sounds to feel faster. What
    I didn’t realize was that I had a fundamental limitation: there was only one CPU
    (or one core, as we would say today), which meant that the graphics, sound, and
    logic code had to run sequentially. The CPU could receive a command to play a
    sound, then go to display some graphics, and then make some computations, and
    since there was a very short lag between the instruction and the actual sound
    playing or the image showing, it seemed as if these tasks were running in parallel.
    But they weren’t: they were concurrent. You could observe this if you loaded the
    system to the maximum since the image and sound were no longer synchronized.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我当时就知道，我想让图形和声音感觉更快。我没有意识到的是，我有一个根本的限制：只有一个CPU（或者说，就像我们今天所说的，一个核心），这意味着图形、声音和逻辑代码必须顺序运行。CPU可以接收一个播放声音的命令，然后转到显示一些图形，然后进行一些计算，由于指令和实际声音播放或图像显示之间的延迟非常短，所以这些任务看起来像是并行运行的。但它们并不是：它们是并发的。如果你将系统加载到最大，图像和声音就不再同步了，你可以观察到这一点。
- en: What would have happened if I had more processors or more cores to work with?
    Well, I could have defined various tasks that can be run on separate processors.
    A capable scheduler could take these tasks and run them in parallel to fill the
    capacity of the idle CPUs. If the tasks are well-defined, we can squeeze a lot
    of the power from the available cores and get the answer faster. This is **parallelism**
    .
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我有更多的处理器或更多的核心来工作，会发生什么情况呢？嗯，我可以定义各种可以在单独的处理器上运行的任务。一个有能力的调度器可以接管这些任务，并将它们并行运行以填充空闲CPU的容量。如果任务定义得很好，我们可以从可用的核心中榨取大量的性能，并更快地得到答案。这就是**并行性**。
- en: A nuance to this definition, which will become useful in this chapter, comes
    from the Haskell community (see [https://wiki.haskell.org/Parallelism_vs._Concurrency](https://wiki.haskell.org/Parallelism_vs._Concurrency)
    ). They make a big distinction between a parallel functional program and a concurrent
    functional program, therefore presuming both programs use immutability. Parallel
    functional programs use cores to execute faster, but they’re deterministic, and
    the meaning of the program is unchanged whether we execute it sequentially or
    in parallel. Contrast this with functional concurrent programs that run concurrent
    threads, each doing I/O operations, and that are non-deterministic since we don’t
    know the order of operations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义的一个细微差别，将在本章中变得有用，来自Haskell社区（见[https://wiki.haskell.org/Parallelism_vs._Concurrency](https://wiki.haskell.org/Parallelism_vs._Concurrency)）。他们在一个并行函数程序和一个并发函数程序之间做出了很大的区分，因此假设这两个程序都使用不可变性。并行函数程序使用核心来执行得更快，但它们是确定性的，程序的意义在顺序执行或并行执行时是不变的。与此相对比的是，并发函数程序运行并发线程，每个线程执行I/O操作，并且是非确定性的，因为我们不知道操作顺序。
- en: Unfortunately, as is common in software development, these terms have a life
    of their own. You might encounter people who believe concurrency and parallelism
    are completely different things. In researching this matter, I came upon a conversation
    on StackOverflow stating the argument that concurrency is a superset of parallelism
    since concurrency refers to a set of methods that are used for managing multiple
    threads. And this may well be how some computer science books treat the topic.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，正如软件开发中常见的那样，这些术语有自己的生命周期。你可能会遇到一些人认为并发和并行是完全不同的东西。在研究这个问题时，我在StackOverflow上发现了一场关于并发生与并行性是不同事物的争论。有人认为并发是并行的超集，因为并发指的是一组用于管理多个线程的方法。这可能是某些计算机科学书籍处理这个主题的方式。
- en: 'The need for clarity constrains us to pick one definition. I’ll pick the definition
    that closely matches my formative years of programming: **concurrency** is when
    multiple operations seem to run at the same time, while parallelism is when they
    do. This difference, while seemingly simple, leads to a difference in intent when
    designing the program. When we design a program expecting it to run in parallel,
    we define operations that can run in parallel and figure out their order. We try
    to squeeze time from the CPU by splitting a larger task into parts that can run
    independently, without them affecting each other much. The intent is different
    when we design a program expecting it to run concurrently: we optimize the response
    time by pushing the longer tasks into the dead times of the CPU.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 需要清晰性的要求迫使我们选择一个定义。我将选择与我编程形成期最接近的定义：**并发**是指多个操作似乎同时运行，而**并行**是指它们确实如此。这种差异，虽然看似简单，但在设计程序时会导致意图上的差异。当我们设计一个预期将并行运行的程序时，我们定义可以并行运行的运算，并确定它们的顺序。我们试图通过将更大的任务分割成可以独立运行的部分来从CPU中挤出时间，这些部分不会相互影响太多。当我们设计一个预期将并发运行的程序时，我们通过将较长的任务推入CPU的空闲时间来优化响应时间。
- en: Both these programming models are challenging, albeit in different ways. Let’s
    remind ourselves of the common issues we face when using them.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种编程模型都具有挑战性，尽管方式不同。让我们提醒自己使用它们时面临的常见问题。
- en: Common issues with parallelism and concurrency
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行和并发中的常见问题
- en: I’m convinced that the fundamental problem of software development is to mentally
    translate the static view of a system – the code – into its dynamic behavior,
    or what the program does when it runs. Programmers run code in their heads every
    time they’re considering a change, often automatically but always at the expense
    of mental energy. This is one of the reasons why I believe practices such as **test-driven
    development** ( **TDD** ) and incremental design are useful; they allow us to
    move part of this mental energy spending from our brains to running the tests
    repeatedly.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我坚信软件开发的基本问题是将系统的静态视图——代码——在心理上转化为其动态行为，或者程序运行时所做的操作。程序员每次考虑更改时都会在脑海中运行代码，通常是自动的，但总是以精神能量为代价。这就是我相信像**测试驱动开发**（**TDD**）和增量设计这样的实践是有用的原因；它们允许我们将部分精神能量支出从大脑转移到重复运行测试上。
- en: This fundamental problem is already difficult for single threads, but for parallel
    or concurrent designs, it adds a new level of challenge. We not only need to imagine
    what the code will do but also how the code will interact with the other parts
    of the code that run at the same time. So, imagination and the brain energy required
    to make sense of parallel execution is the first challenge.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基本问题对于单个线程来说已经很困难了，但对于并行或并发设计来说，它又增加了一个新的挑战层级。我们不仅需要想象代码会做什么，还需要想象代码将如何与其他同时运行的代码部分交互。因此，想象力和理解并行执行所需的脑力是第一个挑战。
- en: Then, there are the purely technical challenges.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，还有纯粹的技术挑战。
- en: When resources are shared, resource management becomes much harder, particularly
    when multiple threads can modify values. One thread might be using a value that
    was already changed by another thread, thus leading to wrong results. A memory
    address might be freed by one thread and then another thread attempts to read
    or write to it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当资源被共享时，资源管理变得更加困难，尤其是在多个线程可以修改值的情况下。一个线程可能正在使用另一个线程已经更改的值，从而导致错误的结果。一个内存地址可能被一个线程释放，然后另一个线程尝试读取或写入它。
- en: Sharing the same infrastructure isn’t easy either. One thread might take all
    the resources due to a bug, thus blocking other threads for long periods. This
    is less of an issue when the program is formed of separate tasks using multiple
    cores, but it still leads to reduced performance since the separate tasks need
    to converge at some point. Threads could wait for one another indefinitely or
    until a timeout occurs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 共享相同的基础设施也不容易。一个线程可能因为一个错误而占用所有资源，从而长时间阻塞其他线程。当程序由使用多个核心的独立任务组成时，这个问题不那么严重，但仍然会导致性能降低，因为独立任务需要在某个点上收敛。线程可能会无限期地等待彼此，或者直到超时发生。
- en: Implementing programs that work with parallel or concurrent tasks from scratch
    is one of the most difficult things you might need to do as a programmer. I remember
    when I once debugged a synchronization issue between threads for a week, and I
    knew my technical lead and my project manager were starting to doubt my abilities.
    I didn’t doubt myself, but I didn’t like how long it took me to finally figure
    it out.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始实现处理并行或并发任务的程序是作为程序员可能需要做的最困难的事情之一。我记得有一次我花了整整一周时间调试线程间的同步问题，我知道我的技术领导和项目经理开始怀疑我的能力。我没有怀疑自己，但我不喜欢最终解决问题所花费的时间那么长。
- en: For this reason, libraries and patterns have appeared that help us implement
    concurrent and parallel programs. Most of them invite us to pass a function that
    represents a thread to a method that sorts out some of the complexities of thread
    synchronization. This is possible by separating the tasks that we might need into
    types of tasks. Additionally, architecture models such as MapReduce that are implemented
    by Hadoop and inspired by functional programming help us deal with large-scale
    parallelization.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，出现了库和模式，帮助我们实现并发和并行程序。大多数都邀请我们向一个方法传递一个表示线程的函数，该方法解决线程同步的一些复杂性。这是通过将我们可能需要的任务分成任务类型来实现的。此外，由Hadoop实现并由函数式编程启发的架构模型MapReduce也帮助我们处理大规模并行化。
- en: As we can see, we can’t discuss modern approaches to parallel programming without
    discussing the functional programming approach to it.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，如果不讨论函数式编程方法，我们就无法讨论现代并行编程的途径。
- en: Functional programming to the rescue!
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程拯救了！
- en: As we’ve seen, one of the problems with parallel and concurrent tasks is the
    shared access to resources. Functional programming, in its pure form, solves this
    out of the box through immutability. Since everything is immutable by default,
    and since any change to a value is made by pointing to a changed value instead
    of modifying the initial one, threads are never at risk of modifying data used
    by other threads. We discussed how to achieve this when we discussed the different
    paradigms available in C++.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，并行和并发任务的一个问题是资源共享。在纯函数式编程中，通过不可变性直接解决了这个问题。由于一切都是不可变的默认值，并且任何对值的更改都是通过指向更改的值而不是修改初始值来实现的，因此线程永远不会面临修改其他线程使用的数据的风险。我们在讨论C++中可用的不同范例时讨论了如何实现这一点。
- en: 'But there’s more: functional programming offers us parallelizable algorithms
    out of the box. The C++ standardization committee recognized this when introducing
    functional algorithms along with an execution policy that allows you to run operations
    on collections in parallel.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有更多：函数式编程直接提供了可并行化的算法。当引入函数式算法和允许你在并行集合上运行操作的执行策略时，C++标准化委员会也认识到了这一点。
- en: 'Let’s look at a simple example: we want to compute the sum of squares of the
    values in a collection. The functional version of this type of algorithm is a
    typical map-reduce one: first, we pass in the initial collection and map it to
    a collection that contains the squares of the values, after which we reduce it
    by adding all the elements. In STL, these operations are implemented in **std::transform**
    and **std::reduce** , respectively. A version that combines them is available
    in **std::transform_reduce** , but we’ll ignore it for now to make the example
    more relevant.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的例子：我们想要计算一个集合中值的平方和。这种算法的函数式版本是一个典型的map-reduce：首先，我们传入初始集合，将其映射到一个包含值平方的集合，然后通过添加所有元素来减少它。在STL中，这些操作分别由**std::transform**和**std::reduce**实现。一个结合它们的版本在**std::transform_reduce**中可用，但我们现在忽略它，以便使例子更相关。
- en: 'Here’s what the function looks like:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 函数看起来是这样的：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The only thing we need to do to run these operations in parallel is to add
    a parameter to both functional algorithms that specifies the execution policy.
    The execution policy we’ll use is **std::execution::par** , an instance of **std::execution_parallel**
    provided by the standard library that specifies that the algorithms need to run
    in parallel:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行运行这些操作，我们只需要向函数式算法添加一个参数，该参数指定了执行策略。我们将使用的执行策略是**std::execution::par**，这是标准库提供的**std::execution_parallel**的一个实例，它指定算法需要并行运行：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: From this example, we can notice a few things.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中，我们可以注意到几点。
- en: First, it’s very easy to switch between the different execution policies when
    you use functional programming. This enables us to fix issues related to parallelization
    more easily and to optimize code. Running the algorithms in parallel isn’t necessarily
    better than sequential execution in all cases. It’s likely that for small numbers
    or short collections, the resources that are used to start threads and manage
    them are larger than the time saved.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，当你使用函数式编程时，在不同的执行策略之间切换非常容易。这使得我们能够更轻松地修复与并行化相关的问题，并优化代码。在所有情况下，并行运行算法并不一定比顺序执行更好。对于小数量或短集合，启动线程和管理它们所使用的资源可能比节省的时间更大。
- en: Second, we can use the execution policy as a parameter or as a general configuration.
    This would allow us to test that algorithms work sequentially in isolation from
    thread synchronization. It also allows us to decide what policy to use at runtime,
    depending on a few factors related to the input data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们可以将执行策略作为参数或作为通用配置。这将使我们能够测试算法在独立于线程同步的情况下顺序执行。它还允许我们根据与输入数据相关的几个因素在运行时决定使用哪种策略。
- en: Third, each of these execution policies imposes limitations on your code. For
    example, the parallel policy we’ve used here requires that the iterators aren’t
    invalidated in the process, thus disallowing write access and the usage of **std::back_inserter**
    . Other execution policies are available in STL besides **std::execution::parallel_policy**
    , **std::execution::sequenced_policy:** , **std::execution::parallel_unsequenced_policy**
    , and **std::execution::unsequenced_policy** , with the remark that the standardization
    committee might add built-in policies for **std::parallel::cuda** and **std::parallel::opencl**
    . Each of these policies has its limitations and constraints, so the most portable
    code is what’s used for maximum immutability and functional algorithms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，这些执行策略中的每一个都对你的代码施加了限制。例如，我们在这里使用的并行策略要求迭代器在过程中不被无效化，因此禁止写访问和**std::back_inserter**的使用。STL中除了**std::execution::parallel_policy**、**std::execution::sequenced_policy**、**std::execution::parallel_unsequenced_policy**和**std::execution::unsequenced_policy**之外，还有其他执行策略，需要注意的是标准化委员会可能会为**std::parallel::cuda**和**std::parallel::opencl**添加内置策略。每个策略都有其局限性和约束，因此最可移植的代码是用于最大不变性和函数式算法的代码。
- en: 'Fourth, the algorithms run in sequence, but each of them is parallelized. If
    we need to squeeze more from our computing resources, we either use the combined
    **std::transform_reduce** algorithm or write our own algorithm combining the two.
    Once again, it’s important to realize that running code in parallel is a trade-off:
    some of the computing resources will be spent on starting and synchronizing threads,
    which for some configurations might not add a big benefit.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，算法按顺序运行，但每个算法都是并行化的。如果我们需要从我们的计算资源中获得更多，我们要么使用组合的**std::transform_reduce**算法，要么编写自己的算法将这两个算法结合起来。再次强调，并行运行代码是一个权衡：一些计算资源将用于启动和同步线程，对于某些配置，这可能不会带来很大的好处。
- en: Finally, the fifth point is that the map-reduce pattern is very powerful. Any
    unary function can be used for **map** and any binary function can be used for
    **reduce** , and we can bind the parameters of functions that require more values
    until we get unary or binary functions. Maps and reduces can be chained in many
    ways. If you start looking at your programs as data in/data out, you’ll notice
    that all our programs can be written as data in/functional transformations/data
    out, with many of the functional transformations being **map** / **reduce** operations.
    This realization leads to a very powerful programming model since we can turn
    parallelization on or off for all or parts of the algorithms. Occasionally, we
    may want to write our own algorithms that optimize parallelization for important
    parts of the code, but we get most of it for free.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第五点是映射-归约模式非常强大。任何一元函数都可以用于**map**，任何二元函数都可以用于**reduce**，我们可以绑定需要更多值的函数的参数，直到我们得到一元或二元函数。映射和归约可以以多种方式链式连接。如果你开始将你的程序视为输入/输出数据，你会发现我们所有的程序都可以写成输入/函数式转换/输出，其中许多函数式转换是**map**/**reduce**操作。这种认识导致了一个非常强大的编程模型，因为我们可以为算法的所有部分或部分开启或关闭并行化。偶尔，我们可能想要编写自己的算法，以优化代码中重要部分的并行化，但我们大多数情况下都可以免费获得。
- en: The only catch is that we need to use immutable data and functional algorithms.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的缺点是我们需要使用不可变数据和函数式算法。
- en: The design style we’ve discussed so far is data-centric since it focuses on
    the data structures and their transformations. As always when it comes to software
    design and architecture, we have the alternative to focus on behavior. Surely
    enough, a design style that splits the program into behaviors and allows for parallel
    programming has emerged in the form of the Actor Model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止讨论的设计风格是数据驱动的，因为它关注数据结构和它们的转换。正如在软件设计和架构方面，我们总是可以选择关注行为。确实，一种将程序分割成行为并允许并行编程的设计风格以Actor
    Model的形式出现。
- en: The Actor Model
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Actor Model
- en: 'The world around us moves in parallel very naturally. Each tree, plant, or
    person does their own thing, and occasionally they interact, and things change
    for the parties involved. So, we already have a mental model of how parallel programs
    could work: separate entities that encapsulate their behavior and communicate
    somehow, on an infrastructure that ensures proper synchronization.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们周围的世界以非常自然的方式并行移动。每一棵树、每一株植物或每一个人都在做自己的事情，偶尔它们会互动，涉及的事物会发生变化。因此，我们已经有了一个关于并行程序如何工作的心理模型：独立的实体封装它们的行为，并以某种方式在确保适当同步的基础设施上进行通信。
- en: 'This idea led to the creation of the Actor Model in 1973 by Carl Hewitt. This
    model splits a program into actors that can do three things:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法导致了1973年卡尔·休伊特（Carl Hewitt）创建Actor Model。这个模型将程序分割成可以进行以下三种操作的actor：
- en: Send messages to other actors
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向其他actor发送消息
- en: Create new actors
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建新的actor
- en: Define the behavior for the next message the actor receives
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义actor接收的下一条消息的行为
- en: Each actor has an address that’s conceptually similar to an email address, and
    actors can only communicate with the actors whose addresses they have. This address
    can be received in a message or obtained by creating a new actor.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 每个actor都有一个地址，在概念上类似于电子邮件地址，actor只能与它们有地址的actor通信。这个地址可以包含在消息中，或者通过创建一个新的actor来获得。
- en: The actor model separates the communication mechanism from the functionality
    of each actor. This has resulted in implementations that allow us to write highly
    parallelizable code without having to deal with thread primitives.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Actor模型将通信机制与每个actor的功能性分开。这导致了允许我们编写高度可并行化代码的实现，而无需处理线程原语。
- en: 'The oldest and most stable implementation for C++ is CAF ( [https://www.actor-framework.org/](https://www.actor-framework.org/)
    ). A newer alternative is **Hiactor** from Alibaba ( [https://github.com/alibaba/hiactor](https://github.com/alibaba/hiactor)
    ). However, the best-known implementation comes from the Java world: the **Akka**
    **toolkit** ( [https://akka.io/](https://akka.io/) ).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: C++最古老且最稳定的实现是CAF（[https://www.actor-framework.org/](https://www.actor-framework.org/)）。一个较新的替代方案是来自阿里巴巴的**Hiactor**（[https://github.com/alibaba/hiactor](https://github.com/alibaba/hiactor)）。然而，最知名的实现来自Java世界：**Akka**
    **工具包**（[https://akka.io/](https://akka.io/)）。
- en: 'Let’s look at a simple example of implementing a chat between two actors using
    CAF. The following code defines the behavior of an actor as a Lambda, instantiates
    two chatting actors, and sends messages between them. Each actor writes their
    message to the console:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用CAF实现两个actor之间聊天的一个简单示例。以下代码定义了一个actor的行为为一个Lambda表达式，创建了两个聊天actor，并在它们之间发送消息。每个actor将它们的消息写入控制台：
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Running this code leads to different outputs. The best one is the one we expect:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码会导致不同的输出。最好的输出是我们预期的：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'However, running the code repeatedly leads to various results, as shown here:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重复运行代码会导致各种结果，如下所示：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can also receive even worse outputs:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以收到更糟糕的输出：
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: These results make it obvious that actors run in parallel. It also shows that
    parallel programming can only mask its complexity so much underneath the magic
    of these frameworks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果清楚地表明actor是并行运行的。它还表明，并行编程可以在这些框架的魔法之下掩盖其复杂性。
- en: However, the actor model offers us a way to think about parallel programming
    in terms of objects that respond to requests and allows us to pick the type of
    actors we need and the type of communication that’s most fit for our system. The
    preceding example shows an event-based actor that receives asynchronous messages,
    but the framework supports blocking messages and various types of actors, depending
    on their life cycle.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，actor模型为我们提供了一种以对象的形式来思考并行编程的方法，这些对象响应请求，并允许我们选择所需的actor类型以及最适合我们系统的通信类型。前面的示例展示了一个基于事件的actor，它接收异步消息，但该框架支持阻塞消息和多种类型的actor，这取决于它们的生命周期。
- en: An advantage of the actor model is that we can distribute the actors on separate
    computers, thus allowing us to scale a model relatively easily. Of course, this
    means that we hit the challenges of distributed systems head-on from the very
    first line of code that uses this model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: actor模型的一个优点是我们可以在不同的计算机上分布actor，从而相对容易地扩展模型。当然，这意味着我们直接面对分布式系统的挑战，从使用此模型的第一行代码开始。
- en: With that, we’ve seen what’s possible today within the standard library and
    by using the venerable actor model. But what still isn’t possible?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经看到了在标准库中使用以及通过使用值得尊敬的actor模型今天可以实现的可能性。但仍然有什么是不可能的？
- en: What we can’t do yet
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们目前还无法做到的是
- en: As you can see, using parallel and concurrent code isn’t as easy as “ *Write
    the code you want and let the tools and compiler make sense of it.* ” Perhaps
    we’ll be able to do this in the future with the intervention of AI, although based
    on my current experience using coding assistants, I have to say this seems very
    far away.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，使用并行和并发代码并不像“*编写你想要的代码，让工具和编译器来理解它*”那样简单。也许在AI的干预下，我们将来能够做到这一点，尽管根据我目前使用代码助手的经验，我必须说这看起来还非常遥远。
- en: Instead, you must structure your code for the programming model you choose.
    And if you start by writing the code base as a single-threaded application and
    without using functional constructs, changing it will prove difficult. I see parallels
    between objects and actors and, in theory, it might be possible to turn each object
    into an actor and each method into an event, but this seems idealistic. The reality
    is that there are still a lot of things that can go wrong when we switch from
    a synchronous to an event-based system, and a lot of them are very difficult to
    debug and require a deep understanding not only of the actor model but also of
    the framework you’re using for the actors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你必须为选择的编程模型结构化你的代码。如果你一开始就把代码库作为一个单线程应用程序编写，并且不使用函数式结构，那么改变它将会很困难。我看到对象和actor之间有相似之处，从理论上讲，可能将每个对象转换成actor，每个方法转换成事件，但这似乎过于理想化。现实是，当我们从同步系统切换到基于事件的系统时，还有很多事情可能会出错，其中很多都非常难以调试，并且需要深入理解actor模型以及你为actor使用的框架。
- en: 'Your best bet is to redesign applications within the paradigm you choose: either
    the data-centric functional one or the behavior-centric actor model.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你最好的选择是在你选择的范式内重新设计应用程序：要么是数据中心的函数式，要么是行为中心的actor模型。
- en: With a data-centric paradigm, you look at the data in and at the set of transformations
    required to get to the desired output. Each of these transformations is immutable,
    therefore taking data as input and returning another data structure as output.
    As we’ve seen, each of these transformations is parallelizable. Occasionally,
    we’ll need our own algorithms or to optimize some of the existing ones, after
    which we can write our own implementations that follow the same pattern. We can
    fine-tune the system using the execution policy and end up with a system that’s
    highly customizable and relatively easy to optimize.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据中心的范式下，你查看输入的数据以及到达所需输出的所需转换集合。这些转换中的每一个都是不可变的，因此以数据作为输入并返回另一个数据结构作为输出。正如我们所见，这些转换中的每一个都是可并行的。偶尔，我们需要自己的算法或优化一些现有的算法，然后我们可以编写遵循相同模式的自己的实现。我们可以使用执行策略来微调系统，最终得到一个高度可定制且相对容易优化的系统。
- en: With a behavior-centric paradigm, you look at your objects as actors that receive
    messages. This is closer to the original view of Alan Kay on object-oriented programming.
    As documented in the email exchange at [https://www.purl.org/stefan_ram/pub/doc_kay_oop_en](https://www.purl.org/stefan_ram/pub/doc_kay_oop_en)
    , a vision focused not on classes but on messaging, and most closely implemented
    in Smalltalk. You build your application from the ground up using actors and their
    messaging mechanics and test that the output is what you expect. You need to know
    about the types of actors and the types of messaging available in detail so that
    you can pick the ones that fit your problem. As shown in this example, actors
    don’t necessarily guarantee the order of execution, which may or may not be a
    concern for your system. This leads to a highly scalable system, but one that’s
    more difficult to understand and debug.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以行为中心的范式，你将你的对象视为接收消息的演员。这更接近艾伦·凯对面向对象编程的原始观点。正如在[https://www.purl.org/stefan_ram/pub/doc_kay_oop_en](https://www.purl.org/stefan_ram/pub/doc_kay_oop_en)的电子邮件交流中所述，这是一种专注于消息而不是类的愿景，并在Smalltalk中得到了最紧密的实现。你从底层开始构建你的应用程序，使用演员及其消息机制，并测试输出是否符合预期。你需要详细了解可用的演员类型和消息类型，以便你可以选择适合你问题的那些。正如这个例子所示，演员并不保证执行顺序，这可能是或可能不是你系统的一个问题。这导致了一个高度可扩展的系统，但同时也更难以理解和调试。
- en: This means we can’t automatically translate applications that are written to
    be synchronous and single-threaded into parallel or concurrent systems. Most of
    the time, a redesign is required.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不能自动将编写为同步和单线程的应用程序转换为并行或并发系统。大多数情况下，需要重新设计。
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Is there a simple way to do parallelism and concurrency in C++? It’s easier
    than it used to be, in that we rarely need to create our own threads and deal
    with their synchronization unless we’re building infrastructure code. We don’t
    necessarily need external libraries or tools since STL supports parallel execution
    for many algorithms.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中实现并行性和并发性有简单的方法吗？这比过去容易，因为我们很少需要创建自己的线程并处理它们的同步，除非我们正在构建基础设施代码。我们不一定需要外部库或工具，因为STL支持许多算法的并行执行。
- en: However, we can’t avoid the essential complexity of parallel and concurrent
    programming. Programs that take advantage of it need to be structured differently,
    have additional constraints, and require a different mindset and a different design
    paradigm. This isn’t a C++ problem – it’s a problem for any attempt at parallelism.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们无法避免并行和并发编程的基本复杂性。利用它的程序需要以不同的方式构建，有额外的约束，需要不同的思维方式和不同的设计范式。这不是C++的问题——这是任何尝试并行化的一个问题。
- en: Therefore, the conclusion is that it can be simpler than it used to be if we
    make the right choices, but it’s still very complicated.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，结论是，如果我们做出正确的选择，事情可以比过去更简单，但它仍然非常复杂。
- en: In the next chapter, we’ll ask the question of whether the fastest form of C++
    is inline assembly.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨最快形式的C++是否是内联汇编。
