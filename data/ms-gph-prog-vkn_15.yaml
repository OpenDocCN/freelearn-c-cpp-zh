- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Adding Reflections with Ray Tracing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用光线追踪添加反射
- en: In this chapter, we are going to implement reflections using ray tracing. Before
    ray tracing hardware was introduced, applications implemented reflections using
    screen-space techniques. However, this technique has drawbacks as it can only
    use information from what’s visible on the screen. If one of the rays goes outside
    the visible geometry on the screen, we usually fall back to an environment map.
    Because of this limitation, the rendered reflections can be inconsistent, depending
    on the camera position.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用光线追踪来实现反射。在引入光线追踪硬件之前，应用程序使用屏幕空间技术来实现反射。然而，这种技术有缺点，因为它只能使用屏幕上可见的信息。如果其中一条光线超出屏幕上可见的几何形状，我们通常会回退到环境贴图。由于这种限制，渲染的反射可能会根据相机位置而不一致。
- en: By introducing ray tracing hardware, we can overcome this limitation as we now
    have access to geometry that is not visible on the screen. The downside is that
    we might need to perform some expensive lighting computations. If the reflected
    geometry is outside the screen, this means we don’t have the data from the G-buffer
    and we need to compute the color, light, and shadow data from scratch.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入光线追踪硬件，我们可以克服这一限制，因为我们现在可以访问屏幕上不可见的几何形状。缺点是我们可能需要进行一些昂贵的光照计算。如果反射的几何形状在屏幕外，这意味着我们没有G缓冲区的数据，需要从头开始计算颜色、光照和阴影数据。
- en: To lower the cost of this technique, developers usually trace reflections at
    half resolution or use ray tracing only if screen-space reflection fails. Another
    approach is to use lower-resolution geometry in the ray tracing path to lower
    the cost of ray traversal. In this chapter, we are going to implement a ray tracing-only
    solution, as this gives the best-quality results. Then, it will be easy to implement
    the optimizations mentioned previously on top of it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了降低这种技术的成本，开发者通常会以半分辨率追踪反射，或者在屏幕空间反射失败时才使用光线追踪。另一种方法是使用较低分辨率的几何形状在光线追踪路径中，以降低光线遍历的成本。在本章中，我们将实现仅使用光线追踪的解决方案，因为这可以提供最佳质量的结果。然后，将很容易在它之上实现之前提到的优化。
- en: 'In this chapter, we’ll cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: How screen-space reflections work
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 屏幕空间反射的工作原理
- en: Implementing ray-traced reflections
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现光线追踪反射
- en: Implementing a denoiser to make the ray-traced output usable
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现降噪器以使光线追踪输出可用
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: By the end of the chapter, you will have a good understanding of the different
    solutions available for reflections. You will also learn how to implement ray-traced
    reflections and how to improve the final result with the help of a denoiser.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将很好地理解可用于反射的不同解决方案。你还将学习如何实现光线追踪反射以及如何借助降噪器来提高最终结果。
- en: 'The code for this chapter can be found at the following URL: [https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter15](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter15).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下URL找到：[https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter15](https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan/tree/main/source/chapter15)。
- en: How screen-space reflections work
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 屏幕空间反射的工作原理
- en: Reflections are an important rendering element that can provide a better sense
    of immersion in the scene. For this reason, developers have developed a few techniques
    over the years to include this effect, even before ray tracing hardware was available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 反射是重要的渲染元素，可以提供更好的沉浸感。因此，多年来，开发者已经开发了一些技术来包括这种效果，甚至在光线追踪硬件可用之前。
- en: One of the most common approaches is to ray-march the scene after the G-buffer
    data becomes available. Whether a surface will produce reflections is determined
    by the material’s roughness. Only materials with a low roughness will emit a reflection.
    This also helps reduce the cost of this technique since usually, only a low number
    of surfaces will satisfy this requirement.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的方法之一是在G缓冲区数据可用后对场景进行光线追踪。一个表面是否会产生反射由材料的粗糙度决定。只有粗糙度低的材料才会产生反射。这也帮助减少了这种技术的成本，因为通常只有少数表面会满足这一要求。
- en: Ray marching is a technique similar to ray tracing and was introduced in [*Chapter
    10*](B18395_10.xhtml#_idTextAnchor152), *Adding Volumetric Fog*. As a quick reminder,
    ray marching works similarly to ray tracing. Instead of traversing the scene to
    determine whether the ray hit any geometry, we move in the ray’s direction by
    small increments for a fixed number of iterations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 射线追踪是一种类似于光线追踪的技术，它在[*第10章*](B18395_10.xhtml#_idTextAnchor152)中介绍，即*添加体积雾*。作为快速提醒，射线追踪的工作原理与光线追踪相似。我们不是遍历场景以确定射线是否击中任何几何体，而是通过固定次数的迭代，以小的增量沿着射线的方向移动。
- en: This has both advantages and disadvantages. The advantage is that this technique
    has a fixed cost independent of the scene’s complexity as the maximum number of
    iterations per ray is pre-determined. The downside is that the quality of the
    results depends on the step size and the number of iterations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这既有优点也有缺点。优点是，这项技术具有固定的成本，与场景的复杂度无关，因为每条射线的最大迭代次数是预先确定的。缺点是，结果的质量取决于步长和迭代次数。
- en: For the best quality, we want a large number of iterations and a small step
    size, but this would make the technique too expensive. The compromise is to use
    a step size that gives good enough results and then pass the result through a
    denoising filter to try and reduce the artifacts introduced by the low-frequency
    sampling.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳质量，我们希望有大量的迭代和小的步长，但这会使技术变得过于昂贵。折衷方案是使用一个步长，以产生足够好的结果，然后将结果通过去噪滤波器传递，以尝试减少由低频采样引入的伪影。
- en: As the name implies, this technique works in screen space, similar to other
    techniques such as **Screen-Space Ambient Occlusion** (**SSAO**). For a given
    fragment, we start by determining whether it produces a reflection or not. If
    it does, we determine the reflected ray’s direction based on the surface normal
    and view direction.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，这项技术类似于其他技术，如**屏幕空间环境遮挡**（**SSAO**），在屏幕空间中工作。对于给定的片段，我们首先确定它是否产生反射。如果产生，我们根据表面法线和视方向确定反射射线的方向。
- en: Next, we move along the reflected ray direction for the given number of iterations
    and step size. At each step, we check against the depth buffer to determine whether
    we hit any geometry. Since the depth buffer has a limited resolution, usually,
    we define a delta value that determines whether we consider a given iteration
    a hit.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们沿着反射射线的方向移动给定次数的迭代和步长。在每一步中，我们检查深度缓冲区以确定是否击中任何几何体。由于深度缓冲区具有有限的分辨率，通常我们定义一个delta值来决定是否将给定的迭代视为击中。
- en: If the difference between the ray depth and the value stored in the depth buffer
    is under this delta, we can exit the loop; otherwise, we must continue. The size
    of this delta can vary, depending on the scene’s complexity, and is usually tweaked
    manually.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果射线深度与深度缓冲区中存储的值的差异小于这个delta值，我们可以退出循环；否则，我们必须继续。这个delta值的大小可能因场景的复杂度而异，通常需要手动调整。
- en: If the ray marching loop hits visible geometry, we look up the color value at
    that fragment and use it as the reflected color. Otherwise, we either return black
    or determine the reflected color using an environment map.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果射线追踪循环击中了可见几何体，我们查找该片段的颜色值并将其用作反射颜色。否则，我们返回黑色或使用环境图确定反射颜色。
- en: We are skipping over some implementation details here as they are not relevant
    to this chapter. We have provided resources that go into more detail in the *Further*
    *reading* section.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里跳过一些实现细节，因为它们与本章无关。我们在*进一步阅读*部分提供了更详细的信息。
- en: As mentioned previously, this technique is limited to information that is visible
    on screen. The main drawback is that reflections will disappear as the camera
    moves if the reflected geometry is no longer rendered on the screen. The other
    downside comes from ray marching as we have limited resolution in terms of the
    number and size of steps we can take.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这项技术仅限于屏幕上可见的信息。主要缺点是，如果反射的几何体不再在屏幕上渲染，随着摄像机的移动，反射将消失。另一个缺点来自射线追踪，因为我们对可以采取的步数和大小有限制。
- en: This can introduce holes in the reflection, which is usually addressed through
    aggressive filtering. This can result in blurry reflections and makes it difficult
    to obtain crisp reflections, depending on the scene and viewpoint.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会在反射中引入孔洞，这通常通过积极的过滤来解决。这可能导致反射模糊，并使得根据场景和视点难以获得清晰的反射。
- en: In this section, we introduced screen space reflections. We explained the main
    ideas behind this technique and some of its shortcomings. In the next section,
    we are going to implement ray-traced reflections, which can reduce some of the
    limitations of this technique.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了屏幕空间反射。我们解释了这种技术背后的主要思想及其一些不足。在下一节中，我们将实现光线追踪反射，这可以减少这种技术的一些限制。
- en: Implementing ray-traced reflections
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现光线追踪反射
- en: 'In this section, we are going to leverage the hardware ray tracing capabilities
    to implement reflections. Before diving into the code, here’s an overview of the
    algorithm:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将利用硬件光线追踪功能来实现反射。在深入代码之前，这里是对算法的概述：
- en: We start with the G-buffer data. We check whether the roughness for a given
    fragment is below a certain threshold. If it is, we move to the next step. Otherwise,
    we don’t process this fragment any further.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从G缓冲区数据开始。我们检查给定片段的粗糙度是否低于某个阈值。如果是，我们进入下一步。否则，我们不再处理这个片段。
- en: 'To make this technique viable in real time, we cast only one reflection ray
    per fragment. We will demonstrate two ways to pick the reflection’s ray direction:
    one that simulates a mirror-like surface and another that samples the GGX distribution
    for a given fragment.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使这种技术在实时中可行，我们只为每个片段发射一条反射光线。我们将展示两种选择反射光线方向的方法：一种模拟类似镜面的表面，另一种为给定片段采样GGX分布。
- en: If the reflection ray hits some geometry, we need to compute its surface color.
    We shoot another ray toward a light that has been selected through importance
    sampling. If the selected light is visible, we compute the color for the surface
    using our standard lighting model.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果反射光线击中某些几何形状，我们需要计算其表面颜色。我们向通过重要性采样选择的光源发射另一条光线。如果选择的光源是可见的，我们使用我们的标准光照模型计算表面的颜色。
- en: Since we are using only one sample per fragment, the final output will be noisy,
    especially since we are randomly selecting the reflected direction at each frame.
    For this reason, the output of the ray tracing step will be processed by a denoiser.
    We have implemented a technique called **spatiotemporal variance-guided filtering**
    (**SVGF**), which has been developed specifically for this use case. The algorithm
    will make use of spatial and temporal data to produce a result that contains only
    a small amount of noise.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们只为每个片段使用一个样本，最终输出将会是噪声的，尤其是因为我们随机选择反射方向。因此，光线追踪步骤的输出将通过去噪器进行处理。我们实现了一种称为**时空方差引导滤波**（**SVGF**）的技术，它专门为这种用途开发。该算法将利用空间和时间数据来生成一个包含少量噪声的结果。
- en: Finally, we use the denoised data during our lighting computation to retrieve
    the specular color.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在光照计算期间使用去噪数据来检索镜面颜色。
- en: 'Now that you have a good overview of the steps involved, let’s dive in! The
    first step is checking whether the roughness for a given fragment is above a certain
    threshold:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对涉及的步骤有了很好的了解，让我们深入探讨！第一步是检查给定片段的粗糙度是否高于某个阈值：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We have selected `0.3` as it gives us the results we are looking for, though
    feel free to experiment with other values. If this fragment is contributing to
    the reflection computation, we initialize our random number generator and compute
    the two values needed to sample the GGX distribution:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了`0.3`，因为它给出了我们想要的结果，尽管你可以自由地尝试其他值。如果这个片段对反射计算有贡献，我们初始化随机数生成器，并计算两个值以采样GGX分布：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The two random functions can be implemented as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 两个随机函数可以如下实现：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These two functions have been taken from the wonderful *Hash Functions for GPU
    Rendering* paper, which we highly recommend. It contains many other functions
    that you can experiment with. We selected this seed function so that we can use
    the fragment’s position.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数是从优秀的《GPU渲染的哈希函数》论文中提取的，我们强烈推荐。它包含许多其他你可以实验的函数。我们选择这个种子函数，以便我们可以使用片段的位置。
- en: 'Next, we need to pick our reflection vector. As mentioned previously, we have
    implemented two techniques. For the first technique, we simply reflect the view
    vector around the surface normal for a mirror-like surface. This can be computed
    as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要选择我们的反射向量。如前所述，我们已经实现了两种技术。对于第一种技术，我们只需将视向量围绕表面法线反射以模拟类似镜面的表面。这可以计算如下：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When using this method, we get the following output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用这种方法时，我们得到以下输出：
- en: '![Figure 15.1 – Mirror-like reflections ](img/B18395_15_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图15.1 – 类似镜面的反射](img/B18395_15_01.jpg)'
- en: Figure 15.1 – Mirror-like reflections
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1 – 类似镜子的反射
- en: 'The other method computes the normal by randomly sampling the GGX distribution:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法通过随机采样GGX分布来计算法线：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `sampleGGXVNDF` function has been taken from the *Sampling the GGX Distribution
    of Visible Normals* paper. Its implementation is clearly described in this paper;
    we suggest you read it for more details.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`sampleGGXVNDF`函数来自《采样可见法线的GGX分布》论文。其实现方式在这篇论文中有详细描述；我们建议您阅读以获取更多细节。'
- en: In brief, this method computes a random normal according to the BRDF of the
    material and the view direction. This process is needed to make sure the computed
    reflection is more physically accurate.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这种方法根据材料的BRDF和视图方向计算一个随机法线。这个过程是为了确保计算出的反射更加物理上准确。
- en: 'Next, we must trace a ray in the scene:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须在场景中追踪一条光线：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If the ray has a hit, we use importance sampling to select a light for our final
    color computation. The main idea behind importance sampling is to determine which
    element, which light in our case, is more likely to be selected based on a given
    probability distribution.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果光线有击中点，我们使用重要性采样来选择一个灯光用于最终颜色计算。重要性采样的主要思想是根据给定的概率分布确定哪个元素，在我们的情况下是哪个灯光，更有可能被选中。
- en: We have adopted the importance value described in the *Importance Sampling of
    Many Lights on the GPU* chapter from the book *Ray* *Tracing Gems*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了来自《Ray Tracing Gems》一书中“在GPU上对许多灯光进行重要性采样”章节中描述的重要性值。
- en: 'We start by looping through all the lights in the scene:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先遍历场景中的所有灯光：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we compute the angle between the light and the normal of the triangle
    that has been hit:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算光线与被击中三角形的法线之间的角度：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we compute the distance between the light and the fragment position in
    the world space:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算灯光与片段在世界空间中的位置之间的距离：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After, we use these two values to determine whether this light should be considered
    for this fragment:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用这两个值来确定是否应该考虑这个灯光：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next step involves computing an orientation parameter. This tells us whether
    the light is shining directly on the fragment or at an angle:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步涉及计算一个方向参数。这告诉我们灯光是直接照在片段上还是以某个角度照射：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we must compute the importance value by also taking into account the
    intensity of the light:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须通过考虑灯光的强度来计算重要性值：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If the given light is not considered active for this fragment, its importance
    will have a value of `0`. Finally, we must accumulate the importance value for
    this light:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果给定的灯光对于这个片段不被考虑为活动状态，其重要性值将为`0`。最后，我们必须累积这个灯光的重要性值：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have the importance values, we need to normalize them. Like any
    other probability distribution function, our values need to sum to `1`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了重要性值，我们需要对它们进行归一化。像任何其他概率分布函数一样，我们的值需要加起来等于`1`：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can now select the light to be used for this frame. First, we must generate
    a new random value:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以选择用于这个帧的灯光。首先，我们必须生成一个新的随机值：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we must loop through the lights and accumulate the importance of each
    light. Once the accumulated value is greater than our random value, we have found
    the light to use:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须遍历灯光并累积每个灯光的重要性。一旦累积值大于我们的随机值，我们就找到了要使用的灯光：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now that we have selected the light, we must cast a ray toward it to determine
    whether it’s visible or not. If it’s visible, we compute the final color for the
    reflected surface using our lighting model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经选择了灯光，我们必须向它发射一条光线以确定它是否可见。如果它是可见的，我们使用我们的光照模型计算反射表面的最终颜色。
- en: We compute the shadow factor as described in [*Chapter 13*](B18395_13.xhtml#_idTextAnchor213),
    *Revisiting Shadows with Ray Tracing*, and the color is calculated in the same
    way as in [*Chapter 14*](B18395_14.xhtml#_idTextAnchor241), *Adding Dynamic Diffuse
    Global Illumination with* *Ray Tracing*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算阴影因子，如[*第13章*](B18395_13.xhtml#_idTextAnchor213)中所述，“使用光线追踪重新审视阴影”，颜色计算方式与[*第14章*](B18395_14.xhtml#_idTextAnchor241)中相同，“使用光线追踪添加动态漫反射全局照明”。
- en: 'This is the result:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 15.2 – The noisy output of the ray tracing step](img/B18395_15_02.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图15.2 – 光线追踪步骤的噪声输出](img/B18395_15_02.jpg)'
- en: Figure 15.2 – The noisy output of the ray tracing step
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2 – 光线追踪步骤的噪声输出
- en: In this section, we illustrated our implementation of ray-traced reflections.
    First, we described two ways to select a ray direction. Then, we demonstrated
    how to use importance sampling to select the light to use in our computation.
    Finally, we described how the selected light is used to determine the final color
    of the reflected surface.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了我们实现的基于光线追踪的反射。首先，我们描述了选择射线方向的两个方法。然后，我们演示了如何使用重要性采样来选择用于计算的灯光。最后，我们描述了如何使用选定的灯光来确定反射表面的最终颜色。
- en: The result of this step will be noisy and cannot be used directly in our lighting
    computation. In the next section, we will implement a denoiser that will help
    us remove most of this noise.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的结果将会是噪声的，不能直接用于我们的光照计算。在下一节中，我们将实现一个降噪器，这将帮助我们移除大部分噪声。
- en: Implementing a denoiser
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现降噪器
- en: To make the output of our reflection pass usable for lighting computations,
    we need to pass it through a denoiser. We have implemented an algorithm called
    SVGF, which has been developed to reconstruct color data for path tracing.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的反射输出可用于光照计算，我们需要将其通过一个降噪器。我们实现了一个名为SVGF的算法，该算法是为了重建路径追踪中的颜色数据而开发的。
- en: 'SVGF consists of three main passes:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: SVGF由三个主要步骤组成：
- en: First, we compute the integrated color and moments for luminance. This is the
    temporal step of the algorithm. We combine the data from the previous frame with
    the result of the current frame.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们计算亮度积分颜色和矩。这是算法的时间步骤。我们将前一帧的数据与当前帧的结果相结合。
- en: Next, we compute an estimate for variance. This is done using the first and
    second moment values we computed in the first step.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们计算方差的估计值。这是通过使用我们在第一步中计算的第一和第二矩值来完成的。
- en: Finally, we perform five passes of a wavelet filter. This is the spatial step
    of the algorithm. At each iteration, we apply a 5x5 filter to reduce the remaining
    noise as much as possible.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们执行五次小波滤波器的步骤。这是算法的空间步骤。在每次迭代中，我们应用一个5x5滤波器，尽可能多地减少剩余的噪声。
- en: 'Now that you have an idea of the main algorithm, we can proceed with the code
    details. We start by computing the moments for the current frame:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了主要算法，我们可以继续处理代码细节。我们首先计算当前帧的矩：
- en: '[PRE16]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, we use the motion vectors value – the same values we computed in [*Chapter
    11*](B18395_11.xhtml#_idTextAnchor178), *Temporal Anti-Aliasing* – to determine
    whether we can combine the data for the current frame with the previous frame.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用运动矢量值——与我们在[*第11章*](B18395_11.xhtml#_idTextAnchor178)，“时间反走样”中计算出的相同值——来确定我们是否可以将当前帧的数据与前一帧的数据合并。
- en: 'First, we compute the position on the screen of the previous frame:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们计算前一帧在屏幕上的位置：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we check whether the old fragment coordinates are valid:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们检查旧的片段坐标是否有效：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we check whether the mesh ID is consistent with the previous frame:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们检查网格ID是否与前一顿一致：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, we check for large depth discontinuities, which can be caused by disocclusion
    from the previous frame. We make use of the difference between the current and
    previous frame’s depth, and also of the screen space derivative of the depth for
    the current frame:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们检查是否存在大的深度不连续性，这可能是由于前一帧的遮挡造成的。我们利用当前帧和前一帧深度之间的差异，以及当前帧深度在屏幕空间中的导数：
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The last consistency check is done by using the normal value:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的一致性检查是通过使用法线值来完成的：
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'If all of these tests pass, this means the values from the previous frame can
    be used for temporal accumulation:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有这些测试都通过，这意味着前一帧的值可以用于时间累积：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If the consistency check fails, we will only use the data from the current
    frame:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一致性检查失败，我们只将使用当前帧的数据：
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This concludes the accumulation pass. This is the output we obtain:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了累积步骤。这是我们获得的结果：
- en: '![Figure 15.3 – The color output after the accumulation step](img/B18395_15_03.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图15.3 – 累积步骤后的颜色输出](img/B18395_15_03.jpg)'
- en: Figure 15.3 – The color output after the accumulation step
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.3 – 累积步骤后的颜色输出
- en: 'The next step is to compute the variance. This can easily be done as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算方差。这可以很容易地按照以下方式完成：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now that we have our accumulated value, we can start implementing the wavelet
    filter. As mentioned previously, this is a 5x5 cross-bilateral filter. We start
    with the familiar double loop, being careful not to access out-of-bounds values:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了累积值，我们可以开始实现小波滤波器。如前所述，这是一个5x5交叉双边滤波器。我们从一个熟悉的双重循环开始，注意不要访问越界值：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we compute the filter kernel value and weighting value, `w`:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算滤波器核值和加权值，`w`：
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We’ll explain the implementation of the weighting function in a moment. Next,
    we load the integrated color and variance for the given fragment:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后解释加权函数的实现。接下来，我们加载给定片段的集成颜色和方差：
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Lastly, we accumulate the new color and variance values:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们累积新的颜色和方差值：
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Before storing the newly computed values, we need to divide them by the accumulated
    weight:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储新计算出的值之前，我们需要将它们除以累积的权重：
- en: '[PRE29]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We repeat this process five times. The resulting color output will be used for
    our lighting computation for the specular color.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复这个过程五次。生成的颜色输出将被用于我们的镜面颜色光照计算。
- en: 'As promised, we are now going to look at the weight computation. There are
    three elements to the weight: normal, depth, and luminance. In the code, we tried
    to follow the naming from the paper so that it’s easier to match with our implementation
    of the formulas.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正如承诺的那样，我们现在将查看权重计算。权重有三个要素：法线、深度和亮度。在代码中，我们尽量遵循论文中的命名，以便更容易与我们的公式实现相匹配。
- en: 'We start with the normals:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从法线开始：
- en: '[PRE30]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We compute the cosine between the normal of the current fragment and the fragment
    from the filter to determine the weight of the normal component.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算当前片段的法线与过滤器中片段之间的余弦值，以确定法线成分的权重。
- en: 'We look at depth next:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来关注深度：
- en: '[PRE31]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: In a similar fashion to the accumulation step, we make use of the difference
    between the depth values between two fragments. The screen-space derivative is
    also included. As before, we want to penalize large depth discontinuities.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 与累积步骤类似，我们利用两个片段之间的深度值之间的差异。屏幕空间导数也被包括在内。像以前一样，我们想要惩罚大的深度不连续性。
- en: 'The last weight element is luminance. We start by computing the luminance for
    the fragments we are processing:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个权重元素是亮度。我们首先计算我们正在处理的片段的亮度：
- en: '[PRE32]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we pass the variance value through a Gaussian filter to reduce instabilities:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将方差值通过高斯滤波器传递以减少不稳定性：
- en: '[PRE33]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, we compute the luminance weight and combine it with the other two
    weight values:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算亮度权重并将其与其他两个权重值结合：
- en: '[PRE34]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This concludes our implementation of the SVGF algorithm. After five passes,
    we get the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了SVGF算法的实现。经过五次迭代后，我们得到以下输出：
- en: '![Figure 15.4 – The output at the end of the denoising step](img/B18395_15_04.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图15.4 – 去噪步骤结束时的输出](img/B18395_15_04.jpg)'
- en: Figure 15.4 – The output at the end of the denoising step
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.4 – 去噪步骤结束时的输出
- en: 'In this section, we described how to implement a common denoising algorithm.
    The algorithm consists of three passes: an accumulation phase for the color and
    luminance moments, a step for computing luminance variance, and a step for the
    wavelet filter, which is repeated five times.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了如何实现一个常见的去噪算法。该算法包括三个步骤：一个用于颜色和亮度矩的累积阶段，一个用于计算亮度方差，以及一个用于小波滤波的步骤，该步骤重复五次。
- en: Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we described how to implement ray-traced reflections. We started
    with an overview of screen-space reflection, a technique that was used for many
    years before ray tracing hardware was available. We explained how it works and
    some of its limitations.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了如何实现光线追踪反射。我们从一个概述开始，即屏幕空间反射，这是一种在光线追踪硬件可用之前使用了多年的技术。我们解释了它是如何工作的以及它的局限性。
- en: Next, we described our ray tracing implementation to determine reflection values.
    We provided two methods to determine the reflected ray direction and explained
    how the reflected color is computed if a hit is returned.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们描述了我们的光线追踪实现以确定反射值。我们提供了两种确定反射射线方向的方法，并解释了如果返回一个碰撞，如何计算反射颜色。
- en: Since we only use one sample per fragment, the result of this step is noisy.
    To reduce as much of this noise as possible, we implemented a denoiser based on
    SVGF. This technique consists of three passes. First, there’s a temporal accumulation
    step to compute color and luminance moments. Then, we compute the luminance variance.
    Finally, we process the color output by passing it through five iterations of
    a wavelet filter.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只为每个片段使用一个样本，因此这一步骤的结果是噪声的。为了尽可能减少这种噪声，我们实现了一个基于SVGF的去噪器。这项技术包括三个步骤。首先，有一个时间累积步骤来计算颜色和亮度矩。然后，我们计算亮度方差。最后，我们通过五个小波滤波器的迭代来处理颜色输出。
- en: This chapter also concludes our book! We hope you enjoyed reading it as much
    as we had fun writing it. When it comes to modern graphics techniques, there is
    only so much that can be covered in a single book. We have included what we thought
    are some of the most interesting features and techniques when it comes to implementing
    them in Vulkan. Our goal is to provide you with a starting set of tools that you
    can build and expand upon. We wish you a wonderful journey on the path to mastering
    graphics programming!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本章也标志着我们书籍的结束！我们希望您阅读这本书的乐趣与我们写作时的乐趣一样。当谈到现代图形技术时，一本书中能涵盖的内容是有限的。我们包括了我们认为在Vulkan中实现时最有趣的一些特性和技术。我们的目标是为您提供一套可以构建和扩展的工具。我们祝愿您在掌握图形编程的道路上有一个美好的旅程！
- en: We very much welcome your feedback and corrections, so please feel free to reach
    out to us.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常欢迎您的反馈和纠正，所以请随时与我们联系。
- en: Further reading
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'We have only provided a brief introduction to screen-space reflections. The
    following articles go into more detail about their implementation, their limitations,
    and how to improve the final results:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只提供了屏幕空间反射的简要介绍。以下文章更详细地介绍了它们的实现、局限性以及如何改进最终结果：
- en: '[https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.xhtml](https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.xhtml)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.xhtml](https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.xhtml)'
- en: '[https://bartwronski.com/2014/01/25/the-future-of-screenspace-reflections/](https://bartwronski.com/2014/01/25/the-future-of-screenspace-reflections/)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://bartwronski.com/2014/01/25/the-future-of-screenspace-reflections/](https://bartwronski.com/2014/01/25/the-future-of-screenspace-reflections/)'
- en: '[https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/](https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/](https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/)'
- en: 'We have only used one of the many hashing techniques presented in the paper
    *Hash Functions for GPU* *Rendering*: [https://jcgt.org/published/0009/03/02/](https://jcgt.org/published/0009/03/02/).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只使用了论文《GPU渲染的哈希函数》中介绍的许多哈希技术之一：[https://jcgt.org/published/0009/03/02/](https://jcgt.org/published/0009/03/02/)。
- en: 'This link contains more details about the sampling technique we used to determine
    the reflection vector by sampling the BRDF – *Sampling the GGX Distribution of
    Visible* *Normals*: [https://jcgt.org/published/0007/04/01/](https://jcgt.org/published/0007/04/01/).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此链接包含了更多关于我们用来通过采样BRDF确定反射向量的采样技术细节：*采样可见法线的GGX分布*：[https://jcgt.org/published/0007/04/01/](https://jcgt.org/published/0007/04/01/)。
- en: 'For more details about the SVGF algorithm we presented, we recommend reading
    the original paper and supporting material: [https://research.nvidia.com/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced](https://research.nvidia.com/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们介绍的SVGF算法的更多细节，我们建议阅读原始论文和相关材料：[https://research.nvidia.com/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced](https://research.nvidia.com/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced)。
- en: 'We used importance sampling to determine which light to use at each frame.
    Another technique that has become popular in the last few years is **Reservoir
    Spatio-Temporal Importance Resampling** (**ReSTIR**). We highly recommend reading
    the original paper and looking up the other techniques that have been inspired
    by it: [https://research.nvidia.com/publication/2020-07_spatiotemporal-reservoir-resampling-real-time-Ray-Tracing-dynamic-direct](https://research.nvidia.com/publication/2020-07_spatiotemporal-reservoir-resampling-real-time-Ray-Tracing-dynamic-direct).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了重要性采样来确定每一帧使用哪种光线。在过去几年中变得流行的一种技术是**水库时空重要性重采样**（**ReSTIR**）。我们强烈建议您阅读原始论文并查找受其启发的其他技术：[https://research.nvidia.com/publication/2020-07_spatiotemporal-reservoir-resampling-real-time-Ray-Tracing-dynamic-direct](https://research.nvidia.com/publication/2020-07_spatiotemporal-reservoir-resampling-real-time-Ray-Tracing-dynamic-direct)。
- en: 'In this chapter, we implemented the SVGF algorithm from scratch for pedagogical
    purposes. Our implementation is a good starting point to build upon, but we also
    recommend looking at production denoisers from AMD and Nvidia to compare results:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为了教学目的从头开始实现了SVGF算法。我们的实现是一个很好的起点，但我们也建议查看AMD和Nvidia的生产级去噪器以比较结果：
- en: '[https://gpuopen.com/fidelityfx-denoiser/](https://gpuopen.com/fidelityfx-denoiser/)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPUOpen FidelityFX Denoiser](https://gpuopen.com/fidelityfx-denoiser/)'
- en: '[https://developer.nvidia.com/rtx/Ray-Tracing/rt-denoisers](https://developer.nvidia.com/rtx/Ray-Tracing/rt-denoisers)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NVIDIA RTX 光线追踪的 RT-Denoiser](https://developer.nvidia.com/rtx/Ray-Tracing/rt-denoisers)'
