- en: Performance
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 性能
- en: One of the most common reasons to choose C++ as a key programming language for
    a project is due to performance requirements. C++ has a clear edge over the competition
    when it comes to performance, but achieving the best results requires understanding
    relevant problems. This chapter focuses on increasing the performance of C++ software.
    We'll start by showing you tools for measuring performance. We'll show you a few
    techniques for increasing single-threaded compute speed. Then we'll discuss how
    to make use of parallel computing. Finally, we'll show how you can use C++20's
    coroutines for non-preemptive multitasking.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 选择C++作为项目的关键编程语言的最常见原因之一是出于性能要求。在性能方面，C++比竞争对手明显更有优势，但要取得最佳结果需要理解相关问题。本章重点介绍如何提高C++软件的性能。我们将首先向您展示用于测量性能的工具。我们将向您展示一些增加单线程计算速度的技术。然后我们将讨论如何利用并行计算。最后，我们将展示如何使用C++20的协程进行非抢占式多任务处理。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Measuring performance
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能测量
- en: Helping the compiler generate performant code
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助编译器生成高性能代码
- en: Parallelizing computations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行计算
- en: Using coroutines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用协程
- en: First, let's specify what you'll need to run the examples in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们指定在本章中运行示例所需的内容。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To replicate the examples from this chapter, you should install the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要复制本章中的示例，您应安装以下内容：
- en: CMake 3.15+
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake 3.15+
- en: A compiler supporting C++20's ranges and coroutines, for instance, GCC 10+
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C++20的范围和协程的编译器，例如GCC 10+
- en: The source code snippets from the chapter can be found at [https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter11](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter11).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码片段可以在[https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter11](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter11)找到。
- en: Measuring performance
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能测量
- en: To effectively improve the performance of your code, you must start by measuring
    how it performs. Without knowing where the actual bottlenecks are, you will end
    up optimizing the wrong places, losing time, and getting surprised and frustrated
    that your hard work gave little to no gains. In this section, we'll show how to
    properly measure performance using benchmarks, how to successfully profile your
    code, and how to gain insights into performance in distributed systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效地提高代码的性能，您必须首先测量其性能。如果不知道实际瓶颈在哪里，最终会优化错误的地方，浪费时间，并且会对您的辛勤工作几乎没有收获感到惊讶和沮丧。在本节中，我们将展示如何使用基准测试正确测量性能，如何成功地对代码进行分析，并如何深入了解分布式系统的性能。
- en: Performing accurate and meaningful measurements
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行准确和有意义的测量
- en: 'For accurate and repeatable measurements, you might also want to put your machine
    into performance mode instead of the usual default power-saving one. If you require
    low latency from your system, you might want to disable power saving permanently
    on both the machines you benchmark on and in your production environment. Many
    times this may mean going into BIOS and configuring your server properly. Note
    that this may not be possible if you use a public cloud provider. If you have
    root/admin permissions on your machine, the OS can often steer some of the settings
    too. For instance, you can force your CPU to run with its maximum frequency on
    a Linux system by running the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得准确和可重复的测量结果，您可能还希望将计算机置于性能模式，而不是通常的默认节能模式。如果您需要系统低延迟，您可能希望永久禁用两台机器上的节能模式，并在生产环境中禁用节能模式。许多时候，这可能意味着进入BIOS并正确配置服务器。请注意，如果您使用公共云提供商，则可能无法做到这一点。如果您在计算机上拥有root/admin权限，操作系统通常也可以调整一些设置。例如，您可以通过在Linux系统上运行以下命令来强制CPU以最大频率运行：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Moreover, to obtain meaningful results, you might want to perform measurements
    on a system that as closely resembles your production environment as possible.
    Aside from configuration, aspects such as the different speeds of RAM, the number
    of CPU caches, and the microarchitecture of your CPUs can also skew your results
    and lead you to incorrect conclusions. The same goes for the hard drive setup
    and even the network topology and hardware used. The software you build on also
    plays a crucial role: from the firmware used, through the OS and kernel, all the
    way up the software stack to your dependencies. It''s best to have a second environment
    that''s identical to your production one and governed using the same tools and
    scripts.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了获得有意义的结果，您可能希望在尽可能接近生产环境的系统上进行测量。除了配置之外，诸如RAM的不同速度、CPU缓存的数量和CPU的微体系结构等方面也可能扭曲您的结果，并导致您得出错误的结论。硬盘设置、甚至网络拓扑和使用的硬件也是如此。您构建的软件也起着至关重要的作用：从固件使用，通过操作系统和内核，一直到软件堆栈和依赖项。最好有一个与您的生产环境相同的第二个环境，并使用相同的工具和脚本进行管理。
- en: Now that we have a solid environment for taking measurements, let's see what
    we can actually measure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了一个稳固的测量环境，让我们看看我们实际上可以测量些什么。
- en: Leveraging different types of measuring tools
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用不同类型的测量工具
- en: There are several ways to measure performance, each focusing on a different
    scope. Let's go through them one by one.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种测量性能的方法，每种方法都侧重于不同的范围。让我们逐一看看它们。
- en: 'Benchmarks can be used to time the speed of your system in a pre-made test.
    Usually, they result in either a time to finish or another performance metric
    such as orders processed per second. There are several types of benchmarks:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试可用于测试系统在预先制定的测试中的速度。通常，它们会导致完成时间或每秒处理的订单等性能指标。有几种类型的基准测试：
- en: '**Microbenchmarks,** which you can use to measure the execution of a small
    code fragment. We''ll cover them in the next section.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微基准测试**，您可以用它来测量小代码片段的执行。我们将在下一节中介绍它们。'
- en: '**Simulations,** which are synthetic tests on a larger scale with artificial
    data. They can be useful if you don''t have access to the target data or your
    target hardware. For instance, when you are planning to check the performance
    of hardware that you''re working on, but it doesn''t exist yet, or when you plan
    to handle incoming traffic, but can only assume how the traffic will look.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模拟**，这是对较大规模的人工数据进行的合成测试。如果您无法访问目标数据或目标硬件，它们可能会很有用。例如，当您计划检查您正在开发的硬件的性能，但它尚不存在，或者当您计划处理传入的流量，但只能假设流量的情况时。'
- en: '**Replays,** which can be a very accurate way of measuring performance under
    the real-life workload. The idea is to record all the requests or workloads coming
    into the production system, often with timestamps. Such dumps can then later be
    "replayed" into the benchmarked system, respecting the time differences between
    them, to check how it performs. Such benchmarks can be great to see how potential
    changes to code or the environment can influence the latency and throughput of
    your system.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重放**，这是一种非常准确的衡量真实工作负载下性能的方法。其思想是记录进入生产系统的所有请求或工作负载，通常带有时间戳。然后可以将这些转储“重放”到基准系统中，尊重它们之间的时间差异，以检查其性能。这样的基准测试可以很好地看到代码或环境的潜在变化如何影响系统的延迟和吞吐量。'
- en: '**Industry-standard**, which is a good way to see how our product performs
    compared to its competitors. Examples of such benchmarks include SuperPi for CPUs,
    3D Mark for graphic cards, and ResNet-50 for artificial intelligence processors.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行业标准**，这是一个很好的方法，可以看到我们的产品与竞争对手相比的表现。此类基准测试的示例包括用于CPU的SuperPi，用于图形卡的3D Mark以及用于人工智能处理器的ResNet-50。'
- en: Aside from benchmarking, another type of tool that is invaluable when it comes
    to measuring performance is profilers. Instead of just giving you overall performance
    metrics, profilers allow you to examine what your code is doing and look for bottlenecks.
    They're useful for catching unexpected things that slow your system down. We'll
    cover them in more detail later in this chapter.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基准测试之外，另一种在衡量性能时非常宝贵的工具是性能分析器。性能分析器不仅可以为您提供整体性能指标，还可以让您检查代码的执行情况并寻找瓶颈。它们对于捕捉减慢系统速度的意外情况非常有用。我们将在本章后面更详细地介绍它们。
- en: 'The last way to grasp your system''s performance is tracing. Tracing is essentially
    a way to log your system''s behavior during execution. By monitoring how long
    it takes for a request to complete various steps of processing (such as being
    handled by different types of microservices), you can gain insight into what parts
    of your system need to improve their performance, or how well your system deals
    with different kinds of requests: either different types or those that get accepted
    or rejected. We''ll cover tracing later in this chapter – right after profiling.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握系统性能的最后一种方法是追踪。追踪本质上是在执行过程中记录系统行为的一种方式。通过监视请求完成各个处理步骤所需的时间（例如由不同类型的微服务处理），您可以洞察系统哪些部分需要改进性能，或者您的系统如何处理不同类型的请求：无论是不同类型的请求还是被接受或拒绝的请求。我们将在本章后面介绍追踪
    - 就在性能分析之后。
- en: Let's now say a few more words on microbenchmarks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们再多说几句关于微基准。
- en: Using microbenchmarks
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用微基准测试
- en: Microbenchmarks are used to measure how fast a "micro" fragment of code can
    perform. If you're wondering how to implement a given functionality or how fast
    different third-party libraries deal with the same task, then they're the perfect
    tool for the job. While they're not representative of a realistic environment,
    they're well suited to perform such small experiments.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 微基准测试用于衡量“微”代码片段的执行速度。如果您想知道如何实现特定功能，或者不同的第三方库如何处理相同的任务的速度，那么它们是完成此任务的完美工具。虽然它们不能代表真实环境，但它们非常适合执行这样的小型实验。
- en: 'Let''s show how to run such experiments using one of the most commonly used
    frameworks to create microbenchmarks in C++: Google Benchmark.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们展示如何使用C++中最常用的框架之一来运行这样的实验：Google Benchmark。
- en: Setting up Google Benchmark
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置Google Benchmark
- en: 'Let''s start by introducing the library into our code by using Conan. Put the
    following in your `conanfile.txt`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先通过Conan将库引入我们的代码中。将以下内容放入您的`conanfile.txt`中：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We''re going to use the CMakeDeps generator as it''s the recommended CMake
    generator in Conan 2.0\. It relies on CMake''s `find_package` feature to use the
    packages installed by our barbaric dependency manager. To install the dependencies
    in their release versions, run the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用CMakeDeps生成器，因为它是Conan 2.0中推荐的CMake生成器。它依赖于CMake的`find_package`功能来使用我们的原始依赖管理器安装的软件包。要安装它们的发布版本的依赖项，请运行以下命令：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you're using a custom Conan profile, remember to add it here as well.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用自定义的Conan配置文件，请记得在这里也添加它。
- en: 'Using it from your `CMakeLists.txt` file is also pretty straightforward, as
    shown next:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从您的`CMakeLists.txt`文件中使用它也非常简单，如下所示：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, we add our build directory to `CMAKE_PREFIX_PATH` so that CMake can find
    the config and/or target files produced by Conan. Next, we just use them to find
    our dependency.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将我们的构建目录添加到`CMAKE_PREFIX_PATH`中，以便CMake可以找到Conan生成的配置文件和/或目标文件。接下来，我们只需使用它们来找到我们的依赖项。
- en: 'As we''re going to create several microbenchmarks, we could use a CMake function
    to help us with defining them:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将创建多个微基准测试，我们可以使用一个CMake函数来帮助我们定义它们：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The function will be able to create single-translation-unit microbenchmarks,
    each using C++20 and linked to the Google Benchmark library. Let''s now use it
    to create our first microbenchmark executable:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将能够创建单一翻译单元的微基准测试，每个测试都使用C++20并链接到Google Benchmark库。现在让我们使用它来创建我们的第一个微基准测试可执行文件：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we're ready to put some code in our source file.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备在源文件中放入一些代码。
- en: Writing your first microbenchmark
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写您的第一个微基准测试
- en: 'We''ll try to benchmark how much faster a lookup takes when it''s done using
    bisection in a sorted vector as compared to just going through it linearly. Let''s
    start with code that will create the sorted vector:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试基准测试使用二分法在排序向量中进行查找时需要多快，与仅线性查找相比。让我们从创建排序向量的代码开始：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Our vector will contain size elements with all the numbers from 0 to size -
    1 in ascending order. Let''s now specify the element we''re looking for and the
    container size:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的向量将包含大小元素，所有数字从0到大小-1按升序排列。现在让我们指定我们要查找的元素和容器的大小：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see, we''ll benchmark how long it takes to find a needle in a haystack.
    The simple linear search can be implemented as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们将基准测试在干草垛中查找针需要多长时间。简单的线性搜索可以实现如下：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, we can see the first use of Google Benchmark. Each microbenchmark should
    accept `State` as an argument. This special type does the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到Google Benchmark的第一次使用。每个微基准测试应该接受`State`作为参数。这种特殊类型执行以下操作：
- en: Contains information about the iterations performed and the time spent on the
    measured computation
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含执行的迭代和测量计算所花费的时间的信息
- en: Counts the bytes processed if wanted
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算所处理的字节数
- en: Can return other state information, such as the need to run further (through
    the `KeepRunning()` member function)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，可以返回其他状态信息，例如需要进一步运行（通过`KeepRunning()`成员函数）
- en: Can be used to pause and resume the timing of an iteration (through the `PauseTiming()`
    and `ResumeTiming()` member functions, respectively)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以用于暂停和恢复迭代的计时（分别通过`PauseTiming()`和`ResumeTiming()`成员函数）
- en: The code in our loop will be measured, making as many iterations as desired,
    based on the total allowed time to run this particular benchmark. The creation
    of our haystack is outside the loop and won't be measured.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的循环中的代码将被测量，根据允许运行此特定基准测试的总时间进行所需的迭代。我们的干草垛的创建在循环外部，不会被测量。
- en: Inside the loop, there's a sink helper named `DoNotOptimize`. Its purpose is
    to ensure the compiler doesn't get rid of our computations as it can prove that
    they are irrelevant outside of this scope. In our case, it will mark the result
    of `std::find` necessary, so the actual code to find the needle is not optimized
    away. Using tools such as objdump or sites such as Godbolt and QuickBench allows
    you to peek if the code you want to run wasn't optimized out. QuickBench has the
    additional advantage of running your benchmarks in the cloud and sharing their
    results online.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环内部，有一个名为`DoNotOptimize`的辅助函数。它的目的是确保编译器不会摆脱我们的计算，因为它可以证明它们在这个范围之外是无关紧要的。在我们的情况下，它将标记`std::find`的结果是必要的，所以实际用于查找目标的代码不会被优化掉。使用诸如objdump或诸如Godbolt和QuickBench的网站等工具，可以查看您想要运行的代码是否已被优化掉。QuickBench的额外优势在于在云中运行您的基准测试并在线共享其结果。
- en: 'Back to our task at hand, we have a microbenchmark for the linear search, so
    let''s now time the binary search in another microbenchmark:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们手头的任务，我们有一个线性搜索的微基准测试，所以现在让我们在另一个微基准测试中计时二进制搜索：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Our new benchmark is pretty similar. It only differs in the function used:
    `lower_bound` will perform a binary search. Note that similar to our base example,
    we don''t even check if the iterator returned points to a valid element in the
    vector, or to its end. In the case of `lower_bound`, we could check if the element
    under the iterator is actually the one we''re looking for.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新基准测试非常相似。它只在使用的函数上有所不同：`lower_bound`将执行二进制搜索。请注意，与我们的基本示例类似，我们甚至不检查迭代器返回的指向向量中的有效元素，还是指向其末尾。在`lower_bound`的情况下，我们可以检查迭代器下的元素是否实际上是我们要查找的元素。
- en: 'Now that we have the microbenchmark functions, let''s create actual benchmarks
    out of them by adding the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了微基准测试函数，让我们通过添加以下内容将它们创建为实际的基准测试：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If the default benchmark settings are okay with you, that''s all you need to
    pass. As the last step, let''s add a `main()` function:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果默认的基准测试设置对您来说没问题，那么您只需要通过。作为最后一步，让我们添加一个`main()`函数：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Simple as that! Alternatively, you can link our program with `benchmark_main`
    instead. Using Google Benchmark''s `main()` function has the advantage of providing
    us with some default options. If you compile our benchmark and run it passing
    `--help` as a parameter, you''ll see the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这么简单！或者，您也可以链接我们的程序而不是`benchmark_main`。使用Google Benchmark的`main()`函数的优点是提供了一些默认选项。如果编译我们的基准测试并在传递`--help`作为参数运行它，您将看到以下内容：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is a nice set of features to use. For example, when designing experiments,
    you can use the `benchmark_format` switch to get a CSV output for easier plotting
    on a chart.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一组很好的功能。例如，在设计实验时，您可以使用`benchmark_format`开关获取CSV输出，以便更容易绘制图表。
- en: 'Let''s now see our benchmark in action by running the compiled executable with
    no command-line arguments. A possible output from running `./microbenchmark_1`
    is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过在编译后的可执行文件上不带命令行参数来看看我们的基准测试的运行情况。运行`./microbenchmark_1`的可能输出如下：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Starting with some data about the running environment (the time of benchmarking,
    the executable name, the server's CPUs, and the current load), we get to the results
    of each benchmark we defined. For each benchmark, we get the average wall time
    per iteration, the average CPU time per iteration, and the number of iterations
    that the benchmark harness ran for us. By default, the longer a single iteration,
    the fewer iterations it will go through. Running more iterations ensures you get
    more stable results.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从运行环境的一些数据开始（基准测试的时间、可执行文件名称、服务器的CPU和当前负载），我们得到了我们定义的每个基准测试的结果。对于每个基准测试，我们得到每次迭代的平均墙时间、每次迭代的平均CPU时间以及基准测试运行的迭代次数。默认情况下，单次迭代时间越长，迭代次数就越少。运行更多的迭代可以确保您获得更稳定的结果。
- en: Passing arbitrary arguments to a microbenchmark
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将任意参数传递给微基准测试
- en: If we were to test more ways of dealing with our problem at hand, we could look
    for a way to reuse the benchmark code and just pass it to the function used to
    perform the lookup. Google Benchmark has a feature that we could use for that.
    The framework actually lets us pass any arguments we want to the benchmark by
    adding them as additional parameters to the function signature.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要测试处理手头问题的更多方法，我们可以寻找一种重用基准代码并将其传递给执行查找的函数的方法。Google Benchmark具有一个我们可以使用的功能。该框架实际上允许我们通过将它们作为函数签名的附加参数来传递任何参数给基准。
- en: 'Let''s see how a unified signature for our benchmark could look with this feature:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用此功能的我们的基准的统一签名会是什么样子：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can notice the new `finder` parameter to the function, which is used in
    the spot where we previously called either `find` or `lower_bound`. We can now
    make our two microbenchmarks using a different macro than we did last time:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以注意到函数的新`finder`参数，它用于我们之前调用`find`或`lower_bound`的位置。现在我们可以使用与上次不同的宏来创建我们的两个微基准测试：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `BENCHMARK_CAPTURE` macro accepts the function, a name suffix, and the
    arbitrary number of parameters. If we wanted more, we could just pass them here.
    Our benchmark function could be a regular function or a template – both are supported.
    Let''s now see what we get when running the code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`BENCHMARK_CAPTURE`宏接受函数、名称后缀和任意数量的参数。如果我们需要更多，我们可以在这里传递它们。我们的基准函数可以是常规函数或模板-两者都受支持。现在让我们看看在运行代码时我们会得到什么：'
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see the arguments passed to the functions are not part of the name,
    but the function name and our suffix are.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，传递给函数的参数不是名称的一部分，而是函数名称和我们的后缀。
- en: Let's now see how we can further customize our benchmarks.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何进一步定制我们的基准测试。
- en: Passing numeric arguments to a microbenchmark
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将数值参数传递给微基准测试
- en: 'A common need when designing experiments like ours is to check it on different
    sizes of arguments. Such needs can be addressed in Google Benchmark in a number
    of ways. The simplest is to just add a call to `Args()` on the object returned
    by the `BENCHMARK` macros. This way, we can pass a single set of values to use
    in a given microbenchmark. To use the passed value, we''d need to change our benchmark
    function as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 设计类似我们的实验时的一个常见需求是在不同大小的参数上进行检查。在Google Benchmark中可以通过多种方式来满足这些需求。最简单的方法就是在`BENCHMARK`宏返回的对象上添加一个调用`Args()`。这样，我们可以传递一组值来在给定的微基准测试中使用。要使用传递的值，我们需要将我们的基准函数更改如下：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The call to `state.range(0)` will read the 0-th argument passed. An arbitrary
    number can be supported. In our case, it''s used to parameterize the haystack
    size. What if we wanted to pass a range of value sets instead? This way, we could
    see how changing the size influences the performance more easily. Instead of calling
    `Args`, we could call `Range` on the benchmark:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对`state.range(0)`的调用将读取传递的第0个参数。可以支持任意数量。在我们的情况下，它用于参数化干草堆的大小。如果我们想要传递一系列值集合呢？这样，我们可以更容易地看到改变大小如何影响性能。我们可以调用`Range`而不是`Args`来进行基准测试：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We specify the range boundaries using a predefined minimum and maximum. We
    then tell the benchmark harness to create the ranges by multiplying by 10 instead
    of the default value. When we run such benchmarks, we could get the following
    results:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用预定义的最小值和最大值来指定范围边界。然后我们告诉基准测试工具通过乘以10来创建范围，而不是使用默认值。当我们运行这样的基准测试时，可能会得到以下结果：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: When analyzing those results, you might be wondering why the linear search doesn't
    show us linear growth. That's because we look for a constant value of the needle
    that can be spotted at a constant position. If the haystack contains our needle,
    we need the same number of operations to find it regardless of the haystack size,
    so the execution time stops growing (but can still be subject to small fluctuations).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析这些结果时，您可能会想知道为什么线性搜索没有显示出线性增长。这是因为我们寻找一个可以在恒定位置被发现的针的恒定值。如果干草堆中包含我们的针，我们需要相同数量的操作来找到它，无论干草堆的大小如何，因此执行时间停止增长（但仍可能受到小波动的影响）。
- en: Why not play with the needle position as well?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不也尝试一下针的位置呢？
- en: Generating the passed arguments programmatically
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 以编程方式生成传递的参数
- en: Generating both the haystack sizes and needle positions might be the easiest
    when done in a simple function. Google Benchmark allows such scenarios, so let's
    show how they work in practice.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个简单的函数中生成干草堆大小和针位置可能是最简单的。Google Benchmark允许这样的场景，让我们看看它们在实践中是如何工作的。
- en: 'Let''s first rewrite our benchmark function to use two parameters passed in
    each iteration:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先重写我们的基准函数，以便在每次迭代中传递两个参数：
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As you can see, `state.range(0)` will mark our needle position, while `state.range(1)`
    will be the haystack size. This means we need to pass two values each time. Let''s
    create a function that generates them:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`state.range(0)`将标记我们的针位置，而`state.range(1)`将是干草堆的大小。这意味着我们需要每次传递两个值。让我们创建一个生成它们的函数：
- en: '[PRE21]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Instead of using `Range` and `RangeMultiplier`, we write a loop to generate
    the haystack sizes, this time increasing them by 100 each time. When it comes
    to the needles, we use three positions in proportionate positions of the haystack
    and one that falls outside of it. We call `Args` on each loop iteration, passing
    both the generated values.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不使用`Range`和`RangeMultiplier`，而是编写一个循环来生成干草堆的大小，这次每次增加100。至于针，我们使用干草堆的成比例位置中的三个位置和一个落在干草堆之外的位置。我们在每次循环迭代中调用`Args`，传递生成的值。
- en: 'Now, let''s apply our generator function to the benchmarks we define:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将我们的生成函数应用于我们定义的基准测试：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Using such functions makes it easy to pass the same generator to many benchmarks.
    Possible results of such benchmarks are as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的函数可以轻松地将相同的生成器传递给许多基准测试。这样的基准测试可能的结果如下：
- en: '[PRE23]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now we have a pretty well-defined experiment for performing the searches. As
    an exercise, run the experiment on your own machine to see the complete results
    and try to draw some conclusions from the results.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个非常明确定义的实验来执行搜索。作为练习，在您自己的机器上运行实验，以查看完整的结果，并尝试从结果中得出一些结论。
- en: Choosing what to microbenchmark and optimize
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择微基准测试和优化的对象
- en: 'Running such experiments can be educative and even addictive. However, keep
    in mind that microbenchmarks shouldn''t be the only type of performance testing
    in your project. As Donald Knuth famously said:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这样的实验可能是有教育意义的，甚至会让人上瘾。但请记住，微基准测试不应该是项目中唯一的性能测试类型。正如唐纳德·克努斯所说：
- en: '*We should forget about small efficiencies, say about 97% of the time: premature
    optimization is the root of all evil*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们应该忘记小的效率，大约97%的时间：过早的优化是万恶之源*'
- en: This means that you should microbenchmark only code that matters, especially
    code on your hot path. Larger benchmarks, along with tracing and profiling, can
    be used to see where and when to optimize instead of guessing and optimizing prematurely.
    First, understand how your software executes.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着您应该只对重要的代码进行微基准测试，特别是您的热路径上的代码。较大的基准测试，以及跟踪和探测，可以用来查看何时何地进行优化，而不是猜测和过早优化。首先，了解您的软件是如何执行的。
- en: 'NOTE: There''s one more point we want to make regarding the quote above. It
    doesn''t mean you should allow premature *pessimization*. Poor choice of data
    structures or algorithms, or even small inefficiencies that spread all your code,
    can sometimes influence the overall performance of your system. For instance,
    performing unnecessary dynamic allocations, although it might not look that bad
    at first, can lead to heap fragmentation over time and cause you serious trouble
    if your app should run for long periods of time. Overuse of node-based containers
    can lead to more cache misses too. Long story short, if it''s not a big effort
    to write efficient code instead of less efficient code, go for it.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：关于上面的引用，我们还想再提一个观点。这并不意味着您应该允许过早的*恶化*。数据结构或算法的选择不佳，甚至是散布在所有代码中的小的低效率，有时可能会影响系统的整体性能。例如，执行不必要的动态分配，虽然一开始看起来可能不那么糟糕，但随着时间的推移可能会导致堆碎片化，并在应用程序长时间运行时给您带来严重的麻烦。过度使用基于节点的容器也可能导致更多的缓存未命中。长话短说，如果编写高效代码而不是低效代码不需要花费太多精力，那就去做吧。
- en: Let's now learn what to do if your project has spots that need to maintain good
    performance over time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们学习一下，如果您的项目有需要长期保持良好性能的地方，应该怎么做。
- en: Creating performance tests using benchmarks
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用基准测试创建性能测试
- en: Similar to having unit tests for precise testing and functional tests for larger-scale
    testing of your code's correctness, you can use microbenchmarks and larger benchmarks
    to test your code's performance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与精确测试的单元测试和代码正确性的大规模功能测试类似，您可以使用微基准测试和较大的基准测试来测试代码的性能。
- en: If you have tight constraints on the execution time for certain code paths,
    having a test that ensures the limit is met can be very useful. Even if you don't
    have such specific constraints, you might be interested in monitoring how the
    performance changes across code changes. If after a change your code runs slower
    than before by a certain threshold, the test could be marked as failed.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果对某些代码路径的执行时间有严格的限制，那么确保达到限制的测试可能非常有用。即使没有这样具体的限制，您可能也对监视性能在代码更改时如何变化感兴趣。如果在更改后，您的代码运行比以前慢了一定的阈值，测试可能会被标记为失败。
- en: 'Although also a useful tool, remember that such tests are prone to the boiling
    frog effect: degrading the performance slowly over time can go unnoticed, so be
    sure to monitor the execution times occasionally. When introducing performance
    tests to your CI, be sure to always run them in the same environment for stable
    results.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管也是一个有用的工具，但请记住，这样的测试容易受到渐渐降低性能的影响：随着时间的推移，性能的下降可能会不被注意，因此请确保偶尔监视执行时间。在您的CI中引入性能测试时，确保始终在相同的环境中运行，以获得稳定的结果。
- en: Let's now discuss the next type of tools in our performance shed.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论性能工具箱中的下一类工具。
- en: Profiling
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探测
- en: While benchmarks and tracing can give you an overview and specific numbers for
    a given scope, profilers can help you analyze where those numbers came from. They
    are an essential tool if you need to gain insight into your performance and improve
    it.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基准测试和跟踪可以为给定范围提供概述和具体数字，但探测器可以帮助您分析这些数字的来源。如果您需要深入了解性能并进行改进，它们是必不可少的工具。
- en: Choosing the type of profiler to use
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择要使用的探测器类型
- en: 'There are two types of profilers available: instrumentation profilers and sampling
    ones. One of the better-known instrumentation profilers is Callgrind, part of
    the Valgrind suite. Instrumentation profilers have lots of overhead because they
    need to, well, instrument your code to see what functions you call and how much
    each of them takes. This way, the results they produce contain even the smallest
    functions, but the execution times can be skewed by this overhead. It also has
    the drawback of not always catching **input/output** (**I/O**) slowness and jitters.
    They slow down the execution, so while they can tell you how often you call a
    particular function, they won''t tell you if the slowness is due to waiting on
    a disk read to finish.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种类型的探测器可用：仪器探测器和采样探测器。较为知名的仪器探测器之一是Callgrind，它是Valgrind套件的一部分。仪器探测器有很大的开销，因为它们需要对您的代码进行仪器化，以查看您调用了哪些函数以及每个函数的执行时间。这样，它们产生的结果甚至包含最小的函数，但执行时间可能会受到这种开销的影响。它还有一个缺点，就是不总是能捕捉到输入/输出的缓慢和抖动。它会减慢执行速度，因此，虽然它可以告诉您调用特定函数的频率，但它不会告诉您缓慢是由于等待磁盘读取完成而引起的。
- en: Due to the flaws of instrumentation profilers, it's usually better to use sampling
    profilers instead. Two worth mentioning are the open source perf for profiling
    on Linux systems and Intel's proprietary tool called VTune (free for open source
    projects). Although they can sometimes miss key events due to the nature of sampling,
    they should usually give you a much better view of where your code spends time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于仪器探测器的缺陷，通常最好使用采样探测器。两个值得一提的是开源的perf用于在Linux系统上进行性能分析，以及英特尔的专有工具VTune（对于开源项目是免费的）。虽然它们有时会由于采样的性质而错过关键事件，但通常应该能够更好地展示代码的时间分配情况。
- en: If you decide to use perf, you should know that you can either use it by invoking
    `perf stat`, which gives you a quick overview of statistics like CPU cache usage,
    or `perf record -g` and `perf report -g` to capture and analyze profiling results.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定使用perf，你应该知道你可以通过调用`perf stat`来使用它，这会给你一个关于CPU缓存使用等统计数据的快速概览，或者使用`perf
    record -g`和`perf report -g`来捕获和分析性能分析结果。
- en: If you want a solid overview of perf, please watch Chandler Carruth's video,
    which shows the tool's possibilities and how to use it, or take a look at its
    tutorial. Both are linked in the *Further reading* section.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要对perf有一个扎实的概述，请观看Chandler Carruth的视频，其中展示了工具的可能性以及如何使用它，或者查看它的教程。这两者都在*进一步阅读*部分中链接。
- en: Preparing the profiler and processing the results
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备分析器和处理结果
- en: When analyzing profiling results, you may often want to perform some preparation,
    cleanup, and processing. For instance, if your code mostly spends time spinning
    around, you might want to filter that out. Before even starting the profiler,
    be sure to compile or download as many debug symbols as you can, both for your
    code, your dependencies, even the OS libraries, and kernel. Also, it's essential
    you disable frame pointer optimizations. On GCC and Clang, you can do so by passing
    the `-fno-omit-frame-pointer` flag. It won't affect performance much but will
    give you much more data about the execution of your code. When it comes to post-processing
    of the results, when using perf, it's usually a good idea to create flame graphs
    from the results. Brendan Gregg's tool from the *Further reading* section is great
    for that. Flame graphs are a simple and effective tool to see where the execution
    takes too much time, as the width of each item on the graph corresponds to the
    resource usage. You can have flame graphs for CPU usage, as well as for resources
    such as memory usage, allocations, and page faults, or the time spent when the
    code is not executing such as staying blocked during system calls, on mutexes,
    I/O operations, and the like. There are also ways to perform diffs on the generated
    flame graphs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析性能分析结果时，你可能经常需要进行一些准备、清理和处理。例如，如果你的代码大部分时间都在忙碌，你可能希望将其过滤掉。在开始使用分析器之前，一定要编译或下载尽可能多的调试符号，包括你的代码、你的依赖项，甚至操作系统库和内核。此外，禁用帧指针优化也是必要的。在GCC和Clang上，你可以通过传递`-fno-omit-frame-pointer`标志来实现。这不会对性能产生太大影响，但会为你提供更多关于代码执行的数据。在结果的后处理方面，使用perf时，通常最好从结果中创建火焰图。Brendan
    Gregg在*进一步阅读*部分中的工具非常适合这个用途。火焰图是一个简单而有效的工具，可以看出执行花费了太多时间的地方，因为图表上每个项目的宽度对应着资源使用情况。你可以得到CPU使用情况的火焰图，以及资源使用情况、分配和页面错误等方面的火焰图，或者代码在不执行时花费的时间，比如在系统调用期间保持阻塞、在互斥锁上、I/O操作等。还有一些方法可以对生成的火焰图进行差异分析。
- en: Analyzing the results
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析结果
- en: 'Keep in mind that not all performance issues will show up on such graphs and
    not all can be found using profilers. While with some experience you''ll be able
    to see that you could benefit from setting affinity to your threads or changing
    which threads execute on specific NUMA nodes, it might not always be that obvious
    to see that you''ve forgotten to disable power-saving features or would benefit
    from enabling or disabling hyper-threading. Information about the hardware you''re
    running on is useful, too. Sometimes you might see the SIMD registers of your
    CPU being used, but the code still doesn''t run at its full speed: you might be
    using SSE instructions instead of AVX ones, AVX instead of AVX2, or AVX2 instead
    of AVX512\. Knowing what specific instructions your CPU is capable of running
    can be golden when you analyze the profiling results.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，并非所有性能问题都会在这样的图表上显示出来，也不是所有问题都可以通过性能分析器找到。尽管有了一些经验，你可能会发现你可以从为线程设置亲和性或更改线程在特定NUMA节点上执行的方式中受益，但并不总是那么明显地看出你忘记了禁用节能功能或者从启用或禁用超线程中受益。关于你运行的硬件的信息也是有用的。有时你可能会看到CPU的SIMD寄存器被使用，但代码仍然无法以最快的速度运行：你可能使用了SSE指令而不是AVX指令，AVX而不是AVX2，或者AVX2而不是AVX512。当你分析性能分析结果时，了解你的CPU能够运行哪些具体指令可能是非常有价值的。
- en: Solving performance issues also requires a bit of experience. On the other hand,
    sometimes experience can lead you to false assumptions. For instance, in many
    cases, using dynamic polymorphism will hurt your performance; there are cases
    where it doesn't slow down your code. Before jumping to conclusions, it might
    be worth profiling the code and gaining knowledge about the various ways a compiler
    can optimize code and the limits of those techniques. Talking specifically about
    virtualization, it's often beneficial to mark your classes of virtual member functions
    as final when you don't want other types to inherit and override them, respectively.
    This tends to help the compilers in lots of cases.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 解决性能问题也需要一些经验。另一方面，有时经验可能会导致你做出错误的假设。例如，在许多情况下，使用动态多态性会影响性能；但也有一些情况下，它不会减慢你的代码。在得出结论之前，值得对代码进行性能分析，并了解编译器优化代码的各种方式以及这些技术的限制。具体来说，关于虚拟化，当你不希望其他类型继承和重写你的虚拟成员函数时，将你的虚拟成员函数的类标记为final通常会帮助编译器在许多情况下。
- en: 'Compilers can also optimize much better if they "see" what type the object
    is: if you create a type in scope and call its virtual member function, the compiler
    should be able to deduce which function should be called. GCC tends to devirtualize
    better than other compilers. For more information on this, you can refer to Arthur
    O''Dwyer''s blog post from the *Further reading* section.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器也可以更好地优化，如果它们“看到”对象的类型：如果你在作用域中创建一个类型并调用它的虚拟成员函数，编译器应该能够推断出应该调用哪个函数。GCC倾向于比其他编译器更好地进行去虚拟化。关于这一点的更多信息，你可以参考*进一步阅读*部分中Arthur
    O'Dwyer的博客文章。
- en: As with other types of tools presented in this section, try not to rely only
    on your profiler. Improvements in profiling results are not a guarantee that your
    system got faster. A better-looking profile can still not tell you the whole story.
    And the better performance of one component doesn't necessarily mean the whole
    system's performance improved. This is where our last type of tool can come in
    use.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 与本节中介绍的其他类型的工具一样，尽量不要只依赖于您的分析器。性能分析结果的改进并不意味着您的系统变得更快。一个看起来更好的性能分析图仍然不能告诉您整个故事。一个组件的更好性能并不一定意味着整个系统的性能都得到了改善。这就是我们最后一种类型的工具可以派上用场的地方。
- en: Tracing
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪
- en: The last technique we'll discuss in this section is meant for distributed systems.
    When looking at the overall system, often deployed in the cloud, profiling your
    software on one box won't tell you the whole story. In such a scope, your best
    bet would be to trace the requests and responses flowing through your system.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中讨论的最后一种技术是针对分布式系统的。在查看整个系统时，通常部署在云中，在一个盒子上对软件进行性能分析并不能告诉您整个故事。在这种范围内，您最好的选择是跟踪请求和响应在系统中的流动。
- en: Tracing is a way to log the execution of your code. It's often used when a request
    (and sometimes its response) has to flow through many parts of your system. Usually,
    such messages are being traced along the route, with timestamps being added at
    interesting points of execution.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪是记录代码执行的一种方式。当一个请求（有时还有其响应）必须流经系统的许多部分时，通常会使用它。通常情况下，这样的消息会沿着路线被跟踪，并在执行的有趣点添加时间戳。
- en: Correlation IDs
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关ID
- en: One common addition to timestamps is correlation IDs. Basically, they're unique
    identifiers that get assigned to each traced message. Their purpose is to correlate
    the logs produced by different components of your system (like different microservices)
    during the processing of the same incoming request and sometimes for the events
    it caused, too. Such IDs should be passed with the message everywhere it goes,
    for example, by appending to its HTTP header. Even when the original request is
    gone, you could add its correlation ID to each of the responses produced.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 时间戳的一个常见补充是相关ID。基本上，它们是分配给每个被跟踪消息的唯一标识符。它们的目的是在处理相同的传入请求期间（有时也是由此引起的事件），相关ID可以将系统的不同组件（如不同的微服务）产生的日志相关联起来。这样的ID应该随着消息一起传递，例如通过附加到其HTTP标头。即使原始请求已经消失，您也可以将其相关ID添加到每个响应中。
- en: By using correlation IDs, you can track how messages for a given request propagate
    through the system and how long it took for different parts of your system to
    process it. Often you'll want additional data to be gathered along the way, like
    the thread that was used to perform the computation, the type, and count of responses
    produced for a given request, or the names of the machines it went through.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用相关ID，您可以跟踪给定请求的消息如何在系统中传播，以及系统的不同部分处理它所花费的时间。通常情况下，您还希望在途中收集额外的数据，例如用于执行计算的线程，为给定请求产生的响应的类型和数量，或者它经过的机器的名称。
- en: Tools like Jaeger and Zipkin (or other OpenTracing alternatives) can help you
    to add tracing support to your system fast.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 像Jaeger和Zipkin（或其他OpenTracing替代方案）这样的工具可以帮助您快速为系统添加跟踪支持。
- en: Let's now tackle a different subject and say a few words about code generation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来处理一个不同的主题，并谈谈代码生成。
- en: Helping the compiler generate performant code
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 帮助编译器生成高性能代码
- en: There are many things that can help your compiler generate efficient code for
    you. Some boil down to steering it properly, others require writing your code
    in a compiler-friendly way.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以帮助编译器为您生成高效的代码。有些方法归结为正确引导编译器，而其他方法则需要以对编译器友好的方式编写代码。
- en: It's also important to know what you need to do on your critical path and to
    design it efficiently. For instance, try to avoid virtual dispatch there (unless
    you can prove it's being devirtualized), and try not to allocate new memory on
    it. Often, the clever design of code to avoid locking (or at least using lock-free
    algorithms) is helpful. Generally speaking, everything that can worsen your performance
    should be kept outside your hot path. Having both your instruction and data caches
    hot is really going to pay out. Even attributes such as `[[likely]]` and `[[unlikely]]`
    that hint to the compiler which branch it should expect to be executed can sometimes
    change a lot.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 了解您在关键路径上需要做什么，并有效地设计它也很重要。例如，尽量避免虚拟分派（除非您可以证明它已被去虚拟化），并尽量不要在其中分配新内存。通常情况下，一切可能会降低性能的东西都应该保持在热路径之外。使指令和数据缓存都保持热度确实会产生回报。甚至像`[[likely]]`和`[[unlikely]]`这样的属性，可以提示编译器应该期望执行哪个分支，有时也会产生很大的变化。
- en: Optimizing whole programs
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化整个程序
- en: 'An interesting way to increase the performance of many C++ projects is to enable
    **link-time optimization** (**LTO**). During compilation, your compiler doesn''t
    know how the code will get linked with other object files or libraries. Many opportunities
    to optimize arise only at this point: when linking, your tools can see the bigger
    picture of how the parts of your program interact with each other. By enabling
    LTO, you can sometimes grab a significant improvement in performance with very
    little cost. In CMake projects, you can enable LTO by setting either the global
    `CMAKE_INTERPROCEDURAL_OPTIMIZATION` flag or by setting the `INTERPROCEDURAL_OPTIMIZATION`
    property on your targets.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 增加许多C++项目性能的一个有趣方法是启用**链接时优化**（**LTO**）。在编译过程中，您的编译器不知道代码将如何与其他目标文件或库链接。许多优化的机会只有在这一点上才会出现：在链接时，您的工具可以看到程序的各个部分如何相互交互的整体情况。通过启用LTO，您有时可以在几乎没有成本的情况下获得显著的性能改进。在CMake项目中，您可以通过设置全局的`CMAKE_INTERPROCEDURAL_OPTIMIZATION`标志或在目标上设置`INTERPROCEDURAL_OPTIMIZATION`属性来启用LTO。
- en: One drawback of using LTO is that it makes the building process longer. Sometimes
    a lot longer. To mitigate this cost for developers, you may want to only enable
    this optimization for builds that undergo performance testing or are meant to
    be released.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LTO的一个缺点是它使构建过程变得更长。有时会长很多。为了减少开发人员的成本，您可能只想为需要性能测试或发布的构建启用此优化。
- en: Optimizing based on real-world usage patterns
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于实际使用模式进行优化
- en: Another interesting way to optimize your code is to use **Profile-Guided Optimization**
    (**PGO**). This optimization is actually a two-step one. In the first step, you
    need to compile your code with additional flags that cause the executable to gather
    special profiling information during runtime. You should then execute it under
    the expected production load. Once you're done with it, you can use the gathered
    data to compile the executable a second time, this time passing a different flag
    that instructs the compiler to use the gathered data to generate code better suited
    for your profile. This way, you'll end up with a binary that's prepared and tuned
    to your specific workload.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 优化代码的另一种有趣方法是使用**基于配置文件的优化**（**PGO**）。这种优化实际上是一个两步过程。在第一步中，您需要使用额外的标志编译代码，导致可执行文件在运行时收集特殊的分析信息。然后，您应该在预期的生产负载下执行它。完成后，您可以使用收集的数据第二次编译可执行文件，这次传递不同的标志，指示编译器使用收集的数据生成更适合您的配置文件的代码。这样，您将得到一个准备好并调整到您特定工作负载的二进制文件。
- en: Writing cache-friendly code
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写友好缓存的代码
- en: 'Both those types of optimization can be of use, but there''s one more important
    thing that you need to keep in mind when working on performant systems: cache
    friendliness. Using flat data structures instead of node-based ones means that
    you need to perform less pointer chasing at runtime, which helps your performance.
    Using data that''s contiguous in memory, regardless of whether you''re reading
    it forward or backward, means your CPU''s memory prefetcher can load it before
    it''s used, which can often make a huge difference. Node-based data structures
    and the mentioned pointer chasing cause random memory access patterns that can
    "confuse" the prefetcher and make it impossible for it to prefetch correct data.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种优化技术都可以派上用场，但在处理高性能系统时，还有一件重要的事情需要牢记：缓存友好性。使用平面数据结构而不是基于节点的数据结构意味着您在运行时需要执行更少的指针追踪，这有助于提高性能。无论是向前还是向后读取，使用内存中连续的数据意味着您的CPU内存预取器可以在使用之前加载它，这通常会产生巨大的差异。基于节点的数据结构和上述指针追踪会导致随机内存访问模式，这可能会“混淆”预取器，并使其无法预取正确的数据。
- en: If you want to see some performance results, please refer to the *C++ Containers
    Benchmark* linked in the *Further reading* section. It compares various usage
    scenarios of `std::vector`, `std::list`, `std::deque`, and `plf::colony`. If you
    don't know that last one, it's an interesting "bag"-type container with great
    fast insertion and deletion of large data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看一些性能结果，请参考* C++容器基准测试*中的链接。它比较了`std::vector`，`std::list`，`std::deque`和`plf::colony`的各种使用场景。如果你不知道最后一个，它是一个有趣的“袋”类型容器，具有快速插入和删除大数据的功能。
- en: When choosing from associative containers, you'll most often want to use "flat"
    implementations instead of node-based ones. This means that instead of using `std::unordered_map`
    and `std::unordered_set`, you might want to try out ones like `tsl::hopscotch_map`
    or Abseil's `flat_hash_map` and `flat_hash_set`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择关联容器时，您通常会希望使用“平面”实现而不是基于节点的实现。这意味着您可能想尝试`tsl::hopscotch_map`或Abseil的`flat_hash_map`和`flat_hash_set`，而不是使用`std::unordered_map`和`std::unordered_set`。
- en: Techniques such as putting colder instructions (such as exception handling code)
    in a non-inline function can help to increase the hotness of your instruction
    cache. This way, lengthy code for handling rare cases will not be loaded in the
    instruction cache, leaving space for more code that should be there, which can
    also improve your performance.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如将较冷的指令（例如异常处理代码）放在非内联函数中的技术可以帮助增加指令缓存的热度。这样，用于处理罕见情况的冗长代码将不会加载到指令缓存中，为应该在那里的更多代码留出空间，这也可以提高性能。
- en: Designing your code with data in mind
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以数据为中心设计您的代码
- en: If you want to help your caches, another technique that can be helpful is data-oriented
    design. Often, it's a good idea to store members used more often close to each
    other in memory. Colder data can often be placed in another struct and just be
    connected with the hotter data by an ID or a pointer.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要帮助缓存，另一种有用的技术是数据导向设计。通常，将更频繁使用的成员存储在内存中靠近彼此的位置是一个好主意。较冷的数据通常可以放在另一个结构中，并通过ID或指针与较热的数据连接。
- en: 'Sometimes, instead of the more commonly spotted arrays of objects, using objects
    of arrays can yield better performance. Instead of writing your code in an object-oriented
    manner, split your object''s data member across a few arrays, each containing
    data for multiple objects. In other words, take the following code:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，与更常见的对象数组不同，使用数组对象可以获得更好的性能。不要以面向对象的方式编写代码，而是将对象的数据成员分布在几个数组中，每个数组包含多个对象的数据。换句话说，采用以下代码：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'And consider replacing it with the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 并考虑用以下内容替换它：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This way, when processing a specific set of data points against some objects,
    the cache hotness increases and so does the performance. If you don't know whether
    this will yield more performance from your code, measure.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，当处理一组特定的数据点与一些对象时，缓存热度增加，性能也会提高。如果你不知道这是否会提高代码的性能，请进行测量。
- en: 'Sometimes even reordering members of your types can give you better performance.
    You should take into account the alignment of your types of data members. If performance
    matters, usually it''s a good idea to order them so that the compiler doesn''t
    need to insert too much padding between the members. Thanks to that, the size
    of your data type can be smaller, so many such objects can fit into one cache
    line. Consider the following example (let''s assume we''re compiling for the x86_64
    architecture):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，甚至重新排列类型的成员也可以带来更好的性能。您应该考虑数据成员类型的对齐。如果性能很重要，通常最好的做法是对它们进行排序，以便编译器不需要在成员之间插入太多填充。由于这样，您的数据类型的大小可以更小，因此许多这样的对象可以适应一个缓存行。考虑以下示例（假设我们正在为x86_64架构编译）：
- en: '[PRE26]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Despite the sizes being 8 bytes each and chars being just 1 byte each, we end
    up with 32 bytes in total! That's because `second_size` must start on an 8-byte
    aligned address, so after `first_char`, we get 7 bytes of padding. The same goes
    for `second_char`, as types need to be aligned with respect to their largest data
    type member.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每个大小都是8字节，每个字符只有1字节，但我们最终总共得到32字节！这是因为`second_size`必须从8字节对齐地址开始，所以在`first_char`之后，我们得到7字节的填充。对于`second_char`也是一样，因为类型需要相对于它们最大的数据类型成员进行对齐。
- en: 'Can we do better? Let''s try switching the order of our members:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能做得更好吗？让我们尝试交换成员的顺序：
- en: '[PRE27]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: By simply putting the biggest members first, we were able to cut the size of
    our structure by 8 bytes, which is 25% of its size. Not bad for such a trivial
    change. If your goal is to pack many such structs in a contiguous block of memory
    and iterate through them, you could see a big performance boost of that code fragment.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单地将最大的成员放在最前面，我们能够将结构的大小减小8字节，这占其大小的25%。对于这样一个微不足道的改变来说，效果不错。如果您的目标是将许多这样的结构打包到连续的内存块中并对它们进行迭代，您可能会看到代码片段的性能大幅提升。
- en: Let's now talk about another way to improve your performance.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们谈谈另一种提高性能的方法。
- en: Parallelizing computations
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行计算
- en: In this section, we'll discuss a few different ways to parallelize computations.
    We will start with a comparison between threads and processes, after which we'll
    show you the tools available in the C++ standard, and last but not least, we'll
    say a few words about the OpenMP and MPI frameworks.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将讨论几种不同的并行计算方法。我们将从线程和进程之间的比较开始，然后向您展示C++标准中可用的工具，最后但并非最不重要的是，我们将简要介绍OpenMP和MPI框架。
- en: Before we start, let's say a few words on how to estimate the maximum possible
    gains you can have from parallelizing your code. There are two laws that can help
    us here. The first is Amdahl's law. It states that if we want to speed up our
    program by throwing more cores at it, then the part of our code that must remain
    sequential (cannot be parallelized) will limit our scalability. For instance,
    if 90% of your code is parallelizable, then even with infinite cores you can still
    get only up to a 10x speedup. Even if we cut down the time to execute that 90%
    to zero, the 10% of the code will always remain there.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们简要介绍一下如何估计您可以从并行化代码中获得的最大可能收益。有两个定律可以帮助我们。第一个是Amdahl定律。它指出，如果我们想通过增加核心数来加速我们的程序，那么必须保持顺序执行的代码部分（无法并行化）将限制我们的可伸缩性。例如，如果您的代码有90%是可并行化的，那么即使有无限的核心，您最多只能获得10倍的加速。即使我们将执行该90%的时间缩短到零，这10%的代码仍将始终存在。
- en: The second law is Gustafson's law. It states that every large-enough task can
    be efficiently parallelized. This means that by increasing the size of the problem,
    we can obtain better parallelization (assuming we have free computing resources
    to use). In other words, sometimes it's better to add more capabilities to be
    run in the same time frame instead of trying to reduce the execution time of existing
    code. If you can cut the time of a task by half by doubling the cores, at some
    point, doubling them again and again will get you diminishing returns, so their
    processing power can be better spent elsewhere.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第二定律是Gustafson定律。它指出，每个足够大的任务都可以有效地并行化。这意味着通过增加问题的规模，我们可以获得更好的并行化（假设我们有空闲的计算资源可用）。换句话说，有时候最好的方法是在相同的时间框架内增加更多的功能，而不是试图减少现有代码的执行时间。如果您可以通过将核心数量翻倍来将任务的时间减少一半，那么在某个时刻，再次翻倍核心数量将会带来递减的回报，因此它们的处理能力可以更好地用在其他地方。
- en: Understanding the differences between threads and processes
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解线程和进程之间的区别
- en: To parallelize computations efficiently, you need to also understand when to
    use processes to perform computation and when threads are the better tool for
    the job. Long story short, if your only target is to actually parallelize work,
    then it's best to start with adding extra threads up to the point where they don't
    bring extra benefits. At such a point, add more processes on other machines in
    your network, each with multiple threads too.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效地并行计算，您还需要了解何时使用进程执行计算，何时线程是更好的工具。长话短说，如果您的唯一目标是实际并行化工作，那么最好是从增加额外线程开始，直到它们不带来额外的好处为止。在这一点上，在您的网络中的其他机器上添加更多进程，每个进程也有多个线程。
- en: Why is that? Because processes are more heavyweight than threads. Spawning a
    process and switching between them takes longer than creating and switching between
    threads. Each process requires its own memory space, while threads within the
    same process share their memory. Also, inter-process communication is slower than
    just passing variables between threads. Working with threads is easier than it
    is with processes, so the development will be faster too.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么呢？因为进程比线程更加笨重。生成一个进程和在它们之间切换所需的时间比创建和在线程之间切换所需的时间更长。每个进程都需要自己的内存空间，而同一进程内的线程共享它们的内存。此外，进程间通信比在线程之间传递变量要慢。使用线程比使用进程更容易，因此开发速度也会更快。
- en: Processes, however, also have their uses in the scope of a single application.
    They're great for isolating components that can independently run and crash without
    taking down the whole application with them. Having separate memory also means
    one process can't snoop another one's memory, which is great when you need to
    run third-party code that could turn out to be malicious. Those two reasons are
    why they're used in web browsers, among other apps. Aside from that, it's possible
    to run different processes with different OS permissions or privileges, which
    you can't achieve with multiple threads.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在单个应用程序范围内，进程也有其用途。它们非常适合隔离可以独立运行和崩溃而不会将整个应用程序一起崩溃的组件。拥有单独的内存也意味着一个进程无法窥视另一个进程的内存，这在您需要运行可能是恶意的第三方代码时非常有用。这两个原因是它们在Web浏览器等应用程序中使用的原因。除此之外，还可以以不同的操作系统权限或特权运行不同的进程，这是无法通过多个线程实现的。
- en: Let's now discuss a simple way to parallelize work in the scope of a single
    machine.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论一种在单台机器范围内并行化工作的简单方法。
- en: Using the standard parallel algorithms
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用标准并行算法
- en: 'If the computations you perform can be parallelized, there are two ways you
    can use that to your advantage. One is by replacing your regular calls to standard
    library algorithms with parallelizable ones. If you''re not familiar with parallel
    algorithms, they were added in C++17 and in essence are the same algorithms, but
    you can pass each of them an execution policy. There are three execution policies:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您执行的计算可以并行化，有两种方法可以利用这一点。一种是用可并行化的标准库算法替换您对常规调用。如果您不熟悉并行算法，它们是在C++17中添加的，在本质上是相同的算法，但您可以向每个算法传递执行策略。有三种执行策略：
- en: '`std::execution::seq`: The sequenced policy for the plain-old execution of
    an algorithm in a non-parallelized way. This one we know too well.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::seq`：用于以非并行化方式执行算法的顺序策略。这个我们也太熟悉了。'
- en: '`std::execution::par`: A parallel policy that signals that the execution *may*
    be parallelized, usually using a thread pool under the hood.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par`：一个并行策略，表示执行*可能*是并行的，通常在底层使用线程池。'
- en: '`std::execution::par_unseq`: A parallel policy that signals that the execution
    *may* be parallelized and vectorized.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par_unseq`：一个并行策略，表示执行*可能*是并行化和矢量化的。'
- en: '`std::execution::unseq`: A C++20 addition to the family. This policy signals
    that the execution can be vectorized, but not parallelized.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::unseq`：C++20添加到该系列的一个策略。该策略表示执行可以矢量化，但不能并行化。'
- en: If the preceding policies are not enough for you, additional ones may be provided
    by a standard library implementation. Possible future additions may include ones
    for CUDA, SyCL, OpenCL, or even artificial intelligence processors.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前面的策略对您来说还不够，标准库实现可能会提供其他策略。可能的未来添加可能包括用于CUDA、SyCL、OpenCL甚至人工智能处理器的策略。
- en: 'Let''s now see the parallel algorithms in action. As an example, to sort a
    vector in a parallel way, you can write the following:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看并行算法的实际应用。例如，要以并行方式对向量进行排序，您可以编写以下内容：
- en: '[PRE28]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Simple and easy. Although in many cases this will yield better performance,
    in some cases you might be better off executing the algorithms in the traditional
    way. Why? Because scheduling work on more threads requires additional work and
    synchronization. Also, depending on the architecture of your app, it may influence
    the performance of other already existing threads and flush their cores' data
    caches. As always, measure first.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 简单又容易。虽然在许多情况下这将产生更好的性能，但在某些情况下，您最好以传统方式执行算法。为什么？因为在更多线程上调度工作需要额外的工作和同步。此外，根据您的应用程序架构，它可能会影响其他已经存在的线程的性能并刷新它们的核心数据缓存。一如既往，先进行测量。
- en: Parallelizing computations using OpenMP and MPI
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenMP和MPI并行化计算
- en: An alternative to using the standard parallel algorithms would be to leverage
    OpenMP's pragmas. They're an easy way to parallelize many types of computations
    by just adding a few lines of code. And if you want to distribute your code across
    a cluster, you might want to see what MPI can do for you. Those two can also be
    joined together.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标准并行算法的替代方法是利用OpenMP的编译指示。它们是一种通过添加几行代码轻松并行化许多类型计算的方法。如果您想要在集群上分发代码，您可能想看看MPI能为您做些什么。这两者也可以结合在一起。
- en: With OpenMP, you can use various pragmas to easily parallelize code. For instance,
    you can write `#pragma openmp parallel for` before a `for` loop to get it executed
    using parallel threads. The library can do much more, such as executing computations
    on GPUs and other accelerators.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenMP，您可以使用各种编译指示轻松并行化代码。例如，您可以在`for`循环之前写`#pragma openmp parallel for`以使用并行线程执行它。该库还可以执行更多操作，例如在GPU和其他加速器上执行计算。
- en: Integrating MPI into your project is harder than just adding an appropriate
    pragma. Here, you'll need to use the MPI API in your code base to send or receive
    data between processes (using calls such as `MPI_Send` and `MPI_Recv`), or perform
    various gather and reduce operations (calling `MPI_Bcast` and `MPI_Reduce`, among
    other functions in this family). Communication can be done point to point or to
    all clusters using objects called communicators.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 将MPI集成到您的项目中比只添加适当的编译指示更难。在这里，您需要在代码库中使用MPI API在进程之间发送或接收数据（使用诸如`MPI_Send`和`MPI_Recv`的调用），或执行各种聚合和减少操作（调用`MPI_Bcast`和`MPI_Reduce`等此类函数）。通信可以通过点对点或使用称为通信器的对象到所有集群进行。
- en: 'Depending on your algorithm implementation, MPI nodes can all execute the same
    code or it can vary when needed. The node will know how it should behave based
    on its rank: a unique number assigned when the computations start. Speaking of
    which, to start a process using MPI, you should run it through a wrapper, like
    so:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的算法实现，MPI节点可以全部执行相同的代码，或者在需要时可以变化。节点将根据其等级知道它应该如何行为：在计算开始时分配的唯一编号。说到这一点，要使用MPI启动进程，您应该通过包装器运行它，如下所示：
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This would read hosts from said file one by one, connect to each of them, and
    run four instances of `my_command` on each with the args passed.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这将逐个从文件中读取主机，连接到每个主机，并在每个主机上运行四个`my_command`实例，传递参数。
- en: There are many implementations of MPI. One of the most notable is OpenMPI (don't
    confuse that with OpenMP). Among some useful features, it offers fault tolerance.
    After all, it's not uncommon for a node to go down.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: MPI有许多实现。其中最值得注意的是OpenMPI（不要将其与OpenMP混淆）。在一些有用的功能中，它提供了容错能力。毕竟，节点宕机并不罕见。
- en: The last tool we'd like to mention in this section is GNU Parallel, which you
    might find useful if you want to easily span processes that perform work by spawning
    parallel processes. It can be used both on a single machine and across a compute
    cluster.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想在本节中提到的最后一个工具是GNU Parallel，如果您想要轻松地生成并行进程来执行工作，那么您可能会发现它很有用。它既可以在单台机器上使用，也可以跨计算集群使用。
- en: 'Speaking about different ways to execute code, let''s now discuss one more
    big topic from C++20: coroutines.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 说到执行代码的不同方式，现在让我们讨论C++20中的另一个重要主题：协程。
- en: Using coroutines
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用协程
- en: Coroutines are functions that can suspend their execution and resume it later
    on. They allow writing asynchronous code in a very similar manner to how you would
    write synchronous code. Compared to writing asynchronous code with `std::async`,
    this allows writing cleaner code that's easier to understand and maintain. There's
    no need to write callbacks anymore, and no need to deal with the verbosity of
    `std::async` with promises and futures.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 协程是可以暂停其执行并稍后恢复的函数。它们允许以非常类似于编写同步代码的方式编写异步代码。与使用`std::async`编写异步代码相比，这允许编写更清晰、更易于理解和维护的代码。不再需要编写回调函数，也不需要处理`std::async`的冗长性与promise和future。
- en: Aside from all that, they can also often provide you with much better performance.
    `std::async` based code usually has more overhead for switching threads and waiting.
    Coroutines can resume and suspend very cheaply even compared to the overhead of
    calling functions, which means they can yield better latency and throughput. Also,
    one of their design goals was to be highly scalable, even to billions of concurrent
    coroutines.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，它们通常还可以为您提供更好的性能。基于`std::async`的代码通常在切换线程和等待方面有更多的开销。协程可以非常廉价地恢复和暂停，甚至与调用函数的开销相比，这意味着它们可以提供更好的延迟和吞吐量。此外，它们的设计目标之一是高度可扩展，甚至可以扩展到数十亿个并发协程。
- en: '![](img/527abf17-78b4-4414-aa38-5bd846f4d1c4.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/527abf17-78b4-4414-aa38-5bd846f4d1c4.png)'
- en: Figure 11.1 – Calling and executing coroutines is different from using regular
    functions as they can be suspended and resumed
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 - 调用和执行协程与使用常规函数不同，因为它们可以被暂停和恢复
- en: 'C++ coroutines are stackless, which means their state is not stored on the
    calling thread''s stack. This gives them an interesting property: several different
    threads can pick up the execution of a coroutine. In other words, even though
    it looks like the coroutine function body would be executed sequentially, parts
    of it can be executed in different threads. This makes it possible to leave parts
    of the function to be executed on dedicated threads. For instance, I/O operations
    can be done in a dedicated I/O thread.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: C++协程是无栈的，这意味着它们的状态不存储在调用线程的堆栈上。这使它们具有一个有趣的特性：几个不同的线程可以接管协程的执行。换句话说，即使看起来协程函数体将按顺序执行，其中的部分也可以在不同的线程中执行。这使得可以将函数的部分留给专用线程来执行。例如，I/O操作可以在专用的I/O线程中完成。
- en: 'To check whether a function is a C++ coroutine, you need to look for one of
    the following keywords in its body:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查一个函数是否是C++协程，需要在其主体中查找以下关键字之一：
- en: '`co_await`, which suspends the coroutine.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`co_await`，暂停协程。'
- en: '`co_yield` for returning a value to the caller and suspending the coroutine.
    Similar to Python''s `yield` keyword used in generators. Allows generating values
    lazily.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`co_yield`，将一个值返回给调用者并暂停协程。类似于Python中生成器中使用的`yield`关键字。允许惰性生成值。'
- en: '`co_return`, which returns a value and finishes executing the coroutine. It''s
    a coroutine equivalent of the `return` keyword.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`co_return`，返回一个值并结束执行协程。这是`return`关键字的协程等价物。'
- en: 'Whenever a function body has one of those keywords, the function automatically
    becomes a coroutine. Although this means it''s an implementation detail, there''s
    one more hint that you can use: coroutine return types must satisfy certain requirements,
    which we''ll discuss later on.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 每当函数主体具有这些关键字之一时，该函数自动成为协程。虽然这意味着这是一个实现细节，但还有一个提示可以使用：协程返回类型必须满足某些要求，我们将在后面讨论。
- en: Coroutines are first-class citizens in the C++ world. This means you can get
    their address, use them as function arguments, return them from functions, and
    store them in objects.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 协程在C++世界中是一等公民。这意味着你可以获得它们的地址，将它们用作函数参数，从函数中返回它们，并将它们存储在对象中。
- en: In C++, you could write coroutines even before C++20\. This was possible thanks
    to libraries such as Boost.Coroutine2, or Bloomberg's Quantum. The latter was
    even used to implement CoroKafka – a library for efficiently dealing with Kafka
    streams using coroutines. With the advent of standard C++ coroutines, new libraries
    started popping up. Now, we're going to show you one of them.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中，即使在C++20之前，你也可以编写协程。这得益于诸如Boost.Coroutine2或Bloomberg的Quantum等库。后者甚至被用来实现CoroKafka
    - 一个使用协程高效处理Kafka流的库。随着标准C++协程的出现，新的库开始出现。现在，我们将向您展示其中之一。
- en: Distinguishing between cppcoro utilities
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 区分cppcoro实用程序
- en: It's hard to write coroutine-based code from scratch. C++20 only offers the
    fundamental utilities for writing coroutines, so we need a set of primitives to
    use when writing our own coroutines. The cppcoro library created by Lewis Baker
    is one of the most commonly used coroutine frameworks for C++. In this section,
    we'll showcase the library and demonstrate how to use it when writing coroutine-based
    code.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始编写基于协程的代码很困难。C++20只提供了编写协程的基本实用程序，因此在编写自己的协程时，我们需要一组原语来使用。由Lewis Baker创建的cppcoro库是C++中最常用的协程框架之一。在本节中，我们将展示该库，并演示在编写基于协程的代码时如何使用它。
- en: 'Let''s start with an overview of the coroutine types the library offers us:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从库提供的协程类型概述开始：
- en: '`task<>`: For scheduling work to be executed later – starts executing when
    it''s `co_awaited` for.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`任务<>`：用于安排稍后执行的工作-当它被`co_awaited`时开始执行。'
- en: '`shared_task<>`: A task that multiple coroutines can await. It can be copied
    so that multiple coroutines reference the same result. Doesn''t offer any thread-safety
    on its own.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shared_task<>`：多个协程可以等待的任务。它可以被复制，以便多个协程引用相同的结果。本身不提供任何线程安全性。'
- en: '`generator`: Produces a sequence of Ts lazily and synchronously. It''s effectively
    a `std::range`: it has a `begin()` returning an iterator and an `end()` returning
    a sentinel.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator`：惰性和同步地产生一系列Ts。它实际上是一个`std::range`：它有一个返回迭代器的`begin()`和一个返回哨兵的`end()`。'
- en: '`recursive_generator`: Similar to `generator<T>`, but can yield either a T
    or `recursive_generator<T>`. Has some extra overhead.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recursive_generator`：类似于`generator<T>`，但可以产生T或`recursive_generator<T>`。有一些额外的开销。'
- en: '`async_generator`: Similar to `generator<T>`, but values may be produced asynchronously.
    This means that, as opposed to generator, asynchronous generators can use `co_await`
    in their bodies.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`async_generator`：类似于`generator<T>`，但值可以异步产生。这意味着与生成器相反，异步生成器可以在其主体中使用`co_await`。'
- en: You should use those types as return types for your coroutines. Usually, in
    your generators (coroutines returning one of the preceding generator types), you'd
    want to return values using `co_yield` (similar to in Python generators). In your
    tasks, however, usually, you'll want to schedule work with `co_await`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该将这些类型用作协程的返回类型。通常，在您的生成器（返回前述生成器类型之一的协程）中，您希望使用`co_yield`返回值（类似于Python生成器）。但是，在您的任务中，通常，您将希望使用`co_await`安排工作。
- en: 'The library actually offers many more programming abstractions than just the
    preceding coroutine types. It also provides the following types:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 该库实际上提供了许多编程抽象，不仅仅是前述的协程类型。它还提供以下类型：
- en: '**Awaitables** types that you can `co_await` on, such as coroutine-flavored
    events and synchronization primitives: mutexes, latches, barriers, and so on.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可等待对象**可以在其上`co_await`的类型，例如协程风格的事件和同步原语：互斥锁、闩锁、屏障等。'
- en: '**Cancellation-related utilities**, essentially allowing you to cancel the
    execution of your coroutines.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与取消相关的实用程序**，基本上允许您取消协程的执行。'
- en: '**Schedulers** – objects allowing you to schedule work through them, such as
    `static_thread_pool`, or ones for scheduling work on a specific thread.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度程序**-允许您通过它们安排工作的对象，例如`static_thread_pool`，或者用于在特定线程上安排工作的对象。'
- en: '**I/O and networking utilities**, allowing you to read from and write to files
    and IP sockets.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I/O和网络实用程序**，允许您从文件和IP套接字中读取和写入。'
- en: '**Meta-functions and concepts**, such as `awaitable_traits`, `Awaitable`, and
    `Awaiter`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元函数和概念**，例如`awaitable_traits`、`Awaitable`和`Awaiter`。'
- en: 'Aside from the preceding utilities, cppcoro offers us functions – utilities
    for using other classes and steering execution, such as the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前述的实用程序之外，cppcoro还为我们提供了函数-用于使用其他类和引导执行的实用程序，例如以下内容：
- en: '`sync_wait`: Block until the passed awaitable completes.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sync_wait`：阻塞，直到传递的可等待对象完成。'
- en: '`when_all, when_all_ready`: Return an awaitable that completes when all the
    passed awaitables complete. The difference between those two is in handling failures
    of the sub-awaitables. `when_all_ready` will complete even in the event of failures
    and the caller can examine each result, while `when_all` will rethrow an exception
    if any of the sub-awaitables throws one (it''s impossible to know which one did,
    though). It will also cancel any incomplete tasks.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`when_all, when_all_ready`：返回一个可等待对象，当所有传递的可等待对象完成时完成。这两者之间的区别在于处理子可等待对象的失败。`when_all_ready`将在发生故障时完成，调用者可以检查每个结果，而`when_all`将重新抛出异常，如果任何子可等待对象抛出异常（尽管不可能知道哪个子对象抛出异常）。它还将取消任何未完成的任务。'
- en: '`fmap`: Similarly to functional programming, applies a function to an awaitable.
    You can think of it as transforming a task of one type into a task of another.
    For example, you can serialize types returned by your coroutines by calling `fmap(serialize,
    my_coroutine())`.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fmap`：类似于函数式编程，将函数应用于可等待对象。您可以将其视为将一种类型的任务转换为另一种类型的任务。例如，您可以通过调用`fmap(serialize,
    my_coroutine())`序列化由您的协程返回的类型。'
- en: '`resume_on`: Instructs the coroutine which scheduler to use to continue execution
    once some work is completed. This enables you to execute certain work in certain
    execution contexts, such as running I/O-related tasks on a dedicated I/O thread.
    Note that this means a single C++ function (coroutine) can execute its parts on
    separate threads. Can be "piped" with computations similarly to `std::ranges`.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume_on`：指示协程在完成某些工作后继续执行时使用哪个调度程序。这使您能够在特定的执行上下文中执行某些工作，例如在专用I/O线程上运行I/O相关的任务。请注意，这意味着单个C++函数（协程）可以在不同的线程上执行其部分。可以类似于`std::ranges`一样与计算一起“管道化”。'
- en: '`schedule_on`: Instructs the coroutine which scheduler to use to start some
    work. Commonly used as `auto foo = co_await schedule_on(scheduler, do_work());`.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`schedule_on`：指示协程使用哪个调度程序开始一些工作。通常用作`auto foo = co_await schedule_on(scheduler,
    do_work());`。'
- en: Before we start using those utilities together, let's say a few more words about
    awaitables.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始一起使用这些实用程序之前，让我们再说几句关于可等待对象。
- en: Looking under the hood of awaitables and coroutines
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看可等待对象和协程的内部工作原理
- en: 'Aside from cppcoro, the standard library offers two more trivial awaitables:
    `suspend_never` and `suspend_always`. By looking at them, we can see how to implement
    our own awaitables when needed:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 除了cppcoro之外，标准库还提供了另外两个简单的可等待对象：`suspend_never`和`suspend_always`。通过查看它们，我们可以看到在需要时如何实现我们自己的可等待对象：
- en: '[PRE30]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'When typing `co_await`, you tell the compiler to first call the awaiter''s
    `await_ready()`. If it says the awaiter is ready by returning true, `await_resume()`
    will get called. The return type of `await_resume()` should be the type the awaiter
    is actually producing. If the awaiter was not ready, the program will instead
    execute `await_suspend()`. After it''s done, we have three cases:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入`co_await`时，您告诉编译器首先调用等待器的`await_ready()`。如果它通过返回true表示等待器已准备就绪，将调用`await_resume()`。`await_resume()`的返回类型应该是等待器实际产生的类型。如果等待器没有准备好，程序将执行`await_suspend()`。完成后，我们有三种情况：
- en: '`await_suspend` returns `void`: The execution will always suspend afterwards.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`await_suspend`返回`void`：执行后总是会暂停。'
- en: '`await_suspend` returns `bool`: The execution will suspend or not depending
    on the returned value.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`await_suspend`返回`bool`：根据返回的值，执行将暂停或不暂停。'
- en: '`await_suspend` returns `std::coroutine_handle<PromiseType>`: Another coroutine
    will get resumed.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`await_suspend`返回`std::coroutine_handle<PromiseType>`：另一个协程将被恢复。'
- en: There's much more going on with coroutines under the hood. Even though coroutines
    don't use the `return` keyword, the compiler will generate code under the hood
    to make them compile and work. When using keywords such as `co_yield`, it will
    rewrite them to calls to the appropriate member functions of helper types. For
    instance, a call to `co_yield x` is equivalent to `co_await` `promise.yield_value(x)`.
    If you want to learn more about what's happening exactly and write your own coroutine
    types, refer to the *Your First Coroutine* article from the *Further reading*
    section.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 协程底层有更多的东西。即使协程不使用`return`关键字，编译器也会在底层生成代码使它们编译和工作。当使用`co_yield`等关键字时，它会将它们重写为对应的辅助类型的成员函数的调用。例如，对`co_yield
    x`的调用等效于`co_await` `promise.yield_value(x)`。如果您想了解更多关于发生了什么并编写自己的协程类型，请参考*进一步阅读*部分的*Your
    First Coroutine*文章。
- en: Okay, let's now use all this knowledge to write our own coroutines. We'll create
    a simple application that mimics doing meaningful work. It will use a thread pool
    to fill a vector with some numbers.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们利用所有这些知识来编写我们自己的协程。我们将创建一个简单的应用程序，模拟进行有意义的工作。它将使用线程池来填充一个向量中的一些数字。
- en: 'Our CMake target will look as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的CMake目标将如下所示：
- en: '[PRE31]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We'll link to the cppcoro library. In our case, we're using Andreas Buhr's fork
    of cppcoro, as it is a well-maintained fork of Lewis Baker's repository and supports
    CMake.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将链接到cppcoro库。在我们的情况下，我们使用Andreas Buhr的cppcoro分支，因为它是Lewis Baker存储库的一个维护良好的分支，并支持CMake。
- en: We'll also link to the excellent `{fmt}` library for text formatting. If your
    standard library offers C++20's string formatting, you can use that instead.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将链接到优秀的`{fmt}`库进行文本格式化。如果您的标准库提供了C++20的字符串格式化，您也可以使用它。
- en: Last but not least, we're going to need a threading library – after all, we
    want to use multiple threads in a pool.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们需要一个线程库 - 毕竟，我们想要在池中使用多个线程。
- en: 'Let''s start our implementation with some constants and a `main` function:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一些常量和一个`main`函数开始我们的实现：
- en: '[PRE32]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We want to produce five items using three pooled threads. cppcoro''s thread
    pool is a neat way to schedule work. By default, it creates as many threads as
    your machine has hardware ones. Moving onward, we need to specify our work:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望使用三个池化线程生成五个项目。cppcoro的线程池是一种很好的调度工作的方式。默认情况下，它会创建与您的机器硬件线程一样多的线程。继续前进，我们需要指定我们的工作：
- en: '[PRE33]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We'll sprinkle our code with log messages so you can better see what's going
    on in which thread. This will help us better understand how coroutines work. We
    create work by calling a coroutine named `do_routine_work`. It returns us the
    coroutine, which we run using the `sync_wait` blocking function. A coroutine won't
    start executing until it is actually being awaited. This means that our actual
    work will start inside this function call.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在代码中添加日志消息，以便您更好地了解在哪个线程中发生了什么。这将帮助我们更好地理解协程的工作原理。我们通过调用名为`do_routine_work`的协程来创建工作。它返回给我们协程，我们使用`sync_wait`阻塞函数来运行它。协程在实际被等待之前不会开始执行。这意味着我们的实际工作将在这个函数调用内开始执行。
- en: 'Once we have our results, let''s log them:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了结果，让我们记录它们：
- en: '[PRE34]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'No voodoo magic here. Let''s define our `do_routine_work` coroutine:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有巫术魔法。让我们定义我们的`do_routine_work`协程：
- en: '[PRE35]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'It returns a task, which produces some integers. Because we''re going to use
    the thread pool, let''s use cppcoro''s `async_mutex` to synchronize the threads.
    Let''s now start using the pool:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回一个任务，产生一些整数。因为我们将使用线程池，让我们使用cppcoro的`async_mutex`来同步线程。现在让我们开始使用池：
- en: '[PRE36]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You might be surprised that the `schedule()` call doesn't pass in any callable
    to execute. In the coroutine's case, we're actually making our current thread
    suspend the coroutine and start executing its caller. This means it will now wait
    for the coroutine to finish (somewhere in the `sync_wait` call).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会感到惊讶，`schedule()`调用没有传入任何可调用对象来执行。在协程的情况下，我们实际上是让当前线程挂起协程并开始执行其调用者。这意味着它现在将等待协程完成（在`sync_wait`调用中的某个地方）。
- en: 'In the meantime, a thread from our pool will resume the coroutine – simply
    continuing to execute its body. Here''s what we''ve prepared for it:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，来自我们池中的一个线程将恢复协程 - 简单地继续执行其主体。这是我们为它准备的：
- en: '[PRE37]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We create a vector of tasks to execute. Each task fills one number in `ints`
    under the mutex. The `schedule_on` call runs the filling coroutine using another
    thread from our pool. Finally, we wait for all the results. At this point, our
    tasks start executing. Finally, as our coroutine is a task, we use `co_return`
    .
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个要执行的任务向量。每个任务在互斥锁下填充`ints`中的一个数字。`schedule_on`调用使用我们池中的另一个线程运行填充协程。最后，我们等待所有的结果。此时，我们的任务开始执行。最后，由于我们的协程是一个任务，我们使用`co_return`。
- en: Don't forget to `co_return` the produced value. If we removed the `co_return
    ints;` line from our example, we would simply return a default constructed vector.
    The program would run, happily print the empty vector, and exit with code 0.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记使用`co_return`返回生成的值。如果我们从示例中删除了`co_return ints;`这一行，我们将简单地返回一个默认构造的向量。程序将运行，愉快地打印空向量，并以代码0退出。
- en: 'Our last step is to implement the coroutine that will produce a number:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一步是实现一个将产生一个数字的协程：
- en: '[PRE38]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This one is a task that doesn''t return any value. Instead, it will add it
    to our vector. Its hard work will actually be done by dozing off for a number
    of milliseconds. After the wake-up, the coroutine will continue with more productive
    endeavors:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个不返回任何值的任务。相反，它将其添加到我们的向量中。它的辛苦工作实际上是通过打盹一定数量的毫秒来完成的。醒来后，协程将继续进行更有成效的努力：
- en: '[PRE39]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: It will lock the mutex. In our case, it's just an `await`. When the mutex is
    locked, it will add a number to our vector – the same number it was called with.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 它将锁定互斥锁。在我们的情况下，它只是一个`await`。当互斥锁被锁定时，它将向我们的向量添加一个数字 - 与调用它的相同的数字。
- en: 'NOTE: Remember to `co_await`. If you forget and your awaitable allows that
    (perhaps because its okay to not consume each awaitable), then you might skip
    some essential computations. In our example, this could mean not locking a mutex.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：记得使用`co_await`。如果你忘记了，而你的可等待对象允许这样做（也许是因为可以不消耗每个可等待对象），那么你可能会跳过一些重要的计算。在我们的示例中，这可能意味着不锁定互斥锁。
- en: 'Let''s finish the coroutine''s implementation now:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在完成协程的实现：
- en: '[PRE40]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Just a simple `status print` and a `co_return` to mark the coroutine as complete.
    Once it returns, the coroutine frame can be destroyed, freeing the memory occupied
    by it.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 只是一个简单的`status print`和一个`co_return`来标记协程为完成。一旦返回，协程帧就可以被销毁，释放其占用的内存。
- en: 'That''s all. Let''s now run our code and see what happens:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了。现在让我们运行我们的代码，看看会发生什么：
- en: '[PRE41]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Our main thread was used to fire up the work on the pool and then waited for
    the results to come. Then, our three threads from the pool were producing numbers.
    The last task scheduled was actually the first one that ran, producing the number
    4\. This is because it was the one that continued executing `do_routine_work`
    all the time: first, it scheduled all other tasks on the pool, then started performing
    the first task when `when_all_ready` was called. Later on, the execution continued
    with the first free thread taking the next task scheduled on the pool until the
    whole vector was filled. Finally, the execution returned to our main thread.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主线程用于在线程池上启动工作，然后等待结果。然后，我们的线程池中的三个线程正在生成数字。最后安排的任务实际上是第一个运行的任务，生成数字4。这是因为它一直在执行`do_routine_work`：首先，在线程池上安排了所有其他任务，然后在调用`when_all_ready`时开始执行第一个任务。随后，执行继续进行，第一个空闲线程接管线程池上安排的下一个任务，直到整个向量填满。最后，执行返回到我们的主线程。
- en: This concludes our short example. And with it, we conclude our last section
    of this chapter. Let's now summarize what we've learned.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们的简短示例。随之而来的是本章的最后一节。现在让我们总结一下我们学到的东西。
- en: Summary
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've learned what types of tools can help us achieve better
    performance with our code. We learned how to perform experiments, write performance
    tests, and look for performance bottlenecks. You're now able to write microbenchmarks
    using Google Benchmark. Moreover, we discussed how to profile your code and how
    (and why) to implement distributed tracing of your system. We also discussed parallelizing
    your computations using both standard library utilities and external solutions.
    Last but not least, we introduced you to coroutines. You now know what C++20 brings
    to the coroutine table, as well as what you can find in the cppcoro library. You've
    also learned how to write your own coroutines.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了什么类型的工具可以帮助我们提高代码的性能。我们学习了如何进行实验，编写性能测试，并寻找性能瓶颈。您现在可以使用Google Benchmark编写微基准测试。此外，我们讨论了如何对代码进行性能分析，以及如何（以及为什么）实现系统的分布式跟踪。我们还讨论了如何使用标准库工具和外部解决方案并行化计算。最后但同样重要的是，我们向您介绍了协程。您现在知道C++20为协程带来了什么，以及您可以在cppcoro库中找到什么。您还学会了如何编写自己的协程。
- en: 'The most important lesson from this chapter is: when it comes to performance,
    measure first and optimize later. This will help you maximize the impact of your
    work.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 本章最重要的教训是：在性能方面，先进行测量，后进行优化。这将帮助您最大限度地发挥您的工作影响。
- en: That's it for performance – the last of quality attributes we wanted to discuss
    in our book. In the next chapter, we'll start moving into the world of services
    and the cloud. We'll start by discussing service-oriented architecture.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是性能 - 我们想在书中讨论的最后一个质量属性。在下一章中，我们将开始进入服务和云的世界。我们将首先讨论面向服务的架构。
- en: Questions
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What can we learn from the performance results from this chapter's microbenchmarks?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从本章微基准测试的性能结果中可以学到什么？
- en: Is how we traverse a multi-dimensional array important for performance? Why/why
    not?
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历多维数组对性能重要吗？为什么/为什么不？
- en: In our coroutines example, why can't we create our thread pool inside the `do_routine_work`
    function?
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的协程示例中，为什么不能在`do_routine_work`函数内创建线程池？
- en: How can we rework our coroutine example so it uses a generator instead of just
    tasks?
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何重新设计我们的协程示例，使其使用生成器而不仅仅是任务？
- en: Further reading
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: When can the C++ compiler devirtualize a call?, blog post, Arthur O'Dwyer, [https://quuxplusone.github.io/blog/2021/02/15/devirtualization/](https://quuxplusone.github.io/blog/2021/02/15/devirtualization/)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++编译器何时可以进行虚函数调用优化？，博客文章，Arthur O'Dwyer，[https://quuxplusone.github.io/blog/2021/02/15/devirtualization/](https://quuxplusone.github.io/blog/2021/02/15/devirtualization/)
- en: 'CppCon 2015: Chandler Carruth "Tuning C++: Benchmarks, and CPUs, and Compilers!
    Oh My!", YouTube video, [https://www.youtube.com/watch?v=nXaxk27zwlk](https://www.youtube.com/watch?v=nXaxk27zwlk)'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CppCon 2015: Chandler Carruth "Tuning C++: Benchmarks, and CPUs, and Compilers!
    Oh My!"，YouTube视频，[https://www.youtube.com/watch?v=nXaxk27zwlk](https://www.youtube.com/watch?v=nXaxk27zwlk)'
- en: Tutorial, Perf Wiki, [https://perf.wiki.kernel.org/index.php/Tutorial](https://perf.wiki.kernel.org/index.php/Tutorial)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教程，Perf Wiki，[https://perf.wiki.kernel.org/index.php/Tutorial](https://perf.wiki.kernel.org/index.php/Tutorial)
- en: CPU Flame Graphs, Brendan Gregg, [http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html](http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html)
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU Flame Graphs，Brendan Gregg，[http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html](http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html)
- en: C++ Containers Benchmark, blog post, Baptiste Wicht, [https://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html](https://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html)
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++ 容器基准测试，Baptiste Wicht 的博客文章，[https://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html](https://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html)
- en: Your First Coroutine, blog post, Dawid Pilarski, [https://blog.panicsoftware.com/your-first-coroutine](https://blog.panicsoftware.com/your-first-coroutine)
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的第一个协程，Dawid Pilarski 的博客文章，[https://blog.panicsoftware.com/your-first-coroutine](https://blog.panicsoftware.com/your-first-coroutine)
