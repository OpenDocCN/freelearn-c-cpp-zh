- en: 3\. Hash Tables and Bloom Filters
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 哈希表和布隆过滤器
- en: Learning Objectives
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够：
- en: Identify lookup-related problems easily in any large-scale application
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何大型应用程序中轻松识别与查找相关的问题
- en: Evaluate whether a problem is suited for a deterministic or non-deterministic
    lookup solution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估问题是否适合确定性或非确定性查找解决方案
- en: Implement an efficient lookup solution based on a scenario
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于场景实现高效的查找解决方案
- en: Implement generic solutions provided as part of C++ STL in large applications
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大型应用程序中实现C++ STL提供的通用解决方案
- en: In this chapter, we'll look at the problem of fast lookup. We will learn about
    the various approaches to solving this problem and understand which one can be
    used for a given situation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究快速查找的问题。我们将了解解决此问题的各种方法，并了解哪种方法可以用于特定情况。
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Lookup is nothing but checking whether an element is present in a container
    or finding the corresponding value for a key in the container. In the student
    database system and the hospital management system examples that we mentioned
    in the previous chapters, a common operation is to fetch a particular record from
    the vast amount of data stored in the system. A similar problem also presents
    itself while getting the meaning of a word from a dictionary, checking whether
    a person is allowed to enter a certain facility based on a set of records (access
    control), and many more applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 查找只是检查元素是否存在于容器中或在容器中查找键的相应值。在我们在前几章中提到的学生数据库系统和医院管理系统示例中，一个常见的操作是从系统中存储的大量数据中获取特定记录。在从字典中获取单词的含义，根据一组记录（访问控制）检查某人是否被允许进入某个设施等许多应用程序中也会出现类似的问题。
- en: For most of these scenarios, just going through all the elements linearly and
    matching the values would be extremely time-consuming, especially considering
    the vast amount of records that are stored. Let's take a simple example of looking
    up a word in a dictionary. There are roughly 170,000 words in the English dictionary.
    One of the simplest ways to do this is to traverse the dictionary linearly and
    compare the given word with all the words in the dictionary until we've found
    the word, or we reach the end of the dictionary. But this is too slow, and it
    will have a time complexity of *O(n)*, where n is the number of words in the dictionary,
    which is not only huge but is also increasing day by day.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数情况，线性遍历所有元素并匹配值将非常耗时，特别是考虑到存储的大量记录。让我们以在字典中查找单词为例。英语词典中大约有17万个单词。最简单的方法之一是线性遍历字典，并将给定的单词与字典中的所有单词进行比较，直到找到单词或者到达字典的末尾。但这太慢了，它的时间复杂度为*O(n)*，其中n是字典中的单词数，这不仅庞大而且每天都在增加。
- en: Hence, we need more efficient algorithms to allow for lookup that works much
    faster. We'll look at a couple of efficient structures in this chapter, that is,
    hash tables and bloom filters. We'll implement both of them and compare their
    pros and cons.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要更高效的算法来实现更快的查找。在本章中，我们将看一些高效的结构，即哈希表和布隆过滤器。我们将实现它们并比较它们的优缺点。
- en: Hash Tables
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希表
- en: Let's look at the very basic problem of searching in a dictionary. There are
    about 170,000 words in the Oxford English Dictionary. As we mentioned in the Introduction,
    a linear search will take *O(n)* time, where *n* is the number of words. A better
    way to store the data is to store it in a height-balanced tree that has similar
    properties to a BST. This makes it much faster than linear search as it has a
    time complexity of only *O(log n)*. But for applications that require tons of
    such queries, this is still not a good enough improvement. Think about the time
    it will take for data containing millions or billions of records, such as neuroscientific
    data or genetic data. It would take days to find something in the data. For these
    situations, we need something much faster, such as a **hash table**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看在字典中搜索的基本问题。牛津英语词典中大约有17万个单词。正如我们在介绍中提到的，线性搜索将花费*O(n)*的时间，其中*n*是单词的数量。存储数据的更好方法是将其存储在具有类似BST属性的高度平衡树中。这使得它比线性搜索快得多，因为它的时间复杂度仅为*O(log
    n)*。但对于需要大量此类查询的应用程序来说，这仍然不是足够好的改进。想想在包含数百万甚至数十亿条记录的数据中查找所需的时间，比如神经科学数据或遗传数据。在这些情况下，我们需要更快的东西，比如**哈希表**。
- en: One of the integral parts of hash tables is **hashing**. The idea behind this
    is to represent each value with a possibly unique key and, later on, use the same
    key to check for the presence of the key or to retrieve a corresponding value,
    depending on the use case. The function that derives a unique key from the given
    data is called a hash function. Let's look at how we can store and retrieve data
    by looking at some examples, and let's learn why we need such a function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表的一个重要部分是**哈希**。其背后的想法是用可能唯一的键表示每个值，然后稍后使用相同的键来检查键的存在或检索相应的值，具体取决于使用情况。从给定数据派生唯一键的函数称为哈希函数。让我们看看如何通过一些示例存储和检索数据，并让我们了解为什么我们需要这样的函数。
- en: Hashing
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 哈希
- en: 'Let''s take one simple example before jumping into hashing. Let''s say we have
    a container storing integers, and we want to know if a particular integer is part
    of the container or not as quickly as possible. The simplest way is to have a
    Boolean array with each bit representing a value that''s the same as its index.
    When we want to insert an element, we''ll set the Boolean value corresponding
    to that element to *0*. To insert *x*, we simply set *data[x] = true*. Checking
    whether a particular integer, *x*, is inside the container is just as simple —
    we simply check whether *data[x]* is *true*. Thus, our insertion, deletion, and
    search functions become *O(1)*. A simple hash table for storing integers numbered
    from *0* to *9* would look as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳入哈希之前，让我们举一个简单的例子。假设我们有一个存储整数的容器，并且我们想尽快知道特定整数是否是容器的一部分。最简单的方法是使用一个布尔数组，其中每个位表示与其索引相同的值。当我们想要插入一个元素时，我们将设置与该元素对应的布尔值为*0*。要插入*x*，我们只需设置*data[x]
    = true*。检查特定整数*x*是否在容器内同样简单——我们只需检查*data[x]*是否为*true*。因此，我们的插入、删除和搜索函数变为*O(1)*。存储从*0*到*9*编号的整数的简单哈希表如下所示：
- en: '![Figure 3.1: A simple hash table](img/C14498_03_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1：一个简单的哈希表](img/C14498_03_01.jpg)'
- en: 'Figure 3.1: A simple hash table'
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.1：一个简单的哈希表
- en: 'However, there are some problems with this approach:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法存在一些问题：
- en: What if the data is floating-point numbers?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据是浮点数呢？
- en: What if the data is not just a number?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据不仅仅是一个数字呢？
- en: What if the range of the data is too high? That is, if we have a billion numbers,
    then we need a Boolean array that's one billion in size, and that is not always
    feasible.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据的范围太高怎么办？也就是说，如果我们有十亿个数字，那么我们需要一个大小为十亿的布尔数组，这并不总是可行的。
- en: To resolve this problem, we can implement a function that will map any value
    of any data type to an integer in the desired range. We can choose the range so
    that its Boolean array will have a feasible size. This function is called a **hash
    function**, as we mentioned in the previous section. It will take one data element
    as input and provide a corresponding output integer within the provided range.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以实现一个函数，将任何数据类型的任何值映射到所需范围内的整数。我们可以选择范围，使其布尔数组的大小可行。这个函数被称为**哈希函数**，正如我们在前一节中提到的。它将一个数据元素作为输入，并在提供的范围内提供相应的输出整数。
- en: The simplest hashing function for integers in a large range is the modulo function
    (denoted by *%*), which divides the element by a specified integer (*n*) and returns
    the remainder. So, we'll simply have an array of size *n*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大范围内的整数，最简单的哈希函数是模函数（用*%*表示），它将元素除以指定的整数（*n*）并返回余数。因此，我们将简单地有一个大小为*n*的数组。
- en: If we want to insert a given value, *x*, we can apply the modulo function on
    it (*x % n*), and we will always get a value between *0* and (*n – 1*), both inclusive.
    Now, *x* can be inserted at position *(x % n)*. Here, the number that's obtained
    by applying the hash function is called the **hash value**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要插入一个给定的值*x*，我们可以对其应用模函数（*x % n*），并且我们将始终得到一个在*0*和（*n – 1*）之间的值，两者都包括在内。现在，*x*可以插入到位置*（x
    % n）*。这里，通过应用哈希函数获得的数字称为**哈希值**。
- en: A major problem we may encounter with this is that two elements may have the
    same output from the modulo function. An example is (*9 % 7*) and (*16 % 7*),
    which both result in a hash value of *2*. Thus, if the slot corresponding to *2*
    is *TRUE* (or *1* for Boolean), we would have no idea which of *2*, *9*, *16*,
    or any other integer that returns *x % 7 = 2* is present in our container. This
    problem is known as collision, because multiple keys have the same values instead
    of unique values after applying the hash function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会遇到的一个主要问题是，两个元素可能具有相同的模函数输出。一个例子是（*9 % 7*）和（*16 % 7*），它们都得到哈希值*2*。因此，如果对应于*2*的槽位为*TRUE*（或布尔值为*1*），我们将不知道我们的容器中存在*2*、*9*、*16*或任何返回*x
    % 7 = 2*的其他整数。这个问题被称为冲突，因为多个键具有相同的值而不是唯一值，而不是应用哈希函数后的唯一值。
- en: If we store the actual value instead of a Boolean integer in our hash table,
    we will know which value we have, but we still cannot store multiple values with
    the same hash value. We will look at how to deal with this in the following section.
    But first, let's look at the implementation of a basic dictionary for a bunch
    of integers in the following exercise.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在哈希表中存储实际值而不是布尔整数，我们将知道我们有哪个值，但我们仍然无法存储具有相同哈希值的多个值。我们将在下一节中看看如何处理这个问题。但首先，让我们看看在下一个练习中为一堆整数实现基本字典的实现。
- en: 'Exercise 13: Basic Dictionary for Integers'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习13：整数的基本字典
- en: 'In this exercise, we shall implement a basic version of a hash map for unsigned
    integers. Let''s get started:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将实现一个无符号整数的基本版本的哈希映射。让我们开始吧：
- en: 'First, let''s include the required headers:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们包括所需的头文件：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let''s add the `hash_map` class. We''ll alias `unsigned int` to avoid
    writing a long name:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加“hash_map”类。我们将别名“unsigned int”以避免编写一个很长的名称：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s add a constructor for this, which will take the size of the data
    or hash map:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为此添加一个构造函数，它将接受数据或哈希映射的大小：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As shown here, we're using `–1` to indicate the absence of an element. This
    is the only negative value we'll use as data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，我们使用“-1”来表示元素的缺失。这是我们作为数据使用的唯一负值。
- en: 'Let''s add the `insert` function:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们添加“insert”函数：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As we can see, we are not really checking whether there was a value already
    present with the same hash value. We're simply overwriting if any value is already
    present. So, for a given hash value, only the latest inserted value will be stored.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们并没有真正检查是否已经存在具有相同哈希值的值。我们只是覆盖了已经存在的任何值。因此，对于给定的哈希值，只有最新插入的值将被存储。
- en: 'Let''s write a lookup function to see whether an element is present in the
    map or not:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写一个查找函数，看看元素是否存在于映射中：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We'll simply check whether the value is present at the index calculated based
    on the hash value.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简单地检查值是否存在于根据哈希值计算的索引处。
- en: 'Let''s implement a `remove` function:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个“remove”函数：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s write a small lambda function in `main` to print the status of the lookup:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在`main`中编写一个小的lambda函数来打印查找的状态：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s use the `insert` and `erase` functions on the map:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在地图上使用`insert`和`erase`函数：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s the output of the program:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是程序的输出：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we can see, we are able to find most of the values we inserted earlier, as
    expected, except for the last case, where `100` is overwritten by `0` because
    they have the same hash value. This is called a collision, as we described previously.
    In the upcoming sections, we'll see how we can avoid this kind of problem to make
    our results more accurate.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们能够找到我们之前插入的大多数值，如预期的那样，除了最后一种情况，其中`100`被`0`覆盖，因为它们具有相同的哈希值。这被称为碰撞，正如我们之前所描述的。在接下来的章节中，我们将看到如何避免这种问题，使我们的结果更准确。
- en: 'The following figures, which demonstrate the different functions from the previous
    exercise, should make this clearer:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了上一个练习中的不同函数，这应该更清楚：
- en: '![Figure 3.2: Basic operations in a hash table](img/C14498_03_02.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2：哈希表中的基本操作](img/C14498_03_02.jpg)'
- en: 'Figure 3.2: Basic operations in a hash table'
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.2：哈希表中的基本操作
- en: '![Figure 3.3: Basic operations in a hash table (continued)](img/C14498_03_03.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3：哈希表中的基本操作（续）](img/C14498_03_03.jpg)'
- en: 'Figure 3.3: Basic operations in a hash table (continued)'
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.3：哈希表中的基本操作（续）
- en: As shown in the preceding figures, we can't insert two elements with the same
    hash value; we have to drop one of them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的图所示，我们无法插入具有相同哈希值的两个元素；我们必须放弃其中一个。
- en: Now, as we mentioned earlier, one major use of hash tables is to find a value
    corresponding to a key, and not just checking whether the key exists. This can
    be simply achieved by storing a key-value pair instead of just the key in the
    data. So, our insertion, deletion, and lookup functions will still calculate the
    hash value based on our key, but once we find the position in the array, we'll
    have our value as the second parameter of the pair.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，正如我们之前提到的，哈希表的一个主要用途是找到与键对应的值，而不仅仅是检查键是否存在。这可以通过存储键值对而不仅仅是数据中的键来简单实现。因此，我们的插入、删除和查找函数仍将根据我们的键计算哈希值，但一旦我们在数组中找到位置，我们的值将作为对的第二个参数。
- en: Collisions in Hash Tables
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希表中的碰撞
- en: In the previous sections, we took a look at how hash tables can help us store
    a lot of keys in a way that makes it easy to look up any required key. However,
    we also encountered a problem where multiple keys had the same hash value, also
    known as a **collision**. In *Exercise 13*, *Basic Dictionary for Integers*, we
    handled this issue by simply rewriting the key and retaining the latest key corresponding
    to a given hash value. However, this does not allow us to store all the keys.
    In the following subtopics, we shall take a look at a couple of approaches that
    help us overcome this problem and allow us to retain all of our key values in
    the hash table.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了哈希表如何帮助我们以一种便于查找任何所需键的方式存储大量键。然而，我们也遇到了一个问题，即多个键具有相同的哈希值，也称为**碰撞**。在*练习13*中，*整数的基本字典*，我们通过简单地重写键并保留与给定哈希值对应的最新键来处理了这个问题。然而，这并不允许我们存储所有的键。在接下来的子主题中，我们将看一下几种方法，这些方法可以帮助我们克服这个问题，并允许我们在哈希表中保留所有的键值。
- en: Close Addressing – Chaining
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 闭合寻址 - 链接
- en: So far, we've only been storing a single element for any hash value. If we already
    have an element for a particular hash value, we have no option but to discard
    either the new value or the old value. The method of `push_back` for new elements)
    is to enable the fast removal of elements from any position. Let's implement this
    in the following exercise.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只为任何哈希值存储了一个单一元素。如果我们已经有一个特定哈希值的元素，我们除了丢弃新值或旧值之外别无选择。`push_back`方法（用于新元素）是为了能够快速从任何位置删除元素。让我们在下一个练习中实现这一点。
- en: 'Exercise 14: Hash Table with Chaining'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习14：使用链表的哈希表
- en: 'In this exercise, we shall implement a hash table and use chaining to handle
    collisions. Let''s get started:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将实现一个哈希表，并使用链接来处理碰撞。让我们开始吧：
- en: 'First, let''s include the required headers:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们包括所需的头文件：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let''s add the `hash_map` class. We''ll alias `unsigned int` to avoid
    writing a long name:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加`hash_map`类。我们将别名`unsigned int`以避免编写一个很长的名称：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let''s add a constructor for `hash_map` that will take the size of the
    data or hash map:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为`hash_map`添加一个构造函数，该构造函数将接受数据或哈希映射的大小：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s add an `insert` function:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们添加一个`insert`函数：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we can see, we are always inserting the value in the data. One alternative
    could be to search for the value and insert it only if the value is not present.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们总是在数据中插入值。一个替代方法是搜索该值，并仅在该值不存在时插入。
- en: 'Let''s write the lookup function to see whether an element is present in the
    map:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写查找函数，以查看地图中是否存在元素：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As we can see, our lookup seems faster than conventional methods, but not as
    fast as it was earlier. This is because now, it is also dependent on the data,
    as well as the value of `n`. We'll come back to this point again after this exercise.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的查找似乎比传统方法更快，但不像之前那样快。这是因为现在它也依赖于数据，以及`n`的值。在这个练习之后，我们将再次回到这一点。
- en: 'Let''s implement a function to remove elements:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个函数来删除元素：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s write the same `main` function as in the previous exercise and look
    at the difference:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编写与上一个练习中相同的`main`函数，并查看其中的区别：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s use the `insert` and `erase` functions on `map`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在`map`上使用`insert`和`erase`函数：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here''s the output of our program:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们程序的输出：
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As we can see, the values are not overwritten because we can store any number
    of values in the list. Hence, our output is completely accurate and reliable.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，值没有被覆盖，因为我们可以在列表中存储任意数量的值。因此，我们的输出是完全准确和可靠的。
- en: 'The following images illustrate how different operations are performed on a
    dataset:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片说明了如何在数据集上执行不同的操作：
- en: '![Figure 3.4: Basic operations on a hash table with chaining](img/C14498_03_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4：哈希表上的基本操作（链接）](img/C14498_03_04.jpg)'
- en: 'Figure 3.4: Basic operations on a hash table with chaining'
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.4：使用链接的哈希表的基本操作
- en: '![Figure 3.5: Basic operations on a hash table with chaining (continued)](img/C14498_03_05.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5：使用链接的哈希表的基本操作（续）](img/C14498_03_05.jpg)'
- en: 'Figure 3.5: Basic operations on a hash table with chaining (continued)'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.5：使用链接的哈希表的基本操作（续）
- en: As we can see, we are appending elements with the same hash value in a list
    placed in the node instead of a single element.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们将具有相同哈希值的元素附加到节点中的列表中，而不是单个元素。
- en: Now, let's consider the time complexity of these operations. As we saw, the
    insertion function is still *O(1)*. Although `push_back` may be a bit slower than
    just setting a value, it is not significantly slower. Considering the problem
    that this approach solves, it is a small price to pay. But lookup and deletion
    may be significantly slower, depending on our hash table's size and dataset. For
    example, if all the keys have the same hash value, the time required for the search
    will be O(n), as it will simply become a linear search in a linked list.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑这些操作的时间复杂度。正如我们所看到的，插入函数仍然是*O(1)*。虽然`push_back`可能比仅设置一个值慢一些，但并不显著慢。考虑到这种方法解决的问题，这是一个小代价。但查找和删除可能会显著慢一些，这取决于我们的哈希表大小和数据集。例如，如果所有的键都具有相同的哈希值，搜索所需的时间将是O(n)，因为它将简单地成为链表中的线性搜索。
- en: If the hash table is very small compared to the number of keys to be stored,
    there will be a lot of collisions, and the lists will be longer on average. On
    the other hand, if we keep a very big hash table, we may end up having very sparse
    data and end up wasting memory. So, the hash table's size should be optimized
    based on the application's context and scenario. We can define these things mathematically
    as well.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果哈希表与要存储的键的数量相比非常小，将会有很多碰撞，并且平均而言列表会更长。另一方面，如果我们保留一个非常大的哈希表，可能会最终产生非常稀疏的数据，并最终浪费内存。因此，哈希表的大小应该根据应用程序的上下文和情景进行优化。我们也可以在数学上定义这些事情。
- en: 'The **load factor** indicates the average number of keys present per list in
    our hash table. It can be computed using the following formula:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**负载因子**表示哈希表中每个列表中存在的平均键的数量。它可以使用以下公式计算：'
- en: '![Figure 3.6: Load factor](img/C14498_03_06.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6：负载因子](img/C14498_03_06.jpg)'
- en: 'Figure 3.6: Load factor'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.6：负载因子
- en: If the number of keys is equal to our hash table size, the load factor will
    be *1*. This is an ideal scenario; we'll get close to *O(1)* for all the operations,
    and all the space will be utilized properly.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果键的数量等于我们的哈希表大小，负载因子将是*1*。这是一个理想的情况；我们将接近*O(1)*的所有操作，并且所有的空间将被充分利用。
- en: If the value is less than *1*, this means that we are not storing even one key
    per list (assuming we want a list at every index) and essentially wasting some
    space.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果值小于*1*，这意味着我们甚至没有在每个列表中存储一个键（假设我们希望在每个索引处都有一个列表），实际上浪费了一些空间。
- en: If the value is more than *1*, this implies that the average length of our lists
    is more than 1, and hence our find and removal functions will be a bit slower
    on average.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果值大于*1*，这意味着我们的列表的平均长度大于1，因此我们的查找和删除函数在平均情况下会慢一些。
- en: The value of the load factor can be computed in *O(1)* at any time. Some advanced
    hash table implementations make use of this value to modify the hash function
    (also known as rehashing) if the value crosses certain thresholds on either side
    of 1\. The hash function is modified so that the load factor is moved closer to
    1\. Then, the size of the hash table can be updated according to our load factor
    and the values redistributed based on the updated hash function. Rehashing is
    an expensive operation, and hence should not be performed too frequently. But
    if it is applied with a proper strategy, we can achieve really good results in
    terms of average time complexity.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 负载因子的值可以在任何时候以*O(1)*的时间计算。一些高级的哈希表实现利用这个值来修改哈希函数（也称为重新散列），如果该值跨过1的某些阈值。哈希函数被修改，以使负载因子更接近1。然后，哈希表的大小可以根据我们的负载因子进行更新，并根据更新后的哈希函数重新分配值。重新散列是一个昂贵的操作，因此不应该太频繁地执行。但是，如果应用了适当的策略，我们可以在平均时间复杂度方面取得非常好的结果。
- en: 'However, the load factor is not the only factor determining the performance
    of this technique. Consider the following scenario: We have a hash table of size
    *7* and it has seven elements. However, all of them have the same hash value,
    and hence all of them are present in a single bucket. So, the search will always
    take *O(n)* instead of *O(1)* time. However, the load factor will be 1, which
    is an absolutely ideal value. Here, the actual problem is the hash function. The
    hash function should be designed in such a way that different keys are distributed
    as evenly as possible across all the possible indexes. Basically, the difference
    between the minimum bucket size and the maximum bucket size should not be very
    high (which is seven in this case). If the hash function is designed in a way
    that all seven elements get different hash values, then all the search function
    calls will result in *O(1)* complexity and instant results. This is because the
    difference between the min and max bucket size will be *0*. However, this is usually
    not done in hash table implementation. It is supposed to be taken care of by the
    hash function itself because the hash table is not dependent on the implementation
    of the hash function.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，负载因子并不是决定这种技术性能的唯一因素。考虑以下情景：我们有一个大小为*7*的哈希表，它有七个元素。然而，它们全部具有相同的哈希值，因此全部存在于一个单独的桶中。因此，搜索将始终需要*O(n)*的时间，而不是*O(1)*的时间。然而，负载因子将是1，这是一个绝对理想的值。在这里，实际的问题是哈希函数。哈希函数应该被设计成以尽可能均匀地分布不同的键到所有可能的索引中。基本上，最小桶大小和最大桶大小之间的差异不应该太大（在这种情况下是七）。如果哈希函数被设计成所有七个元素都获得不同的哈希值，那么所有的搜索函数调用将导致*O(1)*的复杂度和即时结果。这是因为最小和最大桶大小之间的差异将为*0*。然而，这通常不是哈希表实现中所做的。它应该由哈希函数本身来处理，因为哈希表不依赖于哈希函数的实现。
- en: Open Addressing
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开放寻址
- en: Another method for resolving collisions is **open addressing**. In this method,
    we store all the elements inside the hash table instead of chaining the elements
    to the hash table. Hence, to accommodate all the elements, the size of the hash
    table must be greater than the number of elements. The idea is to probe if a cell
    corresponding to a particular hash value is already occupied. There are multiple
    ways we can probe the value, as we shall see in the following subtopics.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 解决碰撞的另一种方法是**开放寻址**。在这种方法中，我们将所有元素存储在哈希表中，而不是将元素链接到哈希表。因此，为了容纳所有元素，哈希表的大小必须大于元素的数量。其思想是探测特定哈希值对应的单元格是否已被占用。我们可以通过多种方式来探测值，我们将在以下子主题中看到。
- en: '**Linear probing**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性探测**'
- en: This is a simple probing technique. If there is a collision at a particular
    hash value, we can simply look at the subsequent hash value for an empty cell
    and insert our element once we find room for it. If the cell at *hash(x)* is full,
    then we need to check whether the cell at *hash(x + 1)* is empty. If it is also
    full, look at *hash(x + 2)*, and so on.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种简单的探测技术。如果在特定哈希值处发生碰撞，我们可以简单地查看后续的哈希值，找到一个空单元并在找到空间后插入我们的元素。如果*hash(x)*处的单元格已满，则需要检查*hash(x
    + 1)*处的单元格是否为空。如果它也已满，再看*hash(x + 2)*，依此类推。
- en: 'The following figure illustrates how linear probing works:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了线性探测的工作原理：
- en: '![Figure 3.7: Basic operations on a hash table with linear probing](img/C14498_03_07.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7：使用线性探测的哈希表上的基本操作](img/C14498_03_07.jpg)'
- en: 'Figure 3.7: Basic operations on a hash table with linear probing'
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.7：使用线性探测的哈希表上的基本操作
- en: '![Figure 3.8: Unable to insert elements after hash table fills up](img/C14498_03_08.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图3.8：哈希表填满后无法插入元素](img/C14498_03_08.jpg)'
- en: 'Figure 3.8: Unable to insert elements after hash table fills up'
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.8：哈希表填满后无法插入元素
- en: As we can see, we are inserting an element in the next available slot if the
    position corresponding to its hash value is already occupied. After inserting
    the first three elements, we can see that they are clustered together. If more
    elements are inserted in the same range, all of them will go at the end of the
    cluster consecutively, thus making the cluster grow. Now, when we try to search
    for a value that is not present at the location first calculated by the hash function,
    but is present at the end of a big cluster, we have to search through all the
    keys in the cluster linearly. And therefore, the search becomes drastically slow.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，如果与其哈希值对应的位置已被占用，我们会将元素插入到下一个可用的插槽中。在插入了前三个元素后，我们可以看到它们聚集在一起。如果在相同范围内插入更多元素，它们都将连续地放在聚集的末尾，从而使聚集增长。现在，当我们尝试搜索一个不在哈希函数计算的位置上，但在一个大聚集的末尾的值时，我们必须线性搜索整个聚集中的所有键。因此，搜索变得极其缓慢。
- en: Thus, we have a major problem if the data is densely clustered. We can say that
    the data is densely clustered if the data is distributed in such a way that there
    are some groups around which the frequency of values is very high. For example,
    let's say that if there are a lot of keys with a hash value of *3* to *7* in a
    hash table of *100*. All the keys will be probed to some values consecutively
    after that, and it will slow down our searching drastically.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果数据密集聚集，我们会遇到一个主要问题。我们可以说数据密集聚集，如果数据分布方式是某些组围绕着非常高频率的值。例如，假设在大小为100的哈希表中有很多哈希值为3到7的键。所有键将在此范围内连续探测到一些值，这将极大地减慢我们的搜索速度。
- en: '**Quadratic probing**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**二次探测**'
- en: As we saw, the major problem with linear probing was clustering. The reason
    behind this was that we were going linearly in the case of collisions. This problem
    can be resolved to a large extent by using a quadratic equation instead of a linear
    one. And that's what quadratic probing provides.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，线性探测的主要问题是聚集。其原因是在碰撞的情况下我们是线性探测的。这个问题可以通过使用二次方程而不是线性方程来解决。这就是二次探测提供的。
- en: First, we try to insert the value *x* at the position *hash(x)*. If that position
    is already occupied, we go to the position *hash(x + 1**2**)*, and then *hash(x
    + 2**2**)*, and so on. So, we increase the offset in a quadratic fashion and thus
    decrease the probability of creating small clusters of data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们尝试将值*x*插入到位置*hash(x)*。如果该位置已被占用，我们继续到位置*hash(x + 1**2**)*，然后*hash(x + 2**2**)*，依此类推。因此，我们以二次方式增加偏移量，从而降低了创建小数据集的概率。
- en: There is one more advantage of both probing techniques – the position of an
    element can be affected by other elements that don't have the same hash value.
    So, basically, even if there's just one key with a certain hash value, it can
    collide because of some other element is present in that location, which was not
    the case with chaining. For example, in linear probing, if we have two keys with
    a hash value of 4, one of them will be inserted at position 4 and the other will
    be inserted at position 5\. Next, if we need to insert a key with a hash value
    of 5, it will need to be inserted at 6\. This key was affected even though it
    did not have the same hash value as any other key.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种探测技术还有一个优势 - 元素的位置可能会受到没有相同哈希值的其他元素的影响。因此，即使只有一个具有特定哈希值的键，也可能会因为该位置存在其他元素而发生碰撞，而这在链接中是不会发生的。例如，在线性探测中，如果我们有两个哈希值为4的键，其中一个将被插入到位置4，另一个将被插入到位置5。接下来，如果我们需要插入一个哈希值为5的键，它将需要插入到6。即使它与任何其他键的哈希值不同，这个键也受到了影响。
- en: Perfect Hashing – Cuckoo Hashing
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完美哈希 - 布谷鸟哈希
- en: As the heading suggests, **cuckoo hashing** is one of the perfect hashing techniques.
    The methods we mentioned previously don't provide a guarantee of *O(1)* time complexity
    in the worst case, but cuckoo hashing can achieve that if implemented properly.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 正如标题所示，**布谷鸟哈希**是完美哈希技术之一。我们之前提到的方法在最坏情况下不能保证*O(1)*的时间复杂度，但是如果正确实现，布谷鸟哈希可以实现这一点。
- en: In cuckoo hashing, we keep two hash tables of the same size, each with their
    own unique hash function. Any element can be present in either of the hash tables,
    and its position is based on the corresponding hash function.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在布谷鸟哈希中，我们保持两个相同大小的哈希表，每个哈希表都有自己独特的哈希函数。任何元素都可以存在于任一哈希表中，并且其位置基于相应的哈希函数。
- en: 'There are two main ways in which cuckoo hashing differs from our previous hashing
    techniques:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 布谷鸟哈希与我们以前的哈希技术有两种主要不同之处：
- en: Any element can be present in any of the two hash tables.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何元素都可以存在于两个哈希表中的任何一个。
- en: Any element can be moved to another location in the future, even after insertion.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何元素都可以在将来移动到另一个位置，即使在插入后。
- en: Earlier hashing techniques did not allow elements to be moved after insertion
    unless we did a complete rehashing, but this is not the case with cuckoo hashing
    because any element can have two possible locations. We can still increase the
    degree by increasing the number of possible locations for any element so that
    we gain better results and have less frequent rehashing. However, in this chapter,
    we'll only look at the version with two possible locations (hash tables) because
    it's easier to understand.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的哈希技术在插入后不允许元素移动，除非我们进行完全的重新哈希，但布谷鸟哈希不是这样，因为任何元素都可以有两个可能的位置。我们仍然可以通过增加任何元素的可能位置的数量来增加程度，以便获得更好的结果并减少频繁的重新哈希。然而，在本章中，我们只会看两个可能位置（哈希表）的版本，因为这样更容易理解。
- en: For lookup, we only need to look at two positions to determine whether the element
    is present or not. Hence, a lookup always requires *O(1)* time.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于查找，我们只需要查看两个位置来确定元素是否存在。因此，查找总是需要 *O(1)* 的时间。
- en: 'However, an insertion function can take a longer time. An insertion function,
    in this case, first checks whether it is possible to insert the new element, let''s
    say *A*, in the first hash table. If so, it inserts the element there, and we
    are done. But if that position is occupied by a preexisting element, let''s say
    *B*, we still go ahead with inserting *A* and move *B* to the second hash table.
    If this new position in the second hash table is also occupied, let''s say by
    element *C*, we again insert *B* there and move *C* to the first table. We can
    carry this on recursively until we are able to find empty slots for all the elements.
    This process is illustrated in the following figure:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，插入函数可能需要更长的时间。在这种情况下，插入函数首先检查是否可能将新元素（比如 *A*）插入第一个哈希表中。如果可以，它就在那里插入元素，然后完成。但是，如果该位置被现有元素（比如
    *B*）占据，我们仍然继续插入 *A* 并将 *B* 移动到第二个哈希表中。如果第二个哈希表中的新位置也被占据（比如元素 *C*），我们再次在那里插入 *B*
    并将 *C* 移动到第一个表中。我们可以递归地进行这个过程，直到我们能够为所有元素找到空槽。这个过程在下图中有所说明：
- en: '![Figure 3.9: Cuckoo hashing](img/C14498_03_09.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图3.9：布谷鸟哈希](img/C14498_03_09.jpg)'
- en: 'Figure 3.9: Cuckoo hashing'
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.9：布谷鸟哈希
- en: 'One major problem is that we could end up in a cycle and the recursion may
    lead to an infinite loop. For the example in the previous paragraph, consider
    that there is an element, *D*, where we wish to insert *C*, but if we try to move
    *D*, it goes to the location of *A*. Thus, we are in an infinite cycle. The following
    figure should help you visualize this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一个主要问题是我们可能会陷入循环，递归可能导致无限循环。对于前面段落中的例子，考虑我们希望插入 *C* 的元素 *D*，但如果我们尝试移动 *D*，它会到达
    *A* 的位置。因此，我们陷入了无限循环。下图应该帮助您可视化这一点：
- en: '![Figure 3.10: A cycle formed during cuckoo hashing](img/C14498_03_10.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图3.10：布谷鸟哈希中形成的循环](img/C14498_03_10.jpg)'
- en: 'Figure 3.10: A cycle formed during cuckoo hashing'
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.10：布谷鸟哈希中形成的循环
- en: To address this, once we've identified the cycle, we need to rehash everything
    with new hash functions. The hash tables that were created with new hash functions
    may still have the same problems, so we may have to rehash and try out different
    hash functions. However, with smart strategies and wisely chosen hash functions,
    we can achieve a performance of amortized *O(1)* with high probability.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，一旦我们确定了循环，我们需要使用新的哈希函数重新对所有内容进行哈希。使用新哈希函数创建的哈希表可能仍然存在相同的问题，因此我们可能需要重新哈希并尝试不同的哈希函数。然而，通过聪明的策略和明智选择的哈希函数，我们可以以高概率实现摊销
    *O(1)* 的性能。
- en: Just like open addressing, we can't store more elements than the combined size
    of the hash tables. To ensure good performance, we should make sure that our load
    factor is less than 50%, that is, the number of elements should be less than half
    of the available capacity.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 就像开放寻址一样，我们不能存储比哈希表的总大小更多的元素。为了确保良好的性能，我们应该确保负载因子小于50%，也就是说，元素的数量应该小于可用容量的一半。
- en: We'll take a look at the implementation of cuckoo hashing in the following exercise.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一个练习中看一下布谷鸟哈希的实现。
- en: 'Exercise 15: Cuckoo Hashing'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习15：布谷鸟哈希
- en: 'In this exercise, we''ll implement cuckoo hashing to create a hash table and
    insert various elements in it. We shall also get a trace of how the operation
    proceeds, which will allow us to take a look at how insertion works. Let''s get
    started:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将实现布谷鸟哈希来创建一个哈希表，并在其中插入各种元素。我们还将获得操作进行的跟踪，这将允许我们查看插入是如何工作的。让我们开始吧：
- en: 'Let''s start by including the required headers, as usual:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们像往常一样包括所需的头文件：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s add a class for the hash map. We''ll also store size separately this
    time:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为哈希映射添加一个类。这次我们也将单独存储大小：
- en: '[PRE19]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we can see, we use two tables.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们使用了两个表。
- en: 'Now, let''s add the corresponding hash functions:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加相应的哈希函数：
- en: '[PRE20]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, we have kept both functions very simple, but these functions can be adapted
    as per the requirements.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将两个函数都保持得非常简单，但这些函数可以根据需求进行调整。
- en: 'Now, let''s add a constructor that will set our data for initialization:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加一个构造函数，用于设置我们的数据进行初始化：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As we can see, we are simply initializing both the data tables as empty (indicated
    by `–1`).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们只是将两个数据表都初始化为空（用 `–1` 表示）。
- en: 'Let''s write a `lookup` function first:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先编写一个 `lookup` 函数：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We are trying to find the key in both tables and return the relevant iterator
    if one is found. We don't always need the iterator, but we'll use it in the deletion
    function to make things easier. We are returning the end of the `data2` table
    if the element is not found. As we can see, the lookup will have a time complexity
    of *O(1)* and will be performed pretty quickly.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们试图在两个表中找到键，并在找到时返回相关的迭代器。我们并不总是需要迭代器，但我们将在删除函数中使用它以简化事情。如果未找到元素，我们将返回`data2`表的末尾。正如我们所看到的，查找将具有*O(1)*的时间复杂度，并且将被执行得非常快速。
- en: 'Let''s implement a delete function:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实现一个删除函数：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As we can see, most of the job is done by calling the `lookup` function. We
    just need to validate the result and reset the value to remove it from the table.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，大部分工作是通过调用`lookup`函数完成的。我们只需要验证结果并重置值以将其从表中移除。
- en: 'For insertion, we shall implement the actual logic in a different function
    because it will be recursive. One more thing we want to do is avoid cycles. However,
    keeping a record of all the values that are visited can be costly. To avoid that,
    we will simply stop the function once it is called more than n times. Since the
    threshold of the recursion depth of n is dependent on our memory (or hash table
    size), this gives good performance:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于插入，我们将在不同的函数中实现实际逻辑，因为它将是递归的。我们还想要避免循环。然而，保留所有访问过的值的记录可能代价高昂。为了避免这种情况，我们将简单地在函数被调用超过n次时停止函数。由于递归深度n的阈值取决于我们的内存（或哈希表大小），这样可以获得良好的性能：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As we can see, the implementation takes three parameters – the key, the table
    in which we want to insert the key, and the count of the recursion call stack
    to keep track of the number of elements we have changed the positions of.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，实现需要三个参数-键、我们要插入键的表以及递归调用堆栈的计数，以跟踪我们已经改变位置的元素数量。
- en: 'Now, let''s write a utility function to print the data inside the hash tables.
    Although this is not really necessary and shouldn''t be exposed, we will do that
    so that we can get a better understanding of how our insert function is managing
    the data internally:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编写一个实用函数来打印哈希表中的数据。虽然这并不是真正必要的，也不应该暴露，但我们将这样做，以便更好地了解我们的插入函数如何在内部管理数据：
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, let''s write the `main` function so that we can use this hash map:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编写`main`函数，以便我们可以使用这个哈希映射：
- en: '[PRE26]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You should see the following output:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该看到以下输出：
- en: '[PRE27]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As we can see, the output is showing the complete trace of how both the tables
    are maintained internally. We have printed the internal steps because some values
    are being moved around. The last insertion of `14` leads to a cycle, as we can
    see from the trace. The depth of insertion has gone beyond `7`. Simultaneously,
    we can also see that both the tables are almost full. We've filled `11` elements
    out of `14`, and hence the chance of replacing values is increasing at each step.
    We printed the table just before the cycle as well.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，输出显示了内部维护两个表的完整跟踪。我们打印了内部步骤，因为一些值正在移动。我们可以从跟踪中看到，`14`的最后插入导致了一个循环。插入的深度已经超过了`7`。同时，我们还可以看到两个表几乎已经满了。我们已经填充了`14`中的`11`个元素，因此在每一步替换值的机会都在增加。我们还在循环之前打印了表。
- en: Also, the deletion of an element takes *O(1)* time here because it just uses
    the `lookup` function and deletes the element, if found. So, the only function
    that is costly is insertion. Hence, this is an ideal implementation if the number
    of insertions is quite a bit lower than the number of lookups in any application.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这里删除元素的时间复杂度为*O(1)*，因为它只是使用`lookup`函数并删除元素（如果找到）。因此，唯一昂贵的函数是插入。因此，如果在任何应用程序中插入的数量要比查找的数量少得多，这是一个理想的实现。
- en: 'Let''s use the following visual aids so that we can understand this better:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下视觉辅助工具，以便更好地理解这一点：
- en: '![Figure 3.11: Inserting elements in a hash table that uses cuckoo hashing](img/C14498_03_11.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图3.11：在使用布谷鸟哈希的哈希表中插入元素](img/C14498_03_11.jpg)'
- en: 'Figure 3.11: Inserting elements in a hash table that uses cuckoo hashing'
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.11：在使用布谷鸟哈希的哈希表中插入元素
- en: '![Figure 3.12: Handling collisions in a hash table using cuckoo hashing](img/C14498_03_12.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12：使用布谷鸟哈希处理哈希表中的碰撞](img/C14498_03_12.jpg)'
- en: 'Figure 3.12: Handling collisions in a hash table using cuckoo hashing'
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.12：使用布谷鸟哈希处理哈希表中的碰撞
- en: '![Figure 3.13: Handling collisions in a hash table using cuckoo hashing (continued)](img/C14498_03_13.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图3.13：使用布谷鸟哈希处理哈希表中的碰撞（续）](img/C14498_03_13.jpg)'
- en: 'Figure 3.13: Handling collisions in a hash table using cuckoo hashing (continued)'
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.13：使用布谷鸟哈希处理哈希表中的碰撞（续）
- en: '![Figure 3.14: Finding values in a hash table that uses cuckoo hashing](img/C14498_03_14.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14：在使用布谷鸟哈希的哈希表中查找值](img/C14498_03_14.jpg)'
- en: 'Figure 3.14: Finding values in a hash table that uses cuckoo hashing'
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.14：在使用布谷鸟哈希的哈希表中查找值
- en: '![Figure 3.15: Erasing values in a hash table that uses cuckoo hashing](img/C14498_03_15.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15：在使用布谷鸟哈希的哈希表中删除值](img/C14498_03_15.jpg)'
- en: 'Figure 3.15: Erasing values in a hash table that uses cuckoo hashing'
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.15：在使用布谷鸟哈希的哈希表中删除值
- en: As we can see from the preceding series of figures, first, we try to insert
    elements in the first table. If there's already another element, we overwrite
    it and insert the preexisting element in the other table. We repeat this until
    it is safe to insert the last element.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从前面一系列的图中所看到的，首先，我们尝试在第一个表中插入元素。如果已经有另一个元素，我们将覆盖它并将现有元素插入到另一个表中。我们重复这个过程，直到安全地插入最后一个元素。
- en: C++ Hash Tables
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++哈希表
- en: As we mentioned previously, the lookup operation is quite frequent in most applications.
    However, we may not always encounter positive integers, which are quite easy to
    hash. You are likely to encounter strings most of the time. Consider the example
    of an English language dictionary that we considered earlier. We can store the
    dictionary data by using the words as keys and the word definitions as the values.
    Another example is the hospital records database we considered in *Chapter 1*,
    *Lists, Stacks, and Queues*, where the patients' names may be used as keys, and
    other related information could be stored as values.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，查找操作在大多数应用程序中是非常频繁的。然而，我们可能并不总是遇到正整数，这些很容易进行哈希。大部分时间你可能会遇到字符串。考虑我们之前考虑过的英语词典的例子。我们可以使用单词作为键，单词定义作为值来存储词典数据。另一个例子是我们在*第1章*，*列表、栈和队列*中考虑过的医院记录数据库，患者的姓名可能被用作键，其他相关信息可以作为值存储。
- en: The simple modulo function we used earlier to calculate the hash values of integers
    does not work for strings. An easy option is to calculate the modulo of the sum
    of the ASCII values of all the characters. However, all the permutations of characters
    in a string would be quite vast, and this would create a lot of collisions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前使用的简单取模函数来计算整数的哈希值对于字符串不起作用。一个简单的选择是计算所有字符的ASCII值的总和的模。然而，字符串中字符的所有排列可能非常庞大，这将导致很多碰撞。
- en: C++ provides a function called `std::hash<std::string>(std::string)` that we
    can use to generate hash values of string. It has a built-in algorithm to take
    care of the hashing function. Similarly, C++ provides such functions for all the
    basic types of data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: C++提供了一个名为`std::hash<std::string>(std::string)`的函数，我们可以用它来生成字符串的哈希值。它有一个内置算法来处理哈希函数。同样，C++为所有基本数据类型提供了这样的函数。
- en: 'Now, looking at the hash table we implemented in *Exercise 14*, *Hash Table
    with Chaining*, it seems obvious that we can simply templatize it based on the
    data type and make a generic solution to provide a hash function for any given
    type of data. STL provides a couple of solutions for this: `std::unordered_set<Key>`
    and `std::unordered_map<Key, Value>`. An unordered set can only store a set of
    keys, whereas an unordered map can store the keys and their values. So, each unique
    key will have a corresponding value in the container.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，看看我们在*练习14*中实现的哈希表，*链式哈希表*，很明显我们可以根据数据类型简单地将其模板化，并提供一个通用解决方案来为任何给定类型的数据提供哈希函数。STL为此提供了几种解决方案：`std::unordered_set<Key>`和`std::unordered_map<Key,
    Value>`。无序集合只能存储一组键，而无序映射可以存储键和它们的值。因此，容器中的每个唯一键都将有一个相应的值。
- en: Both of these containers are implemented in the same way – using hash tables
    with chaining. Each row in the hash table is a vector that stores the keys (and
    the values for the map). The rows are known as **buckets**. So, after calculating
    the hash value for a key, it will be placed into one of the buckets. Each bucket
    is also a list to support chaining.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个容器都是以相同的方式实现的 - 使用链式哈希表。哈希表中的每一行都是一个存储键（和映射的值）的向量。这些行被称为**桶**。因此，在计算密钥的哈希值后，它将被放置到其中一个桶中。每个桶也是一个列表，以支持链式处理。
- en: By default, these containers have a maximum load factor of *1*. As soon as the
    number of elements exceeds the size of the hash table, the hash function will
    be changed, the hash values will be recalculated (rehashing), and a larger hash
    table will be rebuilt to bring down the load factor. We can also use the `rehash`
    function to do this manually. This default maximum limit of *1* for the load factor
    can be changed using the `max_load_factor(float)` function. The values will be
    rehashed once the load factor exceeds the defined maximum limit.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，这些容器的最大负载因子为*1*。一旦元素数量超过哈希表的大小，哈希函数将被更改，哈希值将被重新计算（重新散列），并且将重新构建一个更大的哈希表以降低负载因子。我们也可以使用`rehash`函数手动执行此操作。使用`max_load_factor(float)`函数可以更改负载因子的默认最大限制为*1*。一旦负载因子超过定义的最大限制，值将被重新散列。
- en: These containers provide commonly useful functions such as `find`, `insert`,
    and `erase`. They also provide iterators to iterate over all the elements, as
    well as constructors to create an unordered set and map using other containers,
    such as vectors and arrays. An unordered map also provides `operator[]` so that
    it can return the value for a known key.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这些容器提供了常用的函数，如`find`，`insert`和`erase`。它们还提供迭代器来遍历所有元素，以及使用其他容器（如向量和数组）创建无序集合和映射的构造函数。无序映射还提供`operator[]`，以便它可以返回已知键的值。
- en: We'll look at the implementation of unordered sets and maps in the following
    exercise.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一个练习中看一下无序集合和映射的实现。
- en: 'Exercise 16: Hash Tables Provided by STL'
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习16：STL提供的哈希表
- en: 'In this exercise, we shall implement unordered sets and maps and apply operations
    such as insertion, deletion, and find on these containers. Let''s get started:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将实现无序集合和映射，并对这些容器进行插入、删除和查找等操作。让我们开始吧：
- en: 'Include the required headers:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包括所需的头文件：
- en: '[PRE28]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, let''s write some simple `print` functions to make our `main` function
    more readable:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编写一些简单的`print`函数，以使我们的`main`函数更易读：
- en: '[PRE29]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Similarly, add wrappers over the `find` functions to keep the code neat:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，添加对`find`函数的包装器，以保持代码整洁：
- en: '[PRE30]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, write the `main` function so that we can use `unordered_set` and `unordered_map`,
    and then perform various operations on it. We shall find, insert, and erase the
    elements:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，编写`main`函数，以便我们可以使用`unordered_set`和`unordered_map`，然后对其执行各种操作。我们将查找、插入和删除元素：
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'One of the possible outputs of this program is as follows. The order of elements
    in a set and a map can be different, and hence is called an *unordered* set/map:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个程序的可能输出之一如下。集合和映射中元素的顺序可能不同，因此被称为*无序*集合/映射：
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As we can see, we can insert, find, and erase elements from both containers.
    These operations are working as expected. If we benchmark these operations against
    other containers, such as vector, list, array, deque, and so on, performance will
    be much faster here.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们可以向这两个容器插入、查找和删除元素。这些操作都按预期工作。如果我们将这些操作与其他容器（如vector、list、array、deque等）进行基准测试，性能会更快。
- en: We can store key-value pairs and access the value for any given key using `operator[]`,
    as shown in this exercise. It returns a reference and hence also allows us to
    set the value, and not just retrieve it.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以存储键值对，并使用`operator[]`访问任何给定键的值，就像本练习中所示的那样。它返回一个引用，因此还允许我们设置值，而不仅仅是检索它。
- en: Note
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Since `operator[]` returns a reference, if the key is not found, it will add
    the default value to the entry.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`operator[]`返回一个引用，如果找不到键，它将向条目添加默认值。
- en: In the last line, we are getting `map[100] = 0`, even if `100` was never inserted
    in the map. This is because `operator[]` is returning the default value.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一行，我们得到了`map[100] = 0`，即使`100`从未被插入到映射中。这是因为`operator[]`返回了默认值。
- en: If we want to keep track of the number of buckets as they change based on rehashing,
    we can do that using the `bucket_count()` function. There are other functions
    for getting details about other internal parameters as well, such as `load_factor`,
    `max_bucket_count`, and so on. We can also rehash manually using the `rehash`
    function.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要跟踪基于重新散列而更改的桶的数量，我们可以使用`bucket_count()`函数来实现。还有其他函数可以获取有关其他内部参数的详细信息，比如`load_factor`、`max_bucket_count`等等。我们还可以使用`rehash`函数手动重新散列。
- en: Since these containers are implemented using chaining, they are actually storing
    the key/value pairs in different buckets. So, while searching the keys in any
    bucket, we need to compare them for equality. Hence, we need to define the equality
    operator for the key type. Alternatively, we can pass it as another template parameter.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些容器是使用链接实现的，它们实际上将键/值对存储在不同的桶中。因此，在任何桶中搜索键时，我们需要比较它们是否相等。因此，我们需要为键类型定义相等运算符。或者，我们可以将其作为另一个模板参数传递。
- en: As we can have seen in this exercise, unordered sets and maps do not allow duplicate
    keys. If we need to store duplicate values, we can use `unordered_multiset` or
    `unordered_multimap`. To support multiple values, the insert function does not
    check whether the key already exists in the container. Also, it supports some
    extra functions to retrieve all the items with a particular key. We won't look
    at any more details regarding these containers as it is out of the scope of this
    book.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们可以看到，无序集合和映射不允许重复的键。如果我们需要存储重复的值，我们可以使用`unordered_multiset`或`unordered_multimap`。为了支持多个值，插入函数不会检查键是否已经存在于容器中。此外，它支持一些额外的函数来检索具有特定键的所有项。我们不会再深入研究这些容器的细节，因为这超出了本书的范围。
- en: 'STL provides hash functions for all the basic data types supported by C++.
    So, if we want a custom class or struct as the key type for any of the aforementioned
    containers, we need to implement a hash function inside the `std` namespace. Alternatively,
    we can pass it as a template parameter. However, writing a hash function on our
    own every time is not a good idea because the performance heavily depends on it.
    Designing a hash function requires quite a bit of research and understanding of
    the problem at hand, as well as mathematical skills. Hence, we are leaving it
    out of the scope of this book. For our purposes, we can simply use the `hash_combine`
    function provided in the `boost` library, as shown in the following example:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: STL为C++支持的所有基本数据类型提供了哈希函数。因此，如果我们想要将自定义类或结构作为前述容器中的键类型，我们需要在`std`命名空间内实现一个哈希函数。或者，我们可以将其作为模板参数传递。然而，每次都自己编写哈希函数并不是一个好主意，因为性能在很大程度上取决于它。设计哈希函数需要进行相当多的研究和对手头问题的理解，以及数学技能。因此，我们将其排除在本书的范围之外。对于我们的目的，我们可以简单地使用`boost`库中提供的`hash_combine`函数，就像下面的例子中所示的那样。
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As we can see, we've defined a hashing struct with `operator()`, which will
    be used by unordered containers. We have also defined the comparator struct with
    `operator()` to support relevant functions. We have passed these structs as template
    parameters. This also allows us to have different types of comparators and hashers
    for different objects.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们已经定义了一个具有`operator()`的哈希结构，它将被无序容器使用。我们还定义了一个具有`operator()`的比较器结构，以支持相关函数。我们将这些结构作为模板参数传递。这也允许我们为不同的对象使用不同类型的比较器和哈希器。
- en: Apart from simple hash functions such as modulo, there are some complex hash
    functions, known as cryptographic hash functions, such as MD5, SHA-1, and SHA-256\.
    These algorithms are very complex, and they can take any kind of data — even a
    file — as the input value. An important characteristic of cryptographic functions
    is that it is very difficult to determine the actual data from a given hash value
    (also known as reverse hashing), and hence they are used in some of the most secure
    systems. For example, the Bitcoin blockchain uses the SHA-256 algorithm to store
    an important proof of authenticity of the transaction records. Each *block* in
    the blockchain contains an SHA-256 hash value of its previous linked block, and
    the current block's hash is included in the subsequent block. Illegally modifying
    any block invalidates the entire blockchain from that block onwards, since now
    the modified block's hash value will not match with the value that was stored
    in the next block. Even with some of the fastest supercomputers in the world,
    it would take hundreds of years to break this and create forged transaction records.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单的哈希函数，如取模，还有一些复杂的哈希函数，称为加密哈希函数，如MD5、SHA-1和SHA-256。这些算法非常复杂，它们可以接受任何类型的数据——甚至是文件——作为输入值。加密函数的一个重要特征是，很难从给定的哈希值确定实际数据（也称为逆哈希），因此它们被用于一些最安全的系统中。例如，比特币区块链使用SHA-256算法来存储交易记录的重要真实性证明。区块链中的每个*块*都包含其前一个链接块的SHA-256哈希值，并且当前块的哈希值包含在后续块中。非法修改任何块将使整个区块链从该块开始无效，因为现在修改后的块的哈希值将与下一个块中存储的值不匹配。即使使用世界上一些最快的超级计算机，也需要数百年才能打破这一点，并创建伪造的交易记录。
- en: 'Activity 6: Mapping Long URLs to Short URLs'
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动6：将长URL映射到短URL
- en: In this activity, we'll create a program to implement a service similar to [https://tinyurl.com/](https://tinyurl.com/).
    It can take a very long URL and map it to a small URL that is easy and convenient
    to share. Whenever we enter the short URL, it should retrieve the original URL.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将创建一个程序来实现类似于[https://tinyurl.com/](https://tinyurl.com/)的服务。它可以将一个非常长的URL映射到一个易于分享的小URL。每当我们输入短URL时，它应该检索原始URL。
- en: 'We want the following functionalities:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要以下功能：
- en: Store the original and corresponding smaller URL provided by the user efficiently
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效地存储用户提供的原始URL和相应的较小URL
- en: Retrieve the original URL based on the given smaller URL if found; otherwise,
    return an error
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果找到，基于给定的较小URL检索原始URL；否则，返回错误
- en: 'These high-level steps should help you solve this activity:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高层次的步骤应该帮助你解决这个活动：
- en: Create a class that contains `unordered_map` as the main data member.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含`unordered_map`作为主要数据成员的类。
- en: 'Add a function to insert values. This function should take two parameters:
    the original URL and the smaller version of it.'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个插入值的函数。这个函数应该接受两个参数：原始URL和它的较小版本。
- en: Add a function to find the actual URL based on a given small URL if present.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个函数来查找基于给定小URL的实际URL（如果存在）。
- en: Note
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found on page 498.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第498页找到。
- en: Bloom Filters
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 布隆过滤器
- en: Bloom filters are extremely space-efficient compared to hash tables, but at
    the cost of deterministic answers; that is, we get an answer that is unsure. It
    only guarantees that there won't be any false negatives, but there may be false
    positives. In other words, if we get a positive hit, the element may or may not
    be present; but if we get a negative, then the element is definitely not present.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 与哈希表相比，布隆过滤器在空间上非常高效，但代价是确定性答案；也就是说，我们得到的答案是不确定的。它只保证不会有假阴性，但可能会有假阳性。换句话说，如果我们得到一个正面的命中，元素可能存在，也可能不存在；但如果我们得到一个负面的命中，那么元素肯定不存在。
- en: Just like cuckoo hashing, we will use multiple hash functions here. However,
    we'll keep three functions, as two functions cannot achieve decent accuracy. The
    fundamental idea is that instead of storing the actual values, we store an array
    of Booleans indicating whether or not a value is (maybe) present.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 就像布谷鸟哈希一样，我们将在这里使用多个哈希函数。然而，我们将保留三个函数，因为两个函数无法达到合理的准确性。基本思想是，我们不存储实际值，而是存储一个布尔数组，指示值是否（可能）存在。
- en: To insert an element, we compute the value of all the hash functions and set
    the bits corresponding to all three hash values in the array to *1*. For lookup,
    we compute the value of all the hash functions and check whether all the corresponding
    bits are set to *1*. If so, we return *true*; otherwise, we return *false* (the
    element is not present).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要插入一个元素，我们计算所有哈希函数的值，并将数组中所有三个哈希值对应的位设置为*1*。对于查找，我们计算所有哈希函数的值，并检查所有相应的位是否都设置为*1*。如果是，我们返回*true*；否则，我们返回*false*（元素不存在）。
- en: The obvious question is – why is lookup indeterministic? The reason is that
    any bit can be set by multiple elements. So, there is a relatively significant
    probability that all the relevant bits for a particular value (call it *x*) are
    set to *1* because of some other elements that were inserted earlier, although
    *x* was not inserted at all. In that case, the lookup function will still return
    *true*. Hence, we can expect some false positives. The more elements we insert,
    the higher the chances of false positives. However, if one of the bits for *x*
    is not set, then we can say that the element is not present with confidence. So,
    false negatives cannot be a possibility.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见的问题是——为什么查找是不确定的？原因是任何位都可以被多个元素设置。因此，有相当大的概率，所有特定值（称为*x*）的相关位都设置为*1*，因为之前插入了一些其他元素，尽管*x*根本没有被插入。在这种情况下，查找函数仍然会返回*true*。因此，我们可以期望一些误报。我们插入的元素越多，误报的机会就越大。然而，如果*x*的某个位没有设置，那么我们可以确定地说元素不存在。因此，假阴性不可能发生。
- en: The array will be saturated when all the bits in the Boolean array are set to
    *1*. So, the lookup function will always return *true*, and the insertion function
    will not have any effect at all since all the bits are already set to *1*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 数组中的所有位都设置为*1*时，数组将饱和。因此，查找函数将始终返回*true*，并且插入函数根本不会产生任何影响，因为所有位已经设置为*1*。
- en: 'The following diagrams make this clearer:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表使这一点更清晰：
- en: '![Figure 3.16: Inserting elements in a bloom filter](img/C14498_03_16.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图3.16：在Bloom过滤器中插入元素](img/C14498_03_16.jpg)'
- en: 'Figure 3.16: Inserting elements in a bloom filter'
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.16：在Bloom过滤器中插入元素
- en: '![Figure 3.17: Finding elements in a bloom filter](img/C14498_03_17.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图3.17：在Bloom过滤器中查找元素](img/C14498_03_17.jpg)'
- en: 'Figure 3.17: Finding elements in a bloom filter'
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.17：在Bloom过滤器中查找元素
- en: '![Figure 3.18: Finding elements in a bloom filter (continued)](img/C14498_03_18.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图3.18：在Bloom过滤器中查找元素（续）](img/C14498_03_18.jpg)'
- en: 'Figure 3.18: Finding elements in a bloom filter (continued)'
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.18：在Bloom过滤器中查找元素（续）
- en: As shown in the preceding diagrams, we are setting the relevant bits based on
    the hash functions, and for insertion, we're doing a bitwise `AND` for lookup
    of the element, as we explained earlier.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图表所示，我们根据哈希函数设置相关位，并且对于插入，我们对元素进行位`AND`查找，就像我们之前解释的那样。
- en: We'll implement a Bloom filter in C++ in the following exercise.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的练习中用C++实现一个Bloom过滤器。
- en: 'Exercise 17: Creating Bloom Filters'
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习17：创建Bloom过滤器
- en: 'In this exercise, we shall create a Bloom filter and try out some basic operations.
    We shall also test for false positives in lookup. Let''s get started:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将创建一个Bloom过滤器并尝试一些基本操作。我们还将测试查找中的误报。让我们开始吧：
- en: 'Let''s include the required headers:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们包括所需的头文件：
- en: '[PRE34]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let''s create a class for our Bloom filter and add the required data members:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为我们的Bloom过滤器创建一个类，并添加所需的数据成员：
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, let''s add the required hash functions. Again, we''ll use very basic hash
    functions:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加所需的哈希函数。同样，我们将使用非常基本的哈希函数：
- en: '[PRE36]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As you can see, we're using single functions, with a parameter called `num`
    determining the hash function, to avoid unnecessary `if`-`else` blocks in other
    functions. This is also easy to expand; we just need to add a case for every hash
    function.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们使用单个函数，参数称为`num`，确定哈希函数，以避免其他函数中不必要的`if`-`else`块。这也很容易扩展；我们只需要为每个哈希函数添加一个情况。
- en: 'Let''s add a constructor for the Bloom filter:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为Bloom过滤器添加一个构造函数：
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, let''s add a `lookup` function:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加一个`lookup`函数：
- en: '[PRE38]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The `lookup` function is really simple, as expected. It checks whether all the
    required bits are set to `1`. If there are a variable number of hash functions,
    we can always loop over all of them to check whether all the corresponding bits
    are set to `1`. To make our words more accurate, we are also saying that a key
    *may be present* due to the possibility of false positives. On the other hand,
    we are completely sure that a key is not present if `lookup` returns negative.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，`lookup`函数非常简单。它检查所有必需的位是否都设置为`1`。如果有可变数量的哈希函数，我们总是可以循环遍历所有这些函数，以检查所有相应的位是否都设置为`1`。为了使我们的话更准确，我们还说由于误报的可能性，一个键*可能存在*。另一方面，如果`lookup`返回负数，我们完全确定一个键不存在。
- en: 'Even the insertion function is equally simple:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 甚至插入函数同样简单：
- en: '[PRE39]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let''s add the `main` function so that we can use this class:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加`main`函数，以便我们可以使用这个类：
- en: '[PRE40]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should see the following output:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该看到以下输出：
- en: '[PRE41]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: As we can see, there are a couple of false positives, but no false negatives.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，有一些误报，但没有错误的否定。
- en: Unlike the previous techniques, this structure only required 11 bits to store
    this information, as we can see from the constructor of the Bloom filter. Thus,
    we can easily increase the size of the filter and also update the hash functions
    accordingly to achieve much better results. For example, we can increase the size
    of the array to 1,000 (1,023 is used frequently as it is a prime number), and
    we'll still be using less than 130 bytes, which is much less than most other techniques.
    With the increase in the size of the hash table, our hash functions will also
    become *%1023* or similar and will provide better results and a better distribution
    of numbers.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前的技术不同，这种结构只需要11位来存储这些信息，正如我们从Bloom过滤器的构造函数中所看到的。因此，我们可以轻松地增加过滤器的大小，并相应地更新哈希函数，以获得更好的结果。例如，我们可以将数组的大小增加到1,000（1,023经常被使用，因为它是一个质数），我们仍然将使用少于130字节，这比大多数其他技术要少得多。随着哈希表大小的增加，我们的哈希函数也将变为*%1023*或类似的，并且将提供更好的结果和更好的数字分布。
- en: One important point to note here is that since we are not storing the actual
    data in the container, we can use this as a heterogeneous structure; that is,
    as long as our hash functions are good enough, we can insert different types of
    data, such as integers, strings, and doubles, simultaneously in the same Bloom
    filter.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一个重要点是，由于我们没有在容器中存储实际数据，我们可以将其用作异构结构；也就是说，只要我们的哈希函数足够好，我们可以同时在同一个Bloom过滤器中插入不同类型的数据，比如整数、字符串和双精度浮点数。
- en: There are some really good use cases of this in real life, especially when the
    amount of data is too huge to search even with hash tables, and some false positives
    would be acceptable. For example, when creating a new email address with an email
    provider such as Gmail or Outlook, there is a check to see whether the email address
    already exists. There are billions of email addresses present in the database,
    and an accurate check for such a basic and frequent query would be very expensive.
    Fortunately, even if the email address is not already taken, it is okay to sometimes
    say that it is taken as it doesn't do any harm. The user will simply choose something
    else. In such cases, using a Bloom filter is a feasible option. We'll see this
    in action in *Activity 7*, *Email Address Validator*.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中有一些非常好的用例，特别是当数据量太大，即使使用哈希表也无法搜索，一些误报也是可以接受的。例如，在创建像Gmail或Outlook这样的电子邮件提供商的新电子邮件地址时，会检查电子邮件地址是否已经存在。数据库中存在数十亿个电子邮件地址，对于这样一个基本且频繁的查询，进行准确的检查将非常昂贵。幸运的是，即使电子邮件地址尚未被占用，有时说它已被占用也没关系，因为这不会造成任何伤害。用户只需选择其他内容。在这种情况下，使用Bloom过滤器是一个可行的选择。我们将在*Activity
    7*，*电子邮件地址验证器*中看到它的运作。
- en: Another example is the recommendation algorithm for showing new ads that are
    used by services, such as Facebook ads. It will show you a new ad every time you
    check your feed. It can simply store the IDs of ads you have watched in a Bloom
    filter. Then, the ID of a particular ad can be checked against it before showing
    it on your feed. If the check returns that you have watched a particular ad even
    though you haven't (false positive), it will not show that ad. However, this is
    fine since you wouldn't know about it as you haven't seen that ad anyway. This
    way, you can get new ads every time with a very fast lookup.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是用于显示新广告的推荐算法，这些广告被Facebook等服务使用。每次查看动态时，它都会向您显示一个新广告。它可以简单地将您观看的广告的ID存储在Bloom过滤器中。然后，在显示广告之前，可以针对特定广告的ID进行检查。如果检查返回您观看了特定广告，即使您没有（误报），它也不会显示该广告。然而，这没关系，因为您根本不知道，毕竟您也没有看到那个广告。这样，您可以每次都以非常快的查找获得新广告。
- en: 'Activity 7: Email Address Validator'
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动7：电子邮件地址验证器
- en: In this activity, we'll create a validator for emails, similar to what we find
    in a lot of email service provides (such as Gmail and Outlook) while signing up.
    We'll use a Bloom filter to check whether an email address has already been taken
    by someone else.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将创建一个类似于我们在许多电子邮件服务提供商（如Gmail和Outlook）的注册过程中找到的电子邮件验证器。我们将使用Bloom过滤器来检查电子邮件地址是否已被他人占用。
- en: 'These high-level steps should help you complete this activity:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高级步骤应该帮助您完成此活动：
- en: Create a `BloomFilter` class that can take a number of hash functions and the
    size of the Bloom.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`BloomFilter`类，可以接受一定数量的哈希函数和Bloom的大小。
- en: For hashing, use the MD5 algorithm from the OpenSSL library to generate a hash
    value of a given email. MD5 is a 128-bit hashing algorithm. For multiple hash
    functions, we can use each byte as a separate hash value.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于哈希，使用OpenSSL库中的MD5算法生成给定电子邮件的哈希值。MD5是一种128位的哈希算法。对于多个哈希函数，我们可以使用每个字节作为单独的哈希值。
- en: To add an email in the Bloom filter, we need to set all the bits to *true* that
    are coming from each byte of the hash value we calculated in *step 2*.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在Bloom过滤器中添加电子邮件，我们需要将在*步骤2*中计算的哈希值的每个字节的所有位设置为*true*。
- en: To find any email, we need to check whether all the relevant bits are *true*
    based on the hash value we calculated in *step 2*.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查找任何电子邮件，我们需要检查基于*步骤2*中计算的哈希值的所有相关位是否为*true*。
- en: Note
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: The solution to this activity can be found on page 503.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第503页找到。
- en: Summary
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'As we mentioned in the introduction, the lookup problem is encountered in most
    applications in one way or the other. We can use deterministic as well as probabilistic
    solutions as per our needs. In this chapter, we implemented and saw how we can
    use both of them. In the end, we also looked at an example of built-in containers
    for hashing in C++. These containers are extremely useful while we''re writing
    applications as we don''t need to implement them ourselves every time and for
    every type. A simple rule of thumb is this: if we can see a lot of function calls
    to the `find` function for the container, we should go for a lookup-based solution.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在介绍中提到的，查找问题在大多数应用程序中以一种或另一种方式遇到。根据我们的需求，我们可以使用确定性和概率性解决方案。在本章中，我们实现并看到了如何使用它们。最后，我们还看了C++中用于哈希的内置容器的示例。这些容器在编写应用程序时非常有用，因为我们不需要每次为每种类型都实现它们。一个简单的经验法则是：如果我们可以看到对容器的`find`函数的大量调用，我们应该选择基于查找的解决方案。
- en: So far, we've seen how we can store data in various types of data structures
    and perform some basic operations. In the upcoming chapters, we'll look at various
    types of algorithm design techniques so that we can optimize those operations,
    starting with divide and conquer.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何将数据存储在各种数据结构中并执行一些基本操作。在接下来的章节中，我们将研究各种类型的算法设计技术，以便优化这些操作，从分而治之开始。
