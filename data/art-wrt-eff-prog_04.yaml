- en: '*Chapter 3*: CPU Architecture, Resources, and Performance'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：CPU架构、资源和性能'
- en: 'With this chapter, we begin the exploration of the computing hardware: we want
    to know how to use it optimally and squeeze the best performance from out of it.
    The first hardware component we have to learn about is the central processor.
    The CPU does all the computations, and if we are not using it efficiently, nothing
    is going to save our slow, poorly performing program. This chapter is dedicated
    to learning about CPU resources and capabilities, the optimal ways to use them,
    the more common reasons for not making the best use of CPU resources, and how
    to resolve them.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，我们开始探索计算硬件：我们想知道如何最佳地使用它，并从中挤出最佳性能。我们首先要了解的硬件组件是中央处理器。CPU执行所有计算，如果我们没有有效地使用它，那么没有什么能拯救我们慢速、性能不佳的程序。本章致力于学习CPU资源和能力，最佳使用它们的方式，未能充分利用CPU资源的更常见原因，以及如何解决它们。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: The architecture of modern CPUs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代CPU的架构
- en: Using internal concurrency of the CPUs for optimum performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用CPU的内部并发以获得最佳性能
- en: CPU pipelines and speculative execution
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU流水线和推测执行
- en: Branch optimization and branchless computing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支优化和无分支计算
- en: How to evaluate whether a program uses CPU resources efficiently
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何评估程序是否有效地使用CPU资源
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Again, you will need a C++ compiler and a micro-benchmarking tool, such as
    the Google Benchmark library we used in the previous chapter (found at [https://github.com/google/benchmark](https://github.com/google/benchmark)).
    We will also use the **LLVM Machine Code Analyzer** (**LLVM-MCA**), found at [https://llvm.org/docs/CommandGuide/llvm-mca.html](https://llvm.org/docs/CommandGuide/llvm-mca.html).
    If you want to use the MCA, your choice of compilers is more limited: you need
    an LLVM-based compiler such as Clang.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，您将需要一个C++编译器和一个微基准测试工具，比如我们在上一章中使用的Google Benchmark库（位于[https://github.com/google/benchmark](https://github.com/google/benchmark)）。我们还将使用**LLVM机器码分析器**（**LLVM-MCA**），位于[https://llvm.org/docs/CommandGuide/llvm-mca.html](https://llvm.org/docs/CommandGuide/llvm-mca.html)。如果您想使用MCA，您的编译器选择将更有限：您需要一个基于LLVM的编译器，比如Clang。
- en: The code accompanying this chapter can be found at [https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter03](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter03).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter03](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter03)找到。
- en: The performance begins with the CPU
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能始于CPU
- en: 'As we have observed in the earlier chapters, an efficient program is one that
    makes full use of the available hardware resources and does not waste them for
    tasks that are not needed. A high-performing program cannot be described so simply
    because performance can be defined only with respect to specific targets. Nonetheless,
    in this book, and in particular, in this chapter, we are largely concerned with
    the computational performance or throughput: *how fast can we solve a given problem
    with the hardware resources we have?* This type of performance is closely related
    to efficiency: our program will deliver the result faster if every computation
    it executes brings us closer to the result, and, at every moment, we do as much
    computing as possible.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章中观察到的，一个高效的程序是充分利用可用硬件资源并不浪费它们在不需要的任务上的程序。一个高性能的程序不能如此简单地描述，因为性能只能针对特定目标来定义。尽管如此，在本书中，特别是在本章中，我们主要关注计算性能或吞吐量：*我们能用现有的硬件资源多快地解决一个给定的问题？*这种性能类型与效率密切相关：如果我们的程序执行的每个计算都让我们更接近结果，并且在每一刻都尽可能多地进行计算，那么我们的程序将更快地提供结果。
- en: 'This brings us to the next question: *just how much computing can be done,
    say, in one second?* The answer, of course, will depend on what hardware you have,
    how much of it, and how efficiently your program can use it. Any program needs
    multiple hardware components: processors and memory, obviously, but also networking
    for any distributed program, storage, and other I/O channels for any program that
    manipulates large amounts of external data, possibly other hardware, depending
    on what the program does. But everything starts with the processor, and so, perforce,
    does our exploration of high-performance programming. Furthermore, in this chapter,
    we will limit ourselves to a single thread of execution; concurrency will come
    later.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这带我们来到下一个问题：*比如说，一秒钟内可以做多少计算？*答案当然取决于你拥有什么硬件，有多少硬件，以及你的程序能够有效地使用多少。任何程序都需要多个硬件组件：处理器和内存，显然，但对于任何分布式程序还需要网络，对于操纵大量外部数据的任何程序还需要存储和其他I/O通道，可能还需要其他硬件，具体取决于程序的功能。但一切都始于处理器，因此，我们的高性能编程探索也必然从这里开始。此外，在本章中，我们将限制自己在单个执行线程上；并发将在后面讨论。
- en: 'With this narrower focus, we can define what this chapter is about: *how to
    make the best use of the CPU resources using a single thread*. To understand this,
    we first need to explore what are the resources that a CPU has. Of course, different
    generations and different models of processors will have a different assortment
    of hardware capabilities, but the goal of this book is two-fold: first, to give
    you a general understanding of the subject, and second, to equip you with the
    tools necessary to acquire more detailed and specific knowledge. The general overview
    of the computational resources available on any modern CPU can be summarized,
    unfortunately, as *it''s complicated*. To illustrate, consider this die image
    of an Intel CPU:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更狭窄的焦点下，我们可以定义本章的主题：*如何使用单个线程最佳地利用CPU资源*。要理解这一点，我们首先需要探索CPU具有哪些资源。当然，不同世代和不同型号的处理器将具有不同的硬件能力组合，但本书的目标是双重的：首先，给你一个对主题的一般理解，其次，为你提供获取更详细和具体知识所需的工具。任何现代CPU上可用的计算资源的一般概述可概括为*它很复杂*。为了说明这一点，考虑一下英特尔CPU的芯片图像：
- en: '![Figure 3.1 – Die image of a Pentium CPU, with the markup of functional areas
    (source: Intel)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1 - 带有功能区域标记的奔腾CPU芯片图像（来源：英特尔）'
- en: '](img/Figure_3.1_B16229.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.1_B16229.jpg)'
- en: 'Figure 3.1 – Die image of a Pentium CPU, with the markup of functional areas
    (source: Intel)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 - 带有功能区域标记的奔腾CPU芯片图像（来源：英特尔）
- en: 'Overlaid on top of the image are the descriptions of the major functional areas.
    If this is the first time you have seen such an image, the most startling detail
    may be that the execution unit, that is, the part that does actual additions,
    multiplications, and other operations that we think of as the main function of
    the CPU, actually doesn''t take up even a quarter of all the silicon. The rest
    is *other stuff* whose purpose is, fundamentally, to enable the additions and
    multiplications to work and work efficiently. The second and more practically
    relevant observation is this: the processor has many components with different
    functions. Some of these components largely work by themselves, and there is little
    the programmer needs to do to make the best use of them. Some need a careful arrangement
    of the machine code that, thankfully, is mostly done by the compilers. But more
    than half of the silicon area is dedicated to the components that don''t just
    *optimize themselves*: to get the maximum performance out of this processor, the
    programmer needs to understand how they work, what they can and cannot do, and
    what affects the efficiency of their operations (both positively and negatively).
    Often even the parts that work OK by themselves can benefit from the programmer''s
    attention if truly exceptional performance is desired.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像的顶部叠加了主要功能区域的描述。如果这是你第一次看到这样的图像，最令人震惊的细节可能是执行单元，也就是实际进行加法、乘法和其他我们认为是CPU主要功能的操作的部分，实际上并没有占据整个硅片的四分之一。其余部分是*其他东西*，其基本目的是使加法和乘法能够有效地工作。第二个更实际相关的观察是：处理器有许多具有不同功能的组件。其中一些组件基本上可以自行工作，程序员几乎不需要做什么来充分利用它们。有些需要仔细安排机器代码，幸运的是，这大部分是由编译器完成的。但是超过一半的硅片面积都专门用于那些不仅仅是*自我优化*的组件：为了使处理器发挥最大性能，程序员需要了解它们的工作原理，它们能做什么，不能做什么，以及什么影响了它们操作的效率（无论是积极的还是消极的）。即使是那些自行工作良好的部分，如果真的需要异常的性能，也可以从程序员的关注中受益。
- en: 'There are many books written on processor architecture, including all the hardware
    techniques the designers use to improve the performance of their creations. These
    books can be a source of valuable knowledge and understanding. This is not going
    to be yet another one of those books. What descriptions and explanations of the
    hardware it does have, serve a different goal: here, we will focus on the practical
    ways in which you can explore the performance of your hardware, starting with
    the CPUs. We start this exploration without delay in the next section.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于处理器架构的书籍，包括设计者用来提高其作品性能的所有硬件技术。这些书籍可以成为宝贵的知识和理解的来源。这本书不会是又一本这样的书。它所具有的硬件描述和解释，服务于不同的目标：在这里，我们将专注于您可以探索硬件性能的实际方法，从CPU开始。我们将在下一节中立即开始这项探索。
- en: Probing performance with micro-benchmarks
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用微基准测试探索性能
- en: 'The outcome of the previous section may leave you somewhat daunted: the processor
    is very complex and, apparently, needs a lot of hand-holding on the part of the
    programmer to operate at peak efficiency. Let us start small and see how fast
    a processor can do some basic operations. To that end, we will use the same **Google
    Benchmark** tool we have used in the last chapter. Here is a benchmark for the
    simple addition of two arrays:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节的结果可能让你有些畏缩：处理器非常复杂，显然需要程序员大量辅助才能达到最高效率。让我们从小处着手，看看处理器可以多快地执行一些基本操作。为此，我们将使用上一章中使用过的**Google
    Benchmark**工具。这是一个用于简单数组相加的基准测试：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this first example, we show the benchmark in all details, including input
    generation. While the speed of most operations does not depend on the values of
    the operands, we are going to use random input values, just so we don''t have
    to worry about it when we do get to the operations that are sensitive to the input
    values. Also note that, while we store the values in vectors, we don''t want to
    benchmark the speed of the vector indexing: the compiler will almost certainly
    optimize the expression `v1[i]` to produce the exact same code as `p1[i]`, but
    why take chances? We are excluding as many non-essential details as possible until
    we are left with the most basic problem: we have two arrays of values in memory,
    and we want to do some computations on each element of these arrays.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一个例子中，我们展示了所有细节的基准测试，包括输入生成。虽然大多数操作的速度不取决于操作数的值，但我们将使用随机输入值，这样当我们进行对输入值敏感的操作时就不必担心了。还要注意的是，虽然我们将值存储在向量中，但我们不想对向量索引的速度进行基准测试：编译器几乎肯定会优化表达式`v1[i]`以产生与`p1[i]`完全相同的代码，但为什么要冒险呢？我们排除尽可能多的非必要细节，直到我们只剩下最基本的问题：我们在内存中有两个数组的值，我们想对这些数组的每个元素进行一些计算。
- en: 'On the other hand, we have to be concerned with the possibility of undesired
    compiler optimizations: the compiler may figure out that the entire program is
    just a very long way of doing nothing at all (at least as far as the C++ standard
    is concerned), and come up with a much faster way to do the same by optimizing
    away big chunks of the code. The compiler directions to not optimize away the
    result of the computation and to assume that the state of the memory can change
    between benchmark iterations should prevent such optimizations. It is equally
    important not to get carried away in the other direction: for example, declaring
    the variable `a1` as `volatile` will certainly prevent most undesired optimizations.
    Unfortunately, it will also prevent the compiler from optimizing the loop itself,
    and this is not what we want: we want to see how efficiently the CPU can do the
    addition of the two arrays, which implies generating the most efficient code as
    well. We just don''t want the compiler to figure out that the first iteration
    of the benchmark loop is exactly the same as the second one.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们必须关注不希望的编译器优化的可能性：编译器可能会发现整个程序只是一种非常长的无用操作（至少就C++标准而言），并通过优化掉代码的大部分来找到更快的方法。编译器指示不要优化计算结果，并假设内存状态在基准测试迭代之间可以改变，应该防止这种优化。同样重要的是不要走向另一个极端：例如，将变量`a1`声明为`volatile`肯定会阻止大多数不希望的优化。不幸的是，它也会阻止编译器优化循环本身，这并不是我们想要的：我们想要看到CPU如何高效地对两个数组进行加法，这意味着生成最有效的代码。我们只是不希望编译器发现基准测试循环的第一次迭代与第二次迭代完全相同。
- en: 'Note that this is a somewhat unusual application of the micro-benchmark: usually,
    we have a fragment of code, and we want to find out how fast it is and how we
    can make it faster. Here, we are using the micro-benchmark to learn about the
    performance of the processor by tailoring the code in a way that will give us
    some insights.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是微基准的一个不太常见的应用：通常情况下，我们有一小段代码，我们想知道它有多快，以及如何使它更快。在这里，我们使用微基准来了解处理器的性能，通过调整代码的方式来获得一些见解。
- en: 'The benchmark should be compiled with optimization turned on. Running this
    benchmark will produce the result that looks something like this (the exact numbers
    will depend on your CPU, of course):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试应该在打开优化的情况下进行编译。运行此基准测试将产生类似以下的结果（确切的数字当然取决于您的CPU）：
- en: '![Figure 3.2'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.2'
- en: '](img/Figure_3.2_B16229.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.2_B16229.jpg)'
- en: Figure 3.2
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2
- en: 'So far, we cannot conclude much from this experiment, other than the modern
    CPUs are *fast*: they can add two numbers in less than a nanosecond. If you''re
    curious, you can explore other operations at this point: subtraction and multiplication
    take exactly as much time as addition, while integer division is rather expensive
    (three to four times slower).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，除了现代CPU速度很快之外，我们无法从这个实验中得出太多结论：它们可以在不到一纳秒的时间内添加两个数字。如果你感兴趣，你可以在这一点上探索其他操作：减法和乘法所花费的时间与加法完全相同，而整数除法则相当昂贵（比加法慢三到四倍）。
- en: 'In order to analyze the performance of our code, we have to look at it the
    way the processor sees it, and there is a lot more going on here than the simple
    addition. The two input arrays are stored in memory, but the addition or multiplication
    operations are executed between values stored in registers (or, possibly, between
    a register and a memory location, for some operations). This is how the processor
    sees one iteration of our loop, step by step. At the start of the iteration, the
    index variable `i` is in one of the CPU registers, and the two corresponding array
    elements, `v1[i]` and `v2[i]`, are in memory:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析我们的代码的性能，我们必须以处理器看到的方式来看待它，这里发生的事情远不止简单的加法。两个输入数组存储在内存中，但加法或乘法操作是在寄存器中的值之间执行的（或者可能是在寄存器和内存位置之间执行，对于某些操作）。这就是处理器逐步看到我们循环的一次迭代。在迭代开始时，索引变量`i`在一个CPU寄存器中，两个对应的数组元素`v1[i]`和`v2[i]`在内存中：
- en: '![Figure 3.3 – Processor state at the start of the i-th loop iteration'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3 - 第i次循环迭代开始时的处理器状态'
- en: '](img/Figure_3.3_B16229.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.3_B16229.jpg)'
- en: Figure 3.3 – Processor state at the start of the i-th loop iteration
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 - 第i次循环迭代开始时的处理器状态
- en: 'Before we can do anything, we have to move the input values into the registers.
    A register has to be allocated for each input, plus one register for the result.
    In a given loop iteration, the first instruction will load one of the inputs into
    the register:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们做任何事情之前，我们必须将输入值移入寄存器。必须为每个输入分配一个寄存器，再加上一个寄存器用于结果。在给定的循环迭代中，第一条指令将一个输入加载到寄存器中：
- en: '![Figure 3.4 – Processor state after the first instruction of the i-th iteration'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4 - 第i次迭代的第一条指令后的处理器状态'
- en: '](img/Figure_3.4_B16229.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.4_B16229.jpg)'
- en: Figure 3.4 – Processor state after the first instruction of the i-th iteration
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 - 第i次迭代的第一条指令后的处理器状态
- en: 'The read (or load) instruction uses the register containing the index `i` and
    the location of the array `v1` in memory to access the value `v1[i]` and copy
    it into the register. The next instruction similarly loads the second input:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 读取（或加载）指令使用包含索引`i`和数组`v1`位置的寄存器来访问值`v1[i]`并将其复制到寄存器中。下一条指令类似地加载第二个输入：
- en: '![Figure 3.5 – Processor state after the second instruction of the i-th iteration'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5 - 第i次迭代的第二条指令后的处理器状态'
- en: '](img/Figure_3.5_B16229.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.5_B16229.jpg)'
- en: Figure 3.5 – Processor state after the second instruction of the i-th iteration
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 - 第i次迭代的第二条指令后的处理器状态
- en: 'Now we are finally ready to do the operation such as addition or multiplication:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于准备好执行加法或乘法等操作了：
- en: '![Figure 3.6 – Processor state at the end of the i-th loop iteration'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3 - 第i次循环迭代结束时的处理器状态'
- en: '](img/Image88353.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Image88353.jpg)'
- en: Figure 3.6 – Processor state at the end of the i-th loop iteration
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 - 第i次循环迭代结束时的处理器状态
- en: 'This simple line of code produces all these steps after it is converted into
    hardware instructions (plus the operations necessary to advance to the next iteration
    of the loop):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这行简单的代码在转换为硬件指令后产生了所有这些步骤（以及推进到循环的下一个迭代所需的操作）：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'From the efficiency point of view, we want to focus on that last step: our
    CPU can add or multiply two numbers in under a nanosecond, not bad, but can it
    do more? A lot of transistors are dedicated to processing and executing instructions,
    so they have to be good for something more. Let us try to do two operations on
    the same values instead of just one:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从效率的角度来看，我们希望关注最后一步：我们的CPU可以在不到一纳秒的时间内对两个数字进行加法或乘法运算，这还不错，但它还能做更多吗？许多晶体管专门用于处理和执行指令，因此它们必须还能做更多。让我们尝试在相同的值上执行两个操作，而不仅仅是一个：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If an addition takes one nanosecond and a multiplication takes one nanosecond,
    how long would both take? The benchmark gives us the answer:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果加法需要一纳秒，乘法需要一纳秒，那么两者需要多长时间？基准测试给出了答案：
- en: '![Figure 3.7 – Benchmarks for a single instruction and two instructions'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 单条指令和两条指令的基准测试
- en: '](img/Figure_3.7_B16229.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.7_B16229.jpg)'
- en: Figure 3.7 – Benchmarks for a single instruction and two instructions
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 单条指令和两条指令的基准测试
- en: 'Surprisingly, one plus one equals one here. We can add even more instructions
    to one iteration:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，这里的一加一等于一。我们可以在一个迭代中添加更多的指令：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The time per iteration is still the same (slight differences are within the
    accuracy of the benchmark measurement):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代的时间仍然相同（轻微差异在基准测试测量的精度范围内）：
- en: '![Figure 3.8 – Benchmarks for loops with up to four instructions per iteration'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.8 – 每次迭代最多四条指令的循环基准测试'
- en: '](img/Figure_3.8_B16229.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.8_B16229.jpg)'
- en: Figure 3.8 – Benchmarks for loops with up to four instructions per iteration
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – 每次迭代最多四条指令的循环基准测试
- en: 'It appears that our view of the processor as executing one instruction at a
    time needs to be revised:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎我们对处理器一次执行一条指令的观点需要修订：
- en: '![Figure 3.9 – Processor executing multiple operations in a single step'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9 – 处理器在单个步骤中执行多个操作'
- en: '](img/Figure_3.9_B16229.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.9_B16229.jpg)'
- en: Figure 3.9 – Processor executing multiple operations in a single step
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – 处理器在单个步骤中执行多个操作
- en: 'As long as the operands are already in the registers, the processor can execute
    several operations at once. This is known as **Instruction-Level Parallelism**
    (**ILP**). Of course, there is a limit to how many operations can be executed:
    the processor has only so many execution units capable of doing integer computations.
    Still, it is instructive to try to push the CPU to its limits by adding more and
    more instructions to one iteration:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 只要操作数已经在寄存器中，处理器就可以同时执行多个操作。这被称为**指令级并行性**（**ILP**）。当然，可以执行的操作数量是有限的：处理器只有那么多能够进行整数计算的执行单元。尽管如此，通过在一个迭代中添加越来越多的指令来尝试推动CPU的极限是很有教育意义的：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The exact number of instructions a processor can execute depends on the CPU
    and the instructions, of course, but the previous loop shows a noticeable slowdown
    compared to the single multiplication, at least on the machine I am using:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器可以执行的确切指令数量取决于CPU和指令，但是与单个乘法相比，上一个循环显示出明显的减速，至少在我使用的机器上是这样的：
- en: '![Figure 3.10 – Benchmark of eight instructions per iteration'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.10 – 每次迭代八条指令的基准测试'
- en: '](img/Figure_3.10_B16229.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.10_B16229.jpg)'
- en: Figure 3.10 – Benchmark of eight instructions per iteration
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 每次迭代八条指令的基准测试
- en: 'Now you can appreciate just how inefficient, in terms of the hardware utilization,
    our original code was: the CPU, apparently, can execute between five and seven
    different operations per iteration, so our single multiplication wasn''t taxing
    even a quarter of its capabilities. In truth, the modern processors are even more
    impressively capable: in addition to the integer computation units we have been
    experimenting with, they have separate floating-point hardware that can execute
    instructions on `double` or `float` values, and the vector processing units that
    execute MMX, SSE, AVX, and other specialized instructions, all at the same time!'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以欣赏到我们原始代码在硬件利用方面是多么低效：CPU显然可以在每次迭代中执行五到七个不同的操作，因此我们的单个乘法甚至没有占用其四分之一的能力。事实上，现代处理器的能力更加令人印象深刻：除了我们一直在进行实验的整数计算单元之外，它们还具有专门用于执行`double`或`float`值的指令的独立浮点硬件，以及同时执行MMX、SSE、AVX和其他专门指令的矢量处理单元！
- en: Visualizing instruction-level parallelism
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化指令级并行性
- en: So far, our conclusions about the CPU's ability to execute multiple instructions
    in parallel were based on strong but indirect evidence. It would be good to get
    a direct confirmation that this is indeed what's going on. We can get such confirmation
    from the **Machine Code Analyzer** (**MCA**), which is a part of the LLVM toolchain.
    The analyzer takes assembly code as the input and reports a lot of information
    on how the instructions are executed, what the delays and the bottlenecks are,
    and so on. We are not going to learn all the capabilities of this advanced tool
    here (refer to the project home page, [https://llvm.org/docs/CommandGuide/llvm-mca.html](https://llvm.org/docs/CommandGuide/llvm-mca.html),
    for details). However, we can use it now to see how the CPU executes our operations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对CPU能够并行执行多条指令的能力的结论是基于强有力但间接的证据。从**机器码分析器**（**MCA**）可以得到直接证实，这是确实发生的。分析器是LLVM工具链的一部分。分析器以汇编代码作为输入，并报告有关指令执行方式、延迟和瓶颈等方面的大量信息。我们不打算在这里学习这个高级工具的所有功能（有关详细信息，请参阅项目主页[https://llvm.org/docs/CommandGuide/llvm-mca.html](https://llvm.org/docs/CommandGuide/llvm-mca.html)）。但是，我们现在可以使用它来查看CPU如何执行我们的操作。
- en: 'The first step is to annotate the code with the analyzer markup to select which
    part of the code to analyze:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用分析器标记代码，以选择要分析的代码部分：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You don't have to use `#define` for the analyzer markup, but I find it easier
    to remember these commands than the exact assembly syntax (you can save the `#define`
    lines in a header file and include it as needed). Why did we mark for analysis
    just the body of the loop and not the whole loop? The analyzer actually assumes
    that the selected code fragment runs in a loop and repeats it for some number
    of iterations (ten by default). You can try to mark the entire loop for analysis,
    but, depending on the compiler optimizations, this may confuse the analyzer (it's
    a powerful tool, but not easy to use or, at the time of writing this, particularly
    robust).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您不必为分析器标记使用`#define`，但我发现记住这些命令比记住确切的汇编语法更容易（您可以将`#define`行保存在头文件中，并根据需要包含它）。为什么我们只标记了循环体而不是整个循环进行分析？分析器实际上假设所选的代码片段在循环中运行，并重复了一些迭代次数（默认为十次）。您可以尝试标记整个循环进行分析，但是根据编译器的优化，这可能会使分析器混淆（这是一个强大的工具，但在撰写本文时并不容易使用或特别健壮）。
- en: 'We can run the analyzer now:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行分析器了：
- en: '![Figure 3.11'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.11'
- en: '](img/Figure_3.11_B16229.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.11_B16229.jpg)'
- en: Figure 3.11
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11
- en: 'Note that we do not compile the code into an executable but rather generate
    assembly output (`-S`) in Intel syntax. The output is piped into the analyzer;
    of the many ways the analyzer can report the results, we selected the timeline
    output. The timeline view shows each instruction as it moves through the execution
    process. Let us analyze two code fragments, one with a single operation (addition
    or multiplication) and the other one with both operations. Here is the timeline
    for the iteration with just one multiplication (we have removed all the lines
    in the middle of the timeline):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们没有将代码编译成可执行文件，而是生成了Intel语法的汇编输出（`-S`）。输出被导入分析器；分析器可以以许多方式报告结果，我们选择了时间表输出。时间表视图显示每条指令在执行过程中的移动。让我们分析两个代码片段，一个只有一个操作（加法或乘法），另一个有两个操作。这是只有一个乘法的迭代的时间表（我们已经删除了时间表中间的所有行）：
- en: '![Figure 3.12'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12'
- en: '](img/Figure_3.12_B16229.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.12_B16229.jpg)'
- en: Figure 3.12
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12
- en: The horizontal axis is the time in cycles. The analyzer simulated running the
    selected code fragment for ten iterations; each instruction is identified by its
    sequential number in the code and the iteration index, so the first instruction
    of the first iteration has the index `[0,0]`, and the last instruction has the
    index `[9,2]`. This last instruction is also the third instruction of the tenth
    iteration (there are only three instructions per iteration). The entire sequence
    took 55 cycles, according to the timeline.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 水平轴是周期时间。分析器模拟运行所选代码片段进行十次迭代；每条指令都用代码中的顺序号和迭代索引来标识，因此第一次迭代的第一条指令的索引是`[0,0]`，最后一条指令的索引是`[9,2]`。这最后一条指令也是第十次迭代的第三条指令（每次迭代只有三条指令）。整个序列根据时间轴花费了55个周期。
- en: 'Now let us add another operation that uses the same values `p1[i]` and `p2[i]`
    that we already read from memory:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们添加另一个使用已经从内存中读取的值`p1[i]`和`p2[i]`的操作：
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let us look at the timeline for the code with two operations per iteration,
    one addition and one multiplication:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下每次迭代有两个操作的代码的时间表，一个是加法，一个是乘法：
- en: '![Figure 3.13'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13'
- en: '](img/Figure_3.13_B16229.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.13_B16229.jpg)'
- en: Figure 3.13
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13
- en: 'There are a lot more instructions executed now, six instructions per iteration
    (the last instruction has the index `[9,5]`). However, the duration of the timeline
    has increased by just one cycle: In *Figure 3.12*, the timeline ended on cycle
    54, whereas in *Figure 3.13*, it ends on cycle 55\. As we have suspected, the
    processor managed to execute twice as many instructions in the same length of
    time.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在执行的指令数量增加了很多，每次迭代有六条指令（最后一条指令的索引是`[9,5]`）。然而，时间表的持续时间只增加了一个周期：在*图3.12*中，时间表在第54个周期结束，而在*图3.13*中，它在第55个周期结束。正如我们所怀疑的那样，处理器设法在相同的时间内执行了两倍的指令。
- en: 'You may have also noticed that for all our benchmarks so far, we have increased
    the number of operations done on the same input values (add them, subtract them,
    multiply them, and so on). We have concluded that these extra operations are *free*
    as far as the runtime is concerned (up to a point). This is an important general
    lesson to learn: once you have some values in registers, adding a computation
    on the same values probably won''t cost you any performance unless your program
    was already extremely efficient and was stressing the hardware to the limit. Unfortunately,
    the experiment and the conclusions are of limited practical value. How often does
    it happen that all your computations are done just on a handful of inputs at a
    time, the next iteration uses its own inputs, and you can find some more useful
    computations you can do on the same inputs? Not quite never, but rarely. Any attempt
    to extend our simple demonstration of the CPU''s computational power is going
    to run into one or more complications. The first one is the data dependency: the
    sequential iterations of the loop are usually not independent; instead, each iteration
    needs some data from the previous iterations. We will explore this situation in
    the next section.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还注意到，到目前为止，我们所有的基准测试都增加了对相同输入值的操作次数（加法、减法、乘法等）。我们得出结论，这些额外的操作在运行时来说是*免费*的（在一定程度上）。这是一个重要的一般性教训：一旦您在寄存器中有了一些值，对相同的值进行计算可能不会给您带来任何性能损失，除非您的程序已经非常高效，并且已经极限地利用了硬件。不幸的是，这个实验和结论的实际价值有限。有多少次您的所有计算都只是在少数几个输入上进行，下一次迭代使用自己的输入，并且您可以找到更多有用的计算来处理相同的输入？并不是从来没有，但很少。任何试图扩展我们对CPU计算能力的简单演示的尝试都将遇到一个或多个复杂性。第一个是数据依赖：循环的顺序迭代通常不是独立的；相反，每次迭代都需要来自前几次迭代的一些数据。我们将在下一节中探讨这种情况。
- en: Data dependencies and pipelining
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据依赖和流水线
- en: 'Our analysis of the CPU capabilities so far has shown that the processor can
    execute multiple operations at once as long as the operands are already in the
    registers: we can evaluate a fairly complex expression that depends on just two
    values in exactly as much time as it takes to add these values. The *depends on
    just two values* qualifier is, unfortunately, a very serious restriction. We now
    consider a more realistic code example, and we don''t have to make many changes
    to our code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对CPU功能的分析表明，只要操作数已经在寄存器中，处理器就可以同时执行多个操作：我们可以评估一个相当复杂的表达式，只要花费与这些值相加的时间一样多。*只取决于两个值*的限定词，不幸的是，这是一个非常严重的限制。现在我们考虑一个更现实的代码示例，我们不需要对我们的代码进行太多更改：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Recall that the old code had the same loop with a simpler body: `a1 += (p1[i]
    + p2[i]);`. Also, `p1[i]` is just an alias for the vector element `v1[i]`, same
    for `p2` and `v2`. Why is this code more complex? We have already seen that the
    processor can do addition, subtraction, and multiplication in a single cycle,
    and the expression still depends on just two values, `v1[i]` and `v2[i]`. However,
    this expression cannot be evaluated in one cycle. To clarify this, we introduce
    two temporary variables that are really just names for the intermediate results
    during expression evaluation:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，旧代码中有相同的循环，但主体更简单：`a1 += (p1[i] + p2[i]);`。此外，`p1[i]`只是向量元素`v1[i]`的别名，`p2`和`v2`也是如此。为什么这段代码更复杂？我们已经看到处理器可以在一个周期内进行加法、减法和乘法，而表达式仍然只取决于两个值，`v1[i]`和`v2[i]`。然而，这个表达式不能在一个周期内评估。为了澄清这一点，我们引入了两个临时变量，它们实际上只是在表达式评估过程中的中间结果的名称：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results of the addition and the subtraction, `s[i]` and `d[i]`, can be
    evaluated at the same time, as we saw earlier. However, the last line cannot be
    executed until we have the values of `s[i]` and `d[i]`. It doesn''t matter how
    many additions and multiplications the CPU can do at once: you cannot compute
    the result of an operation whose inputs are unknown; therefore, the CPU has to
    wait for the inputs to the multiplication to become ready. The i-th iteration
    has to be executed in two steps: first, we have to add and subtract (we can do
    both at once), and second, we have to multiply the results. The iteration now
    takes two cycles instead of one because the second step of the computation depends
    on the **data** produced by the first step:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 加法和减法的结果`s[i]`和`d[i]`可以在同一时间进行评估，就像我们之前看到的那样。然而，最后一行直到我们有了`s[i]`和`d[i]`的值才能执行。无论CPU可以同时执行多少次加法和乘法：你不能计算输入未知的操作的结果；因此，CPU必须等待乘法的输入准备就绪。第i次迭代必须分两步执行：首先，我们必须加法和减法（我们可以同时进行），其次，我们必须乘以结果。现在迭代需要两个周期而不是一个，因为计算的第二步取决于第一步产生的**数据**：
- en: '![Figure 3.14 – Data dependency in loop evaluation'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.14 - 循环评估中的数据依赖'
- en: '](img/Figure_3.14_B16229.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.14_B16229.jpg)'
- en: Figure 3.14 – Data dependency in loop evaluation
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 - 循环评估中的数据依赖
- en: 'Even though the CPU has the resources to do all three operations at once, we
    cannot take advantage of this capability because of the data dependency inherent
    in our computations. This, of course, severely limits how efficiently we can use
    our processor. Data dependencies are very common in programs, but fortunately,
    the hardware designers came up with an effective antidote. Consider *Figure 3.14*
    carefully. We have the multiplication hardware unit standing by idly while we
    compute the values of `s[i]` and `d[i]`. We cannot start computing their product
    any earlier, but there is something else we can do: we can multiply the values
    `s[i-1]` and `d[i-1]` from the previous iteration at the same time. Now the two
    iterations of the loop are interleaved in time:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 即使CPU有资源可以同时执行所有三个操作，由于我们计算中固有的数据依赖性，我们无法利用这种能力。当然，这严重限制了我们如何有效地使用处理器。数据依赖在程序中非常常见，但幸运的是，硬件设计者提出了一个有效的解决方法。仔细考虑*图3.14*。我们有乘法硬件单元在我们计算`s[i]`和`d[i]`的值时闲置着。我们不能提前开始计算它们的乘积，但我们可以做另一件事：我们可以同时计算上一次迭代中`s[i-1]`和`d[i-1]`的值。现在循环的两次迭代在时间上交错进行：
- en: '![Figure 3.15 – Pipelining: the rows correspond to the successive iterations;
    all operations in the same row are executed simultaneously'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.15 - 流水线：行对应于连续的迭代；同一行中的所有操作同时执行'
- en: '](img/Figure_3.15_B16229.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.15_B16229.jpg)'
- en: 'Figure 3.15 – Pipelining: the rows correspond to the successive iterations;
    all operations in the same row are executed simultaneously'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 - 流水线：行对应于连续的迭代；同一行中的所有操作同时执行
- en: 'This transformation of the code is known as **pipelining**: a complex expression
    is broken up into stages and executed in a pipeline where stage 2 of the previous
    expression runs at the same time as stage 1 of the next one (a more complex expression
    would have more stages and require a deeper pipeline). If we are correct in our
    expectations, the CPU will be able to compute our two-stage add-subtract-multiply
    expression just as fast as single multiplication as long as we have many iterations:
    the first iteration is going to take two cycles (add/subtract first, then multiply),
    there is no getting around that. Similarly, the last iteration will end with a
    single multiplication, and there is nothing else we can do at the same time. However,
    all the iterations in between will be executing three operations simultaneously.
    We already know that our CPU can add, subtract, and multiply at the same time.
    The fact that the multiplication belongs to a different iteration of the loop
    matters not at all.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这种代码的转换被称为**流水线**：一个复杂的表达式被分解成阶段，并在流水线中执行，前一个表达式的第二阶段与下一个表达式的第一阶段同时运行（更复杂的表达式会有更多的阶段，需要更深的流水线）。如果我们的期望是正确的，只要有很多次迭代，CPU就能够像单个乘法一样快速计算我们的两阶段加减乘表达式：第一次迭代将需要两个周期（先加减，然后乘），这是无法避免的。同样地，最后一次迭代将以单个乘法结束，我们无法同时做其他事情。然而，在中间的所有迭代中，将同时执行三个操作。我们已经知道我们的CPU可以同时进行加法、减法和乘法。乘法属于循环的不同迭代这个事实并不重要。
- en: 'We can confirm our expectations with a direct benchmark, where we compare the
    time it takes to do one multiplication per loop iteration with the time it takes
    to do our two-step iteration:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过直接的基准测试来确认我们的期望，比较每次循环迭代执行一次乘法所需的时间和执行我们的两步迭代所需的时间：
- en: '![Figure 3.16'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.16'
- en: '](img/Figure_3.16_B16229.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.16_B16229.jpg)'
- en: Figure 3.16
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16
- en: 'As expected, both loops run at essentially the same speed. We can conclude
    that the pipelining has completely negated the performance penalty caused by the
    data dependency. Note that the pipelining does not eliminate the data dependency;
    each loop iteration still has to be executed in two stages, with the second stage
    depending on the results of the first one. However, by interleaving the computations
    from different stages, the pipelining does eliminate the inefficiency that would
    be otherwise caused by this dependency (at least in the ideal case, which is what
    we have so far). An even more direct confirmation can be seen in the results of
    the Machine Code Analyzer. Again, the timeline view is the most instructive:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，两个循环的运行速度基本相同。我们可以得出结论，流水线完全抵消了数据依赖造成的性能损失。请注意，流水线并没有消除数据依赖；每个循环迭代仍然需要在两个阶段中执行，第二阶段依赖于第一阶段的结果。然而，通过交错计算不同阶段的计算，流水线确实消除了由此依赖引起的低效（至少在理想情况下，这是我们目前的情况）。通过机器代码分析器的结果，我们可以更直接地确认这一点：
- en: '![Figure 3.17 – A timeline view of the pipelined add-subtract-multiply loop
    (top) vs. a loop with a single multiplication (bottom)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.17 – 流水线加减乘循环的时间轴视图（顶部）与单个乘法循环的时间轴视图（底部）'
- en: '](img/Figure_3.17_B16229.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.17_B16229.jpg)'
- en: Figure 3.17 – A timeline view of the pipelined add-subtract-multiply loop (top)
    vs. a loop with a single multiplication (bottom)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 流水线加减乘循环的时间轴视图（顶部）与单个乘法循环的时间轴视图（底部）
- en: 'As you can see, it takes 56 cycles to execute ten iterations of either loop.
    The key step in the timeline is when an instruction is executed: `e` marks the
    beginning of the execution, and `E` is when the execution ends. The effect of
    the pipelining is clearly visible in the timeline: the first iteration of the
    loop starts to execute on the second cycle with the instruction `[0,0]`; the last
    instruction of the first iteration is done executing on cycle 18 (the horizontal
    axis is the cycle number). The second iteration begins executing on cycle 4, that
    is, there is a significant overlap of the two iterations. This is the pipelining
    in action, and you can see how it improves the efficiency of our program: at almost
    every cycle, the CPU is executing instructions from multiple iterations using
    its many computation units. It takes just as many cycles to execute a simple loop
    as it does to execute the more complex one, so the extra machine operations take
    no additional time.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，执行任何一个循环的十次迭代都需要56个周期。时间轴上的关键步骤是指令执行时：`e`标记执行的开始，`E`标记执行的结束。流水线的效果在时间轴上清晰可见：循环的第一次迭代在第二个周期开始执行，使用指令`[0,0]`；第一次迭代的最后一条指令在第18个周期执行完成（水平轴是周期数）。第二次迭代在第4个周期开始执行，也就是说，两次迭代有显著的重叠。这就是流水线的作用，你可以看到它如何提高了程序的效率：几乎每个周期，CPU都在使用多个计算单元执行多个迭代的指令。执行一个简单循环和执行一个更复杂的循环所需的周期数是一样的，所以额外的机器操作不需要额外的时间。
- en: 'This chapter is not intended to be a manual for the Machine Code Analyzer:
    to understand better the timeline and other information it produces, you should
    study its documentation. There is, however, one issue that we must point out.
    Every iteration of our loop does not just have the same C++ code, it has exactly
    the same machine code as well. This makes sense: the pipelining is done by the
    hardware, not the compiler; the compiler simply generates the code for one iteration
    and the operations needed to advance to the next iteration (or exit the loop upon
    completion). The processor executes multiple instructions in parallel; we can
    see that in the timeline. But something does not make sense upon close examination:
    for example, consider the instruction `[0,4]` in *Figure 3.17*. It is executed
    during cycles 6 through 12, and it uses registers CPU `rax` and `rsi`. Now look
    at the instruction `[1,2]` that is executed during cycles 8 and 9: it also uses
    the same registers, it actually writes into the register `rsi`, which is still
    being used by other instructions at the same time. This cannot be: while the CPU
    can do multiple operations simultaneously using its many independent computing
    units, it cannot store two different values in the same register at the same time.
    This contradiction was actually present, although well-hidden, all the way back
    in *Figure 3.15*: assuming that the compiler generates only one copy of the code
    for all iterations, the register we are going to use to store the value of `s[i]`
    is exactly the same as the one we need to read the value of `s[i-1]`, and both
    actions happen at the same time.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不是Machine Code Analyzer的使用手册：要更好地理解它产生的时间线和其他信息，您应该研究它的文档。然而，有一个问题我们必须指出。我们循环的每次迭代不仅具有相同的C++代码，而且还具有完全相同的机器代码。这是有道理的：流水线是由硬件完成的，而不是由编译器完成；编译器只是为一次迭代生成代码以及推进到下一次迭代（或在完成时退出循环所需的操作）。处理器并行执行多条指令；我们可以在时间线上看到这一点。但是仔细观察后会发现有些地方不合理：例如，看一下*图3.17*中的指令“[0,4]”。它在6到12周期内执行，并使用寄存器CPU“rax”和“rsi”。现在看一下在8和9周期内执行的指令“[1,2]”：它也使用相同的寄存器，实际上写入了寄存器“rsi”，而这个寄存器在同一时间仍然被其他指令使用。这是不可能的：虽然CPU可以使用其许多独立的计算单元同时执行多个操作，但它不能同时在同一个寄存器中存储两个不同的值。这个矛盾实际上一直存在，尽管在*图3.15*中已经很好地隐藏了起来：假设编译器只为所有迭代生成一份代码副本，我们将用来存储“s[i]”值的寄存器恰好与我们需要读取“s[i-1]”值的寄存器相同，并且两个操作同时发生。
- en: 'It is important to understand that we are not running out of registers: the
    CPU has many more registers than we have seen named so far. The problem is that
    the code for one iteration looks exactly like the code for the next iteration,
    including the register names, but at each iteration, different values must be
    stored in the registers. It seems like the pipelining we have assumed and observed
    should not, in fact, be possible: the next iteration must wait for the previous
    iteration to stop using the registers it needs. This is not what really happens,
    and the solution to this apparent contradiction is the hardware technique called
    `rsi`, are not the *real* register names, they are mapped by the CPU to the actual
    physical registers. The same name, `rsi`, can be mapped to different registers
    that all have the same size and functionality.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要明白，我们并不是寄存器用尽了：CPU的寄存器比我们目前看到的要多得多。问题在于，每次迭代的代码看起来都和下一次迭代的代码一模一样，包括寄存器的名称，但是在每次迭代中，不同的值必须存储在寄存器中。看起来我们假设和观察到的流水线似乎是不可能的：下一次迭代必须等待前一次迭代停止使用它所需的寄存器。这并不是真正发生的情况，这个明显的矛盾的解决方案是硬件技术称为“rsi”，不是*真正*的寄存器名称，它们由CPU映射到实际的物理寄存器。相同的名称“rsi”可以映射到不同的寄存器，它们都具有相同的大小和功能。
- en: When the processor executes the code in a pipeline, the instructions from the
    first iteration that refer to `rsi` will, in fact, use an internal register that
    we shall call `rsi1` (this is not its real name, but the actual hardware names
    of registers are not something you would ever encounter unless you are designing
    a processor). The second iteration also has instructions that refer to `rsi` but
    needs to store a different value there, so the processor will use another register,
    `rsi2`. Unless the first iteration no longer needs the value stored in `rsi`,
    the third iteration will have to use yet another register, and so on. This register
    renaming is done by the hardware and is very different from the register assignment
    done by the compiler (in particular, it is entirely invisible to any tool that
    analyzes the object code, such as LLVM-MCA or a profiler). The end effect is that
    multiple iterations of the loop are now executed as a linear sequence of code
    as if `s[i]` and `s[i+1]` really did refer to different registers.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器在流水线中执行代码时，第一次迭代中引用“rsi”的指令实际上将使用一个我们称之为“rsi1”的内部寄存器（这不是它的真实名称，但是寄存器的实际硬件名称不是你会遇到的，除非你是在设计处理器）。第二次迭代也有引用“rsi”的指令，但需要在那里存储不同的值，因此处理器将使用另一个寄存器“rsi2”。除非第一次迭代不再需要存储在“rsi”中的值，否则第三次迭代将不得不使用另一个寄存器，依此类推。这种寄存器重命名是由硬件完成的，与编译器完成的寄存器分配非常不同（特别是对于分析目标代码的任何工具，如LLVM-MCA或分析器，它是完全不可见的）。最终的效果是循环的多个迭代现在被执行为代码的线性序列，就好像“s[i]”和“s[i+1]”确实是指向不同的寄存器一样。
- en: 'Converting a loop into linear code is known as **loop unrolling**; it is a
    popular compiler optimization technique, but this time, it is done in hardware
    and is essential to be able to deal with data dependencies efficiently. The compiler''s
    point of view is closer to the way the source code is written: a single iteration,
    a group of machine instructions, executed over and over by jumping back to the
    beginning of the code fragment for the iteration. The processor''s point of view
    is more like what you see in the timeline, a linear sequence of instructions where
    each iteration has its own copy of the code and can use different registers.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 将循环转换为线性代码称为**循环展开**；这是一种流行的编译器优化技术，但这次是在硬件中完成的，对于能够有效处理数据依赖是至关重要的。编译器的观点更接近源代码的编写方式：单次迭代，一组机器指令，通过跳回到代码片段开始的地方进行重复执行。处理器的观点更像是你在时间线上看到的，一系列线性指令，其中每次迭代都有自己的代码副本并且可以使用不同的寄存器。
- en: 'We can make another important observation: the order in which the CPU executes
    our code is actually not the same order in which the instructions are written.
    This is called out-of-order execution, and it has important consequences for multi-threaded
    programs.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做出另一个重要的观察：CPU执行我们的代码的顺序实际上并不是指令编写的顺序。这被称为乱序执行，并对多线程程序有重要影响。
- en: 'We have seen how the processor avoids the restrictions on the efficiency of
    execution that would be imposed by data dependencies: the antidote to the data
    dependency is the pipelining. However, the story does not end there, and the beautifully
    complex scheme we have devised so far to execute our very simple loop is missing
    something important: the loop must end at some point. In the next section, we
    will see how much that complicates things and what the solution is.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到处理器如何避免数据依赖所施加的执行效率限制：对数据依赖的解药就是流水线。然而，故事并不会在那里结束，到目前为止我们已经设计的非常简单的循环的执行方案缺少了一些重要的东西：循环必须在某个时刻结束。在下一节中，我们将看到这会使事情变得更加复杂，以及解决方案是什么。
- en: Pipelining and branches
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流水线和分支
- en: 'Here is our understanding of the efficient use of a processor so far: first,
    the CPU can do multiple operations at once, such as add and multiply at the same
    time. Not taking advantage of this capability is like leaving free computing power
    on the table. Second, the factor that limits our ability to maximize efficiency
    is how fast we can produce the data to feed into these operations. Specifically,
    we are constrained by the data dependencies: if one operation computed the value
    that the next operation uses as an input, the two operations must be executed
    sequentially. The workaround to this dependency is pipelining: when executing
    loops or long sequences of code, the processor will interleave separate computations
    such as loop iterations, as long as they have at least some operations that can
    be executed independently.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对处理器的高效使用的理解是：首先，CPU可以同时执行多个操作，比如同时进行加法和乘法。不充分利用这种能力就像把免费的计算能力留在桌子上一样。其次，限制我们最大化效率的因素是我们能够产生数据以供这些操作的速度有多快。具体来说，我们受到数据依赖的限制：如果一个操作计算出下一个操作用作输入的值，那么这两个操作必须按顺序执行。解决这种依赖的方法是流水线：在执行循环或长序列的代码时，处理器会交错进行单独的计算，比如循环迭代，只要它们至少有一些可以独立执行的操作。
- en: However, pipelining has an important precondition as well. Pipelining `if(condition)`
    statement, we will execute either the `true` branch or the `false` branch, but
    we won't know which until we evaluate the `condition`. Just like data dependency
    was the bane of instruction-level parallelism, the conditional execution, or branches,
    are the bane of pipelining.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，流水线也有一个重要的前提。流水线`if(condition)`语句，我们将执行`true`分支或`false`分支，但在评估`condition`之前我们不知道哪个分支会执行。就像数据依赖是指令级并行性的祸根一样，条件执行或分支是流水线的祸根。
- en: 'With pipelining disrupted, we can expect a significant reduction in the efficiency
    of our program. It should be very easy to modify our earlier benchmark to observe
    this deleterious effect of conditionals. For example, instead of writing:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线被打断后，我们可以预期程序的效率会显著降低。修改我们之前的基准测试以观察条件语句的有害影响应该是非常容易的。例如，不是写：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We could write:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样写：
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we have reintroduced the data dependency as a code dependency:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据依赖重新引入为代码依赖：
- en: '![Figure 3.18 – Effect of a branch instruction on the pipeline'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.18 - 分支指令对流水线的影响'
- en: '](img/Figure_3.18_B16229.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.18_B16229.jpg)'
- en: Figure 3.18 – Effect of a branch instruction on the pipeline
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 - 分支指令对流水线的影响
- en: There is no obvious way to convert this code into a linear stream of instructions
    to execute, and the conditional jump cannot be avoided.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 没有明显的方法将这段代码转换为线性指令流来执行，条件跳转无法避免。
- en: 'The reality is somewhat more complex: a benchmark such as we have just suggested
    may or may not show significant degradation in performance. The reason is that
    many processors have some sort of **conditional move** or even **conditional add**
    instructions, and the compiler may decide to use them. If this happens, our code
    becomes entirely sequential with no jumps or branches and can be pipelined perfectly:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现实情况要复杂一些：像我们刚刚建议的基准测试可能会或可能不会显示出性能的显著下降。原因是许多处理器都有某种条件移动甚至条件加法指令，编译器可能会决定使用它们。如果发生这种情况，我们的代码就变成了完全顺序的，没有跳转或分支，可以完美地进行流水线处理：
- en: '![Figure 3.19 – Conditional code pipelined with cmove'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.19 - 有条件代码与cmove进行流水线处理'
- en: '](img/Figure_3.19_B16229.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.19_B16229.jpg)'
- en: Figure 3.19 – Conditional code pipelined with cmove
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 - 有条件代码与cmove进行流水线处理
- en: The x86 CPUs have a conditional move instruction, `cmove` (although not all
    compilers will use it to implement the `?:` operator in the previous figure).
    The processors with AVX or AVX2 instruction sets have a powerful set of *masked*
    addition and multiplication instructions that can be used to implement some conditional
    code as well. That is why, when benchmarking and optimizing the code with branches,
    it is very important to examine the generated object code and confirm that the
    code indeed contains branches and that they are indeed affecting the performance.
    There are also profiler tools that can be used for this purpose, and we will see
    one such tool in a moment.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: x86 CPU具有条件移动指令`cmove`（尽管并非所有编译器都会使用它来实现前面图中的`?:`运算符）。具有AVX或AVX2指令集的处理器具有一组强大的*掩码*加法和乘法指令，可以用来实现一些条件代码。因此，在对带有分支的代码进行基准测试和优化时，非常重要的是要检查生成的目标代码，并确认代码确实包含分支，并且它们确实影响了性能。还有一些性能分析工具可以用于此目的，我们马上就会看到其中一个。
- en: 'While branches and conditionals happen everywhere in most real-life programs,
    they can disappear when the program is reduced to just a few lines for a benchmark.
    One reason is that that the compiler may decide to use one of the conditional
    instructions we have mentioned earlier. Another reason that is common in poorly
    constructed benchmarks is that the compiler may be able to figure out, at compile-time,
    what the condition evaluates to. For example, most compilers will completely optimize
    away any code like `if (true)` or `if (false)`: there is no trace of this statement
    in the generated code, and any code that is never going to be executed is also
    eliminated. To observe the deleterious effect of the branches on the loop pipelining,
    we have to construct a test where the compiler cannot predict the outcome of the
    condition check. In your real-life benchmarks, you may have a data set extracted
    from your real program. For this next demonstration, we will use random values:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然分支和条件在大多数实际程序中随处可见，但当程序被简化为用于基准测试的几行代码时，它们可能会消失。一个原因是编译器可能决定使用我们之前提到的条件指令之一。另一个常见的原因是在构建不良的基准测试时，编译器可能能够在编译时弄清楚条件的评估结果。例如，大多数编译器将完全优化掉任何类似`if
    (true)`或`if (false)`的代码：在生成的代码中没有这个语句的痕迹，任何永远不会被执行的代码也被消除了。为了观察分支对循环流水线的不利影响，我们必须构建一个测试，使编译器无法预测条件检查的结果。在您的实际基准测试中，您可能会从实际程序中提取数据集。对于下一个演示，我们将使用随机值：
- en: '[PRE11]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Again, we have two input vectors `v1` and `v2`, plus a control vector `c1`
    that has random values of zero and one (avoid using `vector<bool>` here, it is
    not an array of bytes but a packed array of bits, so accessing it is considerably
    more expensive, and we are not interested in benchmarking bit manipulation instructions
    at this time). The compiler cannot predict whether the next random number is odd
    or even, thus, no optimizations are possible. Also, we have examined the generated
    machine code and confirmed that our compiler (Clang-11 on x86) implements this
    loop using a simple conditional jump. To have a baseline, we will compare the
    performance of this loop with one that does unconditional addition and multiplication
    on each iteration: `a1 += p1[i]*p2[i]`. This simpler loop does both an addition
    and a multiplication on each iteration; however, thanks to the pipelining, we
    get the addition *free*: it is executed simultaneously with the multiplication
    from the next iteration. The conditional branch, on the other hand, is anything
    but free:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们有两个输入向量`v1`和`v2`，以及一个控制向量`c1`，其中包含随机的零和一的值（在这里避免使用`vector<bool>`，因为它不是字节的数组，而是位的打包数组，因此访问它的成本要高得多，而我们目前不感兴趣基准测试位操作指令）。编译器无法预测下一个随机数是奇数还是偶数，因此无法进行任何优化。此外，我们已经检查了生成的机器代码，并确认我们的编译器（x86上的Clang-11）使用简单的条件跳转来实现这个循环。为了有一个基准，我们将比较这个循环的性能与每次迭代都进行无条件加法和乘法的循环：`a1
    += p1[i]*p2[i]`。这个更简单的循环在每次迭代中都进行加法和乘法；然而，由于流水线处理，我们可以*免费*得到加法：它与下一次迭代的乘法同时执行。另一方面，条件分支则完全不是免费的。
- en: '![Figure 3.20'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.20'
- en: '](img/Figure_3.20_B16229.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.20_B16229.jpg)'
- en: Figure 3.20
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20
- en: As you can see, the conditional code is about five times slower than the sequential
    one. This confirms our prediction that when the next instruction depends on the
    result of the previous one, the code cannot be effectively pipelined.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，条件代码比顺序代码慢大约五倍。这证实了我们的预测，即当下一条指令依赖于前一条指令的结果时，代码无法有效地进行流水线处理。
- en: Branch prediction
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分支预测
- en: 'However, an astute reader may point out that the picture we have just described
    cannot possibly be complete, or even true: let us go back, for a moment, to the
    apparently linear code such as the loop we have used extensively in the last section:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个敏锐的读者可能会指出，我们刚刚描述的情况不可能是完整的，甚至不是真实的：让我们回到刚才的线性代码，比如我们在上一节中广泛使用的循环：
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is what the body of this loop looks like from the processor''s point of
    view:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从处理器的角度来看，这个循环的主体是这样的：
- en: '![Figure 3.21 – Loop executed in a pipeline of width w'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.21 – 在宽度为w的流水线中执行的循环'
- en: '](img/Figure_3.21_B16229.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.21_B16229.jpg)'
- en: Figure 3.21 – Loop executed in a pipeline of width w
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 – 在宽度为w的流水线中执行的循环
- en: 'In *Figure 3.21*, we have shown three interleaved iterations, but there could
    be even more, the total width of the pipeline is `w`, and ideally, `w` is large
    enough that at every cycle, the CPU is executing exactly as many instructions
    as it can execute simultaneously (such peak efficiency is rarely possible in practice).
    Note, however, that it may be impossible to access `v[i+2]` at the same time as
    we compute the sum `p1[i] + p2[i]`: there is no guarantee that the loop has two
    more iterations to go, and, if it doesn''t, the element `v[i+2]` does not exist
    and accessing it results in undefined behavior. There is a hidden conditional
    in the previous code: at every iteration, we must check if `i` is less than `N`,
    and only then can we execute the instructions of the i-th iteration.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.21*中，我们展示了三个交错的迭代，但可能会有更多，流水线的总宽度是`w`，理想情况下，`w`足够大，以至于在每个周期，CPU正好执行与其同时执行的指令一样多（在实践中很少可能达到这种峰值效率）。然而，可能无法在计算和存储和`p1[i]
    + p2[i]`的同时访问`v[i+2]`：没有保证循环还有两次迭代，如果没有，元素`v[i+2]`就不存在，访问它会导致未定义的行为。在前面的代码中有一个隐藏的条件：在每次迭代中，我们必须检查`i`是否小于`N`，只有在这种情况下才能执行第i次迭代的指令。
- en: 'Therefore, our comparison in *Figure 3.20* is a lie: we did not compare pipelined
    sequential execution versus an unpredictable conditional one. Both benchmarks
    are, in fact, examples of conditional code, they both have branches.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在*图3.20*中的比较是错误的：我们并没有比较流水线顺序执行和不可预测的条件执行。事实上，这两个基准都是条件代码的例子，它们都有分支。
- en: 'The full truth is somewhere in between. To understand it, we have to learn
    about the antidote to the conditional execution, which poisons the pipelining
    and is itself the antidote to the data dependency. The way to save the pipelining
    in the presence of branches is to attempt to convert the conditional code to the
    sequential one. Such conversion could be done if we knew in advance which path
    the branch is going to take: we would simply eliminate the branch and proceed
    to the next instruction to be executed. Of course, there would be no need even
    to write such code if we knew in advance what the condition is. Still, consider
    the loop termination condition. Assuming the loop is executed many times, it is
    a good bet that the condition `i < N` evaluates to `true` (we would lose this
    bet only one out of `N` times).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的真相在其中。要理解这一点，我们必须了解条件执行的解药，它会破坏流水线，并且本身是数据依赖的解药。在分支存在的情况下保持流水线的方法是尝试将条件代码转换为顺序代码。如果我们事先知道分支将采取的路径，就可以进行这种转换：我们只需消除分支并继续执行下一个要执行的指令。当然，如果我们事先知道条件是什么，甚至不需要编写这样的代码。但是，考虑循环终止条件。假设循环执行多次，很可能条件`i
    < N`评估为`true`（我们只有`N`次中的一次会输掉这个赌注）。
- en: The processor makes the same bet using the technique known as **branch prediction**.
    It analyzes the history of every branch in the code and assumes that the behavior
    will not change in the future. For the end of the loop condition, the processor
    will quickly learn that most of the time, it has to proceed to the next iteration.
    Therefore, the right thing to do is to pipeline the next iteration as if we are
    sure it's going to happen. Of course, we have to defer the actual writing of the
    results into memory until we evaluate the condition and confirm that the iteration
    does happen; the processor has a certain number of write buffers to hold such
    unconfirmed results *in limbo* before committing them to memory.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器使用称为**分支预测**的技术进行同样的赌博。它分析代码中每个分支的历史，并假设行为在未来不会改变。对于循环结束条件，处理器将很快学会，大多数情况下，它必须继续下一次迭代。因此，正确的做法是流水线下一次迭代，就好像我们确定它会发生一样。当然，我们必须推迟将结果写入内存，直到我们评估条件并确认迭代确实发生；处理器有一定数量的写缓冲区来保存这些未经确认的结果，在提交到内存之前。
- en: 'The pipeline for the loop with just an addition, therefore, does look exactly
    as shown in *Figure 3.21*. The only catch is that, when starting to execute iteration
    `i+2` before the i-th iteration is complete, the processor is making a bet based
    on its prediction of whether the conditional branch will be taken or not. Such
    execution of the code before we know for sure that this code really exists is
    known as **speculative execution**. If the bet is won, we already have the results
    by the time we figure out that we needed the computation, and all is well. If
    the processor loses the bet, it has to discard some of the computations to avoid
    producing incorrect results: for example, writing into memory overwrites what
    was there before and cannot be undone on most hardware platforms, while computing
    the result and storing it in a register is entirely reversible, except for the
    time we wasted, of course.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，仅进行加法的循环的流水线看起来确实如*图3.21*所示。唯一的问题是，在完成第i次迭代之前开始执行第`i+2`次迭代时，处理器是基于其对条件分支是否被执行的预测而进行的一种赌博。在我们确定这段代码是否真的存在之前执行代码的这种方式被称为**推测执行**。如果赌赢了，我们在弄清楚我们需要计算时已经有了结果，一切都很好。如果处理器输了，它必须放弃一些计算以避免产生不正确的结果：例如，写入内存会覆盖之前的内容，并且在大多数硬件平台上无法撤消，而计算结果并将其存储在寄存器中是完全可逆的，当然除了我们浪费的时间。
- en: 'We now have a more complete picture of how the pipelining really works: in
    order to find more instructions to execute in parallel, the processor looks at
    the code for the next iterations of the loop and starts to execute it simultaneously
    with the current iteration. If the code includes a conditional branch, which makes
    it impossible to know for sure which instruction will be executed, the processor
    makes an educated guess based on the past outcomes of checking the same condition
    and proceeds to execute the code speculatively. If the prediction proves to be
    correct, the pipelining can be as good as it was for the unconditional code. If
    the prediction is wrong, the processor has to discard the result of every instruction
    that should not have been evaluated, fetch the instructions that it previously
    assumed wouldn''t be needed, and evaluate them instead. This event is called a
    **pipeline flush**, and it is an expensive occurrence indeed.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对流水线的工作原理有了更全面的了解：为了在并行执行更多指令，处理器查看循环的下一次迭代的代码，并开始与当前迭代同时执行。如果代码包括条件分支，使得不可能确定将执行哪个指令，处理器会根据过去检查相同条件的结果做出合理的猜测，并继续推测性地执行代码。如果预测被证明是正确的，流水线的效果可以和无条件代码一样好。如果预测是错误的，处理器必须丢弃不应该被评估的每条指令的结果，获取先前假定不需要的指令，并代替评估它们。这个事件被称为**流水线刷新**，这确实是一个昂贵的事件。
- en: 'Now we have a better understanding of our previous benchmark in *Figure 3.20*:
    both loops have a condition for checking the end of the loop. However, it is predicted
    almost perfectly. The pipeline flush occurs only once at the end of the loop.
    The *conditional* benchmark also has a branch that is based on a random number:
    `if(b1[i])` where `b1[i]` is true 50% of the time, randomly. The processor is
    powerless to predict the outcome, and the pipeline is disrupted half the time
    (or worse, if we manage to confuse the CPU into actually making wrong predictions).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对*图3.20*中的先前基准有了更好的理解：两个循环都有一个用于检查循环结束的条件。但是，它几乎完美地预测。 *条件*基准还具有基于随机数的分支：`if(b1[i])`，其中`b1[i]`
    50%的时间是true，随机的。处理器无法预测结果，管道一半的时间被破坏（或者更糟，如果我们设法混淆CPU以实际进行错误预测）。
- en: 'We should be able to verify our understanding with a direct experiment: all
    we need is to change the *random* condition to something that is always true.
    The only catch is that we have to do it in a way that the compiler cannot figure
    it out. One common way is to change the initialization of the condition vector
    as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该能够通过直接实验来验证我们的理解：我们只需要将*随机*条件更改为始终为true的条件。唯一的问题是我们必须以编译器无法理解的方式来做到这一点。一种常见的方法是将条件向量的初始化更改为以下内容：
- en: '[PRE13]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The compiler doesn''t know that the function `rand()` always returns non-negative
    random numbers and will not eliminate the condition. The branch predictor circuit
    of the CPU will quickly learn that the condition `if(b1[i])` always evaluates
    to true and will execute the corresponding code speculatively. We can compare
    the performance of the well-predicted branch with that of the unpredictable one:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器不知道函数`rand()`总是返回非负随机数，并且不会消除条件。 CPU的分支预测电路将很快学习到条件`if(b1[i])`总是评估为true，并将推测性地执行相应的代码。我们可以将预测良好的分支的性能与不可预测的分支进行比较：
- en: '![Figure 3.22'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.22'
- en: '](img/Figure_3.22_B16229.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.22_B16229.jpg)'
- en: Figure 3.22
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22
- en: Here we can see that the cost of the well-predicted branch is minimal and that
    it is much faster than exactly the same code with a branch that is predicted poorly.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到预测良好的分支的成本是最小的，比预测不佳的分支快得多，即使是完全相同的代码。
- en: Profiling for branch mispredictions
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分支错误预测的分析
- en: Now that you have seen how badly a single mispredicted branch can impact the
    performance of the code, you may wonder, how would you ever find such code so
    you can optimize it? Sure, the function containing this code will take longer
    than you might expect, but how do you know whether it's because of the badly predicted
    branches or due to some other inefficiency? By now, you should know enough to
    avoid making guesses about performance in general; however, speculating about
    the effectiveness of the branch predictor is particularly futile. Fortunately,
    most profilers can profile not just execution time but also various factors determining
    the efficiency, including the branch prediction failures.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经看到单个错误预测的分支会如何影响代码的性能，您可能会想知道，您如何找到这样的代码以便进行优化？当然，包含此代码的函数将花费比您预期的时间更长，但是您如何知道这是因为错误预测的分支还是由于其他一些低效性？到目前为止，您应该已经了解足够多，以避免对性能进行一般性的猜测；但是，对分支预测器的有效性进行推测尤其是徒劳的。幸运的是，大多数分析器不仅可以分析执行时间，还可以分析决定效率的各种因素，包括分支预测失败。
- en: 'In this chapter, we will once again use the `perf` profiler. As the first step,
    we can run this profiler to collect the overall performance metrics of the entire
    benchmark program:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将再次使用`perf`分析器。作为第一步，我们可以运行此分析器以收集整个基准程序的整体性能指标：
- en: '[PRE14]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here are the `perf` results for the program running only the `BM_branch_not_predicted`
    benchmark (other benchmarks are commented out for this test):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这是仅运行`BM_branch_not_predicted`基准的程序的`perf`结果（其他基准已在此测试中注释掉）：
- en: '![Figure 3.23 – Profile of a benchmark with a poorly predicted branch'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.23 - 具有预测不佳分支的基准的概要'
- en: '](img/Figure_3.23_B16229.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.23_B16229.jpg)'
- en: Figure 3.23 – Profile of a benchmark with a poorly predicted branch
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23 - 具有预测不佳分支的基准的概要
- en: 'As you can see, 11% of all branches were mispredicted (the last line of the
    report). Note that this number is cumulative for all branches, including the perfectly
    predictable end of the loop condition, so 11% total is quite bad. We should compare
    it with our other benchmark, `BM_branch_predicted`, which is identical to this
    one except the condition is always true:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，所有分支中有11%被错误预测（报告的最后一行）。请注意，此数字是所有分支的累积值，包括循环条件的完全可预测结尾，因此总共11%相当糟糕。我们应该将其与我们的其他基准`BM_branch_predicted`进行比较，该基准与此基准相同，只是条件始终为真：
- en: '![Figure 3.24 – Profile of a benchmark with a well-predicted branch'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.24 - 具有良好预测分支的基准的配置文件'
- en: '](img/Figure_3.24_B16229.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.24_B16229.jpg)'
- en: Figure 3.24 – Profile of a benchmark with a well-predicted branch
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24 - 具有良好预测分支的基准的配置文件
- en: This time, less than 0.1% of all branches were not predicted correctly.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，不到0.1%的分支没有被正确预测。
- en: 'The overall performance report is very useful, do not ignore its potential:
    it can be used to highlight or dismiss some possible causes of poor performance
    quickly. In our case, we can immediately conclude that our program suffers from
    one or more mispredicted branches. Now we just need to find which one, and the
    profiler can help with that as well. Just like in the previous chapter, where
    we have used the profiler to find out where in the code does our program spends
    the most time, we can generate a detailed line-by-line profile of branch predictions.
    We just need to specify the right performance counter to the profiler:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 整体性能报告非常有用，不要忽视其潜力：它可以快速突出或排除一些可能导致性能不佳的原因。在我们的情况下，我们可以立即得出结论，即我们的程序受到一个或多个错误预测分支的影响。现在我们只需要找出是哪一个，分析器也可以帮助解决这个问题。就像在上一章中，我们已经使用分析器找出程序在代码中花费最多时间的地方一样，我们可以生成分支预测的详细逐行分析。我们只需要向分析器指定正确的性能计数器：
- en: '[PRE15]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In our case, we can copy the name of the counter from the output of `perf stat`,
    because it happens to be one of the counters it measures by default, but the complete
    list can be obtained by running `perf --list`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们可以从`perf stat`的输出中复制计数器的名称，因为它恰好是默认情况下测量的计数器之一，但是完整列表可以通过运行`perf --list`来获取。
- en: 'The profiler runs the program and collects the metrics. We can view them by
    generating a profile report:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器运行程序并收集指标。我们可以通过生成配置文件来查看它们：
- en: '[PRE16]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The report analyzer is interactive and lets us navigate to the branch mispredictions
    counter for each function:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 报告分析器是交互式的，让我们可以导航到每个函数的分支错误预测计数器：
- en: '![Figure 3.25 – Detailed profile report for mispredicted branches'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.25 - 针对错误预测分支的详细配置文件'
- en: '](img/Figure_3.25_B16229.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.25_B16229.jpg)'
- en: Figure 3.25 – Detailed profile report for mispredicted branches
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.25 - 针对错误预测分支的详细配置文件
- en: Over 99% of all mispredicted branches occur in just one function. Since the
    function is small, finding the responsible conditional operation should not be
    hard. In a larger function, we would have to look at the line-by-line profile.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 超过99%的错误预测分支发生在一个函数中。由于该函数很小，找到负责的条件操作不应该很难。在较大的函数中，我们需要查看逐行分析。
- en: 'The branch prediction hardware of a modern processor is fairly sophisticated.
    For example, if a function is called from two different places and, when called
    from the first place, a condition usually evaluates to true, while, when called
    from the second place, the same condition evaluates to false, the predictor will
    learn that pattern and predict the branch correctly based on the origin of the
    function call. Similarly, the predictor can detect fairly complex patterns in
    the data. For example, we can initialize our *random* condition variables so that
    the values always alternate, the first one is random, but the next one is the
    opposite of the first one, and so on:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现代处理器的分支预测硬件相当复杂。例如，如果从两个不同的位置调用一个函数，并且当从第一个位置调用时，条件通常为真，而当从第二个位置调用时，相同的条件为假，那么预测器将学习该模式，并根据函数调用的来源正确预测分支。类似地，预测器可以检测数据中相当复杂的模式。例如，我们可以初始化我们的*random*条件变量，使值始终交替，第一个是随机的，但下一个是第一个的相反，依此类推：
- en: '[PRE17]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The profiler confirms that the branch prediction rate for this data is excellent:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器确认该数据的分支预测率非常好：
- en: '![Figure 3.26 – Branch prediction rate for a "true-false" pattern'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.26 - “真-假”模式的分支预测率'
- en: '](img/Figure_3.26_B16229.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.26_B16229.jpg)'
- en: Figure 3.26 – Branch prediction rate for a "true-false" pattern
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26 - “真-假”模式的分支预测率
- en: We are almost ready to apply our knowledge of how to use the processor efficiently.
    But first, I must admit that we have overlooked a major potential problem.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好了应用我们如何有效使用处理器的知识。但首先，我必须承认我们忽视了一个重大的潜在问题。
- en: Speculative execution
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推测执行
- en: 'We understand now how pipelining keeps the CPU busy and how, by predicting
    the results of conditional branches and executing the expected code speculatively,
    before we know for sure that it must be executed, we allow the conditional code
    to be pipelined. *Figure 3.21* illustrates this approach: by assuming that the
    end of the loop condition is not going to happen after the current iteration,
    we can interleave the instruction from the next iteration with those of the current
    one, so we have more instructions to execute in parallel.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在了解了流水线如何使CPU保持忙碌，以及通过预测条件分支的结果并在我们确定必须执行之前就进行预期代码的执行，我们允许条件代码进行流水线处理。*图3.21*说明了这种方法：假设循环条件在当前迭代之后不会发生，我们可以将下一次迭代的指令与当前迭代的指令交错，因此我们可以并行执行更多指令。
- en: Sooner or later, our prediction will be wrong, but all we have to do is discard
    some results that should have never been computed in the first place and make
    it look like they were indeed never computed. This costs us some time, but we
    more than make up for it by speeding up the pipeline when the branch prediction
    is correct. But is this really all we have to do to cover up the fact that we
    tried to execute some code that doesn't really exist?
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 迟早，我们的预测会是错误的，但我们所要做的就是丢弃一些本来不应该被计算的结果，并且让它看起来好像它们确实从未被计算过。这会花费我们一些时间，但当分支预测正确时，我们通过加速流水线来弥补这一点。但是，这真的是我们必须做的一切来掩盖我们试图执行一些实际上并不存在的代码的事实吗？
- en: 'Consider *Figure 3.21* again: if the i-th iteration is the last iteration in
    the loop, then the next iteration should not have happened. Sure, we can discard
    the value `a[i+1]` and not write it into memory. But, in order to do any pipelining,
    we have to read the value of `v1[i+1]`. There is no *discarding* the fact that
    we read it: we access `v1[i+1]` before we check whether the iteration `i` is the
    last iteration, and there is no way to deny that we did access it. But the element
    `v1[i+1]` is outside of the valid memory region allocated for the vector; even
    reading it results in undefined behavior.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑*图3.21*：如果第i次迭代是循环中的最后一次迭代，那么下一次迭代就不应该发生。当然，我们可以丢弃值`a[i+1]`并且不将其写入内存。但是，为了进行任何流水线处理，我们必须读取`v1[i+1]`的值。我们无法*丢弃*我们读取它的事实：我们在检查迭代`i`是否是最后一次迭代之前就访问了`v1[i+1]`，并且无法否认我们确实访问了它。但是元素`v1[i+1]`在为向量分配的有效内存区域之外；即使读取它也会导致未定义的行为。
- en: 'An even more convincing example of the dangers hiding behind the innocent label
    of *speculative execution* is this very common code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏在“推测执行”无辜标签背后的危险的更有说服力的例子是这个非常常见的代码：
- en: '[PRE18]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let us assume that the pointer `p` is rarely `NULL`, so the branch predictor
    learns that the `true` branch of the `if(p)` statement is usually taken. What
    happens when the function is finally called with `p == NULL`? The branch predictor
    is going to assume the opposite, as usual, and the `true` branch is executed speculatively.
    The first thing it does is dereference a `NULL` pointer. We all know what happens
    next: the program will crash. Later, we would have discovered that oops, very
    sorry, we should not have taken that branch in the first place, but how do you
    undo a crash?'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设指针`p`很少是`NULL`，所以分支预测器学习到`if(p)`语句的`true`分支通常被执行。当函数最终以`p == NULL`被调用时会发生什么？分支预测器会像往常一样假设相反，并且`true`分支会被推测执行。它首先会对`NULL`指针进行解引用。我们都知道接下来会发生什么：程序会崩溃。后来，我们会发现糟糕，非常抱歉，我们一开始不应该选择那个分支，但是如何撤销一个崩溃呢？
- en: 'From the fact that code like our function `f()` is very common and does not
    suffer from unexpected random crashes, we can conclude that either the speculative
    execution does not really exist, or there is a way to undo a crash, sort of. We
    have seen some evidence that speculative execution indeed happens and is very
    effective for improving performance. We will see more direct evidence in the next
    chapter. How, then, does it handle the situation when we speculatively attempt
    to do something impossible, like dereferencing a `NULL` pointer? The answer is,
    the catastrophic response to such a potential disaster must be held pending, neither
    discarded nor allowed to become a reality until the branch condition is actually
    evaluated, and the processor knows whether the speculative execution should be
    considered a real execution or not. In this regard, the faults and other invalid
    conditions are no different from the ordinary memory writes: any action that cannot
    be undone is treated as a potential action as long as the instruction that caused
    that action remains speculative. The CPU must have special hardware circuits,
    such as buffers, to store these events temporarily. The end result is, the processor
    really does dereference a `NULL` pointer or read the non-existing vector element
    `v[i+1]` during the speculative execution, then pretends that it never happened.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 从像我们的函数`f()`这样的代码非常常见且不会遭受意外随机崩溃的事实，我们可以得出结论，要么推测执行实际上并不存在，要么有一种方法可以撤销崩溃，或者类似的。我们已经看到一些证据表明推测执行确实发生并且对提高性能非常有效。我们将在下一章中看到更多直接证据。那么，当我们试图推测执行一些不可能的事情时，比如对`NULL`指针进行解引用，它是如何处理的呢？答案是，对于这种潜在灾难的灾难性响应必须被暂时保留，既不被丢弃也不被允许成为现实，直到分支条件实际被评估，并且处理器知道推测执行是否应该被视为真正的执行。在这方面，故障和其他无效条件与普通的内存写入没有什么不同：只要导致该操作的指令仍然是推测的，任何无法撤销的操作都被视为潜在操作。CPU必须有特殊的硬件电路，比如缓冲区，来暂时存储这些事件。最终结果是，处理器确实对`NULL`指针进行解引用或者在推测执行期间读取不存在的向量元素`v[i+1]`，然后假装这从未发生过。
- en: Now that we understand how branch prediction and speculative execution allow
    the processor to operate efficiently despite the uncertainties created by the
    data and code dependencies, we can turn our attention to optimizing our programs.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了分支预测和推测执行如何使处理器能够在数据和代码依赖性造成的不确定性的情况下高效运行，我们可以把注意力转向优化我们的程序。
- en: Optimization of complex conditions
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复杂条件的优化
- en: When it comes to a program with many conditional statements, usually `if()`
    statements, the effectiveness of the branch prediction often determines the overall
    performance. If the branch is predicted accurately, it has almost no cost. If
    the branch is mispredicted half the time, it can be as expensive as ten or more
    regular arithmetic instructions.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有许多条件语句的程序，通常是`if()`语句，分支预测的有效性通常决定了整体性能。如果分支预测准确，几乎没有成本。如果分支一半时间被错误预测，它可能会像十个或更多常规算术指令一样昂贵。
- en: 'It is very important to understand that the hardware branch prediction is based
    on the conditional instructions executed by the processor. As such, the processor''s
    understanding of what a *condition* is can be different from our understanding.
    The following example helps to drive this point home, with force:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的是要理解，硬件分支预测是基于处理器执行的条件指令。因此，处理器对于*条件*的理解可能与我们的理解不同。以下示例有力地证明了这一点：
- en: '[PRE19]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Of interest here is the condition `if (b1[i] || b2[i])`: by construction, it
    always evaluates to `true`, so we can expect the perfect prediction rate from
    the processor. Of course, I would not be showing this example to you if it was
    as simple as that. What is, logically, a single condition to us is, to the CPU,
    two separate conditional branches: half the time, the overall result is true because
    of the first branch, and the other half the time, it is the second branch that
    makes it true. The overall result is always true, but it is impossible to predict
    which of the branches makes it so. The result is quite unfortunate:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这里感兴趣的是条件`if (b1[i] || b2[i])`：按构造，它总是评估为`true`，因此我们可以期望处理器的完美预测率。当然，如果事情真的那么简单，我就不会向您展示这个例子了。对于我们来说逻辑上是一个条件的东西，在CPU看来是两个单独的条件分支：一半的时间，整体结果是由第一个分支决定的，另一半的时间，是第二个分支使其为真。整体结果总是为真，但无法预测哪个分支使其为真。结果非常不幸：
- en: '![Figure 3.27 – Branch prediction profile of a "fake" branch'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.27 - “假”分支的分支预测概况'
- en: '](img/Figure_3.27_B16229.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.27_B16229.jpg)'
- en: Figure 3.27 – Branch prediction profile of a "fake" branch
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27 - “假”分支的分支预测概况
- en: 'The profiler shows the branch prediction rate that is just as poor as that
    of a truly random branch. The performance benchmark confirms our expectations:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器显示的分支预测率与真正随机分支一样糟糕。性能基准证实了我们的期望：
- en: '![Figure 3.28'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.28'
- en: '](img/Figure_3.28_B16229.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.28_B16229.jpg)'
- en: Figure 3.28
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28
- en: The performance of the *fake* branch (that isn't really a branch at all) is
    just as bad as that of a truly random, unpredictable branch, and is far worse
    than that of a well-predicted branch.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*假*分支（实际上根本不是分支）的性能与真正随机、不可预测的分支一样糟糕，远远不如预测良好的分支。'
- en: 'In a real program, you should not encounter such unnecessary conditional statements.
    What is very common, however, is a complex conditional expression that almost
    always evaluates to the same value but for different reasons. For example, we
    may have a condition that is very rarely false:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实的程序中，不应该遇到这种不必要的条件语句。然而，非常常见的是一个复杂的条件表达式，几乎总是基于不同的原因评估为相同的值。例如，我们可能有一个很少为假的条件：
- en: '[PRE20]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'However, nearly half the time, `c3` is true. When `c3` is false, `c1` and `c2`
    are usually both true. The overall condition should be easily predictable, and
    the true branch is taken. However, from the processor''s point of view, it is
    not a single condition but three separate conditional jumps: if `c1` is true,
    then `c2` must be checked. If `c2` is also true, then the execution jumps to the
    first instruction of the true branch. If one of `c1` or `c2` is false, then `c3`
    is checked, and, if it''s true, the execution again jumps to the true branch.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将近一半的时间，`c3`为真。当`c3`为假时，`c1`和`c2`通常都为真。整体条件应该很容易预测，并且会执行真分支。然而，从处理器的角度来看，这不是一个单一的条件，而是三个单独的条件跳转：如果`c1`为真，则必须检查`c2`。如果`c2`也为真，则执行跳转到真分支的第一条指令。如果`c1`或`c2`中的一个为假，则检查`c3`，如果为真，则再次执行跳转到真分支。
- en: 'The reason this evaluation must be done step by step and in that specific order
    is that the C++ standard (and the C standard before it) dictates that the logical
    operations such as `&&` and `||` are *short-circuited*: as soon as the result
    of the entire expression is known, the evaluation of the rest of the expression
    should stop. This is particularly important when the conditions have side effects:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 必须按特定顺序逐步进行这种评估的原因是，C++标准（以及之前的C标准）规定逻辑操作（如`&&`和`||`）是*短路*的：一旦整个表达式的结果已知，评估剩下的表达式应该停止。当条件具有副作用时，这一点尤为重要：
- en: '[PRE21]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now the function `f2()` will be called only if `f1()` returns `false`. In the
    previous example, the conditions were simply boolean variables `c1`, `c2`, and
    `c3`. The compiler could have detected that there are no side effects and that
    evaluating the entire expression to the end will not change the observable behavior.
    Some compilers do this optimization; if our *fake branch* benchmark were compiled
    with such a compiler, it would have shown the performance of a well-predicted
    branch. Most compilers, unfortunately, do not recognize this as a potential problem
    (and, in fact, there is no way for the compiler to know that the entire expression
    usually evaluates to true, even if its parts do not). So, this is an optimization
    that the programmer must usually do manually.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，只有在`f1()`返回`false`时才会调用函数`f2()`。在前面的示例中，条件只是布尔变量`c1`、`c2`和`c3`。编译器可以检测到没有副作用，并且评估整个表达式到最后不会改变可观察的行为。一些编译器会进行这种优化；如果我们的*假分支*基准是用这样的编译器编译的，它将显示出预测良好分支的性能。不幸的是，大多数编译器不会将这视为潜在问题（实际上，编译器无法知道整个表达式通常评估为真，即使它的部分不是）。因此，这是程序员通常必须手动进行的优化。
- en: Assume that the programmer knows that one of the two branches of the `if()`
    statement is taken much more often. For example, the `else` branch could correspond
    to an error situation or some other exceptional condition that must be handled
    properly but should not arise under normal operation. Let us also assume that
    we did things right and verified, using the profiler, that the individual conditional
    instructions that make up the complex boolean expression are not well-predicted.
    How do we optimize the code?
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 假设程序员知道`if()`语句的两个分支中的一个经常被执行。例如，`else`分支可能对应于错误情况或其他异常情况，必须正确处理，但在正常操作下不应该出现。让我们还假设我们做对了事情，并且使用分析器验证了组成复杂布尔表达式的各个条件指令的预测不准确。我们如何优化代码呢？
- en: 'The first impulse may be to move the condition evaluation out of the `if()`
    statement:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个冲动可能是将条件评估移出`if()`语句：
- en: '[PRE22]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: However, this is almost guaranteed not to work, for two reasons. First, the
    condition expression is still using the logical `&&` and `||` operations, so the
    evaluation still must be short-circuited and will require separate and unpredictable
    branches. Second, the compiler will likely optimize this code by removing the
    unnecessary temporary variable `c`, so the resulting object code probably will
    not change at all.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这几乎肯定不会起作用，原因有两个。首先，条件表达式仍在使用逻辑`&&`和`||`操作，因此评估仍必须被短路，并且需要单独且不可预测的分支。其次，编译器可能通过删除不必要的临时变量`c`来优化此代码，因此生成的目标代码可能根本不会改变。
- en: 'In the case of a loop over an array of conditional variables, a similar transformation
    may be effective. For example, this code is likely to suffer from poor branch
    prediction:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环遍历条件变量数组的情况下，类似的转换可能是有效的。例如，这段代码可能会受到较差的分支预测的影响：
- en: '[PRE23]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'However, if we pre-evaluate all the conditional expressions and store them
    in a new array, most compilers will not eliminate that temporary array:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们预先评估所有条件表达式并将它们存储在一个新数组中，大多数编译器不会消除该临时数组：
- en: '[PRE24]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Of course, the boolean expression used to initialize `c[i]` now suffers from
    branch misprediction, so this transformation works only if the second loop is
    executed many more times than the initialization loop.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，用于初始化`c[i]`的布尔表达式现在受到分支错误预测的影响，因此这种转换只有在第二个循环执行的次数比初始化循环多得多时才有效。
- en: 'Another optimization that is usually effective is to replace the logical `&&`
    and `||` operations with addition and multiplication or with bitwise `&` and `|`
    operations. Before doing this, you must be certain that the arguments to the `&&`
    and `||` operations are booleans (have values of zero or one) and not integers:
    even though a value of, say, `2` is interpreted as true, the result of the expression
    `2 & 1` is not the same as the result of `bool(2) & bool(1)`. The former evaluates
    to 0 (false) while the latter gives us the expected and correct answer, 1 (or
    true).'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通常有效的另一个优化是用加法和乘法或位`&`和`|`操作替换逻辑`&&`和`||`操作。在执行此操作之前，必须确保`&&`和`||`操作的参数是布尔值（值为零或一），而不是整数：即使`2`的值被解释为true，表达式`2
    & 1`的结果与`bool(2) & bool(1)`的结果不同。前者评估为0（false），而后者给出了预期和正确的答案1（或true）。
- en: 'We can compare the performance of all these optimizations in a benchmark:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在基准测试中比较所有这些优化的性能：
- en: '![Figure 3.29'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.29'
- en: '](img/Figure_3.29_B16229.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.29_B16229.jpg)'
- en: Figure 3.29
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29
- en: As you can see, the naïve attempt to optimize the *false branch* by introducing
    a temporary variable, `BM_false_branch_temp`, was utterly ineffective. Using a
    temporary vector gives us the expected performance of a perfectly predicted branch
    because all elements of the temporary vector are equal to true, and that is what
    the branch predictor learns (`BM_false_branch_vtemp`). Replacing the logical `||`
    with either arithmetic addition (`+`) or the bitwise `|` produces similar results.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，通过引入临时变量`BM_false_branch_temp`来优化*false branch*的天真尝试是完全无效的。使用临时向量给出了预期的完全预测分支的性能，因为临时向量的所有元素都等于true，这是分支预测器学到的内容(`BM_false_branch_vtemp`)。用算术加法(`+`)或位`|`替换逻辑`||`产生类似的结果。
- en: 'You should keep in mind that the last two transformations, using arithmetic
    or bitwise operations instead of logic operations, change the meaning of your
    code: specifically, all arguments to the operations in the expression are always
    evaluated, including their side effects. It is up to you to decide whether this
    change will affect the correctness of your program. If these side effects are
    also expensive, then the overall performance change may end up being not in your
    favor. For example, if evaluating `f1()` and `f2()` is very time-consuming, replacing
    the logical `||` in the expression `f1() || f2()` by the equivalent arithmetic
    addition (`f1() + f2()`) may degrade the performance even as it improves the branch
    prediction.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该记住，最后两种转换，即使用算术或位操作代替逻辑操作，会改变代码的含义：特别是，表达式中操作的所有参数都会被评估，包括它们的副作用。由您决定这种改变是否会影响程序的正确性。如果这些副作用也很昂贵，那么整体性能变化可能最终不利于您。例如，如果评估`f1()`和`f2()`非常耗时，将表达式`f1()
    || f2()`中的逻辑`||`替换为等效的算术加法(`f1() + f2()`)可能会降低性能，即使它改善了分支预测。
- en: Overall, there is no standard approach to optimizing the branch prediction in
    *false branches*, which is why it is so hard for the compiler to do any effective
    optimizations as well. The programmer must use problem-specific knowledge, such
    as whether a particular condition is likely to occur, and combine it with profiling
    measurements to arrive at the optimal solution.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，在*false branches*中优化分支预测没有标准方法，这也是为什么编译器很难进行有效的优化。程序员必须使用特定于问题的知识，例如特定条件是否可能发生，并结合分析测量结果得出最佳解决方案。
- en: In this chapter, we have learned how CPU operations affect performance, then
    progressed to a concrete and practically relevant example of applying this knowledge
    to code optimization. Before the end, we will learn about one more such optimization.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经学习了CPU操作如何影响性能，然后进展到一个具体且实际相关的例子，应用这些知识来进行代码优化。在结束之前，我们将学习另一种优化方法。
- en: Branchless computing
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无分支计算
- en: 'Here is what we have learned so far: to use the processor efficiently, we must
    give it enough code to execute many instructions in parallel. The main reason
    we may not have enough instructions to keep the CPU busy is the data dependencies:
    we have the code, but we cannot run it because the inputs aren''t ready. We solve
    this problem by pipelining the code, but in order to do so, we must know in advance
    which instructions are going to be executed. We cannot do this if we do not know
    in advance which path the execution will take. The way we deal with that is by
    making an educated guess about whether a conditional branch will be taken or not,
    based on the history of evaluating this condition. The more reliable the guess,
    the better the performance. Sometimes, there is no way to guess reliably, and
    performance suffers.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学到了：为了有效地使用处理器，我们必须提供足够的代码，以便并行执行多条指令。我们之所以没有足够的指令来让CPU忙碌的主要原因是数据依赖性：我们有代码，但我们无法运行它，因为输入还没有准备好。我们通过流水线处理代码来解决这个问题，但为了这样做，我们必须提前知道哪些指令将被执行。如果我们不提前知道执行的路径，我们就无法做到这一点。我们处理这个问题的方式是根据评估这个条件的历史来做出一个合理的猜测，即猜测条件分支是否会被执行，猜测越可靠，性能就越好。有时，没有可靠的猜测方式，性能就会受到影响。
- en: The root of all of these performance problems is the conditional branches, where
    the next instruction to be executed is not known until runtime. A radical solution
    to the problem would be to rewrite our code to use no branches or at least much
    fewer of them. This is known as **branchless computing**.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些性能问题的根源是条件分支，即在运行时无法知道要执行的下一条指令。解决问题的一个激进方法是重写我们的代码，不使用分支，或者至少减少分支的数量。这就是所谓的**无分支计算**。
- en: Loop unrolling
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 循环展开
- en: 'In truth, the idea is not particularly novel. Now that you understand the mechanism
    by which the branches affect performance, you can recognize the well-known technique
    of loop unrolling as an early example of code transformation for the purpose of
    reducing the number of branches. Let us go all the way back to our original code
    example:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这个想法并不是特别新颖。现在你已经了解了分支如何影响性能的机制，你可以认识到循环展开这一众所周知的技术，作为减少分支数量的早期代码转换的一个例子。让我们回到我们的原始代码示例：
- en: '[PRE25]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We understand now that, while the body of the loop is perfectly pipelined,
    there is a hidden branch in this code: the end of the loop check. This check is
    performed once per loop iteration. If we had prior knowledge that, say, the number
    of iterations `N` is always even, then we don''t need to perform the check after
    odd iterations. We can explicitly omit this check as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们明白了，虽然循环的主体是完全流水线化的，但这段代码中隐藏了一个分支：循环结束的检查。这个检查每次循环迭代都会执行一次。如果我们事先知道，比如说，迭代次数`N`总是偶数，那么我们就不需要在奇数迭代后执行检查。我们可以明确地省略这个检查，如下所示：
- en: '[PRE26]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We have unrolled this loop, converted two iterations into one larger one. In
    this and other similar examples, the manual unrolling is not likely to improve
    performance for several reasons: first of all, the end of the loop branch is predicted
    almost perfectly if `N` is large. Second, the compiler may do the unrolling anyway
    as an optimization; more likely, a vectorizing compiler will use SSE or AVX instructions
    to implement this loop, which, in effect, unrolls its body since the vector instructions
    process several array elements at once. All of these conclusions need to be confirmed
    by benchmarking or profiling; just don''t be surprised if you find out that manual
    loop unrolling had no effect on performance: this does not mean that what we learned
    about branches is not true; it means that our original code already had the benefit
    of loop unrolling, thanks to the compiler optimizations most likely.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展开了这个循环，将两次迭代转换为一次更大的迭代。在这个和其他类似的例子中，手动展开循环不太可能提高性能，原因有几个：首先，如果`N`很大，循环的末尾分支几乎可以完美预测。其次，编译器可能会将循环展开为优化；更有可能的是，矢量化编译器将使用SSE或AVX指令来实现这个循环，实际上展开了它的主体，因为矢量指令一次处理多个数组元素。所有这些结论都需要通过基准测试或性能分析来确认；如果你发现手动循环展开对性能没有影响，不要感到惊讶：这并不意味着我们对分支的了解是错误的；这意味着我们的原始代码已经受益于循环展开，很可能是由于编译器优化。
- en: Branchless selection
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无分支选择
- en: 'Loop unrolling is a very specific optimization that the compilers were *taught*
    to do. Generalizing this idea into branchless computing is a recent advance that
    can yield spectacular performance gains. We will start with a very simple example:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 循环展开是一个非常具体的优化，编译器已经*学会*了这样做。将这个想法概括为无分支计算是一个最近的进展，可以产生惊人的性能提升。我们将从一个非常简单的例子开始：
- en: '[PRE27]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let us assume that the conditional variable `b1[i]` cannot be predicted by
    the processor. As we have already seen, this code runs several times slower than
    a loop with a well-predicted branch. However, we can do even better; we can eliminate
    the branch entirely and replace it by indexing into an array of pointers to the
    two destination variables:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 假设条件变量`b1[i]`不能被处理器预测。正如我们已经看到的，这段代码的运行速度比具有良好预测分支的循环慢了几倍。然而，我们可以做得更好；我们可以完全消除分支，并用指向两个目标变量的指针数组进行替换：
- en: '[PRE28]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In this transformation, we take advantage of the fact that a boolean variable
    can have only two values, 0 (`false`) or 1 (`true`), and is implicitly convertible
    to an integer (if we used some other type instead of `bool`, we would have to
    make sure that all `true` values are indeed represented by 1 since any non-zero
    value is considered `true` but only the value of 1 works in our branchless code).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种转换中，我们利用了一个布尔变量只能有两个值，0（`false`）或1（`true`）的事实，并且可以隐式转换为整数（如果我们使用`bool`之外的其他类型，我们必须确保所有`true`值确实由1表示，因为任何非零值都被认为是`true`，但只有1的值适用于我们的无分支代码）。
- en: 'This transformation replaces a conditional jump to one of two possible instructions
    by conditional access of one of two possible memory locations. Because such conditional
    memory accesses can be pipelined, the branchless version delivers significant
    performance improvement:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转换将对两种可能指令的条件跳转替换为对两种可能内存位置的条件访问。因为这种条件内存访问可以进行流水线处理，无分支版本提供了显著的性能改进：
- en: '![Figure 3.30'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.30'
- en: '](img/Figure_3.30_B16229.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.30_B16229.jpg)'
- en: Figure 3.30
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30
- en: 'In this example, the branchless version of the code is 3.5 times faster. It
    is worth noting that some compilers implement the `?:` operator using a lookup
    array instead of a conditional branch whenever possible. With such a compiler,
    we can gain the same performance benefit by rewriting our loop body as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，无分支版本的代码快了3.5倍。值得注意的是，一些编译器在可能的情况下使用查找数组来实现`?:`运算符，而不是条件分支。有了这样的编译器，我们可以通过将我们的循环体重写如下来获得相同的性能优势：
- en: '[PRE29]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: As usual, the only way to be certain whether this optimization works or how
    effective it is, is to measure.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，要确定这种优化是否有效以及其有效性如何，唯一的方法就是进行测量。
- en: 'The preceding example covers all essential elements of branchless computing:
    instead of conditionally executing this code or that code, we transform the program
    so that the code is the same in all cases, and the conditional logic is implemented
    by an indexing operation. We will go through several more examples to highlight
    some noteworthy considerations and limitations.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子涵盖了无分支计算的所有基本要素：不是有条件地执行这段代码或那段代码，而是将程序转换为在所有情况下都相同的代码，并且条件逻辑由索引操作实现。我们将通过几个更多的例子来强调一些值得注意的考虑和限制。
- en: Branchless computing examples
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无分支计算示例
- en: 'Most of the time, the code that depends on the condition is not as simple as
    where to write the result. Usually, we have to do the computations differently
    depending on some intermediate values:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，取决于条件的代码并不像写入结果那样简单。通常，我们必须根据一些中间值以不同的方式进行计算：
- en: '[PRE30]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Here the condition affects what expression we compute and where the result is
    stored. The only thing common to both branches is the input, and even that doesn't
    have to be the case, in general.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，条件影响我们计算的表达式和结果存储的位置。两个分支的共同之处只是输入，而且一般情况下甚至这个也不一定。 '
- en: 'To compute the same results without branches, we have to fetch the result of
    the correct expression from a memory location indexed by the condition variable.
    This implies that both expressions will be evaluated since we decided not to change
    which code we execute based on the condition. With this understanding, the transformation
    to the branchless form is straightforward:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在没有分支的情况下计算相同的结果，我们必须从由条件变量索引的内存位置中获取正确表达式的结果。这意味着由于我们决定不基于条件改变执行哪些代码，因此将评估两个表达式。在这种理解下，转换为无分支形式是直接的：
- en: '[PRE31]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Both expressions are evaluated, and their results are stored in an array. Another
    array is used to index the destination of the computation, that is, which variable
    is incremented. Overall, we have significantly increased the amount of computing
    the loop body must do; on the other hand, it''s all sequential code with no jumps,
    so, as long as the CPU has the resources to do few more operations without spending
    any extra cycles, we should come out ahead. The benchmark confirms that indeed
    this branchless transformation is effective:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 两个表达式都被评估，并它们的结果被存储在一个数组中。另一个数组用于索引计算的目标，也就是说，哪个变量被增加。总的来说，我们显著增加了循环体必须执行的计算量；另一方面，这都是顺序代码，没有跳转，所以只要CPU有资源可以多做一些操作而不需要额外的周期，我们应该会有所收益。基准测试证实了这种无分支转换的有效性：
- en: '![Figure 3.31'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.31'
- en: '](img/Figure_3.31_B16229.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.31_B16229.jpg)'
- en: Figure 3.31
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.31
- en: 'It must be stressed that there is a limit to how many extra computations you
    can do and still outperform the conditional code. There isn''t even a good general
    *rule of thumb* you could use to make an educated guess here (and you should never
    guess about performance anyway). The effectiveness of such optimizations must
    be measured: it is highly dependent on both the code and the data. For example,
    if the branch predictor were highly effective (predictable condition instead of
    a random one), the conditional code would outperform the branchless version:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 必须强调的是，你可以进行多少额外的计算并且仍然优于条件代码是有限制的。在这里，甚至没有一个好的一般性的*经验法则*可以让你做出明智的猜测（而且你绝对不应该猜测性能）。这种优化的有效性必须进行测量：它高度依赖于代码和数据。例如，如果分支预测非常有效（可预测的条件而不是随机的条件），条件代码将优于无分支版本：
- en: '![Figure 3.32'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.32'
- en: '](img/Figure_3.32_B16229.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.32_B16229.jpg)'
- en: Figure 3.32
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.32
- en: 'Perhaps the most remarkable conclusion we can learn from *Figure 3.31* and
    *Figure 3.32* is just how expensive a pipeline flush (a mispredicted branch) is
    and how much computing the CPU can do at once with instruction-level parallelism.
    The latter can be deduced from the relatively small difference in performance
    between the perfectly predicted branch (*Figure 3.32*) and the branchless implementation
    (*Figure 3.31*). This hidden and largely unused reserve of computing power is
    what branchless computing relies on, and we probably have not exhausted this reserve
    in our example. It is instructive to show another variant of the branchless transformation
    of the same code where, instead of using an array to select the right result variable,
    we always increment both by zero if we don''t want to actually change the result:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我们可以从图3.31和图3.32中学到的最显著的结论是流水线刷新（错误预测的分支）有多么昂贵，以及CPU可以同时进行多少计算。后者可以从完全预测的分支（图3.32）和无分支实现（图3.31）之间性能差异相对较小来推断。无分支计算依赖于这种隐藏且大部分未使用的计算能力储备，我们可能在我们的例子中还没有耗尽这个储备。展示同一代码的无分支转换的另一种变体是很有教育意义的，这种变体不是使用数组来选择正确的结果变量，而是如果我们不想实际改变结果，我们总是同时增加两个值：
- en: '[PRE32]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Instead of an array of destinations, we now have two arrays of intermediate
    values. This version does even more computations unconditionally and yet, provides
    the same performance as the previous branchless code:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们不再有目的地数组，而是有两个中间值的数组。这个版本即使在无条件下进行更多的计算，但与之前的无分支代码一样提供了相同的性能：
- en: '![Figure 3.33 – The results of Figure 3.31, with the alternative branchless
    implementation added as "BM_branchless1"'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.33 - 图3.31的结果，另一种无分支实现被添加为"BM_branchless1"'
- en: '](img/Figure_3.33_B16229.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_3.33_B16229.jpg)'
- en: Figure 3.33 – The results of Figure 3.31, with the alternative branchless implementation
    added as "BM_branchless1"
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.33 - 图3.31的结果，另一种无分支实现被添加为"BM_branchless1"
- en: 'It is important to understand the limitations of the branchless transformations
    and not get carried away. We have already seen the first limitation: branchless
    code usually executes more instructions; therefore, if the branch predictor ends
    up working well, the small number of pipeline flushes may not be enough to justify
    the *optimization*.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 了解无分支转换的局限性并不要得意忘形是很重要的。我们已经看到了第一个局限性：无分支代码通常执行更多指令；因此，如果分支预测器最终运行良好，少量的流水线刷新可能不足以证明这种优化。
- en: 'The second reason for the branchless transformation to not perform as expected
    has to do with the compiler: in some cases, the compiler can do an equivalent
    or even better optimization. For example, consider what is known as a **clamp
    loop**:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 无分支转换不能如预期那样执行的第二个原因与编译器有关：在某些情况下，编译器可以进行等效或者更好的优化。例如，考虑所谓的夹紧循环：
- en: '[PRE33]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This loop *clamps* the values in an array `c` of `unsigned char` to the limit
    of `128`. Assuming the initial values were random, the condition in the body of
    the loop cannot be predicted with any degree of certainty, and we can expect a
    very high branch misprediction rate. The alternative, branchless, implementation
    uses a `256` elements, one for each possible value of unsigned `char`. The table
    entries `LUT[i]` for indices `i` from 0 to 127 contain the index value itself,
    and the entries `LUT[i]` for the higher indices all contain 128:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这个循环将数组`c`中的值（无符号字符）夹紧到`128`的限制。假设初始值是随机的，循环体中的条件无法被准确预测，我们可以预期分支错误预测率非常高。另一种无分支的实现方式使用了`256`个元素，每个元素对应无符号字符的可能值。索引为0到127的表项`LUT[i]`包含索引值本身，而较高索引的表项`LUT[i]`都包含128：
- en: '[PRE34]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'With most modern compilers, this is not optimization at all: the compiler will
    do better with the original code, most likely using SSE or AVX vector instructions
    to copy and clamp multiple characters at once and without any branches at all.
    If we profiled the original code instead of assuming that the branch must be mispredicted,
    we would have discovered that the program does not suffer from a poor branch prediction.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数现代编译器来说，这根本不是优化：编译器通常会使用SSE或AVX矢量指令来一次复制和夹紧多个字符，而且完全没有任何分支。如果我们对原始代码进行了剖析，而不是假设分支一定会被错误预测，我们就会发现程序并没有因为分支预测不佳而受到影响。
- en: 'There is one more scenario where a branchless transformation may not pay off,
    and that is the case when the body of the loop is significantly more expensive
    than the branch, even a mispredicted one. This case is notable because it often
    describes loops that make function calls:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种情况下无分支转换可能不划算，那就是循环体的开销明显大于分支，即使是错误预测的分支。这种情况很重要，因为它通常描述了进行函数调用的循环：
- en: '[PRE35]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here we call one of the two functions, `f1()` or `f2()`, depending on the condition
    `b1`. The `if-else` statement can be eliminated, and the code can be made branchless
    if we use an array of function pointers:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们根据条件`b1`调用`f1()`或`f2()`中的一个函数。`if-else`语句可以被消除，如果我们使用函数指针数组，代码可以变成无分支。
- en: '[PRE36]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Is this an optimization worth doing? Often, it isn't. First of all, if the functions
    `f1()` or `f2()` can be inlined, the function pointer call will prevent that.
    **Inlining** is usually a major optimization; giving up inlining to get rid of
    a branch is almost never justified. When the functions are not inlined, the function
    call by itself disrupts the pipeline (this is one reason inlining is such an effective
    optimization). Compared to the cost of the function call, even a mispredicted
    branch is usually not that much.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种值得做的优化吗？通常不是。首先，如果函数`f1()`或`f2()`可以内联，函数指针调用将阻止内联。内联通常是一种重要的优化；为了摆脱分支而放弃内联几乎是不合理的。当函数没有内联时，函数调用本身会中断流水线（这也是内联是如此有效的优化的原因之一）。与函数调用的成本相比，即使是错误预测的分支通常也不那么重要。
- en: 'Nonetheless, sometimes this function lookup table is a worthwhile optimization:
    it almost never pays off for just two alternatives, but if we had to choose from
    many functions based on a single condition, the function pointer table is more
    efficient than a chained `if-else` statement. It is worth noting that this example
    is very similar to the implementation used by all modern compilers to implement
    virtual function calls; such calls are also dispatched using an array of function
    pointers instead of a chain of comparisons. When faced with a need to optimize
    code that calls one of several functions based on a runtime condition, you should
    consider whether a redesign using polymorphic objects is worthwhile.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，有时查找表是一种值得优化的方法：对于只有两个选择的情况几乎从不值得，但如果我们必须根据单个条件从许多函数中进行选择，函数指针表比链式`if-else`语句更有效。值得注意的是，这个例子与所有现代编译器用来实现虚函数调用的实现非常相似；这样的调用也是使用函数指针数组而不是一系列比较来分派的。当需要优化根据运行时条件调用多个函数的代码时，您应该考虑是否值得使用多态对象进行重新设计。
- en: 'You should also keep in mind the effect of the branchless transformations on
    the readability of your code: a lookup table of function pointers is not as easy
    to read and can be much harder to debug than a `switch` or `if-else` statement.
    Given the many factors contributing to the final outcome (compiler optimizations,
    hardware resource availability, the nature of the data the program operates on),
    any optimizations must be verified by measurements such as benchmarks and profiles
    and weighed against the additional cost imposed on the programmer in terms of
    time, readability, and complexity.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该记住无分支转换对代码的可读性的影响：函数指针的查找表不如`switch`或`if-else`语句易读，而且可能比后者更难调试。考虑到最终结果的许多因素（编译器优化、硬件资源可用性、程序操作的数据的性质），任何优化都必须通过基准测试和性能分析来验证，并权衡对程序员在时间、可读性和复杂性方面的额外成本。
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we have learned about the computing capabilities of the main
    processor and how to use them effectively. The key to high performance is to make
    maximum use of all available computing resources: a program that computes two
    results at the same time is faster than the one that computes the second result
    later (assuming the computing power is available). As we have learned, the CPU
    has a lot of computing units for various types of computations, most of which
    are idle at any given moment unless the program is very highly optimized.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了主处理器的计算能力以及如何有效地使用它们。高性能的关键是充分利用所有可用的计算资源：同时计算两个结果的程序比稍后计算第二个结果的程序更快（假设计算能力可用）。正如我们所了解的，CPU具有各种类型计算的许多计算单元，其中大多数在任何给定时刻都是空闲的，除非程序经过高度优化。
- en: 'We have seen that the main restriction on efficient use of the CPU''s instruction-level
    parallelism is usually the data dependencies: there simply isn''t enough work
    that can be done in parallel to keep the CPU busy. The hardware solution to this
    problem is pipelining: the CPU doesn''t just execute the code at the current point
    in the program but takes some computations from the future that have no unsatisfied
    data dependencies and executes them in parallel. This works well as long as the
    future is well known: the CPU cannot execute the computations from the future
    if it cannot determine what these computations are. Whenever the CPU must wait
    to determine what machine instructions are to be executed next, the pipeline stalls.
    To reduce the frequency of such stalls, the CPU has special hardware that predicts
    the most probable future, the path through the conditional code that is likely
    to be taken, and executes that code speculatively. The performance of the program,
    thus, depends critically on how well this prediction works.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，有效利用CPU指令级并行性的主要限制通常是数据依赖性：简单地说，没有足够的并行工作来让CPU保持忙碌。这个问题的硬件解决方案是流水线：CPU不仅仅执行程序中当前点的代码，而是从没有未满足数据依赖性的未来中获取一些计算，并并行执行它们。只要未来是已知的，这种方法就有效：如果CPU无法确定这些计算是什么，它就无法执行未来的计算。每当CPU必须等待确定下一条要执行的机器指令时，流水线就会停顿。为了减少这种停顿的频率，CPU具有特殊的硬件，可以预测最有可能的未来，通过条件代码的路径，以及推测性地执行该代码。因此，程序的性能关键取决于这种预测的准确性。
- en: We have learned the use of special tools that can help measure the efficiency
    of the code and identify the bottlenecks that limit the performance. Guided by
    the measurements, we have studied several optimization techniques that can make
    the program utilize more of the CPU resources, wait less and compute more, and,
    in the end, help to improve performance.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学会了使用特殊工具来帮助衡量代码的效率并识别限制性能的瓶颈。在测量的指导下，我们研究了几种优化技术，可以使程序更充分地利用CPU资源，等待时间更少，计算更多，并最终有助于提高性能。
- en: 'Throughout this chapter, we have persistently ignored one step every computation
    must do eventually: access the memory. The inputs for any expression reside in
    memory and must be brought into the registers before the rest of the computation
    takes place. The intermediate results can be stored in the registers, but eventually,
    something has to be written back into memory, or the entire code has no lasting
    effect. As it turns out, memory operations (reads and writes) have a significant
    effect on performance and, in many programs, are the limiting factor that prevents
    further optimizations. The next chapter is dedicated to studying the CPU-memory
    interactions.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们一直忽略了每个计算最终必须执行的一步：访问内存。任何表达式的输入都驻留在内存中，并且必须在其余计算发生之前被带入寄存器。中间结果可以存储在寄存器中，但最终，某些东西必须被写回内存，否则整个代码就没有持久的效果。事实证明，内存操作（读取和写入）对性能有显著影响，并且在许多程序中是阻止进一步优化的限制因素。下一章将致力于研究CPU与内存的交互。
- en: Questions
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the key to using the CPU resources efficiently?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何有效地使用CPU资源的关键是什么？
- en: How can we use instruction-level parallelism to improve performance?
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何利用指令级并行性来提高性能？
- en: How can the CPU execute computations in parallel if the latter one needs the
    results of the former one?
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果后一个计算需要前一个计算的结果，CPU如何并行执行计算？
- en: Why are conditional branches much more expensive than simply the cost of evaluating
    a conditional expression?
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么条件分支比简单评估条件表达式的成本要昂贵得多？
- en: What is speculative execution?
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是推测执行？
- en: What optimization techniques are available to improve the effectiveness of pipelining
    in code with conditional computations?
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪些优化技术可用于改善具有条件计算的代码中流水线的效率？
