["```cpp\nclass Layer\n{\npublic:\n    Layer();\n    ~Layer();\n\n    std::string get_name() { return name_; }\n\n    virtual Blob<float> *forward(Blob<float> *input) = 0;\n    virtual Blob<float> *backward(Blob<float> *grad_input) = 0;\n\n    virtual float get_loss(Blob<float> *target);\n    virtual int   get_accuracy(Blob<float> *target);\n\n    void set_cuda_context(CudaContext *context) { cuda_ = context; }\n\n    /* weights update control */\n    void freeze() { freeze_ = true; }\n    void unfreeze() { freeze_ = false;}\n    void set_load_pretrain() { load_pretrain_ = true; }\n    void set_gradient_stop() { gradient_stop_ = true; }\n```", "```cpp\nprotected:\n    std::string name_;\n\n    // Tensor descriptor for the input/output tensor\n    cudnnTensorDescriptor_t input_desc_;\n    cudnnTensorDescriptor_t output_desc_;\n    // filter and bias descriptor for weights and biases\n    cudnnFilterDescriptor_t filter_desc_;\n    cudnnTensorDescriptor_t bias_desc_;\n\n    // output memory\n    Blob<float> *input_ = nullptr;       /* x */\n    Blob<float> *output_ = nullptr;      /* y */\n    Blob<float> *grad_input_ = nullptr;  /* dx */\n    Blob<float> *grad_output_ = nullptr; /* dy */\n\n    // master weights & bias\n    bool freeze_ = false;               /* control parameter updates */\n    Blob<float> *weights_ = nullptr;      /* w */\n    Blob<float> *biases_  = nullptr;      /* b */\n    Blob<float> *grad_weights_ = nullptr; /* dw */\n    Blob<float> *grad_biases_  = nullptr; /* db */\n\n    int batch_size_ = 0; // mini-batch size\n\n    // cuda handle container\n    CudaContext *cuda_ = nullptr;\n\n    // initialize weights along with the input size\n    void init_weight_bias(unsigned int seed = 0);\n    void update_weights_biases(float learning_rate);\n\n    // pretrain parameters\n    bool load_pretrain_ = false;\n    int load_parameter();\n    int save_parameter();\n\n    // gradient stop tagging\n    bool gradient_stop_ = false;\n\n    friend class Network;\n}\n```", "```cpp\nBlob<T>(int n, int c, int h, int w)\n```", "```cpp\n// get specified memory pointer\nftype *ptr() { return h_ptr_; }\n\n// get cuda memory\nftype *cuda() \n{ \n    if (d_ptr_ == nullptr) \n        cudaMalloc((void**)&d_ptr_, sizeof(ftype) * len());\n    return d_ptr_;\n}\n\n// transfer data between memory\nftype *to(DeviceType target) { \n    ftype *ptr = nullptr;\n    if (target == host)\n    {\n        cudaMemcpy(h_ptr_, cuda(), sizeof(ftype) * len(), \n                   cudaMemcpyDeviceToHost);\n        ptr = h_ptr_;\n    }\n    else // DeviceType::cuda\n    {\n        cudaMemcpy(cuda(), h_ptr_, sizeof(ftype) * len(), \n                   cudaMemcpyHostToDevice);\n        ptr = d_ptr_;\n    }\n    return ptr;\n}\n```", "```cpp\n/* Tensor Control */\nbool is_tensor_ = false;\ncudnnTensorDescriptor_t tensor_desc_;\ncudnnTensorDescriptor_t tensor()\n{\n    if (is_tensor_)\n        return tensor_desc_;\n\n    cudnnCreateTensorDescriptor(&tensor_desc_);\n    cudnnSetTensor4dDescriptor(tensor_desc_, \n                                CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n                                n_, c_, h_, w_);\n    is_tensor_ = true;\n    return tensor_desc_;\n}\n```", "```cpp\nDense::Dense(std::string name, int output_size)\n{\n    name_ = name;\n    output_size_ = output_size;\n}\n```", "```cpp\nBlob<float> *Dense::forward(Blob<float> *input) {\n  .. { blob initialization } ..\n\n  // output = weights^T * input (without biases)\n  cublasSgemm(cuda_->cublas(),\n        CUBLAS_OP_T, CUBLAS_OP_N, output_size_, \n        batch_size_, input_size_,\n        &cuda_->one, weights_->cuda(), input_size_,\n        input_->cuda(), input_size_,\n        &cuda_->zero, output_->cuda(), output_size_);\n\n  // output += biases * one_vec^T\n  cublasSgemm(cuda_->cublas(), \n        CUBLAS_OP_N, CUBLAS_OP_N, output_size_, batch_size_, 1,\n        &cuda_->one, biases_->cuda(), output_size_, one_vec, 1, \n        &cuda_->one, output_->cuda(), output_size_);\n  return output_;\n}\n```", "```cpp\n// initialize weights and biases\nif (weights_ == nullptr)\n{\n    // setup parameter size information\n    input_size_ = input->c() * input->h() * input->w();\n\n    // initialize weight, bias, and output\n    weights_ = new Blob<float>(1, 1, input_size_, output_size_);\n    biases_ = new Blob<float>(1, 1, output_size_);\n}\n```", "```cpp\n// initilaize input and output\nif (input_ == nullptr || batch_size_ != input->n())\n{\n  input_ = input;\n  batch_size_ = input->n();\n\n  if (output_ == nullptr)\n    output_ = new Blob<float>(batch_size_, output_size_);\n  else\n    output_->reset(batch_size_, output_size_);\n\n  output_->tensor();\n\n  if (d_one_vec != nullptr)\n    cudaFree(d_one_vec);\n  checkCudaErrors(cudaMalloc((void**)&d_one_vec, sizeof(float) * batch_size_));\n  init_one_vec<<< (batch_size_+BLOCK_DIM_1D-1)/BLOCK_DIM_1D, BLOCK_DIM_1D >>>(d_one_vec, batch_size_);\n\n  if (!freeze_)\n    init_weight_bias();\n}\n```", "```cpp\noutput_ = new Blob<float>(batch_size_, output_size_);\n```", "```cpp\nvoid Layer::init_weight_bias(unsigned int seed)\n{\n    // Create random network\n    std::random_device rd;\n    std::mt19937 gen(seed == 0 ? rd() : static_cast<unsigned int>\n                                        (seed));\n\n    // He normal distribution\n    float range = sqrt(6.f / input_->size());\n    std::uniform_real_distribution<> dis(-range, range);\n\n    for (int i = 0; i < weights_->len(); i++)\n        weights_->ptr()[i] = static_cast<float>(dis(gen));\n    for (int i = 0; i < biases_->len(); i++)\n        biases_->ptr()[i] = 0.f;\n\n    // copy initialized value to the device\n    weights_->to(DeviceType::cuda);\n    biases_->to(DeviceType::cuda);\n}\n```", "```cpp\nif (grad_weights_ == nullptr) {\n  grad_output_ = grad_output;\n  grad_weights_ = new Blob<float>(weights_->shape());\n  grad_biases_ = new Blob<float>(biases_->shape());\n  grad_input_ = new Blob<float>(input_->shape());\n}\n```", "```cpp\nBlob<float> *Dense::backward(Blob<float> *grad_output) {\n  .. { blob initialization } ..\n\n  // db = (dy) * one_vec\n  cublasSgemv(cuda_->cublas(),\n    CUBLAS_OP_N,\n    output_size_, batch_size_,\n    &cuda_->one,\n    grad_output_->cuda(), output_size_,\n    one_vec, 1,\n    &cuda_->zero,\n    grad_biases_->cuda(), 1); \n\n  // dw = x * (dy)^T\n  cublasSgemm(cuda_->cublas(),\n    CUBLAS_OP_N, CUBLAS_OP_T,\n    input_size_, output_size_, batch_size_,\n    &cuda_->one,\n    input_->cuda(), input_size_,\n    grad_output_->cuda(), output_size_,\n    &cuda_->zero,\n    grad_weights_->cuda(), input_size_);\n\n  // dx = W * dy\n  if (!gradients_stop_)\n    cublasSgemm(cuda_->cublas(),\n      CUBLAS_OP_N, CUBLAS_OP_N,\n      input_size_, batch_size_, output_size_,\n      &cuda_->one,\n      weights_->cuda(), input_size_,\n      grad_output_->cuda(), output_size_,\n      &cuda_->zero, \n      grad_input_->cuda(), input_size_);\n\n  return grad_input_;\n}\n```", "```cpp\nvoid Layer::update_weights_biases(float learning_rate)\n{\n  float eps = -1.f * learning_rate;\n  if (weights_ != nullptr && grad_weights_ != nullptr) {\n    // w = w + eps * dw\n    cublasSaxpy(cuda_->cublas(),\n      weights_->len(),\n      &eps,\n      grad_weights_->cuda(), 1,\n      weights_->cuda(), 1);\n  }\n\n  if (biases_ != nullptr && grad_biases_ != nullptr)\n  {\n    // b = b + eps * db\n    cublasSaxpy(cuda_->cublas(),\n      biases_->b(),\n      &eps,\n      grad_biases_->cuda(), 1,\n      biases_->cuda(), 1);\n  }\n}\n```", "```cpp\nLayer::~Layer()\n{\n  if (output_ != nullptr) delete output_;\n  if (grad_input_ != nullptr) delete grad_input_;\n\n  if (weights_ != nullptr) delete weights_;\n  if (biases_ != nullptr) delete biases_;\n  if (grad_weights_ != nullptr) delete grad_weights_;\n  if (grad_biases_ != nullptr) delete grad_biases_;\n}\n```", "```cpp\ncudnnStatus_t cudnnActivationForward( cudnnHandle_t handle,\n    cudnnActivationDescriptor_t activationDesc,\n    const void *alpha, const cudnnTensorDescriptor_t xDesc, \n    const void *x, const void *beta,  \n    const cudnnTensorDescriptor_t yDesc, void *y)\n```", "```cpp\ncudnnStatus_t cudnnActivationBackward( cudnnHandle_t handle,\n    cudnnActivationDescriptor_t activationDesc,\n    const void *alpha, const cudnnTensorDescriptor_t yDesc,  \n    const void *y,\n    const cudnnTensorDescriptor_t dyDesc, const void *dy,\n    const cudnnTensorDescriptor_t xDesc,  const void *x,\n    const void *beta,  const cudnnTensorDescriptor_t dxDesc, void *dx)\n```", "```cpp\nclass Activation: public Layer\n{\npublic:\n  Activation(std::string name, cudnnActivationMode_t mode, \n             float coef = 0.f);\n  ~Activation();\n\n  Blob<float> *forward(Blob<float> *input);\n  Blob<float> *backward(Blob<float> *grad_input);\n\nprivate:\n  cudnnActivationDescriptor_t act_desc_;\n  cudnnActivationMode_t mode_;\n  float coef_;\n};\n```", "```cpp\nActivation::Activation(std::string name, cudnnActivationMode_t mode, float coef)\n{\n  name_ = name;\n  mode_ = mode;\n  coef_ = coef;\n\n  cudnnCreateActivationDescriptor(&act_desc_);\n  cudnnSetActivationDescriptor(act_desc_, mode, CUDNN_PROPAGATE_NAN, coef);\n}\n```", "```cpp\ncudnnDestroyActivationDescriptor(activation_desc);\n```", "```cpp\nif (input_ == nullptr || batch_size_ != input->n())\n{\n  input_ = input;\n  input_desc_ = input->tensor();\n  batch_size_ = input->n();\n\n  if (output_ == nullptr)\n    output_ = new Blob<float>(input->shape());\n  else\n    output_->reset(input->shape());\n\n  output_desc_ = output_->tensor();\n}\n```", "```cpp\ncudnnActivationForward(cudnnHandle, act_desc_, \n    &one, input_desc_, d_input, &zero, output_desc_, d_output);\n```", "```cpp\nif (grad_input_ != grad_output_)\n{\n  grad_output_ = grad_output;\n  grad_input_ = new Blob<float>(input_->shape());\n  grad_input_->reset(input_->shape()); \n}\n```", "```cpp\ncudnnActivationBackward(cudnnHandle, activation_desc, \n    &one, output_desc_, output_->cuda(), output_desc_, \n    d_grad_output, input_desc_, input_->cuda(),\n    &zero, input_desc_, grad_input_->cuda());\n```", "```cpp\ncudnnSoftmaxForward(cudnnHandle, CUDNN_SOFTMAX_ACCURATE, \n      CUDNN_SOFTMAX_MODE_CHANNEL,\n      &one,  input_desc,  d_input, &zero, output_desc, d_output);\n```", "```cpp\n// set grad_input_ as predict\ncudaMemcpyAsync(grad_input_->cuda(), output_->cuda(), \n                output_->buf_size(), cudaMemcpyDeviceToDevice));\n// set grad_input_ = predict - target \ncublasSaxpy(cuda_->cublas(), target->len(), &cuda_->minus_one,\n            target->cuda(), 1, grad_input_->cuda(), 1));\n```", "```cpp\nint grad_output_size = target->n() * target->c() * target->h() * target->w();\nfloat scale = 1.0f / static_cast<float>(target->n());\ncublasSscal(cuda_->cublas(), grad_output_size, &scale, grad_input_->cuda(), 1);\n```", "```cpp\n__global__ void\nsoftmax_loss_kernel(float *reduced_loss, float *predict, \n                    float *target, int size)\n{\n  int batch_idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n  extern __shared__ float s_data[];\n  float loss = 0.f;\n\n  // each thread calculate entropy for each data \n  // and accumulate to shared memory\n  if (batch_idx > 0)\n    return;\n\n  for (int c = 0; c < num_outputs; c++)\n    loss += target[batch_idx * num_outputs + c] * \\\n                logf(predict[batch_idx * num_outputs + c]);\n                workspace[batch_idx] = -loss;\n\n  // Then, we do reduction the result to calculate loss \n  // Using 1 thread block\n  if (blockIdx.x > 0) return;\n\n  // Cumulate workspace data\n  s_data[threadIdx.x] = 0.f;\n  for (int i = 0; i < batch_size; i += blockDim.x)\n    s_data[threadIdx.x] += workspace[threadIdx.x + i];\n\n  __syncthreads();\n\n  // Reduction\n  for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n  {\n    if (threadIdx.x + stride < batch_size)\n      s_data[threadIdx.x] += s_data[threadIdx.x + stride];\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0)\n    reduced_loss[blockIdx.x] = s_data[0];\n}\n```", "```cpp\nBlob<float> *Network::forward(Blob<float> *input) {\n  output_ = input;\n  for (auto layer : layers_)\n    output_ = layer->forward(output_);\n\n  return output_;\n}\n```", "```cpp\nvoid Network::backward(Blob<float> *target) {\n  Blob<float> *gradient = target;\n  // back propagation.. update weights internally.....\n  for (auto layer = layers_.rbegin(); layer != layers_.rend(); layer++) {\n    // getting back propagation status with gradient size\n    gradient = (*layer)->backward(gradient);\n  }\n}\n```", "```cpp\nvoid Network::add_layer(Layer *layer) {\n  layers_.push_back(layer);\n}\n```", "```cpp\n// step 1\\. loading dataset\nMNIST data_loader = MNIST(\"./dataset\");\n// create training dataset loader and shuffling the data\ndata_loader.train(batch_size, true);  \n\n// step 2\\. model initialization\nNetwork model;\nmodel.add_layer(new Dense(\"dense1\", 500));  // 1st layer\nmodel.add_layer(new Dense(\"dense2\", 10));   // 2nd layer\nmodel.cuda();     // set cuda context for each layer\n```", "```cpp\n// get data sample's shared buffer\nBlob<float> *train_data   = data_loader.get_data();   \n// get target's shared buffer\nBlob<float> *train_target = data_loader.get_target(); \n// load data and targets with the batch size\ndata_loader.get_batch();    \ntp_count = 0;  step = 0;\nwhile (step < num_steps)\n{\n  // transfer loaded data to the GPU\n  train_data->to(cuda);\n  train_target->to(cuda);\n\n  model.forward(train_data);    // forward\n  model.backward(train_target); // backward\n  learning_rate *= 1.f / (1.f + lr_decay * step);\n  model.update(learning_rate);  // update\n\n  step = data_loader.next(true); // load next data\n\n  ... monitoring logic ...\n}\n```", "```cpp\ntest_data_loader.test(batch_size_test);                   // create test dataset loader\nBlob<float> *test_data = test_data_loader.get_data();     // get sample data shared buffer\nBlob<float> *test_target = test_data_loader.get_target(); // get target shared buffer\ntest_data_loader.get_batch();    // load samples and targets with the batch size\ntp_count = 0; step = 0;\nwhile (step < num_steps_test) {\n  // transfer loaded data to the GPU\n  test_data->to(cuda);\n  test_target->to(cuda);\n\n  model.forward(test_data);  // forward\n  tp_count += model.get_accuracy(test_target);\n\n  step = test_data_loader.next(); // load next data\n}\nfloat accuracy = 100.f * tp_count / num_steps_test / batch_size_test;\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -lcublas -lcudnn -lnvToolsExt -o train ./train.cpp ./src/layer.cu ./src/loss.cu ./src/mnist.cpp ./src/network.cpp\n```", "```cpp\nConv2D::Conv2D(std::string name,\n        int out_channels, kernel_size, stride, padding, dilation):\n        out_channels_(out_channels), kernel_size_(kernel_size),\n        stride_(stride), padding_(padding), dilation_(dilation) {\n  name_ = name;\n  cudnnCreateFilterDescriptor(&filter_desc_);\n  cudnnCreateConvolutionDescriptor(&conv_desc_);\n  cudnnSetConvolution2dDescriptor(conv_desc_,\n    padding_, padding_, stride_, stride_, dilation_,dilation_,\n    CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT);\n}\n```", "```cpp\n// initialize weights and bias\nif (weights_ == nullptr) {\n  // initialize containers handles\n  cudnnSetFilter4dDescriptor(filter_desc_, \n    CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n    out_channels_, input->c(), kernel_size_, kernel_size_);\n\n  weights_ = new Blob<float>(out_channels_, input->c(), kernel_size_, kernel_size_);\n  biases_ = new Blob<float>(1, out_channels_); // bias size\n  bias_desc_ = biases_->tensor();\n}\n```", "```cpp\n// initilaize input and output\nif (input_ == nullptr || batch_size_ != input->n()) {\n  // initialize input\n  input_ = input;\n  input_desc_ = input->tensor();\n  batch_size_ = input->n();\n\n  // getting output tensor size\n  cudnnGetConvolution2dForwardOutputDim(\n    conv_desc_, input_desc_, filter_desc_,\n    &output_size_[0], &output_size_[1], \n    &output_size_[2], &output_size_[3]);\n\n  // initialize output blob\n  if (output_ == nullptr)\n    output_ = new Blob<float>(output_size_);\n  else\n    output_->reset(output_size_);\n  output_desc_ = output_->tensor();\n\n  // initialize weights\n  if (!freeze_)\n    init_weight_bias();\n\n  // initialize workspace for cudnn\n  set_workspace();\n}\n```", "```cpp\nConv2d::set_workspace() {\n  size_t temp_size = 0;\n\n  // fwd\n  cudnnGetConvolutionForwardAlgorithm(cuda_->cudnn(),\n    input_desc_, filter_desc_, conv_desc_, output_desc_,\n    CUDNN_CONVOLUTION_FWD_PREFER_FASTEST, 0, &conv_fwd_algo_);\n  cudnnGetConvolutionForwardWorkspaceSize(cuda_->cudnn(),\n    input_desc_, filter_desc_, conv_desc_, output_desc_, \n    conv_fwd_algo_, &temp_size);\n  workspace_size = std::max(workspace_size, temp_size);\n\n  // bwd - data\n  cudnnGetConvolutionBackwardDataAlgorithm(cuda_->cudnn(), \n    filter_desc_, output_desc_, conv_desc_, input_desc_, \n    CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST, 0, \n    &conv_bwd_data_algo_);\n  cudnnGetConvolutionBackwardDataWorkspaceSize(cuda_->cudnn(),\n    filter_desc_, output_desc_, conv_desc_, input_desc_, \n    conv_bwd_data_algo_, &temp_size);\n  workspace_size = std::max(workspace_size, temp_size);\n\n  // bwd - filter\n  cudnnGetConvolutionBackwardFilterAlgorithm(cuda_->cudnn(),\n    input_desc_, output_desc_, conv_desc_, filter_desc_,\n    CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST, 0, \n    &conv_bwd_filter_algo_);\n  cudnnGetConvolutionBackwardFilterWorkspaceSize(cuda_->cudnn(),\n    input_desc_, output_desc_, conv_desc_, filter_desc_, \n    conv_bwd_filter_algo_, &temp_size);\n  workspace_size = std::max(workspace_size, temp_size);\n\n  if (workspace_size > 0) {\n    if (d_workspace != nullptr)\n      cudaFree(d_workspace);\n    cudaMalloc((void**)&d_workspace, workspace_size);\n  }\n}\n```", "```cpp\ncudnnConvolutionForward(cuda_->cudnn(), &cuda_->one, input_desc_, input_->cuda(), \\\n    filter_desc_, weights_->cuda(), conv_desc_, conv_fwd_algo_, d_workspace, workspace_size, \\\n    &cuda_->zero, output_desc_, output_->cuda());\ncudnnAddTensor(cuda_->cudnn(), &cuda_->one, bias_desc_, biases_->cuda(), \\\n    &cuda_->one, output_desc_, output_->cuda());\n```", "```cpp\n// initialize grad_output back-propagation space\nif (grad_weights_ == nullptr) {\n  grad_output_  = grad_output;\n  grad_weights_ = new Blob<float>(weights_->shape());\n  grad_biases_  = new Blob<float>(1, biases_->c());\n  grad_input_   = new Blob<float>(input_->shape());\n}\n```", "```cpp\nBlob<float> *Conv2D::backward(Blob<float> *grad_output) {\n  ... { initialization step } ...\n\n  // gradients of biases\n  cudnnConvolutionBackwardBias(cuda_->cudnn(),\n    &cuda_->one, \n    output_desc_, grad_output->cuda(),\n    &cuda_->zero, \n    bias_desc_, grad_biases_->cuda());\n\n  // gradients of weights \n  cudnnConvolutionBackwardFilter(cuda_->cudnn(),\n    &cuda_->one, \n    input_desc_, input_->cuda(), \n    output_desc_, grad_output_->cuda(),\n    conv_desc_, conv_bwd_filter_algo_, d_workspace, workspace_size,\n    &cuda_->zero, \n    filter_desc_, grad_weights_->cuda());\n\n  // gradients of input data\n  if (!gradient_stop_)\n    cudnnConvolutionBackwardData(cuda_->cudnn(),\n      &cuda_->one, \n      filter_desc_, weights_->cuda(), \n      output_desc_, grad_output->cuda(), \n      conv_desc_, conv_bwd_data_algo_, d_workspace, workspace_size,\n      &cuda_->zero, \n      input_desc_, grad_input_->cuda());\n```", "```cpp\ncudnnCreatePoolingDescriptor(&pool_desc_);\ncudnnSetPooling2dDescriptor(pool_desc_, mode_, CUDNN_PROPAGATE_NAN,\n  kernel_size_, kernel_size_, padding_, padding_, stride_, stride_);\n```", "```cpp\nif (input_ == nullptr || batch_size_ != input->n()) {\n  input_ = input;\n\n  // resource initialize\n  input_desc_ = input_->tensor();\n  batch_size_ = input->n();\n\n  // setting output\n  cudnnGetPooling2dForwardOutputDim(pool_desc_, input_desc_, \n    &output_size_[0], &output_size_[1], &output_size_[2], \n    &output_size_[3]);\n  if (output_ == nullptr)\n    output_ = new Blob<float>(output_size_);\n  else\n    output_->reset(output_size_);\n\n  output_desc_ = output_->tensor();\n}\n```", "```cpp\nBlob<float> *Pooling::forward(Blob<float> *input) {\n  ... { initialization step } ...\n\n  cudnnPoolingForward(cudnnHandle, pool_desc_, &one, \n    input_desc_, input_->cuda(),\n    &zero, output_desc_, output_->cuda());\n}\n```", "```cpp\nBlob<float> *Pooling::backward(Blob<float> *grad_output) {\n  if (grad_input_ == nullptr)\n    grad_input_ = new Blob<float>(input_->shape());\n\n  cudnnPoolingBackward(cudnnHandle, pool_desc_,\n    &one, output_desc_, output_->cuda(), \n    output_desc_, grad_output->cuda(), \n    input_desc_, input_->cuda(), \n    &zero, input_desc_, grad_input_->cuda());\n}\n```", "```cpp\nNetwork model;\nmodel.add_layer(new Conv2D(\"conv1\", 20, 5));\nmodel.add_layer(new Pooling(\"pool\", 2, 0, 2, CUDNN_POOLING_MAX));\nmodel.add_layer(new Conv2D(\"conv2\", 50, 5));\nmodel.add_layer(new Pooling(\"pool\", 2, 0, 2, CUDNN_POOLING_MAX));\nmodel.add_layer(new Dense(\"dense1\", 500));\nmodel.add_layer(new Activation(\"relu\", CUDNN_ACTIVATION_RELU));\nmodel.add_layer(new Dense(\"dense2\", 10));\nmodel.add_layer(new Softmax(\"softmax\"));\nmodel.cuda();\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -lcublas -lcudnn -lnvToolsExt -o train ./train.cpp ./src/layer.cu ./src/loss.cu ./src/mnist.cpp ./src/network.cpp\n```", "```cpp\ncudnnSetConvolutionMathType(cudnnConvDesc, CUDNN_TENSOR_OP_MATH);\n```", "```cpp\nint mode = 2; // LSTM in CUDNN\nint seq_length = 512;\nint num_layers = 4;\nint hidden_size = 512;\nint input_size = hidden_size;\nint batch_size = 32;\nfloat dropout_rate = 0;\nbool bidirectional = 0;\nint persistent = 0;\n```", "```cpp\n// hx, cx, hy, cy, dhy, dcy, dhx, and dcs can be null.\nvoid *x;            // input\nvoid *hx = nullptr; // input of initial hidden state\nvoid *cx = nullptr; // input of cell state (LSTM)\n\nvoid *y;            // output\nvoid *hy = nullptr; // output of final hidden state\nvoid *cy = nullptr; // output of final cell state (LSTM)\n\nvoid *dy;            // input of gradient \nvoid *dhy = nullptr; // input of final hidden state\nvoid *dcy = nullptr; // input of final cell state (LSTM)\n\nvoid *dx;            // output of gradient at the input of rnn\nvoid *dhx = nullptr; // output of gradient at the initial hidden state\nvoid *dcx = nullptr; // output of gradient at the initial cell state\n```", "```cpp\nint input_length = seq_length * input_size * batch_size;\nint output_length = seq_length * hidden_size * batch_size;\nint hidden_length = hidden_size * batch_size * num_layers;\n```", "```cpp\ncudnnTensorDescriptor_t x_desc[seq_length], y_desc[seq_length], \\\n                        dx_desc[seq_length], dy_desc[seq_length];\ncudnnTensorDescriptor_t hx_desc, cx_desc;\ncudnnTensorDescriptor_t dhx_desc, dcx_desc;\ncudnnTensorDescriptor_t hy_desc, cy_desc;\ncudnnTensorDescriptor_t dhy_desc, dcy_desc;\n```", "```cpp\nvoid *workspace;\ncudnnFilterDescriptor_t w_desc, dw_desc;\ncudnnSetRNNDescriptor_v6(cudnnHandle, rnn_desc,\n                         hidden_size, num_layers, dropout_desc, CUDNN_LINEAR_INPUT,\n                         bidirectional ? CUDNN_BIDIRECTIONAL : CUDNN_UNIDIRECTIONAL,\n                         CUDNN_LSTM, CUDNN_RNN_ALGO_STANDARD, CUDNN_DATA_FLOAT));\nsize_t weight_size;\ncudnnGetRNNParamsSize(cudnnHandle, rnn_desc, x_desc[0], &weight_size, CUDNN_DATA_FLOAT);\ncudaMalloc((void**)&workspace, weight_size);\n```", "```cpp\ndimW = {weight_size / sizeof(float), 1, 1}\ncudnnCreateFilterDescriptor(&w_desc);\ncudnnCreateFilterDescriptor(&dw_desc);\ncudnnSetFilterNdDescriptor(w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 3, dimW);\ncudnnSetFilterNdDescriptor(dw_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 3, dimW);\ncudnnRNNForwardTraining(cudnnHandle, rnn_desc, seq_length,\n                x_desc, x, hx_desc, hx, cx_desc, cx,\n                w_desc, w, \n                y_desc, y, hy_desc, hy, cy_desc, cy,\n                workspace, workspace_size, reserved_space, \n                reserved_size);\n```", "```cpp\nfor (int layer = 0; layer < num_layers; layer++) {\n  for (int linear_layer = 0; linear_layer < 4; linear_layer++) {\n    for (int sequence = 0; sequence < seq_length; sequence++) {\n      cublasSgemm(cublas_handle, CUBLAS_OP_T, CUBLAS_OP_N,\n      hidden_size, input_size, batch_size,\n      &alpha, input_weight, input_size, x, input_size,\n      &beta, h, hidden_size);\n      cublasSgemm(cublas_handle, CUBLAS_OP_T, CUBLAS_OP_N,\n      hidden_size, hidden_size, batch_size,\n      &alpha, recurrent_weight, hidden_size,\n      h, hidden_size,\n      &beta, y, hidden_size);\n    }\n  }\n}\n```", "```cpp\nfor (int step = 1; step <= 8; step++)\n{\n batch_size = 32 * step;\n printf(\"Batch Size: %3d\\n\", batch_size);\n rnn_operation(seq_length, num_layers, hidden_size, input_size,   \n   batch_size, dropout_rate, bidirectional, mode, persistent);\n cublas_operation(mode, 2ull, input_size, hidden_size, seq_length, batch_size, num_layers);\n}\n```", "```cpp\n$ nvcc -run -m64 -std=c++11 -I/usr/local/cuda/samples/common/inc -gencode arch=compute_70,code=sm_70 -lcublas -lcudnn -lcurand -o rnn ./rnn.cpp\n```", "```cpp\n#/bin/bash\n\nCODE_PATH=\"RN50v1.5\"\nDATASET_PATH=\"/raid/datasets/imagenet/raw-data/\"\nOUTPUT_NAME=\"resnet50_pyt\"\n\n# default profile\ndocker run --rm -ti --runtime=nvidia \\\n    -v $(pwd)/${CODE_PATH}:/workspace \\\n    -v ${DATASET_PATH}:/imagenet \\\n    nvcr.io/nvidia/pytorch:19.08-py3 \\\n       nsys profile -t cuda,nvtx,cudnn,cublas -o ${OUTPUT_NAME} \n         -f true -w true -y 60 -d 20 \\\n       python /workspace/main.py --arch resnet50 -b 64 \n         --fp16 /imagenet\n```", "```cpp\n$ pip install nvtx-plugins-tf\n```", "```cpp\nimport nvtx.plugins.tf as nvtx_tf\nENABLE_NVTX=true\n@nvtx_tf.ops.trace(message='Dense Block', domain_name='Forward',\n        grad_domain_name='Gradient', enabled=ENABLE_NVTX, \n        trainable=True)\ndef dense_layer(x):\n    x = tf.layers.dense(x, 1000, activation=tf.nn.relu, name='dense_1')\n    x = tf.layers.dense(x, 1000, activation=tf.nn.relu, name='dense_2\u2019) \nreturn x\n```", "```cpp\nimport nvtx.plugins.tf as nvtx_tf\nENABLE_NVTX=true\nx, nvtx_context = nvtx_tf.ops.start(x, message='Dense Block', \\ \n        domain_name='Forward\u2019, grad_domain_name='Gradient\u2019, \n        enabled=ENABLE_NVTX, trainable=True)\nx = tf.layers.dense(x, 1000, activation=tf.nn.relu, name='dense_1')\nx = tf.layers.dense(x, 1000, activation=tf.nn.relu, name='dense_2\u2019) \nx = nvtx_tf.ops.end(x, nvtx_context)\n```", "```cpp\nfrom nvtx.plugins.tf.estimator import NVTXHook\n\nnvtx_callback = NVTXHook(skip_n_steps=1, name='Train\u2019)\ntraining_hooks=[]\ntraining_hooks.append(nvtx_callback)\n```", "```cpp\nwith tf.train.MonitoredSession(hooks=training_hooks) as sess:\n```", "```cpp\ntf.estimator.Estimator(hooks=training_hooks, ...)\n```", "```cpp\n#/bin/bash\n\nCODE_PATH=\"RN50v1.5\"\nDATASET_PATH=\"/raid/datasets/imagenet/tfrecord\"\nOUTPUT_NAME=\"resnet50_tf\"\n\n# default profile\ndocker run --rm -ti --runtime=nvidia \\\n    -v $(pwd):/result \\\n    -v $(pwd)/${CODE_PATH}:/workspace \\\n    -v ${DATASET_PATH}:/imagenet \\\n    nvcr.io/nvidia/tensorflow:19.08-py3 \\\n        nsys profile -t cuda,nvtx,cudnn,cublas -o ${OUTPUT_NAME} \n                     -f true -w true -y 40 -d 20 \\\n            python /workspace/main.py --mode=training_benchmark \n                                      --warmup_steps 200 \\\n                --num_iter 500 --iter_unit batch \n                --results_dir=results --batch_size 64\n```"]