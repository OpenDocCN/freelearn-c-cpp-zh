- en: '*Chapter 2*: Performance Measurements'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章：性能测量
- en: 'Whether writing a new high-performance program or optimizing an existing one,
    one of the first tasks set before you will be to define the performance of the
    code in its current state. Your success will be measured by how much you can improve
    its performance. Both of these statements imply the existence of a performance
    metric, something that can be measured and quantified. One of the more interesting
    outcomes of the last chapter was the discovery that there isn''t even a single
    definition of performance that fits every need: what you measure when you want
    to quantify performance depends on the nature of the problem you''re working on.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是编写新的高性能程序还是优化现有程序，您面临的第一个任务之一将是定义代码在当前状态下的性能。您的成功将取决于您能够提高其性能的程度。这两种陈述都意味着性能指标的存在，即可以进行测量和量化的东西。上一章最有趣的结果之一是发现甚至没有一个适用于所有需求的性能定义：在您想要量化性能时，您所测量的内容取决于您正在处理的问题的性质。
- en: But there is much more to the measurements than simply defining the goals and
    confirming success. Every step of your performance optimization, whether of existing
    code or new code you're just writing, should be guided and informed by measurements.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但测量远不止于简单地定义目标和确认成功。您性能优化的每一步，无论是现有代码还是您刚刚编写的新代码，都应该受到测量的指导和启发。
- en: 'The first rule of performance is *Never guess about performance*, and it is
    worth dedicating the first section of this chapter to the goal of convincing you
    to take this rule to heart without questions or doubts. After shattering your
    faith in your intuition, we have to give you something else to stand on instead:
    the tools and approaches for measuring and learning about performance.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 性能的第一条规则是*永远不要猜测性能*，并且值得在本章的第一部分致力于说服您牢记这条规则，不容置疑。在摧毁您对直觉的信任之后，我们必须给您提供其他东西来依靠：用于测量和了解性能的工具和方法。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Why performance measurements are essential
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么性能测量是必不可少的
- en: Why all performance-related decisions must be driven by measurements and data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么所有与性能相关的决策都必须由测量和数据驱动
- en: How to measure the performance of real programs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何测量真实程序的性能
- en: What is benchmarking, profiling, and micro-benchmarking of programs, and how
    to use them to measure performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是程序的基准测试、分析和微基准测试，以及如何使用它们来测量性能
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: First of all, you will need a C++ compiler. All examples in this chapter were
    compiled on a Linux system using GCC or Clang compilers. All major Linux distributions
    have GCC as a part of their regular install; newer versions may be available in
    the distribution's repositories. The Clang compiler is available through the LLVM
    project, [http://llvm.org/](http://llvm.org/), although several Linux distributions
    also maintain their own repositories. On Windows, Microsoft Visual Studio is the
    most common compiler, but both GCC and Clang are available as well.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您将需要一个C++编译器。本章中的所有示例都是在Linux系统上使用GCC或Clang编译器编译的。所有主要的Linux发行版都将GCC作为常规安装的一部分；更新版本可能可以在发行版的存储库中找到。Clang编译器可以通过LLVM项目[http://llvm.org/](http://llvm.org/)获得，尽管一些Linux发行版也维护自己的存储库。在Windows上，Microsoft
    Visual Studio是最常见的编译器，但GCC和Clang也可用。
- en: 'Second, you will need a program profiling tool. In this chapter, we will use
    the Linux "perf" profiler. Again, it comes installed (or is available for installation)
    on most Linux distributions. The documentation can be found here: [https://perf.wiki.kernel.org/index.php/Main_Page](https://perf.wiki.kernel.org/index.php/Main_Page).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，您将需要一个程序分析工具。在本章中，我们将使用Linux的"perf"分析器。同样，它已经安装（或可供安装）在大多数Linux发行版上。文档可以在[https://perf.wiki.kernel.org/index.php/Main_Page](https://perf.wiki.kernel.org/index.php/Main_Page)找到。
- en: 'We will also demonstrate the use of another profiler, the CPU profiler from
    the set of Google Performance tools (GperfTools) found here: [https://github.com/gperftools/gperftools](https://github.com/gperftools/gperftools)
    (again, your Linux distribution may have it available for installation through
    its repositories).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将演示另一个分析器的使用，即来自Google性能工具集（GperfTools）的CPU分析器，可以在[https://github.com/gperftools/gperftools](https://github.com/gperftools/gperftools)找到（同样，您的Linux发行版可能可以通过其存储库进行安装）。
- en: There are many other profiling tools available, both free and commercial. They
    all present fundamentally the same information, but in different ways and with
    many different analysis options. By following the examples in this chapter, you
    can learn what to expect of the profiling tool and what are the possible limitations;
    the specifics of each tool you use will have to be mastered on your own.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他可用的性能分析工具，包括免费和商业工具。它们都基本上提供相同的信息，但以不同的方式呈现，并具有许多不同的分析选项。通过本章的示例，您可以了解性能分析工具的预期和可能的限制；您使用的每个工具的具体情况都需要自己掌握。
- en: 'Finally, we will use a micro-benchmarking tool. In this chapter, we use the
    Google Benchmark library found at [https://github.com/google/benchmark](https://github.com/google/benchmark).
    You will, most likely, have to download and install it yourself: even if it comes
    installed with your Linux distribution, it is likely to be outdated. Follow the
    installation instructions on the web page.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用一个微基准测试工具。在本章中，我们使用了在[https://github.com/google/benchmark](https://github.com/google/benchmark)找到的Google
    Benchmark库。您很可能需要自己下载和安装它：即使它已经与您的Linux发行版一起安装，也可能已经过时。请按照网页上的安装说明进行操作。
- en: With all the necessary tools installed, we are ready to do our first experiment
    in performance measurements.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了所有必要的工具后，我们准备进行我们的第一个性能测量实验。
- en: 'The code for the chapter can be found here: [https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter02](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter02)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在此处找到：[https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter02](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs/tree/master/Chapter02)
- en: Performance measurements by example
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过示例进行性能测量
- en: We will have time to learn about each of the performance analysis tools in more
    detail in the rest of this chapter, but in this section, we will do a quick end-to-end
    example and analyze the performance of a simple program. This will show you what
    the typical performance analysis flow looks like and how different tools are used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将有时间更详细地了解每个性能分析工具，但在本节中，我们将进行一个快速的端到端示例，并分析一个简单程序的性能。这将向您展示典型的性能分析流程是什么样子，以及如何使用不同的工具。
- en: 'There is also a hidden agenda: by the end of this section, you will come to
    believe that you should never guess about performance.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个隐藏的目的：在本节结束时，您将相信您不应该猜测性能。
- en: 'Any real-world program that you may have to analyze and optimize is likely
    to be large enough to take many pages in this book, so we will use a simplified
    example. This program sorts substrings in a very long string: suppose we have
    a string `S`, such as `"abcdcba"` (this is not so long; our actual strings will
    have millions of characters). We can have a substring starting from any character
    in this string, for example, the substring `S0` starts with the offset 0 and,
    therefore, has the value `"abcdcba"`. The substring `S2` starts with offset 2
    and has the value `"cdcba"`, and the substring `S5` has the value `"ba"`. If we
    were to sort these substrings in decreasing order using the regular string comparison,
    the order of the substrings would be `S2`, then `S5`, then `S0` (in order of the
    first characters, `''c''`, `''b''`, and `''a''`, respectively).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要分析和优化的任何真实程序可能足够大，以至于在本书中需要很多页，因此我们将使用一个简化的例子。这个程序对一个非常长的字符串中的子字符串进行排序：假设我们有一个字符串`S`，比如`"abcdcba"`（这并不算很长；我们实际的字符串将有数百万个字符）。我们可以从这个字符串的任何字符开始得到一个子字符串，例如，子字符串`S0`从偏移0开始，因此其值为`"abcdcba"`。子字符串`S2`从偏移2开始，其值为`"cdcba"`，而子字符串`S5`的值为`"ba"`。如果我们使用常规的字符串比较对这些子字符串按降序排序，子字符串的顺序将是`S2`，然后是`S5`，最后是`S0`（按照第一个字符`'c'`，`'b'`和`'a'`的顺序）。
- en: 'We can use the STL sort algorithm, `std::sort`, to sort the substrings if we
    represent them with a character pointer: swapping two substrings now involves
    just swapping the pointers while the underlying string remains unchanged. Here
    is our example program:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用STL排序算法`std::sort`对子字符串进行排序，如果我们用字符指针表示它们：现在交换两个子字符串只涉及交换指针，而基础字符串保持不变。以下是我们的示例程序：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that, in order for this example to compile, we need to include the appropriate
    header files and write the `using` declarations for the names we shorten:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了使此示例编译，我们需要包含适当的头文件，并为我们缩短的名称编写`using`声明。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the subsequent examples, we will omit the common header files and the `using`
    declarations for common names such as `cout` or `vector`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的示例中，我们将省略常见的头文件和对常见名称（如`cout`或`vector`）的`using`声明。
- en: 'The example defines a string that is used as the underlying data for the substrings
    to be sorted and for the vector of substrings (character pointers), but we have
    not yet shown how the data itself is created. Then, the substrings are sorted
    using `std::sort` with a custom comparison function: a lambda expression that
    calls the comparison function itself, `compare()`. We use the lambda expression
    to adapt the interface of the `compare()` function, which takes two pointers and
    the maximum string length, to the interface expected by `std::sort` (just two
    pointers). This is known as the Adapter Pattern.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例定义了一个字符串，用作要排序的子字符串的基础数据，以及子字符串的向量（字符指针），但我们还没有展示数据本身是如何创建的。然后，使用带有自定义比较函数的`std::sort`对子字符串进行排序：一个lambda表达式调用比较函数本身`compare()`。我们使用lambda表达式来适应`compare()`函数的接口，该函数接受两个指针和最大字符串长度，以符合`std::sort`期望的接口（只有两个指针）。这被称为适配器模式。
- en: 'In our case, the lambda expression has the second role: in addition to calling
    the comparison function, it also counts the number of comparison calls. Since
    we are interested in the performance of the sort, this information may be useful
    if we want to compare different sorting algorithms (we are not going to do this
    now, but this is a technique you may find useful in your own performance optimization
    efforts).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，lambda表达式有第二个作用：除了调用比较函数外，它还计算比较调用的次数。由于我们对排序的性能感兴趣，如果我们想比较不同的排序算法，这些信息可能会有用（我们现在不打算这样做，但这是一种技术，您可能会在自己的性能优化工作中发现有用）。
- en: 'The comparison function itself is only declared in this example, but not defined.
    Its definition is in a separate file and reads as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，比较函数本身只是声明了，但没有定义。它的定义在一个单独的文件中，内容如下：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It is a straightforward comparison of two strings: it returns true if the first
    string is greater than the second one and false otherwise. We could have just
    as easily defined the function in the same file as the code itself and avoided
    the need for the extra file, but even with this small example, we are trying to
    reproduce the behavior of a real-world program that will likely call many functions
    scattered across many different files. Therefore, we have the comparison function
    in its own file, which we call `compare.C` in this chapter, and the rest of the
    example is in one file, `example.C`.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是两个字符串的直接比较：如果第一个字符串大于第二个字符串，则返回true，否则返回false。我们可以很容易地在与代码本身相同的文件中定义函数，并避免额外文件的需要，但即使在这个小例子中，我们也试图复制一个可能调用许多函数的真实程序的行为，这些函数分散在许多不同的文件中。因此，我们将比较函数放在自己的文件中，在本章中我们称之为`compare.C`，而示例的其余部分在一个文件中，名为`example.C`。
- en: Lastly, we use the C++ high-resolution timers from the `chrono` library to measure
    how long it took to sort the substrings.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`chrono`库中的C++高分辨率计时器来测量排序子字符串所需的时间。
- en: The only thing that is missing in our example is the actual data for the string.
    The substring sort is a fairly common task in many real applications, and each
    has its own way of acquiring the data. In our artificial example, the data will
    have to be equally artificial. We can, for example, generate a random string.
    On the other hand, in many practical applications of substring sort, there is
    one character that occurs in the string much more often than any other.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例中唯一缺少的是字符串的实际数据。子字符串排序在许多实际应用程序中是一个相当常见的任务，每个应用程序都有自己获取数据的方式。在我们的人工示例中，数据将不得不同样人工。例如，我们可以生成一个随机字符串。另一方面，在许多实际应用程序中，子字符串排序中有一个字符出现的频率比其他任何字符都要高。
- en: 'We can simulate this type of data as well by filling the string with a single
    character and then randomly changing a few of them:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以模拟这种类型的数据，方法是用一个字符填充字符串，然后随机更改其中的一些字符：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The size of the string `L` and the number of substrings `N` are chosen to have
    reasonable run times on the machine that was used to run these tests (if you want
    to repeat the examples, you may have to adjust the numbers up or down depending
    on the speed of your processor).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串`L`的大小和子字符串`N`的数量被选择为在用于运行这些测试的计算机上具有合理的运行时间（如果你想重复这些示例，你可能需要根据你的处理器的速度调整数字）。
- en: 'Now our example is ready to be compiled and executed:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的示例已经准备好编译和执行了：
- en: '![Figure 2.1'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.1'
- en: '](img/Figure_2.1_B16229.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.1_B16229.jpg)'
- en: Figure 2.1
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1
- en: The results you will get depend on the compiler you use, the computer you run
    on, and, of course, on the data corpus.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你得到的结果取决于你使用的编译器、运行的计算机，当然还取决于数据语料库。
- en: Now that we have our first performance measurement, the first question you may
    ask is, how do we optimize it? This is not the first question you should be asking,
    though. The real first question should be, *do we need to optimize?* To answer
    that, you need to have the targets and goals for performance, as well as the data
    on the relative performance of the other parts of this program; for example, if
    the actual string is generated from a simulation that takes ten hours, the one
    hundred seconds it takes to sort it is hardly worth noticing. Of course, we are
    still dealing with the artificial example, and we won't get very far in this chapter
    unless we assume that, yes, we have to improve performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了第一个性能测量，你可能会问的第一个问题是，我们该如何优化它？然而，这并不是你应该问的第一个问题。真正的第一个问题应该是，“我们需要优化吗？”要回答这个问题，你需要有性能的目标和目标，以及关于程序其他部分相对性能的数据；例如，如果实际字符串是从需要十个小时的模拟生成的，那么排序它需要的一百秒几乎不值得注意。当然，我们仍然在处理人工示例，除非我们假设是的，否则在本章中我们不会有太大进展，我们必须改善性能。
- en: 'Now, are we ready to talk about how to optimize it? Again, not so fast: the
    question now should be, **what do we optimize?** Or, more generally, where does
    the program spend the most time? Even in this simple example, it could be the
    sort itself or the comparison function. We do not have access to the source code
    of the sort (unless we want to hack the standard library, anyway), but we could
    insert the timer calls into the comparison function.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好讨论如何优化了吗？再次，不要那么着急：现在应该问的问题是，“我们要优化什么？”或者更一般地说，程序花费最多时间的地方是哪里？即使在这个简单的示例中，可能是排序本身或比较函数。我们无法访问排序的源代码（除非我们想要黑掉标准库），但我们可以在比较函数中插入计时器调用。
- en: 'Unfortunately, this is unlikely to yield good results: each comparison is pretty
    fast, timer calls themselves take time, and calling the timer every time the function
    is called will significantly change the very results we''re trying to measure.
    In a real-world program, such instrumentation with timers is often not practical
    anyway. You would have to insert timers into hundreds of functions if you didn''t
    know where the time is spent (and how would you know that without any measurements?).
    This is where the profiler tools come in.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这不太可能产生良好的结果：每次比较都非常快，计时器调用本身需要时间，每次调用函数时调用计时器将显著改变我们试图测量的结果。在现实世界的程序中，使用计时器进行这样的仪器测量通常也不切实际。如果你不知道时间花在哪里（没有任何测量，你怎么知道呢？），你将不得不在数百个函数中插入计时器。这就是性能分析工具发挥作用的地方。
- en: 'We will learn much more about the profiler tools in the next section. For now,
    suffice it to say that the following command line will compile and execute the
    program and collect its runtime profile using the Google profiler from the GperfTools
    package:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中更多地了解性能分析工具。现在，可以说以下命令行将编译和执行程序，并使用GperfTools包中的Google分析器收集其运行时配置文件：
- en: '![Figure 2.2'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2'
- en: '](img/Figure_2.2_B16229.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.2_B16229.jpg)'
- en: Figure 2.2
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2
- en: The profile data is collected in the file `prof.data`, as given by the `CPUPROFILE`
    environment variable. You may have noticed that the program took longer to run
    this time. This is an almost unavoidable side effect of performance profiling.
    We will come back to it in the next section. The relative performance of the different
    parts of the program should still be correct, assuming the profiler itself is
    working correctly.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件数据存储在文件`prof.data`中，由`CPUPROFILE`环境变量给出。你可能已经注意到，这次程序运行时间更长了。这几乎是性能分析的一个不可避免的副作用。我们将在下一节回到这个问题。假设性能分析工具本身正常工作，程序的不同部分的相对性能应该仍然是正确的。
- en: 'The last line of the output tells us that the profiler has collected some data
    for us, now we need to display it in a readable format. For the data collected
    by the Google profiler, the user interface tool is `google-pprof` (often installed
    as simply `pprof`), and the simplest invocation of it just lists every function
    in the program, along with the fraction of the time spent in that function (the
    second column):'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的最后一行告诉我们，分析器已经为我们收集了一些数据，现在我们需要以可读的格式显示它。对于Google分析器收集的数据，用户界面工具是`google-pprof`（通常安装为`pprof`），最简单的调用方式只是列出程序中的每个函数，以及在该函数中花费的时间的比例（第二列）：
- en: '![Figure 2.3'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.3'
- en: '](img/Figure_2.3_B16229.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.3_B16229.jpg)'
- en: Figure 2.3
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3
- en: The profiler shows that almost all the time is spent in the comparison function
    `compare()` and that the sort hardly takes any time at all (the second line is
    one of the functions called by `std::sort` and should be considered a part of
    the time spent in the sort but outside of the comparison). Note that for any practical
    profiling, we would need more than the 50 samples collected here. The number of
    samples depends on how long the program runs, and, to get reliable data, you need
    to accumulate at least a few dozen samples in every function you want to measure.
    In our case, the result is so glaringly obvious that we can proceed with just
    the samples we collected.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器显示几乎所有的时间都花在了比较函数`compare()`上，而排序几乎没有花费任何时间（第二行是`std::sort`调用的函数之一，应该被视为在排序中花费的时间的一部分，但不包括在比较中）。请注意，对于任何实际的分析，我们需要收集更多的样本，这取决于程序运行的时间，为了获得可靠的数据，您需要在每个要测量的函数中积累至少几十个样本。在我们的情况下，结果是如此明显，我们可以继续使用我们收集的样本。
- en: 'Since the substring comparison function takes 98% of the total run time, we
    have only two ways to improve the performance: we can make this function faster,
    or we can call it fewer times (many people forget the second possibility and go
    straight for the first one). The second approach would require the use of a different
    sort algorithm and is, therefore, outside of the scope of this book. Here we will
    focus on the first option. Let us again review the code for the comparison function:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于子字符串比较函数占总运行时间的98%，我们只有两种方法可以提高性能：我们可以使这个函数更快，或者我们可以减少调用它的次数（许多人忘记了第二种可能性，直接选择第一种）。第二种方法需要使用不同的排序算法，因此超出了本书的范围。在这里，我们将专注于第一种选择。让我们再次审查一下比较函数的代码：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is just a few lines of code, and we should be able to understand and predict
    everything about its behavior. There is the check for comparing a substring to
    itself, which is definitely faster than actually doing the comparison character
    by character, so, unless we are sure that the function is never called with identical
    values for both pointers, this line stays.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是几行代码，我们应该能够理解和预测它的行为。这里有一个检查，用于比较子字符串是否相同，这肯定比逐个字符进行比较要快，因此，除非我们确定该函数从不使用相同的指针值调用，否则这一行保留。
- en: 'Then there is a loop (the body of the loop is comparing the characters one
    at a time), which we have to do because we do not know which character might be
    different. The loop itself runs until we find a difference or until we compare
    the maximum possible number of characters. It is easy to see that the latter condition
    cannot possibly happen: the string is null-terminated, so, even if all characters
    in both substrings are the same, sooner or later we will reach the end of the
    shorter substring, compare the null character at its end with a non-null character
    in the other substring, and the shorter substring will be considered the lesser
    of the two.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是一个循环（循环体逐个比较字符），我们必须这样做是因为我们不知道哪个字符可能不同。循环本身运行直到我们找到一个不同之处，或者直到我们比较了最大可能数量的字符。很容易看出后一种情况不可能发生：字符串以空字符结尾，因此，即使两个子字符串中的所有字符都相同，迟早我们会到达较短子字符串的末尾，将其末尾的空字符与另一个子字符串中的非空字符进行比较，较短的子字符串将被认为是两者中较小的。
- en: 'The only case where we could potentially read past the end of the string is
    when both substrings start at the same location, but we check for that at the
    very beginning of the function. This is great: we have found some unnecessary
    work that we were doing, so we can optimize the code and get rid of one comparison
    operation per loop iteration. Considering that there aren''t many other operations
    in the loop body, this ought to be significant.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一可能读取字符串末尾之外的情况是当两个子字符串从同一位置开始，但我们在函数的开头就检查了这一点。这很好：我们发现了一些不必要的工作，因此我们可以优化代码，摆脱每次循环迭代中的一个比较操作。考虑到循环体中没有太多其他操作，这应该是显著的。
- en: 'The change in the code is simple enough: we can just remove the comparison
    (we also do not need to pass the length into the comparison function anymore):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的改变很简单：我们可以只删除比较（我们也不再需要将长度传递给比较函数）：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fewer parameters, fewer operations, less code all around. Let''s run the program
    and see how much run time this optimization saved us:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更少的参数，更少的操作，代码量也更少。让我们运行程序，看看这种优化节省了我们多少运行时间：
- en: '![Figure 2.4'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.4'
- en: '](img/Figure_2.4_B16229.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.4_B16229.jpg)'
- en: Figure 2.4
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4
- en: To say that this didn't go according to plan would be a major understatement.
    The original code took 98 milliseconds to solve the same problem (*Figure 2.1*).
    The "optimized" code takes 210 milliseconds, despite doing less work (note that
    not all compilers exhibit this particular performance anomaly on this example,
    but we're using a real production compiler; there is no trickery here, this could
    happen to you too).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 说这并不是按计划进行的将是一个严重的低估。原始代码花了98毫秒来解决同样的问题（*图2.1*）。尽管“优化”代码做的工作更少，但花了210毫秒（请注意，并非所有编译器在这个例子上都表现出这种性能异常，但我们使用的是真正的生产编译器；这里没有任何诡计，这也可能发生在你身上）。
- en: 'To wrap up this example, which is actually a much-condensed example from a
    real-life program, I will tell you that while we were trying to optimize this
    fragment of code, another programmer was working in a different part of the code
    and also needed a substring comparison function. When the separately developed
    pieces of code were put together, only one version of this function was kept,
    and it happens to be the one we did not write; the other programmer wrote almost
    the same code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个例子，实际上是一个大大简化的真实程序的例子，我要告诉您，当我们试图优化代码片段时，另一位程序员正在代码的另一个部分工作，也需要一个子字符串比较函数。当分别开发的代码片段放在一起时，只保留了这个函数的一个版本，而这恰好是我们没有编写的版本；另一位程序员几乎写了完全相同的代码：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Examine this code fragment and the one right before it and see if you can spot
    the difference.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 检查这段代码片段和前面的代码片段，看看你能否发现其中的区别。
- en: 'The only difference is the type of the loop variable: earlier, we used `unsigned
    int`, and we were not wrong: the index starts from 0 and advances; we do not expect
    any negative numbers. The last code fragment uses `int`, unnecessarily giving
    up half of the range of the possible index values.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是循环变量的类型：之前，我们使用了`unsigned int`，这并没有错：索引从0开始并递增；我们不期望出现任何负数。最后的代码片段使用了`int`，不必要地放弃了可能的索引值范围的一半。
- en: 'After this code consolidation, we can run our benchmark again, this time with
    the new comparison function. The result is, again, unexpected:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次代码整合之后，我们可以再次运行我们的基准测试，这次使用新的比较函数。结果又是意想不到的：
- en: '![Figure 2.5'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.5'
- en: '](img/Figure_2.5_B16229.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.5_B16229.jpg)'
- en: Figure 2.5
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5
- en: The latest version takes 74 milliseconds, faster than our original version (98
    milliseconds, Fig 2.1) and much faster than the almost identical second version
    (210 milliseconds, Fig 2.2).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最新版本花费了74毫秒，比我们原始版本快（98毫秒，图2.1），比几乎相同的第二个版本快得多（210毫秒，图2.2）。
- en: 'For the explanation of this particular mystery, you will have to wait until
    the next chapter. The goal of this section was to convince you to never guess
    about performance: the "obvious" optimization – doing the exact same computation
    with less code – backfired spectacularly, and the trivial change that should not
    have mattered at all – using signed integers instead of unsigned in a function
    where all values are non-negative anyway – turned out to be an effective optimization.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个特定的谜团的解释，您将不得不等到下一章。本节的目标是说服您永远不要猜测性能：所谓的“显而易见”的优化——用更少的代码进行完全相同的计算——出乎意料地失败了，而本来根本不应该有任何影响的微不足道的改变——在一个所有值都是非负的函数中使用有符号整数而不是无符号整数——竟然成为了一种有效的优化。
- en: If the performance results can be so counter-intuitive even in this very simple
    example, then the only way to make good decisions about performance has to be
    the measurement-driven approach. In the rest of this chapter, we will see some
    of the most common tools used to collect performance measurements, learn how to
    use them, and how to interpret their results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果性能结果在这个非常简单的例子中都如此反直觉，那么做出关于性能的良好决策的唯一方法必须是基于测量的方法。在本章的其余部分，我们将看到一些用于收集性能测量的最常用工具，学习如何使用它们以及如何解释它们的结果。
- en: Performance benchmarking
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能基准测试
- en: 'The easiest way to collect information about the performance of a program is
    to run it and measure how long it takes. Of course, we need more data than that
    to make any useful optimizations: it would be nice to know which parts of the
    program make it take that long, so we don''t waste our own time optimizing the
    code that may be very inefficient but also takes very little time and thus does
    not contribute to the bottom line.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 程序收集性能信息的最简单方法是运行它并测量所需的时间。当然，我们需要比这更多的数据才能进行任何有用的优化：知道程序的哪些部分使其花费那么长时间会很好，这样我们就不会浪费时间优化可能非常低效但花费时间很少且对最终结果没有贡献的代码。
- en: 'We already saw a simple example of that when we added a timer to our sample
    program: now we know how long the sort itself takes. That is, in a nutshell, the
    whole idea of benchmarking. The rest is elbow grease, instrumenting the code with
    timers, collecting the information, and reporting it in a useful format. Let us
    see what tools we have for that, starting with the timers provided by the language
    itself.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在添加计时器到示例程序时已经看到了一个简单的例子：现在我们知道排序本身需要多长时间。简而言之，这就是基准测试的整个理念。其余的工作是费力的，用计时器对代码进行仪器化，收集信息，并以有用的格式报告。让我们看看我们有哪些工具，从语言本身提供的计时器开始。
- en: C++ chrono timers
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++ chrono计时器
- en: 'C++ has some facilities that can be used to collect timing information in its
    chrono library. You can measure the time that elapsed between any two points in
    the program:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: C++有一些设施可以用于收集时间信息，它们在其chrono库中。您可以测量程序中任意两点之间经过的时间：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We should point out that the C++ chrono clocks measure real time (often called
    wall-clock time). Usually, this is what you want to measure. However, a more detailed
    analysis often requires measuring the CPU time, which is the time that is passing
    only when the CPU is working and stands still when the CPU is idle. In a single-threaded
    program, the CPU time cannot be greater than the real time; if the program is
    compute-intensive, the two times are ideally the same, this means that the CPU
    was fully loaded. On the other hand, a user interface program spends most of the
    time waiting for the user and idling the CPU; here, we want the CPU time to be
    as low as possible: it is a sign that the program is efficient and uses as few
    CPU resources as possible to service the user''s requests. For that, we have to
    go beyond what is available in C++17.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该指出，C++ chrono时钟测量实际时间（通常称为挂钟时间）。通常，这是您想要测量的。但是，更详细的分析通常需要测量CPU时间，这是CPU工作时经过的时间，当CPU空闲时停止。在单线程程序中，CPU时间不能大于实际时间；如果程序计算密集型，那么两个时间理想情况下应该是相同的，这意味着CPU已经完全加载。另一方面，用户界面程序大部分时间都在等待用户和空闲CPU；在这种情况下，我们希望CPU时间尽可能低：这表明程序高效，并尽可能少地使用CPU资源来服务用户的请求。为此，我们必须超越C++17提供的内容。
- en: High-resolution timers
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高分辨率计时器
- en: 'To measure the CPU time, we have to use OS-specific system calls; on Linux
    and other POSIX-compliant systems, we can use the `clock_gettime()` call to access
    the hardware high-resolution timers:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量CPU时间，我们必须使用特定于操作系统的系统调用；在Linux和其他符合POSIX标准的系统上，我们可以使用`clock_gettime()`调用来访问硬件高分辨率计时器：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The function returns the current time in its second argument; `tv_sec` is the
    number of seconds since some point in the past, and `tv_nsec` is the number of
    nanoseconds since the last whole second. The origin of time does not really matter
    since we always measure time intervals; however, take care to subtract seconds
    first and only then add nanoseconds, otherwise, you lose significant digits of
    the result by subtracting two large numbers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将当前时间返回到其第二个参数中；`tv_sec`是自过去某个时间点以来的秒数，`tv_nsec`是自上一整秒以来的纳秒数。时间的起点实际上并不重要，因为我们总是测量时间间隔；但是，要小心先减去秒数，然后再加上纳秒数，否则，通过减去两个大数，您将丢失结果的有效数字。
- en: 'There are several hardware timers we can use in the previous code, one of which
    is selected by the value of the `clock_id` variable. One of these timers is the
    same system or real-time clock we have used already. Its ID is `CLOCK_REALTIME`.
    The other two timers of interest to us are the two CPU timers: `CLOCK_PROCESS_CPUTIME_ID`  is
    a timer that measures the CPU time used by the current program, and `CLOCK_THREAD_CPUTIME_ID`
    is a similar timer, but it measures only the time used by the calling thread.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以使用几个硬件计时器，其中一个是由`clock_id`变量的值选择的。我们已经使用过的是相同的系统或实时时钟。它的ID是`CLOCK_REALTIME`。我们感兴趣的另外两个计时器是两个CPU计时器：`CLOCK_PROCESS_CPUTIME_ID`是一个测量当前程序使用的CPU时间的计时器，`CLOCK_THREAD_CPUTIME_ID`是一个类似的计时器，但它只测量调用线程使用的时间。
- en: 'When benchmarking the code, it is often helpful to report the measurements
    from more than one timer. In the simplest case of a single-threaded program that
    is doing uninterrupted computations, all three timers should return the same result:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在对代码进行基准测试时，通常有助于从多个计时器中报告测量结果。在最简单的情况下，即单线程程序进行不间断计算时，所有三个计时器应该返回相同的结果：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here the "CPU-intensive work" is some kind of computation, and all three times
    should be almost identical. You can observe this in a simple experiment with any
    kind of computation. The values of the times will depend on the speed of the computer,
    but, that aside, the result should look like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的“CPU密集型工作”是某种计算，所有三个时间应该几乎相同。您可以通过任何类型的计算的简单实验来观察到这一点。时间的值将取决于计算机的速度，但是除此之外，结果应该看起来像这样：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If the reported CPU time does not match the real time, it is likely that the
    machine is overloaded (many other processes are competing for the CPU resources),
    or the program is running out of memory (if the program uses more memory than
    the physical memory on the machine, it will have to use the much slower disk swap,
    and the CPUs can't do any work while the program is waiting for the memory to
    be paged in from disk).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果报告的CPU时间与实际时间不匹配，很可能是机器负载过重（许多其他进程正在竞争CPU资源），或者程序内存不足（如果程序使用的内存超过了机器上的物理内存，它将不得不使用速度慢得多的磁盘交换，而CPU在程序等待内存从磁盘中分页时无法执行任何工作）。
- en: 'On the other hand, if the program does not compute much but instead, waits
    on user input, or receives the data from the network, or does some other work
    that does not take many CPU resources, we will see a very different result. The
    simplest way to observe this behavior is by calling the `sleep()` function instead
    of the computation we used earlier:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果程序没有进行太多计算，而是等待用户输入，或者从网络接收数据，或者进行其他不需要太多CPU资源的工作，我们将看到非常不同的结果。观察这种行为的最简单方法是调用`sleep()`函数而不是我们之前使用的计算：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we will, hopefully, see that a sleeping program uses very little CPU:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将希望看到一个休眠程序使用非常少的CPU：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The same should be true for a program that is blocked on a socket or a file
    or is waiting for a user action.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在套接字或文件上被阻塞或等待用户操作的程序，情况也应该是如此。
- en: 'So far, we have not seen any difference between the two CPU timers, and you
    will not see any unless your program uses threads. We can make our compute-heavy
    program do the same work but use a separate thread for it:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有看到两个CPU计时器之间的任何差异，除非您的程序使用线程，否则您也不会看到任何差异。我们可以让我们的计算密集型程序执行相同的工作，但使用单独的线程：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The total amount of computations remains the same, and there is still only
    one thread doing the work, so we do not expect any changes to the real time or
    the process-wide CPU time. However, the thread that is calling the timers is now
    idle; all it does is wait on the future returned by `std::async` until the work
    is done. This waiting is very similar to the `sleep()` function in the previous
    example, and we can see it in the results:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 计算的总量保持不变，仍然只有一个线程在工作，因此我们不希望实时或整个进程的CPU时间发生任何变化。然而，调用定时器的线程现在处于空闲状态；它所做的就是等待`std::async`返回的未来，直到工作完成。这种等待与前面例子中的`sleep()`函数非常相似，我们可以从结果中看到：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now the real time and the process-wide CPU time look like those from the "heavy
    computing" example, but the thread-specific CPU time is low, like in the "sleeping"
    example. That is because the overall program is doing heavy computing, but the
    thread that calls the timers is indeed mostly sleeping.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在实时和整个进程的CPU时间看起来像“重型计算”示例中的那样，但特定线程的CPU时间很低，就像“睡眠”示例中的那样。这是因为整体程序正在进行大量计算，但调用定时器的线程确实大部分时间都在睡眠。
- en: 'Most of the time, if we are going to use threads for computing, the goal is
    to do more computations faster, so we will use several threads and spread the
    work between them. Let us modify the preceding example to compute also on the
    main thread:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，如果我们要使用线程进行计算，目标是更快地进行更多的计算，因此我们将使用多个线程并在它们之间分配工作。让我们修改前面的例子，也在主线程上进行计算：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now both threads are doing computations, so the CPU time used by the program
    passes at a double rate compared to the real time:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在两个线程都在进行计算，因此程序使用的CPU时间以双倍速率流逝，与实际时间相比。
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This is pretty good: we have done 1 second worth of computations in only 0.53
    seconds of real time. Ideally, this would have been 0.5 seconds, but in reality,
    there is some overhead for launching threads and waiting for them. Also, one of
    the two threads might have taken slightly longer to do the work, then the other
    thread was idle some of the time.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这很不错：我们在只有0.53秒的实际时间内完成了1秒的计算。理想情况下，这应该是0.5秒，但实际上，启动线程和等待它们会有一些开销。此外，两个线程中的一个可能需要更长的时间来完成工作，然后另一个线程有时会处于空闲状态。
- en: 'Benchmarking a program is a powerful way to collect performance data. Simply
    by observing the time it takes to execute a function or handle an event, we can
    learn a lot about the performance of the code. For compute-intensive code, we
    can see whether the program is indeed doing computations non-stop or is waiting
    on something. For multi-threaded programs, we can measure how effective the concurrency
    is and what the overhead is. But we are not just limited to collecting execution
    times: we can also report any counts and values we deem relevant: how many times
    a function was called, how long the average string we sort is, anything we need
    to help us interpret the measurements.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对程序进行基准测试是收集性能数据的一种强大方式。仅通过观察执行函数或处理事件所需的时间，我们就可以了解代码的性能。对于计算密集型代码，我们可以看到程序是否确实在不停地进行计算，还是在等待某些东西。对于多线程程序，我们可以测量并发性有多有效以及开销是多少。但我们不仅仅局限于收集执行时间：我们还可以报告任何我们认为相关的计数和值：函数被调用的次数，我们排序的平均字符串长度，任何我们需要帮助解释测量的东西。
- en: 'However, this flexibility comes at a price: with benchmarking, we can answer
    almost any question about the performance of the program that we want to ask.
    But we have to ask the question first: we report only what we decided to measure.
    If we want to know how long a certain function takes, we have to add the timers
    to it; if they aren''t there, we will learn nothing until we rewrite the code
    and rerun the benchmark. On the other hand, it would not do to sprinkle timers
    everywhere in the code: these function calls are fairly expensive, so using too
    many can both slow down your program and distort the performance measurements.
    With experience and good coding discipline, you can learn to instrument the code
    you write in advance, so at least its major sections can be benchmarked easily.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种灵活性是有代价的：通过基准测试，我们几乎可以回答关于程序性能的任何问题。但我们必须首先提出问题：我们只报告我们决定测量的内容。如果我们想知道某个函数需要多长时间，我们必须为其添加定时器；如果没有，我们将无法得知任何信息，直到重写代码并重新运行基准测试。另一方面，在代码中到处添加定时器也不可取：这些函数调用相当昂贵，因此使用太多可能会减慢程序速度并扭曲性能测量。通过经验和良好的编码纪律，你可以学会提前为自己编写的代码进行仪器化，这样至少它的主要部分可以轻松进行基准测试。
- en: 'But what should you do if you have no idea where to start? What if you have
    inherited a code base that was not instrumented for any benchmarking? Or, maybe,
    you isolated your performance bottleneck to a large section of code, but there
    are no more timers inside of it? One approach is to continue instrumenting the
    code until you have enough data to analyze the problem. But this brute-force approach
    is slow, so you will want some guidance on where to focus your efforts. This is
    where profiling comes in: it lets you collect performance data for a program that
    wasn''t instrumented, by hand, for easy benchmarking. We will learn about profiling
    in the next section.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你不知道从哪里开始怎么办？如果你继承了一个没有为任何基准测试进行仪器化的代码库怎么办？或者，也许你将性能瓶颈隔离到了一个大段代码中，但里面没有更多的定时器了怎么办？一种方法是继续对代码进行仪器化，直到你有足够的数据来分析问题。但这种蛮力方法很慢，所以你会希望得到一些关于在哪里集中努力的指导。这就是性能分析的作用：它让你可以为一个没有手动进行简单基准测试的程序收集性能数据。我们将在下一节学习有关性能分析的知识。
- en: Performance profiling
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能分析
- en: 'The next set of performance analysis tools that we are going to learn about
    is the profiling tools, or profilers. We have already seen a profiler in use:
    in the last section, we used it to identify the function that was taking the majority
    of the computation time. This is exactly what profilers are used for, to find
    "hot" functions and code fragments, that is, the lines of code where the program
    spends the most time.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要学习的下一组性能分析工具是分析工具，或分析器。我们已经看到了一个分析器的使用：在上一节中，我们使用它来识别占用大部分计算时间的函数。这正是分析器的用途，用于找到“热点”函数和代码片段，也就是程序花费大部分时间的代码行。
- en: There are many different profiling tools available, both commercial and open
    source. In this section, we are going to examine two profilers that are popular
    on Linux systems. The goal is not to make you an expert on a particular tool but
    to give you an idea of what to expect from the profiler you choose to use and
    how to interpret its results.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的分析工具可用，包括商业和开源的。在本节中，我们将研究两种在Linux系统上流行的分析器。我们的目标不是让你成为某个特定工具的专家，而是让你了解你选择使用的分析器可以期望什么以及如何解释其结果。
- en: 'First, let us point out that there are several different types of profilers:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们指出有几种不同类型的分析器：
- en: Some profilers execute the code under an interpreter or a virtual machine and
    observe where it spends the time. The main downside of these profilers is that
    they make the program run much slower than the code compiled directly to machine
    instructions, at least for languages like C++ that are so compiled and do not
    normally run under a virtual machine.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些分析器执行解释器或虚拟机下的代码，并观察它花费时间的地方。这些分析器的主要缺点是，它们使程序运行速度比直接编译成机器指令的代码慢得多，至少对于像C++这样被编译而不通常在虚拟机下运行的语言来说是这样。
- en: Other profilers require that the code is instrumented with special instructions
    during compilation or linking. These instructions provide additional information
    to the profiler, for example, so that they can notify the data collection engine
    when a function is called or a loop begins and ends. These profilers are faster
    than the ones of the previous type but still slower than the native execution.
    They also require a special compilation of the code and rely on the assumption
    that the instrumented code has the same performance as the original code, at least
    relatively, if not absolutely.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他分析器要求在编译或链接期间使用特殊指令对代码进行仪器化。这些指令为分析器提供额外的信息，例如，当函数被调用或循环开始和结束时，它们可以通知数据收集引擎。这些分析器比前一种类型的分析器更快，但仍然比本地执行慢。它们还需要对代码进行特殊编译，并依赖于一个假设，即仪器化的代码与原始代码具有相同的性能，至少是相对的，如果不是绝对的。
- en: 'Most modern profilers use the hardware event counters that are present on all
    modern CPUs. These are special hardware registers that can be used to track certain
    hardware events. An example of a hardware event is executing an instruction. You
    can see how this can be useful for profiling: the processor will do the work of
    counting instructions for us without any additional instrumentation or any overhead.
    All we need to do is to read the values of the counter registers.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数现代分析器使用现代CPU上存在的硬件事件计数器。这些是可以用来跟踪特定硬件事件的特殊硬件寄存器。一个硬件事件的例子是执行一条指令。你可以看到这对于分析是如何有用的：处理器将为我们计算指令而无需任何额外的仪器或开销。我们所需要做的就是读取计数器寄存器的值。
- en: 'Unfortunately, useful profiling is a bit more complicated than simply counting
    instructions. We need to know how much time was spent in each function and even
    in each line of code. This can be done if the profiler reads the instruction count
    before and after executing each function (or each loop, each line of code, and
    so on). This is why some profilers use a hybrid approach: they instrument the
    code to mark the points of interest but use the hardware performance counters
    for the actual measurements.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，有用的分析比简单地计算指令要复杂一些。我们需要知道每个函数甚至每行代码花费了多少时间。如果分析器在执行每个函数（或每个循环、每行代码等）之前和之后读取指令计数，就可以做到这一点。这就是为什么一些分析器使用混合方法：它们对代码进行仪器化以标记感兴趣的点，但使用硬件性能计数器进行实际测量。
- en: 'Other profilers rely on time-based sampling: they interrupt the program at
    a certain interval, say, once per 10 milliseconds, and record the values of the
    performance counters as well as the current location of the program (the instruction
    that is about to be executed). If, say, 90% of all samples were taken during a
    call to the `compare()` function, we can assume that the program spends 90% of
    the time doing string comparisons. The accuracy of this approach depends on the
    number of samples taken and the interval between the samples.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其他分析器依赖于基于时间的采样：它们在一定的间隔内中断程序，比如每10毫秒一次，并记录性能计数器的值以及程序的当前位置（即将执行的指令）。如果，比如，所有样本中有90%是在调用`compare()`函数时进行的，我们可以假设程序花费了90%的时间进行字符串比较。这种方法的准确性取决于采样数量和采样之间的间隔。
- en: The more often we sample the execution of the program, the more data we collect,
    but the greater the overhead is as well. Hardware-based profilers can, in some
    cases, have no adverse effect on the runtime of the program at all if the sampling
    is done not too often.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对程序执行的采样越频繁，我们收集的数据就越多，但开销也越大。基于硬件的分析器在某些情况下可能对程序的运行时没有任何不利影响，如果采样不是太频繁的话。
- en: The perf profiler
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能分析器
- en: The first profiler tool we are going to learn in this section is the Linux `perf`
    profiler. This is one of the most popular profilers on Linux simply because it
    comes installed with most distributions. This profiler uses hardware performance
    counters and time-based sampling; it does not require any instrumentation of the
    code.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中学习的第一个分析器工具是Linux的`perf`分析器。这是Linux上最流行的分析器之一，因为它几乎安装在大多数发行版中。这个分析器使用硬件性能计数器和基于时间的采样；它不需要对代码进行任何仪器化。
- en: 'The simplest way to run this profiler is to collect the counter values for
    the entire program; this is done using the `perf stat` command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个性能分析器的最简单方法是收集整个程序的计数器值；这是使用`perf stat`命令完成的：
- en: '![Figure 2.6'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.6'
- en: '](img/Figure_2.6_B16229.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.6_B16229.jpg)'
- en: Figure 2.6
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6
- en: As you can see in *Figure 2.6*, the compilation does not require any special
    options or tools. The program is executed by the profiler, and the `stat` option
    tells the profiler to display the counts accumulated in the hardware performance
    counters during the entire run of the program. In this case, our program ran for
    158 milliseconds (consistent with the time printed by the program itself) and
    executed over 1.3 billion instructions. There are several other counters shown,
    such as "page-faults" and "branches." What are these counters, and what other
    counters can we see?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在*图2.6*中所看到的，编译不需要任何特殊选项或工具。程序由性能分析器执行，`stat`选项告诉性能分析器在整个程序运行期间显示硬件性能计数器中累积的计数。在这种情况下，我们的程序运行了158毫秒（与程序本身打印的时间一致），执行了超过13亿条指令。还显示了其他几个计数器，如“页面错误”和“分支”。这些计数器是什么，还有哪些计数器可以看到？
- en: 'As it turns out, modern CPUs can collect statistics on many different types
    of events, but only a few types at a time; in the preceding example, eight counters
    were reported, so we can assume that this CPU has eight independent counters.
    However, each of these counters can be assigned to count one of many event types.
    The profiler itself can list all the events that are known to it and can be counted:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，现代CPU可以收集许多不同类型的事件的统计信息，但一次只能收集少数类型；在前面的例子中，报告了八个计数器，因此我们可以假设这个CPU有八个独立的计数器。然而，这些计数器中的每一个都可以被分配来计算许多事件类型中的一个。性能分析器本身可以列出所有已知的事件，并且可以对其进行计数：
- en: '![Figure 2.7'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.7'
- en: '](img/Figure_2.7_B16229.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.7_B16229.jpg)'
- en: Figure 2.7
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7
- en: 'The list in *Figure 2.7* is incomplete (the printout continues for many more
    lines), and the exact counters available vary from one CPU to another (and, if
    you use a virtual machine, on the type and configuration of the hypervisor). The
    results collected by our profiling run in *Figure 2.6* are simply the default
    set of counters, but we can select other counters for profiling:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.7*中的列表是不完整的（打印输出会继续很多行），并且可用的确切计数器会因CPU而异（如果您使用虚拟机，则还会受到hypervisor的类型和配置的影响）。我们在*图2.6*中收集的性能分析运行结果只是默认的计数器集，但我们可以选择其他计数器进行性能分析：'
- en: '![Figure 2.8'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.8'
- en: '](img/Figure_2.8_B16229.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.8_B16229.jpg)'
- en: Figure 2.8
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8
- en: In *Figure 2.8*, we measure CPU cycles and instructions, as well as branches,
    branch misses, cache references, and cache misses. A detailed explanation of these
    counters and the events they monitor will be presented in the next chapter.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.8*中，我们测量CPU周期和指令，以及分支、分支丢失、缓存引用和缓存丢失。这些计数器及其监视的事件的详细解释将在下一章中介绍。
- en: Briefly, the cycle time is the inverse of the CPU frequency, so a 3GHz CPU can
    run 3 billion cycles per second. By the way, most CPUs can run at variable speeds,
    which complicates the measurements. Thus, for accurate profiling and benchmarking,
    it is recommended to disable the power saving mode and other features that can
    cause the CPU clock to vary. The instruction counter measures the number of processor
    instructions that were executed; as you can see, the CPU executes, on average,
    almost four instructions per cycle.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，周期时间是CPU频率的倒数，因此3GHz的CPU可以每秒运行30亿个周期。顺便说一句，大多数CPU可以以可变速度运行，这会使测量变得复杂。因此，为了进行准确的性能分析和基准测试，建议禁用节能模式和其他可能导致CPU时钟变化的功能。指令计数器测量执行的处理器指令数量；正如您所看到的，CPU平均每个周期执行了近四条指令。
- en: 'The "branches" are the conditional instructions: every `if` statement and every
    `for` loop with a condition generates at least one of these instructions. Branch
    misses will be explained in detail in the next chapter; for now, we can just say
    that it is an expensive and undesirable event, from the performance point of view.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '"分支"是条件指令：每个`if`语句和每个带有条件的`for`循环至少生成一个这样的指令。分支丢失将在下一章中详细解释；现在我们只能说，从性能角度来看，这是一个昂贵且不希望发生的事件。'
- en: The "cache references" count how many times the CPU needed to fetch something
    from memory. Most of the time, "something" is a piece of data, such as a character
    in the string. Depending on the state of the processor and memory, this fetch
    can be very fast or very slow; the latter is counted as a "cache miss" ("slow"
    is a relative concept; relative to the processor speed of 3 GHz, 1 microsecond
    is a very long time). The memory hierarchy will be explained in a later chapter;
    again, a cache miss is an expensive event.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '"缓存引用"计算CPU需要从内存中获取数据的次数。大多数情况下，“数据”是一段数据，比如字符串中的一个字符。根据处理器和内存的状态，这种获取可能非常快或非常慢；后者被计为“缓存丢失”（“慢”是一个相对概念；相对于3GHz的处理器速度，1微秒是一个非常长的时间）。内存层次结构将在后面的章节中解释；同样，缓存丢失是一个昂贵的事件。'
- en: Armed with an understanding of how the CPUs and the memory work, you will be
    able to use such measurements to gauge the overall efficiency of your program
    and determine what kinds of factors are limiting its performance.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握了CPU和内存的工作原理，您将能够利用这些测量来评估程序的整体效率，并确定限制其性能的因素类型。
- en: 'So far, we have seen only whole-program measurements. The measurements in *Figure
    2.8* may tell us what is holding back the performance of our code: for example,
    if we accept for now that "cache misses" are bad for performance, we can deduce
    that the main problem in this code is its inefficient memory access (one out of
    ten memory accesses is slow). However, this type of data does not tell us which
    parts of the code are responsible for poor performance. For that, we need to collect
    the data not just before and after but also during the program execution. Let
    us see how to do that with `perf`.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看到了整个程序的测量。*图2.8*中的测量可能告诉我们是什么在阻碍我们代码的性能：例如，如果我们暂时接受“缓存未命中”对性能不利，我们可以推断出这段代码的主要问题是其低效的内存访问（十次内存访问中有一次是慢的）。然而，这种类型的数据并不告诉我们代码的哪些部分负责性能不佳。为此，我们需要收集数据不仅在程序执行之前和之后，还在程序执行期间。让我们看看如何使用`perf`来做到这一点。
- en: Detailed profiling with perf
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用perf进行详细分析
- en: The `perf` profiler combines the hardware counters with time interval-based
    sampling to record the profile of the running program. For each sample, it records
    the position of the program counter (the address of the instruction to be executed)
    and the values of the performance counters that we are monitoring. After the run,
    the data is analyzed; the functions and code lines with the most samples are responsible
    for the majority of the execution time.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`perf`分析器将硬件计数器与基于时间间隔的采样相结合，记录运行程序的性能概况。对于每个样本，它记录程序计数器的位置（要执行的指令的地址）和我们正在监视的性能计数器的值。运行后，数据将被分析；具有最多样本的函数和代码行负责大部分执行时间。'
- en: 'The data collection run of the profiler is no more difficult than the overall
    measurement run. Note that, at run time, the instruction addresses are collected;
    to convert these to the line numbers in the original source code, the program
    must be compiled with debug information. If you are used to the two compilation
    modes, "optimized" and "debug non-optimized," this combination of compiler options
    may come as a surprise: both debug and optimization are enabled. The reason for
    the latter is that we need to profile the same code that will run in production,
    otherwise, the data is mostly meaningless. With this in mind, we can compile our
    code for profiling and run the profiler using the `perf record` command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器的数据收集运行并不比整体测量运行更困难。请注意，在运行时，指令地址被收集；要将这些转换为原始源代码中的行号，程序必须使用调试信息进行编译。如果您习惯于两种编译模式，“优化”和“非优化调试”，那么编译器选项的这种组合可能会让您感到惊讶：调试和优化都已启用。后者的原因是我们需要对将在生产中运行的相同代码进行分析，否则数据大多是无意义的。考虑到这一点，我们可以为分析编译代码并使用`perf
    record`命令运行分析器：
- en: '![Figure 2.9'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.9'
- en: '](img/Figure_2.9_B16229.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.9_B16229.jpg)'
- en: Figure 2.9
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9
- en: 'Just like `perf stat`, we could have specified a counter or a set of counters
    to monitor but, this time, we accept the default counter. We haven''t specified
    how often the samples are taken; again, there is a default for that, but we could
    also specify it explicitly: for example, `perf record -c 1000` records 1000 samples
    per second.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`perf stat`一样，我们可以指定一个计数器或一组计数器来监视，但是这次，我们接受默认计数器。我们没有指定采样的频率；同样，也有一个默认值，但我们也可以明确指定：例如，`perf
    record -c 1000`每秒记录1000个样本。
- en: 'The program runs, produces its regular output, as well as the messages from
    the profiler. The last one tells us that the profiling samples have been captured
    in the file named `perf.data` (again, this is the default that can be changed).
    To visualize the data from this file, we need to use the profile analysis tool,
    which is also a part of the same perftools suite, specifically, the `perf report`
    command. Running this command will launch this screen:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 程序运行，产生常规输出，以及来自分析器的消息。最后一个告诉我们，分析样本已经捕获在名为`perf.data`的文件中（同样，这是可以更改的默认值）。要可视化来自此文件的数据，我们需要使用分析工具，它也是同一perftools套件的一部分，具体来说是`perf
    report`命令。运行此命令将启动此屏幕：
- en: '![Figure 2.10'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.10'
- en: '](img/Figure_2.10_B16229.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.10_B16229.jpg)'
- en: Figure 2.10
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10
- en: 'This is the profiling summary, a breakdown of the execution time by function.
    From here, we can drill down into any function and see which lines contributed
    the most to the execution time:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这是分析摘要，按功能的执行时间分解。从这里，我们可以深入研究任何功能，并查看哪些行对执行时间贡献最大：
- en: '![Figure 2.11'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.11'
- en: '](img/Figure_2.11_B16229.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.11_B16229.jpg)'
- en: Figure 2.11
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11
- en: 'The numbers on the left in *Figure 2.11* are the percentages of the execution
    time spent at each line. So, what exactly does the "line" tell us? *Figure 2.11*
    illustrates one of the more frequent difficulties in analyzing such profiles.
    It shows both the source code and the assembly instructions produced from it;
    the execution time counters are, naturally, associated with every hardware instruction
    (that is what the CPU executes, so that''s the only thing it can count). The correspondence
    between the compiled code and the source is established by the profiler using
    the debugging information embedded by the compiler. Unfortunately, this correspondence
    is not exact, and the reason for this is optimization. The compiler performs a
    wide range of optimizations, all of which end up rearranging the code and changing
    the way the computations are done. You can see the results even in this very simple
    example: why does the source code line'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.11*左侧的数字是每行所花费的执行时间的百分比。那么，“行”到底告诉我们什么？*图2.11*说明了分析此类概要的更频繁的困难之一。它显示了源代码和由此产生的汇编指令；执行时间计数器自然与每个硬件指令相关联（这是CPU执行的内容，因此是唯一可以计数的内容）。编译代码和源代码之间的对应关系是由编译器嵌入的调试信息由分析器建立的。不幸的是，这种对应关系并不精确，原因是优化。编译器执行各种优化，所有这些优化最终都会重新排列代码并改变计算方式。即使在这个非常简单的例子中，您也可以看到结果：为什么源代码行'
- en: '[PRE17]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: appear twice? There is only one such line in the original source code. The reason
    is that the instructions generated from this line are not all in the same place;
    the optimizer reordered them with the instructions originating from other lines.
    So the profiler shows this line near both machine instructions that were originally
    generated from it.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么出现两次？原始源代码中只有一行。原因是从这一行生成的指令不都在同一个地方；优化器将它们与来自其他行的指令重新排序。因此，分析器在这条线附近显示了两次机器指令。
- en: 'Even without looking at the assembler, we can see that the time is spent comparing
    the characters, as well as running the loop itself; these two source lines account
    for most of the time:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 即使不看汇编代码，我们也可以看到时间花在比较字符上，以及运行循环本身；这两行源代码占据了大部分时间：
- en: '[PRE18]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To get the most out of the profile, it helps to understand at least the basics
    of the assembly language of the platform we''re working on (X86 CPUs, in our case).
    The profiler also has some helpful tools that facilitate the analysis. For example,
    by placing the cursor on the `jne` (jump if not equal) instruction, we can see
    where the jump would take us, as well as the condition associated with the jump:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用分析，有助于了解我们正在工作的平台的汇编语言的基础知识（在我们的情况下是X86 CPU）。分析器还有一些有用的工具，可以方便分析。例如，将光标放在`jne`（如果不相等则跳转）指令上，我们可以看到跳转会带我们去哪里，以及与跳转相关的条件：
- en: '![Figure 2.12'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.12'
- en: '](img/Figure_2.12_B16229.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.12_B16229.jpg)'
- en: Figure 2.12
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12
- en: This looks like a jump back to repeat the last few lines of code, so the `cmp`
    (compare) instruction above the jump must be the comparison of the loop, `i1 <
    l`. Together, the jump and the comparison account for 18% of the execution time,
    so our earlier attention to the seemingly unnecessary comparison operation appears
    justified.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像是跳回重复最后几行代码，所以跳转上面的`cmp`（比较）指令必须是循环的比较，`i1 < l`。总的来说，跳转和比较占据了18%的执行时间，所以我们之前对看似不必要的比较操作的关注似乎是合理的。
- en: The perf profiler has many more options and capabilities for analyzing, filtering,
    and aggregating the results, all of which you can learn from its documentation.
    There are also several GUI frontends for this profiler. Next, we are going to
    take a quick look at another profiler, the one from Google Performance tools.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: perf分析器有更多的选项和功能来分析、过滤和聚合结果，所有这些都可以从其文档中学习。此外，还有几个GUI前端用于这个分析器。接下来，我们将快速看一下另一个分析器，来自Google性能工具的分析器。
- en: The Google Performance profiler
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google性能分析器
- en: 'The Google CPU profiler also uses hardware performance counters. It also requires
    link-time instrumentation of the code (but no compile-time instrumentation). To
    prepare the code for profiling, you have to link it with the profiler library:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Google CPU分析器也使用硬件性能计数器。它还需要对代码进行链接时插装（但不需要编译时插装）。为了准备代码进行分析，你必须将其与分析器库链接：
- en: '![Figure 2.13'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.13'
- en: '](img/Figure_2.13_B16229.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.13_B16229.jpg)'
- en: Figure 2.13
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13
- en: 'In *Figure 2.13*, the library is specified by the command-line option `–lprofiler`.
    Unlike perf, this profiler does not need any special tools to invoke the program;
    the necessary code is already linked into the executable. The instrumented executable
    does not automatically start profiling itself. We have to activate the profiling
    by setting the environment variable `CPUPROFILE` to the filename of the file where
    we want to store the results. Other options are also controlled through the environment
    variables instead of command-line options, for example, the variable `CPUPROFILE_FREQUENCY`
    sets the number of samples per second:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.13*中，库由命令行选项`-lprofiler`指定。与perf不同，这个分析器不需要任何特殊的工具来调用程序；必要的代码已经链接到可执行文件中。插装的可执行文件不会自动开始分析自身。我们必须通过设置环境变量`CPUPROFILE`为我们想要存储结果的文件名来激活分析。其他选项也是通过环境变量而不是命令行选项来控制的，例如，变量`CPUPROFILE_FREQUENCY`设置每秒的样本数：
- en: '![Figure 2.14'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.14'
- en: '](img/Figure_2.14_B16229.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.14_B16229.jpg)'
- en: Figure 2.14
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14
- en: 'Again, we see the output from the program itself and from the profiler, and
    we get the profile data file that we must analyze. The profiler has both the interactive
    and the batch mode; the interactive mode is a simple text user interface:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们看到了程序本身和分析器的输出，并且得到了我们必须分析的配置文件。分析器有交互模式和批处理模式；交互模式是一个简单的文本用户界面：
- en: '![Figure 2.15'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.15'
- en: '](img/Figure_2.15_B16229.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.15_B16229.jpg)'
- en: Figure 2.15
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15
- en: 'Simply running `google-pprof` (often installed as just `pprof`) with the names
    of the executable and the profile as arguments brings up the command prompt. From
    here, we can, for example, get the summary of all functions annotated with percentages
    of the execution time. We can further analyze the program performance at the source
    code level:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 只需运行`google-pprof`（通常安装为`pprof`）并将可执行文件和配置文件的名称作为参数，就会弹出命令提示符。从这里，我们可以，例如，获取所有函数的摘要，其中包含执行时间的百分比。我们还可以在源代码级别进一步分析程序性能：
- en: '![Figure 2.16'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.16'
- en: '](img/Figure_2.16_B16229.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.16_B16229.jpg)'
- en: Figure 2.16
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16
- en: 'As you can see, this profiler takes a slightly different approach and does
    not immediately dump us, neck-deep, into machine code (although annotated assembly
    can also be produced). This apparent simplicity is somewhat deceptive, though:
    the caveats we described earlier still apply, the optimizing compiler still does
    its transformations on the code.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这个分析器采用了稍微不同的方法，并没有立即将我们深入到机器代码中（尽管也可以生成带注释的汇编代码）。然而，这种表面上的简单有些欺骗性：我们之前描述的注意事项仍然适用，优化编译器仍然对代码进行转换。
- en: Different profilers have somewhat different strengths and weaknesses, owing
    to the different approaches taken by their authors. Without turning this chapter
    into a profiler manual, we will show in the rest of this section some of the more
    common problems you may encounter when collecting and analyzing the profile.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的性能分析工具由于作者采取的不同方法而具有不同的优势和劣势。我们不想把本章变成性能分析工具的手册，因此在本节的其余部分，我们将展示在收集和分析性能分析结果时可能遇到的一些常见问题。
- en: Profiling with call graphs
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用调用图进行分析
- en: 'So far, our simple example has avoided one problem that, in reality, happens
    in every program. When we discovered that the comparison function is responsible
    for the majority of the execution time, we immediately knew which part of the
    program is responsible: there was only one line that calls this function.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们简单的例子已经避开了一个实际上在每个程序中都会发生的问题。当我们发现比较函数占据了大部分执行时间时，我们立刻知道程序的哪一部分是有问题的：只有一行调用了这个函数。
- en: 'Most real-life programs are not so simple: after all, one of the main reasons
    we write functions is to facilitate code reuse. It stands to reason that many
    functions will be called from multiple locations, some many times and others just
    a few times, often with very different parameters. Simply knowing which function
    takes a lot of time is not enough: we also need to know in which context it happens
    (after all, the most effective optimization may be to call the expensive function
    less often).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现实生活中的程序都不会那么简单：毕竟，我们编写函数的主要原因之一就是为了促进代码重用。很显然，许多函数将会从多个位置被调用，有些会被调用多次，而有些则只会被调用几次，通常使用非常不同的参数。仅仅知道哪个函数花费了很多时间是不够的：我们还需要知道它发生在什么上下文中（毕竟，最有效的优化可能是更少地调用昂贵的函数）。
- en: 'What we need is a profile that does not just tell us how much time is spent
    in each function and on each line of code, but also how much time is spent in
    each call chain. These profilers usually present this information using the call
    graphs: graphs where callers and callees are nodes and calls are edges.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的是一个不仅告诉我们每个函数和每行代码花费了多少时间，还告诉我们每个调用链花费了多少时间的分析结果。这些性能分析工具通常使用调用图来呈现这些信息：图中调用者和被调用者是节点，调用是边。
- en: 'First, we have to modify our example so we can call some function from more
    than one location. Let us start by making two `sort` calls:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须修改我们的例子，以便我们可以从多个位置调用某个函数。让我们首先进行两次`sort`调用：
- en: '[PRE19]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The calls differ only in the comparison functions; in our case, the first comparison
    function is the same as before, and the second one produces the opposite order.
    The two functions have the same loop over substring characters as our old comparison
    function:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这些调用只在比较函数上有所不同；在我们的例子中，第一个比较函数和之前一样，而第二个则产生了相反的顺序。这两个函数都和我们旧的比较函数一样，在子字符串字符上有相同的循环：
- en: '[PRE20]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Both functions use the same common function to compare each character:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数都使用相同的通用函数来比较每个字符：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This isn''t, of course, how you would do it in a real program: if you really
    wanted to avoid the code duplication caused by repeating the loop, you would write
    a single function parametrized by the character comparison operator. However,
    we do not want to deviate too far from the example we started with, and we want
    to keep the code simple so we can explain the results one complication at a time.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这并不是你在真正的程序中会这样做的方式：如果你真的想避免由于重复循环而导致的代码重复，你会编写一个由字符比较运算符参数化的单个函数。然而，我们不想偏离我们开始的例子太远，我们希望保持代码简单，这样我们可以一次解释一个复杂性。
- en: Now we are ready to produce a call graph that will show us how the cost of the
    character comparison is split between the two calls to sort. Both profilers we
    have used can produce call graphs; in this section, we will use the Google profiler.
    For this profiler, data collection already included the call chain information;
    we just haven't tried to visualize it so far.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备生成一个调用图，它将显示字符比较的成本是如何在两次对sort的调用之间分配的。我们使用的两个性能分析工具都可以生成调用图；在本节中，我们将使用Google性能分析工具。对于这个性能分析工具，数据收集已经包括了调用链信息；我们只是到目前为止还没有尝试去可视化它。
- en: 'We compile the code and run the profiler exactly as we did it earlier (for
    simplicity, we put each function in its own source file):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编译代码并运行性能分析器，就像我们之前做的那样（为了简单起见，我们将每个函数放在自己的源文件中）：
- en: '![Figure 2.17'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.17'
- en: '](img/Figure_2.17_B16229.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.17_B16229.jpg)'
- en: Figure 2.17
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 2.17
- en: 'The profiler can show the call graph in several different formats (Postscript,
    GIF, PDF, and so on). For example, to generate the PDF output, we would run this
    command:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析工具可以以几种不同的格式显示调用图（Postscript、GIF、PDF等）。例如，要生成PDF输出，我们将运行以下命令：
- en: '[PRE22]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The information we''re interested in right now is at the bottom of the call
    graph:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在感兴趣的信息在调用图的底部：
- en: '![Figure 2.18'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.18'
- en: '](img/Figure_2.18_B16229.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.18_B16229.jpg)'
- en: Figure 2.18
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18
- en: As you can see in *Figure 2.18*, the `compare()` function, which accounts for
    58.6% of the total execution time, has two callers. Of the two, the `compare1()`
    function makes slightly more calls than the `compare2()` function; the former
    accounts for 27.6% of the execution time (or 59.8% if you include the time spent
    in its share of calls to `compare()`) and the latter is responsible for 13.8%
    of the time by itself, or 40.2% in total.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图2.18*中所看到的，`compare()`函数占据了总执行时间的58.6%，有两个调用者。在这两个调用者中，`compare1()`函数比`compare2()`函数稍微多一些调用；前者占据了27.6%的执行时间（如果包括其对`compare()`的调用所花费的时间，则为59.8%），而后者单独占据了13.8%的时间，或者总共占据了40.2%的时间。
- en: 'The basic call graphs are often enough to identify the problem call chains
    and select areas of the program for further exploration. Profiling tools also
    have more advanced reporting capabilities, such as the filtering of function names,
    aggregation of results, and so on. Mastering the features of your chosen tool
    can be the difference between knowledge and guesswork: interpreting performance
    profiles can be tricky and frustrating, and there are many reasons for it: some
    arise from tool limitations, but others are more fundamental. In the next section,
    we will talk about one of the latter reasons: for the measurements to be relevant,
    they must be done on fully optimized code.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的调用图通常足以识别问题调用链并选择程序的进一步探索区域。性能分析工具还具有更高级的报告功能，如函数名称的过滤、结果的聚合等。掌握所选择工具的功能差异可能是知识和猜测之间的区别：解释性能分析可能会很棘手和令人沮丧，原因有很多：有些是由于工具的限制，但其他一些则更为根本。在下一节中，我们将讨论后者的一个原因：为了使测量结果相关，必须在完全优化的代码上进行。
- en: Optimization and inlining
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化和内联
- en: 'We have already seen how compiler optimization muddies the waters when it comes
    to interpreting performance profiles: all profiling is done, at the end of the
    day, on the compiled machine code, while we see the program in its source form.
    The relation between these two forms is obscured by compiler optimizations. One
    of the most aggressive optimizations, in terms of rearranging the source code,
    is compile-time inlining of function calls.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到编译器优化在解释性能分析时会使情况变得复杂：所有的性能分析最终都是在编译后的机器代码上进行的，而我们看到的程序是以源代码形式呈现的。编译器优化使这两种形式之间的关系变得模糊。在重新排列源代码方面，最具侵略性的优化之一是编译时函数调用的内联。
- en: 'The inlining requires that the source of the function be visible at the call
    site, so, in order to show you how this looks, we have to combine the entire source
    code in one file:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 内联要求函数的源代码在调用点可见，因此，为了向您展示这是什么样子，我们必须将整个源代码合并到一个文件中：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now the compiler can, and probably will, generate the machine code for the
    comparison right where it is used by the sort, instead of calling the external
    function. Such inlining is a potent optimization tool; it happens quite often
    and not just with functions from the same file. Much more often, inlining affects
    header-only functions (functions whose entire implementation is in the header
    file). For example, in the preceding code, the call to `std::sort`, which looks
    like a function call, is almost certainly inlined because `std::sort` is a template
    function: its entire body is in the header files.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在编译器可以并且可能会在使用排序的地方直接生成机器代码，而不是调用外部函数。这种内联是一种强大的优化工具；它经常发生，不仅仅是在同一文件中的函数。更常见的是，内联会影响头文件中的函数（整个实现都在头文件中的函数）。例如，在前面的代码中，对`std::sort`的调用看起来像是一个函数调用，但几乎可以肯定会被内联，因为`std::sort`是一个模板函数：它的整个主体都在头文件中。
- en: 'Let us see how the profiler tools we used earlier deal with the inlined code.
    Running the Google profiler for annotated source lines produces this report:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们之前使用的性能分析工具如何处理内联代码。运行Google性能分析器对带注释的源代码行产生了这份报告：
- en: '![Figure 2.19'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.19'
- en: '](img/Figure_2.19_B16229.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.19_B16229.jpg)'
- en: Figure 2.19
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19
- en: 'As you can see, the profiler knows that the `compare()` function was inlined
    but still shows its original name. The lines in the source code correspond to
    the location where the code for the function is written, not where it is called,
    for example, line 23 is this line:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，性能分析器知道`compare()`函数被内联，但仍显示其原始名称。源代码中的行对应于函数的代码编写位置，而不是调用位置，例如，第23行是这样的：
- en: '[PRE24]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The perf profiler, on the other hand, does not show inline functions as easily:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，perf性能分析器并不容易显示内联函数：
- en: '![Figure 2.20'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.20'
- en: '](img/Figure_2.20_B16229.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.20_B16229.jpg)'
- en: Figure 2.20
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20
- en: 'Here we can see that the time appears to be spent in the sort code and the
    main program itself. Examining the annotated source, however, shows us that the
    code that was generated from the `compare()` function''s source is still responsible
    for the absolute majority of the execution time:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到时间似乎花在了排序代码和主程序本身上。然而，检查带注释的源代码，我们发现从`compare()`函数源代码生成的代码仍然占绝大多数执行时间：
- en: '![Figure 2.21'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.21'
- en: '](img/Figure_2.21_B16229.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.21_B16229.jpg)'
- en: Figure 2.21
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21
- en: There is, unfortunately, no easy way to undo the effects of the optimizations
    on the performance profiles. Inlining, code reordering, and other transformations
    turn detailed performance analysis into a skill that develops with practice. Perforce,
    some practical suggestions for the effective use of profiling are now in order.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有简单的方法来消除优化对性能分析的影响。内联、代码重排和其他转换将详细的性能分析变成了一个随着实践而发展的技能。因此，现在需要一些关于有效使用性能分析的实际建议。
- en: Practical profiling
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际的性能分析
- en: 'It may be tempting to think of profiling as the ultimate solution to all your
    performance measurement needs: run the whole program under a profiler, collect
    all the data, and get the complete analysis of everything that is going on in
    the code. Unfortunately, it rarely works out this way. Sometimes, the tool limitations
    get in the way. Often, the complexity of the information contained in the large
    amounts of data is simply too overwhelming. How, then, should you use profiling
    effectively?'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 也许会有诱惑力认为性能分析是解决所有性能测量需求的终极解决方案：在性能分析器下运行整个程序，收集所有数据，并获得对代码中发生的一切情况的完整分析。不幸的是，情况很少会如此顺利。有时，工具的限制会成为阻碍。通常，大量数据中包含的信息复杂性太过压倒性。那么，你应该如何有效地使用性能分析呢？
- en: 'The recommended approach is to collect high-level information first, then refine
    it. A coarse profile that breaks down the execution time between large modules
    may be a good place to start. On the other hand, you may have that information
    already if the modules are instrumented for benchmarking and have timers bracketing
    all major execution steps. If you don''t have such instrumentation, the initial
    profile offers good suggestions for what these steps are, so consider adding the
    benchmarking instrumentation now, so you have them next time: you don''t really
    expect to solve all your performance problems once and for all, do you?'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 建议的方法是首先收集高级信息，然后进行细化。将执行时间分解为大型模块之间的粗略概要可能是一个很好的起点。另一方面，如果模块已经为基准测试进行了仪器化，并且在所有主要执行步骤中都有计时器，那么你可能已经有了这些信息。如果你没有这样的仪器化，初始概要提供了这些步骤的很好建议，因此考虑现在添加基准测试仪器，这样下次就有了：你真的不指望一劳永逸地解决所有性能问题，对吧？
- en: 'With the benchmarking results and the coarse profile, you will likely encounter
    one of several scenarios. If you are very lucky, the profile will point to some
    low-hanging fruit, like a function that takes 99% of the time doing a sort of
    a list. Yes, it happens: nobody expected the list to be longer than ten elements
    when the code was first written, and so it was for a while, and then everyone
    forgot about that code until it showed up as the long pole on the profile.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过基准测试结果和粗略的概要，你可能会遇到以下几种情况之一。如果你很幸运，概要会指向一些低挂果实，比如一个函数占用了99%的时间来对列表进行排序。是的，这种情况确实会发生：当代码最初编写时，没有人预料到列表会比十个元素更长，所以一段时间内确实如此，然后每个人都忘记了该代码，直到它在概要中显示为长杆。
- en: 'More likely, the profile will lead you to some large functions or modules.
    Now you have to iterate, create tests that focus on the interesting parts of the
    program, and profile a smaller portion of the code in more detail. Some amount
    of benchmarking data can also be very helpful in interpreting the profiles: while
    the profile will tell you how much time was spent in a given function or a loop,
    it won''t count loop iterations or trace through if-else conditions. Note that
    most profilers can count function calls, so a good modular code is easier to profile
    than a huge monolithic mess.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 更有可能的是，概要会引导你到一些大型函数或模块。现在你必须迭代，创建专注于程序有趣部分的测试，并更详细地对代码的一小部分进行概要。一些基准测试数据在解释概要时也可能非常有帮助：虽然概要会告诉你在给定函数或循环中花费了多少时间，但它不会计算循环迭代或跟踪if-else条件。请注意，大多数性能分析工具可以计算函数调用次数，因此良好的模块化代码比庞大的单片混乱代码更容易进行概要。
- en: 'As you collect and refine the profiles, the data will guide your attention
    toward the performance-critical areas of the code. It is also the point where
    you can fall into a common error: as you are focused on the code that is too slow,
    you may jump to optimizing it without considering the bigger picture. For example,
    the profile shows that a particular loop spends most time in memory allocation.
    Before you decide that you need a more efficient memory allocator, consider whether
    you actually need to allocate and deallocate memory on every iteration of the
    loop. The best way to make slow code faster is often to call it less often. This
    may require a different algorithm or just a more efficient implementation.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当你收集和完善概要时，数据将引导你关注代码的性能关键区域。这也是你可能会犯的一个常见错误的时候：当你专注于太慢的代码时，你可能会跳过考虑更大的画面而进行优化。例如，概要显示一个特定循环在内存分配上花费了大部分时间。在决定是否需要更高效的内存分配器之前，考虑一下你是否真的需要在每次循环迭代中分配和释放内存。使慢速代码变快的最佳方法通常是减少调用次数。这可能需要不同的算法或更高效的实现。
- en: Just as often, you will discover that there is a computation you must do, it
    is the performance-critical part of the code, and the only way to speed up the
    program is to make this code faster. Now you have to try different ideas for optimizing
    it and see what works best. You can do it live in the program itself, but often
    this is a wasteful approach that significantly reduces your productivity. Ideally,
    you want to quickly experiment with different implementations or even different
    algorithms for a particular problem. It is here that you can take advantage of
    the third method for collecting performance data, micro-benchmarking.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 同样频繁的是，你会发现有一个计算是必须要做的，它是代码的性能关键部分，而加快程序的唯一方法就是让这段代码更快。现在你必须尝试不同的优化方法，看看哪种效果最好。你可以在程序本身中实时进行，但这通常是一种浪费时间的方法，会显著降低你的生产力。理想情况下，你希望快速尝试不同的实现方法，甚至针对特定问题尝试不同的算法。在这里，你可以利用第三种收集性能数据的方法，微基准测试。
- en: Micro-benchmarking
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微基准测试
- en: By the end of the previous section, we figured out where our program spends
    most of its execution time. We were also surprised when our "obvious" and "foolproof"
    optimization backfired and made the program run slower, not faster. It is clear
    now that we have to investigate the performance-critical function in more detail.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节结束时，我们弄清楚了程序在执行过程中花费大部分时间的地方。当我们的“显而易见”和“万无一失”的优化反而使程序运行得更慢时，我们也感到惊讶。现在很明显，我们必须更详细地调查性能关键函数。
- en: 'We already have the tools for that: the overall program is exercising this
    code, and we have ways to measure its performance. But we''re not really interested
    in the rest of the program anymore, at least not until we solve the performance
    issues we already identified.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了这样的工具：整个程序正在执行这段代码，并且我们有方法来衡量它的性能。但我们现在真的对程序的其余部分不感兴趣了，至少在我们解决了已经确定的性能问题之前是这样。
- en: 'Working with a large program to optimize just a few lines of code has the following
    two major drawbacks:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化程序中的几行代码而使用大型程序有以下两个主要缺点：
- en: First of all, even though the few lines are identified as performance-critical,
    it doesn't mean the rest of the program takes no time at all (in our demo example,
    it does, but recall that this example is supposed to represent the entire large
    program you're working on). You may be waiting for hours before the large program
    gets to the interesting point, either because the entire job is that long or because
    the performance-critical function is called only under certain conditions, like
    a particular request coming over the net.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，即使少数行被确定为性能关键，也并不意味着整个程序根本不需要时间（在我们的演示示例中确实如此，但请记住，这个示例应该代表您正在处理的整个大型程序）。在整个工作或性能关键函数仅在特定条件下调用时，您可能需要等待几个小时，比如特定请求通过网络传输。
- en: 'Second, working with a large program just takes more time: the compile and
    link times are longer, your work may be interacting with code changes made by
    other programmers, even editing takes longer because all the extra code is distracting.
    The bottom line, at this point, is we are interested in just one function, so
    we would like to be able to call this function and measure the results. This is
    where micro-benchmarking comes in.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，处理大型程序需要更多时间：编译和链接时间更长，您的工作可能正在与其他程序员所做的代码更改进行交互，甚至编辑时间更长，因为所有额外的代码会分散注意力。总之，在这一点上，我们只对一个函数感兴趣，所以我们希望能够调用这个函数并测量结果。这就是微基准测试的用武之地。
- en: Basics of micro-benchmarking
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微基准测试的基础知识
- en: 'In a nutshell, micro-benchmarking is just a way to do what we just said we
    want to do: run a small chunk of code and measure its performance. In our case,
    it''s just one function, but it could be a more complex code fragment, too. What''s
    important is that this code fragment could be invoked easily with the right starting
    conditions: for a function, it''s just the arguments, but for a larger fragment,
    a more complex internal state may have to be recreated.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，微基准测试只是我们刚才说我们想要做的事情的一种方式：运行一小段代码并测量其性能。在我们的情况下，只是一个函数，但也可以是一个更复杂的代码片段。重要的是，这个代码片段可以在正确的起始条件下轻松调用：对于一个函数，只是参数，但对于一个更大的片段，可能需要重新创建一个更复杂的内部状态。
- en: 'In our case, we know exactly what arguments we need to call the string comparison
    function with – we constructed the arguments ourselves. The second thing we need
    is to measure the execution time; we have already seen the timers that can be
    used for this purpose. With this in mind, we can write a very simple benchmark
    that calls several variants of our string comparison function and reports the
    results:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们知道我们需要使用哪些参数调用字符串比较函数 - 我们自己构造了参数。我们需要的第二件事是测量执行时间；我们已经看到可以用于此目的的定时器。考虑到这一点，我们可以编写一个非常简单的基准测试，调用我们的字符串比较函数的几个变体并报告结果：
- en: '[PRE25]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this program, we test only two of the comparison functions, both without
    the end of loop condition, one with an `int` index and the other with an `unsigned
    int` index. Also, we will not be repeating the `#include` and `using` statements
    in the subsequent listings. The input data is just a long string filled with the
    same character from start to end, so the substring comparison will run all the
    way to the end of the string. We can, of course, benchmark on any data we need,
    but let's start with the simplest case.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个程序中，我们只测试了两个比较函数，都没有循环结束条件，一个使用`int`索引，另一个使用`unsigned int`索引。此外，我们不会在后续列表中重复`#include`和`using`语句。输入数据只是一个从头到尾填满相同字符的长字符串，因此子字符串比较将一直运行到字符串的末尾。当然，我们可以在任何需要的数据上进行基准测试，但让我们从最简单的情况开始。
- en: 'The program looks like it will do exactly what we need… at least until we run
    it:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序看起来将完全符合我们的需求...至少直到我们运行它为止：
- en: '![Figure 2.22'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.22'
- en: '](img/Figure_2.22_B16229.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.22_B16229.jpg)'
- en: Figure 2.22
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22
- en: 'Zero time, either way. What went wrong? Perhaps, the execution time for a single
    function call is simply too fast to be measured? This is not a bad guess, and
    we can address this problem easily: if one call is too short, we just need to
    make more calls:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 零时间，无论如何。出了什么问题？也许，单个函数调用的执行时间太快，无法测量？这不是一个坏猜测，我们可以很容易地解决这个问题：如果一个调用时间太短，我们只需要进行更多的调用：
- en: '[PRE26]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can increase the number of iterations `NI` until we get some results, right?
    Not so fast:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以增加迭代次数`NI`直到获得一些结果，对吗？不要那么快：
- en: '![Figure 2.23'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.23'
- en: '](img/Figure_2.23_B16229.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.23_B16229.jpg)'
- en: Figure 2.23
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.23
- en: 'Too fast, actually, but why? Let us step through the program in the debugger
    and see what it actually did:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上太快了，但为什么？让我们在调试器中逐步执行程序，看看它实际上做了什么：
- en: '![Figure 2.24'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.24'
- en: '](img/Figure_2.24_B16229.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.24_B16229.jpg)'
- en: Figure 2.24
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.24
- en: We set the breakpoint in `main`, so the program is paused as soon as it launches,
    then we execute the program line by line… except, that's not all the lines we
    have written! Where is the rest of the code? We can guess that the compiler is
    to blame, but why? We need to learn more about compiler optimizations.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`main`中设置断点，因此程序一启动就会暂停，然后我们逐行执行程序...除了我们编写的所有行之外！其他代码在哪里？我们可以猜想是编译器的问题，但为什么？我们需要更多了解编译器优化。
- en: Micro-benchmarking and compiler optimizations
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微基准测试和编译器优化
- en: 'To understand this mystery of the missing code, we have to take a fresh look
    at what the missing code actually does. It creates some strings, calls the comparison
    functions, and … there is no "and." Nothing else happens. Other than watching
    the code scroll by in the debugger, how would you know, just by running this program,
    if this code was executed? You cannot. The compiler has arrived at the same conclusion,
    way ahead of us. Since the programmer cannot tell the difference between executing
    and not executing a part of the code, the compiler has optimized it out. But wait,
    you say, the programmer *can* tell the difference: it takes much less time to
    do nothing than to do something. And here we come to a very important concept
    from the C++ standard that is critical to the understanding of compiler optimizations:
    the observable behavior.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这个缺失代码的奥秘，我们必须重新审视缺失代码实际上做了什么。它创建了一些字符串，调用了比较函数，然后……没有“然后”。除了在调试器中观察代码滚动之外，通过运行这个程序，你怎么知道这段代码是否被执行？你无法知道。编译器已经比我们提前到达了同样的结论。由于程序员无法区分执行和不执行代码的差异，编译器对其进行了优化。但是等等，你说，程序员*可以*区分：什么都不做比做一些事情要花费更少的时间。在这里，我们来到了C++标准中非常重要的一个概念，这对于理解编译器优化至关重要：可观察行为。
- en: 'The standard says that the compiler can make whatever changes it wants to the
    program as long as the effect of these changes does not alter the observable behavior.
    The standard is also very specific about what constitutes the observable behavior:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 标准规定，只要这些更改的效果不会改变可观察行为，编译器可以对程序进行任何更改。标准还非常明确地规定了什么构成了可观察行为：
- en: Accesses (reads and writes) to volatile objects occur strictly according to
    the semantics of the expressions in which they occur. In particular, they are
    not reordered with respect to other volatile accesses on the same thread.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对volatile对象的访问（读取和写入）严格按照它们出现的表达式的语义进行。特别是，它们不会与同一线程上的其他volatile访问重新排序。
- en: At program termination, data written to files is exactly as if the program was
    executed as written.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在程序终止时，写入文件的数据与按原样执行程序时完全相同。
- en: Prompting text that is sent to interactive devices will be shown before the
    program waits for input. More generally, input and output operations cannot be
    omitted or rearranged.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送到交互设备的提示文本将在程序等待输入之前显示。更一般地说，输入和输出操作不能被省略或重新排列。
- en: 'There are a few exceptions to the preceding rules, none of which apply to our
    program. The compiler must follow the *as-if* rule: the optimized program should
    show the same observable behavior as if it was executed exactly as written, line
    for line. Now note what is not included in the preceding list: running the program
    under debugger does not constitute observable behavior. Neither does execution
    time, otherwise, no program could be optimized to make it faster.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的规则有一些例外情况，但都不适用于我们的程序。编译器必须遵循“as-if”规则：优化后的程序应该表现出与按行执行完全相同的可观察行为。现在注意一下前面的列表中没有包括的内容：在调试器下运行程序并不构成可观察行为。执行时间也不构成可观察行为，否则，没有程序可以被优化以使其更快。
- en: 'With this new understanding, let us take another look at the benchmark code:
    the results of the string comparison do not affect the observable behavior in
    any way, so the entire computation can be done or omitted at the compiler''s discretion.
    This observation also gives us a way to fix this problem: we have to make sure
    that the result of the computation affects the observable behavior. One way to
    do it is to take advantage of the volatile semantics described previously:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这种新的理解，让我们再来看一下基准代码：字符串比较的结果以任何方式都不会影响可观察行为，因此整个计算可以由编译器自行决定是否执行或省略。这一观察还给了我们解决这个问题的方法：我们必须确保计算的结果影响可观察行为。其中一种方法是利用先前描述的volatile语义：
- en: '[PRE27]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now the result of every call to the comparison functions is written into a
    volatile variable, and, according to the standard, these values must be correct
    and written in the right order. The compiler now has no choice but to call our
    comparison functions and get the results. The way these results are computed can
    still be optimized as long as the result itself does not change. This is exactly
    what we want: we want the compiler to generate the best code for the comparison
    functions, hopefully, the same code it generates in the real program. We just
    don''t want it to drop these functions altogether. Running this benchmark shows
    that we have finally achieved our goal, the code is definitely running:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每次调用比较函数的结果都被写入一个volatile变量中，并且根据标准，这些值必须是正确的并按正确的顺序写入。编译器现在别无选择，只能调用我们的比较函数并获取结果。只要结果本身不改变，这些结果的计算方式仍然可以被优化。这正是我们想要的：我们希望编译器为比较函数生成最佳代码，希望它生成的代码与实际程序中生成的代码相同。我们只是不希望它完全删除这些函数。运行这个基准测试表明我们终于实现了我们的目标，代码肯定在运行：
- en: '![Figure 2.25'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.25'
- en: '](img/Figure_2.25_B16229.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.25_B16229.jpg)'
- en: Figure 2.25
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.25
- en: The first value is the runtime of the `compare1()` function, which uses `int`
    indices, and it is indeed slightly faster than the `unsigned int` version (but
    don't put too much faith into these results just yet).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个值是`compare1()`函数的运行时间，它使用`int`索引，并且确实比`unsigned int`版本稍快（但不要对这些结果过于信任）。
- en: 'The second option for entangling our computations with some observable behavior
    is to simply print out the results. However, this can get a bit tricky. Consider
    the straightforward attempt:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的计算与一些可观察行为纠缠在一起的第二个选项是简单地打印出结果。然而，这可能会有点棘手。考虑直接的尝试：
- en: '[PRE28]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Note that the variable `sink` is no longer volatile, but instead, we write
    out its final value. This does not work as well as you might expect:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，变量`sink`不再是volatile，而是我们写出它的最终值。这并不像你期望的那样有效：
- en: '![Figure 2.26'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.26'
- en: '](img/Figure_2.26_B16229.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.26_B16229.jpg)'
- en: Figure 2.26
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.26
- en: 'The execution time of the function `compare2()` is in the same ballpark as
    before, but `compare1()` appears to be much faster now. Of course, by now, we
    know enough to understand that this "improvement" is illusory: the compiler simply
    figured out that the result of the first call is overwritten by the second call
    and, therefore, does not affect the observable behavior.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`compare2()`的执行时间与以前差不多，但`compare1()`现在似乎快得多。当然，到现在为止，我们已经知道足够多，以理解这种“改进”是虚幻的：编译器只是简单地发现第一次调用的结果被第二次调用覆盖，因此不会影响可观察的行为。
- en: 'This brings up an interesting question: why didn''t the compiler figure out
    that the second iteration of the loop gives the same result as the first one and
    optimized away every call to the comparison functions except the first one, for
    each function? It could have, if the optimizer were advanced enough, and then
    we would have to do more to get around it: generally, compiling the functions
    as separate compilation units is enough to prevent any such optimizations, although
    some compilers are capable of whole-program optimizations, so you may have to
    turn them off when running micro-benchmarks.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这带来了一个有趣的问题：为什么编译器没有发现循环的第二次迭代给出了与第一次相同的结果，并优化掉了除第一次之外的每次对比函数调用？如果优化器足够先进，它本来可以这样做，然后我们将不得不做更多工作来解决这个问题：通常，将函数编译为单独的编译单元足以防止任何此类优化，尽管一些编译器能够进行整个程序的优化，因此在运行微基准测试时可能需要关闭它们。
- en: 'Note also that our two benchmark runs have produced somewhat different values
    even for the execution time of the function that wasn''t optimized away. If you
    run the program again, you will get yet another value, also somewhere in the same
    range, but slightly different. This isn''t good enough: we need more than just
    ballpark figures. We could run the benchmark several times, figure out how many
    repetitions we need, and compute the average time, but we don''t have to do it
    manually. We don''t have to write code to do this either, because such code has
    already been written and is available as one of several micro-benchmarking tools.
    We are going to learn about one such tool now.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，我们的两次基准运行即使对于未被优化的函数的执行时间也产生了略有不同的值。如果再次运行程序，您将得到另一个值，也在同一范围内，但略有不同。这还不够好：我们需要的不仅仅是大致的数字。我们可以多次运行基准测试，找出我们需要多少次重复，并计算平均时间，但我们不必手动执行。我们也不必编写代码来执行此操作，因为这样的代码已经被编写并作为几种微基准测试工具之一可用。我们现在将学习其中一种工具。
- en: Google Benchmark
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谷歌基准测试
- en: Writing a micro-benchmark involves a lot of boilerplate code, mostly for measuring
    time and accumulating results. Furthermore, this code is critical for the accuracy
    of the measurements. There are several good-quality micro-benchmark libraries
    available. In this book, we use the Google Benchmark library. The instructions
    for downloading and installing the library can be found in the *Technical requirements*
    section. In this section, we will describe how to use the library and interpret
    the results.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 编写微基准测试涉及大量样板代码，主要用于测量时间和累积结果。此外，此代码对于测量的准确性至关重要。有几个高质量的微基准库可用。在本书中，我们使用谷歌基准库。有关下载和安装库的说明可以在*技术要求*部分找到。在本节中，我们将描述如何使用该库并解释结果。
- en: 'To use the Google Benchmark library, we have to write a small program that
    will prepare the inputs and execute the code we want to benchmark. This is a basic
    Google Benchmark program for measuring the performance of one of our string comparison
    functions:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用谷歌基准库，我们必须编写一个小程序，准备输入并执行我们想要进行基准测试的代码。这是一个用于测量我们的字符串比较函数性能的基本谷歌基准程序：
- en: '[PRE29]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Every Google benchmark program must include the header for the library, `benchmark/benchmark.h`,
    plus, of course, any other headers needed to compile the code we want to measure
    (they are omitted in the preceding listing). The program itself consists of a
    number of benchmark "fixtures," each one is just a function with a specific signature:
    it takes one parameter, `benchmark::State`, by reference, and returns nothing.
    The parameter is an object provided by the Google Benchmark library to interface
    with the library itself.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 每个谷歌基准程序必须包括库的头文件`benchmark/benchmark.h`，当然，还有任何其他编译所需的头文件（它们在前面的清单中被省略了）。程序本身由许多基准“固定装置”组成，每个都只是一个具有特定签名的函数：它通过引用接受一个参数`benchmark::State`，并且不返回任何东西。该参数是由谷歌基准库提供的一个对象，用于与库本身进行交互。
- en: We need one fixture for each code fragment, such as a function that we want
    to benchmark. The first thing we do in each benchmark fixture is to set up the
    data we need to use as inputs for the code we want to run. More generally, we
    can say that we need to recreate the initial state of this code to represent what
    it would be in the real program. In our case, the input is the string, so we need
    to allocate and initialize the string. We can hardcode the size of the string
    into the benchmark, but there is also a way to pass arguments into a benchmark
    fixture. Our fixture uses one argument, the string length, which is an integer
    accessed as `state.range(0)`. It is possible to pass arguments of other types,
    please refer to the documentation of the Google Benchmark library for details.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为每个代码片段（例如我们想要进行基准测试的函数）创建一个固定装置。在每个基准装置中，我们要做的第一件事是设置我们需要用作代码输入的数据。更一般地说，我们可以说我们需要重新创建此代码的初始状态，以表示在真实程序中的情况。在我们的情况下，输入是字符串，因此我们需要分配和初始化字符串。我们可以将字符串的大小硬编码到基准测试中，但也有一种方法可以将参数传递给基准测试装置。我们的装置使用一个参数，即字符串长度，它是一个整数，通过`state.range(0)`访问。可以传递其他类型的参数，请参阅谷歌基准库的文档了解详情。
- en: 'The entire setup is free in the sense of the benchmark measurements: we do
    not measure the time it takes to prepare the data. The code whose execution time
    is measured goes into the body of the benchmarking loop, `for (auto _ : state)
    { … }`. In the older examples, you can find this loop written as `while (state.KeepRunning())
    { … }`, which does the same thing but slightly less efficiently. The library measures
    the time it takes to do each iteration and decides how many iterations it wants
    to do to accumulate enough measurements to reduce the random noise that is inevitable
    in measuring the run time of a small fragment of code. Only the run time of the
    code inside the benchmarking loop is measured.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '整个设置在基准测试测量方面是自由的：我们不测量准备数据所需的时间。被测量执行时间的代码放入基准测试循环的主体中，`for (auto _ : state)
    { … }`。在旧的例子中，您可以找到这个循环写成`while (state.KeepRunning()) { … }`，它做的事情是一样的，但效率稍低。该库测量每次迭代所需的时间，并决定要做多少次迭代以积累足够的测量结果，以减少在测量代码片段的运行时间时不可避免的随机噪音。只有基准测试循环内部的代码的运行时间被测量。'
- en: The loop exits when the measurement is accurate enough (or a certain time limit
    is reached). After the loop, we usually have some code to clean up the data that
    was initialized earlier, although in our case, this cleanup is handled by the
    destructor of the `std::unique_ptr` object. We can also make calls on the state
    object to affect what results are reported by the benchmark. The library always
    reports the average time it takes to run one iteration of the loop, but sometimes
    it is more convenient to express the program speed in some other way. For our
    string comparison, one option is to report the number of characters per second
    processed by the code. We can do it by calling `state.SetItemsProcessed()` with
    the number of characters we processed during the entire run, `N` characters per
    iteration (or `2*N` if you want to count both substrings; *items* can count whatever
    you define as a unit of processing).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当测量足够准确时（或达到一定的时间限制）循环退出。循环之后，我们通常有一些代码来清理之前初始化的数据，尽管在我们的情况下，这个清理是由`std::unique_ptr`对象的析构函数处理的。我们还可以调用状态对象来影响基准测试报告的结果。该库总是报告运行循环的一次迭代所需的平均时间，但有时以其他方式表达程序速度更方便。对于我们的字符串比较，一种选择是报告代码每秒处理的字符数。我们可以通过调用`state.SetItemsProcessed()`来实现，其中包括我们在整个运行过程中处理的字符数，每次迭代处理`N`个字符（或者如果要计算两个子字符串，则为`2*N`；*items*可以计算您定义为处理单位的任何内容）。
- en: 'Nothing is going to happen just because we defined a benchmark fixture, we
    need to register it with the library. This is done using the `BENCHMARK` macro;
    the argument of the macro is the name of the function. By the way, there is nothing
    special about that name, it can be any valid C++ identifier; that ours begins
    with `BM_` is merely a naming convention we follow in this book. The `BENCHMARK`
    macro is also where you will specify any arguments you want to pass to the benchmark
    fixture. The arguments and other options affecting the benchmark are passed using
    the overloaded arrow operator, for example:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅定义了一个基准测试装置并不会有任何作用，我们需要在库中注册它。这是使用`BENCHMARK`宏完成的；宏的参数是函数的名称。顺便说一下，该名称并没有什么特别之处，它可以是任何有效的C++标识符；我们的名称以`BM_`开头只是我们在本书中遵循的命名约定。`BENCHMARK`宏也是您将指定要传递给基准测试装置的任何参数的地方。使用重载的箭头运算符传递基准测试的参数和其他选项，例如：
- en: '[PRE30]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This line registers the benchmark fixture `BM_loop_int` with one argument, `1<<20`,
    that can be retrieved inside the fixture by calling `state.range(0)`. We will
    see more examples of different arguments throughout this book, and even more can
    be found in the library documentation.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码使用一个参数`1<<20`注册了基准测试装置`BM_loop_int`，可以通过调用`state.range(0)`在装置内检索到。在本书中，我们将看到更多不同参数的示例，甚至可以在库文档中找到更多。
- en: You will also notice that there is no `main()` in the preceding code listing;
    instead, there is another macro, `BENCHMARK_MAIN()`. The `main()` is not written
    by us but provided by the Google Benchmark library, and it does all the necessary
    work of setting up the benchmarking environment, registering the benchmarks, and
    executing them.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 您还会注意到在前面的代码清单中没有`main()`；相反，有另一个宏，`BENCHMARK_MAIN()`。`main()`不是我们编写的，而是由Google
    Benchmark库提供的，它完成了设置基准测试环境、注册基准测试和执行基准测试的所有必要工作。
- en: 'Let us return for a moment to the code we want to measure and examine it more
    closely:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们想要测量的代码并更仔细地检查一下：
- en: '[PRE31]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `benchmark::DoNotOptimize(…)` wrapper function plays a role similar to
    the `volatile` sink we have used before: it ensures that the compiler does not
    optimize away the entire call to `compare_int()`. Note that it does not actually
    turn off any optimizations; in particular, the code inside the parentheses is
    optimized as usual, which is what we want. All it does is tells the compiler that
    the result of the expression, in our case, the return value of the comparison
    function, should be considered "used" as if it was printed out and cannot be simply
    discarded.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`benchmark::DoNotOptimize(…)`包装函数的作用类似于我们之前使用的`volatile` sink：它确保编译器不会优化掉对`compare_int()`的整个调用。请注意，它实际上并没有关闭任何优化；特别是括号内的代码通常会像我们想要的那样进行优化。它所做的只是告诉编译器，表达式的结果，在我们的情况下是比较函数的返回值，应该被视为“已使用”，就像它被打印出来一样，不能简单地被丢弃。'
- en: 'We are now ready to compile and run our first micro-benchmark:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备编译和运行我们的第一个微基准测试：
- en: '![Figure 2.27'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.27'
- en: '](img/Figure_2.27_B16229.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.27_B16229.jpg)'
- en: Figure 2.27
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.27
- en: The compile line now has to list the path to the Google Benchmark `include`
    files and the library; several additional libraries are needed by the Google Benchmark
    library `libbenchmark.a`. Once invoked, the benchmark program prints some information
    about the system we are running on, then it executes every fixture that was registered,
    with all their arguments. We get one line of output for every benchmark fixture
    and a set of arguments; the report includes the average real time and the average
    CPU time of a single execution of the body of the benchmark loop, how many times
    the loop was executed, and any other statistics we have attached to the report
    (in our case, the number of characters per second processed by the comparison,
    over 2G characters per second).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 现在编译行必须列出Google基准`include`文件和库的路径；Google基准库`libbenchmark.a`需要几个额外的库。一旦调用，基准程序会打印一些关于我们正在运行的系统的信息，然后执行所有已注册的fixture及其所有参数。对于每个基准fixture和一组参数，我们会得到一行输出；报告包括每次基准循环体的平均实际时间和平均CPU时间，循环执行的次数，以及我们附加到报告的任何其他统计信息（在我们的情况下，每秒处理的字符数，超过2G字符每秒）。
- en: 'How much do these numbers vary from run to run? The benchmark library can calculate
    that for us if we enable the statistics collection with the right command-line
    arguments. For example, to repeat the benchmark ten times and report the results,
    we would run the benchmark like so:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字每次运行时有多大的变化？如果我们使用正确的命令行参数启用统计信息收集，基准库可以为我们计算出来。例如，要重复进行基准测试十次并报告结果，我们会这样运行基准测试：
- en: '![Figure 2.28'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.28'
- en: '](img/Figure_2.28_B16229.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.28_B16229.jpg)'
- en: Figure 2.28
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.28
- en: It looks like the measurements are pretty accurate; the standard deviation is
    quite small. Now we can benchmark the different variants of the substring comparison
    function against each other and figure out which one is the fastest. But before
    we do that, I have to let you in on a big secret.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来测量结果相当准确；标准偏差相当小。现在我们可以对比不同变体的子字符串比较函数，并找出哪一个是最快的。但在我们这样做之前，我必须告诉你一个大秘密。
- en: Micro-benchmarks are lies
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微基准测试是谎言
- en: You will discover it soon enough as you start running more and more micro-benchmarks.
    At first, the results make sense, you're making good optimizations, and everything
    looks great. Then you make some small change and get a very different result.
    You go back to investigate, and now the same tests you already ran give very different
    numbers. Eventually, you come up with two almost identical tests that show completely
    opposite results, and you realize that you just can't trust micro-benchmarks.
    It will destroy your faith in micro-benchmarks, and the only thing I can do about
    it is to destroy it now, in a controlled manner, while we can still salvage something
    from the wreckage.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始运行越来越多的微基准测试时，你很快就会发现这一点。起初，结果是合理的，你进行了良好的优化，一切看起来都很好。然后你做了一些小改变，得到了一个完全不同的结果。你回去调查，现在你已经运行过的相同测试给出了完全不同的数字。最终，你找到了两个几乎相同的测试，结果完全相反，你意识到你不能相信微基准测试。它会摧毁你对微基准测试的信心，我现在唯一能做的就是以一种可控的方式摧毁它，这样我们还能从废墟中挽救一些东西。
- en: The fundamental problem with micro-benchmarks and any other detailed performance
    measurements is that they strongly depend on the context. As you read through
    the rest of the book, you will understand more and more that the performance behavior
    of modern computers is very complex. The results do not just depend on what the
    code is doing, but also on what the rest of the system is doing at the same time,
    on what it was doing earlier, and on the path the execution took through the code
    before it got to the point of interest. None of these things are replicated in
    a micro-benchmark.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 微基准测试和任何其他详细的性能测量的根本问题是它们强烈依赖于上下文。当你阅读本书的其余部分时，你会越来越明白现代计算机的性能行为是非常复杂的。结果不仅仅取决于代码在做什么，还取决于系统的其余部分在同一时间在做什么，以及之前它在做什么，以及执行路径在到达感兴趣点之前经过的情况。这些事情在微基准测试中都没有被复制。
- en: 'Instead, the benchmark has its own context. The authors of the benchmarking
    libraries are not ignorant of this problem, and they try to counter it the best
    they can. For example, unseen to you, the Google Benchmark library does a *burn-in*
    on every test: the first few iterations may have very different performance characteristics
    from the rest of the run, so the library ignores the initial measurements until
    the results "settle." But this also defines a particular context, probably different
    from the real program where every call to the function is repeated only once (on
    the other hand, sometimes we do end up calling the same function with the same
    arguments many times throughout the run of the program, so that could be a different
    context).'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，基准测试有它自己的上下文。基准测试库的作者并不对这个问题一无所知，并且他们尽力去对抗它。例如，你看不到的是，Google基准库对每个测试进行了*烧入*：最初的几次迭代可能具有与运行的其余部分非常不同的性能特征，因此库会忽略初始测量，直到结果"稳定"。但这也定义了一个特定的上下文，可能与每次调用函数只重复一次的真实程序不同（另一方面，有时我们确实会在程序运行中多次使用相同的参数调用相同的函数，所以这可能是一个不同的上下文）。
- en: There is nothing you can do to faithfully reproduce the real environment of
    a large program in every detail before running the benchmark. But some details
    are more important than others. In particular, the greatest source of contextual
    differences, by far, is the compiler, or, more specifically, the optimizations
    it does on a real program versus the micro-benchmark. We have already seen how
    the compiler stubbornly tries to figure out that the entire micro-benchmark is
    basically a very slow way of doing nothing useful (or at least nothing observable),
    and replace it with a much faster way of doing the same. The `DoNotOptimize` wrapper
    we used earlier gets us around some of the problems caused by the compiler optimizations.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行基准测试之前，没有什么可以忠实地复制大型程序的真实环境的每一个细节。但是有些细节比其他细节更重要。特别是，上下文差异的最大来源远远是编译器，或者更具体地说，是编译器在真实程序与微基准测试上所做的优化。我们已经看到编译器如何顽固地试图弄清楚整个微基准测试基本上是一种非常缓慢的无用操作（或者至少是不可观察的无用操作），并用更快的方式替换它。我们之前使用的`DoNotOptimize`包装器可以解决一些由编译器优化引起的问题。
- en: However, there is still the possibility that the compiler may, for example,
    figure out that every call to the function returns the same result. Also, because
    the function definition is in the same file as the call site, the compiler can
    inline the entire function and use any information it can gather about the arguments
    to optimize the function code. Such optimizations would not be available in the
    general case when the function is called from another compilation unit.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仍然存在这样的可能性，即编译器可能会发现每次调用函数都返回相同的结果。此外，由于函数定义与调用点在同一个文件中，编译器可以内联整个函数，并使用它可以收集到的关于参数的任何信息来优化函数代码。当函数从另一个编译单元调用时，在一般情况下这样的优化是不可用的。
- en: 'To represent the real situation more accurately in our micro-benchmark, we
    can move the comparison function into its own file and compile it separately.
    Now we have one file (compilation unit) with just the benchmark fixtures:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更准确地在我们的微基准测试中表示真实情况，我们可以将比较函数移动到它自己的文件中，并将其单独编译。现在我们有一个文件（编译单元），其中只有基准测试的固定装置：
- en: '[PRE32]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can compile the files separately and link them together (any full-program
    optimizations must be turned off). Now we have a reasonable expectation that the
    compiler is not generating some special reduced version of the substring comparison
    because of what it figured out about the arguments we use in our benchmark. With
    this simple precaution alone, the results are much more consistent with what we
    observed when we profiled the entire program:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以分别编译文件，然后将它们链接在一起（任何完整程序的优化都必须关闭）。现在我们有一个合理的期望，即编译器没有生成某种特殊的减少版本的子字符串比较，因为它根据我们在基准测试中使用的参数所得出的结论。仅凭这个简单的预防措施，结果就更加符合我们在对整个程序进行性能分析时观察到的情况：
- en: '![Figure 2.29'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.29'
- en: '](img/Figure_2.29_B16229.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.29_B16229.jpg)'
- en: Figure 2.29
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.29
- en: The initial version of the code used the `unsigned int` index and a boundary
    condition in the loop (the last line); simply dropping that boundary condition
    check as entirely unnecessary results in a surprising performance degradation
    (the middle line); finally, changing the index to a `signed int` recovers the
    lost performance and even improves it (the first line).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的初始版本使用了`unsigned int`索引和循环中的边界条件（最后一行）；简单地删除那个完全不必要的边界条件检查导致了令人惊讶的性能下降（中间行）；最后，将索引更改为`signed
    int`恢复了丢失的性能，甚至提高了性能（第一行）。
- en: Compiling the code fragments separately is usually enough to avoid any unwanted
    optimizations. Less commonly, you may find that the compiler does different optimizations
    to a particular chunk of code depending on what else is in the same file. This
    could be simply a bug in the compiler, but it can also be a result of some heuristic
    that is, in the experience of the compiler writers, more often right than not.
    If you observe that the results depend on some code that is not executed at all,
    only compiled, this may be the reason. One solution is to use the compilation
    unit from the real program and just call the function that you want to benchmark.
    Of course, you will have to satisfy compilation and link dependencies, so here
    is yet another reason to write modular code and minimize dependencies.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将代码片段分别编译就足以避免任何不需要的优化。不太常见的是，您可能会发现编译器对同一文件中的特定代码块进行不同的优化，这取决于文件中还有什么其他内容。这可能只是编译器中的一个错误，但也可能是某种启发式的结果，在编译器编写者的经验中，这种启发式更常常是正确的。如果您观察到结果取决于根本没有执行的某些代码，只是编译了的代码，这可能就是原因。一个解决方案是使用真实程序中的编译单元，然后只调用您想要进行基准测试的函数。当然，您将不得不满足编译和链接的依赖关系，这就是编写模块化代码和最小化依赖关系的另一个原因。
- en: 'The other source of the context is the state of the computer itself. Obviously,
    if the entire program ran out of memory and is cycling pages in and out of swap,
    your small memory benchmark will not be representative of the real problem; on
    the other hand, the problem now is not in the "slow" code, the problem is that
    too much memory is consumed elsewhere. However, more subtle versions of this context
    dependency exist and may affect the benchmarks. A tell-tale sign of this situation
    is usually this: the results depend on the order in which the tests are executed
    (in the micro-benchmark, it is the order of the `BENCHMARK` macros). If reordering
    the tests or running just a subset of tests gives different results, there is
    some sort of dependency between them. It could be a code dependency, often as
    straightforward as data accumulation in some global data structure. Or it could
    be a subtle dependency on the hardware state. Those are much harder to figure
    out, but you will learn about some situations that lead to such dependencies later
    in this book.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个上下文的来源是计算机本身的状态。显然，如果整个程序耗尽了内存并且正在在交换区中循环页面，您的小内存基准测试将无法代表真实问题；另一方面，问题现在不在于“慢”代码，问题在于其他地方消耗了太多内存。然而，这种上下文依赖的更微妙的版本存在，并可能影响基准测试。通常这种情况的一个显著迹象是：结果取决于测试执行的顺序（在微基准测试中，是`BENCHMARK`宏的顺序）。如果重新排序测试或仅运行一部分测试会产生不同的结果，那么它们之间存在某种依赖关系。这可能是代码依赖，通常是一些全局数据结构中的数据累积。或者它可能是对硬件状态的微妙依赖。这些更难以弄清楚，但您将在本书的后面学习到一些导致这种依赖的情况。
- en: 'Finally, there is a major source of context dependency that is entirely in
    your hands (which does not necessarily make it easy to avoid, but at least possible).
    It is the dependency on the state of your program. We already had to deal with
    the most obvious aspect of such dependency: the inputs to the code we want to
    benchmark. Sometimes, the inputs are known or can be reconstructed. Often, the
    performance problem happens only for certain kinds of inputs, and we don''t know
    what is so special about them until we analyze the performance of the code with
    these specific inputs, which is exactly what we were trying to do with the micro-benchmark
    in the first place. In such cases, it is often the easiest to capture the inputs
    from the real run of the real program, store them in a file, and use them to recreate
    the state of the code we''re measuring. This input could be as simple as a collection
    of data or as complex as a sequence of events that need to be recorded and "played
    back" to an event handler to reproduce the desired behavior.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有一个主要的上下文依赖来源完全掌握在您手中（这并不一定意味着容易避免，但至少是可能的）。这是对程序状态的依赖。我们已经不得不处理这种依赖的最明显方面：我们想要对代码进行基准测试的输入。有时，输入是已知的或可以重建的。通常，性能问题只发生在某些类型的输入下，我们不知道它们有何特殊之处，直到我们分析具有这些特定输入的代码的性能，这正是我们一开始尝试用微基准测试来做的。在这种情况下，通常最容易的方法是从真实程序的真实运行中捕获输入，将它们存储在文件中，并使用它们来重新创建我们正在测量的代码的状态。这个输入可能是简单的数据集合，也可能是需要记录和“回放”到事件处理程序以重现所需行为的事件序列。
- en: 'The more complex the state we need to reconstruct is, the harder it is to reproduce
    the performance behavior of the real program in a partial benchmark. Note that
    this problem somewhat resembles the problem of writing unit tests: they, too,
    are much harder to write if the program cannot be broken up into smaller units
    with a simpler state. Once again, we see the advantages of a well-designed software
    system: a codebase with good unit test coverage is usually much easier to micro-benchmark,
    piece by piece.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要重建的状态越复杂，就越难在部分基准测试中重现真实程序的性能行为。请注意，这个问题在某种程度上类似于编写单元测试的问题：如果程序无法分解为具有简单状态的较小单元，编写单元测试也会更加困难。再次看到了良好设计的软件系统的优势：具有良好单元测试覆盖率的代码库通常更容易进行微基准测试，逐步进行测试。
- en: As you were warned when we started this section, it is meant to partially restore
    your faith in micro-benchmarks. They can be a useful tool, as we will see many
    times in this book. They can also lead you astray, sometimes very far. You now
    understand some of the reasons why and are better prepared to try to recover the
    useful bits of information from the results, rather than giving up on small-scale
    benchmarking altogether.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始本节时，您已经被警告，这部分内容旨在部分恢复您对微基准测试的信心。它们可以是一个有用的工具，正如我们在本书中多次看到的那样。它们也可能误导您，有时甚至误导得很远。现在您了解了一些原因，更有准备去尝试从结果中恢复有用的信息，而不是完全放弃小规模基准测试。
- en: None of the tools we have presented in this chapter is a solution to every problem;
    they are not meant to be. You can achieve the best results by using these tools
    to collect information in various ways, so they complement each other.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍的工具都不是解决所有问题的解决方案；它们也不是用来解决所有问题的。通过使用这些工具以各种方式收集信息，它们可以相互补充，从而实现最佳结果。
- en: Summary
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you have learned perhaps the single most important lesson
    in the entire book: it makes no sense to talk, or even think, about performance
    without referring to specific measurements. The rest is largely craftsmanship:
    we presented several ways to measure performance, starting from the whole program
    and drilling down to a single line of code.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学到了整本书中可能最重要的一课：谈论性能而不参考具体的测量是没有意义的，甚至是不切实际的。其余的内容主要是技艺：我们介绍了几种测量性能的方法，从整个程序开始，逐渐深入到单行代码。
- en: A large high-performance project will see every tool and method you learned
    about in this chapter used more than once. Coarse measurements – benchmarking
    and profiling the entire program or large parts of it – point to the areas of
    the code that require further investigation. Additional rounds of benchmarking
    or the collection of a more detailed profile usually follow. Eventually, you will
    identify the parts of the code that require optimization, and the question becomes,
    *"how do I do this faster?"* At this point, you can use a micro-benchmark or another
    small-scale benchmark to experiment with the code you're optimizing. You may even
    discover that you don't understand as much as you thought about this code and
    need a more detailed analysis of its performance; don't forget that you can profile
    micro-benchmarks!
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 一个大型高性能项目将会看到本章中学到的每种工具和方法被使用不止一次。粗略的测量 - 对整个程序或其大部分进行基准测试和分析 - 指向了需要进一步调查的代码区域。通常会跟随额外的基准测试轮次或更详细的分析。最终，你会确定需要优化的代码部分，问题变成了，“我该如何更快地做到这一点？”在这一点上，你可以使用微基准测试或其他小规模基准测试来尝试优化的代码。你甚至可能会发现你对这段代码的理解并不如你想象的那么多，需要对其性能进行更详细的分析；不要忘记你可以对微基准进行分析！
- en: 'Eventually, you will have a new version of the performance-critical code that
    looks favorable in small benchmarks. Still, do not assume anything: now you have
    to measure the performance of the complete program with your optimizations or
    enhancements. Sometimes, these measurements will confirm your understanding of
    the problem and validate its solution. At other times, you will discover that
    the problem is not what you thought it was, and the optimization, while beneficial
    by itself, does not have the desired effect on the overall program (it may even
    make things worse). You now have a new data point, you can compare the profiles
    of the old and new solutions and look for the answers in the differences this
    comparison reveals.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你将拥有一个在小型基准测试中看起来有利的性能关键代码的新版本。但是，不要假设任何事情：现在你必须测量你的优化或增强对整个程序的性能。有时，这些测量将确认你对问题的理解并验证其解决方案。在其他时候，你会发现问题并不是你所想象的那样，而优化虽然本身有益，但对整个程序的效果并不如预期（甚至可能使情况变得更糟）。现在你有了一个新的数据点，你可以比较旧解决方案和新解决方案的分析，并在这种比较中揭示的差异中寻找答案。
- en: The development and optimization of high-performance programs is almost never
    a linear, step-by-step process. Instead, it has many iterations of going from
    a high-level overview to low-level detailed work and back. In this process, there
    is a role for your intuition; just make sure always to test and confirm your expectations
    because, when it comes to performance, nothing is truly obvious.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 高性能程序的开发和优化几乎从来都不是一个线性的、一步一步的过程。相反，它经历了许多从高层概述到低层详细工作再返回的迭代。在这个过程中，你的直觉起着一定的作用；只是确保始终测试和确认你的期望，因为在性能方面，没有什么是真正明显的。
- en: 'In the next chapter, we will see the solution to the mystery we encountered
    earlier: removing unnecessary code makes the program slower. In order to do this,
    we have to understand how to use the CPU efficiently for maximum performance,
    and the entire next chapter is dedicated to that.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到我们之前遇到的谜团的解决方案：删除不必要的代码会使程序变慢。为了做到这一点，我们必须了解如何有效地利用CPU以获得最佳性能，整个下一章都致力于此。
- en: Questions
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why are performance measurements necessary?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么性能测量是必要的？
- en: Why do we need so many different ways to measure performance?
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们需要这么多不同的性能测量方法？
- en: What are the advantages and limitations of manual benchmarking?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动基准测试的优势和局限性是什么？
- en: How is profiling used to measure performance?
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析如何用于性能测量？
- en: What are the uses of small-scale benchmarking, including micro-benchmarks?
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小规模基准测试，包括微基准测试的用途是什么？
