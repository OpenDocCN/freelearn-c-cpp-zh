- en: Chapter 13
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章
- en: Concurrency
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发
- en: Over the course of the next two chapters we are going to talk about *concurrency*
    and the theoretical background that is required for developing concurrent programs,
    not only in C, but necessarily in other languages as well. As such, these two
    chapters won't contain any C code and instead use pseudo-code to represent concurrent
    systems and their intrinsic properties.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两章中，我们将讨论**并发**以及开发并发程序所需的理论背景，这不仅适用于C语言，也必然适用于其他语言。因此，这两章将不包含任何C代码，而是使用伪代码来表示并发系统和它们的内在属性。
- en: The topic of concurrency, due to its length, has been split into two chapters.
    In this chapter we will be looking at the basic concepts regarding concurrency
    itself, before moving to *Chapter 14*, *Synchronization*, where we will discuss
    concurrency-related issues and the *synchronization* mechanisms used in concurrent
    programs to resolve said issues. The collective end goal of these two chapters
    is to provide you with enough theoretical knowledge to proceed with the multithreading
    and multi-processing topics discussed in upcoming chapters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并发主题的长度，它已经被分为两个章节。在本章中，我们将探讨关于并发的核心基本概念，然后转向第14章，**同步**，我们将讨论与并发相关的问题以及并发程序中用于解决这些问题的**同步**机制。这两个章节的总体目标是为你提供足够的理论知识，以便在后续章节中继续讨论多线程和多进程主题。
- en: The background knowledge we build in this chapter will also be useful when working
    with the *POSIX threading library*, which we use throughout this book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章建立的知识背景在处理我们全书使用的**POSIX线程库**时也将非常有用。
- en: 'In this first chapter on concurrency, we will be working on understanding:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章关于并发的第一部分，我们将致力于理解：
- en: How parallel systems differ from concurrent systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行系统与并发系统的区别
- en: When we need concurrency
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们需要并发时
- en: What a *task scheduler* is, and what the widely used scheduling algorithms are
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务调度器**是什么，以及广泛使用的调度算法有哪些'
- en: How a concurrent program is run and what the interleavings are
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发程序是如何运行的以及什么是交错
- en: What a shared state is and how various tasks can access it
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享状态是什么以及各种任务如何访问它
- en: Let's start our look into concurrency by giving an introduction to the concept,
    and understanding broadly what it means for us.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从对并发概念的介绍开始，广泛地了解它对我们意味着什么。
- en: Introducing concurrency
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍并发
- en: Concurrency simply means having multiple pieces of logic within a program being
    executed simultaneously. Modern software systems are often concurrent, as programs
    need to run various pieces of logic at the same time. As such, concurrency is something
    that every program today is using to a certain extent.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 并发简单来说就是程序中有多个逻辑部分同时执行。现代软件系统通常是并发的，因为程序需要同时运行多个逻辑部分。因此，并发是今天每个程序都在一定程度上使用的。
- en: We can say that concurrency is a powerful tool that lets you write programs
    that can manage different tasks at the same time, and the support for it usually
    lies in the kernel, which is at the heart of the operating system.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说，并发是一种强大的工具，它允许你编写能够同时管理不同任务的程序，并且对它的支持通常位于内核中，这是操作系统的核心。
- en: There are numerous examples in which an ordinary program manages multiple jobs
    simultaneously. For example, you can surf the web while downloading files. In
    this case, tasks are being executed in the context of the browser process concurrently.
    Another notable example is in a *video streaming* scenario, such as when you are
    watching a video on YouTube. The video player might be in the middle of downloading
    future chunks of the video while you are still watching previously downloaded
    chunks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多例子表明，一个普通程序可以同时管理多个任务。例如，你可以在下载文件的同时上网冲浪。在这种情况下，任务是在浏览器进程的上下文中并发执行的。另一个值得注意的例子是在**视频流**场景中，比如你在YouTube上观看视频时。视频播放器可能正在下载视频的后续片段，而你仍在观看之前下载的片段。
- en: Even simple word-processing software has several concurrent tasks running in
    the background. As I write this chapter on Microsoft Word, a spell checker and
    a formatter are running in the background. If you were to be reading this on the
    Kindle application on an iPad, what programs do you think might be running concurrently
    as part of the Kindle program?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是简单的文字处理软件也有几个并发任务在后台运行。当我在这本Microsoft Word上写这一章时，拼写检查器和格式化器正在后台运行。如果你在iPad上的Kindle应用程序上阅读这本书，你认为作为Kindle程序的一部分，可能正在并发运行哪些程序？
- en: Having multiple programs being run at the same time sounds amazing, but as with
    most technology, concurrency brings along with it several headaches in addition
    to its benefits. Indeed, concurrency brings some of the most painful headaches
    in the history of computer science! These "headaches," which we will address later
    on, can remain hidden for a long time, even for months after a release, and they
    are usually hard to find, reproduce, and resolve.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 同时运行多个程序听起来很神奇，但就像大多数技术一样，并发除了带来好处外，还会带来一些头痛的问题。确实，并发给计算机科学历史带来了最痛苦的头痛问题！这些“头痛”问题，我们将在后面讨论，它们可能长时间隐藏，甚至在发布后数月，而且通常很难找到、重现和解决。
- en: We started this section describing concurrency as having tasks being executed
    at the same time, or concurrently. This description implies that the tasks are
    being run in parallel, but that's not strictly true. Such a description is too
    simple, as well as inaccurate, because *being concurrent is different from being
    parallel*, and we have not yet explained the differences between the two. Two
    concurrent programs are different from two parallel programs, and one of our goals
    in this chapter is to shine a light on these differences and give some definitions
    used by the official literature in this field.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节开始时将并发描述为同时执行任务，或者说是并发执行。这种描述意味着任务是在并行运行，但这并不完全正确。这样的描述过于简单，也不准确，因为*并发不同于并行*，我们还没有解释这两者之间的区别。两个并发程序与两个并行程序不同，我们本章的一个目标就是阐明这些区别，并给出该领域官方文献中使用的某些定义。
- en: In the following sections, we are going to explain some basic concurrency-related
    concepts such as *tasks*, *scheduling*, *interleavings*, *state*, and *shared
    state*, which are some of the terms you will come across frequently in this book.
    It's worth pointing out that most of these concepts are abstract and can be applied
    to any concurrent system, not just in C.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将解释一些基本的并发相关概念，例如*任务*、*调度*、*交错*、*状态*和*共享状态*，这些是在这本书中你将经常遇到的术语。值得注意的是，这些概念大多是抽象的，可以应用于任何并发系统，而不仅仅是C语言。
- en: To understand the difference between parallel and concurrent, we are going to
    briefly touch upon parallel systems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解并行和并发之间的区别，我们将简要介绍并行系统。
- en: Note that in this chapter we stick to simple definitions. Our sole purpose is
    to give you a basic idea of how concurrent systems work, as going beyond this
    would be outside of the scope of this book on C.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在本章中，我们坚持简单的定义。我们的唯一目的是给你一个并发系统如何工作的基本概念，因为超出这个范围就不在本书的C语言范畴之内了。
- en: Parallelism
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行
- en: Parallelism simply means having two tasks run at the same time, or *in parallel*.
    The phrase "in parallel" is the key element that differentiates parallelism from
    concurrency. Why is this? Because parallel implies that two things are happening
    simultaneously. This is not the case in a concurrent system; in concurrent systems,
    you need to pause one task in order to let another continue execution. Note that
    this definition can be too simple and incomplete regarding the modern concurrent
    systems, but it is sufficient for us to give you a basic idea.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 并行简单来说就是同时运行两个任务，或者说是*并行运行*。短语“并行运行”是区分并行和并发的关键元素。为什么是这样呢？因为并行意味着两件事情同时发生。在并发系统中并不是这样；在并发系统中，你需要暂停一个任务以便让另一个任务继续执行。请注意，这个定义可能过于简单且不完整，特别是在现代并发系统中，但它足以让我们对基本概念有一个基本的了解。
- en: We meet parallelism regularly in our daily lives. When you and your friend are
    doing two separate tasks simultaneously, those tasks are being done in parallel.
    To have a number of tasks in parallel, we need separate and isolated *processing
    units*, each of which is assigned to a certain task. For instance, in a computer
    system, each *CPU core* is a processor unit that can handle one task at a time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在日常生活中经常遇到并行。当你和你的朋友同时进行两个不同的任务时，这些任务就是在并行进行。为了使多个任务并行，我们需要独立的、隔离的*处理单元*，每个单元被分配给特定的任务。例如，在计算机系统中，每个*CPU核心*都是一个处理单元，一次可以处理一个任务。
- en: For a minute, look at yourself as the sole reader of this book. You cannot read
    two books in parallel; you would have to pause in reading one of them in order
    to read the other. Yet, if you added your friend into the mix, then it's possible
    for two books to be read in parallel.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时将你自己视为这本书的唯一读者。你不能并行阅读两本书；你不得不暂停阅读其中一本以便阅读另一本。然而，如果你让你的朋友加入进来，那么两本书就可以并行阅读了。
- en: What would happen if you had a third book that needed to be read? Since neither
    of you can read two books in parallel, then one of you would need to pause in
    reading your book to continue with the third one. This simply means that either
    you or your friend need to divide your time properly in order to read all three books.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有第三本书需要阅读会发生什么？既然你们两个人都不能同时阅读两本书，那么其中一个人在阅读自己的书时就需要暂停，以便继续阅读第三本书。这仅仅意味着你们中的任何一个人或者你的朋友都需要合理分配时间，以便阅读这三本书。
- en: In a computer system, there must be at least two separate and independent processing
    units in order to have two parallel tasks being executed on that system. Modern
    CPUs have a number of *cores* inside, and those cores are the actual processing
    units. For example, a 4-core CPU has 4 processing units, and therefore can support
    4 parallel tasks being run simultaneously. For simplicity, in this chapter we
    will suppose that our imaginary CPU has only one core inside and therefore cannot
    perform parallel tasks. There will be some discussion regarding multi-core CPUs
    later, within relevant sections.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机系统中，必须至少有两个独立且分离的处理单元，才能在该系统上执行两个并行任务。现代CPU内部有多个**核心**，这些核心是实际的处理单元。例如，一个4核心CPU有4个处理单元，因此可以同时支持4个并行任务运行。为了简化，在本章中，我们将假设我们的想象中的CPU内部只有一个核心，因此不能执行并行任务。在相关章节中，我们将在稍后讨论多核CPU。
- en: Suppose that you get two laptops with our imaginary CPU inside, with one playing
    a piece of music, and the other one finding the solution to a differential equation.
    Both of them are functioning in parallel, but if you want them to do both on the
    same laptop using only one CPU, and with one core, then it *cannot* be parallel
    and it is in fact concurrent.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你得到两台装有我们想象中的CPU的笔记本电脑，一台播放音乐，另一台求解微分方程。它们都在并行工作，但如果你想在同一台笔记本电脑上使用单个CPU和单个核心同时完成这两项任务，那么这**不可能**是并行的，实际上它是并发的。
- en: Parallelism is about tasks that can be parallelized. This means that the actual
    algorithm can be divided and run on multiple processor units. But most of the
    algorithms we write, as of today, are *sequential* and not parallel in nature.
    Even in multithreading, each thread has a number of sequential instructions that
    cannot be broken into some parallel *execution flows*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化是指可以并行化的任务。这意味着实际的算法可以被分割并在多个处理器单元上运行。但截至目前，我们编写的算法大多数都是**顺序的**，而不是并行的。即使在多线程中，每个线程也有一定数量的顺序指令，这些指令不能被分解成一些并行的**执行流程**。
- en: In other words, a sequential algorithm cannot be easily broken into some parallel
    flows of execution automatically by the operating system, and this should be done
    by a programmer. Therefore, with having a multi-core CPU, you still need to assign
    each of the execution flows to a certain CPU core, and in that core, if you have
    more than one flow assigned, you cannot have both of them running in parallel,
    and you immediately observe a concurrent behavior.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，顺序算法不能被操作系统自动轻易地分解成一些并行执行流程，这需要程序员来完成。因此，尽管拥有多核CPU，你仍然需要将每个执行流程分配给特定的CPU核心，并且在该核心中，如果你分配了多个流程，你不能让它们同时并行运行，你将立即观察到并发行为。
- en: In short, of course having two flows, each assigned to a different core, can
    end up in two parallel flows but assigning them to just one core, would result
    in two concurrent flows. In multi-core CPUs we effectively observe a mixed behavior,
    both parallelism between the cores, and concurrency on the same core.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，当然，将两个流程分别分配给不同的核心，可以最终实现两个并行流程，但将它们分配给同一个核心，就会导致两个并发流程。在多核CPU中，我们实际上观察到的是一种混合行为，既有核心间的并行性，也有同一核心上的并发性。
- en: Despite its simple meaning and numerous everyday examples, parallelism is a complex
    and tough topic in computer architecture. In fact, it is a separate academic subject
    from concurrency, with its own theories, books, and literature. Being able to
    have an operating system that can break a sequential algorithm into some parallel
    execution flows is an open field of research and the current operating systems
    cannot do that.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管并行化具有简单的意义和无数的日常例子，但在计算机体系结构中，它是一个复杂且困难的话题。实际上，它是一个与并发性分开的独立学术领域，拥有自己的理论、书籍和文献。能够拥有一个可以将顺序算法分解成一些并行执行流程的操作系统是一个开放的研究领域，而当前的操作系统无法做到这一点。
- en: As stated, the purpose of this chapter is not to go into any depth in parallelism,
    but only to provide an initial definition for the concept. Since further depth
    of discussion about parallelism is beyond the scope of this book, let's begin
    with the concept of concurrency.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所述，本章的目的不是深入探讨并行性，而是只为这个概念提供一个初步的定义。由于关于并行性的进一步讨论超出了本书的范围，让我们从并发概念开始。
- en: Firstly, we'll talk about concurrent systems and what it really means in comparison
    to parallelism.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将讨论并发系统以及它与并行性的真正含义。
- en: Concurrency
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发
- en: You may have heard about *multitasking* – well, concurrency has the same idea.
    If your system is managing multiple tasks at the same time, you need to understand
    that it does not necessarily mean that the tasks are being run in parallel. Instead,
    there can be a *task scheduler* in the middle; this simply switches very quickly
    between the different tasks and performs a tiny bit of each of them in a fairly
    small amount of time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过**多任务处理**——好吧，并发有同样的理念。如果你的系统正在同时管理多个任务，你需要理解这并不一定意味着任务正在并行运行。相反，中间可能有一个**任务调度器**；它只是非常快速地在不同的任务之间切换，并在相对较短的时间内执行每个任务的一小部分。
- en: This certainly happens when you have just one processor unit. For the rest of
    our discussion in this section, we assume that we are operating on just one processor
    unit.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当你只有一个处理器单元时，这当然会发生。在本节接下来的讨论中，我们假设我们正在仅对一个处理器单元进行操作。
- en: If a task scheduler is sufficiently *fast* and *fair*, you won't notice the
    *switching* between the tasks, and they'll appear to be running in parallel from
    your perspective. That's the magic of concurrency, and the very reason why it
    is being used in most of the widely known operating systems, including Linux,
    macOS, and Microsoft Windows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务调度器足够**快**和**公平**，你不会注意到任务之间的**切换**，它们在你看来就像是并行运行的。这就是并发的魔法，也是它被广泛应用于大多数知名操作系统（包括Linux、macOS和Microsoft
    Windows）中的根本原因。
- en: Concurrency could be seen as a simulation of performing tasks in parallel, using
    a single processor unit. In fact, the whole idea can be referred to as a form
    of artificial parallelism. For old systems that only had a single CPU, with only
    one core, it was a huge advance when people were able to use that single core
    in a multitasking fashion.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 并发可以看作是使用单个处理器单元模拟并行执行任务。实际上，整个想法可以被称为一种形式的人工并行性。对于只有单个CPU、只有一个核心的旧系统来说，人们能够以多任务的方式使用那个单一核心是一项巨大的进步。
- en: As a side note, *Multics* was one of the first operating systems designed to
    multitask and manage simultaneous processes. You'll remember that in *Chapter
    10*, *Unix – History and Architecture*, Unix was built based on the ideas gained
    from the Multics project.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁注，*Multics* 是最早设计为多任务处理和同时管理进程的操作系统之一。你可能会记得，在*第10章*，*Unix – 历史 和 架构*中，Unix
    是基于从Multics项目中获得的想法构建的。
- en: As we've explained previously, almost all operating systems can perform concurrent
    tasks through multitasking, especially POSIX-compliant operating systems, since
    the ability is clearly exposed in the POSIX standard.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前解释的，几乎所有的操作系统都可以通过多任务执行并发任务，尤其是符合POSIX标准的操作系统，因为这种能力在POSIX标准中得到了明确的体现。
- en: Task scheduler unit
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务调度器单元
- en: As we've said before, all multitasking operating systems are required to have
    a *task scheduler* unit, or simply a *scheduler unit*, in their kernel. In this
    section, we're going to see how this unit works and how it contributes to the
    seamless execution of some concurrent tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说的，所有多任务操作系统都需要在其内核中有一个**任务调度器**单元，或者简单地称为**调度器单元**。在本节中，我们将看到这个单元是如何工作的，以及它是如何有助于一些并发任务的无缝执行的。
- en: 'Some facts regarding the task scheduler unit are listed as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 关于任务调度器单元的一些事实如下：
- en: The scheduler has a *queue* for tasks waiting to be executed. *Tasks* or *jobs*
    are simply the pieces of work that should be performed in separate flows of execution.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度器有一个用于等待执行的任务**队列**。**任务**或**作业**仅仅是应该在不同执行流中执行的工作片段。
- en: This queue is usually *prioritized*, with the high-priority tasks being chosen
    to start first.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个队列通常是**优先级**排序的，高优先级任务会被优先选择开始执行。
- en: The processor unit is managed and shared among all the tasks by the task scheduler.
    When the processor unit is free (no task is using it), the task scheduler must
    select another task from its queue before letting it use the processor unit. When
    the task is finished, it releases the processor unit and make it available again,
    then the task scheduler selects another task. This goes on in a continuous loop.
    This is called *task scheduling*, and it is the sole responsibility of the task
    scheduler to do this.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理器单元由任务调度器管理和共享。当处理器单元空闲（没有任务在使用它）时，任务调度器必须在让任务使用处理器单元之前，从其队列中选择另一个任务。当任务完成时，它释放处理器单元并使其再次可用，然后任务调度器选择另一个任务。这个过程持续进行。这被称为*任务调度*，这是任务调度器唯一的责任。
- en: There are many *scheduling algorithms* that the task scheduler can operate,
    but all of them should address specific requirements. For example, all of them
    should be *fair*, and no task should be *starved* in the queue as a result of
    not being chosen for a prolonged period of time.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多*调度算法*供任务调度器操作，但它们都应该满足特定的要求。例如，所有算法都应该*公平*，并且没有任何任务因为长时间未被选中而在队列中*饥饿*。
- en: Based on a chosen *scheduling strategy*, the scheduler should either dedicate
    a specific *time slice* or *time quantum* to the task in order to use the processor
    unit, or alternatively, the scheduler must wait for the task to release the processor
    unit.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据选择的*调度策略*，调度器应该为任务分配特定的*时间片*或*时间量子*以使用处理器单元，或者调度器必须等待任务释放处理器单元。
- en: If the scheduling strategy is *preemptive*, the scheduler should be able to
    forcefully take back the CPU core from the running task in order to give it to
    the next task. This is called *preemptive scheduling*. There is also another scheme
    in which the task releases the CPU voluntarily, which is called *cooperative scheduling*.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果调度策略是*抢占式*的，调度器应该能够强制从正在运行的任务中收回CPU核心，以便将其分配给下一个任务。这被称为*抢占式调度*。还有一种方案是任务自愿释放CPU，这被称为*协作式调度*。
- en: Preemptive scheduling algorithms try to share *time slices* evenly and fairly
    between different tasks. Prioritized tasks may get chosen more frequently, or
    they may even get longer time slices depending upon the implementation of the
    scheduler.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抢占式调度算法试图在不同任务之间公平地平均分配*时间片*。优先级较高的任务可能会被更频繁地选中，或者根据调度器的实现，它们甚至可能获得更长的时间片。
- en: A task is a general abstract concept, used to refer to any piece of work that
    should be done in a concurrent system, not necessarily a computer system. We'll
    look at what exactly these non-computer systems are shortly. Likewise, CPUs are
    not the only type of resource that can be shared between tasks. Humans have been
    scheduling and prioritizing tasks for as long as we have existed, when we are
    faced with tasks that we cannot complete simultaneously. In the next few paragraphs,
    we will consider such a situation as a good example for understanding scheduling.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 任务是一个通用的抽象概念，用来指代在并发系统中应该完成的工作，不一定是计算机系统中的工作。我们很快就会看看这些非计算机系统究竟是什么。同样，CPU也不是唯一可以共享给任务的资源。人类在存在以来就一直对任务进行调度和优先级排序，当我们面临无法同时完成的工作时。在接下来的几段中，我们将考虑这种情况作为理解调度的良好例子。
- en: Let's suppose that we are at the beginning of the twentieth century and there
    is only one telephone booth in the street, and 10 people are waiting to use the
    telephone. In this case, these 10 people should follow a scheduling algorithm
    in order to share the booth fairly between themselves.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们处于20世纪初，街上只有一个电话亭，有10个人在等待使用电话。在这种情况下，这10个人应该遵循一种调度算法，以便在他们之间公平地共享电话亭。
- en: First of all, they need to stand in a queue. This is the most basic decision
    that enters the civilized mind in such a situation – to stand in the queue and
    wait for your turn. However, this alone is not enough; we also need some regulations
    to support this method. The first person, who is currently using the phone, can't
    talk as much as they might like to when there are nine other people waiting for
    the booth. The first person must leave the booth after a certain amount of time
    in order to allow the next person in the queue their turn.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，他们需要排队。在这种情况下，文明心智做出的最基本决定就是排队并等待你的轮次。然而，这还不够；我们还需要一些规则来支持这种方法。目前正在使用电话的第一个人，在还有九个人在等待隔间时，不能像他们可能希望的那样说很多话。第一个人必须在一段时间后离开隔间，以便让队列中的下一个人有机会。
- en: In the rare case that they have not finished their conversation yet, the first
    person should stop using the phone after a certain amount of time, leave the booth,
    and go back to the end of the queue. They must then wait for their next turn so
    that they can continue their talk. This way, each of the 10 people will need to
    continue entering the booth, until they have completed their conversation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在极少数情况下，如果他们还没有结束对话，第一个人应该在一段时间后停止使用电话，离开隔间，并回到队伍的末尾。然后他们必须等待他们的下一轮，以便继续他们的谈话。这样，10个人中的每一个人都需要继续进入隔间，直到他们完成他们的对话。
- en: This is just an example. We encounter examples of sharing resources between
    a number of consumers every day, and humans have invented many ways to share these
    resources fairly between themselves – to the extent that human nature allows!
    In the next section, we return to considering scheduling within the context of
    a computer system.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个例子。我们每天都会遇到多个消费者之间共享资源的例子，人类已经发明了许多方法来在这些资源之间公平地共享——直到人类本性允许的程度！在下一节中，我们将回到考虑计算机系统中的调度。
- en: Processes and threads
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程和线程
- en: 'Throughout this book, we are mainly interested in task scheduling within computer
    systems. In an operating system, tasks are either *processes* or *threads*. We''ll
    explain them and their differences in the upcoming chapters, but for now, you
    should know that most operating systems treat both in basically the same way:
    as some tasks that need to be executed concurrently.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们主要对计算机系统中的任务调度感兴趣。在操作系统内，任务要么是*进程*，要么是*线程*。我们将在接下来的章节中解释它们及其区别，但就目前而言，你应该知道大多数操作系统基本上以相同的方式处理它们：作为需要并发执行的一些任务。
- en: An operating system needs to use a task scheduler to share the CPU cores among
    the many tasks, be they processes or threads, that are willing to use the CPU
    for their execution. When a new process or a new thread is created, it enters
    the scheduler queue as a new task, and it waits to obtain a CPU core before it
    starts running.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统需要使用任务调度器来在许多任务之间共享CPU核心，这些任务无论是进程还是线程，都愿意使用CPU来执行它们的任务。当创建一个新的进程或一个新的线程时，它作为新的任务进入调度队列，并在开始运行之前等待获取CPU核心。
- en: In cases in which a *time-sharing* or *preemptive scheduler* is in place, if
    the task cannot finish its logic in a certain amount of time, then the CPU core
    will be taken back forcefully by the task scheduler and the task enters the queue
    again, just like in the telephone booth scenario.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在存在*时间共享*或*抢占式调度器*的情况下，如果任务在一段时间内无法完成其逻辑，那么任务调度器将强制收回CPU核心，并将任务再次放入队列，就像电话亭场景中一样。
- en: In this case, the task should wait in the queue until it obtains the CPU core
    once more, and then it can continue running. If it cannot finish its logic in
    the second round, the same process continues until it is able to finish.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，任务应该在队列中等待，直到再次获得CPU核心，然后才能继续运行。如果它无法在第二轮中完成其逻辑，这个过程将继续进行，直到它能够完成。
- en: Every time a preemptive scheduler stops a process in the middle of running and puts
    another process into the running state, it is said that a *context switch* has occurred.
    The faster the context switches are, the more a user will feel as if the tasks
    are being run in parallel. Interestingly, most operating systems today use a preemptive
    scheduler, something that will be our main focus for the rest of this chapter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 每次抢占式调度器在运行过程中停止一个进程并将另一个进程放入运行状态时，就会发生一次*上下文切换*。上下文切换越快，用户就会感觉任务似乎是在并行运行。有趣的是，今天的大多数操作系统都使用抢占式调度器，这是我们本章剩余部分的主要焦点。
- en: From now on, all schedulers are assumed to be preemptive. I will specify in
    instances where this is not the case.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，所有调度器都被假定为抢占式的。在不适用此情况时，我会进行说明。
- en: When a task is running, it may experience hundreds or even thousands of context
    switches before being finished. However, context switches have a very bizarre
    and unique characteristic – they are not *predictable*. In other words, we are
    not able to predict when, or even at which instruction, a context switch is going
    to happen. Even in two remarkably close successive runs of a program on the same
    platform, the context switches will happen differently.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个任务运行时，它可能经历数百甚至数千次上下文切换，才能完成。然而，上下文切换有一个非常奇特和独特的特性——它们是不可预测的。换句话说，我们无法预测上下文切换何时发生，甚至无法预测在哪个指令上发生。即使在同一平台上两个非常接近的连续程序运行中，上下文切换也会有所不同。
- en: The importance of this, and the impact it has, cannot be overstated; context
    switches cannot be predicted! Shortly, through the given examples, you'll observe
    the consequences of this for yourself.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点的重要性及其影响不容小觑；上下文切换是不可预测的！简而言之，通过给出的例子，你将亲自观察到这一点带来的后果。
- en: Context switches are highly unpredictable, to such an extent that the best way
    to deal with this uncertainty is to assume that the probability of having a context
    switch on a specific instruction is the same for all instructions. In other words,
    you should expect that all instructions are subject to experiencing a context
    switch in any given run. What this means, simply, is that you may have gaps between
    the execution of any two adjacent instructions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文切换高度不可预测，到了这种程度，处理这种不确定性的最佳方式是假设在特定指令上发生上下文切换的概率对所有指令都是相同的。换句话说，你应该预期所有指令在任何给定运行中都可能经历上下文切换。简单来说，这意味着你可能在任何两个相邻指令的执行之间有间隔。
- en: With that being said, let's now move on and take a look at the only certainties
    that do exist in a concurrent environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们现在继续前进，看看在并发环境中唯一确定存在的事情。
- en: Happens-before constraint
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发生之前约束
- en: We established in the previous section that context switches are not predictable;
    there is uncertainty about the time at which they are likely to occur in our programs.
    Despite that, there is certainty about the instructions that are being executed
    concurrently.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了上下文切换是不可预测的；在我们程序中，它们可能发生的时间存在不确定性。尽管如此，同时执行的指令是确定的。
- en: 'Let''s continue with a simple example. To start with, we''re going to work
    on the basis that we''ve got a task like the one you see next in *Code Box 13-1*,
    which has five instructions. Note that these instructions are abstract, and they
    don''t represent any real instructions like C or machine instructions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续用一个简单的例子来说明。首先，我们将基于我们有一个类似于你在*代码框 13-1*中看到的任务，它有五条指令。请注意，这些指令是抽象的，它们不代表任何真实的指令，如
    C 或机器指令：
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Code Box 13-1: A simple task with 5 instructions'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-1：一个包含 5 条指令的简单任务
- en: As you can see, the instructions are ordered, which means that they *must* be
    executed in that specified order in order to satisfy the purpose of the task.
    We are certain about this. In technical terms, we say that we have a *happens-before
    constraint* between every two adjacent instructions. The instruction `num++` must
    happen before `num = num - 2` and this constraint must be kept satisfied no matter
    how the context switches are happening.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，指令是有序的，这意味着它们*必须*按照指定的顺序执行，以满足任务的目的是。我们对此是确定的。从技术角度来说，我们说我们在每两个相邻指令之间有一个*发生之前约束*。指令
    `num++` 必须在 `num = num - 2` 之前发生，并且这个约束必须得到满足，无论上下文切换如何发生。
- en: Note that we still have uncertainty about when the context switches are going
    to happen; it's key to remember that they can happen anywhere between the instructions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们仍然对上下文切换何时发生存在不确定性；记住这一点很重要，它们可以在指令之间任何地方发生。
- en: 'Here, we are going to present two possible executions of the preceding task,
    with different context switches:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将展示前述任务两种可能的执行方式，具有不同的上下文切换：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Code Box 13-2: One possible run of the above task together with the context
    switches'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-2：上述任务与上下文切换的可能运行之一
- en: 'And for the second run, it is executed as the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二次运行，它执行如下：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Code Box 13-3: Another possible run together with the context switches'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-3：另一个与上下文切换一起的可能运行
- en: As you can see in *Code Box 13-2*, the number of context switches and the places
    they occur can both change in each run. Yet, as we said before, there are certain
    happens-before constraints that should be followed.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*代码框13-2*中可以看到的，上下文切换的次数和它们发生的位置在每个运行中都可以改变。然而，正如我们之前所说的，有一些应该遵循的发生之前约束。
- en: This is the reason we can have an overall deterministic behavior for a specific
    task. No matter how context switches happen in different runs, the *overall state*
    of a task remains the same. By the overall state of a task, we mean the set of
    variables and their corresponding values after the execution of the last instruction
    in the task. For example, for the preceding task, we always have the final state,
    including the `num` variables with a value of `14`, and the variable `x` with
    a value of `10`, regardless of the context switches.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们可以对特定任务有一个总体确定性行为的原因。无论上下文切换在不同运行中如何发生，任务的*总体状态*都保持不变。当我们说任务的总体状态时，我们指的是在任务中最后一条指令执行后，变量及其对应值的集合。例如，对于前面的任务，我们总是有最终状态，包括`num`变量值为`14`，以及变量`x`的值为`10`，无论上下文切换如何。
- en: By knowing that the overall state of a single task does not change in different
    runs, we might be tempted to conclude that due to having to follow the order of
    execution and the happens-before constraints, concurrency cannot affect the overall
    state of a task. Yet, we should be careful about this conclusion.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过知道单个任务的总体状态在不同运行中不会改变，我们可能会倾向于得出结论，由于必须遵循执行顺序和发生之前约束，并发性不会影响任务的总体状态。然而，我们对此结论应持谨慎态度。
- en: Let's assume that we have a system of concurrent tasks, all having read/write
    permissions over a *shared resource*, say a variable. If all the tasks only read
    the shared variable and none of them are going to write to it (change its value),
    we can say that no matter how context switches are happening, and no matter how
    many times you run the tasks, we always get the same results. Note that this is
    also true about a system of concurrent tasks that have no shared variable at all.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个并发任务系统，所有任务都有对*共享资源*的读写权限，比如一个变量。如果所有任务只读取共享变量，而没有任务将要写入它（改变其值），我们可以说，无论上下文切换如何发生，无论你运行任务多少次，我们总是得到相同的结果。请注意，这同样适用于没有共享变量的并发任务系统。
- en: Yet, if just one of the tasks is going to write to the shared variable, then
    the context switches imposed by the task scheduler unit will affect the overall
    state of all tasks. This means that it can be different from one run to another!
    Consequently, a proper control mechanism should be employed to avoid any unwanted
    results. This is all due to the fact that context switches cannot be predicted,
    and the tasks' *intermediate states* can vary from one run to another. An intermediate
    state, as opposed to overall state, is a set of variables together with their
    values at a certain instruction. Every task has only one overall state that is
    determined when it is finished, but it has numerous intermediate states that correspond
    to the variables and their values after executing a certain instruction.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果只有一个任务将要写入共享变量，那么由任务调度器单元强加的上下文切换将影响所有任务的总体状态。这意味着它可能从一个运行到另一个运行而不同！因此，应该采用适当的控制机制来避免任何不希望的结果。这一切都是由于上下文切换无法预测，并且任务的*中间状态*可能从一个运行到另一个运行而变化。与总体状态相对，中间状态是在某个指令下变量及其值的集合。每个任务只有一个总体状态，这是在任务完成时确定的，但它有多个中间状态，对应于执行某个指令后的变量及其值。
- en: In summary, when you have a concurrent system containing several tasks with
    a shared resource that can be written to by any of those tasks, then different
    runs of the system will yield different results. Hence, proper *synchronization*
    methods should be used in order to cancel the effect of context switches and obtain
    the same deterministic results in various runs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，当你有一个包含多个任务且这些任务可以写入共享资源的并发系统时，系统的不同运行将产生不同的结果。因此，应该使用适当的*同步*方法来取消上下文切换的影响，并在各种运行中获得相同的确定性行为。
- en: We now have some of the basic concepts of concurrency, which is the dominant
    topic of this chapter. The concepts explained in this section are fundamental
    to our understanding of many topics, and you will hear them again and again in
    future sections and chapters of this book.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一些并发的基本概念，这是本章的主题。本节中解释的概念对于理解许多主题是基本的，你将在本书未来的章节中反复听到它们。
- en: You'll remember that we also said concurrency could be problematic and in turn,
    it can make things more complicated for us. So, you may be asking, when do we
    need it? In the next section of this chapter, we'll answer that question.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你会记得我们也说过并发可能会出现问题，进而，它可能会使事情对我们来说更加复杂。所以，你可能想知道，我们什么时候需要它？在本章的下一节中，我们将回答这个问题。
- en: When to use concurrency
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用并发
- en: Based on our explanations given so far, it seems that having only one task is
    less problematic than having multiple tasks do the same thing concurrently. This
    is quite right; if you can write a program that runs acceptably without introducing
    concurrency, it is highly recommended that you do so. There are some general patterns
    we can use to know when we have to use concurrency.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们到目前为止的解释，似乎只有一个任务比多个任务同时做同一件事的问题要小得多。这是完全正确的；如果你能编写一个不需要引入并发就能正常运行得不错的程序，那么强烈建议你这样做。我们可以使用一些通用模式来了解何时必须使用并发。
- en: In this section, we are going to walk through what these general patterns are,
    and how they lead us to split a program into concurrent flows.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨这些通用模式是什么，以及它们是如何引导我们将程序拆分为并发流程的。
- en: A program, regardless of the programming language used, is simply a set of instructions
    that should be executed in sequence. In other words, a given instruction won't
    be executed until the preceding instruction has been executed. We call this concept
    a *sequential execution*. It doesn't matter how long the current instruction takes
    to finish; the next instruction must wait until the current one has been completed.
    It is usually said that the current instruction is *blocking* the next instruction;
    this is sometimes described as the current instruction being a *blocking instruction*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 不论使用哪种编程语言，程序本质上是一组应该按顺序执行的指令。换句话说，给定的指令不会执行，直到前面的指令已经执行。我们称这个概念为*顺序执行*。当前指令完成所需的时间有多长并不重要；下一条指令必须等待当前一条指令完成。通常说，当前指令正在*阻塞*下一条指令；这有时被描述为当前指令是一个*阻塞指令*。
- en: In every program, all of the instructions are blocking, and the execution flow
    is sequential in each flow of execution. We can only say a program is running
    quickly if each instruction blocks the following instruction for a relatively
    short time in terms of a few milliseconds. Yet, what happens if a blocking instruction
    takes too much time (for example 2 seconds or 2000 milliseconds), or the time
    that it takes cannot be determined? These are two patterns that tell us we need
    to have a concurrent program.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个程序中，所有的指令都是阻塞的，每个执行流程的执行流程都是顺序的。我们只能说程序运行得快，如果每个指令在几个毫秒内阻塞下一条指令的时间相对较短。然而，如果阻塞指令花费了太多时间（例如2秒或2000毫秒），或者它所需的时间无法确定，会发生什么？这两个模式告诉我们我们需要一个并发程序。
- en: To elaborate further, every blocking instruction consumes an amount of time
    when trying to get completed. For us, the best scenario is that a given instruction
    takes a relatively short time to complete and after that, the next instruction
    can be executed immediately. However, we are not always so fortunate.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步阐述，每个阻塞指令在尝试完成时会消耗一定的时间。对我们来说，最佳情况是，给定的指令完成所需的时间相对较短，然后，下一条指令可以立即执行。然而，我们并不总是这么幸运。
- en: There are certain scenarios where we cannot determine the time that a blocking
    instruction takes to complete. This usually happens when a blocking instruction
    is waiting either for a certain event to occur, or for some data to become available.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些场景，我们无法确定阻塞指令完成所需的时间。这通常发生在阻塞指令正在等待某个事件发生，或者某些数据变得可用时。
- en: Let's continue with an example. Suppose that we have a server program that is
    serving a number of client programs. There is an instruction in the server program
    that waits for a client program to get connected. From the server program's point
    of view, no one can say for sure when a new client is about to connect. Therefore,
    the next instruction cannot be executed on the server side because we don't know
    when we will be done with the current one. It depends entirely on the time at
    which a new client tries to connect.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子继续。假设我们有一个服务器程序，它正在为多个客户端程序提供服务。服务器程序中有一个指令等待客户端程序连接。从服务器程序的角度来看，没有人能确切地说何时会有新的客户端连接。因此，下一条指令不能在服务器端执行，因为我们不知道何时才能完成当前的指令。这完全取决于新客户端尝试连接的时间。
- en: A simpler example is when you read a string from the user. From the program's
    point of view, no one can say for sure when the user will enter their input; hence,
    future instructions cannot be executed. This is the *first pattern* that leads
    to a concurrent system of tasks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更简单的例子是当你从用户那里读取一个字符串时。从程序的角度来看，没有人能确定用户何时会输入他们的输入；因此，未来的指令无法执行。这是导致并发任务系统的*第一个模式*。
- en: The first pattern for concurrency then, is when you have an instruction that
    can block the flow of execution for an indefinite amount of time. At this point
    you should split the existing flow into two separate flows or tasks. You would
    do this if you need to have the later instructions being executed, and you cannot
    wait for the current instruction to complete first. More importantly for this
    scenario, we assume that the later instructions are not dependent on the result
    of the current instructions being completed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 并发的第一个模式是当你有一个可以无限期阻塞执行流程的指令。在这种情况下，你应该将现有的流程分成两个独立的流程或任务。如果你需要执行后续指令，而又不能等待当前指令首先完成，你会这样做。对于这个场景来说，更重要的是，我们假设后续指令不依赖于当前指令完成的结果。
- en: By splitting our preceding flow into two concurrent tasks, while one of the
    tasks is waiting for the blocking instruction to complete, the other task can
    continue and execute those instructions that were blocked in the preceding non-concurrent
    setup.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将前面的流程分成两个并发任务，当其中一个任务正在等待阻塞指令完成时，另一个任务可以继续执行先前非并发设置中阻塞的指令。
- en: The following example that we're going to focus on in this section shows how
    the first pattern can result in a system of concurrent tasks. We will be using
    pseudo-code to represent the instructions in each task.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注的下一个例子将展示第一个模式如何导致并发任务系统。我们将使用伪代码来表示每个任务中的指令。
- en: '**Note**:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：'
- en: No prior knowledge of computer networks is needed to understand the upcoming
    example.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 理解即将到来的例子不需要任何计算机网络知识。
- en: 'The example we''re going to focus on is about a server program that has three objectives:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要关注的例子是关于一个具有三个目标的服务器程序：
- en: It calculates the sum of two numbers read from a client and returns the result
    back to the client.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它计算从客户端读取的两个数字的和，并将结果返回给客户端。
- en: It writes the number of served clients to a file regularly, regardless of whether
    any client is being served or not.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它定期将已服务的客户端数量写入文件，无论是否正在服务任何客户端。
- en: It must also be able to serve multiple clients at once.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还必须能够同时服务多个客户端。
- en: 'Before talking about the final concurrent system that satisfies preceding objectives,
    let''s first suppose that in this example we are going to use only one task (or
    flow) and then we are going to show that a single task cannot accomplish the preceding
    objectives. You can see the pseudo-code for the server program, in a single-task
    setup, in *Code Box 13-4*:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论满足上述目标的最终并发系统之前，让我们首先假设在这个例子中我们只使用一个任务（或流程），然后我们将展示单个任务无法完成上述目标。你可以看到服务器程序的伪代码，在单任务设置中，在*代码框
    13-4*中：
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Code Box 13-4: A server program operating using a single task'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-4：使用单个任务操作的服务器程序
- en: As you can see, our single flow waits for a client on the network to get connected.
    It then reads two numbers from the client, then calculates their sum and returns
    it to the client. Finally, it closes the client connection and writes the number
    of served clients to a file before continuing to wait for the next client to join
    in. Shortly, we'll show that the preceding code cannot satisfy our aforementioned
    objectives.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，我们的单个流程等待网络上的客户端连接。然后从客户端读取两个数字，然后计算它们的和并将其返回给客户端。最后，它关闭客户端连接，在继续等待下一个客户端加入之前将已服务的客户端数量写入文件。很快，我们将展示前面的代码无法满足我们上述的目标。
- en: 'This pseudo-code contains only one task, `T1`. It has 12 lines of instructions,
    and as we''ve said before, they are executed sequentially, and all the instructions
    are blocking. So, what exactly is this code showing us? Let''s walk through it:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个伪代码只包含一个任务，`T1`。它有12条指令，正如我们之前所说的，它们是顺序执行的，并且所有指令都是阻塞的。那么，这段代码究竟向我们展示了什么呢？让我们一步步来看：
- en: The first instruction, `N = 0`, is simple and finishes very quickly.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一条指令，`N = 0`，很简单，并且完成得很快。
- en: The second instruction, `Prepare Server`, is expected to finish in a reasonable
    time so that it won't block the execution of the server program.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二条指令，`准备服务器`，预计会在合理的时间内完成，这样就不会阻塞服务器程序的执行。
- en: The third instruction is just starting the main loop and it should finish quickly
    as we proceed to go inside the loop.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三条指令只是启动主循环，并且随着我们进入循环，它应该很快完成。
- en: The fourth command, `Wait for a client C`, is a blocking instruction with an
    unknown completion time. Therefore, commands *5*, *6*, and the rest won't be executed.
    Hence, it seems that they must wait for a new client to join in, and only after
    that, these instructions can be executed.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四条指令，`等待客户C`，是一个具有未知完成时间的阻塞指令。因此，指令*5*、*6*以及其余的指令将不会执行。因此，它们似乎必须等待新客户加入，只有在此之后，这些指令才能执行。
- en: As we said before, having instructions *5* to *10* wait for a new client is
    must. In other words, those instructions are dependent on the output of instruction
    *4* and they cannot be executed without having a client accepted. However, instruction
    *11*, `Write N to file`, needs to be executed regardless of having a client or
    not. This is dictated by the second objective that we've defined for this example.
    By the preceding configuration, we write `N` to file only if we have a client,
    despite this being against our initial requirement, that is, we write `N` to file
    *regardless* of whether we have a client or not.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说的，指令*5*到*10*等待新客户是必须的。换句话说，这些指令依赖于指令*4*的输出，并且在没有接受客户的情况下不能执行。然而，指令*11*，`将N写入文件`，需要执行，无论是否有客户。这是由我们为这个例子定义的第二项目标所决定的。根据前面的配置，我们只有在有客户的情况下才将`N`写入文件，尽管这与我们的初始要求相矛盾，即，无论是否有客户，我们都将`N`写入文件。
- en: The preceding code has another problem in its flow of instructions; both instructions
    *6* and *7* can potentially block the flow of execution. These instructions wait
    for the client to enter two numbers, and since this is up to the client we cannot
    predict exactly when these instructions are going to finish. This prevents the
    program from continuing its execution.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码在其指令流程中还有一个问题；指令*6*和*7*都有可能阻塞执行流程。这些指令等待客户输入两个数字，由于这取决于客户，我们无法准确预测这些指令何时会完成。这阻止了程序继续执行。
- en: More than that, these instructions potentially block the program from accepting
    new clients. This is because the flow of executions won't reach the command *4* again,
    if commands *6* and *7* are going to take a long time to complete. Therefore,
    the server program cannot serve multiple clients at once, which is again not in
    accordance with our defined objectives.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，这些指令可能会阻止程序接受新的客户。这是因为如果指令*6*和*7*需要很长时间才能完成，执行流程将不会再次达到指令*4*。因此，服务器程序不能同时服务多个客户，这再次不符合我们定义的目标。
- en: To resolve the aforementioned issues, we need to break our single task into
    three concurrent tasks that together will satisfy our requirements for the server program.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，我们需要将单个任务分解为三个并发任务，这三个任务共同满足我们对服务器程序的要求。
- en: 'In the following pseudo-code in *Code Box 13-5*, you will find three flows
    of execution, `T1`, `T2`, and `T3`, that satisfy our defined objectives based
    on a concurrent solution:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在*代码框13-5*中的后续伪代码中，您将找到三个执行流程，`T1`、`T2`和`T3`，它们基于并发解决方案满足我们定义的目标：
- en: '[PRE4]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Code Box 13-5: A server program operating using three concurrent tasks'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框13-5：使用三个并发任务运行的服务器程序
- en: The program starts by executing task `T1`. `T1` is said to be the main task
    of the program because it is the first task that is going to be executed. Take
    note that each program has at least one task and that all other tasks are initiated
    by this task, either directly or indirectly.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先执行任务`T1`。`T1`被称为程序的主要任务，因为它将是第一个要执行的任务。请注意，每个程序至少有一个任务，并且所有其他任务都是由这个任务直接或间接启动的。
- en: In the preceding code box, we have two other tasks that are spawned by the main
    task, `T1`. There is also a shared variable, `N`, which stores the number of served
    clients and can be accessed (read or written) by all the tasks.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码框中，我们还有两个由主任务`T1`派生的其他任务。还有一个共享变量`N`，它存储已服务的客户数量，并且可以被所有任务访问（读取或写入）。
- en: The program starts with the first instruction in task `T1`; through this, it
    initializes the variable `N` to zero. Then the second instruction prepares the
    server. As part of this instruction, some preliminary steps should be taken in
    order for the server program to be able to accept the incoming connections. Note
    that so far there hasn't been any other concurrent task running next to task `T1`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 程序从任务 `T1` 的第一条指令开始；通过这条指令，它将变量 `N` 初始化为零。然后第二条指令准备服务器。作为这条指令的一部分，应该采取一些初步步骤，以便服务器程序能够接受传入的连接。请注意，到目前为止，还没有其他并发任务在任务
    `T1` 旁边运行。
- en: The third instruction in task `T1` creates a new *instance* of task `T2`. The
    creation of a new task is usually fast and takes no time. Therefore, task `T1`
    enters the infinite loop immediately after the creation of task `T2`, where it
    continues to write the value of the shared variable `N` to a file every 30 seconds.
    This was our first objective defined for the server program that has now been
    satisfied. Based on that, without having any interruption or blockage from other
    instructions, task `T1` writes the value of `N` to a file regularly, until the
    program finishes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 任务 `T1` 中的第三条指令创建了一个新的 *实例*，用于任务 `T2`。创建新任务通常很快，且不耗时。因此，任务 `T1` 在创建任务 `T2` 后立即进入无限循环，每30秒将共享变量
    `N` 的值写入文件。这是我们为服务器程序定义的第一个目标，现在已经实现。基于此，在没有其他指令的干扰或阻塞的情况下，任务 `T1` 会定期将 `N` 的值写入文件，直到程序完成。
- en: Let's talk about the spawned task. The sole responsibility of task `T2` is to
    accept the incoming clients as soon as they send the connection request. It's
    also worth remembering that all the instructions in task `T2` are run inside an
    infinite loop. The second command in task `T2` waits for a new client. Here, it
    blocks other instructions in task `T2` from executing, but this is only applied
    to the instructions in task `T2`. Note that if we had spawned two instances of
    task `T2` instead of one, having instructions blocked in one of them would not
    block the instructions in the other instance.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈派生的任务。任务 `T2` 的唯一责任是当客户端发送连接请求时立即接受它们。也值得记住的是，任务 `T2` 中的所有指令都在一个无限循环中运行。任务
    `T2` 中的第二条指令等待新的客户端。在这里，它阻止了任务 `T2` 中其他指令的执行，但这仅适用于任务 `T2` 中的指令。请注意，如果我们派生了两个
    `T2` 实例而不是一个，其中一个实例中的指令被阻塞不会阻止另一个实例中的指令。
- en: 'Other concurrent tasks, in this case only `T1`, continue to execute their instructions
    without any blockage. This is what concurrency enables; while some tasks are blocked
    for a certain event, other tasks can continue their work without any interruption.
    As we said before, this has an important design principle at its core: *Whenever
    you have a blocking operation where either its finishing time is unknown, or it
    takes a long time to complete, then you should break the task into two concurrent
    tasks*.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 其他并发任务，在这种情况下只有 `T1`，会继续执行它们的指令而没有任何阻塞。这正是并发所实现的；当一些任务因为某个事件而阻塞时，其他任务可以继续它们的工作而不会受到任何干扰。正如我们之前所说的，这有一个重要的设计原则作为其核心：*每当遇到一个阻塞操作，要么其完成时间未知，要么完成时间很长，那么你应该将任务分成两个并发任务*。
- en: Now, suppose that a new client joins. We've already seen in *Code Box 13-4*,
    in the non-concurrent version of the server program, that the read operations
    could block the acceptance of new clients. Based on the design principle that
    we pointed out just now, since the read instructions are blocking, we need to
    break the logic into two concurrent tasks, which is why we have introduced task
    `T3`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设有一个新的客户端加入。我们已经在 *代码框 13-4* 中看到，在服务器程序的并发版本中，读取操作可能会阻塞新客户端的接受。基于我们刚才指出的设计原则，由于读取指令是阻塞的，我们需要将逻辑分成两个并发任务，这就是为什么我们引入了任务
    `T3`。
- en: 'Whenever a new client joins, task `T2` spawns a new instance of task `T3` in
    order to communicate with the newly joined client. This was done by instruction
    *4* in task `T2`, which, to remind you, was the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每当有新的客户端加入时，任务 `T2` 会派生一个新的任务 `T3` 实例，以便与新加入的客户端通信。这是通过任务 `T2` 中的指令 *4* 实现的，提醒一下，这是以下命令：
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Code Box 13-6: Instruction 4 in task T2'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-6：任务 T2 中的指令 4
- en: It's important to note that before spawning a new task, task `T2` increments
    the value of the shared variable `N` as an indication of having a new client served.
    Again, a spawn instruction is fairly quick and doesn't block the acceptance of
    new clients.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在派生新任务之前，任务 `T2` 会增加共享变量 `N` 的值，以表示已为新客户端提供服务。再次强调，派生指令相当快，不会阻塞新客户端的接受。
- en: In task `T2`, when instruction *4* is finished, the loop continues, and it goes
    back to instruction *2*, which waits for another client to join. Note that based
    on the pseudo-code that we have, while we have only one instance of task `T1`
    and one instance of task `T2`, we can have multiple instances of `T3` for every
    client.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务 `T2` 中，当指令 *4* 执行完毕后，循环继续，并回到指令 *2*，等待另一个客户端加入。请注意，根据我们已有的伪代码，虽然我们只有一个任务
    `T1` 的实例和一个任务 `T2` 的实例，但我们可以为每个客户端拥有多个 `T3` 的实例。
- en: The sole responsibility of task `T3` is to communicate to the client and read
    the input numbers. It then continues by calculating the sum and sending it back
    to the client. As pointed out before, the blocking instructions inside task `T3`
    cannot block the execution of other tasks, and its blocking behavior is limited
    to the same instance of `T3`. Even the blocking instructions in a specific instance
    of `T3` cannot block the instructions in another instance of `T3`. This way, the
    server program can satisfy all of our desired objectives in a concurrent way.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 任务 `T3` 的唯一责任是与客户端通信并读取输入数字。然后，它继续计算总和并将结果发送回客户端。正如之前指出的，任务 `T3` 内部的阻塞指令不能阻止其他任务的执行，其阻塞行为仅限于同一实例的
    `T3`。即使是特定实例的 `T3` 内的阻塞指令也不能阻止另一个实例的 `T3` 内的指令。这样，服务器程序可以以并发的方式满足我们所有的期望目标。
- en: So, the next question might be, when do the tasks finish? We know that generally,
    when all the instructions within a task are executed, the task is finished. That
    being said, when we have an infinite loop wrapping all instructions inside a task,
    the task won't finish, and its lifetime is dependent on its *parent task* that
    has spawned it. We will discuss this specifically regarding processes and threads
    in future chapters. For the sake of our example, in our preceding concurrent program
    the parent task of all instances of `T3` is the only instance of task `T2`. As
    you can see, a specific instance of task `T3` finishes either when it closes the
    connection to the client after passing two blocking read instructions or when
    the only instance of task `T2` is finished.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，下一个问题可能是，任务何时完成？我们知道，通常情况下，当任务内的所有指令都执行完毕后，任务就完成了。但当我们有一个无限循环包裹着任务内的所有指令时，任务就不会完成，其生命周期取决于创建它的**父任务**。我们将在未来的章节中具体讨论关于进程和线程的内容。为了我们的例子，在我们先前的并发程序中，所有
    `T3` 实例的父任务是唯一的 `T2` 实例。正如你所看到的，一个特定的 `T3` 实例完成要么是在通过两个阻塞读取指令后关闭与客户端的连接，要么是唯一的
    `T2` 实例完成。
- en: In a rare but possible scenario, if all read operations take too much time to
    complete (and this can be either intentional or accidental), and the number of
    incoming clients increases rapidly, then there should be a moment where we have
    too many instances of task `T3` running and all of them are waiting for their
    clients to provide their input numbers. This situation would result in consuming
    a considerable amount of resources. Then, after some time, by having more and
    more incoming connections, either the server program would be terminated by the
    operating system, or it simply cannot serve any more clients.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在一种罕见但可能的情况中，如果所有读取操作完成所需的时间过长（这可能是有意的或意外的），并且进入的客户端数量迅速增加，那么我们可能会有一段时间内运行着过多的
    `T3` 实例，并且它们都在等待客户端提供输入数字。这种情况会导致消耗大量的资源。然后，经过一段时间，由于越来越多的进入连接，服务器程序可能会被操作系统终止，或者它简单地无法再服务任何客户端。
- en: Whatever happens in the preceding case, the server program ceases to serve the
    clients. When this occurs, it's called a **denial of service** (**DoS**). Systems
    with concurrent tasks should be designed in such a way to overcome these extreme
    situations that stop them from serving clients in a reasonable fashion.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 无论前一种情况发生什么，服务器程序都会停止服务客户端。当这种情况发生时，我们称之为**拒绝服务**（**DoS**）。对于具有并发任务的系统，应该设计成能够克服这些极端情况，从而以合理的方式为客户端提供服务。
- en: '**Note**:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：'
- en: When under a DoS attack, congestion of resources on a server machine occurs
    in order to bring it down and make it non-responsive. DoS attacks belong to a
    group of network attacks that try to block a certain service in order to make
    it unavailable to its clients. They cover a wide range of attacks, including *exploits*,
    with the intention of stopping a service. This can even include the *flooding*
    of a network in order to bring down the network infrastructure.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当受到DoS攻击时，服务器机器上的资源拥塞发生，以使其崩溃并使其无响应。DoS攻击属于试图阻止某些服务以使其对客户端不可用的网络攻击组。它们包括广泛的攻击，包括*漏洞利用*，目的是停止服务。这甚至包括为了使网络基础设施崩溃而对网络进行*洪水攻击*。
- en: In the preceding example of the server program, we described a situation in
    which we had a blocking instruction whose completion time could not be determined,
    and this was the first pattern for the use of concurrency. There is another pattern
    that is similar to this, but slightly different.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器程序的先前列举的示例中，我们描述了一种情况，其中我们有一个阻塞指令，其完成时间无法确定，这是并发使用的第一个模式。还有一个与此类似但略有不同的模式。
- en: If an instruction or a group of instructions take too much time to complete,
    then we can put them in a separate task and run the new task concurrent to the
    main task. This is different from the first pattern because, while we do have
    an estimate of the completion time, albeit not a very accurate one, we do know
    that it won't be soon.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一条指令或一组指令需要太长时间才能完成，那么我们可以将它们放入一个单独的任务中，并使新任务与主任务并发运行。这与第一个模式不同，因为虽然我们确实有一个完成时间的估计，尽管不是非常准确，但我们确实知道它不会很快完成。
- en: The last thing to note about the preceding example, regarding the shared variable,
    `N`, is that one of the tasks, specifically the instance of task `T2`, could change
    its value. Based on our previous discussions in this chapter, this system of concurrent
    tasks is therefore prone to concurrency problems because of it having a shared
    variable that can be modified by one of the tasks.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前面示例中提到的共享变量`N`的最后一件事需要注意，那就是其中一个任务，特别是任务`T2`的实例，可能会改变其值。根据我们在本章前面的讨论，因此这个并发任务系统因此容易受到并发问题的困扰，因为它有一个可以被其中一个任务修改的共享变量。
- en: It's important to note that the solution we proposed for the server program
    is far from perfect. In the next chapter, you'll be introduced to concurrency
    issues, and through it you will see that the preceding example suffers from a
    serious *data race* issue over the shared variable, `N`. As a result, proper control
    mechanisms should be employed to resolve the issues created by concurrency.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，我们为服务器程序提出的解决方案远非完美。在下一章中，你将了解到并发问题，通过它你将看到前面的示例在共享变量`N`上存在严重的*数据竞争*问题。因此，应该采用适当的控制机制来解决并发产生的问题。
- en: In the following and final section in this chapter, we are going to talk about
    the *states* that are shared between some concurrent tasks. We will also introduce
    the concept of *interleaving* and its important consequences for a concurrent
    system with a modifiable shared state.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章接下来的最后一节中，我们将讨论一些并发任务之间共享的*状态*。我们还将介绍*交错*的概念及其对具有可修改共享状态的并发系统的重要影响。
- en: Shared states
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享状态
- en: In the previous section, we talked about the patterns suggesting that we require
    a concurrent system of tasks. Before that, we also briefly explained how the uncertainty
    in the pattern of context switches during the execution of a number of concurrent
    tasks, together with having a modifiable shared state, can lead to non-determinism
    occurring in the overall states of all tasks. This section provides an example
    to demonstrate how this non-determinism can be problematic in a simple program.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了表明我们需要一个并发任务系统的模式。在那之前，我们也简要解释了在执行多个并发任务期间，上下文切换模式的不确定性，以及有一个可修改的共享状态，可能会导致所有任务的总体状态中出现非确定性。本节提供了一个示例，以说明这种非确定性在简单程序中可能带来的问题。
- en: In this section, we are going to continue our discussion and bring in *shared
    states* to see how they contribute to the non-determinism we talked about. As
    a programmer, the term *state* should remind you of a set of variables and their
    corresponding values at a specific time. Therefore, when we are talking about
    the *overall state* of a task, as we defined it in the first section, we are referring
    to the set of all existing non-shared variables, together with their corresponding
    values, at the exact moment when the last instruction of the task has been executed.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将继续我们的讨论，并引入*共享状态*，看看它们如何导致我们之前讨论的非确定性。作为一个程序员，术语*状态*应该让你想到一组变量及其在特定时间的对应值。因此，当我们谈论任务的*整体状态*时，正如我们在第一部分定义的那样，我们指的是在任务执行最后一条指令的确切时刻，所有现有非共享变量及其对应值的集合。
- en: Similarly, an *intermediate state* of a task is the set of all existing non-shared
    variables, together with their values when the task has executed a certain instruction.
    Therefore, a task has a different intermediate state for each of its instructions,
    and the number of intermediate states is equal to the number of instructions.
    According to our definitions, the last intermediate state is the same as the overall
    state of the task.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一个任务的*中间状态*是所有现有非共享变量及其在任务执行特定指令时的值的集合。因此，一个任务对于其每条指令都有一个不同的中间状态，中间状态的数量等于指令的数量。根据我们的定义，最后一个中间状态与任务的整体状态相同。
- en: A shared state is also a set of variables together with their corresponding
    values at a specific time which can be read or modified by a system of concurrent
    tasks. A shared state is not owned by a task (it is not local to a task), and
    it can be read or modified by any of the tasks running in the system, and of course
    at any time.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 共享状态也是一组变量及其在特定时间的对应值，这些变量可以被并发任务系统读取或修改。共享状态不属于任何任务（它不是任务本地的），它可以被系统中的任何任务读取或修改，当然是在任何时间。
- en: Generally, we are not interested in shared states that are read-only. They are
    usually safe to be read by many concurrent tasks, and they don't yield any problem.
    However, a shared state that is modifiable usually yields some serious problems
    if it is not protected carefully. Therefore, all the shared states covered by
    this section are considered to be modifiable by at least by one of the tasks.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们对只读的共享状态不感兴趣。它们通常可以安全地被许多并发任务读取，并且不会产生任何问题。然而，如果一个共享状态是可修改的，并且没有仔细保护，通常会导致一些严重的问题。因此，本节中涵盖的所有共享状态都被认为是至少可以被一个任务修改的。
- en: 'Ask yourself this question: what can go wrong if a shared state is modified
    by one of the concurrent tasks in a system? To answer this, we start by giving
    an example of a system of two concurrent tasks accessing a single shared variable,
    which, in this case, is a simple integer variable.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 自问一下这个问题：如果一个共享状态被系统中的一个并发任务修改，可能会出什么问题？为了回答这个问题，我们首先给出一个例子，即两个并发任务访问单个共享变量的系统，在这种情况下，是一个简单的整数变量。
- en: 'Let''s suppose that we have the following system as displayed in *Code Box
    13-7*:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个如下所示的系统，如*代码框13-7*所示：
- en: '[PRE6]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Code Box 13-7: A system of two concurrent tasks with a modifiable shared state'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框13-7：具有可修改共享状态的两个并发任务系统
- en: Suppose that in the preceding system, tasks `P` and `Q` are not concurrently
    run. Therefore, they become executed sequentially. Suppose that the instructions
    in `P` are executed first, before `Q`. If that was the case, then the overall
    state of the whole system, regardless of the overall state of any individual task,
    would be the shared variable, `X`, with a value of 3.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在前面的系统中，任务`P`和`Q`不是并发运行的。因此，它们变成了顺序执行。假设首先执行`P`中的指令，然后是`Q`。如果是这样，那么整个系统整体状态，无论任何单个任务的整体状态如何，都将是一个值为3的共享变量`X`。
- en: If you run the system in reverse order, first the instructions in `Q` and then
    the instructions in `P`, you will get the same overall state. However, this is
    not usually the case and running two different tasks in a reversed order probably
    leads to a different overall state.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你以相反的顺序运行系统，首先执行`Q`中的指令，然后执行`P`中的指令，你将得到相同的状态。然而，这通常不是情况，以相反的顺序运行两个不同的任务可能会导致不同的整体状态。
- en: As you can see, running these tasks sequentially produces a deterministic result
    without worrying about context switches.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，按顺序运行这些任务会产生一个确定的结果，无需担心上下文切换。
- en: Now, suppose that they are run concurrently on the same CPU core. There are
    many possible scenarios for putting the instructions of `P` and `Q` into execution
    by considering various context switches occurring at various instructions.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设它们在同一个 CPU 核心上并发运行。根据各种指令处的上下文切换，将 `P` 和 `Q` 的指令放入执行有许多可能的场景。
- en: 'The following is a possible scenario:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个可能的场景：
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Code Box 13-8: A possible interleaving of tasks P and Q when run concurrently'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-8：当并发运行任务 P 和 Q 时另一种可能的交错
- en: This scenario is only one of many possible scenarios with context switches happening
    at certain places. Each scenario is called an *interleaving*. So, for a system
    of concurrent tasks, there are a number of possible interleavings based on the
    various places that context switches can happen, and in each run only one of these
    many interleavings will happen. This, as a result, makes them unpredictable.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这种场景只是许多可能场景中的一种，这些场景涉及在特定位置发生上下文切换。每个场景都称为 *交错*。因此，对于并发任务系统，根据上下文切换可能发生的各种位置，存在多种可能的交错方式，而在每次运行中，只有这些众多交错方式中的一个会发生。这，结果，使得它们不可预测。
- en: For the preceding interleaving, as you can see in the first and last column,
    the order of instructions and happens-before constraints are preserved, but there
    could be *gaps* between the executions. These gaps are not predictable, and as
    we trace the execution, the preceding interleaving leads to a surprising result.
    Process `P` prints the value `1` and process `Q` prints the value `2`, yet it
    was expected that both of them would print `3` as their final result.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的交错，如您在第一列和最后一列中看到的那样，指令和 happens-before 约束的顺序得到了保留，但执行之间可能存在 *间隙*。这些间隙是不可预测的，并且当我们跟踪执行时，前面的交错导致了一个令人惊讶的结果。进程
    `P` 打印值 `1`，进程 `Q` 打印值 `2`，但预期它们都会打印 `3` 作为它们的最终结果。
- en: Note that in the preceding example, the constraint for accepting the final result
    has been defined like this – the program should print two `3`s in the output.
    This constraint could be something else, and independent of the visible output
    of the program. More than that, there exist other critical constraints that should
    remain *invariant* when facing unpredictable context switches. These could include
    not having any *data race* or *race condition*, having no memory leak at all,
    or even not to crash. All of these constraints are far more important than the
    visible output of the program. In many real applications, a program doesn't even
    have an output at all.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在前面的例子中，接受最终结果的约束被定义为这样——程序应该在输出中打印两个 `3`。这个约束可能是其他东西，并且与程序的可视输出无关。更重要的是，存在其他关键的约束，在面临不可预测的上下文切换时应该保持
    *不变*。这包括没有任何 *数据竞争* 或 *竞争条件*，没有任何内存泄漏，甚至不崩溃。所有这些约束都比程序的可视输出更重要。在许多实际应用中，程序甚至没有输出。
- en: 'The following in *Code Box 13-9* is another interleaving with a different result:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下在 *代码框 13-9* 中是另一种具有不同结果的交错：
- en: '[PRE8]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Code Box 13-9: Another possible interleaving of tasks P and Q when run concurrently'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 代码框 13-9：当并发运行任务 P 和 Q 时另一种可能的交错
- en: In this interleaving, task `P` prints `3`, but task `Q` prints `2`. This occurs
    due to the fact that task `P` hasn't been lucky enough to update the value of
    the shared variable `X` before the third context switch. Therefore, task `Q` just
    printed the value of `X`, which was `2` at that moment. This condition is called
    a *data race* over the variable `X`, and we explain this further in the upcoming
    chapter.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种交错中，任务 `P` 打印 `3`，但任务 `Q` 打印 `2`。这是由于任务 `P` 在第三次上下文切换之前没有足够幸运地更新共享变量 `X`
    的值。因此，任务 `Q` 只打印了 `X` 在那一刻的值，即 `2`。这种情况被称为变量 `X` 的 *数据竞争*，我们将在下一章中进一步解释。
- en: In a real C program, we usually write `X++` or `X = X + 1` instead of firstly
    copying `X` into `A` and then incrementing `A`, and finally putting it back into
    `X`. You will see an example of this in *Chapter 15*, *Thread Execution*.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际的 C 程序中，我们通常编写 `X++` 或 `X = X + 1` 而不是首先将 `X` 复制到 `A` 中，然后增加 `A`，最后将其放回 `X`。您将在
    *第 15 章*，*线程执行* 中看到这个例子。
- en: This clearly shows that a simple `X++` statement in C consists of three smaller
    instructions that won't be executed in a single time slice. In other words, it
    is not an *atomic instruction*, but it has been made up of three smaller atomic
    instructions. An atomic instruction cannot be broken down into smaller operations
    and it cannot be interrupted by context switches. We will see more of this in
    later chapters regarding multithreading.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这清楚地表明，C 语言中的简单 `X++` 语句实际上由三个更小的指令组成，这些指令不会在单个时间片中执行。换句话说，它不是一个 *原子指令*，但它由三个更小的原子指令组成。原子指令不能被分解成更小的操作，也不能被上下文切换中断。我们将在关于多线程的后续章节中看到更多关于这一点的内容。
- en: There is another thing to consider regarding the preceding example. In the preceding
    example, the tasks `P` and `Q` were not the only running tasks in the system;
    there were also other tasks being executed concurrently to our tasks `P` and `Q`,
    but we didn't consider them in our analysis, and we only discussed those two tasks.
    Why is that?
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个例子中，还有另一件事需要考虑。在前面的例子中，任务 `P` 和 `Q` 并不是系统中唯一正在运行的任务；还有其他任务与我们的任务 `P` 和 `Q`
    同时执行，但我们没有在分析中考虑它们，我们只讨论了这两个任务。为什么是这样？
- en: The answer to this question relies on the fact that the different interleavings
    between any of these two tasks and the other tasks in the system could not change
    the intermediate states of the task `P` or `Q`. In other words, the other tasks
    have no shared state with `P` and `Q`, and as we have explained before, when there
    are no shared resources between some tasks, interleavings won't matter, as we
    can see in this case. Therefore, we could assume that there are no other tasks
    besides `P` and `Q` in our hypothetical system.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的答案在于，这两个任务与系统中其他任务之间的不同交错组合不会改变任务 `P` 或 `Q` 的中间状态。换句话说，其他任务与 `P` 和 `Q`
    没有共享状态，正如我们之前解释的，当某些任务之间没有共享资源时，交错组合就不会重要，就像在这个例子中我们看到的那样。因此，我们可以假设在我们的假设系统中除了
    `P` 和 `Q` 之外没有其他任务。
- en: The only effect that the other tasks have upon `P` and `Q` is that, if there
    are too many of them, they can make `P` and `Q`'s execution slower. That's simply
    a result of having long gaps between two successive instructions in `P` or `Q`.
    In other words, the CPU core needs to be shared among more tasks. Therefore, tasks
    `P` and `Q` would need to wait in the queue more often than normally, delaying
    their execution.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 其他任务对 `P` 和 `Q` 唯一的影响是，如果它们的数量太多，它们可以使 `P` 和 `Q` 的执行变慢。这仅仅是 `P` 或 `Q` 中两个连续指令之间有长间隔的结果。换句话说，CPU
    核心需要被更多任务共享。因此，任务 `P` 和 `Q` 需要更频繁地在队列中等待，从而延迟它们的执行。
- en: Using this example, you saw how even a single shared state between only two
    concurrent tasks could lead to a lack of determinism in the overall result. We
    have shown the problems associated with a lack of determinism; we don't want to
    have a program that yields to a different result in each run. The tasks in our
    example were relatively simple, containing four trivial instructions, but real
    concurrent applications that are present in the production environment are much
    more complex than this.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，你看到了即使是两个并发任务之间的单一共享状态也可能导致整体结果缺乏确定性。我们已经展示了与缺乏确定性相关的问题；我们不希望有一个在不同的运行中产生不同结果的程序。我们例子中的任务相对简单，包含四个平凡的指令，但实际存在于生产环境中的并发应用程序比这要复杂得多。
- en: More than that, we have various kinds of shared resources that don't necessarily
    reside in the memory, such as files or services that are available on the network.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，我们有许多不同类型的共享资源，这些资源不一定驻留在内存中，例如网络上的文件或服务。
- en: Likewise, the number of tasks trying to access a shared resource can be high,
    and therefore we need to study concurrency issues in a deeper sense and find mechanisms
    to bring back determinism. In the next chapter, we'll continue our discussions
    by talking about concurrency issues and the solutions to fix them.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，尝试访问共享资源的任务数量可能很高，因此我们需要更深入地研究并发问题，并找到恢复确定性的机制。在下一章中，我们将继续讨论并发问题和解决这些问题的方法。
- en: Before finishing this chapter, let's briefly talk about the task scheduler and
    how it works. If we only have one CPU core, then, at any given moment, we can
    only have one task using that CPU core.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这一章之前，让我们简要地谈谈任务调度器以及它是如何工作的。如果我们只有一个 CPU 核心，那么在任何给定时刻，我们只能有一个任务使用那个 CPU
    核心。
- en: We also know that the task scheduler itself is a piece of program that needs
    a slice of the CPU core to be executed. So, how does it manage different tasks
    in order to use the CPU core when another task is using it? Let's suppose that
    the task scheduler itself is using the CPU core. Firstly, it selects a task from
    its queue before it sets a timer for a *timer interrupt* to happen, and it then
    leaves the CPU core and gives its resources over to the selected task.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也知道，任务调度器本身是一个需要占用CPU核心执行片段的程序。那么，当另一个任务正在使用CPU核心时，它是如何管理不同任务的？让我们假设任务调度器本身正在使用CPU核心。首先，它在设置一个定时器以发生*定时中断*之前，从其队列中选择一个任务，然后它离开CPU核心并将资源交给所选任务。
- en: Now that we have assumed that the task scheduler will give each task a certain
    amount of time, there is a time that the interrupt will act, and the CPU core
    stops the execution of the current task and immediately loads the task scheduler
    back into the CPU. Now, the scheduler stores the latest status of the previous
    task and loads the next one from the queue. All of this goes on until the kernel
    is up and running. Regarding a machine having a CPU with multiple cores, this
    can change, and the kernel can use various cores while scheduling the tasks for
    other cores.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们假设任务调度器会给每个任务一定的时间，那么中断将会发生，CPU核心停止当前任务的执行，并立即将任务调度器加载回CPU。现在，调度器存储前一个任务的最新状态，并从队列中加载下一个任务。所有这些都会一直进行，直到内核启动并运行。关于具有多核心CPU的机器，这可能会改变，内核可以在调度其他核心的任务时使用多个核心。
- en: In this section, we briefly went over the concept of shared states and the way
    they participate in concurrent systems. The discussions will be continued in the
    next chapter by talking about concurrency issues and synchronization techniques.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要介绍了共享状态的概念以及它们如何在并发系统中参与。讨论将在下一章继续，我们将讨论并发问题和同步技术。
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the basics of concurrency, and the essential
    concepts and terminology that you need to know in order to understand the upcoming
    topics of multithreading and multi-processing.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了并发的基础知识，以及为了理解即将到来的多线程和多处理多进程主题，你需要了解的基本概念和术语。
- en: 'Specifically, we discussed the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们讨论了以下内容：
- en: The definitions of concurrency and parallelism – the fact that each parallel
    task needs to have its own processor unit, while concurrent tasks can share a
    single processor.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发和并行性的定义——即每个并行任务都需要自己的处理器单元，而并发任务可以共享单个处理器。
- en: Concurrent tasks use a single processor unit while a task scheduler manages
    the processor time and shares it between different tasks. This will lead to a
    number context switches and different interleavings for each task.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发任务使用单个处理器单元，而任务调度器管理处理器时间，并在不同任务之间共享。这会导致每个任务都有多个上下文切换和不同的交织。
- en: An introduction to blocking instructions. We also explained the patterns that
    suggest when we require concurrency, and the way we could break a single task
    into two or three concurrent tasks.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻塞指令的介绍。我们还解释了表明我们需要并发的情况的模式，以及我们如何将单个任务分解成两个或三个并发任务。
- en: We described what a shared state is. We also showed how a shared state could
    lead to serious concurrency issues like data races when multiple tasks try to
    read and write the same shared state.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们描述了什么是共享状态。我们还展示了共享状态如何导致严重的并发问题，如当多个任务尝试读取和写入相同的共享状态时，会出现数据竞争。
- en: In the following chapter, we complete our discussion on the topic of concurrency,
    and we explain the several types of issues that you will experience in a concurrent
    environment. Talking about the solutions to concurrency-related issues will also
    be a part of our discussions in the following chapter.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们完成对并发主题的讨论，并解释了在并发环境中你将遇到的各种问题。关于并发相关问题的解决方案也将是我们下一章讨论的一部分。
