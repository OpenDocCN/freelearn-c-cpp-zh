- en: '*Chapter 4*: Turning the Source File into an Abstract Syntax Tree'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：将源文件转换为抽象语法树'
- en: 'A compiler is typically divided into two parts: the frontend and the backend.
    In this chapter, we will implement the frontend of a programming language; that
    is, the part that deals with the source language. We will learn about the techniques
    real-world compilers use and apply them to our own programming languages.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器通常分为两部分：前端和后端。在本章中，我们将实现编程语言的前端；也就是处理源语言的部分。我们将学习真实世界编译器使用的技术，并将其应用到我们自己的编程语言中。
- en: We'll begin our journey by defining our programming language's grammar and end
    it with an **abstract syntax tree (AST)**, which will become the basis for code
    generation. You can use this approach for every programming language that you
    would like to implement a compiler for.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从定义编程语言的语法开始，以 **抽象语法树（AST）** 结束，这将成为代码生成的基础。你可以使用这种方法来为你想要实现编译器的每种编程语言。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下主题：
- en: Defining a real programming language introduces you to the `tinylang` language,
    which is a subset of a real programming language, and for which you must implement
    a compiler frontend.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个真正的编程语言将向你介绍 `tinylang` 语言，它是一个真正编程语言的子集，你必须为其实现一个编译器前端。
- en: Creating the project layout, in which you will create the project layout for
    the compiler.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建项目布局，你将为编译器创建项目布局。
- en: Managing source files and user messages, which gives you knowledge of how to
    handle several input files and how to inform the user about problems in a pleasant
    way.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理源文件和用户消息，这将让你了解如何处理多个输入文件，并以愉快的方式通知用户有关问题。
- en: Structuring the lexer, which discusses how the lexer is broken down into modular
    pieces.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建词法分析器，讨论词法分析器如何分解为模块化部分。
- en: Constructing a recursive descent parser, which will talk about the rules you
    can use to derive a parser from grammar to perform syntax analysis.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个递归下降解析器，将讨论从语法中导出解析器的规则，以执行语法分析。
- en: Generating a parser and lexer with bison and flex, in which you will use tools
    to comfortably generate parsers and lexers from a specification.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 bison 和 flex 生成解析器和词法分析器，你将使用工具舒适地从规范中生成解析器和词法分析器。
- en: Performing semantic analysis, in which you will create the AST and evaluate
    its attributes, which will be intertwined with the parser.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行语义分析，你将创建 AST 并评估其属性，这将与解析器交织在一起。
- en: With the skills you will acquire in this chapter, you will be able to build
    a compiler frontend for any programming language.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章节你将获得的技能，你将能够为任何编程语言构建编译器前端。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code files for the chapter are available at [https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter04](https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter04)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可在[https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter04](https://github.com/PacktPublishing/Learn-LLVM-12/tree/master/Chapter04)找到
- en: You can find the code in action videos at [https://bit.ly/3nllhED](https://bit.ly/3nllhED)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://bit.ly/3nllhED](https://bit.ly/3nllhED)找到代码演示视频
- en: Defining a real programming language
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义一个真正的编程语言
- en: A real programming language brings up more challenges than the simple `tinylang`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个真正的编程语言带来的挑战比简单的 `tinylang` 更多。
- en: 'Let''s take a quick tour of subset of the `tinylang` grammar that will be used
    in this chapter. In the upcoming sections, we will derive the lexer and the parser
    from this grammar:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下本章将使用的 `tinylang` 语法的子集。在接下来的章节中，我们将从这个语法中导出词法分析器和语法分析器：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A compilation unit in Modula-2 begins with the `MODULE` keyword, followed by
    the name of the module. The content of a module can be a list of imported modules,
    declarations, and a block containing statements that run at initialization time:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Modula-2 中的编译单元以 `MODULE` 关键字开始，后面跟着模块的名称。模块的内容可以是导入模块的列表、声明和包含在初始化时运行的语句块：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A declaration introduces constants, variables, and procedures. Constants that
    have been declared are prefixed with the `CONST` keyword. Similarly, variable
    declarations begin with the `VAR` keyword. Declaring a constant is very simple:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 声明引入常量、变量和过程。已声明的常量以 `CONST` 关键字为前缀。同样，变量声明以 `VAR` 关键字开头。声明常量非常简单：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The identifier is the name of the constant. The value is derived from an expression,
    which must be computable at compile time. Declaring variables is a bit more complex:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符是常量的名称。值来自表达式，必须在编译时可计算。声明变量稍微复杂一些：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To be able to declare more than one variable in one go, a list of identifiers
    must be used. The type''s name can potentially come from another module and is
    prefixed with the module name in this case. This is called a qualified identifier.
    A procedure requires the most details:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够一次声明多个变量，必须使用标识符列表。类型的名称可能来自另一个模块，在这种情况下，前缀为模块名称。这称为限定标识符。过程需要最多的细节：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding code, you can see how constants, variables, and procedures
    are declared. Procedures can have parameters and a return type. Normal parameters
    are passed as values, while `VAR` parameters are passed by reference. The other
    part missing from the preceding `block` rule is `statementSequence`, which is
    only a list of single statements:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，你可以看到如何声明常量、变量和过程。过程可以有参数和返回类型。普通参数按值传递，而 `VAR` 参数按引用传递。前面的 `block`
    规则中缺少的另一部分是 `statementSequence`，它只是一个单个语句的列表：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'A statement is delimited by a semicolon if it is followed by another statement.
    Again, only a subset of the *Modula-2* statements is supported:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一个语句如果后面跟着另一个语句，就用分号分隔。再次强调，只支持*Modula-2*语句的一个子集：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The first part of this rule describes an assignment or procedure call. A qualified
    identifier followed by `:=` is an assignment. On the other hand, if it is followed
    by `(`, then it is a procedure call. The other statements are the usual control
    statements:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这条规则的第一部分描述了赋值或过程调用。跟着`:=`的限定符标识符是一个赋值。另一方面，如果它后面跟着`(`，那么它就是一个过程调用。其他语句是通常的控制语句：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `IF` statement has a simplified syntax too, since it can only have a single
    `ELSE` block. With that statement, we can conditionally guard a statement:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`IF`语句的语法也很简化，因为它只能有一个`ELSE`块。有了这个语句，我们可以有条件地保护一个语句：'
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `WHILE` statement describes a loop, guarded by a condition. Together with
    the `IF` statement, this enables us to write simple algorithms in `tinylang`.
    Finally, the definition of an expression is missing:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`WHILE`语句描述了一个由条件保护的循环。与`IF`语句一起，这使我们能够在`tinylang`中编写简单的算法。最后，缺少表达式的定义：'
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The expression syntax is very similar to that of calc in the previous chapter.
    Only the `INTEGER` and `BOOLEAN` data types are supported.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式语法与上一章中的calc非常相似。只支持`INTEGER`和`BOOLEAN`数据类型。
- en: Additionally, the `identifier` and `integer_literal` tokens are used. An `H`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还使用了`identifier`和`integer_literal`标记。一个`H`。
- en: That's already a lot of rules, and we're only covering a part of Modula-2 here!
    Nevertheless, it is possible to write small applications in this subset. Let's
    implement a compiler for `tinylang`!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经是很多规则了，我们只覆盖了Modula-2的一部分！尽管如此，在这个子集中编写小型应用是可能的。让我们为`tinylang`实现一个编译器！
- en: Creating the project layout
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建项目布局
- en: The project layout for `tinylang` follows the approach we laid out in [*Chapter
    2*](B15647_02_ePub_RK.xhtml#_idTextAnchor032), *Touring the LLVM Source*. The
    source code for each component is in a subdirectory of the `lib` directory, while
    the header files are in a subdirectory of `include/tinylang`. The subdirectory
    is named after the component. In [*Chapter 2*](B15647_02_ePub_RK.xhtml#_idTextAnchor032),
    *Touring the LLVM Source*, we only created the `Basic` component.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`tinylang`的项目布局遵循我们在[*第2章*](B15647_02_ePub_RK.xhtml#_idTextAnchor032)中提出的方法，*浏览LLVM源码*。每个组件的源代码都在`lib`目录的子目录中，而头文件在`include/tinylang`的子目录中。子目录的名称取决于组件。在[*第2章*](B15647_02_ePub_RK.xhtml#_idTextAnchor032)中，*浏览LLVM源码*，我们只创建了`Basic`组件。'
- en: 'From the previous chapter, we know that we need to implement a lexer, a parser,
    an AST, and a semantic analyzer. Each is a component of its own, called `Lexer`,
    `Parser`, `AST`, and `Sema`. The directory layout that was used in the previous
    chapter looks like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章我们知道，我们需要实现词法分析器、解析器、AST和语义分析器。每个都是自己的组件，称为`Lexer`、`Parser`、`AST`和`Sema`。在上一章中使用的目录布局如下：
- en: '![Figure 4.1 – The directory layout of the tinylang project'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.1 - tinylang项目的目录布局'
- en: '](img/Figure_4.1_B15647.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_4.1_B15647.jpg)'
- en: Figure 4.1 – The directory layout of the tinylang project
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 - tinylang项目的目录布局
- en: The components have clearly defined dependencies. Here, `Lexer` only depends
    on `Basic`. `Parser` depends on `Basic`, `Lexer`, `AST`, and `Sema`. Finally,
    `Sema` only depends on `Basic` and `AST`. These well-defined dependencies help
    with reusing components.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件有明确定义的依赖关系。在这里，`Lexer`只依赖于`Basic`。`Parser`依赖于`Basic`、`Lexer`、`AST`和`Sema`。最后，`Sema`只依赖于`Basic`和`AST`。这些明确定义的依赖关系有助于重用组件。
- en: Let's have a closer look at their implementation!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看它们的实现！
- en: Managing source files and user messages
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理源文件和用户消息
- en: A real compiler must deal with many files. Usually, the developer calls the
    compiler with the name of the main compilation unit. This compilation unit can
    refer to other files, for example, via `#include` directives in C or `import`
    statements in Python or Modula-2\. An imported module can import other modules
    and so on. All these files must be loaded into memory and run through the analysis
    stages of the compiler. During development, a developer may make syntactical or
    semantical errors. When detected, an error message, including the source line
    and a marker, should be printed. At this point, it should be obvious that this
    essential component is not trivial.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个真正的编译器必须处理许多文件。通常，开发人员使用主编译单元的名称调用编译器。这个编译单元可以引用其他文件，例如，通过C中的`#include`指令或Python或Modula-2中的`import`语句。导入的模块可以导入其他模块，依此类推。所有这些文件必须加载到内存中，并通过编译器的分析阶段运行。在开发过程中，开发人员可能会出现语法或语义错误。一旦检测到，应该打印出包括源行和标记的错误消息。在这一点上，显然可以看出这个基本组件并不是简单的。
- en: 'Luckily, LLVM comes with a solution: the `llvm::SourceMgr` class. A new source
    file is added to `SourceMgr` with a call to the `AddNewSourceBuffer()` method.
    Alternatively, a file can be loaded with a call to the `AddIncludeFile()` method.
    Both methods return an ID to identify the buffer. You use this ID to retrieve
    a pointer to the memory buffer of the associated file. To define a location in
    the file, the `llvm::SMLoc` class must be used. This class encapsulates a pointer
    into the buffer. Various `PrintMessage()` methods allow us to emit errors and
    other informational messages to the user.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，LLVM带有一个解决方案：`llvm::SourceMgr`类。通过调用`AddNewSourceBuffer()`方法向`SourceMgr`添加新的源文件。或者，可以通过调用`AddIncludeFile()`方法加载文件。这两种方法都返回一个ID来标识缓冲区。您可以使用此ID来检索与关联文件的内存缓冲区的指针。要在文件中定义位置，必须使用`llvm::SMLoc`类。这个类封装了一个指向缓冲区的指针。各种`PrintMessage()`方法允许我们向用户发出错误和其他信息消息。
- en: Only a way to centrally define messages is missing. In a large piece of software
    (such as a compiler), you do not want to sprinkle message strings all over the
    place. If there is a request to change messages or translate them into another
    language, then you'd better have them in a central place!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 只缺少一个集中定义消息的方法。在大型软件（如编译器）中，您不希望在各个地方散布消息字符串。如果有要求更改消息或将其翻译成另一种语言，那么最好将它们放在一个中心位置！
- en: 'A simple approach is that each message has an ID (an `enum` member), a severity
    level, and a string containing the messages. In your code, you only refer to the
    message ID. The severity level and message string are only used when the message
    is printed. These three items (the ID, the security level, and the message) must
    be managed consistently. The LLVM libraries use a preprocessor to solve this.
    The data is stored in a file with a`.def` suffix and is wrapped in a macro name.
    That file is usually included several times, with different definitions for the
    macro. The definition of this is in the `include/tinylang/Basic/Diagnostic.def`
    file path and looks as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的方法是每个消息都有一个ID（一个`enum`成员），一个严重程度级别和包含消息的字符串。在你的代码中，你只引用消息ID。当消息被打印时，严重程度级别和消息字符串才会被使用。这三个项目（ID、安全级别和消息）必须一致管理。LLVM库使用预处理器来解决这个问题。数据存储在一个带有`.def`后缀的文件中，并且包装在一个宏名称中。该文件通常被多次包含，使用不同的宏定义。这个定义在`include/tinylang/Basic/Diagnostic.def`文件路径中，看起来如下：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The first macro parameter, `ID`, is the enumeration label, the second parameter,
    `Level`, is the severity, and the third parameter, `Msg`, is the message text.
    With this definition at hand, we can define a `DiagnosticsEngine` class to emit
    error messages. The interface is in the `include/tinylang/Basic/Diagnostic.h`
    file:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个宏参数`ID`是枚举标签，第二个参数`Level`是严重程度，第三个参数`Msg`是消息文本。有了这个定义，我们可以定义一个`DiagnosticsEngine`类来发出错误消息。接口在`include/tinylang/Basic/Diagnostic.h`文件中：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After including the necessary header files, `Diagnostic.def` is now used to
    define the enumeration. To not pollute the global namespace, a nested namespace,
    `diag`, must be used:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含必要的头文件之后，现在使用`Diagnostic.def`来定义枚举。为了不污染全局命名空间，必须使用嵌套命名空间`diag`：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `DiagnosticsEngine` class uses a `SourceMgr` instance to emit the messages
    via the `report()` method. Messages can have parameters. To implement this facility,
    the variadic-format support from LLVM must be used. The message text and the severity
    level are retrieved with the help of the `static` method. As a bonus, the number
    of emitted error messages is also counted:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`DiagnosticsEngine`类使用`SourceMgr`实例通过`report()`方法发出消息。消息可以有参数。为了实现这个功能，必须使用LLVM的可变格式支持。消息文本和严重程度级别是通过`static`方法获取的。作为奖励，发出的错误消息数量也被计算：'
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The message string is returned by `getDiagnosticText()`, while the level is
    returned by `getDiagnosticKind()`. Both methods will be implemented in the `.cpp`
    file later:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 消息字符串由`getDiagnosticText()`返回，而级别由`getDiagnosticKind()`返回。这两个方法将在`.cpp`文件中实现：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Since messages can have a variable number of parameters, the solution in C++
    is to use a variadic template. Of course, this is also used by the `formatv()`
    function provided by LLVM. To get the formatted message, we need only to forward
    the template parameters:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于消息可以有可变数量的参数，C++中的解决方案是使用可变模板。当然，LLVM提供的`formatv()`函数也使用了这个。为了获得格式化的消息，我们只需要转发模板参数：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'With that, we have implemented most of the class. Only `getDiagnosticText()`
    and `getDiagnosticKind()` are missing. They are defined in the `lib/Basic/Diagnostic.cpp`
    file and also make use of the `Diagnostic.def` file:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经实现了大部分的类。只有`getDiagnosticText()`和`getDiagnosticKind()`还没有。它们在`lib/Basic/Diagnostic.cpp`文件中定义，并且还使用了`Diagnostic.def`文件：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As in the header file, the `DIAG` macro is defined to retrieve the desired
    part. Here, we will define an array that will hold the text messages. Therefore,
    the `DIAG` macro only returns the `Msg` part. We will use the same approach for
    the level:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与头文件中一样，`DIAG`宏被定义为检索所需的部分。在这里，我们将定义一个数组来保存文本消息。因此，`DIAG`宏只返回`Msg`部分。我们将使用相同的方法来处理级别：
- en: '[PRE17]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Not surprisingly, both functions simply index the array to return the desired
    data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，这两个函数只是简单地索引数组以返回所需的数据：
- en: '[PRE18]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This combination of the `SourceMgr` and `DiagnosticsEngine` classes provides
    a good basis for the other components. Let's use them in the lexer first!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`SourceMgr`和`DiagnosticsEngine`类的组合为其他组件提供了良好的基础。让我们先在词法分析器中使用它们！'
- en: Structuring the lexer
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建词法分析器
- en: As we know from the previous chapter, we need a `Token` class and a `Lexer`
    class. Additionally, a `TokenKind` enumeration is required to give each token
    class a unique number. Having an all-in-one header and an implementation file
    does not scale, so let's restructure things. The `TokenKind` enumeration can be
    used universally and is placed in the `Basic` component. The `Token` and `Lexer`
    classes belong to the `Lexer` component but are placed in different header and
    implementation files.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们从前一章所知，我们需要一个`Token`类和一个`Lexer`类。此外，还需要一个`TokenKind`枚举，以给每个标记类一个唯一的编号。拥有一个全能的头文件和一个实现文件并不可扩展，所以让我们重新构建一下。`TokenKind`枚举可以被普遍使用，并放在`Basic`组件中。`Token`和`Lexer`类属于`Lexer`组件，但放在不同的头文件和实现文件中。
- en: 'There are three different classes of tokens: `CONST` keyword, the `;` delimiter,
    and the `ident` token, which represent the identifiers in the source. Each token
    needs a member name for the enumeration. Keywords and punctuators have natural
    display names that can be used for messages.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种不同的标记类：`CONST`关键字，`;`分隔符和`ident`标记，代表源代码中的标识符。每个标记都需要一个枚举的成员名称。关键字和标点符号有自然的显示名称，可以用于消息。
- en: Like in many programming languages, the keywords are a subset of the identifiers.
    To classify a token as a keyword, we need a keyword filter, which checks if the
    identifier that's been found is indeed a keyword. This is the same behavior as
    in C or C++, where keywords are also a subset of identifiers. Programming languages
    evolve over time and new keywords may be introduced. As an example, the original
    K&R C language had no enumerations defined with the `enum` keyword. Due to this,
    a flag indicating the language level of a keyword should be present.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多编程语言一样，关键字是标识符的子集。要将标记分类为关键字，我们需要一个关键字过滤器，检查找到的标识符是否确实是关键字。这与C或C++中的行为相同，其中关键字也是标识符的子集。编程语言随着时间的推移而发展，可能会引入新的关键字。例如，最初的K＆R
    C语言没有使用`enum`关键字定义枚举。因此，应该存在一个指示关键字的语言级别的标志。
- en: 'We''ve collected several pieces of information, all of which belong to a member
    of the `TokenKind` enumeration: the label for the enumeration member, the spelling
    of the punctuators, and a flag for the keywords. As for the diagnostic messages,
    we centrally store the information in a `.def` file called `include/tinylang/Basic/TokenKinds.def`,
    which looks as follows. One thing to note is that keywords are prefixed with `kw_`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了几个信息片段，所有这些信息都属于`TokenKind`枚举的成员：枚举成员的标签，标点符号的拼写以及关键字的标志。至于诊断消息，我们将信息集中存储在名为`include/tinylang/Basic/TokenKinds.def`的`.def`文件中，如下所示。需要注意的一点是，关键字以`kw_`为前缀：
- en: '[PRE19]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'With these centralized definitions, it''s easy to create the `TokenKind` enumeration
    in the `include/tinylang/Basic/TokenKinds.h` file. Again, the enumeration is put
    into its own namespace, called `tok`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些集中定义，很容易在`include/tinylang/Basic/TokenKinds.h`文件中创建`TokenKind`枚举。同样，枚举被放入自己的命名空间中，称为`tok`：
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The pattern you must use to fill the array should be familiar by now. The `TOK`
    macro is defined to only return the enumeration label''s `ID`. As a useful addition,
    we also define `NUM_TOKENS` as the last member of the enumeration, denoting the
    number of defined tokens:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该熟悉用于填充数组的模式。`TOK`宏被定义为仅返回枚举标签的`ID`。作为有用的补充，我们还将`NUM_TOKENS`定义为枚举的最后一个成员，表示定义的标记数量：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The implementation file, `lib/Basic/TokenKinds.cpp`, also uses the `.def` file
    to retrieve the names:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实现文件`lib/Basic/TokenKinds.cpp`也使用`.def`文件来检索名称：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The textual name of a token is derived from its enumeration label''s `ID`.
    There are two particularities. First, we need two define the `TOK` and `KEYWORD`
    macros because the default definition of `KEYWORD` does not use the `TOK` macro.
    Second, a `nullptr` value is added at the end of the array, accounting for the
    added `NUM_TOKENS` enumeration member:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 标记的文本名称是从其枚举标签的`ID`派生的。有两个特殊之处。首先，我们需要定义`TOK`和`KEYWORD`宏，因为`KEYWORD`的默认定义不使用`TOK`宏。其次，在数组的末尾添加了一个`nullptr`值，考虑到了添加的`NUM_TOKENS`枚举成员：
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We take a slightly different approach for the `getPunctuatorSpelling()` and
    `getKeywordSpelling()` functions. These functions only return meaningful values
    for a subset of the enumeration. This can be realized with a `switch` statement,
    which returns a `nullptr` value by default:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`getPunctuatorSpelling()`和`getKeywordSpelling()`函数，我们采用了稍微不同的方法。这些函数仅对枚举的子集返回有意义的值。这可以通过`switch`语句实现，它默认返回`nullptr`值：
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Tip
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Note how the macros are defined to retrieve the piece of information that's
    required from the file.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意如何定义宏以从文件中检索所需的信息。
- en: 'In the previous chapter, the `Token` class was declared in the same header
    file as the `Lexer` class. To make this more modular, we will put the `Token`
    class into its own header file in `include/Lexer/Token.h`. As in the previous
    case, `Token` stores a pointer to the start of the token, the length, and the
    token''s kind, as defined previously:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，`Token`类是在与`Lexer`类相同的头文件中声明的。为了使其更模块化，我们将`Token`类放入`include/Lexer/Token.h`的头文件中。与之前一样，`Token`存储了指向标记开头的指针，长度和标记的种类，如之前定义的那样：
- en: '[PRE25]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `SMLoc` instance, which denotes the source''s position in the messages,
    is created from the pointer to the token:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`SMLoc`实例，表示消息中源的位置，是从标记的指针创建的：'
- en: '[PRE26]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `getIdentifier()` and `getLiteralData()` methods allow us to access the
    text of the token for identifiers and literal data. It is not necessary to access
    the text for any other token type, as this is implied by the token''s type:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`getIdentifier()`和`getLiteralData()`方法允许我们访问标识符和文字数据的文本。对于任何其他标记类型，不需要访问文本，因为这是标记类型所暗示的：'
- en: '[PRE27]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We declare the `Lexer` class in the `include/Lexer/Lexer.h` header file and
    put the implementation in the `lib/Lexer/lexer.cpp` file. The structure is the
    same as for the calc language from the previous chapter. Here, we must take a
    closer look at two details:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`include/Lexer/Lexer.h`头文件中声明了`Lexer`类，并将实现放在`lib/Lexer/lexer.cpp`文件中。结构与上一章的calc语言相同。在这里，我们必须仔细看两个细节：
- en: 'First, there are operators that share the same prefix; for example, `<` and
    `<=`. When the current character we''re looking at is a `<`, we must check the
    next character first, before deciding which token we found. Remember that we required
    that the input ends with a null byte. Therefore, the next character can always
    be used if the current character is valid:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，有些运算符共享相同的前缀；例如，`<`和`<=`。当我们正在查看的当前字符是`<`时，我们必须先检查下一个字符，然后再决定我们找到了哪个标记。请记住，我们要求输入以空字节结尾。因此，如果当前字符有效，下一个字符总是可以使用的：
- en: '[PRE28]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The other detail is that at this point, there are far more keywords. How can
    we handle this? A simple and fast solution is to populate a hash table with the
    keywords, which are all stored in the `TokenKinds.def` file. This can be done
    while we instantiate the `Lexer` class. In this approach, it is also possible
    to support different levels of the language, as the keywords can be filtered with
    the attached flag. Here, this flexibility is not needed yet. In the header file,
    the keyword filter is defined as follows, using an instance of `llvm::StringMap`
    for the hash table:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个细节是，在这一点上，关键字要多得多。我们该如何处理？一个简单而快速的解决方案是用关键字填充一个哈希表，这些关键字都存储在“TokenKinds.def”文件中。这可以在我们实例化“Lexer”类的同时完成。在这种方法中，也可以支持语言的不同级别，因为关键字可以根据附加的标志进行过滤。在这里，这种灵活性还不需要。在头文件中，关键字过滤器定义如下，使用“llvm::StringMap”的实例作为哈希表：
- en: '[PRE29]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `getKeyword()` method returns the token kind of the given string, or a
    default value if the string does not represent a keyword:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: “getKeyword()”方法返回给定字符串的标记类型，如果字符串不表示关键字，则返回默认值：
- en: '[PRE30]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the implementation file, the keyword table is filled in:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现文件中，关键字表被填充：
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: With these techniques, it's not difficult to write an efficient lexer class.
    Since compilation speed matters, many compilers use a handwritten lexer, an example
    of which is Clang.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些技巧，编写一个高效的词法分析器类并不难。由于编译速度很重要，许多编译器使用手写的词法分析器，Clang就是一个例子。
- en: Constructing a recursive descent parser
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建递归下降解析器
- en: 'As shown in the previous chapter, the parser is derived from its grammar. Let''s
    recall all the *construction rules*. For each rule of grammar, you create a method
    that''s named after the non-terminal on the left-hand side of the rule in order
    to parse the right-hand side of the rule. Following the definition of the right-hand
    side, you must do the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一章所示，解析器是从其语法派生出来的。让我们回顾一下所有的*构造规则*。对于语法的每个规则，你都要创建一个方法，该方法的名称与规则左侧的非终端相同，以便解析规则的右侧。根据右侧的定义，你必须做到以下几点：
- en: For each non-terminal, the corresponding method is called.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个非终端，都会调用相应的方法。
- en: Each token is consumed.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个标记都被消耗。
- en: For alternatives and optional or repeating groups, the look-ahead token (the
    next unconsumed token) is examined to decide where we can continue from.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于替代和可选或重复组，会检查先行标记（下一个未消耗的标记）以决定我们可以从哪里继续。
- en: 'Let''s apply these construction rules to the following rule of the grammar:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些构造规则应用到语法的以下规则上：
- en: '[PRE32]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can easily translate this into the following C++ method:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地将这个转换成以下的C++方法：
- en: '[PRE33]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The whole grammar of `tinylang` can be turned into C++ in this way. In general,
    you must be careful and avoid some pitfalls.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以将“tinylang”的整个语法转换为C++。一般来说，你必须小心并避免一些陷阱。
- en: 'One issue to look out for is left-recursive rules. A rule is **left-recursive**
    if the right-hand side begins with the same terminal that''s on the left-hand
    side. A typical example can be found in the grammar for expressions:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要注意的一个问题是左递归规则。如果右侧开始的终端与左侧相同，则规则是**左递归**。一个典型的例子可以在表达式的语法中找到：
- en: '[PRE34]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'If it''s not already clear from the grammar, then the following translation
    into C++ should make it obvious that this results in infinite recursion:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从语法中还不清楚，那么将其翻译成C++应该很明显，这会导致无限递归：
- en: '[PRE35]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Left recursion can also indirectly occur and involve more rules, which is much
    more difficult to spot. That's why an algorithm exists that can detect and eliminate
    left recursion.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 左递归也可能间接发生，并涉及更多的规则，这更难以发现。这就是为什么存在一种算法，可以检测和消除左递归。
- en: 'At each step, the parser decides how to continue just by using the look-ahead
    token. The grammar is said to have conflicts if this decision cannot be made deterministically.
    To illustrate this, let''s have a look at the `using` statement in C#. Like in
    C++, the `using` statement can be used to make a symbol visible in a namespace,
    such as in `using Math;`. It is also possible to define an alias name for the
    imported symbol; that is, `using M = Math;`. In grammar, this can be expressed
    as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，解析器只需使用先行标记就可以决定如何继续。如果这个决定不能被确定性地做出，那么就说语法存在冲突。为了说明这一点，让我们来看看C#中的“using”语句。就像在C++中一样，“using”语句可以用来使一个符号在命名空间中可见，比如“using
    Math;”。还可以为导入的符号定义别名；也就是说，“using M = Math;”。在语法中，这可以表示如下：
- en: '[PRE36]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Obviously, there's is a problem here. After the parser consumed the `using`
    keyword, the look-ahead token is `ident`. But this information is not enough for
    us to decide if the optional group must be skipped or parsed. This situation always
    arises if the set of tokens that the optional group can begin with overlap with
    the set of tokens that follow the optional group.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这里存在一个问题。在解析器消耗了“using”关键字之后，先行标记是“ident”。但这个信息对我们来说不足以决定是否必须跳过或解析可选组。如果可选组的开始标记集与可选组后面的标记集重叠，那么这种情况总是会出现。
- en: 'Let''s rewrite the rule with an alternative instead of an optional group:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个替代而不是一个可选组来重写规则：
- en: '[PRE37]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, there is a different conflict: both alternatives begin with the same token.
    Looking only at the look-ahead token, the parser can''t decide which of the alternatives
    is the right one.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有一个不同的冲突：两种选择都以相同的标记开头。只看先行标记，解析器无法确定哪个选择是正确的。
- en: 'These conflicts are very common. Therefore, it''s good to know how to handle
    them. One approach is to rewrite the grammar in such a way that the conflict disappears.
    In the previous example, both alternatives begin with the same token. This can
    be factored out, resulting in the following rule:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这些冲突非常常见。因此，了解如何处理它们是很好的。一种方法是以这样的方式重写语法，使冲突消失。在前面的例子中，两种选择都以相同的标记开头。这可以被分解出来，得到以下规则：
- en: '[PRE38]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This formulation has no conflict. However, it should also be noted that it is
    less expressive. In the other two formulations, it is obvious which `ident` is
    the alias name and which `ident` is the namespace name. In this conflict-free
    rule, the left-most `ident` changes its role. First, it is the namespace name,
    but if an equals sign (`=`) follows it, then it turns into the alias name.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表述没有冲突。但是，也应该注意到它的表达力较弱。在另外两种表述中，很明显哪个`ident`是别名，哪个`ident`是命名空间名称。在这个无冲突的规则中，最左边的`ident`改变了它的角色。首先，它是命名空间名称，但如果后面跟着一个等号（`=`），那么它就变成了别名。
- en: 'The second approach is to add an additional predicate to distinguish between
    both cases. This predicate, often called a `Token &peek(int n)` method, which
    returns the nth token after the current look-ahead token. Here, the existence
    of an equals sign can be used as an additional predicate in the decision:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是添加一个额外的谓词来区分两种情况。这个谓词通常被称为`Token &peek(int n)`方法，它返回当前向前看标记之后的第n个标记。在这里，等号的存在可以作为决定的一个额外谓词：
- en: '[PRE39]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, let's incorporate error recovery. In the previous chapter, I introduced
    the so-called *panic mode* as a technique for error recovery. The basic idea is
    to skip tokens until one is found that is suitable for continuing parsing. For
    example, in `tinylang`, a statement is followed by a semicolon (`:`).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们加入错误恢复。在上一章中，我介绍了所谓的*恐慌模式*作为错误恢复的一种技术。基本思想是跳过标记，直到找到适合继续解析的标记。例如，在`tinylang`中，一个语句后面跟着一个分号（`;`）。
- en: If there is a syntax problem in an `IF` statement, then you skip all the tokens
    until you find a semicolon. Then, you continue with the next statement. Instead
    of using an ad hoc definition for the token set, it's better to use a systematic
    approach.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在`IF`语句中有语法问题，那么你会跳过所有标记，直到找到一个分号为止。然后，你继续下一个语句。不要使用特定的标记集的临时定义，最好使用系统化的方法。
- en: For each non-terminal, you compute the set of tokens that can follow the non-terminal
    anywhere (called the `;`, `ELSE`, and `END` tokens can follow. So, you use this
    set in the error recovery part of `parseStatement()`. This method assumes that
    a syntax error can be handled locally. In general, this is not possible. Because
    the parser skips tokens, it could happen that so many are skipped that the end
    of the input is reached. At this point, local recovery is not possible.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个非终结符，计算可以跟随非终结符的任何地方的标记集（称为`；`，`ELSE`和`END`标记可以跟随）。因此，在`parseStatement()`的错误恢复部分中使用这个集合。这种方法假设可以在本地处理语法错误。一般来说，这是不可能的。因为解析器跳过标记，可能会跳过太多标记，导致到达输入的末尾。在这一点上，本地恢复是不可能的。
- en: 'To prevent meaningless error messages, the calling method needs to be informed
    that error recovery has still not finished. This can be done with the `bool` return
    value: `true` means that error recovery hasn''t finished yet, while `false` means
    that parsing (including possible error recovery) was successful.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止无意义的错误消息，调用方法需要被告知错误恢复仍然没有完成。这可以通过`bool`返回值来实现：`true`表示错误恢复尚未完成，而`false`表示解析（包括可能的错误恢复）成功完成。
- en: There are numerous ways to extend this error recovery scheme. One popular way
    is to also use the FOLLOW sets of the active callers. As a simple example, let's
    assume that `parseStatement()` was called by `parseStatementSequence()`, which
    was itself called by `parseBlock()` and that that was called from `parseModule()`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以扩展这种错误恢复方案。一个流行的方法是还使用活动调用者的FOLLOW集。举个简单的例子，假设`parseStatement()`被`parseStatementSequence()`调用，而后者被`parseBlock()`调用，而后者又被`parseModule()`调用。
- en: Here, each of the corresponding non-terminals has a FOLLOW set. If the parser
    detects a syntax error in `parseStatement()`, then tokens are skipped until the
    token is in at least one of the FOLLOW sets of the active callers. If the token
    is in the FOLLOW set of a statement, then the error was recovered locally, and
    a `false` value is returned to the caller. Otherwise, a `true` value is returned,
    meaning that error recovery must continue. A possible implementation strategy
    for this extension is passing a `std::bitset` or `std::tuple` to represent the
    union of the current FOLLOW sets to the callee.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个相应的非终结符都有一个FOLLOW集。如果解析器在`parseStatement()`中检测到语法错误，那么会跳过标记，直到标记至少在活动调用者的FOLLOW集中的一个中。如果标记在语句的FOLLOW集中，那么错误会在本地恢复，向调用者返回一个`false`值。否则，返回一个`true`值，表示错误恢复必须继续。这种扩展的可能实现策略是将一个`std::bitset`或`std::tuple`传递给被调用者，表示当前FOLLOW集的并集。
- en: 'One last question is still open: how can we call error recovery? In the previous
    chapter, a `goto` was used to jump to the error recovery block. This works but
    is not a pleasing solution. Given the discussion earlier, we can skip tokens in
    a separate method. Clang has a method called `skipUntil()` for this purpose, and
    we can also use this for `tinylang`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个问题尚未解决：我们如何调用错误恢复？在上一章中，使用了`goto`来跳转到错误恢复块。这样做虽然有效，但并不是一个令人满意的解决方案。根据之前的讨论，我们可以在一个单独的方法中跳过标记。Clang有一个名为`skipUntil()`的方法，可以用于这个目的，我们也可以在`tinylang`中使用这个方法。
- en: 'Because the next step is to add semantic actions to the parser, it would be
    nice to have a central place to put cleanup code if necessary. A nested function
    would be ideal for this. C++ does not have a nested function. Instead, a lambda
    function can serve a similar purpose. The `parseIfStatement()` method with complete
    error recovery looks as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 因为接下来要向解析器添加语义动作，如果有必要，最好有一个集中的地方放置清理代码。嵌套函数对此来说是理想的。C++没有嵌套函数。相反，lambda函数可以起到类似的作用。完整的错误恢复的`parseIfStatement()`方法如下所示：
- en: '[PRE40]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Generating a parser and lexer with bison and flex
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用bison和flex生成解析器和词法分析器
- en: Manually constructing a lexer and a parser is not difficult and usually results
    in fast components. The disadvantage is that it is not easy to introduce changes,
    especially in the parser. This can be important if you are prototyping a new programming
    language. Using specialized tools can mitigate this issue.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 手动构建词法分析器和解析器并不困难，通常会产生快速的组件。缺点是很难引入更改，特别是在解析器中。如果您正在原型设计一种新的编程语言，这可能很重要。使用专门的工具可以缓解这个问题。
- en: There are many tools available that generate either a lexer or a parser from
    a specification file. In the Linux world, **flex** (https://github.com/westes/flex)
    and **bison** ([https://www.gnu.org/software/bison/](https://www.gnu.org/software/bison/))
    are the most commonly used tools. Flex generates a lexer from a set of regular
    expressions, while bison generates a parser from a grammar description. Usually,
    both tools are used together.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的工具可以从规范文件生成词法分析器或解析器。在Linux世界中，**flex** (https://github.com/westes/flex)
    和 **bison** ([https://www.gnu.org/software/bison/](https://www.gnu.org/software/bison/))
    是最常用的工具。Flex从一组正则表达式生成词法分析器，而bison从语法描述生成解析器。通常，这两个工具一起使用。
- en: 'Bison produces an `tinylang`, stored in a `tinylang.yy` file, begins with the
    following prologue:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Bison生成的`tinylang`，存储在`tinylang.yy`文件中，以以下序言开始：
- en: '[PRE41]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We instruct bison to generate C++ code with the `%language` directive. Using
    the `%define` directive, we override some default values for the code generation:
    the generated class should be named `Parser` and be inside the `tinylang` namespace
    Additionally, the members of the enumeration representing the token kind should
    be prefixed with `T_`. We require version 3.2 or later, because some of these
    variables were introduced with this version. To be able to interact with flex,
    we tell bison to write a `Parser.h` header file with the `%defines` directive.
    Finally, we must declare all used tokens with the `%token` directive. The grammar
    rules come after `%%`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`%language`指令指示bison生成C++代码。使用`%define`指令，我们覆盖了一些代码生成的默认值：生成的类应该命名为`Parser`，并位于`tinylang`命名空间中。此外，表示标记种类的枚举成员应以`T_`为前缀。我们要求版本为3.2或更高，因为这些变量中的一些是在此版本中引入的。为了能够与flex交互，我们告诉bison使用`%defines`指令写入一个`Parser.h`头文件。最后，我们必须使用`%token`指令声明所有使用的标记。语法规则在`%%`之后：
- en: '[PRE42]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Please compare these rules with the grammar specification shown in the first
    section of this chapter. Bison does not know repeating groups, so we need to add
    a new rule called `imports` to model this repetition. In the `import` rule, we
    must introduce an alternative to model the optional group.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请将这些规则与本章第一节中显示的语法规范进行比较。Bison不知道重复组，因此我们需要添加一个称为`imports`的新规则来模拟这种重复。在`import`规则中，我们必须引入一个替代方案来模拟可选组。
- en: 'We also need to rewrite other rules of the `tinylang` grammar in this style.
    For example, the rule for the `IF` statement becomes the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要以这种方式重写“tinylang”语法的其他规则。例如，“IF”语句的规则变成了以下内容：
- en: '[PRE43]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Again, we must introduce a new rule to model the optional `ELSE` statement.
    The `%empty` directive could be omitted, but the use of it makes it clear that
    this is an empty branch of the alternative.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们必须引入一个新规则来模拟可选的“ELSE”语句。`%empty`指令可以省略，但使用它可以清楚地表明这是一个空的替代分支。
- en: 'Once we''ve rewritten all the grammar rules in the bison style, we can generate
    the parser with the following command:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们以bison风格重写了所有语法规则，就可以使用以下命令生成解析器：
- en: '[PRE44]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: That's all it takes to create a parser that's similar to the handwritten one
    in the previous section!
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是创建一个类似于上一节手写的解析器所需的全部内容！
- en: 'Similarly, flex is easy to use. The specification for flex is a list of regular
    expressions and the associated action, which is executed if the regular expression
    matches. The `tinylang.l` file specifies the lexer for `tinylang`. Like the bison
    specification, it begins with a prologue:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，flex易于使用。Flex的规范是一系列正则表达式和相关联的操作，如果正则表达式匹配，则执行该操作。`tinylang.l`文件指定了`tinylang`的词法分析器。与bison规范一样，它以序言开始：
- en: '[PRE45]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The text inside `%{` `}%` is copied into the file generated by flex. We use
    this mechanism to include the header file generated by bison. With the `%option`
    directive, we control which features the generated lexer should have. We only
    read one file and do not want to continue to read another file once we've reached
    the end of it, so we specify `noyywrap` to disable this feature. We also do not
    need access to the underlying file stream and disable it with `nounput` and `noinout`.
    Finally, because we do not need an interactive lexer, we request that a `batch`
    scanner is generated.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`%{` `}%`内的文本被复制到flex生成的文件中。我们使用这种机制来包含bison生成的头文件。使用`%option`指令，我们控制生成的词法分析器应具有哪些特性。我们只读取一个文件，不希望在到达文件末尾后继续读取另一个文件，因此我们指定`noyywrap`以禁用此功能。我们也不需要访问底层文件流，并使用`nounput`和`noinout`禁用它。最后，因为我们不需要交互式词法分析器，我们要求生成一个`batch`扫描器。'
- en: 'Inside the prologue, we can also define character patterns for later use. After
    `%%` follows the definition section:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在序言中，我们还可以定义字符模式以供以后使用。在`%%`之后是定义部分：
- en: '[PRE46]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In the definition section, you specify a regular expression pattern and an action
    to execute if the pattern matches the input. The action can also be empty.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义部分，您指定一个正则表达式模式和一个要执行的操作，如果模式匹配输入。操作也可以为空。
- en: The `{space}+` pattern uses the `space` character pattern defined in the prologue.
    It matches one or more white space characters. We defined no action, so all white
    space will be ignored.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`{space}+`模式使用序言中定义的`space`字符模式。它匹配一个或多个空白字符。我们没有定义操作，因此所有空白将被忽略。'
- en: 'To match a number, we use the `{digit}+` pattern. As an action, we only return
    the associated token kind. The same is done for all the tokens. For example, we
    do the following for the arithmetic operators:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为了匹配一个数字，我们使用`{digit}+`模式。作为操作，我们只返回相关的标记种类。对于所有标记都是这样做的。例如，我们对算术运算符做如下操作：
- en: '[PRE47]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'If several patterns match the input, then the pattern with the longest match
    is selected. If there is still more than one pattern that matches the input, then
    the pattern that comes first lexicographically in the specification file is chosen.
    That''s why it is important to define the patterns for the keywords first and
    the pattern for identifiers only after all the keywords:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有多个模式匹配输入，则选择最长匹配的模式。如果仍然有多个模式匹配输入，则选择规范文件中按字典顺序排列的第一个模式。这就是为什么首先定义关键字的模式，然后才定义标识符的模式很重要：
- en: '[PRE48]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The actions are not limited to just a `return` statement. If your code needs
    more than one line, then you must surround your code with curly braces `{` `}`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作不仅仅限于`return`语句。如果你的代码需要多于一行，那么你必须用大括号`{` `}`括起你的代码。
- en: 'The scanner is generated with the following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描器是用以下命令生成的：
- en: '[PRE49]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Which approach should you use for your language project? Parser generators usually
    generate LALR(1) parsers. The LALR(1) class is larger than the LL(1) class, which
    recursive descent parsers can be constructed for. If you can't tweak your grammar
    so that it fits in the LL(1) class, then you should consider using a parser generator.
    It's not feasible to construct such a bottom-up parser by hand. Even if your grammar
    is LL(1), a parser generator provides more comfort while producing similar code
    to what you could write by hand. Often, this is a choice that's influenced by
    many factors. Clang uses a handwritten parser, while GCC uses a bison-generated
    parser.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你的语言项目应该使用哪种方法？解析器生成器通常生成LALR(1)解析器。LALR(1)类比LL(1)类更大，递归下降解析器可以构造。如果无法调整语法使其适合LL(1)类，则应考虑使用解析器生成器。手动构造这样的自底向上解析器是不可行的。即使你的语法是LL(1)，解析器生成器提供了更多的舒适性，同时生成的代码与手动编写的代码相似。通常，这是受许多因素影响的选择。Clang使用手写解析器，而GCC使用bison生成的解析器。
- en: Performing semantic analysis
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行语义分析
- en: The parser that we constructed in the previous section only checks the syntax
    of the input. The next step is to add the ability to perform semantic analysis.
    In the calc example in the previous chapter, the parser constructed an AST. In
    a separate phase, the semantic analyzer worked on this tree. This approach can
    always be used. In this section, we will use a slightly different approach and
    intertwine the parser and the semantic analyzer more.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中构造的解析器只检查输入的语法。下一步是添加执行语义分析的能力。在上一章的calc示例中，解析器构造了一个AST。在单独的阶段，语义分析器对这棵树进行了处理。这种方法总是可以使用的。在本节中，我们将使用稍微不同的方法，更加交织解析器和语义分析器。
- en: 'These are some of the tasks a semantic analyzer must perform:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是语义分析器必须执行的一些任务：
- en: For each declaration, the semantic analyzer must check if the used name has
    not been declared elsewhere already.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个声明，语义分析器必须检查所使用的名称是否已经在其他地方声明过。
- en: For each occurrence of a name in an expression or statement, the semantic analyzer
    must check that the name is declared and that the desired use fits the declaration.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于表达式或语句中的每个名称出现，语义分析器必须检查名称是否已声明，并且所需的使用是否符合声明。
- en: For each expression, the semantic analyzer must compute the resulting type.
    It is also necessary to compute if the expression is constant and if so, which
    value it has.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个表达式，语义分析器必须计算结果类型。还需要计算表达式是否是常量，如果是，还需要计算它的值。
- en: For assignment and parameter passing, the semantic analyzer must check that
    the types are compatible. Furthermore, we must check that the conditions in the
    `IF` and `WHILE` statements are of the `BOOLEAN` type.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于赋值和参数传递，语义分析器必须检查类型是否兼容。此外，我们必须检查`IF`和`WHILE`语句中的条件是否为`BOOLEAN`类型。
- en: That's already a lot to check for such a small subset of a programming language!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于编程语言的这么小的子集来说，这已经是很多要检查的了！
- en: Handling the scope of names
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理名称的作用域
- en: 'Let''s have a look at the scope of names first. The scope of a name is the
    range where the name is visible. Like C, `tinylang` uses a declare-before-use
    model. For example, the `B` and `X` variables are declared at the module level
    so that they''re of the `INTEGER` type:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来看看名称的作用域。名称的作用域是名称可见的范围。像C一样，`tinylang`使用先声明后使用的模型。例如，`B`和`X`变量在模块级别声明，因此它们是`INTEGER`类型：
- en: '[PRE50]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Before the declaration, the variables are not known and cannot be used. This
    is only possible after the declaration. Inside a procedure, more variables can
    be declared:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在声明之前，变量是未知的，不能使用。只有在声明之后才能使用。在过程内，可以声明更多的变量：
- en: '[PRE51]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Inside this procedure, at the point where the comment is, using `B` refers to
    the local variable `B`, while using `X` refers to the global variable `X`. The
    scope of the local variable, `B`, is the `Proc` procedure. If a name cannot be
    found in the current scope, then the search continues in the enclosing scope.
    Therefore, the `X` variable can be used inside the procedure. In `tinylang`, only
    modules and procedures open a new scope. Other language constructs such as `struct`
    and `class` usually also open a scope. Predefined entities such as the `INTEGER`
    type or the `TRUE` literal are declared in a global scope, enclosing the scope
    of the module.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程内，在注释所在的位置，使用`B`指的是局部变量`B`，而使用`X`指的是全局变量`X`。局部变量`B`的作用域是`Proc`过程。如果在当前作用域中找不到名称，则在封闭作用域中继续搜索。因此，`X`变量可以在过程内使用。在`tinylang`中，只有模块和过程会打开新的作用域。其他语言构造，如`struct`和`class`通常也会打开作用域。预定义实体，如`INTEGER`类型或`TRUE`文字，是在全局作用域中声明的，包围模块的作用域。
- en: 'In `tinylang`, only the name is crucial. Therefore, a scope can be implemented
    as a mapping from a name to its declaration. A new name can only be inserted if
    it is not already present. For the lookup, the enclosing or parent scope must
    also be known. The interface (in the `include/tinylang/Sema/Scope.h` file) is
    as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在`tinylang`中，只有名称是关键的。因此，作用域可以实现为名称到其声明的映射。只有当名称不存在时才能插入新名称。对于查找，还必须知道封闭或父作用域。接口（在`include/tinylang/Sema/Scope.h`文件中）如下：
- en: '[PRE52]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The implementation in the `lib/Sema/Scope.cpp` file looks as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`lib/Sema/Scope.cpp`文件中的实现如下：'
- en: '[PRE53]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Please note that the `StringMap::insert()` method does not override an existing
    entry. The `second` member of the resulting `std::pair` indicates whether the
    table was updated. This information is returned to the caller.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`StringMap::insert()`方法不会覆盖现有条目。结果`std::pair`的`second`成员指示表是否已更新。此信息返回给调用者。
- en: 'To implement the search for the declaration of a symbol, the `lookup()` method
    searches the current scope; if nothing is found, it searches the scopes that have
    been linked by the `parent` member:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现符号声明的搜索，`lookup()`方法搜索当前作用域；如果找不到任何内容，则搜索由`parent`成员链接的作用域：
- en: '[PRE54]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The variable declaration is then processed as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然后变量声明如下处理：
- en: The current scope is the module scope.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前作用域是模块作用域。
- en: The `INTEGER` type declaration is looked up. It's an error if no declaration
    is found or if it is not a type declaration.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找`INTEGER`类型声明。如果找不到声明或者它不是类型声明，则会出错。
- en: A new AST node, `VariableDeclaration`, is instantiated, with the important attributes
    being the name, `B`, and the type.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例化一个新的AST节点`VariableDeclaration`，重要属性是名称`B`和类型。
- en: The name, `B`, is inserted into the current scope, mapped to the declaration
    instance. If the name is already present in the scope, then this is an error.
    The content of the current scope is not changed in this case.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称`B`被插入到当前作用域中，映射到声明实例。如果名称已经存在于作用域中，则这是一个错误。在这种情况下，当前作用域的内容不会改变。
- en: The same is done for the `X` variable.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对`X`变量也是同样的操作。
- en: Two tasks are performed here. Like in the calc example, AST nodes are constructed.
    At the same time, the attributes of the node, such as its type, are computed.
    Why is this possible?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这里执行了两项任务。就像在calc示例中一样，构造了AST节点。同时，计算了节点的属性，例如其类型。为什么这是可能的？
- en: The semantic analyzer can fall back on two different sets of attributes. The
    scope is inherited from the caller. The type declaration can be computed (or synthesized)
    by evaluating the name of the type declaration. The language is designed in such
    a way that these two sets of attributes are sufficient to compute all the attributes
    of the AST node.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分析器可以回退到两组不同的属性。作用域从调用者那里继承。类型声明可以通过评估类型声明的名称来计算（或合成）。语言设计成这样的方式，这两组属性足以计算AST节点的所有属性。
- en: An important aspect of this is the *declare-before-use* model. If a language
    allows the use of names before declaration, such as the members inside a class
    in C++, then it is not possible to compute all the attributes of an AST node at
    once. In such a case, the AST node must be constructed with only partially computed
    attributes or just with plain information (such as in the calc example).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个重要方面是*先声明后使用*模型。如果一种语言允许在声明之前使用名称，例如C++中类内的成员，那么不可能一次计算AST节点的所有属性。在这种情况下，AST节点必须只用部分计算的属性或纯粹的信息（例如在calc示例中）构造。
- en: The AST must be visited one or more times to determine the missing information.
    In the case of `tinylang` (and Modula-2), it would also be possible to dispense
    with the AST construction – the AST is indirectly represented through the call
    hierarchy of the `parseXXX()` methods. Code generation from an AST is much more
    common, so we construct an AST here, too.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: AST必须被访问一次或多次以确定缺失的信息。在`tinylang`（和Modula-2）的情况下，也可以不使用AST构造 - AST是通过`parseXXX()`方法的调用层次结构间接表示的。从AST生成代码更为常见，因此我们也在这里构造了一个AST。
- en: Before we put all the pieces together, we need to understand the LLVM style
    of using **runtime type information** (**RTTI**).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将所有部分放在一起之前，我们需要了解LLVM使用运行时类型信息（RTTI）的风格。
- en: Using LLVM-style RTTI for the AST
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在AST中使用LLVM风格的RTTI
- en: Naturally, the AST nodes are a part of a class hierarchy. A declaration always
    has a name. Other attributes depend on what is being declared. If a variable is
    declared, then a type is required. A constant declaration needs a type and a value,
    and so on. Of course, at runtime, you need to find out which kind of declaration
    you are working with. The `dynamic_cast<>` C++ operator could be used for this.
    The problem is that the required RTTI is only available if the C++ class has a
    virtual table attached to it; that is, it uses virtual functions. Another disadvantage
    is that C++ RTTI is bloated. To avoid these disadvantages, the LLVM developers
    introduced a self-made RTTI style that is used throughout the LLVM libraries.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，AST节点是类层次结构的一部分。声明总是有一个名称。其他属性取决于正在声明的内容。如果声明了变量，则需要一个类型。常量声明需要一个类型和一个值，依此类推。当然，在运行时，您需要找出正在处理的声明的类型。可以使用`dynamic_cast<>`
    C++运算符来实现这一点。问题在于，如果C++类附有虚表，即使用虚函数，则所需的RTTI才可用；另一个缺点是C++ RTTI过于臃肿。为了避免这些缺点，LLVM开发人员引入了一种自制的RTTI风格，该风格在整个LLVM库中使用。
- en: 'The (abstract) base class of our hierarchy is `Decl`. To implement the LLVM-style
    RTTI, a public enumeration containing a label for each subclass is added. Also,
    a private member of this type and a public getter is required. The private member
    is usually called `Kind`. In our case, this looks like this:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们层次结构的（抽象）基类是`Decl`。为了实现LLVM风格的RTTI，需要添加一个包含每个子类标签的公共枚举。此外，还需要一个私有成员和一个公共getter方法。私有成员通常称为`Kind`。在我们的情况下，看起来是这样的：
- en: '[PRE55]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Each subclass now needs a special function member called `classof`. The purpose
    of this function is to determine if a given instance is of the requested type.
    For a `VariableDeclaration`, it is implemented as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每个子类都需要一个名为`classof`的特殊函数成员。此函数的目的是确定给定实例是否是请求的类型。对于`VariableDeclaration`，它的实现如下：
- en: '[PRE56]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Now, you can use the `llvm::isa<>` special templates to check if an object is
    of the requested type and `llvm::dyn_cast<>` to dynamically cast the object. There
    are more templates that exist, but these two are the most commonly used ones.
    For the other templates, see [https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates](https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates)
    and for more information about the LLVM style, including more advanced uses, see
    [https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html](https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用`llvm::isa<>`特殊模板来检查对象是否是请求类型的对象，并使用`llvm::dyn_cast<>`来动态转换对象。还有更多的模板存在，但这两个是最常用的。有关其他模板，请参见[https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates](https://llvm.org/docs/ProgrammersManual.html#the-isa-cast-and-dyn-cast-templates)，有关LLVM样式的更多信息，包括更高级的用法，请参见[https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html](https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html)。
- en: Creating the semantic analyzer
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建语义分析器
- en: 'Equipped with this knowledge, we can now implement the semantic analyzer, operating
    on AST nodes created by the parser. First, we will implement the definition of
    the AST node for a variable, which is stored in the `include/llvm/tinylang/AST/AST.h`
    file. Besides support for the LLVM-style RTTI, the base class stores the name
    of the declaration, the location of its name, and a pointer to the enclosing declaration.
    The latter is required to code-generate nested procedures. The `Decl` base class
    is declared as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些知识，我们现在可以实现语义分析器，它操作由解析器创建的AST节点。首先，我们将实现存储在`include/llvm/tinylang/AST/AST.h`文件中的变量的AST节点的定义。除了支持LLVM样式的RTTI外，基类还存储声明的名称、名称的位置和指向封闭声明的指针。后者是为了生成嵌套过程所必需的。`Decl`基类声明如下：
- en: '[PRE57]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The declaration for a variable only adds a pointer to the type declaration:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的声明只是添加了指向类型声明的指针：
- en: '[PRE58]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The method in the parser needs to be extended with a semantic action and variables
    for the information that''s been collected:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器中的方法需要扩展语义动作和已收集信息的变量：
- en: '[PRE59]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: A `DeclList` is a list of declarations called `std::vector<Decl*>`, while `IdentList`
    is a list of locations and identifiers called `std::vector<std::pair<SMLoc, StringRef>>`.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeclList`是一个称为`std::vector<Decl*>`的声明列表，而`IdentList`是一个称为`std::vector<std::pair<SMLoc,
    StringRef>>`的位置和标识符列表。'
- en: The `parseQualident()` method returns a declaration, which in this case is expected
    to be a type declaration.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`parseQualident()`方法返回一个声明，在这种情况下，预期是一个类型声明。'
- en: 'The parser class knows an instance of the semantic analyzer class, `Sema`,
    which is stored in the `Actions` member. A call to `actOnVariableDeclaration()`
    runs the semantic analyzer and the AST construction. The implementation is in
    the `lib/Sema/Sema.cpp` file:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器类知道语义分析器类`Sema`的一个实例，它存储在`Actions`成员中。调用`actOnVariableDeclaration()`运行语义分析器和AST构造。实现在`lib/Sema/Sema.cpp`文件中：
- en: '[PRE60]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: First, the type declaration is check with `llvm::dyn_cast<TypeDeclaration>`.
    If it is not a type declaration, then an error message is printed. Otherwise,
    for each name in the `Ids` list, a `VariableDeclaration` is instantiated and added
    to the list of declarations. If adding the variable to the current scope fails
    because the name has already been declared, then an error message is printed.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用`llvm::dyn_cast<TypeDeclaration>`检查类型声明。如果它不是类型声明，则打印错误消息。否则，对于`Ids`列表中的每个名称，实例化一个`VariableDeclaration`并将其添加到声明列表中。如果将变量添加到当前作用域失败，因为名称已经被声明，则打印错误消息。
- en: 'Most of the other entities are constructed in the same way, with the complexity
    of their semantic analysis being the only difference. More work is required for
    modules and procedures because they open a new scope. Opening a new scope is easy:
    only a new `Scope` object must be instantiated. As soon as the module or procedure
    has been parsed, the scope must be removed.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数其他实体以相同的方式构建，它们的语义分析复杂性是唯一的区别。模块和过程需要更多的工作，因为它们打开了一个新的作用域。打开一个新的作用域很容易：只需实例化一个新的`Scope`对象。一旦模块或过程被解析，作用域必须被移除。
- en: 'This must be done in a reliable fashion because we do not want to add names
    to the wrong scope in case of a syntax error. This is a classic use of the **Resource
    Acquisition Is Initialization** (**RAII**) idiom in C++. Another complication
    comes from the fact that a procedure can recursively call itself. Due to this,
    the name of the procedure must be added to the current scope before it can be
    used. The semantic analyzer has two methods to enter and leave a scope. The scope
    is associated with a declaration:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这必须以可靠的方式完成，因为我们不希望在语法错误的情况下将名称添加到错误的作用域中。这是C++中**资源获取即初始化**（**RAII**）习惯用法的经典用法。另一个复杂性来自于过程可以递归调用自身的事实。因此，必须在使用之前将过程的名称添加到当前作用域中。语义分析器有两种方法可以进入和离开作用域。作用域与声明相关联：
- en: '[PRE61]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'A simple helper class is used to implement the RAII idiom:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的辅助类用于实现RAII习惯用法：
- en: '[PRE62]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'While parsing a module or procedure, there are now two interactions with the
    semantic analyzer. The first is after the name is parsed. Here, the (almost empty)
    AST node is constructed, and a new scope is established:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析模块或过程时，现在有两种与语义分析器的交互。第一种是在解析名称之后。在这里，（几乎为空的）AST节点被构造，并建立了一个新的作用域：
- en: '[PRE63]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The semantic analyzer does more than check the name in the current scope and
    return the AST node:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分析器不仅仅是检查当前作用域中的名称并返回AST节点：
- en: '[PRE64]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The real work is done once all the declarations and the procedure''s body have
    been parsed. Basically, the semantic analyzer must only check if the name at the
    end of the procedure declaration is equal to the name of the procedure, and also
    if the declaration that''s used for the return type is really a type declaration:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有声明和过程的主体被解析，真正的工作就开始了。基本上，语义分析器只需要检查过程声明末尾的名称是否等于过程的名称，并且用于返回类型的声明是否真的是一个类型声明：
- en: '[PRE65]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Some declarations are inherently present and cannot be defined by the developer.
    This includes the `BOOLEAN` and `INTEGER` types and the `TRUE` and `FALSE` literals.
    These declarations exist in the global scope and must be added programmatically.
    Modula-2 also predefines some procedures, such as `INC` or `DEC`, which should
    also be added to the global scope. Given our classes, the initialization of the
    global scope is simple:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一些声明是固有的，无法由开发人员定义。这包括`BOOLEAN`和`INTEGER`类型以及`TRUE`和`FALSE`字面量。这些声明存在于全局范围，并且必须以编程方式添加。Modula-2还预定义了一些过程，例如`INC`或`DEC`，这些过程也应该添加到全局范围。鉴于我们的类，全局范围的初始化很简单：
- en: '[PRE66]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'With this scheme, all the required calculations for `tinylang` can be done.
    For example, to compute if an expression results in a constant value, you must
    ensure the following occurs:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个方案，“tinylang”的所有必需计算都可以完成。例如，要计算表达式是否产生常量值，您必须确保发生以下情况：
- en: A literal or a reference to a constant declaration is constant.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字面量或对常量声明的引用是常量。
- en: If both sides of an expression are constant, then applying the operator also
    yields a constant.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果表达式的两侧都是常量，那么应用运算符也会产生一个常量。
- en: These rules are easily embedded into the semantic analyzer while creating the
    AST nodes for an expression. Likewise, the type and the constant value can be
    computed.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规则很容易嵌入到语义分析器中，同时为表达式创建AST节点。同样，类型和常量值可以被计算。
- en: It should be noted that not all kinds of computations can be done in this way.
    For example, to detect the use of uninitialized variables, a method called symbolic
    interpretation can be used. In its general form, the method requires a special
    walk order through the AST, which is not possible during construction time. The
    good news is that the presented approach creates a fully decorated AST, which
    is ready for code generation. This AST can, of course, be used for further analysis,
    given the fact that costly analysis can be turned on or off on demand.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 应该指出，并非所有类型的计算都可以以这种方式完成。例如，要检测未初始化变量的使用，可以使用一种称为符号解释的方法。在其一般形式中，该方法需要通过AST的特殊遍历顺序，这在构建时是不可能的。好消息是，所提出的方法创建了一个完全装饰的AST，可以用于代码生成。当然，可以根据需要打开或关闭昂贵的分析，这个AST当然可以用于进一步的分析。
- en: 'To play around with the frontend, you also need to update the driver. Since
    the code generation is missing, a correct `tinylang` program produces no output.
    Still, it can be used to explore error recovery and to provoke semantic errors:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要玩转前端，您还需要更新驱动程序。由于缺少代码生成，正确的“tinylang”程序不会产生任何输出。但是，它可以用来探索错误恢复并引发语义错误：
- en: '[PRE67]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Congratulations! You've finished implementing the frontend for `tinylang`!
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已经完成了对“tinylang”前端的实现！
- en: 'Now, let''s try out what we have learned so far. Save the following source,
    which is an implementation of Euclid''s greatest common divisor algorithm, as
    a `Gcd.mod` file:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试一下我们到目前为止学到的东西。保存以下源代码，这是欧几里德最大公约数算法的实现，保存为`Gcd.mod`文件：
- en: '[PRE68]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Let''s run the compiler on this file with the following command:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用以下命令在这个文件上运行编译器：
- en: '[PRE69]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: There is no output except the version number being printed. This is because
    only the frontend part has been implemented. However, if you change the source
    so that it contains syntax errors, then error messages will be printed.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 除了打印版本号之外，没有其他输出。这是因为只实现了前端部分。但是，如果更改源代码以包含语法错误，那么将打印错误消息。
- en: We'll continue this fun by adding code generation, which is the topic of the
    next chapter.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章讨论代码生成，继续这个有趣的话题。
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about the techniques a real-world compiler uses
    in the frontend. Starting with the project's layout, you created separate libraries
    for the lexer, the parser, and the semantic analyzer. To output messages to the
    user, you extended an existing LLVM class, which allowed the messages to be stored
    centrally. The lexer has now been separated into several interfaces.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了现实世界编译器在前端使用的技术。从项目的布局开始，您为词法分析器、解析器和语义分析器创建了单独的库。为了向用户输出消息，您扩展了现有的LLVM类，这允许消息被集中存储。词法分析器现在已经分成了几个接口。
- en: You then learned how to construct a recursive descent parser from a grammar
    description, which pitfalls to avoid, and how to use generators to do the job.
    The semantic analyzer you constructed performs all the semantic checks that are
    required by the language while being intertwined with the parser and AST construction.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您学会了如何从语法描述中构建递归下降解析器，要避免哪些陷阱，以及如何使用生成器来完成工作。您构建的语义分析器执行了语言所需的所有语义检查，同时与解析器和AST构造交织在一起。
- en: The result of your coding effort was a fully decorated AST, which will be used
    in the next chapter to generate IR code and object code.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 您的编码工作的结果是一个完全装饰的AST，将在下一章中用于生成IR代码和目标代码。
