- en: Parallelism and Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行性和并发性
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Automatically parallelizing code that uses standard algorithms
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动并行化使用标准算法的代码
- en: Putting a program to sleep for specific amounts of time
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让程序在特定时间内休眠
- en: Starting and stopping threads
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动和停止线程
- en: Performing exception-safe shared locking with `std::unique_lock` and `std::shared_lock`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::unique_lock`和`std::shared_lock`执行异常安全的共享锁定
- en: Avoiding deadlocks with `std::scoped_lock`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::scoped_lock`避免死锁
- en: Synchronizing concurrent `std::cout` use
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步并发的`std::cout`使用
- en: Safely postponing initialization with `std::call_once`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::call_once`安全地延迟初始化
- en: Pushing the execution of tasks into the background using `std::async`
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::async`将任务执行推入后台
- en: Implementing the producer/consumer idiom with `std::condition_variable`
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::condition_variable`实现生产者/消费者模式
- en: Implementing the multiple producers/consumers idiom with `std::condition_variable`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::condition_variable`实现多个生产者/消费者模式
- en: Parallelizing the ASCII Mandelbrot renderer using `std::async`
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::async`并行化ASCII Mandelbrot渲染器
- en: Implementing a tiny automatic parallelization library with `std::future`
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`std::future`实现一个小型自动并行化库
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Before C++11, C++ didn't have much support for parallelization. This does not
    mean that starting, controlling, stopping, and synchronizing threads was not possible,
    but it was necessary to use operating system-specific libraries because threads
    are inherently operating system-related.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++11之前，C++对并行化的支持并不多。这并不意味着启动、控制、停止和同步线程是不可能的，但是必须使用特定于操作系统的库，因为线程本质上与操作系统相关。
- en: With C++11, we got `std::thread`, which enables basic portable thread control
    across all operating systems. For synchronizing threads, C++11 also introduced
    mutex classes and comfortable RAII-style lock wrappers. In addition to that, `std::condition_variable`
    allows for flexible event notification between threads.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用C++11，我们得到了`std::thread`，它可以在所有操作系统上进行基本的可移植线程控制。为了同步线程，C++11还引入了互斥类和舒适的RAII风格的锁包装器。除此之外，`std::condition_variable`允许线程之间灵活地进行事件通知。
- en: Some other really interesting additions are `std::async` and `std::future`--we
    can now wrap arbitrary normal functions into `std::async` calls in order to execute
    them asynchronously in the background. Such wrapped functions return `std::future`
    objects that promise to contain the result of the function later, so we can do
    something else before we wait for its arrival.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他非常有趣的添加是`std::async`和`std::future`--我们现在可以将任意普通函数包装成`std::async`调用，以便在后台异步执行它们。这样包装的函数返回`std::future`对象，承诺稍后包含函数结果，因此我们可以在等待其到达之前做其他事情。
- en: Another actually enormous improvement to the STL are *execution policies*, which
    can be added to 69 of the already *existing* algorithms. This addition means that
    we can just add a single execution policy argument to the existing standard algorithm
    calls in our old programs and get parallelization without complex rewrites.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: STL的另一个实际上巨大的改进是*执行策略*，可以添加到69个已经*存在*的算法中。这个添加意味着我们可以在旧程序中的现有标准算法调用中添加一个单一的执行策略参数，从而实现并行化，而无需进行复杂的重写。
- en: In this chapter, we will go through all these additions in order to learn the
    most important things about them. Afterward, we'll have enough oversight of the
    parallelization support in the C++17 STL. We do not cover all the details, but
    the most important ones. The overview gained from this book helps in quickly understanding
    the rest of the parallel programming mechanisms, which you can always look up
    in the C++ 17 STL documentation online.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将逐个介绍所有这些添加内容，以便了解其中最重要的内容。之后，我们将对C++17 STL中的并行化支持有足够的概览。我们不涵盖所有细节，但是最重要的部分。从本书中获得的概览有助于快速理解C++
    17 STL在线文档中的其余并行编程机制。
- en: Finally, this chapter contains two bonus recipes. In one recipe, we will parallelize
    the Mandelbrot ASCII renderer from [Chapter 23](897bfd02-6f27-4b2c-b44d-052811364259.xhtml),
    *Advance Use of STL Algorithms*, with only minimal changes. In the last recipe,
    we will implement a tiny library that helps parallelizing complex tasks implicitly
    and automatically.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，本章包含两个额外的示例。在一个示例中，我们将使用最小的更改来并行化[第23章](897bfd02-6f27-4b2c-b44d-052811364259.xhtml)中的Mandelbrot
    ASCII渲染器，*STL算法的高级使用*。在最后一个示例中，我们将实现一个小型库，以隐式和自动地帮助并行化复杂任务。
- en: Automatically parallelizing code that uses standard algorithms
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动并行化使用标准算法的代码
- en: 'C++17 came with one really *major* extension for parallelism: e*xecution policies*
    for standard algorithms. Sixty nine algorithms were extended to accept execution
    policies in order to run parallel on multiple cores, and even with enabled vectorization.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: C++17带来了一个非常重要的并行扩展：标准算法的*执行策略*。六十九个算法被扩展以接受执行策略，以便在多个核心上并行运行，甚至启用矢量化。
- en: For the user, this means that if we already use STL algorithms everywhere, we
    get a nice parallelization bonus for free. We can *easily* give our applications
    subsequent parallelization by simply adding a single execution policy argument
    to our existing STL algorithm calls.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于用户来说，这意味着如果我们已经在所有地方使用STL算法，我们可以免费获得一个不错的并行化奖励。我们可以通过简单地向现有的STL算法调用中添加一个单一的执行策略参数，轻松地为我们的应用程序提供后续的并行化。
- en: In this recipe, we will implement a simple program (with a not too serious use
    case scenario) that lines up multiple STL algorithm calls. While using these,
    we will see how easy it is to use C++17 execution policies in order to let them
    run multithreaded. In the last subsections of this section, we will have a closer
    look at the different execution policies.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将实现一个简单的程序（具有不太严肃的用例场景），排列多个STL算法调用。在使用这些算法时，我们将看到使用C++17执行策略是多么容易，以便让它们多线程运行。在本节的最后几个小节中，我们将更仔细地研究不同的执行策略。
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In this section, we will write a program that uses some standard algorithms.
    The program itself is more of an example of how real-life scenarios can look than
    doing actual real-life work situation. While using these standard algorithms,
    we are embedding execution policies in order to speed the code up:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将编写一个使用一些标准算法的程序。程序本身更多地是一个示例，展示了现实生活中的情景可能是什么样子，而不是真正的实际工作情况。在使用这些标准算法时，我们嵌入了执行策略以加快代码速度：
- en: 'First, we need to include some headers and declare that we use the `std` namespace.
    The `execution` header is a new one; it came with C++17:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要包含一些头文件，并声明我们使用`std`命名空间。`execution`头文件是一个新的头文件；它是C++17中新增的：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Just for the sake of the example, we''ll declare a predicate function that
    tells whether a number is odd. We will use it later:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅仅为了示例，我们将声明一个谓词函数，告诉一个数字是否是奇数。我们稍后会用到它：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s first define a large vector in our main function. We will fill it with
    a lot of data so that it takes some time to do calculations on it. The execution
    speed of this code will vary *a lot*, depending on the computer this code is executed
    on. Smaller/larger vector sizes might be better on different computers:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先在主函数中定义一个大向量。我们将用大量数据填充它，以便对其进行计算需要一些时间。这段代码的执行速度将会*很大*地变化，取决于执行这段代码的计算机。在不同的计算机上，较小/较大的向量大小可能更好：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In order to get a lot of random data for the vector, let''s instantiate a random
    number generator along with a distribution and pack them up in a callable object.
    If this looks strange to you, please first have a look at the recipes that deal
    with random number generators and distributions in [Chapter 25](bfd75fad-20a0-40bc-a783-12b3281a00bf.xhtml),
    *Utility Classes*:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了获得大量的随机数据用于向量，让我们实例化一个随机数生成器和一个分布，并将它们打包在一个可调用对象中。如果这对你来说看起来很奇怪，请先看一下处理随机数生成器和分布的示例，[第25章](bfd75fad-20a0-40bc-a783-12b3281a00bf.xhtml)，*实用类*：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let''s use the `std::generate` algorithm to fill the vector with random
    data. There is a new C++17 version of this algorithm, which can take a new kind
    of argument: an execution policy. We put in `std::par` here, which allows for
    automatic parallelization of this code. By doing this, we allow for multiple threads
    to start filling the vector together, which reduces the execution time if the
    computer has more than one CPU, which is usually the case with modern computers:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`std::generate`算法来填充向量的随机数据。这个算法有一个新的C++17版本，可以接受一种新类型的参数：执行策略。我们在这里放入了`std::par`，它允许自动并行化这段代码。通过这样做，我们允许多个线程同时开始填充向量，这样可以减少执行时间，如果计算机有多个CPU的话，这通常是现代计算机的情况：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `std::sort` method should also already be familiar. The C++17 version does
    also support an additional argument defining the execution policy:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`std::sort` 方法也应该已经很熟悉了。C++17版本也支持一个额外的参数来定义执行策略：'
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The same applies to `std::reverse`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`std::reverse`也是一样的：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then we use `std::count_if` to count all the odd numbers in the vector. And
    we can even parallelize that by just adding an execution policy again!
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用`std::count_if`来计算向量中所有奇数的个数。我们甚至可以通过只添加一个执行策略来并行化它！
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This whole program did not do any *real* scientific work, as we were just going
    to have a look on how to parallelize standard algorithms, but let''s print something
    in the end:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整个程序并没有做任何*真正*的科学工作，因为我们只是要看一下如何并行化标准算法，但最后让我们打印一些东西：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Compiling and running the program gives us the following output. At this point,
    it is interesting to see how the execution speed differs when using the algorithms
    without an execution policy compared with all the other execution policies. Doing
    this is left as an exercise for the reader. Try it; the available execution policies
    are `seq`, `par`, and `par_vec`. We should get different execution times for each
    of them:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序会给我们以下输出。在这一点上，有趣的是看到在使用算法时，不带执行策略与所有其他执行策略相比，执行速度有何不同。这留给读者作为一个练习。试一试；可用的执行策略有`seq`、`par`和`par_vec`。我们应该得到每个执行策略的不同执行时间：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works...
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Especially since this recipe did not distract us with any complicated real-life
    problem solution, we were able to fully concentrate on the standard library function
    calls. It is pretty obvious that the their parallelized versions are hardly different
    from the classic sequential ones. They only differ by *one additional* argument,
    which is the *execution policy*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是因为这个示例没有让我们分心于任何复杂的现实问题解决方案，我们能够完全集中精力在标准库函数调用上。很明显，它们的并行化版本与经典的顺序版本几乎没有区别。它们只是多了一个参数，即*执行策略*。
- en: 'Let''s have a look at the invocations and answer three central questions:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下调用并回答三个核心问题：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Which STL algorithms can we parallelize this way?
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们可以用这种方式并行化哪些STL算法？
- en: Sixty nine of the existing STL algorithms were upgraded to support parallelism
    in the C++17 standard, and there are seven new ones that also support parallelism.
    While such an upgrade might be pretty invasive for the implementation, not much
    has changed in terms of their interface--they all got an additional `ExecutionPolicy&&
    policy` argument, and that's it. This does *not* mean that we *always* have to
    provide an execution policy argument. It is just that they *additionally* support
    accepting an execution policy as their first argument.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++17标准中，现有的69个STL算法升级为支持并行处理，还有七个新算法也支持并行处理。虽然这样的升级对于实现来说可能相当具有侵入性，但在接口方面并没有太多改变--它们都增加了一个额外的`ExecutionPolicy&&
    policy`参数，就是这样。这*不*意味着我们*总是*必须提供执行策略参数。只是它们*另外*支持接受执行策略作为它们的第一个参数。
- en: 'These are the 69 upgraded standard algorithms. There are also the seven new
    ones that support execution policies from the beginning (highlighted in *bold*):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是升级的69个标准算法。还有七个新的算法从一开始就支持执行策略（用*粗体*标出）：
- en: '| `std::adjacent_difference` `std::adjacent_find`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '| `std::adjacent_difference` `std::adjacent_find`'
- en: '`std::all_of`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::all_of`'
- en: '`std::any_of`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::any_of`'
- en: '`std::copy`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::copy`'
- en: '`std::copy_if`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::copy_if`'
- en: '`std::copy_n`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::copy_n`'
- en: '`std::count`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::count`'
- en: '`std::count_if`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::count_if`'
- en: '`std::equal` `**std::exclusive_scan**`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::equal` `**std::exclusive_scan**`'
- en: '`std::fill`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::fill`'
- en: '`std::fill_n`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::fill_n`'
- en: '`std::find`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::find`'
- en: '`std::find_end`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::find_end`'
- en: '`std::find_first_of`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::find_first_of`'
- en: '`std::find_if`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::find_if`'
- en: '`std::find_if_not` `**std::for_each**`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::find_if_not` `**std::for_each**`'
- en: '`**std::for_each_n**`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`**std::for_each_n**`'
- en: '`std::generate`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::generate`'
- en: '`std::generate_n`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::generate_n`'
- en: '`std::includes` `**std::inclusive_scan**`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::includes` `**std::inclusive_scan**`'
- en: '`std::inner_product` | `std::inplace_merge` `std::is_heap` `std::is_heap_until`
    `std::is_partitioned`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::inner_product` | `std::inplace_merge` `std::is_heap` `std::is_heap_until`
    `std::is_partitioned`'
- en: '`std::is_sorted`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::is_sorted`'
- en: '`std::is_sorted_until`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::is_sorted_until`'
- en: '`std::lexicographical_compare`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::lexicographical_compare`'
- en: '`std::max_element`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::max_element`'
- en: '`std::merge`'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::merge`'
- en: '`std::min_element`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::min_element`'
- en: '`std::minmax_element`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::minmax_element`'
- en: '`std::mismatch`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::mismatch`'
- en: '`std::move`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::move`'
- en: '`std::none_of`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::none_of`'
- en: '`std::nth_element`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::nth_element`'
- en: '`std::partial_sort`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::partial_sort`'
- en: '`std::partial_sort_copy`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::partial_sort_copy`'
- en: '`std::partition`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::partition`'
- en: '`std::partition_copy`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::partition_copy`'
- en: '`std::remove`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::remove`'
- en: '`std::remove_copy`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::remove_copy`'
- en: '`std::remove_copy_if`'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::remove_copy_if`'
- en: '`std::remove_if`'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::remove_if`'
- en: '`std::replace`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::replace`'
- en: '`std::replace_copy`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::replace_copy`'
- en: '`std::replace_copy_if` | `std::replace_if` `std::reverse`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::replace_copy_if` | `std::replace_if` `std::reverse`'
- en: '`std::reverse_copy`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::reverse_copy`'
- en: '`std::rotate`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::rotate`'
- en: '`std::rotate_copy`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::rotate_copy`'
- en: '`std::search`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::search`'
- en: '`std::search_n`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::search_n`'
- en: '`std::set_difference`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::set_difference`'
- en: '`std::set_intersection`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::set_intersection`'
- en: '`std::set_symmetric_difference`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::set_symmetric_difference`'
- en: '`std::set_union`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::set_union`'
- en: '`std::sort`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::sort`'
- en: '`std::stable_partition`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::stable_partition`'
- en: '`std::stable_sort`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::stable_sort`'
- en: '`std::swap_ranges`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::swap_ranges`'
- en: '`std::transform`'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::transform`'
- en: '`**std::transform_exclusive_scan**` `**std::transform_inclusive_scan**` `**std::transform_reduce**`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`**std::transform_exclusive_scan**` `**std::transform_inclusive_scan**` `**std::transform_reduce**`'
- en: '`std::uninitialized_copy`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::uninitialized_copy`'
- en: '`std::uninitialized_copy_n`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::uninitialized_copy_n`'
- en: '`std::uninitialized_fill`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::uninitialized_fill`'
- en: '`std::uninitialized_fill_n`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::uninitialized_fill_n`'
- en: '`std::unique`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::unique`'
- en: '`std::unique_copy` |'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::unique_copy` |'
- en: Having these algorithms upgraded is great news! The more our old programs utilize
    STL algorithms, the easier we can add parallelism to them retroactively. Note
    that this does *not* mean that such changes make every program automatically *N*
    times faster because multiprogramming is quite a bit more complex than that.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法的升级是个好消息！我们的旧程序越多地利用STL算法，我们就越容易事后为它们添加并行性。请注意，这并*不*意味着这些更改会使每个程序自动* N *倍加速，因为多程序设计要复杂得多。
- en: However, instead of designing our own complicated parallel algorithms using
    `std::thread`, `std::async`, or by including external libraries, we can now parallelize
    standard tasks in a very elegant, operating system-independent way.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们现在可以以非常优雅、独立于操作系统的方式并行化标准任务，而不是设计自己复杂的并行算法，使用`std::thread`、`std::async`或包含外部库。
- en: How do those execution policies work?
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这些执行策略是如何工作的？
- en: The execution policy tells which strategy we allow for the automatic parallelization
    of our standard algorithm calls.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 执行策略告诉我们允许使用哪种策略来自动并行化我们的标准算法调用。
- en: 'The following three policy types exist in the `std::execution` namespace:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::execution`命名空间中存在以下三种策略类型：'
- en: '| **Policy** | **Meaning** |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **策略** | **含义** |'
- en: '| --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `sequenced_policy` | The algorithm has to be executed in a sequential form
    similar to the original algorithm without an execution policy. The globally available
    instance has the name `std::execution::seq`. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `sequenced_policy` | 该算法必须以类似于原始算法的顺序形式执行，而不使用执行策略。全局可用的实例名为`std::execution::seq`。|'
- en: '| `parallel_policy` | The algorithm may be executed with multiple threads that
    share the work in a parallel fashion. The globally available instance has the
    name `std::execution::par`. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `parallel_policy` | 该算法可以以多线程方式执行，共享工作以并行方式进行。全局可用的实例名为`std::execution::par`。|'
- en: '| `parallel_unsequenced_policy` | The algorithm may be executed with multiple
    threads sharing the work. In addition to that, it is permissible to vectorize
    the code. In this case, container access can be interleaved between threads and
    also within the same thread due to vectorization. The globally available instance
    has the name `std::execution::par_unseq`. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `parallel_unsequenced_policy` | 该算法可以以多线程共享工作的方式执行。除此之外，允许对代码进行向量化。在这种情况下，容器访问可以在线程之间交错，也可以在同一线程内由于向量化而交错。全局可用的实例名为`std::execution::par_unseq`。|'
- en: 'The execution policies imply specific constraints for us. The stricter the
    specific constraints, the more parallelization strategy measures we can allow:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 执行策略对我们有特定的约束。约束越严格，我们可以允许的并行化策略措施就越多：
- en: All element access functions used by the parallelized algorithm *must not* cause
    *deadlocks* or *data races*
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行化算法使用的所有元素访问函数*不能*引起*死锁*或*数据竞争*
- en: In the case of parallelism and vectorization, all the access functions *must
    not* use any kind of blocking synchronization
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在并行和向量化的情况下，所有访问函数*必须不*使用任何形式的阻塞同步
- en: As long as we comply with these rules, we should be free from bugs introduced
    by using the parallel versions of the STL algorithms.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 只要我们遵守这些规则，我们就应该免受使用STL算法的并行版本引入的错误的影响。
- en: Note that just using parallel STL algorithms correctly does not always lead
    to guaranteed speedup. Depending on the problem we try to solve, the problem size,
    and the efficiency of our data structures and other access methods, measurable
    speedup will vary very much or not occur at all. *Multiprogramming is still hard.*
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，正确使用并行STL算法并不总是会导致保证的加速。根据我们尝试解决的问题、问题规模以及我们的数据结构和其他访问方法的效率，可测量的加速将会变化很大，或者根本不会发生。*多程序设计仍然很困难。*
- en: What does vectorization mean?
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量化是什么意思？
- en: 'Vectorization is a feature that both the CPU and the compiler need to support.
    Let''s have a quick glance at a simple example to briefly understand what vectorization
    is and how it works. Imagine we want to sum up numbers from a very large vector.
    A plain implementation of this task can look like this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化是CPU和编译器都需要支持的功能。让我们简要了解一下向量化是什么以及它是如何工作的。想象一下，我们想要对一个非常大的向量中的数字进行求和。这个任务的简单实现可能如下所示：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The compiler will eventually generate a loop from the `accumulate` call, which
    could look like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器最终将从`accumulate`调用生成一个循环，可能如下所示：
- en: '[PRE12]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Proceeding from this point, with vectorization allowed and enabled, the compiler
    could then produce the following code. The loop does four accumulation steps in
    one loop step and also does four times fewer iterations. For the sake of simplicity,
    the example does not deal with the remainder if the vector does not contain `N
    * 4` elements:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点出发，允许并启用向量化，编译器可以生成以下代码。循环在一个循环步骤中执行四个累加步骤，也减少了四倍的迭代次数。为简单起见，示例未处理向量不包含`N
    * 4`元素的余数：
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Why should it do this? Many CPUs provide instructions that can perform mathematical
    operations such as `sum += v[i] + v[i+1] + v[i + 2] + v[i + 3];` in just *one
    step*. Pressing as *many* mathematical operations into as *few* instructions as
    possible is the target because this speeds up the program.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要这样做？许多CPU提供的指令可以在*一步*中执行数学运算，例如`sum += v[i] + v[i+1] + v[i + 2] + v[i +
    3];`。尽可能多地将*许多*数学运算压缩到*尽可能少*的指令中是目标，因为这会加快程序速度。
- en: Automatic vectorization is hard because the compiler needs to understand our
    program to some degree in order to make our program faster but without tampering
    with its *correctness*. At least, we can help the compiler by using standard algorithms
    as often as possible because those are easier to grasp for the compiler than complicated
    handcrafted loops with complex data flow dependencies.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 自动向量化很难，因为编译器需要在一定程度上理解我们的程序，以使我们的程序更快，但又不影响其*正确性*。至少，我们可以通过尽可能经常使用标准算法来帮助编译器，因为这些对编译器来说比复杂的手工循环和复杂的数据流依赖更容易理解。
- en: Putting a program to sleep for specific amounts of time
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将程序休眠特定时间
- en: A nice and simple possibility to control threads came with C++11\. It introduced
    the `this_thread` namespace, which includes functions that affect only the caller
    thread. It contains two different functions that allow putting a thread to sleep
    for a certain amount of time, so we do not need to use any external or operating
    system-dependent libraries for such tasks any longer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: C++11引入了一种简单的控制线程的可能性。它引入了`this_thread`命名空间，其中包括只影响调用线程的函数。它包含两个不同的函数，允许将线程休眠一段时间，因此我们不再需要为此类任务使用任何外部或操作系统相关的库。
- en: In this recipe, we concentrate on how to suspend threads for a certain amount
    of time, or how to put them to *sleep*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们专注于如何暂停线程一段时间，或者如何将它们置于*休眠*状态。
- en: How to do it...
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will write a short program that just puts the main thread to sleep for certain
    amounts of time:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写一个简短的程序，只是将主线程休眠一段时间：
- en: 'Let''s first include all the needed headers and declare that we''ll use the
    `std` and `chrono_literals` namespaces. The `chrono_literals` namespace contains
    handy abbreviations for creating time-span values:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先包含所有需要的头文件，并声明我们将使用`std`和`chrono_literals`命名空间。`chrono_literals`命名空间包含用于创建时间跨度值的方便缩写：
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s immediately put the main thread to sleep for 5 seconds and 300 milliseconds.
    Thanks to `chrono_literals`, we can express this in a very readable format:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们立即将主线程休眠5秒和300毫秒。由于`chrono_literals`，我们可以以非常易读的格式表达这一点：
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The last sleep statement was `relative`. We can also express `absolute` sleep
    requests. Let''s sleep until the point in time, which is *now* plus `3` seconds:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个休眠语句是`relative`。我们也可以表达`absolute`的休眠请求。让我们休眠到*现在*加上`3`秒的时间点：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Before quitting the program, let''s print something else to signal the end
    of the second sleep period:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在退出程序之前，让我们打印一些其他内容，以示第二个休眠期结束：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Compiling and running the program yields the following results. Linux, Mac,
    and other UNIX-like operating systems provide the `time` command, which accepts
    another command in order to execute it and stop the time it takes. Running our
    program with `time` shows that it ran `8.32` seconds, which is roughly the `5.3`
    and `3` seconds we let our program sleep. When running the program, it is possible
    to count the time between the arrival of the printed lines on the terminal:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序产生以下结果。Linux、Mac和其他类UNIX操作系统提供`time`命令，该命令接受另一个命令以执行它并停止所需的时间。使用`time`运行我们的程序显示它运行了`8.32`秒，大约是我们让程序休眠的`5.3`秒和`3`秒。运行程序时，可以计算在终端上打印行到达之间的时间。
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `sleep_for` and `sleep_until` functions have been added to C++11 and reside
    in the `std::this_thread` namespace. They block the current thread (not the whole
    process or program) for a specific amount of time. A thread does not consume CPU
    time while it is blocked. It is just put into an inactive state by the operating
    system. The operating system does, of course, remind itself of waking the thread
    up again. The best thing about this is that we do not need to care which operating
    system our program runs on because the STL abstracts this detail away from us.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`sleep_for`和`sleep_until`函数已添加到C++11中，并驻留在`std::this_thread`命名空间中。它们阻塞当前线程（而不是整个进程或程序）一段特定的时间。线程在被阻塞时不会消耗CPU时间。它只是被操作系统置于非活动状态。当然，操作系统会提醒自己再次唤醒线程。最好的是，我们不需要关心我们的程序运行在哪个操作系统上，因为STL将这个细节抽象化了。'
- en: The `this_thread::sleep_for` function accepts a `chrono::duration` value. In
    the simplest case, this is just `1s` or `5s + 300ms`, just like in our example
    code. In order to get such nice literals for time spans, we need to declare `using
    namespace std::chrono_literals;`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`this_thread::sleep_for`函数接受`chrono::duration`值。在最简单的情况下，这只是`1s`或`5s + 300ms`，就像我们的示例代码中一样。为了获得这样漂亮的时间跨度文字，我们需要声明`using
    namespace std::chrono_literals;`。'
- en: The `this_thread::sleep_until` function accepts a `chrono::time_point` instead
    of a time span. This is comfortable if we wish to put the thread to sleep until
    some specific wall clock time.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`this_thread::sleep_until`函数接受`chrono::time_point`而不是时间跨度。如果我们希望将线程休眠直到特定的挂钟时间，这是很方便的。'
- en: The timing for waking up is only as accurate as the operating system allows.
    This will be generally accurate *enough* with most operating systems, but it might
    become difficult if some application needs nanosecond-granularity.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 唤醒的时间只有操作系统允许的那么准确。这将在大多数操作系统中通常足够准确，但如果某些应用程序需要纳秒级精度，可能会变得困难。
- en: Another possibility to put a thread to sleep for a short time is `this_thread::yield`.
    It accepts *no* arguments, which means that we cannot know for how long the execution
    of a thread is placed back. The reason is that this function does not really implement
    the notion of sleeping or parking a thread. It just tells the operating system
    in a cooperative way that it can reschedule any other thread of any other process.
    If there are none, then the thread will be executed again immediately. For this
    reason, `yield` is often less useful than just sleeping for a minimal, but specified,
    amount of time.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将线程休眠一小段时间的另一种可能性是`this_thread::yield`。它不接受*任何*参数，这意味着我们无法知道线程的执行被放置回去多长时间。原因是这个函数并没有真正实现睡眠或停放线程的概念。它只是以一种合作的方式告诉操作系统可以重新安排任何其他进程的任何其他线程。如果没有，那么线程将立即再次执行。因此，`yield`通常比仅仅睡眠一段最小但指定的时间不太有用。
- en: Starting and stopping threads
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动和停止线程
- en: Another addition that came with C++11 is the `std::thread` class. It provides
    a clean and simple way to start and stop threads, without any need for external
    libraries or to know how the operating system implements this. It's all just included
    in the STL.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: C++11带来的另一个新增功能是`std::thread`类。它提供了一种干净简单的方法来启动和停止线程，而无需外部库或了解操作系统如何实现这一点。这一切都包含在STL中。
- en: In this recipe, we will implement a program that starts and stops threads. There
    are some minor details to know what to do with threads once they are started,
    so we will go through these too.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将实现一个启动和停止线程的程序。一旦线程启动，就需要了解如何处理线程的一些细节，所以我们也会详细介绍这些内容。
- en: How to do it...
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will start multiple threads and see how our program behaves when we unleash
    multiple processor cores to execute parts of its code at the same time:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将启动多个线程，并查看当我们释放多个处理器核心同时执行其代码的部分时，我们的程序的行为如何：
- en: 'At first, we need to include only two headers and then we declare that we use
    the `std` and `chrono_literals` namespaces:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要包括只有两个标题，然后我们声明使用`std`和`chrono_literals`命名空间：
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In order to start a thread, we need to be able to tell what code should be
    executed by it. So, let''s define a function that can be executed. Functions are
    natural potential entry points for threads. The example function accepts an argument,
    `i`, which acts as the thread ID. This way we can tell which print line came from
    which thread later. Additionally, we use the thread ID to let all threads wait
    for different amounts of time, so we can be sure that they do not try to use `cout`
    at exactly the same time. If they did, that would garble the output. Another recipe
    in this chapter deals specifically with this problem:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了启动一个线程，我们需要能够告诉它应该执行什么代码。因此，让我们定义一个可以执行的函数。函数是线程的自然潜在入口点。示例函数接受一个参数`i`，它充当线程ID。这样我们可以稍后知道哪个打印行来自哪个线程。此外，我们使用线程ID让所有线程等待不同的时间，这样我们可以确保它们不会在完全相同的时间使用`cout`。如果是这样，输出将会混乱。本章的另一个示例专门处理了这个问题：
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In the main function, we can, just out of curiosity, print how many threads
    can be run at the same time, using `std::thread::hardware_concurrency`. This depends
    on how many cores the machine really has and how many cores are supported by the
    STL implementation. This means that this might be a different number on every
    other computer:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主函数中，我们可以出于好奇，使用`std::thread::hardware_concurrency`打印可以同时运行多少个线程。这取决于机器实际上有多少个核心，以及STL实现支持多少个核心。这意味着在每台计算机上这个数字可能是不同的：
- en: '[PRE21]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s now finally start threads. With different IDs for each one, we start
    three threads. When instantiating a thread with an expression such as `thread
    t {f, x}`, this leads to a call of `f(x)` by the new thread. This ,way we can
    give the `thread_with_param` functions different arguments for each thread:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们最终启动线程。对于每个线程，我们使用不同的ID启动三个线程。当使用`thread t {f, x}`这样的表达式实例化线程时，这将导致新线程调用`f(x)`。这样我们可以为每个线程的`thread_with_param`函数提供不同的参数：
- en: '[PRE22]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Since these threads are freely running, we need to stop them again when they
    are done with their work. We do this using the `join` function. It will *block*
    the calling thread until the thread we try to join returns:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这些线程是自由运行的，当它们完成工作时，我们需要再次停止它们。我们使用`join`函数来做到这一点。它将*阻塞*调用线程，直到我们尝试加入的线程返回：
- en: '[PRE23]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'An alternative to joining is *detaching*. If we do not call `join` or detach,
    the whole application will be terminated with a lot of smoke and noise as soon
    as the destructor of the `thread` object is executed. By calling `detach`, we
    tell `thread` that we really want to let thread number 3 to continue running,
    even after its `thread` instance is destructed:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与加入相对应的是*分离*。如果我们不调用`join`或分离，整个应用程序将在`thread`对象的析构函数执行时立即终止。通过调用`detach`，我们告诉`thread`，我们真的希望让线程3继续运行，即使它的`thread`实例被销毁：
- en: '[PRE24]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Before quitting the main function and the whole program, we print another message:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在退出主函数和整个程序之前，我们打印另一条消息：
- en: '[PRE25]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Compiling and running the code shows the following output. We can see that
    my machine has eight CPU cores. Then, we see the *hello* messages from all the
    threads, but the *bye* messages only from the two threads we actually joined.
    Thread 3 is still in its waiting period of 3 seconds, but the whole program does
    already terminate after the second thread has finished waiting for 2 seconds.
    This way, we cannot see the bye message from thread 3 because it was simply killed
    without any chance for completion (and without noise):'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行代码显示了以下输出。我们可以看到我的机器有八个CPU核心。然后，我们看到了所有线程的*hello*消息，但只有两个我们实际加入的线程的*bye*消息。线程3仍然处于等待3秒的期间，但整个程序在第二个线程等待2秒后就已经终止了。这样，我们无法看到线程3的bye消息，因为它被简单地杀死了，没有任何完成的机会（也没有噪音）：
- en: '[PRE26]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Starting and stopping threads is a very simple thing to do. Multiprogramming
    starts to be complicated where threads need to work together (sharing resources,
    waiting for each other, and so on).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 启动和停止线程是一件非常简单的事情。当线程需要共同工作（共享资源，等待彼此等）时，多道程序设计开始变得复杂。
- en: 'In order to start a thread, we first need some function that will be executed
    by it. The function does not need to be special, as a thread could execute practically
    every function. Let''s pin down a minimal example program that starts a thread
    and waits for its completion:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动一个线程，我们首先需要一个将由它执行的函数。这个函数不需要特殊，因为线程可以执行几乎每个函数。让我们确定一个最小的示例程序，启动一个线程并等待它的完成：
- en: '[PRE27]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The constructor call of `std::thread` accepts a function pointer or a callable
    object, followed by arguments that should be used with the function call. It is,
    of course, also possible to start a thread on a function that doesn't accept any
    parameters.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::thread`的构造函数调用接受一个函数指针或可调用对象，后面跟着应该与函数调用一起使用的参数。当然，也可以启动一个不接受任何参数的函数的线程。'
- en: If the system has multiple CPU cores, then the threads can run parallel *and*
    concurrently. What is the difference between parallel and concurrent? If the computer
    has only one CPU core, then there can be a lot of threads that run in parallel
    but never concurrently because one CPU core can only run one thread at a time.
    The threads are then run in an interleaved way where every thread is executed
    for some parts of a second, then paused, and then the next thread gets a time
    slice (for human users, this looks like they run at the same time). If they do
    not need to share a CPU core, then they can run concurrently, as in *really at
    the same time*.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统有多个CPU核心，那么线程可以并行和同时运行。并行和同时运行有什么区别？如果计算机只有一个CPU核心，那么可以有很多线程并行运行，但从来不会同时运行，因为一个CPU核心一次只能运行一个线程。然后线程以交错的方式运行，每个线程执行一部分时间，然后暂停，然后下一个线程获得时间片（对于人类用户来说，这看起来像它们同时运行）。如果它们不需要共享CPU核心，那么它们可以同时运行，就像*真正同时*一样。
- en: 'At this point, we have absolutely *no control* over the following details:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们绝对*无法控制*以下细节：
- en: The *order* in which the threads are interleaved when sharing a CPU core.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当共享一个CPU核心时，线程交错的顺序。
- en: The *priority* of a thread, or which one is more important than the other.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程的*优先级*，或者哪一个比其他更重要。
- en: The fact that threads are really *distributed* among all the CPU cores or if
    the operating system just pins them to the same core. It is indeed *possible*
    that all our threads run on only a single core, although the machine has more
    than 100 cores.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程真正*分布*在所有CPU核心之间，或者操作系统只是将它们固定在同一个核心上。事实上，我们的所有线程可能只在一个核心上运行，尽管机器有100多个核心。
- en: Most operating systems provide possibilities to control also these facets of
    multiprogramming, but such features are, at this point, *not* included in the
    STL.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数操作系统提供了控制多道程序设计这些方面的可能性，但这些功能在STL中*不*包括在内。
- en: 'However, we can start and stop threads and tell them when to work on what and
    when to pause. That should be enough for a large class of applications. What we
    did in this section was we started three additional threads. Afterward, we *joined*
    most of them and *detached* the last one. Let''s summarize in a simple diagram
    what happened:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以启动和停止线程，并告诉它们在什么时候工作，什么时候暂停。这对于大多数应用程序来说应该足够了。在本节中，我们启动了三个额外的线程。之后，我们*加入*了大部分线程，并*分离*了最后一个线程。让我们用一个简单的图表总结一下发生了什么：
- en: '![](img/6b848126-e59e-4cc1-baa0-6f31962879a3.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b848126-e59e-4cc1-baa0-6f31962879a3.png)'
- en: Reading the diagram from top to the bottom, it shows one point in time where
    we split the program workflow to four threads in total. We started three additional
    threads that did something (namely waiting and printing), but after starting the
    threads, the main thread executing the main function remained without work.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 从上到下阅读图表，它显示了程序工作流程在某一时刻分成了总共四个线程。我们启动了三个额外的线程，它们做了一些事情（即等待和打印），但在启动线程之后，执行主函数的主线程仍然没有工作。
- en: Whenever a thread has finished executing the function it was started with, it
    will return from this function. The standard library then does some tidy up work
    that results in the thread being removed from the operating system's schedule,
    and maybe in its destruction, but we do not need to worry about it.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 每当一个线程执行完它启动的函数时，它将从这个函数返回。标准库然后做一些整理工作，导致线程从操作系统的调度中移除，也许会被销毁，但我们不需要担心这些。
- en: The only thing we *need* to worry about is *joining*. When a thread calls function
    `x.join()` on another `thread` object, it is put to sleep until thread `x` returns.
    Note that we are out of luck if the thread is trapped in an endless loop! If we
    want a thread to continue living until it decides to terminate itself, we can
    call `x.detach()`. After doing so, we have no external control over the thread
    any longer. No matter what we decide--we *must* always *join* or *detach* threads.
    If we don't do one of the two, the destructor of the `thread` object will call
    `std::terminate()`, which leads to an abrupt application shutdown.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们唯一需要担心的是*加入*。当一个线程在另一个`thread`对象上调用函数`x.join()`时，它会被放到睡眠状态，直到线程`x`返回。请注意，如果线程被困在无限循环中，我们就没那么幸运了！如果我们希望线程继续存在，直到它决定终止自己，我们可以调用`x.detach()`。这样做后，我们就不再对线程有外部控制。无论我们做出什么决定，我们*必须*始终*加入*或*分离*线程。如果我们不做这两者之一，`thread`对象的析构函数将调用`std::terminate()`，这将导致应用程序突然关闭。
- en: The moment when our main function returns, the whole application is, of course,
    terminated. However, at the same time, our detached thread, `t3`, was still sleeping
    before printing its *bye* message to the terminal. The operating system didn't
    care--it just terminated our whole program without waiting for that thread to
    finish. This is something we need to consider. If that additional thread had to
    complete something important, we would have to make the main function *wait* for
    it.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的主函数返回时，整个应用程序当然被终止。但与此同时，我们分离的线程`t3`仍在睡眠，然后将其*再见*消息打印到终端。操作系统并不在乎，它只是在不等待该线程完成的情况下终止了整个程序。这是我们需要考虑的事情。如果该附加线程必须完成一些重要工作，我们必须让主函数*等待*它。
- en: Performing exception safe shared locking with std::unique_lock and std::shared_lock
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::unique_lock和std::shared_lock执行异常安全的共享锁定
- en: 'Since the operation of threads is a heavily operating system support-related
    thing and the STL provides good operating system-agnostic interfaces for that,
    it is also wise to provide STL support for *synchronization* between threads.
    This way, we can not only start and stop threads without external libraries but
    also synchronize them with abstractions from a single unified library: the STL.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线程的操作是与操作系统支持密切相关的事情，STL为此提供了良好的操作系统无关接口，因此为线程之间的*同步*提供STL支持也是明智的。这样，我们不仅可以在没有外部库的情况下启动和停止线程，还可以使用来自单一统一库的抽象来同步它们：STL。
- en: In this recipe, we will have a look at STL mutex classes and RAII lock abstractions.
    While we play around with some of them in our concrete recipe implementation,
    we will also get an overview of more synchronization helpers that the STL provides.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看看STL互斥锁类和RAII锁抽象。虽然我们在具体的示例实现中玩弄了其中一些，但我们也将概述STL提供的更多同步助手。
- en: How to do it...
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We are going to write a program that uses an `std::shared_mutex` instance in
    its *exclusive* and *shared* modes and to see what that means. Additionally, we
    do not call the lock and unlock functions ourselves but do the locking with automatic
    unlocking using RAII helpers:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写一个程序，该程序在其*独占*和*共享*模式下使用`std::shared_mutex`实例，并查看这意味着什么。此外，我们不调用锁定和解锁函数，而是使用RAII助手进行自动解锁：
- en: 'First, we need to include all necessary headers. Because we use STL functions
    and data structures all the time together with time literals, we declare that
    we use the `std` and `chrono_literal` namespaces:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要包括所有必要的头文件。因为我们一直与时间文字一起使用STL函数和数据结构，所以我们声明我们使用`std`和`chrono_literal`命名空间：
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The whole program revolves around one shared mutex, so let''s define a global
    instance for the sake of simplicity:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整个程序围绕一个共享互斥锁展开，因此为了简单起见，让我们定义一个全局实例：
- en: '[PRE29]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We are going to use the `std::shared_lock` and `std::unique_lock` RAII helpers.
    In order to make their names appear less clumsy, we define short type aliases
    for them:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`std::shared_lock`和`std::unique_lock`的RAII助手。为了使它们的名称看起来不那么笨拙，我们为它们定义了短类型别名：
- en: '[PRE30]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Before beginning with the main function, we define two helper functions that
    both try to lock the mutex in *exclusive* mode. This function here will instantiate
    a `unique_lock` instance on the shared mutex. The second constructor argument
    `defer_lock` tells the object to keep the lock unlocked. Otherwise, its constructor
    would try to lock the mutex and then block until it succeeds. Then we call `try_lock`
    on the `exclusive_lock` object. This call will return immediately and its boolean
    return value tells us if it got the lock or if the mutex was locked already somewhere
    else:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始主函数之前，我们定义了两个辅助函数，它们都尝试以*独占*模式锁定互斥锁。这个函数在共享互斥锁上实例化一个`unique_lock`实例。第二个构造函数参数`defer_lock`告诉对象保持锁定。否则，它的构造函数将尝试锁定互斥锁，然后阻塞直到成功。然后我们在`exclusive_lock`对象上调用`try_lock`。这个调用将立即返回，其布尔返回值告诉我们它是否获得了锁，还是互斥锁已经在其他地方被锁定：
- en: '[PRE31]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The other helper function tries to lock the mutex in exclusive mode, too. It
    blocks until it gets the lock. Then we simulate some error case by throwing an
    exception (which carries just a plain integer number instead of a more complex
    exception object). Although this leads to an immediate exit of the context in
    which we hold a locked mutex, the mutex will cleanly be released again. That is
    because the destructor of `unique_lock` will release the lock in any case by design:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一个辅助函数也尝试以独占模式锁定互斥锁。它会阻塞直到获得锁。然后我们通过抛出异常来模拟一些错误情况（它只携带一个普通整数而不是更复杂的异常对象）。尽管这会导致我们持有锁定互斥锁的上下文立即退出，但互斥锁将会被设计上的`unique_lock`析构函数在任何情况下都会释放锁定：
- en: '[PRE32]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now to the main function. First, we open up another scope and instantiate a
    `shared_lock` instance. Its constructor immediately locks the mutex in `shared`
    mode. We will see what this means in the next steps:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在到主要功能。首先，我们打开另一个范围并实例化一个`shared_lock`实例。它的构造函数立即以`shared`模式锁定互斥锁。我们将在接下来的步骤中看到这意味着什么：
- en: '[PRE33]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now we open yet another scope and instantiate a second `shared_lock` instance
    on the same mutex. We have two `shared_lock` instances now, and they both hold
    a shared lock on the mutex. In fact, we could instantiate arbitrarily many `shared_lock`
    instances on the same mutex. Then we call `print_exclusive`, which tries to lock
    the mutex in *exclusive* mode. This will not succeed because it is locked in *shared*
    mode already:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们打开另一个作用域，并在同一个互斥体上实例化第二个`shared_lock`实例。现在我们有两个`shared_lock`实例，它们都持有互斥体的共享锁。实际上，我们可以在同一个互斥体上实例化任意多个`shared_lock`实例。然后我们调用`print_exclusive`，它试图以*独占*模式锁定互斥体。这不会成功，因为它已经以*共享*模式锁定了：
- en: '[PRE34]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After leaving the latest scope, the destructor of the `shared_lock` `sl2` releases
    its shared lock on the mutex. The `print_exclusive` function will again fail because
    the mutex is still in shared lock mode:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在离开最新的作用域后，`shared_lock` `sl2`的析构函数释放了它对互斥体的共享锁。`print_exclusive`函数将再次失败，因为互斥体仍处于共享锁定模式：
- en: '[PRE35]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After leaving also the other scope, all `shared_lock` objects are destroyed,
    and the mutex is in unlocked state again. *Now* we can finally lock the mutex
    in exclusive mode. Let''s do this by calling `exclusive_throw` and then `print_exclusive`.
    Remember that we throw an exception in `exclusive_throw`. But because `unique_lock`
    is an RAII object that gives us exception safety, the mutex will be unlocked again
    no matter how we return from `exclusive_throw`. This way `print_exclusive` will
    not block on an erroneously still locked mutex:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在离开另一个作用域后，所有`shared_lock`对象都被销毁，互斥体再次处于未锁定状态。*现在*我们终于可以以独占模式锁定互斥体。让我们通过调用`exclusive_throw`然后`print_exclusive`来做到这一点。请记住，我们在`exclusive_throw`中抛出异常。但是因为`unique_lock`是一个RAII对象，它给我们提供了异常安全性，无论我们如何从`exclusive_throw`返回，互斥体都将再次被解锁。这样`print_exclusive`将不会在错误地仍然锁定的互斥体上阻塞：
- en: '[PRE36]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Compiling and running the code yields the following output. The first two lines
    show that we got the two shared lock instances. Then the `print_exclusive` function
    fails to lock the mutex in exclusive mode. After leaving the inner scope and unlocking
    the second shared lock, the `print_exclusive` function still fails. After leaving
    the other scope too, which finally released the mutex again, `exclusive_throw`
    and `print_exclusive` are finally able to lock the mutex:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行代码产生以下输出。前两行显示我们得到了两个共享锁实例。然后`print_exclusive`函数无法以独占模式锁定互斥体。在离开内部作用域并解锁第二个共享锁后，`print_exclusive`函数仍然失败。在离开另一个作用域后，最终释放了互斥体，`exclusive_throw`和`print_exclusive`最终能够锁定互斥体：
- en: '[PRE37]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works...
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: When looking at the C++ documentation, it is at first a little confusing that
    there are different mutex classes and RAII lock-helpers. Before looking at our
    concrete code sample, let us summarize what the STL has available for us.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看C++文档时，首先会让人感到困惑的是有不同的互斥类和RAII锁辅助工具。在查看我们的具体代码示例之前，让我们总结一下STL为我们提供了什么。
- en: Mutex classes
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥类
- en: The term mutex stands for **mut**ual **ex**clusion. In order to prevent that
    concurrently running threads alter the same object in a non-orchestrated way that
    might lead to data corruption, we can use mutex objects. The STL provides different
    mutex classes with different specialties. They all have in common that they have
    a `lock` and an `unlock` method.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 术语互斥体代表**mut**ual **ex**clusion。为了防止并发运行的线程以非协调的方式更改相同的对象，可能导致数据损坏，我们可以使用互斥对象。STL提供了不同的互斥类，具有不同的特性。它们都有一个`lock`和一个`unlock`方法。
- en: Whenever a thread is the first one to call `lock()` on a mutex that was not
    locked before, it owns the mutex. At this point, other threads will block on their
    `lock` calls, until the first thread calls `unlock` again. `std::mutex` can do
    exactly this.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 每当一个线程是第一个在之前未锁定的互斥体上调用`lock()`的线程时，它就拥有了互斥体。在这一点上，其他线程将在它们的`lock`调用上阻塞，直到第一个线程再次调用`unlock`。`std::mutex`正好可以做到这一点。
- en: 'There are many different mutex classes in the STL:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: STL中有许多不同的互斥类：
- en: '| **Type name** | **Description** |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| **类型名称** | **描述** |'
- en: '| --- | --- |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `mutex` | Standard mutex with a `lock` and an `unlock` method. Provides an
    additional nonblocking `try_lock` method. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| `mutex` | 具有`lock`和`unlock`方法的标准互斥体。提供额外的非阻塞`try_lock`方法。 |'
- en: '| `timed_mutex` | Same as mutex, but provides additional `try_lock_for` and
    `try_lock_until` methods that allow for *timing out* instead of blocking forever.
    |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| `timed_mutex` | 与互斥体相同，但提供了额外的`try_lock_for`和`try_lock_until`方法，允许*超时*而不是永远阻塞。
    |'
- en: '| `recursive_mutex` | Same as `mutex`, but if a thread locked an instance of
    it already, it can call `lock` multiple times on the same mutex object without
    blocking. It is released after the owning thread called `unlock` as often as it
    called `lock`. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| `recursive_mutex` | 与`mutex`相同，但如果一个线程已经锁定了它的实例，它可以在同一个互斥对象上多次调用`lock`而不会阻塞。在拥有线程调用`unlock`与调用`lock`的次数一样多后，它将被释放。
    |'
- en: '| `recursive_timed_mutex` | Provides the features of both `timed_mutex` and
    `recursive_mutex`. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| `recursive_timed_mutex` | 提供了`timed_mutex`和`recursive_mutex`的特性。 |'
- en: '| `shared_mutex` | This mutex is special in that regard, that it can be locked
    in *exclusive* mode and in *shared* mode. In exclusive mode, it shows the same
    behavior as the standard mutex class. If a thread locks it in shared mode, it
    is possible for other threads to lock it in shared mode, too. It will then be
    unlocked as soon as the last shared mode lock owner releases it. While a lock
    is locked in shared mode, it is not possible to obtain exclusive ownership. This
    is very similar to the behavior of `shared_ptr`, only that it does not manage
    memory, but lock ownership. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| `shared_mutex` | 这个互斥体在这方面很特别，它可以以*独占*模式和*共享*模式锁定。在独占模式下，它显示与标准互斥体类相同的行为。如果一个线程以共享模式锁定它，其他线程也可以以共享模式锁定它。只要最后一个共享模式锁定所有者释放它，它就会被解锁。在共享模式锁定时，不可能获得独占所有权。这与`shared_ptr`的行为非常相似，只是它不管理内存，而是锁的所有权。
    |'
- en: '| `shared_timed_mutex` | Combines the features of `shared_mutex` and `timed_mutex`
    for both exclusive and shared mode. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| `shared_timed_mutex` | 结合了`shared_mutex`和`timed_mutex`的特性，既可以进行独占模式也可以进行共享模式。
    |'
- en: Lock classes
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁类
- en: Everything is nice and easy as long as threads do just lock a mutex, access
    some concurrence protected object and unlock the mutex again. As soon as a forgetful
    programmer misses to unlock a mutex somewhere after locking it, or an exception
    is thrown while a mutex is still locked, things look ugly pretty quick. In the
    best case, the program just hangs immediately and the missing unlock call is identified
    quickly. Such bugs, however, are very similar to memory leaks, which also occur
    when there are missing explicit `delete` calls.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 只要线程只锁定互斥锁，访问一些并发保护对象，然后再次解锁互斥锁，一切都很顺利。一旦一个健忘的程序员在某处忘记解锁互斥锁，或者在互斥锁仍然被锁定时抛出异常，事情就会很快变得混乱。在最好的情况下，程序会立即挂起，并且很快就会发现缺少的解锁调用。然而，这些错误与内存泄漏非常相似，当缺少显式的`delete`调用时也会发生内存泄漏。
- en: 'When regarding memory management, we have `unique_ptr`, `shared_ptr` and `weak_ptr`.
    Those helpers provide very convenient ways to avoid memory leaks. Such helpers
    exist for mutexes, too. The simplest one is `std::lock_guard`. It can be used
    as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑内存管理时，我们有`unique_ptr`、`shared_ptr`和`weak_ptr`。这些辅助程序提供了非常方便的方法来避免内存泄漏。互斥锁也有这样的辅助程序。最简单的是`std::lock_guard`。可以按照以下方式使用：
- en: '[PRE38]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`lock_guard` element''s constructor accepts a mutex, on which it calls `lock`
    immediately. The whole constructor call will block until it obtains the lock on
    the mutex. Upon destruction, it unlocks the mutex again. This way it is hard to
    get the `lock`/`unlock` cycle wrong because it happens automatically.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`lock_guard`元素的构造函数接受一个互斥锁，在该互斥锁上立即调用`lock`。整个构造函数调用将阻塞，直到它获得互斥锁上的锁。在销毁时，它再次解锁互斥锁。这样做是为了防止`lock`/`unlock`循环出错，因为它会自动发生。'
- en: 'The C++17 STL provides the following different RAII lock-helpers. They all
    accept a template argument that shall be of the same type as the mutex (although,
    since C++17, the compiler can deduce that type itself):'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: C++17 STL提供了以下不同的RAII锁辅助程序。它们都接受一个模板参数，该参数应与互斥锁的类型相同（尽管自C++17以来，编译器可以自行推断该类型）：
- en: '| **Name** | **Description** |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **描述** |'
- en: '| --- | --- |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `lock_guard` | This class provides nothing else than a constructor and a
    destructor, which `lock` and `unlock` a mutex. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| `lock_guard` | 该类除了构造函数和析构函数外，没有提供其他内容，它们`lock`和`unlock`一个互斥锁。 |'
- en: '| `scoped_lock` | Similar to `lock_guard`, but supports arbitrarily many mutexes
    in its constructor. Will release them in opposite order in its destructor. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| `scoped_lock` | 类似于`lock_guard`，但在其构造函数中支持任意数量的互斥锁。在其析构函数中以相反的顺序释放它们。 |'
- en: '| `unique_lock` | Locks a mutex in exclusive mode. The constructor also accepts
    arguments that instruct it to timeout instead of blocking forever on the lock
    call. It is also possible to not lock the mutex at all, or to assume that it is
    locked already, or to only *try* locking the mutex. Additional methods allow to
    lock and unlock the mutex during the `unique_lock` lock''s lifetime. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| `unique_lock` | 以独占模式锁定互斥锁。构造函数还接受参数，指示它在锁定调用时超时而不是永远阻塞。还可以选择根本不锁定互斥锁，或者假定它已经被锁定，或者仅*尝试*锁定互斥锁。额外的方法允许在`unique_lock`锁的生命周期内锁定和解锁互斥锁。'
- en: '| `shared_lock` | Same as `unique_lock`, but all operations are applied on
    the mutex in shared mode. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| `shared_lock` | 与`unique_lock`相同，但所有操作都以共享模式应用于互斥锁。 |'
- en: While `lock_guard` and `scoped_lock` have dead-simple interfaces that only consist
    of constructor and destructor, `unique_lock` and `shared_lock` are more complicated,
    but also more versatile. We will see in later recipes of this chapter, how else
    they can be used if not for plain simple lock regions.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`lock_guard`和`scoped_lock`具有非常简单的接口，只包括构造函数和析构函数，但`unique_lock`和`shared_lock`更复杂，但也更灵活。在本章的后续配方中，我们将看到它们可以如何被用于不仅仅是简单的锁定区域。
- en: Let's get back to the recipe code now. Although we only ran the code in single
    thread context, we have seen how it is meant to use the lock helpers. The `shrd_lck`
    type alias stands for `shared_lock<shared_mutex>` and allows us to lock an instance
    multiple times in shared mode. As long as `sl1` and `sl2` exist, no `print_exclusive`
    call is able to lock the mutex in exclusive mode. This is still simple.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回到配方代码。虽然我们只在单线程上运行了代码，但我们已经看到了如何使用锁辅助程序。`shrd_lck`类型别名代表`shared_lock<shared_mutex>`，允许我们以共享模式多次锁定实例。只要`sl1`和`sl2`存在，就无法通过`print_exclusive`调用以独占模式锁定互斥锁。这仍然很简单。
- en: 'Now let''s get to the exclusively locking functions that came later in the
    main function:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下稍后在主函数中出现的独占锁定函数：
- en: '[PRE39]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: One important detail is that after returning from `exclusive_throw`, the `print_exclusive`
    function is able to lock the mutex again, although `exclusive_throw` did not exit
    cleanly due to the exception it throws.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的细节是，在从`exclusive_throw`返回后，`print_exclusive`函数能够再次锁定互斥锁，尽管`exclusive_throw`由于抛出的异常而没有干净地退出。
- en: 'Let''s have another look at `print_exclusive` because it used a strange constructor
    call:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一下`print_exclusive`，因为它使用了一个奇怪的构造函数调用：
- en: '[PRE40]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We did not only provide `shared_mut` but also `defer_lock` as constructor arguments
    for `unique_lock` in this procedure. `defer_lock` is an empty global object that
    can be used to select a different constructor of `unique_lock` that simply does
    not lock the mutex. By doing so, we are able to call `l.try_lock()` later, which
    does not block. In case the mutex is locked already, we can do something else.
    If it was indeed possible to get the lock, we still have the destructor tidying
    up after us.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们不仅提供了`shared_mut`，还提供了`defer_lock`作为`unique_lock`的构造函数参数。`defer_lock`是一个空的全局对象，可以用来选择`unique_lock`的不锁定互斥锁的不同构造函数。通过这样做，我们能够稍后调用`l.try_lock()`，它不会阻塞。如果互斥锁已经被锁定，我们可以做其他事情。如果确实可能获得锁，我们仍然有析构函数在我们之后整理。
- en: Avoiding deadlocks with std::scoped_lock
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::scoped_lock避免死锁
- en: 'If deadlocks had occurred in road traffic, they would have looked like the
    following situation:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果死锁发生在道路交通中，它们看起来会像以下情况：
- en: '![](img/e02fbc8d-bc97-496b-b388-f0ecbea0e5e5.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e02fbc8d-bc97-496b-b388-f0ecbea0e5e5.png)'
- en: In order to get the traffic flow going again, we either need a large crane that
    randomly picks one car from the center of the street intersection and removes
    it. If that is not possible, then we need enough drivers to be cooperative. The
    deadlock can be solved by all drivers in one direction driving several meters
    backwards, making space for the other drivers to continue.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让交通流量再次畅通，我们要么需要一台大型起重机，随机从街道交叉口中心挑选一辆汽车并将其移走。如果这不可能，那么我们需要足够多的司机合作。死锁可以通过一个方向的所有司机向后倒车几米，为其他司机继续行驶腾出空间来解决。
- en: In multithreaded programs, such situations, of course, need to be avoided strictly
    by the programmer. It is however too easy to fail in that regard when the program
    is really complex.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程程序中，当然需要程序员严格避免这种情况。然而，当程序真正复杂时，很容易在这方面失败。
- en: In this recipe, we are going to write code which intentionally provokes a deadlock
    situation. Then we will see how to write code that acquires the same resources
    that led the other code into a deadlock, but use the new STL lock class `std::scoped_lock`
    that came with C++17, in order to avoid this mistake.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将编写故意引发死锁情况的代码。然后我们将看到如何编写代码，以获取导致其他代码陷入死锁的相同资源，但使用新的C++17中引入的STL锁类`std::scoped_lock`来避免这个错误。
- en: How to do it...
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The code of this section contains two pairs of functions that ought to be executed
    by concurrent threads, and that acquire two resources in form of mutexes. One
    pair provokes a deadlock and the other avoids it. In the main function, we are
    going to try them out:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的代码包含两对应该由并发线程执行的函数，它们以互斥量的形式获取两个资源。一对引发死锁，另一对避免了死锁。在主函数中，我们将尝试它们：
- en: 'Let''s first include all needed headers and declare that we use namespace `std`
    and `chrono_literals`:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先包含所有需要的头文件，并声明我们使用`std`和`chrono_literals`命名空间：
- en: '[PRE41]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then we instantiate two mutex objects which we need in order to run into a
    deadlock:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们实例化两个互斥对象，这是为了陷入死锁所必需的：
- en: '[PRE42]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In order to provoke a deadlock with two resources, we need two functions. One
    function tries to lock mutex A and then mutex B, while the other function will
    do that in the opposite order. By letting both functions sleep a bit between the
    locks, we can make sure that this code blocks forever on a deadlock. (This is
    for demonstration purposes. A program without some sleep lines might run successfully
    without a deadlock sometimes if we start it repeatedly.)
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了通过两个资源引发死锁，我们需要两个函数。一个函数尝试锁定互斥量A，然后锁定互斥量B，而另一个函数将以相反的顺序执行。通过让两个函数在锁定之间稍微休眠一会儿，我们可以确保这段代码永远在死锁上阻塞。（这是为了演示目的。如果我们重复启动程序，没有一些休眠行可能会成功运行而不会发生死锁。）
- en: 'Note that we do not use the `''n''` character in order to print a line break,
    but we use `endl`. `endl` does not only perform a line break but also flushes
    the stream buffer of `cout`, so we can be sure that prints are not bunched up
    and postponed:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不使用`'n'`字符来打印换行，而是使用`endl`。`endl`不仅执行换行，还刷新了`cout`的流缓冲区，因此我们可以确保打印不会被堆积和延迟：
- en: '[PRE43]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As promised in the last step, `deadlock_func_2` looks exactly same as `deadlock_func_1`,
    but it locks mutex A and B in the opposite order:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如上一步所承诺的，`deadlock_func_2`看起来与`deadlock_func_1`完全相同，但是以相反的顺序锁定了互斥量A和B：
- en: '[PRE44]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now we write a deadlock-free variant of those two functions we just implemented.
    They use the class `scoped_lock`, which locks all mutexes we provide as constructor
    arguments. Its destructor unlocks them again. While locking the mutexes, it internally
    applies a deadlock avoidance strategy for us. Note that both functions still use
    mutex A and B in opposite order:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们编写这两个函数的无死锁变体。它们使用`scoped_lock`类，该类锁定我们提供为构造函数参数的所有互斥量。它的析构函数再次解锁它们。在锁定互斥量时，它内部为我们应用了死锁避免策略。请注意，这两个函数仍然以相反的顺序使用互斥量A和B：
- en: '[PRE45]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In the main function, we will go through two scenarios. First, we use the *sane*
    functions in multithreaded context:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主函数中，我们将通过两种情况。首先，我们在多线程环境中使用*正常*函数：
- en: '[PRE46]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Then we use the deadlock-provoking functions that do not utilize any deadlock
    avoidance strategy:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用不使用任何死锁避免策略的引发死锁的函数：
- en: '[PRE47]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Compiling and running the program yields the following output. The first two
    lines show that the *sane* locking function scenario works and both functions
    return without blocking forever. The other two functions run into a deadlock.
    We can tell that this is a deadlock because we see the print lines that tell that
    the individual threads try to lock mutexes A and B and then wait *forever*. Both
    do not reach the point where they successfully locked both mutexes. We can let
    this program run for hours, days, and years, and *nothing* will happen.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序产生以下输出。前两行显示*正常*锁定函数场景有效，并且两个函数都能够返回而不会永远阻塞。另外两个函数陷入了死锁。我们可以看到这是一个死锁，因为我们看到打印行告诉我们各个线程尝试锁定互斥量A和B，然后永远等待。两者都没有达到成功锁定两个互斥量的地方。我们可以让这个程序运行数小时、数天和数年，*什么*都不会发生。
- en: 'This application needs to be killed from outside, for example by pressing the
    keys *Ctrl* + *C*:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序需要从外部终止，例如通过按下*Ctrl* + *C*键：
- en: '[PRE48]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: How it works...
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: By implementing code that willfully causes a deadlock, we've seen how quick
    such an unwanted scenario can happen. In a large project, where multiple programmers
    write code that needs to share a common set of mutex-protected resources, all
    programmers need to comply with the *same order* when locking and unlocking mutexes.
    While such strategies or rules are really easy to follow, they are also easy to
    forget. Another term for this problem is *lock order inversion*.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实现故意引发死锁的代码，我们看到了这种不希望的情况会发生得多么迅速。在一个大型项目中，多个程序员编写需要共享一组互斥保护资源的代码时，所有程序员都需要遵守*相同的顺序*来锁定和解锁互斥量。虽然这些策略或规则确实很容易遵循，但也很容易忘记。这个问题的另一个术语是*锁定顺序倒置*。
- en: '`scoped_lock` is a real help in such situations. It came with C++17 and works
    the same way as `lock_guard` and `unique_lock` work: its constructor performs
    the locking, and its destructor the unlocking of a mutex. `scoped_lock`''s specialty
    is that it can do this with *multiple* mutexes.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`scoped_lock`在这种情况下真的很有帮助。它是C++17中的新功能，工作方式与`lock_guard`和`unique_lock`相同：它的构造函数执行锁定，其析构函数执行互斥量的解锁。`scoped_lock`的特点是它可以使用*多个*互斥量来执行这个操作。'
- en: '`scoped_lock` uses the `std::lock` function, which applies a special algorithm
    that performs a series of `try_lock` calls on all the mutexes provided, in order
    to prevent deadlocking. Therefore it is perfectly safe to use `scoped_lock` or
    call `std::lock` on the same set of locks, but in different orders.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`scoped_lock`使用`std::lock`函数，该函数应用一种特殊的算法，对提供的所有互斥量执行一系列`try_lock`调用，以防止死锁。因此，可以完全安全地使用`scoped_lock`或在不同顺序下调用`std::lock`相同的一组锁。'
- en: Synchronizing concurrent std::cout use
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步并发使用std::cout
- en: One inconvenience in multithreaded programs is that we must practically secure
    *every* data structure they modify, with mutexes or other measures that protect
    from uncontrolled concurrent modification.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程程序中的一个不便之处是，我们必须实际上保护*每一个*它们修改的数据结构，使用互斥量或其他措施来防止不受控制的并发修改。
- en: One data structure that is typically used very often for printing is `std::cout`.
    If multiple threads access `cout` concurrently, then the output will appear in
    interesting mixed patterns on the terminal. In order to prevent this, we would
    need to write our own function that prints in a concurrency-safe fashion.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通常用于打印的一个数据结构是`std::cout`。如果多个线程同时访问`cout`，那么输出将以有趣的混合模式出现在终端上。为了防止这种情况，我们需要编写自己的函数，以并发安全的方式进行打印。
- en: We are going to learn how to provide a `cout` wrapper that consists of minimal
    code itself and that is as comfortable to use as `cout`.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何提供一个由最少代码组成且与`cout`一样方便使用的`cout`包装器。
- en: How to do it...
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In this section, we are going to implement a program that prints to the terminal
    concurrently from many threads. In order to prevent garbling of the messages due
    to concurrency, we implement a little helper class that synchronizes printing
    between threads:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个程序，它可以从许多线程并发地打印到终端。为了防止消息由于并发而混乱，我们实现了一个小的辅助类，它在线程之间同步打印：
- en: 'As always, the includes come first:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和往常一样，首先是包含：
- en: '[PRE49]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Then we implement our helper class, which we call `pcout`. The `p` stands for
    *parallel* because it works in a synchronized way for parallel contexts. The idea
    is that `pcout` publicly inherits from `stringstream`. This way we can use `operator<<`
    on instances of it. As soon as a `pcout` instance is destroyed, its destructor
    locks a mutex and then prints the content of the `stringstream` buffer. We will
    see how to use it in the next step:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们实现我们的辅助类，我们称之为`pcout`。`p`代表*parallel*，因为它可以在并行上下文中同步工作。`pcout`公开继承自`stringstream`。这样我们就可以在它的实例上使用`operator<<`。一旦`pcout`实例被销毁，它的析构函数会锁定一个互斥量，然后打印`stringstream`缓冲区的内容。我们将在下一步中看到如何使用它：
- en: '[PRE50]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now let''s write two functions that can be executed by additional threads.
    Both accept a thread ID as arguments. Then, their only difference is that the
    first one simply uses `cout` for printing. The other one looks nearly identical,
    but instead of using `cout` directly, it instantiates `pcout`. This instance is
    a temporary object that lives only exactly for this line of code. After all `operator<<`
    calls have been executed, the internal string stream is filled with what we want
    to print. Then `pcout` instance''s destructor is called. We have seen what the
    destructor does: it locks a specific mutex all `pcout` instances share along and
    prints:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们编写两个可以由额外线程执行的函数。两者都接受线程ID作为参数。它们唯一的区别是第一个简单地使用`cout`进行打印。另一个看起来几乎相同，但是它不直接使用`cout`，而是实例化`pcout`。这个实例是一个临时对象，只在这行代码中存在。在所有`operator<<`调用执行完毕后，内部字符串流被填充了我们想要打印的内容。然后调用`pcout`实例的析构函数。我们已经看到析构函数的作用：它锁定所有`pcout`实例共享的特定互斥量并进行打印：
- en: '[PRE51]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s try it out. First, we are going to use `print_cout`, which just uses
    `cout` for printing. We start 10 threads which concurrently print their strings
    and wait until they finish:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们试一下。首先，我们将使用`print_cout`，它只使用`cout`进行打印。我们启动10个线程，它们同时打印它们的字符串并等待直到它们完成：
- en: '[PRE52]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Then we do the same thing with the `print_pcout` function:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们用`print_pcout`函数做同样的事情：
- en: '[PRE53]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Compiling and running the program yields the following result. As we see, the
    first 10 prints are completely garbled. This is how it can look like when `cout`
    is used concurrently without locking. The last 10 lines of the program are the
    `print_pcout` lines which do not show any signs of garbling. We can see that they
    are printed from different threads because their order appears randomized every
    time when we run the program again:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序产生以下结果。正如我们所看到的，前10个打印完全是乱码。这就是在没有锁定的情况下并发使用`cout`时的情况。程序的最后10行是`print_pcout`行，没有显示任何乱码的迹象。我们可以看到它们是从不同的线程打印出来的，因为它们的顺序在每次运行程序时都是随机的：
- en: '![](img/c9208c3b-6c0c-4187-aaba-dd51820c5c5e.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9208c3b-6c0c-4187-aaba-dd51820c5c5e.png)'
- en: How it works...
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它的工作原理...
- en: Ok, we've built this *"cout wrapper"* that automatically serializes concurrent
    printing attempts. How does it work?
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们已经构建了这个*"cout包装器"*，它可以自动序列化并发打印尝试。它是如何工作的呢？
- en: 'Let''s do the same steps our `pcout` helper does in a manual manner without
    any magic. First, it instantiates a string stream and accepts the input we feed
    into it:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以手动方式执行我们的`pcout`辅助程序所做的相同步骤，而不使用任何魔法。首先，它实例化一个字符串流并接受我们输入的内容：
- en: '[PRE54]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Then it locks a globally available mutex:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 然后它锁定一个全局可用的互斥量：
- en: '[PRE55]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'In this locked scope, it accesses the content of string stream `ss`, prints
    it, and releases the mutex again by leaving the scope. The `cout.flush()` line
    tells the stream object to print to the terminal immediately. Without this line,
    a program might run faster because multiple printed lines can be bunched up and
    printed in a single run later. In our recipes, we will like to see all output
    lines immediately, so we use the `flush` method:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个锁定的范围内，它访问字符串流`ss`的内容，打印它，然后通过离开范围释放互斥锁。`cout.flush()`行告诉流对象立即打印到终端。没有这一行，程序可能会运行得更快，因为多个打印行可以被捆绑在一起，并在稍后一次运行中打印。在我们的示例中，我们希望立即看到所有输出行，所以我们使用`flush`方法：
- en: '[PRE56]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Ok, this is simple enough but tedious to write if we have to to the same thing
    again and again. We can shorten down the `stringstream` instantiation as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这很简单，但如果我们不得不一遍又一遍地做同样的事情，那就太繁琐了。我们可以将`stringstream`的实例化缩短如下：
- en: '[PRE57]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This instantiates a string stream object, feeds everything we want to print
    into it and then destructs it again. The lifetime of the string stream is reduced
    to just this line. Afterward, we cannot print it any longer, because we cannot
    access it. Which code is the last that is able to access the stream's content?
    It is the destructor of `stringstream`.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这实例化了一个字符串流对象，将我们想要打印的所有内容输入其中，然后再次销毁它。字符串流的生命周期仅缩短到这一行。之后，我们无法再打印它，因为我们无法访问它。哪段代码是最后能够访问流内容的？它是`stringstream`的析构函数。
- en: 'We cannot modify `stringstream` instance''s member methods, but we can extend
    them by wrapping our own type around it via inheritance:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能修改`stringstream`实例的成员方法，但是我们可以通过继承将自己的类型包装在它周围来扩展它们：
- en: '[PRE58]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This class *is still* a string stream and we can use it like any other string
    stream. The only difference is that it will lock a mutex and print its own buffer
    using `cout`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类*仍然*是一个字符串流，我们可以像任何其他字符串流一样使用它。唯一的区别是它将锁定一个互斥锁，并使用`cout`打印自己的缓冲区。
- en: We also moved the `cout_mutex` object into struct `pcout` as a static instance
    so we have both bundled in one place.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将`cout_mutex`对象移入结构`pcout`中作为静态实例，这样我们就可以在一个地方将它们捆绑在一起。
- en: Safely postponing initialization with std::call_once
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::call_once安全地延迟初始化
- en: Sometimes we have specific code sections that can be run in parallel context
    by multiple threads with the obligation that some *setup code* must be executed
    exactly once before executing the actual functions. A simple solution is to just
    execute the existing setup function before the program enters a state from which
    parallel code can be executed from time to time.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们有特定的代码部分，可以由多个线程在并行上下文中运行，但必须在执行实际函数之前执行一些*设置代码*。一个简单的解决方案是在程序进入可以不时执行并行代码的状态之前，只需执行现有的设置函数。
- en: 'The drawbacks of such an approach are the following ones:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的缺点如下：
- en: If the parallel function comes from a library, the user must not forget to call
    the setup function. That does not make the library easier to use.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果并行函数来自库，用户不能忘记调用设置函数。这并不会使库更容易使用。
- en: If the setup function is expensive in some way, and it might not even need to
    be executed in case the parallel functions that need this setup are not even always
    used, then we need code that decides when/if to run it.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果设置函数在某种方式上是昂贵的，并且甚至可能不需要在并行函数不总是被使用的情况下执行，那么我们需要的是决定何时/是否运行它的代码。
- en: In this recipe, we will have a look at `std::call_once`, which is a helper function
    that solves this problem for us in a simple to use and elegant implicit way.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看看`std::call_once`，它是一个帮助函数，以一种简单易用和优雅的隐式方式解决了这个问题。
- en: How to do it...
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We are going to write a program that starts multiple threads with exactly the
    same code. Although they are programmed to execute exactly the same code, our
    example setup function will only be called once:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写一个程序，使用完全相同的代码启动多个线程。尽管它们被编程为执行完全相同的代码，但我们的示例设置函数只会被调用一次：
- en: 'First, we need to include all the necessary headers:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要包括所有必要的头文件：
- en: '[PRE59]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We are going to use `std::call_once` later. In order to use it, we need an
    instance of `once_flag` somewhere. It is needed for the synchronization of all
    threads that use `call_once` on a specific function:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们稍后将使用`std::call_once`。为了使用它，我们需要在某个地方有一个`once_flag`的实例。它用于同步所有使用`call_once`的线程在特定函数上：
- en: '[PRE60]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The function which must be only executed once is the following one. It just
    prints a single exclamation mark:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须只执行一次的函数如下。它只打印一个感叹号：
- en: '[PRE61]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'All threads will execute the print function. The first thing we do is calling
    the function `once_print` through the function `std::call_once`. `call_once` needs
    the variable `callflag` we defined before. It will use it to orchestrate the threads:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有线程将执行打印函数。我们首先通过`std::call_once`函数调用函数`once_print`。`call_once`需要我们之前定义的变量`callflag`。它将用它来编排线程：
- en: '[PRE62]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Ok, let''s now start 10 threads which all use the `print` function:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 好的，现在让我们启动10个使用`print`函数的线程：
- en: '[PRE63]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Compiling and running yields the following output. First, we see the exclamation
    mark from the `once_print` function. Then we see all thread IDs. `call_once` did
    not only make sure that `once_print` was only called once. Additionally, it synchronized
    all threads, so that no ID is printed *before* `once_print` was executed:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行产生以下输出。首先，我们看到`once_print`函数的感叹号。然后我们看到所有线程ID。`call_once`不仅确保`once_print`只被调用一次。此外，它还同步了所有线程，以便在执行`once_print`之前不会打印任何ID：
- en: '[PRE64]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: How it works...
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: '`std:call_once` works like a barrier. It maintains access to a function (or
    a callable object). The first thread to reach it gets to execute the function.
    Until it has finished, any other thread that reaches the `call_once` line is blocked.
    After the first thread returns from the function, all other threads are released,
    too.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '`std:call_once`的工作原理类似于屏障。它维护对函数（或可调用对象）的访问。第一个到达它的线程将执行该函数。直到它完成，任何到达`call_once`行的其他线程都将被阻塞。在第一个线程从函数返回后，所有其他线程也将被释放。'
- en: In order to organize this little choreography, a variable is needed from which
    the other threads can determine if they must wait and when they are released again.
    This is what our variable `once_flag callflag;` is for. Every `call_once` line
    also needs a `once_flag` instance as the argument prepending the function that
    shall be called only once.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 为了组织这个小舞蹈，需要一个变量，其他线程可以从中确定它们是否必须等待，以及它们何时被释放。这就是我们的变量`once_flag callflag;`的作用。每个`call_once`行也需要一个`once_flag`实例作为参数，该参数在调用一次的函数之前。
- en: 'Another nice detail is: If it happens, that the thread which is selected to
    execute the function in `call_once` *fails* because some *exception* is thrown,
    then the next thread is allowed to execute the function again. This happens in
    the hope that it will not throw an exception the next time.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个好处是：如果发生了这种情况，即所选用来执行`call_once`函数的线程*失败*，因为抛出了一些*异常*，那么下一个线程就可以再次执行该函数。希望下一次不会再抛出异常。
- en: Pushing the execution of tasks into the background using std::async
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::async将任务推送到后台执行
- en: 'Whenever we want some code to be executed in the background, we can simply
    start a new thread that executes this code. While this happens, we can do something
    else and then wait for the result. It''s simple:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们希望某些代码在后台执行时，我们可以简单地启动一个新线程来执行这些代码。在此期间，我们可以做其他事情，然后等待结果。这很简单：
- en: '[PRE65]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'But then the inconvenience starts: `t.join()` does not give us the return value
    of `my_function`. In order to get at that, we need to write a function that calls
    `my_function` and stores its return value in some variable that is also accessible
    for the first thread in which we started the new thread. If such situations occur
    repeatedly, then this represents quite a bunch of boilerplate code we have to
    write again and again.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 但接下来就会出现不便：`t.join()`不会给我们`my_function`的返回值。为了得到它，我们需要编写一个调用`my_function`并将其返回值存储在某个变量中的函数，该变量也可以被我们启动新线程的第一个线程访问。如果这种情况反复发生，那么我们就需要一遍又一遍地编写大量样板代码。
- en: Since C++11, we have `std::async` which can do exactly this job for us and not
    only that. In this recipe, we are going to write a simple program that does multiple
    things at the same time using asynchronous function calls. As `std::async` is
    a bit more powerful than that alone, we will have a closer look at its different
    facets.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 自C++11以来，我们有`std::async`可以为我们做这个工作，不仅如此。在这个示例中，我们将编写一个简单的程序，使用异步函数调用同时执行多个任务。由于`std::async`比单独使用更强大，我们将更仔细地研究它的不同方面。
- en: How to do it...
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We are going to implement a program that does multiple different things concurrently
    but instead of explicitly starting threads, we use `std::async` and `std::future`:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现一个程序，它可以同时执行多个不同的任务，但我们不是显式地启动线程，而是使用`std::async`和`std::future`：
- en: 'First, we include all necessary headers and declare that we use the `std` namespace:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们包括所有必要的头文件，并声明我们使用`std`命名空间：
- en: '[PRE66]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We implement three functions which have nothing to do with parallelism but
    do interesting tasks. The first function accepts a string and creates a histogram
    of all characters occurring within that string:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现了三个函数，它们与并行无关，但执行有趣的任务。第一个函数接受一个字符串，并创建该字符串中出现的所有字符的直方图：
- en: '[PRE67]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The second function does also accept a string and returns a sorted copy of
    it:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个函数也接受一个字符串，并返回它的排序副本：
- en: '[PRE68]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The third one counts how many vowels exist within the string it accepts:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个函数计算它接受的字符串中存在多少元音字母：
- en: '[PRE69]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'In the main function, we read the whole standard input into a string. In order
    to not segment the input into words, we deactivate `ios::skipws`. This way we
    get one large string, no matter how much white space the input contains. We use
    `pop_back` on the resulting string afterward because we got one string terminating
    `''''` character too much this way:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主函数中，我们将整个标准输入读入一个字符串。为了不将输入分割成单词，我们取消了`ios::skipws`。这样我们就得到了一个大字符串，无论输入包含多少空白。之后我们对结果字符串使用`pop_back`，因为这样我们得到了一个多余的终止`''`字符：
- en: '[PRE70]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Now let''s get the return values from all the functions we implemented before.
    In order to speed the execution up for very long input, we launch them *asynchronously*.
    The `std::async` function accepts a policy, a function, and arguments for that
    function. We call `histogram`, `sorted`, and `vowels` with `launch::async` as
    a policy (we will see later what that means). All functions get the same input
    string as arguments:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们从之前实现的所有函数中获取返回值。为了加快非常长输入的执行速度，我们*异步*启动它们。`std::async`函数接受一个策略、一个函数和该函数的参数。我们使用`launch::async`作为策略调用`histogram`、`sorted`和`vowels`（稍后我们将看到这意味着什么）。所有函数都以相同的输入字符串作为参数：
- en: '[PRE71]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The `async` calls return immediately because they do not actually execute our
    functions. Instead, they set up synchronization structures which will obtain the
    results of the function calls later. The results are now being calculated concurrently
    by additional threads. In the meantime, we are free to do whatever we want, as
    we can pick up those values later. The return values `hist`, `sorted_str` and
    `vowel_count` are of the types the functions `histogram`, `sorted`, and `vowels`
    return, but they were wrapped in a `future` type by `std::async`. Objects of this
    type express that they will contain their values at some point in time. By using
    `.get()` on all of them, we can make the main function block until the values
    arrive, and then use them for printing:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`async`调用会立即返回，因为它们实际上并不执行我们的函数。相反，它们设置了同步结构，稍后将获取函数调用的结果。结果现在正在由额外的线程并发计算。与此同时，我们可以自由地做任何我们想做的事情，因为我们可以稍后获取这些值。返回值`hist`、`sorted_str`和`vowel_count`是函数`histogram`、`sorted`和`vowels`的返回类型，但它们被`std::async`包装在`future`类型中。这种类型的对象表明它们将在某个时间点包含它们的值。通过对它们所有使用`.get()`，我们可以使主函数阻塞，直到值到达，然后用它们进行打印：'
- en: '[PRE72]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Compiling and running the code looks like the following. We use a short example
    string that does not really make it worth being parallelized, but for the sake
    of this example, the code is nevertheless executed concurrently. Additionally,
    the overall structure of the program did not change much compared to a naive sequential
    version of it:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行代码如下。我们使用一个简短的示例字符串，这并不值得并行化，但为了这个例子，代码仍然是并发执行的。此外，程序的整体结构与其天真的顺序版本相比并没有太大变化：
- en: '[PRE73]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: How it works...
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'If we would not have used `std::async` the serial unparallelized code could
    have looked as simple as that:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有使用`std::async`，串行未并行化的代码可能看起来就像这样简单：
- en: '[PRE74]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The only thing we did in order to parallelize the code was the following. We
    wrapped the three function calls into `async(launch::async, ...)` calls. This
    way these three functions are not executed by the main thread we are currently
    running in. Instead, `async` starts new threads and lets them execute the functions
    concurrently. This way we get to execute only the overhead of starting another
    thread and can continue with the next line of code, while all the work happens
    in the background:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为了并行化代码所做的唯一事情是将这三个函数调用包装在`async(launch::async, ...)`调用中。这样这三个函数就不会由我们当前运行的主线程执行。相反，`async`启动新线程并让它们并发执行函数。这样我们只执行启动另一个线程的开销，并且可以继续下一行代码，而所有的工作都在后台进行：
- en: '[PRE75]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: While `histogram` for example, returns us a map instance, `async(..., histogram,
    ...)` does return us a map that was wrapped in a `future` object before. This
    `future` object is kind of an empty *placeholder* until the thread that executes
    the `histogram` function returns. The resulting map is then placed into the `future`
    object so we can finally access it. The `get` function then gives us access to
    the encapsulated result.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`histogram`返回给我们一个map实例，而`async(..., histogram, ...)`返回给我们一个被包装在`future`对象中的map。这个`future`对象在执行`histogram`函数返回之前是一种空的*占位符*。然后将生成的map放入`future`对象中，这样我们最终可以访问它。然后`get`函数给我们访问封装结果的权限。
- en: 'Let''s have a look at another minimal example. Consider the following code
    snippet:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个最小的例子。考虑以下代码片段：
- en: '[PRE76]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Instead of writing the preceding code, we can also do the following:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 与编写前面的代码相比，我们也可以这样做：
- en: '[PRE77]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'That''s basically it. Executing tasks in the background might have never been
    easier in standard C++. There is still one thing left to resolve: What does `launch::async`
    mean? `launch::async` is a flag that defines the launch policy. There are two
    policy flags which allow for three constellations:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上就是这样。在标准C++中执行后台任务可能从未如此简单。还有一件事需要解决：`launch::async`是什么意思？`launch::async`是一个标志，定义了启动策略。有两个策略标志，允许三种情况：
- en: '| **Policy choice** | **Meaning** |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| **策略选择** | **含义** |'
- en: '| --- | --- |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `launch::async` | The function is guaranteed to be executed by another thread.
    |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| `launch::async` | 保证函数由另一个线程执行。 |'
- en: '| `launch::deferred` | The function is executed by the same thread, but later
    (*lazy evaluation*). Execution then happens when `get` or `wait` is called on
    the future. If *none* of both happens, the function is not called *at all*. |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| `launch::deferred` | 函数由同一个线程执行，但稍后执行（*延迟评估*）。当在future上调用`get`或`wait`时才会执行。如果*两者都没有*发生，函数根本不会被调用。
    |'
- en: '| `launch::async &#124; launch::deferred` | Having both flags set, the STL''s
    `async` implementation is free to choose which policy shall be followed. This
    is the default choice if no policy is provided. |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| `launch::async &#124; launch::deferred` | 两个标志都设置时，STL的`async`实现可以自由选择要遵循哪种策略。如果没有提供策略，则这是默认选择。
    |'
- en: By just calling `async(f, 1, 2, 3)` without a policy argument, we automatically
    select *both* policies. The implementation of `async` is then free to choose which
    policy to employ. This means that we cannot be *sure* that another thread is started
    at all, or if the execution is just deferred in the current thread.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 通过只调用`async(f, 1, 2, 3)`而不带有策略参数，我们自动选择*两种*策略。然后，`async`的实现可以自由选择要使用哪种策略。这意味着我们无法*确定*是否启动了另一个线程，或者执行是否只是在当前线程中延迟进行。
- en: There's more...
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There is indeed one last thing we should know about. Suppose, we write code
    as follows:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 确实还有最后一件事我们应该知道。假设我们编写如下代码：
- en: '[PRE78]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: This might have the motivation of executing functions `f` and `g` (we do not
    care about their return values in this example) in concurrent threads and then
    doing different things at the same time. While running such code, we will notice
    that the code *blocks* on this calls, which is most probably not what we want.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是为了在并发线程中执行函数`f`和`g`（在这个例子中我们不关心它们的返回值），然后同时做不同的事情。在运行这样的代码时，我们会注意到代码在这些调用上*阻塞*，这很可能不是我们想要的。
- en: 'So why does it block? Isn''t `async` all about nonblocking asynchronous calls?
    Yes it is, but there is one special peculiarity: if a future was obtained from
    an async call with the `launch::async` policy, then its destructor performs a
    *blocking wait*.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么会阻塞呢？`async`不是关于非阻塞异步调用的吗？是的，但有一个特殊的特点：如果从带有`launch::async`策略的async调用中获得了一个future，那么它的析构函数会执行*阻塞等待*。
- en: This means that *both* the async calls from this short example are blocking
    because the lifetime of the futures they return ends in the same line! We can
    fix this by capturing their return values in variables with a longer lifetime.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着这个简短示例中的两个async调用都是阻塞的，因为它们返回的futures的生命周期在同一行结束！我们可以通过将它们的返回值捕获到具有更长生命周期的变量中来解决这个问题。
- en: Implementing the producer/consumer idiom with std::condition_variable
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::condition_variable实现生产者/消费者习语
- en: In this recipe, we are going to implement a typical producer/consumer program
    with multiple threads. The general idea is that there is one thread that produces
    items and puts them into a queue. Then there is another thread that consumes such
    items. If there is nothing to produce, the producer thread sleeps. If there is
    no item in the queue to consume, the consumer sleeps.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将实现一个具有多个线程的典型生产者/消费者程序。总体思路是有一个线程生产项目并将它们放入队列。然后有另一个线程消费这些项目。如果没有东西可以生产，生产者线程就会休眠。如果队列中没有要消费的项目，消费者就会休眠。
- en: Since the queue that both threads have access to is also modified by both whenever
    an item is produced or consumed, it needs to be protected by a mutex.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个线程都可以访问的队列在每次生产或消费项目时都会被两者修改，因此需要通过互斥锁来保护。
- en: 'Another thing to consider is: What does the consumer do if there is no item
    in the queue? Does it poll the queue every second until it sees new items? That
    is not necessary because we can let the consumer wait for wakeup *events* that
    are triggered by the producer, whenever there are new items.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的事情是：如果队列中没有项目，消费者该怎么办？它是否每秒轮询队列，直到看到新项目？这是不必要的，因为我们可以让消费者等待由生产者触发的唤醒*事件*，每当有新项目时。
- en: C++11 provides a nice data structure called `std::condition_variable` for this
    kind of events. In this recipe, we are going to implement a simple producer/consumer
    app that takes advantage of this.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: C++11提供了一种称为`std::condition_variable`的很好的数据结构，用于这种类型的事件。在这个配方中，我们将实现一个简单的生产者/消费者应用程序，利用这一点。
- en: How to do it...
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We are going to implement a simple producer/consumer program which runs a single
    producer of values in its own thread, as well as a single consumer thread in another
    thread:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现一个简单的生产者/消费者程序，其中一个线程中有一个单一的值生产者，另一个线程中有一个单一的消费者线程：
- en: 'First, we need to perform all the needed includes:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要执行所有需要的包含：
- en: '[PRE79]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We instantiate a queue of simple numeric values and call it `q`. The producer
    will push values into it, and the consumer will take values out of it. In order
    to synchronize both, we need a mutex. In addition to that, we instantiate a `condition_variable`
    `cv`. The variable `finished` will be the producer''s way to tell the consumer
    that no more values will follow:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实例化一个简单数值值队列，并称其为`q`。生产者将向其中推送值，消费者将从中取出值。为了同步两者，我们需要一个互斥锁。除此之外，我们实例化一个`condition_variable`
    `cv`。变量`finished`将是生产者告诉消费者不会再有更多值的方式：
- en: '[PRE80]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Let''s first implement the producer function. It accepts an argument `items`
    which limits the maximum number of items for production. In a simple loop, it
    will sleep 100 milliseconds for every item, which simulates some computational
    *complexity*. Then we lock the mutex that synchronizes access to the queue. After
    successful production and insertion to the queue, we call `cv.notify_all()`. This
    function wakes the consumer up. We will see later at the consumer side how this
    works:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先实现生产者函数。它接受一个名为`items`的参数，限制了生产的最大项目数。在一个简单的循环中，它将为每个项目休眠100毫秒，这模拟了一些计算*复杂性*。然后我们锁定同步访问队列的互斥锁。在成功生产并插入队列后，我们调用`cv.notify_all()`。这个函数唤醒消费者。我们稍后会在消费者端看到这是如何工作的：
- en: '[PRE81]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'After having produced all items, we lock the mutex again because we are going
    to change to set the `finished` bit. Then we call `cv.notify_all()` again:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生产完所有项目后，我们再次锁定互斥锁，因为我们将要更改设置`finished`位。然后我们再次调用`cv.notify_all()`：
- en: '[PRE82]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Now we can implement the consumer function. It takes no arguments because it
    will blindly consume until the queue runs empty. In a loop that is executed as
    long as `finished` is not set, it will first lock the mutex that protects both
    the queue and the `finished` flag. As soon as it has the lock, it calls `cv.wait`
    with the lock and a lambda expression as arguments. The lambda expression is a
    predicate that tells if the producer thread is still alive and if there is anything
    to consume in the queue:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以实现消费者函数。它不带参数，因为它会盲目地消费，直到队列为空为止。在一个循环中，只要`finished`没有设置，它首先会锁定保护队列和`finished`标志的互斥锁。一旦获得锁，它就会调用`cv.wait`，并将锁和lambda表达式作为参数。lambda表达式是一个断言，告诉生产者线程是否仍然存活，以及队列中是否有任何东西可以消费。
- en: '[PRE83]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The `cv.wait` call unlocks the lock and waits until the condition described
    by the predicate function holds. Then, it locks the mutex again and consumes everything
    from the queue until it appears empty. If the producer is still alive, it will
    iterate through the loop again. Otherwise, it will terminate because `finished`
    is set, which is the producer''s way to signal that there are no further items
    being produced:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cv.wait`调用解锁锁，并等待由断言函数描述的条件成立。然后，它再次锁定互斥锁，并从队列中消费所有东西，直到它为空。如果生产者仍然存活，它将再次迭代循环。否则，它将终止，因为`finished`被设置，这是生产者告知不再生产更多项目的方式：'
- en: '[PRE84]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'In the main function, we start a producer thread which produces 10 items, and
    a consumer thread. Then we wait until their completion and terminate the program:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主函数中，我们启动一个生产者线程，它会生产10个项目，以及一个消费者线程。然后我们等待它们完成并终止程序：
- en: '[PRE85]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Compiling and running the program yields the following output. When the program
    is executed, we can see that there is some time (100 milliseconds) between each
    line, because the production of items takes some time:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序产生以下输出。当程序执行时，我们可以看到每行之间有一些时间（100毫秒），因为生产项目需要一些时间：
- en: '[PRE86]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: How it works...
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we simply started two threads. The first thread produces items
    and puts them into a queue. The other takes items out of the queue. Whenever one
    of those threads touches the queue in any way, it locks the common mutex `mut`
    which is accessible for both. This way we made sure that it cannot happen that
    both threads manipulate the queue's state at the same time.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们简单地启动了两个线程。第一个线程生产项目并将它们放入队列。另一个从队列中取出项目。每当这些线程中的一个以任何方式触及队列时，它都会锁定共同的互斥锁`mut`，这对两者都是可访问的。通过这种方式，我们确保不会发生两个线程同时操纵队列状态的情况。
- en: 'Apart from the queue and the mutex, we declared generally four variables that
    were involved in the producer-consumer thing:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 除了队列和互斥锁，我们通常声明了四个与生产者-消费者相关的变量：
- en: '[PRE87]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: The variable `finished` is easy to explain. It was set to `true` when the producer
    finished producing its fixed amount of items. When the consumer sees that this
    variable is `true`, it consumes the last items in the queue and stops consuming.
    But what is the `condition_variable` `cv` for? We used `cv` in two different contexts.
    One of the contexts was *waiting for a specific condition*, and the other was
    *signaling that condition*.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`finished`很容易解释。当生产者完成生产固定数量的物品时，它被设置为`true`。当消费者看到这个变量为`true`时，它会消耗队列中的最后物品并停止消耗。但`condition_variable`
    `cv`是用来做什么的？我们在两个不同的上下文中使用了`cv`。一个上下文是*等待特定条件*，另一个是*发出该条件的信号*。
- en: 'The consumer side that waits for a specific condition looks like this. The
    consumer thread loops over a block that first locks mutex `mut` in a `unique_lock`.
    Then it calls `cv.wait`:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 等待特定条件的消费者端看起来像这样。消费者线程循环执行一个块，首先在`unique_lock`中锁定互斥锁`mut`。然后调用`cv.wait`：
- en: '[PRE88]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This code is *somewhat* equivalent to the following alternative code. We will
    elaborate soon why it is not really the same:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码*在某种程度上*等同于以下替代代码。我们很快会详细说明为什么它实际上并不相同：
- en: '[PRE89]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'This means that we generally first acquire the lock and then check what scenario
    we have:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着通常我们首先获取锁，然后检查我们的情况是什么：
- en: Are there items to consume? Then keep the lock, consume, release the lock, and
    start over.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有可消耗的物品吗？那么保持锁定，消耗，释放锁定，然后重新开始。
- en: Else, if there are *no consumable items* but the producer is still *alive,*
    release the mutex to give the producer a chance of adding items to the queue.
    Then, try to lock it again in hope that the situation changes and we get to see
    situation 1.
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 否则，如果没有可消耗的物品，但生产者仍然*活着*，则释放互斥锁以使生产者有机会向队列中添加物品。然后，尝试再次锁定它，希望情况会改变，我们会看到情况1。
- en: The real reason why the `cv.wait` line is not equivalent to the `while (q.empty()
    && ... )` construct is, that we cannot simply loop over a `l.unlock(); l.lock();`
    cycle. If the producer thread is inactive for some time, then this would lead
    to continuous locking and unlocking of the mutex, which makes no sense because
    it needlessly burns CPU cycles.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv.wait`行不等同于`while (q.empty() && ... )`构造的真正原因是，我们不能简单地循环执行`l.unlock(); l.lock();`。如果生产者线程在某段时间内处于非活动状态，那么这将导致互斥锁的持续锁定和解锁，这是没有意义的，因为这会不必要地消耗CPU周期。'
- en: An expression like `cv.wait(lock, predicate)` will wait until `predicate()`
    returns `true`. But it does not do this by continuously unlocking and locking
    `lock`. In order to wake a thread up that blocks on the `wait` call of a `condition_variable`
    object, another thread has to call the `notify_one()` or `notify_all()` method
    on the same object. Only then the waiting thread(s) is/are kicked out of their
    sleep in order to check if `predicate()` holds.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 像`cv.wait(lock, predicate)`这样的表达式将等待，直到`predicate()`返回`true`。但它并不是通过不断解锁和锁定`lock`来做到这一点的。为了唤醒一个在`condition_variable`对象的`wait`调用上阻塞的线程，另一个线程必须在同一对象上调用`notify_one()`或`notify_all()`方法。只有这样，等待的线程才会被唤醒，以检查`predicate()`是否成立。
- en: The nice thing about the `wait` call checking the predicate is that if there
    is a *spurious* wakeup call, the thread will go to sleep immediately again. This
    means that it does not really harm the program flow (but maybe the performance)
    if we have too many notify calls.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '`wait`调用检查谓词的好处是，如果有*虚假*唤醒调用，线程将立即再次进入睡眠状态。这意味着如果我们有太多的通知调用，它并不会真正影响程序流程（但可能会影响性能）。'
- en: On the producer side, we just called `cv.notify_all()` after the producer inserted
    an item to the queue and after it produced its last item and set the `finished`
    flag to `true`. This was enough to direct the consumer.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产者端，我们在生产者将物品插入队列后和生产者生产最后一个物品并将`finished`标志设置为`true`后，只需调用`cv.notify_all()`。这足以引导消费者。
- en: Implementing the multiple producers/consumers idiom with std::condition_variable
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::condition_variable实现多个生产者/消费者习语
- en: 'Let''s pick up the producer/consumer problem from the last recipe and make
    it a bit more complicated: We make *multiple* producers produce items and *multiple*
    consumers consume them. In addition to that, we define that the queue shall not
    exceed a maximum size.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从上一个示例中解决生产者/消费者问题，并使其变得更加复杂：我们让*多个*生产者生产物品，*多个*消费者消耗它们。除此之外，我们定义队列不得超过最大大小。
- en: This way not only the consumers have to sleep from time to time if there are
    no items in the queue, but also the producers have to sleep from time to time
    when there are *enough* items in the queue.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方式不仅消费者必须不时休眠，如果队列中没有物品，生产者也必须不时休眠，当队列中有足够的物品时。
- en: We are going to see how to solve this problem with multiple `std::condition_variable`
    objects and will also use them in slightly different ways than in the last recipe.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如何使用多个`std::condition_variable`对象解决此问题，并且还将以与上一个示例略有不同的方式使用它们。
- en: How to do it...
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In this section, we are going to implement a program just like in the recipe
    before, but this time with multiple producers and multiple consumers:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个程序，就像在上一个示例中一样，但这次有多个生产者和多个消费者：
- en: 'First, we need to include all needed headers and we declare that we use namespace
    `std` and `chrono_literals`:'
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要包含所有需要的标头，并声明我们使用`std`和`chrono_literals`命名空间：
- en: '[PRE90]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Then we implement the synchronized printing helper from the other recipe in
    this chapter because we are going to do a lot of concurrent printing:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们在本章的另一个示例中实现了同步打印助手，因为我们将进行大量并发打印：
- en: '[PRE91]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'All producers write values into the same queue and all consumers will also
    take values out of this queue. In addition to that queue, we need a mutex that
    protects both the queue and a flag that can tell if the production was stopped
    at some point:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有生产者将值写入同一个队列，所有消费者也将从该队列中取出值。除了该队列，我们还需要一个保护队列和一个标志的互斥锁，该标志可以告诉我们生产是否在某个时刻停止：
- en: '[PRE92]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We are going to employ two different `condition_variables` in this program.
    In the single producer/consumer recipe, we had a `condition_variable` telling
    that there are new items in the queue. In this case, we make it a bit more complicated.
    We want the producers to produce until the queue contains a certain *stock amount*
    of items. If that stock amount is reached, they shall *sleep*. This way the `go_consume`
    variable can be used to wake up consumers which then, in turn, can wake up the
    producers with the `go_produce` variable again:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个程序中，我们将使用两个不同的`condition_variables`。在单个生产者/消费者配方中，我们有一个`condition_variable`告诉队列中有新物品。在这种情况下，我们要复杂一点。我们希望生产者生产，直到队列包含一定数量的*库存物品*。如果达到了库存量，它们将*休眠*。这样`go_consume`变量可以用来唤醒消费者，然后消费者可以再次用`go_produce`变量唤醒生产者：
- en: '[PRE93]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'The producer function accepts a producer ID number, a total number of items
    to produce and a stock limit as arguments. It then enters its own production loop.
    There, it first locks the queue''s mutex and unlocks it again in the `go_produce.wait`
    call. It waits for the condition that the queue size is below the `stock` threshold:'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者函数接受生产者ID号、要生产的物品总数和库存限制作为参数。然后它进入自己的生产循环。在那里，它首先锁定队列的互斥量，并在`go_produce.wait`调用中再次解锁。它等待队列大小低于`stock`阈值的条件：
- en: '[PRE94]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'After the producer was woken up, it produces an item and pushes it into the
    queue. The queue value is calculated from the expression `id * 100 + i`. This
    way we can later see which producer produced it because the hundreds in the number
    are the producer ID. We also print the production event to the terminal. The format
    of the printing may look strange, but it will align nicely with the consumer output
    in the terminal later:'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者被唤醒后，它生产一个物品并将其推入队列。队列值是从表达式`id * 100 + i`计算出来的。这样我们以后可以看到哪个生产者生产了它，因为数字中的百位数是生产者ID。我们还将生产事件打印到终端。打印的格式可能看起来奇怪，但它将与终端中的消费者输出很好地对齐：
- en: '[PRE95]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'After production, we can wake up sleeping consumers. A sleeping period of 90
    milliseconds simulates that producing items takes some time:'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产后，我们可以唤醒正在睡眠的消费者。90毫秒的睡眠时间模拟了生产物品需要一些时间：
- en: '[PRE96]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Now to the consumer function that only accepts a consumer ID as an argument.
    It shall continue waiting for items if the production has not stopped, or the
    queue is not empty. If the queue is empty, but the production has not stopped,
    then it is possible that there might be new items soon:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是消费者函数，它只接受一个消费者ID作为参数。如果生产还没有停止，或者队列不为空，它将继续等待物品。如果队列为空，但生产还没有停止，那么可能很快会有新的物品：
- en: '[PRE97]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'After locking the queue mutex, we unlock it again in order to wait on the `go_consume`
    event variable. The lambda expression argument describes that we want to return
    from the wait call when the queue contains items. The second argument `1s` tells
    that we do not want to wait forever. If it takes longer than 1 second, we want
    to drop out of the wait function. We can distinguish if the `wait_for` function
    returned because the predicate condition holds, or if we dropped out of it because
    of a timeout because it will return `false` in case of the timeout. If there are
    new items in the queue, we consume them and print this event to the terminal:'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在锁定队列互斥量后，我们再次解锁它，以便在`go_consume`事件变量上等待。lambda表达式参数描述了我们希望在队列包含物品时从等待调用中返回。第二个参数`1s`表示我们不想永远等待。如果超过1秒，我们希望退出等待函数。我们可以区分`wait_for`函数返回的原因，因为谓词条件成立，或者因为超时而退出，因为在超时的情况下它将返回`false`。如果队列中有新物品，我们会消耗它们并将此事件打印到终端：
- en: '[PRE98]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'After item consumption, we notify the producers and sleep for 130 milliseconds
    to simulate that consuming items is also time-consuming:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在物品消耗后，我们通知生产者并睡眠130毫秒，以模拟消耗物品也需要时间：
- en: '[PRE99]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'In the main function, we instantiate a vector for worker threads and another
    for consumer threads:'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主函数中，我们为工作线程实例化一个向量，另一个为消费者线程：
- en: '[PRE100]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Then we spawn three producer threads and five consumer threads:'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们生成三个生产者线程和五个消费者线程：
- en: '[PRE101]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'We first let the producer threads finish. As soon as all of them have returned,
    we set the `production_stopped` flag, which will lead the consumers to finish,
    too. We need to collect those and then we can quit the program:'
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先让生产者线程完成。一旦它们全部返回，我们设置`production_stopped`标志，这将导致消费者也完成。我们需要收集它们，然后我们可以退出程序：
- en: '[PRE102]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Compiling and running the program leads to the following output. The output
    is very long, which is why it is truncated here. We can see that the producers
    go to sleep from time to time, and let the consumers eat up some items until they
    finally produce again. It is interesting to alter the wait times for producers/consumers,
    as well as manipulating the number of producers/consumers and stock items because
    this completely changes the output patterns:'
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序会产生以下输出。输出非常长，这就是为什么在这里进行截断。我们可以看到生产者不时进入睡眠状态，让消费者吃掉一些物品，直到它们最终再次生产。改变生产者/消费者的等待时间以及操纵生产者/消费者和库存物品的数量是很有趣的，因为这完全改变了输出模式：
- en: '[PRE103]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: How it works...
  id: totrans-466
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This recipe is an extension of the preceding recipe. Instead of synchronizing
    only one producer with one consumer, we implemented a program that synchronizes
    `M` producers with `N` consumers. On top of that, not only the consumers go to
    sleep if there are no items for them left, but also the producers go to sleep
    as soon as the item queue becomes *too long*.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方是前一个配方的扩展。我们不仅同步一个生产者和一个消费者，而是实现了一个同步`M`个生产者和`N`个消费者的程序。除此之外，如果没有物品留给消费者，不仅消费者会进入睡眠状态，一旦物品队列变得*太长*，生产者也会进入睡眠状态。
- en: When multiple consumers wait for the same queue to fill up, then this would
    generally also work with the consumer code from the one producer/one consumer
    scenario. As long as only one thread locks the mutex that protects the queue and
    then takes items out of it, the code is safe. It does not matter how many threads
    are waiting for the lock at the same time. The same applies to the producers,
    as in both scenarios the only important thing is that the queue is never accessed
    by more than one thread at a time.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个消费者等待相同的队列填满时，这通常也适用于一个生产者/一个消费者场景中的消费者代码。只要只有一个线程锁定保护队列的互斥锁，然后从中取出项目，代码就是安全的。无论有多少线程同时等待锁定，都无关紧要。生产者也是如此，因为在这两种情况下，唯一重要的是队列永远不会被多个线程同时访问。
- en: 'So what makes this program really more complex than just running the one producer/one
    consumer example with more threads is the fact that we make the producer threads
    stop as soon as the item queue length reached a certain threshold. In order to
    meet that requirement, we implemented two different signals with their own `condition_variable`:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序之所以比只有一个生产者/一个消费者的例子更复杂，是因为我们让生产者线程在项目队列长度达到一定阈值时停止。为了满足这一要求，我们实现了两个不同的信号，它们各自拥有自己的`condition_variable`：
- en: The `go_produce` signals the event that the queue is not completely filled to
    the maximum and the producers may fill it up again.
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`go_produce`信号着事件，队列没有完全填满到最大，生产者可以再次填满它。'
- en: The `go_consume` signals the event that the queue reached its maximum length
    and consumers are free to consume items again.
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`go_consume`信号着事件，队列达到最大长度，消费者可以再次消费项目。'
- en: 'This way producers fill items into the queue and signal the `go_consume` event
    to the consuming threads, which wait on the following line:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，生产者将项目填入队列，并向消费者线程发出`go_consume`事件的信号，消费者线程在以下行上等待：
- en: '[PRE104]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'The producers, on the other hand, wait on the following line until they are
    allowed to produce again:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，生产者会在以下行上等待，直到被允许再次生产：
- en: '[PRE105]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'One interesting detail is that we do not let consumers wait *forever*. In the
    `go_consume.wait_for` call, we additionally added a timeout argument of 1 second.
    This is the exit mechanism for consumers: if the queue is empty for longer than
    a second, maybe there are no active producers any longer.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的细节是，我们不让消费者永远等待。在`go_consume.wait_for`调用中，我们额外添加了一个1秒的超时参数。这是消费者的退出机制：如果队列空闲超过一秒，可能没有活跃的生产者了。
- en: For the sake of simplicity, the code tries to keep the queue length *always
    at the maximum*. A more sophisticated program could let the consumer threads push
    a wake-up notification, *only* if the queue has only *half* the size of its maximum
    length. This way producers would be woken up before the queue runs empty again,
    but not unnecessarily earlier when there are still enough items in the queue.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，代码试图始终将队列长度保持在最大值。更复杂的程序可以让消费者线程在队列只有其最大长度的一半时推送唤醒通知，*只有*在队列中的项目数量仍然足够时，生产者才会被提前唤醒。这样，生产者就不会在队列中仍有足够的项目时被不必要地提前唤醒。
- en: 'One situation that `condition_variable` solves elegantly for us is the following:
    If a consumer fires the `go_produce` notification, there might be a horde of producers
    racing to produce the next item. If only one item is missing, then there will
    only be one producer producing it. If all producers would always produce an item
    as soon as the `go_produce` event is fired, we would often see the case that the
    queue is filled above its allowed maximum.'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '`condition_variable`为我们优雅地解决了以下情况：如果消费者触发了`go_produce`通知，可能会有一大群生产者竞相生产下一个项目。如果只缺一个项目，那么只会有一个生产者生产它。如果所有生产者在`go_produce`事件触发后总是立即生产一个项目，我们经常会看到队列填满到允许的最大值以上的情况。'
- en: Let's imagine the situation that we have `(max - 1)` items in the queue and
    want one new item produced so that the queue is filled up again. No matter if
    a consumer thread calls `go_produce.notify_one()` (which would wake up only one
    waiting thread) or `go_produce.notify_all()` (which wakes up *all* waiting threads),
    we have the guarantee that only one producer thread will exit the `go_produce.wait`
    call, because, for all other producer threads, the `q.size() < stock` wait condition
    doesn't hold any longer as soon as they get the mutex after being woken up.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的队列中有`(max - 1)`个项目，并且希望生产一个新项目，以便再次填满队列。无论消费者线程调用`go_produce.notify_one()`（只唤醒一个等待线程）还是`go_produce.notify_all()`（唤醒*所有*等待线程），我们保证只有一个生产者线程会退出`go_produce.wait`调用，因为对于所有其他生产者线程来说，一旦它们在被唤醒后获得互斥锁，`q.size()
    < stock`等待条件就不再成立。
- en: Parallelizing the ASCII Mandelbrot renderer using std::async
  id: totrans-480
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::async并行化ASCII Mandelbrot渲染器
- en: Remember the *ASCII Mandelbrot renderer* from [Chapter 23](897bfd02-6f27-4b2c-b44d-052811364259.xhtml),
    *Advanced Use of STL algorithms*? In this recipe, we will make it use threads
    in order to speed its calculation time a bit up.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得[第23章](897bfd02-6f27-4b2c-b44d-052811364259.xhtml)中的*ASCII Mandelbrot渲染器*吗，*STL算法的高级用法*？在这个配方中，我们将使用线程来加速其计算时间。
- en: First, we will modify the line in the original program that limits the number
    of iterations for every selected coordinate. This will make the program *slower*
    and its results *more accurate* than we can actually display on the terminal,
    but then we have a nice example target for parallelization.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将修改原始程序中限制每个选定坐标迭代次数的行。这将使程序*变慢*，其结果*比我们实际上可以在终端上显示的更准确*，但这样我们就有了一个很好的并行化目标。
- en: Then, we will apply minor modifications to the program and see how the whole
    program runs faster. After those modifications, the program runs with `std::async`
    and `std::future`. In order to fully understand this recipe, it is crucial to
    understand the original program.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将对程序进行轻微修改，看整个程序如何运行得更快。在这些修改之后，程序将使用`std::async`和`std::future`运行。为了充分理解这个配方，理解原始程序是至关重要的。
- en: How to do it...
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In this section, we take the ASCII Mandelbrot fractal renderer that we implemented
    in [Chapter 23](897bfd02-6f27-4b2c-b44d-052811364259.xhtml), *Advanced Use of
    STL Algorithms*. First, we are going to make the calculation take much more time
    by incrementing the calculation limit. Then we get some speedup by doing only
    four little changes to the program in order to parallelize it:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将采用我们在[第23章](897bfd02-6f27-4b2c-b44d-052811364259.xhtml)中实现的ASCII Mandelbrot分形渲染器，*STL算法的高级用法*。首先，我们将通过增加计算限制来使计算时间更长。然后，我们通过对程序进行四处小改动来实现加速，以便并行化：
- en: In order to follow the steps, it is best to just copy the whole program from
    the other recipe. Then follow the instructions in the following steps in order
    to do all needed adjustments. All differences from the original program are highlighted
    in *bold*.
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了跟随这些步骤，最好是直接从其他的配方中复制整个程序。然后按照以下步骤的说明进行所有必要的调整。所有与原始程序的不同之处都用*加粗*标出。
- en: 'The first change is an additional header, `<future>`:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '第一个变化是一个额外的头文件，`<future>`:'
- en: '[PRE106]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'The `scaler` and `scaled_cmplx` functions don''t need any change:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`scaler`和`scaled_cmplx`函数不需要任何更改：'
- en: '[PRE107]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'In the function `mandelbrot_iterations`, we are just going to increment the
    number of iterations in order to make the program a bit more computation-heavy:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在函数`mandelbrot_iterations`中，我们只是增加迭代次数，以使程序更加计算密集：
- en: '[PRE108]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Then we have a part of the main function that does not need any change again:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们有一个主函数的一部分，它再次不需要任何更改：
- en: '[PRE109]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'In the `to_iteration_count` function, we do not call `mandelbrot_iterations(x_to_xy(x))`
    directly any longer, but make the call asynchronous using `std::async`:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`to_iteration_count`函数中，我们不再直接调用`mandelbrot_iterations(x_to_xy(x))`，而是使用`std::async`异步调用：
- en: '[PRE110]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Before the last change, the function `to_iteration_count` returned us the number
    of iterations a specific coordinate needs for the Mandelbrot algorithm to converge.
    Now it returns a `future` variable that will contain the same value later because
    it is computed asynchronously. Because of this, we need a vector that holds all
    the future values, so let''s just add one. The output iterator we provide `transform`
    as the third argument must be the begin iterator of the new output vector `r`:'
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后一个变化之前，函数`to_iteration_count`返回了特定坐标需要Mandelbrot算法收敛的迭代次数。现在它返回一个将来会包含相同值的`future`变量，因为它是异步计算的。因此，我们需要一个保存所有未来值的向量，所以让我们添加一个。我们提供给`transform`的输出迭代器作为新输出向量`r`的起始迭代器：
- en: '[PRE111]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'The `accumulate` call which did all the printing for us doesn''t get `size_t`
    values as its second argument any longer, but `future<size_t>` values. We need
    to adapt it to this type (if we had used `auto&` as its type from the beginning
    then this would not even be necessary), and then we need to call `x.get()` where
    we just accessed `x` before, in order to wait for the value to arrive:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`accumulate`调用不再接受`size_t`值作为第二个参数，而是`future<size_t>`值。我们需要调整为这种类型（如果一开始就使用`auto&`作为它的类型，那么这甚至是不必要的），然后我们需要调用`x.get()`来等待值的到来，而不是之前直接访问`x`：'
- en: '[PRE112]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Compiling and running gives us the same output as before. The only interesting
    difference is the execution speed. If we increase the number of iterations for
    the original version of the program, too, then the parallelized version should
    compute faster. On my computer with four CPU cores with hyperthreading (which
    results in 8 virtual cores), I get different results with GCC and clang. The best
    speedup is `5.3`, and the worst is `3.8`. The results will also vary across machines,
    of course.
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行给我们与以前相同的输出。唯一有趣的区别是执行速度。如果我们也增加原始版本程序的迭代次数，那么并行化版本应该计算得更快。在我的计算机上，有四个CPU核心和超线程（导致8个虚拟核心），我用GCC和clang得到了不同的结果。最佳加速比为`5.3`，最差为`3.8`。当然，结果在不同的机器上也会有所不同。
- en: How it works...
  id: totrans-502
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'It is crucial to understand the whole program first because then it is clear
    that all the CPU-intense work happens in one line of code in the main function:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要理解整个程序，因为这样就清楚了所有的CPU密集型工作都发生在主函数的一行代码中：
- en: '[PRE113]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: The vector `v` contains all the indices that are mapped to complex coordinates,
    which are then in turn iterated over with the Mandelbrot algorithm. The result
    of each iteration is saved in vector `r`.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 向量`v`包含了所有映射到复坐标的索引，然后用Mandelbrot算法迭代。每次迭代的结果都保存在向量`r`中。
- en: In the original program, this is the single line which consumes all the processing
    time for calculating the fractal image. All code that precedes it is just set
    up work and all code that follows it is just for printing. This means that parallelizing
    this line is key to more performance.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始程序中，这是消耗所有处理时间来计算分形图像的单行代码。它之前的所有代码都是设置工作，之后的所有代码都是用于打印。这意味着并行化这一行是提高性能的关键。
- en: One possible approach to parallelizing this is to break up the whole linear
    range from `begin(v)` to `end(v)` into chunks of the same size and distribute
    them evenly across all cores. This way all cores would share the amount of work.
    If we used the parallel version of `std::transform` with a parallel execution
    policy, this would exactly be the case. Unfortunately, this is not the right strategy
    for *this* problem, because every single point in the Mandelbrot set shows a very
    individual number of iterations.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化这个问题的一种可能方法是将从`begin(v)`到`end(v)`的整个线性范围分成相同大小的块，并均匀分配到所有核心上。这样所有核心将共享工作量。如果我们使用带有并行执行策略的`std::transform`的并行版本，这将正好是这种情况。不幸的是，这不是*这个*问题的正确策略，因为Mandelbrot集中的每个点都显示出非常独特的迭代次数。
- en: Our approach here is to make every single vector item which represents an individually
    printed character cell on the terminal later an asynchronously calculated `future`
    value. As source and target vector are `w * h` items large, which means `100 *
    40` in our case, we have a vector of 4000 future values that are calculated asynchronously.
    If our system had 4000 CPU cores, then this would mean that we start 4000 threads
    that do the Mandelbrot iteration really concurrently. On a normal system with
    fewer cores, the CPUs will just process one asynchronous item after the other
    per core.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法是使每个单独的向量项（代表终端上的单个打印字符单元）成为一个异步计算的`future`值。由于源向量和目标向量都有`w * h`个项，也就是在我们的情况下是`100
    * 40`，我们有一个包含4000个异步计算值的向量。如果我们的系统有4000个CPU核心，那么这意味着我们启动了4000个线程，这些线程真正同时进行Mandelbrot迭代。在具有较少核心的普通系统上，CPU将依次处理每个核心的一个异步项。
- en: While the `transform` call with the asynchronized version of `to_iteration_count`
    itself does *no calculation* but setting up of threads and future objects, it
    returns practically immediately. The original version of the program blocked at
    this point because the iterations took so long.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '`transform`调用与`to_iteration_count`的异步版本本身*不进行计算*，而是设置线程和future对象，它几乎立即返回。程序的原始版本在这一点上被阻塞，因为迭代时间太长。'
- en: 'The parallelized version of the program does of course block *somewhere*, too.
    The function that prints all our values on the terminal must access the results
    from within the futures. In order to do that, it calls `x.get()` on all the values.
    And this is the trick: while it waits for the first value to be printed, a lot
    of other values are calculated at the same time. So if the `get()` call of the
    first future returns, the next future might be ready for printing already too!'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的并行化版本当然也会在*某个地方*阻塞。在终端上打印所有值的函数必须访问future中的结果。为了做到这一点，它对所有值调用`x.get()`。这就是诀窍：当它等待第一个值被打印时，很多其他值同时被计算。因此，如果第一个future的`get()`调用返回，下一个future可能已经准备好打印了！
- en: In case `w * h` results in much larger numbers, there will be some measurable
    overhead in creating and synchronizing all these futures. In this case, the overhead
    is not too significant. On my laptop with an Intel i7 processor with 4 *hyperthreading*
    capable cores (which results in eight virtual cores), the parallel version of
    this program ran more than 3-5 times faster compared to the original program.
    The ideal parallelization would make it indeed 8 times faster. Of course, this
    speedup will vary between different computers, because it depends on a lot of
    factors.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`w * h`的结果是非常大的数字，那么创建和同步所有这些future将会有一些可测量的开销。在这种情况下，开销并不太显著。在我的笔记本电脑上，配备了一颗Intel
    i7处理器，有4个*超线程*核心（结果是八个虚拟核心），与原始程序相比，这个程序的并行版本运行速度快了3-5倍。理想的并行化会使其快8倍。当然，这种加速会因不同的计算机而异，因为它取决于很多因素。
- en: Implementing a tiny automatic parallelization library with std::future
  id: totrans-512
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用std::future实现一个微小的自动并行化库
- en: Most complex tasks can be broken down into subtasks. From all subtasks, we can
    draw an **directed acyclic graph** (**DAG**) that describes which subtask depends
    on what other subtasks in order to finish the higher level task. Let us, for example,
    imagine that we want to produce the string `"foo bar foo bar this that "`, and
    we can only do this by creating single words and concatenate those with other
    words, or with themselves. Let's say this functionality is provided by three primitive
    functions `create`, `concat`, and `twice`.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数复杂的任务可以分解成子任务。从所有子任务中，我们可以绘制一个描述哪个子任务依赖于其他子任务以完成更高级任务的**有向无环图**（**DAG**）。例如，假设我们想要生成字符串`"foo
    bar foo bar this that "`，我们只能通过创建单词并将其与其他单词或自身连接来实现。假设这个功能由三个基本函数`create`、`concat`和`twice`提供。
- en: 'Taking this into account, we can draw the following DAG that visualizes the
    dependencies between them in order to get the final result:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们可以绘制以下DAG，以可视化它们之间的依赖关系，以便获得最终结果：
- en: '![](img/0648ebd7-03e5-4c9c-8ee2-8ed58cb25773.png)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0648ebd7-03e5-4c9c-8ee2-8ed58cb25773.png)'
- en: When implementing this in code, it is clear that everything can be implemented
    in a serial manner on one CPU core. Alternatively, all subtasks that depend on
    no other subtasks or other subtasks that already have been finished, can be executed
    *concurrently* on multiple CPU cores.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中实现这一点时，很明显一切都可以在一个CPU核心上以串行方式实现。或者，所有不依赖其他子任务或其他已经完成的子任务的子任务可以在多个CPU核心上*并发*执行。
- en: It might perhaps seem tedious to write such code, even with `std::async` because
    the dependencies between the subtasks need to be modeled. In this recipe, we will
    implement two little library helper functions that help to transform the normal
    functions `create`, `concat`, and `twice` to functions that work asynchronously.
    With those, we will find a really elegant way to set up the dependency graph.
    During execution, the graph will parallelize itself in a *seemingly intelligent*
    way in order to calculate the result as fast as possible.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 编写这样的代码可能看起来有点乏味，即使使用`std::async`，因为子任务之间的依赖关系需要被建模。在本配方中，我们将实现两个小型库辅助函数，帮助将普通函数`create`、`concat`和`twice`转换为异步工作的函数。有了这些，我们将找到一种真正优雅的方式来设置依赖图。在执行过程中，图将以一种*看似智能*的方式并行化，以尽可能快地计算结果。
- en: How to do it...
  id: totrans-518
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In this section, we are going to implement some functions that simulate computation-intensive
    tasks that depend on each other, and let them run as parallel as possible:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一些函数，模拟相互依赖的计算密集型任务，并让它们尽可能并行运行：
- en: 'Let''s first include all the necessary headers:'
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先包含所有必要的头文件：
- en: '[PRE114]'
  id: totrans-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'We need to synchronize concurrent access to `cout`, so let''s use the synchronization
    helper from the other recipe in this chapter:'
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要同步对`cout`的并发访问，因此让我们使用本章其他配方中的同步助手：
- en: '[PRE115]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Now let''s implement three functions which transform strings. The first function
    shall create an `std::string` object from a C-string. We let it sleep for 3 seconds
    to simulate that string creation is computation-heavy:'
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们实现三个转换字符串的函数。第一个函数将从C字符串创建一个`std::string`对象。我们让它休眠3秒来模拟字符串创建是计算密集型的：
- en: '[PRE116]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'The next function accepts two string objects as arguments and returns their
    concatenation. We give it 5-second wait time to simulate that this is a time-consuming
    task:'
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个函数接受两个字符串对象作为参数并返回它们的连接。我们给它5秒的等待时间来模拟这是一个耗时的任务：
- en: '[PRE117]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'The last computation-heavy function accepts a string and concatenates it with
    itself. It shall take 3 seconds to do this:'
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个计算密集型的函数接受一个字符串并将其与自身连接。这将花费3秒的时间：
- en: '[PRE118]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'We could now already use those functions in a serial program, but we want to
    get some elegant automatic parallelization. So let''s implement some helpers for
    this. *Attention please*, the following three functions look really complicated.
    `asynchronize` accepts a function `f` and returns a callable object that captures
    it. We can call this callable object with any number of arguments, and then it
    will capture those together with `f` in another callable object which it returns
    to us. This last callable object can be called without arguments. It does then
    call `f` asynchronously with all the arguments it captures:'
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经可以在串行程序中使用这些函数了，但我们想要实现一些优雅的自动并行化。所以让我们为此实现一些辅助函数。*请注意*，接下来的三个函数看起来非常复杂。`asynchronize`接受一个函数`f`并返回一个可调用对象来捕获它。我们可以用任意数量的参数调用这个可调用对象，然后它将这些参数与`f`一起捕获在另一个可调用对象中返回给我们。然后可以无需参数调用这个最后的可调用对象。它会异步地使用捕获的所有参数调用`f`：
- en: '[PRE119]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'The next function will be used by the function we declare in the next step
    afterward. It accepts a function `f`, and captures it in a callable object that
    it returns. That object can be called with a number of future objects. It will
    then call `.get()` on all the futures, apply `f` to them and return its result:'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个函数将被我们在下一步中声明的函数使用。它接受一个函数`f`，并将其捕获在一个可调用对象中返回。该对象可以用一些future对象调用。然后它将在所有的future上调用`.get()`，对它们应用`f`，并返回其结果：
- en: '[PRE120]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'The last helper function does also accept a function `f`. It returns a callable
    object that captures `f`. That callable object can be called with any number of
    callable objects as arguments, which it returns captured together with `f` in
    another callable object. That final callable object can then be called without
    arguments. It does then call all the callable objects that are captured in the
    `xs...` pack. These return futures which need to be unwrapped with `fut_unwrap`.
    The future-unwrapping and actual application of the real function `f` on the real
    values from the futures does again happen asynchronously using `std::async`:'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个辅助函数也接受一个函数`f`。它返回一个可调用对象来捕获`f`。这个可调用对象可以用任意数量的可调用对象作为参数调用，然后它将这些与`f`一起捕获在另一个可调用对象中返回。然后可以无需参数调用这个最后的可调用对象。它会异步地调用捕获在`xs...`包中的所有可调用对象。这些将返回future，需要使用`fut_unwrap`来解开。未来的解开和对来自未来的实际值应用真实函数`f`的实际应用再次使用`std::async`异步进行：
- en: '[PRE121]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Ok, that was maybe kind of a crazy ride that was slightly reminiscent of the
    movie *"Inception"* because of the lambda expressions that return lambda expressions.
    We will have a very detailed look at this voodoo-code later. Now let''s take the
    functions `create`, `concat`, and `twice` and make them asynchronous. The function
    `async_adapter` makes a completely normal function wait for future arguments and
    return a future result. It is kind of a translating wrapper from the synchronous
    to the asynchronous world. We apply it to `concat` and `twice`. We must use `asynchronize`
    on `create` because it shall return a future, but we will feed it with real values
    instead of futures. The task dependency chain must begin with `create` calls:'
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 好的，这可能有点疯狂，有点像电影《盗梦空间》，因为它使用了返回lambda表达式的lambda表达式。我们稍后会对这段代码进行非常详细的解释。现在让我们将函数`create`、`concat`和`twice`改为异步的。函数`async_adapter`使一个完全正常的函数等待未来的参数并返回未来的结果。它是一种从同步到异步世界的翻译包装。我们将其应用于`concat`和`twice`。我们必须在`create`上使用`asynchronize`，因为它应该返回一个future，但我们将用实际值而不是future来提供它。任务依赖链必须从`create`调用开始：
- en: '[PRE122]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'Now we have automatically parallelizing functions that have the same names
    as the original synchronous ones, but with a `p`-prefix. Let us now set up a complex
    example dependency tree. First, we create the strings `"foo "` and `"bar "`, which
    we immediately concatenate to `"foo bar "`. This string is then concatenated with
    itself using `twice`. Then we create the strings `"this "` and `"that "`, which
    we concatenate to `"this that "`. Finally, we concatenate the results to `"foo
    bar foo bar this that "`. The result shall be saved in the variable `callable`.
    Then finally call `callable().get()` in order to start the computation and wait
    for its return value, in order to also print that. No computation is done before
    we call `callable()`, and after this call, all the magic starts:'
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了自动并行化的函数，它们的名称与原来的同步函数相同，但带有`p`前缀。现在让我们建立一个复杂的依赖树示例。首先，我们创建字符串`"foo "`和`"bar
    "`，然后立即将它们连接成`"foo bar "`。然后使用`twice`将这个字符串与自身连接。然后我们创建字符串`"this "`和`"that "`，将它们连接成`"this
    that "`。最后，我们将结果连接成`"foo bar foo bar this that "`。结果将保存在变量`callable`中。然后最后调用`callable().get()`来开始计算并等待其返回值，以便打印出来。在调用`callable()`之前不会进行任何计算，而在此调用之后，所有的魔法就开始了：
- en: '[PRE123]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'Compiling and running the program shows that all the `create` calls are performed
    at the same time, and then the other calls are performed. It looks as if they
    were scheduled intelligently. The whole program runs for 16 seconds. If the steps
    were not performed in parallel, it would take 30 seconds to complete. Note that
    we need a system with at least four CPU cores to be able to perform all `create`
    calls at the same time. If the system had fewer CPU cores, then some calls would
    have to share CPUs which would of course then consume more time:'
  id: totrans-540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和运行程序显示所有`create`调用同时执行，然后执行其他调用。看起来它们被智能地调度了。整个程序运行了16秒。如果步骤不是并行执行的，完成需要30秒。请注意，我们需要至少四个CPU核心的系统才能同时执行所有`create`调用。如果系统的CPU核心较少，那么一些调用将不得不共享CPU，这当然会消耗更多时间。
- en: '[PRE124]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: How it works...
  id: totrans-542
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'A plain serial version of this program without any `async` and `future` magic
    would look like the following:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序的普通串行版本，没有任何`async`和`future`魔法，看起来像这样：
- en: '[PRE125]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: In this recipe, we wrote the helper functions `async_adapter` and `asynchronize`
    that helped us create new functions from `create`, `concat`, and `twice`. We called
    those new asynchronous functions `pcreate`, `pconcat`, and `ptwice`.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们编写了辅助函数`async_adapter`和`asynchronize`，帮助我们从`create`、`concat`和`twice`创建新函数。我们称这些新的异步函数为`pcreate`、`pconcat`和`ptwice`。
- en: Let us first ignore the complexity of the implementation of `async_adapter`
    and `asynchronize`, in order to first have a look what this got us.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先忽略`async_adapter`和`asynchronize`的实现复杂性，先看看这给我们带来了什么。
- en: 'The serial version looks similar to this code:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 串行版本看起来类似于这段代码：
- en: '[PRE126]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'The parallelized version looks similar to the following:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化版本看起来类似于以下内容：
- en: '[PRE127]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Okay, now we get at the complicated part. The type of the parallelized result
    is not `string`, but a callable object that returns a `future<string>` on which
    we can call `get()`. This might indeed look crazy at first.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们来到了复杂的部分。并行化结果的类型不是`string`，而是一个返回`future<string>`的可调用对象，我们可以在其上调用`get()`。这一开始可能看起来很疯狂。
- en: 'So, how and *why* did we exactly end up with callable objects that return futures?
    The problem with our `create`, `concat`, and `twice` methods is, that they are
    *slow*. (okay, we made them artificially slow, because we tried to model real
    life tasks that consume a lot of CPU time). But we identified that the dependency
    tree which describes the data flow has independent parts that could be executed
    in parallel. Let''s have a look at two example schedules:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们到底是如何以及*为什么*最终得到了返回future的可调用对象？我们的`create`、`concat`和`twice`方法的问题在于它们很*慢*。（好吧，我们人为地让它们变慢，因为我们试图模拟消耗大量CPU时间的真实任务）。但我们发现描述数据流的依赖树有独立的部分可以并行执行。让我们看两个示例调度：
- en: '![](img/8745f882-ba89-481e-bfcd-06203d12370f.png)'
  id: totrans-553
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8745f882-ba89-481e-bfcd-06203d12370f.png)'
- en: On the left side, we see a *single core* schedule. All the function calls have
    to be done one after each other because we have only a single CPU. That means,
    that when `create` costs 3 seconds, `concat` costs 5 seconds and `twice` costs
    3 seconds, it will take 30 seconds to get the end result.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，我们看到一个*单核*调度。所有函数调用必须一个接一个地执行，因为我们只有一个CPU。这意味着，当`create`花费3秒，`concat`花费5秒，`twice`花费3秒时，获取最终结果需要30秒。
- en: On the right side, we see a *parallel schedule* where as much is done in parallel
    as the dependencies between the function calls allow. In an ideal world with four
    cores, we can create all substrings at the same time, then concatenate them and
    so on. The minimal time to get the result with an optimal parallel schedule is
    16 seconds. We cannot go faster if we cannot make the function calls themselves
    faster. With just four CPU cores we can achieve this execution time. We measurably
    achieved the optimal schedule. How did it work?
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，我们看到一个*并行调度*，在这个调度中尽可能多地并行执行函数调用之间的依赖关系。在一个理想的拥有四个核心的世界中，我们可以同时创建所有子字符串，然后连接它们等等。以最佳并行调度获得结果的最短时间是16秒。如果函数调用本身不能更快，我们就无法更快地进行。只有四个CPU核心，我们就可以实现这个执行时间。我们可以明显地实现了最佳调度。这是如何实现的？
- en: 'We could naively write the following code:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以天真地写下以下代码：
- en: '[PRE128]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: This is a good start for `a`, `b`, `c`, and `d`, which represent the four substrings
    to begin with. These are created asynchronously in the background. Unfortunately,
    this code blocks on the line where we initialize `e`. In order to concatenate
    `a` and `b`, we need to call `get()` on both of them, which *blocks* until these
    values are *ready*. Obviously, this is not a good idea, because the parallelization
    stops being parallel on the first `get()` call. We need a better strategy.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`a`、`b`、`c`和`d`的良好起点，它们代表了最初的四个子字符串。这些都是在后台异步创建的。不幸的是，这段代码在初始化`e`的地方阻塞了。为了连接`a`和`b`，我们需要在它们两个上调用`get()`，这会*阻塞*直到这些值准备好。显然，这不是一个好主意，因为并行化在第一次`get()`调用时就停止了。我们需要一个更好的策略。
- en: 'Okay, so let us roll out the complicated helper functions we wrote. The first
    one is `asynchronize`:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们先展开我们编写的复杂辅助函数。第一个是`asynchronize`：
- en: '[PRE129]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'When we have a function `int f(int, int)` then we can do the following:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一个函数`int f(int, int)`时，我们可以这样做：
- en: '[PRE130]'
  id: totrans-562
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '`f2` is our asynchronous version of `f`. It can be called with the same arguments
    like `f`, because it *mimics* `f`. Then it returns a callable object, which we
    save in `f3`. `f3` now captures `f` and the arguments `1, 2`, but it did not call
    anything yet. This is just about the capturing.'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '`f2`是我们的`f`的异步版本。它可以用与`f`相同的参数调用，因为它*模仿*了`f`。然后它返回一个可调用对象，我们将其保存在`f3`中。`f3`现在捕获了`f`和参数`1,
    2`，但它还没有调用任何东西。这只是关于捕获的。 '
- en: When we call `f3()` now, then we finally get a future, because `f3()` does the
    `async(launch::async, **f, 1, 2**);` call! In that sense, the semantic meaning
    of `f3` is "*Take the captured function and the arguments, and throw them together
    into `std::async`.*".
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们现在调用`f3()`时，最终我们得到一个future，因为`f3()`执行了`async(launch::async, **f, 1, 2**);`调用！从这个意义上说，`f3`的语义意思是“*取得捕获的函数和参数，然后将它们一起抛到`std::async`中*”。
- en: 'The inner lambda expression that does not accept any arguments gives us an
    indirection. With it, we can set up work for parallel dispatch but do not have
    to call anything that blocks, *yet*. We follow the same principle in the much
    more complicated function `async_adapter`:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 不接受任何参数的内部lambda表达式给了我们一个间接引用。有了它，我们可以为并行调度设置工作，但不必调用任何阻塞的东西，*至少*目前还不用。我们在更复杂的函数`async_adapter`中也遵循相同的原则：
- en: '[PRE131]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: This function does also first return a function that mimics `f` because it accepts
    the same arguments. Then that function returns a callable object that again accepts
    no arguments. And then that callable object finally differs from the other helper
    function.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数首先返回一个模仿`f`的函数，因为它接受相同的参数。然后该函数返回一个可调用对象，再次不接受任何参数。然后这个可调用对象最终与其他辅助函数不同。
- en: 'What does the `async(launch::async, fut_unwrap(f), xs()...);` line mean? The
    `xs()...` part means, that all arguments that are saved in pack `xs` are assumed
    to be callable objects (like the ones we are creating all the time!), and so they
    are all called without arguments. Those callable objects that we are producing
    all the time themselves produce future values, on which we can call `get()`. This
    is where `fut_unwrap` comes into play:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '`async(launch::async, fut_unwrap(f), xs()...);`这一行是什么意思？`xs()...`部分意味着，保存在包`xs`中的所有参数都被假定为可调用对象（就像我们一直在创建的那些对象！），因此它们都被调用而不带参数。我们一直在产生的这些可调用对象本身产生未来值，我们可以在其上调用`get()`。这就是`fut_unwrap`发挥作用的地方：'
- en: '[PRE132]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '`fut_unwrap` just transforms a function `f` into a function object that accepts
    a range of arguments. This function object does then call `.get()` on *all* of
    them and then finally forwards them to `f`.'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '`fut_unwrap`只是将函数`f`转换为一个接受一系列参数的函数对象。然后这个函数对象调用`.get()`，最后将它们转发给`f`。'
- en: Take your time to digest all of this. When we used this in our main function,
    then the `auto result (pconcat(...));` call chain did just construct a large callable
    object that contains all functions and all arguments. No `async` call was done
    at this point yet. Then, when we called `result()`, we *unleashed a little avalanche*
    of `async` and `.get()` calls that come just in the right order to not block each
    other. In fact, no `get()` call happens before not all `async` calls have been
    dispatched.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 慢慢消化这一切。当我们在主函数中使用时，`auto result (pconcat(...));`调用链只是构造了一个包含所有函数和所有参数的大型可调用对象。此时还没有进行任何`async`调用。然后，当我们调用`result()`时，我们*释放了一小波*`async`和`.get()`调用，它们恰好按照正确的顺序来避免相互阻塞。事实上，在所有`async`调用都已经分派之前，没有`get()`调用会发生。
- en: In the end, we can finally call `.get()` on the future value that `result()`
    returned, and there we have our final string.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们终于可以在`result()`返回的未来值上调用`.get()`，然后我们就得到了我们的最终字符串。
