- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Proceeding with Inter-Process Communication
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 继续进行进程间通信
- en: The previous chapter presented many features of C++20 that allow you to execute
    tasks in parallel. Outside of the global variables, it didn’t cover ways to communicate
    between processes or threads. On a system level, most of the asynchronous calls
    are born in the continuous communication between processes and different computer
    systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了C++20的许多功能，允许你并行执行任务。除了全局变量外，它没有涵盖进程或线程之间的通信方式。在系统级别，大多数异步调用都源于进程和不同计算机系统之间的持续通信。
- en: In this chapter, you will learn about the **inter-process communication** (**IPC**)
    interfaces that Linux provides. Through them, you will get a full picture of possibilities
    to cover your system and software requirements. You’ll start by learning about
    **message queues** (**MQs**) as a continuation of the discussion about pipes in
    [*Chapter 3*](B20833_03.xhtml#_idTextAnchor047). In addition, we will analyze
    in detail the work of the **semaphore** and **mutex** synchronization techniques.
    We will introduce you to some new C++20 features in this area that are easy to
    use, and you will no longer have to implement such yourself.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解Linux提供的**进程间通信**（**IPC**）接口。通过它们，你将全面了解满足系统和软件需求的可能性。你将从学习**消息队列**（**MQs**）作为对*第3章*（[B20833_03.xhtml#_idTextAnchor047](B20833_03.xhtml#_idTextAnchor047)）中管道讨论的延续。此外，我们将详细分析**信号量**和**互斥锁**同步技术的工作。我们将介绍一些易于使用的C++20新特性，你将不再需要自己实现这些特性。
- en: This allows us to proceed with the **shared memory** technique, which will give
    you the option to transfer large amounts of data fast. Finally, if you’re interested
    in communication between computer systems on the network, you’ll learn about sockets
    and network communication protocols. With this, we give you some practical and
    commands to administer your own system on the network.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够继续使用**共享内存**技术，这将为你提供快速传输大量数据的选择。最后，如果你对网络中计算机系统的通信感兴趣，你将了解套接字和网络通信协议。通过这些，我们为你提供了一些实际命令来管理自己的网络系统。
- en: We will build on the discussions started in this chapter in [*Chapter 9*](B20833_09.xhtml#_idTextAnchor129).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章开始的讨论基础上，在*第9章*（[B20833_09.xhtml#_idTextAnchor129](B20833_09.xhtml#_idTextAnchor129)）中进行扩展。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introducing MQs and the pub/sub mechanism
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍MQs和发布/订阅机制
- en: Guaranteeing atomic operations through semaphores and mutual exclusions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过信号量和互斥锁保证原子操作
- en: Using shared memory
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用共享内存
- en: Communicating through the network with sockets
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过套接字进行网络通信
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To run the code examples, you must prepare the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行代码示例，你必须准备以下内容：
- en: A Linux-based system capable of compiling and executing C++20 (for example,
    **Linux** **Mint 21**)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种基于Linux的系统，能够编译和执行C++20（例如，**Linux** **Mint 21**）
- en: A GCC 12.2 compiler ([https://gcc.gnu.org/git/gcc.git gcc-source](https://gcc.gnu.org/git/gcc.gitgcc-source))
    with the `-std=c++2a`, `-lpthread`, and `-``lrt` flags
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有`-std=c++2a`、`-lpthread`和`-lrt`标志的GCC 12.2编译器([https://gcc.gnu.org/git/gcc.git
    gcc-source](https://gcc.gnu.org/git/gcc.gitgcc-source))
- en: For all the examples, you can alternatively use [https://godbolt.org/](https://godbolt.org/)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有示例，你也可以选择使用[https://godbolt.org/](https://godbolt.org/)
- en: All code examples in this chapter are available for download from [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中所有代码示例均可从[https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207)下载
- en: Introducing MQs and the pub/sub mechanism
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍MQs和发布/订阅机制
- en: We’re glad to be back on the IPC topic. The last time we discussed it was in
    [*Chapter 3*](B20833_03.xhtml#_idTextAnchor047), where we explained pipes and
    used some code examples. You learned about the basic mechanism of exchanging data
    between processes, but as you remember, there are some blocking points. As with
    any programming instrument, pipes have particular usage – they are fast, and they
    can help you send and receive data from both related (forked) processes (through
    **anonymous pipes**) and unrelated processes (through **named pipes**).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很高兴再次回到 IPC 主题。上次我们讨论它是在[*第 3 章*](B20833_03.xhtml#_idTextAnchor047)，在那里我们解释了管道并使用了一些代码示例。你学习了进程间交换数据的基本机制，但正如你所记得的，有一些阻塞点。与任何编程工具一样，管道有特定的用途
    – 它们速度快，可以帮助你从相关（派生）进程（通过**匿名管道**）和不相关进程（通过**命名管道**）发送和接收数据。
- en: 'In a similar fashion, we could use MQs to transfer data, which are available
    to related and unrelated processes, too. They provide the ability to send a single
    message to multiple receiving processes. But as you saw, pipes are primitive in
    the sense of sending and receiving binary data as is, while MQs bring the notion
    of a *message* to the table. The policy of the transfer is still configured in
    the calling process – queue name, size, signal handling, priority, and so on –
    but its policy and ability to serialize data are now in the hands of the MQ’s
    implementation. This gives the programmer a relatively simple and flexible way
    to prepare and handle messages of data. Based on our software design, we could
    easily implement an asynchronous send-receive data transfer or a **publish/subscribe**
    (**pub/sub**) mechanism. Linux provides two different interfaces for MQs – one
    designed for local server applications (coming from System V) and one designed
    for real-time applications (coming from POSIX). For the purposes of the book,
    we prefer to use the POSIX interface as it is richer and cleaner in configuration.
    It is also a file-based mechanism, as discussed in [*Chapter 1*](B20833_01.xhtml#_idTextAnchor014),
    and you can find a mounted queue through the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式，我们可以使用 MQ 来传输数据，这些数据对相关和不相关的进程都是可用的。它们提供了向多个接收进程发送单个消息的能力。但正如你所见，管道在发送和接收二进制数据方面是原始的，而
    MQ 则引入了 *消息* 的概念。传输策略仍然在调用过程中配置 – 队列名称、大小、信号处理、优先级等 – 但其策略和数据序列化的能力现在掌握在 MQ 的实现手中。这为程序员提供了一种相对简单灵活的方式来准备和处理数据消息。根据我们的软件设计，我们可以轻松实现异步发送-接收数据传输或
    **发布/订阅**（**pub/sub**）机制。Linux 为 MQ 提供了两个不同的接口 – 一个是为本地服务器应用程序设计的（来自 System V），另一个是为实时应用程序设计的（来自
    POSIX）。出于本书的目的，我们更喜欢使用 POSIX 接口，因为它在配置上更丰富、更简洁。它也是一个基于文件的机制，如[*第 1 章*](B20833_01.xhtml#_idTextAnchor014)中所述，你可以通过以下方式找到挂载的队列：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This interface is available through the OS real-time functions library, `librt`,
    so you need to link it during compilation. The MQ itself can be visualized as
    follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此接口可通过操作系统实时函数库 `librt` 获取，因此在编译时需要链接它。MQ 本身可以表示如下：
- en: '![Figure 7.1 – Representation of IPC through the MQ](img/Figure_7.1_B20833.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 通过 MQ 表示 IPC](img/Figure_7.1_B20833.jpg)'
- en: Figure 7.1 – Representation of IPC through the MQ
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 通过 MQ 表示 IPC
- en: 'Let’s look at an example where we send data from one process to another. The
    exemplary data is already stored in a file and loaded to be sent through the MQ.
    The full example can be found at [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子，其中我们从一个进程向另一个进程发送数据。示例数据已经存储在文件中，并加载到通过 MQ 发送。完整的示例可以在[https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207)找到：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We set our initial configuration together with the queue name as the pathname:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初始配置与队列名称一起作为路径名设置：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Additional configuration is applied to the MQ and the receiving end is prepared.
    The `mq_open()`function is called in order to create the MQ on the filesystem
    and open its reading end. Through an endless loop, the data is received as it
    is read from a binary file and printed out (markers `{2}` and `{3}` in the preceding
    code) until the file is fully consumed. Then, the receiving ends and the reading
    end are closed (marker `{4}` in the following code). If there’s nothing else to
    be done, the MQ is deleted from the filesystem through `mq_unlink()`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的配置应用于消息队列，并且接收端已准备就绪。通过调用 `mq_open()` 函数，在文件系统中创建消息队列并打开其读取端。通过一个无限循环，数据在从二进制文件中读取的同时被接收并打印出来（前述代码中的标记
    `{2}` 和 `{3}`）。直到文件完全被消耗。然后，关闭接收端和读取端（以下代码中的标记 `{4}`）。如果没有其他事情要做，可以通过 `mq_unlink()`
    从文件系统中删除消息队列：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This example is implemented with two threads but could be done in the same fashion
    with two processes. The MQ functionality will remain the same. We call `mq_open()`
    again and open the MQ for writing (marker `{5}` in the following code). The created
    queue can fit up to 10 messages and each message can be 1,024 bytes in size –
    this is defined through the MQ attributes in the earlier code snippet. If you
    don’t want the MQ operations to be blocking, you could use the `O_NONBLOCK` flag
    in the attributes, or use `mq_notify()` prior to the `mq_receive()` call. That
    way, if the MQ is empty, the reader will be blocked, but `mq_notify()` will trigger
    a signal on message arrival and the process will be resumed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子使用两个线程实现，但也可以用两个进程以同样的方式完成。消息队列的功能将保持不变。我们再次调用 `mq_open()` 并为写入打开消息队列（以下代码中的标记
    `{5}`）。创建的队列可以容纳多达 10 条消息，每条消息的大小为 1,024 字节——这是通过之前代码片段中的消息队列属性定义的。如果您不希望消息队列操作阻塞，可以在属性中使用
    `O_NONBLOCK` 标志，或者在 `mq_receive()` 调用之前使用 `mq_notify()`。这样，如果消息队列为空，读取器将被阻塞，但
    `mq_notify()` 会在消息到达时触发一个信号，进程将被恢复。
- en: 'Then, the locally stored file is opened with the test data and we read from
    it (markers `{6}` and `{7}` in the following code). While we read (you could use
    `std::ofstream` as well), we send its contents through the MQ (marker `{8}` in
    the following code). The message has the lowest priority possible, which means
    `0`. In a system with more messages in a queue, we could set a higher priority
    and they will be handled in a decreasing order. The maximum value is visible from
    `sysconf(_SC_MQ_PRIO_MAX)`, where, for Linux, this is `32768`, but POSIX enforces
    a range from 0 to 31 in order to be compliant with other OSs as well. Let’s check
    the following code snippet:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用测试数据打开本地存储的文件，并从中读取（以下代码中的标记 `{6}` 和 `{7}`）。在读取的同时（您也可以使用 `std::ofstream`），我们通过消息队列发送其内容（以下代码中的标记
    `{8}`）。消息具有可能的最小优先级，这意味着 `0`。在一个队列中有更多消息的系统，我们可以设置更高的优先级，并且它们将按降序处理。最大值可以从 `sysconf(_SC_MQ_PRIO_MAX)`
    中看到，对于 Linux 来说，这是 `32768`，但 POSIX 强制从 0 到 31 的范围，以便与其他操作系统兼容。让我们检查以下代码片段：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we send a zero-sized message to indicate the end of the communication
    (marker `{9}`):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们发送一个零大小的消息来指示通信的结束（标记 `{9}`）：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result is the following (the printed data from the file is reduced for
    readability):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下（为了可读性，文件中的打印数据已缩减）：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is a very simple example considering we have only two workers – `readFromQueue()`
    and `writeToQueue()`. The MQs allow us to scale up and execute a many-to-many
    communication. This approach could be found on many embedded systems, as it’s
    also real-time compliant and doesn’t expect any synchronization primitives to
    be used. Many microservice architectures and serverless applications rely on it.
    In the next section, we are going to discuss one of the most popular patterns,
    based on MQs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们只有两个工作者——`readFromQueue()` 和 `writeToQueue()`，这是一个非常简单的例子。消息队列允许我们扩展并执行多对多的通信。这种方法可以在许多嵌入式系统中找到，因为它也符合实时性，并且不需要使用任何同步原语。许多微服务架构和无服务器应用程序都依赖于它。在下一节中，我们将讨论基于消息队列的最流行的模式之一。
- en: The pub/sub mechanism
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发布/订阅机制
- en: You’ve probably figured out that one MQ could become a bottleneck while scaling
    up. As you observed in the previous example, there’s the message count and size
    limitation. Another issue is the fact that after a message is consumed, it is
    removed from the queue – there can be only one consumer of a given message at
    a time. The data provider (the producer) has to manage the correct message address
    as well, meaning adding extra data to help the consumers identify to whom the
    message is sent, and each consumer has to follow that policy.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经意识到，在扩展时，一个MQ可能会成为瓶颈。正如你在前面的例子中观察到的，存在消息计数和大小限制。另一个问题是，消息被消费后，它将从队列中移除——同一时间只能有一个消费者消费特定的消息。数据提供者（生产者）还必须管理正确的消息地址，这意味着添加额外的数据以帮助消费者识别消息是发送给谁的，每个消费者都必须遵循这一策略。
- en: A preferred approach is to create a separate MQ for each consumer. The producer
    will be aware of those MQs a priori, either at compile time (all MQs are listed
    in the data segment by the system programmer) or runtime (each consumer will send
    its MQ pathname at startup and the producer will handle this information). That
    way, the consumers are *subscribing* to receive data from a given producer, and
    the producer *publishes* its data to all MQs it’s aware of. Therefore, we call
    this a **publish-subscribe** mechanism.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一种推荐的方法是为每个消费者创建一个单独的消息队列（MQ）。生产者事先知道这些MQ，无论是在编译时（所有MQ都由系统程序员在数据段中列出）还是在运行时（每个消费者在启动时都会发送其MQ路径名，生产者将处理这些信息）。这样，消费者就*订阅*接收来自特定生产者的数据，而生产者则将其数据发布到它所知道的全部MQ。因此，我们称这种机制为**发布-订阅**机制。
- en: 'Of course, the exact implementations might vary, depending on the software
    design, but the idea will remain the same. In addition, there could be multiple
    producers sending data to multiple consumers, and we say this is a **many-to-many**
    realization. Take a look at the following diagram:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，具体的实现可能会有所不同，这取决于软件设计，但基本思想将保持不变。此外，可能有多个生产者向多个消费者发送数据，我们称这种情况为**多对多**实现。请看下面的图示：
- en: '![Figure 7.2 – Representation of the MQ realization of the pub/sub mechanism](img/Figure_7.2_B20833.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2 – pub/sub机制的MQ实现表示](img/Figure_7.2_B20833.jpg)'
- en: Figure 7.2 – Representation of the MQ realization of the pub/sub mechanism
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – pub/sub机制的MQ实现表示
- en: As we proceed toward the decoupling of processes, we make our system more flexible.
    It becomes easier to scale as the subscribers don’t lose computational time identifying
    whether the messages are directed to them or not. It is also easy to add a new
    producer or consumer without disturbing others. The MQ is implemented on an OS
    level, thus we could take it as a robust IPC mechanism. One possible disadvantage,
    though, is the fact that producers usually don’t receive any health information
    from the subscribers. This leads to MQs being full of unconsumed data and the
    producers being blocked. Thus, additional implementation frameworks are implemented
    on a more abstract level, which takes care of such use cases. We encourage you
    to additionally research the **Observer** and **Message Broker** design patterns.
    In-house-developed pub/sub mechanisms are usually built on top of them and not
    always through MQs. Nonetheless, as you have probably guessed, sending large amounts
    of data is going to be a slow operation through such mechanisms. So, we need an
    instrument to get a big portion of data fast. Unfortunately, this requires additional
    synchronization management to avoid data races, similar to [*Chapter 6*](B20833_06.xhtml#_idTextAnchor086).
    The next section is about the synchronization primitives.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们向进程解耦的方向发展，我们的系统变得更加灵活。由于订阅者不需要花费计算时间来识别消息是否是针对他们的，因此更容易进行扩展。添加新的生产者或消费者而不打扰他人也很容易。MQ是在操作系统级别实现的，因此我们可以将其视为一个健壮的进程间通信（IPC）机制。然而，一个可能的缺点是，生产者通常不会从订阅者那里收到任何健康信息。这导致MQ中充满了未消费的数据，生产者被阻塞。因此，在更抽象的级别上实现了额外的实现框架，以处理此类用例。我们鼓励你进一步研究**观察者**和**消息代理**设计模式。内部开发的pub/sub机制通常建立在它们之上，而不一定通过MQ。尽管如此，正如你可能已经猜到的，通过这样的机制发送大量数据将是一个缓慢的操作。因此，我们需要一个工具来快速获取大量数据。不幸的是，这需要额外的同步管理来避免数据竞争，类似于[*第6章*](B20833_06.xhtml#_idTextAnchor086)。下一节将介绍同步原语。
- en: Guaranteeing atomic operations through semaphores and mutual exclusions
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过信号量和互斥保证原子操作
- en: Let’s try to *zoom in* on a shared resource and see what happens in the CPU.
    We will provide a simple and effective way to explain where exactly the data races
    start from. They were already thoroughly discussed in [*Chapter 6*](B20833_06.xhtml#_idTextAnchor086).
    Everything we learn here should be considered as an addition, in a sense, but
    the analysis methodology of concurrent and parallel processing remains the same
    as earlier. But now, we focus on concrete low-level problems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试*放大*共享资源，看看在CPU中会发生什么。我们将提供一个简单而有效的方法来解释数据竞争究竟从哪里开始。它们已经在[*第6章*](B20833_06.xhtml#_idTextAnchor086)中进行了充分讨论。我们在这里学到的所有内容都应该被视为一种补充，但并发和并行处理的分析方法与之前相同。但现在，我们关注具体低级问题。
- en: 'Let’s look closely at the following snippet:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看以下片段：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It is a very simple piece of code in which a variable is incremented and printed
    out. According to C++ standards, such a modification is an undefined behavior
    in multithreaded environments. Let’s see how – instead of going through the process’s
    memory layout here, we will analyze its pseudo-assembly code side by side:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段非常简单的代码，其中变量被增加并打印出来。根据C++标准，这种修改在多线程环境中是未定义的行为。让我们看看它是如何做到的——而不是在这里通过进程的内存布局来分析，我们将并行分析其伪汇编代码：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Suppose this increment procedure is in a thread function and there’s more than
    one thread executing it. The `add 1` instruction is done on the loaded value,
    and not on the actual memory location of `shrd_res`. The preceding code snippet
    will be executed multiple times, and most probably in parallel. If we note that
    the thread is a set of instructions, the intuition would be that the instructions
    are executed in a monolithic manner. In other words, each thread routine should
    be run without interruption, which is usually the case. However, there is a small
    particularity that we should keep in mind – the CPU is engineered to keep a small
    latency. It is not built for data parallelism. Therefore, figuratively speaking,
    its main goal is to load itself with a large number of small tasks. Each of our
    threads is executed in a separate processor; this could be a separate CPU, a CPU
    thread, or a CPU core – it really depends on the system. If the number of processors
    (CPUs, cores, or threads) is smaller than *N*, then the remaining threads are
    expected to queue themselves and wait until a processor is freed up.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这个增加过程在一个线程函数中，并且有多个线程在执行它。`加1`指令是在加载的值上执行的，而不是在`shrd_res`的实际内存位置上。前面的代码片段将被多次执行，并且很可能是并行的。如果我们注意到线程是一组指令，那么直观的想法是这些指令将以单一的方式执行。换句话说，每个线程例程应该在没有中断的情况下运行，这通常是情况。然而，我们应该记住一个小细节——CPU被设计成保持较小的延迟。它不是为了数据并行而构建的。因此，从字面上讲，它的主要目标是加载大量的小型任务。我们的每个线程都在一个单独的处理器上执行；这可能是单独的CPU、CPU线程或CPU核心——这完全取决于系统。如果处理器的数量（CPU、核心或线程）小于*N*，那么剩余的线程预计会排队等待，直到有处理器空闲。
- en: Now, the initial threads’ instructions are already loaded there and executed
    as they are. Even when the CPU cores are architecturally the same, their goal
    is to be executed as fast as possible. This means that it is not expected for
    them to be equal in speed because of multiple hardware fluctuations. But `shared_resource`
    is a variable that is, well... a shared resource. This means that whoever gets
    to increment it first will do it and others will follow. Even if we don’t care
    about the `std::cout` result (for example, the printing order stops being sequential),
    we still have something to worry about. And you’ve probably guessed it! We don’t
    know which value we are actually going to increment – is it going to be the last
    stored value of `shared_resource` or the newly incremented one? How could this
    happen?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，初始线程的指令已经加载到那里并按原样执行。即使CPU核心在架构上相同，它们的目的是尽可能快地执行。这意味着由于多个硬件波动，它们在速度上并不期望相等。但`shared_resource`是一个变量，它……是一个共享资源。这意味着第一个到达并增加它的将会这样做，其他人会跟随。即使我们不在乎`std::cout`的结果（例如，打印顺序不再顺序进行），我们仍然有东西要担心。你可能已经猜到了！我们不知道我们将要增加的值是什么——是`shared_resource`的最后一个存储值，还是新增加的一个？这怎么可能发生？
- en: 'Let’s see:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Did you follow what just happened? `Thread 1`’s sequence of instructions was
    disrupted, because of the execution of `Thread 2`. Now, can we predict what’s
    going to be printed? This is known as an `Thread 2` was never executed, as the
    last value to be stored in `shared_resource` will be the one incremented in:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否理解了刚才发生的事情？`Thread 1` 的指令序列因为 `Thread 2` 的执行而被中断。现在，我们能预测将要打印的内容吗？这被称为 `Thread
    2` 永远没有被执行，因为存储在 `shared_resource` 中的最后一个值将是：
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In other words, we lost one increment. There was nothing instructing the CPU
    that both procedures have to be called separately and continuously executed. It
    should be clear that a finite number of instruction combinations are possible,
    all of them leading to unexpected behavior, because it depends on the hardware’s
    state. Such an operation is called **non-atomic**. In order to handle parallelism
    correctly, we need to rely on **atomic** operations! It is the job of the software
    developer to consider this and inform the CPU about such sets of instructions.
    Mechanisms such as mutexes and semaphores are used to manage *atomic* scopes.
    We are going to analyze their roles thoroughly in the next sections.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们丢失了一个增加。没有指令告诉 CPU 这两个过程必须分别调用并连续执行。应该很清楚，可能存在有限数量的指令组合，所有这些都会导致意外的行为，因为这取决于硬件的状态。这种操作被称为
    **非原子**。为了正确处理并行性，我们需要依赖于 **原子** 操作！这是软件开发者的工作，要考虑这一点，并通知 CPU 这样的指令集。例如，互斥锁和信号量用于管理
    *原子* 范围。我们将在下一节中详细分析它们的作用。
- en: Semaphore
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信号量
- en: If you make a questionnaire asking people in multiple professions what a **semaphore**
    is, you will get different answers. A person from the airport will tell you that
    this is a system for signaling someone through the use of flags. A police officer
    might tell you that this is just a traffic light. Asking a train driver will probably
    give you a similar response. Interestingly, this is where *our* semaphores come
    from. Overall, these answers should hint to you that this is a *signaling* mechanism.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你做一个问卷调查，询问多个职业的人什么是 **信号量**，你会得到不同的答案。一个来自机场的人会告诉你这是一个通过使用旗帜来向某人发出信号的系统。一个警察可能会告诉你这只是一个交通灯。询问一个火车司机可能会得到类似的回答。有趣的是，这就是
    *我们的* 信号量的来源。总的来说，这些答案应该向你暗示这是一个 *信号* 机制。
- en: Important note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Programming semaphores were invented by Edsger Dijkstra and are mainly used
    to prevent race conditions. They help us signal when a resource is available or
    not and count how many shared resource units of a given kind are available.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 编程信号量是由 Edsger Dijkstra 发明的，主要用于防止竞态条件。它们帮助我们指示资源是否可用，并计算给定类型的共享资源单元的数量。
- en: Like the previously mentioned signaling mechanisms, semaphores don’t guarantee
    error-free code, as they do not prevent processes or threads from acquiring a
    resource unit – they just inform. In the same way that a train might ignore the
    signal and proceed to an occupied train track or a car could proceed at a busy
    crossroad, this might be catastrophic! Again, it is the software engineer’s task
    to figure out how to use semaphores for the system’s good health. Therefore, let’s
    get to using them.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前提到的信号机制一样，信号量不能保证代码无错误，因为它们不能阻止进程或线程获取资源单元——它们只是通知。就像火车可能会忽略信号并驶向被占用的轨道一样，或者汽车可能会在繁忙的十字路口继续行驶，这可能会造成灾难！再次强调，软件工程师的任务是找出如何使用信号量来确保系统的健康。因此，让我们开始使用它们。
- en: 'Dijkstra provided us with two main functions surrounding a critical section:
    `P(S)` and `V(S)`. As you probably know, he was Dutch, so these functions’ names
    come from the Dutch words for *try* and *increase* (*probeer* and *vrhoog*, respectively),
    where `S` is the semaphore variable. Just by their names, you already get an idea
    about what they are going to do. Let’s look at them in pseudocode:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Dijkstra 提供了我们围绕临界区的主要两个函数：`P(S)` 和 `V(S)`。正如你可能知道的，他是荷兰人，所以这些函数的名称来自荷兰语中的 *尝试*
    和 *增加* (*probeer* 和 *vrhoog*，分别)，其中 `S` 是信号量变量。仅从它们的名称中，你就可以得到它们将要做什么的线索。让我们用伪代码来看看它们：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'So, `P(S)` will endlessly check whether the semaphore has signaled that the
    resource is available – the semaphore is incremented. As soon as `S` is incremented,
    the loop is stopped, and the semaphore value is decreased for some other code
    to be executed. Based on the increment’s value, we recognize two types of semaphores:
    **binary** and **counting**. The binary semaphore is often mistaken for a **mutual
    exclusion** (**mutex**) mechanism. The logic is the same – for example, whether
    the resource is free to be accessed and modified or not – but the nature of the
    technique is different, and as we explained earlier, nothing is stopping some
    bad concurrent design from ignoring a semaphore. We will get to that in a minute,
    but for now, let’s pay attention to what the semaphore does. Before we begin with
    the code, let’s put a disclaimer that there are a few semaphore interfaces on
    Unix-like OSs. The choice of usage depends on the level of abstraction and the
    standards. For example, not every system has POSIX, or it is not exposed fully.
    As we are going to focus on the C++20 usage, we will use the next examples just
    for reference. The full source code of the next examples can be found at [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`P(S)`会无限期地检查信号量是否已发出资源可用的信号——信号量被增加。一旦`S`被增加，循环就会停止，信号量的值会减少，以便其他代码可以执行。根据增加的值，我们可以识别两种类型的信号量：**二进制**和**计数**。二进制信号量常被误认为是**互斥**（**mutex**）机制。逻辑是相同的——例如，资源是否可以自由访问和修改——但技术的本质是不同的，正如我们之前解释的，没有任何东西阻止一些不良的并发设计忽略信号量。我们将在稍后讨论这个问题，但现在，让我们关注信号量做了什么。在我们开始编写代码之前，让我们声明一下，在类
    Unix 操作系统上存在一些信号量接口。使用的选择取决于抽象级别和标准。例如，并非每个系统都有 POSIX，或者它并没有完全公开。由于我们将专注于 C++20
    的使用，我们将使用以下示例仅作为参考。以下示例的完整源代码可以在[https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207)找到。
- en: 'Let’s take a look at two common semaphore interfaces on Linux. The first one
    is the **unnamed semaphore** – we can present it through the following interface:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 Linux 上的两个常见信号量接口。第一个是**无名信号量**——我们可以通过以下接口来展示它：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `sem` variable is the semaphore, which is initialized and de-initialized
    by `sem_init()` and `sem_destroy()`, respectively. The `P(S)` function is represented
    by `sem_wait()` and the `V(S)` function by `sem_post()`. There are also `sem_trywait()`,
    if you want to report an error when the decrement doesn’t happen immediately,
    and `sem_timedwait()`, which is a blocking call for a time window in which the
    decrement could happen. This seems pretty clear, except for the initialization
    part. You’ve probably noticed the `value` and `pshared` arguments. The first one
    shows the initial value of the semaphore. For example, a binary semaphore could
    be `0` or `1`. The second is more interesting.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`sem`变量是信号量，它分别通过`sem_init()`和`sem_destroy()`进行初始化和销毁。`P(S)`函数由`sem_wait()`表示，而`V(S)`函数由`sem_post()`表示。还有`sem_trywait()`，如果你想在减少不立即发生时报告错误，以及`sem_timedwait()`，它是一个在减少可能发生的特定时间窗口内的阻塞调用。这看起来很清楚，除了初始化部分。你可能已经注意到了`value`和`pshared`参数。第一个显示了信号量的初始值。例如，二进制信号量可以是`0`或`1`。第二个更有趣。'
- en: 'As you might recall, in [*Chapter 2*](B20833_02.xhtml#_idTextAnchor029) we
    discussed memory segments. Imagine that we create the semaphore on the `pshared`
    is used exactly for this purpose. If it’s set to `0`, then the semaphore is local
    for the process, but if it is set to a non-zero value, then it is shared between
    processes. The catch is to create the semaphore on a globally visible region of
    memory, such as shmem, including the filesystem as a shared resource pool. Here
    is an overview of **named semaphores**:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所回忆，在[*第二章*](B20833_02.xhtml#_idTextAnchor029)中，我们讨论了内存段。想象一下，如果我们创建的信号量在`pshared`上被用于这个目的。如果它被设置为`0`，那么信号量是进程本地的，但如果它被设置为非零值，那么它是进程间共享的。关键是创建一个在全局可见内存区域上的信号量，例如共享内存（shmem），包括文件系统作为一个共享资源池。以下是**命名信号量**的概述：
- en: 'The `/dev/shm`. We treat it as a file. For example, the following code will
    create a semaphore with the name `/sem` and `0644` permissions – it will be readable
    and writable only by its owner, but only readable by others, and it will be visible
    on the filesystem until it is later removed through code:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/dev/shm`。我们将其视为文件。例如，以下代码将创建一个名为 `/sem` 且权限为 `0644` 的信号量——它只能由所有者读写，但其他人只能读取，并且它将在文件系统中可见，直到稍后通过代码删除：'
- en: '[PRE13]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `P(S)` and `V(S)` calls remain the same. After we finish, we must close
    the file, and remove it, if we don’t need it anymore:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`P(S)` 和 `V(S)` 调用保持不变。完成之后，我们必须关闭文件，如果不再需要，则删除它：'
- en: '[PRE14]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As mentioned in [*Chapter 1*](B20833_01.xhtml#_idTextAnchor014), you see that
    the POSIX calls follow the same pattern through the `<object>_open`, `<object>_close`,
    `<object>_unlink`, and `<object>_<specific function>` suffixes. This makes their
    usage common for every POSIX object, as you probably already observed earlier
    in the chapter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第 1 章*](B20833_01.xhtml#_idTextAnchor014)所述，您可以看到 POSIX 调用遵循相同的模式，通过 `<object>_open`、`<object>_close`、`<object>_unlink`
    和 `<object>_<specific function>` 后缀。这使得它们的使用对每个 POSIX 对象都是通用的，正如您可能已经在本章早期观察到的那样。
- en: A quick remark is that there are **lower-level semaphores** where the system
    calls are strongly related to the OS types or are based on direct OS signal manipulations.
    Such approaches are complex to implement and maintain because they are specific
    and considered fine-tuning. Feel free to research more about your own system.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 简要说明一下，存在**低级信号量**，其中系统调用与 OS 类型紧密相关或基于直接 OS 信号操作。这种方法的实现和维护比较复杂，因为它们是特定的，被认为是微调。请随意研究您自己的系统。
- en: A C++ semaphores primer
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++ 信号量入门
- en: With this in mind, we’d like to continue leveling up the abstraction, and so
    we’ll discuss the C++ semaphore objects. This is a new feature in C++20 and it’s
    useful when you want to make the code more system-generic. Let’s check it out
    through the `atomic<uint16_t> shared_resource`. As mentioned at the beginning
    of this section, the semaphores help in task synchronization, but we need a data
    race guard. The `atomic` type is making sure we follow the C++ memory model and
    the compiler will keep the sequence of CPU instructions as per `std::memory_oder`.
    You can revisit [*Chapter 6*](B20833_06.xhtml#_idTextAnchor086) for a data race
    explanation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个想法，我们希望继续提升抽象级别，因此我们将讨论 C++ 的信号量对象。这是 C++20 中的一个新特性，当您想要使代码更加系统通用时非常有用。让我们通过
    `atomic<uint16_t> shared_resource` 来查看它。如本节开头所述，信号量有助于任务同步，但我们需要一个数据竞争保护。`atomic`
    类型确保我们遵循 C++ 内存模型，编译器将按照 `std::memory_order` 保持 CPU 指令的顺序。您可以回顾[*第 6 章*](B20833_06.xhtml#_idTextAnchor086)以了解数据竞争的解释。
- en: 'We will continue by creating two global `binary_semaphore` objects in order
    to synchronize the access appropriately (like a ping-pong). The `binary_semaphore`
    object is an alias of the `counting_semaphore` object with a maximum value of
    `1`. We will need a program-ending rule so we will define a limit of iterations.
    We will ask the compiler to make it a constant, if possible, through the `constexpr`
    keyword. Last, but not least, we will create two threads that will act as a producer
    (incrementing the shared resource) and a consumer (decrementing it). Let’s look
    at the code example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续创建两个全局 `binary_semaphore` 对象，以适当地同步访问（如乒乓球）。`binary_semaphore` 对象是 `counting_semaphore`
    对象的别名，其最大值为 `1`。我们需要一个程序结束规则，因此我们将定义迭代次数的限制。我们将要求编译器通过 `constexpr` 关键字将其定义为常量。最后，但同样重要的是，我们将创建两个线程，它们将作为生产者（增加共享资源）和消费者（减少它）。让我们看看代码示例：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The semaphores are constructed and initialized. We proceed with the threads.
    The `release()` function increments an internal counter, which signals the others
    (marker `{2}` in the following code, similar to `sem_post()`). We use `osyncstream(cout)`
    to build a non-interleaved output. Here’s the producer thread:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 信号量被构建和初始化。我们继续处理线程。`release()` 函数增加一个内部计数器，这会向其他人发出信号（以下代码中的 `{2}` 标记，类似于 `sem_post()`）。我们使用
    `osyncstream(cout)` 来构建非交错输出。以下是生产者线程：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'And here’s the consumer thread:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是消费者线程：
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As we do this iteratively, we see this output multiple times, depending on
    `limit`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在迭代过程中，我们根据 `limit` 会看到多次此输出：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Going back to the code’s logic, we must emphasize that the C++ semaphores are
    considered lightweight and allow multiple concurrent accesses to the shared resource.
    But be careful: the provided code uses `acquire()` (marker `{1}`, similar to `sem_wait()`),
    which is a blocking call – for example, your task will be blocked until the semaphore
    is released. You could use `try_acquire()` for non-blocking purposes. We rely
    on both semaphores to create a predictable sequence of operations. We start the
    process (for example, the main thread) by releasing the producer semaphore, so
    the producer would be signaled to start first.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 回到代码的逻辑，我们必须强调，C++ 信号量被认为是轻量级的，并允许对共享资源进行多个并发访问。但请注意：提供的代码使用了 `acquire()`（标记
    `{1}`，类似于 `sem_wait()`），这是一个阻塞调用——例如，你的任务将会被阻塞，直到信号量被释放。你可以使用 `try_acquire()`
    来实现非阻塞。我们依赖于这两个信号量来创建可预测的操作序列。我们通过释放生产者信号量（例如，主线程）来启动这个过程，这样生产者就会收到信号，首先开始工作。
- en: The code could be changed to use POSIX semaphores, just by removing the C++
    primitives and adding the aforementioned system calls to the same places in the
    code. In addition, we encourage you to achieve the same effect with one semaphore.
    Think about using a helper variable or a condition variable. Keep in mind that
    such an action makes the synchronization heterogenous and on a large scale, which
    is hard to manage.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可以通过移除 C++ 原语并添加上述系统调用到代码中的相同位置来修改，以使用 POSIX 信号量。此外，我们鼓励你使用一个信号量实现相同的效果。考虑使用辅助变量或条件变量。请记住，这样的操作会使同步变得异构，并且在大规模上难以管理。
- en: The current code is obviously not able to synchronize multiple processes, unlike
    the **named semaphore**, so it’s not really an alternative there. We also could
    want to be stricter on the shared resource access – for example, to have a single
    moment of access in a concurrent environment. Then, we’d need the help of the
    mutex, as described in the next section.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的代码显然无法同步多个进程，与**命名信号量**不同，因此它实际上不是那里的替代品。我们还可以希望对共享资源的访问更加严格——例如，在并发环境中只有一个访问时刻。那么，我们就需要下一节中描述的互斥锁的帮助。
- en: Mutual exclusion (mutex)
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互斥（mutex）
- en: The mutex is a mechanism that comes from the operations of the OS. A shared
    resource is also known as a **critical section** and it needs to be accessed without
    the risk of race conditions. A mechanism that allows only a single task to modify
    the critical section at a given moment, excluding every other task’s request to
    do the same, is called a **mutual exclusion** or a **mutex**. The mutexes are
    implemented internally by the OS and remain hidden from the user space. They provide
    a *lock-unlock* access functionality and are considered stricter than the semaphores,
    although they are controlled as binary semaphores.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁是一种来自操作系统操作的机制。共享资源也被称为**临界区**，需要无风险地访问，以避免竞态条件。一种允许在给定时刻只允许一个任务修改临界区，并排除其他任务相同请求的机制，称为**互斥**或**互斥锁**。互斥锁由操作系统内部实现，对用户空间是隐藏的。它们提供了一种**锁定-解锁**的访问功能，并且被认为比信号量更严格，尽管它们被作为二进制信号量来控制。
- en: Important note
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The calling thread locks the resource and is obliged to unlock it. There’s no
    guarantee that a higher entity in the system’s hierarchy would be able to override
    the lock and unblock the parallel functionality. It is advisable for each lock
    to be released as fast as possible to allow the system threads to scale up and
    save idle time.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 调用线程锁定资源，并被迫解锁它。没有保证系统中的更高实体能够覆盖锁定并解除并行功能的阻塞。建议尽快释放每个锁定，以允许系统线程扩展并节省空闲时间。
- en: 'A POSIX mutex is created and used in much the same way as the unnamed semaphore:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: POSIX 互斥锁的创建和使用与未命名的信号量几乎相同：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The pattern of the function names is followed again, so let’s focus on `pthread_mutex_lock()`
    and `pthread_mutex_unlock()`. We use them to lock and unlock a critical section
    for manipulation, but they cannot help us in the sequence of events. Locking the
    resource only guarantees there are no race conditions. The correct sequencing
    of events, if required, is designed by the system programmer. Bad sequencing might
    lead to **deadlocks** and **livelocks**:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 函数名的模式再次被遵循，因此让我们关注 `pthread_mutex_lock()` 和 `pthread_mutex_unlock()`。我们使用它们来锁定和解锁一个临界区以进行操作，但它们不能帮助我们处理事件序列。锁定资源只能保证没有竞态条件。如果需要，正确的事件序列是由系统程序员设计的。错误的事件序列可能会导致**死锁**和**活锁**：
- en: '**Deadlock**: One or more threads are blocked and cannot change their state
    because they are waiting for an event that never occurs. A common bug is two (or
    more) threads being looped together – for example, one is waiting for a shared
    resource A while holding a lock on shared resource B, and a second thread holds
    a lock on A but will unlock it when B is unlocked. Both will remain blocked because
    neither will be the first to *give up on the resource*. Such a behavior could
    be caused even without mutexes. Another bug is to lock a mutex twice, which, in
    the case of Linux, is detectable by the OS. There are deadlock resolution algorithms,
    where locking a number of mutexes will not succeed at first because of the deadlock,
    but will be successful with a guarantee after a finite number of attempts.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**死锁**：一个或多个线程被阻塞并且无法改变它们的状态，因为它们正在等待一个永远不会发生的事件。一个常见的错误是两个（或更多）线程相互循环——例如，一个线程正在等待共享资源A，同时持有共享资源B的锁，而第二个线程持有A的锁，但会在B解锁时释放它。两者都将保持阻塞，因为它们都不会是第一个**放弃资源**的。即使没有互斥锁，这种行为也可能发生。另一个错误是两次锁定互斥锁，在Linux的情况下，这可以通过操作系统检测到。存在死锁解决算法，其中锁定多个互斥锁可能由于死锁而最初无法成功，但在有限次数的尝试后可以保证成功。'
- en: '[PRE20]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Livelock**: The threads are not blocked, but then again, they cannot change
    their state because they require the shared resource to continue forward. A good
    real-world example is two people meeting face to face at an entrance. Both will
    move aside out of politeness, but they will most probably move in the same direction
    as their counterpart. If that happens and they continue to do that all the time,
    then nobody will be blocked, but at the same time, they cannot proceed forward.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活锁**：线程没有被阻塞，但同样，它们无法改变它们的状态，因为它们需要共享资源来继续前进。一个很好的现实世界例子是两个人面对面站在入口处。双方都会出于礼貌让开，但他们很可能会朝着对方的方向移动。如果发生这种情况，并且他们一直这样做，那么没有人会被阻塞，但与此同时，他们无法继续前进。'
- en: Both classes of bugs are common and could be reproduced with semaphores, as
    they are blocking too, and rarely happen on small-scale systems, where they are
    easy to debug. It is trivial to follow the code’s logic with just a few threads,
    and the processes are manageable. Large-scale systems with thousands of threads
    execute an enormous number of locks at the same time. The bug reproductions are
    usually a matter of bad timing and ambiguous task sequences. Therefore, they are
    hard to catch and debug, and we advise you to be careful when you lock a critical
    section.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这两类错误都很常见，可以用信号量复制，因为它们也是阻塞的，并且很少出现在小规模系统中，那里它们很容易调试。只有几个线程时，代码的逻辑很容易跟踪，并且进程是可管理的。具有数千个线程的大规模系统同时执行了大量的锁。错误复制通常是一个坏时机和模糊的任务序列的问题。因此，它们很难捕捉和调试，我们建议你在锁定关键部分时要小心。
- en: 'C++ provides a flexible lock interface. It is constantly upgraded and we now
    have several behaviors to choose from. Let’s do a parallel increment of a variable.
    We use the `increment()` thread procedure for the sake of clarity, similar to
    the previous code, but we replace the semaphores with one mutex. And you’ve probably
    guessed that the code will be guarded against race conditions, but the sequence
    of the thread executions is undefined. We could arrange this sequence through
    an additional flag, condition variable, or just a simple sleep, but let’s keep
    it this way for the experiment. The updated code snippet is the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: C++提供了一个灵活的锁接口。它不断升级，我们现在有几种行为可供选择。让我们对变量进行并行增加。为了清晰起见，我们使用`increment()`线程过程，类似于之前的代码，但我们用互斥锁替换了信号量。你可能已经猜到了，代码将防止竞争条件，但线程执行的顺序是未定义的。我们可以通过额外的标志、条件变量或简单的睡眠来安排这个顺序，但让我们保持这种方式进行实验。更新的代码片段如下：
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We defined our shared resource and the mutex. Let’s see how the increment happens:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了我们的共享资源和互斥锁。让我们看看增加是如何发生的：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The observed output is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到的输出如下：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It’s obvious that incrementing the variable without multithreading will be much
    faster than this result. You could even try running it until `UINT_MAX`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，在不使用多线程的情况下增加变量会比这个结果快得多。你甚至可以尝试运行它直到`UINT_MAX`。
- en: So, the preceding code creates a globally visible mutex and uses a `unique_lock`
    object (marker `{1}`) to wrap it. It is similar to `pthread_mutex_init()` – it
    allows us to defer locking, do a recursive lock, transfer lock ownership, and
    carry out attempts to unlock it within certain time constraints. The lock is in
    effect for the scope block it is in – in the current example, it is the thread
    procedures’ scope. The lock takes ownership of the mutex. When it reaches the
    end of the scope, the lock is destroyed and the mutex is released. You should
    already know this approach as `scoped_lock` object to lock multiple mutexes while
    avoiding a deadlock by its design.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前面的代码创建了一个全局可见的互斥锁，并使用一个`unique_lock`对象（标记 `{1}`）来包装它。这类似于`pthread_mutex_init()`，它允许我们延迟锁定，执行递归锁定，转移锁定所有权，并在特定时间约束内执行解锁尝试。锁在其作用域块内有效——在当前示例中，它是线程过程的范围。锁拥有互斥锁的所有权。当它达到作用域的末尾时，锁被销毁，互斥锁被释放。你应该已经知道这种做法作为`scoped_lock`对象来锁定多个互斥锁，同时通过其设计避免死锁。
- en: 'There is something else you should consider when using a mutex. The mutex reaches
    the kernel level. The task states are affected by it directly and multiple locks
    will cause multiple **context switches**. As you recall from earlier, we will
    probably lose time in rescheduling. This means that the OS needs to jump from
    one memory region in RAM to another just to load another task’s instructions.
    You must consider what’s beneficial for you: many locks with small scopes leading
    to many switches, or a few locks with bigger scope blocks holding resources for
    longer timespans.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用互斥锁时，你还需要考虑其他一些事情。互斥锁达到内核级别。任务状态直接受到影响，多个锁将导致多个**上下文切换**。正如你之前回忆的那样，我们可能会在重新调度中浪费时间。这意味着操作系统需要从RAM中的一个内存区域跳转到另一个内存区域，只是为了加载另一个任务的指令。你必须考虑对你有利的事情：许多具有小范围的锁导致许多切换，或者少数具有较大作用域块的锁在更长的时间段内保持资源。
- en: 'At the end of the day, our goal was just to instruct the CPU about an atomic
    region. If you remember, we used an `atomic` template in the semaphore example.
    We could update our code with an `atomic` variable and remove the mutex with the
    lock:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们的目标只是向CPU指示一个原子区域。如果你还记得，我们在信号量示例中使用了`atomic`模板。我们可以用`atomic`变量更新我们的代码，并移除互斥锁的锁定：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The result is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, there is a significant time improvement just by the removal
    of the mutex. For the sake of argument, you could add the semaphores back and
    you will still observe a faster execution than the mutex. We advise you to look
    at the code’s disassembly for the three cases – just with the `atomic` variable,
    with the mutex, and with the semaphore. You will observe that an `atomic` object
    is very simple instruction-wise and is executed at a user level. As it is truly
    atomic, the CPU (or its core) will be kept busy during the increment. Bear in
    mind that any technique for resolving data races will inherently carry a performance
    cost. The best performance can be achieved by minimizing the places and their
    scope where synchronization primitives are needed.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，仅仅通过移除互斥锁就能显著提高时间效率。为了辩论的目的，你可以重新添加信号量，你仍然会观察到比互斥锁更快的执行速度。我们建议你查看代码的汇编代码，针对三种情况——只有`atomic`变量、有互斥锁和有信号量。你会发现`atomic`对象在指令层面上非常简单，并且在用户级别执行。由于它是真正的原子操作，CPU（或其核心）将在增加时保持忙碌。记住，任何解决数据竞争的技术都会固有地带来性能成本。最佳性能可以通过最小化需要同步原语的位置及其作用域来实现。
- en: Important note
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: C++20 provides exciting features for concurrent execution, such as **jthread**,
    **coroutines**, **updated atomic types**, and **cooperative cancelation**. Except
    for the first one, we will look at the others later in the book. In addition to
    these, Linux has system calls for using the IPC entities, which are built for
    the purposes of multiprocessing data exchange. That said, we advise you to think
    about using an already existing mechanism for asynchronous work before you attempt
    combinations of mutexes, semaphores, flags, and conditional variables. All those
    C++ and Linux features are designed to scale up in a stable manner and save you
    time for solution design.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: C++20为并发执行提供了令人兴奋的特性，例如**jthread**、**协程**、**更新的原子类型**和**合作取消**。除了第一个之外，我们将在本书的后面部分查看其他特性。除了这些之外，Linux还有用于使用IPC实体的系统调用，这些实体是为多进程数据交换而构建的。话虽如此，我们在尝试组合互斥锁、信号量、标志和条件变量之前，建议你考虑使用现有的异步工作机制。所有这些C++和Linux特性都是为了以稳定的方式扩展并节省你设计解决方案的时间。
- en: 'Everything we did until now is just to make sure we have atomic access to a
    critical section. Atomics, mutexes, and semaphores will give you this – a way
    to instruct the CPU about the scope of instructions. But two questions remain:
    Could we do it faster and lighter? Does being atomic mean we keep the order of
    the instructions? The answer to the first question is *Probably*. To the second
    one, the answer is *No*! Now we have the incentive to move and dive into the C++
    **memory model** and **memory order**. If this interests you, we invite you to
    jump to [*Chapter 9*](B20833_09.xhtml#_idTextAnchor129), where we discuss more
    interesting concurrent tasks. Now, we will continue the topic of shared resources
    through the **shmem** **IPC** mechanism.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止所做的一切都是为了确保我们能够原子性地访问临界区。原子操作、互斥锁和信号量会给你这个——一种指示CPU指令作用域的方法。但还有两个问题：我们能做得更快、更轻量吗？原子操作意味着我们保持指令的顺序吗？第一个问题的答案是**可能**。第二个问题的答案是**不**！现在我们有动力去深入了解C++的**内存模型**和**内存顺序**。如果你对此感兴趣，我们邀请你跳转到[*第9章*](B20833_09.xhtml#_idTextAnchor129)，在那里我们讨论更多有趣的并发任务。现在，我们将继续通过**shmem**
    **IPC**机制讨论共享资源的话题。
- en: Using shared memory
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用共享内存
- en: As with pipes, the MQ data is lost once consumed. Duplex message data copying
    increases user space-kernel space calls, therefore an overhead is to be expected.
    The **shmem** mechanism is fast. As you learned in the previous chapter and the
    previous section, the synchronization of the data access is an issue that must
    be resolved by the system programmer, especially when it comes to race conditions.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与管道一样，一旦消耗了MQ数据，数据就会丢失。双工消息数据复制会增加用户空间和内核空间之间的调用，因此预期会有开销。**shmem**机制是快速的。正如你在上一章和上一节中学到的，数据访问的同步是一个必须由系统程序员解决的问题，尤其是在出现竞态条件时。
- en: An important remark is that the term *shared memory* is vague in itself. Is
    it a global variable that two threads could access simultaneously? Or is it a
    shared region of RAM, which multiple CPU cores use as a common ground to transfer
    data between each other? Is it a file in the filesystem that many processes modify?
    Great questions – thanks for asking! In general, all of those are kinds of shared
    resources, but when we speak about the term *memory*, we should really think about
    a region in the **main memory** that is visible to many processes and where multiple
    tasks could use it to exchange and modify data. Not only tasks but also different
    processor cores and core complexes (such as ARM) if they have access to the same
    predefined memory region. Such techniques require a specific configuration file
    – a memory map, which strictly depends on the processor and is implementation-specific.
    It provides the opportunity to use, for example, **tightly coupled memory** (**TCM**)
    to speed up, even more, the frequently used portions of code and data, or to use
    a portion of the RAM as shmem for data exchange between the cores. As this is
    too dependent on the processor, we are not going to continue discussing it. Instead,
    we will move on to discuss Linux’s **shmem** **IPC** mechanism.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明：术语**共享内存**本身是模糊的。它是两个线程可以同时访问的全局变量吗？或者是一个多个CPU核心用作在彼此之间传输数据的共同基础的共享RAM区域？或者是一个文件系统中的文件，许多进程对其进行修改？很好的问题——感谢提问！一般来说，所有这些都是共享资源的一种，但当我们谈论术语**内存**时，我们应该真正考虑一个在**主内存**中可见的区域，其中多个任务可以使用它来交换和修改数据。不仅限于任务，还包括不同的处理器核心和核心复杂（如ARM），如果它们可以访问相同的预定义内存区域。这些技术需要特定的配置文件——一个内存映射，它严格依赖于处理器，并且具有特定的实现。它提供了使用，例如，**紧密耦合内存**（**TCM**）来加速频繁使用的代码和数据部分，或者将RAM的一部分用作核心之间的数据交换的shmem的机会。由于这太依赖于处理器，我们不会继续讨论它。相反，我们将继续讨论Linux的**shmem**
    **IPC**机制。
- en: Important note
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: The processes allocate a portion of their **virtual memory** as a shared segment.
    Traditionally, the OS forbids processes to access each other’s memory regions,
    but the shmem is a mechanism for the processes to ask for the removal of this
    restriction in the boundaries of the shmem. We use it to ingest and modify large
    portions of data quickly through simple read and write operations, or the already
    provided functions in POSIX. Such functionality is not possible through MQs or
    pipes.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 进程将它们的部分**虚拟内存**分配为一个共享段。传统上，操作系统禁止进程访问彼此的内存区域，但shmem是一种机制，允许进程在shmem的边界内请求移除这种限制。我们使用它通过简单的读写操作或POSIX中已提供的函数快速摄取和修改大量数据，而通过MQ或管道是无法实现这种功能的。
- en: 'In contrast to MQs, there’s no serialization or synchronization here. The system
    programmer is responsible for managing the IPC’s data transfer policy (again).
    But with the shared region being in the RAM, we have fewer context switches, thus
    we reduce the overhead. We can visualize it through the following figure:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 与MQs相比，这里没有序列化或同步。系统程序员负责管理IPC的数据传输策略（再次）。但是，由于共享区域位于RAM中，我们减少了上下文切换，从而降低了开销。我们可以通过以下图来可视化它：
- en: '![Figure 7.3 – Shmem presentation through the process’s memory segments](img/Figure_7.3_B20833.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – 通过进程的内存段展示Shmem](img/Figure_7.3_B20833.jpg)'
- en: Figure 7.3 – Shmem presentation through the process’s memory segments
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 通过进程的内存段展示Shmem
- en: The shmem region is usually depicted between the two processes’ address spaces.
    The idea is to emphasize how that space is truly shared between the processes.
    In reality, this is implementation-specific and we leave it to the kernel – what
    we care about is the map to the shmem segments itself. It allows both processes
    to observe the same contents simultaneously. Let’s get to it then.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: shmem区域通常被描绘在两个进程的地址空间之间。目的是强调这个空间在进程之间是如何真正共享的。实际上，这取决于具体实现，我们将其留给内核 – 我们关心的是映射到shmem段本身。它允许两个进程同时观察相同的内容。那么，让我们开始吧。
- en: Learning about mmap() and shm_open()
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解mmap()和shm_open()
- en: The initial system call for the creation of a shmem mapping is `shmget()`. This
    is applicable to any Unix-based OS, but for POSIX-compliant systems, there are
    more comfortable approaches. If we imagine that we do a mapping between a process’s
    address space and a file, then the `mmap()` function will pretty much get the
    job done. It is POSIX-compliant and executes the read operation on demand. You
    can simply use `mmap()` to point to a regular file, but the data will remain there
    after the processes have finished their work. Do you remember the pipes from [*Chapter
    3*](B20833_03.xhtml#_idTextAnchor047)? It’s a similar case here. There are `mmap()`
    system call with `fork()`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 创建shmem映射的初始系统调用是`shmget()`。这适用于任何基于Unix的操作系统，但对于符合POSIX标准的系统，有更舒适的途径。如果我们想象我们在进程的地址空间和文件之间进行映射，那么`mmap()`函数将基本上完成这项工作。它是符合POSIX标准的，并且按需执行读取操作。你可以简单地使用`mmap()`来指向一个常规文件，但数据将在进程完成工作后仍然保留在那里。你还记得[第3章](B20833_03.xhtml#_idTextAnchor047)中的管道吗？这里的情况类似。有与`fork()`一起使用的`mmap()`系统调用。
- en: 'If you have independent processes, then the only way for them to know how to
    address the shared region is through its pathname. The `shm_open()` function will
    provide you a file with a name, in the same way that `mq_open()` did – you could
    observe it in `/dev/shm`. It would require `librt` as well. Knowing this, you
    intuitively get that we limit the I/O overhead and the context switches because
    of the filesystem operations, as this file is in the RAM. Last but not least,
    this kind of shared memory is flexible in size and could be enlarged to gigabytes
    in size when needed. Its limitations are dependent on the system. The full version
    of the following example can be found at https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有多独立进程，那么它们知道如何访问共享区域的唯一方式是通过其路径名。`shm_open()`函数将为你提供一个带有名称的文件，就像`mq_open()`所做的那样
    – 你可以在`/dev/shm`中观察到它。这同样需要`librt`库。了解这一点后，你会直觉地认为我们通过文件系统操作限制了I/O开销和上下文切换，因为该文件位于RAM中。最后但同样重要的是，这种共享内存的大小是灵活的，在需要时可以扩大到几GB。其限制取决于系统。以下示例的完整版本可以在https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207找到：
- en: '[PRE26]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This example is very specific as we intentionally used processes instead of
    threads. This allows us to demonstrate the usage of `shm_open()` (marker `{1})`
    as the different processes use the shmem’s pathname (which is known at compile
    time) to access it. Let’s continue with reading the data:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子非常具体，因为我们故意使用了进程而不是线程。这使我们能够展示`shm_open()`（标记{1}）的使用，因为不同的进程使用shmem的路径名（在编译时已知）来访问它。让我们继续读取数据：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We could use mutexes, but currently, we only need one process to signal to
    the other that its work is done, so we apply semaphores (markers `{3}` and `{7}`
    in the previous code block) as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用互斥锁，但当前我们只需要一个进程向另一个进程发出信号，表明其工作已完成，所以我们应用了信号量（在之前的代码块中标记为{3}和{7}）如下：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To make the memory region shared, we use the `mmap()` function with the `MAP_SHARED`
    option, and we mark the reader and the writer credentials accordingly through
    the following page settings: `PROT_READ` and `PROT_WRITE` (markers `{2}` and `{6}`).
    We also use the `ftruncate()` function to set the region’s size (marker `{5}`).
    In the given example, the information is written in the shmem, and someone has
    to read it. It’s a kind of a single-shot producer-consumer because after the writing
    is done, the writer gives the reader time (marker `{8}`), and then the shmem is
    set to zero (marker `{9}`) and deleted (marker `{10}`). Now, let’s proceed with
    the parent’s code - the producer of the data:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要使内存区域共享，我们使用带有`MAP_SHARED`选项的`mmap()`函数，并通过以下页面设置相应地标记读取器和写入器凭据：`PROT_READ`和`PROT_WRITE`（标记为`{2}`和`{6}`）。我们还使用`ftruncate()`函数设置区域的大小（标记为`{5}`）。在给定的示例中，信息被写入shmem，而有人必须读取它。这是一种单次生产者-消费者模式，因为写入完成后，写入者会给读取者时间（标记为`{8}`），然后shmem被设置为零（标记为`{9}`）并删除（标记为`{10}`）。现在，让我们继续讨论父进程的代码——数据的生产者：
- en: '[PRE29]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Again, the shmem region is mapped:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，shmem区域被映射：
- en: '[PRE30]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As done previously, we use the `sem_open()` named semaphore (marker `{11}`)
    to allow both processes to synchronize. We wouldn’t be able to do so through the
    semaphores we discussed earlier in the chapter, as they don’t have a name and
    are known only in the context of a single process. At the end, we remove the semaphore
    from the filesystem as well (marker `{12}`), as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们使用`sem_open()`命名的信号量（标记为`{11}`）允许两个进程进行同步。我们无法通过本章前面讨论的信号量来完成，因为它们没有名称，只在单个进程的上下文中知名。最后，我们还将信号量从文件系统中删除（标记为`{12}`），如下所示：
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The program’s result is as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的结果如下：
- en: '[PRE32]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Shmem is an interesting topic, which we will return to in [*Chapter 9*](B20833_09.xhtml#_idTextAnchor129).
    One reason for being so is that C++ allows us to wrap the POSIX code appropriately
    and make the code safer. Similar to [*Chapter 3*](B20833_03.xhtml#_idTextAnchor047),
    mixing system calls with C++ code should be well thought out. But it’s worthwhile
    to visit the `memory_order` use cases as well. If **jthreads** or **coroutines**
    are not applicable to your use cases, then the currently discussed synchronization
    mechanisms, together with the **smart pointers**, give you the flexibility to
    design the best possible solution for your system. But before we get there, we
    need to talk about something else first. Let’s proceed to the communication between
    computer systems.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Shmem是一个有趣的话题，我们将在[*第9章*](B20833_09.xhtml#_idTextAnchor129)中再次回到这个话题。其中一个原因是C++允许我们适当地封装POSIX代码，并使代码更安全。类似于[*第3章*](B20833_03.xhtml#_idTextAnchor047)，在C++代码中混合系统调用应该经过深思熟虑。但同样值得探讨`memory_order`的使用案例。如果**jthreads**或**coroutines**不适用于您的用例，那么目前讨论的同步机制，连同**智能指针**，为您提供了设计最适合您系统的最佳解决方案的灵活性。但在我们达到那里之前，我们首先需要讨论其他事情。让我们继续讨论计算机系统之间的通信。
- en: Communicating through the network with sockets
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过套接字进行网络通信
- en: If the pipes, MQs, and the shmem could together overcome their problems, then
    why do we need sockets? This is a great question with a simple answer – we need
    them to communicate between different systems on the network. With this, we have
    our full set of instruments to exchange data. Before we understand sockets, we
    need to get a quick overview of network communication. No matter the network type
    or its medium, we must follow the design established by the **Open Systems Interconnection**
    (**OSI**) **basic reference model**. Nowadays, almost all OSs support the **Internet
    Protocol** (**IP**) family. The easiest way to set up communications with other
    computer systems is by using these protocols. They follow layering, as described
    in the **ISO-OSI** model, and now we are going to take a quick look at that.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果管道、MQ和shmem能够共同克服它们的问题，那么为什么我们还需要套接字？这是一个简单答案的伟大问题——我们需要它们在网络上不同系统之间进行通信。有了这个，我们就拥有了交换数据的完整工具集。在我们理解套接字之前，我们需要快速了解网络通信。无论网络类型或其介质如何，我们都必须遵循由**开放系统互连**（**OSI**）**基本参考模型**确立的设计。如今，几乎所有的操作系统都支持**互联网协议**（**IP**）家族。与其他计算机系统建立通信的最简单方法就是使用这些协议。它们遵循分层，正如**ISO-OSI**模型所描述的，现在我们将快速看一下这一点。
- en: Overview of the OSI model
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OSI模型的概述
- en: 'The OSI model is typically represented as shown in the next table. System programmers
    usually require it to analyze where their communication is disturbed. Although
    sockets are intended to execute the network data transfer, they are also applicable
    for a local IPC. One reason is that the communication layers, especially on large
    systems, are separate utilities or abstraction layers over the applications. As
    we want to make them environmentally agnostic, meaning we don’t care whether the
    data is transferred locally or over the internet, then the sockets fit perfectly.
    That said, we must be aware of the channel we use and where our data is transported.
    Let’s take a look:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: OSI模型通常表示如下表所示。系统程序员通常需要它来分析他们的通信在哪里受到干扰。尽管套接字旨在执行网络数据传输，但它们也适用于本地进程间通信（IPC）。一个原因是通信层，尤其是在大型系统中，是独立实用程序或抽象层，位于应用程序之上。因为我们希望使它们与环境无关，这意味着我们不在乎数据是在本地传输还是通过互联网传输，那么套接字就非常适合。话虽如此，我们必须意识到我们使用的通道以及我们的数据是如何传输的。让我们看看：
- en: '![Figure 7.4 – The OSI model represented as a table](img/Figure_7.4_B20833.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4 – 以表格形式表示的OSI模型](img/Figure_7.4_B20833.jpg)'
- en: Figure 7.4 – The OSI model represented as a table
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 以表格形式表示的OSI模型
- en: Global network communication, especially the internet, is a broad and complex
    topic, which we cannot grasp in a single section of the book. But it’s worthwhile
    to think about your system – what kind of hardware for network communication it
    has; maybe you should consider checking out the *Physical* and *Data Link* layers.
    A simple exercise is to configure your home network – connected devices, routers,
    and so on – yourself. Could the system be safely and securely addressed by the
    outside (if needed)? Then check the *Network*, *Presentation*, and *Application*
    layers. Try out some **port forwarding** and create an application with data exchange
    encryption. Could the software scale fast enough, with the current bandwidth and
    speed? Let’s see what the *Session* and *Transport* layers have to offer – we
    will look into them in the next paragraph. Is it robust and does it remain available
    if attacked? Then revisit all the layers. Of course, these are simple and one-sided
    observations, but they allow you to double-check your requirements.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 全球网络通信，特别是互联网，是一个广泛且复杂的话题，我们无法在本书的单个章节中掌握它。但思考你的系统是有价值的——它有什么样的网络通信硬件；也许你应该考虑检查*物理*和*数据链路*层。一个简单的练习是配置你自己的家庭网络——连接的设备、路由器等等。系统是否可以安全且安全地被外部（如果需要）访问？然后检查*网络*、*表示*和*应用*层。尝试一些**端口转发**并创建一个具有数据交换加密的应用程序。软件是否能够足够快地扩展，以适应当前的带宽和速度？让我们看看*会话*和*传输*层能提供什么——我们将在下一段中探讨它们。它是否健壮，在受到攻击时是否仍然可用？然后重新审视所有层。当然，这些都是简单且单方面的观察，但它们允许你双重检查你的需求。
- en: So, if we ignore the role of the hardware and just focus on establishing a connection,
    we could get back to the sockets and the respective *Session* layer. You’ve probably
    noticed that some websites log you out automatically after some time. Ever wondered
    why? Well, the **session** is an established two-way link for information exchange
    between devices or ends. It’s highly recommended to apply time limits and requirements
    for a session to be destroyed. The opened connection means not only an opened
    channel for sniffing by attackers but also a used resource on the server side.
    This requires computational power, which could be redirected elsewhere. The server
    usually holds the current state and the session history, so we note this kind
    of communication as *stateful* – at least one of the devices keeps the state.
    But if we manage to handle requests without the need to know and keep previous
    data, we could proceed with *stateless* communication. Still, we require the session
    to build a connection-oriented data exchange. A known protocol for the job is
    found in the *Transport* layer – the **Transmission Control Protocol** (**TCP**).
    If we don’t want to establish a two-way information transfer channel but just
    want to implement a broadcast application, then we could proceed with the connectionless
    communication, provided through the **User Datagram Protocol** (**UDP**). Let’s
    check them out in the following sections.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们忽略硬件的作用，只关注建立连接，我们就可以回到套接字和相应的**会话**层。你可能已经注意到，一些网站会在一段时间后自动注销你。你有没有想过为什么会这样？好吧，**会话**是在设备或端点之间建立的信息交换的双向链接。强烈建议为会话的销毁应用时间限制和需求。打开的连接不仅意味着攻击者可以嗅探的开放通道，而且意味着服务器端使用的一种资源。这需要计算能力，而这可能被重新分配到其他地方。服务器通常保留当前状态和会话历史，因此我们将此类通信标记为**有状态的**——至少一个设备保持状态。但如果我们能够处理请求而无需知道并保留以前的数据，我们就可以进行**无状态的**通信。然而，我们仍然需要会话来建立面向连接的数据交换。为此，在**传输**层找到了一个已知的协议——**传输控制协议**（**TCP**）。如果我们不想建立双向信息传输通道，而只想实现广播应用程序，那么我们可以通过**用户数据报协议**（**UDP**）提供的无连接通信来进行。让我们在接下来的章节中检查它们。
- en: Getting familiar with networking through UDP
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过UDP熟悉网络
- en: 'As we said, this protocol could realize connectionless communication, although
    this doesn’t mean there’s no connection between the endpoints. It means that they
    don’t need to be constantly in connection to maintain the data transfer and interpret
    it on their ends. In other words, losing some packets (leading to not hearing
    someone well on the call while in an online meeting, for example) is probably
    not going to be crucial for the system’s behavior itself. It might be crucial
    to you, but let’s be honest, we bet you require the high speed more, and it comes
    with a cost. Network applications such as the **Domain Name System** (**DNS**),
    the **Dynamic Host Configuration Protocol** (**DHCP**), audio-video streaming
    platforms, and others use UDP. Discrepancies and loss of packets are usually handled
    by data retransmission, but this is realized on the *Application* layer and depends
    on the programmer’s implementation. Schematically, the system calls for establishing
    such a connection are as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说，这个协议可以实现无连接通信，但这并不意味着端点之间没有连接。这意味着它们不需要持续连接来维护数据传输并在它们自己的端进行解释。换句话说，丢失一些数据包（例如，在在线会议中通话时听不到某人，可能）对于系统的行为本身可能不是至关重要的。这可能对你来说很重要，但让我们说实话，我们打赌你更需要高速，而这是有代价的。像**域名系统**（**DNS**）、**动态主机配置协议**（**DHCP**）、音视频流平台等网络应用程序都使用UDP。差异和数据包丢失通常通过数据重传来处理，但这是在**应用**层实现的，并取决于程序员的实现。从示意图上看，建立此类连接的系统调用如下：
- en: '![Figure 7.5 – UDP system call realization](img/Figure_7.5_B20833.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5 – UDP系统调用实现](img/Figure_7.5_B20833.jpg)'
- en: Figure 7.5 – UDP system call realization
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – UDP系统调用实现
- en: 'As you can see, it is truly simple – applications on both (or more) sides of
    the communication must only follow that sequence. The protocol doesn’t oblige
    you with the message order or the transfer quality, it’s just fast. Let’s see
    the following example, requesting a die roll from a socket *N* number of times.
    The full version of the code is found at [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这确实很简单——通信双方（或更多）的应用程序只需遵循该顺序即可。该协议并不强制您遵守消息顺序或传输质量，它只是快速。让我们看看以下示例，请求从套接字进行
    *N* 次骰子投掷。代码的完整版本可以在 [https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207](https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207)
    找到：
- en: '[PRE33]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As you can see, the communication configuration is fairly easy – one side has
    to bind to an address in order to be aware of where to receive data from (marker
    `{3}`), whereas the other only writes data directly to the socket. The socket
    configuration is described at marker `{1}`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，通信配置相当简单——一方必须绑定到一个地址，以便知道从哪里接收数据（标记 `{3}`），而另一方只需直接将数据写入套接字。套接字配置在标记 `{1}`
    中描述：
- en: '[PRE34]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The address family is defined as `AF_INET`, meaning we will rely on IPv4-compliant
    addresses. We could use `AF_INET6` for IPv6, or `AF_BLUETOOTH` for Bluetooth.
    We are using the UDP through the `SOCK_DGRAM` setting of the socket (markers `{2}`
    and `{10}`). Through this, we are transferring a number from one process to another.
    You could imagine them as a server and a client:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 地址族被定义为 `AF_INET`，这意味着我们将依赖于 IPv4 兼容的地址。我们可以使用 `AF_INET6` 来表示 IPv6，或者使用 `AF_BLUETOOTH`
    来表示蓝牙。我们通过套接字的 `SOCK_DGRAM` 设置使用 UDP（标记 `{2}` 和 `{10}`）。通过这种方式，我们将一个进程中的数字传输到另一个进程。您可以想象它们是一个服务器和一个客户端：
- en: '[PRE35]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'A request for a new die roll is received (marker `{4}`) and the request data
    is printed out. Then, the request string is compared to an immutable one, so we
    know that this request is just for a die roll (marker `{5}`). As you can see,
    we use the `MSG_WAITALL` setting, which means that the socket operation will block
    the calling process – usually when there is no incoming data. In addition, this
    is a UDP communication, therefore the packet order might not be followed, and
    receiving `0` bytes through `recvfrom()` is a valid use case. That said, we use
    additional messages to mark the ending of the communication (markers `{6}` and
    `{14}`). For simplicity, if the `request.compare()` result is not `0`, the communication
    is ended. Additional checks for multiple options could be added, though. We could
    use a similar handshake to start the communication in the first place – this is
    depending on the system programmer’s decision and the application requirements.
    Proceeding with the client’s functionality:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 收到新的骰子投掷请求（标记 `{4}`）并打印出请求数据。然后，将请求字符串与一个不可变的字符串进行比较，这样我们就知道这个请求只是为了骰子投掷（标记
    `{5}`）。如您所见，我们使用了 `MSG_WAITALL` 设置，这意味着套接字操作将阻塞调用进程——通常在没有传入数据时。此外，这是一个 UDP 通信，因此数据包顺序可能不会遵循，并且通过
    `recvfrom()` 接收 `0` 字节是一个有效的用例。话虽如此，我们使用额外的消息来标记通信的结束（标记 `{6}` 和 `{14}`）。为了简单起见，如果
    `request.compare()` 的结果不是 `0`，则通信结束。可以添加对多个选项的额外检查。我们可以使用类似的手势来开始通信——这取决于系统程序员的决策和应用需求。继续进行客户端的功能：
- en: '[PRE36]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `die_roll()` function is called for `dice_rolls` a number of times (markers
    `{10}` and `{11}`) and the result is sent through the socket (marker `{12}`).
    After the results are received back (marker `{13}`), an ending message is sent
    (marker `{14}`). We have mostly used `MSG_CONFIRM` for this example, but you must
    be careful with this flag. It should be used when you expect a response from the
    same peer you send to. It is telling the Data Link layer of the OSI model that
    there’s a successful reply. We could change the `recvfrom()` setting to `MSG_DONTWAIT`,
    as in marker `{12}`, but it would be a good idea to implement our own retry mechanism,
    or switch to TCP:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`die_roll()` 函数被调用 `dice_rolls` 次数（标记 `{10}` 和 `{11}`），结果通过套接字（标记 `{12}`）发送。在收到结果后（标记
    `{13}`），发送结束消息（标记 `{14}`）。我们在这个例子中主要使用了 `MSG_CONFIRM`，但必须小心使用这个标志。它应该在您期望从发送给同一对等方收到响应时使用。它告诉
    OSI 模型的数据链路层有一个成功的回复。我们可以将 `recvfrom()` 设置更改为 `MSG_DONTWAIT`，就像标记 `{12}` 一样，但实现自己的重试机制或切换到
    TCP 会是一个好主意：'
- en: '[PRE37]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We close the communication after the closing statement (markers `{8}` and `{15}`):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在关闭语句之后关闭通信（标记 `{8}` 和 `{15}`）：
- en: '[PRE38]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The shortened version of the output is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的简短版本如下：
- en: '[PRE39]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We have to set the address and port where our server could be accessed from.
    Usually, server computers have many applications constantly running, some of which
    execute services for customers. These services bind with the ports of the server
    and users can call them to do some work – get an online store’s contents, check
    the weather, get some banking details, visualize a graphical website, and so on.
    Only one application (service) can work with a given port at a time. If you try
    to use it with another while the first one is active, you will get an `Address
    already in use` error (or similar). Currently, we’re using port `8080`, which
    is commonly opened for TCP/UDP (and HTTP). You could also try `80`, but on Linux,
    non-root users don’t have this capability – you will need higher user permissions
    to use ports less than `1000`. Last but not least, the IP address is set as `INADDR_ANY`.
    This is often used when we do the communication on a single system and we don’t
    care about its address. Still, we could use it, if we want, after we take it from
    the result of the following command:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须设置服务器可以被访问的地址和端口。通常，服务器计算机上会持续运行许多应用程序，其中一些为顾客执行服务。这些服务与服务器端口绑定，用户可以调用它们来完成一些工作——获取在线商店的内容、查看天气、获取一些银行详情、可视化图形网站等等。一次只有一个应用程序（服务）可以与给定的端口一起工作。如果您在第一个应用程序活动时尝试使用它，您将得到一个`Address
    already in use`错误（或类似错误）。目前，我们正在使用端口`8080`，这是为TCP/UDP（和HTTP）通常打开的。您也可以尝试使用`80`，但在Linux上，非root用户没有这个能力——您需要更高的用户权限来使用小于`1000`的端口。最后但同样重要的是，IP地址设置为`INADDR_ANY`。这通常在我们在一个系统上进行通信时使用，我们不在乎它的地址。不过，如果我们想使用它，我们可以在执行以下命令后使用它：
- en: '[PRE40]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'In our case, this is `192.168.136.128`. We could update the code at marker
    `{1}` as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，这是`192.168.136.128`。我们可以在标记`{1}`处更新代码如下：
- en: '[PRE41]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Another option is that the localhost address – `127.0.0.1` – could be used
    with the loopback device address: `INADDR_LOOPBACK`. We use it to run local servers,
    usually for testing purposes. But if we use an exact IP address, then this is
    done when we need to be very specific about the application’s endpoint, and if
    the IP address is a static one, we expect others on the local network to be able
    to call it. If we want to expose it to the outside world so we make our service
    available to others (let’s say we own an online shop and we want to provide our
    shopping service to the world), then we must think about **port forwarding**.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是使用localhost地址——`127.0.0.1`——与回环设备地址：`INADDR_LOOPBACK`一起使用。我们用它来运行本地服务器，通常用于测试目的。但如果我们使用一个确切的IP地址，那么这是在我们需要非常具体地指定应用程序端点时进行的，如果IP地址是静态的，我们期望本地网络上的其他人能够调用它。如果我们想将其暴露给外界，以便我们的服务对其他人可用（比如说我们拥有一个在线商店，我们希望向世界提供我们的购物服务），那么我们必须考虑**端口转发**。
- en: Important note
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: Nowadays, just exposing the port is considered unsafe because the device can
    be accessed by anybody. Instead, services are not only guarded by firewalls, encryption
    mechanisms, and so on but are also deployed on virtual machines. This creates
    an extra layer of security as the attacker will never have access to the real
    device, just to a very limited version of it. Such a decision also provides higher
    availability as the attacked surface could be immediately removed and the system
    administrator could bring up a new virtual machine from a healthy snapshot, making
    the service available again. Depending on the implementation, this could be automated
    as well.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，仅仅暴露端口被认为是不安全的，因为任何人都可以访问该设备。相反，服务不仅由防火墙、加密机制等保护，还被部署在虚拟机上。这增加了一层额外的安全防护，因为攻击者永远无法访问真实设备，而只能访问其一个非常有限的版本。这样的决定也提供了更高的可用性，因为受攻击的表面可以立即移除，系统管理员可以从健康快照中启动一个新的虚拟机，使服务再次可用。根据实现方式，这也可以自动化。
- en: One last thing – the file’s contents might be misplaced if we are transferring
    larger amounts of data. This is again expected from UDP, as expressed earlier,
    because of the packets’ ordering. If it does not suit your purpose and you require
    a more robust implementation, then you should check the TCP description in the
    next section.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点——如果我们传输大量数据，文件内容可能会被放置不当。这同样可以从之前提到的UDP中预期，因为数据包的顺序。如果这不符合您的需求，并且您需要一个更健壮的实现，那么您应该检查下一节中的TCP描述。
- en: Thinking about robustness through TCP
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过TCP考虑健壮性
- en: The alternative to UDP is TCP. It is considered reliable – the messages are
    ordered, it is connection-oriented, and it has a lengthened latency. Applications
    such as the **World Wide Web** (**WWW**), email, remote administration applications,
    and so on are based on this protocol. What you’ve probably noticed already (and
    you’re going to observe in *Figure 7**.6*) is that the respective system calls
    are in the same sequence and have similar names as in other programming languages.
    This helps people with different areas of expertise to have a common ground for
    designing network applications and easily understand the sequence of events. This
    is a very simple way to help them follow the protocols in the OSI model, using
    those names as hints for where the communication is currently at. As we already
    mentioned in the previous section, sockets are used for environment-agnostic solutions,
    where systems have different OSs and the communicating applications are in different
    programming languages. For example, they are implemented in C, C++, Java, or Python,
    and their clients could be in PHP, JavaScript, and so on.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: UDP的替代方案是TCP。它被认为是可靠的——消息是有序的，它是面向连接的，并且具有延长的延迟。像万维网（**WWW**）、电子邮件、远程管理应用程序等应用程序都是基于此协议的。你可能已经注意到了（你将在**图7.6**中观察到），相应的系统调用在顺序上与其他编程语言中的名称相似。这有助于不同领域专家在设计网络应用程序时有一个共同的基础，并轻松理解事件序列。这是一个非常简单的方法，帮助他们遵循OSI模型中的协议，使用这些名称作为提示，了解当前通信的位置。正如我们在上一节中提到的，套接字用于环境无关的解决方案，其中系统具有不同的操作系统，通信的应用程序使用不同的编程语言。例如，它们是用C、C++、Java或Python实现的，而它们的客户端可以是PHP、JavaScript等等。
- en: 'The system calls for TCP communication are represented in the following diagram:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: TCP通信的系统调用在以下图中表示：
- en: '![Figure 7.6 – TCP system call realization](img/Figure_7.6_B20833.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![**图7.6 – TCP系统调用实现**](img/Figure_7.6_B20833.jpg)'
- en: Figure 7.6 – TCP system call realization
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**图7.6 – TCP系统调用实现**'
- en: As you can see, it is more complicated than UDP, as was expected. How so? Well,
    we need to keep an established connection and the kernel acknowledges the packet
    transfer. If you remember, in [*Chapter 1*](B20833_01.xhtml#_idTextAnchor014)
    and [*Chapter 2*](B20833_02.xhtml#_idTextAnchor029), we discussed that sockets
    are files as well, and we could treat them as such. Instead of doing the `send()`
    and `recv()` calls, you could simply do `write()` and `read()` calls. The first
    ones are specialized in the role of network communication, while the latter are
    generally for all files. Using the `read()` and `write()` calls will be like communicating
    through a pipe but between computer systems, therefore it again depends on your
    needs.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它比UDP更复杂，正如预期的那样。为什么会这样？好吧，我们需要保持一个已建立的连接，并且内核确认数据包传输。如果你记得，在**第1章**[B20833_01.xhtml#_idTextAnchor014]和**第2章**[B20833_02.xhtml#_idTextAnchor029]中，我们讨论了套接字也是文件，我们可以这样对待它们。而不是执行`send()`和`recv()`调用，你可以简单地执行`write()`和`read()`调用。前者专门用于网络通信的角色，而后者通常是所有文件通用的。使用`read()`和`write()`调用将类似于通过管道进行通信，但这是在计算机系统之间，因此它再次取决于你的需求。
- en: 'Let’s look at the following example – a simple request-response exchange, which
    we will execute on different machines on the local network, as the IP address
    from earlier is valid only for our internal network. First, let’s see whether
    we can ping the server:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下示例——一个简单的请求-响应交换，我们将在本地网络上的不同机器上执行这个交换，因为之前提到的IP地址仅适用于我们的内部网络。首先，让我们看看我们是否可以ping通服务器：
- en: '[PRE42]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'So, we have access to the machine. Now, let’s run the server as a separate
    application (the full code can be found at https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207).
    The configuration is almost the same, so we skip those parts from the snippet:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经可以访问这台机器。现在，让我们将服务器作为一个独立的应用程序运行（完整的代码可以在https://github.com/PacktPublishing/C-Programming-for-Linux-Systems/tree/main/Chapter%207中找到）。配置几乎相同，所以我们省略了代码片段中的这些部分：
- en: '[PRE43]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We open the socket:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们打开套接字：
- en: '[PRE44]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We use `SOCK_STREAM` to indicate this ias a TCP connection. We also use the
    hardcoded IP. After we bind to the address, we need to listen for a `BACKLOG`
    number of active connections. Each new connection could be accepted in general
    if the number of connections is smaller than the `BACKLOG` value:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`SOCK_STREAM`来表示这是一个TCP连接。我们还使用了硬编码的IP地址。在绑定到地址后，我们需要监听一个`BACKLOG`数量的活动连接。如果连接数小于`BACKLOG`值，通常可以接受每个新的连接：
- en: '[PRE45]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Until this point, we just have the following:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只有以下内容：
- en: '[PRE46]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, let’s prepare to accept a client and handle its requests. We use the `MSG_PEEK`
    flag to check for incoming messages, and we send messages with `MSG_DONTWAIT`.
    We leave `sendto()` without a result check for simplicity and readability:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们准备接受客户端并处理其请求。我们使用`MSG_PEEK`标志来检查传入的消息，并使用`MSG_DONTWAIT`发送消息。为了简单和可读性，我们省略了`sendto()`的结果检查：
- en: '[PRE47]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'And the socket is closed at the end:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 并且在结束时关闭套接字：
- en: '[PRE48]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, let’s connect a client from another system. Its implementation is similar
    to the UDP one, except `connect()` must be called and must be successful:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从另一个系统连接一个客户端。它的实现与UDP类似，除了必须调用`connect()`并且必须成功：
- en: '[PRE49]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The server’s output changes as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器的输出如下变化：
- en: '[PRE50]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let’s continue the communication, sending information back:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续通信，发送信息回来：
- en: '[PRE51]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We are closing the communication on the client side, including the socket.
    The client’s output is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在关闭客户端端的通信，包括套接字。客户端的输出如下：
- en: '[PRE52]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'As the client’s job is done, the process terminates and its socket is closed,
    but the server remains active for other clients, so if we call the client multiple
    times from different shells, we will have the following output for the server:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端的工作完成时，进程终止并关闭其套接字，但服务器仍然为其他客户端保持活跃，因此如果我们从不同的shell多次调用客户端，服务器将会有以下输出：
- en: '[PRE53]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The server will handle up to five client sessions in its backlog. If the clients
    don’t close their sockets or the server doesn’t forcefully terminate their connections
    after some timeout, it will not be able to accept new clients, and the `Client
    connection failed` message will be observed. In the next chapter, we will discuss
    different time-based techniques, so think about combining them with your implementation
    to provide a meaningful session timeout.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器将在其队列中处理最多五个客户端会话。如果客户端没有关闭它们的套接字，或者服务器在超时后没有强制终止它们的连接，它将无法接受新的客户端，并且会观察到“客户端连接失败”的消息。在下一章中，我们将讨论不同的基于时间的技巧，所以请考虑将它们与您的实现相结合，以提供有意义的会话超时。
- en: 'If we want to gracefully handle the server termination, we could simply implement
    a signal handler, as we did in [*Chapter 3*](B20833_03.xhtml#_idTextAnchor047).
    This time, we will handle the *Ctrl* + *C* key combination, leading to the following
    output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要优雅地处理服务器终止，可以简单地实现一个信号处理程序，就像我们在[*第3章*](B20833_03.xhtml#_idTextAnchor047)中所做的那样。这次，我们将处理*Ctrl*
    + *C*键组合，导致以下输出：
- en: '[PRE54]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'As mentioned earlier, ungraceful termination of servers and clients could lead
    to hanging sockets and opened ports. This will become problematic for a system,
    as simple application restarts will fail with `Address already in use`. If this
    happens, double-check for remaining processes through the `ps` command. You can
    terminate the running process through the `kill` command, as you learned in [*Chapter
    1*](B20833_01.xhtml#_idTextAnchor014) and [*Chapter 2*](B20833_02.xhtml#_idTextAnchor029).
    Sometimes, this is not enough either, and servers should not be terminated that
    easily. Therefore, you could just change a port after checking which ports are
    opened. You could do that through the following command:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，服务器和客户端的不当终止可能导致挂起的套接字和打开的端口。这将对系统造成问题，因为简单的应用程序重启将失败并显示`Address already
    in use`。如果发生这种情况，请通过`ps`命令检查剩余的进程。您可以通过`kill`命令终止正在运行的过程，就像您在[*第1章*](B20833_01.xhtml#_idTextAnchor014)和[*第2章*](B20833_02.xhtml#_idTextAnchor029)中学到的那样。有时，这还不够，服务器也不应该那么容易终止。因此，您可以在检查了哪些端口已打开后更改端口。您可以通过以下命令完成此操作：
- en: '[PRE55]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'You can see the server is up and running on the respective address and port:
    `192.168.136.128:8080`. We can also check the connections to a certain port by
    using the following:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到服务器正在指定的地址和端口上运行：`192.168.136.128:8080`。我们也可以使用以下方法检查到某个端口的连接：
- en: '[PRE56]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: With multiple online services nowadays, we cannot escape network programming.
    We encourage you to use these examples as simple applications to start from. It’s
    also important to spend some time learning more about the multiple socket settings
    as they will help you cover your specific requirements.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 随着现在在线服务的增多，我们无法避免网络编程。我们鼓励您将这些示例作为简单的应用程序开始。了解更多的套接字设置也很重要，因为这将帮助您满足特定的需求。
- en: Summary
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you’ve learned about various ways to execute IPC. You got familiar
    with MQs as simple, real-time, and reliable instruments for sending small chunks
    of data. We also got into the details of fundamental synchronization mechanisms
    such as semaphores and mutexes, along with their C++20 interfaces. In combination
    with shmem, you observed how we could exchange large amounts of data fast. At
    the end, the network communication through sockets was introduced to you through
    the main protocols, UDP and TCP.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了各种执行IPC的方法。你熟悉了消息队列（MQs）作为发送小块数据的简单、实时和可靠的工具。我们还深入探讨了基本同步机制，如信号量和互斥锁，以及它们的C++20接口。结合共享内存（shmem），你观察到我们如何快速交换大量数据。最后，通过主要的协议UDP和TCP，介绍了通过套接字进行网络通信。
- en: Complex applications usually rely on multiple IPC techniques to achieve their
    goals. It’s important to be aware of them – both their strengths and their disadvantages.
    This will help you decide on your particular implementation. Most of the time,
    we build layers on top of IPC solutions in order to guarantee the robustness of
    an application – for example, through retry mechanisms, polling, event-driven
    designs, and so on. We will revisit these topics in [*Chapter 9*](B20833_09.xhtml#_idTextAnchor129).
    The next chapter will give you the instruments to self-monitor your availability
    and performance through different timers.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的应用通常依赖于多种进程间通信（IPC）技术来实现其目标。了解它们——包括它们的优点和缺点——非常重要。这将帮助你决定你特定的实现方案。大多数情况下，我们会在IPC解决方案之上构建层，以确保应用程序的健壮性——例如，通过重试机制、轮询、事件驱动设计等。我们将在[*第9章*](B20833_09.xhtml#_idTextAnchor129)中重新探讨这些主题。下一章将为你提供通过不同计时器自我监控可用性和性能的工具。
