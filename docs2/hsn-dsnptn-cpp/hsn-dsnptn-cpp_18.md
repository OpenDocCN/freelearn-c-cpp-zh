

# 第十八章：并发模式

上一章专门介绍了一组用于并发程序的模式。并发与 C++之间有一种相当复杂的关系。一方面，C++是一种以性能为导向的语言，并发几乎总是被用来提高性能，因此两者是自然匹配的。当然，C++从语言最早的时候就开始被用来开发并发程序了。另一方面，对于经常被用来编写并发程序的语言来说，C++在直接解决并发编程需求的结构和特性方面却出奇地缺乏。这些需求主要是由广泛的社区开发的库以及通常针对特定应用的解决方案来满足的。在本章中，我们将回顾在并发程序开发中遇到的常见问题以及多年经验中出现的解决方案；这些共同构成了设计模式的两面。

本章涵盖了以下主题：

+   C++中并发支持的现状如何？

+   并发的挑战主要有哪些？

+   数据同步的挑战以及 C++工具如何应对这些挑战

+   并发的设计是怎样的？

+   C++中管理并发工作负载的常见模式有哪些？

# 技术要求

本章的示例代码可以在 GitHub 上找到，链接如下：[`github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter18`](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-CPP-Second-Edition/tree/master/Chapter18)。此外，对并发的一般知识和 C++中的并发支持也是先决条件。

# C++与并发

并发的概念是在 C++11 中引入到语言中的，但并发程序在那时之前就已经用 C++编写了。本章的目的不是介绍并发，甚至也不是介绍 C++中的并发。这个主题在文献中已经得到了很好的覆盖（在本书出版时，一本既全面又更新的作品是 Anthony Williams 的《C++并发实战》）。此外，虽然并发几乎总是用来提高性能，但在这里我们不会直接讨论性能和优化问题；对于这些问题，你可以参考我的书《编写高效程序的技艺》。我们将专注于并发软件设计中出现的问题。

在开发并发程序时，从广义上讲，我们会遇到三种类型的挑战。首先，如何在多个线程同时操作同一数据的情况下确保程序的正确性？其次，如何通过多线程执行程序的工作来提高整体性能？最后，如何设计软件，使其能够让我们对其进行分析、理解其功能以及维护它，同时还要考虑到并发的复杂性。

第一组挑战主要与数据共享和同步相关。我们将首先检查相关的模式：程序首先必须是正确的，在一个崩溃或产生不可信结果的程序中实现高性能是毫无用处的。

# 同步模式

同步模式有一个总的目标：确保多个线程共享的数据的正确操作。这些模式对于绝大多数并发程序至关重要。唯一不需要同步的程序是那些执行几个完全独立的任务且不涉及任何公共数据（除了可能读取共享的不可变输入）并产生单独结果的程序。对于其他所有程序，都需要管理一些共享状态，这使我们面临可怕的数据竞争的风险。正式来说，C++标准指出，如果没有适当的同步来保证每个线程的独占访问，则对同一对象（同一内存位置）的并发访问会导致未定义行为。更精确地说，如果至少有一个线程可以修改共享数据，则行为是未定义的：如果数据从未被任何线程更改，则不可能发生数据竞争。有一些设计模式利用了这个漏洞，但让我们从最广为人知的同步模式开始。当你听到避免数据竞争时，首先想到的是什么？

## 互斥锁和锁定模式

如果有一个用于编写并发程序的工具，那就是互斥锁。互斥锁用于保证多个线程访问共享数据时的独占访问：

```cpp
std::mutex m;
MyData data;
...
// On several threads:
m.lock();
transmogrify(data);
m.unlock();
```

数据修改操作 `transmogrify()` 必须保证对共享数据的独占访问：在任何给定时间只能有一个线程执行此操作。程序员使用 `lock()` 和 `unlock()`。

使用互斥锁足以确保对共享数据的正确访问，但这几乎不是一个好的设计。第一个问题是它容易出错：如果 `transmogrify()` 抛出异常，或者如果程序员添加了对返回值的检查并提前退出关键部分，最终的 `unlock()` 永远不会执行，互斥锁将永远锁定，从而阻止其他任何线程访问数据。

这个挑战可以通过对我们在 *第五章* 中已经看到的非常通用的 C++模式的一种特定应用来轻松解决，即 *全面审视 RAII*。我们需要的只是一个用于锁定和解锁互斥锁的对象，而 C++标准库已经提供了一个，`std::lock_guard`：

```cpp
// Example 01
std::mutex m;
int i = 0;
void add() {
  std::lock_guard<std::mutex> l(m);
  ++i;
}
...
std::thread t1(add);
std::thread t2(add);
t1.join();
t2.join();
std::cout << i << std::endl;
```

函数`add()`修改共享变量`i`，因此需要独占访问；这是通过使用互斥量`m`来实现的。请注意，如果你在没有互斥量的情况下运行此示例，你仍然可能会得到正确的结果，因为其中一个线程会在另一个线程之前执行。有时程序会失败，而更多的时候则不会。这并不意味着它是正确的，只是使得调试变得困难。你可以通过使用`--sanitize=address`来启用它，并使用`add()`中的互斥量（*示例 02*），用 TSAN 编译，运行程序，你将看到以下内容：

```cpp
WARNING: ThreadSanitizer: data race
...
Location is global 'i' of size 4 at <address>
```

显示了更多信息，以帮助您确定哪些线程存在数据竞争以及对于哪个变量。这是一种比等待程序失败更可靠的测试数据竞争的方法。

在 C++17 中，使用`std::lock_guard`稍微简单一些，因为编译器会从构造函数中推断模板参数：

```cpp
// Example 03
std::lock_guard l(m);
```

在 C++20 中，我们可以使用`std::jthread`来代替显式调用`join()`：

```cpp
// Example 03
{
  std::jthread t1(add);
  std::jthread t2(add);
}
std::cout << i << std::endl;
```

注意，在使用计算结果之前必须小心地销毁线程，因为析构函数现在会连接线程并等待计算完成。否则，将存在另一个数据竞争：主线程在`i`值被增加时正在读取它的值（TSAN 也会发现这个竞争）。

RAII 的使用确保每次锁定互斥量时都会解锁，但这并不能避免在使用互斥量时可能发生的其他错误。最常见的一个是忘记最初使用互斥量。同步保证仅适用于每个线程都使用相同的机制来确保对数据的独占访问。如果甚至有一个线程没有使用互斥量，即使只是读取数据，那么整个程序都是不正确的。

开发了一种模式来防止对共享数据的未同步访问。这个模式通常被称为“互斥量保护”或“互斥量保护”，它有两个关键元素：首先，需要保护的数据和用于此目的的互斥量被组合在同一个对象中。其次，设计确保对数据的每次访问都由互斥量保护。以下是一个基本的互斥量保护类模板：

```cpp
// Example 04
template <typename T> class MutexGuarded {
  std::mutex m_;
  T data_ {};
  public:
  MutexGuarded() = default;
  template <typename... Args>
  explicit MutexGuarded(Args&&... args) :
    data_(std::forward<Args>(args)...) {}
  template <typename F> decltype(auto) operator()(F f) {
    std::lock_guard<std::mutex> l(m_);
    return f(data_);
  }
};
```

如您所见，此模板将互斥量和它所保护的数据结合起来，并只提供一种访问数据的方式：通过使用任意可调用对象调用`MutexGuarded`对象。这确保了所有数据访问都是同步的：

```cpp
// Example 04
MutexGuarded<int> i_guarded(0);
void add() {
  i_guarded([](int& i) { ++i; });
}
...
// On many threads:
std::thread t1(add);
std::thread t2(add);
t1.join();
t2.join();
i_guarded([](int i) { std::cout << i << std::endl; });
```

这些是正确和可靠使用互斥锁模式的最基本的版本。在实践中，需求通常更为复杂，因此解决方案也是如此：有比`std::mutex`更高效的锁（例如，用于保护短计算的自旋锁，你可以在我的书《编写高效程序的艺术》中找到），还有更复杂的锁，如共享锁和独占锁，用于高效的读写访问。此外，我们通常需要同时操作多个共享对象，这导致了安全锁定多个互斥锁的问题。许多这些问题都是通过我们刚刚看到的模式的更复杂变体来解决的。有些需要完全不同的数据访问同步方法，我们将在本节后面看到这些方法。最后，一些数据访问挑战在整体系统设计的更高层次上解决更好；这一点也将在本章中展示。

让我们接下来回顾一下超越常用互斥锁的数据共享的不同方法。

## 不共享是最好的共享

虽然使用互斥锁来保护共享数据看起来并不复杂，但实际上，数据竞争是任何并发程序中最常见的错误。虽然声称你不能访问你不共享的数据以避免数据竞争可能看似一个无用的真理，但事实上，不共享是共享的一个经常被忽视的替代方案。换句话说，通常可以重新设计程序以避免共享某些变量，或者将共享数据的访问限制在代码的较小部分。

这个想法是设计模式的基础，这种模式容易解释但往往难以应用，因为它需要跳出思维定势——线程特定数据模式。它也被称为“线程局部数据”，但这个名字容易与 C++的`thread_local`关键字混淆。为了说明这个想法，我们考虑以下示例：我们需要计算可能在多个线程同时发生的事件（在这个演示中，计数的内容并不重要）。我们需要整个程序中这些事件的累计计数，所以直接的方法是有一个共享计数，当线程检测到事件时（在演示中，我们计算能被 10 整除的随机数）：

```cpp
// Example 05
MutexGuarded<size_t> count;
void events(unsigned int s) {
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&s) % 10) == 0) { // Event!
      count([](size_t& i) { ++i; });
    }
  }
}
```

这是一个直接的设计；它不是最好的。注意，虽然每个线程都在计数事件，但它不需要知道其他线程计数了多少事件。这并不与我们的实现中每个线程需要知道当前计数值以便正确增加它的这一事实相混淆。这种区别很微妙但很重要，并暗示了一个替代方案：每个线程可以使用线程特定的计数来计数它自己的事件，每个线程一个。这些计数都不正确，但只要我们能在需要正确的总事件计数时将所有计数相加，那就没关系了。这里有几个可能的设计。我们可以为事件使用局部计数，并在线程退出之前更新一次共享计数：

```cpp
// Example 06
MutexGuarded<size_t> count;
void events(unsigned int s) {
  size_t n = 0;
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&s) % 10) == 0) { // Event!
      ++n;
    }
  }
  if (n > 0) count(n { i += n; });
}
```

在一个或多个线程正在执行其函数时声明的任何局部（栈分配）变量都是特定于每个线程的：每个线程的栈上都有一个唯一的变量副本，并且当它们都引用相同的名称 `n` 时，每个线程访问它自己的变量。

我们也可以给每个线程提供一个唯一的计数变量来增加，并在所有计数线程完成后在主线程中将它们相加：

```cpp
// Example 07
void events(unsigned int s, size_t& n) {
  for (size_t i = 1; i != 100; ++i) {
    if ((rand_r(&s) % 10) == 0) ++n;
  }
}
```

在多个线程上调用这个计数函数时，我们必须采取一些预防措施。显然，我们应该给每个线程自己的计数变量 `n`。这还不够：由于称为“伪共享”的硬件相关效应，我们还必须确保线程特定的计数在内存中不是相邻的（有关伪共享的详细描述可以在我的书 *《编写高效程序的艺术》* 中找到）：

```cpp
// Example 07
alignas(64) size_t n1 = 0;
alignas(64) size_t n2 = 0;
std::thread t1(events, 1, std::ref(n1));
std::thread t2(events, 2, std::ref(n2));
t1.join();
t2.join();
size_t count = n1 + n2;
```

`alignas` 属性确保每个计数变量有 64 字节的对齐，从而确保 `n1` 和 `n2` 的地址之间至少有 64 字节的区别（64 是大多数现代 CPU（包括 X86 和 ARM）的缓存行大小）。注意，对于 `std::thread` 来调用使用引用参数的函数，需要 `std::ref` 包装器。

前一个例子将共享数据访问的需求减少到每个线程一次，而最后一个例子则完全没有共享数据；首选的解决方案取决于总计数值何时需要。

最后一个例子可以从一个稍微不同的角度来审视；稍微重写它会有所帮助：

```cpp
// Example 08
struct {
  alignas(64) size_t n1 = 0;
  alignas(64) size_t n2 = 0;
} counts;
std::thread t1(events, 1, std::ref(counts.n1));
std::thread t2(events, 2, std::ref(counts.n2));
t1.join();
t2.join();
size_t count = counts.n1 + counts.n2;
```

这并没有改变任何实质性的东西，但我们可以将线程特定的计数视为同一数据结构的一部分，而不是为每个线程创建的独立变量。这种思维方式引导我们到达线程特定数据模式的另一个变体：有时，多个线程必须操作相同的数据，但可能可以将数据分区，并给每个线程分配它自己的子集来工作。

在下一个示例中，我们需要对向量中的每个元素进行 clamp 操作（如果一个元素超过最大值，它将被替换为这个值，因此结果总是在零和最大值之间）。计算是通过以下模板算法实现的：

```cpp
// Example 09
template <typename IT, typename T>
void clamp(IT from, IT to, T value) {
  for (IT it = from; it != to; ++it) {
    if (*it > value) *it = value;
  }
}
```

一个生产质量的实现将确保迭代器参数满足迭代器要求，并且最大值可以与迭代器值类型进行比较，但我们为了简洁起见省略了所有这些（我们有一个关于概念和其他限制模板方法的整个章节）。

`clamp()` 函数可以在任何序列上调用，有时我们可能会幸运地有可以独立在多个线程上处理的不同且无关的数据结构。但是，为了继续这个例子，让我们假设我们只有一个需要 clamp 的向量。然而，情况并非全无希望，因为我们可以在没有数据竞争风险的情况下，在多个线程上处理它的非重叠部分：

```cpp
// Example 09
std::vector<int> data = ... data ...;
std::thread t1([&](){
  clamp(data.begin(), data.begin() + data.size()/2, 42);
});
std::thread t2([&](){
  clamp(data.begin() + data.size()/2, data.end(), 42);
});
...
t1.join();
t2.join();
```

尽管我们程序中的数据结构在两个线程之间是共享的，并且两个线程都对其进行修改，但这个程序是正确的：对于每个向量元素，只有一个线程可以修改它。但是，向量对象本身呢？它不是在所有线程之间共享的吗？

我们已经强调，有一种情况允许数据共享而不需要任何同步：只要没有其他线程正在修改它，任意数量的线程都可以读取相同的变量。我们的例子就利用了这一点：所有线程都读取向量的大小和其他向量对象的成员变量，但没有线程修改它们。

线程特定数据模式的运用必须经过仔细思考，通常需要很好地理解数据结构。我们必须绝对确信没有任何线程试图修改它们共享的变量，例如向量对象本身的成员变量的大小和指针。例如，如果某个线程可以调整向量的大小，即使没有两个线程访问相同的元素，这也会成为数据竞争：向量的大小是一个变量，它被一个或多个线程修改，但没有加锁。

在本小节中，我们想要描述的最后一种模式适用于多个线程需要修改整个数据集（因此不能分区）但不需要看到其他线程所做的修改的情况。通常，这种情况发生在修改作为某些结果计算的一部分时，但修改后的数据本身不是最终结果。在这种情况下，有时最好的方法是为每个线程创建一个线程特定的数据副本。这种模式在副本是“一次性”对象时效果最好：每个线程都需要修改其副本，但修改的结果不需要提交回原始数据结构。

在下面的示例中，我们使用一个算法来计算向量中唯一元素的数量，该算法在原地排序向量：

```cpp
// Example 10
void count_unique(std::vector<int> data, size_t& count) {
  std::sort(data.begin(), data.end());
  count = std::unique(data.begin(),
                      data.end()) - data.begin();
}
```

此外，当我们只需要计数满足某个谓词的元素时，我们首先删除所有其他元素（`std::erase_if` 是 C++20 的新增功能，但在 C++ 的早期版本中也很容易实现）：

```cpp
// Example 10
void count_unique_even(std::vector<int> data, size_t& count) {
  std::erase_if(data, [](int i) { return i & 1; });
  std::sort(data.begin(), data.end());
  count = std::unique(data.begin(),
                      data.end()) - data.begin();
}
```

这两种操作都是对向量的破坏性操作，但它们只是达到目的的手段：一旦我们得到了计数，就可以丢弃修改后的向量。在多个线程上同时计算我们的计数的最简单、通常也是最高效的方法是创建向量的线程特定副本。实际上，我们已经这样做了：这两个计数函数都是通过值传递向量参数，因此会创建一个副本。通常，这会是一个错误，但在这个情况下，这是故意的，并且允许这两个函数同时操作同一个向量：

```cpp
// Example 10
std::vector<int> data = ...;
size_t unique_count = 0;
size_t unique_even_count = 0;
{
  std::jthread t1(count_unique, data,
                  std::ref(unique_count));
  std::jthread t2(count_unique_even, data,
                  std::ref(unique_even_count));
}
```

当然，仍然存在对原始数据的并发访问，并且没有使用锁：两个线程都需要创建它们的线程特定副本。然而，这属于只读并发访问的例外情况，是安全的。

从原则上讲，尽可能避免数据共享，在必要时使用互斥锁，就足以在任何程序中安排无竞争的数据访问。然而，这可能不是实现这一目标的最有效方式，而良好的性能几乎总是并发的目标。现在，我们将考虑几种其他用于并发访问共享数据的模式，当适用时，可以提供更好的性能。我们将从比互斥锁更高级的同步原语开始，这些原语专门设计用来允许线程高效地等待某些事件。

## 等待模式

等待是并发程序中经常遇到的问题，它有多种形式。我们已经看到了一个：互斥锁。确实，如果有两个线程试图同时进入临界区，其中一个将不得不等待。但在这里，等待并不是目标，只是对临界区独占访问的不幸副作用。还有其他情况下，等待是主要目标。例如，我们可能有等待某些事件发生的线程。这可能是一个用户界面线程等待输入（性能要求很低）或等待网络套接字的线程（性能要求适中）或甚至是一个高性能线程，如线程池中的计算线程等待执行任务（性能要求极高）。不出所料，这些场景有不同的实现，但基本上有两种方法：轮询和通知。我们将首先探讨通知。

等待通知的基本模式是**条件模式**。它通常由一个条件变量和一个互斥锁组成。一个或多个线程被阻塞等待条件变量。在这段时间里，还有一个线程锁定互斥锁（从而保证独占访问）并执行其他线程等待完成的工作。一旦工作完成，完成工作的线程必须释放互斥锁（这样其他线程就可以访问包含此工作结果的共享数据）并通知等待的线程它们可以继续。

例如，在一个线程池中，等待的线程是等待将任务添加到池中的池工作线程。由于池任务队列是一个共享资源，一个线程需要独占访问来推送或弹出任务。向队列添加一个或多个任务的线程必须在执行此操作时持有互斥锁，然后通知工作线程有任务要执行。

现在我们来看一个只有两个线程的非常基本的示例，说明通知模式。首先，我们有主线程，它启动一个工作线程，然后等待它产生一些结果：

```cpp
// Example 11
std::mutex m;
std::condition_variable cv;
size_t n = 0;               // Zero until work is done
// Main thread
void main_thread() {
  std::unique_lock l(m);
  std::thread t(produce);     // Start the worker
  cv.wait(l, []{ return n != 0; });
  ... producer thread is done, we have the lock ...
}
```

在这种情况下，锁定是由`std::unique_lock`提供的，这是一个围绕互斥锁包装的对象，具有类似互斥锁的接口，具有`lock()`和`unlock()`成员函数。互斥锁在构造函数中被锁定，并在我们开始等待条件时几乎立即由`wait()`函数解锁。当接收到通知时，`wait()`在返回控制权给调用者之前再次锁定互斥锁。

许多等待和条件的实现都存在所谓的虚假唤醒问题：即使没有通知，等待也可以被中断。这就是为什么我们还要检查结果是否准备好，在我们的例子中，通过检查结果计数`n`：如果它仍然是零，则没有结果，主线程被错误唤醒，我们可以回到等待状态（注意，等待线程必须在`wait()`返回之前获取互斥锁，因此它必须等待工作线程释放这个互斥锁）。

工作线程在访问共享数据之前必须锁定相同的互斥锁，然后在通知主线程工作已完成之前解锁它：

```cpp
// Example 11
// Worker thread
void produce() {
  {
    std::lock_guard l(m);
    ... compute results ...
    n = ... result count ...
  } // Mutex unlocked
  cv.notify_one();          // Waiting thread notified
}
```

在工作线程活跃的整个时间内没有必要一直持有互斥锁：它的唯一目的是保护共享数据，例如我们例子中的结果计数`n`。

两个同步原语`std::conditional_variable`和`std::unique_lock`是标准 C++工具，用于实现带有条件的等待模式。就像互斥锁一样，有许多变体。

通知的替代方法是轮询。在这个模式中，等待的线程反复检查是否满足某些条件。在 C++20 中，我们可以使用`std::atomic_flag`实现一个简单的轮询等待示例，它本质上是一个原子布尔变量（在 C++20 之前，我们可以用`std::atomic<bool>`做同样的事情）：

```cpp
// Example 12
std::atomic_flag flag;
// Worker thread:
void produce() {
  ... produce the results ...
  flag.test_and_set(std::memory_order_release);
}
// Waiting thread:
void main_thread() {
  flag.clear();
  std::thread t(produce);
  while (!flag.test(std::memory_order_acquire)) {} // Wait
  ... results are ready ...
}
```

原子操作，例如 `test_and_set()`，利用**内存屏障**：一种全局同步标志，确保在设置（释放）该标志之前对内存所做的所有更改都对在标志测试（获取）之后执行的任何其他线程上的任何操作可见。关于这些屏障还有很多内容，但这些都超出了本书的范围，可以在许多关于并发和效率的书中找到。

与上一个示例相比，最重要的区别是等待线程在*示例 12*中的显式轮询循环。如果等待时间很长，这会非常低效，因为等待线程在整个等待过程中都在忙于计算（从内存中读取）。任何实际实现都会在等待循环中引入一些睡眠，但这样做也会付出代价：等待线程不会在工作者线程设置标志后立即唤醒，而必须先完成睡眠。这些效率问题超出了本书的范围；在这里，我们想展示这些模式的整体结构和组件。

轮询和等待之间的界限并不总是清晰的。例如，据我们所知，`wait()` 可能是通过定期轮询条件变量的某些内部状态来实现的。实际上，我们刚才看到的相同的原子标志可以用来等待通知：

```cpp
// Example 13
std::atomic_flag flag;
// Worker thread:
void produce() {
  ... produce the results ...
  flag.test_and_set(std::memory_order_release);
  flag.notify_one();
}
// Waiting thread:
void main_thread() {
  flag.clear();
  std::thread t(produce);
  flag.wait(true, std::memory_order_acquire); // Wait
  while (!flag.test(std::memory_order_acquire)) {}
  ... results are ready ...
}
```

对 `wait()` 的调用需要一个相应的 `notify_one()`（或如果有多个线程在等待该标志，则为 `notify_all()`）调用。它的实现几乎肯定比我们的简单轮询循环更高效。在接收到通知并结束等待后，我们检查标志以确保它确实被设置了。标准说这不是必要的，`std::atomic_flag::wait()` 不会遭受虚假唤醒，但 GCC 和 Clang 中的 TSAN 都不同意（这可能是 TSAN 中的假阳性或标准库实现中的错误）。

有许多其他情况下需要等待，而我们需要等待的条件各不相同。另一个常见的需求是等待一定数量的事件发生。例如，我们可能有几个线程在生成结果，我们可能需要它们在主线程继续之前完成它们的工作份额。这是通过在屏障或闩锁上等待来实现的。在 C++20 之前，我们需要自己实现这些同步原语或使用第三方库，但在 C++20 中它们已成为标准：

```cpp
// Example 14
// Worker threads
void produce(std::latch& latch) {
  ... do the work ...
  latch.count_down();     // One more thread is done
}
void main_thread() {
  constexpr size_t nthread = 4;
  std::jthread t[nthread];
  std::latch latch(nthread); // Wait for 4 count_down()
  for (size_t i = 0; i != nthread; ++i) {
    t[i] = std::jthread(std::ref(latch));
  }
  latch.wait();   // Wait for producers to finish
  ... results are ready ...
}
```

闩锁初始化为等待事件的数量。当完成这么多 `count_down()` 调用后，它将解锁。

等待有许多其他应用，但几乎所有的等待模式都可以大致分为本节中我们看到的一种类别（特定实现可能会对特定情况下的性能产生显著影响，因此你更有可能看到这些同步构造的特定应用版本，而不是非标准容器或其他基本数据结构）。

现在我们将看到几个非常专业且非常高效的同步模式的例子。它们并不适用于所有情况，但当它们符合需求时，它们通常提供最佳性能。

## 无锁同步模式

大多数情况下，安全访问共享数据依赖于互斥锁。C++还支持另一种同步并发线程的类型：原子操作。同样，详细的解释超出了本书的范围，本节需要一些关于原子的先验知识。

基本思想是这样的：一些数据类型（通常是整数）有特殊的硬件指令，允许一些简单的操作，如读取、写入或增加值以原子方式执行，在单个事件中完成。在原子操作期间，其他线程根本无法访问原子变量，因此如果一个线程执行原子操作，所有其他线程都可以看到操作前后相同的变量，但不能在操作过程中看到。例如，增加是一个读取-修改-写入操作，但原子增加是一个特殊的硬件事务，一旦读取开始，其他线程就无法访问变量，直到写入完成。这些原子操作通常伴随着内存屏障；我们已经在程序中使用了它们，以确保不仅仅是原子操作，所有其他操作都是同步的，并且没有数据竞争。

原子操作最简单但有用的应用是计数。我们经常需要在程序中计数，在并发程序中，我们可能需要计数在多个线程上可能发生的一些事件。如果我们只对所有线程完成后的事件总数感兴趣，这最好由我们之前看到的“非共享”或线程特定的计数器来处理。但如果有所有线程都需要知道当前计数的情况呢？我们总是可以使用互斥锁，但使用互斥锁来保护一个整数的简单增加是非常低效的。C++为我们提供了一种更好的方法，即原子计数器：

```cpp
// Example 15
std::atomic<size_t> count;
void thread_work() {
  size_t current_count = 0;
  if (... counted even ...) {
    current_count =
      count.fetch_add(1, std::memory_order_relaxed);
  }
}
```

在这个例子中只有一个共享变量，即`count`本身。由于我们没有其他共享数据，所以我们不需要内存屏障（“宽松”内存顺序意味着对其他数据的访问顺序没有要求）。`fetch_add()`操作是一个原子增加操作，它将`count`增加 1 并返回`count`的旧值。

原子计数也可以用来让多个线程在无需加锁的情况下对同一数据结构进行操作：为此，我们需要确保只有一个线程在处理数据结构中的每个元素。以这种方式使用时，该模式通常被称为原子索引。在下一个示例中，我们有一个所有线程共享的数据数组：

```cpp
// Example 16
static constexpr size_t N = 1024;
struct Data { ... };
Data data[N] {};
```

我们还有一个原子索引，由所有需要将工作结果存储在数组中的线程使用。为了安全地这样做，每个线程都会增加一个原子索引，并使用预增量值作为数组的索引。由于没有两个原子增量操作会产生相同的值，因此每个线程都会得到自己的数组元素来处理：

```cpp
// Example 16
std::atomic<size_t> index(0);
// Many producer threads
void produce(size_t& n) {
  while (... more work … ) {
    const size_t s =
      index.fetch_add(1, std::memory_order_relaxed);
    if (s >= N) return;     // No more space
    data[s] = ... results ...
  }
}
```

每个线程可以初始化尽可能多的数组元素，并在它（以及所有其他线程）填满整个数组时停止。主线程必须等待所有工作完成才能访问任何结果。仅使用原子索引是无法做到这一点的，因为它是当线程开始处理特定数组元素时增加的，而不是当线程完成工作后。我们必须使用其他同步机制来使主线程等待直到所有工作完成，例如一个闩锁，或者在简单情况下，将生产者线程连接起来：

```cpp
// Example 16
void main_thread() {
  constexpr size_t nthread = 5;
  std::thread t[nthread];
  for (size_t i = 0; i != nthread; ++i) {
    t[i] = std::thread(produce);
  }
  // Wait for producers. to finish.
  for (size_t i = 0; i != nthread; ++i) {
    t[i].join();
  }
  ... all work is done, data is ready ...
}
```

当我们不依赖于计数值来访问已生成的结果时，原子计数是好的。在上一个示例中，生产者线程不需要访问其他线程计算出的数组元素，主线程在访问结果之前等待所有线程完成。通常情况下并非如此，我们需要在数据生成过程中访问数据。这就是内存屏障发挥作用的地方。

依赖于内存屏障的最简单但出奇强大的无锁模式被称为发布协议。当有一个线程正在生产一些数据，当它准备好时，这些数据将被提供给一个或多个其他线程时，这种模式适用。该模式看起来是这样的：

```cpp
// Example 17
std::atomic<Data*> data;
void produce() {
  Data* p = new Data;
  ... complete *p object ...
  data.store(p, std::memory_order_release);
}
void consume() {
  Data* p = nullptr;
  while (!(p = data.load(std::memory_order_acquire))) {}
  ... safe to use *p ...
}
```

共享变量是一个指向数据的原子指针。它通常被称为“根指针”，因为数据本身可能是一个复杂的包含多个指针连接其部分的数据结构。这种模式的关键要求是只能通过根指针访问整个数据结构。

生产者线程构建它需要生产的所有数据。它使用一个线程特定的指针，通常是一个局部变量，来访问数据。由于根指针没有指向它，并且生产者线程的局部指针没有与其他线程共享，因此其他线程还看不到这些数据。

最后，当数据完成时，生产者将数据指针原子地存储在共享的根指针中。通常说生产者原子地发布数据，因此这种模式被称为发布协议。

消费者必须等待数据被发布：只要根指针为空，他们就没有事情可做。他们等待根指针变为非空（等待不必使用轮询，也可以使用通知机制）。一旦数据被发布，消费者线程可以通过根指针访问它。因为没有其他同步机制，一旦数据被发布，就没有线程可以修改数据（数据可能包含互斥锁或其他机制，允许其部分安全地修改）。

原子变量本身不足以保证这种模式没有数据竞争：所有线程不仅访问原子指针，还访问它指向的内存。这就是为什么我们需要特定的内存屏障：当发布数据时，生产者使用释放屏障不仅原子地初始化指针，还确保在指针上的原子写操作之前所做的所有内存修改都对读取指针新值的任何人可见。消费者使用获取屏障确保在读取指针新值之后对共享数据的任何操作都观察到数据发布时共享数据的最新状态。换句话说，如果你读取指针的值然后解引用它，你通常不知道你是否会得到指针指向的数据的最新值。但如果你使用获取屏障读取指针（并且指针是用释放屏障写入的），那么你可以确信你会读取（获取）最后写入（发布）的数据。释放和获取屏障共同保证消费者看到的共享数据与生产者在发布根指针中数据地址时的所见完全一致。

同样的模式可以用来发布线程间共享的更大数据结构的完成元素。例如，我们可以有一个生产者线程发布它用结果初始化了多少个数组元素：

```cpp
// Example 18
constexpr size_t N = ...;
Data data[N];     // Shared, not locked
std::atomic<size_t> size;
void produce() {
  for (size_t n = 0; n != N; ++n) {
    data[n] = ... results ...
    size.store(n, std::memory_order_release);
  }
}
void consume() {
  size_t n = 0;
  do {
    n = size.load(std::memory_order_acquire);
    ... n elements are safe to access ...
  } while (n < N - 1);
}
```

这个想法与前面的例子完全相同，只是我们使用数组中的索引而不是指针。在两种情况下，我们都有一个计算并发布数据的生产者线程，以及一个或多个等待数据发布的消费者线程。如果我们需要多个生产者，我们必须使用其他同步机制来确保它们不会在相同的数据上工作，例如我们刚刚看到的原子索引。

在具有多个生产者和消费者线程的程序中，我们通常必须结合使用几种同步模式。在下一个例子中，我们有一个大型的共享数据结构，它组织成一个指向各个元素的指针数组。几个生产者线程用结果填充这个数据结构；我们将使用原子索引来确保每个元素只由一个生产者处理：

```cpp
// Example 19
static constexpr size_t N = 1024;
struct Data { ... };
std::atomic<Data*> data[N] {};
std::atomic<size_t> size(0);     // Atomic index
void produce() {
  Data* p = new Data;
  ... compute *p ...
  const size_t s =
    size.fetch_add(1, std::memory_order_relaxed);
  data[s].store(p, std::memory_order_release);
}
```

我们的生成器计算结果，然后获取当前索引值，同时增加索引，以便下一个生成器不能获得相同的索引值。因此，数组槽`data[s]`是唯一为这个生成器线程保留的。这足以避免生产者之间的共享冲突，但消费者不能使用相同的索引来知道数组中已经有多少元素：索引在相应的数组元素初始化之前增加。对于消费者，我们使用发布协议：每个数组元素都是一个原子指针，直到数据发布之前保持为 null。消费者必须在可以访问数据之前等待指针变为非 null：

```cpp
// Example 19
void consumer() {
  for (size_t i = 0; i != N; ++i) {
    const Data* p =
      data[i].load(std::memory_order_acquire);
    if (!p) break; // No more data
    ... *p is safe to access ...
  }
}
```

在这个例子中，消费者一旦找到不准备好的数据元素就会停止。我们可以继续扫描数组：一些后续的元素可能已经准备好了，因为它们被另一个生产者线程填充。如果我们这样做，我们必须以某种方式记住回来处理我们遗漏的元素。正确的方法当然取决于我们需要解决的问题。

无锁编程的文献非常丰富，充满了（通常是）非常复杂的例子。我们展示的并发模式只是更复杂数据结构和数据同步协议的基本构建块。

在下一节中，我们将看到一些适用于此类数据结构或甚至整个程序及其主要组件设计的更高层次的模式。

# 并发设计模式和指南

设计和实现并发软件是困难的。即使是控制对共享数据访问的基本模式，如我们在上一节中看到的，也是复杂的，充满了微妙的细节。未能注意到这些细节通常会导致难以调试的数据竞争。为了简化编写并发程序的任务，编程社区提出了几项指南。所有这些指南都源于早期的灾难性经验，因此请认真对待这些指南。这些指南的核心是线程安全保证的概念。

## 线程安全保证

虽然这并不是一个模式，但这是一个范围更广的概念，并且是任何并发软件的关键设计原则之一。任何并发程序中的每个类、函数、模块或组件都应该指定它提供的线程安全保证，以及它对其使用的组件所要求的保证。

通常，一个软件组件可以提供三个级别的线程安全保证：

+   **强线程安全保证**：任何数量的线程都可以无限制地访问此组件，而不会遇到未定义的行为。对于一个函数，这意味着任何数量的线程都可以同时调用此函数（可能对参数有一些限制）。对于一个类，这意味着任何数量的线程都可以并发调用此类的成员函数。对于一个更大的组件，任何数量的线程都可以操作其接口（同样，可能有一些限制）。这样的组件、类和数据结构有时被称为线程安全。

+   (`const` 成员函数)。在任何时候，只有一个线程可以修改组件的状态，锁定或其他确保这种独占访问的方式是调用者的责任。这样的组件、类和数据结构有时被称为线程兼容，因为你可以使用适当的同步机制从它们构建并发程序。所有 STL 容器都提供这种级别的保证。

+   **无线程安全保证**：此类组件根本不能用于并发程序，有时被称为线程敌对。这些类和函数通常具有隐藏的全局状态，无法以线程安全的方式访问。

通过设计每个组件以提供一定的线程安全保证，我们可以将使整个程序线程安全这一难以处理的问题分解为一系列设计挑战，其中更复杂的组件利用简单组件提供的保证。这一过程的核心是事务接口的概念。

## 事务接口设计

事务接口设计理念非常简单：每个组件都应该有一个接口，使得每个操作都是一个原子事务。从程序其他部分的角度来看，操作要么尚未发生，要么已经完成。在操作期间，没有其他线程可以观察到组件的状态。这可以通过互斥锁或其他适合需求的同步方案来实现——特定的实现可以影响性能，但只要接口保证了事务处理，它就不是正确性的关键。

这个指南对于设计并发程序的数据结构非常有用。在这里，它如此重要，以至于普遍认为，不能设计一个不提供事务接口（至少不是一个有用的数据结构）的线程安全数据结构。例如，我们可以考虑一个队列。C++ 标准库提供了一个 `std::queue` 模板。与其他任何 STL 容器一样，它提供弱保证：只要没有线程调用任何非 `const` 方法，任意数量的线程都可以调用队列的 `const` 方法。或者，任何单个线程都可以调用一个非 `const` 方法。为了确保后者，我们必须使用外部互斥锁锁定对队列的所有访问。如果我们想追求这种方法，我们应该将队列和互斥锁组合在一个新的类中：

```cpp
template <typename T> class ts_queue {
  std::mutex m_;
  std::queue<T> q_;
  public:
  ts_queue() = default;
  ...
};
```

要将另一个元素推送到队列中，我们需要锁定互斥锁，因为 `push()` 成员函数会修改队列：

```cpp
template <typename T> class ts_queue {
  public:
  void push(const T& t) {
    std::lock_guard l(m_);
    q_.push(t);
  }
};
```

这完全符合我们的预期：任意数量的线程都可以调用 `push()`，每个元素将正好被添加到队列中一次（如果同时发生多个调用，顺序将是任意的，但这并发性的本质）。我们已经成功提供了强线程安全保证！

不幸的是，这种成功将是短暂的。让我们看看从队列中弹出元素需要什么。有一个成员函数 `pop()` 可以从队列中移除元素，因此我们可以用相同的互斥锁保护它：

```cpp
template <typename T> class ts_queue {
  public:
  void pop() {
    std::lock_guard l(m_);
    q_.pop();
  }
};
```

注意到这个函数不返回任何内容：它移除队列中最旧的元素并销毁它，但这并不是我们需要找出该元素是什么（或曾经是什么）的原因。为此，我们需要使用返回对最旧元素引用但不修改队列的 `front()` 函数。它是一个 `const` 成员函数，因此我们只需要在同时调用任何非 `const` 函数时锁定它；我们现在将忽略这种优化可能性，并始终锁定这个调用：

```cpp
template <typename T> class ts_queue {
  public:
  T& front() const {
    std::lock_guard l(m_);
    return q_.front();
  }
};
```

如果我们从多个线程调用 `front()` 而不调用任何其他函数，这种实现是次优的，但并不错误。

我们忽略了一个特殊情况：如果队列为空，你不应该调用 `pop()` 或 `front()` – 根据标准，这样做会导致未定义的行为。你如何知道从队列中弹出元素是否安全？你可以检查队列是否为空。这是一个另一个 `const` 成员函数，我们再次将过度保护它并锁定对它的每个调用：

```cpp
template <typename T> class ts_queue {
  public:
  bool empty() const {
    std::lock_guard l(m_);
    return q_.empty();
  }
};
```

现在，底层 `std::queue` 的每个成员函数都由互斥锁保护。我们可以从任意数量的线程中调用它们，并保证在任何时候只有一个线程可以访问队列。技术上，我们已经实现了强保证。不幸的是，这并不非常实用。

为了理解原因，让我们考虑从队列中移除一个元素的过程：

```cpp
ts_queue<int> q;
int i = 0;
if (!q.empty()) {
  i = q.front();
  q.pop();
}
```

在单线程上这工作得很好，但我们并不需要互斥锁来处理它。当我们有两个线程时，一个线程将新元素推入队列，另一个线程从队列中取出元素，它仍然（大多数情况下）可以正常工作。让我们考虑当两个线程都试图各自弹出队列中的一个元素时会发生什么。首先，它们都调用了`empty()`。假设队列不为空，并且两次调用都返回`true`。然后，它们都调用了`front()`。由于两个线程都没有调用过`pop()`，它们都得到了相同的队首元素。这不是我们想要的结果，如果我们希望每个线程都能从队列中弹出一个元素的话。最后，两个线程都调用了`pop()`，队列中移除了两个元素。其中有一个元素我们从未见过，也永远不会再见到，所以我们丢失了一些已经入队的资料。

但这并不是唯一可能出错的方式。如果队列中只有一个元素会发生什么？两次对`empty()`的调用仍然返回`true`——一个只有一个元素的队列不是空的。两次对`front()`的调用仍然返回（相同的）队首元素。第一次对`pop()`的调用成功，但第二次调用是未定义的行为，因为队列现在为空了。也有可能一个线程在另一个线程调用`front()`之前调用`pop()`，但在调用`empty()`之后。在这种情况下，第二次对`front()`的调用也是未定义的。

我们有一个既安全又毫无用处的数据结构。显然，线程安全保证是不够的。我们还需要一个不会暴露我们于未定义行为的接口，而实现这一点的唯一方法是在单个临界区中执行弹出操作的所有三个步骤（`empty()`、`front()`和`pop()`），即在调用之间不释放互斥锁。除非我们希望调用者提供自己的互斥锁，否则实现这一点的唯一方法就是改变我们的`ts_queue`类的接口：

```cpp
// Example 20
template <typename T> class ts_queue {
  std::queue<T> q_;
  std::mutex m_;
  public:
  ts_queue() = default;
  template <typename U> void push(U&& u) {
    std::lock_guard l(m_);
    q_.push(std::forward<U>(u));
  }
  std::optional<T> pop() {
    std::lock_guard l(m_);
    if (q_.empty()) return {};
    std::optional<T> res(std::move(q_.front()));
    q_.pop();
    return res;
 }
};
```

`push()`函数与之前相同（我们使参数类型更加灵活，但这与线程安全无关）。我们不需要改变推送操作的原因是它已经是事务性的：在操作结束时，队列比操作开始时多了一个元素，队列的其他状态保持不变。我们只是通过互斥锁来保护它，使其原子化（没有其他正确使用相同互斥锁的线程可以观察到我们的队列在其过渡的非不变状态）。

`pop()`操作是事务性接口看起来非常不同的地方。为了提供一个有意义的线程安全性保证，我们必须提供一个返回前端元素给调用者并从队列中原子性地移除它的操作：其他线程不应该能够看到相同的前端元素，因此，我们必须使用相同的互斥锁锁定原始队列上的`front()`和`pop()`。我们还必须考虑队列可能为空且我们没有前端元素可以返回给调用者的可能性。在这种情况下我们返回什么？如果我们决定通过值返回前端元素，我们就必须默认构造这个值（或者返回一些其他商定的值，表示“没有元素”）。在 C++17 中，更好的方法是返回一个包含前端元素的`std::optional`，如果有的话。

现在`pop()`和`push()`都是原子性和事务性的：我们可以从任意多的线程中调用这两个方法，结果总是良好定义的。

你可能会想知道为什么`std::queue`一开始没有提供这种事务性接口。首先，STL 是在线程进入标准之前设计的。但另一个非常重要的原因是，队列接口受到了提供异常安全性的需求的影响。异常安全性是保证在抛出异常时对象保持良好定义状态的保证。在这里，原始的队列接口做得很好：`empty()`只是返回大小，不会抛出异常，`front()`返回前端元素的引用，也不会抛出异常，最后`pop()`调用前端元素的析构函数，这通常也不会抛出异常。当然，当访问前端元素时，调用者的代码可能会抛出异常（例如，如果调用者需要将前端元素复制到另一个对象中），但预期调用者会处理这种情况。无论如何，队列本身保持在一个良好定义的状态。

我们的线程安全队列，然而，存在一个异常安全性问题：将队列的前端元素复制以返回给调用者的代码现在位于`pop()`函数内部。如果在构造局部`std::optional`变量`res`期间抛出异常，我们可能没问题。然而，如果在将结果返回给调用者时抛出异常（这可能通过移动或复制发生），那么`pop()`操作已经完成，因此我们将丢失刚刚从队列中弹出的元素。

在线程安全和异常安全之间的这种紧张关系通常是不可避免的，在设计用于并发程序的线程安全数据结构时必须考虑。无论如何，必须重申，设计线程安全数据结构或更大的模块的唯一方法是要确保每个接口调用都是一个完整的交易：任何条件定义的步骤必须与确保满足这些条件所需的操作一起打包成一个单一的交易调用。然后，整个调用应该由互斥锁或其他确保无竞争的独占访问的方式保护。

设计线程安全数据结构通常非常困难，尤其是如果我们想要良好的性能（如果我们不追求并发，那么并行的意义何在呢？）。这就是为什么利用任何使用限制或特殊要求来限制这些数据结构的使用方式非常重要。在下一节中，我们将看到这种限制的一个常见案例。

## 具有访问限制的数据结构

设计线程安全数据结构如此困难，以至于我们应该寻找任何机会简化要求和实现。如果你现在不需要任何场景，想想如果你不支持该场景，你是否可以使你的代码更简单。一个明显的例子是，一个由单个线程构建的数据结构（不需要线程安全保证），然后变为不可变，并被许多作为读者的线程访问（一个弱保证就足够了）。例如，任何 STL 容器都可以以这种方式运行。我们仍然需要确保在容器被填充数据时，没有读者可以访问容器，但这可以通过一个屏障或条件轻松完成。这是一个非常有用但相当简单的情况。我们还能利用哪些其他限制？

在本节中，我们考虑一个相当常见且允许使用更简单数据结构的特定用例。具体来说，我们考察了当某个数据结构仅由两个线程访问的情况。一个线程是生产者，它向数据结构添加数据。另一个线程是消费者，它从数据结构中移除数据。两个线程都会修改数据结构，但方式不同。这种情况相当常见，并且往往允许非常专业且非常高效的数据结构实现。这或许值得被认可为并发设计的设计模式，并且它已经有一个普遍认可的名字：“单生产者单消费者数据结构。”

在本节中，我们将看到一个单生产者单消费者队列的例子。这是一个经常与一个生产者和一个消费者线程一起使用的数据结构，但我们在这里探讨的思想也可以用来设计其他数据结构。这个队列的主要区别特征将是它是无锁的：它根本不包含互斥锁，因此我们可以期望从它那里获得更高的性能。

队列是基于一个固定大小的数组构建的，因此，与普通队列不同，它不能无限增长（这是用于简化无锁数据结构的一个常见限制）：

```cpp
// Example 21
template <typename T, size_t N> class ts_queue {
  T buffer_[N];
  std::atomic<size_t> back_{0};
  std::atomic<size_t> front_{N - 1};
  ...
};
```

在我们的例子中，我们默认构造数组中的元素。如果这不可取，我们也可以使用一个正确对齐的未初始化缓冲区。所有对队列的访问都由两个原子变量`back_`和`front_`决定。前者是我们将新元素推入队列时将要写入的数组元素的索引。后者是我们需要从队列中弹出元素时将要读取的数组元素的索引。范围`[front_`, `back_]`内的所有数组元素都填充了队列上的当前元素。请注意，这个范围可以绕过缓冲区的末尾：在使用了`buffer_[N-1]`元素之后，队列并没有用完空间，而是从`buffer_[0]`重新开始。这被称为**循环缓冲区**。

我们如何使用这些索引来管理队列？让我们从推入操作开始：

```cpp
// Example 21
template <typename T, size_t N> class ts_queue {
  public:
  template <typename U> bool push(U&& u) {
    const size_t front =
      front_.load(std::memory_order_acquire);
    size_t back = back_.load(std::memory_order_relaxed);
    if (back == front) return false;
    buffer_[back] = std::forward<U>(u);
    back_.store((back + 1) % N, std::memory_order_release);
    return true;
  }
};
```

当然，我们需要读取`back_`的当前值：这是我们即将写入的数组元素的索引。我们只支持一个生产者，只有生产者线程可以增加`back_`，因此在这里我们不需要特别的预防措施。然而，我们需要小心避免覆盖队列中已经存在的任何元素。为此，我们必须检查`front_`的当前值（我们可以在读取`back_`之前或之后读取它，这没有关系）。如果我们即将覆盖的`buffer_[back]`元素也是队首元素，那么队列已满，`push()`操作将失败（请注意，对于这个问题还有另一种常用的解决方案：如果队列已满，最老的元素将被静默覆盖并丢失）。在存储新元素后，我们原子性地增加`back_`的值，以通知消费者这个槽位现在可以读取。因为我们正在发布这个内存位置，所以我们必须使用释放屏障。此外，请注意模运算：在达到数组元素`N-1`之后，我们将循环回到元素 0。

接下来，让我们看看`pop()`操作：

```cpp
// Example 21
template <typename T, size_t N> class ts_queue {
  public:
  std::optional<T> pop() {
    const size_t back =
      back_.load(std::memory_order_acquire);
    const size_t front =
     (front_.load(std::memory_order_relaxed) + 1) % N;
    if (front == back) return {};
    std::optional<T> res(std::move(buffer_[front]));
    front_.store(front, std::memory_order_release);
    return res;
  }
};
```

再次强调，我们需要读取`front_`和`back_`两个部分：`front_`是我们即将读取的元素的索引，只有消费者可以前进这个索引。另一方面，`back_`是确保我们实际上有一个元素可以读取所必需的：如果前一个和后一个索引相同，那么队列就是空的；再次强调，我们使用`std::optional`来返回可能不存在的一个值。在读取`back_`时，我们必须使用获取屏障来确保我们看到生产者线程写入数组中的元素值。最后，我们前进`front_`以确保我们不会再次读取相同的元素，并使这个数组槽位对生产者线程可用。

这里有几个必须指出的微妙细节。读取`back_`和`front_`不是在一个单一的事务中完成的（它不是原子的）。特别是，如果生产者首先读取`front_`，那么当它读取`back_`并与两个值进行比较时，消费者可能已经前进`front_`了。这并不会使我们的数据结构出错。最坏的情况是，生产者可能会报告队列已满，而实际上它已经不再满了。我们可以原子地读取这两个值，但这只会降低性能，调用者仍然需要处理队列已满的情况。同样，当`pop()`报告队列为空时，到调用完成时它可能已经不再为空了。这些是并发不可避免的复杂性：每个操作都反映了数据在某个时间点的状态。当调用者获取返回值并分析它时，数据可能已经发生了变化。

另一个值得注意的细节是对队列元素生命周期的谨慎管理。我们在数组中默认构造所有元素，因此在`push()`期间从调用者将数据传输到队列的正确方式是通过复制或移动赋值（`std::forward`可以完成这两者）。另一方面，一旦`pop()`将值返回给调用者，我们就不再需要那个值了，所以这里的正确操作是移动，首先移动到`optional`中，然后移动到调用者的返回值对象中。请注意，移动一个对象与销毁它不同；实际上，被移动的数组元素直到队列本身被销毁时才被销毁。如果一个数组元素被重用，它会被复制或移动赋值一个新的值，而赋值是可以在移动后的对象上安全执行的三种操作之一（第三种是析构函数，我们最终也会调用它）。

单生产者单消费者模式是一种常见的模式，它允许程序员极大地简化他们的并发数据结构。还有其他模式，你可以在专门针对并发数据结构的书籍和论文中找到它们。所有这些模式最终都是为了帮助你编写在多线程访问时能够正确且高效执行的数据结构。然而，我们必须继续前进，最终解决使用这些线程来完成一些有用工作的问题。

# 并发执行模式

我们必须学习的下一个并发模式组是执行模式。这些模式用于组织在多个线程上完成的计算。你会发现，就像我们之前看到的同步模式一样，所有这些都是低级模式：大多数实际问题的解决方案必须将这些模式组合成更大、更复杂的结构。这并不是因为 C++不适合这样的更大设计；实际上，情况正好相反：在 C++中有许多方法来实现，例如线程池，对于每个具体的应用，都有一个在性能和功能方面都理想的版本。这就是为什么很难将这些更完整的解决方案描述为模式：虽然它们解决的问题很常见，但解决方案有很大的不同。但所有这些设计都有许多挑战需要解决，而解决这些挑战的解决方案通常反复使用相同的工具，因此我们至少可以将这些更基本的挑战和它们的常见解决方案描述为设计模式。

## 活动对象

我们将要看到的第一个并发执行模式是活动对象。活动对象通常封装要执行的代码、执行所需的数据以及执行代码所需的控制流。这种控制流可能只是一个对象启动并连接的单独线程。在大多数情况下，我们不会为每个任务启动一个新的线程，所以活动对象会有某种方式在其多线程执行器（如线程池）上运行其代码。从调用者的角度来看，活动对象是一个调用者构建的对象，用数据初始化，然后告诉对象执行自己，执行是异步发生的。

基本的活动对象看起来像这样：

```cpp
// Example 22
class Job {
  ... data ...
  std::thread t_;
  bool done_ {};
  public:
  Job(... args ...) { ... initialize data ... }
  void operator()() {
    t_ = std::thread([this](){ ... computations ... }
  );
  }
  void wait() {
    if (done_) return;
    t_.join();
    done_ = true;
  }
  ~Job() { wait(); }
  auto get() { this->wait(); return ... results ...; }
};
Job j(... args ...);
j();     // Execute code on a thread
... do other work ...
std::cout << j.get();  // Wait for results and print them
```

在这里展示的最简单的情况下，活动对象包含一个用于异步执行代码的线程。在大多数实际情况下，你会使用一个执行器，它在它管理的线程之一上调度工作，但这使我们陷入了实现特定的细节。执行开始于调用`operator()`时；我们也可以通过在构造函数中调用`operator()`来使对象在构造时立即执行。在某个时刻，我们必须等待结果。如果我们使用一个单独的线程，我们可以在那时连接线程（并且要注意，如果调用者再次调用`wait()`，不要尝试两次连接它）。如果对象代表的是一个线程池或某些其他执行器中的任务，而不是线程，我们会进行必要的清理工作。

正如你所见，一旦我们确定了一种特定的异步执行代码的方式，编写具有不同数据和代码的活动对象就变得相当重复。没有人像我们刚才那样编写活动对象，我们总是使用某种通用的可重用框架。实现此类框架有两种一般方法。第一种使用继承：基类执行样板工作，而派生类包含独特的任务特定数据和代码。继续使用我们简单的活动对象方法，我们可以将基类编写如下：

```cpp
// Example 23
class Job {
  std::thread t_;
  bool done_ {};
  virtual void operator()() = 0;
  public:
  void wait() {
    if (done_) return;
    t_.join();
    done_ = true;
  }
  void run() {
    t_ = std::thread([this](){ (*this)(); });
  }
  virtual ~Job() { wait(); }
};
```

基础对象 `Job` 包含实现异步控制流所需的一切：用于仅一次连接线程的线程和状态标志。它还定义了通过调用非虚函数 `run()` 来执行代码的方式。在线程上执行的代码必须由派生对象通过重载 `operator()` 提供。请注意，只有 `run()` 是公开的，而 `operator()` 则不是：这就是非虚语法的实际应用（我们在 *第十四章*，*模板方法模式和* *非虚语法*）中看到了它）。

派生对象是针对特定问题的，但通常看起来是这样的：

```cpp
// Example 23
class TheJob final : public Job {
  ... data ...
  void operator()() override { ... work ... }
  public:
  TheJob(... args ...) {
    ... initialize data ...
    this->run();
  }
  auto get() { this->wait(); return ... results ...; }
};
```

这里的唯一细微差别是在派生对象构造函数结束时对 `run()` 的调用。这不是必需的（我们可以稍后自己执行活动对象）但如果我们想让构造函数运行它，就必须在派生类中完成。如果我们从基类构造函数开始启动线程和异步执行，那么我们将在线程上的执行（`operator()`）和派生类构造函数中继续的其余初始化之间产生竞争。出于同样的原因，从构造函数开始执行的活动对象不应再次派生；我们通过使对象成为最终类来确保这一点。

使用我们的活动对象非常简单：我们创建它，对象开始在后台（在单独的线程）执行代码，当我们需要结果时，我们请求它（这可能涉及等待）：

```cpp
// Example 23
TheJob j1(... args ...);
TheJob j2(... args ...);
... do other stuff ...
std::cout << "Results: " << j1.get() << " " << j2.get();
```

如果你曾经在任何 C++ 并发代码中编写过代码，那么你肯定已经使用过活动对象了：`std::thread` 是一个活动对象，它让我们能够在单独的线程上执行任意代码。对于 C++，有并发库，其中线程是一个基础对象，所有具体的线程都从中派生出来。但 C++ 标准线程并没有选择这种方法。它遵循实现可重用活动对象的第二种方式：类型擦除。如果你需要熟悉它，请重新阅读 *第六章*，*理解类型擦除*。尽管 `std::thread` 本身就是一个类型擦除的活动对象，但我们还是将实现自己的，以展示设计（标准库代码相当难以阅读）。这次，没有基类。框架由一个单一类提供：

```cpp
// Example 24
class Job {
  bool done_ {};
  std::function<void()> f_;
  std::thread t_;
  public:
  template <typename F> explicit Job(F&& f) :
    f_(f), t_(f_) {}
  void wait() {
     if (done_) return;
     t_.join();
     done_ = true;
  }
  ~Job() { wait(); }
};
```

要实现类型擦除的可调用对象，我们使用`std::function`（我们也可以使用*第六章*，*理解类型擦除*中更有效的实现之一，或者按照相同的方法自己实现类型擦除）。调用者提供的要在线程上执行的代码来自构造函数参数中的可调用对象`f`。请注意，类成员的顺序非常重要：异步执行是在线程`t_`初始化后立即开始的，因此其他数据成员，特别是可调用对象`f_`，必须在那时之前初始化。

要使用这种风格的主动对象，我们需要提供一个可调用对象。它可以是 lambda 表达式或命名对象，例如：

```cpp
// Example 24
class TheJob {
  ... data ...
  public:
  TheJob(... args ...) { ... initialize data ... }
  void operator()() { // Callable!
    ... do the work ...
  }
};
Job j(TheJob(... args ...));
j.wait();
```

注意，在这个设计中，没有简单的方法可以直接访问可调用对象`TheJob`的数据成员，除非它被创建为一个命名对象。因此，结果通常是通过构造函数传入的引用参数返回的（这与我们使用`std::thread`的方式相同）：

```cpp
// Example 24
class TheJob {
  ... data ...
  double& res_; // Result
  public:
  TheJob(double& res, ... args ...) : res_(res) {
    ... initialize data ...
  }
  void operator()() { // Callable!
    ... do the work ...
    res_ = ... result ...
  }
};
double res = 0;
Job j(TheJob(res, ... args ...));
j.wait();
std::cout << res;
```

主动对象可以在每个并发 C++程序中找到，但它们的一些用法是常见和专门的，因此被认可为它们自己的并发设计模式。我们现在将看到这些模式中的几个。

## 反应器对象模式

反应器模式通常用于事件处理或响应服务请求。它解决了一个特定问题，即我们有多条针对某些操作的请求，这些请求由多个线程发出；然而，这些操作的本质是，至少部分操作必须在某个线程上执行或进行同步。反应器对象是处理这些请求的对象：它接受来自多个线程的请求并执行它们。

这里是一个反应器的例子，它可以接受请求以使用调用者提供的输入执行特定的计算，并将结果存储起来。请求可以来自任意数量的线程。每个请求都会在结果数组中分配一个槽位——这就是必须在所有线程之间同步的部分。在槽位分配后，我们可以并发地进行计算。为了实现这个反应器，我们将使用原子索引为每个请求分配唯一的数组槽位：

```cpp
// Example 25
class Reactor {
  static constexpr size_t N = 1024;
  Data data_[N] {};
  std::atomic<size_t> size_{0};
  public:
  bool operator()(... args ...) {
    const size_t s =
      size_.fetch_add(1, std::memory_order_acq_rel);
    if (s >= N) return false;  // Array is full
    data_[s] = ... result ...;
    return true;
  }
  void print_results() { ... }
};
```

对`operator()`的调用是线程安全的：任意数量的线程可以同时调用此操作符，并且每个调用都会将计算结果添加到下一个数组槽位，而不会覆盖其他调用产生的任何数据。要从对象中检索结果，我们可以等待所有请求完成，或者实现另一种同步机制，例如发布协议，以使对`operator()`和`print_results()`的调用在彼此之间是线程安全的。

注意，通常，反应器对象异步处理请求：它有一个单独的线程来执行计算，并且有一个队列来将所有请求通道到一个线程。我们可以通过结合我们之前看到的几个模式来构建这样的反应器，例如，我们可以向基本反应器添加一个线程安全的队列来得到一个异步反应器（我们很快将看到一个这样的设计示例）。

到目前为止，我们专注于启动和执行工作，然后等待工作完成。下一个模式专注于处理异步任务的完成。

## Proactor 对象模式

Proactor 模式用于通过一个或多个线程的请求来执行异步任务，通常是长时间运行的任务。这听起来很像反应器，但区别在于任务完成时发生的情况：在反应器的情况下，我们只需要等待工作完成（等待可以是阻塞的或非阻塞的，但在所有情况下，调用者都启动了完成检查）。Proactor 对象将每个任务与一个回调关联，当任务完成时，回调异步执行。反应器和 Proactor 是处理并发任务完成的同步和异步解决方案。

Proactor 对象通常有一个任务队列，用于异步执行任务，或者使用另一个执行器来调度这些任务。每个任务都提交一个回调，通常是可调用的。当任务完成时执行回调；通常，执行任务的同一线程也会调用回调。由于回调总是异步的，如果它需要修改任何共享数据（例如，任何由提交任务到 Proactor 的线程访问的数据），必须以线程安全的方式访问。

这里是一个使用上一节中线程安全队列的 Proactor 对象的示例。在这个例子中，每个任务接受一个整数作为输入并计算一个 `double` 结果：

```cpp
// Example 26
class Proactor {
  using callback_t = std::function<void(size_t, double)>;
  struct op_task {
    size_t n;
    callback_t f;
  };
  std::atomic<bool> done_{false}; // Must come before t_
  ts_queue<op_task> q_;           // Must come before t_
  std::thread t_;
  public:
  Proactor() : t_([this]() {
    while (true) {
      auto task = q_.pop();
      if (!task) {                // Queue is empty
        if (done_.load(std::memory_order_relaxed)) {
          return;                 // Work is done
        }
        continue;                 // Wait for more work
      }
      ... do the work ...
      double x = ... result ...
      task->f(n, x);
    } // while (true)
  }) {}
  template <typename F>
  void operator()(size_t n, F&& f) {
    q_.push(op_task{n, std::forward<F>(f)});
  }
  ~Proactor() {
    done_.store(true, std::memory_order_relaxed);
    t_.join();
  }
};
```

队列存储工作请求，这些请求由输入和可调用对象组成；任何数量的线程都可以调用 `operator()` 将请求添加到队列中。一个更通用的 Proactor 可能会接受一个可调用对象作为工作请求，而不是将计算编码到具体的 Proactor 对象中。Proactor 按顺序在一个线程上执行所有请求。当请求的计算完成时，线程调用回调并将结果传递给它。这就是我们可能使用这样的 Proactor 对象的方式：

```cpp
// Example 26
Proactor p;
for (size_t n : ... all inputs ...) {
  p(n, [](double x) { std::cout << x << std::endl; });
}
```

注意，我们的 Proactor 在一个线程上执行所有回调，主线程不做任何输出。否则，我们就必须用互斥锁来保护 `std::cout`。

Proactor 模式用于执行异步事件，并在这些事件发生时执行附加操作（回调）。在本节中我们探索的最后一个模式不执行任何操作，而是用于对外部事件做出反应。

## 监视器模式

当我们需要观察或监控某些条件并对某些事件做出响应时，使用监视器模式。通常，监视器在自己的线程上运行，该线程大部分时间处于休眠或等待状态。线程可以通过通知或简单地通过时间的流逝而被唤醒。一旦唤醒，监视器对象将检查它被分配观察的系统状态。如果满足指定的条件，它可能会采取某些行动，然后线程返回等待状态。

我们将看到一种使用超时的监视器实现；具有条件变量的监视器可以使用相同的方法实现，但使用本章前面看到的等待通知模式。

首先，我们需要一些可以监控的东西。让我们假设我们有几个生产者线程执行一些计算并将结果存储在一个数组中，使用原子索引：

```cpp
// Example 27
static constexpr size_t N = 1UL << 16;
struct Data {... data ... };
Data data[N] {};
std::atomic<size_t> index(0);
void produce(std::atomic<size_t>& count) {
  for (size_t n = 0; ; ++n) {
    const size_t s =
      index.fetch_add(1, std::memory_order_acq_rel);
    if (s >= N) return;
    const int niter = 1 << (8 + data[s].n);
    data[s] = ... result ...
    count.store(n + 1, std::memory_order_relaxed);
  }
}
```

我们的生产者还将线程计算的结果计数存储在传递给它的`count`变量中。以下是启动生产者线程的方式：

```cpp
// Example 27
std::thread t[nthread];
std::atomic<size_t> work_count[nthread] = {};
for (size_t i = 0; i != nthread; ++i) {
  t[i] = std::thread(produce, std::ref(work_count[i]));
}
```

每个线程都有一个结果计数，因此每个生产者都有自己的计数来递增。那么，为什么我们使计数原子化呢？因为计数也是我们将要监控的内容：我们的监视器线程将定期报告完成的工作量。因此，每个工作计数被两个线程访问，即生产者和监视器，我们需要使用原子操作或互斥锁来避免数据竞争。

监视器将是一个独立的线程，它时不时地醒来，读取结果计数的值，并报告工作进度：

```cpp
// Example 27
std::atomic<bool> done {false};
std::thread monitor([&]() {
  auto print = [&]() { ... print work_count[] ... };
  std::cout << "work counts:" << std::endl;
  while (!done.load(std::memory_order_relaxed)) {
    std::this_thread::sleep_for(
      std::chrono::duration<double, std::milli>(500));
    print();
  }
  print();
});
```

监视器可以在生产者线程之前启动，或者在我们需要监控工作进度时启动，它将报告每个生产者线程计算的结果数量，例如：

```cpp
work counts:
1096 1083 957 1046 1116 -> 5298/65536
2286 2332 2135 2242 2335 -> 11330/65536
...
13153 13061 13154 12979 13189 -> 65536/65536
13153 13061 13154 12979 13189 -> 65536/65536
```

在这里，我们使用了五个线程来计算总共 64K 个结果，监视器报告了每个线程的计数和总结果计数。要关闭监视器，我们需要设置`done`标志并加入监视器线程：

```cpp
// Example 27
done.store(true, std::memory_order_relaxed);
monitor.join();
```

监视器模式的另一种常见变体是，我们不是等待计时器，而是等待一个条件。这种监视器是基本监视器和我们在本章前面看到的等待通知模式的组合。

并发编程社区已经提出了许多其他用于解决与并发相关常见问题的模式；大多数这些模式都可以用于 C++程序，但它们并不特定于 C++。有一些 C++特有的功能，如原子变量，影响了我们实现和使用这些模式的方式。本章的示例应该足以指导你将任何其他并发模式适应到 C++中。

执行模式的描述基本上完成了对 C++并发模式的简要研究。在你翻到最后一页之前，我想向你展示一种完全不同类型的并发模式，这种模式刚刚进入 C++。

# C++中的协程模式

协程是 C++ 中非常新的特性：它们是在 C++20 中引入的，目前的状态是构建库和框架的基础，而不是你应该直接在应用程序代码中使用的特性。这是一个复杂的特性，包含许多细微的细节，需要整整一章的篇幅来解释它（我的书《编写高效程序的艺术》中就有这样的章节）。简而言之，协程是可以暂停和恢复自己的函数。它们不能被强制暂停，协程会继续执行直到它自己暂停。它们用于实现所谓的协作多任务，在这种多任务中，多个执行流自愿地将控制权交给彼此，而不是被操作系统强制抢占。

本章中我们看到的每一个执行模式，以及更多，都可以使用协程来实现。然而，现在还过早地说这将成为 C++ 中协程的常见用法，所以我们不能确定“生产者协程”是否会成为一种模式。不过，协程的一个应用正在成为 C++ 中的一个新模式：协程生成器。

当我们想要将通常使用复杂循环完成的某些计算重写为迭代器时，这种模式就会发挥作用。例如，假设我们有一个三维数组，我们想要遍历它的所有元素并对它们进行一些计算。这用循环来做很容易：

```cpp
size_t*** a; // 3D array
for (size_t i = 0; i < N1; ++i) {
  for (size_t j = 0; j < N2; ++j) {
    for (size_t k = 0; k < N3; ++k) {
      ... do work with a[i][j][k] ...
    }
  }
}
```

但以这种方式编写可重用代码是困难的：如果我们需要自定义对每个数组元素执行的工作，我们必须修改内部循环。如果我们有一个遍历整个三维数组的迭代器会容易得多。不幸的是，为了实现这个迭代器，我们必须将循环颠倒过来：首先，我们将 `k` 增加直到它达到 `N3`；然后，我们将 `j` 增加 1 并回到增加 `k`，依此类推。结果是代码非常复杂，许多程序员不得不依靠手指计数来避免一次性错误：

```cpp
// Example 28
class Iterator {
  const size_t N1, N2, N3;
  size_t*** const a;
  size_t i = 0, j = 0, k = 0;
  bool done = false;
  public:
  Iterator(size_t*** a, size_t N1, size_t N2, size_t N3) :
    N1(N1), N2(N2), N3(N3), a(a) {}
  bool next(size_t& x) {
    if (done) return false;
    x = a[i][j][k];
    if (++k == N3) {
      k = 0;
      if (++j == N2) {
        j = 0;
        if (++i == N1) return (done = true);
      }
    }
    return true;
  }
};
```

我们甚至走了一个捷径，给我们的迭代器提供了一个非标准的接口：

```cpp
// Example 28
Iterator it(a, N1, N2, N3);
size_t val;
while (it.next(val)) {
  ... val is the current array element ...
}
```

如果我们想要符合 STL 迭代器接口，实现过程会更加复杂。

这种问题，比如我们的嵌套循环在执行过程中必须暂停，以便调用者可以执行一些任意代码并恢复暂停的函数，非常适合协程。确实，一个产生与我们的迭代器相同序列的协程看起来非常简单和自然：

```cpp
// Example 28
generator<size_t>
coro(size_t*** a, size_t N1, size_t N2, size_t N3) {
  for (size_t i = 0; i < N1; ++i) {
    for (size_t j = 0; j < N2; ++j) {
      for (size_t k = 0; k < N3; ++k) {
        co_yield a[i][j][k];
      }
    }
  }
}
```

就这样；我们有一个函数，它接受遍历 3D 数组所需的参数，一个常规的嵌套循环，并且我们对每个元素执行一些操作。秘密在于最内层的行，其中“一些操作”发生：C++20 关键字 `co_yield` 暂停协程并返回值 `a[i][j][k]` 给调用者。它与 `return` 操作符非常相似，但 `co_yield` 并不会永久退出协程：调用者可以恢复协程，并且执行从 `co_yield` 之后的下一行继续。

使用这种协程的方法也很直接：

```cpp
// Example 28
auto gen = coro(a, N1, N2, N3);
while (true) {
  const size_t val = gen();
  if (!gen) break;
  ... val is the current array element ...
}
```

协程的魔法发生在由协程返回的生成器对象内部。其实现方式远非简单，如果你想要自己编写，你必须成为 C++ 协程的专家（通过阅读另一本书或文章来实现）。你可以在 *示例 28* 中找到一个非常简单的实现，并且，在协程的良好参考手册的帮助下，你可以逐行理解其内部工作原理。幸运的是，如果你只想编写像之前展示的那样简单的代码，你实际上并不需要学习协程的细节：有几个开源库提供了如生成器（接口略有不同）之类的实用类型，并且，在 C++23 中，`std::generator` 将被添加到标准库中。

虽然使用循环和 `co_yield` 编写协程确实比迭代器的复杂倒置循环更容易，但这种便利的代价是什么？显然，你必须要么编写一个生成器，要么在库中找到一个生成器，但一旦完成，协程还有其他缺点吗？一般来说，协程比常规函数涉及更多的工作，但生成的代码的性能很大程度上取决于编译器，并且可能会因为代码看似微不足道的更改而变化（就像任何编译器优化一样）。协程仍然相当新颖，编译器还没有为它们提供全面的优化。话虽如此，协程的性能可以与手工编写的迭代器相媲美。对于我们的 *示例 28*，当前（在撰写本文时）的 Clang 17 版本给出了以下结果：

```cpp
Iterator time: 9.20286e-10 s/iteration
Generator time: 6.39555e-10 s/iteration
```

另一方面，GCC 13 给了迭代器一个优势：

```cpp
Iterator time: 6.46543e-10 s/iteration
Generator time: 1.99748e-09 s/iteration
```

我们可以期待编译器在将来能更好地优化协程。

当我们想要生成的值序列没有预先限制，并且我们只想在需要时生成新元素（懒生成器）时，协程生成器的另一种变体是有用的。同样，协程的优势在于从循环内部向调用者返回结果的简单性。

这里是一个简单的随机数生成器，实现为一个协程：

```cpp
// Example 29
generator<size_t> coro(size_t i) {
  while (true) {
    constexpr size_t m = 1234567890, k = 987654321;
    for (size_t j = 0; j != 11; ++j) {
      if (1) i = (i + k) % m; else ++i;
    }
    co_yield i;
  }
}
```

这个协程永远不会结束：它会挂起自己以返回下一个伪随机数`i`，每次它被恢复时，执行都会跳回无限循环。再次强调，生成器是一个相当复杂的对象，有很多样板代码，你最好从库中获取（或者等待 C++23）。但一旦完成，生成器的使用就非常简单：

```cpp
// Example 29
auto gen = coro(42);
size_t random_number = gen();
```

每次调用`gen()`，你都会得到一个新的随机数（由于我们实现了一个最古老和最简单的伪随机数生成器，所以质量相当差，所以请将此示例仅用于说明）。生成器可以调用任意多次；当它最终被销毁时，协程也会被销毁。

在未来几年中，我们可能会看到更多利用协程的设计模式。目前，生成器是唯一确立的模式，而且刚刚确立，因此，在本书的 C++设计模式最后一章中，加入我们模式工具箱的最新补充是合适的。

# 摘要

在本章中，我们探讨了开发并发软件的常见 C++解决方案。与之前我们研究过的所有内容相比，这是一个非常不同类型的问题。我们在这里的主要关注点是正确性，特别是通过避免数据竞争，以及性能。同步模式是控制对共享数据访问的标准方式，以避免未定义的行为。执行模式是线程调度器和异步执行器的基本构建块。最后，并发设计的高级模式和指南是我们，程序员，在试图思考所有可能同时发生的事情之前、之后或同时发生的事情时保持理智的方法。

# 问题

1.  什么是并发？

1.  C++如何支持并发？

1.  什么是同步设计模式？

1.  什么是执行设计模式？

1.  对于并发程序的设计和架构，应该遵循哪些总体指南？

1.  什么是事务接口？

# 评估

# 第一章，继承和多态简介

1.  对象和类是 C++程序的基本构建块。通过将数据和算法（*代码*）组合成一个单一单元，C++程序表示了它所模拟的系统组件，以及它们的交互。

1.  公共继承表示对象之间的*is-a*关系——派生类的对象可以像基类对象一样使用。这种关系意味着基类的接口，包括其不变性和限制，也是派生类的一个有效接口。与公共继承不同，私有继承没有关于接口的说明。它表达的是*has-a*或*is implemented in terms of*关系。派生类重用了基类提供的实现。在大多数情况下，可以通过组合实现相同的效果。在可能的情况下应优先选择组合；然而，空基类优化和（较少见）虚方法覆盖是使用私有继承的有效理由。

1.  C++中的多态对象是一个其行为取决于其类型且在编译时（至少在请求行为的相关点）类型未知的对象。如果一个对象被引用为基类对象，并且它确实是其派生类的类型，那么它可以表现出派生类的行为。在 C++中，多态行为是通过虚函数实现的。

1.  动态转换在运行时验证转换的目标类型是否有效：它必须是对象的实际类型（对象创建时使用的类型）或其基类型之一。正是检查对象的所有可能基类型的这部分使得动态转换变得昂贵。

# 第二章，类和函数模板

1.  模板不是一种类型；它是一个为具有相似结构的许多不同类型提供服务的*工厂*。模板是用泛型类型编写的；用具体类型替换这些泛型类型将生成从模板生成的类型。

1.  存在类模板、函数模板和变量模板。每种模板生成相应的实体——函数模板生成函数，类模板生成类（类型），变量模板生成变量。

1.  模板可以有类型参数和非类型参数。类型参数是类型。非类型参数可以是整型或枚举值或模板（在变长模板的情况下，占位符也是非类型参数）。

1.  模板实例化是由模板生成的代码。通常，实例化是隐式的；使用模板会强制其实例化。没有使用的情况下也可以进行显式实例化；它生成可以在以后使用的类型或函数。模板的显式特化是一种所有泛型类型都已指定的特化；它不是实例化，并且直到模板被使用之前不会生成任何代码。它只是为这些特定类型生成代码的另一种方法。

1.  通常，参数包是通过递归来迭代的。编译器通常会内联由这种递归生成的代码，因此递归仅在编译期间存在（以及程序员阅读代码的头部）。在 C++17（以及很少见的 C++14）中，可以在不递归的情况下操作整个包。

1.  Lambda 表达式本质上是一种声明可以像函数一样调用的局部类的方法。它们用于有效地将代码片段存储在变量中（或者更确切地说，将代码与变量关联起来），以便稍后调用此代码。

1.  概念对模板参数施加限制。这可以用来避免替换类型和实例化会导致模板体中发生错误的模板。在更复杂的情况下，概念可以用来消除多个模板重载之间的歧义。

# 第三章，内存和所有权

1.  清晰的内存所有权，以及由此扩展的资源所有权，是良好设计的关键属性之一。有了清晰的拥有权，资源在需要时一定会被创建并可供使用，在使用期间得到维护，在不再需要时释放/清理。

1.  资源泄露，包括内存泄露；悬垂句柄（资源句柄，如指针、引用或迭代器，指向不存在的资源）；多次尝试释放同一资源；多次尝试构造同一资源。

1.  非所有权、独占所有权、共享所有权，以及不同类型所有权的转换和所有权转移。

1.  对于通过拥有指针处理的所有权，所有权无关的函数和类应通过原始指针和引用来引用对象。如果对象由丰富指针或容器拥有，问题会变得更加复杂。如果丰富指针中包含的额外数据不需要，或者访问容器中的单个元素，原始指针和引用就足够了。否则，理想情况下，我们会使用相应的非拥有引用对象，如`std::string_view`或范围库中的视图之一。如果没有可用的，可能不得不通过引用传递拥有对象本身。

1.  独占内存所有权更容易理解，并且可以更好地跟随程序的流程控制。它也更有效率。

1.  最好是通过在栈上分配对象或作为拥有类的数据成员（包括容器类）来分配对象。如果需要引用语义或某些移动语义，应使用唯一指针。对于条件构造的对象，`std::optional`是一个很好的解决方案。

1.  共享所有权应通过共享指针，如`std::shared_ptr`来表示。

1.  在大型系统中共享所有权难以管理，并且可能不必要地延迟资源的释放。与独占所有权相比，它还有相当大的性能开销。在线程安全的并发程序中维护共享所有权需要非常谨慎的实现。

1.  如`std::string_view`、`std::span`和来自`std::ranges`的视图等视图本质上是非拥有丰富指针。一个字符串视图到字符串就像原始指针到唯一指针：一个不拥有对象，包含与相应拥有对象相同的信息。

# 第四章，从简单到微妙——交换

1.  交换函数交换两个对象的状态。在交换调用之后，对象应该保持不变，除了它们被访问的名称之外。

1.  交换通常用于提供提交或回滚语义的程序中；首先创建一个临时结果副本，然后只有在没有检测到错误的情况下才将其交换到最终目的地。

1.  使用交换来提供提交或回滚语义假设交换操作本身不能抛出异常或以其他方式失败，并留下未定义状态的对象。

1.  应始终提供一个非成员交换函数，以确保非成员交换的调用能够正确执行。也可以提供一个成员交换函数，原因有两个——首先，这是唯一一种可以交换临时对象的方法，其次，交换实现通常需要访问类的私有数据成员。如果两者都提供，则非成员函数应该调用两个参数中的一个的成员交换函数。

1.  所有 STL 容器和一些其他标准库类都提供了一个成员函数`swap()`。此外，非成员`std::swap()`函数模板为所有 STL 类型提供了标准重载。

1.  `std::qualifier`禁用了依赖参数的查找，并强制调用默认的`std::swap`模板实例化，即使该类已实现了一个自定义的交换函数。为了避免这个问题，建议也提供一个`std::swap`模板的显式实例化。

# 第五章，全面审视 RAII

1.  内存是最常见的资源，但任何对象都可以是资源。程序操作的所有虚拟或物理量都是资源。

1.  资源不应丢失（泄漏）。如果资源通过句柄访问，例如指针或 ID，则该句柄不应悬空（指不存在的资源）。当不再需要资源时，应按获取它们的方式释放资源。

1.  资源获取即初始化是一个惯用语；它是 C++中资源管理的主要方法，其中每个资源都由一个对象拥有，在构造函数中获取，并在该对象的析构函数中释放。

1.  RAII 对象应始终在栈上创建或作为另一个对象的数据成员。当程序的流程离开包含 RAII 对象的范围或包含 RAII 对象的大对象被删除时，RAII 对象的析构函数将被执行。这无论控制流如何离开范围都会发生。

1.  如果每个资源都由 RAII 对象拥有，并且 RAII 对象不提供原始句柄（或者用户小心地不克隆原始句柄），则句柄只能从 RAII 对象中获取，只要该对象保持存在，资源就不会被释放。

1.  最常用的是`std::unique_ptr`用于内存管理；`std::lock_guard`用于管理互斥锁。

1.  通常，RAII 对象必须是不可复制的。移动 RAII 对象会转移资源的所有权；经典的 RAII 模式不支持这一点，因此大多数 RAII 对象应该是不可移动的（区分`std::unique_ptr`和`const std::unique_ptr`）。

1.  RAII 在处理释放失败时存在困难，因为异常不能从析构函数中传播，因此没有很好的方法将失败报告给调用者。因此，未能释放资源通常会导致未定义的行为（C++标准有时也采取这种方法）。

# 第六章，理解类型擦除

1.  类型擦除是一种编程技术，程序本身不显示对它使用的某些类型的显式依赖。当用于将抽象行为与特定实现分离时，它是一种强大的设计工具。

1.  实现涉及一个多态对象和虚函数调用，或者一个专门为擦除类型实现并通过函数指针调用的函数。通常，这会与泛型编程结合使用，以构建这样的多态对象或从模板自动生成函数，并确保具体化的类型始终与构造期间提供的类型相同。

1.  程序可以编写成避免明确提及大多数类型。类型是通过模板函数推导出来的，并声明为`auto`或模板推导的 typedef 类型。然而，被`auto`隐藏的对象的实际类型仍然取决于对象操作的所有类型（例如，指针的删除器类型）。擦除的类型根本不被对象类型捕获。换句话说，如果你能让编译器告诉你这个特定的`auto`代表什么，所有类型都会明确地在那里。但如果类型被擦除，即使是最详细的包含对象的声明也无法揭示它（例如`std::shared_ptr<int>`——这是整个类型，删除器类型不在其中）。

1.  类型是通过为该类型生成的函数来具体化的：虽然其签名（参数）不依赖于擦除类型，但函数体则依赖于它。通常，第一步是将其中一个参数从`void*`等通用指针转换为擦除类型的指针。

1.  与直接调用相同的可调用对象相比，类型擦除总是会产生一些开销：总会有额外的间接引用及其相关的指针。几乎所有实现都使用运行时多态（虚函数或动态类型转换）或函数指针的等效虚拟表，这增加了时间和内存（虚拟指针）。最大的开销通常来自额外的内存分配，这是为了存储编译时不知道大小的对象。如果可以最小化这种分配，并将额外的内存局部化到对象中，运行时的总开销可能相当小（内存开销仍然存在，并且通常通过这种优化而增加）。

# 第七章，SFINAE、概念和重载解析管理

1.  对于每个函数调用，它是从调用位置（其可访问性可能受命名空间、嵌套作用域等因素影响）可访问的所有具有指定名称的函数的集合。

1.  这是根据参数及其类型选择重载集中哪个函数将被调用的过程。

1.  对于模板函数和成员函数（以及 C++17 中的类构造函数），类型推导从函数参数的类型推导出模板参数的类型。对于每个参数，可能可以从多个参数中推导出类型。在这种情况下，这种推导的结果必须相同，否则类型推导将失败。一旦推导出模板参数的类型，就将具体类型替换到所有参数、返回类型和默认参数中的模板参数。这是一个类型替换。

1.  如前所述的类型替换可能导致无效的类型，例如，对于没有成员函数的类型，成员函数指针就是一个无效的类型。这种替换失败不会生成编译错误；相反，失败的函数重载将从重载集中移除。

1.  这仅适用于函数声明（返回类型、参数类型和默认值）。重载解析所选函数体中的替换失败是硬错误。

1.  如果每个重载返回不同的类型，这些类型可以在编译时进行检查。这些类型必须有一些方法来区分它们，例如，不同的大小或嵌入常量的不同值。对于`constexpr`函数，我们还可以检查返回值（在这种情况下，函数需要函数体）。

1.  它被谨慎地使用。通过故意造成替换失败，我们可以将重载解析引导到特定的重载。通常，除非失败，否则首选期望的重载；否则，变长参数重载仍然存在并被选择，这表明我们想要测试的表达式是无效的。通过使用它们的返回类型区分重载，我们可以生成一个编译时（`constexpr`）常量，该常量可用于条件编译。

1.  C++20 的约束提供了更自然、更容易理解的语法。当被调用的函数不符合要求时，它们还导致更清晰的错误消息。此外，与 SFINAE 不同，约束不仅限于函数模板的替换参数。

1.  标准不仅定义了语言中的概念和约束，还提供了一种思考模板限制的方法。虽然存在广泛的基于 SFINAE 的技术，但如果将 SFINAE 的使用限制为几种类似概念使用的方法，代码将更容易阅读和维护。

# 第八章，奇特重复的模板模式

1.  虽然在绝对数值上并不非常昂贵（最多只有几纳秒），但虚函数调用比非虚函数调用要贵上几倍，并且可能比内联函数调用慢一个数量级或更多。这种开销来自于间接引用：虚函数总是通过函数指针来调用，而实际的函数在编译时是未知的，因此不能内联。

1.  如果编译器知道将要调用的确切函数，它可以消除间接引用并可能将函数内联。

1.  正如通过基类指针进行运行时多态调用一样，静态多态调用也必须通过基类的指针或引用来进行。在 CRTP 和静态多态的情况下，基类型实际上是基类模板生成的整个类型集合，每个派生类一个。为了进行多态调用，我们必须使用一个函数模板，它可以实例化在任何这些基类型上。

1.  当直接调用派生类时，CRTP 的使用与编译时等价的虚函数有很大不同。它成为一种实现技术，为多个派生类提供公共功能，每个派生类都扩展并定制了基类模板的接口。

1.  严格来说，使用多个 CRTP 基类不需要任何新的东西：派生类可以继承自几个这样的基类型，每个都是 CRTP 基类模板的一个实例化。然而，将这些基类与每个正确的模板参数（派生类本身）一起列出变得繁琐。将派生类声明为具有模板模板参数的变长模板，并从整个参数包中继承，更容易且更不容易出错。

# 第九章，命名参数、方法链和构造者模式

1.  容易误计参数数量，更改错误的参数，或者使用错误类型的参数，该参数恰好转换为参数类型。此外，添加新参数需要更改所有必须传递这些参数的功能签名。

1.  聚合内的参数值具有显式名称。添加新值不需要更改功能签名。为不同参数组制作的类具有不同的类型，并且不能意外混合。

1.  命名参数习语允许使用临时聚合对象。我们不是通过名称更改每个数据成员，而是编写一个方法来设置每个参数的值。所有这些方法都返回对对象的引用，并且可以在一个语句中连在一起。

1.  方法级联将多个方法应用于同一对象。在方法链中，通常，每个方法返回一个新的对象，下一个方法应用于它。通常，方法链用于级联方法。在这种情况下，所有链式方法都返回对原始对象的引用。

1.  构造者模式是一种设计模式，它使用一个单独的构造者对象来构建复杂对象。当构造函数不足以构建对象或难以使用来构建对象在其期望的完全构建状态时，会使用它。当正在构建的对象的构造函数无法修改（用于特定目的的通用对象）时，当所需的构造函数会有许多类似参数且在构建过程复杂时难以使用，或者当构建过程计算成本高昂但某些结果可以重用时，可能需要构造者。

1.  流式接口是一种使用方法链来呈现可以在对象上执行的多条指令、命令或操作的接口。特别是，在 C++中，流式构造者用于将复杂对象的构建分解成多个较小的步骤。其中一些步骤可以是条件性的或依赖于其他数据。

# 第十章，本地缓冲区优化

1.  微基准测试可以测量代码小片段的独立性能。为了在程序上下文中测量相同片段的性能，我们必须使用分析器。

1.  处理少量数据通常涉及相应的小量计算，因此非常快。内存分配增加了一个常数开销，与数据大小不成比例。当处理时间短时，相对影响更大。此外，内存分配可能使用全局锁或以其他方式序列化多个线程。

1.  本地缓冲区优化用对象本身的一部分缓冲区替换外部内存分配。这避免了额外的内存分配成本和开销。

1.  无论是否发生任何次要分配，对象都必须被构造，并且为其分配内存。这种分配有一定的成本——如果对象在堆上分配，成本更高，如果是栈变量，成本更低——但必须在对象可以使用之前支付这种成本。局部缓冲区优化增加了对象的大小，因此也增加了原始分配的大小，但通常这不会显著影响分配的成本。

1.  短字符串优化涉及将字符串字符存储在字符串对象内部的局部缓冲区中，直到字符串的某个特定长度。

1.  小向量优化涉及将向量内容的一小部分存储在向量对象内部的局部缓冲区中。

# 第十一章，ScopeGuard

1.  错误安全程序即使在遇到错误的情况下也能保持一个良好定义的状态（一组不变量）。异常安全性是一种特定的错误安全性；它假设错误是通过抛出表达式来表示的。当抛出（允许的）表达式时，程序不得进入一个未定义的状态。异常安全程序可能需要某些操作不抛出异常。

1.  如果必须在多个动作之间保持一致的状态，而这些动作中任何一个都可能失败，那么如果后续的动作失败，则必须撤销先前的动作。这通常要求动作在事务成功到达终点之前不完整地提交。最终的提交操作不能失败（例如，抛出异常），否则无法保证错误安全性。回滚操作也不能失败。

1.  RAII 类确保当程序离开作用域（如函数）时，总是执行某个特定的动作。使用 RAII，关闭动作不能被跳过或绕过，即使函数通过提前返回或抛出异常提前退出作用域。

1.  经典的 RAII（Resource Acquisition Is Initialization）需要为每个动作创建一个特殊的类。ScopeGuard 能够自动从一个任意的代码片段（至少，如果支持 lambda 表达式的话）生成一个 RAII 类。

1.  如果状态是通过错误代码返回的，那么就不能这样做。如果程序中的所有错误都通过异常来表示，并且任何函数的返回都是成功，那么我们可以在运行时检测到是否抛出了异常。复杂的是，受保护的运算可能本身就在由另一个异常引起的栈展开过程中进行。当保护类必须决定操作是成功还是失败时，该异常正在传播，但它的存在并不表示受保护的运算失败（它可能表示其他地方出了问题）。健壮的异常检测必须跟踪受保护作用域的开始和结束时传播了多少个异常，这只有在 C++17（或使用编译器扩展）中才可能实现。

1.  ScopeGuard 类通常是模板实例化。这意味着 ScopeGuard 的具体类型对程序员来说是未知的，或者至少难以明确指定。ScopeGuard 依赖于生命周期扩展和模板参数推导来管理这种复杂性。类型擦除的 ScopeGuard 是一个具体类型；它不依赖于它所包含的代码。缺点是类型擦除需要运行时多态性，并且大多数情况下需要内存分配。

# 第十二章，友元工厂

1.  非成员友元函数具有与成员函数相同的对类成员的访问权限。

1.  将友元授予模板会使该模板的每个实例化都成为友元；这包括相同模板的实例化，但具有不同、无关的类型。

1.  作为成员函数实现的二元运算符始终在运算符的左侧操作数上调用，不允许对该对象进行转换。允许对右侧操作数进行转换，根据成员运算符的参数类型。这导致表达式如`x + 2`和`2 + x`之间存在不对称，因为后者不能由成员函数处理，因为`2`的类型（`int`）没有任何转换。

1.  插入器的第一个操作数始终是流，而不是要打印的对象。因此，成员函数必须在该流上，这是标准库的一部分；用户不能扩展它以包括用户定义的类型。

1.  虽然细节很复杂，但主要区别在于，在调用非模板函数时，会考虑用户定义的转换（隐式构造函数和转换运算符），但对于模板函数，参数类型必须与参数类型（几乎）完全匹配，不允许用户定义的转换。

1.  在类模板中定义一个就地友元函数（定义紧随声明之后）会导致该模板的每个实例化都在包含的作用域中生成一个具有给定名称和参数类型的非模板、非成员函数。

# 第十三章，虚构造函数和工厂

1.  有几个原因，但最简单的原因是内存必须以`sizeof(T)`的数量分配，其中`T`是实际的对象类型，而`sizeof()`运算符是`constexpr`（编译时常量）。

1.  工厂模式是一种创建型模式，它解决了在不需要显式指定对象类型的情况下创建对象的问题。

1.  虽然 C++ 中必须在构造点指定实际类型，但工厂模式允许我们将构造点与程序必须决定构建什么对象以及使用某种替代标识符（如数字、值或另一种类型）来识别类型的点分开。

1.  虚拟拷贝构造函数是一种特殊的工厂，其中要构建的对象由我们已有的另一个对象的类型来识别。一个典型的实现涉及在每个派生类中重写的虚拟 `clone()` 方法。

1.  模板模式描述了一种设计，其中整体控制流程由基类决定，而派生类在预定义的某些点上提供定制。在我们的情况下，整体控制流程是工厂构建，定制点是构建对象的行为（内存分配和构造函数调用）。

1.  建造者模式在需要（或更方便）将构建对象的工作委托给另一个类而不是在构造函数中完成完整初始化时使用。一个根据某些运行时信息使用工厂方法构建不同类型对象的对象也是一个建造者。除了工厂本身之外，这样的建造者或工厂类通常还有其他运行时数据，用于构建对象，并且必须存储在另一个对象中——在我们的例子中，是工厂对象，它也是建造者对象。

# 第十四章，模板方法模式和非虚拟习语

1.  行为模式描述了一种通过使用特定方法在不同对象之间进行通信来解决常见问题的方法。

1.  模板方法模式是一种标准的实现算法的方式，该算法有一个严格的 *骨架*，或整体控制流程，但允许一个或多个定制点来处理特定类型的问题。

1.  模板方法允许子类（派生类型）实现其他通用算法的特定行为。这个模式的关键是基类和派生类型之间的交互方式。

1.  更常见的分层设计方法是将低级代码提供 *构建块*，高级代码通过特定的控制流程将它们组合起来构建特定的算法。在模板模式中，高级代码不决定整体算法，也不控制整体流程。低级代码控制算法并决定何时调用高级代码来调整执行的特定方面。

1.  它是一种模式，其中类层次结构的公共接口由基类的非虚拟公共方法实现，而派生类只包含虚拟私有方法（以及实现它们所需的任何必要数据和非虚拟方法）。

1.  公共虚拟函数执行两个独立的任务——它提供接口（因为它公开）并修改实现。更好的关注点分离是仅使用虚拟函数来自定义实现，并使用基类的非虚拟函数来指定公共接口。

1.  一旦采用了 NVI（Non-Virtual Interface），通常可以将虚拟函数设置为私有。一个例外是当派生类需要调用基类的虚拟函数以委托部分实现时。在这种情况下，该函数应设置为受保护的。

1.  析构函数是按照*嵌套*顺序调用的，从最派生的类开始。当派生类的析构函数完成时，它会调用基类的析构函数。到那时，派生类包含的*额外*信息已经被销毁，只剩下基类部分。如果基类的析构函数调用一个虚拟函数，它必须被调度到基类（因为那时派生类已经不存在了）。基类的析构函数没有方法调用派生类的虚拟函数。

1.  当对基类的更改无意中破坏了派生类时，就会显现出脆弱基类问题。虽然这不是模板方法的特有现象，但它可能影响所有面向对象的设计，包括基于模板模式的设计。在最简单的例子中，如果以改变调用以自定义算法行为所调用的虚拟函数名称的方式更改基类中的非虚拟公共函数，那么所有现有的派生类都将被破坏，因为它们当前的定制，通过具有旧名称的虚拟函数实现，将突然停止工作。为了避免这个问题，不应更改现有的定制点。

# 第十五章，基于策略的设计

1.  策略模式是一种行为模式，它允许用户通过从提供的一组替代算法中选择一个实现该行为的算法，或者通过提供一个新的实现，来自定义类的一定行为方面。

1.  虽然传统的面向对象策略在运行时适用，但 C++通过一种称为基于策略设计的技术将泛型编程与策略模式相结合。在这种方法中，主要类模板将某些行为方面委托给用户指定的策略类型。

1.  通常，对策略类型几乎没有限制，尽管类型声明的特定方式和使用方式按照惯例施加了某些限制。例如，如果策略作为一个函数被调用，则可以使用任何可调用类型。另一方面，如果调用策略的特定成员函数，策略必然是一个类，并提供所需的成员函数。模板策略也可以使用，但必须与指定的模板参数数量完全匹配。

1.  主要有两种方式：组合和继承。组合通常应该被优先考虑；然而，实践中许多策略是空类，没有数据成员，并且可以从空基类优化中受益。除非策略还必须修改主类的公共接口，否则应该优先考虑私有继承。需要操作基于策略的主类本身的策略通常必须使用 CRTP。在其他情况下，当策略对象本身不依赖于主模板构建中使用的类型时，策略行为可以通过静态成员函数公开。

1.  通常情况下，只包含常量并用于约束公共接口的策略更容易编写和维护。然而，在某些情况下，通过基类策略注入公共成员函数是首选的：当我们还需要向类中添加成员变量时，或者当完整的公共函数集难以维护或可能导致冲突时。

1.  主要的缺点是复杂性，以各种形式表现出来。具有不同策略的策略类型通常是不同的类型（唯一的替代方案，类型擦除，通常具有禁止的运行时开销）。这可能会迫使代码的大部分内容也要模板化。长列表的策略难以维护和正确使用。因此，应避免创建不必要的或难以证明合理的策略。有时，具有两个足够不相关的策略集的类型最好分成两个单独的类型。

# 第十六章，适配器和装饰器

1.  适配器是一个非常通用的模式，它修改了一个类或函数（或在 C++中的模板）的接口，使其可以在需要不同接口但具有相似底层行为的上下文中使用。

1.  装饰器模式是一个更窄的模式；它通过添加或删除行为来修改现有接口，但不会将接口转换为完全不同的接口。

1.  在经典的面向对象实现中，被装饰的类和装饰器类都继承自一个公共基类。这有两个限制；最重要的是，被装饰的对象保留了被装饰类的多态行为，但不能保留在具体（派生）装饰类中添加的接口，而这个接口在基类中不存在。第二个限制是装饰器特定于特定的层次结构。我们可以使用 C++的泛型编程工具来消除这两个限制。

1.  通常，装饰器尽可能地保留被装饰类的接口。任何行为未被修改的函数都保持不变。因此，公共继承被广泛使用。如果一个装饰器必须显式地将大多数调用转发到被装饰的类，那么继承方面就不那么重要了，可以使用组合或私有继承。

1.  与装饰器不同，适配器通常与原始类的接口非常不同。在这种情况下，通常更倾向于使用组合。例外的是编译时适配器，它们修改模板参数，但本质上仍然是相同的类模板（类似于模板别名）。这些适配器必须使用公有继承。

1.  主要限制是它不能应用于模板函数。它也不能用来用包含这些参数的表达式替换函数参数。

1.  模板别名在函数模板实例化时永远不会被考虑。适配器和策略模式都可以用来添加或修改类的公共接口。

1.  适配器很容易堆叠（组合）以逐步构建一个复杂的接口。未启用的功能根本不需要任何特殊处理；如果未使用相应的适配器，则该功能将不会启用。传统的策略模式需要为每个模式预定槽位。除了最后一个显式指定的默认参数之后的所有策略，即使是默认策略，也必须显式指定。另一方面，堆栈中间的适配器无法访问对象的最终类型，这使实现变得复杂。基于策略的类总是最终类型，使用 CRTP，这种类型可以传播到需要它的策略中。

# 第十七章，访问者模式与多分派

1.  访问者模式提供了一种将算法的实现与它们操作的对象的实现分离的方法；换句话说，这是一种在不修改类的情况下通过编写新成员函数向类添加操作的方法。

1.  访问者模式允许我们扩展类层次结构的功能。它可以在类源代码不可用或修改此类修改难以维护时使用。

1.  双重分派是基于两个因素来调度函数调用（选择要运行的算法）的过程。双重分派可以通过使用访问者模式（虚拟函数提供单分派）在运行时实现，或者通过使用模板或编译时访问者在编译时实现。

1.  经典的访问者类层次结构与可访问类层次结构之间存在循环依赖。虽然当添加新的访问者时，可访问类不需要被编辑，但当访问者层次结构发生变化时，它们需要重新编译。后者必须在每次添加新的可访问类时发生，因此产生依赖循环。无环访问者通过使用交叉转换和多继承来打破这个循环。

1.  接受访问者进入由更小对象组成的对象的一种自然方式是逐个访问这些对象。这种通过递归实现的模式最终会访问对象中包含的每个内置数据成员，并且以固定的、预定的顺序进行。因此，该模式自然映射到序列化和反序列化的需求，我们必须将对象解构为内置类型的集合，然后恢复它。

# 第十八章，并发模式

1.  并发是程序的一种属性，允许多个任务同时执行或在时间上部分重叠。通常，通过使用多个线程来实现并发。

1.  C++11 为编写并发程序提供了基本支持：线程、互斥锁和条件变量。C++14 和 C++17 添加了几个便利类和工具，但 C++ 并发功能的主要新增是在 C++20：在这里，我们有了几个新的同步原语以及协程的引入。

1.  同步模式是解决访问共享数据基本问题的常见解决方案。通常，它们提供了安排对由多个线程修改或由某些线程在修改时访问的数据的独占访问的方法。

1.  执行模式是使用一个或多个线程来安排某些计算异步执行的标准方式。这些模式提供了启动某些代码执行并接收执行结果的方法，而调用者本身并不负责执行（程序中的其他实体承担这一职责）。

1.  设计并发的最重要的指导原则是模块化；当具体应用于并发时，这意味着从满足其在并发程序中行为一定限制的组件构建并发软件。这些限制中最重要的是线程安全保证：通常，从允许广泛线程安全操作的组件构建并发软件要容易得多。

1.  为了在并发程序中发挥作用，任何数据结构或组件都必须提供事务接口。一个操作如果是执行一个定义明确的完整计算并将系统置于一个定义明确的状态，则称为事务。识别哪些操作是事务以及哪些不是的一个简化方法是：如果一个并发程序在锁定状态下执行每个操作，但操作之间没有顺序保证，那么系统的状态是否可以保证是定义明确的？如果不行，那么一些操作应该作为一个序列执行，而不释放锁。这个序列就是一个事务；序列中的操作本身不是事务。不应该由调用者负责安排这些操作的顺序。相反，数据结构或组件应该提供接口，以便将整个事务作为一个单一操作执行。
