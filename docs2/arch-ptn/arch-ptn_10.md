# 第十章：容器化和可靠应用程序的模式

Docker 启用的容器化范式正在正确轨道上，有望成为一项有影响力和洞察力的技术，随着越来越多的第三方产品和工具供应商带来的关键进步，它正在取得成功。特别是，未来属于具有现成的容器开发、部署、网络和组合技术和工具的容器化云环境。与编排、治理、监控、测量和管理平台（如 Kubernetes、Mesos 等）结合的 Docker 容器将极大地促进建立和维持下一代容器化云环境，这些环境因其提供企业级、基于微服务、事件驱动、面向服务的、云托管、知识丰富、洞察力相关、人工智能赋能、以人为本、运营商级、生产就绪和基础设施感知的应用程序而闻名。除了容器之外，微服务和以微服务为中心的应用程序的概念也具有特殊意义。构建可靠应用程序的基本要求是更快地实现弹性微服务，这些微服务被定位为下一代应用程序的标准和优化构建块和部署单元。本章重点介绍以下主题：

+   容器化模式

+   弹性微服务模式

+   可靠的应用程序模式

# 简介

毋庸置疑，Docker 是目前**信息技术**（**IT**）领域最受欢迎和最强大的技术。在 Docker 生态系统中存在两个主要趋势。首先，开源的 Docker 平台正在不断被赋予更多权利和相关的功能，以便使其成为最典范的 IT 平台，不仅对软件开发者，也对本地和远程 IT 运营团队来说都是如此。第二个趋势是全球各地的 IT 服务和解决方案提供商前所未有的采用 Docker 启发的容器化技术，以向其尊贵的消费者和客户提供越来越多的优质产品。开发全新软件应用的简化、Docker 容器的自动化和加速部署，以及 Docker 容器的极端灵活性，被广泛宣传为其前所未有的成功的关键差异化因素。

我们希望进一步阐明 Docker，并展示为什么它被吹捧为即将到来的数字、理念、API、知识和洞察经济的下一件大事。

# 容器化的关键驱动因素

Docker 启用容器化的首要驱动因素是有效地完全克服虚拟化范式被广泛表达的局限性。实际上，我们已经对经过验证的虚拟化技术和工具进行了相当长一段时间的工作，以实现迫切需要的软件可移植性。也就是说，为了消除软件与硬件之间的抑制性依赖，已经出现了几个意外包括成熟的和稳定的虚拟化范式。虚拟化是一种有益的抽象，它通过在硬件资源和软件组件之间引入额外的间接层来实现。通过这个新引入的抽象层（虚拟机管理程序或**虚拟机监控程序**（**VMM**）），任何类型的软件应用程序都可以在任何底层硬件上无缝运行。简而言之，软件可移植性是通过这个中间件层实现的。然而，即使是通过虚拟化技术，广泛发布的可移植性目标也没有完全实现。虚拟机管理程序软件和来自不同供应商的不同数据封装格式阻碍了确保所需的应用程序可移植性。此外，操作系统和应用程序工作负载的分布、版本、版本和修补差异阻碍了工作负载在系统和位置之间的顺畅迁移。

类似地，虚拟化范式还伴随着各种其他缺点。在数据中心和服务器农场中，虚拟化技术通常用于将物理机转换为多个虚拟机（VM），每个虚拟机都有自己的**操作系统**（**OS**）。通过通过自动化工具和受控资源共享实现的这种坚实和合理的隔离，可以在物理机上容纳多个和异构的应用程序。也就是说，硬件辅助的虚拟化使得不同的应用程序可以在单个物理服务器上同时运行。在虚拟化范式下，各种 IT 基础设施（服务器机器、存储设备、网络解决方案）变得开放、可编程、可远程监控、可管理和可维护。然而，由于冗长和臃肿（每个虚拟机都携带自己的操作系统），虚拟机的配置通常需要几分钟。这对实时和按需可扩展性是一个很大的障碍。

另一个被广泛表达的缺点是与虚拟化紧密相关，那就是由于过度使用宝贵的昂贵 IT 资源（处理能力、内存、存储、网络带宽等），虚拟化系统的性能也会下降。由于从客户操作系统、虚拟机管理程序到底层硬件的多层结构，虚拟机的执行时间较高。

最后，计算虚拟化已经蓬勃发展，而其他与之紧密相关的网络和存储虚拟化概念才刚刚起步。确切地说，构建分布式应用程序和满足不断变化的企业期望需要更快和更灵活的资源分配、高可用性、可靠性、可扩展性和灵活性。计算、存储和网络组件需要协同工作以满足各种 IT 和业务需求。在 IT 环境中，随着虚拟化元素和实体的增加，运营复杂性必然会迅速增长。

转向容器化的世界；所有先前的障碍都一扫而空。也就是说，不断发展的应用程序容器化概念冷静而自信地贡献于软件可移植性目标的空前成功。容器通常包含一个应用程序/服务/进程。除了主要应用程序外，所有相关的库、二进制文件、文件和其他依赖项都被打包并压缩在一起，形成一个全面而紧凑的容器。应用程序容器可以轻松地在任何本地和远程环境中运输、运行和管理。容器异常轻量级，高度便携，快速部署，可扩展，水平可扩展，等等。此外，许多行业领导者聚集在一起，形成了一种联盟，开始了一次决定性和灵巧的系统化生产、包装和交付行业级和标准化容器的旅程。

这种有意识和集体的转变使得 Docker 深入且广泛地渗透。开源社区同时通过一系列协调活动领导着容器化难题，旨在简化并精炼容器化概念。容器化生命周期步骤正在通过各种第三方工具实现自动化。

为了在 IT 环境中尽可能实现自动化，Docker 生态系统也在快速发展。容器集群和编排正在受到越来越多的关注，因此地理上分布的容器及其集群可以迅速连接起来，产生更大、更好的过程感知和复合容器。容器化的新概念有助于分布式计算。容器能够形成联邦云环境，以实现特定的业务目标。云服务提供商和企业 IT 环境都准备好拥抱这种独特的分区技术，以提高资源利用率，并将基础设施优化提升到新的水平。在性能方面，有足够的测试表明 Docker 容器达到了裸金属服务器的性能。简而言之，通过 DevOps 方面的智能利用 Docker 功能容器，确保了 IT 的敏捷性，这反过来又导致了商业的敏捷性、适应性和可负担性。

# Docker 容器的设计模式

带有 Docker 功能的容器化正在迅速兴起和演变。随着容器生命周期管理的复杂性不断升级，对启用模式的需要正在感受到。相关的专业人士和评论家正在齐心协力制定和巩固各种特定于容器的模式。在未来的日子里，我们将遇到更多模式。本节和即将到来的各节中，将简洁地呈现广泛阐述和接受的内容。

随着在云环境中（公共、私有和雾/边缘）Docker 功能容器的无与伦比的激增，Docker 爱好者、传教士和专家有意识地提出了一系列启用模式。读者们可以在本节中找到它们。让我们从容器构建模式开始。构建 Docker 镜像和容器受到许多挑战和问题的限制。Docker 模式需要达到一个稳定的水平。

# 容器构建模式

本节描述了构建 Docker 镜像的一些常见方法。根据 Alex Collins ([`alexecollins.com/developing-with-docker-building-patterns/`](https://alexecollins.com/developing-with-docker-building-patterns/)) 的说法，有几种选择：`scratch + binary`、`language stack` 和 `distribution+ package manager`。`scratch + binary - scratch` 是最基本的基础镜像，它根本不包含任何文件或程序。我们必须构建一个 *独立二进制应用程序* 来使用它。以下是一个示例。首先，我们将使用 Docker 构建一个独立二进制应用程序。步骤如下：

1.  创建一个空目录，然后创建一个 `main.go` 应用程序：

```cpp
package main
import "fmt"
// this is a comment
func main() {
    fmt.Println("Hello World")
}
```

1.  编译应用程序：

```cpp
docker run --rm -ti -v $(pwd):/go/src/myapp google/golang go build myapp
```

1.  为应用程序创建一个 Dockerfile：

```cpp
FROM scratchADD myapp /CMD ["myapp"]
```

1.  最后，构建并运行镜像：

```cpp
docker build -t myapp:1 .docker run --rm -ti myapp:1
```

这将在终端中输出 `Hello World`。

这适用于可以打包为独立二进制文件的应用程序。因为没有语言运行时，较大的应用程序必然需要更多的磁盘空间。

Docker 为常见语言提供了许多预构建的运行时基础镜像。以下是一个示例：

1.  创建一个新的空目录并详细说明`Main.java`应用程序：

```cpp
public class Main {  public static void main(String[] args) {    System.out.println("Hello World");  }}
```

1.  现在，使用**Java 开发工具包**（**JDK**）编译此应用程序：

```cpp
docker run --rm -ti -v $(pwd):/myapp -w /myapp java:8-jdk javac Main.java
```

1.  使用**Java 运行环境**（**JRE**）创建以下 Dockerfile：

```cpp
FROM java:8-jreADD Main.class /CMD ["java", "-cp", "/", "Main"]
```

1.  最后，构建并运行此 Docker 镜像：

```cpp
docker build -t myapp:1 .docker run --rm -it myapp:1
```

下载基础镜像后部署此应用程序会更快，如果许多其他应用程序使用相同的基镜像，那么所需的额外层非常小。

要构建一个不在支持的语言堆栈上的镜像，需要从一个发行版开始创建自己的镜像，然后就是使用包管理器添加必需的依赖项。Linux 总是包含一个包管理器。

这条注释安装了 JRE：

```cpp
FROM ubuntu:15.10 RUN apt-get update && apt-get install --no-install-recommends -y openjdk-8-jre ADD Main.class / CMD ["java", "-cp", "/", "Main"]
```

现在，构建并运行此基础镜像：

```cpp
docker build -t myapp:1 .docker run --rm -it myapp:1
```

优点是我们可以构建一个应用程序，并且有可能将多个应用程序放入单个镜像中（使用`systemd`）。

# Docker 镜像构建模式

如我们所知，Docker 容器是优化和有机封装复杂构建过程的绝佳方式。通常，任何软件包都需要大量的依赖项。正如[第九章](https://cdp.packtpub.com/architectural_patterns/wp-admin/post.php?post=271&action=edit)《微服务架构模式》中所述，每个微服务都是作为一个 Docker 镜像开发和交付的。每个微服务都有自己的代码仓库（GitHub）和自己的 CI 构建任务。微服务可以使用任何编程语言进行编码。让我们在这里关注 Java 语言。如果一个服务是使用编译语言（Java、Go 等）构建和运行的，那么构建环境可以与运行环境分离。Java 服务的`Dockerfile.build`来自`openjdk-7-jdk`目录，其`Dockerfile`来自`openjdk-7-jre`目录，这个目录比 JDK 小得多。

对于 Java 编程语言，在它的微服务成为可执行之前需要额外的工具和流程。然而，当编译程序运行时，不需要 JDK。另一个原因是与**Java 运行环境**（**JRE**）相比，JDK 是一个更大的包。此外，开发和重用可重复的过程和统一的环境来部署微服务似乎是一种远见。因此，将 Java 工具和包打包到容器中至关重要。这种设置允许在任何机器上构建基于 Java 的微服务，包括 CI 服务器，而无需任何特定的环境要求，如 JDK 版本、分析测试工具、操作系统、Maven、环境变量等。

因此，对于每个服务，都有两个 Dockerfile：一个用于服务运行时，另一个包含构建服务所需的所有工具。首先，重点是制作`Dockerfile.build`文件，它可以加快 Maven 构建速度。现在，在任意机器（本地或远程）上编译和运行微服务变得非常简单。这种分离的方法在很大程度上简化了**持续集成**（**CI**）过程。

配方如下：

1.  **构建文件**：拥有一个包含构建任何服务所需的所有工具和包的 Dockerfile。将其命名为`Dockerfile.build`。

1.  **运行文件**：拥有一个包含运行服务所需所有包的另一个 Dockerfile。将这两个文件以及服务代码一起保留。

1.  构建一个新的**构建器**镜像，从它创建一个容器，并使用卷或`docker cp`命令提取构建工件。

1.  构建服务镜像。

因此，将构建过程与运行过程分离对于容器化范式的预期成功非常有利。一方面是执行构建，另一方面是在第一个镜像中不包含构建链和工具的情况下，将第一个构建的结果交付出去。Terra Nullius 在[`blog.terranillius.com/post/docker_builder_pattern/`](http://blog.terranillius.com/post/docker_builder_pattern/)上发布了相关细节。构建器模式描述了开发人员必须遵循的构建容器的设置。它通常涉及两个 Docker 镜像：

+   一个安装了所有构建工具的**构建**镜像，能够创建生产就绪的应用程序文件

+   一个能够运行应用程序的**服务**镜像

构建器模式背后的基本思想很简单：创建包含所需工具（编译器、链接器和测试工具）的额外 Docker 镜像，并使用这些镜像生成精简、安全和生产就绪的 Docker 镜像。

# 多阶段镜像构建模式

最新版本的 Docker 发布版简化了创建单个 Dockerfile 的过程，该 Dockerfile 可以构建多个辅助镜像，包括编译器、工具和测试，并使用镜像中的文件来生成**最终**的 Docker 镜像，这在下文中有生动的说明。

Docker 平台可以通过读取 Dockerfile 中的指令来构建 Docker 镜像。Dockerfile 是一个包含构建新 Docker 镜像所需所有命令的文本文件。Dockerfile 的语法和核心原则非常简单直接，如下所示：

```cpp
1 Dockerfile -> 1 Docker Image
```

也就是说，每个 Dockerfile 都创建一个 Docker 镜像。这个原则对于基本用例来说效果很好，但为了创建高级、安全和精简的 Docker 镜像，一个单独的 Dockerfile 就远远不够了。

多阶段构建是最新 Docker 版本中引入的新特性，这对于那些在保持 Dockerfile 易读和易于维护的同时努力优化 Dockerfile 的人来说非常有趣。构建 Docker 镜像时最大的挑战之一是保持镜像大小。Dockerfile 中的每条指令都会向镜像中添加一层。软件工程师必须在进入下一层之前清理掉所有不需要的工件。为了编写一个真正高效的 Dockerfile，他传统上需要使用 shell 技巧和其他逻辑来尽可能保持层尽可能瘦和轻，并确保每一层都从上一层获取所需的工件，而没有任何其他东西。

通常情况下，人们会为开发使用一个 Dockerfile，为生产使用一个精简版的 Dockerfile。维护两个 Dockerfile 并非理想的做法。使用多阶段构建，他可以在 Dockerfile 中使用多个 `FROM` 指令。每个 `FROM` 指令可以使用不同的基础镜像，并且每个都开始构建的新阶段。他可以选择性地将工件从一个阶段复制到另一个阶段，留下最终镜像中不需要的所有内容。最终结果是和之前一样的微小生产镜像，但复杂度显著降低。

# 容器之间文件共享的模式

Docker 是一种流行的容器化工具，用于打包和提供包含所需运行文件系统的软件应用程序。Docker 容器是短暂的，因为它们可以运行直到容器中发出的命令完成。有时应用程序需要访问数据、共享数据或在容器删除后进行数据持久化。通常，Docker 镜像不适合数据库；网站的用户生成内容和应用程序必须访问以进行必要处理日志文件。Docker 卷提供了所需的数据持久访问。在某个时候，生产就绪的应用程序文件需要从构建容器复制到主机机器。有两种方法可以实现这一点：

+   使用 `docker cp`

+   使用 `bind-mount volumes`

Matthias Noback ([`matthiasnoback.nl/2017/04/docker-build-patterns/`](https://matthiasnoback.nl/2017/04/docker-build-patterns/)) 为这两者都提供了描述，并附带了易于理解的示例。

# 使用 bind-mount volumes

将编译步骤作为容器构建过程的一部分并不好。普遍的期望是 Docker 镜像需要高度可重用。如果源代码被修改，那么需要重新构建构建镜像，但人们希望再次运行相同的构建镜像。

因此，编译步骤必须移动到 ENTRYPOINT ([`docs.docker.com/engine/reference/builder/#entrypoint`](https://docs.docker.com/engine/reference/builder/#entrypoint)) 或 CMD 指令。源文件不应该作为构建上下文的一部分，而应该作为 bind-mount 卷挂载到正在运行的 build 容器内部。

这里有很多优势。每次运行 build 容器时，它都会编译 `/project/source/` 中的文件，并在 `/project/target/` 产生一个新的可执行文件。由于 `/project` 是一个绑定挂载卷，可执行文件会自动在主机机器上的 `target/` 目录中可用。无需显式地从容器中复制它。一旦应用程序文件在主机机器上，就很容易将它们复制到服务镜像中，因为可以使用常规的 `COPY` 指令来完成此操作。

# 管道和过滤器模式

需要一个应用程序来对其接收到的信息执行各种不同复杂度的任务。一个单体模块可以做到这一点，但存在一些不灵活性。假设一个应用程序从两个来源接收并处理数据。每个来源的数据都由一个单独的模块处理，该模块执行一系列任务以转换这些数据，然后将结果传递给应用程序的业务逻辑。每个模块执行的处理任务或每个任务的部署要求可能会变化。一些任务可能是计算密集型的，可能需要运行在强大的硬件上，而其他任务可能不需要这样昂贵的资源。此外，未来可能需要额外的处理，或者处理任务执行的顺序可能会改变。

可行的解决方案是将每个数据流所需的处理分解成一系列单独的组件（或过滤器），每个组件执行单一任务。通过标准化每个组件接收和发送的数据格式，这些过滤器可以组合成一个管道。这有助于避免代码重复，并在处理需求发生变化时，便于移除、替换或集成额外的组件。

处理单个请求所需的时间取决于管道中最慢的过滤器的速度。一个或多个过滤器可能成为瓶颈，特别是如果来自特定数据源的请求流中出现大量请求时。管道结构的优势之一是它提供了运行慢速过滤器并行实例的机会，从而使系统能够分散负载并提高吞吐量。

构成管道的过滤器可以在不同的机器上运行，这使得它们可以独立扩展并利用许多云环境提供的弹性。计算密集型的过滤器可以在高性能硬件上运行，而其他要求较低的过滤器可以托管在成本较低的通用硬件上。

如果一个过滤器的输入和输出都结构化为流，那么可以并行地对每个过滤器进行处理。管道中的第一个过滤器可以开始工作并输出其结果，这些结果在第一个过滤器完成其工作之前直接传递给序列中的下一个过滤器。如果一个过滤器失败或运行它的机器不再可用，管道可以重新安排该过滤器正在执行的工作，并将这项工作指向该组件的另一个实例。

通过结合使用经过验证的管道和过滤器模式以及补偿事务模式，可以采用一种替代方法来实现复杂的分布式事务。分布式事务可以被分解为单独且可补偿的任务，每个任务都可以通过使用也实现了补偿事务模式的过滤器来实现。管道中的过滤器可以实施为在它们维护的数据附近运行的独立托管任务，从而出现新的可能性。

对于容器世界来说，前面的模式是有益的。也就是说，为了将生成的文件从容器中取出，利用前面的*管道和过滤器*模式将文件流式传输到`stdout`被视为一个有趣的解决方案。这种流式传输也有许多优点：

+   数据不再需要最终存储在文件中，因为它可以保持在内存中。这提供了对数据的更快访问。

+   使用`stdout`允许通过管道操作符（`|`）直接将输出发送到其他进程。其他进程可以修改输出，然后执行相同操作，或者将最终结果存储在文件中。

+   文件的确切位置变得无关紧要。如果我们只使用`stdin`和`stdout`，则不会通过文件系统进行耦合。构建容器不需要将其文件放在`/target`中，构建脚本也不需要查找`/target`，它们只需传递数据。

# 容器化应用程序 - 自动驾驶模式

部署容器化应用程序并将它们连接起来是一个明确的挑战，因为通常，云原生应用程序由数百个微服务组成。微服务架构为组织提供了一个管理开发过程日益增长的复杂性的工具，而应用程序容器提供了一种管理依赖关系的新方法，以加速微服务的部署。但是，部署和连接这些服务仍然是一个挑战。

将基于微服务应用程序投入运营会带来一些挑战。开发人员必须在内部嵌入一些东西以简化部署和交付。自动导航应用程序是解决这些问题的强大设计模式。自动导航模式在代码中自动化了应用程序重复且乏味的操作任务，包括启动、关闭、扩展以及从预期的故障条件中恢复，以提高可靠性、易用性和生产效率。通过将独特的责任和操作任务嵌入到应用程序中，运维团队成员的工作量必然会有所减少。

自动导航模式面向开发人员和运维人员。它是为了让运维人员的生活变得有序，以及为了让开发人员使他们的应用程序易于使用。它主要用于微服务应用程序和多层应用程序。最重要的是，它旨在与我们的应用程序在开发和运营的所有阶段共存和成长。

自动导航模式自动化了应用程序每个组件的生命周期。任何应用程序都可以有多个组件。Web 和应用服务器、数据库服务器、内存缓存、反向代理等，是任何应用程序最突出的组件。这些组件中的每一个都可以容器化，每个为应用程序贡献的容器都有自己的生命周期。大多数自动导航模式实现都采用单用途或单服务容器。自动导航模式确实要求开发人员和运维人员思考在组件生命周期的关键点如何操作应用程序。该独特模式的作者在 [`autopilotpattern.io/`](http://autopilotpattern.io/) 提供了一些有效的问题，这些问题在设计自动导航模式时非常有用。

一些应用正在出现，其中至少包含了一些内置的逻辑。Traefik 是一个代理服务器，它使用 Consul 或其他服务目录来自动发现其后端。Traefik 在这些服务目录中不会自我注册，以便其他应用可以使用它。ContainerPilot 是一个用 Golang 编写的辅助工具，它位于容器内部，可以帮助完成这项工作。

ContainerPilot 为微服务架构提供应用程序编排、依赖管理、健康检查、错误处理、生命周期管理和有状态服务的线性及非线性扩展。此外，它提供了一个设计用于容器内部的私有 init 系统。它充当进程管理器，回收僵尸进程，运行健康检查，在服务目录中注册应用程序，监视服务目录的变化，并在容器生命周期的相关事件中运行用户指定的代码，以确保一切正常工作。ContainerPilot 使用 Consul 在应用程序容器之间协调全局状态。

使用一个小型配置文件，ContainerPilot 可以在容器内部触发事件，从而自动化对这些事件的操作，包括 preStart（之前称为 onStart）、health、onChange、preStop 和 postStop。

这里是一个示例场景（读者可以在 [`autopilotpattern.io/example`](http://autopilotpattern.io/example) 找到详细信息）。本例的作者从两个服务开始，即销售和客户服务。Nginx 作为反向代理。对 `/customers/` 的请求会转发到客户服务，对 `/sales/` 的请求会转发到销售服务。销售服务需要从客户服务获取一些数据来处理其请求，反之亦然。这里有几个关键问题。配置是静态的。这阻止了添加新实例，并使得处理失败的实例变得更加困难。通过配置管理工具配置此堆栈意味着将新的依赖项打包到该应用程序中，但静态配置意味着每次添加新实例时都需要重新部署大多数容器。需要一个机制让应用程序能够自我组装和自我管理日常任务，因此 autopilot 模式越来越受欢迎。

启用 autopilot！这个 autopilot 设计模式的作者为客户服务推出了适当的 Dockerfile。这是一个监听端口 `4000` 的小型 Node.js 应用程序。他使用 Consul 进行服务发现，每个服务都会向 Consul 发送 TTL 心跳。所有节点都知道所有其他节点，因此不需要使用外部代理或负载均衡器来在节点之间进行通信。图表生动地展示了所有内容。

然而，需要让每个服务都意识到 Consul 的存在。为此，作者使用了 ContainerPilot。源代码和其他实现细节可以在 [`github.com/autopilotpattern/workshop`](https://github.com/autopilotpattern/workshop) 找到。

根据 autopilot 模式实现了可重用的 Nginx 基础镜像，用于自动发现和配置。目标是创建一个可以在不同环境中重用的 Nginx 镜像，而无需重建整个镜像。Nginx 的配置完全通过 ContainerPilot 作业和 watch 处理器进行，这些处理器通过 consul-template 更新磁盘上的 Nginx 配置。相关细节可以在 [`github.com/autopilotpattern/nginx`](https://github.com/autopilotpattern/nginx) 找到。类似地，还有其他流行应用程序（如 WordPress）的 autopilot 实现。将大量自动化引入各种基于微服务的软件应用程序正在获得很大的动力。

如前所述，许多手动任务正在不同层次和级别上实现自动化，特别是某些关键的自动化需求越来越多地在应用层实现。随着 Docker 平台的快速成熟和稳定，Docker 容器正在迅速扩展其翅膀。随着容器管理软件解决方案的广泛可用，基于微服务应用程序正在获得大量的市场份额和心智份额。此外，还有一些服务网格框架，因此弹性微服务和可靠应用程序的日子并不遥远。越来越多的自动化能力被附加到这些应用程序上，这种进步使得应用程序能够表现出适应性。现在，自动驾驶模式在添加额外的自动化功能和设施方面发挥着关键作用。

# 容器 - 持久化存储模式

通常，容器空间起源于非永久存储数据的应用程序容器。也就是说，当容器崩溃时，存储或缓存在容器中的数据会丢失。然而，出于几个原因，包括实现有状态应用程序，数据持久性方面被强调，因此正在开发新的机制以确保在容器中安全地持久化数据。因此，为了持久化数据，引入了额外的容器类型，例如数据或卷容器。

# 持久化存储的上下文

广泛表达的一个担忧是，容器非常适合无状态应用程序，但并不适合持久化数据的具有状态的应用程序。因此，持久化存储模式在容器世界中获得了特殊的重要性。以下段落简要介绍了无状态和有状态应用程序。

随机数生成器是无状态的，因为我们每次运行它都会得到不同的值。我们可以轻松地将其 Docker 化，如果实例失败，我们可以在另一个主机上瞬间启动它以继续服务，而不会出现任何中断和延迟。在新主机上，实例的行为也保持不变。然而，我们的银行账户并非如此。如果银行账户应用程序需要在新的服务器上重新部署，它必须具有来自第一个服务器实例的原始数据。

这是一个有状态的数据分类。通常，配置数据，包括密钥和其他秘密，经常被写入各种文件中。在配置实例时，这些数据很容易恢复。用户生成的内容包括文本、视频或银行交易。存在动态配置细节。合适的例子是服务 *A* 和 *B* 之间的连接。将应用程序/服务连接到其后端数据库系统是另一个突出的例子。通常，应用程序/服务将这种发现和连接视为配置数据，以及其他配置细节。为了使应用程序可扩展和具有弹性，在应用程序运行时更新此配置信息是必要的。也就是说，当我们添加或删除服务的实例时，我们必须更新所有连接到该服务的其他服务实例。否则，预期的性能提升就不会发生。其他相关的配置细节可能包括性能调整参数。这些配置细节可以存储在应用程序仓库中，以方便应用程序/服务版本控制和更容易的跟踪。配置信息的另一种选择是利用动态存储，这样它们可以在不重新构建和重新部署应用程序的情况下进行更改。使用像 `git2consul` 这样的工具自动复制仓库内容到配置存储也是可能的。最佳实践是将配置数据和模板保存在一致的分布式键/值数据存储中。

# 持久性存储选项

容器旨在是短暂的，因此对于无状态应用程序来说，扩展得相当好。然而，有状态容器需要被不同对待。对于有状态应用程序，容器概念要正确且相关，必须存在持久性存储机制。容器可以在没有数据持久性的情况下开发和拆卸。数据位于容器内。如果发生任何变化，则数据会丢失。对于某些情况，这种数据丢失不是一个大问题。对于某些场景，数据丢失是不被接受的；必须存在数据持久性功能。Docker 提供的解决方案在下一节中给出。

在容器的可写层中存储数据是可能的，但有一些缺点：

+   当该容器不再运行时，数据不会持久化，如果另一个进程需要这些数据，从容器中获取数据可能会很困难。

+   容器的可写层与容器运行的宿主机紧密耦合。将数据移动到其他地方是一件困难的事情。

+   向容器的可写层写入需要**存储驱动**来管理文件系统。存储驱动通过使用 Linux 内核提供联合文件系统。这种额外的抽象与使用直接写入宿主机文件系统的**数据卷**相比会降低性能。

Docker 提供了三种不同的方式将数据从 Docker 宿主机挂载到容器中：**卷**、**绑定挂载**或**tmpfs**挂载。卷几乎总是正确的选择。卷是用于持久化由 Docker 容器生成和使用的数据的首选机制。虽然绑定挂载依赖于宿主机的目录结构，但卷完全由 Docker 管理。卷相对于绑定挂载有以下几个优点：

+   卷比绑定挂载更容易备份或迁移

+   使用 Docker CLI 命令或 Docker API，卷易于管理

+   卷可以在 Linux 和 Windows 容器上工作

+   卷可以在多个容器之间更安全地共享

+   卷驱动允许在远程主机或云提供商上存储卷，加密卷的内容，或添加其他功能

+   新卷的内容可以被容器预先填充

卷通常比在容器的可写层持久化数据是一个更好的选择，因为使用卷不会增加使用它的容器的尺寸，并且卷的内容存在于特定容器的生命周期之外。

如果容器生成非持久状态数据，那么考虑使用**tmpfs**挂载来避免永久存储数据，并通过避免写入容器的可写层来提高容器的性能。

所有三种选项如下所述：

+   **卷**存储在宿主机文件系统中由 Docker 管理的部分（在 Linux 上为`/var/lib/docker/volumes/`）。非 Docker 进程不能修改文件系统的这部分。

+   **绑定挂载**可以存储在宿主系统的任何位置。它们甚至可能是重要的系统文件或目录。Docker 宿主机上的非 Docker 进程或 Docker 容器可以在任何时间修改它们。

+   **tmpfs**挂载仅存储在宿主系统的内存中，并且永远不会写入宿主系统的文件系统。

让我们更深入地讨论它们。

# 卷

我们可以使用`docker volume create`命令显式创建卷，或者 Docker 可以在创建容器或服务时创建卷。当我们创建卷时，它存储在 Docker 宿主机上的一个目录中。当我们将卷挂载到容器中时，这就是挂载到容器上的目录。这与绑定挂载的工作方式类似，只是卷由 Docker 管理，并且与宿主机的核心功能隔离。

某个卷可以同时挂载到多个容器中。当没有正在运行的容器使用卷时，该卷仍然对 Docker 可用，并且不会自动删除。您可以使用 `docker volume prune` 命令删除未使用的卷。卷还支持使用 *volume drivers*，这允许在远程主机、云提供商等地方存储数据。

# 绑定挂载

当我们使用绑定挂载时，主机机器上的文件或目录会被挂载到容器中。文件或目录通过主机机器上的完整路径进行引用。文件或目录不需要在 Docker 主机上已经存在，并且可以在需要时创建。绑定挂载性能非常好，但它们依赖于主机机器的文件系统具有特定的目录结构。无法使用 Docker CLI 命令直接管理绑定挂载。

# tmpfs 挂载

tmpfs 挂载在 Docker 主机或容器内部都不会持久化到磁盘。它可以在容器生命周期内被容器使用，以存储非持久状态或敏感信息。例如，内部，swarm 服务使用 tmpfs 挂载将秘密挂载到服务的容器中。

# Docker Compose 配置模式

我们越来越频繁地听到、阅读，甚至体验到多容器应用。也就是说，复合应用是通过多容器组合来实现的。这种组合技术由于两个关键趋势而具有特殊意义。首先，强大的微服务概念正在逐渐改变 IT 行业。也就是说，大型单体服务正在逐渐让位于小型和自主的微服务集群。不同的分布式微服务正在被发现、检查并连接在一起，以创建和运行业务级、生产就绪、流程感知、任务关键、企业级复合应用。第二是 Docker 容器化不仅改变了服务的架构，也改变了创建它们的环境的结构。现在，软件被系统地容器化、存储和分发，开发者获得了选择首选应用程序的完全自由。结果，即使是像 **持续集成** (**CI**) 服务器这样的复杂环境，带有数据库后端系统和分析基础设施，也可以在几秒钟内实例化。简而言之，软件开发、部署和交付变得更加容易和快速。

Docker Compose 是一个用于定义和运行复杂应用的 Docker 工具。使用 Compose，可以在单个文件中定义一个多容器应用，然后通过一个命令启动应用，该命令会完成所有必要的操作以使其运行。使用 Compose 基本上是一个三步过程：

1.  使用 Dockerfile 定义您应用程序的环境，以便它可以在任何地方重现

1.  在`docker-compose.yml`中定义构成应用程序的服务，以便它们可以在隔离环境中一起运行

1.  最后，运行`docker-compose up`，Compose 将启动并运行整个应用程序

我们可以通过 Docker Compose 传递环境变量，以实现一次创建容器镜像并在任何环境中（开发、测试和生产）重用。采用这种方法，可以开发以 Compose 为中心的容器，这些容器需要一些配置管理来处理基于环境变量值的启动前事件。该模式的作者详细介绍了源代码在[`github.com/jay-johnson/docker-schema-prototyping-with-mysql`](https://github.com/jay-johnson/docker-schema-prototyping-with-mysql)。

作者构建了这个项目，用于使用 MySQL Docker 容器快速原型设计数据库模式，该容器部署自己的 ORM 模式文件并在启动时填充初始记录。通过设置几个环境变量，我们可以为我们自己的 Docker 容器提供一个可用的 MySQL 实例、浏览器就绪的 phpMyAdmin 服务器以及我们的数据库，包括表，初始化成我们想要的样子。有兴趣的读者请访问前面的页面，以获取有关这种独特模式的更详细信息。

# Docker 容器反模式

我们在上一节中讨论了大多数可用的容器特定模式。许多 Docker 容器化的倡导者和专家基于他们在开发、部署和交付容器化服务和应用程序方面的丰富经验，引入了一些反模式。本节专门用于传达 Docker 实践者发现和传播的反模式。

随着开源和商业级工具的随时可用，容器创建和部署正变得越来越容易和快速。DevOps 团队成员应该学习一些技术和技巧，以避免在迁移到 Docker 时犯错误。

# 在 Docker 容器内安装操作系统

使用 Docker 在容器内托管整个操作系统很少有一个合理的理由。有平台可以生成和运行系统容器。Docker 平台专门设计和微调，用于生成应用程序容器。也就是说，应用程序及其运行时依赖项被组合在一起，打包并传输到目的地。

# 选择优化的 Docker 镜像

当构建容器镜像时，我们应该只包含容器将要托管的应用程序绝对必需的服务。任何额外的服务都会浪费资源并扩大潜在的攻击向量，最终可能导致安全问题。例如，在容器内运行 SSH 服务器是不好的，因为我们可以使用 Docker 的*exec*调用来与容器化应用程序交互。相关的建议是创建一个新的目录，并将 Dockerfile 和其他相关文件包含在该目录中。还应该考虑在创建镜像之前使用`.dockerignore`来删除任何日志、源代码等。此外，养成在解压后删除任何下载的工件的习惯。

在开发、测试、预生产和生产环境中使用不同的镜像或甚至不同的标签是不正确的。作为*真相来源*的镜像应该一次性创建并推送到仓库。该镜像应继续用于不同的环境。任何系统集成测试都应该在将要推送到生产的镜像上进行。

由 Docker 镜像生成的容器应尽可能短暂。这里的“短暂”是指它可以被停止和销毁，并且可以以绝对最小的设置和配置来构建和部署新的容器。

最佳实践是不在容器中保留关键数据。有两个主要原因。当容器意外或故意崩溃时，容器内的数据会立即丢失。第二个原因是容器的安全性不如虚拟机，因此将机密、关键、客户和公司信息存储在容器中并不是一个好的发展方向。对于持久化数据，有可用的机制。流行的 ELK 堆栈可以用来存储和处理日志。如果在早期测试过程中使用了管理卷，那么建议使用`docker rm`命令的`-v`开关来删除它们。

此外，不要在 Dockerfile 中存储任何安全凭证。它们是明文形式，这使得它们完全易受攻击。不要忘记使用`-e`来指定密码作为运行时环境变量。或者，可以使用`--env-file`从文件中读取环境变量。此外，选择`CMD`或`ENTRYPOINT`来指定脚本，该脚本将从第三方获取凭证然后配置应用程序。

# 仅在容器注册表中存储容器镜像

容器注册表专为托管容器镜像而设计。将注册表用作通用存储库来托管其他类型的数据是不合适的。

# 仅在容器内托管一个服务

在微服务世界中，应用程序正被划分为一组动态的、交互式、单用途、自主的、API 驱动、易于管理和可组合的服务**.***容器成为微服务最佳运行时环境。因此，在容器内有一个服务是合乎逻辑的。因此，为了运行一个应用程序，需要利用多个容器来运行多个服务。例如，一个容器可以安装并使用 MySQL、WordPress，甚至可能还有 phpMyAdmin、nginx 和一个 SSH 守护进程。此外，可以在不同的容器中托管一个服务的多个实例。通过容器实现的冗余能力在确保通过容错、高可用性、水平扩展、独立部署等确保业务连续性方面发挥了重要作用。现在，随着强大的容器编排平台的兴起，分布式和多个容器可以连接起来，形成复合应用程序。容器化的一个优点是在出现安全问题时能够快速重新构建镜像，例如，并快速推出一套全新的容器。而且因为容器是单关注点，所以无需每次都重新部署云基础设施。同样，可以从基础镜像构建多个 Docker 镜像。此外，容器还可以转换为新的镜像。

我们可以在制定 Dockerfile 时使用 CMD 和 ENTRYPOINT 命令。通常，CMD 将使用一个脚本，该脚本将执行一些镜像配置，然后启动容器。最好避免使用该脚本启动多个进程。这将使得管理容器、收集日志和更新每个单独的进程变得困难。也就是说，我们需要在创建 Docker 镜像时遵循*关注点分离*模式。将应用程序拆分成多个容器并分别管理是未来的发展方向。

# 最新不代表最佳

在编写 Dockerfile 时，获取每个依赖项的最新版本是非常诱人的。然而，*黄金法则*是创建具有已知和稳定版本的系统和依赖项的容器，这些系统和依赖项是我们知道我们的软件将能够运行的。

# 带有 SSH 的 Docker 容器

一种相关且同样不幸的做法是将 SSH 守护进程烘焙到镜像中。在容器内拥有 SSH 守护进程可能导致对容器基础设施的未记录、不可追踪的更改，但 Docker 容器被吹捧为不可变的基础设施。

有几种情况需要 SSH 到容器中：

+   更新操作系统、服务或依赖项

+   Git pull 或以其他方式更新任何应用程序

+   检查日志

+   备份一些文件

+   重启服务

除了使用 SSH 之外，建议使用以下机制：

+   在容器的 Dockerfile 中做出更改，重建镜像，并部署容器。

+   使用环境变量或通过卷共享可访问的配置文件来执行更改并可能重新启动容器。

+   如前所述，使用`docker exec`。`docker exec`命令在运行的容器中启动一个新的命令，因此必须是最后的手段。

# 容器的 IP 地址

每个容器都会分配一个 IP 地址。在容器化环境中，多个容器必须相互交互以实现业务目标。此外，容器经常被终止，新的容器正在被创建。因此，依赖于容器的 IP 地址来启动容器通信面临着真正的挑战。首选的方法是创建服务。这将提供一个逻辑名称，可以独立于容器数量的增加和减少而被引用。它还提供了基本的负载均衡。

此外，不要使用`-p`来发布所有暴露的端口。这有助于运行多个容器并发布它们的暴露端口。但这也带来了一定的代价。那就是，所有端口都将被发布，从而带来安全风险。相反，使用`-p`来发布特定的端口。

# Root 用户

这是一个安全缓解技巧。不要以 root 用户身份运行容器。主机和容器共享相同的内核。如果容器被入侵，root 用户可以对底层主机造成更大的损害。相反，创建一个组并在其中创建一个用户。使用用户指令切换到该用户。每个用户在镜像中创建一个新的层。此外，避免来回切换用户以减少层的数量。

# 容器之间的依赖关系

通常，应用程序依赖于容器以特定顺序启动。例如，数据库容器必须启动，应用程序才能连接到它。应用程序应该对这种变化具有弹性，因为容器可能随时被终止或启动。在这种情况下，让应用程序容器在继续之前等待数据库连接成功。不要在 Dockerfile 中使用*wait-for*脚本来指定容器的启动顺序。

总之，容器是开发、部署和执行的新颖而强大的单元。业务应用程序、IT 平台、数据库和中间件正式容器化并存储在公开可用的和可访问的镜像存储库中，以便软件开发人员可以挑选并利用它们来满足他们的软件开发需求。系统可移植性是一个关键优势。容器镜像的更容易、更快的机动性、可测试性和可组合性被吹捧为容器化的最有希望和最有潜力的优势。分布式计算的概念极大地简化了分布式计算的必然性。跨集群的多个容器可以轻松连接，以实现智能和复杂的应用程序。

# 高可靠性应用的模式

IT 系统对于业务自动化是不可或缺的。我们 IT 和业务应用广泛面临的挑战是展示高可靠性。系统应该具有响应性、弹性、可伸缩性和安全性，以内在地展示所需的可靠性。系统越来越多地是多模态和多媒体的。系统必须捕捉、理解和展示适当的行为。此外，系统必须在任何情况下都能随时响应。此外，随着大数据时代的到来，分布式计算已经成为主流的计算模型。在本节中，我们将讨论构建可靠系统的突出模式，以满足专业和个人需求。有希望的方法包括：

+   反应性和认知编程技术

+   弹性微服务

+   容器化云环境

在分布式系统中，由于多个移动部分和参与系统模块之间令人恶心的依赖关系，故障是不可避免的。硬件可能失败，应用程序可能崩溃，网络可能发生瞬态故障。很少，整个服务或区域可能会出现中断。云正在成为一站式 IT 解决方案。

**弹性**是系统承受和容忍故障以持续运行的能力。即使它失败了，它也有能力反弹回原始状态。确切地说，这关乎的不是避免故障，而是它从故障中恢复的速度有多快，以便在没有中断和减速的情况下提供服务。此外，系统组件中的故障不应级联到其他组件，以使整个系统崩溃。有弹性策略、模式、最佳实践、方法和技术。 

**高可用性**（**HA**）是应用程序在健康状态下继续运行的能力，没有显著的中断时间。也就是说，应用程序继续响应用户的请求。

**灾难恢复**（**DR**）是从罕见但重大的事件中恢复的能力：非瞬态、广泛范围的故障，例如影响整个区域的服务中断。灾难恢复包括数据备份和存档，可能包括手动干预，例如从备份中恢复数据库。

弹性必须设计到系统中，以下是一个通用的模型供参考：

1.  **定义**基于业务需求的应用可用性要求。

1.  **设计**具有弹性的应用程序架构。从一个遵循既定实践和架构决策的架构开始，然后确定该架构中可能出现的故障点。注意处理依赖关系。同时，选择支持弹性的最佳架构模式和风格。

1.  **开发**应用程序时使用适当的设计模式，并纳入检测和从故障中恢复的策略。

1.  通过模拟故障和触发强制故障转移来**构建和测试**实现，并彻底调试识别出的问题。

1.  根据需要**决定**基础设施容量并**提供**它们。

1.  **部署** 应用程序到生产环境，使用可靠且可重复的过程。

1.  **监控** 应用程序以检测故障。监控活动有助于评估应用程序的健康状况。健康检查在提供即时响应时非常有用。

1.  **响应** 如果发生需要任何手动干预的事件。

# 弹性实现策略

随着弹性要求的坚持，各个商业企业的 IT 部门正在探索各种方法和手段，以构建和发布弹性应用程序服务。在不同的级别（基础设施、平台、数据库、中间件、网络和应用程序）上，弹性价值正在被强制执行，以便整个系统和环境变得弹性。

在本节中，我们将深入探讨，描述如何努力实现和阐述弹性目标，以了解现实情况。有一些值得注意的故障。其中关键的一些包括以下内容：

+   **重试短暂故障**：短暂故障可能由许多原因、缺陷和干扰引起。通常，通过重试请求可以简单地解决临时故障。然而，每次重试都会增加总延迟。此外，过多的失败请求可能导致瓶颈，因为挂起的请求在队列中积累。这些阻塞的请求可能持有关键系统资源，如内存、线程、数据库连接等。在这种情况下，一个可行的解决方案是增加每次重试尝试之间的延迟，并限制失败请求的总数。

+   **跨实例负载均衡**：这是 IT 环境中常见的事情。位于应用程序前面的**负载均衡器**（**LB**）实例有助于添加更多应用程序实例，以提高弹性。

+   **复制数据**：在数据库和文件系统中处理非短暂故障已经是一种标准方法。数据存储技术本身提供内置的复制功能。然而，为了满足高可用性要求，副本正在被制作并放置在地理上分布的位置。因此，如果一个区域发生故障，另一个区域可以处理业务连续性。然而，这显著增加了跨区域复制数据的延迟。通常，考虑到区域之间的长距离，数据复制以异步方式进行。在这种情况下，我们无法期望实时和强一致性。相反，我们需要满足最终一致性。如果副本失败，企业必须容忍潜在的数据丢失。

+   **优雅降级**：如果一个服务失败且没有故障转移路径，应用程序可能能够在仍然提供可接受的用户体验的同时优雅降级。

+   **限制高流量用户**：有时，少数用户会创建过度的负载。这可能会对其他用户产生不良影响。应用程序可能会在一定时间内限制高流量用户。限制并不意味着用户正在恶意操作。如果请求数量超过阈值，则开始限制。

# 弹性测试方法

测试人员必须测试在仅偶尔发生的故障条件下端到端工作负载的表现，有以下两种类型：

+   **故障注入测试**：这是在故障期间测试系统弹性的方法之一，可以通过触发实际故障或模拟它们来实现。

+   **负载测试**：有开源和商业级的负载生成工具，通过这些工具进行应用程序的负载测试。负载测试对于识别仅在负载下发生的故障至关重要，例如后端数据库过载或服务限制。使用生产数据或尽可能接近生产数据的合成数据进行峰值负载测试。目标是观察应用程序在真实世界条件下的行为。

# 弹性部署方法

软件部署是建立和维持弹性重要的一环。在应用程序部署到生产级服务器后，软件更新也可能成为错误源。任何不完整或错误的更新都可能导致系统崩溃。有一些经过验证的部署和更新方法可以避免任何形式的停机。在部署和后续更新之前必须进行适当的检查。部署通常包括提供各种服务器、网络和存储资源，部署经过精选和优化的应用程序代码，以及应用所需的正确配置设置。更新可能涉及所有三个任务或这三个任务的一个子集。因此，建议实施一个辅助工具、自动化和幂等的过程。与弹性部署相关的有两个主要概念：

+   **基础设施即代码**是使用代码来提供和配置基础设施的实践。基础设施即代码可能使用声明性方法或命令性方法，或者两者的结合。

+   **不可变基础设施**符合基础设施在生产后不应被干扰或修改的原则。

# 部署模式

**蓝绿部署**是一种技术，其中更新被部署到一个与实时应用程序分开的生产环境中。在部署得到验证后，然后切换流量路由到更新版本。

在**金丝雀发布**的情况下，我们不必将所有流量切换到更新版本，而是可以通过将部分流量路由到新部署来将更新推出给一小部分用户。如果有问题，就退回到旧部署。否则，将更多流量路由到新版本，直到它获得 100%的流量。

无论采用何种方法，都必须确保我们可以在新版本不符合预期的情况下回滚到最后已知的好部署。此外，如果发生错误，应用程序日志必须指出是哪个版本导致了错误。

# 监控和诊断

对应用程序进行持续和工具辅助的监控对于实现弹性至关重要。如果出现拖沓、滞后或失败的情况，运营团队必须立即被告知，并附带所有正确和相关的细节，以便采取正确的行动。正如我们大家所同意的，监控大规模分布式系统是一个更大的挑战。随着“分而治之”技术的广泛接受，任何企业级应用程序的移动部件数量稳步且急剧增长。今天，作为模块化的一部分，我们已经广泛接受和采用虚拟化和容器化概念。任何 IT 环境中的虚拟机数量都在增长。此外，由于轻量级特性，用于运行任何关键任务应用程序的容器数量也在迅速且显著地增加。简而言之，精确监控裸金属服务器、虚拟机和容器对于运营团队来说确实是一个挑战。此外，各种软件和硬件都会生成大量的日志文件，导致大量运营数据。将各种运营数据用于提取可操作见解已成为一种常见做法。不仅 IT 系统是分布式的，而且它们也非常动态。明天数据中心和服务器农场监控、测量和管理复杂性持续上升。

监控并不等同于故障检测。例如，我们的应用程序可能检测到一个短暂错误并重试，从而避免了停机时间。但同时也应该记录重试操作，以便我们可以监控错误率，从而获得应用程序整体健康状况的全面了解。

弹性策略对于确保 IT 系统和业务应用程序的服务弹性至关重要。随着企业越来越多地采用云模式，云服务提供商正专注于增强其云服务器、存储和网络的可恢复能力。应用程序开发者也在快速学习技巧和技术，以便推出具有弹性的应用程序。结合弹性基础设施、平台和应用程序，实现弹性 IT 的日子，这对于敏捷、动态、高效和适应性强的企业来说是越来越近了。

# 弹性实现模式

模式始终是挖掘和阐述针对各种重复性问题的高效解决方案的一种流行且无与伦比的机制。我们将探讨一系列有前景且经过验证的设计模式，以实现最重要的目标——弹性。

# 电路断路器模式

电路断路器模式可以防止应用程序反复尝试可能失败的操作。电路断路器封装了对服务的调用。它可以处理在连接到远程服务或资源时可能需要不同时间恢复的故障。这可以提高应用程序的稳定性和弹性。

**问题描述**——远程连接在分布式应用程序中很常见。由于网络速度慢、超时、服务不可用或服务负载过重等大量短暂故障，对远程应用程序服务的调用可能会失败。这些故障通常是短暂的，通常在短时间内自行纠正。重试模式策略建议，一个健壮的云应用程序可以轻松处理这些短暂故障，以满足服务请求。

然而，也可能存在故障是由于更大问题的情况。严重程度从暂时性连接丢失到由于各种原因和原因导致的服务完全失败不等。在这里，不断重试建立已损坏的连接是不合逻辑的。相反，应用程序必须理解和接受这种情况，以优雅地处理失败。

假设请求的服务非常繁忙，那么整个系统崩溃的可能性就存在。

通常，调用服务的操作被配置为实施超时，并在服务未能响应指定的时间段内回复失败消息。然而，这种策略可能导致许多并发请求同一操作的请求被阻塞，直到超时期间结束。这些阻塞的请求可能会占用关键系统资源，如内存、线程、数据库连接等。最终，资源可能会耗尽，导致其他相关甚至无关的系统组件失败。其理念是使操作立即失败，并且只有在可能成功的情况下才尝试再次调用服务。这里的要点是智能地设置超时，因为较短的超时可能有助于解决这个问题，但较短的超时可能会使操作大部分时间都失败。

**解决方案方法**—解决方案是经过验证的断路器模式，它可以防止应用程序反复尝试执行可能失败的操作。这允许它在等待故障修复或确定故障持续时间较长时，不浪费 CPU 周期继续运行。断路器模式还使应用程序能够检测故障是否已解决。如果问题似乎已经修复，应用程序可以尝试调用该操作。

重试模式允许应用程序在预期操作将成功的情况下重试操作。另一方面，断路器模式防止应用程序执行可能失败的操作。应用程序可以通过使用断路器通过重试模式调用操作来结合这两种模式。然而，重试逻辑应该对断路器返回的任何异常高度敏感，如果断路器指示故障不是瞬时的，则应放弃重试尝试。此外，断路器充当可能失败的操作的代理。代理应监控最近发生的失败次数，并使用这些信息来决定是否允许操作继续，或者简单地立即返回异常。代理可以作为一个具有以下状态的状态机实现：

+   **关闭状态**：这是断路器的原始状态。因此，断路器向服务发送请求，并有一个计数器持续跟踪最近失败的次数。如果在给定的时间段内，失败计数超过阈值水平，则断路器切换到*打开*状态。

+   **打开状态**：在此状态下，断路器打开并立即失败所有请求，而不调用服务。应用程序必须使用缓解路径，例如从副本数据库读取数据或简单地向用户返回错误。当断路器切换到打开状态时，它启动一个计时器。当计时器到期时，断路器切换到半开状态。

+   **半开状态**：在此状态下，断路器允许有限数量的请求通过到服务。如果它们成功，则假定服务已恢复，断路器切换回原始关闭状态。否则，它将恢复到打开状态。半开状态防止恢复中的服务突然被一系列服务请求淹没。

断路器模式确保系统在从故障中缓慢而稳定地恢复的同时保持系统稳定性，并最小化对系统性能的影响。它可以通过快速拒绝可能失败的操作的请求，而不是等待操作超时，来帮助保持系统的响应时间。如果断路器每次改变状态时都引发一个事件，则可以使用这些信息来监控由断路器保护的系统部分的健康状况，或者在断路器跳转到开启状态时提醒管理员。

该模式高度可定制，可以根据可能出现的故障类型进行调整。例如，可以将一个增加的超时计时器用于断路器。我们最初可以将断路器置于开启状态几秒钟，如果故障尚未解决，则将超时时间增加到几分钟，依此类推。在某些情况下，与其让开启状态返回一个故障并引发异常，不如返回一个对应用程序有意义的默认值。

总结来说，此模式用于防止应用程序尝试调用远程服务或访问共享资源，如果这种操作高度可能失败。此模式不是：

+   用于处理应用程序中对本地私有资源的访问，例如内存中的数据结构

+   作为处理应用程序业务逻辑中异常的替代方案

断路器模式在微服务中变得越来越常见，成为分割大型应用程序和将应用程序呈现为有组织的微服务集合的最优化方式。

# Bulkhead pattern

**问题描述**——云应用通常由多个相互关联的服务组成。一个服务可以作为服务实例在不同的和分布式的服务上运行。对于每个服务实例，可能有多个消费者请求。当消费者向一个配置错误或未响应的服务发送请求时，客户端请求使用的资源可能无法及时释放。

随着对服务的请求持续不断，这些资源可能很快就会耗尽。占用的资源包括数据库连接。最终结果是，对云应用中其他服务的任何请求都会受到影响。最终，云应用可能无法向消费者提供服务。其他消费者也是如此。简而言之，来自一个客户端的大量请求可能会耗尽服务中的可用资源。这是级联效应，而此模式在克服这一问题中非常有用。

**解决方案方法**——解决方案是将服务实例智能地分区到不同的组，基于消费者负载和可用性要求。这种设计有助于隔离故障，并允许在故障期间为某些消费者维持服务功能。消费者还可以分区资源，以确保用于调用一个服务的资源不会影响用于调用另一个服务的资源。例如，为不同的服务选择不同的连接池是一个可行的选项。因此，一个连接池的崩溃不会停止其他连接。

这种模式的优点包括以下内容：

+   这隔离了服务消费者和服务，防止级联故障。这种隔离坚决防止整个解决方案崩溃。

+   实例级别的隔离有助于保留服务的其他实例。因此，服务可用性得到保证，同样地，应用程序的其他服务继续执行其分配的功能。

+   这有助于识别消费应用的需求，并相应地允许部署提供不同**服务质量**（**QoS**）的服务。也就是说，可以配置一个高优先级的消费者池来使用高优先级的服务。

总结来说，一个子系统的任何类型的故障有时会级联到其他组件，导致系统崩溃。为了避免这种情况，我们需要将系统分区成几个隔离的组，以便一个分区的故障不会渗透到其他分区。容器化与多语言微服务的结合是拥有分区和无忧系统的强大选择。

# 补偿事务模式

这是一个撤销另一个已完成事务效果的交易。在分布式系统中，实现强事务一致性可能非常困难。补偿事务是通过使用一系列较小且独立的交易来实现一致性的方法，这些交易可以在每个步骤中撤销。

**问题描述**——典型的业务操作由一系列独立的步骤组成。当这些步骤正在执行时，系统的整体状态视图可能是不一致的，但是当操作完成并且所有步骤都已执行时，系统应该再次变得一致。最终一致性模型中的挑战是如何处理失败的步骤。在这种情况下，可能需要撤销操作中之前步骤完成的所有工作。然而，数据不能简单地回滚，因为其他并发应用程序实例可能已经更改了它。即使在数据没有被并发实例更改的情况下，撤销一个步骤可能不仅仅是恢复原始状态的问题。这要求应用各种特定于业务规则。如果一个实现最终一致性的操作跨越几个异构数据存储，撤销操作中的步骤将需要依次访问每个数据存储。必须在每个数据存储中可靠地撤销执行的工作，以防止系统保持不一致。

在**面向服务的架构**（**SOA**）环境中，一个操作可能会在服务中调用一个动作并导致该服务持有的状态发生变化。为了撤销操作，这种状态变化也必须被撤销。这可能涉及到再次调用服务并执行另一个动作，以逆转第一个动作的效果。

**解决方案方法**——解决方案是实施一个补偿事务。补偿事务中的步骤必须撤销原始操作中步骤的效果。补偿事务可能无法简单地用操作开始时系统的状态替换当前状态，因为这种方法可能会覆盖其他并发应用程序实例所做的更改。相反，它必须是一个智能过程，考虑到任何并发实例完成的工作。这个过程通常将是特定于应用程序的，由原始操作执行的工作的性质驱动。

一种常见的方法是使用工作流来实现需要补偿的最终一致操作。随着原始操作的进行，系统记录有关每个步骤的信息以及该步骤执行的工作如何被撤销。如果在任何点上操作失败，工作流将回滚到已完成的步骤，并执行逆转每个步骤的工作。

建议仅在使用失败时必须撤销的操作中使用此模式。如果可能，设计解决方案以避免需要补偿事务的复杂性。

# 健康端点监控模式

**问题描述**——应用程序及其服务需要持续监控，以获得对其可用性和性能水平和模式的牢固把握。与任何本地服务相比，在本地、按需和在线环境中运行的监控服务相当困难。有许多因素会影响云托管应用程序，例如网络延迟、底层计算和存储系统的性能和可用性，以及它们之间的网络带宽。服务可能会完全或部分失败，这可能是由于任何这些因素造成的。因此，我们必须定期验证服务是否正常运行。

**解决方案方法**——我们需要通过向应用程序的端点发送请求来进行健康监控。应用程序应执行必要的检查，并返回其状态的指示。健康监控检查通常结合两个因素：

+   应用程序或服务在响应健康验证端点请求时执行的分配检查。

+   执行健康验证检查的健康监控工具对结果的分析。

健康监控工具正在检查几个参数和条件，以便完全且简洁地了解应用程序的状态。

从不同的本地或托管位置运行这些检查以测量和比较响应时间也是有用的。由于客户在地理上分布，检查必须从靠近客户的位置启动和实施。

另一点是要公开至少一个应用使用的核心服务的端点，以及另一个用于低优先级服务的端点。这允许为每个监控结果分配不同的重要性级别。同时，考虑公开更多端点，例如为每个核心服务公开一个端点以实现额外的监控粒度也是好的。越来越频繁地，数据库、存储和其他关键服务都在进行健康验证检查。正常运行时间和响应时间决定了应用程序的质量。

这种模式对于检查网站、Web 和移动应用程序以及云托管应用程序的健康状况非常有用。

# 领导选举模式

**问题描述**——典型的云应用程序有许多任务以协调的方式工作。这些任务可能都是运行相同代码的实例，需要访问相同的资源，或者它们可能并行工作以执行复杂计算的各个部分。任务实例可能大部分时间都是独立运行的，但有时也可能需要协调每个实例的动作，以确保它们不会冲突，不会对共享资源产生竞争，或者意外地干扰其他任务实例正在进行的工作。

例如，云系统通过扩展或扩展来保证可伸缩性。在扩展（水平扩展）的情况下，可能会有多个相同任务/服务的实例。每个实例服务于不同的用户。如果这些实例写入共享资源，那么协调它们的行动以防止每个实例覆盖其他实例所做的更改是必要的。同样，如果任务正在并行执行复杂计算的各个单独元素，那么结果需要适当汇总以给出最终答案。任务实例都是对等的，因此没有自然领导者可以充当协调器或聚合器。

**解决方案方法**——应该选举一个单独的任务实例来充当领导者，并且这个实例应该协调其他下属任务实例的行动。如果所有任务实例都在运行相同的代码，它们各自都能充当领导者。因此，选举过程必须得到妥善管理，以防止两个或多个实例同时接管领导者角色。系统必须提供一种强大的机制来选择领导者。这种方法必须应对网络中断或进程故障等事件。在许多解决方案中，下属任务实例通过某种心跳方法或轮询来监控领导者。如果指定的领导者意外终止，或者网络故障使领导者对下属任务实例不可用，它们必须选举一个新的领导者。这就像在传感器网络中选择集群头节点一样。

这种模式在分布式应用程序中的任务，例如云托管解决方案，需要仔细协调且没有自然领导者时表现最佳。避免将领导者作为系统瓶颈是谨慎的做法。领导者的目的是协调下属任务的工作，它本身并不一定必须参与这项工作——尽管如果任务没有被选为领导者，它应该能够这样做。

# 基于队列的负载均衡模式

应用程序可能会经历突然的交通高峰，这可能会轰炸后端系统。如果后端服务无法快速响应请求，可能会导致请求排队（积压），或者可能导致服务限制应用程序。为了避免这种情况，我们可以使用队列作为缓冲。当有新的工作项时，不是立即调用后端服务，而是应用程序将工作项排队以异步运行。队列充当缓冲区，可以平滑负载的峰值。

**问题描述**—为了达到以业务为中心、流程感知的综合应用，云应用之间必须相互交互。服务可以是本地可用或远程访问。各种热情的软件开发者带来了现代应用，并以小额费用或有时免费的方式向全球订阅者提供。同样，还有**独立软件供应商**（**ISVs**）与托管服务提供商签订合同，以运行其软件，使其被发现和绑定。也就是说，各种云服务必须与其他许多服务连接和协作，以便对消费者来说是正确和相关的。在这个错综复杂的环境中，如果某个服务受到间歇性重负载的影响，可能会引起性能或可靠性问题。在特定时间服务用户数量的可预测性也是一个难题。因此，静态容量规划已不再适用。*动态性*是 IT 领域的新热门词汇。

如前所述，应用程序可以被分割成多个服务。每个服务可以作为单独的实例在不同的容器中运行。也就是说，可以在 IT 环境中运行多个服务的实例。在服务世界中，一切都可以通过 API 启用，以便其他服务发现和利用。一个服务可以被多个任务同时使用。一个服务可以是与其使用的任务相同的应用程序的一部分，也可以由第三方服务提供商提供。例如，该服务可以是资源服务，如缓存或存储服务。

一个服务可能会经历需求高峰，导致其过载，无法及时响应请求。如果服务无法处理这些请求造成的竞争，向服务发送大量并发请求也可能导致服务失败。

**解决方案方法**—建议重构解决方案，并在任务和服务之间引入队列。任务和服务异步运行。任务将包含服务所需数据的消息发布到队列中。队列充当缓冲区，存储消息，直到服务检索它。服务从队列中检索消息并处理它们。来自多个任务（这些任务可以以高度可变的速度生成）的请求可以通过同一个消息队列传递到服务。

此模式提供了以下好处：

+   它可以帮助最大化应用程序的可用性，因为服务中出现的延迟不会立即直接影响到应用程序，即使服务不可用或当前未处理消息，应用程序也可以继续向队列发送消息。

+   它可以帮助最大化可伸缩性，因为队列的数量和服务的数量都可以根据需求进行调整。

+   这有助于控制成本，因为部署的服务实例数量只需足够满足平均负载，而不是峰值负载。

# 重试模式

**问题描述**—我们之前已经讨论过这种模式的一些内容。应用是以服务的形式表达和暴露的，并且从不同的 IT 环境中（私有、公共和边缘云）进行分发。通常，IT 跨越嵌入式、企业和云领域。随着设备生态系统的快速增长，连接性已经扩展到地面层级的各种设备。这就是我们经常听到、读到甚至体验到**网络物理系统**（**CPS**）的原因。此外，企业规模的应用（无论是传统还是现代）相应地进行了现代化改造，并迁移到云环境中以获得云理念的独特优势。然而，由于某些特定原因，某些应用仍然保留在企业服务器/私有云中。随着嵌入式和网络设备的加入主流计算，边缘/雾设备被启用以形成某种临时的云，以促进实时数据捕获、存储、处理和决策。需要注意的是，应用服务应该连接到附近的其他服务，并在远程网络上持有服务。可能会发生故障，导致应用调用激增。正如之前所述，存在暂时性的故障，影响服务的连接性、交互和执行。然而，这些故障通常是自我纠正的，如果在适当的延迟后重复触发故障的动作，连接性和可访问性可能会恢复。

**解决方案方法**—在云环境中，暂时性故障很常见，应用应该设计得能够优雅且透明地处理这些故障。这最小化了故障对应用正当执行的业务任务可能产生的影响。如果应用在尝试向远程服务发送请求时检测到故障，它可以采用以下策略来处理故障：

+   **取消**：如果故障表明失败不是暂时的（即持续更长时间），或者如果重复尝试，则可能无法成功，应用应取消操作并报告异常。

+   **重试**：如果报告的具体故障不寻常或罕见，可能是由于一些不寻常的情况，例如在网络传输过程中数据包被损坏。在这种情况下，应用可以再次尝试，因为后续的请求可能会获得所需的成功。

+   **延迟后重试**：如果故障是由更常见的连接或繁忙失败引起的，那么应用必须等待一段时间后再尝试。

应用程序应将所有尝试访问远程服务的尝试封装在实现重试策略的代码中，该策略与之前列出的策略之一相匹配。发送到不同服务的请求可以受到不同策略的影响。一些供应商提供了实现重试策略的库，其中应用程序可以指定最大重试次数、重试尝试之间的时间以及其他参数。应用程序应记录故障和失败操作的详细信息。这些信息对操作员很有用。如果一个服务频繁不可用或繁忙，通常是因为该服务已经耗尽了其资源。我们可以通过扩展服务来减少这些故障的频率。例如，如果一个数据库服务持续过载，可能有益于对数据库进行分区并将负载分散到多台服务器上。

总结来说，在理解了下一代 IT 系统的弹性、鲁棒性和可靠性对于满足所有 QoS（服务质量）和**服务质量体验**（**QoE**）特性和原则的重要性之后，IT 行业专业人士、学术教授和研究人员正在投入他们的才智、财富和时间，挖掘大量易于理解且实用的技术、技巧和窍门，以简化并优化软件和基础设施工程任务。我建议读者访问[`docs.microsoft.com/en-us/azure/architecture/patterns/category/resiliency`](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/resiliency)以获取更多阅读材料。

# 摘要

无论是传统应用还是现代应用，都应被修复为微服务的集合。微服务可以在容器内托管和运行。每个微服务可以有多个实例。每个容器可以运行一个微服务实例。因此，在典型的 IT 环境中，可能会有数百台物理机器（也称为**裸机服务器**）。每台物理机器反过来又能够运行数百个容器。因此，将会有数万个容器。管理和运营的复杂性因此必然会增加。这种模式在成功运行托管微服务的容器方面非常有用。有一些技术，如 Istio 和 Linkerd，可以确保微服务的弹性。这种弹性最终确保了应用程序的可靠性。与软件定义的云基础设施一起，可靠的应用程序确保了云环境在托管和交付下一代业务负载时的可靠性。

接下来的章节将讨论各种软件定义的云应用程序设计和部署模式。
