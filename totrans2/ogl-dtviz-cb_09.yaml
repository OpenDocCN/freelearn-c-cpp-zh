- en: Chapter 9. Augmented Reality-based Visualization on Mobile or Wearable Platforms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章.移动或可穿戴平台上的基于增强现实的可视化
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: 'Getting started I: Setting up OpenCV on Android'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入门 I：在Android上设置OpenCV
- en: 'Getting started II: Accessing the camera live feed using OpenCV'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入门 II：使用OpenCV访问相机实时流
- en: Displaying real-time video processing with texture mapping
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用纹理映射显示实时视频处理
- en: Augmented reality-based data visualization over real-world scenes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于增强现实的真实场景数据可视化
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: The field of digital graphics has traditionally been living within its own virtual
    world since computers were invented. Often, computer-generated content has no
    awareness of the user and how the information is relevant to the user in the real
    world. The application is always simply waiting for a user command such as the
    mouse or keyboard input. One major limiting factor in the early design of computer
    applications is that computers are typically sitting on a desk in an office or
    in a home environment. The lack of mobility and the inability to interact with
    its environment or user ultimately limited the development of real-world interactive
    visualization applications.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数字图形领域自计算机发明以来，传统上一直生活在自己的虚拟世界中。通常，计算机生成的内容没有意识到用户，以及信息在现实世界中与用户的关联性。应用程序总是简单地等待用户的命令，如鼠标或键盘输入。在计算机应用程序早期设计中，一个主要的限制因素是计算机通常坐在办公室或家庭环境中的桌子上。缺乏移动性和无法与环境或用户互动，最终限制了现实世界交互式可视化应用程序的发展。
- en: Today, with the evolution of mobile computing, we have redefined many of our
    daily interactions with the world—for example, through applications that enable
    navigation with GPS using a mobile phone. However, instead of enabling users to
    seamlessly interact with the world, mobile devices still draw users away from
    the real world. In particular, as in previous generations of desktop computing,
    users are still required to look away from the real world into a virtual world
    (in many cases, just a tiny mobile screen).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，随着移动计算的演变，我们重新定义了我们与世界日常互动的许多方面——例如，通过使用手机通过GPS进行导航的应用程序。然而，移动设备并没有使用户能够无缝地与世界互动，反而将用户从现实世界中引开。特别是，就像在桌面计算的前几代中一样，用户仍然需要从现实世界转向虚拟世界（在许多情况下，只是一个微小的移动屏幕）。
- en: The notion of **Augmented Reality** (**AR**) is a step towards reconnecting
    the user with the real world through the fusion of the virtual world (generated
    by the computer) with the real world. This is distinctly different from virtual
    reality, in which the user is immersed into the virtual world and detached from
    the real world. For example, a typical embodiment of AR involves the use of a
    video see-through display in which virtual content (such as a computer-generated
    map) is combined with a real-world scene (captured continuously with a built-in
    camera). Now, the user is engaged with the real world—a step closer to a truly
    human-centric application.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**增强现实**（AR）的概念是通过融合虚拟世界（由计算机生成）与现实世界，重新连接用户与真实世界的一步。这与虚拟现实截然不同，在虚拟现实中，用户沉浸于虚拟世界，脱离了现实世界。例如，AR的一个典型实现是使用视频透视显示器，其中虚拟内容（如计算机生成的地图）与真实场景（通过内置摄像头连续捕获）相结合。现在，用户与真实世界互动——更接近真正以人为中心的应用。'
- en: Ultimately, the emergence of AR-enabled wearable computing devices (such as
    Meta's AR eyeglasses, which features the world's first holographic interface with
    3D gesture detection and 3D stereoscopic display) will create a new era of computing
    that will greatly revolutionize the way humans interact with computers. Developers
    interested in data visualization now have another set of tools that are significantly
    more human-centric and intuitive. Such a design, needless to say, truly connects
    human, machine, and the real world together. Having information directly overlaid
    onto the real world (for example, by overlaying a virtual guidance map for navigation)
    is so much more powerful and meaningful.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，AR功能的可穿戴计算设备（如Meta的AR眼镜，具有世界上第一个具有3D手势检测和3D立体显示的全息界面）的出现将创造一个新的计算时代，将极大地改变人类与计算机互动的方式。对数据可视化感兴趣的开发商现在有一套更以人为中心且直观的工具。这种设计，不用说，真正将人、机器和现实世界连接在一起。将信息直接叠加到现实世界（例如，通过叠加虚拟导航地图）要强大得多，也更有意义。
- en: 'This final chapter introduces the fundamental building blocks for creating
    your first AR-based application on a commodity Android-based mobile device: OpenCV
    for computer vision, OpenGL for graphics rendering, as well as Android''s sensor
    framework for interaction. With these tools, the graphics rendering capability
    that used to only exist in Hollywood movie production can now be made available
    at everyone''s fingertips. While we will only focus on the use of an Android-based
    mobile device in this chapter, the conceptual framework for AR-based data visualization
    introduced in this chapter can be similarly extended to state-of-the-art wearable
    computing platforms, such as Meta''s AR eyeglasses.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了创建第一个基于AR的应用程序的基本构建块，该应用程序运行在基于Android的移动设备上：OpenCV用于计算机视觉，OpenGL用于图形渲染，以及Android的传感器框架用于交互。有了这些工具，以前只在好莱坞电影制作中存在的图形渲染能力现在可以随时供每个人使用。虽然我们本章将只关注基于Android的移动设备的使用，但本章介绍的基于AR的数据可视化的概念框架可以类似地扩展到最先进的可穿戴计算平台，如Meta的AR眼镜。
- en: 'Getting started I: Setting up OpenCV on Android'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始：在Android上设置OpenCV
- en: In this section, we will outline the steps to set up the OpenCV library on the
    Android platform, which is needed to enable access to the live camera stream central
    to any Augmented Reality applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将概述在Android平台上设置OpenCV库的步骤，这是启用访问任何增强现实应用程序的核心实时相机流所必需的。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We assume that the Android SDK and NDK are configured exactly as discussed in
    [Chapter 7](ch07.html "Chapter 7. An Introduction to Real-time Graphics Rendering
    on a Mobile Platform using OpenGL ES 3.0"), *An Introduction to Real-time Graphics
    Rendering on a Mobile Platform Using OpenGL ES 3.0*. Here, we add in the support
    of OpenCV for Android. We will import and integrate the OpenCV library into our
    existing code structure from the previous chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设Android SDK和NDK的配置与第7章中讨论的完全一致，即《在移动平台上使用OpenGL ES 3.0进行实时图形渲染的介绍》，*在移动平台上使用OpenGL
    ES 3.0进行实时图形渲染的介绍*。在这里，我们增加了对Android OpenCV的支持。我们将从上一章的现有代码结构中导入和集成OpenCV库。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here, we describe the major steps for setting up the OpenCV library, mainly
    path setup and pre-configuration of the Java SDK project setup:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们描述了设置OpenCV库的主要步骤，主要是路径设置和Java SDK项目预配置：
- en: Download the OpenCV for Android SDK package, Version 3.0.0 (`OpenCV-3.0.0-android-sdk-1.zip`)
    at [http://sourceforge.net/projects/opencvlibrary/files/opencv-android/3.0.0/OpenCV-3.0.0-android-sdk-1.zip](http://sourceforge.net/projects/opencvlibrary/files/opencv-android/3.0.0/OpenCV-3.0.0-android-sdk-1.zip).
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[http://sourceforge.net/projects/opencvlibrary/files/opencv-android/3.0.0/OpenCV-3.0.0-android-sdk-1.zip](http://sourceforge.net/projects/opencvlibrary/files/opencv-android/3.0.0/OpenCV-3.0.0-android-sdk-1.zip)下载OpenCV
    for Android SDK包，版本3.0.0（`OpenCV-3.0.0-android-sdk-1.zip`）。
- en: Move the package (`OpenCV-3.0.0-android-sdk-1.zip`) to the `3rd_party/android`
    folder created in [Chapter 7](ch07.html "Chapter 7. An Introduction to Real-time
    Graphics Rendering on a Mobile Platform using OpenGL ES 3.0"), *An Introduction
    to Real-time Graphics Rendering on a Mobile Platform Using OpenGL ES 3.0*.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将包（`OpenCV-3.0.0-android-sdk-1.zip`）移动到第7章中创建的`3rd_party/android`文件夹中，即《在移动平台上使用OpenGL
    ES 3.0进行实时图形渲染的介绍》，*在移动平台上使用OpenGL ES 3.0进行实时图形渲染的介绍*。
- en: Unzip the package with the following commands
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令解压包
- en: '[PRE0]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then in the project folder (for example `ch9/code/opencv_demo_1`), run the
    following script to initialize the project for Android. Note that the `3rd_party`
    folder is assumed to be in the same top-level directory as in previous chapters:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后在项目文件夹中（例如`ch9/code/opencv_demo_1`），运行以下脚本以初始化Android项目。请注意，`3rd_party`文件夹假设与上一章中的顶级目录相同：
- en: '[PRE1]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Finally, include the OpenCV path in the build script `jni/Android.mk`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在构建脚本`jni/Android.mk`中包含OpenCV路径。
- en: '[PRE2]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, the project is linked to the OpenCV library, both from the Java side as
    well as from the native side.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，该项目已与OpenCV库相连，既包括Java端也包括本地端。
- en: Next we must install the OpenCV Manager on the mobile phone. The OpenCV Manager
    allows us to create applications without statically linking all the required libraries,
    and it is recommended. To install the package, we can execute the following `adb`
    command from the same project folder (`ch9/code/opencv_demo_1`). Again, note the
    relative location of the `3rd_party` folder. You can also execute this command
    within the Android SDK folder and modify the relative path of the `3rd_party`
    folder accordingly.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须在手机上安装 OpenCV 管理器。OpenCV 管理器允许我们创建应用程序，而无需将所有必需的库静态链接，这是推荐的。要安装软件包，我们可以从同一项目文件夹（`ch9/code/opencv_demo_1`）中执行以下
    `adb` 命令。再次注意 `3rd_party` 文件夹的相对位置。您也可以在 Android SDK 文件夹中执行此命令，并相应地修改 `3rd_party`
    文件夹的相对路径。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After we have successfully completed the setup, we are ready to create our first
    OpenCV Android application on the phone.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们成功完成设置后，我们就准备好在手机上创建我们的第一个 OpenCV Android 应用程序了。
- en: See also
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'Windows users should consult the following tutorials on Android development
    with OpenCV for setup instructions: [http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/android_dev_intro.html](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/android_dev_intro.html)
    and [http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html#native-c](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html#native-c).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Windows 用户应参考以下关于使用 OpenCV 进行 Android 开发的教程，以获取设置说明：[http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/android_dev_intro.html](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/android_dev_intro.html)
    和 [http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html#native-c](http://docs.opencv.org/doc/tutorials/introduction/android_binary_package/dev_with_OCV_on_Android.html#native-c)。
- en: For further information on using OpenCV in an Android application, consult the
    online documentation at [http://opencv.org/platforms/android.html](http://opencv.org/platforms/android.html).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在 Android 应用中使用 OpenCV 的更多信息，请参阅 [http://opencv.org/platforms/android.html](http://opencv.org/platforms/android.html)
    在线文档。
- en: 'Getting started II: Accessing the camera live feed using OpenCV'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始 II：使用 OpenCV 访问相机实时流
- en: 'Next we need to demonstrate how to integrate OpenCV into our Android-based
    development framework. The following block diagram illustrates the core functions
    and relationship among the classes that will be implemented in this chapter (only
    the functions or classes relevant to the introduction of OpenCV will be discussed
    in this section):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要演示如何将 OpenCV 集成到我们的基于 Android 的开发框架中。以下块图说明了本章将实现的核心功能和类之间的关系（本节将仅讨论与
    OpenCV 介绍相关的功能或类）：
- en: '![Getting started II: Accessing the camera live feed using OpenCV](img/9727OS_09_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![开始 II：使用 OpenCV 访问相机实时流](img/9727OS_09_01.jpg)'
- en: In particular, we will demonstrate how to extract an image frame from the camera
    video stream for further image processing steps. The OpenCV library provides camera
    support for accessing the live camera feed (the raw data buffer of the video data
    stream) as well as controlling the camera parameters. This feature allows us to
    get the raw frame data from the live preview camera with optimal resolution, frame
    rate, and image format.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我们将演示如何从相机视频流中提取图像帧，以进行后续的图像处理步骤。OpenCV 库提供了对访问实时相机流的相机支持（视频数据流的原始数据缓冲区）以及控制相机参数。此功能允许我们以最佳分辨率、帧率和图像格式从实时预览相机中获取原始帧数据。
- en: Getting ready
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The demos in this chapter build upon the basic structure introduced in the sample
    code of [Chapter 8](ch08.html "Chapter 8. Interactive Real-time Data Visualization
    on Mobile Devices"), *Interactive Real-time Data Visualization on Mobile Devices*
    which utilizes the multi-touch interface and motion sensor inputs to enable interactive
    real-time data visualization on mobile devices. The major changes that are made
    to support OpenCV will be highlighted. For the complete code, download the code
    package from the Packt Publishing website.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的示例基于第 8 章示例代码中介绍的基本结构，即 *移动设备上的交互式实时数据可视化*，它利用多点触控界面和运动传感器输入，在移动设备上实现交互式实时数据可视化。为了支持
    OpenCV 所做的重大更改将在本章中突出显示。完整的代码，请从 Packt Publishing 网站下载代码包。
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, we will highlight the changes to the Java source files required to enable
    the use of OpenCV and the OpenCV camera module. Rename `GL3JNIActivity.java` (`src/com/android/gl3jni/`)
    as `GL3OpenCVDemo.java` and modify the code as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将突出显示修改Java源文件所需的更改，以启用OpenCV和OpenCV相机模块的使用。将`GL3JNIActivity.java`（`src/com/android/gl3jni/`）重命名为`GL3OpenCVDemo.java`，并按以下方式修改代码：
- en: 'Include the packages for the OpenCV library:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包含OpenCV库的包：
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Add the `CvCameraViewListener2` interface to the `GL3OpenCVDemo` class:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`CvCameraViewListener2`接口添加到`GL3OpenCVDemo`类：
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the variables to handle the camera view:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建处理相机视图的变量：
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Implement the `BaseLoaderCallback` function for `OpenCVLoader`:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现`BaseLoaderCallback`函数，用于`OpenCVLoader`：
- en: '[PRE7]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Implement the OpenCV camera callback functions and pass the image data to the
    JNI C/C++ side for processing and rendering:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现OpenCV相机回调函数，并将图像数据传递到JNI C/C++侧进行处理和渲染：
- en: '[PRE8]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Initialize the camera in the `onCreate` function, upon starting the application:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序启动时，在`onCreate`函数中初始化相机：
- en: '[PRE9]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load the OpenCV library using the asynchronized initialization function called
    `initAsync` from the `OpenCVLoader` class. This event is captured by the `BaseLoaderCallback
    mLoaderCallback` function defined earlier:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`OpenCVLoader`类中的异步初始化函数`initAsync`加载OpenCV库。此事件由之前定义的`BaseLoaderCallback
    mLoaderCallback`函数捕获：
- en: '[PRE10]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, handle the `onPause` event, which pauses the camera preview when the
    application is no longer running in the foreground:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，处理`onPause`事件，当应用程序不再在前台运行时，暂停相机预览：
- en: '[PRE11]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now inside `GL3JNILib.java` (`src/com/android/gl3jni/`), add the native `setImage`
    function to pass the camera raw data. The entire source file is shown here, given
    its simplicity:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在在`GL3JNILib.java`（`src/com/android/gl3jni/`）中，添加原生的`setImage`函数以传递相机原始数据。由于源文件的简单性，此处显示了整个源文件：
- en: '[PRE12]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, the source code inside `GL3JNIView.java` is virtually identical except
    that we offer the option to reset the rotation data and call the `setZOrderOnTop`
    function to ensure that the OpenGL layer is on top of the Java layer:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，`GL3JNIView.java`文件内的源代码几乎完全相同，除了我们提供了重置旋转数据并调用`setZOrderOnTop`函数的选项，以确保OpenGL层位于Java层之上：
- en: '[PRE13]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Finally, define the JNI prototypes to interface with the Java side in the `main.cpp`
    file that connects all components.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在`main.cpp`文件中定义JNI原型，该文件连接所有组件，以与Java侧进行接口：
- en: '[PRE14]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To access the device camera, the following elements must be declared in the
    `AndroidManifest.xml` file to ensure we have the permission to control the camera.
    In our current example, we request access to the front and back cameras with autofocus
    support.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要访问设备相机，必须在`AndroidManifest.xml`文件中声明以下元素，以确保我们有控制相机的权限。在我们的当前示例中，我们请求访问具有自动对焦支持的前后摄像头。
- en: '[PRE15]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: At this point, we have developed a full demo application that supports OpenCV
    and real-time camera feed. In the next section, we will connect the camera raw
    data stream to the OpenGL layer and perform real-time feature extraction with
    OpenCV in C/C++.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经开发了一个支持OpenCV和实时相机流的完整演示应用程序。在下一节中，我们将连接相机原始数据流到OpenGL层，并在C/C++中使用OpenCV进行实时特征提取。
- en: How it works...
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: On the Java side, we have integrated the OpenCV Manager (installed previously)
    to handle the dynamic loading of all libraries at runtime. Upon starting the application,
    we must call the `OpenCVLoader.initAsync` function; all OpenCV-related JNI libraries
    must only be called after the OpenCV libraries are successfully loaded. To synchronize
    these actions in our case, the `callback` function (`BaseLoaderCallback`) checks
    the status of the initialization of OpenCV, and we proceed with the `System.loadLibrary`
    function to initialize OpenGL and other components only if the OpenCV loader returns
    success (`LoaderCallbackInterface.SUCCESS`). For simplicity, we did not include
    the implementation to handle library loading exceptions in this demo.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java方面，我们已经集成了之前安装的OpenCV Manager来处理运行时所有库的动态加载。在启动应用程序时，我们必须调用`OpenCVLoader.initAsync`函数；所有与OpenCV相关的JNI库必须在OpenCV库成功加载后才能调用。为了同步这些操作，在我们的情况下，`callback`函数（`BaseLoaderCallback`）检查OpenCV初始化的状态，并且只有当OpenCV加载器返回成功（`LoaderCallbackInterface.SUCCESS`）时，我们才使用`System.loadLibrary`函数来初始化OpenGL和其他组件。为了简化，我们没有在这个示例中包含处理库加载异常的实现。
- en: On the sensor side, we have also changed the implementation for the `SensorManager`
    function to return the rotation matrix instead of the Euler angles to avoid the
    issue of Gimbal lock (refer to [http://en.wikipedia.org/wiki/Gimbal_lock](http://en.wikipedia.org/wiki/Gimbal_lock)).
    We also remapped the coordinates (from device orientation to OpenGL camera orientation)
    using the `SensorManager.remapCoordinateSystem` function. Then the rotation matrix
    is directed to the OpenGL side with the native calls `GL3JNILib.setRotMatrix`.
    Also, we can allow the user to reset the default orientation by touching the screen.
    This is achieved by calling the `GL3JNILib.resetRotDataOffset` function, which
    resets the rotation matrix with the touch event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在传感器方面，我们还改变了`SensorManager`函数的实现，以返回旋转矩阵而不是欧拉角，以避免陀螺仪锁定问题（参考[http://en.wikipedia.org/wiki/Gimbal_lock](http://en.wikipedia.org/wiki/Gimbal_lock)）。我们还使用`SensorManager.remapCoordinateSystem`函数重新映射坐标（从设备方向到OpenGL摄像头方向）。然后，旋转矩阵通过原生调用`GL3JNILib.setRotMatrix`传递到OpenGL端。此外，我们可以允许用户通过触摸屏幕重置默认方向。这是通过调用`GL3JNILib.resetRotDataOffset`函数实现的，该函数使用触摸事件重置旋转矩阵。
- en: Additionally, we have added the `OpenCV CvCameraViewListener2` interface and
    `CameraBridgeViewBase` class to enable native camera access. The `CameraBridgeViewBase`
    class is a basic class that handles the interaction with the Android Camera class
    and OpenCV library. It is responsible for controlling the camera, such as resolution,
    and processing the frame, such as changing the image format. The client implements
    `CvCameraViewListener` to receive callback events. In the current implementation,
    we manually set the resolution as 1280 x 720\. However, we can increase or decrease
    the resolution based on the application needs. Finally, the color frame buffers
    are returned in RGBA format, and the data stream will be transferred to the JNI
    C/C++ side and rendered using texture mapping.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还添加了`OpenCV CvCameraViewListener2`接口和`CameraBridgeViewBase`类，以实现原生摄像头访问。`CameraBridgeViewBase`类是一个基本类，用于处理与Android
    Camera类和OpenCV库的交互。它负责控制摄像头，例如分辨率，以及处理帧，例如更改图像格式。客户端实现`CvCameraViewListener`以接收回调事件。在当前实现中，我们手动将分辨率设置为1280
    x 720。然而，我们可以根据应用需求增加或减少分辨率。最后，颜色帧缓冲区以RGBA格式返回，数据流将被传输到JNI C/C++端并使用纹理映射进行渲染。
- en: Displaying real-time video using texture mapping
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用纹理映射显示实时视频
- en: Today, most mobile phones are equipped with cameras that are capable of capturing
    high-quality photos as well as videos. For example, the Samsung Galaxy Note 4
    is equipped with a 16MP back-facing camera as well as a 3.7MP front-facing camera
    for video conferencing applications. With these built-in cameras, we can record
    high-definition videos with exceptional image quality in both outdoor and indoor
    environments. The ubiquity of these imaging sensors, as well as the increasing
    computational capability of mobile processors, now enable us to develop much more
    interactive applications such as real-time tracking of objects or faces.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，大多数手机都配备了能够捕捉高质量照片和视频的摄像头。例如，三星Galaxy Note 4配备了1600万像素的后置摄像头以及370万像素的前置摄像头，用于视频会议应用。有了这些内置摄像头，我们可以在户外和室内环境中录制具有卓越图像质量的高清视频。这些成像传感器的普遍存在以及移动处理器的计算能力不断提高，现在使我们能够开发出更多交互式应用，例如实时跟踪物体或人脸。
- en: By combining OpenGL with the OpenCV library, we can create interactive applications
    that perform real-time video processing of the real world to register and augment
    3D virtual information onto real-world objects. Since both libraries are hardware-accelerated
    (GPU and CPU optimized), it is important that we explore the use of these libraries
    to obtain real-time performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合OpenGL和OpenCV库，我们可以创建交互式应用，这些应用可以对现实世界进行实时视频处理，以注册和增强3D虚拟信息到现实世界物体上。由于这两个库都是硬件加速的（GPU和CPU优化），探索使用这些库以获得实时性能非常重要。
- en: 'In the previous section, we introduced the framework that provides access to
    the live camera feed. Here, we will create a full demo that displays real-time
    video using OpenGL-based texture mapping techniques (similar to those introduced
    in [Chapter 4](ch04.html "Chapter 4. Rendering 2D Images and Videos with Texture
    Mapping"), *Rendering 2D Images and Videos with Texture Mapping* to [Chapter 6](ch06.html
    "Chapter 6. Rendering Stereoscopic 3D Models using OpenGL"), *Rendering Stereoscopic
    3D Models using OpenGL*, except we will deploy OpenGL ES for mobile platforms),
    and processes the video stream to perform corner detection using OpenCV. To help
    readers understand the additional code needed to finalize the demo, here is an
    overview diagram of the implementation:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了提供访问实时摄像头流的框架。在这里，我们将创建一个完整的演示，使用基于OpenGL的纹理映射技术（类似于在第4章（ch04.html
    "第4章. 使用纹理映射渲染2D图像和视频"）到第6章（ch06.html "第6章. 使用OpenGL渲染立体3D模型"）中介绍的）显示实时视频，并使用OpenCV处理视频流以执行角点检测。为了帮助读者理解完成演示所需的额外代码，以下是实现概述图：
- en: '![Displaying real-time video using texture mapping](img/9727OS_09_02.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![使用纹理映射显示实时视频](img/9727OS_09_02.jpg)'
- en: Getting ready
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: This demo requires the completion of all the *Getting ready* steps to enable
    the capture of the real-time video stream using OpenCV on an Android device. The
    implementation of the shader program and texture mapping code is based on the
    demos from [Chapter 8](ch08.html "Chapter 8. Interactive Real-time Data Visualization
    on Mobile Devices"), *Interactive Real-time Data Visualization on Mobile Devices*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此演示需要完成所有*准备工作*步骤，以便在Android设备上使用OpenCV捕获实时视频流。着色器程序和纹理映射代码的实现基于第8章（ch08.html
    "第8章. 移动设备上的交互式实时数据可视化"）中的演示。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: On the native code side, create two new files called `VideoRenderer.hpp` and
    `VideoRenderer.cpp`. These files contain the implementation to render the video
    using texture mapping. Also, we will import the `Texture.cpp` and `Texture.hpp`
    files from the previous chapter to handle texture creation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地代码方面，创建两个新的文件，分别命名为`VideoRenderer.hpp`和`VideoRenderer.cpp`。这些文件包含使用纹理映射渲染视频的实现。此外，我们还将从上一章导入`Texture.cpp`和`Texture.hpp`文件来处理纹理创建。
- en: 'Inside the `VideoRenderer.hpp` file, define the `VideoRenderer` class as follows
    (the details of each function will be discussed next):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在`VideoRenderer.hpp`文件中，按照以下方式定义`VideoRenderer`类（每个函数的详细信息将在下一节讨论）：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Inside the `VideoRenderer.cpp` file, we implement each of the three key member
    functions (`setup`, `initTexture`, and `render`). Here is the complete implementation:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在`VideoRenderer.cpp`文件中，我们实现了三个关键成员函数（`setup`、`initTexture`和`render`）。以下是完整的实现：
- en: 'Include the `VideoRenderer.hpp` header file, define functions to print debug
    messages, and define the constructor and destructor:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包含`VideoRenderer.hpp`头文件，定义打印调试信息的函数，并定义构造函数和析构函数：
- en: '[PRE17]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define the vertex and fragment shaders as well as associated configuration
    steps (similar to [Chapter 8](ch08.html "Chapter 8. Interactive Real-time Data
    Visualization on Mobile Devices"), *Interactive Real-time Data Visualization on
    Mobile Devices*):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义顶点和片段着色器以及相关的配置步骤（类似于[第8章](ch08.html "第8章. 移动设备上的交互式实时数据可视化")，*移动设备上的交互式实时数据可视化*）：
- en: '[PRE18]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Initialize and bind the texture:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化并绑定纹理：
- en: '[PRE19]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Render the camera feed on the screen with texture mapping:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用纹理映射在屏幕上渲染摄像头流：
- en: '[PRE20]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: To further enhance the readability of the code, we encapsulate the handling
    of the shader program and texture mapping inside `Shader.hpp` (`Shader.cpp`) and
    `Texture.hpp` (`Texture.cpp`), respectively. We will only show the header files
    here for completeness and refer readers to the code package on the Packt Publishing
    website for the detailed implementation of each function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高代码的可读性，我们将着色器程序和纹理映射的处理封装在`Shader.hpp`（`Shader.cpp`）和`Texture.hpp`（`Texture.cpp`）中，分别。这里我们只展示头文件以示完整，并请读者参考Packt
    Publishing网站上的代码包以获取每个函数的详细实现。
- en: 'Here is the `Shader.hpp` file:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`Shader.hpp`文件：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `Texture.hpp` file should read:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`Texture.hpp`文件应如下所示：'
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we integrate everything inside the `main.cpp` file with the following
    steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们按照以下步骤在`main.cpp`文件中整合所有内容：
- en: Include all headers. In particular, include `pthread.h` to handle synchronization
    and OpenCV libraries for image processing.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包含所有头文件。特别是，包含 `pthread.h` 以处理同步和 OpenCV 库以进行图像处理。
- en: '[PRE23]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Define the `VideoRenderer` and `Shader` objects, as well as the `pthread_mutex_t`
    lock variable to handle synchronization for data copying using a mutex lock.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `VideoRenderer` 和 `Shader` 对象，以及 `pthread_mutex_t` 锁变量，以使用互斥锁处理数据复制的同步。
- en: '[PRE24]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Set up the `VideoRenderer` object in the `setupGraphics` function and initialize
    the texture.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `setupGraphics` 函数中设置 `VideoRenderer` 对象并初始化纹理。
- en: '[PRE25]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Create a `processFrame` helper function to handle feature extraction with the
    OpenCV `goodFeaturesToTrack` function. The function also draws the result directly
    on the frame for visualization.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `processFrame` 辅助函数，用于处理使用 OpenCV 的 `goodFeaturesToTrack` 函数的特征提取。该函数还直接在帧上绘制结果以进行可视化。
- en: '[PRE26]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Implement frame copying with mutex lock synchronization (to avoid frame corruption
    due to shared memory and race condition) in the `renderFrame` function. Process
    the frame with the OpenCV library and render the result using OpenGL texture-mapping
    techniques.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `renderFrame` 函数中实现带有互斥锁同步的帧复制（以避免由于共享内存和竞态条件导致的帧损坏）。使用 OpenCV 库处理帧，并使用 OpenGL
    纹理映射技术渲染结果。
- en: '[PRE27]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Define the JNI prototypes and implement the `setImage` function, which receives
    the raw camera image data from the Java side using a mutex lock to ensure data
    copying is protected. Also, implement the `toggleFeatures` function to turn feature
    tracking on and off upon touching the screen.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 JNI 原型并实现 `setImage` 函数，该函数通过互斥锁确保数据复制受保护，从 Java 端接收原始相机图像数据。还实现了 `toggleFeatures`
    函数，用于在触摸屏幕时开启和关闭特征跟踪。
- en: '[PRE28]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![How to do it...](img/9727OS_09_03.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/9727OS_09_03.jpg)'
- en: The resulting image is a post-processed frame from OpenCV. In addition to displaying
    the raw video frame, we demonstrate that our implementation can easily be extended
    to support real-time video processing with OpenCV. The `processFrame` function
    uses the OpenCV `goodFeaturesToTrack` corner detection function and we overlay
    all corners extracted from the scene on the image.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像是来自 OpenCV 的后处理帧。除了显示原始视频帧外，我们还展示了我们的实现可以轻松扩展以支持使用 OpenCV 的实时视频处理。`processFrame`
    函数使用 OpenCV 的 `goodFeaturesToTrack` 角点检测功能，并将从场景中提取的所有角点叠加到图像上。
- en: Image features are the fundamental elements for many tracking algorithms such
    as **Simultaneous localization and Mapping** (**SLAM**) as well as recognition
    algorithms such as image-based matching. For example, with the SLAM algorithm,
    we can construct a map of the environment and, at the same time, keep track of
    the position of the device in space. Such techniques are particularly useful in
    AR applications as we always need to align the virtual world with the real world.
    Next, we can see a feature extraction algorithm (corner detection) running in
    real-time on a mobile phone.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图像特征是许多跟踪算法（如**同时定位与建图**（**SLAM**））以及识别算法（如基于图像的匹配）的基本元素。例如，使用 SLAM 算法，我们可以构建环境的地图，并同时跟踪设备在空间中的位置。这些技术在
    AR 应用中特别有用，因为我们始终需要将虚拟世界与真实世界对齐。接下来，我们可以看到在手机上实时运行的特征提取算法（角点检测）。
- en: '![How to do it...](img/9727OS_09_04.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/9727OS_09_04.jpg)'
- en: How it works...
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `VideoRenderer` class has two primary functions:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`VideoRenderer` 类有两个主要功能：'
- en: Creating the shader program that handles texture mapping (`Shader.cpp` and `Texture.cpp`).
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建处理纹理映射的着色器程序（`Shader.cpp` 和 `Texture.cpp`）。
- en: Updating the texture memory with the OpenCV raw camera frame. Each time a new
    frame is retrieved from OpenCV, we call the render function, which updates the
    texture memory and also draws the frame on the screen.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenCV 的原始相机帧更新纹理内存。每次从 OpenCV 获取新帧时，我们调用渲染函数，该函数更新纹理内存并在屏幕上绘制帧。
- en: The `main.cpp` file connects all the components of the implementation, and encapsulates
    all the logics for the interaction. It interfaces with the Java side (for example,
    `setImage`) and we offload all computationally intensive tasks to the C++ native
    side. For example, the `processFrame` function handles the OpenCV video processing
    pipeline, and we can efficiently handle memory I/O and parallelization. On the
    other hand, the `VideoRenderer` class accelerates rendering with OpenGL for real-time
    performance on the mobile platform.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`main.cpp` 文件连接了实现的所有组件，并封装了所有交互逻辑。它与Java端（例如，`setImage`）接口，我们将所有计算密集型任务卸载到C++原生端。例如，`processFrame`
    函数处理OpenCV视频处理管道，我们可以高效地处理内存I/O和并行化。另一方面，`VideoRenderer` 类通过OpenGL加速渲染，以在移动平台上实现实时性能。'
- en: One may notice that the implementations of OpenGL and OpenCV on Android are
    mostly identical to the desktop version. That's the key reason why we employ such
    cross-platform languages as we can easily extend our code to any future platform
    with minimal effort.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有人会注意到，Android上的OpenGL和OpenCV的实现与桌面版本大多相同。这就是我们采用跨平台语言的关键原因，我们可以轻松地将代码扩展到任何未来平台，而无需付出太多努力。
- en: See also
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'On a mobile platform, computational resources are particularly limited and
    thus it is important to optimize the use of all available hardware resources.
    With OpenGL-based hardware acceleration, we can reduce most of our overhead in
    rendering graphics in 2D and 3D on the graphics processor. In the near future,
    especially with the emergence of mobile processors supporting GPGPU (for example,
    Nvidia''s K1 mobile processor), we will enable more parallelized processing for
    computer vision algorithms and offer real-time performance for many applications
    on a mobile device. For example, Nvidia now officially supports CUDA for all its
    upcoming mobile processors, so we will see many more real-time image processing,
    machine learning (such as deep learning algorithms), and high-performance graphics
    emerging on the mobile platform. See the following website for more information:
    [https://developer.nvidia.com/embedded-computing](https://developer.nvidia.com/embedded-computing).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在移动平台上，计算资源尤其有限，因此优化所有可用硬件资源的利用非常重要。基于OpenGL的硬件加速可以减少我们在图形处理器上渲染2D和3D图形的大部分开销。在不久的将来，特别是随着支持GPGPU的移动处理器的出现（例如，Nvidia的K1移动处理器），我们将为计算机视觉算法提供更多并行化处理，并为移动设备上的许多应用提供实时性能。例如，Nvidia现在正式支持其所有即将推出的移动处理器上的CUDA，因此我们将在移动平台上看到更多实时图像处理、机器学习（如深度学习算法）和高性能图形的出现。更多信息请参阅以下网站：[https://developer.nvidia.com/embedded-computing](https://developer.nvidia.com/embedded-computing)。
- en: Augmented reality-based data visualization over real-world scenes
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于增强现实的真实世界场景数据可视化
- en: 'In our ultimate demo, we will introduce the basic framework for AR-based data
    visualization by overlaying 3D data on real-world objects and scenes. We apply
    the same GPU-accelerated simulation model and register it to the world with a
    sensor-based tracking approach. The following diagram illustrates the final architecture
    of the implementation in this chapter:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的最终演示中，我们将通过在现实世界的物体和场景上叠加3D数据来介绍基于AR的数据可视化的基本框架。我们应用相同的GPU加速模拟模型，并使用基于传感器的跟踪方法将其注册到世界中。以下图表展示了本章实现中的最终架构：
- en: '![Augmented reality-based data visualization over real-world scenes](img/9727OS_09_08.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![基于增强现实的真实世界场景数据可视化](img/9727OS_09_08.jpg)'
- en: Getting ready
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: This final demo integrates together all the concepts previously introduced in
    this chapter and requires the capture (and possibly processing) of a real-time
    video stream using OpenCV on an Android-based phone. To reduce the complexity
    of the code, we have created the Augmented Reality layer (`AROverlayRenderer`)
    and we can improve the registration, alignment, and calibration of the layer with
    more advanced algorithms in the future.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最终演示整合了本章之前介绍的所有概念，并需要在基于Android的手机上使用OpenCV捕获（并可能处理）实时视频流。为了减少代码的复杂性，我们创建了增强现实层（`AROverlayRenderer`），我们可以在未来使用更先进的算法来改进层的注册、对齐和校准。
- en: How to do it...
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Let''s define a new class called `AROverlayRenderer` inside the `AROverlayRenderer.hpp`
    file:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `AROverlayRenderer.hpp` 文件中定义一个新的类 `AROverlayRenderer`：
- en: '[PRE29]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now implement the `AROverlayRenderer` member functions inside the `AROverlayRenderer.cpp`
    file:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在 `AROverlayRenderer.cpp` 文件中实现 `AROverlayRenderer` 成员函数：
- en: 'Include the `AROverlayRenderer.hpp` header file and define functions to print
    messages as well as the constructor and destructor:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包含 `AROverlayRenderer.hpp` 头文件，并定义打印消息以及构造函数和析构函数：
- en: '[PRE30]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Initialize the grid pattern for the simulation:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化模拟的网格模式：
- en: '[PRE31]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Set up the shader program to overlay graphics:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置用于叠加图形的着色器程序：
- en: '[PRE32]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Create helper functions to set the scale, screen size, and rotation variables
    from the touch interface:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建辅助函数，从触摸界面设置比例、屏幕大小和旋转变量：
- en: '[PRE33]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Compute the projection and view matrices based on the camera parameters:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据相机参数计算投影和视图矩阵：
- en: '[PRE34]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Render the graphics on the screen:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在屏幕上渲染图形：
- en: '[PRE35]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we only need to make minor modifications to the `main.cpp` file used
    in the previous demo to enable the AR overlay on top of the real-time video stream
    (real-world scene). Only the relevant code snippets that highlight the required
    modifications are shown here (download the complete code from the Packt Publishing
    website):'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们只需要对之前演示中使用的 `main.cpp` 文件进行少量修改，即可在实时视频流（现实场景）上启用 AR 叠加。这里只展示了突出所需修改的相关代码片段（从
    Packt Publishing 网站下载完整代码）：
- en: '[PRE36]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'With this framework, one can overlay virtually any dataset on different real-world
    objects or surfaces and enable truly interactive applications, using the built-in
    sensors and gesture interface on mobile devices and emerging state-of-the-art
    wearable AR eyeglasses. Following are the results demonstrating a real-time, interactive,
    AR-based visualization of a 3-D dataset (in this case, a Gaussian distribution)
    overlaid on real-world scenes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个框架，可以在不同的现实世界物体或表面上叠加任何虚拟数据集，并启用真正交互式应用程序，使用移动设备内置的传感器和手势界面以及新兴的最先进可穿戴 AR
    眼镜。以下是一些结果，展示了基于 AR 的实时、交互式 3-D 数据集（在这种情况下，高斯分布）叠加在现实场景中的可视化：
- en: '![How to do it...](img/9727OS_09_05.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/9727OS_09_05.jpg)'
- en: How it works...
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The key element for enabling an AR application is the ability is overlay information
    onto the real world. The `AROverlayRenderer` class implements the core functions
    essential to all AR applications. First, we create a virtual camera that matches
    the parameters of the actual camera on the mobile phone. Parameters such as the
    **field of view** (**FOV**) and aspect ratio of the camera are currently hard-coded,
    but we can easily modify them in the `computeProjectionMatrices` function. Then,
    to perform the registration between the real world and virtual world, we control
    the orientation of the virtual camera based on the orientation of the device.
    The orientation values are fed through the rotation matrix passed from the Java
    side (the `setRotMatrix` function) and we apply this directly to the OpenGL camera
    view matrix (`view_matrix`). Also, we use the multi-touch interface of the mobile
    phone to reset the default orientation of the rotation matrix. This is achieved
    by storing the rotational matrix value upon the touch event (the `resetRotDataOffset`
    function) and we apply the inverse to the rotational matrix to the view matrix
    (this is equivalent to rotating the camera in the opposite direction).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 AR 应用程序的关键要素是将信息叠加到现实世界中的能力。`AROverlayRenderer` 类实现了所有 AR 应用程序必需的核心功能。首先，我们创建一个虚拟相机，其参数与手机上实际相机的参数相匹配。相机的参数，如**视野**（**FOV**）和宽高比，目前是硬编码的，但我们可以很容易地在
    `computeProjectionMatrices` 函数中修改它们。然后，为了在现实世界和虚拟世界之间进行注册，我们根据设备的方向控制虚拟相机的方向。方向值通过从
    Java 端传递的旋转矩阵（`setRotMatrix` 函数）输入，我们将其直接应用于 OpenGL 相机视图矩阵（`view_matrix`）。此外，我们使用手机的触摸屏界面来重置旋转矩阵的默认方向。这是通过在触摸事件（`resetRotDataOffset`
    函数）上存储旋转矩阵值来实现的，并将旋转矩阵的逆应用于视图矩阵（这相当于将相机向相反方向旋转）。
- en: In terms of user interaction, we have enabled the pinch and drag option to support
    dynamic interaction with the virtual object. Upon the pinch event, we take the
    scale factor and we position the rendered object at a farther distance by applying
    the `glm::translate` function on the `model_matrix` variable. In addition, we
    rotate the virtual object by capturing the dragging action from the Java side
    (the `setDxDy` function). The user can control the orientation of the virtual
    object by dragging a finger across the screen. Together, these multi-touch gestures
    enable a highly interactive application interface that allows users to change
    the perspective of the rendered object intuitively.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户交互方面，我们已启用捏合和拖动选项以支持与虚拟对象的动态交互。在捏合事件发生时，我们获取缩放因子，并通过在 `model_matrix` 变量上应用
    `glm::translate` 函数将渲染对象放置在更远的位置。此外，我们通过捕获 Java 端的拖动动作（`setDxDy` 函数）来旋转虚拟对象。用户可以通过在屏幕上拖动手指来控制虚拟对象的朝向。这些多指手势共同实现了一个高度交互的应用程序界面，使用户能够直观地改变渲染对象的视角。
- en: 'Due to the underlying complexity of the calibration process, we will not cover
    these details here. However, advanced users may consult the following website
    for a more in-depth discussion: [http://docs.opencv.org/doc/tutorials/calib3d/camera_calibration/camera_calibration.html](http://docs.opencv.org/doc/tutorials/calib3d/camera_calibration/camera_calibration.html).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于校准过程的潜在复杂性，我们在此不涵盖这些细节。然而，高级用户可以参考以下网站以进行更深入的讨论：[http://docs.opencv.org/doc/tutorials/calib3d/camera_calibration/camera_calibration.html](http://docs.opencv.org/doc/tutorials/calib3d/camera_calibration/camera_calibration.html)。
- en: Also, the current registration process is purely based on the IMU, and it does
    not support translation (that is, the virtual object does not move exactly with
    the real world). To address this, we can apply various image-processing techniques
    such as mean shift tracking, feature-based tracking, and marker-based tracking
    to recover the full 6 DOF (degree of freedom) model of the camera. SLAM, for example,
    is a great candidate to recover the 6 DOF camera model, but its detailed implementation
    is beyond the scope of this chapter.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当前的注册过程完全基于 IMU，并且不支持平移（即虚拟对象不会与真实世界精确移动）。为了解决这个问题，我们可以应用各种图像处理技术，如均值漂移跟踪、基于特征的跟踪和基于标记的跟踪，以恢复摄像头的完整
    6 自由度 (DOF) 模型。例如，SLAM 是恢复 6 自由度摄像头模型的一个很好的候选方案，但其详细实现超出了本章的范围。
- en: See also
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'Indeed, in this chapter, we have only covered the fundamentals of AR. The field
    of AR is becoming an increasingly hot topic in both academia and industry. If
    you are interested in implementing AR data visualization applications on the latest
    wearable computing platforms (such as the one provided by Meta that features 3D
    gesture input and 3D stereoscopic output), visit the following websites:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，在本章中，我们只涵盖了增强现实 (AR) 的基础知识。AR 领域在学术界和工业界都变得越来越热门。如果您对在最新的可穿戴计算平台上实现 AR 数据可视化应用（例如，Meta
    提供的具有 3D 手势输入和 3D 立体输出的平台）感兴趣，请访问以下网站：
- en: '[https://www.getameta.com/](https://www.getameta.com/)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.getameta.com/](https://www.getameta.com/)'
- en: '[http://www.eyetap.org/publications/](http://www.eyetap.org/publications/)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.eyetap.org/publications/](http://www.eyetap.org/publications/)'
- en: 'For further technical details on AR eyeglasses, please consult the following
    publications:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 AR 眼镜的更多技术细节，请参阅以下出版物：
- en: Raymond Lo, Alexander Chen, Valmiki Rampersad, Jason Huang, Han Wu, Steve Mann
    (2013). "Augmediated reality system based on 3D camera selfgesture sensing," IEEE
    International Symposium on Technology and Society (ISTAS) 2013, pp. 20-31.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raymond Lo, Alexander Chen, Valmiki Rampersad, Jason Huang, Han Wu, Steve Mann
    (2013). "基于 3D 摄像头自手势感知的增强现实系统," IEEE 国际技术与社会研讨会 (ISTAS) 2013，第 20-31 页。
- en: Raymond Lo, Valmiki Rampersad, Jason Huang, Steve Mann (2013). "Three Dimensional
    High Dynamic Range Veillance for 3D Range-Sensing Cameras," IEEE International
    Symposium on Technology and Society (ISTAS) 2013, pp. 255-265.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raymond Lo, Valmiki Rampersad, Jason Huang, Steve Mann (2013). "三维高动态范围监控用于
    3D 范围感测摄像头," IEEE 国际技术与社会研讨会 (ISTAS) 2013，第 255-265 页。
- en: Raymond Chun Hing Lo, Steve Mann, Jason Huang, Valmiki Rampersad, and Tao Ai.
    2012\. "High Dynamic Range (HDR) Video Image Processing For Digital Glass." In
    Proceedings of the 20th ACM international conference on Multimedia (MM '12). ACM,
    New York, NY, USA, pp. 1477-1480.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raymond Chun Hing Lo, Steve Mann, Jason Huang, Valmiki Rampersad, and Tao Ai.
    2012\. "高动态范围 (HDR) 视频图像处理用于数字玻璃." 在第 20 届 ACM 国际多媒体会议 (MM '12) 论文中。ACM，纽约，纽约，美国，第
    1477-1480 页。
- en: 'Steve Mann, Raymond Lo, Jason Huang, Valmiki Rampersad, Ryan Janzen, Tao Ai
    (2012). "HDRchitecture: Real-Time stereoscopic HDR Imaging for Extreme Dynamic
    Range," In ACM SIGGRAPH 2012 Emerging Technologies (SIGGRAPH ''12).'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '史蒂夫·曼恩，雷蒙德·洛，黄杰森，瓦尔米基·兰佩拉斯，瑞安·詹森，爱涛（2012）。"HDRchitecture: 极大动态范围的实时立体HDR成像"，载于ACM
    SIGGRAPH 2012新兴技术（SIGGRAPH ''12）。'
