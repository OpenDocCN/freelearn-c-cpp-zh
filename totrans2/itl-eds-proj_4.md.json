["```cpp\nsrc/gz all http://repo.opkg.net/edison/repo/all\nsrc/gz edison http://repo.opkg.net/edison/repo/edison\nsrc/gz core2-32 http://repo.opkg.net/edison/repo/core2-32  \n\n```", "```cpp\necho \"src/gz all http://repo.opkg.net/edison/repo/all\nsrc/gz edison http://repo.opkg.net/edison/repo/edison\nsrc/gz core2-32 http://repo.opkg.net/edison/repo/core2-32\" >> /etc/opkg/base-feeds.conf \n\n```", "```cpp\nopkg update  \n\n```", "```cpp\nopkg install git  \n\n```", "```cpp\n git clone https://github.com/drejkim/edison-scripts.git ~/edison\n      scripts\n\n```", "```cpp\n echo'export PATH=$PATH:~/edison-scripts'>>~/.profile\n source~/.profile  \n\n```", "```cpp\n # Resize /boot -- we need the extra space to add an additional\n      kernel resizeBoot.sh\n\n # Install pip, Python's package manager installPip.sh\n\n # Install MRAA, the low level skeleton library for IO\n      communication on, Edison, and other platforms installMraa.sh\n\n```", "```cpp\n      opkg install kernel-modules\n\n```", "```cpp\naplay -Ll  \n\n```", "```cpp\npcm.!default sysdefault:Device\n\n```", "```cpp\naplay /usr/share/sounds/alsa/Front_Center.wav\n\n```", "```cpp\narecord ~/test.wav\n\n```", "```cpp\naplay ~/test.wav\n\n```", "```cpp\npip install cython\n\n```", "```cpp\n git clone \n\n```", "```cpp\nchmod +x <FILE_NAME>\n\n```", "```cpp\n./installSphinxbase.sh\n\n```", "```cpp\necho 'export LD_LIBRARY_PATH=/usr/local/lib' >> ~/.profile\necho 'export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig' >> ~/.profile\nsource ~/.profile\n\n```", "```cpp\n./installPocketsphinx.sh\n\n```", "```cpp\n./installPyAudio.sh\n\n```", "```cpp\nimport collections \nimport mraa \nimport os \nimport sys \nimport time \n\n# Import things for pocketsphinx \nimport pyaudio \nimport wave \nimport pocketsphinx as ps \nimport sphinxbase \n\nled = mraa.Gpio(13)   \nled.dir(mraa.DIR_OUT) \n\nprint(\"Starting\") \nwhile 1: \n         #PocketSphinx parameters \n         LMD   = \"/home/root/vcreg/5608.lm\" \n         DICTD = \"/home/root/vcreg/5608.dic\" \n         CHUNK = 1024 \n         FORMAT = pyaudio.paInt16 \n         CHANNELS = 1 \n         RATE = 16000 \n         RECORD_SECONDS = 3 \n         PATH = 'vcreg' \n         p = pyaudio.PyAudio() \n         speech_rec = ps.Decoder(lm=LMD, dict=DICTD) \n         #Record audio \n         stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n         input=True, frames_per_buffer=CHUNK) \n         print(\"* recording\") \n         frames = [] \n         fori in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n               data = stream.read(CHUNK) \n               frames.append(data) \n         print(\"* done recording\") \n         stream.stop_stream() \n         stream.close() \n         p.terminate() \n         # Write .wav file \n         fn = \"test.wav\" \n         #wf = wave.open(os.path.join(PATH, fn), 'wb') \n         wf = wave.open(fn, 'wb') \n         wf.setnchannels(CHANNELS) \n         wf.setsampwidth(p.get_sample_size(FORMAT)) \n         wf.setframerate(RATE) \n         wf.writeframes(b''.join(frames)) \n         wf.close() \n\n         # Decode speech \n         #wav_file = os.path.join(PATH, fn) \n         wav_file=fn \n         wav_file = file(wav_file,'rb') \n         wav_file.seek(44) \n         speech_rec.decode_raw(wav_file) \n         result = speech_rec.get_hyp() \n         recognised= result[0] \n         print(\"* LED section begins\") \n         print(recognised) \n         if recognised == 'ON.': \n               led.write(1) \n         else: \n               led.write(0) \n         cm = 'espeak \"'+recognised+'\"' \n         os.system(cm) \n\n```", "```cpp\nimport collections \nimport mraa \nimport os \nimport sys \nimport time \n\n# Import things for pocketsphinx \nimport pyaudio \nimport wave \nimport pocketsphinx as ps \nimport Sphinxbase \n\n```", "```cpp\nled = mraa.Gpio(13)   \nled.dir(mraa.DIR_OUT) \n\n```", "```cpp\n#PocketSphinx and Audio recording parameters \n         LMD   = \"/home/root/vcreg/5608.lm\" \n         DICTD = \"/home/root/vcreg/5608.dic\" \n         CHUNK = 1024 \n         FORMAT = pyaudio.paInt16 \n         CHANNELS = 1 \n         RATE = 16000 \n         RECORD_SECONDS = 3 \n         PATH = 'vcreg' \n         p = pyaudio.PyAudio() \n         speech_rec = ps.Decoder(lm=LMD, dict=DICTD) \n\n```", "```cpp\n#Record audio \n         stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n         input=True, frames_per_buffer=CHUNK) \n         print(\"* recording\") \n         frames = [] \n         fori in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n               data = stream.read(CHUNK) \n               frames.append(data) \n         print(\"* done recording\") \n         stream.stop_stream() \n         stream.close() \n         p.terminate() \n\n```", "```cpp\n# Write .wav file \n         fn = \"test.wav\" \n         #wf = wave.open(os.path.join(PATH, fn), 'wb') \n         wf = wave.open(fn, 'wb') \n         wf.setnchannels(CHANNELS) \n         wf.setsampwidth(p.get_sample_size(FORMAT)) \n         wf.setframerate(RATE) \n         wf.writeframes(b''.join(frames)) \n         wf.close() \n\n```", "```cpp\n# Decode speech \n         #wav_file = os.path.join(PATH, fn) \n         wav_file=fn \n         wav_file = file(wav_file,'rb') \n         wav_file.seek(44) \n         speech_rec.decode_raw(wav_file) \n         result = speech_rec.get_hyp() \n         recognised= result[0] \n         print(\"* LED section begins\") \n         print(recognised) \n         if recognised == 'ON.': \n               led.write(1) \n         else: \n               led.write(0) \n         cm = 'espeak \"'+recognised+'\"' \n         os.system(cm) \n\n```", "```cpp\npython VoiceRecognitionTest.py \n\n```", "```cpp\npython Servo.py\n\n```", "```cpp\nfrom Servo import * \nimport time \nmyServo = Servo(\"Servo\") \nmyServo.attach(6) \nwhile True: \n   # From 0 to 180 degrees \n   for angle in range(0,180): \n         myServo.write(angle) \n         time.sleep(0.005) \n   # From 180 to 0 degrees \n   for angle in range(180,-1,-1): \n         myServo.write(angle) \n         time.sleep(0.005)             \n\n```", "```cpp\ndoor open close \n\n```", "```cpp\nimport collections \nimport mraa \nimport os \nimport sys \nimport time \n\n# Import things for pocketsphinx \nimport pyaudio \nimport wave \nimport pocketsphinx as ps \nimport sphinxbase \n# Import for Servo  \nfrom Servo import * \n\nled = mraa.Gpio(13)   \nled.dir(mraa.DIR_OUT) \nmyServo = Servo(\"First Servo\") \nmyServo.attach(6) \n\nprint(\"Starting\") \nwhile 1: \n         #PocketSphinx parameters \n         LMD   = \"/home/root/Voice-Recognition-using-Intel-Edison/8578.lm\" \n         DICTD = \"/home/root/Voice-Recognition-using-Intel-Edison/8578.dic\" \n         CHUNK = 1024 \n         FORMAT = pyaudio.paInt16 \n         CHANNELS = 1 \n         RATE = 16000 \n         RECORD_SECONDS = 3 \n         PATH = 'Voice-Recognition-using-Intel-Edison' \n         p = pyaudio.PyAudio() \n         speech_rec = ps.Decoder(lm=LMD, dict=DICTD) \n         #Record audio \n         stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK) \n         print(\"* recording\") \n         frames = [] \n         fori in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n               data = stream.read(CHUNK) \n               frames.append(data) \n         print(\"* done recording\") \n         stream.stop_stream() \n         stream.close() \n         p.terminate() \n         # Write .wav file \n         fn = \"test.wav\" \n         #wf = wave.open(os.path.join(PATH, fn), 'wb') \n         wf = wave.open(fn, 'wb') \n         wf.setnchannels(CHANNELS) \n         wf.setsampwidth(p.get_sample_size(FORMAT)) \n         wf.setframerate(RATE) \n         wf.writeframes(b''.join(frames)) \n         wf.close() \n\n         # Decode speech \n         #wav_file = os.path.join(PATH, fn) \n         wav_file=fn \n         wav_file = file(wav_file,'rb') \n         wav_file.seek(44) \n         speech_rec.decode_raw(wav_file) \n         result = speech_rec.get_hyp() \n         recognised= result[0] \n         print(\"* LED section begins\") \n         print(recognised) \n         ifrecognised == 'DOOR OPEN': \n               led.write(1) \n               myServo.write(90) \n         else: \n               led.write(0) \n               myServo.write(0) \n         cm = 'espeak \"'+recognised+'\"' \n         os.system(cm) \n\n```", "```cpp\nimportnumpy\nimport cv2 \n\n```", "```cpp\nopkg update\nopkg upgrade\n\n```", "```cpp\nopkg install python-numpy python-opencv\n\n```", "```cpp\npython \n\n```", "```cpp\nimportnumpy\nimport cv2 \n\n```", "```cpp\nimport cv2 \n\ncap = cv2.VideoCapture(0) \n\nwhile(True): \n    # Capture frame-by-frame \n    ret, frame = cap.read() \n\n    # Our operations on the frame come here \n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n\n    # Display the resulting frame \n    cv2.imshow('frame',gray) \n    if cv2.waitKey(1) & 0xFF == ord('q'): \n      break \n\n# When everything done, release the capture \ncap.release() \ncv2.destroyAllWindows() \n\n```", "```cpp\nret, frame = cap.read()\n\n```", "```cpp\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n```", "```cpp\nif cv2.waitKey(1) & 0xFF == ord('q'):\nbreak\n\n```", "```cpp\nimport cv2 \nimport sys \nimport os \n\nfaceCascade = cv2.CascadeClassifier('C:/opencv/build/haarcascade_frontalface_default.xml') \nvideo_capture = cv2.VideoCapture(0) \nwhile (1): \n    # Capture frame-by-frame \n    ret, frame = video_capture.read() \n\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n    faces = faceCascade.detectMultiScale(gray, 1.3, 5)  \n    # Draw a rectangle around the faces \n\n    for (x, y, w, h) in faces: \n      cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2) \n\n    # Display the resulting frame \n    cv2.imshow('Video', frame) \n\n    if cv2.waitKey(25) == 27: \n      video_capture.release() \n      break \n\n# When everything is done, release the capture \nvideo_capture.release() \ncv2.destroyAllWindows() \n\n```", "```cpp\nimport cv2 \nimport sys \nimport os \n\n```", "```cpp\nfaceCascade = cv2.CascadeClassifier('C:/opencv/build/haarcascade_frontalface_default.xml') \nvideo_capture = cv2.VideoCapture(0) \n\n```", "```cpp\nret, frame = video_capture.read() \ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n\n```", "```cpp\nfaces = faceCascade.detectMultiScale(gray, 1.3, 5)  \n\n```", "```cpp\n      # Draw a rectangle around the faces     \n      for (x, y, w, h) in faces: \n      cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2) \n\n```", "```cpp\nimport cv2 \nimport numpy as np \nimport sys \nimport os \n\nfaceCascade = cv2.CascadeClassifier('C:/opencv/build/haarcascade_frontalface_default.xml') \nvideo_capture = cv2.VideoCapture(0) \nled = mraa.Gpio(13)   \nled.dir(mraa.DIR_OUT) \nwhile (1): \nled.write(0) \n    # Capture frame-by-frame \n    ret, frame = video_capture.read() \n\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n    faces = faceCascade.detectMultiScale(gray, 2, 4) \n    iflen(faces) > 0: \n      print(\"Detected\") \n        led.write(1) \n    else: \n      print(\"You are clear to proceed\") \n        led.write(0) \n    if cv2.waitKey(25) == 27: \n      video_capture.release() \n      break \n\n# When everything is done, release the capture \nvideo_capture.release() \ncv2.destroyAllWindows() \n\n```", "```cpp\nfaces = faceCascade.detectMultiScale(gray, 2, 4) \n\n```"]