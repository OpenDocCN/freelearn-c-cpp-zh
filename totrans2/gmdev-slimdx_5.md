# Chapter 5. Rendering Simple 3D Graphics

Now that we've covered user input, 2D graphics, and sound, let's take a look at 3D graphics. Most games these days are 3D, probably because 3D graphics are cooler than 2D graphics! That's not to say that 2D graphics are bad or outdated. There are still many games made using 2D graphics, but creating a game in 3D literally adds another dimension to the game, giving the world that much more depth and making it more interesting to explore.

In this chapter we will cover the following topics:

*   The Direct3D graphics rendering pipeline
*   Shaders
*   Rendering a triangle
*   Rendering a cube with texturing

# The Direct3D graphics rendering pipeline

The Direct3D graphics rendering pipeline takes our geometry data and turns it into graphics on the screen. It is designed to generate graphics for real-time applications such as video games. The pipeline consists of a number of stages that our data goes through to produce the finished image for the current frame. Some of these stages are programmable, giving us a lot more power. Let's take a look at the main pipeline stages, which are:

*   Input assembler
*   Vertex shader
*   Rasterizer
*   Pixel shader
*   Output merger

## Input assembler

The main purpose of the **input assembler** is to take our raw vertex data (points, lines, or triangles), and assemble them into primitives, such as `PrimitiveType.TriangleList`, which can be used by the graphics rendering pipeline. This primitive type tells Direct3D that our vertex data is arranged so that every three vertices in the list make a single triangle. All of the primitive types supported by Direct3D are defined in the `PrimitiveType` enumeration.

## Vertex shader

The **vertex shader** stage performs per-vertex operations on vertex data outputted from the input assembler stage. These operations are things such as transformations, per-vertex lighting, morphing, and skinning.

## Rasterizer

The **rasterizer** stage takes the primitives processed in the previous stages and turns them into pixels to make a rendered image. It also performs the clipping of vertices, which means that if part of a triangle is off the screen, it will clip that part of the triangle off, so to speak, since it doesn't need to be drawn.

## Pixel shader

The **pixel shader** stage of the graphics pipeline performs shading techniques, such as per-pixel lighting or post-processing stuff. The rasterizer invokes the pixel shader stage once for each pixel, which is covered by the current primitive that it is processing.

## Output merger

The **output merger** generates the final pixel color using a combination of numerous things, including the current state of the graphics pipeline, the data generated by the pixel shader stage, and the contents of render targets, and depth/stencil buffers, which we'll get into a bit later in the chapter.

This was a pretty quick overview of the Direct3D graphics pipeline. There are other stages in the pipeline besides these, but we will not be using them. For a more in-depth look at the graphics pipeline, check out Microsoft's documentation: [http://msdn.microsoft.com/en-us/library/windows/desktop/ff476882(v=vs.85).aspx](http://msdn.microsoft.com/en-us/library/windows/desktop/ff476882(v=vs.85).aspx).

# Shaders

As you can see above, **shaders** are a fairly integral part of 3D graphics programming. So what exactly is a shader? A shader is a small program that we write for one of the programmable stages of the Direct3D graphics pipeline. Two of the stages we previously looked at are programmable: the vertex shader stage and the pixel shader stage. These are not the only programmable stages in the graphics pipeline though.

Shaders have what is known as a **shader signature**. The signature of a shader is just a list of the input and/or output parameters of that shader.

In this chapter we will create two demos. Each will have its own shader file, named `Effects.fx`. This is just a text file containing the code for our shaders. Shaders are written in **HLSL** (**High Level Shader Language**). The downloadable code for this chapter includes the `Effects.fx` files for both demo projects (they are *NOT* the same).

For more information on shaders and HLSL, check out the HLSL programming guide on Microsoft's website at [http://msdn.microsoft.com/en-us/library/windows/desktop/bb509635(v=vs.85).aspx](http://msdn.microsoft.com/en-us/library/windows/desktop/bb509635(v=vs.85).aspx).

# Rendering a triangle

In this section we will set up a basic Direct3D application and render a simple triangle on the screen. We will start by creating a new project called `Triangle`. In this project, we will first create a new class named `TriangleGameWindow.cs`. We will need to make it inherit from our `GameWindow` base class and implement `IDisposable`, of course.

### Note

You will need to get the downloadable code for this book to complete this chapter, particularly for the second demo we will create in this chapter.

Now that we have a new game window class, the next item of business is to get Direct3D set up and ready to go. We will need to add some `using` statements to the top of the file first though. These allow us to use Direct3D in our code. The following are the new statements that we need:

[PRE0]

Next, we need to create our member variables. They are as follows:

[PRE1]

The `m_Device` variable will hold our Direct3D device object. The `m_DeviceContext` variable is just a convenience variable that holds the device context for us. This shortens some lines of code since we don't have to access it through `m_Device`.

The `m_RenderTargetView` variable will hold our `RenderTargetView` object, which is similar to the `RenderTarget` object we worked with in [Chapter 3](ch03.html "Chapter 3. Rendering 2D Graphics"), *Rendering 2D Graphics*. This is basically our Direct3D render target.

The `m_SwapChain` variable will hold our **swap chain**. The swap chain is just a chain of buffers. Remember that a buffer is just an area in memory for storing data. The simplest swap chain would have two buffers, which hold the graphics that our program is drawing. Each time we draw a new frame, the buffers get swapped, so the buffer containing our new frame becomes visible on the screen. The buffer we draw into is called the **back buffer** because it is behind the scenes, so the player cannot see it while we are drawing the next frame. The buffer that is currently displayed on the screen is called the **front buffer**. When the buffers get swapped, the back buffer becomes the new front buffer and vice versa.

At first, this may seem like a waste of memory. Why not just draw into the buffer that is currently displayed onscreen so we can have one buffer rather than two? The reason is that doing so can cause some flickering. This is because the player could see things appear on the screen as they are being drawn. So instead, we draw into an offscreen buffer until the frame is fully drawn. Then, we swap the buffers so that the new frame appears on the screen all at once. This makes for smoother animation. This rendering technique is called **double buffering** . You can add more buffers in between the back buffer and the front buffer as well. If you add one additional buffer in between them, you will be doing **triple buffering**, which actually provides speed improvement over double buffering.

Back to our member variables; the next one is `m_Viewport`. The view port simply specifies the area of the render target that we want to draw on. It also specifies the minimum and maximum depth values. These are normally set to `0.0f` and `1.0f` respectively.

The next member variable is `m_InputLayout`. The `InputLayout` object tells Direct3D about the vertex format and shader model we are using. Remember that, a shader is basically just a small program that is run by the video card.

The `m_VertexShader` variable will hold our vertex shader. The `m_VShaderSignature` variable holds the signature for the vertex shader. A shader signature is just a list of parameters that are inputted to or outputted from the shader. And lastly, `m_PixelShader` will hold our pixel shader. We'll get into shaders a bit later in the chapter.

If you don't fully understand all of these member variables, that's fine. They should become a little clearer once we start using them. We need to initialize Direct3D now, so let's get started.

## Initializing Direct3D

We are now ready to initialize Direct3D. For this task, we will create a new method named `InitD3D()`. The following is the code for this method:

[PRE2]

As you can see, the first thing we do in this method is create `SwapChainDescription` to configure the swap chain we will create in a moment. We are using the initializer syntax here, which is a handy way for us to set the values of the struct's properties when it is created. You can use the initializer syntax for structs, arrays, and lists by opening a brace block after the line that creates the new object, and then setting the values of its properties inside the brace block.

The `BufferCount` property specifies how many buffers we want to have in our swap chain, in addition to the front buffer. You should not use more than four buffers as you will get a performance decrease with too many. In the windowed mode, the desktop is used as the front buffer, but in the fullscreen mode, a dedicated front buffer is required in the swap chain. The `Usage` property specifies how we intend to use our swap chain surfaces. The term **surface** refers to a buffer that we will draw on, so the surfaces of our swap chain are just the buffers that are in it. For the `OutputHandle` property, we set this to the handle of our game window to tell it what window we will be displaying our graphics in. The `IsWindowed` property determines whether we want to start the program in windowed mode. Remember that we haven't implemented fullscreen mode yet.

Next, we have the `ModeDescription` property, which specifies the video mode we want to use. The first two parameters of the `ModeDescription` object are the height and width. In other words, they are the screen resolution we want to use. The third parameter is the refresh rate specified as a numerator and a denominator. Here, we have it set to the fraction *60/1*, which means a refresh rate of 60 times per second. And lastly, we have the format parameter. This tells it the pixel format, and as you can see, we have it set to `Format.R8G8B8A8_UNorm`. This means we have eight bits for each of the four color channels (red, green, blue, and alpha). The `UNorm` part of this format name indicates that the values of the color channels are unsigned, normalized integers (normalized meaning they are in the range `0.0`-`1.0`). An **unsigned integer** is similar to a normal `integer` variable, except that it does not support negative numbers. This allows an unsigned integer to hold much larger values than you can store in a normal integer variable of the same size. The opposite of an unsigned integer is a **signed integer** variable, which has to use half of its possible values to represent negative numbers.

The next property we set on the `SwapChainDescription` object is the `SampleDescription` property. For this, we create a new sample description object and give it two parameters: the first parameter is the number of multisamples per pixel, and the second parameter is the quality level. The valid range for the quality level is `0` to one less than the level returned by the `CheckMultisampleQualityLevel()` method of the Direct3D device object (remember that the device is stored in our `m_Device` member variable). Of course, higher quality levels are more expensive to perform than lower ones. Here, we set the count to `1` and quality to `0`. This is the default sampler state with no anti-aliasing. Note that there are also a couple of standard values we can use to set our multisampling level, and they are defined in the `Direct3D11.StandardMultisamplQualityLevel` enumeration.

### Note

If your PC is not able to use Direct3D 11, you can change the code in this chapter to use Direct3D 10 instead. The code should be nearly identical, since Direct3D 11 is in reality an extension of Direct3D 10, and we are not using any advanced features or new stuff that Direct3D 11 brings to the table. Just make sure you change all objects from the Direct3D 11 namespace to their counterparts in the Direct3D 10 namespace.

You may notice that there is also Direct3D 11.1\. We are not using this because it is the Windows 8 version of Direct3D 11, and you can only use it on Windows 8.

So what is **multisampling** and **anti-aliasing**? Anti-aliasing is actually an effect of multisampling, where the jagged edges of objects are smoothed, so they don't look jagged on the screen anymore. This jaggedness is caused by the fact that the pixels on the screen are not infinitely small, and thus you can sometimes see a stair-step pattern on the edges of objects on the screen. Multisampling involves looking at the colors of adjacent pixels and blending them together in some fashion so as to soften edges on the screen and remove other graphical artifacts that can be caused by aliasing, such as moiré patterns. You can look up for moiré patterns on Wikipedia: [http://en.wikipedia.org/wiki/Moir%C3%A9_pattern](http://en.wikipedia.org/wiki/Moir%C3%A9_pattern).

The next property we set on the `SwapChainDescription` object is the `Flags` property. This property lets us set various flags that affect the behavior of our swap chain. In this case, we set it to the `SwapChainFlags.AllowModeSwitch` flag, which allows us to switch the screen mode of our swap chain by calling its `ResizeTarget()` method.

And the final property we are setting on our `SwapChainDescription` object is the `SwapEffect` property. This sets options for how to handle the back buffer's contents after it has been displayed on the screen. We have set this to `SwapEffect.Discard`. And with that, we are done setting up our `SwapChainDescription` object.

We are now ready to create our swap chain and the Direct3D device. Both of these are accomplished with the next line of code, which calls a static member of the `SlimDX.Direct3D11.Device` class; that method is the `CreateWithSwapChain()` method. As you can see, there are six parameters. The first parameter specifies the driver type. In this case, we set it to `DriverType.Hardware`, since we want hardware acceleration if it is available. The second parameter is the device creation flag. In this case, we have used `DeviceCreationFlags.Debug`, which creates a Direct3D device that supports the debug layer. Of course, you would change this to something else before you release your game, since the debug code slows down the game and hurts performance.

The third parameter specifies feature levels. In this case, we have only used `FeatureLevel.Level_11_0`, which means we want the Direct3D 11 features. As this parameter is an array, you can, of course, provide more than one feature level if your program needs to support more levels.

The fourth parameter is our `SwapChainDescription` object, and the last two parameters begin with the `out` keyword. This means they are actually output from the function, or in other words, the variables we pass in are modified by the function to return data. In this case, the fifth parameter is our `m_Device` member variable, and the sixth parameter is our `m_SwapChain` variable. So this function creates the Direct3D device and stores it in the variable we passed into the fifth parameter. And it also creates the swap chain, storing it in the variable that we passed into the sixth parameter.

The next thing we need to do is create our render target. As you can see, the next piece of code is a `using` block, which creates a `SlimDX.Direct3D11.Resource` object using the `Resource` class's static method, `FromSwapChain()`. The `<Texture2D>` part of this line indicates that the function is **generic**. A generic method is one that allows you to specify a data type when you call it. In other words, it is a function that is able to act on multiple data types, whereas a normal function can't do that. In this case, we have specified the data type of `Direct3D11.Texture2D`. A `Texture2D` object represents an image. The `FromSwapChain()` method takes two parameters. The first one is the swap chain we want to create the resource from, and the second parameter is the index of one of the buffers in that swap chain.

Then, inside of this `using` statement, we have a single line of code that creates our `RenderTargetView` object. This object is essentially our render target. As you can see, we pass in two parameters when we create the `RenderTargetView` object. The first parameter is our Direct3D device, and the second parameter is the resource we just created.

The next line of code stores the Direct3D device context in our `m_DeviceContext` member variable. Remember that this variable is just for convenience. Using it allows us to shorten some of our lines of code. The device context is accessed via the Direct3D device object's `ImmediateContext` property.

Next up, we create our viewport. The `ViewPort` object specifies the area of the swap chain buffer that we want to draw onto, as well as the minimum and maximum depth values. The first two parameters we pass in when we create the `Viewport` object are the x and y position of the rectangular area we want to draw in. The third and fourth parameters are the width and height of that area. As you can see, we have specified that we want to use the entire window to draw on. The last two parameters are the minimum and maximum depth values, which are usually set to `0.0f` and `1.0f` respectively. These specify how much of the depth range to draw. Setting them to `0.0f` and `1.0f` tells it to draw the entire depth range of the scene. You could set both to `0.0f` to draw all objects to the foreground, or set both to `1.0f` to draw everything in the background.

As you can see, next up is code consisting of two lines. The first one sets the `Viewport` we just created on the **rasterizer**. Remember that, the rasterizer is one of the stages in the Direct3D graphics processing pipeline. It clips primitives, prepares them for the pixel shader (another stage in the pipeline), and also determines how to call the pixel shaders for them.

The second line of code here sets our `RenderTargetView` on the output merger (remember that the output merger is a stage of the graphics pipeline).

We've finally reached the last piece of code in our `InitD3D()` method. It's another `using` block, this time getting a `Factory` object. It then calls the `SetWindowAssociation()` method on this object. This method takes two parameters: the first being the handle of our game window and the second being the window association flags we want to use. In this case, we are using the `WindowAssociationFlags.IgnoreAltEnter` flag. So why are we doing this? The answer is to prevent **DXGI** from handling *Alt* + *Enter* since it does not work properly with WinForms. Remember that DXGI is one of the namespaces that we included with a `using` statement when we started this project. DXGI is short for DirectX Graphics Infrastructure. We will handle the *Alt* + *Enter* keyboard shortcut ourselves later. It will toggle the fullscreen mode for our program.

With that done, we need to create two more initialization functions: one will initialize our shaders, and the other will initialize our geometry (the triangle we are going to draw).

## Initializing the shaders

We will create a new method named `InitShaders()` to initialize our shaders for us. In this demo, we will set up both a vertex shader and a pixel shader. The following is the code for this method:

[PRE3]

You can see that this function contains two blocks of code that are quite similar to each other. The first one initializes our vertex shader. The downloadable code contains a file called `Effects.fx`, which is simply a text file containing the code of our basic shaders.

The first line creates a string variable named `vsCompileError`. This will receive any errors that are raised by the next piece of code. As you can see, it is a `using` block that calls the `ShaderBytecode.CompileFromFile()` method to compile our vertex shader. The returned byte code is the compiled form of our vertex shader. The `CreateFromFile()` method takes a handful of parameters, and it also has several overloads. An `overload` method is another version of the same function with a different parameter list.

The first parameter of the `CompileFromFile()` method is the file containing the code of the shader we want to compile. The second parameter is the name of the method in the shader file that contains the code for this shader. The third parameter is the shader model. In this case we used `"vs_4_0"`, which tells it that we want to use shader model 4\. The fourth parameter is the shader flags we use. We used `ShaderFlags.Debug` here. Again, you'd probably want to remove this flag when your game is done since the debug code will slow down performance. The next two parameters are a list of shader macros to define during shader compilation and an interface for handling the `include` files. These two parameters are set to `null` as they are beyond the scope of this chapter. And the final parameter is the `psCompileError` variable we created above the `using` block. If there are any errors, they will be put in this variable.

Inside of this `using` block we have two lines of code. The first gets the signature for this shader. Remember that the signature of a shader is just a list of the input and/or output parameters of that shader. The second line of code creates a `VertexShader` object to hold our vertex shader, and stores it in our `m_VertexShader` variable.

The second block of code in our `InitShaders()` method is very similar to the first one. It does the same stuff but for the pixel shader. It compiles our pixel shader and stores it in our `m_PixelShader` member variable. You may have noticed that it uses the same shader file as the vertex shader code at the top of this method. You can define multiple shaders in a single file, and we've done that here for simplicity.

### Note

Remember that the vertex shader is one of the stages in the Direct3D graphics pipeline, as is the pixel shader.

The last two lines of code in this method tell the graphics processing pipeline to use our vertex shader and pixel shader. So why do we have shaders anyway? The reason is because some stages in the Direct3D graphics pipeline are programmable. Shaders are the programs we write for these stages, so a shader is essentially a small program that tells Direct3D what to do during that stage in the pipeline. There are more shader types besides vertex and pixel shaders too, but they are beyond the scope of this book. Shaders are a powerful tool that allow us to customize the graphics processing pipeline, so we can do things that otherwise we might not be able to do. You can have more than one shader of a given type and switch between them at will too (we will actually do this in the second demo we make in this chapter), so you're not stuck with the first shader you set. At this point, we are ready to initialize our scene.

## Initializing the scene

In 3D graphics, the term **scene** is used much as it is in the movies. However, in this case, the term scene refers to the world, or 3D scene, that we are rendering. To initialize our scene, we will create one more initialization method named `InitScene()`. The code for this method looks as follows:

[PRE4]

The first thing we do in this method is create an array of the `Vector3` objects. These are the vertices that make up our inverted triangle. So, each `Vector3` object contains the x, y, and z coordinates for the vertex it represents.

The next block of code is a `using` block that creates a `DataStream` object. We pass in the three parameters when we create this object. The first parameter is the total size in bytes of our vertex data. The last two parameters are `canRead` and `canWrite`. They specify whether or not reading and writing to the buffer should be allowed.

The next line sets the position of the data stream to the start. The following three lines write our vertices into the data stream one by one. And the last line here sets the data stream's position back to the beginning again.

Now that our geometry data is ready, we need to create a `VertexBuffer` object to put it in. The next block of code creates a `BufferDescription` object for this purpose. We set the `ResourceUsage` property to `ResourceUsage.Default`. Next, we set the `SizeInBytes` property to the size of our vertex data, so the vertex buffer will be big enough to hold it all. Then, we set the `BindFlags` property to `BindFlags.VertexBuffer` since this buffer is going to be used as a vertex buffer. We have set both the `CpuAccessFlags` and `OptionFlags` properties to `None` on the next two lines as they are beyond the scope of this discussion.

The next line of code creates the `VertexBuffer` object. We pass in three parameters when we create it. The first parameter is our Direct3D device. The second parameter is the `DataStream` object we wrote our vertex data into, and the last parameter is the `BufferDescription` object we just created.

At this point, the `using` block ends. When program execution reaches this point, our `DataStream` object gets disposed of since we no longer need it.

The next bit of code creates an array of the `InputElement` objects. This tells Direct3D what data we have stored in each of our vertices, and how it is formatted. As you can see, we have only added one input element here. It is the position of the vertex in 3D space.

There are a handful of parameters we pass in when creating this `InputElement` object. The first parameter is a string indicating what type of element this is. We set this to `"POSITION"` since this input element holds the position of our vertex in 3D space. The second parameter is an index that is used when you have multiple elements with the same name. So if we had two elements named `"POSITION"`, we would set the index parameter to `1` for the second one. The third parameter is the data format used by this input element. In this case, we need to store three numbers since a coordinate in 3D space is composed of three integers. So, we used the format `Format.R32G32B32_Float`. This format holds three float values, each of which is 32 bits in size. The next parameter is an offset to the next input element.

For convenience, we've set this to `InputElement.AppendAligned`, which means this input element will start directly after the previous one. The next parameter is the input slot to use for this input element. The valid values for this property are `0`-`15`. Then, we have the slot class parameter, which we've set to `InputClassification.PerVertexData`. This is because this element is being used on a per-vertex basis since we need to store the position for every vertex. The last parameter is the step rate. We have set this to `0` in our code since we are not using this feature, and it is beyond the scope of this chapter.

With that, we're almost done now. The next line of code creates an `InputLayout` object that will hold the information we just set up. We pass in three parameters when we create it. The first parameter is our Direct3D device object. The second parameter is the signature of our vertex shader, and the last parameter is the input elements array we just created.

The next line of code tells the input assembler to use our new `InputLayout` object. Remember from earlier in this chapter that the input assembler is a stage in the Direct3D graphics pipeline.

Next, we call the `SetVertexBuffers()` method on the `InputAssembler`. This tells it what vertex buffer we want to use. If you had multiple objects to draw, you can reset the vertex buffers multiple times in the `RenderScene()` method. This method takes three parameters. The first parameter is the slot we want to use. Depending on the feature level we are using, the maximum number of slots available to use can vary. The second parameter is a `VertexBufferBinding` object. We give it three parameters when we create it. The first parameter is our vertex buffer that we created a moment ago. The second parameter is the total size of our vertex buffer, and the last parameter is an offset to the first vertex in the buffer. We have set this to `0` since our first vertex is at the very beginning of the buffer.

Finally, we have one more line of code to set the **primitive topology**. This setting basically tells the graphics pipeline how to interpret our vertex data. In this case, we set this to `PrimitiveTopology.TriangleList`. This tells Direct3D that our vertex data is a list of triangles, or, in other words, every three vertices in the list form a triangle. There are a number of other options you can use for this setting, and they are all defined in the `PrimitiveTopology` enumeration.

The input assembler also has a `SetIndexBuffer()` method for setting **index buffers**. An index buffer simply holds a list of offsets into a vertex buffer to allow for more efficient rendering. For example, let's say we want to render a square. It has four vertices, but we'd have to create six to render it using a vertex buffer alone (three per triangle, and a square is composed of two triangles). We could accomplish this using only four vertices if we use an index buffer. Our index buffer would have two values in it.

The first value would be `0`, since the first triangle starts with the first vertex. The second value would be the index of the first vertex of the second triangle in the vertex buffer. This allows triangles to share vertices, as it is very common for two triangles to have vertices that are at the same point in 3D space. Clearly, this wastes memory if we re-define the same vertex more than once to create a separate instance of it for each triangle that has that vertex in it. Index buffers allow us to get around this problem. For simplicity though, we will not use an index buffer in this demo.

## Rendering the scene

To draw our scene, we just need to add three lines of code to our `RenderScene()` method so that it looks like the following:

[PRE5]

As you can see, this code is fairly simple. At the top of the method, we have the same `if` statement we've been using here in previous demos. Remember that this `if` statement prevents this method from doing anything if the program isn't initialized yet or if it has already been disposed of. This prevents the crashing that could otherwise occur when the program first starts up or shuts down.

The next line of code clears the screen using whatever color is stored in our `ClearColor` property that is defined by the `GameWindow` base class. Then, we call the `Draw()` method of the Direct3D device context to draw our geometry. This method takes two parameters. The first one is the total number of vertices we want to draw. The second parameter is the index to start at in the vertex buffer. We want to draw all of our vertices, so we set this to `0` to start with the first vertex.

And lastly, we call the `Present()` method on the swap chain. It takes two parameters. The first parameter is the sync interval, and the second is the present flags. Both of these are beyond the scope of this chapter, so we are using `0` for the first parameter, and `PresentFlags.None` for the second parameter.

Before we test the code, we'll do one more little thing. We will edit the `ToggleFullscreen()` method of our `TriangleGameWindow` class so it looks like the next code snippet. Remember that this function is an override of a method defined by our `GameWindow` base class:

[PRE6]

The first line toggles the value of our `IsFullScreen` property that was defined by the `GameWindow` base class. The second line sets the fullscreen state of our swap chain to the new value in the `IsFullScreen` property. With this bit of code, we can now toggle fullscreen mode while the program is running. If you press *Alt* + *Enter*, the program will toggle its fullscreen mode. Remember that we added code to detect the *Alt* + *Enter* key stroke back in [Chapter 1](ch01.html "Chapter 1. Getting Started"), *Getting Started*, when we created the `GameWindow` base class.

Note that the resolution we are rendering at does not change when you do this. When we resize the window, the image we drew simply gets stretched to fit the new size of the window. You can have your swap chain and viewport resized by adding an event handler and subscribing it to the `Resize` event of our form (remember that our `RenderForm` object is stored in our `FormObject` property that is defined by the `GameWindow` base class). In this event handler, you would dispose of the `RenderTargetView` object using its `Dispose()` method and recreate it with the new window size. You would then reset the viewport as well.

Before you run the program, remember to edit the `Dispose(bool)` method, and make sure it disposes of all of our objects. See the downloadable code for this chapter to see the new code for this method. Once that's done, we're ready to run the program. The following is a screenshot of this program in action, showing our inverted triangle:

![Rendering the scene](img/7389_05_01.jpg)

Our inverted triangle being rendered in our game window

You may be wondering why the triangle is blue. We never set a color for it, so how did that happen? Well, if you look in our `Effects.fx` file at the shader code, you will see that the pixel shader is hardcoded to shade every pixel it draws blue. The pixel shader has only a single line of code that returns the color blue in RGBA format. The color returned by the pixel shader is the color for the current pixel that the graphics pipeline is processing. The `Effects.fx` file is included with the downloadable code for this chapter.

# Rendering a cube

In this section we will render a cube since it is actually 3D, unlike our triangle in the previous demo. We will modify the project from the previous demo to create the cube demo. In the downloadable code for this chapter, you will find the code for the cube demo in a separate project so you can look at the code for both demos. The `Triangle` project is set as the startup project by default. When you want to run the `Cube` demo, remember that you will have to set the `Cube` project as the startup project to run it.

To get started, we will add an enumeration named `GraphicsMode`. We will use it to specify how we will render our cube. This enumeration looks like the following:

[PRE7]

The first option will make the program render all the pixels of the cube blue. The second option renders the cube using colors specified with each vertex and blending them across each **face** (or side) of the cube. And the third option will render our cube with a texture on it, which happens to be the red brick tile from our 2D demo in [Chapter 3](ch03.html "Chapter 3. Rendering 2D Graphics"), *Rendering 2D Graphics*. Next, we need to make a new structure to represent a vertex since we need to store more information for each vertex now. We will name it `Vertex`. It looks as follows:

[PRE8]

The first variable holds the position of the vertex in 3D space. The second one stores a color for this vertex, and the third variable stores the texture coordinates for this vertex. The texture coordinates simply define how the texture is applied to the polygon. For example, to texture a square, you'd give the upper-left vertex `(0,0)` for its texture coordinates. The upper-right vertex would be `(1,0)`, the lower-left vertex would be `(0,1)`, and the lower-right vertex would have `(1,1)` for its texture coordinates. In the texture coordinates, `(0,0)` is the upper-left corner of the texture image, and `(1,1)` represents the bottom-right corner of the texture image. So, the texture coordinates we just saw would make the texture fill the entire face of the square. They are basically attaching the top-left corner of the texture to the top-left corner of the square, the bottom-right corner of the texture to the bottom-right corner of the square, and so on.

Now, we will need to add a few sets of new member variables. The first one is for our **constant buffers** . A constant buffer is just a buffer that we use to communicate certain information to the video card, such as the projection and view matrices. We have four variables for our constant buffers:

[PRE9]

The first three variables will hold our three constant buffers. But why do we have three? The reason is that it's more efficient this way compared to using only one. The `m_CbChangesOnResize` buffer will hold the projection matrix that only needs to change when the window is resized. In this demo, this never changes since we just let it keep rendering at the same resolution and stretch it to fit the window. By having it in a separate buffer, we never have to change it unless the window changes size, which saves time. The `m_CbChangesPerFrame` buffer will hold our view matrix, which can change per frame any time that you press one of the movement keys. And lastly, the `m_CbChangesPerObject` buffer will hold information that is object-specific. This buffer would be updated each time before you draw the next object in your scene by filling it with the information for that object.

Next up, we need to add a few matrix variables:

[PRE10]

The first two variables will hold our view and projection matrices. We will look at these matrices in more detail in a moment. The other two variables hold two matrices for our cube object. The **world matrix** is used to convert the coordinates of a **model** into **world space** , which is the coordinate system of our 3D world.

A model is a 3D geometrical representation of an object. In other words, it holds all of the geometry for the object it represents. Models often have their own coordinate system known as **model space** , which is why we need to convert it.

Lastly, the rotation matrix you see there for our cube controls the pitch, yaw, and roll of our cube. It is known as a **transformation matrix** , because it transforms the object we use it on in some way, such as moving it, scaling it, or rotating it. The projection and view matrices are, of course, also transformation matrices. Transformation matrices are a very central concept in 3D graphics.

Now, we also need to add a few depth stencil and sampler member variables:

[PRE11]

The first variable holds the depth stencil's texture. The **depth stencil** is basically a texture. Each pixel in it holds a depth value representing the nearest object that has been drawn on that pixel so far while rendering the current frame. This is how Direct3D knows whether an object is in front of or behind another object. When the pixel shader goes to draw a pixel, it checks the depth value for that pixel in the depth stencil texture. If that pixel's depth value is closer than the depth of the pixel it is trying to draw, that pixel is discarded since it belongs to an object behind another closer one that we already drew on this pixel.

The second variable holds our `DepthStencilView` object, which accesses the depth stencil texture when Direct3D is doing depth testing on a pixel. The next two variables have to do with sampling. The first one will hold our texture that we will put on the cube. The second variable holds the sampler state that we will use with our texture.

**Sampling** is the act of reading image data from our texture so that we can use it to render pixels in the pixel shader. Basically, the pixel shader gets the pixel color from the texture based on the texture coordinates of the vertices that make up the face it is drawing.

Lastly, we have one more small set of member variables to look at:

[PRE12]

The first variable here keeps track of the position of our camera, of course. The second variable tracks the current rotation amount (on the y axis) for our cube. The `m_MoveSpeed` variable specifies how fast the camera moves when you press one of the movement keys. And the last variable specifies how we want to render our cube.

I wanted to make a demo that we could really experiment with, so I added this feature. So how does it work? If you look at the code in the `InitShaders()` method in the downloadable code for this demo, you can see that we have changed the code that loads the pixel shader. Now, it has `if` statements above it that check the value of the `m_GraphicsMode` member variable. So basically, depending on which graphics mode you set, it will load and use the appropriate pixel shader. If you look in the `Effects.fx` file in the downloadable code for this demo, you can see that we have three pixel shaders in there, one for each of our three graphics modes.

## Initializing the depth stencil

Anyway, now that we've covered the new member variables and the changes to the `InitShaders()` method, we need to add a couple of entirely new methods. The first one is the `InitDepthStencil()` method that will initialize our depth stencil for us:

[PRE13]

As you can see, the first thing we do is create a `Texture2DDescription` to configure the depth stencil texture. The `width` and `height` properties, of course, are setting its size to the same size as our rendering area. The `MipLevels` and `ArraySize` parameters are beyond the scope of this text, so we will ignore them. The `Format` property is, of course, the format our texture is in. The `D24_UNorm_S8_UInt` format means 24 bits for depth and 8 bits for the stencil component, but this is getting into the details of how the depth stencil actually works, which is beyond the scope of this text. The `SampleDescription` property sets the multisampling parameters for this texture. The `Usage` property specifies how this resource will be used during rendering. We set the `BindFlags` property to `BindFlags.DepthStencil` to tell Direct3D that this will be used for depth stenciling. And lastly, we set the `CpuAccessFlags` and `OptionsFlags` to `None` as we've done before.

Next, we create a `DepthStencilViewDescription` to configure the depth stencil view object. The `Format` property specifies the format, for which we just pass in the value we set for the `Format` property of the depth stencil texture description we just filled in. We set the `Dimension` property to `DepthStencilViewDimension.Texture2D` since we are using a `Texture2D` object for the depth stencil texture. And the `MipSlice` property is beyond the scope of this text, so we set it to `0`.

The next line of code creates the depth stencil texture object. And after that, the following line creates the `DepthStencilView` object. And the last line tells the output merger to use our new depth stencil along with our render target.

### Note

In this demo we only have one object, so we won't really see the depth stencil in action. If we had two cubes, with one partially obscured by the other, then we'd see the depth stencil in action, making the front cube actually get drawn in front as we want.

With that done, we need to initialize our constant buffers now, so that we can communicate various bits of information to the graphics card, such as our projection and view matrices.

## Initializing the constant buffers

Next we will create the `InitConstantBuffers()` method to initialize our constant buffers:

[PRE14]

In this method, we start by creating a `BufferDescription`. In this case, all three of our constant buffers will be the same size (64 bytes), which means we can get away with using just this one `BufferDescription` to create all three buffers. We set its `ResourceUsage` property to `default` and its `BindFlags` property to `BindFlags.ConstantBuffer` since we want to use these buffers as constant buffers. We set the `CpuAccessFlags` property to `None` once again, and the `SizeInBytes` property we set to `64` since that's the size we need our constant buffers to be. The reason is that in this demo, each of these buffers will simply hold a single 4 x 4 matrix, which takes 64 bytes of memory.

The next three lines of code create each of our three constant buffers. Then, the next block of code creates a `DataStream` object and stores it in our `m_DataStream` member variable so we can re-use it. Then we set the position of the data stream to `0` so that we start writing at the beginning of it. Next, we write the transpose of the projection matrix into the data stream and reset its position back to `0` again. The last line is slightly complex, but it simply sends the data in the data stream into the `m_CbChangesOnResize` constant buffer to make it available to the graphics pipeline. The details of how this line actually works are beyond the scope of this chapter.

### Note

You may have noticed that we didn't create our `DataStream` object in a `using` block this time. The reason is that we continue to use it throughout the life of the program, so we can't dispose of it here, or else the demo would crash!

The next set of code does the same thing, but for the view matrix, sending it into the `m_CbChangesPerFrame` constant buffer. And lastly, the final three lines in this method tell the vertex shader to use our three new constant buffers. As you can see, we put each constant buffer in its own slot; hence, the second parameter increments by one in each line. This parameter specifies which slot to set the constant buffer to.

We are now ready to initialize our scene and create our cube!

## Initializing the scene

A lot of the code for this method is the same as before, so we won't show it all here. At the top of this method, we add some new code to initialize the projection and view matrices:

[PRE15]

The first line creates the projection matrix. The projection matrix is analogous to choosing a type of lens for the camera. The four parameters we pass into the `Matrix.PerspectiveFovLH()` method set the vertical field of view, the aspect ratio, and the **near clipping plane** and **far clipping plane** distances. The `Fov` part in the method name is, of course, short for field of view. The `LH` part indicates that this is the method to use if you are working in a left-handed coordinate system. We are using a left-handed coordinate system in this demo because video games generally use the left-handed coordinate system. There is, of course, another version of this method that ends in `RH` for use in right-handed coordinate systems. For a more in-depth look at these two types of coordinate systems, take a look at this article on Microsoft's MSDN website [http://msdn.microsoft.com/en-us/library/windows/desktop/bb324490(v=vs.85).aspx](http://msdn.microsoft.com/en-us/library/windows/desktop/bb324490(v=vs.85).aspx).

Clipping is the removing of objects from the render list that don't need to be drawn in the current frame—generally because they are not visible anyway. This provides performance benefits and is necessary since trying to render everything in your 3D world is not practical unless it happens to be a very small world. Trying to do so may result in very low frame rates.

The near clipping plane is the minimum distance an object must be from the camera to be rendered. If an object is closer to the camera than this, it will not be rendered. This can prevent objects from being partially rendered if the player gets too close to them. Likewise, the far clipping plane is the maximum distance an object can be from the camera and still be drawn. An object farther away than this will not be drawn. Note that Direct3D takes care of basic clipping for us.

The next bit of code creates the view matrix using the `Matrix.LookAtLH()` method. The three parameters we pass in are all `Vector3` objects. The first one is the position of the camera (in other words, the player's viewpoint) in 3D space. The second parameter is the coordinates for the camera to look at. And the last parameter is simply a vector that specifies which way is up in our 3D world. We are using the positive y axis as the vertical axis here, which is what you'll use most of the time.

Under this code, we have new vertex data, but it is far too big to show here, so check out the downloadable code to see it. It specifies a position, color, and texture coordinates for each vertex, which is a big departure from our previous demo that only had a position for each vertex. This means that the input elements array will be very different this time too. Again, check out the downloadable code to see this.

Lastly, we need to add this code to the bottom of this method:

[PRE16]

As you can see, the first line loads our cube texture. As mentioned before, this is just the red brick tile from our 2D demo back in [Chapter 3](ch03.html "Chapter 3. Rendering 2D Graphics"), *Rendering 2D Graphics* . Next, we create a sampler description, which we will use to create a sampler state to use with our cube texture. Most of the properties of the `SamplerDescription` are beyond the scope of this text. And finally, the last line creates a `SamplerState` for our cube texture. Now that our cube texture is set up, we are ready to update the scene in our `UpdateScene()` method.

## Updating the scene

Next, we need to modify our `UpdateScene()` method. First, we need to add the following code after the `if` statement at the top of this method:

[PRE17]

Here, we increment the `m_CubeRotation` variable to increase the cube's rotation slightly for this frame. Note that this rotation value is in radians, not degrees. The `if` statement resets this variable to `0` when it gets too large. Over many frames, this causes the cube to rotate.

Below that, we will add the following `if` statement:

[PRE18]

This `if` statement checks if the player has pressed the up arrow key or the *W* key. If so, we increase the camera's position on the z axis. Then, below this we would add another `if` statement that does the same for moving backwards if you press the down arrow key or the *D* key. If you have pressed one of these keys, it will decrease the camera's position on the z axis. Check out the downloadable code for this chapter to see this code.

### Note

Remember that `UserInput` is a variable defined by our `GameWindow` base class, which provides access to its `UserInput` object that we created in [Chapter 2](ch02.html "Chapter 2. Responding to Player Inputs"), *Responding to Player Inputs*.

You may notice that the camera acts a bit oddly if you move forward until you pass the cube. This is just because the camera is effectively locked on to the cube. If you try to add controls for moving left/right or up/down, you will notice the camera will act a bit oddly for this same reason when you move it in those directions. The camera auto-rotates so that it is always looking towards the cube, no matter where you move it. The next block of code recreates the view matrix, and then sends that data into the `m_CbChangesPerFrame` constant buffer. We need to update the view matrix every time the camera moves. The following is that code:

[PRE19]

Lastly, we update the cube's rotation matrix with the new value in the `m_CubeRotation` variable that we updated at the top of this method:

[PRE20]

The first parameter of the `Matrix.RotationAxis()` method is `Vector3` specifying the axis we want the cube to rotate around. The second parameter is our rotation amount in radians, which is in our `m_CubeRotation` member variable. And finally we update the cube's world matrix with the new rotation matrix we just created.

## Rendering the scene

We have one last thing to change and we should be ready to run the program. We need to change the code in our `RenderScene()` method to draw the cube. After the line that clears the screen, we add the following line:

[PRE21]

This line clears the depth stencil texture, so it is empty before we start rendering this frame. Then below this, we need to add the following block of code:

[PRE22]

The first two lines set our cube texture as a resource on the pixel shader so that it can use it. The second line sets the sampler state to use with it. Then the next block of code uses our `DataStream` to send the updated information for our cube into the `m_CbChangesPerObject` constant buffer.

Now we need to change the line that calls the `Draw()` method on the `DeviceContext`:

[PRE23]

As you can see, we've changed it to draw 36 vertices now. This is because our cube has 36 vertices. But a cube only has eight corners, right? Well, each corner vertex is duplicated for each side it is shared by. You can avoid this somewhat by using the `TriangleStrip` primitive topology rather than `TriangleList` as we've used here and by using index buffers as discussed earlier in this chapter.

As always, don't forget to edit the `Dispose(bool)` method, and make sure it disposes of all of our disposable objects. The following are some examples of the program running in all three of our graphics modes:

![Rendering the scene](img/7389_05_02.jpg)

The cube demo in all three graphics modes

The first part of the previous diagram shows the program when you set `m_GraphicsMode` to `GraphicsMode.SolidBlue`. The second image shows `GraphicsMode.PerVertexColoring`, and the last image shows `GraphicsMode.Textured`.

# Summary

In this chapter we dived into the world of 3D graphics. It's a very complicated subject, but we drew a blue triangle on the screen in our first demo, where we looked at the basics of setting up a Direct3D application. Then, we started work on our cube demo, where we introduced the concepts of depth stencils and constant buffers. We gave this demo three graphics modes that you can run it in by changing the value of the `m_GraphicsMode` member variable in the `CubeGameWindow` class. In the next chapter, we'll take a look at a few other topics briefly and discuss where to go from here in learning the art of game programming.