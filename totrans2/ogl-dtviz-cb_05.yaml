- en: Chapter 5. Rendering of Point Cloud Data for 3D Range-sensing Cameras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：3D范围感应相机的点云数据渲染
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Getting started with the Microsoft Kinect (PrimeSense) 3D range-sensing camera
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用微软Kinect（PrimeSense）3D范围感应相机
- en: Capturing raw data from depth-sensing cameras
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从深度感应相机捕获原始数据
- en: OpenGL point cloud rendering with texture mapping and overlays
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带纹理映射和叠加的OpenGL点云渲染
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: 'The purpose of this chapter is to introduce the techniques to visualize another
    interesting and emerging class of data: depth information from 3D range-sensing
    cameras. Devices with 3D depth sensors are hitting the market everyday, and companies
    such as Intel, Microsoft, SoftKinetic, PMD, Structure Sensor, and Meta (wearable
    Augmented Reality eyeglasses) are all using these novel 3D sensing devices to
    track user inputs, such as hand gestures for interaction and/or tracking a user''s
    environment. An interesting integration of 3D sensors with OpenGL is the ability
    to look at a scene in 3D from different perspectives, thereby enabling a virtual
    3D fly-through of a scene captured with the depth sensors. In our case, for data
    visualization, being able to walk through a massive 3D dataset could be particularly
    powerful in scientific computing, urban planning, and many other applications
    that involve the visualization of 3D structures of a scene.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是介绍可视化另一类有趣且新兴数据的技术：来自3D范围感应相机的深度信息。带有3D深度传感器的设备每天都在市场上出现，英特尔、微软、SoftKinetic、PMD、Structure
    Sensor和Meta（可穿戴增强现实眼镜）等公司都在使用这些新颖的3D感应设备来跟踪用户输入，例如手势交互和/或跟踪用户的环境。3D传感器与OpenGL的有趣集成是能够从不同的视角查看场景，从而实现使用深度传感器捕获的场景的虚拟3D飞行浏览。在我们的案例中，对于数据可视化，能够在庞大的3D数据集中行走可能特别强大，在科学计算、城市规划以及许多涉及场景3D结构可视化的其他应用中。
- en: In this chapter, we propose a simplified pipeline that takes any 3D point data
    (*X*, *Y*, *Z*) with color (*r*, *g*, *b*) and renders these point clouds on the
    screen in real time. The point clouds will be obtained directly from real-world
    data using a 3D range-sensing camera. We will also provide ways to fly around
    the point cloud and have dynamic ways to adjust the camera's parameters. This
    chapter will build on the OpenGL graphics rendering pipeline discussed in the
    previous chapter, and we will show you a few additional tricks to filter the data
    with GLSL. We will display our depth information using our heat map generator
    to see the depth in 2D and remap this data to a 3D point cloud using texture mapping
    and perspective projection. This will allow us to see the real-life depth-based
    rendering of a scene and navigate around the scene from any perspective.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们提出了一种简化的流程，它接受任何带有颜色（*r*，*g*，*b*）的3D点数据（*X*，*Y*，*Z*），并在屏幕上实时渲染这些点云。点云将直接从使用3D范围感应相机的现实世界数据中获得。我们还将提供绕点云飞行的方法和动态调整相机参数的方式。本章将在前一章讨论的OpenGL图形渲染管道的基础上构建，我们将向您展示一些额外的技巧来使用GLSL过滤数据。我们将使用我们的热图生成器显示深度信息，以在2D中查看深度，并使用纹理映射和透视投影将此数据重新映射到3D点云。这将使我们能够看到场景的真实深度渲染，并从任何视角在场景中导航。
- en: Getting started with the Microsoft Kinect (PrimeSense) 3D range-sensing camera
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用微软Kinect（PrimeSense）3D范围感应相机
- en: The Microsoft Kinect 3D range-sensing camera based on the PrimeSense technology
    is an interesting piece of equipment that enables the estimation of the 3D geometry
    of a scene through depth-sensing using light patterns. The 3D sensor has an active
    infrared laser projector, which emits encoded speckle light patterns. The sensors
    allow users to capture color images and provide a 3D depth map at a resolution
    of 640 x 480\. Since the Kinect sensor is an active sensor, it is invariant to
    indoor lighting condition (that is, it even works in the dark) and enables many
    applications, such as gesture and pose tracking as well as 3D scanning and reconstruction.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于PrimeSense技术的微软Kinect 3D范围感应相机是一套有趣的设备，它通过使用光模式进行深度感应来估计场景的3D几何形状。3D传感器具有一个主动红外激光投影仪，它发射编码的斑点光模式。这些传感器允许用户捕获彩色图像，并提供分辨率为640
    x 480的3D深度图。由于Kinect传感器是一个主动传感器，它对室内照明条件（即，即使在黑暗中也能工作）不变，从而使得许多应用成为可能，例如手势和姿态跟踪以及3D扫描和重建。
- en: In this section, we will demonstrate how to set up this type of range-sensing
    camera, as an example. While we do not require readers to purchase a 3D range-sensing
    camera for this chapter (since we will provide the raw data captured on this device
    for the purpose of running our demos), we will demonstrate how one can set up
    the device to capture data directly, primarily for those who are interested in
    further experimenting with real-time 3D data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示如何设置此类范围感应相机，作为一个示例。虽然我们不需要读者为本章购买3D范围感应相机（因为我们将为运行我们的演示提供该设备捕获的原始数据），但我们将演示如何设置设备以直接捕获数据，主要针对那些对进一步实验实时3D数据感兴趣的人。
- en: How to do it...
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Windows users can download the OpenNI 2 SDK and driver from [http://structure.io/openni](http://structure.io/openni)
    (or using the direct download link: [http://com.occipital.openni.s3.amazonaws.com/OpenNI-Windows-x64-2.2.0.33.zip](http://com.occipital.openni.s3.amazonaws.com/OpenNI-Windows-x64-2.2.0.33.zip))
    and follow the on-screen instructions. Linux users can download the OpenNI 2 SDK
    from the same website at [http://structure.io/openni](http://structure.io/openni).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Windows用户可以从[http://structure.io/openni](http://structure.io/openni)（或使用直接下载链接：[http://com.occipital.openni.s3.amazonaws.com/OpenNI-Windows-x64-2.2.0.33.zip](http://com.occipital.openni.s3.amazonaws.com/OpenNI-Windows-x64-2.2.0.33.zip)）下载OpenNI
    2 SDK和驱动程序，并按照屏幕上的说明操作。Linux用户可以从同一网站[http://structure.io/openni](http://structure.io/openni)下载OpenNI
    2 SDK。
- en: 'Mac users can install the OpenNI2 driver as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Mac用户可以按照以下步骤安装OpenNI2驱动程序：
- en: 'Install libraries with Macport:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Macport安装库：
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Download OpenNI2 from [https://github.com/occipital/openni2](https://github.com/occipital/openni2).
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://github.com/occipital/openni2](https://github.com/occipital/openni2)下载OpenNI2。
- en: 'Compile the source code with the following commands:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令编译源代码：
- en: '[PRE1]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Run the `SimpleViewer` executable:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`SimpleViewer`可执行文件：
- en: '[PRE2]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you are using a computer with a USB 3.0 interface, it is important that you
    first upgrade the firmware for the PrimeSense sensor to version 1.0.9 ([http://dasl.mem.drexel.edu/wiki/images/5/51/FWUpdate_RD109-112_5.9.2.zip](http://dasl.mem.drexel.edu/wiki/images/5/51/FWUpdate_RD109-112_5.9.2.zip)).
    This upgrade requires a Windows platform. Note that the Windows driver for the
    PrimeSense sensor must be installed ([http://structure.io/openni](http://structure.io/openni))
    for you to proceed. Execute the `FWUpdate_RD109-112_5.9.2.exe` file, and the firmware
    will be automatically upgraded. Further details on the firmware can be found at
    [http://dasl.mem.drexel.edu/wiki/index.php/4._Updating_Firmware_for_Primesense](http://dasl.mem.drexel.edu/wiki/index.php/4._Updating_Firmware_for_Primesense).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是具有USB 3.0接口的计算机，那么首先升级PrimeSense传感器的固件到版本1.0.9[http://dasl.mem.drexel.edu/wiki/images/5/51/FWUpdate_RD109-112_5.9.2.zip](http://dasl.mem.drexel.edu/wiki/images/5/51/FWUpdate_RD109-112_5.9.2.zip)非常重要。此升级需要Windows平台。请注意，为了继续操作，您必须安装PrimeSense传感器的Windows驱动程序[http://structure.io/openni](http://structure.io/openni)。执行`FWUpdate_RD109-112_5.9.2.exe`文件，固件将自动升级。有关固件的更多详细信息，请参阅[http://dasl.mem.drexel.edu/wiki/index.php/4._Updating_Firmware_for_Primesense](http://dasl.mem.drexel.edu/wiki/index.php/4._Updating_Firmware_for_Primesense)。
- en: See also
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Detailed technical specifications of the Microsoft Kinect 3D system can be obtained
    from [http://msdn.microsoft.com/en-us/library/jj131033.aspx](http://msdn.microsoft.com/en-us/library/jj131033.aspx),
    and further installation instructions and prerequisites to build OpenNI2 drivers
    can be found at [https://github.com/occipital/openni2](https://github.com/occipital/openni2).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从[http://msdn.microsoft.com/en-us/library/jj131033.aspx](http://msdn.microsoft.com/en-us/library/jj131033.aspx)获取Microsoft
    Kinect 3D系统的详细技术规格，并且有关安装OpenNI2驱动程序的进一步说明和先决条件可以在[https://github.com/occipital/openni2](https://github.com/occipital/openni2)找到。
- en: In addition, Microsoft Kinect V2 is also available and is compatible with Windows.
    The new sensor provides higher resolution images and better depth fidelity. More
    information about the sensor, as well as the Microsoft Kinect SDK, can be found
    at [https://www.microsoft.com/en-us/kinectforwindows](https://www.microsoft.com/en-us/kinectforwindows).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Microsoft Kinect V2也可用，并且与Windows兼容。新的传感器提供更高分辨率的图像和更好的深度保真度。有关传感器的更多信息以及Microsoft
    Kinect SDK，请参阅[https://www.microsoft.com/en-us/kinectforwindows](https://www.microsoft.com/en-us/kinectforwindows)。
- en: Capturing raw data from depth-sensing cameras
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从深度感应相机捕获原始数据
- en: Now that you have installed the prerequisite libraries and drivers, we will
    demonstrate how to capture raw data from your depth-sensing camera.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已安装了必要的库和驱动程序，我们将演示如何从您的深度感应相机捕获原始数据。
- en: How to do it...
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To capture sensor data directly in a binary format, implement the following
    function:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要直接以二进制格式捕获传感器数据，实现以下函数：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Similarly, we also capture the raw RGB color data with the following implementation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们使用以下实现方法捕获原始的RGB颜色数据：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding code snippet can be added to any sample code within the OpenNI2
    SDK that provides depth and color data visualization (to enable raw data capture).
    We recommend that you modify the `Viewer.cpp` file in the `OpenNI2-master/Samples/SimpleViewer`
    folder. The modified sample code is included in our code package. To capture raw
    data, press *R* and the data will be stored in the `depth_frame0.bin` and `color_frame0.bin`
    files.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段可以添加到OpenNI2 SDK中提供深度和颜色数据可视化的任何示例代码中（以启用原始数据捕获）。我们建议您修改`OpenNI2-master/Samples/SimpleViewer`文件夹中的`Viewer.cpp`文件。修改后的示例代码包含在我们的代码包中。要捕获原始数据，请按*R*键，数据将被存储在`depth_frame0.bin`和`color_frame0.bin`文件中。
- en: How it works...
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: The depth sensor returns two streams of data in real time. One data stream is
    a 3D depth map, which is stored in 16-bits unsigned short data type (see the following
    figure on the left-hand side). Another data stream is a color image (see the following
    figure on the right-hand side), which is stored in a 24 bits per pixel, RGB888
    format (that is, the memory is aligned in the R, G, and B order, and *8 bits *
    3 channels = 24 bits* are used per pixel).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 深度传感器实时返回两个数据流。一个数据流是3D深度图，存储在16位无符号短数据类型中（见以下图左侧）。另一个数据流是彩色图像（见以下图右侧），存储在每像素24位，RGB888格式中（即内存按R、G、B顺序对齐，每个像素使用*8位*
    *3通道* = 24位）。
- en: '![How it works...](img/9727OS_05_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/9727OS_05_01.jpg)'
- en: The binary data is written directly to the hard disk without compression or
    modification to the data format. On the client side, we read the binary files
    as if there is a continuous stream of data and color data pairs arriving synchronously
    from the hardware device. The OpenNI2 driver provides the mechanism to interface
    with the PrimeSense-based sensors (Microsoft Kinect or PS1080).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制数据直接写入硬盘，不进行压缩或修改数据格式。在客户端，我们读取二进制文件，就像有连续的数据流和颜色数据对同步从硬件设备到达一样。OpenNI2驱动程序提供了与基于PrimeSense的传感器（Microsoft
    Kinect或PS1080）接口的机制。
- en: The `openni::VideoFrameRef depthFrame` variable, for example, stores the reference
    to the depth data buffer. By calling the `depthFrame.getData()` function, we obtain
    a pointer to the buffer in the `DepthPixel` format, which is equivalent to the
    unsigned short data type. Then, we write the binary data to a file using the `write()`
    function in the `fstream` library. Similarly, we perform the same task with the
    color image, but the data is stored in the RGB888 format.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`openni::VideoFrameRef depthFrame`变量存储了对深度数据缓冲区的引用。通过调用`depthFrame.getData()`函数，我们获得一个指向`DepthPixel`格式缓冲区的指针，这相当于无符号短数据类型。然后，我们使用`fstream`库中的`write()`函数将二进制数据写入文件。同样，我们使用彩色图像执行相同的任务，但数据存储在RGB888格式中。
- en: 'Additionally, we can enable the `setImageRegistrationMode` (`openni::IMAGE_REGISTRATION_DEPTH_TO_COLOR`)
    depth map registration function in OpenNI2 to automatically compute and map a
    depth value onto the color image. The depth map is overlaid onto the color image
    and is shown in the following figure:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以在OpenNI2中启用`setImageRegistrationMode`（`openni::IMAGE_REGISTRATION_DEPTH_TO_COLOR`）深度图注册功能，以自动计算并将深度值映射到颜色图像上。深度图叠加在颜色图像上，如图所示：
- en: '![How it works...](img/9727OS_05_02.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/9727OS_05_02.jpg)'
- en: In the next section, we will assume that the raw depth map is precalibrated
    with image registration by OpenNI2 and can be used to compute the real-world coordinates
    and UV mapping indices directly.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将假设原始深度图已经通过OpenNI2的图像配准预校准，可以直接用于计算真实世界的坐标和UV映射索引。
- en: OpenGL point cloud rendering with texture mapping and overlays
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带纹理映射和叠加的OpenGL点云渲染
- en: We will build on the OpenGL framework discussed in the previous chapter for
    point cloud rendering in this section. The texture mapping technique introduced
    in the previous chapter can also be applied in the point cloud format. Basically,
    the depth sensor provides a set of vertices in real-world space (the depth map),
    and the color camera provides us with the color information of the vertices. UV
    mapping is a simple lookup table once the depth map and color camera are calibrated.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在上一章讨论的OpenGL框架的基础上构建本节中的点云渲染。上一章中引入的纹理映射技术也可以应用于点云格式。基本上，深度传感器提供了一组实际空间中的顶点（深度图），而颜色相机为我们提供了顶点的颜色信息。一旦深度图和颜色相机校准，UV映射就是一个简单的查找表。
- en: Getting ready
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Readers should use the raw data provided for the subsequent demo or obtain
    their own raw data from a 3D range-sensing camera. In either case, we assume these
    filenames will be used to denote the raw data files: `depth_frame0.bin` and `color_frame0.bin`.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 读者应使用提供的原始数据用于后续演示或从3D范围感应相机获取自己的原始数据。在任一情况下，我们假设这些文件名将用于表示原始数据文件：`depth_frame0.bin`和`color_frame0.bin`。
- en: How to do it...
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Similar to the previous chapter, we will divide the program into three major
    components: the main program (`main.cpp`), shader programs (`shader.cpp`, `shader.hpp`,
    `pointcloud.vert`, `pointcloud.frag`), and texture-mapping functions (`texture.cpp`,
    `texture.hpp`). The main program performs the essential tasks to set up the demo,
    while the shader programs perform the specialized processing. The texture-mapping
    functions provide a mechanism to load and map the color information onto the vertices.
    Finally, we modify the `control.cpp` file to provide more refined controls over
    the **fly-through** experience through various additional keyboard inputs (using
    the up, down, left, and right arrow keys to zoom in and out in addition to adjusting
    the rotation angles using the *a*, *s*, *x*, and *z* keys).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一章类似，我们将程序分为三个主要组件：主程序（`main.cpp`）、着色器程序（`shader.cpp`，`shader.hpp`，`pointcloud.vert`，`pointcloud.frag`）和纹理映射函数（`texture.cpp`，`texture.hpp`）。主程序执行设置演示的基本任务，而着色器程序执行专门的加工。纹理映射函数提供了一种将颜色信息加载并映射到顶点的机制。最后，我们修改`control.cpp`文件，通过各种额外的键盘输入（使用上、下、左、右箭头键进行缩放，以及使用*a*、*s*、*x*和*z*键调整旋转角度）提供对**飞行体验**的更精细控制。
- en: First, let's take a look at the shader programs. We will create two vertex and
    fragment shader programs inside the `pointcloud.vert` and `pointcloud.frag` files
    that are compiled and loaded by the program at runtime by using the `LoadShaders`
    function in the `shader.cpp` file.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下着色器程序。我们将在`pointcloud.vert`和`pointcloud.frag`文件中创建两个顶点和片段着色器程序，这些程序在程序运行时通过`shader.cpp`文件中的`LoadShaders`函数编译和加载。
- en: 'For the `pointcloud.vert` file, we implement the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`pointcloud.vert`文件，我们实现以下内容：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For the `pointcloud.frag` file, we implement the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`pointcloud.frag`文件，我们实现以下内容：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, let''s put everything together with the `main.cpp` file:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用`main.cpp`文件将所有内容组合在一起：
- en: 'Include prerequisite libraries and the shader program header files inside the
    common folder:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在公共文件夹中包含先决库和着色器程序头文件：
- en: '[PRE7]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a global variable for the GLFW window:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为GLFW窗口创建一个全局变量：
- en: '[PRE8]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Define the width and height of the input depth dataset as well as other window/camera
    properties for rendering:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入深度数据集的宽度和高度以及其他用于渲染的窗口/相机属性：
- en: '[PRE9]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Define helper functions to parse the raw depth and color data:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义辅助函数以解析原始深度和颜色数据：
- en: '[PRE10]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Create callback functions to handle key strokes:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建回调函数以处理按键：
- en: '[PRE11]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Start the main program with the initialization of the GLFW library:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用GLFW库的初始化启动主程序：
- en: '[PRE12]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Set up the GLFW window:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置GLFW窗口：
- en: '[PRE13]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create the GLFW window object and make it current for the calling thread:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建GLFW窗口对象并使其对调用线程当前：
- en: '[PRE14]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Initialize the GLEW library and include support for experimental drivers:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化GLEW库并包含对实验性驱动程序的支持：
- en: '[PRE15]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Set up keyboard callback:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置键盘回调：
- en: '[PRE16]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Set up the shader programs:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置着色器程序：
- en: '[PRE17]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create the vertex (*x*, *y*, *z*) for all depth pixels:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所有深度像素创建顶点（*x*，*y*，*z*）：
- en: '[PRE18]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Read the raw data using the helper functions defined previously:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用先前定义的辅助函数读取原始数据：
- en: '[PRE19]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Load the color information into a texture object:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将颜色信息加载到纹理对象中：
- en: '[PRE20]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create a set of vertices in a real-world space based on the depth map and also
    define the UV mapping for the color mapping:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据深度图在真实空间中创建一组顶点，并定义颜色映射的UV映射：
- en: '[PRE21]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Get the location for various uniform and attribute variables:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取各种统一和属性变量的位置：
- en: '[PRE22]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Generate the vertex array object:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成顶点数组对象：
- en: '[PRE23]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Initialize the vertex buffer memory:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化顶点缓冲区内存：
- en: '[PRE24]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create and bind the UV buffer memory:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建并绑定UV缓冲区内存：
- en: '[PRE25]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Use our shader program:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们的着色器程序：
- en: '[PRE26]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Bind the texture in Texture Unit 0:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在纹理单元0中绑定纹理：
- en: '[PRE27]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Set up attribute buffers for vertices and UV mapping:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为顶点和UV映射设置属性缓冲区：
- en: '[PRE28]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Run the draw functions and loop:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行绘制函数和循环：
- en: '[PRE29]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Clean up and exit the program:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理并退出程序：
- en: '[PRE30]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In `texture.cpp`, we implement the additional image-loading functions based
    on the previous chapter:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `texture.cpp` 中，我们基于上一章实现了额外的图像加载函数：
- en: '[PRE31]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In `texture.hpp`, we simply define the function prototypes:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `texture.hpp` 中，我们简单地定义了函数原型：
- en: '[PRE32]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In `control.cpp`, we modify the `computeViewProjectionMatrices` function with
    the following code to support additional translation controls:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `control.cpp` 中，我们使用以下代码修改 `computeViewProjectionMatrices` 函数以支持额外的平移控制：
- en: '[PRE33]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now we have created a way to visualize the depth sensor information in a 3D
    fly-through style; the following figure shows the rendering of the point cloud
    with a virtual camera at the central position of the frame:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了一种以3D飞行浏览风格可视化深度传感器信息的方法；以下图显示了以帧中央位置为虚拟摄像机的点云渲染：
- en: '![How to do it...](img/9727OS_05_03.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/9727OS_05_03.jpg)'
- en: 'By rotating and translating the virtual camera, we can create various representations
    of the scene from different perspectives. With a bird''s eye view or side view
    of the scene, we can see the contour of the face and hand more apparently from
    these two angles, respectively:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过旋转和移动虚拟摄像机，我们可以从不同的视角创建场景的各种表示。从场景的鸟瞰图或侧视图，我们可以分别从这两个角度更明显地看到面部和手的轮廓：
- en: '![How to do it...](img/9727OS_05_04.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/9727OS_05_04.jpg)'
- en: 'This is the side view of the same scene:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是同一场景的侧视图：
- en: '![How to do it...](img/9727OS_05_05.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/9727OS_05_05.jpg)'
- en: 'By adding an additional condition to the remapping loop, we can render the
    unknown regions (holes) from the scene where the depth camera fails to reconstruct
    due to occlusion, field of view limitation, range limitation, and/or surface properties
    such as reflectance:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在重映射循环中添加一个额外的条件，我们可以渲染场景中的未知区域（空洞），这些区域由于遮挡、视场限制、范围限制以及/或表面特性（如反射率）等原因，深度相机无法重建：
- en: '[PRE34]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This condition allows us to segment the region and project the regions with
    depth values of 0 onto a plane that is 0.2 meters away from the virtual camera,
    as shown in the following figure:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这种条件允许我们将深度值为0的区域分割并投影到距离虚拟摄像机0.2米远的平面上，如图所示：
- en: '![How to do it...](img/9727OS_05_06.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/9727OS_05_06.jpg)'
- en: How it works...
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: 'In this chapter, we exploited the GLSL pipeline and texture-mapping technique
    to create an interactive point cloud visualization tool that enables the 3D navigation
    of a scene captured with a 3D range-sensing camera. The shader program also combines
    the result with the color image to produce our desired effect. The program reads
    two binary images: the calibrated depth map image and the RGB color image. The
    color is loaded into a texture object directly using the new `loadRGBImageToTexture()`
    function, which converts the data from `GL_RGB` to `GL_RGBA`. Then, the depth
    map data is converted into point cloud data in real-world coordinates based on
    the intrinsic value of the cameras as well as the depth value at each pixel, as
    follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们利用GLSL管道和纹理映射技术创建了一个交互式的点云可视化工具，该工具能够使用3D范围感应相机捕获的场景进行3D导航。着色器程序还将结果与彩色图像结合以产生我们期望的效果。程序读取两个二进制图像：校准的深度图图像和RGB彩色图像。颜色直接使用新的
    `loadRGBImageToTexture()` 函数加载到纹理对象中，该函数将数据从 `GL_RGB` 转换为 `GL_RGBA`。然后，根据相机的内在值以及每个像素的深度值，将深度图数据转换为基于实际坐标的点云数据，如下所示：
- en: '![How it works...](img/9727OS_05_07.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/9727OS_05_07.jpg)'
- en: Here, *d* is the depth value in millimeter, *x* and *y* are the positions of
    the depth value in pixel (projective) space, ![How it works...](img/9727OS_05_11.jpg)
    and ![How it works...](img/9727OS_05_12.jpg) are the principle axes of the depth
    camera, ![How it works...](img/9727OS_05_13.jpg) and ![How it works...](img/9727OS_05_14.jpg)
    are the focal lengths of the camera, and ![How it works...](img/9727OS_05_15.jpg)
    is the position of the point cloud in the real-world coordinate.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*d* 是毫米级的深度值，*x* 和 *y* 是深度值在像素（投影）空间中的位置，![如何工作...](img/9727OS_05_11.jpg)
    和 ![如何工作...](img/9727OS_05_12.jpg) 是深度相机的原理轴，![如何工作...](img/9727OS_05_13.jpg)
    和 ![如何工作...](img/9727OS_05_14.jpg) 是相机的焦距，而 ![如何工作...](img/9727OS_05_15.jpg) 是点云在真实世界坐标系中的位置。
- en: 'In our example, we do not require fine alignment or registration as our visualizer
    uses a primitive estimation of the intrinsic parameters:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们不需要精细的对齐或注册，因为我们的可视化器使用了对内在参数的原始估计：
- en: '![How it works...](img/9727OS_05_16.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/9727OS_05_16.jpg)'
- en: These numbers could be estimated with the camera calibration tools in OpenCV.
    The details of these tools are beyond the scope of this chapter.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数值可以使用OpenCV中的相机标定工具进行估计。这些工具的详细内容超出了本章的范围。
- en: For our application, we are provided a set of 3D points (*x*, *y*, *z*) as well
    as the corresponding color information (*r*, *g*, *b*) to compute the point cloud
    representation. However, the point visualization does not support dynamic lighting
    and other more advanced rendering techniques. To address this, we can extend the
    point cloud further into a mesh (that is, a set of triangles to represent surfaces),
    which will be discussed in the next chapter.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用，我们提供了一组3D点（*x*，*y*，*z*）以及相应的颜色信息（*r*，*g*，*b*）来计算点云表示。然而，点可视化不支持动态照明和其他更高级的渲染技术。为了解决这个问题，我们可以将点云进一步扩展成网格（即，一组三角形来表示表面），这将在下一章中讨论。
