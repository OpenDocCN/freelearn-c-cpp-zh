["```cpp\n    cd 3rd_party/android && unzip OpenCV-3.0.0-android-sdk-1.zip\n\n    ```", "```cpp\n    #!/bin/bash\n    ANDROID_SDK_PATH=\"../../../3rd_party/android/android-sdk-macosx\"\n    OPENCV_SDK_PATH=\"../../../3rd_party/android/OpenCV-android-sdk\"\n\n    #initialize the SDK Java library\n    $ANDROID_SDK_PATH/tools/android update project -p $OPENCV_SDK_PATH/sdk/java -s --target \"android-18\"\n    $ANDROID_SDK_PATH/tools/android update project -p . -s --target \"android-18\" --library $OPENCV_SDK_PATH/sdk/java\n    ```", "```cpp\n    LOCAL_PATH:= $(call my-dir)\n    #build the OpenGL + OpenCV code in JNI\n    include $(CLEAR_VARS)\n    #including OpenCV SDK\n    include ../../../3rd_party/android/OpenCV-android-sdk/sdk/native/jni/OpenCV.mk\n    ```", "```cpp\n$ANDROID_SDK_PATH/platform-tools/adb install ../../../3rd_party/android/OpenCV-android-sdk/apk/OpenCV_3.0.0_Manager_3.00_armeabi-v7a.apk\n```", "```cpp\n    package com.android.gl3jni;\n    ...\n    import org.opencv.android.BaseLoaderCallback;\n    import org.opencv.android.LoaderCallbackInterface;\n    import org.opencv.android.OpenCVLoader;\n    import org.opencv.android.CameraBridgeViewBase;\n    import org.opencv.android.CameraBridgeViewBase.CvCameraViewFrame;\n    import org.opencv.android.CameraBridgeViewBase.CvCameraViewListener2;\n    import org.opencv.core.CvType;\n    import org.opencv.core.Mat;\n\n    import android.widget.RelativeLayout;\n    import android.view.SurfaceView;\n    ```", "```cpp\n    public class GL3OpenCVDemo extends Activity implements SensorEventListener, CvCameraViewListener2{\n    ```", "```cpp\n      private GL3JNIView mView=null;\n      ...\n      private boolean gl3_loaded = false;\n      private CameraBridgeViewBase mOpenCvCameraView;\n      private RelativeLayout l_layout;\n    ```", "```cpp\n      private BaseLoaderCallback mLoaderCallback = new BaseLoaderCallback(this) {\n      @Override \n      public void onManagerConnected(int status) {\n        switch (status) {\n          case LoaderCallbackInterface.SUCCESS:{\n            Log.i(\"OpenCVDemo\", \"OpenCV loaded successfully\");\n            // load the library *AFTER* we have OpenCV lib ready!\n            System.loadLibrary(\"gl3jni\");\n            gl3_loaded = true;\n\n            //load the view as we have all JNI loaded \n            mView = new GL3JNIView(getApplication());\n            l_layout.addView(mView);\n            setContentView(l_layout);\n\n            /* enable the camera, and push the images to the OpenGL layer */\n            mOpenCvCameraView.enableView();\n          } break;\n          default:{\n            super.onManagerConnected(status);\n          } break;\n        }\n      }\n    };\n    ```", "```cpp\n    public void onCameraViewStarted(int width, int height) {\n    }\n    public void onCameraViewStopped() {\n    }\n    public Mat onCameraFrame(CvCameraViewFrame inputFrame) {\n      //Log.i(\"OpenCVDemo\", \"Got Frame\\n\");\n      Mat input = inputFrame.rgba();\n      if(gl3_loaded){\n        GL3JNILib.setImage(input.nativeObj);\n      }\n      //don't show on the java side\n      return null;\n    }\n    ```", "```cpp\n    @Override protected void onCreate(Bundle icicle) {\n      super.onCreate(icicle);\n      ...\n      //setup the Java Camera with OpenCV\n      setContentView(R.layout.ar);\n      l_layout = (RelativeLayout)findViewById(R.id.linearLayoutRest);\n      mOpenCvCameraView = (CameraBridgeViewBase)findViewById(R.id.opencv_camera_surface_view);\n      mOpenCvCameraView.setVisibility( SurfaceView.VISIBLE );\n      mOpenCvCameraView.setMaxFrameSize(1280, 720); /* cap it at 720 for performance issue */\n      mOpenCvCameraView.setCvCameraViewListener(this);\n      mOpenCvCameraView.disableView();\n    }\n    ```", "```cpp\n    @Override\n    protected void onResume() {\n      super.onResume();\n      OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION_3_0_0, this, mLoaderCallback);  \n      ...\n    }\n    ```", "```cpp\n    @Override\n    protected void onPause() {\n      super.onPause();\n      mSensorManager.unregisterListener(this);\n      //stop the camera\n      if(mView!=null){\n        mView.onPause();\n      }\n      if (mOpenCvCameraView != null)\n        mOpenCvCameraView.disableView();\n      gl3_loaded = false;\n    }\n    ```", "```cpp\n    package com.android.gl3jni;\n\n    public class GL3JNILib { \n      public static native void init(int width, int height);\n      public static native void step();\n\n      //pass the image to JNI C++ side\n      public static native void setImage(long imageRGBA);\n\n      //pass the device rotation angles and the scaling factor\n      public static native void resetRotDataOffset();\n      public static native void setRotMatrix(float[] rotMatrix);\n      public static native void setScale(float scale);\n    }\n    ```", "```cpp\n    class GL3JNIView extends GLSurfaceView {\n      ...\n      public GL3JNIView(Context context) {\n        super(context);\n        // Pick an EGLConfig with RGB8 color, 16-bit depth, no stencil \n        setZOrderOnTop(true);\n        setEGLConfigChooser(8, 8, 8, 8, 16, 0);\n        setEGLContextClientVersion(3);\n        getHolder().setFormat(PixelFormat.TRANSLUCENT);\n        renderer = new Renderer();\n        setRenderer(renderer);\n        //handle gesture input\n        mScaleDetector = new ScaleGestureDetector(context, new ScaleListener());\n      }\n      ...\n      @Override\n      public boolean onTouchEvent(MotionEvent ev) {\n        mScaleDetector.onTouchEvent(ev);\n        int action = ev.getActionMasked();\n        switch (action) {\n          case MotionEvent.ACTION_DOWN:\n            GL3JNILib.resetRotDataOffset();\n            break;\n        }\n        return true;\n      }\n      ...\n    }\n    ```", "```cpp\n    //external calls for Java\n    extern \"C\" {\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setImage(JNIEnv * jenv, jobject, jlong imageRGBA);\n    };\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setImage(\n        JNIEnv * jenv, jobject, jlong imageRGBA) {\n          cv::Mat* image = (cv::Mat*) imageRGBA;\n          /* use mutex lock to ensure the write/read operations are synced (to avoid corrupting the frame) */\n          pthread_mutex_lock(&count_mutex);\n          frame = image->clone();\n          pthread_mutex_unlock(&count_mutex);\n          //LOGI(\"Got Image: %dx%d\\n\", frame.rows, frame.cols);\n    }\n    ```", "```cpp\n    <uses-permission android:name=\"android.permission.CAMERA\"/>\n    <uses-feature android:name=\"android.hardware.camera\" android:required=\"false\"/>\n    <uses-feature android:name=\"android.hardware.camera.autofocus\" android:required=\"false\"/>\n    <uses-feature android:name=\"android.hardware.camera.front\" android:required=\"false\"/>\n    <uses-feature android:name=\"android.hardware.camera.front.autofocus\" android:required=\"false\"/>\n    ```", "```cpp\n#ifndef VIDEORENDERER_H_\n#define VIDEORENDERER_H_\n//The shader program and basic OpenGL calls\n#include <Shader.hpp>\n//for texture support\n#include <Texture.hpp>\n//opencv support\n#include <opencv2/core/core.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/highgui/highgui.hpp>\n\nclass VideoRenderer {\n  public:\n    VideoRenderer();\n    virtual ~VideoRenderer();\n    //setup all shader program and texture mapping variables\n    bool setup();\n    bool initTexture(cv::Mat frame);\n    //render the frame on screen\n    void render(cv::Mat frame);\n\n  private:\n    //this handles the generic camera feed view\n    GLuint gProgram;\n    GLuint gvPositionHandle;\n    GLuint vertexUVHandle;\n    GLuint textureSamplerID;\n    GLuint texture_id;\n    Shader shader;\n};\n\n#endif /* VIDEORENDERER_H_ */\n```", "```cpp\n    #include \"VideoRenderer.hpp\"\n\n    #define  LOG_TAG    \"VideoRenderer\"\n    #define  LOGI(...) __android_log_print(ANDROID_LOG_INFO,LOG_TAG,__VA_ARGS__)\n    #define  LOGE(...) __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)\n\n    VideoRenderer::VideoRenderer() {\n    }\n\n    VideoRenderer::~VideoRenderer() {\n    }\n    ```", "```cpp\n    bool VideoRenderer::setup(){\n      // Vertex shader source code\n      const char g_vshader_code[] =\n      \"#version 300 es\\n\"\n      \"layout(location = 1) in vec4 vPosition;\\n\"\n      \"layout(location = 2) in vec2 vertexUV;\\n\"\n      \"out vec2 UV;\\n\"\n      \"void main() {\\n\"\n        \"  gl_Position = vPosition;\\n\"\n        \"  UV=vertexUV;\\n\"\n      \"}\\n\";\n      // fragment shader source code\n      const char g_fshader_code[] =\n      \"#version 300 es\\n\"\n      \"precision mediump float;\\n\"\n      \"out vec4 color;\\n\"\n      \"uniform sampler2D textureSampler;\\n\"\n      \"in vec2 UV;\\n\"\n      \"void main() {\\n\"\n        \"  color = vec4(texture(textureSampler, UV).rgb, 1.0);\\n\"\n      \"}\\n\";\n\n      LOGI(\"setupVideoRenderer\");\n      gProgram =   shader.createShaderProgram(g_vshader_code, g_fshader_code);\n      if (!gProgram) {\n        LOGE(\"Could not create program.\");\n        return false;\n      }\n\n      gvPositionHandle = glGetAttribLocation(gProgram, \"vPosition\");\n      shader.checkGlError(\"glGetAttribLocation\");\n      LOGI(\"glGetAttribLocation(\\\"vPosition\\\") = %d\\n\",\n      gvPositionHandle);\n\n      vertexUVHandle = glGetAttribLocation(gProgram, \"vertexUV\");\n      shader.checkGlError(\"glGetAttribLocation\");\n      LOGI(\"glGetAttribLocation(\\\"vertexUV\\\") = %d\\n\",\n      vertexUVHandle);\n\n      textureSamplerID = glGetUniformLocation(gProgram, \"textureSampler\");\n      shader.checkGlError(\"glGetUniformLocation\");\n      LOGI(\"glGetUniformLocation(\\\"textureSampler\\\") =   %d\\n\", textureSamplerID);\n\n      return true;\n    }\n    ```", "```cpp\n    bool VideoRenderer::initTexture(cv::Mat frame){\n      texture_id = initializeTexture(frame.data, frame.size().width, frame.size().height);\n      //binds our texture in Texture Unit 0\n      glActiveTexture(GL_TEXTURE0);\n      glBindTexture(GL_TEXTURE_2D, texture_id);\n      glUniform1i(textureSamplerID, 0);\n\n      return true;\n    }\n    ```", "```cpp\n    void VideoRenderer::render(cv::Mat frame){\n      //our vertices\n      const GLfloat g_vertex_buffer_data[] = {\n        1.0f,1.0f,0.0f,\n        -1.0f,1.0f,0.0f,\n        -1.0f,-1.0f,0.0f,\n        1.0f,1.0f\n        ,0.0f,\n        -1.0f,-1.0f,0.0f,\n        1.0f,-1.0f,0.0f\n      };\n      //UV map for the vertices\n      const GLfloat g_uv_buffer_data[] = {\n        1.0f, 0.0f,\n        0.0f, 0.0f,\n        0.0f, 1.0f,\n        1.0f, 0.0f,\n        0.0f, 1.0f,\n        1.0f, 1.0f\n      };\n\n      glUseProgram(gProgram);\n      shader.checkGlError(\"glUseProgram\");\n\n      glEnableVertexAttribArray(gvPositionHandle);\n      shader.checkGlError(\"glEnableVertexAttribArray\");\n\n      glEnableVertexAttribArray(vertexUVHandle);\n      shader.checkGlError(\"glEnableVertexAttribArray\");\n\n      glVertexAttribPointer(gvPositionHandle, 3, GL_FLOAT, GL_FALSE, 0, g_vertex_buffer_data);\n      shader.checkGlError(\"glVertexAttribPointer\");\n\n      glVertexAttribPointer(vertexUVHandle, 2, GL_FLOAT, GL_FALSE, 0, g_uv_buffer_data);\n      shader.checkGlError(\"glVertexAttribPointer\");\n\n      updateTexture(frame.data, frame.size().width, frame.size().height, GL_RGBA);\n\n      //draw the camera feed on the screen\n      glDrawArrays(GL_TRIANGLES, 0, 6);\n      shader.checkGlError(\"glDrawArrays\");\n\n      glDisableVertexAttribArray(gvPositionHandle);\n      glDisableVertexAttribArray(vertexUVHandle);\n    }\n    ```", "```cpp\n#ifndef SHADER_H_\n#define SHADER_H_\n\n#define GLM_FORCE_RADIANS\n#include <jni.h>\n#include <android/log.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <GLES3/gl3.h>\n#include <glm/glm.hpp>\n#include <glm/gtc/matrix_transform.hpp>\n\nclass Shader {\n  public:\n  Shader();\n  virtual ~Shader();\n  GLuint loadShader(GLenum shader_type, const char*p_source);\n  GLuint createShaderProgram(const char*vertex_shader_code, const char*fragment_shader_code);\n  void printGLString(const char *name, GLenum s) ;\n  void checkGlError(const char* op);\n};\n\n#endif /* SHADER_H_ */\n```", "```cpp\n#ifndef TEXTURE_HPP\n#define TEXTURE_HPP\n\n#include <GLES3/gl3.h>\n\nclass Texture {\n  public:\n    Texture();\n    virtual ~Texture();\n    GLuint initializeTexture(const unsigned char *image_data, int width, int height);\n    void updateTexture(const unsigned char *image_data, int width, int height, GLenum format);\n};\n\n#endif\n```", "```cpp\n    ...\n    #include <pthread.h>\n    #include <Texture.hpp>\n    #include <Shader.hpp>\n    #include <VideoRenderer.hpp>\n\n    //including opencv headers\n    #include <opencv2/core/core.hpp>\n    #include <opencv2/imgproc/imgproc.hpp>\n    #include <opencv2/highgui/highgui.hpp>\n    #include <opencv2/features2d/features2d.hpp>\n    ...\n    ```", "```cpp\n    //mutex lock for data copying\n    pthread_mutex_t count_mutex;\n    ...\n    //pre-set image size.\n    const int IMAGE_WIDTH = 1280;\n    const int IMAGE_HEIGHT = 720; \n\n    bool enable_process = true;\n    //main camera feed from the Java side\n    cv::Mat frame;\n    //all shader related code\n    Shader shader;\n    //for video rendering\n    VideoRenderer videorenderer;\n    ```", "```cpp\n    bool setupGraphics(int w, int h) {\n      ...\n      videorenderer.setup();\n      //template for the first texture\n      cv::Mat frameM(IMAGE_HEIGHT, IMAGE_WIDTH, CV_8UC4, cv::Scalar(0,0,0,255));\n      videorenderer.initTexture(frameM);\n      frame = frameM;\n      ...\n      return true;\n    }\n    ```", "```cpp\n    void processFrame(cv::Mat *frame_local){\n      int maxCorners = 1000;\n      if( maxCorners < 1 ) { maxCorners = 1; }\n      cv::RNG rng(12345);\n      // Parameters for Shi-Tomasi algorithm\n      std::vector<cv::Point2f> corners;\n      double qualityLevel = 0.05;\n      double minDistance = 10;\n      int blockSize = 3;\n      bool useHarrisDetector = false;\n      double k = 0.04;\n\n      // Copy the source image\n      cv::Mat src_gray;\n      cv::Mat frame_small;\n      cv::resize(*frame_local, frame_small, cv::Size(), 0.5, 0.5, CV_INTER_AREA);\n      cv::cvtColor(frame_small, src_gray, CV_RGB2GRAY );\n\n      // Apply feature extraction\n      cv::goodFeaturesToTrack( src_gray, corners, maxCorners, qualityLevel, minDistance, cv::Mat(), blockSize, useHarrisDetector, k );\n\n      // Draw corners detected on the image\n      int r = 10;\n      for( int i = 0; i < corners.size(); i++ )\n      {\n        cv::circle(*frame_local, 2*corners[i], r, cv::Scalar(rng.uniform(0,255), \n        rng.uniform(0,255), rng.uniform(0,255), 255), -1, 8, 0 );\n      }\n      //LOGI(\"Found %d features\", corners.size());\n    }\n    ```", "```cpp\n    void renderFrame() {\n      shader.checkGlError(\"glClearColor\");\n      glClearColor(0.0f, 0.0f, 0.0f, 0.0f);\n      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);\n\n      shader.checkGlError(\"glClear\");\n\n      pthread_mutex_lock(&count_mutex);\n      cv::Mat frame_local = frame.clone();\n      pthread_mutex_unlock(&count_mutex);\n\n      if(enable_process)\n        processFrame(&frame_local);\n\n      //render the video feed on screen\n      videorenderer.render(frame_local);\n      //LOGI(\"Rendering OpenGL Graphics\");\n    }\n    ```", "```cpp\n    extern \"C\" {\n    ..\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setImage(JNIEnv * jenv, jobject, jlong imageRGBA);\n      //toggle features\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_toggleFeatures(JNIEnv * jenv, jobject);\n    };\n\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_toggleFeatures(JNIEnv * env, jobject obj){\n      //toggle the processing on/off \n      enable_process = !enable_process;\n    }\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setImage(\n      JNIEnv * jenv, jobject, jlong imageRGBA) {\n      cv::Mat* image = (cv::Mat*) imageRGBA;\n      /* use mutex lock to ensure the write/read operations are synced (to avoid corrupting the frame) */\n      pthread_mutex_lock(&count_mutex);\n      frame = image->clone();\n      pthread_mutex_unlock(&count_mutex);\n      //LOGI(\"Got Image: %dx%d\\n\", frame.rows, frame.cols);\n    }\n    ```", "```cpp\n#ifndef AROVERLAYRENDERER_H_\n#define AROVERLAYRENDERER_H_\n\n#include<Shader.hpp>\n\nclass AROverlayRenderer {\n  public:\n    AROverlayRenderer();\n    virtual ~AROverlayRenderer();\n    void render();\n    bool setup();\n    void setScale(float s);\n\n    void setOldRotMatrix(glm::mat4 r_matrix);\n    void setRotMatrix(glm::mat4 r_matrix);\n    void resetRotMatrix();\n    void setScreenSize(int width, int height);\n    void setDxDy (float dx, float dy);\n  private:\n    //this renders the overlay view\n    GLuint gProgramOverlay;\n    GLuint gvOverlayPositionHandle;\n    GLuint gvOverlayColorHandle;\n    GLuint matrixHandle;\n    GLuint sigmaHandle;\n    GLuint scaleHandle;\n\n  //vertices for the grid\n  int grid_size;\n  GLfloat *gGrid;\n  GLfloat sigma;\n\n  //for handling the object rotation from user\n  GLfloat dx, dy;\n  GLfloat rotX, rotY;\n\n  //the view matrix and projection matrix\n  glm::mat4 g_view_matrix;\n  glm::mat4 g_projection_matrix;\n\n  //initial position of the camera\n  glm::vec3 g_position;\n  //FOV of the virtual camera in OpenGL\n  float g_initial_fov;\n\n  glm::mat4 rotMatrix;\n  glm::mat4 old_rotMatrix;\n\n  float scale;\n  int width;\n  int height;\n\n  Shader shader;\n  void computeProjectionMatrices();\n  void computeGrid();\n};\n\n#endif /* AROVERLAYRENDERER_H_ */\n```", "```cpp\n    #include \"AROverlayRenderer.hpp\"\n\n    #define  LOG_TAG    \"AROverlayRenderer\"\n    #define  LOGI(...) __android_log_print(ANDROID_LOG_INFO,LOG_TAG,__VA_ARGS__)\n    #define  LOGE(...) __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)\n\n    AROverlayRenderer::AROverlayRenderer() {\n      //initial position of the camera\n      g_position = glm::vec3( 0.0f, 0.0f, 0.0f );\n\n      //FOV of the virtual camera in OpenGL\n      //45 degree FOV\n      g_initial_fov = 45.0f*glm::pi<float>()/180.0f;\n\n      /* scale for the panel and other objects, allow for zooming in with pinch. */\n      scale = 1.0f;\n      dx=0.0f; dy=0.0f;\n      rotX=0.0f, rotY=0.0f;\n      sigma = 0;\n\n      grid_size = 400;\n      //allocate memory for the grid\n      gGrid = (GLfloat*) malloc(sizeof(GLfloat)*grid_size*grid_size*3);\n    }\n\n    AROverlayRenderer::~AROverlayRenderer() {\n      //delete all dynamically allocated objects here\n      free(gGrid);\n    }\n    ```", "```cpp\n    void AROverlayRenderer::computeGrid(){\n      float grid_x = grid_size;\n      float grid_y = grid_size;\n      unsigned int data_counter = 0;\n      //define a grid ranging from -1 to +1\n      for(float x = -grid_x/2.0f; x<grid_x/2.0f; x+=1.0f){\n        for(float y = -grid_y/2.0f; y<grid_y/2.0f; y+=1.0f){\n          float x_data = x/grid_x;\n          float y_data = y/grid_y;\n          gGrid[data_counter] = x_data;\n          gGrid[data_counter+1] = y_data;\n          gGrid[data_counter+2] = 0;\n          data_counter+=3;\n        }\n      }\n    }\n    ```", "```cpp\n    bool AROverlayRenderer::setup(){\n      // Vertex shader source code\n      static const char g_vshader_code_overlay[] =\n        \"#version 300 es\\n\"\n        \"in vec4 vPosition;\\n\"\n        \"uniform mat4 MVP;\\n\"\n        \"uniform float sigma;\\n\"\n        \"uniform float scale;\\n\"\n        \"out vec4 color_based_on_position;\\n\"\n        \"// Heat map generator                \\n\"\n        \"vec4 heatMap(float v, float vmin, float vmax){\\n\"\n        \"    float dv;\\n\"\n        \"    float r=1.0, g=1.0, b=1.0;\\n\"\n        \"  if (v < vmin){\\n\"\n        \"    v = vmin;}\\n\"\n        \"  if (v > vmax){\\n\"\n        \"    v = vmax;}\\n\"\n        \"  dv = vmax - vmin;\\n\"\n        \"  if (v < (vmin + 0.25 * dv)) {\\n\"\n          \"    r = 0.0;\\n\"\n          \"    g = 4.0 * (v - vmin) / dv;\\n\"\n        \"  } else if (v < (vmin + 0.5 * dv)) {\\n\"\n          \"    r = 0.0;\\n\"\n          \"    b = 1.0 + 4.0 * (vmin + 0.25 * dv - v) / dv;\\n\"\n        \"  } else if (v < (vmin + 0.75 * dv)) {\\n\"\n          \"    r = 4.0 * (v - vmin - 0.5 * dv) / dv;\\n\"\n          \"    b = 0.0;\\n\"\n        \"  } else {\\n\"\n          \"    g = 1.0 + 4.0 * (vmin + 0.75 * dv - v) / dv;\\n\"\n          \"    b = 0.0;\\n\"\n        \"  }\\n\"\n        \"    return vec4(r, g, b, 0.1);\\n\"\n      \"}\\n\"\n      \"void main() {\\n\"\n        \"  //Simulation on GPU \\n\"\n        \"  float x_data = vPosition.x;\\n\"\n        \"  float y_data = vPosition.y;\\n\"\n        \"  float sigma2 = sigma*sigma;\\n\"\n        \"  float z = exp(-0.5*(x_data*x_data)/(sigma2)-0.5*(y_data*y_data)/(sigma2));\\n\"\n        \"  vec4 position = vPosition;\\n\"\n        \"  position.z = z*scale;\\n\"\n        \"  position.x = position.x*scale;\\n\"\n        \"  position.y = position.y*scale;\\n\"\n        \"  gl_Position = MVP*position;\\n\"\n        \"  color_based_on_position = heatMap(position.z, 0.0, 0.5);\\n\"\n        \"  gl_PointSize = 5.0*scale;\\n\"\n      \"}\\n\";\n\n      // fragment shader source code\n      static const char g_fshader_code_overlay[] =\n        \"#version 300 es\\n\"\n          \"precision mediump float;\\n\"\n        \"in vec4 color_based_on_position;\\n\"\n        \"out vec4 color;\\n\"\n        \"void main() {\\n\"\n          \"  color = color_based_on_position;\\n\"\n        \"}\\n\";\n\n        //setup the shader for the overlay\n        gProgramOverlay = shader.createShaderProgram(g_vshader_code_overlay, g_fshader_code_overlay);\n      if (!gProgramOverlay) {\n        LOGE(\"Could not create program for overlay.\");\n        return false;\n      }\n      //get handlers for the overlay side\n      matrixHandle = glGetUniformLocation(gProgramOverlay, \"MVP\");\n      shader.checkGlError(\"glGetUniformLocation\");\n      LOGI(\"glGetUniformLocation(\\\"MVP\\\") = %d\\n\",\n          matrixHandle);\n\n      gvOverlayPositionHandle = glGetAttribLocation(gProgramOverlay, \"vPosition\");\n      shader.checkGlError(\"glGetAttribLocation\");\n      LOGI(\"glGetAttribLocation(\\\"vPosition\\\") = %d\\n\",\n          gvOverlayPositionHandle);\n\n      sigmaHandle = glGetUniformLocation(gProgramOverlay, \"sigma\");\n      shader.checkGlError(\"glGetUniformLocation\");\n      LOGI(\"glGetUniformLocation(\\\"sigma\\\") = %d\\n\",\n          sigmaHandle);\n\n      scaleHandle = glGetUniformLocation(gProgramOverlay, \"scale\");\n      shader.checkGlError(\"glGetUniformLocation\");\n      LOGI(\"glGetUniformLocation(\\\"scale\\\") = %d\\n\",\n        scaleHandle);\n\n      computeGrid();\n    }\n    ```", "```cpp\n    void AROverlayRenderer::setScale(float s) {\n      scale = s;\n    }\n\n    void AROverlayRenderer::setScreenSize(int w, int h) {\n      width = w;\n      height = h;\n    }\n\n    void AROverlayRenderer::setRotMatrix(glm::mat4 r_matrix){\n      rotMatrix= r_matrix;\n    }\n\n    void AROverlayRenderer::setOldRotMatrix(glm::mat4 r_matrix){\n      old_rotMatrix = r_matrix;\n    }\n\n    void AROverlayRenderer::resetRotMatrix(){\n      old_rotMatrix = rotMatrix;\n    }\n\n    void AROverlayRenderer::setDxDy(float dx, float dy){\n      //update the angle of rotation for each\n      rotX += dx/width;\n      rotY += dy/height;\n    }\n    ```", "```cpp\n    void AROverlayRenderer::computeProjectionMatrices(){\n      //direction vector for z\n      glm::vec3 direction_z(0.0, 0.0, -1.0);\n      //up vector\n      glm::vec3 up = glm::vec3(0.0, -1.0, 0.0);\n\n      float aspect_ratio = (float)width/(float)height;\n      float nearZ = 0.01f;\n      float farZ = 50.0f;\n      float top = tan(g_initial_fov/2*nearZ);\n      float right = aspect_ratio*top;\n      float left = -right;\n      float bottom = -top;\n      g_projection_matrix = glm::frustum(left, right, bottom, top, nearZ, farZ);\n\n      g_view_matrix = glm::lookAt(\n        g_position,           // camera position\n        g_position+direction_z, //viewing direction \n        up                  // up direction\n      );\n    }\n    ```", "```cpp\n    void AROverlayRenderer::render(){\n      //update the variables for animations\n      sigma+=0.002f;\n      if(sigma>0.5f){\n        sigma = 0.002f;\n      }\n      glUseProgram(gProgramOverlay);\n      /* Retrieve the View and Model matrices and apply them to the rendering */\n      computeProjectionMatrices();\n      glm::mat4 projection_matrix = g_projection_matrix;\n      glm::mat4 view_matrix = g_view_matrix;\n      glm::mat4 model_matrix = glm::mat4(1.0);\n\n      model_matrix = glm::translate(model_matrix, glm::vec3(0.0f, 0.0f, scale-5.0f));\n      //X,Y reversed for the screen orientation\n      model_matrix = glm::rotate(model_matrix, rotY*glm::pi<float>(), glm::vec3(-1.0f, 0.0f, 0.0f));\n      model_matrix = glm::rotate(model_matrix, rotX*glm::pi<float>(), glm::vec3(0.0f, -1.0f, 0.0f));\n      model_matrix = glm::rotate(model_matrix, 90.0f*glm::pi<float>()/180.0f, glm::vec3(0.0f, 0.0f, 1.0f));\n      /* the inverse of rotational matrix is to counter-  rotate the graphics to the center. This allows us to reset the camera orientation since R*inv(R) = I. */\n      view_matrix = rotMatrix*glm::inverse(old_rotMatrix)*view_matrix;\n\n      //create the MVP (model view projection) matrix\n      glm::mat4 mvp = projection_matrix * view_matrix * model_matrix;\n      glUniformMatrix4fv(matrixHandle, 1, GL_FALSE, &mvp[0][0]);\n      shader.checkGlError(\"glUniformMatrix4fv\");\n      glEnableVertexAttribArray(gvOverlayPositionHandle);\n      shader.checkGlError(\"glEnableVertexAttribArray\");\n      glVertexAttribPointer(gvOverlayPositionHandle, 3, GL_FLOAT, GL_FALSE, 0, gGrid);\n      shader.checkGlError(\"glVertexAttribPointer\");\n      glUniform1f(sigmaHandle, sigma);\n      shader.checkGlError(\"glUniform1f\");\n\n      glUniform1f(scaleHandle, 1.0f);\n      shader.checkGlError(\"glUniform1f\");\n\n      //draw the overlay graphics\n      glDrawArrays(GL_POINTS, 0, grid_size*grid_size);\n      shader.checkGlError(\"glDrawArrays\");\n      glDisableVertexAttribArray(gvOverlayPositionHandle);\n    }\n    ```", "```cpp\n    ...\n    #include <AROverlayRenderer.hpp>\n    ...\n    AROverlayRenderer aroverlayrenderer;\n    ...\n    bool setupGraphics(int w, int h) {\n      ...\n      videorenderer.setup();\n      aroverlayrenderer.setup();\n      ...\n      videorenderer.initTexture(frame);\n      aroverlayrenderer.setScreenSize(width, height);\n    }\n\n    void renderFrame() {\n      ...\n      videorenderer.render(frame);\n      aroverlayrenderer.render();\n    }\n    ...\n    extern \"C\" {\n      ...\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setScale(JNIEnv * env, jobject obj,  jfloat jscale);\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_resetRotDataOffset(JNIEnv * env, jobject obj);\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setRotMatrix (JNIEnv *env, jobject obj, jfloatArray ptr);\n      JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setDxDy(JNIEnv *env, jobject obj,  jfloat dx,  jfloat dy);\n    };\n    ...\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_resetRotDataOffset (JNIEnv * env, jobject obj){\n      aroverlayrenderer.resetRotMatrix();\n    }\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setScale (JNIEnv * env, jobject obj, jfloat jscale)\n    {\n      aroverlayrenderer.setScale(jscale);\n      LOGI(\"Scale is %lf\", scale);\n    }\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_resetRotDataOffset (JNIEnv * env, jobject obj){\n      aroverlayrenderer.resetRotMatrix();\n    }\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setRotMatrix (JNIEnv *env, jobject obj, jfloatArray ptr) {\n      jsize len = env->GetArrayLength(ptr);\n      jfloat *body = env->GetFloatArrayElements(ptr,0);\n      //should be 16 elements from the rotation matrix\n      glm::mat4 rotMatrix(1.0f);\n      int count = 0;\n      for(int i = 0; i<4; i++){\n        for(int j=0; j<4; j++){\n          rotMatrix[i][j] = body[count];\n          count++;\n        }\n      }\n      env->ReleaseFloatArrayElements(ptr, body, 0);\n      aroverlayrenderer.setRotMatrix(rotMatrix);\n    }\n    JNIEXPORT void JNICALL Java_com_android_gl3jni_GL3JNILib_setDxDy(JNIEnv * env, jobject obj, jfloat dx, jfloat dy){\n      aroverlayrenderer.setDxDy(dx, dy);\n    }\n    ```"]