["```cpp\n    class MachineCSE : public MachineFunctionPass {\n        const TargetInstrInfo *TII;\n        const TargetRegisterInfo *TRI;\n        AliasAnalysis *AA;\n        MachineDominatorTree *DT;\n        MachineRegisterInfo *MRI;\n    ```", "```cpp\n    public:\n        static char ID; // Pass identification\n        MachineCSE() : MachineFunctionPass(ID), LookAheadLimit(5), CurrVN(0) {\n          initializeMachineCSEPass(*PassRegistry::getPassRegistry());\n        }\n    ```", "```cpp\n        void getAnalysisUsage(AnalysisUsage &AU) const override {\n          AU.setPreservesCFG();\n          MachineFunctionPass::getAnalysisUsage(AU);\n          AU.addRequired<AliasAnalysis>();\n          AU.addPreservedID(MachineLoopInfoID);\n          AU.addRequired<MachineDominatorTree>();\n          AU.addPreserved<MachineDominatorTree>();\n        }\n    ```", "```cpp\n      private:\n    …..\n    …..\n\n    bool PerformTrivialCopyPropagation(MachineInstr *MI,\n                                       MachineBasicBlock *MBB);\n\n    bool isPhysDefTriviallyDead(unsigned Reg,\n             MachineBasicBlock::const_iterator I,\n             MachineBasicBlock::const_iterator E) const;\n\n    bool hasLivePhysRegDefUses(const MachineInstr *MI,\n                         const MachineBasicBlock *MBB,\n                       SmallSet<unsigned,8> &PhysRefs,\n                  SmallVectorImpl<unsigned> &PhysDefs,\n                              bool &PhysUseDef) const;\n\n    bool PhysRegDefsReach(MachineInstr *CSMI, MachineInstr *MI,\n                          SmallSet<unsigned,8> &PhysRefs, SmallVectorImpl<unsigned> &PhysDefs,\n                          bool &NonLocal) const;\n    ```", "```cpp\n        bool isCSECandidate(MachineInstr *MI);\n        bool isProfitableToCSE(unsigned CSReg, unsigned Reg,\n                         MachineInstr *CSMI, MachineInstr *MI);\n\n    Actual CSE performing function\n        bool PerformCSE(MachineDomTreeNode *Node);\n    ```", "```cpp\n    bool MachineCSE::runOnMachineFunction(MachineFunction &MF){\n      if (skipOptnoneFunction(*MF.getFunction()))\n        return false;\n\n      TII = MF.getSubtarget().getInstrInfo();\n      TRI = MF.getSubtarget().getRegisterInfo();\n      MRI = &MF.getRegInfo();\n      AA = &getAnalysis<AliasAnalysis>();\n      DT = &getAnalysis<MachineDominatorTree>();\n      return PerformCSE(DT->getRootNode());\n    }\n    ```", "```cpp\n    bool MachineCSE::PerformCSE(MachineDomTreeNode *Node) {\n      SmallVector<MachineDomTreeNode*, 32> Scopes;\n      SmallVector<MachineDomTreeNode*, 8> WorkList;\n      DenseMap<MachineDomTreeNode*, unsigned> OpenChildren;\n\n      CurrVN = 0;\n    // DFS to populate worklist\n      WorkList.push_back(Node);\n      do {\n        Node = WorkList.pop_back_val();\n        Scopes.push_back(Node);\n        const std::vector<MachineDomTreeNode*> &Children = Node->getChildren();\n        unsigned NumChildren = Children.size();\n        OpenChildren[Node] = NumChildren;\n        for (unsigned i = 0; i != NumChildren; ++i) {\n          MachineDomTreeNode *Child = Children[i];\n          WorkList.push_back(Child);\n        }\n      } while (!WorkList.empty());\n\n      // perform CSE.\n      bool Changed = false;\n      for (unsigned i = 0, e = Scopes.size(); i != e; ++i) {\n        MachineDomTreeNode *Node = Scopes[i];\n        MachineBasicBlock *MBB = Node->getBlock();\n        EnterScope(MBB);\n        Changed |= ProcessBlock(MBB);\n        ExitScopeIfDone(Node, OpenChildren);\n      }\n\n      return Changed;\n    }\n    ```", "```cpp\n    bool MachineCSE::ProcessBlock(MachineBasicBlock *MBB) {\n      bool Changed = false;\n\n      SmallVector<std::pair<unsigned, unsigned>, 8> CSEPairs;\n      SmallVector<unsigned, 2> ImplicitDefsToUpdate;\n\n    // Iterate over each Machine instructions in the MachineBasicBlock\n      for (MachineBasicBlock::iterator I = MBB->begin(), E = MBB->end(); I != E; ) {\n        MachineInstr *MI = &*I;\n        ++I;\n\n    // Check if this can be a CSE candidate.\n        if (!isCSECandidate(MI))\n          continue;\n\n        bool FoundCSE = VNT.count(MI);\n        if (!FoundCSE) {\n          // Using trivial copy propagation to find more CSE opportunities.\n          if (PerformTrivialCopyPropagation(MI, MBB)) {\n            Changed = true;\n\n            // After coalescing MI itself may become a copy.\n            if (MI->isCopyLike())\n              continue;\n\n            // Try again to see if CSE is possible.\n            FoundCSE = VNT.count(MI);\n          }\n        }\n\n        bool Commuted = false;\n        if (!FoundCSE && MI->isCommutable()) {\n          MachineInstr *NewMI = TII->commuteInstruction(MI);\n          if (NewMI) {\n            Commuted = true;\n            FoundCSE = VNT.count(NewMI);\n            if (NewMI != MI) {\n              // New instruction. It doesn't need to be kept.\n              NewMI->eraseFromParent();\n              Changed = true;\n            } else if (!FoundCSE)\n              // MI was changed but it didn't help, commute it back!\n              (void)TII->commuteInstruction(MI);\n          }\n        }\n\n        // If the instruction defines physical registers and the values *may* be\n        // used, then it's not safe to replace it with a common subexpression.\n        // It's also not safe if the instruction uses physical registers.\n        bool CrossMBBPhysDef = false;\n        SmallSet<unsigned, 8> PhysRefs;\n        SmallVector<unsigned, 2> PhysDefs;\n        bool PhysUseDef = false;\n\n    // Check if this instruction has been marked for CSE. Check if it is using physical register, if yes then mark as non-CSE candidate\n     if (FoundCSE && hasLivePhysRegDefUses(MI, MBB, PhysRefs,\n                                                    PhysDefs, PhysUseDef)) {\n          FoundCSE = false;\n    …\n    …\n        }\n\n        if (!FoundCSE) {\n          VNT.insert(MI, CurrVN++);\n          Exps.push_back(MI);\n          continue;\n        }\n\n        // Finished job of determining if there exists a common subexpression.\n      // Found a common subexpression, eliminate it.\n        unsigned CSVN = VNT.lookup(MI);\n        MachineInstr *CSMI = Exps[CSVN];\n        DEBUG(dbgs() << \"Examining: \" << *MI);\n        DEBUG(dbgs() << \"*** Found a common subexpression: \" << *CSMI);\n\n        // Check if it's profitable to perform this CSE.\n        bool DoCSE = true;\n        unsigned NumDefs = MI->getDesc().getNumDefs() +\n                           MI->getDesc().getNumImplicitDefs();\n\n        for (unsigned i = 0, e = MI->getNumOperands(); NumDefs && i != e; ++i) {\n          MachineOperand &MO = MI->getOperand(i);\n          if (!MO.isReg() || !MO.isDef())\n            continue;\n          unsigned OldReg = MO.getReg();\n          unsigned NewReg = CSMI->getOperand(i).getReg();\n\n          // Go through implicit defs of CSMI and MI, if a def is not dead at MI,\n          // we should make sure it is not dead at CSMI.\n          if (MO.isImplicit() && !MO.isDead() && CSMI->getOperand(i).isDead())\n            ImplicitDefsToUpdate.push_back(i);\n          if (OldReg == NewReg) {\n            --NumDefs;\n            continue;\n          }\n\n          assert(TargetRegisterInfo::isVirtualRegister(OldReg) &&\n                 TargetRegisterInfo::isVirtualRegister(NewReg) &&\n                 \"Do not CSE physical register defs!\");\n\n          if (!isProfitableToCSE(NewReg, OldReg, CSMI, MI)) {\n            DEBUG(dbgs() << \"*** Not profitable, avoid CSE!\\n\");\n            DoCSE = false;\n            break;\n          }\n\n          // Don't perform CSE if the result of the old instruction cannot exist\n          // within the register class of the new instruction.\n          const TargetRegisterClass *OldRC = MRI->getRegClass(OldReg);\n          if (!MRI->constrainRegClass(NewReg, OldRC)) {\n            DEBUG(dbgs() << \"*** Not the same register class, avoid CSE!\\n\");\n            DoCSE = false;\n            break;\n          }\n\n          CSEPairs.push_back(std::make_pair(OldReg, NewReg));\n          --NumDefs;\n        }\n\n        // Actually perform the elimination.\n        if (DoCSE) {\n          for (unsigned i = 0, e = CSEPairs.size(); i != e; ++i) {\n            MRI->replaceRegWith(CSEPairs[i].first, CSEPairs[i].second);\n            MRI->clearKillFlags(CSEPairs[i].second);\n          }\n\n          // Go through implicit defs of CSMI and MI, if a def is not dead at MI,\n          // we should make sure it is not dead at CSMI.\n          for (unsigned i = 0, e = ImplicitDefsToUpdate.size(); i != e; ++i)\n            CSMI->getOperand(ImplicitDefsToUpdate[i]).setIsDead(false);\n\n          if (CrossMBBPhysDef) {\n            // Add physical register defs now coming in from a predecessor to MBB\n            // livein list.\n            while (!PhysDefs.empty()) {\n              unsigned LiveIn = PhysDefs.pop_back_val();\n              if (!MBB->isLiveIn(LiveIn))\n                MBB->addLiveIn(LiveIn);\n            }\n            ++NumCrossBBCSEs;\n          }\n\n          MI->eraseFromParent();\n          ++NumCSEs;\n          if (!PhysRefs.empty())\n            ++NumPhysCSEs;\n          if (Commuted)\n            ++NumCommutes;\n          Changed = true;\n        } else {\n          VNT.insert(MI, CurrVN++);\n          Exps.push_back(MI);\n        }\n        CSEPairs.clear();\n        ImplicitDefsToUpdate.clear();\n      }\n\n      return Changed;\n    }\n    ```", "```cpp\n    bool MachineCSE::isCSECandidate(MachineInstr *MI) {\n    // If Machine Instruction is PHI, or inline ASM or implicit defs, it is not a candidate for CSE.\n\n      if (MI->isPosition() || MI->isPHI() || MI->isImplicitDef() || MI->isKill() ||\n          MI->isInlineAsm() || MI->isDebugValue())\n        return false;\n\n      // Ignore copies.\n      if (MI->isCopyLike())\n        return false;\n\n      // Ignore instructions that we obviously can't move.\n      if (MI->mayStore() || MI->isCall() || MI->isTerminator() || MI->hasUnmodeledSideEffects())\n        return false;\n\n      if (MI->mayLoad()) {\n        // Okay, this instruction does a load. As a refinement, we allow the target\n        // to decide whether the loaded value is actually a constant. If so, we can\n        // actually use it as a load.\n        if (!MI->isInvariantLoad(AA))\n          return false;\n      }\n      return true;\n    }\n    ```", "```cpp\n    bool MachineCSE::isProfitableToCSE(unsigned CSReg, unsigned Reg,\n      MachineInstr *CSMI, MachineInstr *MI) {\n\n      // If CSReg is used at all uses of Reg, CSE should not increase register\n      // pressure of CSReg.\n      bool MayIncreasePressure = true;\n      if (TargetRegisterInfo::isVirtualRegister(CSReg) &&\n          TargetRegisterInfo::isVirtualRegister(Reg)) {\n        MayIncreasePressure = false;\n        SmallPtrSet<MachineInstr*, 8> CSUses;\n        for (MachineInstr &MI : MRI->use_nodbg_instructions(CSReg)) {\n          CSUses.insert(&MI);\n        }\n        for (MachineInstr &MI : MRI->use_nodbg_instructions(Reg)) {\n          if (!CSUses.count(&MI)) {\n            MayIncreasePressure = true;\n            break;\n          }\n        }\n      }\n      if (!MayIncreasePressure) return true;\n\n      // Heuristics #1: Don't CSE \"cheap\" computation if the def is not local or in\n      // an immediate predecessor. We don't want to increase register pressure and\n      // end up causing other computation to be spilled.\n      if (TII->isAsCheapAsAMove(MI)) {\n        MachineBasicBlock *CSBB = CSMI->getParent();\n        MachineBasicBlock *BB = MI->getParent();\n        if (CSBB != BB && !CSBB->isSuccessor(BB))\n          return false;\n      }\n\n      // Heuristics #2: If the expression doesn't not use a vr and the only use\n      // of the redundant computation are copies, do not cse.\n      bool HasVRegUse = false;\n      for (unsigned i = 0, e = MI->getNumOperands(); i != e; ++i) {\n        const MachineOperand &MO = MI->getOperand(i);\n        if (MO.isReg() && MO.isUse() &&\n            TargetRegisterInfo::isVirtualRegister(MO.getReg())) {\n          HasVRegUse = true;\n          break;\n        }\n      }\n      if (!HasVRegUse) {\n        bool HasNonCopyUse = false;\n        for (MachineInstr &MI : MRI->use_nodbg_instructions(Reg)) {\n          // Ignore copies.\n          if (!MI.isCopyLike()) {\n            HasNonCopyUse = true;\n            break;\n          }\n        }\n        if (!HasNonCopyUse)\n          return false;\n      }\n\n      // Heuristics #3: If the common subexpression is used by PHIs, do not reuse\n      // it unless the defined value is already used in the BB of the new use.\n      bool HasPHI = false;\n      SmallPtrSet<MachineBasicBlock*, 4> CSBBs;\n      for (MachineInstr &MI : MRI->use_nodbg_instructions(CSReg)) {\n        HasPHI |= MI.isPHI();\n        CSBBs.insert(MI.getParent());\n      }\n\n      if (!HasPHI)\n        return true;\n      return CSBBs.count(MI->getParent());\n    }\n    ```", "```cpp\n    $ cat interval.c\n    void donothing(int a) {\n     return;\n    }\n\n    int func(int i) {\n     int a = 5;\n     donothing(a);\n     int m = a;\n     donothing(m);\n     a = 9;\n     if (i < 5) {\n     int b = 3;\n     donothing(b);\n     int z = b;\n     donothing(z);\n     }\n     else {\n     int k = a;\n     donothing(k);\n     }\n\n     return m;\n    }\n\n    ```", "```cpp\n    $ clang -cc1 -emit-llvm interval.c\n\n    $ cat interval.ll\n    ; ModuleID = 'interval.c'\n    target datalayout = \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\"\n    target triple = \"x86_64-unknown-linux-gnu\"\n\n    ; Function Attrs: nounwind\n    define void @donothing(i32 %a) #0 {\n     %1 = alloca i32, align 4\n     store i32 %a, i32* %1, align 4\n     ret void\n    }\n\n    ; Function Attrs: nounwind\n    define i32 @func(i32 %i) #0 {\n     %1 = alloca i32, align 4\n     %a = alloca i32, align 4\n     %m = alloca i32, align 4\n     %b = alloca i32, align 4\n     %z = alloca i32, align 4\n     %k = alloca i32, align 4\n     store i32 %i, i32* %1, align 4\n     store i32 5, i32* %a, align 4\n     %2 = load i32, i32* %a, align 4\n     call void @donothing(i32 %2)\n     %3 = load i32, i32* %a, align 4\n     store i32 %3, i32* %m, align 4\n     %4 = load i32, i32* %m, align 4\n     call void @donothing(i32 %4)\n     store i32 9, i32* %a, align 4\n     %5 = load i32, i32* %1, align 4\n     %6 = icmp slt i32 %5, 5\n     br i1 %6, label %7, label %11\n\n    ; <label>:7                               ; preds = %0\n     store i32 3, i32* %b, align 4\n     %8 = load i32, i32* %b, align 4\n     call void @donothing(i32 %8)\n     %9 = load i32, i32* %b, align 4\n     store i32 %9, i32* %z, align 4\n     %10 = load i32, i32* %z, align 4\n     call void @donothing(i32 %10)\n     br label %14\n\n    ; <label>:11                              ; preds = %0\n     %12 = load i32, i32* %a, align 4\n     store i32 %12, i32* %k, align 4\n     %13 = load i32, i32* %k, align 4\n     call void @donothing(i32 %13)\n     br label %14\n\n    ; <label>:14                              ; preds = %11, %7\n     %15 = load i32, i32* %m, align 4\n     ret i32 %15\n    }\n\n    attributes #0 = { nounwind \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"false\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-realign-stack\" \"stack-protector-buffer-size\"=\"8\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\n\n    !llvm.ident = !{!0}\n\n    !0 = !{!\"clang version 3.7.0 (trunk 234045)\"}\n\n    ```", "```cpp\n    void LiveIntervals::computeVirtRegInterval(LiveInterval &LI) {\n      assert(LRCalc && \"LRCalc not initialized.\");\n      assert(LI.empty() && \"Should only compute empty intervals.\");\n      LRCalc->reset(MF, getSlotIndexes(), DomTree, &getVNInfoAllocator());\n      LRCalc->calculate(LI, MRI->shouldTrackSubRegLiveness(LI.reg));\n      computeDeadValues(LI, nullptr);\n\n    /**** add the following code ****/\n    + llvm::outs() << \"********** INTERVALS **********\\n\";\n\n      // Dump the regunits.\n      + for (unsigned i = 0, e = RegUnitRanges.size(); i != e; ++i)\n        + if (LiveRange *LR = RegUnitRanges[i])\n          + llvm::outs() << PrintRegUnit(i, TRI) << ' ' << *LR << '\\n';\n\n      // Dump the virtregs.\n      + llvm::outs() << \"virtregs:\";\n      + for (unsigned i = 0, e = MRI->getNumVirtRegs(); i != e; ++i) {\n        + unsigned Reg = TargetRegisterInfo::index2VirtReg(i);\n        + if (hasInterval(Reg))\n          + llvm::outs() << getInterval(Reg) << '\\n';\n      + }\n    ```", "```cpp\n    $ llc interval.ll\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    %vreg2 [144r,192r:0)  0@144r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    %vreg2 [144r,192r:0)  0@144r\n    %vreg5 [544r,592r:0)  0@544r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    %vreg2 [144r,192r:0)  0@144r\n    %vreg5 [544r,592r:0)  0@544r\n    %vreg6 [352r,368r:0)  0@352r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    %vreg2 [144r,192r:0)  0@144r\n    %vreg5 [544r,592r:0)  0@544r\n    %vreg6 [352r,368r:0)  0@352r\n    %vreg7 [416r,464r:0)  0@416r\n    ********** INTERVALS **********\n    virtregs:%vreg0 [16r,32r:0)  0@16r\n    %vreg1 [80r,96r:0)  0@80r\n    %vreg2 [144r,192r:0)  0@144r\n    %vreg5 [544r,592r:0)  0@544r\n    %vreg6 [352r,368r:0)  0@352r\n    %vreg7 [416r,464r:0)  0@416r\n    %vreg8 [656r,672r:0)  0@656r\n\n    ```", "```cpp\n    namespace X86 {\n    enum {\n      NoRegister,\n      AH = 1,\n      AL = 2,\n      AX = 3,\n      BH = 4,\n      BL = 5,\n      BP = 6,\n      BPL = 7,\n      BX = 8,\n      CH = 9,\n    …\n    ```", "```cpp\n    def AL : X86Reg<\"al\", 0>;\n    def DL : X86Reg<\"dl\", 2>;\n    def CL : X86Reg<\"cl\", 1>;\n    def BL : X86Reg<\"bl\", 3>;\n\n    def AH : X86Reg<\"ah\", 4>;\n    def DH : X86Reg<\"dh\", 6>;\n    def CH : X86Reg<\"ch\", 5>;\n    def BH : X86Reg<\"bh\", 7>;\n\n    def AX : X86Reg<\"ax\", 0, [AL,AH]>;\n    def DX : X86Reg<\"dx\", 2, [DL,DH]>;\n    def CX : X86Reg<\"cx\", 1, [CL,CH]>;\n    def BX : X86Reg<\"bx\", 3, [BL,BH]>;\n\n    // 32-bit registers\n    let SubRegIndices = [sub_16bit] in {\n    def EAX : X86Reg<\"eax\", 0, [AX]>, DwarfRegNum<[-2, 0, 0]>;\n    def EDX : X86Reg<\"edx\", 2, [DX]>, DwarfRegNum<[-2, 2, 2]>;\n    def ECX : X86Reg<\"ecx\", 1, [CX]>, DwarfRegNum<[-2, 1, 1]>;\n    def EBX : X86Reg<\"ebx\", 3, [BX]>, DwarfRegNum<[-2, 3, 3]>;\n    def ESI : X86Reg<\"esi\", 6, [SI]>, DwarfRegNum<[-2, 6, 6]>;\n    def EDI : X86Reg<\"edi\", 7, [DI]>, DwarfRegNum<[-2, 7, 7]>;\n    def EBP : X86Reg<\"ebp\", 5, [BP]>, DwarfRegNum<[-2, 4, 5]>;\n    def ESP : X86Reg<\"esp\", 4, [SP]>, DwarfRegNum<[-2, 5, 4]>;\n    def EIP : X86Reg<\"eip\", 0, [IP]>, DwarfRegNum<[-2, 8, 8]>;\n    …\n    ```", "```cpp\n    def GR8 : RegisterClass<\"X86\", [i8],  8,\n                            (add AL, CL, DL, AH, CH, DH, BL, BH, SIL, DIL, BPL, SPL,\n                                 R8B, R9B, R10B, R11B, R14B, R15B, R12B, R13B)> {\n    ```", "```cpp\n    $ llc –regalloc=basic interval.ll –o intervalregbasic.s\n\n    ```", "```cpp\n    $ cat intervalregbasic.s\n     .text\n     .file  \"interval.ll\"\n     .globl  donothing\n     .align  16, 0x90\n     .type  donothing,@function\n    donothing:                              # @donothing\n    # BB#0:\n     movl  %edi, -4(%rsp)\n     retq\n    .Lfunc_end0:\n     .size  donothing, .Lfunc_end0-donothing\n\n     .globl  func\n     .align  16, 0x90\n     .type  func,@function\n    func:                                   # @func\n    # BB#0:\n     subq  $24, %rsp\n     movl  %edi, 20(%rsp)\n     movl  $5, 16(%rsp)\n     movl  $5, %edi\n     callq  donothing\n     movl  16(%rsp), %edi\n     movl  %edi, 12(%rsp)\n     callq  donothing\n     movl  $9, 16(%rsp)\n     cmpl  $4, 20(%rsp)\n     jg  .LBB1_2\n    # BB#1:\n     movl  $3, 8(%rsp)\n     movl  $3, %edi\n     callq  donothing\n     movl  8(%rsp), %edi\n     movl  %edi, 4(%rsp)\n     jmp  .LBB1_3\n    .LBB1_2:\n     movl  16(%rsp), %edi\n     movl  %edi, (%rsp)\n    .LBB1_3:\n     callq  donothing\n     movl  12(%rsp), %eax\n     addq  $24, %rsp\n     retq\n    .Lfunc_end1:\n     .size  func, .Lfunc_end1-func\n\n    ```", "```cpp\n    $ llc –regalloc=pbqp interval.ll –o intervalregpbqp.s\n\n    ```", "```cpp\n    $cat intervalregpbqp.s\n     .text\n     .file  \"interval.ll\"\n     .globl  donothing\n     .align  16, 0x90\n     .type  donothing,@function\n    donothing:                              # @donothing\n    # BB#0:\n     movl  %edi, %eax\n     movl  %eax, -4(%rsp)\n     retq\n    .Lfunc_end0:\n     .size  donothing, .Lfunc_end0-donothing\n\n     .globl  func\n     .align  16, 0x90\n     .type  func,@function\n    func:                                   # @func\n    # BB#0:\n     subq  $24, %rsp\n     movl  %edi, %eax\n     movl  %eax, 20(%rsp)\n     movl  $5, 16(%rsp)\n     movl  $5, %edi\n     callq  donothing\n     movl  16(%rsp), %eax\n     movl  %eax, 12(%rsp)\n     movl  %eax, %edi\n     callq  donothing\n     movl  $9, 16(%rsp)\n     cmpl  $4, 20(%rsp)\n     jg  .LBB1_2\n    # BB#1:\n     movl  $3, 8(%rsp)\n     movl  $3, %edi\n     callq  donothing\n     movl  8(%rsp), %eax\n     movl  %eax, 4(%rsp)\n     jmp  .LBB1_3\n    .LBB1_2:\n     movl  16(%rsp), %eax\n     movl  %eax, (%rsp)\n    .LBB1_3:\n     movl  %eax, %edi\n     callq  donothing\n     movl  12(%rsp), %eax\n     addq  $24, %rsp\n     retq\n    .Lfunc_end1:\n     .size  func, .Lfunc_end1-func\n\n    ```", "```cpp\n    class PEI : public MachineFunctionPass {\n      public:\n        static char ID;\n        PEI() : MachineFunctionPass(ID) {\n          initializePEIPass(*PassRegistry::getPassRegistry());\n        }\n    ```", "```cpp\n        void calculateSets(MachineFunction &Fn);\n        void calculateCallsInformation(MachineFunction &Fn);\n        void calculateCalleeSavedRegisters(MachineFunction &Fn);\n        void insertCSRSpillsAndRestores(MachineFunction &Fn);\n        void calculateFrameObjectOffsets(MachineFunction &Fn);\n        void replaceFrameIndices(MachineFunction &Fn);\n        void replaceFrameIndices(MachineBasicBlock *BB, MachineFunction &Fn,\n                                 int &SPAdj);\n        void scavengeFrameVirtualRegs(MachineFunction &Fn);\n    ```", "```cpp\n        void insertPrologEpilogCode(MachineFunction &Fn);\n    ```", "```cpp\n    bool PEI::runOnMachineFunction(MachineFunction &Fn) {\n      const Function* F = Fn.getFunction();\n      const TargetRegisterInfo *TRI = Fn.getSubtarget().getRegisterInfo();\n      const TargetFrameLowering *TFI = Fn.getSubtarget().getFrameLowering();\n\n      assert(!Fn.getRegInfo().getNumVirtRegs() && \"Regalloc must assign all vregs\");\n\n      RS = TRI->requiresRegisterScavenging(Fn) ? new RegScavenger() : nullptr;\n      FrameIndexVirtualScavenging = TRI->requiresFrameIndexScavenging(Fn);\n\n      // Calculate the MaxCallFrameSize and AdjustsStack variables for the\n      // function's frame information. Also eliminates call frame pseudo\n      // instructions.\n      calculateCallsInformation(Fn);\n\n      // Allow the target machine to make some adjustments to the function\n      // e.g. UsedPhysRegs before calculateCalleeSavedRegisters.\n      TFI->processFunctionBeforeCalleeSavedScan(Fn, RS);\n\n      // Scan the function for modified callee saved registers and insert spill code\n      // for any callee saved registers that are modified.\n      calculateCalleeSavedRegisters(Fn);\n\n      // Determine placement of CSR spill/restore code:\n      // place all spills in the entry block, all restores in return blocks.\n      calculateSets(Fn);\n\n      // Add the code to save and restore the callee saved registers\n      if (!F->hasFnAttribute(Attribute::Naked))\n        insertCSRSpillsAndRestores(Fn);\n\n      // Allow the target machine to make final modifications to the function\n      // before the frame layout is finalized.\n      TFI->processFunctionBeforeFrameFinalized(Fn, RS);\n\n      // Calculate actual frame offsets for all abstract stack objects...\n      calculateFrameObjectOffsets(Fn);\n\n      // Add prolog and epilog code to the function.  This function is required\n      // to align the stack frame as necessary for any stack variables or\n      // called functions.  Because of this, calculateCalleeSavedRegisters()\n      // must be called before this function in order to set the AdjustsStack\n      // and MaxCallFrameSize variables.\n      if (!F->hasFnAttribute(Attribute::Naked))\n        insertPrologEpilogCode(Fn);\n\n      // Replace all MO_FrameIndex operands with physical register references\n      // and actual offsets.\n      replaceFrameIndices(Fn);\n\n      // If register scavenging is needed, as we've enabled doing it as a\n      // post-pass, scavenge the virtual registers that frame index elimination\n      // inserted.\n      if (TRI->requiresRegisterScavenging(Fn) && FrameIndexVirtualScavenging)\n        scavengeFrameVirtualRegs(Fn);\n\n      // Clear any vregs created by virtual scavenging.\n      Fn.getRegInfo().clearVirtRegs();\n\n      // Warn on stack size when we exceeds the given limit.\n      MachineFrameInfo *MFI = Fn.getFrameInfo();\n      uint64_t StackSize = MFI->getStackSize();\n      if (WarnStackSize.getNumOccurrences() > 0 && WarnStackSize < StackSize) {\n        DiagnosticInfoStackSize DiagStackSize(*F, StackSize);\n        F->getContext().diagnose(DiagStackSize);\n      }\n      delete RS;\n      ReturnBlocks.clear();\n      return true;\n    }\n    ```", "```cpp\n    void PEI::insertPrologEpilogCode(MachineFunction &Fn) {\n      const TargetFrameLowering &TFI = *Fn.getSubtarget().getFrameLowering();\n\n      // Add prologue to the function.\n      TFI.emitPrologue(Fn);\n\n      // Add epilogue to restore the callee-save registers in each exiting block\n      for (MachineFunction::iterator I = Fn.begin(), E = Fn.end(); I != E; ++I) {\n        // If last instruction is a return instruction, add an epilogue\n        if (!I->empty() && I->back().isReturn())\n          TFI.emitEpilogue(Fn, *I);\n      }\n\n      // Emit additional code that is required to support segmented stacks, if\n      // we've been asked for it.  This, when linked with a runtime with support\n      // for segmented stacks (libgcc is one), will result in allocating stack\n      // space in small chunks instead of one large contiguous block.\n      if (Fn.shouldSplitStack())\n        TFI.adjustForSegmentedStacks(Fn);\n\n      // Emit additional code that is required to explicitly handle the stack in\n      // HiPE native code (if needed) when loaded in the Erlang/OTP runtime. The\n      // approach is rather similar to that of Segmented Stacks, but it uses a\n      // different conditional check and another BIF for allocating more stack\n      // space.\n      if (Fn.getFunction()->getCallingConv() == CallingConv::HiPE)\n        TFI.adjustForHiPEPrologue(Fn);\n    }\n    ```", "```cpp\n    void AsmPrinter::EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const ;\n    ```", "```cpp\n    void AsmPrinter::EmitGlobalVariable(const GlobalVariable *GV);\n    ```", "```cpp\n    void AsmPrinter::EmitFunctionHeader();\n    ```", "```cpp\n    void AsmPrinter::EmitFunctionBody();\n    ```", "```cpp\n    void AsmPrinter::EmitJumpTableInfo();\n    ```", "```cpp\n    void AsmPrinter::EmitJumpTableEntry(const MachineJumpTableInfo *MJTI, const MachineBasicBlock *MBB,\n    unsigned UID) const;\n    ```", "```cpp\n    void AsmPrinter::EmitInt8(int Value) const {\n      OutStreamer.EmitIntValue(Value, 1);\n    }\n\n    void AsmPrinter::EmitInt16(int Value) const {\n      OutStreamer.EmitIntValue(Value, 2);\n    }\n\n    void AsmPrinter::EmitInt32(int Value) const {\n    OutStreamer.EmitIntValue(Value, 4);\n    }\n    ```", "```cpp\n    $ cat tailcall.ll\n    declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4)\n\n    define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {\n     %l1 = add i32 %in1, %in2\n     %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1)\n     ret i32 %tmp\n    }\n\n    ```", "```cpp\n    $ llc -tailcallopt tailcall.ll\n\n    ```", "```cpp\n    $ cat tailcall.s\n     .text\n     .file  \"tailcall.ll\"\n     .globl  tailcaller\n     .align  16, 0x90\n     .type  tailcaller,@function\n    tailcaller:                             # @tailcaller\n     .cfi_startproc\n    # BB#0:\n     pushq  %rax\n    .Ltmp0:\n     .cfi_def_cfa_offset 16\n     # kill: ESI<def> ESI<kill> RSI<def>\n     # kill: EDI<def> EDI<kill> RDI<def>\n     leal  (%rdi,%rsi), %ecx\n     # kill: ESI<def> ESI<kill> RSI<kill>\n     movl  %edi, %edx\n     popq  %rax\n     jmp  tailcallee              # TAILCALL\n    .Lfunc_end0:\n     .size  tailcaller, .Lfunc_end0-tailcaller\n     .cfi_endproc\n\n     .section  \".note.GNU-stack\",\"\",@progbits\n\n    ```", "```cpp\n    $ llc tailcall.ll -o tailcall1.s\n\n    ```", "```cpp\n    $ cat tailcall1.s\n     .text\n     .file  \"tailcall.ll\"\n     .globl  tailcaller\n     .align  16, 0x90\n     .type  tailcaller,@function\n    tailcaller:                             # @tailcaller\n     .cfi_startproc\n    # BB#0:\n     # kill: ESI<def> ESI<kill> RSI<def>\n     # kill: EDI<def> EDI<kill> RDI<def>\n     leal  (%rdi,%rsi), %ecx\n     # kill: ESI<def> ESI<kill> RSI<kill>\n     movl  %edi, %edx\n     jmp  tailcallee              # TAILCALL\n    .Lfunc_end0:\n     .size  tailcaller, .Lfunc_end0-tailcaller\n     .cfi_endproc\n     .section  \".note.GNU-stack\",\"\",@progbits\n\n    ```", "```cpp\nThe code in function SDValue X86TargetLowering::LowerCall (…….)\nbool IsMustTail = CLI.CS && CLI.CS->isMustTailCall();\n  if (IsMustTail) {\n    // Force this to be a tail call.  The verifier rules are enough to ensure\n    // that we can lower this successfully without moving the return address\n    // around.\n    isTailCall = true;\n  } else if (isTailCall) {\n    // Check if it's really possible to do a tail call.\n    isTailCall = IsEligibleForTailCallOptimization(Callee, CallConv,\n                    isVarArg, SR != NotStructReturn,\n                    MF.getFunction()->hasStructRetAttr(), CLI.RetTy,\n                    Outs, OutVals, Ins, DAG);\n```", "```cpp\n$ cat sibcall.ll\ndeclare i32 @bar(i32, i32)\n\ndefine i32 @foo(i32 %a, i32 %b, i32 %c) {\n entry:\n %0 = tail call i32 @bar(i32 %a, i32 %b)\n ret i32 %0\n}\n\n```", "```cpp\n    $ llc sibcall.ll\n\n    ```", "```cpp\n    $ cat sibcall.s\n     .text\n     .file    \"sibcall.ll\"\n     .globl    foo\n     .align    16, 0x90\n     .type    foo,@function\n    foo:                                    # @foo\n     .cfi_startproc\n    # BB#0:                                 # %entry\n     jmp    bar                     # TAILCALL\n    .Lfunc_end0:\n     .size    foo, .Lfunc_end0-foo\n     .cfi_endproc\n\n     .section    \".note.GNU-stack\",\"\",@progbits\n\n    ```"]