- en: Chapter 3. Implementing Client Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a synchronous TCP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a synchronous UDP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an asynchronous TCP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **client** is a part of a distributed application that communicates with another
    part of this application called a **server**, in order to consume services it
    provides. The server, on the other hand, is a part of distributed application
    that passively waits for requests arriving from clients. When a request arrives,
    the server performs the requested operation and sends a response—the result of
    the operation—back to the client.
  prefs: []
  type: TYPE_NORMAL
- en: The key characteristic of a client is that it needs a service provided by the
    server and it initiates the communication session with that server in order to
    consume the service. The key characteristic of the server is that it serves the
    requests coming from the clients by providing a requested service.
  prefs: []
  type: TYPE_NORMAL
- en: We'll consider servers in the next chapter. In this chapter, we are going to
    focus on client applications and will consider several types of them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The classification of client applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Client applications can be classified by the transport layer protocol they use
    for communication with the server. If the client uses a UDP protocol, it is called
    a **UDP client**. If it uses a TCP protocol, it is called a **TCP client** correspondingly.
    Of course, there are many other transport layer protocols that client applications
    may use for communication. Moreover, there are multiprotocol clients that can
    communicate over several protocols. However, they are beyond the scope of this
    book. In this chapter, we are going to focus on pure UDP and TCP clients as such,
    which are the most popular and are the most often used in general purpose software
    today.
  prefs: []
  type: TYPE_NORMAL
- en: The decision as to which transport layer protocol to choose for communication
    between the parts of a distributed application should be made at the early stages
    of the application design based on the application specification. Because TCP
    and UDP protocols are conceptually different, it may be quite difficult to switch
    from one of them to another at the later stages of the application development
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to classify client applications is according to whether the client
    is synchronous or asynchronous. A **synchronous client application** uses synchronous
    socket API calls that block the thread of execution until the requested operation
    is completed, or an error occurs. Thus, a typical synchronous TCP client would
    use the `asio::ip::tcp::socket::write_some()` method or the `asio::write()` free
    function to send a request to the sever and then use the `asio::ip::tcp::socket::read_some()`
    method or the `asio::read()` free function to receive a response. These methods
    and functions are blocking, which makes the client synchronous.
  prefs: []
  type: TYPE_NORMAL
- en: An **asynchronous client application** as opposed to a synchronous one uses
    asynchronous socket API calls. For example, an asynchronous TCP client may use
    the `asio::ip::tcp::socket::async_write_some()` method or the `asio::async_write()`
    free function to send a request to the server and then use the `asio::ip::tcp::socket::async_read_some()`
    method or the `asio::async_read()` free function to asynchronously receive a response.
  prefs: []
  type: TYPE_NORMAL
- en: Because the structure of a synchronous client significantly differs from that
    of an asynchronous one, the decision as to which approach to apply should be made
    early at the application design stage, and this decision should be based on the
    careful analysis of the application requirements. Besides, possible application
    evolution paths and new requirements that may appear in the future should be considered
    and taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous versus asynchronous
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As usually, each approach has its advantages and disadvantages. When a synchronous
    approach gives better results in one situation, it may be absolutely unacceptable
    in another. In the latter case, an asynchronous approach should be used. Let's
    compare two approaches to better understand when it is more beneficial to use
    each of them.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of a synchronous approach is its *simplicity*. A synchronous
    client is significantly easier to develop, debug, and support than a functionally
    equal asynchronous one. Asynchronous clients are more complex due to the fact
    that asynchronous operations that are used by them complete in other places in
    code (mainly in callbacks) than they are initiated. Usually, this requires allocating
    additional data structures in the free memory to keep the context of the request
    and callback functions, and also involves thread synchronization and other extras
    that may make the application structure quite complex and error-prone. Most of
    these extras are not required in synchronous clients. Besides, the asynchronous
    approach brings in additional computational and memory overhead, which makes it
    less efficient than a synchronous one in some conditions.
  prefs: []
  type: TYPE_NORMAL
- en: However, the synchronous approach has some functional limitations, which often
    make this approach unacceptable. These limitations consist of the inability to
    cancel a synchronous operation after it has started, or to assign it a timeout
    so that it gets interrupted if it is running longer than a certain amount of time.
    As opposed to synchronous operations, asynchronous ones can be canceled at any
    moment after operation initiation and before the moment it completes.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a typical modern web browser. A request cancellation is a very important
    feature of a client application of this kind. After issuing a command to load
    a particular website, the user may change his or her mind and decide to cancel
    the command before the page gets loaded. From the user's perspective, it would
    be quite strange not to be able to cancel the command until the page gets fully
    loaded. Therefore, this is when a synchronous approach is not a good option.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the difference in the complexity and functionality described above,
    the two approaches differ in efficiency when it comes to running several requests
    in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we are developing a web crawler, an application that traverses
    the pages of websites and processes them in order to extract some interesting
    information. Given a file with a long list of websites (say several millions),
    the application should traverse all the pages of each of the sites listed in the
    file and then process each page. Naturally, one of the key requirements of the
    application is to perform the task as fast as possible. Provided with these requirements,
    which approach should we choose, synchronous or asynchronous?
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we answer this question, let''s consider the stages of a request life
    cycle and their timings from the client application''s perspective. Conceptually,
    the request life cycle consists of five stages as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparing the request**: This stage involves any operations required to prepare
    a request message. The duration of this step depends on the particular problem
    the application solves. In our example, this could be reading the next website
    address from the input file and constructing a string representing a request in
    accordance with an HTTP protocol.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transmitting a request from the client to the server**: This stage assumes
    the transmission of the request data from the client to the server over the network.
    The duration of this step does not depend on a client application. It depends
    on the properties and the current state of the network.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Processing the request by the server**: The duration of this step depends
    on the server''s properties and its current load. In our example, the server application
    is a web server and the request processing lies in constructing a requested web
    page, which may involve I/O operations such as reading files and loading data
    from a database.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transmitting a response from the server to the client**: Like stage 2, this
    stage also assumes the transmission of the data over the network; however, this
    time it is in the opposite direction—from the server to the client. The duration
    of this stage does not depend on the client or the server. It only depends on
    the properties and the state of the network.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Processing the response by the client**: The duration of this stage depends
    on a particular task that the client application is intended to perform. In our
    example, this could be scanning the web page, extracting interesting information
    and storing it into a database.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that, for the sake of simplicity, we omitted low-level substages such as
    connection establishment and connection shutdown, which are important when using
    TCP protocol but don't add a substantial value in our conceptual model of a request
    life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, only in stages 1 and 5 does the client perform some effective
    job related to the request. Having initiated the transmission of the request data
    at the end of stage 1, the client has to wait during the next three stages (2,
    3, and 4) of the request life cycle before it can receive the response and process
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Now, with the stages of the request life cycle in mind, let's see what happens
    when we apply synchronous and asynchronous approaches to implement our sample
    web crawler.
  prefs: []
  type: TYPE_NORMAL
- en: If we apply a synchronous approach, the thread of execution processing a single
    request synchronously will be sleeping during stages 2-4 of the request life cycle,
    and only during stages 1 and 5, will it perform an effective job (for simplicity,
    we assume that stages 1 and 5 don't include instructions that block the thread).
    This means that the resource of an operating system, namely a thread, is used
    inefficiently, because there are number of times when it is simply doing nothing
    while there is still a lot of work available—millions of other pages to request
    and process. In this situation, an asynchronous approach seems to be more efficient.
    With an asynchronous approach, instead of a thread being blocked during stages
    2-4 of a request life cycle, it can be effectively used to perform stages 1 or
    5 of another request.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we direct a single thread to process the different stages of different
    requests (this is called **overlapping**), which results in the more efficient
    usage of a thread and consequently increases the overall performance of the application.
  prefs: []
  type: TYPE_NORMAL
- en: However, an asynchronous approach is not always more efficient than a synchronous
    one. As it has been mentioned, asynchronous operations imply additional computational
    overheads, which means that the overall duration of an asynchronous operation
    (from initiation till completion) is somewhat bigger than the equivalent synchronous
    one. This means that, if the average total duration of stages 2-4 is less than
    the overhead of the timing asynchronous approach per single request, then a synchronous
    approach turns out to be more efficient, and therefore may be considered to be
    the right way to go.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing the total duration of stages 2-4 of the request life cycle and the
    overhead of the asynchronous approach is usually done experimentally. The duration
    may significantly vary, and it depends on the properties and the state of the
    network through which the requests and responses are transmitted and also on the
    properties and the load level of the server application that serves the request.
  prefs: []
  type: TYPE_NORMAL
- en: The sample protocol
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to consider three recipes, each of which demonstrates
    how to implement a particular type of a client application: the synchronous UDP
    client, synchronous TCP client, and asynchronous TCP client. In all the recipes,
    it is assumed that the client application communicates with the server application
    using the following simple application-level protocol.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The server application accepts a request represented as an ASCII string. The
    string has the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Where `[s]` is a positive integer value and `<LF>` is ASCII a new-line symbol.
  prefs: []
  type: TYPE_NORMAL
- en: 'The server interprets this string as a request to perform a dummy operation
    that lasts for `[s]` seconds. For example, a request string may look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This means that the client sending this request wants the server to perform
    the dummy operation for `10` seconds and then send a response to it.
  prefs: []
  type: TYPE_NORMAL
- en: Like the request, the response returned by the server is represented by an ASCII
    string. It may either be `OK<LF>` if the operation completes successfully or `ERROR<LF>`
    if the operation fails.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a synchronous TCP client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A synchronous TCP client is a part of a distributed application that complies
    with the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: Acts as a client in the client-server communication model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicates with the server application using a TCP protocol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses I/O and control operations (at least those I/O operations that are related
    to communication with a server) that block the thread of execution until the corresponding
    operation completes, or an error occurs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A typical synchronous TCP client works according to the following algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain the IP-address and the protocol port number of the server application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Allocate an active socket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Establish a connection with the server application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exchange messages with the server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Shut down the connection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deallocate the socket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This recipe demonstrates how to implement a synchronous TCP client application
    with Boost.Asio.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code sample demonstrates a possible implementation of a synchronous
    TCP client application with Boost.Asio. The client uses the application layer
    protocol described in the introduction section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The sample client application consists of two main components—the `SyncTCPClient`
    class and the application entry point function `main()` in which the `SyncTCPClient`
    class is used to communicate with the server application. Let's consider each
    component separately.
  prefs: []
  type: TYPE_NORMAL
- en: The SyncTCPClient class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `SyncTCPClient` class is the key component in the sample. It implements
    and provides access to the communication functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'The class has three private members as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`asio::io_service m_ios`: This is the object providing access to the operating
    system''s communication services, which are used by the socket object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asio::ip::tcp::endpoint m_ep`: This is an endpoint designating the server
    application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asio::ip::tcp::socket m_sock`: This is the socket used for communication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each object of the class is intended to communicate with a single server application;
    therefore, the class's constructor accepts the server IP-address and the protocol
    port number as its arguments. These values are used to instantiate the `m_ep`
    object in the constructor's initialization list. The socket object `m_sock` is
    instantiated and opened in the constructor too.
  prefs: []
  type: TYPE_NORMAL
- en: The three public methods comprise the interface of the `SyncTCPClient` class.
    The first method named `connect()` is quite simple; it performs the connection
    of the socket to the server. The `close()` method shuts the connection down and
    closes the socket, which leads to the operating system's socket and other resources
    associated with it to be deallocated.
  prefs: []
  type: TYPE_NORMAL
- en: The third interface method is `emulateLongComputationOp(unsigned int duration_sec)`.
    This method is where the I/O operations are performed. It begins with preparing
    the request string according to the protocol. Then, the request is passed to the
    class's private method `sendRequest(const std::string& request)`, which sends
    it to the server. When the request is sent and the `sendRequest()` method returns,
    the `receiveResponse()` method is called to receive the response from the server.
    When the response is received, the `receiveResponse()` method returns the string
    containing the response. After this, the `emulateLongComputationOp()` method returns
    the response to its caller.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the `sendRequest()` and `receiveResponse()` methods in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sendRequest()` method has the following prototype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Its purpose is to send a string, passed to it as an argument, to the server.
    In order to send the data to the server, the `asio::write()` free synchronous
    function is used. The function returns when the request is sent. That's it about
    the `sendRequest()` method. Basically, all it does is, it fully delegates its
    job to the `asio::write()` free function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having sent the request, now we want to receive the response from the server.
    This is the purpose of the `receiveResponse()` method of the `SyncTCPClient` class.
    To perform its job, method uses the `asio::read_until()` free function. According
    to the application layer protocol, the response message sent by the server may
    vary in length, but must end with the `\n` symbol; therefore, we specify this
    symbol as a delimiter when calling the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The function blocks the thread of execution until it encounters the `\n` symbol
    as a part of the message that arrived from the server. When the function returns,
    the stream buffer `buf` contains the response. The data is then copied from the
    `buf` buffer to the `response` string and the latter is returned to the caller.
    The `emulateLongComputationOp()` method in turn returns the response to its caller—the
    `main()` function.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note with regard to the `SyncTCPClient` class is that it contains
    no error handling-related code. That's because the class uses only those overloads
    of Boost.Asio functions and objects' methods that throw exceptions in case of
    failure. It is assumed that the user of the class is responsible for catching
    and handling the exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: The main() entry point function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This function acts as a user of the `SyncTCPClient` class. Having obtained the
    server IP-address and the protocol port number (this part is omitted from the
    sample), it instantiates and uses an object of the `SyncTCPClient` class to communicate
    with the server in order to consume its service, mainly to emulate an operation
    on the server that performs dummy calculations for 10 seconds. The code of this
    function is simple and self-explanatory and thus requires no additional comments.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html "Chapter 2. I/O Operations"), *I/O Operations*, includes
    recipes providing detailed discussions on how to perform synchronous I/O'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a synchronous UDP client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A synchronous UDP client is a part of a distributed application that complies
    with the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: Acts as a client in the client-server communication model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicates with the server application using UDP protocol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses I/O and control operations (at least those I/O operations that are related
    to communication with the server) that block the thread of execution until the
    corresponding operation completes, or an error occurs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A typical synchronous UDP client works according to the following algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain an IP-address and a protocol port number of each server the client application
    is intended to communicate with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Allocate a UDP socket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exchange messages with the servers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deallocate the socket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This recipe demonstrates how to implement a synchronous UDP client application
    with Boost.Asio.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code sample demonstrates a possible implementation of a synchronous
    UDP client application with Boost.Asio. It is assumed that the client uses UDP
    protocol with the underlying IPv4 protocol for communication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The sample consists of two main components—the `SyncUDPClient` class and the
    application entry point function `main()` that uses the `SyncUDPClient` class
    to communicate with two server applications. Let's consider each component separately.
  prefs: []
  type: TYPE_NORMAL
- en: The SyncUDPClient class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `SyncUDPClient` class is the key component in the sample. It implements
    the server communication functionality and provides access to it for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'The class has two private members as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`asio::io_service m_ios`: This is the object providing access to the operating
    system''s communication services, which are used by the socket object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asio::ip::udp::socket m_sock`: This is the UDP socket used for communication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The socket object `m_sock` is instantiated and opened in the class's constructor.
    Because the client is intended to use IPv4 protocol, we pass the object returned
    by the `asio::ip::udp::v4()` static method to the socket's `open()` method to
    designate the socket to use IPv4 protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the `SyncUDPClient` class implements communication over UDP protocol,
    which is a connectionless protocol, a single object of this class can be used
    to communicate with multiple servers. The interface of the class consists of a
    single method—`emulateLongComputationOp()`. This method can be used to communicate
    with the server just after the object of the `SyncUDPClient` class is instantiated.
    The following is the prototype of the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Besides the `duration_sec` argument that represents a request parameter, the
    method accepts the server IP-address and the protocol port number. This method
    may be called multiple times to communicate with different servers.
  prefs: []
  type: TYPE_NORMAL
- en: The method begins with preparing a request string according to the application
    layer protocol and creating an endpoint object designating the target server application.
    Then, the request string and the endpoint object are passed to the class's private
    method `sendRequest()`, which sends the request message to the specified server.
    When the request is sent and the `sendRequest()` method returns, the `receiveResponse()`
    method is called to receive a response from the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the response is received, the `receiveResponse()` method returns the string
    containing the response. In turn, the `emulateLongComputationOp()` method returns
    the response to its caller. The `sendRequest()` method uses the socket object''s
    `send_to()` method to send the request message to a particular server. Let''s
    have a look at the declaration of this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The method accepts a buffer containing the request and an endpoint designating
    the server to which the content of the buffer should be sent as arguments and
    blocks until the whole buffer is sent, or an error occurs. Note that, if the method
    returns without an error, it only means that the request has been sent and *does
    not* mean that the request has been received by the server. UDP protocol doesn't
    guarantee message delivery and it provides no means to check whether the datagram
    has been successfully received on the server-side or got lost somewhere on its
    way to the server.
  prefs: []
  type: TYPE_NORMAL
- en: Having sent the request, now we want to receive the response from the server.
    This is the purpose of the `receiveResponse()` method of the `SyncUDPClient` class.
    This method begins with allocating a buffer that will hold the response message.
    We choose the size of the buffer such that it can fit the largest message that
    the server may send according to the application layer protocol. This message
    is an `ERROR\n` string that consists of six ASCII symbols, which is therefore
    6 bytes long; hence is the size of our buffer - 6 bytes. Because the buffer is
    small enough, we allocate it on the stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'To read the response data arriving from the server, we use the socket object''s
    `receive_from()` method. Here is the prototype of the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This method copies a datagram that came from the server designated by the `sender_endpoint`
    object to the buffer specified by the `buffers` argument.
  prefs: []
  type: TYPE_NORMAL
- en: There are two things to note about socket object's `receive_from()` method.
    The first thing is that this method is synchronous and it blocks the thread of
    execution until the datagram arrives from the specified server. If the datagram
    never arrives (for example, gets lost somewhere on its way to the client), the
    method will never unblock and the whole application will hang. The second thing
    is that if the size of the datagram that arrives from the server is larger than
    the size of the supplied buffer, the method will fail.
  prefs: []
  type: TYPE_NORMAL
- en: After the response is received, the `std::string` object is created, initialized
    with a response string, and returned to the caller—the `emulateLongComputationOp()`
    method. This in turn returns the response to its caller—the `main()` function.
  prefs: []
  type: TYPE_NORMAL
- en: The `SyncUDPClient` class does not contain error handling-related code. That's
    is because it uses only those overloads of Boost.Asio functions and objects' methods
    that throw exceptions in case of failure. It is assumed that the user of the class
    is responsible for catching and handling the exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: The main() entry point function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this function, we use the `SyncUDPClient` class in order to communicate with
    two server applications. Firstly, we obtain the IP-addresses and the port numbers
    of the target server applications. Then, we instantiate the object of the `SyncUDPClient`
    class and call the object's `emulateLongComputationOp()` method twice to synchronously
    consume the same service from two different servers.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html "Chapter 2. I/O Operations"), *I/O Operations*, includes
    recipes that provide detailed discussions on how to perform synchronous I/O'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an asynchronous TCP client
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As it has already been mentioned in the introduction section of this chapter,
    the simplest asynchronous client is structurally more complex than equivalent
    synchronous one. When we add a feature such as request canceling to the asynchronous
    client, it becomes even more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll consider an asynchronous TCP client application supporting
    the asynchronous execution of the requests and request canceling functionality.
    Here is the list of requirements the application will fulfill:'
  prefs: []
  type: TYPE_NORMAL
- en: Input from the user should be processed in a separate thread—the user interface
    thread. This thread should never be blocked for a noticeable amount of time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user should be able to issue multiple requests to different servers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user should be able to issue a new request before the previously issued
    requests complete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user should be able to cancel the previously issued requests before they
    complete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As our application needs to support request canceling, we begin with specifying
    settings that enable request canceling on Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we include the necessary headers and specify the `using` directive for
    our convenience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We continue with defining a data type representing a pointer to a callback
    function. Because our client application is going to be asynchronous, we need
    a notion of callback as a request completion notification mechanism. Later, it
    will become clear as to why we need it and how it is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define a data structure whose purpose is to keep the data related
    to a particular request while it is being executed. Let''s name it `Session`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The purpose of all the fields that the `Session` data structure contains will
    become clear later as we go.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define a class that provides the asynchronous communication functionality.
    Let''s name it `AsyncTCPClient`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This class is the key component in our sample, providing most of the functionality
    of the application. This functionality is accessible to the user of the class
    through its public interface that contains three public methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`void emulateLongComputationOp(unsigned int duration_sec, const std::string&
    raw_ip_address, unsigned short port_num, Callback callback, unsigned int request_id)`:
    This method initiates a request to the server'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void cancelRequest(unsigned int request_id)`: This method cancels the previously
    initiated request designated by the `request_id` argument'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void close()`: This method blocks the calling thread until all the currently
    running requests complete and deinitializes the client. When this method returns,
    the corresponding instance of the `AsyncTCPClient` class can''t be used anymore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we define a function that will serve as a callback, which we''ll pass
    to the `AsyncTCPClient::emulateLongComputationOp()` method. In our case, this
    function is quite simple. It outputs the result of the request execution and the
    response message to the standard output stream if the request is completed successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `handler()` function's signature corresponds to the function pointer type
    `Callback` defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have all the ingredients, we define an entry point of the application—the
    `main()` function—which demonstrates how to use the components defined above in
    order to communicate with the server. In our sample function, `main()` emulates
    the behavior of a human user by initiating three requests and canceling one of
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our sample client application uses two threads of execution. The first one—UI
    thread—is responsible for processing a user input and initiating requests. The
    responsibility of the second thread—I/O thread—is to run the event loop and call
    the asynchronous operation's callback routines. Such configuration allows us to
    make our application's user interface responsive.
  prefs: []
  type: TYPE_NORMAL
- en: Starting the application – the main() entry point function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `main()` function is invoked in the context of the UI thread. This function
    emulates the behavior of the user who initiates and cancels requests. Firstly,
    it creates an instance of the `AsyncTCPClient` class and then calls its `emulateLongComputationOp()`
    method three times to initiate three asynchronous requests, each time specifying
    a different target server. The first request (the one assigned ID 1) is canceled
    by calling the `cancelRequest()`method several seconds after the request has been
    initiated.
  prefs: []
  type: TYPE_NORMAL
- en: Request completion – the handler() callback function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For all three requests initiated in the `main()` function `handler()` is specified
    as a callback. This function is called when the request is finished regardless
    of the reason as to why it finished—be it a successful completion or an error.
    Also, this function is called when the request is canceled by the user. The function
    accepts three arguments as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`unsigned int request_id`: This contains the unique identifier of the request.
    This is the same identifier that was assigned to the request when it was initiated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::string& response`: This contains the response data. This value is considered
    valid only if the request is completed successfully and is not canceled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`system::error_code& ec`: If an error occurs during a request life cycle, this
    object contains the error information. If the request was canceled, it contains
    the `asio::error::operation_aborted` value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `handler()` function is quite simple in our sample. Based on the values
    of the parameters passed to it, it outputs information about the finished request.
  prefs: []
  type: TYPE_NORMAL
- en: The AsyncTCPClient class – initializing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As it has already been mentioned, all the functionality related to communication
    with the server application is hidden in the `AsyncTCPClient` class. This class
    has a nonempty constructor that accepts no arguments and does two things. Firstly,
    it instantiates an object of the `asio::io_service::work` class passing an instance
    of the `asio::io_service` class named `m_ios` to its constructor. Then, it spawns
    a thread that calls the `run()` method of the `m_ios` object. The object of the
    `asio::io_service::work` class keeps threads running event loop from exiting this
    loop when there are no pending asynchronous operations. The spawned thread plays
    the role of I/O thread in our application; in the context of this thread, the
    callbacks assigned asynchronous operations will be invoked.
  prefs: []
  type: TYPE_NORMAL
- en: The AsyncTCPClient class – initiating a request
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `emulateLongComputationOp()` method is intended to initiate an asynchronous
    request. It accepts five arguments. The first one named `duration_sec` represents
    the request parameter according to the application layer protocol. The `raw_ip_address`
    and `port_num` specify the server to which the request should be sent. The next
    argument is a pointer to a callback function, which will be called when the request
    is complete. We'll turn back to the discussion of the callback later in this section.
    The last argument `request_id` is the unique identifier of the request. This identifier
    is associated with the request and is used to refer to it later, for example,
    when there is a need to cancel it.
  prefs: []
  type: TYPE_NORMAL
- en: The `emulateLongComputationOp()` method begins with preparing a request string
    and allocating an instance of the `Session` structure that keeps the data associated
    with the request including a socket object that is used to communicate with the
    server.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the socket is opened and the pointer to the `Session` object is added
    to the `m_active_sessions` map. This map contains pointers to the `Session` objects
    associated with all active requests, that is, those requests that have been initiated
    but have not finished yet. When the request completes, before the corresponding
    callback is called, the pointer to the `Session` object associated with this request
    is removed from the map.
  prefs: []
  type: TYPE_NORMAL
- en: The `request_id` argument is used as a key of the corresponding `Session` object
    added to the map. We need to cache the `Session` objects in order to have access
    to them in case the user decides to cancel the previously initiated request. If
    we would not need to support canceling of a request, we could avoid using the
    `m_active_sessions` map.
  prefs: []
  type: TYPE_NORMAL
- en: We synchronize the access to the `m_active_sessions` map with a `m_active_session_guard`
    mutex. Synchronization is necessary because the map can be accessed from multiple
    threads. Items are added to it in UI thread, and removed in an I/O thread that
    calls a callback when the corresponding request is finished.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, when the pointer to the corresponding `Session` object is cached, we need
    to connect the socket to the server, which we do by calling the socket''s `async_connect()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: An endpoint object designating the server to which we want to connect and a
    callback function to be called when the connection is complete or an error occurs,
    are passed as arguments to this method. In our sample we use lambda function as
    a callback function. The call to the socket's `async_connect()` method is the
    last statement in the `emulateLongComputationOp()` method. When `async_connect()`
    returns, `emulateLongComputationOp()` returns too, which means that the request
    has been initiated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a closer look at the lambda function that we pass to `async_connect()`
    as a callback. Here is its code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The callback begins with checking the error code passed to it as the `ec` argument,
    the value of which when different from zero means that the corresponding asynchronous
    operation has failed. In case of failure, we store the `ec` value in the corresponding
    `Session` object, call the class's `onRequestComplete()` private method passing
    the `Session` object to it as an argument, and then return.
  prefs: []
  type: TYPE_NORMAL
- en: If the `ec` object designates success, we lock the `m_cancel_guard` mutex (the
    member of the request descriptor object) and check whether the request has not
    been canceled yet. More details about the canceling request are provided later
    in this section, where the `cancelRequest()` method is considered.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we see that the request has not been canceled, we initiate the next asynchronous
    operation calling the Boost.Asio free function `async_write()` to send the request
    data to the server. Again, we pass to it a lambda function as a callback. This
    callback is very similar to the one passed to the `anync_connect()` method when
    the asynchronous connection operation was initiated. We first check the error
    code and then if it indicates success, we check whether or not the request has
    been canceled. Also, if it has not, we initiate the next asynchronous operation—`async_read_until()`—in
    order to receive a response from the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we pass a lambda function as a callback argument to the `async_read_until()`
    free function. This callback function is quite simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It checks the error code and in the case of success, it stores the received
    response data in the corresponding `Session` object. Then, the `AsyncTCPClient`
    class's private method `onRequestComplete()` is called and the `Session` object
    is passed to it as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: The `onRequestComplete()` method is called whenever the request completes with
    any result. It is called when the request completes successfully, when the request
    fails at any stage of its life cycle, or when it is canceled by the user. The
    purpose of this method is to perform a cleanup and then to call a callback provided
    by the caller of the `emulateLongComputationOp()` method, when initiating this
    request.
  prefs: []
  type: TYPE_NORMAL
- en: The `onRequestComplete()` method begins with shutting down the socket. Note
    that here we use the overload of the socket's `shutdown()` method, which doesn't
    throw exceptions. We don't care if the shutting down of the connection fails as
    this is not a critical operation in our case. Then, we remove the corresponding
    entry from the `m_active_sessions` map as the request is finished and hence it
    is not active anymore. Also, as the last step, the user supplied callback is called.
    After the callback function returns, the request life cycle is finished.
  prefs: []
  type: TYPE_NORMAL
- en: The AsyncTCPClient class – canceling the request
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, let's take a look at the `cancelRequst()` method of the `AsyncTCPClient`
    class. This method accepts an identifier of the request to be canceled as an argument.
    It begins with looking for the `Session` object corresponding to the specified
    request in the `m_active_sessions` map. If one is found, it calls the `cancel()`
    method on the socket object stored in this `Session` object. This leads to the
    interruption of the currently running asynchronous operation associated with this
    socket object.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a chance that the `cancelRequest()` method will be called
    at the moment when one asynchronous operation has already been completed and the
    next one has not been initiated yet. For example, imagine that the I/O thread
    is now running the callback of the `async_connect()` operation associated with
    a particular socket. At this moment, no asynchronous operation associated with
    this socket is in progress (because the next asynchronous operation `async_write()`
    has not been initiated yet); therefore, calling `cancel()` on this socket will
    have no effect. That's why we use an additional flag `Session::m_was_cancelled`
    designating, as its name suggests, whether the request has been canceled (or to
    be more precise, whether the `cancelRequest()` method has been called by the user).
    In the callback of the asynchronous operation, we look at the value of this flag
    before initiating the next asynchronous operation. If we see that the flag is
    set (which means that the request was canceled), we don't initiate the next asynchronous
    operation, but instead we interrupt the request execution and call the `onRequestComplete()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `Session::m_cancel_guard` mutex in the `cancelRequest()` method
    and in the callbacks of the asynchronous operations such as `async_connect()`
    and `async_write()` to enforce the following order of operations: request can
    be canceled either before the value of the `Session::m_was_cancelled` flag is
    tested in the callback, or after the next asynchronous operation is initiated.
    This order guarantees the proper canceling of a request whenever a user calls
    the `cancelRequest()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: The AsyncTCPClient class – closing the client
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the client has been used and is not needed anymore, it should be properly
    closed. The `close()` method of the `AsyncTCPClient` class allows us to do that.
    Firstly, this method destroys the `m_work` object that allows the I/O thread to
    exit the event message loop when all the asynchronous operations are completed.
    Then, it joins the I/O thread to wait until it exits.
  prefs: []
  type: TYPE_NORMAL
- en: After the `close()` method returns, the corresponding object of the `AsyncTCPClient`
    class cannot be used anymore.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `AsyncTCPClient` class in the presented sample implements an asynchronous
    **single-threaded** TCP client. It uses a single thread that runs the event loop
    and processes the requests. Usually, when the request rate is low, the size of
    the response is not large and the request handler does not perform the complex
    and time-consuming processing of the response (stage 5 of the request life cycle);
    one thread is enough.
  prefs: []
  type: TYPE_NORMAL
- en: However, when we want the client to make millions of requests and process them
    as fast as possible, we may want to turn our client into a **multithreaded** one,
    where multiple threads may run several requests truly simultaneously. Of course,
    it assumes that the computer running the client is a multicore or a multiprocessor
    computer. The application running more threads than the number of cores or processors
    installed in the computer may slow down the application due to the effect of the
    thread switching overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a multithreaded TCP client application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to turn our single-treaded client application into a multithreaded
    one, we need to make several changes in it. Firstly, we need to replace the `m_thread`
    member of the `AnyncTCPClient` class that represents a single I/O thread, with
    a list of pointers to the `std::thread` objects, which will represent a collection
    of I/O threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to change the class''s constructor so that it accepts an argument
    representing the number of I/O threads to be created. Besides, the constructor
    should spawn the specified number of I/O threads and add them all to the pool
    of threads running the event loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Like in a single-threaded version of the client, each thread calls the `run()`
    method of the `m_ios` object. As a result, all threads are added to the thread
    pool, controlled by the `m_ios` object. All threads from the pool will be used
    to call the corresponding asynchronous operation completion callbacks. This means
    that on a multicore or multiprocessor computer, several callbacks may be running
    truly simultaneously in different threads, each on a separate processor; whereas,
    in a single-threaded version of the client, they would be executed serially.
  prefs: []
  type: TYPE_NORMAL
- en: After each thread is created, the pointer to it is put to the `m_threads` list
    so that we have the access to the thread objects later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, the last change is in the `close()` method. Here, we need to join each
    thread in the list. This is how the method looks after the change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Having destroyed the `work` object, we iterate through the list of I/O threads
    and join each of them to make sure they all have exited.
  prefs: []
  type: TYPE_NORMAL
- en: The multithreaded TCP client application is ready. Now, when we create an object
    of multithreaded `AsyncTCPClient` class, the number specifying how many threads
    should be used to process the requests should be passed to the constructor of
    the class. All other aspects of usage of the class are identical to those of a
    single-threaded one.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html "Chapter 2. I/O Operations"), *I/O Operations*, includes
    recipes that provide detailed discussions on how to perform asynchronous I/O with
    TCP socket and how to cancel asynchronous operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Using timers* recipe from [Chapter 6](ch06.html "Chapter 6. Other Topics"),
    *Other Topics*, demonstrates how to use timers provided by Boost.Asio. Timers
    can be used to implement an asynchronous operation timeout mechanism.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
