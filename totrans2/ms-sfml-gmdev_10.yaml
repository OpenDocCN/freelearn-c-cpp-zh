- en: Chapter 10. A Chapter You Shouldnt Skip - Final Optimizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What's the most important aspect of any game? According to a very famous e-celebrity,
    it's being able to play it. Fancy graphics and advanced techniques definitely
    add a necessary touch of polish to a medium as visual and interactive as video
    games, but if that gets in the way of enjoying the most fundamental experience
    of smooth gameplay, the whole thing might as well just be a fancy screensaver.
    Optimizing code, even when the application runs fine on higher-end machines, is
    extremely important, since every iteration excludes potential machines that are
    older but could still be used to expand the fan base of a game.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The basics of profiling and reading code metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing and repairing inefficiencies in our code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basics of light culling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's not waste any more clock cycles and get to cleaning up some of those inefficiencies!
  prefs: []
  type: TYPE_NORMAL
- en: Use of third-party software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As expected, we can't do all of this work with no additional tools. Profiling
    applications is a subject that requires a backend of established software, used
    to neatly organize and present us with the data of performance subtleties. *CodeXL*
    is an application we have already covered in [Chapter 9](ch09.html "Chapter 9. 
    The Speed of Dark - Lighting and Shadows") , *The Speed of Dark - Lighting and
    Shadows* and although we used it to view runtime OpenGL states, it also has quite
    a suite of options used to profile both CPU and GPU code. It can be found and
    downloaded here: [http://gpuopen.com/compute-product/codexl/](http://gpuopen.com/compute-product/codexl/).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if we don't have AMD hardware, only a very limited set of tools for
    profiling are available. Although we can get by with the limited CPU profiling
    options, GPU profiling on an Nvidia card, for example, would require a different
    tool. There are some choices out there, but one notable option is *Nvidia Nsight*: [http://www.nvidia.com/object/nsight.html](http://www.nvidia.com/object/nsight.html).
  prefs: []
  type: TYPE_NORMAL
- en: It's worth mentioning, however, that the newest versions of Nsight don't support
    some of the legacy functions SFML invokes, so the functionalities are, once again,
    rather limited.
  prefs: []
  type: TYPE_NORMAL
- en: The devil's in the details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'They say that a master craftsman knows not only how, but also when to use their
    tools. Many programmers often enough arrive at the false conclusion that they
    must constantly write beautiful, efficient, and overall perfect code that will
    never fail. In practice, this couldn''t be farther from the truth. Many find this
    out the hard way. As *Donald Knuth* said:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Programmers waste enormous amounts of time thinking about, or worrying about,
    the speed of noncritical parts of their programs, and these attempts at efficiency
    actually have a strong negative impact when debugging and maintenance are considered.
    We should forget about small efficiencies, say about 97% of the time: premature
    optimization is the root of all evil."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This doesn't mean that one shouldn't take performance into consideration. Things
    such as designing a class with later features in mind, or even picking the right
    algorithm for the job both fall under that remaining 3%. Rather, it simply means
    that, unless the application is noticeably slow, tackling performance issues in
    code should be one of the final tasks at all times.
  prefs: []
  type: TYPE_NORMAL
- en: Another common mistake programmers often make is relying on intuition when it
    comes to evaluating performance. It's easy to forget that a program has tons of
    underlying complexity and moving parts, which is why it's incredibly hard to always
    know exactly how a specific chunk of code is going to behave unless properly tested.
    That's the key here always profile! Is the game running slow? Break out the profiler
    and take it for a spin. Feeling like enemy path-finding code is really weighing
    down on performance? Don't feel, just profile! The same thing can be said about
    the state of your code after optimizations have been made. Don't just replace
    a ton of code and assume it runs faster. Take a base measurement, make the appropriate
    changes, and profile the final result to make sure the new code runs faster. Starting
    to see the picture? Good. With that out of the way, let's jump straight into the
    basics of profiling!
  prefs: []
  type: TYPE_NORMAL
- en: Profiling basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a variety of different ways an application can be profiled. Anything
    from branching and individual instructions, to usage of caches and patterns of
    data access can be tracked in a project. Since our game isn't exactly overflowing
    with complexity, however, we really only need to worry about time-based profiling.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three basic ways a profiler can gather information about an application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling**: This is a periodic application stack capture that yields relatively
    inaccurate results, yet has very little overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event collection**: This involves tapping into the compilation process and
    configuring it in such a way that allows certain information to be sent to the
    profiling DLLs. A higher amount of overhead with a higher precision.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instrumentation**: This involves direct code injection into the application
    during run time that allows for the most precise results and has the highest level
    of overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any of these techniques can be utilized, depending on what software is being
    used and the data it needs to collect. Because we don't really need incredibly
    precise results to locate the hotspots of our code, it's best to go with a sampling
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have already established, profiling is not a free task. In some instances,
    it can slow down an application to a crawl, which, depending on the task, can
    be absolutely normal.
  prefs: []
  type: TYPE_NORMAL
- en: Time-based sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the time-based sampling technique will create a rough estimate of all
    of the application's function/method calls, initializations/destructions, virtually
    anything that can be created or invoked, and assign a sample value to them. This
    even includes underlying libraries, such as STL, SFML, OpenGL, and so on. If your
    code uses it, it will be on the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sample value represents how much time is spent executing a certain line
    of code. There are two types of time samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inclusive**: This involves all of the time spent inside a specific line/chunk
    of code, including all of the time it took to execute other functions that may
    have been called.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exclusive**: This involves only the amount of time that a specific line/chunk
    of code took to execute on its own.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are not necessarily going to be dealing with exclusive sample counts, but
    it's important to understand these terms nonetheless.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, it's important to understand that samples are relative. If a program
    is running slowly, fewer samples will be captured across the board. This particular
    benchmark shouldn't be interpreted based on quantity, but rather in comparison
    to the rest of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sampling should always be done with all of the relevant project's optimizations
    enabled, because it strips away unnecessary code that's used for debugging, which
    would interfere with the results. In the case of Visual Studio, the release mode
    should be used when sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling our application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have the fundamentals covered, let's actually fire up a profile
    and get started! The first important aspect of this process is actually spending
    enough time sampling the state of the desired application. In our case, sampling
    should be done in the `Game` state, and for at least 20 seconds, to capture enough
    information. It isn't going to help us understand the time complexities of the
    entity component system, for example, if the majority of the application sampling
    time is spent inside the menu state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, we should probably test our application in a stressful state, just
    to make sure it holds up well under nonideal conditions. For our purposes, we
    will simply add a bunch more entities, particle emitters, and lights to the scene
    until a **stress test** that looks like the following is constructed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Sampling our application](img/image_10_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It isn't pretty, but then again, neither are performance issues.
  prefs: []
  type: TYPE_NORMAL
- en: Once the application has been sampled enough and is terminated, most profilers
    will show a *profile overview* of all the processes that have been running during
    the sampling process. It's important to select only our game by clicking on it,
    because that's what we're interested in.
  prefs: []
  type: TYPE_NORMAL
- en: 'After navigating to the **Function** tab, we should be left with something
    similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Sampling our application](img/image_10_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: By clicking on the **Timer** tab and sorting entries in a descending order,
    we can view the functions that have the highest amount of samples, thus taking
    the most time to run. This is where you will find the trade-off between using
    a general purpose library such as *SFML* and sacrificing some performance. While
    it's true that writing case-specific code would probably be more optimal in terms
    of performance, it's still a worthy price to pay when considering how versatile
    SFML is for small to medium-sized projects.
  prefs: []
  type: TYPE_NORMAL
- en: While it's obvious our own SFML rendering code could probably use some work
    and utilize vertex arrays when rendering sprites and tiles to reduce this bottleneck,
    we're not going to concern ourselves with SFML-specific optimizations this time.
    Instead, let's analyze the highlighted entries on the list first. As the `glm::`
    namespace seems to suggest, the OpenGL math library we're using for various calculations
    is the culprit. Upon closer inspection, it seems that all three of these hotspots
    have to do with matrix operations; the most expensive of which is the `glm::operator*`.
    By right-clicking on the entry, we can view it in a call graph.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A **call graph** is a tool that helps locate all points in our code that use
    a specific function.
  prefs: []
  type: TYPE_NORMAL
- en: 'By simply analyzing the information onscreen, we''re now able to see what code
    uses the GLM matrices in such a way that causes performance problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Sampling our application](img/image_10_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As the **Parents** section indicates, the majority of time samples regarding
    this particular bottleneck are located inside the `GL_Transform::GetModelMatrix()`
    method. Double-clicking on the function allows us to also view the code and specific
    hotspots of each individual line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Sampling our application](img/image_10_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This should all start to add up by now. The two most sampled lines in relation
    to matrices were `glm::tmat4x4<float,0>::tmat4x4<float,0>(float const&)`, which
    is the matrix constructor, and `glm::rotate`, which we're calling three times.
    Every time we want to obtain a model matrix from this class (which is once for
    each shadow caster every frame), a bunch of new matrices are constructed and filled
    out using quite expensive GLM function calls, not to mention being multiplied
    later as well.
  prefs: []
  type: TYPE_NORMAL
- en: Finding GPU bottlenecks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finding GPU bottlenecks is fairly similar to what we did with the CPU. It also
    utilizes time sampling and will generate similar looking reports that list OpenGL
    code based on how long it took to execute, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Finding GPU bottlenecks](img/image_10_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We''re not going to be covering GPU optimizations heavily here, but the idea
    is exactly the same: finding bottlenecks, re-implementing code in a more efficient
    manner, and testing again.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some GPU profiling tools, such as Nvidia Nsight, don't support legacy OpenGL
    API calls made by SFML.
  prefs: []
  type: TYPE_NORMAL
- en: Improving CPU code performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After establishing a baseline reading, we can begin making changes to our code.
    Some of these changes involve simply understanding the libraries we're using and
    being more cautious about the way they're deployed, while others revolve around
    making better design choices, applying faster and more appropriate algorithms,
    designing data structures better, and using the newest features of the C++ standard.
    Let's begin by taking a look at some easy changes that can be made to our code.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the three most obvious bottlenecks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Judging by the profiler's results, there is quite a bit of room for improvement
    of the code we've written so far. In this section, we're going to be addressing
    three of the most inefficient implementations and how they can be fixed.
  prefs: []
  type: TYPE_NORMAL
- en: GL_Transform optimizations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The very first example we used to illustrate how time sampling works is a perfect
    candidate for improvement. There really is nothing subtle about it. First, the
    recalculation of all matrices involved in obtaining a model matrix every time
    one is requested is incredibly inefficient. To add insult to injury, all *7* of
    those matrices has to be created all over again. That''s a lot of clock cycles
    wasted for no reason. Let''s see how that can be quickly improved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Firstly, notice the change of the return parameter of `GetModelMatrix` to a
    *const* *reference*. This ensures that we're not returning a newly constructed
    matrix each time. Additionally, we have added a Boolean flag that will help us
    keep track of whether the position, scale, or rotation of the object has changed
    and whether the model matrix needs to be updated to reflect that. Lastly, we're
    storing all 7 matrices inside the transform object now, so that they are created
    only once. This is important, because we don't want to recalculate three rotational
    matrices along with its combined matrix, for example, just because the position
    of the object was changed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s actually implement these changes, starting with the setters of
    this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The general idea here is to first check whether the argument provided to the
    setter method isn't already the current value of whatever parameter it's supposed
    to override. If it isn't, the position is changed and the position matrix is updated,
    along with the `m_needsUpdate` flag being set to `true`. This will ensure that
    the model matrix is updated later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rotation follows the exact same principle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Before the assignment is committed to, however, we must check each individual
    member of the vector class, because each one of them has their own matrix. The
    point, as it's becoming clearer and clearer now, is to only calculate what we
    absolutely have to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scale, once again, follows this idea exactly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `GetModelMatrix` method should now be implemented this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: First, the update flag is checked to determine whether the matrix needs to be
    updated. If it does, all three relevant matrices are multiplied and the flag is
    reset back to `false`. We then return the const reference to the `m_modelMatrix`
    data member, ensuring one isn't created just to be thrown away later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s follow our own advice and profile the application again to make sure
    our changes worked:'
  prefs: []
  type: TYPE_NORMAL
- en: '![GL_Transform optimizations](img/image_10_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: All three of the previously highlighted lines to do with `glm::` have now completely
    disappeared from the top of the list! The highlighted exception in this illustration
    was taken during the sampling of `GL_Transform::GetModelMatrix()` that **did not**
    return by const reference, just to show that our approach does indeed work. When
    the method does return a const reference, even the highlighted function completely
    vanishes. This perfectly illustrates how avoiding useless copies of data can vastly
    improve overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: Particle system optimizations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another massive bottleneck that''s right at the top of the sample list is the
    `ParticleSystem::Draw` method. In fact, it''s the highest sampled piece of code
    that we have actually written. It''s understandable that rendering so many particles
    would be taxing, but in this case, the unoptimized version of this method knocks
    the frame rate of our game down to 10 FPS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Particle system optimizations](img/image_10_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Fraps** is a free piece of screen capture software that can record video,
    take screenshots, and most importantly for our purposes, show the frame rate!
    Although it''s Windows specific, there are other tools like it for Linux and OSX.
    The frame rate counter can also be easily implemented by simply counting the frames
    in our code and displaying the result using SFML.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That is absolutely unforgivable, so let''s break out the profiler and dissect
    the `Draw` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Particle system optimizations](img/image_10_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Judging by the sample count, the main inefficiency lies somewhere inside the
    material value shader pass, where each particle is rendered for the normal and
    specular passes. There is something slightly weird going on, though, and that''s
    the fact that the normal pass samples seem to be really low, but when the time
    comes to render for the specular pass, they suddenly jump much higher. This may
    look especially weird considering all we''re doing is setting a `vec3` uniform
    and drawing to a render texture. This is where further digging through the function
    stack and understanding of how SFML needs to handle things behind the scenes comes
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Particle system optimizations](img/image_10_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Because of context switching and the way render textures work behind the scenes,
    it's extremely inefficient to render two different types of material maps as we
    did. Switching textures too many times during runtime can cause serious performance
    bottlenecks, which is why sprite and tile sheets are used by games, rather than
    individual images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try and split up these two different types into two separate loops,
    making sure only one texture is being rendered two at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the material uniform is also moved outside of the loop to prevent
    unnecessary copies from being constructed and sent to the shader every time. By
    just running the application now, a very obvious jump in performance will quickly
    become apparent. Let''s see how much faster it got by simply splitting up the
    little bit of code we had into two pieces:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Particle system optimizations](img/image_10_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We just jumped from 10 FPS to 65 FPS by simply separating the normal and specular
    material passes! That''s more like it! You will notice that this sudden jump in
    performance will increase the sample count drastically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Particle system optimizations](img/image_10_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is because the game is running much faster now and doesn't indicate that
    the function is taking more time to execute. Remember, the samples are relative.
    Upon looking through the list, the two previously highlighted bits of code are
    found much lower now, with sample counts in the 20s. That's only slightly lower
    than before, but because the samples are relative and they all jumped up to about
    6 times higher, it indicates a huge performance gain.
  prefs: []
  type: TYPE_NORMAL
- en: Light culling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last main inefficiency we have to fix has to do with the lighting system
    implemented in [Chapter 8](ch08.html "Chapter 8.  Let There Be Light - An Introduction
    to Advanced Lighting") , *Let There Be Light! - An Introduction to Advanced Lighting*,
    and [Chapter 9](ch09.html "Chapter 9.  The Speed of Dark - Lighting and Shadows")
    , *The Speed of Dark - Lighting and Shadows*.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with multiple lights in a scene by using multipass shading/rendering
    is a great technique, but it can quickly become inefficient when those passes
    start to add up. The first obvious step to fixing that issue is not rendering
    lights that will not affect anything in the final image. The technique of reducing
    the number of objects being rendered by eliminating those that cannot be directly
    observed by the scene's view frustum, also known as **culling**, is going to help
    out with that.
  prefs: []
  type: TYPE_NORMAL
- en: Since we're only dealing with omni-directional point lights at this moment,
    culling lights can be achieved by simply checking for circle on rectangle collisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set up some helper functions to help us do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The function works by first creating an outer radius around the view's rectangle,
    so that we can default to a circle-on-circle collision checking for the majority
    of cases where the light is nowhere near the view frustum. The distance between
    the view's centre and circle's centre is obtained and checked for exceeding the
    sum of the view's outer bounding circle's radius summed with the circle's radius.
    This is the easiest way to check whether the light circle is anywhere close to
    the view's rectangle.
  prefs: []
  type: TYPE_NORMAL
- en: If the light is closer to the view, another circle radius for the view's rectangle
    is constructed. This time, the circle is inside the view and only has the radius
    of the smaller dimension of the rectangle's size. If the distance between the
    light and the view's center is lower than the sum of the inner radius and the
    circle's radius, we know for sure that we have a collision. That's another common
    case that we can scratch off the list, before defaulting to a more complicated
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if we know the light may be intersecting with one of the corners, its
    direction towards the view is normalized and used to obtain the closest point
    that is then checked for intersecting a constructed `sf::FloatRect` that represents
    our view.
  prefs: []
  type: TYPE_NORMAL
- en: 'Actual changes to the `RenderScene()` method of the light manager class simply
    involve storing a new list of lights that are definitely affecting something on
    screen, so that they can be passed to the shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note that we're not taking into account the light's falloff or how it's attenuated
    in the shader to determine whether it should be culled or not.
  prefs: []
  type: TYPE_NORMAL
- en: After all the unnecessary lights have been culled, only the very busy areas
    will experience some performance loss. At this point, it's the area of level design
    that should show concern and improve the architecture of the map.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations on making it all the way to the end! It has been quite a journey,
    and we can certainly say that a lot of things have been covered here that should
    inspire confidence in advanced game development in anyone. Even so, as always,
    there's still a ton of features, optimizations, techniques, and topics that we
    either just briefly touched upon, or haven't even acknowledged yet. Use that as
    inspiration to seek greatness, because, as we have already established, master
    craftsmen know not only how, but when to use their tools. While we have covered
    the basics, there are still many more tools to add to your tool belt. Use them,
    abuse them, break them and replace them. Do whatever it takes, but always remember
    to take something out of it and make it better next time.
  prefs: []
  type: TYPE_NORMAL
- en: With that, may your next project exhibit that extra level of polish, and run
    just a little bit faster! Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
