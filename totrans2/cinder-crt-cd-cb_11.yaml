- en: Chapter 11. Sensing and Tracking Input from the Camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to receive and process data from input devices
    such as a camera or a Microsoft Kinect sensor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following recipes will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Capturing from the camera
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking an object based on color
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking motion using optical flow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object tracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading QR code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building UI navigation and gesture recognition with Kinect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an augmented reality with Kinect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capturing from the camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will learn how to capture and display frames from a camera.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Include the necessary files to capture images from a camera and draw them to
    OpenGL textures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Also add the following `using` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now capture and draw frames from the camera.
  prefs: []
  type: TYPE_NORMAL
- en: 'Declare the following members in your application class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method we will initialize `mCamera`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `update` method, we will check if `mCamera` was successfully initialized.
    Also if there is any new frame available, copy the camera''s image into `mTexture`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `draw` method, we will simply clear the background, check if `mTexture`
    has been initialized, and draw it''s image on the screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `ci::Capture` is a class that wraps around Quicktime on Apple computers,
    AVFoundation on iOS platforms, and Directshow on Windows. Under the hood it uses
    these lower level frameworks to access and capture frames from a webcam.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever a new frame is found, it's pixels are copied into the `ci::Surface
    method`. In the previous code we check on every `update` method if there is a
    new frame by calling the `ci::Capture::checkNewFrame` method, and update our texture
    with its surface.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is also possible to get a list of available capture devices and choose which
    one you wish to start with.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ask for a list of devices and print their information, we could write the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To initialize `mCapture` using a specific device, you simply pass `ci::Capture::DeviceRef`
    as a third parameter in the constructor.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you wanted to initialize `mCapture` with the first device,
    you should write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Tracking an object based on color
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will show how to track objects with a specified color using
    the OpenCV library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe we will use OpenCV, so please refer to the *Integrating with
    OpenCV* recipe from [Chapter 3](ch03.html "Chapter 3. Using Image Processing Techniques"),
    *Using Image Processing Techniques*. We will also need InterfaceGl which is covered
    in the *Setting up a GUI for parameter tweaking* recipe from [Chapter 2](ch02.html
    "Chapter 2. Preparing for Development"), *Preparing for Development*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will create an application that tracks an object with a selected color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Include the necessary header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store the original and processed frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store the tracked object''s coordinates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store the parameters that will be passed to the tracking algorithms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to handle the capturing device and frame texture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method we will set the window dimensions and initialize capturing
    device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method we have to initialize variables and setup the GUI for
    a preview of the tracked color value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `update` method, check if there is any new frame to process and convert
    it to `cv::Mat`, which is necessary for further OpenCV operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Process the captured frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Close the `if` statement's body.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the method `setTrackingHSV`, which sets color''s values for tracking:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `mouseDown` event handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `draw` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By preparing the captured frame for processing we are converting it into a **hue,
    saturation, and value** (**HSV**) color space description method, which will be
    very useful in this case. Those are the properties describing the color in the
    HSV color space in a more intuitive way for color tracking. We can set a fixed
    hue value for detection, while saturation and value can vary with in a specified
    range. This can eliminate a noise caused by constantly changing light in the camera
    view. Take a look at the first step of the frame image processing; we are using
    the `cv::inRange` function to get a mask of pixels that fits our tracking color
    range. The range of the tracking colors is calculated from the color value picked
    by clicking inside the window, which is implemented inside the `mouseDown` handler
    and the `setTrackingHSV` method.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see inside `setTrackingHSV`, we are calculating `mColorMin` and `mColorMax`
    by simply widening the range. You may have to adjust these calculations depending
    on your camera noise and lighting conditions.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'HSV on Wikipedia: [http://en.wikipedia.org/wiki/HSL_and_HSV](http://en.wikipedia.org/wiki/HSL_and_HSV)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The OpenCV documentation: [http://opencv.willowgarage.com/documentation/cpp/](http://opencv.willowgarage.com/documentation/cpp/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking motion using optical flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will learn how to track motion in the images produced from
    a webcam using OpenCV using the popular Lucas Kanade optical flow algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will need to use OpenCV in this recipe, so please refer to the *Integrating
    with OpenCV* recipe from [Chapter 3](ch03.html "Chapter 3. Using Image Processing
    Techniques"), *Using Image Processing Techniques* and add OpenCV and it''s CinderBlock
    to your project. Include the following files to your source file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following `using` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will read frames from the camera and track motion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Declare the `ci::gl::Texture` and `ci::Capture` objects to display and capture
    from a camera. Also, declare a `cv::Mat` object as the previous frame, two `std::vector<cv::Point2f>`
    objects to store the current and previous features, and a `std::vector<uint8_t>`
    object to store the status of each feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method we will initialize `mCamera`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `update` method we need to check if `mCamera` has been correctly initialized
    and whether it has a new frame available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After those `if` statements we will get a reference to `ci::Surface` of `mCamera`
    and then copy it to our `mTexture` for drawing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s create a `cv::Mat` with the current camera frame. We will also check
    if `mPreviousFrame` contains any initialized data, calculate the good features
    to track, and calculate their motion from the previous camera frame to the current
    frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we just need to copy the frame to `mPreviousFrame` and close the initial
    `if` statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `draw` method we will begin by clearing the background with black and
    drawing `mTexture`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will draw red lines on the features we have tracked, using `mFeatureStatus`
    to draw the features that have been matched:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will draw a line between the previous features and the current
    ones, also using `mFeatureStatus` to draw one of the features that has been matched:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following image, the red dots represent good features to track:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![How to do it…](img/8703OS_11_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The optical flow algorithm will make an estimation of how much the tracked point
    has moved from one frame to the other.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe we are using the `cv::goodFeaturesToTrack` object to calculate
    which features are optimal for tracking, but it is also possible to manually choose
    which points we wish to track. All we have to do is populate `mFeatures` manually
    with whatever points we wish to track and pass it to the `cv::calcOpticalFlowPyrLK`.
    object
  prefs: []
  type: TYPE_NORMAL
- en: Object tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to track specific planar objects in our webcam
    using OpenCV and it's corresponding CinderBlock.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will need an image depiction of the physical object you wish to track in
    the camera. For this recipe place that image in the `assets` folder and name it
    `object.jpg`.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the OpenCV CinderBlock in this recipe, so please refer to the *Integrating
    with OpenCV* recipe from [Chapter 3](ch03.html "Chapter 3. Using Image Processing
    Techniques"), *Using Image Processing Techniques* and add OpenCV and it's CinderBlock
    to your project.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using a Mac, you will need to compile the OpenCV static libraries
    yourself, because the OpenCV CinderBlock is missing some needed libraries on OSX
    (it will work fine on Windows). You can download the correct version from the
    following link: [http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.3/](http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.3/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to compile the static libraries yourself using the provided `CMake`
    files. Once your libraries are correctly added to your project, include the following
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following `using` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will track an object in the camera frames based on an image depicting the
    object
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by creating a `struct` method to store the necessary objects for
    feature tracking and matching. Add the following code before your application
    class declaration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In your class declaration add the following member objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method let''s start by initializing the camera:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lets resize `mCorners`, load our object image, and calculate its `image`, `keyPoints`,
    `texture`, and `descriptor`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `update` method, we will check if `mCamera` has been initialized and
    whether we have a new frame to process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s get the surface of `mCamera` and initialize `texture` and `image`
    objects of `mCameraInfo`. We will create a `ci::Channel` object from `cameraSurface`
    that converts color surfaces to gray channel surfaces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s calculate `features` and `descriptor` values of `mCameraInfo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s use `mMatcher` to calculate the matches between `mObjectInfo` and
    `mCameraInfo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To perform a test to check for false matches, we will calculate the minimum
    distance between matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we will add all the points whose distance is less than `minDist*3.0` to
    `mObjectInfo.goodPoints.clear();`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`}` With all our points calculated and matched, we need to calculate the homography
    between the points of `mObjectInfo` and `mCameraInfo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create `vector<cv::Point2f>` with the corners of our object and perform
    a perspective transform to calculate the corners of our object in the camera image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Don't forget to close the brackets we opened earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s move to the `draw` method and begin by clearing the background and drawing
    the camera and object textures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s iterate over `goodPoints` values in both `mObjectInfo` and `mCameraInfo`
    and draw them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s iterate over `mCorners` and draw the corners of the found object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Build and run the application. Grab the physical object you depicted in the
    `object.jpg` image and put it in front of the image. The program will try to track
    that object in the camera image and draw it's corners in the image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are using a **Speeded Up Robust Features** (**SURF**) feature detector and
    descriptor to identify features. In the step 4, we are calculating the features
    and descriptor. We use a `cv::SurfFeatureDetect` object `or` that calculates good
    features to track on our object. The `cv::SurfDescriptorExtractor` object then
    uses these features to create a description of our object. In the step 7, we do
    the same for the camera image.
  prefs: []
  type: TYPE_NORMAL
- en: In the step 8, we then use a **Fast Library for Approximate Nearest Neighbor**
    (**FLANN**) called `cv::FlannBasedMatcher`. This matcher takes the description
    from both the camera frame and our object, and calculates matches between them.
  prefs: []
  type: TYPE_NORMAL
- en: In steps 9 and 10, we use the minimum distance between matches to eliminate
    the possible false matches. The result is passed into `mObjectInfo.goodPoints`
    and `mCameraInfo.goodPoints`.
  prefs: []
  type: TYPE_NORMAL
- en: In the step 11, we calculate the homography between image and camera. A homography
    is a projection transformation from one space to another using projective geometry.
    We use it in the step 12 to apply a perspective transformation to `mCorners` to
    identify the object corners in the camera image.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn more about what SURF is and how it works, please refer to the following
    web page: [http://en.wikipedia.org/wiki/SURF](http://en.wikipedia.org/wiki/SURF).'
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about FLANN, please refer to the web page [http://en.wikipedia.org/wiki/Nearest_neighbor_search](http://en.wikipedia.org/wiki/Nearest_neighbor_search).
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about homography please refer to the following web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://en.wikipedia.org/wiki/Homography](http://en.wikipedia.org/wiki/Homography).'
  prefs: []
  type: TYPE_NORMAL
- en: Reading QR code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example we will use the ZXing library for QR code reading.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Please download the Cinder ZXing block from GitHub and unpack it to the `blocks`
    folder: [https://github.com/dawidgorny/Cinder-ZXing](https://github.com/dawidgorny/Cinder-ZXing)'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now create a QR code reader:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a header search path to the build settings of your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a path from the precompiled ZXing library to the build settings of your
    project: `$(CINDER_PATH)/blocks/zxing/lib/macosx/libzxing.a`. For a debug configuration,
    use `$(CINDER_PATH)/blocks/zxing/lib/macosx/libzxing_d.a`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add Cinder ZXing block files to your project structure as follows:![How to do
    it…](img/8703OS_11_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `libiconv.dylib` library to the `Link Binary With Libraries` list:![How
    to do it…](img/8703OS_11_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the necessary header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following members to your main application class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `setup` method, set window dimensions and initialize capturing from
    camera:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `update` function as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `draw` function as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are using regular ZXing library methods. The `SurfaceBitmapSource` class
    delivered by the Cinder ZXing block provides integration with Cinder `Surface`
    type objects. While the QR code is detected and read, the `mDetected` flag is
    set to `true` and the read data is stored in the `mData` member.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/8703OS_11_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Building UI navigation and gesture recognition with Kinect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will create interactive GUI controlled with a Kinect sensor.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the **Kinect for Windows SDK** is available only for Windows, this recipe
    is written for Windows users only.
  prefs: []
  type: TYPE_NORMAL
- en: '![Building UI navigation and gesture recognition with Kinect](img/8703OS_11_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example we are using the `InteractiveObject` class that we covered in
    the *Creating an interactive object that responds to the mouse* recipe from [Chapter
    10](ch10.html "Chapter 10. Interacting with the User"), *Interacting with the
    User*.
  prefs: []
  type: TYPE_NORMAL
- en: Download and install the Kinect for Windows SDK from [http://www.microsoft.com/en-us/kinectforwindows/](http://www.microsoft.com/en-us/kinectforwindows/).
  prefs: []
  type: TYPE_NORMAL
- en: Download the KinectSDK CinderBlock from GitHub at [https://github.com/BanTheRewind/Cinder-KinectSdk](https://github.com/BanTheRewind/Cinder-KinectSdk),
    and unpack it to the `blocks` directory.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now create a Cinder application controlled with hand gestures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Include the necessary header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the Kinect SDK using the following statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the class for a waving hand gesture recognition as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement `NuiInteractiveObject` extending the `InteractiveObject` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `NuiController` class that manages the active objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the members to you main application class for handling Kinect devices and
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store the calculated cursor position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the members that we will use for gesture recognition and user activation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a member to handle `NuiController`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set window settings by implementing `prepareSettings`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method, set the default values for members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method initialize Kinect and gesture recognition for `10` users:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `setup` method, initialize the user interface consisting of objects
    of type `NuiInterativeObject`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `update` method, we are checking if the Kinect device is capturing,
    getting tracked skeletons, and iterating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the loop, we are checking if the skeleton is complete and deactivating
    the cursor controls if it is not complete:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the loop check if the skeleton is valid. Notice we are only processing
    10 skeletons. You can modify this number, but remember to provide sufficient number
    of gesture controllers in `mGestureControllers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the loop and the `if` statement, check for the completed activation
    gesture. While the skeleton is activated, we are calculating person interaction
    zone:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the loop and the `if` statement, we are calculating cursor positions
    for active users:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Close the opened `if` statements and the `for` loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'At the end of the `update` method, update the `NuiController` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `draw` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The application is tracking users using Kinect SDK. Skeleton data of the active
    user are used to calculate the cursor position by following the guidelines provided
    by Microsoft with Kinect SDK documentation. Activation is invoked by a hand waving
    gesture.
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of UI responsive to cursor controlled by a user's hand. Elements
    of the grid light up under the cursor and fade out on roll-out.
  prefs: []
  type: TYPE_NORMAL
- en: Building an augmented reality with Kinect
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will learn how to combine both Kinect's depth and image frames
    to create augmented reality application.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since Kinect for Windows SDK is available only for Windows, this recipe is written
    for Windows users only.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Download and install Kinect for Windows SDK from [http://www.microsoft.com/en-us/kinectforwindows/](http://www.microsoft.com/en-us/kinectforwindows/).
  prefs: []
  type: TYPE_NORMAL
- en: Download KinectSDK CinderBlock from GitHub at [https://github.com/BanTheRewind/Cinder-KinectSdk](https://github.com/BanTheRewind/Cinder-KinectSdk),
    and unpack it to the `blocks` directory.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we are using assets from one of the sample programs delivered
    with the Cinder package. Please copy the `ducky.mshducky.png`, `phong_vert.glsl`,
    and `phong_frag.glsl` files from `cinder_0.8.4_mac/samples/Picking3D/resources/`
    into your `assets` folder.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now create an augmented reality application using a sample 3D model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Include the necessary header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the `using` statement of the Kinect SDK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the members to you main application class for handling Kinect device and
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store 3D camera scene properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members to store calibration settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add members that will store geometry, texture, and shader program for 3D object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `setup` method, set the window dimensions and initial values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `setup` method load geometry, texture, and shader program for 3D
    object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside the `setup` method, initialize the Kinect device and start capturing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'At the end of the `setup` method, create GUI for parameter tweaking:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `update` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `drawObject` method that will draw our 3D model with the texture
    and shading applied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `draw` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last thing that is missing is the `draw3DScene` method invoked inside the
    `draw` method. Implement the `draw3DScene` method as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement the `shutdown` method to stop capturing from Kinect on program termination:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The application is tracking users using the Kinect SDK. Skeleton data of the
    users are used to calculate the coordinates of the 3D duck model taken from one
    of the Cinder sample programs. The 3D model is rendered right above the right
    hand of the user when the user's hand is in front of the user. The activation
    distance is calculated using the `mActivationDist` member value.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/8703OS_11_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To properly overlay 3D scene onto a video frame, you have to set the camera
    FOV according to the Kinect video camera. To do this, we are using the `Camera
    FOV` property.
  prefs: []
  type: TYPE_NORMAL
