<html><head></head><body><div class="chapter" title="Chapter&#xA0;4.&#xA0;Adding Sound"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Adding Sound</h1></div></div></div><p>As you have undoubtedly noticed, the little game demo we made in the previous chapter was a little lifeless without any sound. It goes to show how important sound and music really are to<a id="id267" class="indexterm"/> create the full experience of a game. Music sets the mood for the scene, and sound effects add more depth to the game world.</p><p>In this chapter we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">DirectSound versus XAudio2</li><li class="listitem" style="list-style-type: disc">The basics of sound</li><li class="listitem" style="list-style-type: disc">DirectSound</li><li class="listitem" style="list-style-type: disc">XAudio2</li></ul></div><div class="section" title="DirectSound versus XAudio2"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec25"/>DirectSound versus XAudio2</h1></div></div></div><p>As <a id="id268" class="indexterm"/>with user input and graphics rendering, we have a couple of <a id="id269" class="indexterm"/>options in the sound department as well; they are <span class="strong"><strong>DirectSound</strong></span> and <span class="strong"><strong>XAudio2</strong></span>. So let's take a look at these two.</p><p>First, there<a id="id270" class="indexterm"/> was DirectSound. When DirectSound was developed, game <a id="id271" class="indexterm"/>audio was still fairly simple. Games would play a <a id="id272" class="indexterm"/>single <code class="literal">.wav</code> sound file when a given event happened<a id="id273" class="indexterm"/> in the game world, and DirectSound allowed <a id="id274" class="indexterm"/>for improved performance if your PC had a sound card in it by offloading sound processing from the <span class="strong"><strong>CPU</strong></span> (<span class="strong"><strong>Central Processing Unit</strong></span>) to the sound <a id="id275" class="indexterm"/>card. This is very similar to how graphic cards handle graphics processing, allowing the CPU to do other things.</p><p>As time went on, the processing power of both PCs and gaming consoles increased greatly, and the simple sound model used by DirectSound was becoming insufficient for the increasingly complex sound systems that game developers were starting to create.</p><p>During development of the Xbox 360 gaming console, Microsoft realized that DirectSound just wasn't going to cut it. So, they created XAudio to meet the increasing demands of composers <a id="id276" class="indexterm"/>and sound designers in the video game industry. Meanwhile, Windows Vista (codenamed <span class="strong"><strong>Longhorn</strong></span>) was also in development. The team working on that created a <a id="id277" class="indexterm"/>new audio API called <span class="strong"><strong>Longhorn Extensible Audio Processor</strong></span>.</p><p>It wasn't long <a id="id278" class="indexterm"/>before <a id="id279" class="indexterm"/>both Xbox 360 and Windows <a id="id280" class="indexterm"/>Vista <a id="id281" class="indexterm"/>had launched, Microsoft<a id="id282" class="indexterm"/> turned their attention back to the idea of creating a <a id="id283" class="indexterm"/>cross-platform audio API to replace DirectSound. They had received positive feedback on their XAudio API from Xbox 360 game developers, but at the same time, the Longhorn Extensible Audio Processor API had some advantages over XAudio, such as providing a more streamlined and more efficient audio engine and a few additional features that XAudio did not have. So, Microsoft decided to take the best of both, and XAudio2 was the result.</p><p>So, this means we would obviously want to use XAudio2, right? The answer is yes, but that's not the whole answer. But this raises another potential question: why is DirectSound still included in DirectX when it has been replaced? The answer is, of course, for backward compatibility. Removing DirectSound from DirectX would have broken all applications that were written using the DirectSound API. They left it in so that those applications would still work.</p><p>As I said, XAudio2 is not quite the complete answer to the API we should use for the sound needs of our games. You may want to support DirectSound for users who may have older<a id="id284" class="indexterm"/> systems. However, XAudio2 is, as mentioned previously, a multi-platform API. You can use it to handle your sound needs in applications for Xbox 360, Windows Phone, and Windows PCs (Windows XP and higher).</p><p>For completeness, we'll take a look at both DirectSound and XAudio2 in this chapter, but first let's take a look at what sound really is and some of its properties.</p></div></div>
<div class="section" title="The basics of sound"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec26"/>The basics of sound</h1></div></div></div><p>Before we get into our sound programming, let's cover the basics of sound. We need to have a <a id="id285" class="indexterm"/>basic understanding of sound before we start doing our sound programming.</p><p>Sound is composed of waves. A <span class="strong"><strong>sound wave</strong></span>
<a id="id286" class="indexterm"/> is essentially just a pressure wave traveling through the air. When it hits your eardrum, a signal is then sent to the brain telling it about the sound wave that hit it. The brain converts this information into what we think of as a sound.</p><p>One of the most <a id="id287" class="indexterm"/>common attributes we give to sounds is the idea of <span class="strong"><strong>volume</strong></span>. So what exactly is volume? Simply put, it is the amplitude of the sound waves. If you think of a drawing of a wave, the height of a wave is its amplitude. In other words, amplitude is how big the wave is. Look at the following diagram to see this:</p><div class="mediaobject"><img src="graphics/7389OS_04_01.jpg" alt="The basics of sound"/><div class="caption"><p>The amplitude or volume of a sound wave</p></div></div><p>Another very important attribute of sound is the idea of <span class="strong"><strong>frequency</strong></span>. So, on a drawing of a wave, its wavelength<a id="id288" class="indexterm"/> is simply how wide the wave is, and the length of the waves determines their frequency. Frequency refers to how often the waves hit, rather than to the length of a single wave. The higher the frequency of the sound waves, the higher the <span class="strong"><strong>pitch</strong></span>
<a id="id289" class="indexterm"/> of the sound is. Likewise, lower frequency sounds have a lower <a id="id290" class="indexterm"/>pitch. The term pitch of course refers to how high or low a sound is. The following diagram shows the concept of frequency: </p><div class="mediaobject"><img src="graphics/7389OS_04_02.jpg" alt="The basics of sound"/><div class="caption"><p>The wavelength or frequency of a sound wave</p></div></div><p>Frequency is measured in <a id="id291" class="indexterm"/>
<span class="strong"><strong>Hertz</strong></span> (<span class="strong"><strong>Hz</strong></span>). The term Hertz generally means cycles per second. So if we have a sound that is at 100 Hz, this means that 100 sound waves hit our eardrums per second. The unit Hertz can be applied to any event that happens regularly, such as the ticking of a clock, the beating of a heart, or the speed of a computer processor. The speed of a modern computer processor is generally given in <span class="strong"><strong>Gigahertz</strong></span> (<span class="strong"><strong>GHz</strong></span>) these <a id="id292" class="indexterm"/>days. That's pretty fast if you consider that one <span class="strong"><strong>Kilohertz</strong></span> (<span class="strong"><strong>KHz</strong></span>) is 1,000 Hz, one Megahertz is 1,000 KHz (or 1 million Hertz), and one<a id="id293" class="indexterm"/> Gigahertz is 1,000 MHz (or 1 billion Hertz). The hearing range for humans is on average from around 20 to 20,000 Hz.</p><p>Ok, that's <a id="id294" class="indexterm"/>enough of that since your head probably "Hertz" now. Get it? Anyway, we know what the frequency of a sound is now. So, let's move on and look at the idea of <span class="strong"><strong>stereo</strong></span> sound<a id="id295" class="indexterm"/>.</p></div>
<div class="section" title="Stereo sound"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec27"/>Stereo sound</h1></div></div></div><p>When a sound <a id="id296" class="indexterm"/>is played in stereo, it means that the sound has two channels: one channel is played by the left speaker while the other is played by the right speaker. This gives a bit of a 3D effect to the sound for the listener. In other words, the sound is composed of two separate sound tracks, one for each speaker.</p><p>This leads us to the concept of <a id="id297" class="indexterm"/>a <span class="strong"><strong>phase</strong></span>. You can think of this as referring to how well the channels in a sound are synced with one another. If the channels are perfectly in sync, they are said to be <span class="emphasis"><em>in phase</em></span>. Otherwise, they are said to be <span class="emphasis"><em>out of phase</em></span>. So if you delay one of the channels by a fraction of a second, your sound is out of phase because the sound from the left and right speakers is not correctly synced with each other.</p><p>There is one last interesting property of sound that we will take a quick look at. It is directly linked to the concept of a phase. The following diagram shows this:</p><div class="mediaobject"><img src="graphics/7389OS_04_03.jpg" alt="Stereo sound"/></div><p>In the previous figure, we have two sets of sound waves: one is continuous, and the other is dotted. As<a id="id298" class="indexterm"/> you can see, the dotted one is the continuous wave inverted. So the result is that we have two audio tracks, where one has the opposite phase of the other. So what happens when we play this sound? Nothing! That's right, absolutely nothing. Why? Because sound waves with opposite phases will cancel each other out. In other words, if two sound waves of the same amplitude and frequency coincide with each other, but one of them is inverted, then they cancel each other out. The second half of the previous diagram shows this. There are no sound waves left since they canceled each other out, and thus we have silence.</p></div>
<div class="section" title="DirectSound"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec28"/>DirectSound</h1></div></div></div><p>We will add <a id="id299" class="indexterm"/>some simple sound to the 2D world we made in the previous chapter. So, open Visual Studio and let's get started!</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note12"/>Note</h3><p>Before we get started, it should be noted that the music track we are using in this chapter (<code class="literal">lost_village_128.wav</code>) is courtesy of <a class="ulink" href="http://wrathgames.com/blog">http://wrathgames.com/blog</a> (<span class="emphasis"><em>WrathGames Studio</em></span>). So, a big thanks goes<a id="id300" class="indexterm"/> out to them.</p><p>This sound file is, of course, included in the downloadable code for this chapter.</p></div></div><p>Open the <code class="literal">TileGameWindow.cs</code> file. First of all, we need to add the following <code class="literal">using</code> statements to the top of the file so that we can use DirectSound:</p><div class="informalexample"><pre class="programlisting">using SlimDX.DirectSound;
using SlimDX.Multimedia;</pre></div><p>Now, we need to <a id="id301" class="indexterm"/>add some new member variables to this class. The first one we will add is a Boolean variable named <code class="literal">m_UseDirectSound</code>. This variable can be set to either <code class="literal">true</code>, or <code class="literal">false</code>. When it is set to <code class="literal">true</code>, the program will use DirectSound, but if this variable is set to <code class="literal">false</code>, the program will use XAudio2. The following is the declaration of this variable:</p><div class="informalexample"><pre class="programlisting">bool m_UseDirectSound = true; </pre></div><p>Next, we need to create three more member variables that will hold our <code class="literal">DirectSound</code> objects. They are as follows:</p><div class="informalexample"><pre class="programlisting">DirectSound m_DirectSound;  
PrimarySoundBuffer m_DSoundPrimaryBuffer; 
SecondarySoundBuffer m_DSoundBuffer;</pre></div><p>The first variable will hold our <code class="literal">DirectSound</code> object. The second one is the primary sound buffer, and the third variable is a secondary sound buffer that will store the sound we want to play.</p><p>Now, we will add a new method called <code class="literal">InitDirectSound()</code> to the <code class="literal">TileGameWindow</code> class. The following is the code for it:</p><div class="informalexample"><pre class="programlisting">public void InitDirectSound()
{
    // Create our DirectSound object.
    m_DirectSound = new DirectSound();

    // Set the cooperative level.
    m_DirectSound.SetCooperativeLevel(m_Form.Handle, SlimDX.DirectSound.CooperativeLevel.Priority);

    // Create the primary sound buffer.
    SoundBufferDescription desc = new SoundBufferDescription();
    desc.Flags = SlimDX.DirectSound.BufferFlags.PrimaryBuffer;
    m_DSoundPrimaryBuffer = new PrimarySoundBuffer(m_DirectSound, desc);

    // Create our secondary sound buffer.
    using (WaveStream wavFile = new WaveStream(Application.StartupPath + "\\" + "lost_village_128.wav"))
    {
        SoundBufferDescription DSoundBufferDesc;
        DSoundBufferDesc = new SoundBufferDescription();
        DSoundBufferDesc.SizeInBytes = (int) wavFile.Length;
        DSoundBufferDesc.Flags = SlimDX.DirectSound.BufferFlags.ControlVolume;
        DSoundBufferDesc.Format = wavFile.Format;

        m_DSoundBuffer = new SecondarySoundBuffer(m_DirectSound, DSoundBufferDesc);

        // Now load the sound.
        byte[] wavData = new byte[DSoundBufferDesc.SizeInBytes];
        wavFile.Read(wavData, 0, (int)wavFile.Length);
        m_DSoundBuffer.Write(wavData, 0, LockFlags.None);

        // Play our music and have it loop continuously.
        m_DSoundBuffer.Play(0, SlimDX.DirectSound.PlayFlags.Looping);
    }

}</pre></div><p>The first<a id="id302" class="indexterm"/> line in this method creates our <code class="literal">DirectSound</code> object.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip09"/>Tip</h3><p>In a real program, you would have much better error handling than we have in our demos in this book. It has been left out to save space.</p></div></div><p>In this case, we would need to handle the situation where the creation of the <code class="literal">DirectSound</code> object fails. This could happen, for example, when the user does not have a DirectSound-compatible sound card installed in his/her system. If this happens, SlimDX will throw a <code class="literal">DirectSound</code> exception (or error). We would catch the exception by putting a <code class="literal">try</code> block around the initialization code as follows:</p><div class="informalexample"><pre class="programlisting">try
{
    // Create our DirectSound object.
    m_DirectSound = new DirectSound();
}
catch (DirectSoundException dsException)
{
    return;
}</pre></div><p>Inside the <code class="literal">catch</code> block, we input our code to handle the error condition. In this case, we just make the constructor return without finishing initialization. This prevents the program from crashing, but it still won't work, right? (It won't have sound.) So, basically, if the initialization of the <code class="literal">DirectSound</code> object fails, the code in the <code class="literal">catch</code> block will run.</p><p>Error <a id="id303" class="indexterm"/>handling is extremely important in real-world applications, so don't forget about it!</p><p>Next, we set the cooperative level. The cooperative level determines the extent to which the system allows this program to use the device. This is because Windows is a multitasking environment and therefore multiple applications could be using the sound device at the same time. Cooperative level is the way the system makes sure that we don't have two programs trying to use the device at exactly the same time, as this can cause problems. As you can see, we set the cooperative level to <code class="literal">CooperativeLevel.Priority</code> here. This is usually what you'll want to set it to if your application is a game.</p><p>The next three lines of code create our <code class="literal">PrimarySoundBuffer</code> object and give it the <code class="literal">BufferFlags.PrimaryBuffer</code> flag.</p><p>The next chunk of code sets up our <code class="literal">SecondarySoundBuffer</code> object. It starts with a <code class="literal">using</code> block that creates a <code class="literal">WaveStream</code> object that is using our sound file. Inside the <code class="literal">using</code> block, we create a <code class="literal">SoundBufferDescription</code> object that we will use to specify the properties of our <code class="literal">SecondarySoundBuffer</code> object when we create it. We set the <code class="literal">SizeInBytes</code> property to the size of our wave file. Then, we set the <code class="literal">Flags</code> property to have the <code class="literal">BufferFlags.ControlVolume</code> flag. Having this flag set allows us to control the volume of the sound. There are other buffer flags too, of course. Some examples are <code class="literal">ControlPan</code>, which lets you control the left/right balance of the sound, <code class="literal">ControlFrequency</code>, which lets you control the frequency of the sound, and <code class="literal">ControlEffects</code>, which allows you to apply effects to the sound.</p><p>Next, we get the wave format from the <code class="literal">WaveStream</code> object and copy it into the <code class="literal">Format</code> property of the <code class="literal">SoundBufferDescription</code> object. Then, we create the <code class="literal">SecondarySoundBuffer</code> object using the <code class="literal">DirectSound</code> object, and the <code class="literal">SoundBufferDescription</code> object we just filled out.</p><p>The next block of code loads our sound file. The first line here creates a byte array of the same size as our wave file. The next line reads all of the data from the wave file into the byte array. The third line copies the data from the byte array into our <code class="literal">SecondarySoundBuffer</code> object. The second parameter here is the offset into the buffer that we want to start writing the data at. Since we want to start at the beginning of the buffer, we specify <code class="literal">0</code> for this. If we specified <code class="literal">10</code>, the wave data would be written starting <code class="literal">10</code> bytes in from the beginning of the buffer.</p><p>The final <a id="id304" class="indexterm"/>line tells the <code class="literal">SecondarySoundBuffer</code> object to start playing <a id="id305" class="indexterm"/>our sound by calling its <code class="literal">Play()</code> method. The first parameter is the priority for this sound. The second parameter specifies flags that affect how the sound is played. In this case we are using <code class="literal">PlayFlags.Looping</code> to make our music loop continuously.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note13"/>Note</h3><p>You will need your sound file to be properly set up for looping. A sound file that is not meant for looping will probably not sound good when it loops back to the start. A sound file that is meant for looping has a smooth transition at the end, so that the end transitions nicely into the start so that the sound can repeat seamlessly.</p></div></div><p>The <code class="literal">SecondarySoundBuffer</code> object has other methods as well. The <code class="literal">Pause()</code> method, for example, will pause the sound. When you start playing it again, it will resume from where it left off. The <code class="literal">Stop()</code> method<a id="id306" class="indexterm"/>, on the other hand, stops playback and also rewinds the sound back to its beginning. So when you start the sound playing again, it will start over from the beginning.</p><p>At this point, we need to go back and add a line of code into the constructor to call this new <code class="literal">InitDirectSound()</code> method that we have created. For that, we simply add the following <code class="literal">if</code> statement to the end of the constructor:</p><div class="informalexample"><pre class="programlisting">if (m_UseDirectSound)
    InitDirectSound();</pre></div><p>We are not quite finished though. We still need to dispose of our <code class="literal">DirectSound</code> objects when we are done with them. So, add the following code into the managed section of our <code class="literal">Dispose(bool)</code> method:</p><div class="informalexample"><pre class="programlisting">if (m_DSoundBuffer != null)
    m_DSoundBuffer.Dispose();

if (m_DSoundPrimaryBuffer != null)
    m_DSoundPrimaryBuffer.Dispose();

if (m_DirectSound != null)
    m_DirectSound.Dispose();</pre></div><p>With that, our DirectSound code is done. If you run the program now, you should notice music playing in our 2D tile-based world. You may also notice that the music will pause if the window loses focus. If you then click on the window again to give it the focus, the music will start back up where it left off.</p><p>We should also talk about the sound buffer's <code class="literal">Status</code> property, which you can access to find out <a id="id307" class="indexterm"/>the current status of your sound buffer. For example, you can <a id="id308" class="indexterm"/>use this to check if the sound is currently playing or looping, among other things.</p><div class="section" title="Volume control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec27"/>Volume control</h2></div></div></div><p>In this section of code, we mentioned several of the buffer flags, and we set the <code class="literal">BufferFlags.ControlVolume</code> flag on our <code class="literal">SecondarySoundBuffer</code> object, which tells DirectSound <a id="id309" class="indexterm"/>that we want the capability to change the <a id="id310" class="indexterm"/>volume of the sound. We didn't actually mess with this, but to change the volume, you would simply change the value of the sound buffer's <code class="literal">Volume</code> property. In DirectSound, volume is specified in 100th of a <span class="strong"><strong>decibel</strong></span> (<span class="strong"><strong>dB</strong></span>). The valid range for this property is <code class="literal">0</code> to <code class="literal">10,000</code>. Also, note that the maximum value of <code class="literal">10,000</code> represents the original volume of the sound. As you can see, this means that DirectSound does not support amplification, as is stated in their documentation.</p></div><div class="section" title="Frequency control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec28"/>Frequency control</h2></div></div></div><p>This is <a id="id311" class="indexterm"/>similar to controlling the volume. You can <a id="id312" class="indexterm"/>change the frequency of the sound by setting the <code class="literal">BufferFlags.ControlFrequency</code> flag and then changing the value of the sound buffer's <code class="literal">Frequency</code> property. The valid range of values for this property is <code class="literal">100</code> to <code class="literal">100,000</code>. If you want to use the original frequency of the audio track, set this property to a value of <code class="literal">0</code>. If you wanted to double the playback speed of your sound for example, you would need to double its frequency.</p></div><div class="section" title="Pan control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec29"/>Pan control</h2></div></div></div><p>If you set the <code class="literal">BufferFlags.ControlPan</code> flag on the buffer, you can change the left/right<a id="id313" class="indexterm"/> balance of the sound by editing the sound buffer's <code class="literal">Pan</code> property. If you shift it right, the sound will come out of the right speaker more than <a id="id314" class="indexterm"/>the left. The valid range of values for this property is <code class="literal">-10,000</code> to <code class="literal">10,000</code>. At <code class="literal">-10,000</code>, the sound will only come out of the left speaker, and at <code class="literal">10,000</code> it will only come out of the right speaker. A value of <code class="literal">0</code> specifies the center, or in other words, the sound will come out of both speakers equally.</p><p>There are, of course, more flags besides these ones too and other effects that you can apply to your sound, but we don't have room to cover them <a id="id315" class="indexterm"/>here. These flags are all defined in the <code class="literal">BufferFlags</code> enumeration.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note14"/>Note</h3><p>You <a id="id316" class="indexterm"/>need to set the proper buffer flags as mentioned previously, before you can use these various controls on your sound.</p></div></div></div></div>
<div class="section" title="XAudio2"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec29"/>XAudio2</h1></div></div></div><p>XAudio2 is, of <a id="id317" class="indexterm"/>course, newer and more powerful than DirectSound. We will add some more code to the same file we've spent the first part of this chapter working on (<code class="literal">TileGameWindow.cs</code>).</p><p>As usual, we first need to add some <code class="literal">using</code> statements at the top of the file, so that we can use XAudio2.</p><div class="informalexample"><pre class="programlisting">using SlimDX.XAudio2;</pre></div><p>Next, we will create some member variables to hold our <code class="literal">XAudio2</code> objects. This time there are four of them.</p><div class="informalexample"><pre class="programlisting">XAudio2 m_XAudio2;
MasteringVoice m_MasteringVoice;
AudioBuffer m_AudioBuffer;
SourceVoice m_SourceVoice;</pre></div><p>The first one, <code class="literal">m_XAudio2</code>, will hold our <code class="literal">XAudio2</code> object. The second one will hold our <span class="strong"><strong>mastering voice</strong></span>
<a id="id318" class="indexterm"/>. In XAudio2, the <code class="literal">MasteringVoice</code> class is used to represent the sound output device. The third variable is the buffer that we will store our sound in. Lastly, we have a <code class="literal">SourceVoice</code> object. This is used to submit our audio data to the <code class="literal">MasteringVoice</code> object for processing.</p><p>The next thing we should do is edit the <code class="literal">if</code> statement we added to the bottom of the constructor earlier in this chapter. The following code needs to be changed:</p><div class="informalexample"><pre class="programlisting">if (m_UseDirectSound)
    InitDirectSound();</pre></div><p>The following change has to be made:</p><div class="informalexample"><pre class="programlisting">if (m_UseDirectSound)
    InitDirectSound();
else
    InitXAudio2();</pre></div><p>This change makes it such that the program will use XAudio2 instead of DirectSound if the <code class="literal">m_UseDirectSound</code> member variable is set to <code class="literal">false</code>. So, go to the top of the class file, find that variable, and change its value to <code class="literal">false</code>.</p><p>With that taken<a id="id319" class="indexterm"/> care of, we need to create the <code class="literal">InitXAudio2()</code> method so that if the <code class="literal">m_UseDirectSound</code> variable is set to <code class="literal">false</code>, the method is called. The following is the code for this method:</p><div class="informalexample"><pre class="programlisting">public void InitXAudio2()
{
    // Create the XAudio2 object.
    m_XAudio2 = new XAudio2();

    // Check that we have a valid sound device to use.
    if (m_XAudio2.DeviceCount == 0)
        return;

    // Create our mastering voice object. This object represents the sound output device.
    m_MasteringVoice = new MasteringVoice(m_XAudio2);

    // Open the .wav file that contains our sound.
    using (WaveStream wavFile = new WaveStream(Application.StartupPath + "\\" + "lost_village_128.wav"))
    {
        // Create the audio buffer and store the audio data from the file in it.
        m_AudioBuffer = new AudioBuffer();
        m_AudioBuffer.AudioData = wavFile;
        m_AudioBuffer.AudioBytes = (int) wavFile.Length;

        // Setup our audio buffer for looping.
        m_AudioBuffer.LoopCount = XAudio2.LoopInfinite;

        // Create the source voice object. This is used to submit our audio data to the
        // mastering voice object so we can play it.
        m_SourceVoice = new SourceVoice(m_XAudio2, wavFile.Format);
        m_SourceVoice.SubmitSourceBuffer(m_AudioBuffer);
        m_SourceVoice.Start();
    }
}</pre></div><p>This method can be a bit confusing, so I left the comments in the previous code listing. As you can see, the first thing we do is create our XAudio2 object. Then, we have an <code class="literal">if</code> statement that checks to see if we have any valid sound devices to use. If not, then the <code class="literal">XAudio2</code> object's <code class="literal">DeviceCount</code> property will return <code class="literal">0</code>. In this case, if no sound device is available, we simply return and don't try to continue initializing XAudio2, since this would probably<a id="id320" class="indexterm"/> cause a crash. This goes back to the tip in the <span class="emphasis"><em>DirectSound</em></span> section of this chapter; error handling is very important in a real game, so don't forget it or put if off! Next, we create the <code class="literal">MasteringVoice</code> object. I know you're probably thinking something along the lines of "what the heck is a mastering voice?". Well, it is simply a class that represents the audio output device; however, you cannot submit an audio buffer directly to the mastering voice object. We will use our <code class="literal">SourceVoice</code> object to do that in a minute.</p><p>Now, we have a <code class="literal">using</code> block similar to the one we have in our <code class="literal">InitDirectSound()</code> method. It opens our sound file so we can get the audio data and put it into our buffer.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note15"/>Note</h3><p>Remember that the <code class="literal">using</code> block will automatically dispose of our <code class="literal">WaveStream</code> when program execution reaches the end of the <code class="literal">using</code> block, and that <code class="literal">using</code> blocks only work like this with types that implement the <code class="literal">IDisposable</code> interface.</p></div></div><p>The first four lines of code inside the <code class="literal">using</code> block set up our audio buffer. The first one creates the <code class="literal">AudioBuffer</code> object. The second line sets the buffer's <code class="literal">AudioData</code> property to our <code class="literal">WaveStream</code> object to get the audio data from the <code class="literal">.wav</code> file and into our audio buffer. The third line sets the buffer's <code class="literal">AudioBytes</code> property to the length of the <code class="literal">.wav</code> file, so the buffer knows how much data we have shoved into it. </p><p>The next line of code tells XAudio2 that we want to loop this sound. This is done by setting the <code class="literal">LoopCount</code> property to <code class="literal">XAudio2.LoopInfinite</code>. The <code class="literal">LoopCount</code> property sets how many times we want to loop the sound. You can set the start position for the loop and the end position via the <code class="literal">AudioBuffer</code>'s <code class="literal">BeginLoop</code> and <code class="literal">EndLoop</code> properties. This is not necessary if your audio file already has looping data in it. In this case these properties are already set for us based on the data from the file. Note that the <code class="literal">AudioBuffer</code> class also has the <code class="literal">PlayBegin</code> and <code class="literal">PlayLength</code> properties that let you set the portion of the sound that you wish to play. These properties are set to the beginning and end of the sound file by default.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>The <code class="literal">BufferFlags</code> enumeration we just used is not the same one we used when we were working with DirectSound. The DirectSound enumeration for buffer flags is <code class="literal">SlimDX.DirectSound.BufferFlags</code>, while the XAudio2 enumeration for buffer flags is <code class="literal">SlimDX.XAudio2.BufferFlags</code>.</p></div></div><p>The last three lines of code set up our <code class="literal">SourceVoice</code> object. This object is used to submit our audio data to the <code class="literal">MasteringVoice</code> object so that we can play it. So, the first of these three lines creates the <code class="literal">SourceVoice</code> object. The second line submits the audio data from our <code class="literal">AudioBuffer</code>, so that we can play it, and the last line plays our sound.</p><p>There is still one more little thing we need to take care of before we test our XAudio2 code. We need to add some new code into the managed section of our <code class="literal">Dispose(bool)</code> method. We <a id="id321" class="indexterm"/>have four objects we need to dispose of, so the code looks like the following:</p><div class="informalexample"><pre class="programlisting">// XAudio2 Stuff
if (m_SourceVoice != null)
    m_SourceVoice.Dispose();

if (m_AudioBuffer != null)
    m_AudioBuffer.Dispose();

if (m_MasteringVoice != null)
    m_MasteringVoice.Dispose();

if (m_XAudio2 != null)
    m_XAudio2.Dispose();</pre></div><p>We are now ready to test our new code. If you run the program, the music will keep looping until you close the program. You may also notice that unlike the DirectSound demo, if the window loses focus, XAudio2 just keeps playing the sound.</p><p>As we could in DirectSound, we can of course change the volume of our sound, or pan it in XAudio2. So how do we accomplish this?</p><div class="section" title="Volume control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec30"/>Volume control</h2></div></div></div><p>We can <a id="id322" class="indexterm"/>change the overall volume of our sound by changing the <a id="id323" class="indexterm"/>value of the <code class="literal">SourceVoice</code> object's <code class="literal">Volume</code> property. The value of this property is a floating point amplitude multiplier in the range -<code class="literal">2</code><sup>24</sup> to <code class="literal">2</code>
<sup>24</sup>. With a value of <code class="literal">1.0f</code>, there is no attenuation and no gain. A value of <code class="literal">0</code> results in silence. Negative values can be used to invert the phase of the audio.</p></div><div class="section" title="Frequency control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec31"/>Frequency control</h2></div></div></div><p>Adjusting the frequency<a id="id324" class="indexterm"/> of the sound is a bit different in <a id="id325" class="indexterm"/>XAudio2 than it is in DirectSound. In XAudio2, this is expressed as a frequency ratio. You can change it by altering the value of the <code class="literal">SourceVoice</code> object's <code class="literal">FrequencyRatio</code> property. A ratio of 1:1 means that there is no pitch change. This is the default value for this property. The valid range of values is <code class="literal">1/1,024</code> to <code class="literal">1,024/1</code>. At a ratio of 1:1,024 the sound's pitch is lowered by 10 octaves. On the other hand, a ratio of 1,024:1 will raise the pitch of the sound by 10 octaves. This property is of the type <code class="literal">float</code>, so you would have to calculate the ratio and pass it in. So if you want to pass in the ratio 1:1, this property would be set to a value of <code class="literal">1</code> since one divided by one is one.</p><p>To put this in <a id="id326" class="indexterm"/>context, the default ratio has a value of <code class="literal">1</code> as<a id="id327" class="indexterm"/> we just said. A value of <code class="literal">2</code> will double the frequency of the sound and will increase its pitch by one octave. A ratio of <code class="literal">0.5</code> will cut the frequency in half, making the track take twice as long to play and lowering its pitch by one octave. So for example, if you want to make a sound play at three times its normal speed, you would set the <code class="literal">FrequencyRatio</code> property to a value of <code class="literal">3</code>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note17"/>Note</h3><p>Each time you halve the frequency of the sound, you lower its pitch by one octave, and likewise, each time you double the frequency, you increase the pitch by one octave.</p></div></div></div><div class="section" title="Pan control"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec32"/>Pan control</h2></div></div></div><p>Panning is a <a id="id328" class="indexterm"/>bit more complicated in XAudio2 than it is in DirectSound. There are a number of steps we must take to pan in XAudio2. The first <a id="id329" class="indexterm"/>step is to create an output <span class="strong"><strong>matrix</strong></span>. A matrix is simply a two-dimensional <a id="id330" class="indexterm"/>table of numbers. This simply contains the calculated panning values for each channel. We create the array as follows:</p><div class="informalexample"><pre class="programlisting">float[] outputMatrix = new float[8];</pre></div><p>We created this array with eight elements, so that it can support speaker configurations up to 7.1. For simplicity, our sample code here will simply be for stereo output. Next, we need to calculate or set the values for the left- and right-side speakers. So, in this case, we will create two more variables to hold these values.</p><div class="informalexample"><pre class="programlisting">float left = 0.5f;
float right = 0.5f;</pre></div><p>We have both values set to <code class="literal">0.5</code>, which means the sound will play evenly from both speakers. If we set left to <code class="literal">1.0</code> and right to <code class="literal">0.0</code>, the sound will only play from the left speaker. And of course, if we set left to <code class="literal">0.0</code> and right to <code class="literal">1.0</code>, then the sound will only play from the right speaker. So as you can see, these values are in essence volume levels for the left and right channels of the sound.</p><p>Now, we need to set these values into the correct indices in the <code class="literal">outputMatrix</code> array that we created previously. We need to get the <span class="strong"><strong>channel mask</strong></span> first, so we know what speaker configuration <a id="id331" class="indexterm"/>we are dealing with. How you do this differs depending on whether you are developing for Windows 7 and earlier versions, or Windows 8. For Windows 7 and earlier versions, we get the channel mask by using the <code class="literal">GetDeviceDetails()</code> method of the <code class="literal">XAudio2</code> object:</p><div class="informalexample"><pre class="programlisting">m_XAudio2.GetDeviceDetails(0).OutputFormat.ChannelMask</pre></div><p>Note that the parameter to the <code class="literal">GetDeviceDetails()</code> method is simply the index of the device to query, and <code class="literal">0</code> is the default device. On the Windows 8 version of XAudio2, we get the channel mask from the <code class="literal">MasteringVoice</code> object's <code class="literal">ChannelMask</code> property:</p><div class="informalexample"><pre class="programlisting">m_MasteringVoice.ChannelMask</pre></div><p>As you can<a id="id332" class="indexterm"/> see, this code is a bit shorter in the Windows 8 version <a id="id333" class="indexterm"/>of XAudio2 compared to the DirectX SDK version (Windows 7 and earlier versions).</p><p>So what is this channel mask value? Well, it is simply a flag variable with various flags set in it to specify the speaker configuration of the PC. There is a flag for each different speaker type. These flags are defined by the <code class="literal">Speakers</code> enumeration (which is in the <code class="literal">SlimDX.Multimedia</code> namespace), and here they are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">BackCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">BackLeft</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">BackRight</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FrontCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FrontLeft</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FrontLeftOfCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FrontRight</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FrontRightOfCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">SideLeft</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">SideRight</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">LowFrequency</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopBackCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopBackLeft</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopBackRight</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopFrontCenter</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopFrontLeft</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TopFrontRight</code></li></ul></div><p>So, basically, these flags are used to indicate which types of speaker(s) are being used. You probably won't need to use most of these flags, but I have included them in the previous list for reference purposes. However, the <code class="literal">Speakers</code> enumeration actually has a few more flags in it that make life a little simpler for us programmers. These flags differ from the previous list in that they do not specify a single speaker; instead, each of these flags is a combination of the flags listed previously. They are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">All</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FourPointOne</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FivePointOne</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">FivePointOneSurround</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">None</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">Mono</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">Quadraphonic</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">SevenPointOne</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">SevenPointOneSurround</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">Stereo</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">Surround</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">TwoPointOne</code></li></ul></div><p>We will use<a id="id334" class="indexterm"/> these simpler flags in our example code. Now that we <a id="id335" class="indexterm"/>know about these flags, we can use them to write the code that tests to see what the speaker configuration is. We will not use any of the flags from the first list, but rather we will just check for certain speaker configurations using some of the flags from the second set of flags listed previously. For example, an <code class="literal">if</code> statement checking to see if we have a configuration with two output channels would look something like the following:</p><div class="informalexample"><pre class="programlisting">if (channelMask.HasFlag(Speakers.Stereo) ||
     channelMask.HasFlag(Speakers.TwoPointOne) ||
     channelMask.HasFlag(Speakers.Surround))
    {
        outputMatrix[0] = left;
        outputMatrix[1] = 0.0f;
        outputMatrix[2] = 0.0f;
        outputMatrix[3] = right;
     }</pre></div><p>If this code is checking for a configuration using two speakers, why are we setting four values here? The reason is because we have two channels of input. So for the left speaker, we set a volume level for both channels. The index <code class="literal">0</code> in the array is set to the value of our <code class="literal">left</code> variable. The index <code class="literal">1</code> of the array represents the volume level of the right channel. Since we don't want the right channel to play out of the left speaker at all, we set this to <code class="literal">0.0f</code>. Likewise, the elements <code class="literal">2</code> and <code class="literal">3</code> are setting the volume levels for the right speaker. We set element <code class="literal">2</code> to a value of <code class="literal">0.0f</code>, since we don't want the left channel sound to play out of the right speaker. And lastly, element <code class="literal">3</code> is set to our <code class="literal">right</code> variable. So, as you can see, for each speaker that will be outputting sound, we must set the volume levels for all of the channels that our sound has.</p><p>You can find this sample code in the downloadable code for this chapter. This panning code is commented out though. Just uncomment it and play around with it.</p><p>Note that<a id="id336" class="indexterm"/> better sound configurations, such as 5.1 or 7.1, will use<a id="id337" class="indexterm"/> more elements of this array, since they have more channels to set the volume levels for.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip10"/>Tip</h3><p>The XAudio2 object has many utility methods and constants that you will need in some cases. This is also true of many of the other major DirectX objects we've covered so far in this book, such as the <code class="literal">DirectSound</code> object earlier in this chapter, or the <code class="literal">Direct2D</code> object discussed in the previous chapter.</p></div></div><p>If you want to use the <a id="id338" class="indexterm"/>
<code class="literal">.ogg</code> or <a id="id339" class="indexterm"/>
<code class="literal">.mp3</code> files instead of the <code class="literal">.wav</code> files<a id="id340" class="indexterm"/> like we did in this chapter, you will need to write a method to load in each file type, since you will have to decode it before you can play it. Alternatively, you could of course convert your files to the <code class="literal">.wav</code> format and just use them like that.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec30"/>Summary</h1></div></div></div><p>In this chapter we got into the world of sound programming. First we looked at what sound is and some of its basic properties. Then, we looked at the differences between DirectSound and XAudio2. We added music to our 2D tile world demo using DirectSound. Next, we added some code to do the same thing but using XAudio2, and we created a member variable to control whether the program will use DirectSound or XAudio2 to play its sound. We also looked at how to control volume, frequency, and panning for a sound in both DirectSound and XAudio2. In the next chapter, we will take a look at Direct3D and how to render simple 3D graphics.</p></div></body></html>