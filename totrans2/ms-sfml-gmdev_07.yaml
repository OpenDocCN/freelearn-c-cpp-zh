- en: Chapter 7.  One Step Forward, One Level Down - OpenGL Basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often times it's easy to take a library like SFML for granted. After all, the
    ideas and concepts offered by it seem quite intuitive. Building something rather
    simple can take as little as a couple of minutes, and there are no major headaches
    to deal with. In a perfect world, we could just offload those troubles to someone
    else and simply rely on increasingly higher levels of abstraction to get the job
    done. However, what happens when certain limitations make us slam face-first into
    a brick wall? In order to know the way around them, it's necessary to know the
    fundamentals that SFML was built on. In other words, at that point, downward is
    the only way forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to be covering:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up and using OpenGL with a window from SFML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shaping and submitting data to the GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating, building, and using shaders for rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying textures to geometry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at various coordinate spaces and model transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a camera
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That is quite a laundry list of things to do, so let us not waste any time and
    jump right in!
  prefs: []
  type: TYPE_NORMAL
- en: Use of copyrighted resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As always, let us acknowledge those who deserve to be acknowledged, and give
    credit where credit''s due. These are the resources used in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Old wall texture by `texturelib.com` under the CC0: [license:http://texturelib.com/texture/?path=/Textures/brick/medieval/brick_medieval_0121](http://texturelib.com/texture/?path=/Textures/brick/medieval/brick_medieval_0121)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: STB public domain image loader by *Sean Barrett* under the CC0 license: [https://github.com/nothings/stb/blob/master/stb_image.h](https://github.com/nothings/stb/blob/master/stb_image.h)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up OpenGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to have access to the latest version of OpenGL, we need to download
    two libraries. One is named the OpenGL Extension Wrangler Library. It loads and
    makes available all OpenGL extensions that are supported on the target platform.
    The library can be downloaded here [http://glew.sourceforge.net/](http://glew.sourceforge.net/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other library we need is called OpenGL Mathematics, or GLM for short. It
    is a header-only library that adds a lot of extra data types and functions, which
    come in handy more often than not. Anything from simple vector data types to functions
    used to calculate cross products are added in by this library. It can be found
    here [http://glm.g-truc.net/0.9.8/index.html](http://glm.g-truc.net/0.9.8/index.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a Visual Studio project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alongside the usual SFML includes, which we are still going to need for creating
    a window, we also need to add the GLEW and GLM `include` folders in the **Include
    Directories** field under **VC++ Directories**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GLEW **Additional Library Directory** must be added in as well in the **General**
    section under **Linker**. The library files are located inside the `Release` folder,
    which holds a couple of directories: `Win32` and `x64`. These need to be set up
    correctly for different build configurations.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `glew32.lib` file has to be added to the **Additional Dependencies**
    field in the **Input** section under **Linker**, as well as the `OpenGL32.lib`
    file. It can be linked statically, in which case, `glew32s.lib` needs to be added
    instead of the regular `glew32.lib`. If linking statically, the `GLEW_STATIC` **Preprocessor
    Definition** in the **Preprocessor** section under **C/C++** needs to be added
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Using GLEW
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we are going to need if we are working with OpenGL is a window.
    Luckily, window creation isn''t OpenGL specific, so one can be made using almost
    any library out there that supports it, including SFML. For our purposes, we''ll
    be reusing the Window class with some minor adjustments to it, including the actual
    SFML window type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the data type of the `m_window` data member. If actual SFML is not used
    to draw anything, we do not need an instance of `sf::RenderWindow` and can instead
    work with `sf::Window`. This means that any task that does not have anything to
    do with the actual window has to be handled separately. This even includes clearing
    the window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here we get a glimpse at the first two GL functions we are going to be using.
    Because GLEW is a C API, code that looks like this will be quite common. There
    are no classes to manage, as every task is performed via function calls and a
    shared state. Case in point, our first function `glClearColor()` actually sets
    up the color that the screen will be cleared with, including the alpha channel.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This specific function, as well as many others, takes in what is known as a
    **normalized** vector. It is useful when representing proportion. For example,
    clearing the screen to the color purple would mean passing the value *0.5f* as
    the first and the third parameter, which would mean half of the colour is red,
    and the other half is blue.
  prefs: []
  type: TYPE_NORMAL
- en: The second function call actually performs the clearing with the stored value.
    It takes in a single argument, which is essentially just a bitmask, defined using
    the `#define` pre-processor directive. This specific implementation detail allows
    more masks to be passed into the function call by utilizing **bitwise** or operations,
    represented by the pipe *|* symbol. This concept will be revisited by us eventually.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that out of the way, let us actually create the window and initialize
    the `GLEW` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: All we need to do in order to initialize GLEW is to call a single function `glewInit()`.
    It returns a value, which represents the success/failure of the operation. Another
    useful function to keep around is `glGetString()`. It returns a static string
    that represents specific information about the OpenGL version that is supported
    by the computer it is executed on. In this case, we specifically want to check
    the version of OpenGL and print it out, but it can also be used to determine the
    OpenGL extensions, the supported GLSL version, the name of the hardware rendering
    platform, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The rendering pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When drawing something on the screen, a certain sequence of steps must be followed
    in order to submit the geometry, convert it to pixels, and color them all appropriately.
    This particular sequence of steps is often referred to as the **rendering pipeline**.
    How it functions depends entirely on the version of OpenGL you are using. Versions
    below *3.0* use what is called a **fixed function pipeline**, while newer OpenGL
    releases of *3.0 +* utilize the **programmable pipeline**. The former is now deprecated
    and is referred to as **legacy** OpenGL, while the latter is widely used and applied,
    even on mobile devices, and has become the standard.
  prefs: []
  type: TYPE_NORMAL
- en: Fixed function pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Actually drawing things on screen with the fixed function pipeline is much
    easier than the modern way of doing things, but it comes at a price. Consider
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This particular block of code is quite easily readable, which is one advantage
    of the legacy method. We begin by invoking the `glBegin()` method and passing
    in a value, which signifies how the actual vertices should be interpreted as they
    are being submitted. We are working with triangles, which means that every three
    vertices submitted in a row will be connected and turned into a triangle. Note
    the calls to `glColor3f` as well. The color of the vertices is set as they are
    being submitted, and the same can be done with texture coordinates as well. The
    final call to the `glEnd()` method flushes all of the submitted data to the GPU
    for rendering.
  prefs: []
  type: TYPE_NORMAL
- en: While this is very readable and easy to understand for newcomers, the vertex
    data has to be resubmitted to the GPU every frame, which heavily impacts performance.
    Small applications would not notice the difference, but the memory transfer overhead
    really starts to add up after a significant number of primitives have been submitted.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue with this approach is how limited it is. Certain effects, if at
    all possible, can be extremely slow to pull off with the fixed function pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Programmable pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the programmable pipeline is quite a bit more complicated for small tasks,
    but it proves invaluable for larger projects. Just like the fixed function pipeline,
    there are steps that are static and unchanging. The programmable pipeline does,
    however, provide a way to customize certain aspects of how the data submitted
    to the GPU is processed. This is where **shaders** come in. Shaders have already
    been briefly covered in the previous chapter; however, there is much more to them
    that has not yet been explained. They are the programs that can be written in
    a C-like language and executed on the GPU instead of the CPU. As it turns out,
    shaders are used to customize certain parts of the programmable pipeline. Consider
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Programmable pipeline](img/image_07_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Just like the fixed-function pipeline, vertex data is submitted to the GPU.
    However, this data is not re-submitted every frame. Instead, the vertex data lives
    on the GPU and can be referred to when it needs to be rendered. Once a call has
    been made to draw a specific set of vertices, they're passed in to be processed
    and relayed to the vertex shader.
  prefs: []
  type: TYPE_NORMAL
- en: The **Vertex shader** is one of few programmable bits of this pipeline. It is
    often used to calculate the positions of vertices in the appropriate coordinate
    system, and pass these vertices down the pipeline to be processed further.
  prefs: []
  type: TYPE_NORMAL
- en: The **Tessellation** stage essentially is responsible for performing sub-divisions
    of our existing geometry into smaller primitives. It actually ends up connecting
    the vertices and passing these primitives further down the pipeline. There are
    two shaders in this stage that can be written and used; however, we are not going
    to be doing that.
  prefs: []
  type: TYPE_NORMAL
- en: All of the primitive data is then passed down to a **Geometry shader**, which
    just like the two tessellation shaders is optional. It can be used to generate
    more vertices from the existing geometry.
  prefs: []
  type: TYPE_NORMAL
- en: After the primitives have been properly assembled, they are passed further down
    and handled by the rasterizer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rasterization** is the actual process of turning vertex and primitive information
    into pixel data. These pixels are then passed further down the pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: The last programmable bit of this pipeline receives all of the pixel information
    from the previous stage. It is called the **Fragment shader** (that is, pixel
    shader), and can be used to determine the value of each individual pixel within
    the geometry we are rendering. Anything from assigning specific colors, to actually
    sampling pixels of a texture is done at this stage. These pixels are then pushed
    further down to be handled by other stages.
  prefs: []
  type: TYPE_NORMAL
- en: The **Depth & Stencil** stage performs various tests in order to clip unneeded
    pixels that should not be drawn on screen. If a pixel is outside of the window
    area or even behind another bit of geometry, it is dropped at this stage.
  prefs: []
  type: TYPE_NORMAL
- en: Unclipped pixels are then blended onto the existing frame buffer, which is used
    to draw everything on screen. Before they are blended, however, the **Dithering**
    process takes place, making sure pixels are correctly rounded up or down if the
    render image has less or more precision than the value we have.
  prefs: []
  type: TYPE_NORMAL
- en: Although it may be hard to grasp this concept at first, the programmable pipeline
    is a superior approach to modern rendering. Out of all of these stages covered,
    we only really need to write the vertex and fragment shaders to get started. We
    will be covering that very soon.
  prefs: []
  type: TYPE_NORMAL
- en: Storing and drawing primitives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All of our primitive data has to be represented as a set of vertices. Whether
    we are dealing with a triangle or a sprite on screen, or if it is a huge, complex
    model of a monster, it can all be broken down to this fundamental type. Let us
    take a look at a class that represents it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it is only a simple `struct` that holds a 3D vector that represents
    a position. Later on, we might want to store other information about a vertex,
    such as texture coordinates, its color, and so on. These different pieces of information
    about a specific vertex are usually referred to as **attributes**. For convenience,
    we are also enumerating different attributes to make the rest of our code more
    clear.
  prefs: []
  type: TYPE_NORMAL
- en: Vertex storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before any primitives can be drawn, their data must be stored on the GPU. In
    OpenGL, this task is achieved by utilizing **Vertex Array Objects** (**VAO**)
    and **Vertex Buffer Objects** (**VBO**).
  prefs: []
  type: TYPE_NORMAL
- en: A vertex buffer object can simply be thought of as space that gets allocated
    on the GPU for storing data. That data can be anything. It could be vertex positions,
    colors, texture coordinates, and so on. We are going to use VBOs to store all
    of our primitive information.
  prefs: []
  type: TYPE_NORMAL
- en: A vertex array object is like a parent to a VBO, or even multiple VBOs. It stores
    information about how data that lives inside a VBO should be accessed, how information
    can be passed into various shader stages, and many more details that together
    form a state. If a VBO is the actual data pool, a VAO can be thought of as an
    instruction set of how to access that data.
  prefs: []
  type: TYPE_NORMAL
- en: Both VAO and VBO instances are identified by simple integers, which get returned
    after the space is allocated. These integers will be used to differentiate different
    buffers and array objects.
  prefs: []
  type: TYPE_NORMAL
- en: The model class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With that bit of information out of the way, we can finally get down to actually
    implementing a model class! A model, in our case, is any set of triangles that
    can form a shape. With enough triangles, any shape can be modelled. Let us take
    a look at the class header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can tell, it is quite simple. The constructor takes in two arguments
    for now: a pointer to the first instance of a vertex, and the number of vertices
    we are actually submitting. This makes it easy for us to load a model quickly
    from a simple array of vertices, although it may not be the best way of loading
    more complex meshes.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the class also has a `Draw()` method, which will be used later on
    to actually submit its vertices to the rendering pipeline and begin the drawing
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we have the two *GL unsigned integer* types: `m_VAO` and `m_vertexVBO`.
    These integers will refer to the actual vertex array object that is used with
    this model, as well as the vertex buffer object, used to store all of the vertex
    information. We also have an *unsigned integer*, `m_drawCount`, which is going
    to store the number of vertices this particular model has in order to draw them
    all.'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the model class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With that out of the way, let us begin allocating and filling in our data structures!
    The constructor of the `GL_Model` class is going to be helping us with that task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We begin by copying the amount of vertices to the `m_drawCount` data member.
    This is going to be useful later, as we need to know exactly how many vertices
    need to be drawn before actually rendering them. Some space for a VAO is then
    allocated, using the `glGenVertexArrays` function. Its first argument is the amount
    of objects that need to be created, while the second one takes a pointer to a
    variable that is going to store the returned identifiers.
  prefs: []
  type: TYPE_NORMAL
- en: The next function call, `glBindVertexArray()`, actually enables a vertex array
    object with the provided identifier, so that any subsequent function call after
    this one modifies the vertex array object that was passed in as the argument.
    Any vertex array object manipulation from this point on will be performed on the
    VAO with the identifier, `m_VAO`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because GLEW is a C API, the idea of binding and unbinding something dominates
    most aspects of it. In order to modify or do anything with certain data that lives
    on the GPU, the appropriate buffer must be bound first.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the VAO, the vertex buffer object also needs to be generated. The
    function `glGenBuffers` does just that. In this case, we only need one buffer
    object, which is what the first argument denotes. Once it is generated, just like
    the VAO, we need to bind to this buffer in order to modify it. This is where the
    `glBindBuffer` function comes in. As it is bound to, we also need to specify the
    type of buffer we are going to treat it as. Because we just want an array of data,
    `GL_ARRAY_BUFFER` is used.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a buffer created, we can push some data to it! A call to `glBufferData`
    does just that. The first argument, just like the previous function, determines
    what kind of buffer we are dealing with. The second argument is the **byte** size
    of the data chunk we want to submit, which OpenGL has to know in order to allocate
    enough space for the buffer to hold all of the data. In this case, it is just
    the number of vertices multiplied by the number of bytes the first element takes
    up. The third argument is just a pointer to the actual data structure we want
    to submit. How much of that is read in is determined by the second argument, which,
    in this case, is all of it. Finally, the last argument is used as a hint for OpenGL
    to manage the data storage as efficiently as possible depending on its use. It
    stores the data differently depending on what we do with it. `GL_STATIC_DRAW`
    means we are not going to be modifying the data, so that it can store it a certain
    way that is most efficient for this situation.
  prefs: []
  type: TYPE_NORMAL
- en: With all of the data buffered, we can begin working with the VAO again and give
    it information about how the vertex information should be accessed. Because the
    vertex position has to be passed to the fragment shader, we need to enable it
    as an attribute and store information about how it should be processed in the
    VAO. This is where `glEnableVertexAttribArray()` and `glVertexAttribPointer()`
    functions come in.
  prefs: []
  type: TYPE_NORMAL
- en: 'The former function simply enables a certain attribute to be used by the vertex
    shader. `VertexAttribute::Position` evaluates to `0`, so the *0th* attribute in
    the vertex shader is enabled for use. The latter, however, actually specifies
    how this data is read and processed before it gets piped down the vertex shader.
    In this case, the *0th* attribute is defined as a set of three variables, all
    of which are floats. The next argument can be useful if we want to normalize the
    data before it gets sent to the vertex shader. In this case, we do not need to
    do that, so `GL_FALSE` is passed in instead. The last two arguments are the byte
    stride and byte offset of the data we are interested in inside the buffer. Because
    we are only storing the vertexes position inside the `GL_Vertex` structure so
    far, both of these values are `0`. However, what would happen if we had more attributes?
    Consider the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the model class](img/image_07_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Imagine we have all of the data inside a buffer, which was shown previously.
    For each vertex in there, its position is followed by its color, and then by another
    vertexes position. If we just want to filter out the position data, for example,
    stride and offset can be very useful. The stride argument is the number of bytes
    that have to be jumped from the beginning of one data segment to another. Effectively,
    stride can be thought of as the size of the entire vertex's data structure, which,
    in this case, is the sum of the size of the position vector, as well as the color
    vector. To put it simply, it's the number of bytes from the beginning of one vertex,
    to the beginning of another.
  prefs: []
  type: TYPE_NORMAL
- en: Offset, on the other hand, is just the number of bytes we need to move from
    the beginning of whichever structure we happen to be reading in order to reach
    the desired element. Accessing the color element would mean the offset would have
    to be the size of the position vector. To put it simply, the offset is the number
    of bytes from the beginning of the structure to the beginning of the desired element.
  prefs: []
  type: TYPE_NORMAL
- en: After our data is submitted and accounted for, we can use `glBindVertexArray`
    again to bind to *0*, which would show that we're done with the VAO.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of this allocated data actually has to be disposed of when it''s no longer
    needed. The destructor can help us here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: First, the vertex buffer object needs to be disposed of. We pass the number
    of VBOs, as well as the pointer to the first identifier to the `glDeleteBuffers`
    function, which purges all of the buffer data on the GPU. The VAO follows a similar
    procedure afterwards.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can implement the `Draw` method of our `Model` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Before drawing something, we need to specify which data the pipeline should
    use. All of the vertex information sits safely in our buffer object that is managed
    by the VAO, so we bind it. The `glDrawArrays` function is then invoked. As the
    name states, it draws arrays of vertices. Its first argument is the type of primitive
    we want to draw, which in this case is triangles. Lines, points, and other types
    can also be drawn like this. The second argument is the starting index inside
    the buffer array object. Since we want to draw everything from the beginning,
    this is set to *0*. Lastly, the number of vertices to be drawn is passed in. The
    call to this function actually initiates the rendering pipeline, sending all of
    the vertex data into the vertex shader. The final call is to the `glBindVertexArray()`
    function that simply unbinds our VAO.
  prefs: []
  type: TYPE_NORMAL
- en: Using shaders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The standardization of the programmable pipeline now means shaders have to be
    written for certain tasks, including the basic ones. This means that simply submitting
    our vertex data and rendering it would do nothing, as the two fundamental chunks
    of the rendering pipeline, the vertex and fragment shaders, are non-existent.
    In this section, we are going to cover how shaders are loaded, built, and applied
    to our virtual geometry, in turn producing those glorious pixels on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: Loading shader files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can use shaders, we must first discuss how they are loaded. All we
    technically need to create a shader is a string, containing all of its code. A
    very simple helper function can be written to parse a file and return it as a
    string, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This is nothing we have not seen before, when it comes to file reading and parsing.
    A string is created, then appended to with each new line of the file being read,
    and finally returned.
  prefs: []
  type: TYPE_NORMAL
- en: Creating shader programs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenGL shaders themselves are part of programs that are used throughout the
    rendering pipeline. If we have a vertex shader and a fragment shader we wish to
    utilize, both of them are actually joined into one program, which is then bound
    to so that the pipeline can use the appropriate shader at the right time. This
    is important, because it shapes the way the `GL_Shader` data structure is built:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: First, we enumerate the shader types we are going to be using. For basic purposes,
    vertex and fragment shaders are more than enough.
  prefs: []
  type: TYPE_NORMAL
- en: The constructor of the class takes a filename of the shader(s) we are going
    to be loading. There is also a `Bind()` method, which will be used to enable a
    specific shader program before rendering begins.
  prefs: []
  type: TYPE_NORMAL
- en: We also have two static helper methods, used for printing out errors inside
    shaders, and actually building them. Yes, shaders need to be compiled and linked
    before they can be used, much like C/C++.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need two *GL unsigned integer* data members, the latter of which
    is an array. The first integer is going to represent the shader program, which
    contains all attached shaders. The array of integers keeps track of identifiers
    of all types of shaders that are in the program.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the shader class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let us get down to actually creating some shaders! As always, a good place
    to start is the constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Before any shader compilation is done, we first need to have the actual source
    code loaded in memory. OpenGL does not do this for you, so we are going to be
    utilizing the `ReadFile` function implemented earlier. Once both types of shaders
    are loaded and checked for not being empty, a new shader program is created using
    `glCreateProgram()`. It returns an identifier that we need to keep track of if
    we want to use the shaders when rendering.
  prefs: []
  type: TYPE_NORMAL
- en: For the actual vertex and fragment shaders the static `BuildShader()` method
    is invoked, and the returned identifier is stored inside the `m_shader` array
    for the relevant type of shader. Note the `GL_VERTEX_SHADER` and `GL_FRAGMENT_SHADER`
    definitions being passed to the method call. These are the shader types OpenGL
    needs in order to build the shaders.
  prefs: []
  type: TYPE_NORMAL
- en: After the shaders have been built, they need to be attached to our created program.
    For this we can simply use a loop and invoke `glAttachShader`, which takes the
    ID of the program, as well as an ID of the shader to be attached to said program.
  prefs: []
  type: TYPE_NORMAL
- en: Shaders need to have some sort of input as they are being executed. Remember
    that our model rendering begins with a binding to a VAO, which holds the information
    about how certain attributes of a VBO should be accessed, followed by a draw call.
    In order for the data feeding to work properly, our shader class needs to bind
    a name and attribute location. This can be done by calling `glBindAttribLocation`,
    and passing in the ID of the program, the actual attribute location, which is
    enumerated as `VertexAttribute`, and the name of the attribute variable that's
    going to be used inside the shader program. This step ensures that the data being
    fed into the vertex shader will be accessible through a *position* variable. This
    will be covered more in the *Writing basic shaders* section.
  prefs: []
  type: TYPE_NORMAL
- en: After the shaders are built and have their attributes bound, all we have left
    is linking and validation, the latter of which determines if the shader executable
    can run given the current OpenGL state. Both `glLinkProgram` and `glValidateProgram`
    simply take the ID of the program. After each of these function calls, we also
    invoke the other static helper method, `CheckError`. It is responsible for actually
    fetching a string of information, pertaining to any sort of errors during the
    linking and compilation stages. This method takes in the program ID, a flag that
    is used to determine what stage of the shader building process we are actually
    interested in, a *Boolean* value that signifies whether the whole shader program
    is being checked or if it is just an individual shader, and a string to be split
    out into the console window before the actual error is printed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Shaders, just like any resource, need to be cleaned up once we are done with
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the `ShaderType` enumeration, we know exactly how many shader types
    we support, and so we are able to simply run a loop for each one during cleanup.
    For each shader type, we must first detach it from the shader program using `glDetachShader`,
    which takes the program ID and the shader ID, and then deletes it using `glDeleteShader`.
    Once all the shaders are removed, the program itself is deleted through the `glDeleteProgram()`
    function call.
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed previously, OpenGL operates using function calls and a shared
    state. This means that certain resources such as shaders, for example, must be
    bound to before being used for rendering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In order to use a shader for a specific set of primitives to be drawn, we simply
    need to call `glUseProgram` and pass in the ID of the shader program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us take a look at one of our helper methods, used to determine if there
    were any errors during the various stages of the shader program setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'First, a few local variables are set up for storing the state information:
    a success flag, and a buffer for an error message to be put in. If the `l_program`
    flag is true, it means we are trying to fetch information about the actual shader
    program. Otherwise, we are only interested in an individual shader. To obtain
    the parameter that signifies success or failure of link/validation/compilation
    stages of a shader/program, we need to use `glGetProgramiv` or `glGetShaderiv`.
    Both of them take an ID to a shader or program being checked, a flag of the parameter
    we are interested in, and a pointer to the return value that is to be overwritten
    with either `GL_TRUE` or `GL_FALSE` in this case.'
  prefs: []
  type: TYPE_NORMAL
- en: If whichever stage of the shader building process we are interested in finished
    successfully, we simply return from the method. Otherwise, we invoke either  `glGetProgramInfoLog()`
    or `glGetShaderInfoLog()` to fetch the error information of the program or individual
    shader. Both of these functions take the identifier of either the program or shader
    being checked, the size of the error message buffer we have allocated, a pointer
    to a variable that would be used to store the length of the string returned, which
    we do not really need so `nullptr` is passed in, and a pointer to the error message
    buffer that is to be written to. Afterwards, it is as simple as printing out our
    `l_errorMsg` prefix, followed by the actual error written to the `error` message
    buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last, but definitely not least, let us see what it takes to build an individual
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'First, an individual shader has to be created using the `glCreateShader()`
    method. It takes in a shader type, such as `GL_VERTEX_SHADER`, which we used in
    the constructor of this class. If, for some reason, the shader creation failed,
    an error message is written to the console window and the method returns a `0`.
    Otherwise, two arrays of GL types are set up: one for the sources of potentially
    multiple shaders, and one for the lengths of each source string. For now we''re
    only going to be dealing with one source per shader, but it is possible to handle
    multiple sources later on, should we ever want to.'
  prefs: []
  type: TYPE_NORMAL
- en: After the source code and its length have been written to the arrays we just
    set up, `glShaderSource` is used to submit the code to a buffer before it gets
    compiled. The function takes in the ID of the newly created shader, the number
    of source strings we're passing in, a pointer to the source array, as well as
    a pointer to the source length array. The shader is then actually compiled using
    `glCompileShader`, and the `CheckError` helper method is invoked to print out
    any possible compilation errors. Note the `GL_COMPILE_STATUS` flag being passed
    in, as well as the false flag, showing that we're interested in checking the status
    of an individual shader, rather than the whole shader program.
  prefs: []
  type: TYPE_NORMAL
- en: Writing basic shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As our `GL_Shader` class is done, we can finally get to write some basic shaders
    for our application! Let us get started by taking a look at a file named `basic.vert`,
    which is our vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: First, we set up the `attribute` of the shader that is going to be written to
    by OpenGL. It is an attribute of type `vec3`, and is going to represent our **vertex
    position** information that gets fed into this shader one by one. This type was
    set up inside the `GL_Model` class constructor using the `glVertexAttribPointer`,
    and then named in the `GL_Shader` class constructor, using the `glBindVertexAttribLocation`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: The body of the shader has to have a main function, where all of the magic happens.
    In this case, all we need to do is set the internal OpenGL variable `gl_Position`
    to the position we want our vertex to have. It requires a `vec4` type, so the
    position attribute is converted to it, with the last vector value, which is used
    for clipping purposes, being set to `1.0`. For now, we do not need to worry about
    this. Just keep in mind that the actual vertex position in normalized device coordinates
    (coordinates in a range of *(-1,-1)* and *(1,1)*) are set here.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note the version number on the very first line. If your computer does not support
    OpenGL 4.5, this can be changed to anything else, especially because we are not
    doing anything that older versions do not support.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the vertex information is processed, we also need to worry about shading
    the individual pixels that make up our geometry correctly. This is where the fragment
    shader comes in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This shader also uses an internal OpenGL variable. This time it is named `gl_FragColor`,
    and, predictably enough, is used for setting the color of the pixel we are processing.
    For now, let us just shade all of the pixels of our geometry white.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing our first triangle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have our model class that handles all of the geometry data, as well as the
    shader class, which deals with processing our data at various points of the programmable
    rendering pipeline. With that out of the way, all we have left to do is actually
    set up and use these classes. Let us start by adding them as data members to the
    `Game` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'They can then be set up in the constructor of our `Game` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'First, the shader class is created and a path with a filename is passed to
    it, so that the `basic.vert` and `basic.frag` shaders inside the `GL` directory
    of our executable directory can be loaded. An array of vertices is then set up,
    with each one being initialized to a particular position in normalized device
    coordinates. This particular arrangement creates three vertices in the middle
    of the screen, which will be connected into a triangle. The coordinates here fall
    within the range of what is known as **normalized device coordinates**. It is
    the coordinate system that the window uses, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Drawing our first triangle](img/image_07_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A `GL_Model` object is then created, with the vertex array and vertex count
    being passed in as arguments. The `GL_Model` then goes on to push this data to
    the GPU, as discussed previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, let us take a look at how we can render our triangle on screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'After the window is cleared inside the `BeginDraw()` method, the shader program
    is bound to, so that the vertex and fragment shaders we wrote earlier are used
    when the vertex data of our `GL_Model` is being pushed through the rendering pipeline.
    The models `Draw()` method is then invoked, to begin the rendering process. After
    successful program compilation and execution, this is what we should see on screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Drawing our first triangle](img/image_07_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Hooray! After about 20 pages of theory, we have a triangle. This may be a little
    bit discouraging, but keep in mind that everything from this point on is going
    to get much, much easier. Congratulations on making it this far!
  prefs: []
  type: TYPE_NORMAL
- en: Using textures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A basic, white triangle is not very exciting to look at. The next obvious improvement
    to make to our code is making textures available to the fragment shader, so that
    they can be sampled and applied to our geometry. Unfortunately, OpenGL does not
    provide a way of actually loading image data, especially since there are so many
    different formats to keep up with. For that, we are going to use one of our resources
    listed at the beginning of this chapter, the STB image loader. It is a small,
    single header C library, used to load image data into a buffer that can later
    be used by OpenGL, or any other library for that matter.
  prefs: []
  type: TYPE_NORMAL
- en: The texture class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember the remark that everything is going to get much easier at this point?
    It is true. Let us breeze through the texturing process, starting with a class
    definition for a texture object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Although OpenGL does not actually handle loading texture data, it is still going
    to be handled within the confines of this class. Because of that, the constructor
    of our texture class is still going to take a path to the texture file to be loaded.
    Also, much like the shader class, we are going to need to bind to a specific texture
    before it can be used when rendering geometry. For now, ignore the argument it
    takes. It will be explained down the line.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenGL textures, just like shaders or geometry data, have to be stored on
    the GPU. Because of that, it stands to reason that texture data will be referred
    to by a `GLuint` identifier, just like shaders or buffers.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the texture class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let us take a look at what needs to be done in order to successfully load textures
    from the hard disk, and push them into the GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: First, a few integers are created in order to be filled in with information
    about the texture that is going to be loaded. We then invoke the `stbi_load()`
    function, which is part of the STB image loading library, passing in a path to
    the texture file, pointers to the width, height, and the component count variables
    that are about to be written to, as well as the number of components the file
    is expected to have. The data is stored in the form of an *unsigned char*, a pointer
    to which is returned by the `stbi_load()` function. If `nullptr` was returned,
    we obviously need to return, as the loading process failed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of components an image has is simply the number of color channels.
    Passing in a value of 0 would mean the image data is loaded as is, while any other
    value *forces* the data to contain other color channel information. The component
    number to channel configuration can be evaluated like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Components** | **Channels** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Gray |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Gray, alpha |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Red, green, blue |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Red, green, blue, alpha |'
  prefs: []
  type: TYPE_TB
- en: From this point on, we follow what should be a familiar pattern by now. First,
    a texture object is generated using `glGenTextures`, to which the number of textures
    we want is passed as the first argument, and the pointer to the texture identifier
    or a list of them as the second argument. We then bind to the newly created texture
    using `glBindTexture`. The first argument of this function simply lets OpenGL
    know what kind of texture we are dealing with. In this case, `GL_TEXTURE_2D` is
    used, because it is a basic 2D image.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenGL supports a myriad of different types of textures for various tasks, including
    3D textures, cube maps, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a texture is bound to, we can manipulate various details it comes with.
    For textures, the parameter manipulation function is named `glTexParameter()`.
    There are many different types of this single function, all with different suffixes
    that give a hint to the programmer of what data type it is expecting. For our
    purposes, we are going to be using two types: *integer* and *float*, appropriately
    ended by letters *i* and *f*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first two lines deal with defining behavior for cases when texture data
    is being read outside of the boundaries of its size, that is, how the texture
    is wrapped. The `GL_TEXTURE_WRAP_S` parameter deals with wrapping on the *X* axis,
    while the `GL_TEXTURE_WRAP_T` parameter deals with the *Y* axis. Why *S* and *T*
    you may ask? The answer to that is simple. Positional vectors, color data, and
    texture coordinates are enumerated differently, but they both mean roughly the
    same thing. Consider the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | 1 | 2 | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Position | X | Y | Z | W |'
  prefs: []
  type: TYPE_TB
- en: '| Color | R | G | B | A |'
  prefs: []
  type: TYPE_TB
- en: '| Textures | S | T | P | Q |'
  prefs: []
  type: TYPE_TB
- en: They are all vectors of four values. Accessing the position *X* value is the
    same as accessing the red channel of a color structure, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The next two function calls deal with how the texture is interpolated when being
    sized down or up. Both cases specify the `GL_LINEAR` parameter, which means the
    pixels will be linearly interpolated.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we actually submit the loaded pixel information to the GPU by invoking
    the `glTexImage2D()` method. Its first argument, once again, lets OpenGL know
    what type of texture we are submitting. The second argument is the texture's level
    of detail, which will be used for mip-mapping. The value `0` simply means it is
    the base level texture.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mip-mapping is an optional technique that can be utilized by OpenGL, in which
    multiple versions of the same texture, but of different resolutions, are loaded
    and submitted to the GPU, and later applied to geometry depending on how far it
    is from the viewer. If it is further away, a lower resolution texture (with a
    higher mip-mapping level) is used. This can be done for performance reasons, when
    necessary.
  prefs: []
  type: TYPE_NORMAL
- en: The third argument lets OpenGL know what arrangement the pixel information data
    is in. This is necessary, because certain formats may store it in varying configurations.
    The width and height information is passed in next, along with a number of pixels
    that can be used to add a border to the texture. We are not going to be using
    that feature, which is why `0` is passed in. The next argument is, once again,
    a flag for a certain arrangement of pixels. This time it lets OpenGL know which
    arrangement we want it to store the pixel data in. Finally, a flag for the type
    that our loaded texture is in is passed, along with a pointer to the actual texture
    data. We are using the `GL_UNSIGNED_BYTE` parameter, because that is what the
    STB image loader returns, and the *char* type is exactly one byte long.
  prefs: []
  type: TYPE_NORMAL
- en: After the texture information is submitted to the GPU, we no longer need to
    keep the image data buffer around. It's destroyed by calling `stbi_image_free`,
    and passing in the pointer to the buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data we submitted to the GPU needs to be released once we no longer need
    the texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `glDeleteTextures` function takes the number of textures we want to dispose
    of, as well as a pointer to an array of *GLuint* identifiers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s implement the `Bind()` method, which is going to give us the
    ability to use the texture when rendering:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: OpenGL actually supports the ability for multiple textures to be bound all at
    once while rendering, so that complex geometry can be textured more efficiently.
    The exact number, at least at the time of writing, is `32` units. Most of the
    time we are not going to need that many, but it is nice to have the option. The
    identifier of the unit we want to use is passed in as an argument to the `Bind()`
    method. In order to avoid confusion, we are going to perform an `assert()` method
    and make sure that the `l_unit` value is in the right range first.
  prefs: []
  type: TYPE_NORMAL
- en: In order to enable a specific unit for a texture, the `glActiveTexture()` method
    needs to be called. It takes a single argument, which is the enumerated texture
    unit. It ranges from `GL_TEXTURE0` all the way to `GL_TEXTURE31`. Because those
    values are sequential, a neat trick is to simply add the `l_unit` to the `GL_TEXTURE0`
    definition, which will give us the right unit enumeration. After that, we simply
    bind to the texture as before, using the `glBindTexture()` method and passing
    in the type of texture we have, along with its identifier.
  prefs: []
  type: TYPE_NORMAL
- en: Model and shader class changes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To add support for textured geometry, we first need to make some changes to
    the vertex information that gets stored. Let us take a look at the `GL_Vertex`
    structure to see what needs to be added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we need an additional vertex attribute, which is the coordinate
    of the texture a vertex is associated with. It is a simple two-dimensional vector
    that represents the texture coordinates, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Model and shader class changes](img/image_07_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The great thing about representing texture coordinates in this fashion is the
    fact that it makes the coordinates resolution-independent. A point *(0.5,0.5)*
    on a smaller texture is going to be the exact same point on its larger counterpart.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we now have more information about a single vertex that needs to be
    stored and accessed, the VAO needs to know exactly how to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We now get to utilize the stride and offset parameters that were discussed previously!
    The stride is, of course, the full size of a `GL_Vertex` structure, while the
    offset to obtain texture coordinates is the size of the vertex position vector,
    because that is the amount by which the pointer needs to be offset.
  prefs: []
  type: TYPE_NORMAL
- en: After the data is submitted to the buffer, we enable the vertex position attribute
    and provide its pointer with the `stride`. The offset remains `0`, because `Position`
    is the first attribute.
  prefs: []
  type: TYPE_NORMAL
- en: We also need to enable the `TexCoord` attribute, because it will be passed to
    the shaders as well. Its pointer is set up similarly to that of position, except
    we have `2` floats instead of `3`, and the offset now needs to be applied, so
    that the position data is skipped.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note the `void*` cast for the last argument. This is because the offset actually
    takes a pointer, rather than a number of bytes. It is one of the leftover *legacy*
    details, and only means the number of bytes in newer versions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final change to our C++ code pertains to updating the `GL_Shader` class,
    in order to register the new attribute that is going to be passed in to the vertex
    shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: It simply establishes a name for our texture coordinate attribute, which is
    now `"texCoordVert"`.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the shaders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The actual sampling of the texture takes place inside the fragment shader.
    However, as the data is actually received in the vertex shader first, let us see
    how it needs to be updated to cater to our needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `texCoordVert` attribute is established here, along with
    a `varying` 2D vector named `texCoord`. A varying type simply means that its data
    is going to be passed down the rendering pipeline and received by the next shader
    in line. In our case, `texCoord` is going to be accessible inside the fragment
    shader. Its value is set to the input attribute of `texCoordVert`. Why? Because
    varying data received by any shader down the line is **interpolated**. That''s
    right. Take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Updating the shaders](img/image_07_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to accurately sample color information for each pixel of our geometry,
    we do not really need to do any math by ourselves. Interpolation, or weighted
    averaging, takes care of that for us. If one vertex has texture coordinates of,
    let''s say **(1,1)**, and the opposite vertex has the coordinates **(0,0)**, the
    fragment shader executing on a pixel somewhere in between those vertices will
    receive the **interpolated** value of **(0.5, 0.5)**. This makes coloring a pixel
    as easy as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: First, note the `uniform` variable of type `sampler2D`, called `texture`. We
    do not need to manually pass this into our shaders as it is done behind the scenes.
    It simply provides access to the data of the current texture that it is bound
    to. Next, we set up the varying variable `texCoord`, which completes the *piping*
    of data from the vertex shader to the fragment shader. The fragment color is then
    set to a `vec4`, which gets returned from the `texture2D()` function that takes
    in the texture received by the fragment shader, as well as the coordinates we
    want to sample. Since the `vec4` that gets returned represents the color of the
    pixel, that is all that it takes to texture geometry!
  prefs: []
  type: TYPE_NORMAL
- en: Using a texture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Applying the texture to our geometry is quite simple at this point. First,
    the `GL_Texture` class needs to be added as a data member to the `Game` object.
    We can then proceed to set everything else up as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `GL_Vertex` objects now take an additional argument, which represents the
    texture coordinates of the vertex. We also load the brick texture in the constructor,
    which is then bound to in the `Render()` method, right before the shader. When
    our model is rendered, it should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using a texture](img/image_07_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We now have a motionless model with a texture applied. Still not very exciting,
    but we are getting there!
  prefs: []
  type: TYPE_NORMAL
- en: Applying transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Moving, rotating, and otherwise manipulating vertex data may seem quite straight
    forward. One may even be tempted to simply update the vertex position information
    and simply resubmit that data back to the VBO. While things may have been done
    that way for a while in the past, there are much more efficient, albeit more math-intensive
    ways of performing this task. Displacing vertices is now done in the vertex shader
    by simply multiplying the vertex positions by something called a **matrix**.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix basics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Matrices are extremely useful in graphics programming, because they can represent
    any kind of rotation, scale, or displacement manipulation that can be applied
    to a vector. There are many different types of matrices, but they are all just
    blocks of information that look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix basics](img/image_07_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This particular matrix is a 4x4 identity matrix, but a variety of differently
    sized matrices exist, such as 3x3, 2x3, 3x2, and so on. There are rules when it
    comes to adding, subtracting, multiplying, or dividing them. We are not really
    going to get into that as it is beyond the scope of this chapter. The nice thing
    is that the `glm` library abstracts all of this away for us, so it is not absolutely
    necessary to know much about this for now. A thing to take away from this is that
    positional vectors can be transformed when added to or multiplied by matrices.
  prefs: []
  type: TYPE_NORMAL
- en: The world space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Up until this point, we have been working with vertex positions that are specified
    in the normalized device coordinate space. This means that each vertex coordinate
    is actually relative to the center of the screen. In order to properly deal with
    transformations; however, we want to treat our geometry as being relative to an
    origin point that falls within the **model space**, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The world space](img/image_07_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If a model has an origin, it can also have a global position within our world,
    where its origin is relative to some arbitrary point within the game world we
    have constructed. This global position, as well as some other attributes, such
    as the scale and rotation of the object, can be represented by a matrix. Applying
    these attributes to the vertex coordinates that are in model space, which is exactly
    what happens when they are multiplied by the **model matrix**, allows us to bring
    those coordinates into what is known as **world space**, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The world space](img/image_07_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This transformation simply means that the vertices are now relative to the world's
    origin, rather than the model origin, allowing us to accurately represent models
    in our own coordinate system before drawing them on screen.
  prefs: []
  type: TYPE_NORMAL
- en: The transform class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before any transformations can be applied, they should be properly grouped
    together and represented by a single data structure. The `GL_Transform` class
    is going to do exactly that for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: First, note the included headers on top. These are necessary for the data types
    and transformation functions that are going to be used in this class. Outside
    of that, we have three vectors that are going to represent the model's position,
    rotation, and scale, which are going to be used for calculating the model matrix
    that transforms vertices into world coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the transform class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The constructor simply takes in the appropriate arguments and sets up some
    data members using the initializer list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The meat of this class is the `GetModelMatrix()` method, as it deals with all
    the necessary math:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The model matrix is going to be a result of many other matrices being multiplied
    together, thus making it contain all of the necessary transformation information.
    We begin by creating what is known as a **translation matrix**. Calling `glm::translate`
    creates one for us, with the position information of `m_position`. It is used
    to bring the positions of our vertices into world space.
  prefs: []
  type: TYPE_NORMAL
- en: We then create a **scale matrix**, which is responsible for representing scaling
    or shrinking of a model. For example, if a model should be drawn as twice as big
    as it's stored on the GPU, the scale matrix will be used to adjust the positions
    of all vertices to make it look that way. Using `glm::scale` and passing in the
    scale vector as the argument will construct one for us.
  prefs: []
  type: TYPE_NORMAL
- en: The final type of matrix we need is the **rotation matrix**. It obviously represents
    different rotation values of an object, thus displacing all the vertices around
    an origin point. This one, however, is not quite so straightforward due to the
    fact that we are storing rotation information as a vector of **degrees**. Because
    of that, matrices of each axis need to be created using the `glm::rotate` function,
    which takes the degree of rotation, as well as a **directional vector**, representing
    the axis around which the rotation is desired. It simply means setting a value
    of `1` for the *x*, *y*, or *z* component, depending on which axis we are dealing
    with. The final rotational matrix is then calculated by multiplying all three
    previous matrices together. Using a different multiplication order will produce
    different results. Generally, a rule of thumb is to multiply all matrices in reverse
    order of application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can calculate the model matrix by multiplying all previous matrices
    together like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing the transform class](img/image_07_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The resulting model matrix is then returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of this class is fairly straightforward, as there is nothing else
    except setters and getters left:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Updating the shader class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once again, we are going to be using the shader class to submit the necessary
    matrix information to the vertex shader, where it will be used. The reason this
    is done inside the vertex shader is because the GPU is optimized for operations
    like this. Let us take a look at what we need to change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: First, note a new enumeration that we have established. It enumerates all the
    uniform variable types that our shaders need, which, for now, consists of only
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A uniform performs a different task from the usual shader attributes or varying
    variables. Attributes are *filled in* by OpenGL behind the scenes, using data
    from the VBO. Varying shader variables are passed between shaders. A uniform variable
    is actually passed into the shader by our C++ code, which is why we need to treat
    it differently.
  prefs: []
  type: TYPE_NORMAL
- en: The `GL_Shader` class now also needs an `Update()` method, which is going to
    take in a reference to the `GL_Transform` class and use it to pass the model matrix
    to the vertex shader. Lastly, we need to store identifiers that are used to locate
    uniform variables within shaders, so that they can be used. The `m_uniform` data
    member exists for that exact purpose.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how a uniform variable location can be obtained and stored:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, OpenGL provides a nice function for that, called `glGetUniformLocation`.
    It takes an identifier of the program we are using, as well as the name of the
    uniform variable inside the shader, which is `"transform"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting the value of a uniform variable also comes down to a single function
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: First, we obtain the model matrix from the transform class. The `glUniform`
    function is then called. It has a suffix of the exact data type we are submitting,
    which, in this case, is a 4x4 matrix of floats. The uniform ID we stored earlier
    is used as the first argument. The amount of data being submitted is the second
    argument, which in this case is only `1`, as one matrix is being submitted. The
    third argument is a flag that lets us transpose the matrix. We do not need to
    do that, so `GL_FALSE` is passed in. Finally, a pointer to the first element of
    the matrix is passed as the last argument. OpenGL knows exactly how big the matrix
    is, as we are calling the appropriate function, which allows it to read the entire
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we need to modify the vertex shader in order to actually perform the
    transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note the `uniform` of type `mat4` being added. We simply need to multiply it
    by the position in the main function, which gives us our transformed vertex position.
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating the triangle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once again, all we have left to do in order to apply the code we have written
    is add it to the `Game` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'It really does not need any more setting up than that. We can jump straight
    to manipulation of the transform''s properties, by editing the `Update()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we are simply playing around with rotations along all axes. After
    making those modifications, it is important to pass the transform object to the
    `GL_ShaderUpdate()` method, so that the vertices can be properly transformed,
    giving us this resulting rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Manipulating the triangle](img/image_07_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now we are getting somewhere! Still, we have no interaction with the scene.
    This whole time we are just sitting still while the geometry just spins around.
    At best, this is just a very elaborate screensaver. Let's actually implement something
    that will give us some *mobility*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenGL, unlike SFML, does not offer any means of actually moving around the
    view or the camera. While this may seem odd at first, that is mainly because there
    is no camera or view to move around. Yes, you heard that right. No camera, no
    views, just vertex data, shaders, and raw math to the rescue. How? Let's take
    a look!
  prefs: []
  type: TYPE_NORMAL
- en: View projection essentials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All of the rendering and programming trickery that lots of libraries abstract
    away is exactly that - tricks. When it comes to moving around the game world,
    there is no real *camera* that conveniently films the right sides of geometry
    to be rendered. The camera is just an illusion, used to abstract away concepts
    that are not intuitive. Moving around a game world involves nothing else except
    additional matrix math that is performed on the **vertices themselves**. The act
    of rotating the *camera* around the scene simply comes down to the exact opposite
    of that: rotating the scene around a point in space that is referred to as the
    camera. Once again, we are going to be transforming our vertices to be relative
    to yet another point of origin, and this time, it is the camera itself. Consider
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![View projection essentials](img/image_07_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In order to implement the camera class and be able to *move around* the world,
    we need to know a few basics. First of all, we have to decide how wide the view
    angle of the camera should be. This affects how much we can actually see. The
    other important detail is correctly setting up the **view frustum**. Think of
    it as a pyramid shaped piece of geometry that defines the range of the camera's
    view. It determines how close certain things can be until they are no longer seen,
    as well as what's the maximum distance of an object from the camera until it's
    no longer rendered.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aspect ratio of our window, as well as the field of view, near/far distances
    of the view frustum, and the position of the camera all add up to a total of two
    matrices we are going to calculate: the **view matrix** and **projection matrix**.
    The former deals with positioning vertices relative to the camera''s position,
    while the latter adjusts and warps them, which depends on how close or far away
    they are from the view frustum, the field of view, and other attributes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are mainly two projection types we can work with: **perspective** and
    **orthographic**. The perspective projection offers a realistic result where objects
    can appear to be further away from the camera, while orthographic projection is
    more of a fixed depth feel, making objects look the same size regardless of their
    distances. We are going to be using the perspective projection for our purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: The camera class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With all of this information covered, we are finally ready for the smoke and
    mirrors that is the `GL_Camera` class. Let us see what it takes in order to manoeuvre
    around our world:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are storing all of the covered details, as well as a couple
    of new ones. Along with the field of view angle, the aspect ratio, and the near
    and far frustum values, we also need to keep around the position, a forward direction
    vector, and the up direction vector. The `m_forwardDir` is a normalized directional
    vector that represents which way the camera is looking. The `m_upDir` is also
    a normalized directional vector, but it simply stores the *up* direction. This
    will all start to make sense soon.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the camera class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let us see what the constructor of this class looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Outside of initializing our data members, the constructor has three tasks. It
    recalculates the perspective matrix, which only needs to be done once unless the
    window is resized, and it sets up both the forward direction, and the up direction.
    The camera starts out looking towards the positive *Z* axis, which is literally
    *towards* the screen, if you imagine it in those terms. The *up* direction is
    the positive Y axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating the perspective matrix is quite simple, thanks to the `glm` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Our matrix is constructed by the `glm::perspective` function, which takes in
    the field of view, the aspect ratio, and both frustum distances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can obtain the **view projection matrix**, which is simply a combination
    of the view and projection matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We begin by calculating the view matrix, using the `glm::lookAt` function. It
    takes in the position of the camera, the point the camera is looking at, and the
    *up* direction. Afterwards, the multiplication of our perspective matrix and the
    view matrix results in obtaining the view projection matrix, which is returned
    for later use.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the rest of the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Because our geometry needs to, once again, be transformed relative to yet another
    origin, we need to update the `GL_Shader` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Because the vertex shader is already multiplying its position by a transform,
    we can simply change which matrix it uses inside the `Update()` method. After
    the model matrix is obtained, we also grab the view projection matrix and multiply
    the two together. The resulting **model view matrix** is then passed down to the
    vertex shader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the camera needs to be created inside the `Game` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'It also needs to be set up with the appropriate information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We begin by calculating the window's aspect ratio, which is its width divided
    by its height. After the `frustum_near` and `frustum_far` values are set up, they
    get passed in to the camera's constructor, along with its initial position, the
    field of view angle, and the aspect ratio of the window.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we just need to update the shader class with the camera''s information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Upon successful compilation and execution, we should see our triangle slightly
    further away from the camera, because its position was set to `-5.f`on the *Z*
    axis.
  prefs: []
  type: TYPE_NORMAL
- en: Moving the camera around
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having a programmable camera is nice, but it still does not allow us to freely
    roam the scene. Let ''s actually give our camera class the ability to be manipulated
    in real time, so that we can have the illusion of floating around the world:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we are going to use two methods for that: one for moving the
    camera, and another for rotating it. We are also defining a helpful enumeration
    of all six possible directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving a position vector is fairly simple. Assume we have a scalar value that
    represents the speed of the camera. If we multiply it by a direction vector, we
    get a proportional position change based on which direction the vector was pointed
    at, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Moving the camera around](img/image_07_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With that in mind, let us implement the `MoveBy()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: If we are moving the camera forwards or backwards, the `l_amount` scalar value
    is multiplied by the forward direction. Moving the camera up and down is equally
    as simple, since the up direction can be used for that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving left or right is slightly more complex. We cannot just statically change
    the position, because the camera''s idea of *left* or *right* depends on which
    way we are looking. This is where the **cross product** comes in:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Moving the camera around](img/image_07_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The cross product of two vectors is a slightly harder formula to memorize,
    but it is very useful. It gives us a vector that is **orthogonal** to the vectors
    *a* and *b*. Consider the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Moving the camera around](img/image_07_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'An orthogonal vector is one way of saying that the direction of that vector
    is **perpendicular** to the plane the other two vectors form. Knowing that, we
    can implement left and right strafing with relative ease:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: After obtaining the cross product of the forward and up vectors, we simply multiply
    it by the scalar and add the result to the camera's position, creating left and
    right movement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rotating the camera is slightly more involved, but not trivial:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, we use the cross product to obtain the orthogonal vector of the
    forward direction and up direction vectors plane. A rotation matrix is then calculated,
    by multiplying two rotation matrices of *X* and *Y* axes. For the *X* axis, we
    are simply rotating around the up direction vector, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Moving the camera around](img/image_07_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The *Y* axis rotation is made available by rotating along the orthogonal vector
    of the view direction and up vector''s plane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Moving the camera around](img/image_07_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Having this functionality now allows us to program in actual camera movement,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: We are using the keyboard keys *W*, *S*, *A*, and *D* to move around the camera,
    and mouse position changes as scalar values to rotate it, provided the left mouse
    button is pressed.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing with vertex indices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One last thing that is quite important for us before moving on is covering a
    more efficient way of rendering shapes. Our current method is fine for rendering
    a single triangle, but it can get inefficient really quickly when rendering something
    more complex, like a cube. If we are using vertices only, it would require a grand
    total of *36* to render *six* cube faces. A much more efficient approach would
    obviously be submitting *eight* vertices for each corner of the cube and then
    reusing them to draw each face. Luckily, there is a way to do just that by using
    an **index array**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using indices simply means that for each model we are drawing, we also need
    to store an array of indices that represent the draw order of vertices. Each vertex
    in a model is given an index, starting from *0*. An array of these indices would
    then be used to connect the vertices, instead of having to re-submit them. Let''s
    implement this functionality, starting with the `GL_Model` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'As the new data member suggests, we need to store these indices in their own
    VBO, all of which happens inside the constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The constructor needs to take two extra arguments: a pointer to an array of
    indices, and the count of indices in that array. Note that `m_drawCount` is now
    being set to `l_indexCount`. This is because we only need *eight* vertices for
    a cube model, but there are *36* indices that describe how to draw it.'
  prefs: []
  type: TYPE_NORMAL
- en: After a new VBO is generated for the indices, we bind to it and submit the index
    data pretty much in the same way as before. The main difference here is the `GL_ELEMENT_ARRAY_BUFFER`
    flag. We cannot use `GL_ARRAY_BUFFER`, as the indices actually refer to the vertex
    data, which is located inside another VBO.
  prefs: []
  type: TYPE_NORMAL
- en: 'Obviously, this new data needs to be released once the model is no longer needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Drawing our model using indices requires a different `Draw()` call altogether:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The call to the `glDrawElements()` method takes four arguments: the type of
    primitives we are going to be drawing, the total number of indices, the data type
    that these indices are represented by, and an offset that can be used to skip
    them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That is all there is to drawing geometry using indices! Now let''s set up a
    more exciting model to show it off:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we''ve now set up `8` vertices, and we''ve created another
    array for indices. Once the model is rendered, we would see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Drawing with vertex indices](img/image_07_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the bottom face is actually rendered on top for some reason. This
    is caused by OpenGL not knowing which geometry to render on top, and this will
    be solved in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Face culling and depth buffer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way of solving the draw order issues is by using a **depth buffer**. In
    the simplest terms, a depth buffer, also commonly known as the **Z-buffer**, is
    basically a texture managed by OpenGL in the background that contains depth information
    of each pixel. When a pixel is being rendered, its depth (*Z* value) is checked
    against that on the depth buffer. If a pixel being rendered has a lower *Z* value,
    the pixel is overwritten, as it is clearly on top.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enabling the depth buffer only comes down to a single `glEnable()` method call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that the depth buffer is a texture. It is imperative to make sure
    it gets allocated when the window is created, and it has enough data to work with.
    We can make sure of that by creating an `sf::ContextSettings` structure and filling
    out its `depthBits` data member before passing it to the SFML''s window `Create()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'If we just ran the code as is, the screen would be completely blank. Why? Well,
    remember that the Z-buffer is a texture. A texture, just like the display, needs
    to be cleared every cycle. We can accomplish that like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding the pipe symbol allows us to perform a bitwise or operation on the `glClear`''s
    argument, joining in the `GL_DEPTH_BUFFER_BIT` definition. This ensures that the
    depth buffer is also cleared to black, and we can finally enjoy our cube:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Face culling and depth buffer](img/image_07_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Back face culling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to save on performance, it is a good idea to let OpenGL know that
    we would like to cull faces that are not visible from the current perspective.
    This feature can be enabled like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'After we `glEnable` face culling, the `glCullFace` function is invoked to let
    OpenGL know which faces to cull. This will work right out of the box, but we may
    notice weird artifacts like this if our model data is not set up correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back face culling](img/image_07_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is because the order our vertices are rendered in actually defines whether
    a face of a piece of geometry is facing inwards or outwards. For example, if the
    vertices of a face are rendered in a clockwise sequence, the face, by default,
    is considered to be facing **inwards** of the model and vice versa. Consider the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back face culling](img/image_07_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Setting up the model draw order correctly allows us to save on performance by
    not drawing invisible faces, and having our cube back just the way it was.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That may have been quite a lot to take in, but if you have made it all the way
    to the end, congratulations! The hard part is now over, and you are familiar with
    the modern versions of OpenGL, the programmable pipeline and general-purpose rendering.
    Even SFML itself was built around basic principles like the ones we have gone
    over, some of which we have already covered extensively.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to be covering the basics of lighting to create
    a more dynamic feel to our world. See you there!
  prefs: []
  type: TYPE_NORMAL
