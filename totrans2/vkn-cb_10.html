<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Helper Recipes</h1>
            </header>

            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Preparing a translation matrix</li>
<li>Preparing a rotation matrix</li>
<li>Preparing a scaling matrix</li>
<li>Preparing a perspective projection matrix</li>
<li>Preparing an orthographic projection matrix</li>
<li>Loading texture data from a file</li>
<li>Loading a 3D model from an OBJ file</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Introduction</h1>
            </header>

            <article>
                
<p>In previous chapters, we have learned about the various aspects of the Vulkan API. We now know how to use the graphics library and how to create applications that render 3D images and perform mathematical calculations. But the sole knowledge about the Vulkan API may not be enough to generate more complicated scenes and to implement various rendering algorithms. There are several very useful operations that can aid us in creating, manipulating, and displaying 3D objects.</p>
<p>In this chapter, we will learn how to prepare transformation matrices that are used to move, rotate, and scale 3D meshes. We will also see how to generate projection matrices. Finally, we will use simple yet very powerful single-header libraries to load images and 3D models stored in files.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Preparing a translation matrix</h1>
            </header>

            <article>
                
<p>Basic operations that can be performed on 3D models include moving the objects in a desired direction for a selected distance (number of units).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Prepare three variables of type <kbd>float</kbd> named <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd>, and initialize them with the amount of translation (movement distance) applied to the object along the <kbd>x</kbd> (right/left), <kbd>y</kbd> (up/down), and <kbd>z</kbd> (near/far) directions respectively.</li>
<li>Create a variable of type <kbd>std::array&lt;float, 16&gt;</kbd> named <kbd>translation_matrix</kbd> that will hold a matrix representing the desired operation. Initialize elements of the <kbd>translation_matrix</kbd> array with the following values:
<ul>
<li>All elements initialize with a <kbd>0.0f</kbd> value</li>
<li>0<sup>th</sup>, 5<sup>th</sup>, 10<sup>th,</sup> and 15<sup>th</sup> elements (main diagonal) with a <kbd>1.0f</kbd> value</li>
<li>12<sup>th</sup> element with a value stored in the <kbd>x</kbd> variable</li>
<li>13<sup>th</sup> element with a value stored in the <kbd>y</kbd> variable</li>
<li>14<sup>th</sup> element with a value stored in the <kbd>z</kbd> variable</li>
</ul>
</li>
<li>Provide values of all elements of the <kbd>translation_matrix</kbd> variable to shaders (possibly via a uniform buffer or a push constant) or multiply it by another matrix to accumulate multiple operations in one matrix.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Translation is one of three basic transformations that can be applied to an object (the rest are rotation and scaling). It allows us to move a 3D model in a desired direction for a desired distance:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="282" src="assets/image_10_001.png" width="389"/></div>
<p>Movement can also be applied to the camera, thus changing the point from which we observe a whole rendered scene.</p>
<p>Creating a translation matrix is a simple process. We need an identity 4x4 matrix--all its elements must be initialized with zeros (<kbd>0.0f</kbd>) except for the elements on the main diagonal, which must be initialized with ones (<kbd>1.0f</kbd>). Now we initialize the first three elements of the fourth column with the distance we want to apply in the <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd> axes respectively, as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="138" src="assets/image_10_002.png" width="159"/></div>
<p>The following code creates a translation matrix:</p>
<pre>
std::array&lt;float, 16&gt; translation_matrix = { 
  1.0f, 0.0f, 0.0f, 0.0f, 
  0.0f, 1.0f, 0.0f, 0.0f, 
  0.0f, 0.0f, 1.0f, 0.0f, 
     x,    y,    z, 1.0f 
}; 
return translation_matrix;
</pre>
<p>In the preceding code, we assume the matrix has a <kbd>column_major</kbd> order (first four elements compose a first column of the matrix, next four elements compose a second column, and so on), so it is transposed compared to the preceding figure. But the order of elements of the matrix provided to the shaders depends on a <kbd>row_major</kbd> or <kbd>column_major</kbd> <strong>layout qualifier</strong> specified in the shaders' source code.</p>
<div class="packt_tip">Keep in mind the order of elements of matrix defined in the shaders. It is specified through a <kbd>row_major</kbd> or <kbd>column_major</kbd> layout qualifier.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml">Chapter 5</a>, <em>Descriptor Sets</em>, see the following recipe:
<ul>
<li><em>Creating a uniform buffer</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml">Chapter 7</a>, <em>Shaders</em>, see the following recipes:
<ul>
<li><em>Writing a vertex shader that multiplies vertex position by a projection matrix</em></li>
<li><em>Using push constants in shaders</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipe:
<ul>
<li> <em>Providing data to shaders through push constants</em></li>
</ul>
</li>
<li>The following recipes in this chapter:
<ul>
<li><em>Preparing a scaling matrix</em></li>
<li><em>Preparing a rotation matrix</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Preparing a rotation matrix</h1>
            </header>

            <article>
                
<p>When we create a 3D scene and manipulate its objects, we usually need to rotate them in order to properly place and orient them among other objects. Rotating an object is achieved with a rotation matrix. For it, we need to specify a vector, around which rotation will be performed, and an angle--how much rotation we want to apply.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Prepare three variables of type <kbd>float</kbd> named <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd>. Initialize them with values that define an arbitrary vector, around which rotation should be performed. Make sure the vector is normalized (has a length equal to <kbd>1.0f</kbd>).</li>
<li>Prepare a variable of type <kbd>float</kbd> named <kbd>angle</kbd> and store an angle of the rotation (in radians) in it.</li>
<li>Create a variable of type <kbd>float</kbd> named <kbd>c</kbd>. Store a cosine of the angle in it.</li>
<li>Create a variable of type <kbd>float</kbd> named <kbd>s</kbd>. Store a sine of the angle in it.</li>
<li>Create a variable of type <kbd>std::array&lt;float, 16&gt;</kbd> named <kbd>rotation_matrix</kbd> that will hold a matrix representing the desired operation. Initialize elements of the <kbd>rotation_matrix</kbd> array with the following values:
<ul>
<li>0<sup>th</sup> element with a <kbd>x * x * (1.0f - c) + c</kbd></li>
<li>1<sup>st</sup> element with a <kbd>y * x * (1.0f - c) - z * s</kbd></li>
<li>2<sup>nd</sup> element with a <kbd>z * x * (1.0f - c) + y * s</kbd></li>
<li>4<sup>th</sup> element with a <kbd>x * y * (1.0f - c) + z * s</kbd></li>
<li>5<sup>th</sup> element with a <kbd>y * y * (1.0f - c) + c</kbd></li>
<li>6<sup>th</sup> element with a <kbd>z * y * (1.0f - c) - x * s</kbd></li>
<li>8<sup>th</sup> element with a <kbd>x * z * (1.0f - c) - y * s</kbd></li>
<li>9<sup>th</sup> element with a <kbd>y * z * (1.0f - c) + x * s</kbd></li>
<li>10<sup>th</sup> element with a <kbd>z * z * (1.0f - c) + c</kbd></li>
<li>The rest of the elements initialize with a <kbd>0.0f</kbd> value</li>
<li>Except for the 15<sup>th</sup> element, which should contain a <kbd>1.0f</kbd> value</li>
</ul>
</li>
<li>Provide values of all elements of the <kbd>rotation_matrix</kbd> variable to shaders (possibly via a uniform buffer or a push constant) or multiply it by another matrix to accumulate multiple operations in one matrix.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Preparing a matrix that represents a general rotation transformation is quite complicated. It can be divided into three separate matrices--representing rotations around each of the <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd> axis--that are later multiplied to generate the same result. Each such rotation is much simpler to prepare, but all in all it requires more operations to be performed, thus it may have a worse performance.</p>
<p>That's why it is better to prepare a matrix that represents a rotation around a selected (arbitrary) vector. For this we need to specify an angle, which defines the amount of rotation to apply, and a vector. This vector should be normalized, or the amount of the applied rotation will be scaled proportionally to the length of the vector.</p>
<div class="packt_tip">Vector, around which rotation is performed, should be normalized.</div>
<p>The following figure shows a rotation matrix. Data needed to perform rotation transformation is placed in the upper-left 3x3 matrix. Each column of such matrix defines the directions of <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd> axes respectively after the rotation is performed. What's more, a transposed rotation matrix defines exactly the opposite transformation:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="147" src="assets/image_10_003.png" width="170"/></div>
<p>For example, if we want to rotate a camera to simulate that the character we control looks around left and right, or if we want to display a car that is turning left or right, we should specify a vector that points upwards (<kbd>0.0f, 1.0f, 0.0f</kbd>). We can also specify a vector that points downwards (<kbd>0.0f, -1.0f, 0.0f</kbd>). In this case, the object will be rotated for the same angle, but in the opposite direction. We need to choose which option is more convenient for us:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/image_10_004.png"/></div>
<p>The following is the code that creates a rotation matrix. It first checks if we want to normalize the vector and modifies its components accordingly. Next, helper variables are prepared that store temporary results. Finally, all elements of the rotation matrix are initialized:</p>
<pre>
if( normalize ) { 
  std::array&lt;float, 3&gt; normalized = Normalize( x, y, z ); 
  x = normalized[0]; 
  y = normalized[1]; 
  z = normalized[2]; 
} 
const float c = cos( Deg2Rad( angle ) ); 
const float _1_c = 1.0f - c; 
const float s = sin( Deg2Rad( angle ) ); 
std::array&lt;float, 16&gt; rotation_matrix = { 
  x * x * _1_c + c, 
  y * x * _1_c - z * s, 
  z * x * _1_c + y * s, 
  0.0f, 
  x * y * _1_c + z * s, 
  y * y * _1_c + c, 
  z * y * _1_c - x * s, 
  0.0f, 
  x * z * _1_c - y * s, 
  y * z * _1_c + x * s, 
  z * z * _1_c + c, 
  0.0f, 
  0.0f, 
  0.0f, 
  0.0f, 
  1.0f 
}; 
return rotation_matrix;
</pre>
<p>We need to remember the order of elements in an array (application) and in the matrix defined in a shaders source code. Inside shaders, we control it with <kbd>row_major</kbd> or <kbd>column_major</kbd> layout qualifiers.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml">Chapter 5</a>, <em>Descriptor Sets</em>, see the following recipe:
<ul>
<li> <em>Creating a uniform buffer</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml">Chapter 7</a>, <em>Shaders</em>, see the following recipes:
<ul>
<li><em>Writing a vertex shader that multiplies vertex position by a projection matrix</em></li>
<li><em>Using push constants in shaders</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipe:
<ul>
<li> <em>Providing data to shaders through push constants</em></li>
</ul>
</li>
<li>The following recipe in this chapter:
<ul>
<li><em>Preparing a translation matrix</em></li>
<li><em>Preparing a scaling matrix</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Preparing a scaling matrix</h1>
            </header>

            <article>
                
<p>The third transformation that can be performed on a 3D model is scaling. This allows us to change an object's size.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Prepare three variables of type <kbd>float</kbd> named <kbd>x</kbd>, <kbd>y,</kbd> and <kbd>z</kbd> that will hold the scaling factor applied to a model in x (width), y (height), and z (depth) dimensions, respectively.</li>
<li>Create a variable of type <kbd>std::array&lt;float, 16&gt;</kbd> named <kbd>scaling_matrix</kbd>, in which a matrix representing the desired operation will be stored. Initialize elements of the <kbd>scaling_matrix</kbd> array with the following values:
<ul>
<li>All elements initialize with a <kbd>0.0f</kbd> value</li>
<li>0th element with a value stored in the <kbd>x</kbd> variable</li>
<li>5<sup>th</sup> element with a value stored in the <kbd>y</kbd> variable</li>
<li>10<sup>th</sup> element with a value stored in the <kbd>z</kbd> variable</li>
<li>15<sup>th</sup> element with a <kbd>1.0f</kbd> value</li>
</ul>
</li>
<li>Provide values of all elements of the <kbd>scaling_matrix</kbd> variable to shaders (possibly via a uniform buffer or a push constant) or multiply it by another matrix to accumulate multiple operations in one matrix.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Sometimes we need to change an object's size (compared to other objects in the scene). For example, due to the effect of a magical incantation, our character shrinks to fit into a very small hole. This transformation is achieved with a scaling matrix that looks like this:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="123" src="assets/image_10_005.png" width="142"/></div>
<p>Using the scaling matrix, we can resize the model differently in each dimension:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="305" src="assets/image_10_006.png" width="421"/></div>
<p>We must be cautious if we don't scale an object uniformly. Usually, to simplify the code and improve the performance, we provide a combined transformation matrix to a shader and use the same matrix to transform not only vertices, but also normal vectors. When we scale an object uniformly, we just need to normalize the normal vector in the shader after the transformation. But when we use a transformation that scales an object differently in each dimension, we cannot apply it to a normal vector, because lighting calculations will be incorrect (direction represented by the normal vector will be changed). If we really need to perform such scaling, we need to use an inverse transpose matrix for the normal vector transformation. We must prepare it separately and provide it to a shader.</p>
<div class="packt_tip">When an object is scaled differently in each dimension, a normal vector must be transformed by an inverse transformation matrix.</div>
<p>Preparing a scaling matrix can be performed with the following code:</p>
<pre>
std::array&lt;float, 16&gt; scaling_matrix = { 
     x, 0.0f, 0.0f, 0.0f, 
  0.0f,    y, 0.0f, 0.0f, 
  0.0f, 0.0f,    z, 0.0f, 
  0.0f, 0.0f, 0.0f, 1.0f 
}; 
return scaling_matrix;
</pre>
<p>As with all other matrices, we need to remember about the order of elements defined in our application (CPU) and order of elements of the matrices defined in the shader source code (<kbd>column_major</kbd> versus <kbd>row_major</kbd> order).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml">Chapter 5</a>, <em>Descriptor Sets</em>, see the following recipe:
<ul>
<li><em>Creating a uniform buffer</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml">Chapter 7</a>, <em>Shaders</em>, see the following recipes:
<ul>
<li><em>Writing a vertex shader that multiplies vertex position by a projection matrix</em></li>
<li><em>Using push constants in shaders</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipe:
<ul>
<li> <em>Providing data to shaders through push constants</em></li>
</ul>
</li>
<li>The following recipes in this chapter:
<ul>
<li><em>Preparing a translation matrix</em></li>
<li><em>Preparing a rotation matrix</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Preparing a perspective projection matrix</h1>
            </header>

            <article>
                
<p>3D applications usually try to simulate the effect of how we perceive the world around us--objects in the distance seem smaller than the objects that are closer to us. To achieve this effect, we need to use a perspective projection matrix.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Prepare a variable of type <kbd>float</kbd> named <kbd>aspect_ratio</kbd> that will hold an aspect ratio of a renderable area (image's width divided by its height).</li>
<li>Create a variable of type <kbd>float</kbd> named <kbd>field_of_view</kbd>. Initialize it with an angle (in radians) of a vertical field of view of a camera.</li>
<li>Create a variable of type <kbd>float</kbd> named <kbd>near_plane</kbd> and initialize it with the distance from the camera's position to the near clipping plane.</li>
<li>Create a variable of type <kbd>float</kbd> named <kbd>far_plane</kbd>. Store the distance between a camera and the far clipping plane in the variable.</li>
<li>Calculate a value of <kbd>1.0f</kbd> divided by a tangent of the half of the <kbd>field_of_view</kbd> (<kbd>1.0f / tan(Deg2Rad(0.5f * field_of_view))</kbd>) and store the result in a variable of type <kbd>float</kbd> named <kbd>f</kbd>.</li>
<li>Create a variable of type <kbd>std::array&lt;float, 16&gt;</kbd> named <kbd>perspective_projection_matrix</kbd> that will hold a matrix representing the desired projection. Initialize elements of the <kbd>perspective_projection_matrix</kbd> array with the following values:
<ul>
<li>0<sup>th</sup> element with a <kbd>f / aspect_ratio</kbd></li>
<li>5<sup>th</sup> element with a <kbd>-f</kbd></li>
<li>10<sup>th</sup> element with a <kbd>far_plane / (near_plane - far_plane)</kbd></li>
<li>11<sup>th</sup> element with a <kbd>-1.0f</kbd> value</li>
<li>14<sup>th</sup> element with a <kbd>(near_plane * far_plane) / (near_plane - far_plane)</kbd></li>
<li>The rest of the elements initialize with a <kbd>0.0f</kbd> value</li>
</ul>
</li>
<li>Provide values of all elements of the <kbd>perspective_projection_matrix</kbd> variable to shaders (possibly via a uniform buffer or a push constant) or multiply it by another matrix to accumulate multiple operations in one matrix.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>A graphics pipeline operates on vertex positions defined in a so-called clip space. Usually, we specify vertices in a local (model) coordinate system and provide them directly to a vertex shader. That's why we need to transform provided vertex positions from their local space to a clip space in one of the vertex processing stages (vertex, tessellation control, tessellation evaluation, or a geometry shader). This transformation is performed with a projection matrix. If we want to simulate the effect of a perspective division, we need to use a perspective projection matrix and multiply it by a vertex position:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="346" src="assets/image_10_007.png" width="553"/></div>
<p>To create a perspective projection matrix, we need to know the dimensions of a renderable area, to calculate its aspect ratio (width divided by height). We also need to specify a (vertical) field of view, which we can think of as a zoom of a virtual camera:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="267" src="assets/image_10_008.png" width="266"/></div>
<p>One last thing required to create a perspective projection matrix are two distances to near and far clipping planes. As they impact the depth calculations, they should be specified as close to the objects on the scene as possible. If we specify a large value for a near plane, and a small value for a far plane, our scene will be (in general) clipped--we will see how objects are popping in and out of the scene. On the other hand, if the near distance is too small, and the distance to the far plane is too big, we will lose the precision of a depth buffer and depth calculations may be incorrect.</p>
<div class="packt_tip">Near and far clipping planes should correspond to the scene being displayed.</div>
<p>Using the preceding described data, we can create a perspective projection matrix using the following code:</p>
<pre>
float f = 1.0f / tan( Deg2Rad( 0.5f * field_of_view ) );

Matrix4x4 perspective_projection_matrix = {
 f / aspect_ratio,
 0.0f,
 0.0f,
 0.0f,

 0.0f,
 -f,
 0.0f,
 0.0f,

 0.0f,
 0.0f,
 far_plane / (near_plane - far_plane),
 -1.0f,

 0.0f,
 0.0f,
 (near_plane * far_plane) / (near_plane - far_plane),
 0.0f
};
return perspective_projection_matrix;
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml">Chapter 5</a>, <em>Descriptor Sets</em>, see the following recipe:
<ul>
<li> <em>Creating a uniform buffer</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml">Chapter 7</a>, <em>Shaders</em>, see the following recipes:
<ul>
<li><em>Writing a vertex shader that multiplies vertex position by a projection matrix</em></li>
<li><em>Using push constants in shaders</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipe:
<ul>
<li> <em>Providing data to shaders through push constants</em></li>
</ul>
</li>
<li>The following recipe in this chapter: 
<ul>
<li><em>Preparing an orthographic projection matrix</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Preparing an orthographic projection matrix</h1>
            </header>

            <article>
                
<p>Orthographic projection is another type of operation that transforms vertices from their local coordinate system to a clip space. But opposed to a perspective projection, it doesn't take a perspective division into account (doesn't simulate the way we perceive our surroundings). But similarly to a perspective projection, it is also represented by a 4x4 matrix, which we need to create in order to use this type of projection.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Create two variables of type <kbd>float</kbd> named <kbd>left_plane</kbd> and <kbd>right_plane</kbd>, and initialize them with the positions (on the <kbd>x</kbd> axis) of left and right clipping planes, respectively.</li>
<li>Prepare two variables of type <kbd>float</kbd> named <kbd>bottom_plane</kbd> and <kbd>top_plane</kbd>. Initialize them with positions of (on the <kbd>y</kbd> axis) of the bottom and top clipping planes, respectively.</li>
<li>Create two variables of type <kbd>float</kbd> named <kbd>near_plane</kbd> and <kbd>far_plane</kbd>. Use them to hold distances from the camera to the near and far clipping planes, respectively.</li>
<li>Create a variable of type <kbd>std::array&lt;float, 16&gt;</kbd> named <kbd>orthographic_projection_matrix</kbd>. It will hold a matrix representing the desired projection. Initialize elements of the <kbd>orthographic_projection_matrix</kbd> array with the following values:
<ul>
<li>All elements of the matrix initialize with a <kbd>0.0f</kbd> value</li>
<li>0<sup>th</sup> element with a <kbd>2.0f / (right_plane - left_plane)</kbd></li>
<li>5<sup>th</sup> element with a <kbd>2.0f / (bottom_plane - top_plane)</kbd></li>
<li>10th element with a <kbd>1.0f / (near_plane - far_plane)</kbd></li>
<li>12<sup>th</sup> element with a <kbd>-(right_plane + left_plane) / (right_plane - left_plane)</kbd></li>
<li>13<sup>th</sup> element with a <kbd>-(bottom_plane + top_plane) / (bottom_plane - top_plane)</kbd></li>
<li>14th element with a <kbd>near_plane / (near_plane - far_plane)</kbd></li>
<li>15<sup>th</sup> element with a <kbd>1.0f</kbd> value</li>
</ul>
</li>
<li>Provide values of all elements of the <kbd>orthographic_projection_matrix</kbd> variable to shaders (possibly via a uniform buffer or a push constant) or multiply it by another matrix to accumulate multiple operations in one matrix.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>When we use orthographic projection, all objects in the scene maintain their size and screen position no matter how far from the camera they are. That's why orthographic projection is very useful for drawing all kinds of <strong>UIs</strong> (<strong>user interfaces</strong>). We can define our virtual screen, we know all its sides (planes defined for the projection), and we can easily place and manipulate interface elements on screen. We can also use depth tests if needed.</p>
<p>Orthographic projection is also widely used in <strong>CAD</strong> programs (<strong>Computer Aided Design</strong>). These tools are used for designing buildings, ships, electronic circuits, or mechanical devices. In such situations, all sizes of all objects in the scene must be exactly the ones as defined by the designers and all directions must keep their relations (that is, all parallel lines must always stay parallel), no matter how far from the camera objects are and from which angle they are viewed.</p>
<p>The following code is used to create a matrix that represents an orthographic projection:</p>
<pre>
Matrix4x4 orthographic_projection_matrix = {
  2.0f / (right_plane - left_plane),
  0.0f,
  0.0f,
  0.0f,

  0.0f,
  2.0f / (bottom_plane - top_plane),
  0.0f,
  0.0f,

  0.0f,
  0.0f,
  1.0f / (near_plane - far_plane),
  0.0f,

  -(right_plane + left_plane) / (right_plane - left_plane),
  -(bottom_plane + top_plane) / (bottom_plane - top_plane),
  near_plane / (near_plane - far_plane),
  1.0f
 };
 return orthographic_projection_matrix;
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml">Chapter 5</a>, <em>Descriptor Sets</em>, see the following recipe:
<ul>
<li> <em>Creating a uniform buffer</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml">Chapter 7</a>, <em>Shaders</em>, see the following recipes:
<ul>
<li><em>Writing a vertex shader that multiplies vertex position by a projection matrix</em></li>
<li><em>Using push constants in shaders</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipe:
<ul>
<li> <em>Providing data to shaders through push constants</em></li>
</ul>
</li>
<li>The <em>Preparing a perspective projection matrix</em> recipe in this chapter</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Loading texture data from a file</h1>
            </header>

            <article>
                
<p>Texturing is a commonly used technique. It allows us to place an image on the surface of an object in a similar way to how we put wallpaper on walls. This way we don't need to increase the geometric complexity of a mesh, which would be both too complex for the hardware to process it, and would use too much memory. Texturing is simpler to handle and allows us to achieve better, more convincing results.</p>
<p>Textures can be generated procedurally (dynamically in code), but usually their contents are read from images or photos.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>There are many different libraries allowing us to load contents of images. All of them have their own specific behaviors, usages, and licenses. In this recipe, we will use a <kbd>stb_image</kbd> library created by <em>Sean T. Barrett</em>. It is very simple to use, yet supports enough image formats to start developing a Vulkan application. And one of its main strengths is that it is a single header library, all its code is placed in just one header file. It doesn't depend on any other libraries, files, or resources. Another advantage is that we can use it in whatever way we want.</p>
<div class="packt_tip">The <kbd>stb_image.h</kbd> file is available at <a href="https://github.com/nothings/stb"><span class="URLPACKT">https://github.com/nothings/stb</span></a>.</div>
<p>To use the <kbd>stb_image</kbd> library in our application, we need to download a <kbd>stb_image.h</kbd> file from <a href="https://github.com/nothings/stb"><span class="URLPACKT">https://github.com/nothings/stb</span></a> and include it in our project. This file can be included at many places in our code, but to create the library's implementation in only one of the source files we need to include the file and precede it with a <kbd>#define STB_IMAGE_IMPLEMENTATION</kbd> definition like this:</p>
<pre>
#include ... 
#define STB_IMAGE_IMPLEMENTATION 
#include "stb_image.h"
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Store the name of a file, from which the texture image should be loaded, in a variable of type <kbd>char const *</kbd> named <kbd>filename</kbd>.</li>
<li>Create a variable of type <kbd>int</kbd> named <kbd>num_requested_components</kbd>. Initialize it with the desired number of components to be loaded from a file (a value from <kbd>1</kbd> to <kbd>4</kbd>) or with a <kbd>0</kbd> value to load all available components.</li>
<li>Create three variables of type <kbd>int</kbd> named <kbd>width</kbd>, <kbd>height</kbd>, and <kbd>num_components</kbd>, and initialize all of them with a <kbd>0</kbd> value.</li>
<li>Create a variable of type <kbd>unsigned char *</kbd> named <kbd>stbi_data</kbd>.</li>
<li>Call <kbd>stbi_load( filename, &amp;width, &amp;height, &amp;num_components, num_requested_components )</kbd> and provide the <kbd>filename</kbd> variable, pointers to the <kbd>width</kbd>, <kbd>height</kbd>, and <kbd>num_components</kbd> variables, and the <kbd>num_requested_components</kbd> variable. Store the result of the function call in the <kbd>stbi_data</kbd> variable.</li>
<li>Make sure the call successfully loaded the contents of the specified file by checking if a value stored in the <kbd>stbi_data</kbd> variable is not equal to a <kbd>nullptr</kbd> value and if the values stored in the <kbd>width</kbd>, <kbd>height</kbd>, and <kbd>num_components</kbd> variables are greater than <kbd>0</kbd>.</li>
<li>Create a variable of type <kbd>int</kbd> named <kbd>data_size</kbd> and initialize it with a value calculated using the following formulae:</li>
</ol>
<div class="CDPAlignCenter CDPAlign packt_quote" style="padding-left: 120px"><em>width * height * (0 &lt; num_requested_components ? num_requested_components : num_components)</em></div>
<ol start="8">
<li>Create a variable of type <kbd>std::vector&lt;unsigned char&gt;</kbd> named <kbd>image_data</kbd>. Resize it to hold the <kbd>data_size</kbd> number of elements.</li>
<li>Copy <kbd>data_size</kbd> number of bytes from the <kbd>stbi_data</kbd> to a memory starting at the first element of the <kbd>image_data</kbd> vector using the following call:</li>
</ol>
<pre>
      std::memcpy( image_data.data(), stbi_data.get(), data_size )
</pre>
<ol start="10">
<li>Call <kbd>stbi_image_free( stbi_data )</kbd>.</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Using the <kbd>stb_image</kbd> library comes down to calling the <kbd>stbi_load()</kbd> function. It takes the name of a file, the selected number of components to be loaded from the file, and returns a pointer to the memory containing the loaded data. The library always converts an image's contents to 8 bits per channel. The width and height of the image and the real number of components available in the image are stored in optional variables.</p>
<p>The code loading an image is presented as follows:</p>
<pre>
int width = 0; 
int height = 0; 
int num_components = 0; 
std::unique_ptr&lt;unsigned char, void(*)(void*)&gt; stbi_data( stbi_load( filename, &amp;width, &amp;height, &amp;num_components, num_requested_components ), stbi_image_free );

if( (!stbi_data) || 
    (0 &gt;= width) || 
    (0 &gt;= height) || 
    (0 &gt;= num_components) ) { 
  std::cout &lt;&lt; "Could not read image!" &lt;&lt; std::endl; 
  return false; 
}
</pre>
<p>The pointer returned by the <kbd>stbi_load()</kbd> function must be released by calling the <kbd>stbi_image_free()</kbd> function with a value returned by the former function provided as its only parameter. That's why it is good to copy loaded data to our own variable (that is, a vector) or directly to one of the Vulkan resources (image), so there are no memory leaks. This is presented as follows:</p>
<pre>
std::vector&lt;unsigned char&gt; image_data; 
int data_size = width * height * (0 &lt; num_requested_components ? num_requested_components : num_components); 
image_data.resize( data_size ); 
std::memcpy( image_data.data(), stbi_data.get(), data_size ); 
return true;
</pre>
<p>In the preceding code, the memory pointer returned by the <kbd>stbi_load()</kbd> function is released automatically, because we are storing it in a smart pointer of type <kbd>std::unique_ptr</kbd>. In the example, we copy the image's contents to a vector. This vector can be used later in our application as a source of texture data.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="f1332ca0-b5a2-49bd-ac41-e37068e31042.xhtml"><span class="ChapterrefPACKT">Chapter 4</span></a>, <em>Resources and Memory</em>, see the following recipes:
<ul>
<li><em>Creating an image</em></li>
<li><em>Allocating and binding memory object to an image</em></li>
<li><em>Creating an image view</em></li>
</ul>
</li>
<li>In <a href="fe2cb528-9d22-49db-a05b-372bce2f87ee.xhtml"><span class="ChapterrefPACKT">Chapter 5</span></a>, <em>Descriptor Sets</em>, see the following recipes:
<ul>
<li><em>Creating a sampled image</em></li>
<li><em>Creating a combined image sampler</em></li>
</ul>
</li>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml"><span class="ChapterrefPACKT">Chapter 7</span></a>, <em>Shaders</em>, see the following recipe:
<ul>
<li> <em>Writing a texturing vertex and fragment shaders</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Loading a 3D model from an OBJ file</h1>
            </header>

            <article>
                
<p>Rendering 3D scenes requires us to draw objects, which are also called models or meshes. A mesh is a collection of vertices (points) with information about how these vertices form surfaces or faces (usually triangles).</p>
<p>Objects are prepared in modeling software or CAD programs. They can be stored in many various formats, which are later loaded in 3D applications, provided to graphics hardware, and then rendered. One of the simpler file types, which holds mesh data, is a <strong>Wavefront OBJ</strong>. We will learn how to load models stored in this format.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>There are multiple libraries that allow us to load OBJ files (or other file types). One of the simpler, yet very fast and still being improved, libraries is a <strong>tinyobjloader</strong> developed by <em>Syoyo Fujita</em>. It is a single header library, so we don't need to include any other files or reference any other libraries.</p>
<div class="packt_tip">The tinyobjloader library can be downloaded from <a href="https://github.com/syoyo/tinyobjloader"><span class="URLPACKT">https://github.com/syoyo/tinyobjloader</span></a>.</div>
<p>To use the library, we need to download a <kbd>tiny_obj_loader.h</kbd> file from <a href="https://github.com/syoyo/tinyobjloader"><span class="URLPACKT">https://github.com/syoyo/tinyobjloader</span></a>. We can include it at many places in our code, but to generate its implementation, we need to include it in one of our source files and precede the inclusion with a <kbd>#define TINYOBJLOADER_IMPLEMENTATION</kbd> definition like this:</p>
<pre>
#include ... 
#define TINYOBJLOADER_IMPLEMENTATION 
#include "tiny_obj_loader.h"
</pre>
<p>For the purpose of this recipe, we will also use a custom <kbd>Mesh</kbd> type that will hold the loaded data in a form that can be easily used with a Vulkan API. This type has the following definition:</p>
<pre>
struct Mesh { 
  std::vector&lt;float&gt;  Data; 
  struct Part { 
    uint32_t  VertexOffset; 
    uint32_t  VertexCount; 
  }; 
  std::vector&lt;Part&gt;   Parts; 
};
</pre>
<p>The <kbd>Data</kbd> member stores vertex attributes--positions, normals, and texture coordinates (normal vectors and texcoords are optional). Next there is a vector member named <kbd>Parts</kbd>, which defines separate parts of the model. Each such part needs to be drawn with a separate API call (such as the <kbd>vkCmdDraw()</kbd> function). The model part is defined by two parameters. <kbd>VertexOffset</kbd> defines where the given part starts (what is its offset in an array of vertex data). <kbd>VertexCount</kbd> defines the number of vertices the given part is composed of.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Prepare a variable of type <kbd>char const *</kbd> named <kbd>filename</kbd> and store a name of the file, from which model data will be loaded, in the variable.</li>
<li>Create the following variables:
<ul>
<li>Of type <kbd>tinyobj::attrib_t</kbd> named <kbd>attribs</kbd></li>
<li>Of type <kbd>std::vector&lt;tinyobj::shape_t&gt;</kbd> named <kbd>shapes</kbd></li>
<li>Of type <kbd>std::vector&lt;tinyobj::material_t&gt;</kbd> named <kbd>materials</kbd></li>
<li>Of type <kbd>std::string</kbd> named <kbd>error</kbd></li>
</ul>
</li>
<li>Call <kbd>tinyobj::LoadObj( &amp;attribs, &amp;shapes, &amp;materials, &amp;error, filename )</kbd>, for which provide pointers to the <kbd>attribs</kbd>, <kbd>shapes</kbd>, <kbd>materials</kbd>, and <kbd>error</kbd> variables, and also the <kbd>filename</kbd> variable as the last parameter.</li>
<li>Make sure the call successfully loaded the model data from file by checking if the function call returned a <kbd>true</kbd> value.</li>
<li>Create a variable of type <kbd>Mesh</kbd> named <kbd>mesh</kbd> that will hold model data in a form suitable for a Vulkan API.</li>
<li>Create a variable of type <kbd>uint32_t</kbd> named <kbd>offset</kbd> and initialize it with a <kbd>0</kbd> value.</li>
<li>Iterate over all elements of the <kbd>shapes</kbd> vector. Assuming that the current element is stored in a variable of type <kbd>tinyobj::shape_t</kbd> named <kbd>shape</kbd>, do the following operations for each element:
<ol>
<li>Create a variable of type <kbd>uint32_t</kbd> named <kbd>part_offset</kbd>. Initialize it with a value stored in the <kbd>offset</kbd> variable.</li>
</ol>
<ol start="2">
<li>Iterate over all elements of the <kbd>shape.mesh.indices</kbd> vector, store currently processed elements in a variable of type <kbd>tinyobj::index_t</kbd> named <kbd>index</kbd>, and do the following operations for each element:
<ul>
<li>Copy three elements of an <kbd>attribs.vertices</kbd> vector, available at indices equal to (<kbd>3 * index.vertex_index</kbd>), (<kbd>3 * index.vertex_index + 1</kbd>), and (<kbd>3 * index.vertex_index + 2</kbd>), as new elements of the <kbd>mesh.Data</kbd> vector</li>
<li>If normal vectors should be loaded, copy three elements of an <kbd>attribs.normals</kbd> vector, which are indicated by indices equal to (<kbd>3 * index.normal_index</kbd>), (<kbd>3 * index.normal_index + 1</kbd>), and (<kbd>3 * index.normal_index + 2</kbd>), to the <kbd>mesh.Data</kbd> vector</li>
<li>If texture coordinates should also be loaded, add two elements to the <kbd>mesh.Data</kbd> vector and initialize them with values stored in an <kbd>attribs.texcoords</kbd> vector at positions (<kbd>2 * index.texcoord_index</kbd>) and (<kbd>2 * index.texcoord_index + 1</kbd>)</li>
<li>Increase the value of the <kbd>offset</kbd> variable by one</li>
</ul>
</li>
<li>Store a calculated value of <kbd>offset - part_offset</kbd> in a variable of type <kbd>uint32_t</kbd> named <kbd>part_vertex_count</kbd>.</li>
<li>If the value of the <kbd>part_vertex_count</kbd> variable is greater than zero (a <kbd>0</kbd> value), add a new element to the <kbd>mesh.Parts</kbd> vector. Initialize its contents with the following values:
<ul>
<li>The <kbd>part_offset</kbd> variable for <kbd>VertexOffset</kbd></li>
<li>The <kbd>part_vertex_count</kbd> variable for <kbd>VertexCount</kbd></li>
</ul>
</li>
</ol>
</li>
</ol>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>3D models should be as small as possible to speed the loading process and lower the disk space required to store them. Usually, when we think about creating games, we should choose one of the binary formats, because most of them meet the mentioned requirements.</p>
<p>But when we start learning new APIs, it is good to choose a simpler format. OBJ files contain data stored in a text form, so we can easily view it or even modify it by ourselves. Most (if not all) commonly used modeling programs allow generated models to be exported to OBJ files. So it is a good format to get started with.</p>
<p>Here we will focus on loading only the vertex data. First we need to prepare storage for a model. After that we can load the model using the tinyobjloader library. If anything goes wrong, we check the error message and display it to a user:</p>
<pre>
tinyobj::attrib_t                attribs; 
std::vector&lt;tinyobj::shape_t&gt;    shapes; 
std::vector&lt;tinyobj::material_t&gt; materials; 
std::string                      error; 
bool result = tinyobj::LoadObj( &amp;attribs, &amp;shapes, &amp;materials, &amp;error, filename.c_str() ); 
if( !result ) { 
  std::cout &lt;&lt; "Could not open '" &lt;&lt; filename &lt;&lt; "' file."; 
  if( 0 &lt; error.size() ) { 
    std::cout &lt;&lt; " " &lt;&lt; error; 
  } 
  std::cout &lt;&lt; std::endl; 
  return false; 
}
</pre>
<p>Theoretically, we could end our model-loading code here, but this data structure is not well suited for the Vulkan API. Though the normal vector and texture coordinates of a single vertex may be placed in separate arrays, they should be placed at the same index. Unfortunately, this may not be the case when it comes to an OBJ file format, which reuses the same values for multiple vertices. Because of that, we need to convert loaded data to a format that can be easily used by a graphics hardware:</p>
<pre>
Mesh mesh = {}; 
uint32_t offset = 0; 
for( auto &amp; shape : shapes ) { 
  uint32_t part_offset = offset; 

  for( auto &amp; index : shape.mesh.indices ) { 
    mesh.Data.emplace_back( attribs.vertices[3 * index.vertex_index + 0] ); 
    mesh.Data.emplace_back( attribs.vertices[3 * index.vertex_index + 1] ); 
    mesh.Data.emplace_back( attribs.vertices[3 * index.vertex_index + 2] ); 
    ++offset; 

    if( (load_normals) &amp;&amp; 
        (attribs.normals.size() &gt; 0) ) { 
      mesh.Data.emplace_back( attribs.normals[3*index.normal_index+0]); 
      mesh.Data.emplace_back( attribs.normals[3*index.normal_index+1]); 
      mesh.Data.emplace_back( attribs.normals[3*index.normal_index+2]); 
    } 

    if( (load_texcoords) &amp;&amp; 
        (attribs.texcoords.size() &gt; 0)) { 
      mesh.Data.emplace_back( attribs.texcoords[2 * index.texcoord_index + 0] ); 
      mesh.Data.emplace_back( attribs.texcoords[2 * index.texcoord_index + 1] ); 
    } 
  } 

  uint32_t part_vertex_count = offset - part_offset; 
  if( 0 &lt; part_vertex_count ) { 
    mesh.Parts.push_back( { part_offset, part_vertex_count } ); 
  } 
}
</pre>
<p>After the preceding conversion, data stored in the <kbd>Data</kbd> member of the <kbd>mesh</kbd> variable can be directly copied to a vertex buffer. On the other hand, <kbd>VertexOffset</kbd> and <kbd>VertexCount</kbd> members of each part of the model are used during drawing--we can provide them to a <kbd>vkCmdDraw()</kbd> function.</p>
<p>When we create a graphics pipeline, which will be used to draw models loaded with the tinyobjloader library and stored in variables of a custom type <kbd>Mesh</kbd>, we need to specify a <kbd>VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST</kbd> topology for an input assembly state (refer to the <em>Specifying pipeline input assembly state</em> recipe from <a href="5744ea05-b18a-4f84-a1df-250b549dfea5.xhtml">Chapter 8</a>, <em>Graphics and Compute Pipelines</em>). We also need to remember that each vertex is composed of three floating point values defining its position. When vertex normals are also loaded, they are also described by three floating point values. Texture coordinates, which are also optional, contain two floating point values. Each of the position, normal, and texcoord attributes are placed one after another for the first vertex, and then there are the position, normal, and texcoord attributes of the second vertex, and so on. The preceding information is required to properly set up vertex binding and attribute descriptions specified during graphics pipeline creation (refer to the <em>Specifying pipeline vertex binding description, attribute description and input state</em> recipe from <a href="5744ea05-b18a-4f84-a1df-250b549dfea5.xhtml">Chapter 8</a>, <em>Graphics and Compute Pipelines</em>).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">See also</h1>
            </header>

            <article>
                
<ul>
<li>In <a href="f1332ca0-b5a2-49bd-ac41-e37068e31042.xhtml"><span class="ChapterrefPACKT">Chapter 4</span></a>, <em>Resources and Memory</em>, see the following recipes:
<ul>
<li><em>Creating a buffer</em></li>
<li><em>Allocating and binding memory object to a buffer</em></li>
<li><em>Using staging buffer to update a buffer with a device-local memory bound</em></li>
</ul>
</li>
</ul>
<ul>
<li>In <a href="97217f0d-bed7-4ae1-a543-b4d599f299cf.xhtml"><span class="ChapterrefPACKT">Chapter 7</span></a>, <em>Shaders</em>, see the following recipe:
<ul>
<li> <em>Writing vertex shaders</em></li>
</ul>
</li>
<li>In <a href="5744ea05-b18a-4f84-a1df-250b549dfea5.xhtml"><span class="ChapterrefPACKT">Chapter 8</span></a>, <em>Graphics and Compute Pipelines</em>, see the following recipes:
<ul>
<li><em>Specifying pipeline vertex binding description, attribute description and input state</em></li>
<li><em>Specifying pipeline input assembly state</em></li>
</ul>
</li>
<li>In <a href="0a69f5b5-142e-422b-aa66-5cb09a6467b3.xhtml"><span class="ChapterrefPACKT">Chapter 9</span></a>, <em>Command Recording and Drawing</em>, see the following recipes:
<ul>
<li><em>Binding vertex buffers</em></li>
<li><em>Drawing a geometry</em></li>
</ul>
</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>