<html><head></head><body><div><div><div><div><div><div><h1 class="title"><a id="ch08"/>Chapter 8.  Let There Be Light - An Introduction to Advanced Lighting </h1></div></div></div><p>There is a certain standard expected of a game in this day and age. As technology progresses and the number of transistors in any given computational unit increases, there is more and more power at our disposal to do what was previously unheard of. One thing that definitely makes use of all of this extra horse power is dynamic lighting. Because of its stunning visual results, it has become an integral part of most video games, and is now one of the core technologies that are expected to come with them.</p><p>In this chapter, we're going to cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using the technique of deferred rendering/shading</li><li class="listitem" style="list-style-type: disc">Implementing a multi-pass lighting shader</li><li class="listitem" style="list-style-type: disc">Faking geometry complexity using normal maps</li><li class="listitem" style="list-style-type: disc">Using specular maps to create shiny surfaces</li><li class="listitem" style="list-style-type: disc">Using height maps to make lighting feel more three-dimensional</li></ul></div><p>Let's start shedding some light on this subject!</p><div><div><div><div><h1 class="title"><a id="ch08lvl1sec69"/>Using third-party software</h1></div></div></div><p>None of the material maps used in this chapter are hand-drawn. For the generation of certain material maps, <em>Crazybump</em> was used, which can be found at <a class="ulink" href="http://crazybump.com/">http://crazybump.com/</a>.</p><p>There are other free alternatives that can be found online.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec70"/>Deferred rendering</h1></div></div></div><p>Deferred rendering/shading is a technique that gives us greater control over how certain effects are applied to a scene by not enabling them during the first pass. Instead, the scene can be rendered to an off screen buffer, along with other buffers that hold other material types of the same image, and then drawn on the screen in a later pass, after the effects have been applied, potentially in multiple passes as well. Using this approach allows us to separate and compartmentalize certain logic that would otherwise be entangled with our main rendering code. It also gives us an opportunity to apply as many effects to the final image as we want. Let's see what it takes to implement this technique.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec75"/>Modifying the renderer</h2></div></div></div><p>In order to support all the fancy new techniques we're about to utilize, we need to make some changes to our renderer. It should be able to keep a buffer texture and render to it in multiple passes in order to create the lighting we're looking for:</p><pre class="programlisting">class Renderer { 
  friend Window; 
public: 
  ... 
  void EnableDeferredRendering(); 
  void BeginSceneRendering(); 
  void BeginTextureRendering(); 
  sf::RenderTexture* GetCurrentTexture(); 
  sf::RenderTexture* GetFinishedTexture(); 
  void SwapTextures(); 
  void ClearCurrentTexture(); 
  void ClearFinishedTexture(); 
  void ClearTextures(); 
  void DrawBufferTexture(); 
  void DisableDeferredRendering(); 
  ... 
private: 
  void CreateTextures(); 
  ... 
  sf::Shader* m_currentShader; 
  sf::RenderTexture* m_currentTexture; 
  sf::RenderTexture m_texture1; 
  sf::RenderTexture m_texture2; 
  ... 
  bool m_deferred; 
}; 
</pre><p>For convenience, we have a couple of methods for toggling the deferred rendering process. Also, since rendering a scene to a texture is slightly different than rendering a texture to another texture, because of where the camera (view) is positioned, we will use the <code class="literal">BeginSceneRendering()</code> and <code class="literal">BeginTextureRendering()</code> methods to properly handle the task.</p><p>Note the use of two textures in this class as well as a pointer to point to the texture that is currently in use. The essence of a multi-pass approach is being able to sample the texture holding the information of the previous render pass while drawing to the current render target.</p><p>Lastly, we'll discuss three methods for clearing the current texture, the texture of a previous render pass, and both of these. The most recent render pass texture can then be rendered by calling the <code class="literal">DrawBufferTexture()</code> method.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec14"/>Implementing changes in the Renderer class</h3></div></div></div><p>Let's start with something simple. Implement the deferred rendering toggle methods; they will help you keep track of the current rendering state:</p><pre class="programlisting">void Renderer::EnableDeferredRendering() { 
  if (!m_useShaders) { return; } 
  m_deferred = true; 
} 
 
void Renderer::DisableDeferredRendering() { m_deferred = false; } 
</pre><p>As you can see, it's as simple as flipping a flag. In the case of enabling deferred rendering, we also need to check whether the use of shaders is allowed.</p><p>Also, the textures we're using as buffers clearly need to be created:</p><pre class="programlisting">void Renderer::CreateTextures() { 
  if (!m_useShaders) { return; } 
  m_texture1.create(m_screenSize.x, m_screenSize.y); 
  m_texture2.create(m_screenSize.x, m_screenSize.y); 
  ClearTextures(); 
  m_texture1.display(); 
  m_texture2.display(); 
  m_currentTexture = &amp;m_texture1; 
} 
</pre><p>This particular method is invoked inside the constructor of <code class="literal">Renderer</code>.</p><p>Next, we have something equally as simple, yet quite a bit more important:</p><pre class="programlisting">void Renderer::BeginSceneRendering() { 
  auto&amp; view = m_window-&gt;GetRenderWindow()-&gt;getView(); 
  m_currentTexture-&gt;setView(view); 
} 
 
void Renderer::BeginTextureRendering() { 
  auto&amp; view = m_window-&gt;GetRenderWindow()-&gt;getDefaultView(); 
  m_currentTexture-&gt;setView(view); 
} 
</pre><p>By using these methods at the appropriate time, we can successfully draw shapes that would have world coordinates for a standalone texture buffer the size of a window. We can also simply draw information from another window-sized texture to the buffer.</p><p>Some helpful getter methods are always useful:</p><pre class="programlisting">sf::RenderTexture* Renderer::GetCurrentTexture() { 
  if (!m_useShaders) { return nullptr; } 
  return m_currentTexture; 
} 
 
sf::RenderTexture* Renderer::GetFinishedTexture() { 
  if (!m_useShaders) { return nullptr; } 
  if (!m_currentTexture) { return nullptr; } 
  return (m_currentTexture == &amp;m_texture1 ? 
    &amp;m_texture2 : &amp;m_texture1); 
} 
</pre><p>While the first one simply returns a pointer to the current buffer texture being used, the second method does the exact opposite. It determines which texture is <em>not</em> the current buffer; once it identifies this, it returns a pointer to that object instead. Why exactly this is useful will become apparent shortly.</p><p>Clearing these textures is just as simple as one might think:</p><pre class="programlisting">void Renderer::ClearCurrentTexture() { 
  if (!m_useShaders) { return; } 
  if (!m_currentTexture) { return; } 
  m_currentTexture-&gt;clear(); 
} 
 
void Renderer::ClearFinishedTexture() { 
  if (!m_useShaders) { return; } 
  auto texture = GetFinishedTexture(); 
  if (!texture) { return; } 
  texture-&gt;clear(); 
} 
 
void Renderer::ClearTextures() { 
  if (!m_useShaders) { return; } 
  m_texture1.clear(); 
  m_texture2.clear(); 
} 
</pre><p>In order to prepare for another render pass and display all the changes made to the first buffer, the textures must be swapped like so:</p><pre class="programlisting">void Renderer::SwapTextures() { 
  if (!m_useShaders) { return; } 
  if (m_currentTexture) { m_currentTexture-&gt;display(); } 
  if (m_currentTexture != &amp;m_texture1) { 
    m_currentTexture = &amp;m_texture1; 
  } else { 
    m_currentTexture = &amp;m_texture2; 
  } 
} 
</pre><p>Note the call to the texture's <code class="literal">display</code> method. Calling <code class="literal">display</code> is required because we want all of the changes made to the texture to be reflected. Without calling this method, our progress would not manifest.</p><p>Another key alteration to this class is making sure the buffer texture is being used while deferred rendering is enabled:</p><pre class="programlisting">void Renderer::Draw(const sf::Drawable&amp; l_drawable, 
  sf::RenderTarget* l_target) 
{ 
  if (!l_target) { 
    if (!m_deferred || !m_useShaders) { 
      l_target = m_window-&gt;GetRenderWindow(); 
    } else { l_target = m_currentTexture; } 
  } 
  sf::RenderStates states = sf::RenderStates::Default; 
  if (m_addBlend) { states.blendMode = sf::BlendAdd; } 
  if (m_useShaders &amp;&amp; m_currentShader) { 
    states.shader = m_currentShader; 
  } 
  l_target-&gt;draw(l_drawable, states); 
  ++m_drawCalls; 
} 
</pre><p>After a couple of checks to make sure we're not overwriting an already provided render target and that the use of shaders is enabled, we select the buffer texture by overwriting the <code class="literal">l_target</code> pointer with its address.</p><p>Finally, the buffer texture that has all of the render pass information can be drawn on the screen like so:</p><pre class="programlisting">void Renderer::DrawBufferTexture() { 
  if (!m_useShaders) { return; } 
  auto texture = GetFinishedTexture(); 
  if (!texture) { return; } 
  m_sprite.setTexture(texture-&gt;getTexture()); 
  Draw(m_sprite); 
} 
</pre><p>This simple, yet powerful, design provides us with the possibilities of implementing almost any postprocessing effect imaginable.</p></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec76"/>A minimal example</h2></div></div></div><p>One of the effects incidentally, the focus of this chapter is dynamic lighting. Before we go further and implement the more advanced features or delve into more complex concepts, let's walk through the process of using the newly implemented renderer features. Let's take one step at a time.</p><p>First, the scene should be drawn to the texture buffer as usual:</p><pre class="programlisting">renderer-&gt;EnableDeferredRendering(); 
renderer-&gt;UseShader("default"); 
renderer-&gt;BeginSceneRendering(); 
 
for (unsigned int i = 0; i &lt; Sheet::Num_Layers; ++i) { 
  context-&gt;m_gameMap-&gt;Draw(i); 
  context-&gt;m_systemManager-&gt;Draw(window, i); 
  particles-&gt;Draw(window, i); 
} 
particles-&gt;Draw(window, -1); 
 
renderer-&gt;SwapTextures(); 
</pre><p>As you can see, once deferred rendering is enabled, the default shader is used and the scene rendering process begins. For each layer, the map, entities, and particles are all drawn as usual. The only difference now is that the buffer texture is being used behind the scenes. Once everything is rendered, the textures are swapped; this allows the current back buffer texture to display all the changes:</p><pre class="programlisting">renderer-&gt;BeginTextureRendering(); 
 
if(renderer-&gt;UseShader("LightPass")) { 
  auto shader = renderer-&gt;GetCurrentShader(); 
  auto time = context-&gt;m_gameMap-&gt;GetTimeNormal(); 
  shader-&gt;setUniform("AmbientLight", 
    sf::Glsl::Vec3(time, time, time)); 
  sf::Vector3f lightPos(700.f, 300.f, 10.f); 
  sf::Vector2i screenPos = window-&gt;GetRenderWindow()-&gt; 
    mapCoordsToPixel({ lightPos.x, lightPos.y }); 
  shader-&gt;setUniform("LightPosition", 
    sf::Glsl::Vec3(screenPos.x, window-&gt;GetWindowSize().y - 
    screenPos.y, lightPos.z)); 
  shader-&gt;setUniform("LightColor", 
    sf::Glsl::Vec3(0.1f, 0.1f, 0.1f)); 
  shader-&gt;setUniform("LightRadius", 128.f); 
 
  shader-&gt;setUniform("texture", 
    renderer-&gt;GetFinishedTexture()-&gt;getTexture()); 
 
  auto size = context-&gt;m_wind-&gt;GetWindowSize(); 
 
  sf::VertexArray vertices(sf::TrianglesStrip, 4); 
  vertices[0] = sf::Vertex(sf::Vector2f(0, 0), 
    sf::Vector2f(0,   1)); 
  vertices[1] = sf::Vertex(sf::Vector2f(size.x, 0), 
    sf::Vector2f(1, 1)); 
  vertices[2] = sf::Vertex(sf::Vector2f(0, size.y), 
    sf::Vector2f(0, 0)); 
  vertices[3] = sf::Vertex(sf::Vector2f(size), 
    sf::Vector2f(1, 0)); 
 
  renderer-&gt;Draw(vertices); 
  renderer-&gt;SwapTextures(); 
} 
</pre><p>Once the scene is rendered, we enter what from now on is going to be referred to as the light pass. This special pass uses its own shader and is responsible for the illumination of the scene. It sets up what is known as <em>ambient light</em> as well as regular omnidirectional light.</p><div><div><h3 class="title"><a id="note24"/>Note</h3><p><strong>Ambient light</strong> is a type of light that has no position. It illuminates any part of the scene evenly, regardless of the distance.</p></div></div><p>As illustrated in the preceding code, the point light first has its world coordinates converted into screen-space coordinates, which are then passed as a uniform to the shader. Then, the light color and radius are passed to the shader along with the texture of the previous pass, which, in this case, is simply the color (diffuse) map of the scene.</p><div><div><h3 class="title"><a id="note25"/>Note</h3><p><strong>Point light</strong> is a type of light that emits light in all directions (omnidirectional) from a single point, creating a sphere of illumination.</p></div></div><div><div><h3 class="title"><a id="tip26"/>Tip</h3><p>The screen-space coordinate system has its <em>Y</em> axis inversed from the world coordinate format, meaning the positive <em>Y</em> values go up, not down. This is the reason the light position's <em>Y</em> coordinate has to be adjusted before it is passed to the shader.</p></div></div><p>The next portion of the code is essentially meant to just trigger a full redraw of the diffuse texture onto the buffer texture. We're making a quad comprised of two triangular strips represented as <code class="literal">sf::VertexArray</code>. It's made to be the size of the entire window so that all the pixels could surely be redrawn. Once the quad is drawn, the textures are once again swapped to reflect all the changes:</p><pre class="programlisting">renderer-&gt;DisableDeferredRendering(); 
window-&gt;GetRenderWindow()-&gt;setView( 
  window-&gt;GetRenderWindow()-&gt;getDefaultView()); 
renderer-&gt;DrawBufferTexture(); 
window-&gt;GetRenderWindow()-&gt;setView(currentView); 
renderer-&gt;DisableShader(); 
</pre><p>The last bit of this example simply turns off deferred rendering so that all render operations from now on are done to the window. The window view is then set to its default state, so that the buffer texture can be drawn onscreen easily. Finally, we reset the view back, shortly before whatever shader is still active is disabled.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec15"/>Shader code</h3></div></div></div><p>We're almost done! The last, but definitely not the least, important piece of this puzzle is writing the lighting pass shader correctly in order to get proper results. Given what we already know about the light pass procedure in our C++ code, let's see what GLSL has to offer:</p><pre class="programlisting">uniform sampler2D texture; 
uniform vec3 AmbientLight; 
uniform vec3 LightPosition; 
uniform vec3 LightColor; 
uniform float LightRadius; 
 
void main() 
{ 
  vec4 pixel = texture2D(texture, gl_TexCoord[0].xy); 
 
  float dist = sqrt( 
    pow(LightPosition.x - gl_FragCoord.x, 2) + 
    pow(LightPosition.y - gl_FragCoord.y, 2) + 
    pow(LightPosition.z - gl_FragCoord.z, 2)); 
   
  vec4 finalPixel; 
   
  if(dist &lt;= LightRadius) 
    finalPixel = (gl_Color * pixel) + 
    (pixel * vec4(LightColor, 1.0)); 
  else 
    finalPixel = (gl_Color * pixel) * vec4(AmbientLight, 1.0); 
  gl_FragColor = finalPixel; 
} 
</pre><p>As expected, we need to process the diffuse texture in this pass in order to preserve color information. The other uniform values consist of a 3D vector that represents the ambient color, two 3D vectors for the position and color of a regular source of light, and a floating point value for the radius of the same light.</p><p>The texture that was passed to the shader is sampled at the appropriate, interpolated texture coordinates and stored in the <code class="literal">pixel</code> variable. The distance between the pixel being processed and the light's center is then calculated using the Pythagorean variant distance formula:</p><div><img src="img/B05590_08_01-1.jpg" alt="Shader code"/></div><div><div><h3 class="title"><a id="note27"/>Note</h3><p>The <code class="literal">gl_FragCoord</code> parameter holds the pixel coordinates in the screen space. Its <em>Z</em> component is a depth value, which we're not going to use for the time being.</p></div></div><div><div><h3 class="title"><a id="tip28"/>Tip</h3><p>The <code class="literal">pow</code> function simply returns a value that is raised to the power of its second argument.</p></div></div><p>After the distance is calculated, a check is made to determine whether the distance between the light and the pixel we're working with is within the light's radius. If it is, the color information of our pixel is multiplied by the light color and added to the final pixel that's going to be written. Otherwise, the color information is simply multiplied by the ambient color.</p><p>This fairly basic principle gives us, as one should expect, fairly basic and non-realistic lighting:</p><div><img src="img/image_08_002.jpg" alt="Shader code"/></div><p>Although it works, in reality, light is emitted in all directions. It also slowly loses its brightness. Let's see what it takes to make this happen in our game.</p></div></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec71"/>Attenuating light</h1></div></div></div><p>Light attenuation, also known as gradual loss in intensity, is what we're going to use when creating the effect of a light source that is slowly bleeding away. It essentially comes down to using yet another formula inside the light pass shader. There are many variations of attenuating light that work for different purposes. Let's take a look:</p><pre class="programlisting">uniform sampler2D texture; 
uniform vec3 AmbientLight; 
uniform vec3 LightPosition; 
uniform vec3 LightColor; 
uniform float LightRadius; 
uniform float LightFalloff; 
 
void main() 
{ 
  vec4 pixel = texture2D(texture, gl_TexCoord[0].xy); 
  // Nornalized light vector and distance to the light surface. 
  vec3 L = LightPosition - gl_FragCoord.xyz; 
  float distance = length(L); 
  float d = max(distance - LightRadius, 0); 
  L /= distance; 
  // calculate basic attenuation 
  float attenuation = 1 / pow(d/LightRadius + 1, 2); 
   
  attenuation = (attenuation - LightFalloff) / (1 - LightFalloff); 
  attenuation = max(attenuation, 0); 
   
  vec4 finalPixel = (gl_Color * pixel); 
  finalPixel *= vec4(AmbientLight, 1.0); // IF FIRST PASS ONLY! 
  finalPixel += (pixel * vec4(LightColor, 1.0) * attenuation); 
   
  gl_FragColor = finalPixel; 
} 
</pre><p>Once again, we're dealing with the same uniform values being passed in, but with one additional value of <code class="literal">LightFalloff</code>. It's a factor between <em>0</em> and <em>1</em> that determines how fast a source of light would lose its brightness.</p><p>Inside the <code class="literal">main()</code> function, the diffused pixel is sampled as usual. This is done before we calculate a vector <code class="literal">L</code> that represents the position difference between the pixel and the light's center. This vector is then converted into distance using the <code class="literal">length</code> function. This is the same type of distance that we calculated manually in the first iteration of this shader. The floating number variable <code class="literal">d</code> is then used to calculate the distance between the fragment and the outside of the light by subtracting the light's radius from it. The <code class="literal">max()</code> function simply makes sure we don't get a negative value back if the pixel is inside the light's bubble.</p><p>The attenuation itself, as mentioned before, can have many variations. This particular variation visually works best for the type of game we're dealing with.</p><p>After the calculations are performed, the final output pixel is multiplied by the ambient light (which should only be done during the first pass if there are multiple light passes). Additionally, the light information is multiplied by the diffuse pixel and the attenuation factor is added to it. This last bit of multiplication ensures that, given the pixel is outside the effective light range, no additional light is added to it. The result of this is slightly more appealing to look at:</p><div><img src="img/image_08_003.jpg" alt="Attenuating light"/></div><p>At this point, a very good question you could ask is 'How on earth is this going to work with multiple light input?' Luckily, this is a bit simpler than one might think.</p></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec72"/>Multi-pass shading</h1></div></div></div><p>Much like <em>C/C++</em> code, GLSL does support the use of data arrays. Using them can seem like an obvious choice to just push information about multiple light streams into the shader and have it all done in one pass. Unlike <em>C++</em>, however, GLSL needs to know the sizes of these arrays at compile time, which is very much like <em>C</em>. At the time of writing, dynamic size arrays aren't supported. While this information can put a damper on a naive plan of handling multiple light sources with ease, there are still options to choose from, obviously.</p><p>One approach to combat this may be to have a very large, statically sized array of data. Only some of that data would be filled in and the shader would process it by looping over the array while using a uniform integer that tells it how many lights were actually passed to it. This idea comes with a few obvious bottlenecks. First, there would be a threshold for the maximum number of light streams allowed on the screen. The second issue is performance. Sending data over to the GPU is costly and can quickly become inefficient if we send over too much information all at once.</p><p>As flawed as the first idea is, it has one component that comes in handy when considering a better strategy: the maximum number of light streams allowed. Instead of pushing tons and tons of data through to the GPU at once, why not just do it a little bit at a time in different passes. If the right number of light streams is sent each time, both the CPU and GPU performance bottlenecks can be minimized. The results of each pass can then be blended together into a single texture.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec77"/>Modifying the light pass shader</h2></div></div></div><p>There are a couple of challenges we need to overcome in order to correctly blend the buffer textures of multiple passes. First, there's loss of information due to ambient lighting. If the light is too dark, every subsequent pass becomes less and less visible. To fix this problem, in addition to the color information of the last render pass, we're going to need access to the actual diffuse map.</p><p>The second issue is choosing the right number of light streams per shader pass. This can be benchmarked or simply gotten right through trial and error. For our purposes, we'll go with 3-4 light streams per pass. Let's take a look at how the light shader can be modified to achieve this:</p><pre class="programlisting">uniform sampler2D LastPass; 
uniform sampler2D DiffuseMap; 
uniform vec3 AmbientLight; 
uniform int LightCount; 
uniform int PassNumber; 
 
struct LightInfo { 
  vec3 position; 
  vec3 color; 
  float radius; 
  float falloff; 
}; 
 
const int MaxLights = 3; 
uniform LightInfo Lights[MaxLights]; 
</pre><p>First, note the new <code class="literal">sampler2D</code> uniform type being passed in for the diffuse map. This is going to be invaluable in order to avoid light colors from being washed out with additional passes. The other two bits of additional information we're going to need are values that determine the number of light streams that have been sent to the shader for the current pass and the pass we're dealing with at the moment.</p><p>The actual light information is now neatly stored away in a <code class="literal">struct</code> that holds the usual data we expect. Underneath it, we need to declare a constant integer for the number of maximum light streams per shader pass and the uniform array that's going to be filled in by our C++ code for the light information.</p><p>Let's see the changes that the body of the shader needs to undergo in order to support this:</p><pre class="programlisting">void main() 
{ 
  vec4 pixel = texture2D(LastPass, gl_TexCoord[0].xy); 
  vec4 diffusepixel = texture2D(DiffuseMap, gl_TexCoord[0].xy); 
  vec4 finalPixel = gl_Color * pixel; 
  if(PassNumber == 1) { finalPixel *= vec4(AmbientLight, 1.0); } 
  // IF FIRST PASS ONLY! 
  for(int i = 0; i &lt; LightCount; ++i) { 
     vec3 L = Lights[i].position - gl_FragCoord.xyz; 
     float distance = length(L); 
     float d = max(distance - Lights[i].radius, 0); 
     L /= distance; 
     float attenuation = 1 / pow(d/Lights[i].radius + 1, 2); 
     attenuation = (attenuation - Lights[i].falloff) / 
       (1 - Lights[i].falloff); 
     attenuation = max(attenuation, 0); 
     finalPixel += diffusepixel * 
       ((vec4(Lights[i].color, 1.0) * attenuation)); 
  } 
  gl_FragColor = finalPixel; 
} 
</pre><p>First, we need to sample the diffuse pixel as well as the pixel from the previous shader pass. The <code class="literal">finalPixel</code> variable is established early on and uses the information from the previous shader pass. It is important you note this, because the previous pass would be lost otherwise. Since we have access to the pass number in the shader now, we can selectively apply the ambient light to the pixel only during the first pass.</p><p>We can then jump into a <code class="literal">for</code> loop that uses the <code class="literal">LightCount</code> uniform passed in from the C++ side. This design gives us control to only use as much data as was sent to the shader and not go overboard if the last shader pass has fewer light streams than the maximum number allowed.</p><p>Finally, let's see what needs to change when it comes to the actual shading of the fragment. All our calculations remain the same, except for using light data. The lights uniform is now accessed with the square brackets to fetch the correct information during each iteration of the loop. Note the final pixel calculation at the very bottom of the loop. It now uses the diffuse pixel instead of the pixel of a previous shader pass.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec78"/>Changes in the C++ code</h2></div></div></div><p>None of the fanciness in the GLSL we've just finished is complete without appropriate support from our actual code base. First, let's start with something simple and conveniently represent a light stream in a proper <code class="literal">struct</code>:</p><pre class="programlisting">struct LightBase { 
  LightBase(const sf::Vector3f&amp; l_pos, 
    const sf::Vector3f&amp; l_color, float l_rad, float l_fall) 
    : m_lightPos(l_pos), m_lightColor(l_color), m_radius(l_rad), 
    m_falloff(l_fall) {} 
  LightBase(const sf::Vector3f&amp; l_color): m_lightColor(l_color) {} 
  sf::Vector3f m_lightPos; 
  sf::Vector3f m_lightColor; 
  float m_radius; 
  float m_falloff; 
}; 
</pre><p>That's better! Now let's begin passing in all of the additional information to the shader itself:</p><pre class="programlisting">... // Diffuse pass. 
renderer-&gt;SwapTextures(); 
auto DiffuseImage = renderer-&gt;GetFinishedTexture()-&gt; 
  getTexture().copyToImage(); 
DiffuseImage.flipVertically(); 
auto DiffuseTexture = sf::Texture(); 
DiffuseTexture.loadFromImage(DiffuseImage); 
renderer-&gt;BeginTextureRendering(); 
... 
std::vector&lt;LightBase&gt; lights; 
// {Position}, {Color}, Radius, Falloff 
lights.push_back({ { 700.f, 350.f, 10.f }, { 1.f, 0.f, 0.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 600.f, 350.f, 10.f }, { 0.f, 1.f, 0.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 500.f, 350.f, 10.f }, { 0.f, 0.f, 1.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 400.f, 600.f, 10.f },{ 1.f, 0.f, 0.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 300.f, 600.f, 10.f },{ 0.f, 1.f, 0.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 200.f, 600.f, 10.f },{ 0.f, 0.f, 1.f }, 
  128.f, 0.005f }); 
lights.push_back({ { 600.f, 550.f, 0.f }, { 1.f, 1.f, 1.f }, 
  128.f, 0.005f }); 
 
const int LightsPerPass = 3; 
</pre><p>Right after we're done with drawing onto the diffuse texture, it's copied over and stored in a separate buffer. It's then flipped along the <em>Y</em> axis, as the copying process inverts it.</p><div><div><h3 class="title"><a id="tip29"/>Tip</h3><p>The copying and flipping of the texture here is a proof of concept. It shouldn't be performed in production code, as it's highly inefficient.</p></div></div><p>At this point, we're ready to begin the light pass. Just before we start this, ensure that a couple of light streams are added to <code class="literal">std::vector</code> and are waiting to be passed in. Also, declare a constant at the very bottom that denotes how many light streams are supposed to be passed to a shader every time. This number has to match the constant inside the shader.</p><p>Let's begin with the actual light pass and see what it involves:</p><pre class="programlisting">if (renderer-&gt;UseShader("LightPass")) { 
  renderer-&gt;BeginTextureRendering(); 
  auto shader = renderer-&gt;GetCurrentShader(); 
  shader-&gt;setUniform("AmbientLight", 
    sf::Glsl::Vec3(0.f, 0.f, 0.2f)); 
  int i = 0; 
  int pass = 0; 
  auto lightCount = lights.size(); 
  for (auto&amp; light : lights) { 
    std::string id = "Lights[" + std::to_string(i) + "]"; 
    sf::Vector2i screenPos = window-&gt;GetRenderWindow()-&gt; 
      mapCoordsToPixel({light.m_lightPos.x, light.m_lightPos.y}); 
    shader-&gt;setUniform(id + ".position", sf::Glsl::Vec3( 
      screenPos.x, window-&gt;GetWindowSize().y - screenPos.y, 
      light.m_lightPos.z)); 
    shader-&gt;setUniform(id + ".color", 
      sf::Glsl::Vec3(light.m_lightColor)); 
    shader-&gt;setUniform(id + ".radius", light.m_radius); 
    shader-&gt;setUniform(id + ".falloff", light.m_falloff); 
    ++i; 
    if (i &lt; LightsPerPass &amp;&amp; (pass * LightsPerPass) + i 
      &lt; lightCount) 
    { continue; } 
    shader-&gt;setUniform("LightCount", i); 
    i = 0; 
    shader-&gt;setUniform("PassNumber", pass + 1); 
    shader-&gt;setUniform("LastPass", 
      renderer-&gt;GetFinishedTexture()-&gt;getTexture()); 
    shader-&gt;setUniform("DiffuseMap", DiffuseTexture); 
    renderer-&gt;Draw(vertices); 
    renderer-&gt;SwapTextures(); 
    renderer-&gt;BeginTextureRendering(); 
    ++pass; 
  } 
} 
... 
</pre><p>Ambient lighting is first set up, as it's not going to change between the iterations. In this case, we're giving it a slight blue tint. Additionally, a couple of local variables for the iteration and pass are created in order to have this information handy.</p><p>As we're iterating over each light stream, a string called <code class="literal">id</code> is created with the integer of each iteration passed inside. This is meant to represent the array access analysis of the light streams' uniform inside the shader, and it will serve as a helpful way of allowing us to access and overwrite that data. The light information is then passed in using the <code class="literal">id</code> string with an attached dot operator and the name of the <code class="literal">struct</code> data member. The light's identifier <code class="literal">i</code> is incremented shortly after. At this point, we need to decide whether the required number of light streams have been processed in order to invoke the shader. If the last light stream for the pass has been added, or if we're dealing with the last light stream of the scene, the rest of the uniforms are initialized and the fullscreen <code class="literal">sf::VertexArray</code> quad we talked about earlier is drawn, invoking a shader for each visible pixel. This effectively gives us a result like this:</p><div><img src="img/image_08_004.jpg" alt="Changes in the C++ code"/></div><p>Now we're getting somewhere! The only downside to this is all of the mess we have to deal with in our C++ code, as none of this data is managed properly. Let's fix this now!</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec73"/>Managing light input</h1></div></div></div><p>Good data organization is important in every aspect of software design. It's hard to imagine an application that would run quickly and efficiently, yet wants have a strong, powerful, and flexible framework running in the backend. Our situation up until this point has been fairly manageable, but imagine you want to draw additional textures for the map, entities, and all your particles. This would quickly become tiresome to deal with and maintain. It's time to utilize our engineering ingenuity and come up with a better system.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec79"/>Interface for light users</h2></div></div></div><p>First and foremost, each class that desires to use our lighting engine would need to implement their own version of drawing certain types of textures to the buffer(s). For diffuse maps, we already have the plain old regular <code class="literal">Draw</code> calls, but even if they are all lucky enough to have the same signature, that's not good enough. A common interface for these classes is needed in order to make them a successful part of the lighting family:</p><pre class="programlisting">class LightManager; 
class Window; 
 
class LightUser { 
  friend class LightManager; 
  virtual void Draw(MaterialMapContainer&amp; l_materials, 
    Window&amp; l_window, int l_layer) = 0; 
}; 
</pre><p>The <code class="literal">LightUser</code> class forces any derivatives to implement a special <code class="literal">Draw</code> method that uses a material container. It also has access to the <code class="literal">Window</code> class and knows which layer it's trying to draw to. 'What's a material container?' you may ask? Let's find out by taking this design further.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec80"/>The light manager class</h2></div></div></div><p>Before we design a grand class that would take care of all our lighting needs, let's talk about materials. As it so happens, we've already dealt with one type of material: the diffuse map. There are many other possible materials we're going to work with, so let's not beat around the bush any longer and see what they are:</p><pre class="programlisting">enum class MaterialMapType { Diffuse, Height, Normal, 
  Specular, COUNT }; 
using MaterialMapContainer = std::unordered_map&lt; 
  MaterialMapType, std::unique_ptr&lt;sf::RenderTexture&gt;&gt;; 
</pre><p>In addition to diffuse maps, we're going to build <em>height</em>, <em>normal</em>, and <em>specular</em> maps as well. None of these terms will probably make sense right now, but that's alright. Each one will be explained in detail as we cross that bridge.</p><p>The material map container type is simply a map that links a type to a <code class="literal">sf::RenderTexture</code>. This way, we can have a separate texture for each material type.</p><p>For the light manager, we're only going to need two type definitions:</p><pre class="programlisting">using LightContainer = std::vector&lt;LightBase&gt;; 
using LightUserContainer = std::vector&lt;LightUser*&gt;; 
</pre><p>As you can see, they're extremely simple. We're going to store the light streams themselves along with pointers to the light user classes in vectors, as nothing fancier is necessary here. With that, let's take a look at the actual definition of the <code class="literal">LightManager</code> class:</p><pre class="programlisting">class Window; 
 
class LightManager { 
public: 
  LightManager(Window* l_window); 
 
  void AddLight(const LightBase&amp; l_light); 
  void AddLightUser(LightUser* l_user); 
  LightBase* GetAmbientLight(); 
 
  void RenderMaterials(); 
  void RenderScene(); 
 
  const unsigned int LightsPerPass = 4; 
protected: 
  MaterialMapContainer m_materialMaps; 
private: 
  void ClearAll(); 
  void SetViews(); 
  void DisplayAll(); 
  LightBase m_ambientLight; 
  LightContainer m_lights; 
  LightUserContainer m_users; 
 
  sf::VertexArray m_fullScreenQuad; 
 
  Window* m_window; 
}; 
</pre><p>As you can see, this is as basic as it can be. The constructor takes in a pointer to the <code class="literal">Window</code> class. We have a couple of <code class="literal">add</code>methods for the light users, as well as the light streams themselves. We also have a few render methods for specific tasks. Note the constant integer that this class defines for the maximum number of light streams allowed per shader pass. Rendering only three light streams like we did before is a bit wasteful, so this can be upped even more, provided it doesn't become detrimental to the performance of the process.</p><p>The helper methods of which there are three--deal with clearing the buffer textures, setting their views, and displaying the changes made to them. We also store the <code class="literal">sf::VertexArray</code> of the quad that we're going to use to perform a light pass operation.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec16"/>Implementing the light manager</h3></div></div></div><p>As always, let's begin by seeing what needs to be constructed when the light manager is created:</p><pre class="programlisting">LightManager::LightManager(Window* l_window) : m_window(l_window), 
  m_ambientLight({ 0.f, 0.f, 0.f }) 
{ 
  auto windowSize = l_window-&gt;GetWindowSize(); 
  for (auto i = 0; 
    i &lt; static_cast&lt;int&gt;(MaterialMapType::COUNT); ++i) 
  { 
    auto pair = m_materialMaps.emplace( 
      static_cast&lt;MaterialMapType&gt;(i), 
      std::move(std::make_unique&lt;sf::RenderTexture&gt;())); 
    auto&amp; texture = pair.first-&gt;second; 
    texture-&gt;create(windowSize.x, windowSize.y); 
  } 
 
  m_fullScreenQuad = sf::VertexArray(sf::TriangleStrip, 4); 
 
  m_fullScreenQuad[0] = sf::Vertex( 
    sf::Vector2f(0, 0), sf::Vector2f(0, 1)); 
  m_fullScreenQuad[1] = sf::Vertex( 
    sf::Vector2f(windowSize.x, 0), sf::Vector2f(1, 1)); 
  m_fullScreenQuad[2] = sf::Vertex( 
    sf::Vector2f(0, windowSize.y), sf::Vector2f(0, 0)); 
  m_fullScreenQuad[3] = sf::Vertex( 
    sf::Vector2f(windowSize), sf::Vector2f(1, 0)); 
} 
</pre><p>The initializer list is useful for storing the <code class="literal">Window</code> pointer, as well as initializing the ambient lighting to absolute black. Once this is done, the window size is obtained and all the material textures are created. Lastly, the window-sized quad is set up for later use.</p><p>The adder and getter methods are quite simple, yet they are necessary:</p><pre class="programlisting">void LightManager::AddLight(const LightBase&amp; l_light) { 
  m_lights.push_back(l_light); 
} 
void LightManager::AddLightUser(LightUser* l_user) { 
  m_users.emplace_back(l_user); 
} 
LightBase* LightManager::GetAmbientLight() { 
  return &amp;m_ambientLight; 
} 
</pre><p>Dealing with material maps all at once can be quite wasteful typing-wise, so we need a few methods to help us do this quickly:</p><pre class="programlisting">void LightManager::ClearAll() { 
  for (auto&amp; map : m_materialMaps) { map.second-&gt;clear(); } 
} 
 
void LightManager::SetViews() { 
  auto view = m_window-&gt;GetRenderWindow()-&gt;getView(); 
  for (auto&amp; map : m_materialMaps) { map.second-&gt;setView(view); } 
} 
 
void LightManager::DisplayAll() { 
  for (auto&amp; map : m_materialMaps) { map.second-&gt;display(); } 
} 
</pre><p>Note the view we're using in <code class="literal">SetViews()</code>. Since these material maps are going to be used instead of the window, they must use the window's view in order to handle the world coordinates of all the visuals being drawn.</p><p>Speaking of material maps, every class that wishes to use our light manager should be able to draw to every single one of them. Luckily, we've made it easier on ourselves by making it a requirement that these classes implement a purely virtual <code class="literal">Draw</code> method:</p><pre class="programlisting">void LightManager::RenderMaterials() { 
  ClearAll(); 
  SetViews(); 
  // Render each elevation in proper order. 
  for (auto i = 0; i &lt; Sheet::Num_Layers; ++i) { 
    for (auto&amp; user : m_users) { 
      user-&gt;Draw(m_materialMaps, *m_window, i); 
    } 
  } 
  // Render everything above allowed height. 
  for (auto&amp; user : m_users) { 
    user-&gt;Draw(m_materialMaps, *m_window, -1); 
  } 
  DisplayAll(); 
} 
</pre><p>After all the textures are cleared and their views are set, each light user needs to draw something for each of the allowed layers our game engine supports. Quite literally, on top of this, any visuals that are above these elevations also need to have a chance to be rendered, which we can achieve by using the second loop. All the material textures are then updated by invoking the <code class="literal">DisplayAll()</code> method.</p><p>Once the materials are drawn, we need to go through the same process of multi-pass shading as we did in our minimal code example:</p><pre class="programlisting">void LightManager::RenderScene() { 
  auto renderer = m_window-&gt;GetRenderer(); 
  auto window = m_window-&gt;GetRenderWindow(); 
  auto size = window-&gt;getSize(); 
  auto currentView = window-&gt;getView(); 
 
  renderer-&gt;EnableDeferredRendering(); 
 
  if (renderer-&gt;UseShader("LightPass")) { 
    // Light pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    shader-&gt;setUniform("AmbientLight", 
      sf::Glsl::Vec3(m_ambientLight.m_lightColor)); 
    shader-&gt;setUniform("DiffuseMap", 
      m_materialMaps[MaterialMapType::Diffuse]-&gt;getTexture()); 
    ... 
    int LightID = 0; 
    int pass = 0; 
    for (auto&amp; light : m_lights) { 
      std::string id = "Lights[" + std::to_string(LightID) + "]"; 
      sf::Vector2i screenPos = window-&gt;mapCoordsToPixel( 
        { light.m_lightPos.x, light.m_lightPos.y }, currentView); 
      float y = static_cast&lt;float&gt;( 
        static_cast&lt;int&gt;(size.y) - screenPos.y); 
      shader-&gt;setUniform(id + ".position", 
        sf::Glsl::Vec3(screenPos.x, y, light.m_lightPos.z)); 
      shader-&gt;setUniform(id + ".color", 
        sf::Glsl::Vec3(light.m_lightColor)); 
      shader-&gt;setUniform(id + ".radius", light.m_radius); 
      shader-&gt;setUniform(id + ".falloff", light.m_falloff); 
      ++LightID; 
      if (LightID &lt; LightsPerPass &amp;&amp; (pass * LightsPerPass) 
        + LightID &lt; m_lights.size()) 
      { continue; } 
      renderer-&gt;BeginTextureRendering(); 
      shader-&gt;setUniform("LightCount", LightID); 
      LightID = 0; 
      shader-&gt;setUniform("PassNumber", pass + 1); 
      if (pass == 0) { 
        shader-&gt;setUniform("LastPass", 
          m_materialMaps[MaterialMapType::Diffuse]-&gt;getTexture()); 
      } else { 
        shader-&gt;setUniform("LastPass", 
          renderer-&gt;GetFinishedTexture()-&gt;getTexture()); 
      } 
      renderer-&gt;Draw(m_fullScreenQuad); 
      renderer-&gt;SwapTextures(); 
      ++pass; 
    } 
  } 
   
  renderer-&gt;DisableDeferredRendering(); 
  renderer-&gt;DisableShader(); 
  window-&gt;setView(window-&gt;getDefaultView()); 
  renderer-&gt;DrawBufferTexture(); 
  window-&gt;setView(currentView); 
} 
</pre><p>This is very close to the already established model we discussed before. A couple of changes to note here are: the use of an internal data member called <code class="literal">m_materialMaps</code> for passing material information to the light pass shader and the check near the bottom where the diffuse texture is passed in as the <code class="literal">"LastPass"</code> uniform if it is the very first shader pass. This has to be done otherwise we'd be sampling a completely black texture.</p></div><div><div><div><div><h3 class="title"><a id="ch08lvl3sec17"/>Integrating the light manager class</h3></div></div></div><p>Once the light manager is implemented, we can add all the classes that use it to its list:</p><pre class="programlisting">State_Game::State_Game(StateManager* l_stateManager) 
  : BaseState(l_stateManager), 
    m_lightManager(l_stateManager-&gt;GetContext()-&gt;m_wind) 
{ 
  auto context = m_stateMgr-&gt;GetContext(); 
  m_lightManager.AddLightUser(context-&gt;m_gameMap); 
  m_lightManager.AddLightUser(context-&gt;m_systemManager); 
  m_lightManager.AddLightUser(context-&gt;m_particles); 
} 
</pre><p>In this case, we're only working with the game map, the system manager, and the particle manager classes as light users.</p><p>Setting up our previous light information is equally as easy now as it was before:</p><pre class="programlisting">void State_Game::OnCreate() { 
  ... 
  m_lightManager.GetAmbientLight()-&gt;m_lightColor = 
    sf::Vector3f(0.2f, 0.2f, 0.2f); 
  m_lightManager.AddLight({ { 700.f, 350.f, 32.f }, 
    { 1.f, 0.f, 0.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 600.f, 350.f, 32.f }, 
    { 0.f, 1.f, 0.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 500.f, 350.f, 32.f }, 
    { 0.f, 0.f, 1.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 400.f, 600.f, 32.f }, 
    { 1.f, 0.f, 0.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 300.f, 600.f, 32.f }, 
    { 0.f, 1.f, 0.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 200.f, 600.f, 32.f }, 
    { 0.f, 0.f, 1.f }, 128.f, 0.005f }); 
  m_lightManager.AddLight({ { 600.f, 550.f, 33.f }, 
    { 1.f, 1.f, 1.f }, 128.f, 0.01f }); 
} 
</pre><p>Finally, we just need to make sure the material maps are drawn, just like the scene itself:</p><pre class="programlisting">void State_Game::Draw() { 
  m_lightManager.RenderMaterials(); 
  m_lightManager.RenderScene(); 
} 
</pre><p>Now, the only thing left to do is to adapt those pesky classes to the new lighting model we have set up here.</p></div></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec74"/>Adapting classes to use lights</h1></div></div></div><p>Obviously, each and every single class that does any rendering in our game does it differently. Rendering the same graphics to different types of material maps is no exception to this rule. Let's see how every light-supporting class should implement their respective <code class="literal">Draw</code> methods in order to stay in sync with our lighting system.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec81"/>The Map class</h2></div></div></div><p>The first class we need to deal with is the <code class="literal">Map</code> class. It will be a bit different due to the way it handles the drawing of tiles. So let's take a look at what needs to be added in:</p><pre class="programlisting">class Map : ..., public LightUser { 
public: 
  ... 
  void Draw(MaterialMapContainer&amp; l_materials, 
    Window&amp; l_window, int l_layer); 
protected: 
  ... 
  Void CheckTextureSizes(int l_fromZ, int l_toZ); 
  std::array&lt;sf::RenderTexture, Sheet::Num_Layers&gt; m_textures; 
  ... 
}; 
</pre><p>So far, so good! The <code class="literal">Map</code> class is now using the <code class="literal">LightUser</code> interface. The <code class="literal">m_textures</code> data member is an established array that existed before all of this and it simply stores different textures for each supported elevation. One new protected member function is added though, called <code class="literal">CheckTextureSizes</code>:</p><pre class="programlisting">void Map::CheckTextureSizes(int l_fromZ, int l_toZ) { 
  auto realMapSize = m_tileMap.GetMapSize() * 
    static_cast&lt;unsigned int&gt;(Sheet::Tile_Size); 
  for (auto layer = l_fromZ; layer &lt;= l_toZ; ++layer) { 
    if (m_textures[layer].getSize() != realMapSize) { 
      ... // Information printed to the console. 
      if (!m_textures[layer].create(realMapSize.x, realMapSize.y)) 
      { ... } // Error message. 
    } 
    ... // Other textures. 
  } 
} 
</pre><p>This is just a handy way of making sure all the future textures, as well as the current diffuse maps, have the appropriate size.</p><p>Let's see what the <code class="literal">Redraw</code> method now needs to do in order to fully support the light manager:</p><pre class="programlisting">void Map::Redraw(sf::Vector3i l_from, sf::Vector3i l_to) { 
  ... 
  CheckTextureSizes(l_from.z, l_to.z); 
  ClearMapTexture(l_from, originalTo); 
  auto renderer = m_window-&gt;GetRenderer(); 
 
  if (renderer-&gt;UseShader("default")) { 
    // Diffuse pass. 
    for (auto x = l_from.x; x &lt;= l_to.x; ++x) { 
      for (auto y = l_from.y; y &lt;= l_to.y; ++y) { 
        for (auto layer = l_from.z; layer &lt;= l_to.z; ++layer) { 
          auto tile = m_tileMap.GetTile(x, y, layer); 
          if (!tile) { continue; } 
          auto&amp; sprite = tile-&gt;m_properties-&gt;m_sprite; 
          sprite.setPosition( 
            static_cast&lt;float&gt;(x * Sheet::Tile_Size), 
            static_cast&lt;float&gt;(y * Sheet::Tile_Size)); 
          renderer-&gt;Draw(sprite, &amp;m_textures[layer]); 
        } 
      } 
    } 
  } 
  ... // Other passes. 
  renderer-&gt;DisableShader(); 
  DisplayAllTextures(l_from.z, l_to.z); 
} 
</pre><p>Only a few extra lines add the support here. We just need to make sure the renderer is involved when the drawing is happening because it allows the right shader to be used in the process.</p><p>Since we're going to add more material maps quite soon, clearing of these textures also needs to be integrated into the existing code:</p><pre class="programlisting">void Map::ClearMapTexture(sf::Vector3i l_from, sf::Vector3i l_to){ 
  ... 
  if (l_to.x == -1 &amp;&amp; l_to.y == -1) { 
    // Clearing the entire texture. 
    for (auto layer = l_from.z; layer &lt;= toLayer; ++layer) { 
      m_textures[layer].clear({ 0,0,0,0 }); 
      ... // Other textures. 
    } 
    return; 
  } 
  // Portion of the map needs clearing. 
  ... 
  for (auto layer = l_from.z; layer &lt;= toLayer; ++layer) { 
    m_textures[layer].draw(shape, sf::BlendMultiply); 
    ... // Other textures. 
  } 
  DisplayAllTextures(l_from.z, toLayer); 
} 
</pre><p>The spaces for doing so are marked with comments, which is exactly the same for the helper methods that aid in displaying all the changes made to these buffer textures:</p><pre class="programlisting">void Map::DisplayAllTextures(int l_fromZ, int l_toZ) { 
  for (auto layer = l_fromZ; layer &lt;= l_toZ; ++layer) { 
    m_textures[layer].display(); 
    ... // Other textures. 
  } 
} 
</pre><p>The actual <code class="literal">Draw</code> method from the <code class="literal">LightUser</code> class can be implemented like this:</p><pre class="programlisting">void Map::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  if (l_layer &lt; 0) { return; } 
  if (l_layer &gt;= Sheet::Num_Layers) { return; } 
  auto rect = sf::IntRect(sf::Vector2i(0, 0), 
    sf::Vector2i(m_textures[l_layer].getSize())); 
  m_layerSprite.setTextureRect(rect); 
  // Diffuse. 
  m_layerSprite.setTexture(m_textures[l_layer].getTexture()); 
  m_window-&gt;GetRenderer()-&gt;Draw(m_layerSprite, 
    l_materials[MaterialMapType::Diffuse].get()); 
  ... // Other textures. 
} 
</pre><p>Because of the way the <code class="literal">Map</code> class works, all we have to do is set up the sprite we're working with to use the right texture for the appropriate material type. In this case, all we need is the diffuse texture.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec82"/>The entity renderer system</h2></div></div></div><p>If you recall, the <code class="literal">SystemManager</code> class is the one we added to <code class="literal">LightManager</code> as <code class="literal">LightUser</code>. Although there's only one system that does the rendering for now, we still want to keep it this way and simply forward all the arguments passed to <code class="literal">SystemManager</code>. This keeps our options for additional systems doing the same thing open in the future:</p><pre class="programlisting">void SystemManager::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  auto system = dynamic_cast&lt;S_Renderer*&gt;(itr-&gt;second.get()); 
  system-&gt;Draw(l_materials, l_window, l_layer); 
} 
</pre><p>The forwarded arguments are sent to <code class="literal">S_Renderer</code> and can be used like so:</p><pre class="programlisting">void S_Renderer::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("default")) { 
    // Diffuse pass. 
    for (auto &amp;entity : m_entities) { 
      auto position = entities-&gt;GetComponent&lt;C_Position&gt;( 
        entity, Component::Position); 
      if (position-&gt;GetElevation() &lt; l_layer) { continue; } 
      if (position-&gt;GetElevation() &gt; l_layer) { break; } 
      C_Drawable* drawable = GetDrawableFromType(entity); 
      if (!drawable) { continue; } 
      drawable-&gt;Draw(&amp;l_window, 
        l_materials[MaterialMapType::Diffuse].get()); 
    } 
  } 
  ... // Other passes. 
  renderer-&gt;DisableShader(); 
} 
</pre><p>It's fairly similar to how the <code class="literal">Map</code> class handles its redrawing process. All we need to do is make sure the Renderer class is used to do the drawing to the diffuse texture, which is what happens under the hood, as <code class="literal">C_Drawable</code> simply passes these arguments down the line:</p><pre class="programlisting">class C_Drawable : public C_Base{ 
  ... 
  virtual void Draw(Window* l_wind, 
    sf::RenderTarget* l_target = nullptr) = 0; 
}; 
 
class C_SpriteSheet : public C_Drawable{ 
  ... 
  void Draw(Window* l_wind, sf::RenderTarget* l_target = nullptr){ 
    if (!m_spriteSheet) { return; } 
    m_spriteSheet-&gt;Draw(l_wind, l_target); 
  } 
  ... 
}; 
 
void SpriteSheet::Draw(Window* l_wnd, sf::RenderTarget* l_target) { 
  l_wnd-&gt;GetRenderer()-&gt;Draw(m_sprite, l_target); 
} 
</pre></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec83"/>The particle system</h2></div></div></div><p>Drawing particles in this way is not much different from how other <code class="literal">LightUser</code> do it:</p><pre class="programlisting">void ParticleSystem::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("default")) { 
  // Diffuse pass. 
    for (size_t i = 0; i &lt; container-&gt;m_countAlive; ++i) { 
      if (l_layer &gt;= 0) { 
        if (positions[i].z &lt; l_layer * Sheet::Tile_Size) 
        { continue; } 
        if (positions[i].z &gt;= (l_layer + 1) * Sheet::Tile_Size) 
        { continue; } 
      } else if(positions[i].z&lt;Sheet::Num_Layers*Sheet::Tile_Size) 
      { continue; } 
      renderer-&gt;AdditiveBlend(blendModes[i]); 
      renderer-&gt;Draw(drawables[i], 
        l_materials[MaterialMapType::Diffuse].get()); 
    } 
  } 
  renderer-&gt;AdditiveBlend(false); 
  ... // Other passes. 
  renderer-&gt;DisableShader(); 
} 
</pre><p>Once again, it's all about making sure the materials are passed through <code class="literal">Renderer</code>.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec75"/>Preparing for additional materials</h1></div></div></div><p>Drawing basic light streams is fairly nifty. But let's face it, we want to do more than that! Any additional processing is going to require further material information about the surfaces we're working with. As far as storing those materials goes, the <code class="literal">Map</code> class needs to allocate additional space for textures that will be used for this purpose:</p><pre class="programlisting">class Map : ..., public LightUser { 
public: 
  ... 
  void Draw(MaterialMapContainer&amp; l_materials, 
    Window&amp; l_window, int l_layer); 
protected: 
  ... 
  std::array&lt;sf::RenderTexture, Sheet::Num_Layers&gt; m_textures; 
  std::array&lt;sf::RenderTexture, Sheet::Num_Layers&gt; m_normals; 
  std::array&lt;sf::RenderTexture, Sheet::Num_Layers&gt; m_speculars; 
  std::array&lt;sf::RenderTexture, Sheet::Num_Layers&gt; m_heightMap; 
  ... 
}; 
</pre><p>These textures will also need to be checked for incorrect sizes and adjusted if it ever comes to that:</p><pre class="programlisting">void Map::CheckTextureSizes(int l_fromZ, int l_toZ) { 
  auto realMapSize = m_tileMap.GetMapSize() * 
    static_cast&lt;unsigned int&gt;(Sheet::Tile_Size); 
  for (auto layer = l_fromZ; layer &lt;= l_toZ; ++layer) { 
    ... 
    if (m_normals[layer].getSize() != realMapSize) { 
      if (!m_normals[layer].create(realMapSize.x, realMapSize.y)) 
      { ... } 
    } 
    if (m_speculars[layer].getSize() != realMapSize) { 
      if (!m_speculars[layer].create(realMapSize.x,realMapSize.y)) 
      { ... } 
    } 
    if (m_heightMap[layer].getSize() != realMapSize) { 
      if (!m_heightMap[layer].create(realMapSize.x,realMapSize.y)) 
      { ... } 
    } 
  } 
} 
</pre><p>Clearing the material maps is equally as simple; we just need to add a couple of extra lines:</p><pre class="programlisting">void Map::ClearMapTexture(sf::Vector3i l_from, sf::Vector3i l_to) 
{ 
  ... 
  if (l_to.x == -1 &amp;&amp; l_to.y == -1) { 
    for (auto layer = l_from.z; layer &lt;= toLayer; ++layer) { 
      ... 
      m_normals[layer].clear({ 0,0,0,0 }); 
      m_speculars[layer].clear({ 0,0,0,0 }); 
      m_heightMap[layer].clear({ 0,0,0,0 }); 
    } 
    return; 
  } 
  ... 
  for (auto layer = l_from.z; layer &lt;= toLayer; ++layer) { 
    ... 
    m_normals[layer].draw(shape, sf::BlendMultiply); 
    m_speculars[layer].draw(shape, sf::BlendMultiply); 
    m_heightMap[layer].draw(shape, sf::BlendMultiply); 
  } 
  DisplayAllTextures(l_from.z, toLayer); 
} 
</pre><p>Displaying the changes that were made to the buffer textures follows the same easy and manageable approach:</p><pre class="programlisting">void Map::DisplayAllTextures(int l_fromZ, int l_toZ) { 
  for (auto layer = l_fromZ; layer &lt;= l_toZ; ++layer) { 
    m_textures[layer].display(); 
    m_normals[layer].display(); 
    m_speculars[layer].display(); 
    m_heightMap[layer].display(); 
  } 
} 
</pre><p>Finally, drawing this information to the internal buffers of <code class="literal">LightManager</code>, in the case of the <code class="literal">Map</code> class, can be done like so:</p><pre class="programlisting">void Map::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... // Diffuse. 
  // Normal. 
  m_layerSprite.setTexture(m_normals[l_layer].getTexture()); 
  m_window-&gt;GetRenderer()-&gt;Draw(m_layerSprite, 
    l_materials[MaterialMapType::Normal].get()); 
  // Specular. 
  m_layerSprite.setTexture(m_speculars[l_layer].getTexture()); 
  m_window-&gt;GetRenderer()-&gt;Draw(m_layerSprite, 
    l_materials[MaterialMapType::Specular].get()); 
  // Height. 
  m_layerSprite.setTexture(m_heightMap[l_layer].getTexture()); 
  m_window-&gt;GetRenderer()-&gt;Draw(m_layerSprite, 
    l_materials[MaterialMapType::Height].get()); 
} 
</pre><p>Easy enough? Good! Let's keep progressing and build shaders that can handle the process of drawing these material maps.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec84"/>Preparing the texture manager</h2></div></div></div><p>In order to automatically load the additional material maps when loading diffuse images, we need to make some very quick and painless changes to the <code class="literal">ResourceManager</code> and <code class="literal">TextureManager</code> classes:</p><pre class="programlisting">class ResourceManager{ 
public: 
  bool RequireResource(const std::string&amp; l_id, 
    bool l_notifyDerived = true) 
  { 
    ... 
    if (l_notifyDerived) { OnRequire(l_id); } 
    return true; 
  } 
 
  bool ReleaseResource(const std::string&amp; l_id, 
    bool l_notifyDerived = true) 
  { 
    ... 
    if (l_notifyDerived) { OnRelease(l_id); } 
    return true; 
  } 
protected: 
  ... 
  virtual void OnRequire(const std::string&amp; l_id) {} 
  virtual void OnRelease(const std::string&amp; l_id) {} 
}; 
 
class TextureManager : ...{ 
public: 
  ... 
  void OnRequire(const std::string&amp; l_id) { 
    if (RequireResource(l_id + "_normal", false)) { ... } 
    if (RequireResource(l_id + "_specular", false)) { ... } 
  } 
 
  void OnRelease(const std::string&amp; l_id) { 
    if (ReleaseResource(l_id + "_normal", false)) { ... } 
    if (ReleaseResource(l_id + "_specular", false)) { ... } 
  } 
}; 
</pre><p>By adding the <code class="literal">OnRequire()</code> and <code class="literal">OnRelease()</code> methods and integrating them properly with the <code class="literal">l_notifyDerived</code> flag to avoid infinite recursion, <code class="literal">TextureManager</code> can safely load in both the normal and specular material maps when a diffuse texture is loaded, provided they are found. Note that the texture manager actually passes in <code class="literal">false</code> as the second argument when it needs these maps to avoid infinite recursion.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec85"/>Material pass shaders</h2></div></div></div><p>There will be two types of material pass shaders we'll use. One type, simply referred to as <em>MaterialPass</em>, will sample the material color from a texture:</p><pre class="programlisting">uniform sampler2D texture; 
uniform sampler2D material; 
void main() 
{ 
  vec4 pixel = texture2D(texture, gl_TexCoord[0].xy); 
  vec4 materialPixel = texture2D(material, gl_TexCoord[0].xy); 
  materialPixel.a *= pixel.a; 
  gl_FragColor = gl_Color * materialPixel; 
} 
</pre><p>It retrieves the diffuse pixel and the material texture pixel, as well as uses the diffuse alpha value to display the right color. This effectively means that if we're dealing with a transparent pixel on a diffuse map, no material color is going to be rendered for it. Otherwise, the material color is completely independent of the diffuse pixel. This is useful for drawing images that also have material maps located in a different texture.</p><p>The second type of material shader, known from here on out as <em>MaterialValuePass</em>, will also sample the diffuse pixel. Instead of using a material texture, however, it'll simply use a static color value for all the pixels that aren't transparent:</p><pre class="programlisting">uniform sampler2D texture; 
uniform vec3 material; 
void main() 
{ 
  vec4 pixel = texture2D(texture, gl_TexCoord[0].xy); 
  float alpha = 0.0; 
  if(pixel == vec4(0.0, 0.0, 0.0, 1.0)) 
    alpha = gl_Color.a; 
  else 
    alpha = pixel.a; 
  gl_FragColor = gl_Color * vec4(material.rgb, alpha); 
} 
</pre><p>Here, we first verify that the sampled pixel isn't completely black. If it is, the <code class="literal">alpha</code> value of <code class="literal">gl_Color</code> is used instead of that of the pixel. Then, we simply write the static material color value to the fragment. This type of shader is useful for drawable objects that don't have material maps and instead use a static color for every single pixel.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec76"/>Normal maps</h1></div></div></div><p>Lighting can be used to create visually complex and breath taking scenes. One of the massive benefits of having a lighting system is the ability it provides to add extra details to your scene, which wouldn't have been possible otherwise. One way of doing so is using <strong>normal maps</strong>.</p><p>Mathematically speaking, the word <em>normal</em> in the context of a surface is simply a directional vector that is perpendicular to said surface. Consider the following illustration:</p><div><img src="img/image_08_005.jpg" alt="Normal maps"/></div><p>In this case, what's normal is facing up because that's the direction perpendicular to the plane. How is this helpful? Well, imagine you have a really complex model with many vertices; it'd be extremely taxing to render said model because of all the geometry that would need to be processed with each frame. A clever trick to work around this, known as <strong>normal mapping</strong>, is to take the information of all of those vertices and save them on a texture that looks similar to this one:</p><div><img src="img/image_08_006.jpg" alt="Normal maps"/></div><p>It probably looks extremely funky, especially if being looked at in a physical release of this book that's in grayscale, but try not to think of this in terms of colors, but directions. The red channel of a normal map encodes the <em>-x</em> and <em>+x</em> values. The green channel does the same for <em>-y</em> and <em>+y</em> values, and the blue channel is used for <em>-z</em> to <em>+z</em>. Looking back at the previous image now, it's easier to confirm which direction each individual pixel is facing. Using this information on geometry that's completely flat would still allow us to light it in such a way that it would make it look like it has all of the detail in there; yet, it would still remain flat and light on performance:</p><div><img src="img/image_08_007.jpg" alt="Normal maps"/></div><p>These normal maps can be hand-drawn or simply generated using software such as <em>Crazybump</em>. Let's see how all of this can be done in our game engine.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec86"/>Implementing normal map rendering</h2></div></div></div><p>In the case of maps, implementing normal map rendering is extremely simple. We already have all the material maps integrated and ready to go, so at this time, it's simply a matter of sampling the texture of the tile sheet normals:</p><pre class="programlisting">void Map::Redraw(sf::Vector3i l_from, sf::Vector3i l_to) { 
  ... 
  if (renderer-&gt;UseShader("MaterialPass")) { 
    // Material pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    auto textureName = m_tileMap.GetTileSet().GetTextureName(); 
    auto normalMaterial = m_textureManager-&gt; 
      GetResource(textureName + "_normal"); 
    for (auto x = l_from.x; x &lt;= l_to.x; ++x) { 
      for (auto y = l_from.y; y &lt;= l_to.y; ++y) { 
        for (auto layer = l_from.z; layer &lt;= l_to.z; ++layer) { 
          auto tile = m_tileMap.GetTile(x, y, layer); 
          if (!tile) { continue; } 
          auto&amp; sprite = tile-&gt;m_properties-&gt;m_sprite; 
          sprite.setPosition( 
            static_cast&lt;float&gt;(x * Sheet::Tile_Size), 
            static_cast&lt;float&gt;(y * Sheet::Tile_Size)); 
          // Normal pass. 
          if (normalMaterial) { 
            shader-&gt;setUniform("material", *normalMaterial); 
            renderer-&gt;Draw(sprite, &amp;m_normals[layer]); 
          } 
        } 
      } 
    } 
  } 
  ... 
} 
</pre><p>The process is exactly the same as drawing a normal tile to a diffuse map, except that here we have to provide the material shader with the texture of the tile-sheet normal map. Also note that we're now drawing to a normal buffer texture.</p><p>The same is true for drawing entities as well:</p><pre class="programlisting">void S_Renderer::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("MaterialPass")) { 
    // Material pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    auto textures = m_systemManager-&gt; 
      GetEntityManager()-&gt;GetTextureManager(); 
    for (auto &amp;entity : m_entities) { 
      auto position = entities-&gt;GetComponent&lt;C_Position&gt;( 
        entity, Component::Position); 
      if (position-&gt;GetElevation() &lt; l_layer) { continue; } 
      if (position-&gt;GetElevation() &gt; l_layer) { break; } 
      C_Drawable* drawable = GetDrawableFromType(entity); 
      if (!drawable) { continue; } 
      if (drawable-&gt;GetType() != Component::SpriteSheet) 
      { continue; } 
      auto sheet = static_cast&lt;C_SpriteSheet*&gt;(drawable); 
      auto name = sheet-&gt;GetSpriteSheet()-&gt;GetTextureName(); 
      auto normals = textures-&gt;GetResource(name + "_normal"); 
      // Normal pass. 
      if (normals) { 
        shader-&gt;setUniform("material", *normals); 
        drawable-&gt;Draw(&amp;l_window, 
          l_materials[MaterialMapType::Normal].get()); 
      } 
    } 
  } 
  ... 
} 
</pre><p>You can try obtaining a normal texture through the texture manager. If you find one, you can draw it to the normal map material buffer.</p><p>Dealing with particles isn't much different from what we've seen already, except for one small detail:</p><pre class="programlisting">void ParticleSystem::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("MaterialValuePass")) { 
    // Material pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    for (size_t i = 0; i &lt; container-&gt;m_countAlive; ++i) { 
      if (l_layer &gt;= 0) { 
        if (positions[i].z &lt; l_layer * Sheet::Tile_Size) 
        { continue; } 
        if (positions[i].z &gt;= (l_layer + 1) * Sheet::Tile_Size) 
        { continue; } 
      } else if (positions[i].z &lt; 
        Sheet::Num_Layers * Sheet::Tile_Size) 
      { continue; } 
      // Normal pass. 
      shader-&gt;setUniform("material", 
        sf::Glsl::Vec3(0.5f, 0.5f, 1.f)); 
      renderer-&gt;Draw(drawables[i], 
        l_materials[MaterialMapType::Normal].get()); 
    } 
  } 
  ... 
} 
</pre><p>As you can see, we're actually using the material value shader in order to give particles static normals, which are always sort of pointing to the camera. A normal map buffer should look something like this after you render all the normal maps to it:</p><div><img src="img/image_08_008.jpg" alt="Implementing normal map rendering"/></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec87"/>Changing the lighting shader</h2></div></div></div><p>Now that we have all of this information, let's actually use it when calculating the illumination of the pixels inside the light pass shader:</p><pre class="programlisting">uniform sampler2D LastPass; 
uniform sampler2D DiffuseMap; 
uniform sampler2D NormalMap; 
uniform vec3 AmbientLight; 
uniform int LightCount; 
uniform int PassNumber; 
 
struct LightInfo { 
  vec3 position; 
  vec3 color; 
  float radius; 
  float falloff; 
}; 
 
const int MaxLights = 4; 
uniform LightInfo Lights[MaxLights]; 
 
void main() 
{ 
  vec4 pixel = texture2D(LastPass, gl_TexCoord[0].xy); 
  vec4 diffusepixel = texture2D(DiffuseMap, gl_TexCoord[0].xy); 
  vec4 normalpixel = texture2D(NormalMap, gl_TexCoord[0].xy); 
  vec3 PixelCoordinates = 
    vec3(gl_FragCoord.x, gl_FragCoord.y, gl_FragCoord.z); 
  vec4 finalPixel = gl_Color * pixel; 
  vec3 viewDirection = vec3(0, 0, 1); 
  if(PassNumber == 1) { finalPixel *= vec4(AmbientLight, 1.0); } 
  // IF FIRST PASS ONLY! 
  vec3 N = normalize(normalpixel.rgb * 2.0 - 1.0); 
  for(int i = 0; i &lt; LightCount; ++i) { 

    vec3 L = Lights[i].position - PixelCoordinates;
    float distance = length(L);
    float d = max(distance - Lights[i].radius, 0);
    L /= distance;
    float attenuation = 1 / pow(d/Lights[i].radius + 1, 2); 
    attenuation = (attenuation - Lights[i].falloff) / 
      (1 - Lights[i].falloff); 
    attenuation = max(attenuation, 0); 
    float normalDot = max(dot(N, L), 0.0); 
    finalPixel += (diffusepixel * 
      ((vec4(Lights[i].color, 1.0) * attenuation))) * normalDot; 
  } 
  gl_FragColor = finalPixel; 
} 
</pre><p>First, the normal map texture needs to be passed to it, as well as sampled, which is where the first two highlighted lines of code come in. Once this is done, for each light we're drawing on the screen, the normal directional vector is calculated. This is done by first making sure that it can go into the negative range and then normalizing it. A normalized vector only represents a direction.</p><div><div><h3 class="title"><a id="note30"/>Note</h3><p>Since the color values range from <em>0</em> to <em>255</em>, negative values cannot be directly represented. This is why we first bring them into the right range by multiplying them by <em>2.0</em> and subtracting by <em>1.0</em>.</p></div></div><p>A <strong>dot product</strong> is then calculated between the normal vector and the normalized <code class="literal">L</code> vector, which now represents the direction from the light to the pixel. How much a pixel is lit up from a specific light is directly contingent upon the dot product, which is a value from <em>1.0</em> to <em>0.0</em> and represents magnitude.</p><div><div><h3 class="title"><a id="note31"/>Note</h3><p>A <strong>dot product</strong> is an algebraic operation that takes in <em>two vectors</em>, as well as the <em>cosine</em> of the angle between them, and produces a scalar value between <em>0.0</em> and <em>1.0</em> that essentially represents how "orthogonal" they are. We use this property to light pixels less and less, given greater and greater angles between their normals and the light.</p></div></div><p>Finally, the dot product is used again when calculating the final pixel value. The entire influence of the light is multiplied by it, which allows every pixel to be drawn differently as if it had some underlying geometry that was pointing in a different direction.</p><p>The last thing left to do now is to pass the normal map buffer to the shader in our C++ code:</p><pre class="programlisting">void LightManager::RenderScene() { 
  ... 
  if (renderer-&gt;UseShader("LightPass")) { 
    // Light pass. 
    ... 
    shader-&gt;setUniform("NormalMap", 
      m_materialMaps[MaterialMapType::Normal]-&gt;getTexture()); 
    ... 
  } 
  ... 
} 
</pre><p>This effectively enables normal mapping and gives us beautiful results such as this:</p><div><img src="img/image_08_009.jpg" alt="Changing the lighting shader"/></div><p>The leaves, the character, and pretty much everything in this image, now look like they have a definition, ridges, and crevices; it is lit as if it had geometry, although it's paper-thin. Note the lines around each tile in this particular instance. This is one of the main reasons why normal maps for pixel art, such as tile sheets, shouldn't be automatically generated; it can sample the tiles adjacent to it and incorrectly add bevelled edges.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec77"/>Specular maps</h1></div></div></div><p>While normal maps provide us with the possibility of faking how bumpy a surface is, specular maps allow us to do the same with the shininess of a surface. This is what the same segment of the tile sheet we used as an example for a normal map looks like in a specular map:</p><div><img src="img/image_08_010.jpg" alt="Specular maps"/></div><p>It's not as complex as a normal map, since it only needs to store one value: the shininess factor. We can leave it up to each light to decide how much <em>shine</em> it will cast upon the scenery by letting it have its own values:</p><pre class="programlisting">struct LightBase { 
  ... 
  float m_specularExponent = 10.f; 
  float m_specularStrength = 1.f; 
}; 
</pre><div><div><div><div><h2 class="title"><a id="ch08lvl2sec88"/>Adding support for specularity</h2></div></div></div><p>Similar to normal maps, we need to use the material pass shader to render to a specularity buffer texture:</p><pre class="programlisting">void Map::Redraw(sf::Vector3i l_from, sf::Vector3i l_to) { 
  ... 
  if (renderer-&gt;UseShader("MaterialPass")) { 
    // Material pass. 
    ... 
    auto specMaterial = m_textureManager-&gt;GetResource( 
      textureName + "_specular"); 
    for (auto x = l_from.x; x &lt;= l_to.x; ++x) { 
      for (auto y = l_from.y; y &lt;= l_to.y; ++y) { 
        for (auto layer = l_from.z; layer &lt;= l_to.z; ++layer) { 
          ... // Normal pass. 
          // Specular pass. 
          if (specMaterial) { 
            shader-&gt;setUniform("material", *specMaterial); 
            renderer-&gt;Draw(sprite, &amp;m_speculars[layer]); 
          } 
        } 
      } 
    } 
  } 
  ... 
} 
</pre><p>The texture for specularity is once again attempted to be obtained; it is passed down to the material pass shader if found. The same is true when you render entities:</p><pre class="programlisting">void S_Renderer::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("MaterialPass")) { 
    // Material pass. 
    ... 
    for (auto &amp;entity : m_entities) { 
      ... // Normal pass. 
      // Specular pass. 
      if (specular) { 
        shader-&gt;setUniform("material", *specular); 
        drawable-&gt;Draw(&amp;l_window, 
          l_materials[MaterialMapType::Specular].get()); 
      } 
    } 
  } 
  ... 
} 
</pre><p>Particles, on the other hand, also use the material value pass shader:</p><pre class="programlisting">void ParticleSystem::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("MaterialValuePass")) { 
    // Material pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    for (size_t i = 0; i &lt; container-&gt;m_countAlive; ++i) { 
      ... // Normal pass. 
      // Specular pass. 
      shader-&gt;setUniform("material", 
        sf::Glsl::Vec3(0.f, 0.f, 0.f)); 
      renderer-&gt;Draw(drawables[i], 
        l_materials[MaterialMapType::Specular].get()); 
    } 
  } 
} 
</pre><p>For now, we don't want any of them to be specular at all. This can obviously be tweaked later on, but the important thing is that we have that functionality available and yielding results, such as the following:</p><div><img src="img/image_08_011.jpg" alt="Adding support for specularity"/></div><p>This specularity texture needs to be sampled inside a light pass, just like a normal texture. Let's see what this involves.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec89"/>Changing the lighting shader</h2></div></div></div><p>Just as before, a uniform <code class="literal">sampler2D</code> needs to be added to sample the specularity of a particular fragment:</p><pre class="programlisting">uniform sampler2D LastPass; 
uniform sampler2D DiffuseMap; 
uniform sampler2D NormalMap; 
uniform sampler2D SpecularMap; 
uniform vec3 AmbientLight; 
uniform int LightCount; 
uniform int PassNumber; 
 
struct LightInfo { 
  vec3 position; 
  vec3 color; 
  float radius; 
  float falloff; 
  float specularExponent; 
  float specularStrength; 
}; 
 
const int MaxLights = 4; 
uniform LightInfo Lights[MaxLights]; 
 
const float SpecularConstant = 0.4; 
 
void main() 
{ 
  ... 
  vec4 specularpixel = texture2D(SpecularMap, gl_TexCoord[0].xy); 
  vec3 viewDirection = vec3(0, 0, 1); // Looking at positive Z. 
  ... 
  for(int i = 0; i &lt; LightCount; ++i){ 
    ... 
    float specularLevel = 0.0; 
    specularLevel = 
      pow(max(0.0, dot(reflect(-L, N), viewDirection)), 
      Lights[i].specularExponent * specularpixel.a) 
      * SpecularConstant; 
    vec3 specularReflection = Lights[i].color * specularLevel * 
      specularpixel.rgb * Lights[i].specularStrength; 
    finalPixel += 
      (diffusepixel * ((vec4(Lights[i].color, 1.0) * attenuation)) 
      + vec4(specularReflection, 1.0)) * normalDot; 
  } 
  gl_FragColor = finalPixel; 
} 
</pre><p>We also need to add in the specular exponent and strength to each light's <code class="literal">struct</code>, as it's now part of it. Once the specular pixel is sampled, we need to set up the direction of the camera as well. Since that's static, we can leave it as is in the shader.</p><p>The specularity of the pixel is then calculated by taking into account the dot product between the pixel's normal and the light, the color of the specular pixel itself, and the specular strength of the light. Note the use of a specular constant in the calculation. This is a value that can, and should, be tweaked in order to obtain the best results, as 100% specularity rarely looks good.</p><p>Then, all that's left is to make sure the specularity texture is also sent to the light pass shader, in addition to the light's specular exponent and strength values:</p><pre class="programlisting">void LightManager::RenderScene() { 
  ... 
  if (renderer-&gt;UseShader("LightPass")) { 
    // Light pass. 
    ... 
    shader-&gt;setUniform("SpecularMap", 
      m_materialMaps[MaterialMapType::Specular]-&gt;getTexture()); 
    ... 
    for (auto&amp; light : m_lights) { 
      ... 
      shader-&gt;setUniform(id + ".specularExponent", 
        light.m_specularExponent); 
      shader-&gt;setUniform(id + ".specularStrength", 
        light.m_specularStrength); 
      ... 
    } 
  } 
} 
</pre><p>The result may not be visible right away, but upon closer inspection of moving a light stream, we can see that correctly mapped surfaces will have a glint that will move around with the light:</p><div><img src="img/image_08_012.jpg" alt="Changing the lighting shader"/></div><p>While this is nearly perfect, there's still some room for improvement.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec78"/>Height maps</h1></div></div></div><p>The main point of illuminating the world is to make all the visual details pop up in a realistic manner. We have already added artificial dynamic lighting, fake 3D geometry, and shininess, so what's left? Well, there's nothing that shows the proper height of the scene yet. Until this very moment, we've been dealing with the scene as if it's completely flat when calculating the lighting distances. Instead of this, we need to work on something referred to as the height map that will store the heights of the pixels.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec90"/>Adapting the existing code</h2></div></div></div><p>Drawing heights properly can be quite tricky, especially in the case of tile maps. We need to know which way a tile is facing when drawing realistic heights. Consider the following illustration:</p><div><img src="img/image_08_013.jpg" alt="Adapting the existing code"/></div><p>The tiles right next to point <strong>A</strong> have no normals associated with them, while the tiles next to point <strong>B</strong> are all facing the camera. We can store normal data inside our map files by making these few simple alterations:</p><pre class="programlisting">struct Tile { 
  ... 
  sf::Vector3f m_normal; 
}; 
 
void TileMap::ReadInTile(std::stringstream&amp; l_stream) { 
  ... 
  sf::Vector3f normals(0.f, 1.f, 0.f); 
  l_stream &gt;&gt; normals.x &gt;&gt; normals.y &gt;&gt; normals.z; 
  tile-&gt;m_normal = normals; 
  ... 
} 
 
TILE 57 15 3 1 1 // Tile entry without a normal. 
TILE 144 15 8 1 1 0 0 1 // Tile entry with a normal 0,0,1 
</pre><p>The <code class="literal">Tile</code> structure itself holds on to a normal value now, which will be used later on. When tiles are being read in from a file, additional information is loaded at the very end. The last two lines here show the actual entries from a map file.</p><p>Drawing the heights of these tiles based on their normals is all done in the appropriate shader, so let's pass all of the information it needs:</p><pre class="programlisting">void Map::Redraw(sf::Vector3i l_from, sf::Vector3i l_to) { 
  ... 
  if (renderer-&gt;UseShader("HeightPass")) { 
    // Height pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    for (auto x = l_from.x; x &lt;= l_to.x; ++x) { 
      for (auto y = l_from.y; y &lt;= l_to.y; ++y) { 
        for (auto layer = l_from.z; layer &lt;= l_to.z; ++layer) { 
          auto tile = m_tileMap.GetTile(x, y, layer); 
          if (!tile) { continue; } 
          auto&amp; sprite = tile-&gt;m_properties-&gt;m_sprite; 
          sprite.setPosition( 
            static_cast&lt;float&gt;(x * Sheet::Tile_Size), 
            static_cast&lt;float&gt;(y * Sheet::Tile_Size)); 
          shader-&gt;setUniform("BaseHeight", 
            static_cast&lt;float&gt;(layer * Sheet::Tile_Size)); 
          shader-&gt;setUniform("YPosition", sprite.getPosition().y); 
          shader-&gt;setUniform("SurfaceNormal", 
            sf::Glsl::Vec3(tile-&gt;m_normal)); 
          renderer-&gt;Draw(sprite, &amp;m_heightMap[layer]); 
        } 
      } 
    } 
  } 
  ... 
} 
</pre><p>The height pass shader uses a value for the base height of the drawable, which, in this case, is just elevation in world coordinates. It also uses the <em>Y</em> world coordinate of the <code class="literal">Drawable</code> class and takes in the surface normal. The same values need to be set up for the entities as well:</p><pre class="programlisting">void S_Renderer::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("HeightPass")) { 
    // Height pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    shader-&gt;setUniform("BaseHeight", 
      static_cast&lt;float&gt;(l_layer * Sheet::Tile_Size)); 
    shader-&gt;setUniform("SurfaceNormal", 
      sf::Glsl::Vec3(0.f, 0.f, 1.f)); 
    for (auto &amp;entity : m_entities) { 
      auto position = entities-&gt;GetComponent&lt;C_Position&gt;( 
        entity, Component::Position); 
      if (position-&gt;GetElevation() &lt; l_layer) { continue; } 
      if (position-&gt;GetElevation() &gt; l_layer) { break; } 
      C_Drawable* drawable = GetDrawableFromType(entity); 
      if (!drawable) { continue; } 
      if (drawable-&gt;GetType() != Component::SpriteSheet) 
      { continue; } 
      auto sheet = static_cast&lt;C_SpriteSheet*&gt;(drawable); 
      shader-&gt;setUniform("YPosition", position-&gt;GetPosition().y); 
      drawable-&gt;Draw(&amp;l_window, 
        l_materials[MaterialMapType::Height].get()); 
    } 
  } 
  ... 
} 
</pre><p>In this case, however, we're using the same normal for all the entities. This is because we want them to face the camera and be illuminated as if they're standing perpendicular to the ground. Particles, on the other hand, are not facing the camera, but instead have normals pointing up toward the positive <em>Y</em> axis:</p><pre class="programlisting">void ParticleSystem::Draw(MaterialMapContainer&amp; l_materials, 
  Window&amp; l_window, int l_layer) 
{ 
  ... 
  if (renderer-&gt;UseShader("HeightPass")) { 
    // Height pass. 
    auto shader = renderer-&gt;GetCurrentShader(); 
    shader-&gt;setUniform("SurfaceNormal", 
      sf::Glsl::Vec3(0.f, 1.f, 0.f)); 
    for (size_t i = 0; i &lt; container-&gt;m_countAlive; ++i) { 
      if (l_layer &gt;= 0) { 
        if (positions[i].z &lt; l_layer * Sheet::Tile_Size) 
        { continue; } 
        if (positions[i].z &gt;= (l_layer + 1) * Sheet::Tile_Size) 
        { continue; } 
      } else if (positions[i].z &lt; 
        Sheet::Num_Layers * Sheet::Tile_Size) 
      { continue; } 
      shader-&gt;setUniform("BaseHeight", positions[i].z); 
      shader-&gt;setUniform("YPosition", positions[i].y); 
      renderer-&gt;Draw(drawables[i], 
        l_materials[MaterialMapType::Height].get()); 
    } 
  } 
  ... 
} 
</pre></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec91"/>Writing the height pass shader</h2></div></div></div><p>The height pass is the only program we've written so far that uses both the vertex and the fragment shaders.</p><p>Let's take a look at what needs to happen in the vertex shader:</p><pre class="programlisting">uniform float YPosition; 
out float Height; 
void main() 
{ 
  gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex; 
  gl_TexCoord[0] = gl_TextureMatrix[0] * gl_MultiTexCoord0; 
  gl_FrontColor = gl_Color; 
  Height = gl_Vertex.y - YPosition; 
} 
</pre><p>There's only one line here that isn't standard from what is traditionally known as a vertex shader, outside of the uniform variable and the out variable, of course. The vertex shader outputs a floating point value called <code class="literal">Height</code> to the fragment shader. It's simply the height between the <em>Y</em> component of the vertex of a shape in world coordinates and the base <em>Y</em> position of that same shape. The height is then interpolated between all the fragments, giving a nice, gradient distribution.</p><div><div><h3 class="title"><a id="note32"/>Note</h3><p>The <code class="literal">gl_Vertex</code> information is stored in world coordinates. The bottom <em>Y</em> coordinates always start at the same height as the drawable, which makes the top <em>Y</em> coordinates equal to the sum of its position and height.</p></div></div><p>Finally, we can take a look at the fragment shader and actually do some filling up of fragments:</p><pre class="programlisting">uniform sampler2D texture; 
uniform vec3 SurfaceNormal; 
uniform float BaseHeight; 
in float Height; 
void main() 
{ 
  vec4 pixel = texture2D(texture, gl_TexCoord[0].xy); 
  float value = (BaseHeight - (Height * SurfaceNormal.z)) / 255.0; 
  gl_FragColor = vec4(value, value, value, pixel.a); 
} 
</pre><p>As shown previously, it takes in the diffuse texture, the surface normal, the base height of the drawable, and the interpolated <code class="literal">Height</code> value from the vertex shader. The diffuse pixel is then sampled in order to use its alpha value for transparency. The height value itself is calculated by subtracting the result of the pixel height being multipled by the surface normal's <em>Z </em>component from the base height of the drawable. The whole thing is finally divided by <em>255</em> because we want to store color information in a normalized format.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec92"/>Changing the lighting shader</h2></div></div></div><p>Finally, the light pass shader can be changed as well by sampling the height map:</p><pre class="programlisting">... 
uniform sampler2D HeightMap; 
... 
void main() 
{ 
  ... 
  float pixelheight = texture2D(HeightMap, gl_TexCoord[0].xy).r 
    * 255; 
  vec3 PixelCoordinates = 
    vec3(gl_FragCoord.x, gl_FragCoord.y, pixelheight); 
  ... 
  gl_FragColor = finalPixel; 
} 
</pre><p>Once the pixel height is sampled and multiplied by <em>255</em> to bring it back to world coordinates, all we need to do is replace the <code class="literal">gl_FragCoord.z</code> value with <code class="literal">pixelHeight</code> when calculating the distance between a pixel and a fragment. Yes, that's really all it takes!</p><p>The <code class="literal">HeightMap</code> can then be actually passed to the shader for sampling, like so:</p><pre class="programlisting">void LightManager::RenderScene() { 
  ... 
  if (renderer-&gt;UseShader("LightPass")) { 
    // Light pass. 
    ... 
    shader-&gt;setUniform("HeightMap", 
      m_materialMaps[MaterialMapType::Height]-&gt;getTexture()); 
    ... 
  } 
  ... 
} 
</pre><p>This gives us a very nice effect that can actually show off the height of a particular structure, given it has elevated properly and has the right normals:</p><div><img src="img/image_08_014.jpg" alt="Changing the lighting shader"/></div><p>The light post on the left has no normals, while the post on the right has normals that face the <em>+Z</em> direction. The light position is exactly the same in both these images.</p></div></div></div></div>
<div><div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec79"/>Summary</h1></div></div></div><p>If you are still here, congratulations! That was quite a bit of information to take in, but just as our world is finally beginning to take shape visually, we're about to embark on an even more stunning feature that will be discussed in the next chapter. See you there!</p></div></div></div></body></html>