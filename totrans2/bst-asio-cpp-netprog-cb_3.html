<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Implementing Client Applications</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing a synchronous TCP client</li><li class="listitem" style="list-style-type: disc">Implementing a synchronous UDP client</li><li class="listitem" style="list-style-type: disc">Implementing an asynchronous TCP client</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec26"/>Introduction</h1></div></div></div><p>A <strong>client</strong> <a id="id132" class="indexterm"/>is a part of a distributed application that communicates with another part of this application called a <a id="id133" class="indexterm"/>
<strong>server</strong>, in order to consume services it provides. The server, on the other hand, is a part of distributed application that passively waits for requests arriving from clients. When a request arrives, the server performs the requested operation and sends a response—the result of the operation—back to the client.</p><p>The key characteristic of a client is that it needs a service provided by the server and it initiates the communication session with that server in order to consume the service. The key characteristic of the server is that it serves the requests coming from the clients by providing a requested service.</p><p>We'll consider servers in the next chapter. In this chapter, we are going to focus on client applications and will consider several types of them in detail.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec71"/>The classification of client applications</h2></div></div></div><p>Client<a id="id134" class="indexterm"/> applications can be classified by the transport layer protocol they use for communication with the server. If the client uses a UDP protocol, it is called a <a id="id135" class="indexterm"/>
<strong>UDP client</strong>. If it uses a TCP protocol, it is called a <strong>TCP client</strong>
<a id="id136" class="indexterm"/> correspondingly. Of course, there are many other transport layer protocols that client applications may use for communication. Moreover, there are multiprotocol clients that can communicate over several protocols. However, they are beyond the scope of this book. In this chapter, we are going to focus on pure UDP and TCP clients as such, which are the most popular and are the most often used in general purpose software today.</p><p>The decision as to which transport layer protocol to choose for communication between the parts of a distributed application should be made at the early stages of the application design based on the application specification. Because TCP and UDP protocols are conceptually different, it may be quite difficult to switch from one of them to another at the later stages of the application development process.</p><p>Another <a id="id137" class="indexterm"/>way to classify client applications is according to whether the client is synchronous or asynchronous. A <strong>synchronous client application</strong>
<a id="id138" class="indexterm"/> uses synchronous socket API calls that block the thread of execution until the requested operation is completed, or an error occurs. Thus, a typical synchronous TCP client would use the <code class="literal">asio::ip::tcp::socket::write_some()</code> method or the <code class="literal">asio::write()</code> free function to send a request to the sever and then use the <code class="literal">asio::ip::tcp::socket::read_some()</code> method or the <code class="literal">asio::read()</code> free function to receive a response. These methods and functions are blocking, which makes the client synchronous.</p><p>An <strong>asynchronous client application</strong>
<a id="id139" class="indexterm"/> as opposed to a synchronous one uses asynchronous socket API calls. For example, an asynchronous TCP client may use the <code class="literal">asio::ip::tcp::socket::async_write_some()</code> method or the <code class="literal">asio::async_write()</code> free function to send a request to the server and then use the <code class="literal">asio::ip::tcp::socket::async_read_some()</code> method or the <code class="literal">asio::async_read()</code> free function to asynchronously receive a response.</p><p>Because the structure of a synchronous client significantly differs from that of an asynchronous one, the decision as to which approach to apply should be made early at the application design stage, and this decision should be based on the careful analysis of the application requirements. Besides, possible application evolution paths and new requirements that may appear in the future should be considered and taken into account.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec72"/>Synchronous versus asynchronous</h2></div></div></div><p>As usually, each <a id="id140" class="indexterm"/>approach <a id="id141" class="indexterm"/>has its advantages and disadvantages. When a synchronous approach gives better results in one situation, it may be absolutely unacceptable in another. In the latter case, an asynchronous approach should be used. Let's compare two approaches to better understand when it is more beneficial to use each of them.</p><p>The main advantage of a synchronous approach is its <em>simplicity</em>. A synchronous client is significantly easier to develop, debug, and support than a functionally equal asynchronous one. Asynchronous clients are more complex due to the fact that asynchronous operations that are used by them complete in other places in code (mainly in callbacks) than they are initiated. Usually, this requires allocating additional data structures in the free memory to keep the context of the request and callback functions, and also involves thread synchronization and other extras that may make the application structure quite complex and error-prone. Most of these extras are not required in synchronous clients. Besides, the asynchronous approach brings in additional computational and memory overhead, which makes it less efficient than a synchronous one in some conditions.</p><p>However, the <a id="id142" class="indexterm"/>synchronous <a id="id143" class="indexterm"/>approach has some functional limitations, which often make this approach unacceptable. These limitations consist of the inability to cancel a synchronous operation after it has started, or to assign it a timeout so that it gets interrupted if it is running longer than a certain amount of time. As opposed to synchronous operations, asynchronous ones can be canceled at any moment after operation initiation and before the moment it completes.</p><p>Imagine a typical modern web browser. A request cancellation is a very important feature of a client application of this kind. After issuing a command to load a particular website, the user may change his or her mind and decide to cancel the command before the page gets loaded. From the user's perspective, it would be quite strange not to be able to cancel the command until the page gets fully loaded. Therefore, this is when a synchronous approach is not a good option.</p><p>Besides the difference in the complexity and functionality described above, the two approaches differ in efficiency when it comes to running several requests in parallel.</p><p>Imagine that we are developing a web crawler, an application that traverses the pages of websites and processes them in order to extract some interesting information. Given a file with a long list of websites (say several millions), the application should traverse all the pages of each of the sites listed in the file and then process each page. Naturally, one of the key requirements of the application is to perform the task as fast as possible. Provided with these requirements, which approach should we choose, synchronous or asynchronous?</p><p>Before we answer this question, let's consider the stages of a request life cycle and their timings from the client application's perspective. Conceptually, the request life cycle consists of five stages as follows:</p><div><ol class="orderedlist arabic"><li class="listitem"><strong>Preparing the request</strong>: This <a id="id144" class="indexterm"/>stage involves any operations required to prepare a request message. The duration of this step depends on the particular problem the application solves. In our example, this could be reading the next website address from the input file and constructing a string representing a request in accordance with an HTTP protocol.</li><li class="listitem"><strong>Transmitting a request from the client to the server</strong>: This stage assumes the transmission of the request data from the client to the server over the network. The duration of this step does not depend on a client application. It depends on the properties and the current state of the network.</li><li class="listitem"><strong>Processing the request by the server</strong>: The duration of this step depends on the server's properties and its current load. In our example, the server application is a web server and the request processing lies in constructing a requested web page, which may involve I/O operations such as reading files and loading data from a database.</li><li class="listitem"><strong>Transmitting a response from the server to the client</strong>: Like stage 2, this stage also assumes the transmission of the data over the network; however, this time it is in the opposite direction—from the server to the client. The duration of this stage does not depend on the client or the server. It only depends on the properties and the state of the network.</li><li class="listitem"><strong>Processing the response by the client</strong>: The duration of this stage depends on a particular task that the client application is intended to perform. In our example, this could be scanning the web page, extracting interesting information and storing it into a database.</li></ol></div><p>Note that, for the sake of simplicity, we omitted low-level substages such as connection establishment and connection shutdown, which are important when using TCP protocol but don't add a substantial value in our conceptual model of a request life cycle.</p><p>As we can see, only in stages 1 and 5 does the client perform some effective job related to the request. Having initiated the transmission of the request data at the end of stage 1, the client has to wait during the next three stages (2, 3, and 4) of the request life cycle before it can receive the response and process it.</p><p>Now, with the stages of the request life cycle in mind, let's see what happens when we apply synchronous and asynchronous approaches to implement our sample web crawler.</p><p>If we apply a synchronous approach, the thread of execution processing a single request synchronously will be sleeping during stages 2-4 of the request life cycle, and only during stages 1 and 5, will it perform an effective job (for simplicity, we assume that stages 1 and 5 don't include instructions that block the thread). This means that the resource of an operating system, namely a thread, is used inefficiently, because there are number of times when it is simply doing nothing while there is still a lot of work available—millions of other pages to request and process. In this situation, an asynchronous approach seems to be more efficient. With an asynchronous approach, instead of a thread being blocked during stages 2-4 of a request life cycle, it can be effectively used to perform stages 1 or 5 of another request.</p><p>Thus, we direct a single thread to process the different stages of different requests (this is called <a id="id145" class="indexterm"/>
<strong>overlapping</strong>), which results in the more efficient usage of a thread and consequently increases the overall performance of the application.</p><p>However, an asynchronous approach is not always more efficient than a synchronous one. As it has been mentioned, asynchronous operations imply additional computational overheads, which means that the overall duration of an asynchronous operation (from initiation till completion) is somewhat bigger than the equivalent synchronous one. This means that, if the average total duration of stages 2-4 is less than the overhead of the timing asynchronous approach per single request, then a synchronous approach turns out to be more efficient, and therefore may be considered to be the right way to go.</p><p>Assessing the total duration of stages 2-4 of the request life cycle and the overhead of the asynchronous approach is usually done experimentally. The duration may significantly vary, and it depends on the properties and the state of the network through which the requests and responses are transmitted and also on the properties and the load level of the server application that serves the request.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec73"/>The sample protocol</h2></div></div></div><p>In this chapter, we are going to <a id="id146" class="indexterm"/>consider three recipes, each of which demonstrates how to implement a particular type of a client application: the synchronous UDP client, synchronous TCP client, and asynchronous TCP client. In all the recipes, it is assumed that the client application communicates with the server application using the following simple application-level protocol.</p><p>The server application accepts a request represented as an ASCII string. The string has the following format:</p><div><pre class="programlisting">EMULATE_LONG_COMP_OP [s]&lt;LF&gt;</pre></div><p>Where <code class="literal">[s]</code> is a positive integer value and <code class="literal">&lt;LF&gt;</code> is ASCII a new-line symbol.</p><p>The server interprets this string as a request to perform a dummy operation that lasts for <code class="literal">[s]</code> seconds. For example, a request string may look as follows:</p><div><pre class="programlisting">"EMULATE_LONG_COMP_OP 10\n"</pre></div><p>This means that the client sending this request wants the server to perform the dummy operation for <code class="literal">10</code> seconds and then send a response to it.</p><p>Like the request, the response returned by the server is represented by an ASCII string. It may either be <code class="literal">OK&lt;LF&gt;</code> if the operation completes successfully or <code class="literal">ERROR&lt;LF&gt;</code> if the operation fails.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec27"/>Implementing a synchronous TCP client</h1></div></div></div><p>A <a id="id147" class="indexterm"/>synchronous TCP client is a part of a distributed application that complies with the following statements:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Acts as a client in the client-server communication model</li><li class="listitem" style="list-style-type: disc">Communicates with the server application using a TCP protocol</li><li class="listitem" style="list-style-type: disc">Uses I/O and control operations (at least those I/O operations that are related to communication with a server) that block the thread of execution until the corresponding operation completes, or an error occurs</li></ul></div><p>A<a id="id148" class="indexterm"/> typical synchronous TCP client works according to the following algorithm:</p><div><ol class="orderedlist arabic"><li class="listitem">Obtain the IP-address and the protocol port number of the server application.</li><li class="listitem">Allocate an active socket.</li><li class="listitem">Establish a connection with the server application.</li><li class="listitem">Exchange messages with the server.</li><li class="listitem">Shut down the connection.</li><li class="listitem">Deallocate the socket.</li></ol></div><p>This recipe demonstrates how to implement a synchronous TCP client application with Boost.Asio.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec74"/>How to do it…</h2></div></div></div><p>The following code sample demonstrates a possible implementation of a synchronous TCP client application with Boost.Asio. The client uses the application layer protocol described in the introduction section of this chapter:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;

using namespace boost;

class SyncTCPClient {
public:
  SyncTCPClient(const std::string&amp; raw_ip_address,
    unsigned short port_num) :
    m_ep(asio::ip::address::from_string(raw_ip_address),
    port_num),
    m_sock(m_ios) {

    m_sock.open(m_ep.protocol());
  }

  void connect() {
    m_sock.connect(m_ep);
  }

  void close() {
    m_sock.shutdown(
      boost::asio::ip::tcp::socket::shutdown_both);
    m_sock.close();
  }

  std::string emulateLongComputationOp(
    unsigned int duration_sec) {

    std::string request = "EMULATE_LONG_COMP_OP "
      + std::to_string(duration_sec)
      + "\n";

    sendRequest(request);
    return receiveResponse();
  };

private:
  void sendRequest(const std::string&amp; request) {
    asio::write(m_sock, asio::buffer(request));
  }

  std::string receiveResponse() {
    asio::streambuf buf;
    asio::read_until(m_sock, buf, '\n');

    std::istream input(&amp;buf);

    std::string response;
    std::getline(input, response);

    return response;
  }

private:
  asio::io_service m_ios;

  asio::ip::tcp::endpoint m_ep;
  asio::ip::tcp::socket m_sock;
};

int main()
{
  const std::string raw_ip_address = "127.0.0.1";
  const unsigned short port_num = 3333;

  try {
    SyncTCPClient client(raw_ip_address, port_num);

    // Sync connect.
    client.connect();

    std::cout &lt;&lt; "Sending request to the server... "
      &lt;&lt; std::endl;

    std::string response =
      client.emulateLongComputationOp(10);

    std::cout &lt;&lt; "Response received: " &lt;&lt; response
      &lt;&lt; std::endl;

    // Close the connection and free resources.
    client.close();
  }
  catch (system::system_error &amp;e) {
    std::cout &lt;&lt; "Error occured! Error code = " &lt;&lt; e.code()
      &lt;&lt; ". Message: " &lt;&lt; e.what();

    return e.code().value();
  }

  return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec75"/>How it works…</h2></div></div></div><p>The <a id="id149" class="indexterm"/>sample client application consists of two main components—the <code class="literal">SyncTCPClient</code> class and the application entry point function <code class="literal">main()</code> in which the <code class="literal">SyncTCPClient</code> class is used to communicate with the server application. Let's consider each component separately.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec15"/>The SyncTCPClient class</h3></div></div></div><p>The <code class="literal">SyncTCPClient</code> class is the<a id="id150" class="indexterm"/> key component in the sample. It implements and <a id="id151" class="indexterm"/>provides access to the communication functionality.</p><p>The class has three private members<a id="id152" class="indexterm"/> as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">asio::io_service m_ios</code>: This is the <a id="id153" class="indexterm"/>object providing access to the operating system's communication services, which are used by the socket object</li><li class="listitem" style="list-style-type: disc"><code class="literal">asio::ip::tcp::endpoint m_ep</code>: This<a id="id154" class="indexterm"/> is an endpoint designating the server application</li><li class="listitem" style="list-style-type: disc"><code class="literal">asio::ip::tcp::socket m_sock</code>: This is the socket <a id="id155" class="indexterm"/>used for communication</li></ul></div><p>Each object of the class is intended to communicate with a single server application; therefore, the class's constructor accepts the server IP-address and the protocol port number as its arguments. These values are used to instantiate the <code class="literal">m_ep</code> object in the constructor's initialization list. The socket object <code class="literal">m_sock</code> is instantiated and opened in the constructor too.</p><p>The three public methods comprise the interface of the <code class="literal">SyncTCPClient</code> class. The first method named <code class="literal">connect()</code> is quite simple; it performs the connection of the socket to the server. The <code class="literal">close()</code> method shuts the connection down and closes the socket, which leads to the operating system's socket and other resources associated with it to be deallocated.</p><p>The third interface method is <code class="literal">emulateLongComputationOp(unsigned int duration_sec)</code>. This method is where the I/O operations are performed. It begins with preparing the request string according to the protocol. Then, the request is passed to the class's private method <code class="literal">sendRequest(const std::string&amp; request)</code>, which sends it to the server. When the request is sent and the <code class="literal">sendRequest()</code> method returns, the <code class="literal">receiveResponse()</code> method is called to receive the response from the server. When the response is received, the <code class="literal">receiveResponse()</code> method returns the string containing the response. After this, the <code class="literal">emulateLongComputationOp()</code> method returns the response to its caller.</p><p>Let's look at the <code class="literal">sendRequest()</code> and <code class="literal">receiveResponse()</code> methods in more detail.</p><p>The <code class="literal">sendRequest()</code> method<a id="id156" class="indexterm"/> has the following prototype:</p><div><pre class="programlisting">void sendRequest(const std::string&amp; request)</pre></div><p>Its purpose is to send a string, passed to it as an argument, to the server. In order to send the data to the server, the <code class="literal">asio::write()</code> free synchronous function is used. The function returns when the request is sent. That's it about the <code class="literal">sendRequest()</code> method. Basically, all it does is, it fully delegates its job to the <code class="literal">asio::write()</code> free function.</p><p>Having sent the request, now we want to receive the response from the server. This is the purpose of the <code class="literal">receiveResponse()</code> method of the <code class="literal">SyncTCPClient</code> class. To perform its job, method uses the <code class="literal">asio::read_until()</code> free function. According to the application layer protocol, the response message sent by the server may vary in length, but must end with the <code class="literal">\n</code> symbol; therefore, we specify this symbol as a delimiter when calling the function:</p><div><pre class="programlisting">asio::streambuf buf;
asio::read_until(m_sock, buf, <strong>'\n'</strong>);</pre></div><p>The function blocks the <a id="id157" class="indexterm"/>thread of execution until it encounters the <code class="literal">\n</code> symbol as a part of the message that arrived from the server. When the function returns, the stream buffer <code class="literal">buf</code> contains the response. The data is then copied from the <code class="literal">buf</code> buffer to the <code class="literal">response</code> string and the latter is returned to the caller. The <code class="literal">emulateLongComputationOp()</code> method in turn returns the response to its caller—the <code class="literal">main()</code> function.</p><p>One thing to note with regard to the <code class="literal">SyncTCPClient</code> class is that it contains no error handling-related code. That's because the class uses only those overloads of Boost.Asio functions and objects' methods that throw exceptions in case of failure. It is assumed that the user of the class is responsible for catching and handling the exceptions.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec16"/>The main() entry point function</h3></div></div></div><p>This<a id="id158" class="indexterm"/> function acts as a user of the <code class="literal">SyncTCPClient</code> class. Having obtained the server IP-address and the protocol port number (this part is omitted from the sample), it instantiates and uses an object of the <code class="literal">SyncTCPClient</code> class to communicate with the server in order to consume its service, mainly to emulate an operation on the server that performs dummy calculations for 10 seconds. The code of this function is simple and self-explanatory and thus requires no additional comments.</p></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec76"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes providing detailed discussions on how to perform synchronous I/O</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec28"/>Implementing a synchronous UDP client</h1></div></div></div><p>A synchronous UDP client<a id="id159" class="indexterm"/> is a part of a distributed application that complies with the following statements:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Acts as a client in the client-server communication model</li><li class="listitem" style="list-style-type: disc">Communicates with the server application using UDP protocol</li><li class="listitem" style="list-style-type: disc">Uses I/O and control operations (at least those I/O operations that are related to communication with the server) that block the thread of execution until the corresponding operation completes, or an error occurs</li></ul></div><p>A typical synchronous UDP client works according to the following algorithm:</p><div><ol class="orderedlist arabic"><li class="listitem">Obtain an IP-address and a protocol port number of each server the client application is intended to communicate with.</li><li class="listitem">Allocate a UDP socket.</li><li class="listitem">Exchange messages with the servers.</li><li class="listitem">Deallocate the socket.</li></ol></div><p>This recipe demonstrates how to implement a synchronous UDP client application with Boost.Asio.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec77"/>How to do it…</h2></div></div></div><p>The following code sample<a id="id160" class="indexterm"/> demonstrates a possible implementation of a synchronous UDP client application with Boost.Asio. It is assumed that the client uses UDP protocol with the underlying IPv4 protocol for communication:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;
#include &lt;iostream&gt;

using namespace boost;

class SyncUDPClient {
public:
  SyncUDPClient() :
    m_sock(m_ios) {

    m_sock.open(asio::ip::udp::v4());
  }

  std::string emulateLongComputationOp(
    unsigned int duration_sec,
    const std::string&amp; raw_ip_address,
    unsigned short port_num) {

    std::string request = "EMULATE_LONG_COMP_OP "
      + std::to_string(duration_sec)
      + "\n";

    asio::ip::udp::endpoint ep(
      asio::ip::address::from_string(raw_ip_address),
      port_num);

    sendRequest(ep, request);
    return receiveResponse(ep);
  };

private:
  void sendRequest(const asio::ip::udp::endpoint&amp; ep,
    const std::string&amp; request) {

    m_sock.send_to(asio::buffer(request), ep);
  }

  std::string receiveResponse(asio::ip::udp::endpoint&amp; ep) {
    char response[6];
    std::size_t bytes_recieved =
      m_sock.receive_from(asio::buffer(response), ep);

    m_sock.shutdown(asio::ip::udp::socket::shutdown_both);
    return std::string(response, bytes_recieved);
  }

private:
  asio::io_service m_ios;

  asio::ip::udp::socket m_sock;
};

int main()
{
  const std::string server1_raw_ip_address = "127.0.0.1";
  const unsigned short server1_port_num = 3333;

  const std::string server2_raw_ip_address = "192.168.1.10";
  const unsigned short server2_port_num = 3334;

  try {
    SyncUDPClient client;

    std::cout &lt;&lt; "Sending request to the server #1 ... "
      &lt;&lt; std::endl;

    std::string response =
      client.emulateLongComputationOp(10,
      server1_raw_ip_address, server1_port_num);

    std::cout &lt;&lt; "Response from the server #1 received: "
      &lt;&lt; response &lt;&lt; std::endl;

    std::cout &lt;&lt; "Sending request to the server #2... "
      &lt;&lt; std::endl;

    response =
      client.emulateLongComputationOp(10,
      server2_raw_ip_address, server2_port_num);

    std::cout &lt;&lt; "Response from the server #2 received: "
      &lt;&lt; response &lt;&lt; std::endl;
  }
  catch (system::system_error &amp;e) {
    std::cout &lt;&lt; "Error occured! Error code = " &lt;&lt; e.code()
      &lt;&lt; ". Message: " &lt;&lt; e.what();

    return e.code().value();
  }

  return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec78"/>How it works…</h2></div></div></div><p>The sample consists <a id="id161" class="indexterm"/>of two main components—the <code class="literal">SyncUDPClient</code> class and the application entry point function <code class="literal">main()</code> that uses the <code class="literal">SyncUDPClient</code> class to communicate with two server applications. Let's consider each component separately.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec17"/>The SyncUDPClient class</h3></div></div></div><p>The <code class="literal">SyncUDPClient</code> class is the <a id="id162" class="indexterm"/>key component in the sample. It implements the server <a id="id163" class="indexterm"/>communication functionality and provides access to it for the user.</p><p>The class has two private members<a id="id164" class="indexterm"/> as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">asio::io_service m_ios</code>: This is the object providing access to the operating system's<a id="id165" class="indexterm"/> communication services, which are used by the socket object</li><li class="listitem" style="list-style-type: disc"><code class="literal">asio::ip::udp::socket m_sock</code>: This is the UDP <a id="id166" class="indexterm"/>socket used for communication</li></ul></div><p>The socket object <code class="literal">m_sock</code> is instantiated and opened in the class's constructor. Because the client is intended to use IPv4 protocol, we pass the object returned by the <code class="literal">asio::ip::udp::v4()</code> static method to the socket's <code class="literal">open()</code> method to designate the socket to use IPv4 protocol.</p><p>Because the <code class="literal">SyncUDPClient</code> class implements communication over UDP protocol, which is a connectionless protocol, a single object of this class can be used to communicate with multiple servers. The interface of the class consists of a single method—<code class="literal">emulateLongComputationOp()</code>. This method can be used to communicate with the server just after the object of the <code class="literal">SyncUDPClient</code> class is instantiated. The following is the prototype of the method:</p><div><pre class="programlisting">std::string emulateLongComputationOp(
         unsigned int duration_sec,
         const std::string&amp; raw_ip_address,
         unsigned short port_num)</pre></div><p>Besides the <code class="literal">duration_sec</code> argument that represents a request parameter, the method accepts the server IP-address and the protocol port number. This method may be called multiple times to communicate with different servers.</p><p>The method begins with preparing a request string according to the application layer protocol and creating an endpoint object designating the target server application. Then, the request string and the endpoint object are passed to the class's private method <code class="literal">sendRequest()</code>, which sends the request message to the specified server. When the request is sent and the <code class="literal">sendRequest()</code> method returns, the <code class="literal">receiveResponse()</code> method is called to receive a response from the server. </p><p>When the response is received, the <code class="literal">receiveResponse()</code> method returns the string containing the response. In turn, the <code class="literal">emulateLongComputationOp()</code> method returns the response to its caller. The<code class="literal"> sendRequest()</code> method uses the socket object's <code class="literal">send_to()</code> method to send the request message to a particular server. Let's have a look at the declaration of this method:</p><div><pre class="programlisting">  template &lt;typename ConstBufferSequence&gt;
  std::size_t send_to(const ConstBufferSequence&amp; buffers,
      const endpoint_type&amp; destination)</pre></div><p>The method accepts a buffer <a id="id167" class="indexterm"/>containing the request and an<a id="id168" class="indexterm"/> endpoint designating the server to which the content of the buffer should be sent as arguments and blocks until the whole buffer is sent, or an error occurs. Note that, if the method returns without an error, it only means that the request has been sent and <em>does not</em> mean that the request has been received by the server. UDP protocol doesn't guarantee message delivery and it provides no means to check whether the datagram has been successfully received on the server-side or got lost somewhere on its way to the server.</p><p>Having sent the request, now we want to receive the response from the server. This is the purpose of the <code class="literal">receiveResponse()</code> method of the <code class="literal">SyncUDPClient</code> class. This method begins with allocating a buffer that will hold the response message. We choose the size of the buffer such that it can fit the largest message that the server may send according to the application layer protocol. This message is an <code class="literal">ERROR\n</code> string that consists of six ASCII symbols, which is therefore 6 bytes long; hence is the size of our buffer - 6 bytes. Because the buffer is small enough, we allocate it on the stack.</p><p>To read the response data arriving from the server, we use the socket object's <code class="literal">receive_from()</code> method. Here is the prototype of the method:</p><div><pre class="programlisting">  template &lt;typename MutableBufferSequence&gt;
  std::size_t receive_from(const MutableBufferSequence&amp; buffers,
      endpoint_type&amp; sender_endpoint) </pre></div><p>This method copies a datagram that came from the server designated by the <code class="literal">sender_endpoint</code> object to the buffer specified by the <code class="literal">buffers</code> argument.</p><p>There are two things to note about socket object's <code class="literal">receive_from()</code> method. The first thing is that this method is synchronous and it blocks the thread of execution until the datagram arrives from the specified server. If the datagram never arrives (for example, gets lost somewhere on its way to the client), the method will never unblock and the whole application will hang. The second thing is that if the size of the datagram that arrives from the server is larger than the size of the supplied buffer, the method will fail.</p><p>After the response is received, the <code class="literal">std::string</code> object is created, initialized with a response string, and returned to the caller—the <code class="literal">emulateLongComputationOp()</code> method. This in turn returns the response to its caller—the <code class="literal">main()</code> function.</p><p>The <code class="literal">SyncUDPClient</code> <a id="id169" class="indexterm"/>class does not contain error<a id="id170" class="indexterm"/> handling-related code. That's is because it uses only those overloads of Boost.Asio functions and objects' methods that throw exceptions in case of failure. It is assumed that the user of the class is responsible for catching and handling the exceptions.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec18"/>The main() entry point function</h3></div></div></div><p>In this function, we use<a id="id171" class="indexterm"/> the <code class="literal">SyncUDPClient</code> class in order to communicate with two server applications. Firstly, we obtain the IP-addresses and the port numbers of the target server applications. Then, we instantiate the object of the <code class="literal">SyncUDPClient</code> class and call the object's <code class="literal">emulateLongComputationOp()</code> method twice to synchronously consume the same service from two different servers.</p></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec79"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes that provide detailed discussions on how to perform synchronous I/O</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec29"/>Implementing an asynchronous TCP client</h1></div></div></div><p>As it has already <a id="id172" class="indexterm"/>been mentioned in the introduction section of this chapter, the simplest asynchronous client is structurally more complex than equivalent synchronous one. When we add a feature such as request canceling to the asynchronous client, it becomes even more complex.</p><p>In this recipe, we'll consider an asynchronous TCP client application supporting the asynchronous execution of the requests and request canceling functionality. Here is the list of requirements the application will fulfill:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Input from the user should be processed in a separate thread—the user interface thread. This thread should never be blocked for a noticeable amount of time.</li><li class="listitem" style="list-style-type: disc">The user should be able to issue multiple requests to different servers.</li><li class="listitem" style="list-style-type: disc">The user should be able to issue a new request before the previously issued requests complete.</li><li class="listitem" style="list-style-type: disc">The user should be able to cancel the previously issued requests before they complete.</li></ul></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec80"/>How to do it…</h2></div></div></div><p>As our application needs to support request canceling, we begin with specifying settings that enable request canceling on Windows:</p><div><pre class="programlisting">#include &lt;boost/predef.h&gt; // Tools to identify the OS.

// We need this to enable cancelling of I/O operations on
// Windows XP, Windows Server 2003 and earlier.
// Refer to "http://www.boost.org/doc/libs/1_58_0/
// doc/html/boost_asio/reference/basic_stream_socket/
// cancel/overload1.html" for details.
#ifdef BOOST_OS_WINDOWS
#define _WIN32_WINNT 0x0501

#if _WIN32_WINNT &lt;= 0x0502 // Windows Server 2003 or earlier.
  #define BOOST_ASIO_DISABLE_IOCP
  #define BOOST_ASIO_ENABLE_CANCELIO  
#endif
#endif</pre></div><p>Then, we include <a id="id173" class="indexterm"/>the necessary headers and specify the <code class="literal">using</code> directive for our convenience:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;

#include &lt;thread&gt;
#include &lt;mutex&gt;
#include &lt;memory&gt;
#include &lt;iostream&gt;

using namespace boost;</pre></div><p>We continue with defining a data type representing a pointer to a callback function. Because our client application is going to be asynchronous, we need a notion of callback as a request completion notification mechanism. Later, it will become clear as to why we need it and how it is used:</p><div><pre class="programlisting">// Function pointer type that points to the callback
// function which is called when a request is complete.
typedef void(*Callback) (unsigned int request_id,
  const std::string&amp; response,
  const system::error_code&amp; ec);</pre></div><p>Next, we define a <a id="id174" class="indexterm"/>data structure whose purpose is to keep the data related to a particular request while it is being executed. Let's name it <code class="literal">Session</code>:</p><div><pre class="programlisting">// Structure represents a context of a single request.
struct Session {
  Session(asio::io_service&amp; ios,
  const std::string&amp; raw_ip_address,
  unsigned short port_num,
  const std::string&amp; request,
  unsigned int id,
  Callback callback) :
  m_sock(ios),
  m_ep(asio::ip::address::from_string(raw_ip_address),
  port_num),
  m_request(request),
  m_id(id),
  m_callback(callback),
  m_was_cancelled(false) {}

  asio::ip::tcp::socket m_sock; // Socket used for communication
  asio::ip::tcp::endpoint m_ep; // Remote endpoint.
  std::string m_request;        // Request string.

  // streambuf where the response will be stored.
  asio::streambuf m_response_buf;
  std::string m_response; // Response represented as a string.

  // Contains the description of an error if one occurs during
  // the request life cycle.
  system::error_code m_ec;

  unsigned int m_id; // Unique ID assigned to the request.

  // Pointer to the function to be called when the request
  // completes.
  Callback m_callback;

  bool m_was_cancelled;
  std::mutex m_cancel_guard;
};</pre></div><p>The purpose of <a id="id175" class="indexterm"/>all the fields that the <code class="literal">Session</code> data structure contains will become clear later as we go.</p><p>Next, we define a class that provides the asynchronous communication functionality. Let's name it <code class="literal">AsyncTCPClient</code>:</p><div><pre class="programlisting">class AsyncTCPClient : public boost::noncopyable {
class AsyncTCPClient : public boost::noncopyable {
public:
   AsyncTCPClient(){
      m_work.reset(new boost::asio::io_service::work(m_ios));

      m_thread.reset(new std::thread([this](){
         m_ios.run();
      }));
   }

   void emulateLongComputationOp(
      unsigned int duration_sec,
      const std::string&amp; raw_ip_address,
      unsigned short port_num,
      Callback callback,
      unsigned int request_id) {

      // Preparing the request string.
      std::string request = "EMULATE_LONG_CALC_OP "
         + std::to_string(duration_sec)
         + "\n";

      std::shared_ptr&lt;Session&gt; session =
         std::shared_ptr&lt;Session&gt;(new Session(m_ios,
         raw_ip_address,
         port_num,
         request,
         request_id,
         callback));

      session-&gt;m_sock.open(session-&gt;m_ep.protocol());

      // Add new session to the list of active sessions so
      // that we can access it if the user decides to cancel
      // the corresponding request before it completes.
      // Because active sessions list can be accessed from 
      // multiple threads, we guard it with a mutex to avoid 
      // data corruption.
      std::unique_lock&lt;std::mutex&gt;
         lock(m_active_sessions_guard);
      m_active_sessions[request_id] = session;
      lock.unlock();

      session-&gt;m_sock.async_connect(session-&gt;m_ep, 
         [this, session](const system::error_code&amp; ec) 
         {
         if (ec != 0) {
            session-&gt;m_ec = ec;
            onRequestComplete(session);
            return;
         }

         std::unique_lock&lt;std::mutex&gt;
            cancel_lock(session-&gt;m_cancel_guard);

         if (session-&gt;m_was_cancelled) {
            onRequestComplete(session);
            return;
         }

                asio::async_write(session-&gt;m_sock, 
                             asio::buffer(session-&gt;m_request),
         [this, session](const boost::system::error_code&amp; ec,
                            std::size_t bytes_transferred) 
         {
         if (ec != 0) {
            session-&gt;m_ec = ec;
            onRequestComplete(session);
            return;
         }

         std::unique_lock&lt;std::mutex&gt;
            cancel_lock(session-&gt;m_cancel_guard);

         if (session-&gt;m_was_cancelled) {
            onRequestComplete(session);
            return;
         }

                asio::async_read_until(session-&gt;m_sock,
                                  session-&gt;m_response_buf, 
                                  '\n', 
         [this, session](const boost::system::error_code&amp; ec,
              std::size_t bytes_transferred) 
         {
         if (ec != 0) {
            session-&gt;m_ec = ec;
         } else {
            std::istream strm(&amp;session-&gt;m_response_buf);
            std::getline(strm, session-&gt;m_response);
         }

         onRequestComplete(session);
      });});});
   };

   // Cancels the request.  
   void cancelRequest(unsigned int request_id) {
      std::unique_lock&lt;std::mutex&gt;
         lock(m_active_sessions_guard);

      auto it = m_active_sessions.find(request_id);
      if (it != m_active_sessions.end()) {
         std::unique_lock&lt;std::mutex&gt;
            cancel_lock(it-&gt;second-&gt;m_cancel_guard);

         it-&gt;second-&gt;m_was_cancelled = true;
         it-&gt;second-&gt;m_sock.cancel();
      }
   }

   void close() {
      // Destroy work object. This allows the I/O thread to
      // exits the event loop when there are no more pending
      // asynchronous operations. 
      m_work.reset(NULL);

      // Wait for the I/O thread to exit.
      m_thread-&gt;join();
   }

private:
   void onRequestComplete(std::shared_ptr&lt;Session&gt; session) {
      // Shutting down the connection. This method may
      // fail in case socket is not connected. We don’t care 
      // about the error code if this function fails.
      boost::system::error_code ignored_ec;

      session-&gt;m_sock.shutdown(
         asio::ip::tcp::socket::shutdown_both,
         ignored_ec);

      // Remove session form the map of active sessions.
      std::unique_lock&lt;std::mutex&gt;
         lock(m_active_sessions_guard);

      auto it = m_active_sessions.find(session-&gt;m_id);
      if (it != m_active_sessions.end())
         m_active_sessions.erase(it);

      lock.unlock();

      boost::system::error_code ec;

      if (session-&gt;m_ec == 0 &amp;&amp; session-&gt;m_was_cancelled)
         ec = asio::error::operation_aborted;
      else
         ec = session-&gt;m_ec;

      // Call the callback provided by the user.
      session-&gt;m_callback(session-&gt;m_id, 
         session-&gt;m_response, ec);
   };

private:
   asio::io_service m_ios;
   std::map&lt;int, std::shared_ptr&lt;Session&gt;&gt; m_active_sessions;
   std::mutex m_active_sessions_guard;
   std::unique_ptr&lt;boost::asio::io_service::work&gt; m_work;
   std::unique_ptr&lt;std::thread&gt; m_thread;
};</pre></div><p>This class is the <a id="id176" class="indexterm"/>key component in our sample, providing most of the functionality of the application. This functionality is accessible to the user of the class through its public interface that contains three public methods:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">void emulateLongComputationOp(unsigned int duration_sec, const std::string&amp; raw_ip_address, unsigned short port_num, Callback callback, unsigned int request_id)</code>: This method initiates a request to the server</li><li class="listitem" style="list-style-type: disc"><code class="literal">void cancelRequest(unsigned int request_id)</code>: This method cancels the previously initiated request designated by the <code class="literal">request_id</code> argument</li><li class="listitem" style="list-style-type: disc"><code class="literal">void close()</code>: This method blocks the calling thread until all the currently running requests complete and deinitializes the client. When this method returns, the corresponding instance of the <code class="literal">AsyncTCPClient</code> class can't be used anymore.</li></ul></div><p>Now, we define a function that will serve as a callback, which we'll pass to the <code class="literal">AsyncTCPClient::emulateLongComputationOp()</code> method. In our case, this function is quite simple. It outputs the result of the request execution and the response message to the standard output stream if the request is completed successfully:</p><div><pre class="programlisting">void handler(unsigned int request_id,
         const std::string&amp; response, 
                const system::error_code&amp; ec) 
{
  if (ec == 0) {
    std::cout &lt;&lt; "Request #" &lt;&lt; request_id
      &lt;&lt; " has completed. Response: "
      &lt;&lt; response &lt;&lt; std::endl;
  } else if (ec == asio::error::operation_aborted) {
    std::cout &lt;&lt; "Request #" &lt;&lt; request_id
      &lt;&lt; " has been cancelled by the user." 
            &lt;&lt; std::endl;
  } else {
    std::cout &lt;&lt; "Request #" &lt;&lt; request_id
      &lt;&lt; " failed! Error code = " &lt;&lt; ec.value()
      &lt;&lt; ". Error message = " &lt;&lt; ec.message() 
             &lt;&lt; std::endl;
  }

  return;
}</pre></div><p>The <code class="literal">handler()</code> function's<a id="id177" class="indexterm"/> signature corresponds to the function pointer type <code class="literal">Callback</code> defined earlier.</p><p>Now that we have all the ingredients, we define an entry point of the application—the <code class="literal">main()</code> function—which demonstrates how to use the components defined above in order to communicate with the server. In our sample function, <code class="literal">main()</code> emulates the behavior of a human user by initiating three requests and canceling one of them:</p><div><pre class="programlisting">int main()
{
  try {
    AsyncTCPClient client;

    // Here we emulate the user's behavior.

    // User initiates a request with id 1.
    client.emulateLongComputationOp(10, "127.0.0.1", 3333,
      handler, 1);
    // Then does nothing for 5 seconds.
    std::this_thread::sleep_for(std::chrono::seconds(5));
    // Then initiates another request with id 2.
    client.emulateLongComputationOp(11, "127.0.0.1", 3334,
      handler, 2);
    // Then decides to cancel the request with id 1.
    client.cancelRequest(1);
    // Does nothing for another 6 seconds.
    std::this_thread::sleep_for(std::chrono::seconds(6));
    // Initiates one more request assigning ID3 to it.
    client.emulateLongComputationOp(12, "127.0.0.1", 3335,
      handler, 3);
    // Does nothing for another 15 seconds.
    std::this_thread::sleep_for(std::chrono::seconds(15));
    // Decides to exit the application.
    client.close();
  }
  catch (system::system_error &amp;e) {
    std::cout &lt;&lt; "Error occured! Error code = " &lt;&lt; e.code()
      &lt;&lt; ". Message: " &lt;&lt; e.what();

    return e.code().value();
  }

  return 0;
};</pre></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec81"/>How it works…</h2></div></div></div><p>Our sample client <a id="id178" class="indexterm"/>application uses two threads of execution. The first one—UI thread—is responsible for processing a user input and initiating requests. The responsibility of the second thread—I/O thread—is to run the event loop and call the asynchronous operation's callback routines. Such configuration allows us to make our application's user interface responsive.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec19"/>Starting the application – the main() entry point function</h3></div></div></div><p>The <code class="literal">main()</code> function is<a id="id179" class="indexterm"/> invoked in the context of the UI thread. This function emulates the behavior of the user who initiates and cancels requests. Firstly, it creates an instance of the <code class="literal">AsyncTCPClient</code> class and then calls its <code class="literal">emulateLongComputationOp()</code> method three times to initiate three asynchronous requests, each time specifying a different target server. The first request (the one assigned ID 1) is canceled by calling the <code class="literal">cancelRequest()</code>method several seconds after the request has been initiated.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec20"/>Request completion – the handler() callback function</h3></div></div></div><p>For all three<a id="id180" class="indexterm"/> requests initiated in the <code class="literal">main()</code> function <code class="literal">handler()</code> is specified as a callback. This function is called when the request is finished regardless of the reason as to why it finished—be it a successful completion or an error. Also, this function is called when the request is canceled by the user. The function accepts three arguments as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">unsigned int request_id</code>: This contains the unique identifier of the request. This is the same identifier that was assigned to the request when it was initiated.</li><li class="listitem" style="list-style-type: disc"><code class="literal">std::string&amp; response</code>: This contains the response data. This value is considered valid only if the request is completed successfully and is not canceled.</li><li class="listitem" style="list-style-type: disc"><code class="literal">system::error_code&amp; ec</code>: If an error occurs during a request life cycle, this object contains the error information. If the request was canceled, it contains the <code class="literal">asio::error::operation_aborted</code> value.</li></ul></div><p>The <code class="literal">handler()</code> function is quite simple in our sample. Based on the values of the parameters passed to it, it outputs information about the finished request.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec21"/>The AsyncTCPClient class – initializing</h3></div></div></div><p>As it has already<a id="id181" class="indexterm"/> been mentioned, all the functionality related to <a id="id182" class="indexterm"/>communication with the server application is hidden in the <code class="literal">AsyncTCPClient</code> class. This class has a nonempty constructor that accepts no arguments and does two things. Firstly, it instantiates an object of the <code class="literal">asio::io_service::work</code> class passing an instance of the <code class="literal">asio::io_service</code> class named <code class="literal">m_ios</code> to its constructor. Then, it spawns a thread that calls the <code class="literal">run()</code> method of the <code class="literal">m_ios</code> object. The object of the <code class="literal">asio::io_service::work</code> class keeps threads running event loop from exiting this loop when there are no pending asynchronous operations. The spawned thread plays the role of I/O thread in our application; in the context of this thread, the callbacks assigned asynchronous operations will be invoked.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec22"/>The AsyncTCPClient class – initiating a request</h3></div></div></div><p>The <code class="literal">emulateLongComputationOp()</code> method is intended to initiate an asynchronous request. It accepts five<a id="id183" class="indexterm"/> arguments. The first one named <code class="literal">duration_sec</code> represents the request parameter according to the application layer protocol. The <code class="literal">raw_ip_address</code> and <code class="literal">port_num</code> specify the server to which the request should be sent. The next argument is a pointer to a callback function, which will be called when the request is complete. We'll turn back to the discussion of the callback later in this section. The last argument <code class="literal">request_id</code> is the unique identifier of the request. This identifier is associated with the request and is used to refer to it later, for example, when there is a need to cancel it.</p><p>The <code class="literal">emulateLongComputationOp()</code> method begins with preparing a request string and allocating an instance of the <code class="literal">Session</code> structure that keeps the data associated with the request including a socket object that is used to communicate with the server.</p><p>Then, the socket is opened and the pointer to the <code class="literal">Session</code> object is added to the <code class="literal">m_active_sessions</code> map. This map contains pointers to the <code class="literal">Session</code> objects associated with all active requests, that is, those requests that have been initiated but have not finished yet. When the request completes, before the corresponding callback is called, the pointer to the <code class="literal">Session</code> object associated with this request is removed from the map.</p><p>The <code class="literal">request_id</code> argument is used as a key of the corresponding <code class="literal">Session</code> object added to the map. We need to cache the <code class="literal">Session</code> objects in order to have access to them in case the user decides to cancel the previously initiated request. If we would not need to support canceling of a request, we could avoid using the <code class="literal">m_active_sessions</code> map.</p><p>We synchronize the access to the <code class="literal">m_active_sessions</code> map with a <code class="literal">m_active_session_guard</code> mutex. Synchronization is necessary because the map can be accessed from multiple threads. Items are added to it in UI thread, and removed in an I/O thread that calls a callback when the corresponding request is finished.</p><p>Now, when the pointer to the corresponding <code class="literal">Session</code> object is cached, we need to connect the socket to the server, which we do by calling the socket's <code class="literal">async_connect()</code> method:</p><div><pre class="programlisting">session-&gt;m_sock.async_connect(session-&gt;m_ep,
  [this, session](const system::error_code&amp; ec)
  { 
         // ...
  });</pre></div><p>An endpoint object designating the server to which we want to connect and a callback function to be called when the connection is complete or an error occurs, are passed as arguments to this method. In our sample we use lambda function as a callback function. The call to the socket's <code class="literal">async_connect()</code> method is the last statement in the <code class="literal">emulateLongComputationOp()</code> method. When <code class="literal">async_connect()</code> returns, <code class="literal">emulateLongComputationOp()</code> returns too, which means that the request has been initiated.</p><p>Let's have a closer look<a id="id184" class="indexterm"/> at the lambda function that we pass to <code class="literal">async_connect()</code> as a callback. Here is its code:</p><div><pre class="programlisting">[this, session](const system::error_code&amp;ec)
{
  if (ec != 0) {
    session-&gt;m_ec = ec;
    onRequestComplete(session);
    return;
  }

  std::unique_lock&lt;std::mutex&gt;
    cancel_lock(session-&gt;m_cancel_guard);

  if (session-&gt;m_was_cancelled) {
     onRequestComplete(session);
     return;
  }

  asio::async_write(session-&gt;m_sock,
  asio::buffer(session-&gt;m_request),
        [this, session](const boost::system::error_code&amp; ec,
              std::size_t bytes_transferred)
              {
                    //...
        });
}</pre></div><p>The callback begins with checking the error code passed to it as the <code class="literal">ec</code> argument, the value of which when different from zero means that the corresponding asynchronous operation has failed. In case of failure, we store the <code class="literal">ec</code> value in the corresponding <code class="literal">Session</code> object, call the class's <code class="literal">onRequestComplete()</code> private method passing the <code class="literal">Session</code> object to it as an argument, and then return.</p><p>If the <code class="literal">ec</code> object designates success, we lock the <code class="literal">m_cancel_guard</code> mutex (the member of the request descriptor object) and check whether the request has not been canceled yet. More details about the canceling request are provided later in this section, where the <code class="literal">cancelRequest()</code> method is considered.</p><p>If we see that the request has not been canceled, we initiate the next asynchronous operation calling the Boost.Asio free function <code class="literal">async_write()</code> to send the request data to the server. Again, we pass to it a lambda function as a callback. This callback is very similar to the one passed to the <code class="literal">anync_connect()</code> method when the asynchronous connection operation was initiated. We first check the error code and then if it indicates success, we check whether or not the request has been canceled. Also, if it has not, we initiate the <a id="id185" class="indexterm"/>next asynchronous operation—<code class="literal">async_read_until()</code>—in order to receive a response from the server:</p><div><pre class="programlisting">[this, session](const boost::system::error_code&amp; ec,
         std::size_t bytes_transferred){
  if (ec != 0) {
    session-&gt;m_ec = ec;
    onRequestComplete(session);
    return;
  }

  std::unique_lock&lt;std::mutex&gt;
    cancel_lock(session-&gt;m_cancel_guard);

  if (session-&gt;m_was_cancelled) {
    onRequestComplete(session);
    return;
  }

  asio::async_read_until(session-&gt;m_sock,
        session-&gt;m_response_buf, '\n', 
     [this, session](const boost::system::error_code&amp; ec,
              std::size_t b'ytes_transferred) 
        {
      // ...
        });
}</pre></div><p>Again, we pass a lambda function as a callback argument to the <code class="literal">async_read_until()</code> free function. This callback function is quite simple:</p><div><pre class="programlisting">[this, session](const boost::system::error_code&amp; ec,
    std::size_t bytes_transferred) 
{
  if (ec != 0) {
    session-&gt;m_ec = ec;
  } else {
    std::istream strm(&amp;session-&gt;m_response_buf);
    std::getline(strm, session-&gt;m_response);
  }

  onRequestComplete(session);
}</pre></div><p>It checks the error code and<a id="id186" class="indexterm"/> in the case of success, it stores the received response data in the corresponding <code class="literal">Session</code> object. Then, the <code class="literal">AsyncTCPClient</code> class's private method <code class="literal">onRequestComplete()</code> is called and the <code class="literal">Session</code> object is passed to it as an argument.</p><p>The <code class="literal">onRequestComplete()</code> method is called whenever the request completes with any result. It is called when the request completes successfully, when the request fails at any stage of its life cycle, or when it is canceled by the user. The purpose of this method is to perform a cleanup and then to call a callback provided by the caller of the <code class="literal">emulateLongComputationOp()</code> method, when initiating this request.</p><p>The <code class="literal">onRequestComplete()</code> method begins with shutting down the socket. Note that here we use the overload of the socket's <code class="literal">shutdown()</code> method, which doesn't throw exceptions. We don't care if the shutting down of the connection fails as this is not a critical operation in our case. Then, we remove the corresponding entry from the <code class="literal">m_active_sessions</code> map as the request is finished and hence it is not active anymore. Also, as the last step, the user supplied callback is called. After the callback function returns, the request life cycle is finished.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec23"/>The AsyncTCPClient class – canceling the request</h3></div></div></div><p>Now, let's take a <a id="id187" class="indexterm"/>look at the <code class="literal">cancelRequst()</code> method of the <code class="literal">AsyncTCPClient</code> class. This method accepts an identifier of the request to be canceled as an argument. It begins with looking for the <code class="literal">Session</code> object corresponding to the specified request in the <code class="literal">m_active_sessions</code> map. If one is found, it calls the <code class="literal">cancel()</code> method on the socket object stored in this <code class="literal">Session</code> object. This leads to the interruption of the currently running asynchronous operation associated with this socket object.</p><p>However, there is a chance that the <code class="literal">cancelRequest()</code> method will be called at the moment when one asynchronous operation has already been completed and the next one has not been initiated yet. For example, imagine that the I/O thread is now running the callback of the <code class="literal">async_connect()</code> operation associated with a particular socket. At this moment, no asynchronous operation associated with this socket is in progress (because the next asynchronous operation <code class="literal">async_write()</code> has not been initiated yet); therefore, calling <code class="literal">cancel()</code> on this socket will have no effect. That's why we use an additional flag <code class="literal">Session::m_was_cancelled</code> designating, as its name suggests, whether the request has been canceled (or to be more precise, whether the <code class="literal">cancelRequest()</code> method has been called by the user). In the callback of the asynchronous operation, we look at the value of this flag before initiating the next asynchronous operation. If we see that the flag is set (which means that the request was canceled), we don't initiate the next asynchronous operation, but instead we interrupt the request execution and call the <code class="literal">onRequestComplete()</code> method.</p><p>We use the <code class="literal">Session::m_cancel_guard</code> mutex in the <code class="literal">cancelRequest()</code> method and in the callbacks of the<a id="id188" class="indexterm"/> asynchronous operations such as <code class="literal">async_connect()</code> and <code class="literal">async_write()</code> to enforce the following order of operations: request can be canceled either before the value of the <code class="literal">Session::m_was_cancelled</code> flag is tested in the callback, or after the next asynchronous operation is initiated. This order guarantees the proper canceling of a request whenever a user calls the <code class="literal">cancelRequest()</code> method.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec24"/>The AsyncTCPClient class – closing the client</h3></div></div></div><p>After the client has <a id="id189" class="indexterm"/>been used and is not needed anymore, it should be properly closed. The <code class="literal">close()</code> method of the <code class="literal">AsyncTCPClient</code> class allows us to do that. Firstly, this method destroys the <code class="literal">m_work</code> object that allows the I/O thread to exit the event message loop when all the asynchronous operations are completed. Then, it joins the I/O thread to wait until it exits.</p><p>After the <code class="literal">close()</code> method returns, the corresponding object of the <code class="literal">AsyncTCPClient</code> class cannot be used anymore.</p></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec82"/>There's more…</h2></div></div></div><p>The <code class="literal">AsyncTCPClient</code> class in the presented sample implements an asynchronous<a id="id190" class="indexterm"/> <strong>single-threaded</strong> TCP client. It uses a single thread that runs the event loop and processes the requests. Usually, when the request rate is low, the size of the response is not large and the request handler does not perform the complex and time-consuming processing of the response (stage 5 of the request life cycle); one thread is enough.</p><p>However, when we want the client to make millions of requests and process them as fast as possible, we may want to turn our client into a <strong>multithreaded</strong>
<a id="id191" class="indexterm"/> one, where multiple threads may run several requests truly simultaneously. Of course, it assumes that the computer running the client is a multicore or a multiprocessor computer. The application running more threads than the number of cores or processors installed in the computer may slow down the application due to the effect of the thread switching overhead.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec25"/>Implementing a multithreaded TCP client application</h3></div></div></div><p>In order to turn our<a id="id192" class="indexterm"/> single-treaded client application into a multithreaded one, we need to make several changes in it. Firstly, we need to replace the <code class="literal">m_thread</code> member of the <code class="literal">AnyncTCPClient</code> class that represents a single I/O thread, with a list of pointers to the <code class="literal">std::thread</code> objects, which will represent a collection of I/O threads:</p><div><pre class="programlisting">std::list&lt;std::unique_ptr&lt;std::thread&gt;&gt; m_threads;</pre></div><p>Next, we need to change the class's constructor so that it accepts an argument representing the number of I/O threads to be created. Besides, the constructor should spawn the specified number of I/O threads and add them all to the pool of threads running the event loop:</p><div><pre class="programlisting">AsyncTCPClient(unsigned char num_of_threads){
  m_work.reset(new boost::asio::io_service::work(m_ios));

  for (unsigned char i = 1; i &lt;= num_of_threads; i++) {
         std::unique_ptr&lt;std::thread&gt; th(
               new std::thread([this](){
        m_ios.run();
      }));

      m_threads.push_back(std::move(th));
    }
  }</pre></div><p>Like in a single-threaded version of the client, each thread calls the <code class="literal">run()</code> method of the <code class="literal">m_ios</code> object. As a result, all threads are added to the thread pool, controlled by the <code class="literal">m_ios</code> object. All threads from the pool will be used to call the corresponding asynchronous operation completion callbacks. This means that on a multicore or multiprocessor computer, several callbacks may be running truly simultaneously in different threads, each on a separate processor; whereas, in a single-threaded version of the client, they would be executed serially.</p><p>After each thread is created, the pointer to it is put to the <code class="literal">m_threads</code> list so that we have the access to the thread objects later.</p><p>Also, the last change is in the <code class="literal">close()</code> method. Here, we need to join each thread in the list. This is how the method looks after the change:</p><div><pre class="programlisting">void close() {
  // Destroy work object. This allows the I/O threads to
  // exit the event loop when there are no more pending
  // asynchronous operations. 
  m_work.reset(NULL);

  // Waiting for the I/O threads to exit.
  for (auto&amp; thread : m_threads) {
    thread-&gt;join();
  }
}</pre></div><p>Having destroyed the <a id="id193" class="indexterm"/>
<code class="literal">work</code> object, we iterate through the list of I/O threads and join each of them to make sure they all have exited.</p><p>The multithreaded TCP client application is ready. Now, when we create an object of multithreaded <code class="literal">AsyncTCPClient</code> class, the number specifying how many threads should be used to process the requests should be passed to the constructor of the class. All other aspects of usage of the class are identical to those of a single-threaded one.</p></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec83"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes that provide detailed discussions on how to perform asynchronous I/O with TCP socket and how to cancel asynchronous operations.</li><li class="listitem" style="list-style-type: disc">The <em>Using timers</em> recipe from <a class="link" href="ch06.html" title="Chapter 6. Other Topics">Chapter 6</a>, <em>Other Topics</em>, demonstrates how to use timers provided by Boost.Asio. Timers can be used to implement an asynchronous operation timeout mechanism.</li></ul></div></div></div></body></html>