- en: Chapter 6. Rendering Stereoscopic 3D Models using OpenGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Open Asset Import Library (Assimp)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading the first 3D model in the Wavefront Object (.obj) format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rendering 3D models with points, lines, and triangles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stereoscopic 3D rendering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will demonstrate how to visualize data with stunning stereoscopic
    3D technology using OpenGL. Stereoscopic 3D devices are becoming increasingly
    popular, and the latest generation's wearable computing devices (such as the 3D
    vision glasses from NVIDIA, Epson, and more recently, the augmented reality 3D
    glasses from Meta) can now support this feature natively.
  prefs: []
  type: TYPE_NORMAL
- en: The ability to visualize data in a stereoscopic 3D environment provides a powerful
    and highly intuitive platform for the interactive display of data in many applications.
    For example, we may acquire data from the 3D scan of a model (such as in architecture,
    engineering, and dentistry or medicine) and would like to visualize or manipulate
    3D objects in real time.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, OpenGL does not provide any mechanism to load, save, or manipulate
    3D models. Thus, to support this, we will integrate a new library named **Open
    Asset Import Library** (**Assimp**) into our code. The source code in this chapter
    is built on top of the *OpenGL point cloud rendering with texture mapping and
    overlays* recipe in [Chapter 5](ch05.html "Chapter 5. Rendering of Point Cloud
    Data for 3D Range-sensing Cameras"), *Rendering of Point Cloud Data for 3D Range-sensing
    Cameras*. The main dependencies include the GLFW library that requires OpenGL
    version 3.2 and higher. We will assume that you have all the prerequisite packages
    installed from earlier chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Open Asset Import Library (Assimp)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assimp is an open source library that loads and processes 3D geometric scenes
    from various 3D model data formats. The library provides a unified interface to
    load many different data formats, such as **Wavefront Object** (**.obj**), **3ds
    Max 3DS** (**.3ds**), and **Stereolithography** (**.stl**). Moreover, this library
    is written in portable, ISO-compliant C++, and thus, it allows further customization
    and long-term support. Since the library is cross-platform, we can easily install
    it in Mac OS X, Linux, as well as Windows with the instructions given in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To obtain the library source files or binary library for Assimp 3.0, download
    them directly from Assimp's official website at [http://sourceforge.net/projects/assimp/files/assimp-3.0/](http://sourceforge.net/projects/assimp/files/assimp-3.0/).
    Alternatively, for Linux and Mac OS X users, use the command-line interface to
    simplify the installation steps described next.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Mac OS X, install Assimp using the MacPort''s command-line interface. It
    automatically resolves all dependencies, so this is recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In Linux, install Assimp using the `apt-get` command interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After the installation, modify the Makefile to ensure the libraries are linked
    to the source files by appending the following to the `LIBS` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'and the `INCLUDES` path variable, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The final Makefile is shown here for your reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To install Assimp in Windows, first, download the binary library from this
    link: [http://sourceforge.net/projects/assimp/files/assimp-3.0/assimp--3.0.1270-full.zip/download](http://sourceforge.net/projects/assimp/files/assimp-3.0/assimp--3.0.1270-full.zip/download).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we configure the environment with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Unpack `assimp--3.0.1270-full.zip` and save it in `C:/Program Files (x86)/`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the DLL path, `C:/Program Files (x86)/assimp--3.0.1270-sdk/bin/assimp_release-dll_win32`,
    to the PATH environment variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Include the `CMakeLists.txt` file to the project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, generate the build files with the same steps as described in [Chapter
    4](ch04.html "Chapter 4. Rendering 2D Images and Videos with Texture Mapping"),
    *Rendering 2D Images and Videos with Texture Mapping* and [Chapter 5](ch05.html
    "Chapter 5. Rendering of Point Cloud Data for 3D Range-sensing Cameras"), *Rendering
    of Point Cloud Data for 3D Range-sensing Cameras*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to importing 3D model objects, Assimp also supports the exporting
    of 3D models in `.obj`, `.stl`, and `.ply` formats. By combining this library
    with the OpenGL graphics rendering engine, we have created a simple yet powerful
    mechanism to visualize and exchange 3D models collaboratively or remotely. The
    Assimp library can also handle some postprocessing tasks of 3D scenes after importing
    the model (for example, splitting large meshes to overcome certain GPU limitations
    on vertex count). These additional features are documented on the official website
    and may be of interest to advanced users ([http://assimp.sourceforge.net/lib_html/index.html](http://assimp.sourceforge.net/lib_html/index.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Loading the first 3D model in the Wavefront Object (.obj) format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we are ready to integrate a 3D object loader into our code. The first
    step is to create an empty class called `ObjLoader` along with the source (`.cpp`)
    and header (`.h`) files. This class handles all the functions related to 3D object
    loading, parsing, and drawing using the OpenGL and Assimp libraries. The headers
    of the class will include the Assimp core functions for the handling of the data
    structures and all I/O mechanisms of the 3D data format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the `ObjLoader.h` file, we provide interfaces for the main program to create,
    destroy, load, and display the 3D data. In the `ObjLoader.cpp` file, we implement
    a set of functions to parse the scene (a hierarchical representation of the 3D
    objects in terms of meshes and faces) using the built-in functions from Assimp.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Assimp library can support various 3D model data formats; however, in our
    example, we will focus on the Wavefront Object (`.obj`) format due to its simplicity.
    The `.obj` file is a simple geometric definition file that was first developed
    by Wavefront Technologies. The file contains the core elements of graphics, such
    as vertex, vertex position, normal face and so on, and is stored in a simple text
    format. Since the files are stored in ASCII text, we can easily open and examine
    the files without any parsers. For example, the following is the `.obj` file of
    a front-facing square:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the preceding example, the representation is quite simple
    and intuitive for beginners. The vertices can be read and extracted one line at
    a time, and then they can be modified.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will show the full implementation, which allows users
    to load the `.obj` file, store the scene in a vertex buffer object, and display
    the scene.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we create the `ObjLoader.h` file in the common folder and append the
    class function definitions and variables that will be used in our implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The names of classes from the Assimp library are preceded by the prefix `ai-`
    (for example, `aiScene` and `aiVector3D`). The `ObjLoader` file provides ways
    to dynamically load and draw the object loaded into the memory. It also handles
    simple dynamic scaling so that the object will fit on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the source file, `ObjLoader.cpp`, we start by adding the constructor for
    the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we implement the file-loading mechanism with the `aiImportFile` function.
    The scene is processed to extract the bounding box size for proper scaling to
    fit the screen. The number of vertices of the scene is then used to allow dynamic
    vertex buffer creation in later steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract the total number of vertices required to draw the scene, we recursively
    walk through every node in the tree hierarchy. The implementation requires a simple
    recursive function that returns the number of vertices in each node, and then
    the total is calculated based on the summation of all nodes upon the return of
    the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, to calculate the size of the bounding box (that is, the minimum
    volume that is required to contain the scene), we recursively examine each node
    and extract the points that are farthest away from the center of the object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The resulting bounding box allows us to calculate the scaling factor and recenter
    the object coordinate to fit within the viewable screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `main.cpp` file, we integrate the code by first inserting the header
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create the `ObjLoader` object and load the model with the given filename
    in the main function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ObjLoader` contains an algorithm that recursively examines each mesh and
    computes the bounding box and the number of vertices in the scene. Then, we dynamically
    allocate the vertex buffer based on the number of vertices and load the vertices
    into the buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have all the necessary vertex information for display with our custom
    shader program written in OpenGL.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assimp provides the mechanism to load and parse the 3D data format efficiently.
    The key feature we utilized is the hierarchical way to import 3D objects, which
    allows us to unify our rendering pipeline regardless of the 3D format. The `aiImportFile`
    function reads the given file and returns its content in the `aiScene` structure.
    The second parameter of this function specifies the optional postprocessing steps
    to be executed after a successful import. The `aiProcessPreset_TargetRealtime_MaxQuality`
    flag is a predefined variable, which combines the following set of parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: These postprocessing options are described in further detail at [http://assimp.sourceforge.net/lib_html/postprocess_8h.html#a64795260b95f5a4b3f3dc1be4f52e410](http://assimp.sourceforge.net/lib_html/postprocess_8h.html#a64795260b95f5a4b3f3dc1be4f52e410).
    Advanced users can look into each option and understand whether these functions
    need to be enabled or disabled based on the content.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have a simple mechanism to load graphics into the Assimp `aiScene`
    object, present the bounding box size, as well as extract the number of vertices
    required to render the scene. Next, we will create a simple shader program as
    well as various drawing functions to visualize the content with different styles.
    In short, by integrating this with the OpenGL graphics rendering engine, we now
    have a flexible way to visualize 3D models using the various tools we developed
    in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Rendering 3D models with points, lines, and triangles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next step after importing the 3D model is to display the content on the
    screen using an intuitive and aesthetically pleasing way. Many complex scenes
    consist of multiple surfaces (meshes) and many vertices. In the previous chapter,
    we implemented a simple shader program to visualize the point cloud at various
    depth values based on a heat map. In this section, we will utilize very simple
    primitives (points, lines, and triangles) with transparency to create skeleton-like
    rendering effects.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will continue the implementation of the `ObjLoader` class to support loading
    vertices and draw the graphics for each mesh in the scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the source file of `ObjLoader.cpp`, we add a recursive function to extract
    all vertices from the scene and store them in a single vertex buffer array. This
    allows us to reduce the number of vertex buffers to be managed, thus reducing
    the complexity of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To draw the graphics, we traverse the `aiScene` object from the root node and
    draw the meshes one piece at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In the vertex shader, `pointcloud.vert`, we compute the color of vertices based
    on their positions in space. The remapping algorithm creates a heat map representation
    of the object in space, and it serves as an important depth cue for the human
    eye (depth perception):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The vertex shader passes the heat-mapped color information along to the fragment
    shader through the `color_based_on_position` variable. Then, the final color is
    returned through the fragment shader (`pointcloud.frag`) directly without further
    processing. The implementation of such a simple pipeline is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we draw the scene with various styles: lines, points, and triangles
    with transparency. The following is the code snippet inside the drawing loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The series of screenshots that follow illustrate the aesthetically pleasing
    results we can achieve with our custom shader. The color mapping based on the
    depth position using the heat map shader provides a strong depth perception that
    helps us understand the 3D structure of the objects more easily. Furthermore,
    we can enable and disable various rendering options separately to achieve various
    effects. For example, the same object can be rendered with different styles: points,
    lines, and triangles (surfaces) with transparency.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the effects, we will first render two objects with points only.
    The first example is a dragon model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The second example is an architectural model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The point-based rendering style is great for visualizing a large dataset with
    unknown relations or distribution. Next, we will render the same objects with
    lines only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the architectural model rendered with lines only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With the lines, now we can see the structure of the object more easily. This
    rendering technique is great for simple structures, such as architectural models
    and other well-defined models. In addition, we can render the scene with both
    points and lines enabled, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the architectural model rendered with points and lines enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The combination of both points and lines provides additional visual cue to
    the structure of the object (that is, emphasis on the intersection points). Finally,
    we render the scene with all options enabled: points, lines, and triangles (surfaces)
    with transparency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the architectural model rendered using points, lines and triangles
    with transparency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The final combination with all the options enabled provides an even more intuitive
    visualization of the volume of the object as well as the overall 3D structure.
    Alternatively, we can also enable the depth test and render the solid model with
    no transparency:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Instructions on how to enable/disable these options at runtime are documented
    in the source code.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By combining the Assimp library and OpenGL, we can now dynamically load 3D models
    on the screen and create visually appealing 3D effects through an OpenGL-based
    interactive visualization tool.
  prefs: []
  type: TYPE_NORMAL
- en: In `ObjLoader.cpp`, the `loadVertices` function converts the scene into a single
    vertex buffer array to reduce the complexity of memory management. In particular,
    this approach reduces the number of OpenGL memory copies and the number of memory
    buffers on the rendering side (that is, `glBufferData` and `glGenBuffers`). In
    addition, the loading function handles the scaling and centering of vertices based
    on the bounding box. This step is critical as most 3D formats do not normalize
    their coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the `draw` function in `ObjLoader.cpp` traverses the `aiScene` object
    and draws each part of the scene with the vertex buffer. In the case of point-based
    rendering, we can skip this step and directly draw the entire array using `glDrawArray`
    because there is no dependency among the neighboring vertices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The vertex shader (`pointcloud.vert`) contains the implementation of the heat
    map color generator. The `heatmap` function takes in three parameters: the input
    value (that is, the depth or *z* value), the minimum value, and maximum value.
    It returns the heat map color representation in the RGBA format.'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the drawing loop, the `computeStereoViewProjectionMatrices` function
    constructs the view and projection matrices. The details are explained in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can mix and match various rendering techniques; for example, by
    enabling both points and lines only for skeleton-based rendering. Various depth
    visual cues, such as occlusion and motion parallax, can be easily added by supporting
    rotation or translation of the object. To further improve the result, other rendering
    techniques such as lighting or shading can be added based on the application requirements.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Assimp library also supports many file formats in addition to `.obj` files.
    For example, we can load `.stl` files into our system without changing the source
    code at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'To download more 3D models, visit various 3D model-sharing websites such as
    *Makerbot ThingiVerse* ([http://www.thingiverse.com/](http://www.thingiverse.com/))
    or *Turbosquid* ([http://www.turbosquid.com/](http://www.turbosquid.com/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![See also](img/9727OS_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Stereoscopic 3D rendering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '3D television and 3D glasses are becoming much more prevalent with the latest
    trends in consumer electronics and technological advances in wearable computing.
    In the market, there are currently many hardware options that allow us to visualize
    information with stereoscopic 3D technology. One common format is side-by-side
    3D, which is supported by many 3D glasses as each eye sees an image of the same
    scene from a different perspective. In OpenGL, creating side-by-side 3D rendering
    requires asymmetric adjustment as well as viewport adjustment (that is, the area
    to be rendered) – asymmetric frustum parallel projection or equivalently to lens-shift
    in photography. This technique introduces no vertical parallax and widely adopted
    in the stereoscopic rendering. To illustrate this concept, the following diagram
    shows the geometry of the scene that a user sees from the right eye:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stereoscopic 3D rendering](img/9727OS_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The **intraocular distance** (**IOD**) is the distance between two eyes. As
    we can see from the diagram, the **Frustum Shift** represents the amount of skew/shift
    for asymmetric frustrum adjustment. Similarly, for the left eye image, we perform
    the transformation with a mirrored setting. The implementation of this setup is
    described in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code illustrates the steps to construct the projection and view
    matrices for stereoscopic 3D visualization. The code uses the intraocular distance,
    the distance of the image plane, and the distance of the near clipping plane to
    compute the appropriate frustum shifts value. In the source file, `common/controls.cpp`,
    we add the implementation for the stereo 3D matrix setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In the rendering loop in `main.cpp`, we define the viewports for each eye (*left*
    and *right*) and set up the projection and view matrices accordingly. For each
    eye, we translate our camera position by half of the intraocular distance, as
    illustrated in the previous figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The final rendering result consists of two separate images on each side of the
    display, and note that each image is compressed horizontally by a scaling factor
    of two. For some display systems, each side of the display is required to preserve
    the same aspect ratio depending on the specifications of the display.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the final screenshots of the same models in true 3D using stereoscopic
    3D rendering:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s the rendering of the architectural model in stereoscopic 3D:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/9727OS_06_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The stereoscopic 3D rendering technique is based on the parallel axis and asymmetric
    frustum perspective projection principle. In simpler terms, we rendered a separate
    image for each eye as if the object was seen at a different eye position but viewed
    on the same plane. Parameters such as the intraocular distance and frustum shift
    can be dynamically adjusted to provide the desired 3D stereo effects.
  prefs: []
  type: TYPE_NORMAL
- en: For example, by increasing or decreasing the frustum asymmetry parameter, the
    object will appear to be moved in front or behind the plane of the screen. By
    default, the zero parallax plane is set to the middle of the view volume. That
    is, the object is set up so that the center position of the object is positioned
    at the screen level, and some parts of the object will appear in front of or behind
    the screen. By increasing the frustum asymmetry (that is, positive parallax),
    the scene will appear to be pushed behind the screen. Likewise, by decreasing
    the frustum asymmetry (that is, negative parallax), the scene will appear to be
    pulled in front of the screen.
  prefs: []
  type: TYPE_NORMAL
- en: The `glm::frustum` function sets up the projection matrix, and we implemented
    the asymmetric frustum projection concept illustrated in the drawing. Then, we
    use the `glm::lookAt` function to adjust the eye position based on the IOP value
    we have selected.
  prefs: []
  type: TYPE_NORMAL
- en: To project the images side by side, we use the `glViewport` function to constrain
    the area within which the graphics can be rendered. The function basically performs
    an affine transformation (that is, scale and translation) which maps the normalized
    device coordinate to the window coordinate. Note that the final result is a side-by-side
    image in which the graphic is scaled by a factor of two vertically (or compressed
    horizontally). Depending on the hardware configuration, we may need to adjust
    the aspect ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'The current implementation supports side-by-side 3D, which is commonly used
    in most wearable **Augmented Reality** (**AR**) or **Virtual Reality** (**VR**)
    glasses. Fundamentally, the rendering technique, namely the asymmetric frustum
    perspective projection described in our chapter, is platform-independent. For
    example, we have successfully tested our implementation on the Meta 1 Developer
    Kit ([https://www.getameta.com/products](https://www.getameta.com/products)) and
    rendered the final results on the optical see-through stereoscopic 3D display:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/9727OS_06_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is the front view of the Meta 1 Developer Kit, showing the optical see-through
    stereoscopic 3D display and 3D range-sensing camera (introduced in [Chapter 5](ch05.html
    "Chapter 5. Rendering of Point Cloud Data for 3D Range-sensing Cameras"), *Rendering
    of Point Cloud Data for 3D Range-sensing Cameras*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/9727OS_06_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The result is shown as follows, with the stereoscopic 3D graphics rendered
    onto the real world (which forms the basis of augmented reality):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/9727OS_06_16.jpg)![How it works...](img/9727OS_06_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the upcoming chapters, we will transition to the increasingly powerful and
    ubiquitous mobile platform and introduce how to use OpenGL to visualize data in
    interesting ways using built-in motion sensors on mobile devices. Further details
    on implementing augmented reality applications will be covered in [Chapter 9](ch09.html
    "Chapter 9. Augmented Reality-based Visualization on Mobile or Wearable Platforms"),
    *Augmented reality-based visualization on mobile or wearable platforms*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition, we can easily extend our code to support shutter glasses-based
    3D monitors by utilizing the Quad Buffered OpenGL APIs (refer to the `GL_BACK_RIGHT`
    and `GL_BACK_LEFT` flags in the `glDrawBuffer` function). Unfortunately, such
    3D formats require specific hardware synchronization and often require higher
    frame rate display (for example, 120Hz) as well as a professional graphics card.
    Further information on how to implement stereoscopic 3D in your application can
    be found at [http://www.nvidia.com/content/GTC-2010/pdfs/2010_GTC2010.pdf](http://www.nvidia.com/content/GTC-2010/pdfs/2010_GTC2010.pdf).
  prefs: []
  type: TYPE_NORMAL
