<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Implementing Server Applications</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing a synchronous iterative TCP server</li><li class="listitem" style="list-style-type: disc">Implementing a synchronous parallel TCP server</li><li class="listitem" style="list-style-type: disc">Implementing an asynchronous TCP server</li></ul></div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec30"/>Introduction</h1></div></div></div><p>A <strong>server</strong> is <a id="id194" class="indexterm"/>a part of a distributed application that provides a service or services that are consumed by other parts of this application—<strong>clients</strong>. Clients communicate <a id="id195" class="indexterm"/>with the server in order to consume services provided by it.</p><p>Usually, a server application plays a passive role in the client-server communication process. During start-up, a server application attaches to a particular well-known port (meaning, it is known to the potential clients or at least it can be obtained by the clients at runtime from some well-known registry) on the host machine. After this, it passively waits for incoming requests arriving to that port from the clients. When the request arrives, the server processes it (serves) by performing actions according to the specification of the service it provides.</p><p>Depending on the services that particular server provides, the request processing may mean a different thing. An HTTP server, for example, would usually read the content of a file specified in the request message and send it back to the client. A proxy server would simply redirect a client's request to a different server for the actual processing (or maybe for another round of redirection). Other more specific servers may provide services that perform complex computations on the data provided by the client in the request and return results of such computations back to the client.</p><p>Not all servers play a passive role. Some server applications may send messages to the clients without waiting for the clients to first send a request. Usually, such servers act as <a id="id196" class="indexterm"/>
<em>notifiers</em>, and they <a id="id197" class="indexterm"/>
<em>notify</em> clients of some interesting events. In this case, clients may not need to send any data to the server at all. Instead, they passively wait for notifications from the server and having received one, they react accordingly. Such a communication model is called <a id="id198" class="indexterm"/>
<em>push-style communication</em>. This model is gaining popularity in modern web applications, providing additional flexibility.</p><p>So, the first way to classify a server application is by the function (or functions) they perform or a service (or services) they provide to their clients.</p><p>Another obvious classification dimension is the transport layer protocol used by the server to communicate with the clients.</p><p>TCP protocol is very popular today and many general purpose server applications use it for communication. Other, more specific servers may use UDP protocol. Hybrid server applications that provide their services through both TCP and UDP protocols at the same time fall under the third category and are called <a id="id199" class="indexterm"/>
<strong>multiprotocol servers</strong>. In this chapter, we will consider several types of TCP servers.</p><p>One more characteristic of a server is a manner in which it serves clients. An <a id="id200" class="indexterm"/>
<strong>iterative server</strong> serves clients in one-by-one fashion, meaning that it does not start serving the next client before it completes serving the one it is currently serving. A <a id="id201" class="indexterm"/>
<strong>parallel server</strong> can serve multiple clients in parallel. On a single-processor computer, a parallel server interleaves different stages of communication with several clients running them on a single processor. For example, having connected to one client and while waiting for the request message from it, the server can switch to connecting the second client, or read the request from the third one; after this, it can switch back to the first client to continue serving it. Such parallelism is called pseudo parallelism, as a processor is merely switching between several clients, but does not serve them truly simultaneously, which is impossible with a single processor.</p><p>On multiprocessor computers, the true parallelism is possible, when a server serves more than one client at the same time using different hardware threads for each client.</p><p>Iterative servers are relatively simple to implement and can be used when the request rate is low enough so that the server has time to finish processing one request before the next one arrives. It is clear that iterative servers are not scalable; adding more processors to the computer running such a server will not increase the server's throughput. Parallel servers, on the other hand, can handle higher request rates; if properly implemented, they are scalable. A truly parallel server running on a multiprocessor computer can handle higher request rates than the same server running on a single processor computer.</p><p>Another way to classify server applications, from an implementation's point of view, is according to whether the server is synchronous or asynchronous. A <strong>synchronous server</strong>
<a id="id202" class="indexterm"/> uses synchronous socket API calls that block the thread of execution until the requested operation is completed, or else an error occurs. Thus, a typical synchronous TCP server would use methods such as <code class="literal">asio::ip::tcp::acceptor::accept()</code> to accept the client connection request, <code class="literal">asio::ip::tcp::socket::read_some()</code> to receive the request message from the client, and then <code class="literal">asio::ip::tcp::socket::write_some()</code> to send the response message back to the client. All three methods are blocking. They block the thread of execution until the requested operation is completed, or an error occurs, which makes the server using these <a id="id203" class="indexterm"/>operations <strong>synchronous</strong>.</p><p>An <strong>asynchronous server application</strong>, as <a id="id204" class="indexterm"/>opposed to the synchronous one, uses asynchronous socket API calls. For example, an asynchronous TCP server may use the <code class="literal">asio::ip::tcp::acceptor::async_accept()</code> method to asynchronously accept the client connection request, the <code class="literal">asio::ip::tcp::socket::async_read_some()</code> method or the <code class="literal">asio::async_read()</code> free function to asynchronously receive the request message from the client, and then the <code class="literal">asio::ip::tcp::socket::async_write_some()</code> method or the <code class="literal">asio::async_write()</code> free function to asynchronously send a response message back to the client.</p><p>Because the structure of a synchronous server application significantly differs from that of an asynchronous one, the decision as to which approach to apply should be made early at the server application design stage, and this decision should be based on the careful analysis of the application requirements. Besides, the possible application evolution paths and new requirements that may appear in the future should be considered and taken into account.</p><p>As usually, each approach has its advantages and disadvantages. When a synchronous approach yields better results in one situation, it may be absolutely unacceptable in another; in this case, an asynchronous approach might be the right choice. Let's compare two approaches to better understand the strengths and weaknesses of each of them.</p><p>The main <a id="id205" class="indexterm"/>advantage of a synchronous approach<a id="id206" class="indexterm"/> as compared to an asynchronous one is its <em>simplicity</em>. A <a id="id207" class="indexterm"/>synchronous server is significantly easier to implement, debug, and support than a functionally equal asynchronous one. Asynchronous servers are more complex due to the fact that asynchronous operations used by them complete in other places in code than they are initiated. Usually, this requires allocating additional data structures in the free memory to keep the context of the request, implementing callback functions, thread synchronization, and other extras that may make the application structure quite complex and error-prone. Most of these extras are not required in synchronous servers. Besides, an asynchronous approach brings in additional computational and memory overheads, which may make it less efficient than a synchronous one in some situations.</p><p>However, a <a id="id208" class="indexterm"/>synchronous approach has some functional limitations, which often makes it unacceptable. These limitations consist of the inability to cancel a synchronous operation after it has started, or to assign it a timeout so that it gets interrupted if it is running for too long. As opposed to synchronous operations, asynchronous ones can be canceled at any moment after the operation has been initiated.</p><p>The fact that synchronous operations cannot be canceled significantly limits the area of the application of synchronous servers. Publicly available servers that use synchronous operations are vulnerable to the attacks of a culprit. If such a server is single-threaded, a single malicious client is enough to block the server, not allowing other clients to communicate with it. Malicious client used by a culprit connects to the server and does not send any data to it, while the latter is blocked in one of the synchronous reading functions or methods, which does not allow it to serve other clients.</p><p>Such servers would usually be used in safe and protected environments in private networks, or as an internal part of an application running on a single computer using such a server for interprocess communication. Another possible application area of synchronous servers is, of course, the implementation of throwaway prototypes.</p><p>Besides the difference in the structural complexity and functionality described above, the two approaches differ in the efficiency and scalability when it comes to serving large numbers of clients sending requests at high rates. Servers using asynchronous operations are more efficient and scalable than synchronous servers especially when they run on multiprocessor computers with operating systems natively supporting an asynchronous network I/O.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec84"/>The sample protocol</h2></div></div></div><p>In this<a id="id209" class="indexterm"/> chapter, we are going to consider three recipes describing how to implement the synchronous iterative TCP server, synchronous parallel TCP server, and asynchronous TCP server. In all the recipes, it is assumed that the server communicates with clients using the following intentionally trivialized (for the sake of clarity) application layer protocol.</p><p>A server application accepts request messages represented as ASCII strings containing a sequence of symbols ending with a new-line ASCII symbol. All the symbols coming after the new-line symbol are ignored by the server.</p><p>Having received a request, the server performs some dummy operations and replies with a constant message as follows:</p><div><pre class="programlisting">"Response\n"</pre></div><p>Such a trivial protocol <a id="id210" class="indexterm"/>allows us to concentrate on the implementation of the <em>server</em> and not the <em>service</em> provided by it.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec31"/>Implementing a synchronous iterative TCP server</h1></div></div></div><p>A<a id="id211" class="indexterm"/> synchronous iterative TCP server is a part of a distributed application that satisfies the following criteria:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Acts as a server in the client-server communication model</li><li class="listitem" style="list-style-type: disc">Communicates with client applications over TCP protocol</li><li class="listitem" style="list-style-type: disc">Uses I/O and control operations that block the thread of execution until the corresponding operation completes, or an error occurs</li><li class="listitem" style="list-style-type: disc">Handles clients in a serial, one-by-one fashion</li></ul></div><p>A typical synchronous iterative TCP server works according to the following algorithm:</p><div><ol class="orderedlist arabic"><li class="listitem">Allocate an acceptor socket and bind it to a particular TCP port.</li><li class="listitem">Run a loop until the server is stopped:<div><ol class="orderedlist arabic"><li class="listitem">Wait for the connection request from a client.</li><li class="listitem">Accept the client's connection request when one arrives.</li><li class="listitem">Wait for the request message from the client.</li><li class="listitem">Read the request message.</li><li class="listitem">Process the request.</li><li class="listitem">Send the response message to the client.</li><li class="listitem">Close the connection with the client and deallocate the socket.</li></ol></div></li></ol></div><p>This recipe demonstrates how to implement a synchronous iterative TCP server application with Boost.Asio.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec85"/>How to do it…</h2></div></div></div><p>We begin implementing our server application by defining a class responsible for handling a single client by reading the request message, processing it, and then sending back the response message. This class represents a single service provided by the server application and, therefore, we will give it a name <code class="literal">Service</code>:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;

#include &lt;thread&gt;
#include &lt;atomic&gt;
#include &lt;memory&gt;
#include &lt;iostream&gt;

using namespace boost;

class Service {
public:
  Service(){}

  void HandleClient(asio::ip::tcp::socket&amp; sock) {
    try {
      asio::streambuf request;
      asio::read_until(sock, request, '\n');

      // Emulate request processing.
      inti = 0;
      while (i != 1000000)
        i++;
        std::this_thread::sleep_for(
std::chrono::milliseconds(500));

      // Sending response.
      std::string response = "Response\n";
      asio::write(sock, asio::buffer(response));
}
    catch (system::system_error&amp;e) {
      std::cout  &lt;&lt; "Error occured! Error code = " 
&lt;&lt;e.code() &lt;&lt; ". Message: "
          &lt;&lt;e.what();
    }
  }
};</pre></div><p>To keep things<a id="id212" class="indexterm"/> simple, in our sample server application, we implement a dummy service, which only emulates the execution of certain operations. The request processing emulation consists of performing many increment operations to emulate operations that intensively consume CPU and then putting the thread of control to sleep for some time to emulate such operations as reading a file or communicating with a peripheral device synchronously.</p><div><div><h3 class="title"><a id="note11"/>Note</h3><p>The <code class="literal">Service</code> class is quite simple and contains only one method. However, classes representing services in real-world applications would usually be more complex and richer in functionality, though the main idea would stay the same.</p></div></div><p>Next, we<a id="id213" class="indexterm"/> define another class that represents a high-level <em>acceptor</em> concept (as compared to the low-level concept represented by the <code class="literal">asio::ip::tcp::acceptor</code> class). This class is responsible for accepting connection requests arriving from clients and instantiating objects of the <code class="literal">Service</code> class, which will provide the service to the connected clients. Let's name this class correspondingly—<code class="literal">Acceptor</code>:</p><div><pre class="programlisting">class Acceptor {
public:
  Acceptor(asio::io_service&amp;ios, unsigned short port_num) :
    m_ios(ios),
    m_acceptor(m_ios,
        asio::ip::tcp::endpoint(
              asio::ip::address_v4::any(),
              port_num))
  {
    m_acceptor.listen();
  }

  void Accept() {
    asio::ip::tcp::socket sock(m_ios);

    m_acceptor.accept(sock);

    Service svc;
    svc.HandleClient(sock);
  }

private:
  asio::io_service&amp;m_ios;
  asio::ip::tcp::acceptor m_acceptor;
};</pre></div><p>This class owns an object of the <code class="literal">asio::ip::tcp::acceptor</code> class named <code class="literal">m_acceptor</code>, which is used to synchronously accept incoming connection requests.</p><p>Also, we define a class that represents the server itself. The class is named correspondingly—<code class="literal">Server</code>:</p><div><pre class="programlisting">class Server {
public:
  Server() : m_stop(false) {}

  void Start(unsigned short port_num) {
    m_thread.reset(new std::thread([this, port_num]() {
      Run(port_num);
    }));
  }

  void Stop() {
    m_stop.store(true);
    m_thread-&gt;join();
  }

private:
  void Run(unsigned short port_num) {
    Acceptor acc(m_ios, port_num);

    while (!m_stop.load()) {
      acc.Accept();
    }
  }

  std::unique_ptr&lt;std::thread&gt;m_thread;
  std::atomic&lt;bool&gt;m_stop;
  asio::io_servicem_ios;
};</pre></div><p>This class <a id="id214" class="indexterm"/>provides an interface comprised by two methods—<code class="literal">Start()</code> and <code class="literal">Stop()</code> that are used to start and stop the server correspondingly. The loop runs in a separate tread spawned by the <code class="literal">Start()</code> method. The <code class="literal">Start()</code> method is nonblocking, while the <code class="literal">Stop()</code> method blocks the caller thread until the server is stopped.</p><p>Thorough inspection of the <code class="literal">Server</code> class reveals one serious drawback of the implementation of the server—the <code class="literal">Stop()</code> method may never return under some circumstances. The discussion of this problem and the ways to resolve it is provided later in this recipe.</p><p>Eventually, we implement the application entry point function <code class="literal">main()</code> that demonstrates how to use the <code class="literal">Server</code> class:</p><div><pre class="programlisting">int main()
{
  unsigned short port_num = 3333;

  try {
    Server srv;
    srv.Start(port_num);

    std::this_thread::sleep_for(std::chrono::seconds(60));

    srv.Stop();
  }
  catch (system::system_error&amp;e) {
        std::cout  &lt;&lt; "Error occured! Error code = " 
                   &lt;&lt;e.code() &lt;&lt; ". Message: "
                   &lt;&lt;e.what();
  }

  return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec86"/>How it works…</h2></div></div></div><p>The sample<a id="id215" class="indexterm"/> server application consists of four components—the <code class="literal">Server</code>, <code class="literal">Acceptor</code>, and <code class="literal">Service</code> classes and the application entry point function <code class="literal">main()</code>. Let's consider how each of these components work.</p><div><div><div><div><h3 class="title"><a id="ch04lvl3sec26"/>The Service class</h3></div></div></div><p>The <code class="literal">Service</code> class<a id="id216" class="indexterm"/> is the key functional component in the whole application. While other components are infrastructural in their purpose, this class implements the actual function (or service) provided by the server to the clients.</p><p>This class is simple and consists of a single <code class="literal">HandleClient()</code> method. This method accepts an object representing a socket connected to the client as its input argument and handles that particular client.</p><p>In our sample, such handling is trivial. Firstly, the request message is synchronously read from the socket until a new line ASCII symbol <code class="literal">\n</code> is encountered. Then, the request is processed. In our case, we emulate processing by running a dummy loop performing one million increment operations and then putting the thread to sleep for half a second. After this, the response message is prepared and synchronously sent back to the client.</p><p>The exceptions that may be thrown by Boost.Asio I/O functions and methods are caught and handled in the <code class="literal">HandleClient()</code> method and are not propagated to the method caller so that if the handling of one client fails, the server continues working.</p><p>Depending on the needs of a particular application, the <code class="literal">Service</code> class can be extended and enriched with a functionality to provide the needed service.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec27"/>The Acceptor class</h3></div></div></div><p>The <a id="id217" class="indexterm"/>
<code class="literal">Acceptor</code> class is a part of the server application infrastructure. When constructed, it instantiates an acceptor socket object <code class="literal">m_acceptor</code> and calls its <code class="literal">listen()</code> method to start listening for connection requests from clients.</p><p>This class exposes a single public method named <code class="literal">Accept()</code>. This method when called, instantiates an object of the <code class="literal">asio::ip::tcp::socket</code> class named <code class="literal">sock</code>, representing an active socket, and tries to accept a connection request. If there are pending connection requests available, the connection request is processed and the active socket <code class="literal">sock</code> is connected to the new client. Otherwise, this method blocks until a new connection request arrives.</p><p>Then, an instance of the <code class="literal">Service</code> object is created and its <code class="literal">HandleClient()</code> method is called. The <code class="literal">sock</code> object connected to the client is passed to this method. The <code class="literal">HandleClient()</code> method blocks until communication with the client and request processing completes, or an error occurs. When the <code class="literal">HandleClient()</code> method returns, the <code class="literal">Accept()</code> method of the <code class="literal">Acceptor</code> class returns too. Now, <em>the acceptor</em> is ready to accept the next connection request.</p><p>One execution of the class's <code class="literal">Accept()</code>method performs the full handling cycle of one client.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec28"/>The Server class</h3></div></div></div><p>The <a id="id218" class="indexterm"/>
<code class="literal">Server</code> class, as its name suggests, represents a <em>server</em> that can be controlled through class's interface methods <code class="literal">Start()</code>and <code class="literal">Stop()</code>.</p><p>The <code class="literal">Start()</code> method initiates the start-up of the server. It spawns a new thread, which starts its execution from the <code class="literal">Server</code> class's <code class="literal">Run()</code> private method and returns. The <code class="literal">Run()</code> method accepts a single argument named <code class="literal">port_num</code> specifying the number of protocol port on which the acceptor socket should listen for incoming connection requests. When invoked, the method first instantiates an object of the <code class="literal">Acceptor</code> class and then starts a loop in which the <code class="literal">Accept()</code> method of the <code class="literal">Acceptor</code> object is called. The loop terminates when the value of the <code class="literal">m_stop</code> atomic variable becomes <code class="literal">true</code>, which happens when the <code class="literal">Stop()</code> method is invoked on the corresponding instance of the <code class="literal">Server</code> class.</p><p>The <code class="literal">Stop()</code> method synchronously stops the server. It does not return until the loop started in the <code class="literal">Run()</code> method is interrupted and the thread spawned by the <code class="literal">Start()</code> method finishes its execution. To interrupt the loop, the value of the atomic variable <code class="literal">m_stop</code> is set to <code class="literal">true</code>. After this, the <code class="literal">Stop()</code> method calls the <code class="literal">join()</code> method on the <code class="literal">m_thread</code> object representing the thread running the loop in the <code class="literal">Run()</code> method to wait until it exits the loop and finishes its execution.</p><p>The presented <a id="id219" class="indexterm"/>implementation has a significant drawback consisting in the fact that the server may not be stopped immediately. More than that, there is a possibility that the server will not be stopped at all and the <code class="literal">Stop()</code> method will block its caller forever. The root cause of the problem is that the server has a hard dependency on the behavior of the clients.</p><p>If the <code class="literal">Stop()</code> method is called and the value of the atomic variable <code class="literal">m_stop</code> is set to <code class="literal">true</code> just before the loop termination condition in the <code class="literal">Run()</code> method is checked, the server is stopped almost immediately and no problem appears. However, if the <code class="literal">Stop()</code> method is called while the server's thread is blocked in the <code class="literal">acc.Accept()</code> method waiting for the next connection request from the client, or in one of the synchronous I/O operations inside the <code class="literal">Service</code> class waiting for the request message from the connected client, or for the client to receive the response message, the server cannot be stopped until these blocking operations are completed. Hence, for example, if at the moment, when the <code class="literal">Stop()</code> method is called, there are no pending connection requests, the server will not be stopped until a new client connects and gets handled, which in general case may never happen and will lead to the server being blocked forever.</p><p>Later, in this section, we will consider the possible ways to tackle this drawback.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec29"/>The main() entry point function</h3></div></div></div><p>This<a id="id220" class="indexterm"/> function demonstrates the usage of the server. It creates an instance of the <code class="literal">Server</code> class named <code class="literal">srv</code> and calls its <code class="literal">Start()</code> method to start the server. Because the server is represented as an active object running in its own thread of control, the <code class="literal">Start()</code> method returns immediately and the thread running method <code class="literal">main()</code> continues execution. To let the server run for some time, the main thread is put to sleep for 60 seconds. After the main thread wakes up, it calls the <code class="literal">Stop()</code> method on the <code class="literal">srv</code> object to stop the server. When the <code class="literal">Stop()</code> method returns, the <code class="literal">main()</code> function returns too and our sample application exits.</p><p>Of course, in the real application, the server would be stopped as a reaction to a user input or any other relevant event, rather than after dummy 60 seconds, after the server's start-up run out.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec30"/>Eliminating the drawbacks</h3></div></div></div><p>As it has<a id="id221" class="indexterm"/> already been mentioned, the presented implementation has two drawbacks that significantly limit its applicability. The first problem is that it may be impossible to stop the server if the <code class="literal">Stop()</code> method is called while the server thread is blocked waiting for the incoming connection request, no connection requests arrive. The second problem is that the server can be easily hung by a single malicious (or buggy) client, making it unavailable to other clients. To hang the <a id="id222" class="indexterm"/>server, the client application can simply connect to the server and never send any request to it, which will make the server application hang in the blocking input operation forever.</p><p>The root cause of both the issues is the usage of blocking operations in the server (which is natural for synchronous servers). A reasonable and simple solution to both these issues would be to assign a timeout to the blocking operations, which would guarantee that the server would unblock periodically to check whether the stop command has been issued and also to forcefully discard clients that do not send requests for a long period of time. However, Boost.Asio does not provide a way to cancel synchronous operations, or to assign timeouts to them. Therefore, we should try to find other ways to make our synchronous server more responsive and stable.</p><p>Let's consider ways to tackle each of the two drawbacks.</p><div><div><div><div><h4 class="title"><a id="ch04lvl4sec01"/>Stopping a server in reasonable amount of time</h4></div></div></div><p>As the only<a id="id223" class="indexterm"/> legitimate way to make the <code class="literal">accept()</code>synchronous method of an acceptor socket unblock when there are no pending connection requests is to send a dummy connection request to the port on which the acceptor is listening, we can do the following trick to solve our problem.</p><p>In the <code class="literal">Server</code> class's <code class="literal">Stop()</code> method, after setting the value of the <code class="literal">m_stop</code> atomic variable to <code class="literal">true</code>, we can create a dummy active socket, connect it to this same server, and send some dummy request. This will guarantee that the server thread will leave the <code class="literal">accept()</code> method of the acceptor socket and will eventually check the value of the <code class="literal">m_stop</code> atomic variable to find out that its value is equal to <code class="literal">true</code>, which will lead to termination of the loop and completion of the<code class="literal"> Acceptor::Accept()</code> method.</p><p>In the described method, it is assumed that the server stops itself by sending a message to itself (actually a message is sent from an I/O thread to the worker thread). Another approach would be to have a special client (separate application) that would connect and send a special service message (for example, <code class="literal">stop\n</code>) to the server, which will be interpreted by the server as a signal to stop. In this case, the server would be controlled externally (from a different application) and the <code class="literal">Server</code> class would not need to have the <code class="literal">Stop()</code> method.</p></div><div><div><div><div><h4 class="title"><a id="ch04lvl4sec02"/>Dealing with the server's vulnerability</h4></div></div></div><p>Unfortunately, the<a id="id224" class="indexterm"/> nature of blocking the I/O operation without the timeout assigned to it is such that it can be used to easily hang the iterative server that uses such operations and make it inaccessible to other clients.</p><p>Obviously, to <a id="id225" class="indexterm"/>protect the server from this vulnerability, we need to redesign it so that it never gets blocked by I/O operations. One way to achieve this is to use nonblocking sockets (which will turn our server into reactive) or use asynchronous I/O operations. Both the options mean that our server stops being synchronous. We will consider some of these solutions in other recipes of this chapter.</p></div></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec31"/>Analyzing the results</h3></div></div></div><p>Vulnerabilities <a id="id226" class="indexterm"/>that are inherent in the synchronous iterative servers implemented with Boost.Asio described above do not allow using them in public networks, where there is a risk of misuse of the server by a culprit. Usually, synchronous servers would be used in closed and protected environments where clients are carefully designed so that they do not hang the server.</p><p>Another limitation of the iterative synchronous server is that they are not scalable and cannot take advantage of a multiprocessor hardware. However, their advantage—simplicity—is the reason why this type of a server is a good choice in many cases.</p></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec87"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes providing detailed discussions on how to perform synchronous I/O.</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec32"/>Implementing a synchronous parallel TCP server</h1></div></div></div><p>A <a id="id227" class="indexterm"/>synchronous parallel TCP server is a part of a distributed application that satisfies the following criteria:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Acts as a server in the client-server communication model</li><li class="listitem" style="list-style-type: disc">Communicates with client applications over TCP protocol</li><li class="listitem" style="list-style-type: disc">Uses I/O and control operations that block the thread of execution until the corresponding operation completes, or an error occurs</li><li class="listitem" style="list-style-type: disc">May handle more than one client simultaneously</li></ul></div><p>A typical synchronous parallel TCP server works according to the following algorithm:</p><div><ol class="orderedlist arabic"><li class="listitem">Allocate an acceptor socket and bind it to a particular TCP port.</li><li class="listitem">Run a loop until the server is stopped:<div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Wait for the incoming connection request from a client</li><li class="listitem" style="list-style-type: disc">Accept the client's connection request</li><li class="listitem" style="list-style-type: disc">Spawn a thread of control and in the context of this thread:<div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Wait for the request message from the client</li><li class="listitem" style="list-style-type: disc">Read the request message</li><li class="listitem" style="list-style-type: disc">Process the request</li><li class="listitem" style="list-style-type: disc">Send a response message to the client</li><li class="listitem" style="list-style-type: disc">Close the connection with the client and deallocate the socket</li></ul></div></li></ul></div></li></ol></div><p>This recipe <a id="id228" class="indexterm"/>demonstrates how to implement a synchronous parallel TCP server application with Boost.Asio.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec88"/>How to do it…</h2></div></div></div><p>We begin implementing our server application by defining the class responsible for handling a single client by reading the request message, processing it, and then sending back the response message. This class represents a single service provided by the server application and, therefore, we will name it <code class="literal">Service</code>:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;

#include &lt;thread&gt;
#include &lt;atomic&gt;
#include &lt;memory&gt;
#include &lt;iostream&gt;

using namespace boost;

class Service {
public:
   Service(){}

   void StartHandligClient(
         std::shared_ptr&lt;asio::ip::tcp::socket&gt; sock) {


      std::thread th(([this, sock]() {
         HandleClient(sock);
      }));

      th.detach();
   }

private: 
void HandleClient(std::shared_ptr&lt;asio::ip::tcp::socket&gt; sock) {
      try {
         asio::streambuf request;
         asio::read_until(*sock.get(), request, '\n');

         // Emulate request processing.
         int i = 0;
         while (i != 1000000)
            i++;

            std::this_thread::sleep_for(
std::chrono::milliseconds(500));

         // Sending response.
         std::string response = "Response\n";
         asio::write(*sock.get(), asio::buffer(response));
      } 
      catch (system::system_error &amp;e) {
         std::cout    &lt;&lt; "Error occured! Error code = " 
&lt;&lt; e.code() &lt;&lt; ". Message: "
               &lt;&lt; e.what();
      }

      // Clean-up.
      delete this;
   }
};</pre></div><p>To keep things <a id="id229" class="indexterm"/>simple, in our sample server application, we implement a dummy service, which only emulates the execution of certain operations. The request processing emulation consists of performing many increment operations to emulate operations that intensively consume CPU and then putting the thread of control to sleep for some time to emulate I/O operations such as reading a file or communicating with a peripheral device synchronously.</p><div><div><h3 class="title"><a id="note12"/>Note</h3><p>The <code class="literal">Service</code> class is quite simple and contains only one method. However, classes representing services in real-world applications would usually be more complex and richer in functionality, though the main idea would stay the same.</p></div></div><p>Next, we define another class that represents a high-level <em>acceptor</em> concept (as compared to the low-level concept represented by the <code class="literal">asio::ip::tcp::acceptor</code> class). This class is responsible <a id="id230" class="indexterm"/>for accepting the connection requests arriving from clients and instantiating the objects of the <code class="literal">Service</code> class, which will provide the service to connected clients. Let's name it <code class="literal">Acceptor</code>:</p><div><pre class="programlisting">class Acceptor {
public:
   Acceptor(asio::io_service&amp; ios, unsigned short port_num) :
      m_ios(ios),
      m_acceptor(m_ios,
          asio::ip::tcp::endpoint(
asio::ip::address_v4::any(), 
port_num))
   {
      m_acceptor.listen();
   }

   void Accept() {
      std::shared_ptr&lt;asio::ip::tcp::socket&gt; 
sock(new asio::ip::tcp::socket(m_ios));

      m_acceptor.accept(*sock.get());

      (new Service)-&gt;StartHandligClient(sock);
   }

private:
   asio::io_service&amp; m_ios;
   asio::ip::tcp::acceptor m_acceptor;
};</pre></div><p>This class owns an object of the <code class="literal">asio::ip::tcp::acceptor</code> class named <code class="literal">m_acceptor</code>, which is used to synchronously accept incoming connection requests.</p><p>Also, we define a class that represents the server itself. The class is named correspondingly—<code class="literal">Server</code>:</p><div><pre class="programlisting">class Server {
public:
  Server() : m_stop(false) {}

  void Start(unsigned short port_num) {
    m_thread.reset(new std::thread([this, port_num]() {
      Run(port_num);
    }));
  }

  void Stop() {
    m_stop.store(true);
    m_thread-&gt;join();
  }

private:
  void Run(unsigned short port_num) {
    Acceptor acc(m_ios, port_num);

    while (!m_stop.load()) {
      acc.Accept();
    }
  }

  std::unique_ptr&lt;std::thread&gt;m_thread;
  std::atomic&lt;bool&gt;m_stop;
  asio::io_servicem_ios;
};</pre></div><p>This class <a id="id231" class="indexterm"/>provides an interface comprised of two methods—<code class="literal">Start()</code> and <code class="literal">Stop()</code> that are used to start and stop the server correspondingly. The loop runs in a separate thread spawned by the <code class="literal">Start()</code> method. The <code class="literal">Start()</code> method is nonblocking, while the <code class="literal">Stop()</code> method is. It blocks the caller thread until the server is stopped.</p><p>Thorough inspection of the <code class="literal">Server</code> class reveals one serious drawback of the implementation of the server—the <code class="literal">Stop()</code> method may block forever. The discussion of this problem and ways to resolve it is provided below.</p><p>Eventually, we implement the application entry point function <code class="literal">main()</code> that demonstrates how to use the <code class="literal">Server</code> class:</p><div><pre class="programlisting">int main()
{
   unsigned short port_num = 3333;

   try {
      Server srv;
      srv.Start(port_num);

      std::this_thread::sleep_for(std::chrono::seconds(60));

      srv.Stop();
   }
   catch (system::system_error &amp;e) {
      std::cout    &lt;&lt; "Error occured! Error code = " 
&lt;&lt; e.code() &lt;&lt; ". Message: "
            &lt;&lt; e.what();
   }

   return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec89"/>How it works…</h2></div></div></div><p>The sample <a id="id232" class="indexterm"/>server application consists of four components—the <code class="literal">Server</code>, <code class="literal">Acceptor</code>, and <code class="literal">Service</code> classes and the application entry point function <code class="literal">main()</code>. Let's consider how each of these components work.</p><div><div><div><div><h3 class="title"><a id="ch04lvl3sec32"/>The Service class</h3></div></div></div><p>The <a id="id233" class="indexterm"/>
<code class="literal">Service</code> class is the key functional component in the whole application. While other components constitute the infrastructure of the server, this class implements the actual function (or service) provided by the server to the clients.</p><p>This class has a single method in its interface called <code class="literal">StartHandlingClient()</code>. This method accepts a pointer to an object representing a TCP socket connected to the client as its input argument and starts handling that particular client.</p><p>This method spawns a thread of control, which starts its execution from the class's <code class="literal">HandleClient()</code> private method, where the actual synchronous handling is performed. Having spawned the thread, the <code class="literal">StartHandlingClient()</code> method "lets it go" by detaching the thread from the <code class="literal">std::thread</code> object representing it. After this, the <code class="literal">StartHandlingClient()</code> method returns.</p><p>The <code class="literal">HandleClient()</code> private method, as its name suggests, handles the client. In our sample, such handling is trivial. Firstly, the request message is synchronously read from the socket until a new line ASCII symbol <code class="literal">\n</code> is encountered. Then, the request is processed. In our case, we emulate processing by running a dummy loop performing one million increment operations and then putting the thread to sleep for half a second. After this, the response message is prepared and sent back to the client.</p><p>When the response message is sent, the object of the <code class="literal">Service</code> class associated with the <code class="literal">HandleClient()</code> method, which is currently running, is deleted by the <code class="literal">delete</code> operator. Of course, the design of the class assumes that its instances will be allocated in free memory by a <code class="literal">new</code> operator rather than on the stack.</p><p>Depending <a id="id234" class="indexterm"/>on the needs of a particular application, the <code class="literal">Service</code> class can be extended and enriched with the functionality to provide the needed service.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec33"/>The Acceptor class</h3></div></div></div><p>The<a id="id235" class="indexterm"/> <code class="literal">Acceptor</code> class is a part of the server application infrastructure. When constructed, it instantiates an acceptor socket object <code class="literal">m_acceptor</code> and calls its <code class="literal">listen()</code> method to start listening for connection requests from clients.</p><p>This class exposes a single <code class="literal">Accept()</code> public method. This method when called, instantiates an object of the <code class="literal">asio::ip::tcp::socket</code> class named <code class="literal">sock</code>, representing an active socket, and tries to accept a connection request. If there are pending connection requests available, the connection request is processed and the active socket <code class="literal">sock</code> is connected to the new client. Otherwise, this method blocks until a new connection request arrives.</p><p>Then, an instance of the <code class="literal">Service</code> object is allocated in free memory and its <code class="literal">StartHandlingClient()</code> method is called. The <code class="literal">sock</code> object is passed to this method as an input argument. The <code class="literal">StartHandlingClient()</code> method spawns a thread in the context of which the client will be handled and returns immediately. When the <code class="literal">StartHandlingClient()</code> method returns, the <code class="literal">Accept()</code> method of the <code class="literal">Acceptor</code> class returns too. Now, <em>the acceptor</em> is ready to accept the next connection request.</p><p>Note that <code class="literal">Acceptor</code> does not take the ownership of the object of the <code class="literal">Service</code> class. Instead, the object of the <code class="literal">Service</code> class will destroy itself when it completes its job.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec34"/>The Server class</h3></div></div></div><p>The <a id="id236" class="indexterm"/>
<code class="literal">Server</code> class, as its name suggests, represents a <em>server</em> that can be controlled through the class's interface <code class="literal">Start()</code>and <code class="literal">Stop()</code> methods.</p><p>The <code class="literal">Start()</code> method<a id="id237" class="indexterm"/> initiates the start-up of the server. It spawns a new thread that begins its execution from the <code class="literal">Server</code> class's <code class="literal">Run()</code> private method and returns. The <code class="literal">Run()</code> method accepts a single argument <code class="literal">port_num</code> specifying the number of the protocol port on which the acceptor socket should listen for incoming connection requests. When invoked, the method first instantiates an object of the <code class="literal">Acceptor</code> class and then starts a loop in which the <code class="literal">Accept()</code> method of the <code class="literal">Acceptor</code> object is called. The loop terminates when the value of the <code class="literal">m_stop</code> atomic variable becomes <code class="literal">true</code>, which happens when the <code class="literal">Stop()</code> method is invoked on the corresponding instance of the <code class="literal">Server</code> class.</p><p>The <code class="literal">Stop()</code> method<a id="id238" class="indexterm"/> synchronously stops the server. It does not return until a loop that started in the <code class="literal">Run()</code> method is interrupted and the thread that is spawned by the <code class="literal">Start()</code> method finishes its execution. To interrupt the loop, the value of the atomic variable <code class="literal">m_stop</code> is set to <code class="literal">true</code>. After this, the <code class="literal">Stop()</code> method calls the <code class="literal">join()</code> method on the <code class="literal">m_thread</code> object representing the thread running the loop in the <code class="literal">Run()</code> method in order to wait until it finishes its execution.</p><p>The presented implementation has a significant drawback consisting of the fact that the server may not be stopped immediately. More than that, there is a possibility that the server will not be stopped at all and the <code class="literal">Stop()</code> method will block its caller forever. The root cause of the problem is that the server has a hard dependency on the behavior of the clients.</p><p>If the <code class="literal">Stop()</code> method is called and sets the value of atomic variable <code class="literal">m_stop</code> variable to <code class="literal">true</code> just before the loop termination condition in the <code class="literal">Run()</code> method is checked, the server is stopped almost immediately and no problem occurs. However, if the <code class="literal">Stop()</code> method is called while the server's thread is blocked in the <code class="literal">acc.Accept()</code> method waiting for the next connection request from the client—or in one of synchronous I/O operations inside the <code class="literal">Service</code> class is waiting for the request message from the connected client or for the client to receive the response message—the server cannot be stopped until these blocking operations complete. Hence, for example, if at the moment when the <code class="literal">Stop()</code> method is called, there are no pending connection requests, the server will not be stopped until a new client connects and gets handled, which in general case may never happen and may lead to the server being blocked forever.</p><p>Later, in this section, we will consider possible ways to tackle this drawback.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec35"/>The main() entry point function</h3></div></div></div><p>This <a id="id239" class="indexterm"/>function demonstrates the usage of the server. It creates an instance of the <code class="literal">Server</code> class named <code class="literal">srv</code> and calls its method <code class="literal">Start()</code> to start the server. Because the server is represented as an active object running in its own thread of control, the <code class="literal">Start()</code> method returns immediately and the thread running the <code class="literal">main()</code>method continues the execution. To allow the server to run for some time, the main thread is put to sleep for 60 seconds. After the main thread wakes up, it calls the <code class="literal">Stop()</code> method on the <code class="literal">srv</code> object to stop the server. When the <code class="literal">Stop()</code> method returns, the <code class="literal">main()</code> function returns too and our sample application exits.</p><p>Of course, in the real application, the server would be stopped as a reaction to the user input or any other<a id="id240" class="indexterm"/> relevant event, rather than after the dummy 60 seconds after the server's start-up run out.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec36"/>Eliminating the drawbacks</h3></div></div></div><p>The drawbacks inherent in synchronous parallel server application implemented with Boost.Asio library are similar to those of synchronous iterative server application considered in previous recipe. Please refer to the <em>Implementing synchronous iterative TCP server</em> recipe for the discussion of the drawbacks and the ways to eliminate them.</p></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec90"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Recipe <em>Implementing synchronous iterative TCP server</em> provides more details on the drawbacks inherent in both synchronous iterative and synchronous parallel servers and the possible ways to eliminate them</li><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes providing detailed discussions on how to perform synchronous I/O</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec33"/>Implementing an asynchronous TCP server</h1></div></div></div><p>An <a id="id241" class="indexterm"/>asynchronous TCP server<a id="id242" class="indexterm"/> is a part of a distributed application that satisfies the following criteria:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Acts as a server in the client-server communication model</li><li class="listitem" style="list-style-type: disc">Communicates with client applications over TCP protocol</li><li class="listitem" style="list-style-type: disc">Uses the asynchronous I/O and control operations</li><li class="listitem" style="list-style-type: disc">May handle multiple clients simultaneously</li></ul></div><p>A typical asynchronous TCP server<a id="id243" class="indexterm"/> works according to the following algorithm:</p><div><ol class="orderedlist arabic"><li class="listitem">Allocate an acceptor socket and bind it to a particular TCP port.</li><li class="listitem">Initiate the asynchronous accept operation.</li><li class="listitem">Spawn one or more threads of control and add them to the pool of threads that run the Boost.Asio event loop.</li><li class="listitem">When the asynchronous accept operation completes, initiate a new one to accept the next connection request.</li><li class="listitem">Initiate the asynchronous reading operation to read the request from the connected client.</li><li class="listitem">When the asynchronous reading operation completes, process the request and prepare the response message.</li><li class="listitem">Initiate the asynchronous writing operation to send the response message to the client.</li><li class="listitem">When the asynchronous writing operation completes, close the connection and deallocate the socket.</li></ol></div><p>Note that the steps starting from the fourth step in the preceding algorithm may be performed in arbitrary order depending on the relative timing of the concrete asynchronous operations in a concrete application. Due to the asynchronous model of the server, sequential order of execution of the steps may not hold even when the server is running on a single-processor computer.</p><p>This recipe demonstrates how to implement an asynchronous TCP server application with Boost.Asio.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec91"/>How to do it…</h2></div></div></div><p>We begin implementing our server application by defining a class responsible for handling a single client by reading the request message, processing it, and then sending back the response message. This class represents a single service provided by the server application. Let's name it <code class="literal">Service</code>:</p><div><pre class="programlisting">#include &lt;boost/asio.hpp&gt;

#include &lt;thread&gt;
#include &lt;atomic&gt;
#include &lt;memory&gt;
#include &lt;iostream&gt;

using namespace boost;

class Service {
public:
   Service(std::shared_ptr&lt;asio::ip::tcp::socket&gt; sock) :
      m_sock(sock)
   {}

   void StartHandling() {

      asio::async_read_until(*m_sock.get(), 
            m_request, 
            '\n', 
            [this](
                        const boost::system::error_code&amp; ec,
                        std::size_t bytes_transferred) 
                        {                  
                              onRequestReceived(ec,
                               bytes_transferred);
               });
   }

private:
   void onRequestReceived(const boost::system::error_code&amp; ec,
                std::size_t bytes_transferred) {
      if (ec != 0) {
         std::cout &lt;&lt; "Error occured! Error code = "
            &lt;&lt; ec.value()
            &lt;&lt; ". Message: " &lt;&lt; ec.message();

         onFinish();
                return;
      }
      
// Process the request.
      m_response = ProcessRequest(m_request);

      // Initiate asynchronous write operation.
      asio::async_write(*m_sock.get(), 
            asio::buffer(m_response),
            [this](
                            const boost::system::error_code&amp; ec,
                            std::size_t bytes_transferred) 
                            {
                  onResponseSent(ec,
                                  bytes_transferred);
               });
   }

   void onResponseSent(const boost::system::error_code&amp; ec,
                      std::size_t bytes_transferred) {
      if (ec != 0) {
         std::cout &lt;&lt; "Error occured! Error code = "
            &lt;&lt; ec.value()
            &lt;&lt; ". Message: " &lt;&lt; ec.message();
      }

      onFinish();
   }

   // Here we perform the cleanup.
   void onFinish() {
      delete this;
   }

   std::string ProcessRequest(asio::streambuf&amp; request) {

      // In this method we parse the request, process it
      // and prepare the request.

      // Emulate CPU-consuming operations.
      int i = 0;
      while (i != 1000000)
         i++;

      // Emulate operations that block the thread
// (e.g. synch I/O operations).
         std::this_thread::sleep_for(
                      std::chrono::milliseconds(100));

      // Prepare and return the response message. 
      std::string response = "Response\n";
      return response;
   }

private:
   std::shared_ptr&lt;asio::ip::tcp::socket&gt; m_sock;
   std::string m_response;
   asio::streambuf m_request;
};</pre></div><p>To keep things <a id="id244" class="indexterm"/>simple, in our sample server application, we implement a dummy service which only emulates the execution of certain operations. The request processing emulation consists of performing many increment operations to emulate operations that intensively consume CPU and then putting the thread of control to sleep for some time to emulate I/O operations such as reading a file or communicating with a peripheral device synchronously.</p><p>Each instance of the <code class="literal">Service</code> class is intended to handle one connected client by reading the request message, processing it, and then sending the response message back.</p><p>Next, we define another class, which represents a high-level <em>acceptor</em> concept (as compared to the low-level concept represented by the <code class="literal">asio::ip::tcp::acceptor</code> class). This class is responsible for accepting the connection requests arriving from clients and instantiating the objects of the <code class="literal">Service</code> class, which will provide the service to connected clients. Let's name it <code class="literal">Acceptor</code>:</p><div><pre class="programlisting">class Acceptor {
public:
  Acceptor(asio::io_service&amp;ios, unsigned short port_num) :
    m_ios(ios),
    m_acceptor(m_ios,
      asio::ip::tcp::endpoint(
                  asio::ip::address_v4::any(), 
                  port_num)),
    m_isStopped(false)
  {}

  // Start accepting incoming connection requests.
  void Start() {
    m_acceptor.listen();
    InitAccept();
  }
  
  // Stop accepting incoming connection requests.
  void Stop() {
    m_isStopped.store(true);
  }

private:
  void InitAccept() {
    std::shared_ptr&lt;asio::ip::tcp::socket&gt;
              sock(new asio::ip::tcp::socket(m_ios));

    m_acceptor.async_accept(*sock.get(),
      [this, sock](
                   const boost::system::error_code&amp; error) 
           {
        onAccept(error, sock);
      });
  }

  void onAccept(const boost::system::error_code&amp;ec,
               std::shared_ptr&lt;asio::ip::tcp::socket&gt; sock) 
  {
    if (ec == 0) {
      (new Service(sock))-&gt;StartHandling();
    }
    else {
      std::cout&lt;&lt; "Error occured! Error code = "
        &lt;&lt;ec.value()
        &lt;&lt; ". Message: " &lt;&lt;ec.message();
    }

    // Init next async accept operation if
    // acceptor has not been stopped yet.
    if (!m_isStopped.load()) {
      InitAccept();
    }
    else {
      // Stop accepting incoming connections
      // and free allocated resources.
      m_acceptor.close();
    }
  }

private:
  asio::io_service&amp;m_ios;
  asio::ip::tcp::acceptor m_acceptor;
  std::atomic&lt;bool&gt;m_isStopped;
}; </pre></div><p>This class owns <a id="id245" class="indexterm"/>an object of the <code class="literal">asio::ip::tcp::acceptor</code> class named <code class="literal">m_acceptor</code>, which is used to asynchronously accept the incoming connection requests.</p><p>Also, we define a class that represents the server itself. The class is named correspondingly—<code class="literal">Server</code>:</p><div><pre class="programlisting">class Server {
public:
   Server() {
      m_work.reset(new asio::io_service::work(m_ios));
   }

   // Start the server.
   void Start(unsigned short port_num, 
unsigned int thread_pool_size) {
      
      assert(thread_pool_size &gt; 0);

      // Create and start Acceptor.
      acc.reset(new Acceptor(m_ios, port_num));
      acc-&gt;Start();

      // Create specified number of threads and 
      // add them to the pool.
      for (unsigned int i = 0; i &lt; thread_pool_size; i++) {
         std::unique_ptr&lt;std::thread&gt; th(
                   new std::thread([this]()
                   {
                          m_ios.run();
                   }));

         m_thread_pool.push_back(std::move(th));
      }
   }

   // Stop the server.
   void Stop() {
      acc-&gt;Stop();
      m_ios.stop();

      for (auto&amp; th : m_thread_pool) {
         th-&gt;join();
      }
   }

private:
   asio::io_servicem_ios;
   std::unique_ptr&lt;asio::io_service::work&gt;m_work;
   std::unique_ptr&lt;Acceptor&gt;acc;
   std::vector&lt;std::unique_ptr&lt;std::thread&gt;&gt;m_thread_pool;
};</pre></div><p>This class provides<a id="id246" class="indexterm"/> an interface consisting of two methods—<code class="literal">Start()</code> and <code class="literal">Stop()</code>. The <code class="literal">Start()</code> method accepts a protocol port number on which the server should listen for the incoming connection requests and the number of threads to add to the pool as input arguments and starts the server. The <code class="literal">Stop()</code> method stops the server. The <code class="literal">Start()</code> method is nonblocking, while the <code class="literal">Stop()</code> method is. It blocks the caller thread until the server is stopped and all the threads running the event loop exit.</p><p>Eventually, we implement the application entry point function <code class="literal">main()</code> that demonstrates how to use an object of the <code class="literal">Server</code> class:</p><div><pre class="programlisting">const unsigned intDEFAULT_THREAD_POOL_SIZE = 2;

int main()
{
  unsigned short port_num = 3333;

  try {
    Server srv;

    unsigned intthread_pool_size =
      std::thread::hardware_concurrency() * 2;
    
      if (thread_pool_size == 0)
      thread_pool_size = DEFAULT_THREAD_POOL_SIZE;

    srv.Start(port_num, thread_pool_size);

    std::this_thread::sleep_for(std::chrono::seconds(60));

    srv.Stop();
  }
  catch (system::system_error&amp;e) {
    std::cout  &lt;&lt; "Error occured! Error code = " 
               &lt;&lt;e.code() &lt;&lt; ". Message: "
               &lt;&lt;e.what();
  }

  return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec92"/>How it works…</h2></div></div></div><p>The sample server application<a id="id247" class="indexterm"/> consists of four components—the <code class="literal">Service</code>, <code class="literal">Acceptor</code>, and <code class="literal">Service</code> classes and an application entry point function <code class="literal">main()</code>. Let's consider how each of these components work.</p><div><div><div><div><h3 class="title"><a id="ch04lvl3sec37"/>The Service class</h3></div></div></div><p>The <a id="id248" class="indexterm"/>
<code class="literal">Service</code> class is the key functional component in the application. While other components constitute an infrastructure of the server, this class implements the actual function (or service) provided by the server to the clients.</p><p>One instance of this class is intended to handle a single connected client by reading the request, processing it, and then sending back the response message.</p><p>The class's constructor accepts a shared pointer to an object representing a socket connected to a particular client as an argument and caches this pointer. This socket will be used later to communicate with the client application.</p><p>The public interface of the <code class="literal">Service</code> class consists of a single method <code class="literal">StartHandling()</code>. This method starts handling the client by initiating the asynchronous reading operation to read the request message from the client specifying the <code class="literal">onRequestReceived()</code> method as a callback. Having initiated the asynchronous reading operation, the <code class="literal">StartHandling()</code> method returns.</p><p>When the request reading completes, or an error occurs, the callback method <code class="literal">onRequestReceived()</code> is called. This method first checks whether the reading succeeded by testing the <code class="literal">ec</code> argument that contains the operation completion status code. In case the reading finished with an error, the corresponding message is output to the standard output stream and then the <code class="literal">onFinish()</code> method is called. After this, the <code class="literal">onRequestReceieved()</code> method returns, which leads to client-handling process interruption.</p><p>If the request message has been read successfully, the <code class="literal">ProcessRequest()</code> method is called to perform the requested operations and prepare the response message. When the <code class="literal">ProcessRequest()</code> method completes and returns the string containing the response message, the asynchronous writing operation is initiated to send this response message back to the client. The <code class="literal">onResponseSent()</code> method is specified as a callback.</p><p>When the writing operation completes (or an error occurs), the <code class="literal">onResponseSent()</code>method is called. This method first checks whether the operation succeeded. If the operation failed, the corresponding message is output to the standard output stream. Next, the <code class="literal">onFinish()</code>method is called to perform the cleanup. When the <code class="literal">onFinish()</code>method returns, the full cycle of client handling is considered completed.</p><p>The <code class="literal">ProcessRequest()</code> method <a id="id249" class="indexterm"/>is the heart of the class because it implements the service. In our server application, we have a dummy service that runs a dummy loop performing one million increment operations and then puts the thread to sleep for 100 milliseconds. After this, the dummy response message is generated and returned to the caller.</p><p>Depending on the needs of a particular application, the <code class="literal">Service</code> class and particularly its <code class="literal">ProcessRequest()</code> method can be extended and enriched with a functionality to provide the needed service.</p><p>The <code class="literal">Service</code> class is designed so that its objects delete themselves when their job is completed. Deletion is performed in the class's <code class="literal">onFinish()</code> private method, which is called in the end of the client handling cycle whether it is successful or erroneous:</p><div><pre class="programlisting">void onFinish() {
  delete this;
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec38"/>The Acceptor class</h3></div></div></div><p>The <a id="id250" class="indexterm"/>
<code class="literal">Acceptor</code> class is a part of the server application's infrastructure. Its constructor accepts a port number on which it will listen for the incoming connection requests as its input argument. The object of this class contains an instance of the <code class="literal">asio::ip::tcp::acceptor</code> class as its member named <code class="literal">m_acceptor</code>, which is constructed in the <code class="literal">Acceptor</code> class's constructor.</p><p>The <code class="literal">Acceptor</code> class exposes two public methods—<code class="literal">Start()</code> and <code class="literal">Stop()</code>. The <code class="literal">Start()</code> method is intended to instruct an object of the <code class="literal">Acceptor</code> class to start listening and accepting incoming connection requests. It puts the <code class="literal">m_acceptor</code> acceptor socket into listening mode and then calls the class's <code class="literal">InitAccept()</code> private method. The <code class="literal">InitAccept()</code> method, in turn, constructs an active socket object and initiates the asynchronous accept operation, calling the <code class="literal">async_accept()</code> method on the acceptor socket object and passing the object representing an active socket to it as an argument. The <code class="literal">onAccept()</code> method of the <code class="literal">Acceptor</code> class is specified as a callback.</p><p>When the connection request is accepted or an error occurs, the callback method <code class="literal">onAccept()</code> is called. This method first checks whether any error occurred while the asynchronous operation was executed by checking the value of its input argument <code class="literal">ec</code>. If the operation completed successfully, an instance of the <code class="literal">Service</code> class is created and its <code class="literal">StartHandling()</code> method is called, which starts handling the connected client. Otherwise, in case of error, the corresponding message is output to the standard output stream.</p><p>Next, the <a id="id251" class="indexterm"/>value of the <code class="literal">m_isStopped</code> atomic variable is checked to see whether the stop command has been issued on the <code class="literal">Acceptor</code> object. If it has (which means that the <code class="literal">Stop()</code> method has been called on the <code class="literal">Acceptor</code> object), a new asynchronous accept operation is not initiated and the low-level acceptor object is closed. At this point, <code class="literal">Acceptor</code> stops listening and accepting incoming connection requests from clients. Otherwise, the <code class="literal">InitAccept()</code> method is called to initiate a new asynchronous accept operation to accept the next incoming connection request.</p><p>As it has already been mentioned, the <code class="literal">Stop()</code> method instructs the <code class="literal">Acceptor</code> object not to initiate the next asynchronous accept operation when the currently running one completes. However, the currently running accept operation is not canceled by this method.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec39"/>The Server class</h3></div></div></div><p>The <code class="literal">Server</code> class, as its name suggests, represents a <em>server</em> itself. The class's public interface consists of <a id="id252" class="indexterm"/>two methods: <code class="literal">Start()</code> and <code class="literal">Stop()</code>.</p><p>The <code class="literal">Start()</code> method starts the server up. It accepts two arguments. The first argument named <code class="literal">port_num</code> specifies the number of the protocol port on which the server should listen for incoming connections. The second argument named <code class="literal">thread_pool_size </code>specifies the number of threads to add to the pool of threads running the even loop and deliver asynchronous operation completion events. This argument is very important and should be chosen with care as it directly influences the performance of the server.</p><p>The <code class="literal">Start()</code> method begins by instantiating an object of the <code class="literal">Acceptor</code> class that will be used to accept incoming connections and then starting it up by calling its <code class="literal">Start()</code> method. After this, it spawns a set of worker threads, each of which is added to the pool, by calling the <code class="literal">run()</code> method of the <code class="literal">asio::io_service</code> object. Besides, all the <code class="literal">std::thread</code> objects are cached in the <code class="literal">m_thread_pool</code> member vector so that the corresponding threads can be joined later when the server is stopped.</p><p>The <code class="literal">Stop()</code>method first stops the <code class="literal">Acceptor</code> object <code class="literal">acc</code>, calling its <code class="literal">Stop()</code>method. Then, it calls the <code class="literal">stop()</code> method on the <code class="literal">asio::io_service</code> object <code class="literal">m_ios</code>, which makes all the threads that previously called <code class="literal">m_ios.run()</code> to join the pool to exit as soon as possible, discarding all pending asynchronous operations. After this, the <code class="literal">Stop()</code> method waits for all threads in the pool to exit by iterating through all the <code class="literal">std::thread</code> objects cached in the <code class="literal">m_thread_pool</code> vector and joining each of them.</p><p>When all threads exit, the <code class="literal">Stop()</code> method returns.</p></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec40"/>The main() entry point function</h3></div></div></div><p>This <a id="id253" class="indexterm"/>function demonstrates the usage of the server. Firstly, it instantiates an object of the <code class="literal">Server</code> class named <code class="literal">srv</code>. Because the <code class="literal">Start()</code> method of the <code class="literal">Server</code> class requires a number of threads constituting a pool to be passed to it, before starting the server, the optimal size of the pool is calculated. The general formula often used in parallel applications to find the optimal number of threads is the number of processors the computer has multiplied by 2. We use the <code class="literal">std::thread::hardware_concurrency()</code> static method to obtain the number of processors. However, because this method may fail to do its job returning 0, we fall back to default value represented by the constant <code class="literal">DEFAULT_THREAD_POOL_SIZE</code>, which is equal to 2 in our case.</p><p>When the thread pool size is calculated, the <code class="literal">Start()</code> method is called to start the server. The <code class="literal">Start()</code> method does not block. When it returns, the thread running the <code class="literal">main()</code> method continues the execution. To allow the server to run for some time, the main thread is put to sleep for 60 seconds. When the main thread wakes up, it calls the <code class="literal">Stop()</code> method on the <code class="literal">srv</code> object to stop the server. When the <code class="literal">Stop()</code> method returns, the <code class="literal">main()</code> function returns too and our application exits.</p><p>Of course, in the real application, the server would be stopped as a reaction to some relevant event such as the user input, rather than when some dummy period of time elapses.</p></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec93"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="link" href="ch02.html" title="Chapter 2. I/O Operations">Chapter 2</a>, <em>I/O Operations</em>, includes recipes providing detailed discussions on how to perform synchronous I/O.</li><li class="listitem" style="list-style-type: disc">The <em>Using timers</em> recipe from <a class="link" href="ch06.html" title="Chapter 6. Other Topics">Chapter 6</a>, <em>Other Topics</em>, demonstrates how to use timers provided by Boost.Asio. Timers can be used to implement an asynchronous operation timeout mechanism.</li></ul></div></div></div></body></html>