# 第十章：并发和多线程

并发编程可以创建更高效的程序。很长一段时间以来，C++没有内置对并发或多线程的支持。现在它完全支持并发编程、线程、线程同步对象以及本章将讨论的其他功能。

在语言更新以支持线程之前，程序员必须使用第三方库。最流行的多线程解决方案之一是**POSIX**（**可移植操作系统接口**）线程。自 C++11 以来，C++引入了线程支持。这使得语言更加健壮，并适用于更广泛的软件开发领域。对于 C++程序员来说，理解线程有些关键，因为他们倾向于尽可能地压榨程序的每一点，使其运行得更快。线程向我们介绍了一种完全不同的方式，通过并发运行函数来加速程序。在基本水平上学习多线程对于每个 C++程序员来说都是必不可少的。有很多程序在其中无法避免使用多线程，例如网络应用程序、游戏和 GUI 应用程序。本章将向您介绍 C++中的并发和多线程基础知识以及并发代码设计的最佳实践。

本章将涵盖以下主题：

+   理解并发和多线程

+   使用线程

+   管理线程和共享数据

+   设计并发代码

+   使用线程池避免线程创建开销

+   熟悉 C++20 中的协程

# 技术要求

本章中使用`-std=c++2a`选项的 g++编译器来编译示例。您可以在[`github.com/PacktPublishing/Expert-CPP`](https://github.com/PacktPublishing/Expert-CPP)找到本章中使用的源文件。

# 理解并发和多线程

运行程序的最简单形式涉及其指令由**CPU**（**中央处理单元**）逐个执行。正如您已经从之前的章节中了解到的，程序由几个部分组成，其中一个部分包含程序的指令。每个指令都加载到 CPU 寄存器中，以便 CPU 解码和执行。实际上，无论您使用何种编程范式来生成应用程序，结果始终是一样的——可执行文件包含机器代码。

我们提到，诸如 Java 和 C#之类的编程语言使用支持环境。然而，如果在中间删减支持环境（通常是虚拟机），那么最终执行的指令应该具有特定 CPU 熟悉的形式和格式。程序员明显知道，CPU 运行的语句顺序在任何情况下都不会混合。例如，我们可以确定并且可以继续确定以下程序将分别输出`4`，`"hello"`和`5`：

```cpp
int a{4};
std::cout << a << std::endl;
int b{a};
++b;
std::cout << "hello" << std::endl;
b--;
std::cout << (b + 1) << std::endl;
```

我们可以保证在将`a`变量打印到屏幕之前，其值将被初始化。同样，我们可以保证在将`"hello"`字符串打印到屏幕之前，我们会减少`b`的值，并且在将`(b + 1)`的和打印到屏幕之前，该和将被计算。每条指令的执行可能涉及从内存中读取数据或向内存中写入数据。

在第五章中介绍了*内存管理和智能指针*，内存层次结构足够复杂，使我们对程序执行的理解变得更加困难。例如，前面例子中的`int b{a};`这一行假设`a`的值从内存加载到 CPU 的寄存器中，然后将用于写入`b`的内存位置。关键词在于*位置*，因为它对我们来说有一点特殊的解释。更具体地说，我们谈论的是内存位置。并发支持取决于语言的内存模型，即对内存并发访问的一组保证。尽管字节是最小的可寻址内存单元，但 CPU 处理数据时使用的是字。也就是说，字是 CPU 从内存读取或写入的最小单位。例如，我们认为以下两个声明是不同的变量：

```cpp
char one;
char two;
```

如果这些变量分配在同一个字中（假设字的大小大于`char`的大小），读取和写入任何一个变量都涉及读取包含它们两个的字。对变量的并发访问可能导致意外的行为。这就是需要内存模型保证的问题。C++内存模型保证了两个线程可以访问和更新不相互干扰的内存位置。内存位置是标量类型。标量类型是算术类型、指针、枚举或`nullptr_t`。最大的非零长度相邻位字段序列也被认为是内存位置。一个经典的例子是以下结构：

```cpp
struct S
{
  char a;             // location #1
  int b: 5;           // location #2
  unsigned c: 11;
  unsigned :0;        // :0 separates bit fields
  unsigned d: 8;      // location #3
  struct {
    int ee: 8;
  } e;                // location #4 
};
```

对于前面的例子，两个线程访问同一个结构的不同内存位置不会相互干扰。那么，当谈论并发或多线程时，我们应该考虑什么呢？

并发通常与多线程混淆。它们在性质上是相似的，但在细节上是不同的概念。为了简化问题，只需想象并发是两个操作的运行时间交错在一起。如果操作`A`与操作`B`同时运行，它们的开始和结束时间在任何时刻都是交错的，如下图所示：

![](img/5a602270-5f05-4ec9-9d02-5ab13bbf4883.png)

当两个任务同时运行时，并不一定要并行运行。想象一下以下情况：你正在看电视，同时上网冲浪。虽然这不是一个好的做法，但是，让我们想象一下，你有一个不能错过的最爱电视节目，同时，你的朋友让你研究一些关于蜜蜂的资料。你实际上无法专注于这两个任务；在任何固定的时刻，你的注意力都会被你正在观看的节目或者你在网上找到的关于蜜蜂的有趣事实所吸引。你的注意力会不时地从节目转移到蜜蜂身上。

就并发而言，你同时进行两个任务。你的大脑给节目一个时间段：你观看，享受，然后切换到文章，读几句话，然后再切换回节目。这是同时运行任务的简单例子。仅仅因为它们的开始和结束时间交错，并不意味着它们同时运行。另一方面，你在做任何前面提到的任务时都在呼吸。呼吸是在后台进行的；你的大脑不会将你的注意力从节目或文章转移到你的肺部来吸气或呼气。在看节目的同时呼吸是并行运行任务的一个例子。这两个例子都向我们展示了并发的本质。

那么，当您在计算机上运行多个应用程序时会发生什么？它们是否并行运行？可以肯定的是它们是同时运行的，然而，实际的并行性取决于您计算机的硬件。大多数大众市场计算机都只有一个 CPU。正如我们从前面的章节中所知，CPU 的主要工作是逐个运行应用程序的指令。单个 CPU 如何处理同时运行两个应用程序的情况？要理解这一点，我们应该了解进程。

# 进程

进程是内存中运行程序的映像。当我们启动一个程序时，操作系统从硬盘读取程序的内容，将其复制到内存中，并将 CPU 指向程序的起始指令。进程有其私有的虚拟地址空间、堆栈和堆。两个进程不会以任何方式相互干扰。这是操作系统提供的保证。这也使得程序员的工作非常困难，如果他们的目标是**进程间通信**（**IPC**）。我们在本书中不讨论低级硬件特性，但你应该对运行程序时发生的事情有一个基本的了解。这实际上取决于底层硬件，更具体地说，取决于 CPU 的种类和结构。CPU 的数量、CPU 核心的数量、缓存内存的级别以及 CPU 或其核心之间的共享缓存内存——所有这些都会影响操作系统运行和执行程序的方式。

计算机系统中的 CPU 数量定义了真正并行运行的进程数量。这在下图中显示：

![](img/249ef5f9-c6a5-43bf-bad3-7648ec848c90.png)

当我们谈论多处理时，我们考虑的是允许多个进程同时运行的环境。这就是棘手的部分。如果进程实际上是同时运行的，那么我们说它们是并行运行的。因此，并发不是并行，而并行意味着并发。

如果系统只有一个 CPU，进程会同时运行但不是并行的。操作系统通过一种称为**上下文切换**的机制来管理这一点。上下文切换意味着暂停进程的工作一会儿，复制进程在当前时间使用的所有寄存器值，并存储进程的所有活动资源和值。当一个进程停止时，另一个进程获得运行的权利。在为第二个进程提供的指定时间段之后，操作系统开始为其进行上下文切换。同样，它复制进程使用的所有资源。然后，之前的进程开始。在启动它之前，操作系统将资源和值复制回第一个进程使用的相应槽位，然后恢复执行此进程。

有趣的是，这些过程甚至没有意识到这样的事情。所描述的过程发生得如此之快，以至于用户实际上无法注意到操作系统中运行的程序实际上并不是同时运行的。下图描述了由单个 CPU 运行的两个进程。当其中一个进程处于*活动*状态时，CPU 按顺序执行其指令，将任何中间数据存储在其寄存器中（你也应该考虑缓存内存，就像在游戏中一样）。另一个进程正在*等待*操作系统提供其运行的时间段：

![](img/a385b09c-4de2-4fd5-8057-8831d0675c61.png)

运行多个进程对操作系统来说是一项复杂的工作。它管理进程的状态，确定哪个进程应该比其他进程占用更多的 CPU 时间等。每个进程在操作系统切换到另一个进程之前都有固定的运行时间。这个时间对于一个进程可能更长，对于另一个进程可能更短。使用优先级表来调度进程。操作系统为优先级更高的进程提供更多的时间，例如，系统进程的优先级高于用户进程。另一个例子可能是，监控网络健康的后台任务的优先级高于计算器应用程序。当提供的时间片用完时，操作系统会启动上下文切换，即，它会存储**进程 A**的状态以便稍后恢复其执行：

![](img/1d6e1429-9787-443b-9ea6-2a591b51de4c.png)

在存储状态之后，如下图所示，它切换到下一个进程来执行：

![](img/9ba4ecae-987c-4b5a-a51c-2790b12a3c5e.png)

显然，如果**进程 B**之前正在运行，它的状态应该被加载回 CPU。同样，当**进程 B**的时间片（或时间量子）用完时，操作系统会存储它的状态，并将**进程 A**的状态加载回 CPU（在被操作系统暂停之前的状态）：

![](img/ed451d71-cf02-45f6-8929-484ecb4ed453.png)

进程之间没有任何共同之处，或者至少它们认为是这样。每个运行的进程都表现得好像它是系统中唯一的。它拥有操作系统可以提供的所有资源。实际上，操作系统设法让进程彼此不知晓，因此为每个进程模拟了自由。最后，在将**进程 A**的状态加载回来后，CPU 继续执行它的指令，就好像什么都没有发生过：

![](img/b44e37d7-6d77-4248-ad76-e94dc8ab76f4.png)

**进程 B**被冻结，直到有新的时间片可用于运行它。

一个单 CPU 运行多个进程类似于一位老师检查学生的考卷。老师一次只能检查一份考卷，尽管他们可以通过逐个检查每个考试的答案来引入一些并发性。首先，他们检查一个学生的第一个问题的答案，然后切换到第二个学生的考试的第一个答案，然后再切换回第一个学生的第二个答案，依此类推。每当老师从一份考卷切换到另一份时，他们都会记下他们停下来的问题的编号。这样，当他们回到同一份考卷时，他们就知道从哪里开始。

同样，操作系统在暂停一个进程以恢复另一个进程之前记录下进程的执行点。第二个进程可以（而且很可能会）使用被暂停进程使用的相同寄存器集。这迫使操作系统将第一个进程的寄存器值存储在某个地方，以便稍后恢复。当操作系统暂停第二个进程以恢复第一个进程时，它会将已保存的寄存器值加载回相应的寄存器中。恢复的进程不会注意到任何差异，并将继续工作，就好像它从未被暂停过一样。

前两段描述的一切都与单 CPU 系统有关。在多 CPU 系统中，系统中的每个 CPU 都有自己的寄存器集。此外，每个 CPU 可以独立地执行程序指令，而不受其他 CPU 的影响，这允许进程并行运行而无需暂停和恢复它们。在这个例子中，一位老师和几个助手类似于一个有三个 CPU 的系统。他们每个人都可以检查一份考卷；他们在任何时候都在检查三份不同的考卷。

# 进程的挑战

当进程需要以某种方式相互联系时，困难就会出现。比如，一个进程应该计算某些东西并将值传递给一个完全不同的进程。有几种方法可以实现 IPC，其中一种是使用在进程之间共享的内存段。下图描述了两个进程访问共享内存段的情况：

![](img/ba6aa4ed-83da-4987-b27f-17429fa23ec4.png)

一个进程将计算结果存储到内存中的共享段中，第二个进程从该段中读取。在我们之前的例子中，老师和他们的助手在共享的纸上分享他们的检查结果。另一方面，线程共享进程的地址空间，因为它们在进程的上下文中运行。虽然进程是一个程序，线程是一个函数而不是一个程序。也就是说，一个进程必须至少有一个线程，我们称之为执行线程。线程是在系统中运行的程序的指令容器，而进程封装了线程并为其提供资源。我们大部分的兴趣都在于线程及其编排机制。现在让我们亲自见见它们。

# 线程

线程是进程范围内可以由操作系统调度的代码部分。虽然进程是运行程序的映像，但与利用多线程的项目相比，管理多进程项目以及 IPC 要困难得多，有时也是无用的。程序处理数据，通常是数据集合。访问、处理和更新数据是通过函数来完成的，这些函数要么是对象的方法，要么是组合在一起以实现最终结果的自由函数。在大多数项目中，我们处理成千上万个函数和对象。每个函数代表一堆指令，这些指令以一个合理的名称包装起来，用于被其他函数调用。多线程旨在并发运行函数以实现更好的性能。

例如，一个计算三个不同向量的和并打印它们的程序调用计算第一个向量的和的函数，然后是第二个向量，最后是最后一个。这一切都是顺序进行的。如果处理单个向量需要 A 的时间，那么程序将在`3A`的时间内运行。以下代码演示了这个例子：

```cpp
void process_vector(const std::vector<int>& vec) 
{
 // calculate the sum and print it
}

int main()
{
 std::vector<int> vec1{1, 2, 3, 4, 5};
 std::vector<int> vec2{6, 7, 8, 9, 10};
 std::vector<int> vec3{11, 12, 13, 14, 15};
 process_vector(vec1); // takes A amount of time
 process_vector(vec2); // takes A amount of time
 process_vector(vec3); // takes A amount of time
}
```

如果有一种方法可以同时为三个不同的向量运行相同的函数，那么在前面的例子中整个程序只需要 A 的时间。执行线程，或者说线程，是并发运行任务的确切方式。通过任务，我们通常指的是一个函数，尽管你也应该记住`std::packaged_task`。再次强调，并发不应与并行混淆。当我们谈论线程并发运行时，你应该考虑之前讨论的进程的上下文切换。几乎同样适用于线程。

`std::packaged_task`类似于`std::function`。它包装了一个可调用对象——函数、lambda、函数对象或绑定表达式。与`std::packaged_task`的区别在于它可以异步调用。本章后面会详细介绍这一点。

每个进程都有一个单一的执行线程，有时被称为**主线程**。一个进程可以有多个线程，这时我们称之为**多线程**。线程几乎以与进程相同的方式运行。它们也有上下文切换。

线程彼此独立运行，但因为所有线程都属于同一个进程，它们大部分资源都是共享的。进程占用硬件和软件资源，如 CPU 寄存器和内存段，包括自己的堆栈和堆。虽然进程不与其他进程共享其堆栈或堆，但其线程必须使用进程占用的相同资源。线程的一切生活都发生在进程内部。

然而，线程不共享堆栈。每个线程都有自己的堆栈部分。这种隔离的原因在于，线程只是一个函数，函数本身应该可以访问堆栈来管理其参数和局部变量的生命周期。当我们将相同的函数作为两个（或更多）分别运行的线程运行时，运行时应该以某种方式处理它们的边界。虽然这很容易出错，但你可以通过值或引用将一个变量从一个线程传递到另一个线程。假设我们启动了三个线程，分别运行上面例子中的三个向量的`process_vector()`函数。你应该想象启动一个线程意味着以某种方式*复制*底层函数（它的变量但不是指令）并将其独立地运行。在这种情况下，相同的函数将被复制为三个不同的图像，并且每个图像都将独立于其他图像运行，因此每个图像都应该有自己的堆栈。另一方面，堆在线程之间是共享的。因此，基本上我们得到了以下结论：

![](img/2837ebc0-a491-4359-aa66-f0e737feff43.png)

与进程一样，并发运行的线程不一定是并行运行的。每个线程都会获得一小部分 CPU 时间来运行，而且从一个线程切换到另一个线程也会有开销。每个暂停的线程状态都应该被存储在某个地方，以便在恢复时能够恢复。CPU 的内部结构定义了线程是否能够真正并行运行。CPU 核心的数量定义了可以真正并行运行的线程数量。

C++线程库提供了`hardware_concurrency()`函数，用于查找可以真正并发运行的线程数量。在设计并发代码时，可以参考这个数字。

下图描述了两个 CPU，每个 CPU 都有四个核心。每个核心可以独立地运行一个线程：

![](img/82938768-6461-41e2-94dc-454295e6fd96.png)

不仅两个进程并行运行，它们的线程也使用 CPU 核心并行运行。那么，如果我们有几个线程但只有一个单核 CPU，情况会如何改变呢？几乎与我们之前为进程所说明的情况相同。看看下面的图表——它描述了 CPU 如何在某个时间片段内执行**线程 1**：

![](img/43a122ae-5378-4cb0-8770-cfea0b51cad2.png)

当前活动的**进程 A**有两个同时运行的线程。在每个指定的时间点，只有一个线程被执行。当**线程 1**的时间片用完时，**线程 2**被执行。与我们讨论过的进程模型的不同之处在于，线程共享进程的资源，如果我们不关心并发代码设计问题，这会导致不自然的行为。让我们深入了解 C++线程支持，并找出在使用多线程时会出现什么问题。

# 使用线程

当 C++程序启动时，也就是`main()`函数开始执行时，你可以创建并启动新的线程，这些线程将与主线程并发运行。要在 C++中启动一个线程，你应该声明一个线程对象，并将要与主线程并发运行的函数传递给它。以下代码演示了使用`<thread>`中定义的`std::thread`声明和启动线程：

```cpp
#include <thread> #include <iostream>

void foo() { std::cout << "Testing a thread in C++" << std::endl; }

int main() 
{
 std::thread test_thread{foo};
}
```

就是这样。我们可以创建一个更好的例子来展示两个线程如何同时工作。假设我们同时在循环中打印数字，看看哪个线程打印了什么：

```cpp
#include <thread>
#include <iostream>

void print_numbers_in_background() 
{
 auto ix{0};  // Attention: an infinite loop!
 while (true) {
 std::cout << "Background: " << ix++ << std::endl;
 }
}

int main()
{
 std::thread background{print_numbers_in_background};
  auto jx{0};
  while (jx < 1000000) {
    std::cout << "Main: " << jx++ << std::endl;
  }
}
```

上面的例子将打印出带有`Main:`和`Background:`前缀混合在一起的两个输出。输出的摘录可能如下所示：

```cpp
...
Main: 90
Main: 91
Background: 149
Background: 150
Background: 151
Background: 152
Background: 153
Background: 
Main: 92
Main: 93
...
```

当主线程完成其工作（向屏幕打印一百万次）时，程序希望在不等待后台线程完成的情况下结束。这会导致程序终止。让我们看看如何修改之前的例子。

# 等待线程

如果要等待线程完成，`thread`类提供了`join()`函数。以下是等待`background`线程的修改版本的示例：

```cpp
#include <thread>
#include <iostream>

void print_numbers_in_background()
{
  // code omitted for brevity
}

int main()
{
  std::thread background{print_numbers_in_background};
  // the while loop omitted for brevity
 background.join();
}
```

正如我们之前讨论的，`thread`函数作为一个独立的实体运行，独立于其他线程-甚至是启动它的线程。它不会等待它刚刚启动的线程，这就是为什么您应该明确告诉调用函数在自己之前等待它完成。在它完成之前，必须发出信号表明调用线程（主线程）正在等待线程完成。

`join()`函数的对称相反是`detach()`函数。`detach()`函数表示调用者对等待线程完成不感兴趣。在这种情况下，线程可以有独立的生命周期。就像这里显示的（就像它已经 18 岁了）：

```cpp
std::thread t{foo};
t.detach(); 
```

尽管分离线程可能看起来很自然，但有很多情况需要等待线程完成。例如，我们可能会将局部变量传递给正在运行的线程。在这种情况下，我们不能让调用者分离线程，因为调用者可能比线程更早完成其工作。让我们为了清晰起见举个例子。**Thread 1**声明了`loc`变量并将其传递给了从**Thread 1**启动的**Thread 2**：

![](img/8bcd907b-742d-4b19-9484-87822f730a68.png)

如果**Thread 1**在**Thread 2**之前完成其执行，那么通过地址访问`loc`会导致未定义的行为：

![](img/58cea33e-6366-4f28-9ac5-84e785da0452.png)

不再有这样的对象，因此我们可以希望程序最好崩溃。这将导致意外行为，因为运行线程将不再访问调用者的局部变量。您应该加入或分离线程。

我们可以将任何可调用对象传递给`std::thread`。以下示例显示了将 lambda 表达式传递给线程：

```cpp
#include <thread>

int main() {
  std::thread tl{[]{
 std::cout << "A lambda passed to the thread";
 }};
  tl.join();
}
```

此外，我们可以使用可调用对象作为线程参数。看一下以下代码，声明了具有重载的`operator()`函数的`TestTask`类：

```cpp
#include <thread>

class TestTask
{
public:
  TestTask() = default;

 void operator()() {
 state_++;
 }

private:
  int state_ = 0;
};

int main() {
  std::thread t{TestTask()};
  t.join();
}
```

函数对象（具有重载的`operator()`函数的`TestTask`类）的一个优点是它能够存储状态信息。函数对象是命令设计模式的一个美丽实现，我们将在第十一章中讨论，*使用设计模式设计策略游戏*。回到线程，让我们继续讨论语言中的一个新添加，它允许更好地加入线程的方式。

# 使用 std::jthread

C++20 引入了可加入线程`std::jthread`。它提供了与`std::thread`相同的接口，因此我们可以在代码中用 jthreads 替换所有线程。它实际上是对`std::thread`的封装，因此基本上是将操作委托给封装的线程。

如果您的编译器版本不支持`std::jthread`，您可以选择使用**RAII**（**资源获取即初始化**）习惯用法，这对线程非常适用。看一下以下代码：

```cpp
class thread_raii
{
public:
  explicit thread_raii(std::thread& t)
    : thread_(std::move(t))
  {}

  ~thread_raii() {
    thread_.join();  
  }

private:
  std::thread thread_;
};

void foo() {
  std::cout << "Testing thread join";
}

int main() {
 std::thread t{foo};
 thread_raii r{t};
  // will automatically join the thread
}
```

然而，前面的代码缺少了一个额外的检查，因为传递给 RAII 类的线程可能已经被分离。为了查看线程是否可以加入，我们使用`joinable()`函数。这是我们应该如何重写`thread_raii`类的方式：

```cpp
class thread_raii
{
public:
  explicit thread_raii(std::thread& t)
    : thread_(std::move(t))
  {}

 ~thread_raii()
 {
 if (thread_.joinable()) {
 thread_.join();
 }
 }
private:
  std::thread thread_;
};
```

在调用`join()`函数之前，析构函数首先测试线程是否可加入。但是，与其处理习惯用法并担心线程在加入之前是否已经加入，我们更喜欢使用`std::jthread`。以下是如何使用先前声明的`TestTask`函数来做到这一点：

```cpp
std::jthread jt{TestTask()};
```

就是这样——不需要调用`jt.join()`，并且我们使用`std::jthread`内置的新的协作可中断功能。我们说`jthread`是协作可中断的，因为它提供了`request_stop()`函数，它做了它的名字所说的事情——请求线程停止。尽管请求的实现是定义的，但这是一个不必永远等待线程的好方法。回想一下线程在无限循环中打印数字的例子。我们修改了主线程来等待它，这导致永远等待它。下面是我们如何使用`std::jthread`修改线程以利用`request_stop()`函数：

```cpp
int main()
{
 std::jthread background{print_numbers_in_background};
  auto jx{0};
  while (jx < 1000000) {
    std::cout << "Main: " << jx << std::endl;
  }
  // The main thread is about to finish, so we request the background thread to stop
 background.request_stop();
}
```

`print_numbers_in_background()`函数现在接收到一个请求，并可以相应地行为。现在，让我们看看如何将参数传递给线程函数。

# 将参数传递给线程函数

`std::thread`构造函数接受参数并将它们转发给底层的`thread`函数。例如，要将参数`4`和`2`传递给`foo()`函数，我们将参数传递给`std::thread`构造函数：

```cpp
void foo(int one, int two) {
  // do something
}

std::thread t{foo, 4, 2};
```

`4`和`2`参数将作为`foo()`函数的第一个和第二个参数传递。

以下示例说明了通过引用传递参数：

```cpp
class big_object {};

void make_changes(big_object&);

void error_prone()
{
  big_object b;
 std::jthread t{make_changes, b};
  // do something else
}
```

为了理解为什么我们将函数命名为`error_prone`，我们应该知道线程构造函数会复制传递给它的值，然后使用`rvalue`引用将它们传递给线程函数。这是为了处理仅可移动类型。因此，它将尝试使用`rvalue`调用`make_changes()`函数，这将无法编译通过（不能将`rvalue`传递给期望非常量引用的函数）。我们需要在需要引用的参数中使用`std::ref`进行包装。

```cpp
std::thread t{make_changes, std::ref(b)};
```

前面的代码强调了参数应该通过引用传递。处理线程需要更加注意，因为程序中有许多方法可以获得意外结果或未定义的行为。让我们看看如何管理线程以生成更安全的多线程应用程序。

# 管理线程和共享数据

正如之前讨论的，线程的执行涉及暂停和恢复其中一些线程，如果线程数量超过硬件支持的并行运行线程数量。除此之外，线程的创建也有开销。在项目中处理有许多线程的建议做法之一是使用线程池。

线程池的概念在于缓存的概念。我们创建并保留线程在某个容器中以便以后使用。这个容器称为池。例如，以下向量表示一个简单的线程池：

```cpp
#include <thread>
#include <vector>

std::vector<std::thread> pool;
```

每当我们需要一个新线程时，我们不是声明相应的`std::thread`对象，而是使用已在池中创建的线程。当我们完成线程时，我们可以将其推回向量以便以后使用。这在处理 10 个或更多线程时可以节省一些时间。一个合适的例子是一个 Web 服务器。

Web 服务器是一个等待传入客户端连接并为每个客户端创建一个独立连接以独立处理的程序。一个典型的 Web 服务器通常同时处理数千个客户端。每当与某个客户端启动新连接时，Web 服务器都会创建一个新线程并处理客户端请求。以下伪代码演示了 Web 服务器传入连接管理的简单实现：

```cpp
void process_incoming_connections() {
  if (new connection from client) {
    t = create_thread(); // potential overhead
    t.handle_requests(client);
  }
}
while (true) {
  process_incoming_connections();
}
```

使用线程池时，前面的代码将避免每次处理客户端请求时都创建一个线程。创建新线程需要操作系统额外且昂贵的工作。为了节省时间，我们使用一种机制，可以在每个请求时省略创建新线程。为了使线程池更好，让我们用队列替换它的容器。每当我们请求一个线程时，线程池将返回一个空闲线程，每当我们完成一个线程时，我们将其推回线程池。线程池的简单设计如下：

```cpp
#include <queue>
#include <thread>

class ThreadPool
{
public:
  ThreadPool(int number_of_threads = 1000) {
    for (int ix = 0; ix < number_of_threads; ++ix) {
      pool_.push(std::thread());
    }
  }

  std::thread get_free_thread() {
    if (pool_.empty()) {
      throw std::exception("no available thread");
    }
    auto t = pool_.front();
    pool_.pop();
    return t;
  }

  void push_thread(std::thread t) {
    pool_.push(t);
  }

private:
  std::queue<std::thread> pool_;
};
```

构造函数创建并将线程推送到队列。在下面的伪代码中，我们用之前介绍的`ThreadPool`替换了直接创建线程来处理客户端请求：

```cpp
ThreadPool pool;
void process_incoming_connections() {
  if (new connection from client) {
    auto t = pool.get_free_thread();
    t.handle_request(client);
  }
}

while (true) {
  process_incoming_connections();
}
```

假设`handle_request()`函数在完成时将线程推回线程池，那么线程池就像是连接线程的集中存储。虽然前面的片段远未准备好投入生产，但它传达了在密集应用中使用线程池的基本思想。

# 共享数据

竞争条件是多线程程序员害怕并尽量避免的事情。想象一下两个函数同时处理相同的数据，如下所示：

```cpp
int global = 0;

void inc() {
  global = global + 1;
}
...
std::thread t1{inc};
std::thread t2{inc};
```

可能发生竞争条件，因为线程`t1`和`t2`正在用多个步骤修改相同的变量。在单个线程安全步骤中执行的任何操作称为**原子操作**。在这种情况下，即使使用增量运算符，增加变量的值也不是原子操作。

# 使用互斥锁保护共享数据

为了保护共享数据，广泛使用称为**互斥锁**的对象。互斥锁是控制线程运行的对象。想象线程就像人类一样，一次处理数据的交易。当一个线程锁定一个互斥锁时，另一个线程会等待，直到它完成数据并解锁互斥锁。然后另一个线程锁定互斥锁并开始处理数据。以下代码演示了如何使用互斥锁解决竞争条件的问题：

```cpp
#include <mutex>
...
std::mutex locker;
void inc() {
  locker.lock();
  global = global + 1;
  locker.unlock();
}
...
std::thread t1{inc};
std::thread t2{inc};

```

当`t1`开始执行`inc()`时，它锁定一个互斥锁，这样可以避免其他线程访问全局变量，除非原始线程不解锁下一个线程。

C++17 引入了锁保护，允许保护互斥锁，以免忘记解锁它：

```cpp
std::mutex locker;
void inc() {
  std::lock_guard g(locker);
  global = global + 1;
}
```

如果可能的话，最好使用语言提供的保护。

# 避免死锁

互斥锁会带来新的问题，比如**死锁**。死锁是多线程代码的一种情况，当两个或多个线程锁定一个互斥锁并等待另一个解锁时发生。

避免死锁的常见建议是始终以相同的顺序锁定两个或多个互斥锁。C++提供了`std::lock()`函数，用于相同的目的。

以下代码说明了`swap`函数，它接受两个类型为`X`的参数。我们假设`X`有一个名为`mt`的成员，它是一个互斥锁。`swap`函数的实现首先锁定左对象的互斥锁，然后锁定右对象的互斥锁：

```cpp
void swap(X& left, X& right)
{
  std::lock(left.mt, right.mt);
  std::lock_guard<std::mutex> lock1(left.mt, std::adopt_lock);
  std::lock_guard<std::mutex> lock2(right.mt, std::adopt_lock);
  // do the actual swapping
}
```

为了一般地避免死锁，避免嵌套锁。也就是说，如果已经持有一个锁，则不要获取另一个锁。如果不是这种情况，则按固定顺序获取锁。固定顺序将允许您避免死锁。

# 设计并发代码

当并发引入时，项目复杂性会急剧上升。与并发对应的同步代码相比，处理顺序执行的同步代码要容易得多。许多系统通过引入事件驱动开发概念（如事件循环）来避免使用多线程。使用事件循环的目的是引入一种可管理的异步编程方法。进一步想象，任何提供图形用户界面（GUI）的应用程序。每当用户点击任何 GUI 组件，如按钮；在字段中输入；甚至移动鼠标时，应用程序都会接收有关用户操作的所谓事件。无论是`button_press`、`button_release`、`mouse_move`还是其他任何事件，它都代表了应用程序对信息的正确反应。一种流行的方法是将事件循环结合起来，以排队用户交互期间发生的任何事件。

当应用程序忙于当前任务时，由用户操作产生的事件被排队等待在将来的某个时间进行处理。处理涉及调用附加到每个事件的处理程序函数。它们按照它们被放入队列的顺序进行调用。

将多线程引入项目会带来额外的复杂性。现在，您需要关注竞争条件和适当的线程处理，甚至可能使用线程池来重用线程对象。在顺序执行的代码中，您只关心代码。使用多线程，您现在需要更多地关注相同代码的执行方式。例如，一个简单的设计模式，如单例，在多线程环境中的行为会有所不同。单例的经典实现如下：

```cpp
class MySingleton
{
public:
 static MySingleton* get_instance() {
 if (instance_ == nullptr) {
 instance_ = new MySingleton();
 }
 return instance_;
 }

  // code omitted for brevity
private:
  static inline MySingleton* instance_ = nullptr;
};
```

以下代码启动了两个线程，都使用了`MySingleton`类：

```cpp
void create_something_unique() 
{
 MySingleton* inst = MySingleton::get_instance();
  // do something useful
}

void create_something_useful() 
{
  MySingleton* anotherInst = MySingleton::get_instance();
  // do something unique
}  

std::thread t1{create_something_unique};
std::thread t2{create_something_useful};
t1.join();
t2.join();
// some other code
```

线程`t1`和`t2`都调用`MySingleton`类的`get_instance()`静态成员函数。可能`t1`和`t2`都通过了对空实例的检查，并且都执行了新操作符。很明显，这里存在竞争条件。在这种情况下，资源（在本例中是类实例）应该受到保护。以下是使用互斥量的明显解决方案：

```cpp
class MySingleton
{
public:
  static MySingleton* get_instance() {
 std::lock_guard lg{mutex_};
    if (instance_ == nullptr) {
      instance_ = new MySingleton();
    }
    return instance_;
  }

  // code omitted for brevity
private:
 static std::mutex mutex_;
  static MySingleton* instance_;
}
```

使用互斥量可以解决问题，但会使函数的工作速度变慢，因为每次线程请求一个实例时，都会锁定一个互斥量（这涉及操作系统内核的额外操作）。正确的解决方案是使用双重检查锁定模式。它的基本思想是这样的：

1.  在`instance_`检查后锁定互斥量。

1.  在锁定互斥量后再次检查`instance_`，因为另一个线程可能已经通过了第一次检查，并等待互斥量解锁。

有关详细信息，请参阅代码：

```cpp
static MySingleton* get_instance() {
  if (instance_ == nullptr) {
 std::lock_guard lg{mutex_};
 if (instance_ == nullptr) {
 instance_ = new MySingleton();
 }
  }
  return instance_;
}
```

几个线程可能通过第一次检查，其中一个线程将锁定互斥量。只有一个线程可以进行新操作符调用。然而，在解锁互斥量后，通过第一次检查的线程将尝试锁定它并创建实例。第二次检查是为了防止这种情况发生。上述代码使我们能够减少同步代码的性能开销。我们提供的方法是为并发代码设计做好准备的一种方式。

并发代码设计在很大程度上基于语言本身的能力。C++的发展是非常了不起的。在最早的版本中，它没有内置支持多线程。现在，它有一个稳固的线程库，而新的 C++20 标准为我们提供了更强大的工具，如协程。

# 引入协程

在讨论 GUI 应用程序时，我们讨论了异步代码执行的一个例子。GUI 组件通过触发相应的事件来对用户操作做出反应，这些事件被推送到事件队列中。然后，这些队列会通过调用附加的处理程序函数逐个进行处理。所描述的过程在一个循环中发生；这就是为什么我们通常将这个概念称为事件循环。

异步系统在 I/O 操作中非常有用，因为任何输入或输出操作都会在 I/O 调用点阻塞执行。例如，以下伪代码从目录中读取文件，然后在屏幕上打印欢迎消息：

```cpp
auto f = read_file("filename");
cout << "Welcome to the app!";
process_file_contents(f);
```

与同步执行模式相结合，我们知道只有在`read_file()`函数执行完成后才会打印出欢迎来到应用程序！`process_file_contents()`将在`cout`完成后调用。处理异步代码时，我们对代码执行的了解开始表现得像是一些无法识别的东西。以下修改版本的前面的例子使用`read_file_async()`函数异步读取文件内容：

```cpp
auto p = read_file_async("filename");
cout << "Welcome to the app!";
process_file_contents(p); // we shouldn't be able to do this
```

考虑到`read_file_async()`是一个异步函数，欢迎来到应用程序！的消息将比文件内容更早打印出来。异步执行的本质允许我们调用要在后台执行的函数，这为我们提供了非阻塞的输入/输出。

然而，我们对函数的返回值处理方式有一点变化。如果我们处理一个异步函数，它的返回值被视为一种称为**承诺**或**承诺对象**的东西。这是系统在异步函数完成时通知我们的方式。承诺对象有三种状态：

+   挂起

+   拒绝

+   实现

承诺对象在函数完成并且结果准备好被处理时被认为是已实现的。在发生错误时，承诺对象将处于拒绝状态。如果承诺既没有被拒绝也没有被实现，它就处于挂起状态。

C++20 引入了协程作为经典异步函数的补充。协程将代码的后台执行提升到了下一个级别；它们允许函数在必要时暂停和恢复。想象一个读取文件内容并在中途停止的函数，将执行上下文传递给另一个函数，然后恢复文件的读取直到结束。因此，在深入研究之前，将协程视为以下函数：

+   开始

+   暂停

+   恢复

+   完成

要使函数成为协程，您可以使用关键字`co_await`、`co_yield`或`co_return`之一。`co_await`是一个构造，告诉代码等待异步执行的代码。这意味着函数可以在那一点被暂停，并在结果准备好时恢复执行。例如，以下代码使用套接字从网络请求图像：

```cpp
task<void> process_image()
{
  image i = co_await request_image("url");
  // do something useful with the image
}
```

由于网络请求操作也被视为**输入/输出**操作，它可能会阻塞代码的执行。为了防止阻塞，我们使用异步调用。在前面的例子中使用`co_await`的行是函数执行可能被暂停的地方。简单来说，当执行到达带有`co_await`的行时，会发生以下情况：

1.  它暂时退出函数（直到没有准备好的数据）。

1.  它继续执行`process_image()`被调用之前的位置。

1.  然后它再次回来继续执行`process_image()`在它离开的地方。

为了实现这一点，协程（`process_image()`函数是一个协程）在 C++中不像处理常规函数那样处理。协程的一个有趣甚至令人惊讶的特性是它们是**无堆栈的。**我们知道函数不能没有堆栈。这是函数在执行指令之前推送其参数和局部变量的地方。另一方面，协程不是将任何东西推送到堆栈，而是将它们的状态保存在堆中，并在恢复时恢复它们。

这很棘手，因为还有堆栈式协程。堆栈式协程，也称为**纤程**，有一个单独的堆栈。

协程与调用者相连。在前面的例子中，调用`sprocess_image()`的函数将执行转移到协程，协程的暂停（也称为**yielding**）将执行返回给调用者。正如我们所说，堆用于存储协程的状态，但实际的函数特定数据（参数和局部变量）存储在调用者的堆栈上。就是这样——协程与存储在调用函数堆栈上的对象相关联。显然，协程的生存期与其对象一样长。

协程可能会给人一种错误的印象，认为它增加了语言的冗余复杂性，但它们的用例在改进使用异步 I/O 代码（如前面的例子中）或延迟计算的应用程序中非常好。也就是说，当我们不得不发明新的模式或引入复杂性来处理懒惰计算等项目时，现在我们可以通过在 C++中使用协程来改善我们的体验。请注意，异步 I/O 或延迟计算只是协程应用的两个例子。还有更多。

# 摘要

在本章中，我们讨论了并发的概念，并展示了并行之间的区别。我们学习了进程和线程之间的区别，后者引起了我们的兴趣。多线程使我们能够更有效地管理程序，尽管它也带来了额外的复杂性。为了处理数据竞争，我们使用诸如互斥锁之类的同步原语。互斥锁是一种锁定一个线程使用的数据的方式，以避免多个线程同时访问相同数据产生的无效行为。

我们还讨论了输入/输出操作被认为是阻塞的概念，而异步函数是使其非阻塞的方法之一。协程作为代码的异步执行的一部分在 C++20 中被引入。

我们学习了如何创建和启动线程。更重要的是，我们学习了如何在线程之间管理数据。在下一章中，我们将深入研究在并发环境中使用的数据结构。

# 问题

1.  并发是什么？

1.  并发和并行之间的区别是什么？

1.  什么是进程？

1.  进程和线程之间的区别是什么？

1.  编写代码启动一个线程。

1.  如何使单例模式线程安全？

1.  重写`MySingleton`类，使用`std::shared_ptr`返回实例。

1.  什么是协程，`co_await`关键字用于什么？

# 进一步阅读

+   *Anthony Williams，《C++并发实战》，[`www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/`](https://www.amazon.com/C-Concurrency-Action-Anthony-Williams/dp/1617294691/)*
