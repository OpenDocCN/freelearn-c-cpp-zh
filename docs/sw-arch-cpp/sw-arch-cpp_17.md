# 第十三章：设计微服务

随着微服务的日益流行，我们希望在本书的一个整章中专门讨论它们。在讨论架构时，你可能会听到，“我们应该使用微服务吗？”本章将向您展示如何将现有应用程序迁移到微服务架构，以及如何构建利用微服务的新应用程序。

本章将涵盖以下主题：

+   深入微服务

+   构建微服务

+   观察微服务

+   连接微服务

+   扩展微服务

# 技术要求

本章中介绍的大多数示例不需要任何特定的软件。对于`redis-cpp`库，请查看[`github.com/tdv/redis-cpp`](https://github.com/tdv/redis-cpp)。

本章中的代码已放置在 GitHub 上[`github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter13`](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter13)。

# 深入微服务

虽然微服务不受任何特定的编程语言或技术的限制，但在实现微服务时常见的选择是 Go 语言。这并不意味着其他语言不适合微服务开发-恰恰相反。C++的低计算和内存开销使其成为微服务的理想选择。

但首先，我们将从微服务的一些优缺点的详细视图开始。之后，我们将专注于通常与微服务相关的设计模式（而不是第四章中涵盖的一般设计模式，*架构和系统设计*）。

## 微服务的好处

你可能经常听到有关微服务的赞美之词。它们确实带来了一些好处，以下是其中一些。

### 模块化

由于整个应用程序被分割成许多相对较小的模块，更容易理解每个微服务的功能。这种理解的自然结果是，测试单个微服务也更容易。测试也受到每个微服务通常具有有限范围的事实的帮助。毕竟，测试日历应用程序比测试整个**个人信息管理**（**PIM**）套件更容易。

然而，这种模块化也是有代价的。你的团队可能对单个微服务有更好的理解，但同时可能会发现更难理解整个应用程序是如何组成的。虽然不应该需要了解构成应用程序的微服务的所有内部细节，但组件之间的关系数量之多构成了认知挑战。在使用这种架构方法时，使用微服务契约是一个良好的实践。

### 可扩展性

更容易扩展范围有限的应用程序。其中一个原因是潜在的瓶颈较少。

缩放工作流程的较小部分也更具成本效益。想象一下，一个负责管理贸易展会的单片应用程序。一旦系统开始出现性能问题，唯一的扩展方式就是为单体引入更大的机器来运行。这被称为垂直扩展。

使用微服务，第一个优势是你可以水平扩展，也就是说，引入更多的机器而不是更大的机器（通常更便宜）。第二个优势来自于你只需要扩展那些出现性能问题的应用程序部分。这也有助于节省基础设施成本。

### 灵活性

当正确设计时，微服务不太容易受到供应商锁定的影响。当您决定要更换第三方组件中的一个时，您不必一次性进行整个痛苦的迁移。微服务设计考虑到您需要使用接口，因此唯一需要修改的部分是您的微服务与第三方组件之间的接口。

组件也可以逐个迁移，有些仍在使用旧提供商的软件。这意味着您可以将在多个地方引入破坏性变化的风险分开。而且，您可以将这与金丝雀部署模式结合起来，以更精细地管理风险。

这种灵活性不仅仅与单个服务有关。它也可能意味着不同的数据库、不同的排队和消息传递解决方案，甚至完全不同的云平台。虽然不同的云平台通常提供不同的服务和 API 来使用它们，但是在微服务架构中，您可以逐步开始迁移工作负载，并在新平台上独立测试它。

当由于性能问题、可扩展性或可用依赖性而需要重写时，重写微服务要比重写单体应用程序快得多。

### 与传统系统集成

微服务不一定是一刀切的方法。如果您的应用程序经过了充分测试，并且迁移到微服务可能会带来很多风险，那么就没有必要完全拆除正在运行的解决方案。最好只拆分需要进一步开发的部分，并将它们作为原始单体应用程序将使用的微服务引入。

通过遵循这种方法，您将获得与微服务相关的敏捷发布周期的好处，同时避免从头开始创建新架构并基本上重建整个应用程序。如果某些东西已经运行良好，最好专注于如何在不破坏良好部分的情况下添加新功能，而不是从头开始。在这里要小心，因为从头开始通常被用作自我提升！

### 分布式开发

开发团队规模小且共同办公的时代已经一去不复返。远程工作和分布式开发即使在传统的办公公司中也是事实。像 IBM、微软和英特尔这样的巨头公司有来自不同地点的人们一起在一个项目上工作。

微服务允许更小更灵活的团队，这使得分布式开发变得更加容易。当不再需要促进 20 人或更多人之间的沟通时，也更容易构建需要较少外部管理的自组织团队。

## 微服务的缺点

即使您认为由于其好处，您可能需要微服务，也要记住它们也有一些严重的缺点。简而言之，它们绝对不适合每个人。大公司通常可以抵消这些缺点，但较小的公司通常没有这种奢侈。

### 依赖成熟的 DevOps 方法

构建和测试微服务应该比在大型单片应用上执行类似操作要快得多。但为了实现敏捷开发，这种构建和测试需要更频繁地进行。

虽然在处理单体应用程序时手动部署应用程序可能是明智的，但是如果应用于微服务，同样的方法将导致许多问题。

为了在开发中采用微服务，您必须确保您的团队具有 DevOps 思维，并了解构建和运行微服务的要求。仅仅将代码交给其他人然后忘记它是不够的。

DevOps 思维将帮助您的团队尽可能自动化。在软件架构中，开发微服务而没有持续集成/持续交付流水线可能是最糟糕的想法之一。这种方法将带来微服务的所有其他缺点，而又无法实现大部分的好处。

### 调试更困难

微服务需要引入可观察性。没有它，当出现问题时，你永远不确定从哪里开始寻找潜在的根本原因。可观察性是一种推断应用程序状态的方式，而无需运行调试器或记录工作负载所在的机器。

日志聚合、应用程序指标、监控和分布式跟踪的组合是管理基于微服务的架构的先决条件。一旦考虑到自动扩展和自愈，甚至可能阻止您访问个别服务（如果它们开始崩溃），这一点尤其重要。

### 额外开销

微服务应该是精益和敏捷的。通常情况下是这样的。然而，基于微服务的架构通常需要额外的开销。首层开销与微服务通信使用的额外接口有关。RPC 库和 API 提供者和消费者不仅要按微服务的数量增加，还要按其副本的数量增加。然后还有辅助服务，如数据库、消息队列等。这些服务还包括通常由存储设施和收集数据的个体收集器组成的可观察性设施。

通过更好的扩展优化的成本可能会被运行整个服务群所需的成本所抵消，而这些服务并没有带来即时的业务价值。而且，你可能很难向利益相关者证明这些成本（无论是基础设施还是开发开销）。

## 微服务的设计模式

许多通用设计模式也适用于微服务。还有一些设计模式通常与微服务相关联。这里介绍的模式对于绿地项目和从单块应用程序迁移都很有用。

### 分解模式

这些模式涉及微服务的分解方式。我们希望确保架构稳定，服务之间松耦合。我们还希望确保服务具有内聚性和可测试性。最后，我们希望自治团队完全拥有一个或多个服务。

#### 按业务能力分解

其中一种分解模式要求按业务能力进行分解。业务能力涉及业务为产生价值而做的事情。业务能力的例子包括商家管理和客户管理。业务能力通常以层次结构组织。

应用这种模式的主要挑战是正确识别业务能力。这需要对业务本身有一定的了解，并可能受益于与业务分析师的合作。

#### 按子域分解

另一种分解模式与**领域驱动设计**（**DDD**）方法有关。要定义服务，需要识别 DDD 子域。就像业务能力一样，识别子域需要了解业务背景。

这两种方法的主要区别在于，按业务能力分解更多关注业务的组织（其结构），而按子域分解更关注业务试图解决的问题。

### 每个服务一个数据库模式

存储和处理数据在每种软件架构中都是一个复杂的问题。错误的选择可能会影响可伸缩性、性能或维护成本。对于微服务来说，由于我们希望微服务之间松耦合，这增加了额外的复杂性。

这导致了一种设计模式，每个微服务连接到自己的数据库，因此独立于其他服务引入的任何更改。虽然这种模式增加了一些开销，但其额外的好处是你可以为每个微服务单独优化架构和索引。

由于数据库往往是相当庞大的基础设施，这种方法可能不可行，因此在微服务之间共享数据库是可以理解的权衡。

### 部署策略

当多个主机上运行微服务时，您可能会想知道分配资源的更好方式是哪种。让我们比较两种可能的方法。

#### 每个主机单个服务

使用这种模式，我们允许每个主机只为特定类型的微服务提供服务。主要好处是你可以调整机器以更好地适应所需的工作负载，并且服务是良好隔离的。当你提供额外大的内存或快速存储时，你可以确保它只用于需要它的微服务。服务也无法消耗比所分配的资源更多的资源。

这种方法的缺点是一些主机可能被低效利用。一个可能的解决方法是在必要时使用尽可能小的机器来满足微服务的要求，并在必要时对其进行扩展。然而，这种解决方法并不能解决主机本身的额外开销问题。

#### 每个主机多个服务

相反的方法是在一个主机上托管多个服务。这有助于优化机器的利用率，但也带来一些缺点。首先，不同的微服务可能需要不同的优化，因此在单个主机上托管它们仍然是不可能的。此外，使用这种方法，您失去了对主机分配的控制，因此一个微服务中的问题可能会导致共存的另一个微服务中断，即使后者在其他情况下不受影响。

另一个问题是微服务之间的依赖冲突。当微服务彼此不隔离时，部署必须考虑不同的可能依赖关系。这种模型也不太安全。

### 可观察性模式

在前面的部分中，我们提到微服务是有代价的。这个代价包括引入可观察性的要求，否则就会失去调试应用程序的能力。以下是一些与可观察性相关的模式。

#### 日志聚合

微服务像单片应用程序一样使用日志记录。日志不是存储在本地，而是被聚合并转发到一个中央设施。这样，即使服务本身宕机，日志也是可用的。以集中的方式存储日志还有助于关联来自不同微服务的数据。

#### 应用程序指标

要基于数据做出决策，首先需要一些数据来采取行动。收集应用程序指标有助于了解实际用户使用的应用程序行为，而不是合成测试中的行为。收集这些指标的方法有推送（应用程序主动调用性能监控服务）和拉取（性能监控服务定期检查配置的端点）。

#### 分布式跟踪

分布式跟踪不仅有助于调查性能问题，还有助于更好地了解应用程序在真实流量下的行为。与日志记录不同，日志跟踪关注的是单个事务的整个生命周期，从它起源于用户操作的地方开始。

#### 健康检查 API

由于微服务经常是自动化的目标，它们需要能够传达其内部状态。即使进程存在于系统中，也不意味着应用程序正在运行。对于开放的网络端口也是如此；应用程序可能正在监听，但还不能响应。健康检查 API 提供了一种外部服务确定应用程序是否准备处理工作负载的方法。自愈和自动扩展使用健康检查来确定何时需要干预。基本前提是给定的端点（例如`/health`）在应用程序表现如预期时返回 HTTP 代码`200`，如果发现任何问题，则返回不同的代码（或根本不返回）。

现在你已经了解了所有的优缺点和模式，我们将向你展示如何将单片应用程序分割并逐步转换为微服务。所提出的方法不仅限于微服务；它们在其他情况下也可能有用，包括单片应用程序。

# 构建微服务

关于单片应用程序有很多不同的观点。一些架构师认为单片应用程序本质上是邪恶的，因为它们不易扩展，耦合度高，难以维护。还有一些人声称，单片应用程序带来的性能优势可以抵消它们的缺点。紧密耦合的组件在网络、处理能力和内存方面需要的开销要少得多。

由于每个应用程序都有独特的业务需求，并在利益相关者的独特环境中运行，因此没有关于哪种方法更适合的通用规则。更令人困惑的是，在从单片应用程序迁移到微服务后，一些公司开始将微服务合并成宏服务。这是因为维护成千上万个单独的软件实例的负担太大，无法处理。

选择一种架构而不是另一种架构应该始终来自业务需求和对不同替代方案的仔细分析。将意识形态置于实用主义之前通常会导致组织内的大量浪费。当一个团队试图不顾一切地坚持某种方法，而不考虑不同的解决方案或不同的外部意见时，该团队就不再履行为工作提供正确工具的义务。

如果你正在开发或维护一个单片应用程序，你可能会考虑提高其可扩展性。本节介绍的技术旨在解决这个问题，同时使您的应用程序更容易迁移到微服务，如果您决定这样做的话。

瓶颈的三个主要原因如下：

+   内存

+   存储

+   计算

我们将向您展示如何处理每个问题，以开发基于微服务的可扩展解决方案。

## 外包内存管理

帮助微服务扩展的一种方法是外包它们的一些任务。可能会妨碍扩展努力的一个任务是内存管理和缓存数据。

对于单个单片应用程序，直接将缓存数据存储在进程内存中并不是问题，因为进程将是唯一访问缓存的进程。但是，对于一个进程的多个副本，这种方法开始显示一些问题。

如果一个副本已经计算了一部分工作负载并将其存储在本地缓存中，另一个副本并不知道这一事实，必须重新计算。这样，您的应用程序既浪费了计算时间（因为同样的任务必须执行多次），又浪费了内存（因为结果也分别存储在每个副本中）。

为了缓解这些挑战，考虑切换到外部内存存储，而不是在应用程序内部管理缓存。使用外部解决方案的另一个好处是，缓存的生命周期不再与应用程序的生命周期绑定。您可以重新启动和部署应用程序的新版本，缓存中已经存储的值将被保留。

这可能还会导致启动时间更短，因为您的应用程序在启动时不再需要执行计算。内存缓存的两种流行解决方案是 Memcached 和 Redis。

### Memcached

Memcached 于 2003 年发布，是这两者中较老的产品。它是一个通用的、分布式的键值存储。该项目的最初目标是通过将缓存值存储在内存中来卸载 Web 应用程序中使用的数据库。Memcached 是通过设计进行分布的。自版本 1.5.18 以来，可以在不丢失缓存内容的情况下重新启动 Memcached 服务器。这是通过使用 RAM 磁盘作为临时存储空间实现的。

它使用一个简单的 API，可以通过 telnet 或 netcat 操作，也可以使用许多流行的编程语言的绑定。虽然没有专门针对 C++的绑定，但可以使用 C/C++的`libmemcached`库。

### Redis

Redis 是比 Memcached 更新的项目，最初版本于 2009 年发布。自那时起，Redis 已经在许多情况下取代了 Memcached 的使用。与 Memcached 一样，它是一个分布式的、通用的、内存中的键值存储。

与 Memcached 不同，Redis 还具有可选的数据持久性。虽然 Memcached 操作的是简单字符串的键和值，但 Redis 还支持其他数据类型，例如以下内容：

+   字符串列表

+   字符串集

+   字符串的排序集

+   键和值都是字符串的哈希表

+   地理空间数据（自 Redis 3.2 起）

+   HyperLogLogs

Redis 的设计使其成为缓存会话数据、缓存网页和实现排行榜的绝佳选择。除此之外，它还可以用于消息队列。Python 的流行分布式任务队列库 Celery 使用 Redis 作为可能的代理之一，还有 RabbitMQ 和 Apache SQS。

微软、亚马逊、谷歌和阿里巴巴都在其云平台中提供基于 Redis 的托管服务。

C++中有许多 Redis 客户端的实现。两个有趣的实现是使用 C++17 编写的`redis-cpp`库（[`github.com/tdv/redis-cpp`](https://github.com/tdv/redis-cpp)）和使用 Qt 工具包的 QRedisClient（[`github.com/uglide/qredisclient`](https://github.com/uglide/qredisclient)）。

以下是从官方文档中摘取的`redis-cpp`用法示例，说明了如何在存储中设置和获取一些数据：

```cpp
#include <cstdlib>
#include <iostream>

#include <redis-cpp/execute.h>
#include <redis-cpp/stream.h>

int main() {
  try {
    auto stream = rediscpp::make_stream("localhost", "6379");

    auto const key = "my_key";

    auto response = rediscpp::execute(*stream, "set", key,
                                      "Some value for 'my_key'", "ex", 
                                      "60");

    std::cout << "Set key '" << key << "': " 
              << response.as<std::string>()
              << std::endl;

    response = rediscpp::execute(*stream, "get", key);
    std::cout << "Get key '" << key << "': " 
              << response.as<std::string>()
              << std::endl;
  } catch (std::exception const &e) {
    std::cerr << "Error: " << e.what() << std::endl;
    return EXIT_FAILURE;
  }
  return EXIT_SUCCESS;
}
```

正如您所看到的，该库处理不同数据类型的处理。该示例将值设置为字符串列表。

### 哪种内存缓存更好？

对于大多数应用程序，Redis 现在可能是一个更好的选择。它拥有更好的用户社区、许多不同的实现，并得到了良好的支持。除此之外，它还具有快照、复制、事务和发布/订阅模型。可以在 Redis 中嵌入 Lua 脚本，并且对地理空间数据的支持使其成为地理启用的 Web 和移动应用程序的绝佳选择。

然而，如果您的主要目标是在 Web 应用程序中缓存数据库查询的结果，那么 Memcached 是一个更简单的解决方案，开销更小。这意味着它应该更好地利用资源，因为它不必存储类型元数据或在不同类型之间执行转换。

## 外包存储

引入和扩展微服务时的另一个可能的限制是存储。传统上，本地块设备用于存储不属于数据库的对象（如静态 PDF 文件、文档或图像）。即使在今天，块存储仍然非常受欢迎，包括本地块设备和网络文件系统，如 NFS 或 CIFS。

虽然 NFS 和 CIFS 属于网络附加存储（NAS）的领域，但也有与在不同级别上运行的概念相关的协议：存储区域网络（SAN）。一些流行的协议包括 iSCSI、网络块设备（NBD）、以太网上的 ATA、光纤通道协议和以太网上的光纤通道。

另一种方法是针对分布式计算设计的集群文件系统：GlusterFS、CephFS 或 Lustre。然而，所有这些都作为块设备运行，向用户公开相同的 POSIX 文件 API。

作为亚马逊网络服务的一部分，提出了存储的新观点。亚马逊简单存储服务（S3）是对象存储。API 提供对存储在存储桶中的对象的访问。这与传统文件系统不同，因为文件、目录或索引节点之间没有区别。有存储桶和指向对象的键，对象是由服务存储的二进制数据。

## 外包计算

微服务的原则之一是一个进程只负责执行工作流的一部分。从单体架构迁移到微服务的一个自然步骤将是定义可能的长时间运行的任务，并将它们拆分为单独的进程。

这是任务队列背后的概念。任务队列处理管理任务的整个生命周期。与自己实现线程或多进程不同，使用任务队列，您将任务委托给异步处理任务的任务队列。任务可能在与发起进程相同的机器上执行，但也可能在具有专门要求的机器上运行。

任务及其结果是异步的，因此在主进程中没有阻塞。Web 开发中流行的任务队列示例包括 Python 的 Celery、Ruby 的 Sidekiq、Node.js 的 Kue 和 Go 的 Machinery。所有这些都可以与 Redis 一起使用作为代理。不幸的是，对于 C++，目前没有类似成熟的解决方案。

如果您认真考虑采用这种方法，一个可能的方法是直接在 Redis 中实现任务队列。Redis 及其 API 提供了支持这种行为所需的基本操作。另一种可能的方法是使用现有的任务队列之一，例如 Celery，并通过直接调用 Redis 来调用它们。然而，这并不被建议，因为它依赖于任务队列的实现细节，而不是文档化的公共 API。另一种方法是使用 SWIG 或类似方法提供的绑定来接口任务队列。

# 观察微服务

您构建的每个微服务都需要遵循一般的架构设计模式。微服务和传统应用程序之间的主要区别在于前者需要实现可观察性。

本节重点介绍了一些可观察性的方法。我们在这里描述了几种开源解决方案，当您设计系统时可能会发现有用。

## 记录

记录是一个即使您从未设计过微服务也应该熟悉的主题。日志（或日志文件）存储有关系统中发生事件的信息。系统可能指的是您的应用程序、您的应用程序运行的操作系统，或者您用于部署的云平台。这些组件中的每一个都可能提供日志。

日志被存储为单独的文件，因为它们提供了所有事件的永久记录。当系统变得无响应时，我们希望查询日志，并找出停机的可能根本原因。

这意味着日志也提供审计跟踪。因为事件是按时间顺序记录的，我们能够通过检查记录的历史状态来了解系统的状态。

为了帮助调试，日志通常是人类可读的。虽然日志也有二进制格式，但在使用文件存储日志时，这样的格式相当罕见。

### 使用微服务记录

这种日志记录方法本身与传统方法并没有太大区别。微服务通常不使用文本文件来存储日志，而是通常将日志打印到`stdout`。然后使用统一的日志层来检索和处理日志。要实现日志记录，您需要一个日志库，可以根据您的需求进行配置。

### 使用 spdlog 在 C++中记录日志

C++中一种流行且快速的日志库是`spdlog`。它使用 C++11 构建，可以作为仅头文件库或静态库使用（可减少编译时间）。

`spdlog`的一些有趣特性包括以下内容：

+   格式化

+   多个输出端：

+   轮换文件

+   控制台

+   Syslog

+   自定义（实现为单个函数）

+   多线程和单线程版本

+   可选的异步模式

`spdlog`可能缺少的一个功能是直接支持 Logstash 或 Fluentd。如果要使用这些聚合器之一，仍然可以配置`spdlog`以使用文件输出，并使用 Filebeat 或 Fluent Bit 将文件内容转发到适当的聚合器。

### 统一日志层

大多数情况下，我们无法控制所有使用的微服务。其中一些将使用一个日志库，而其他人将使用不同的日志库。更糟糕的是，格式将完全不同，它们的轮换策略也将不同。更糟糕的是，我们仍然希望将操作系统事件与应用程序事件相关联。这就是统一日志层发挥作用的地方。

统一日志层的目的之一是从不同来源收集日志。这种统一日志层工具提供了许多集成，并理解不同的日志格式和传输方式（如文件、HTTP 和 TCP）。

统一日志层还能够过滤日志。我们可能需要过滤以满足合规性，匿名化客户的个人信息，或保护我们服务的实现细节。

为了更容易在以后查询日志，统一日志层还可以在不同格式之间进行转换。即使您使用的不同服务将日志存储为 JSON、CSV 和 Apache 格式，统一的日志层解决方案也能够将它们全部转换为 JSON 以赋予它们结构。

统一日志层的最终任务是将日志转发到它们的下一个目的地。根据系统的复杂性，下一个目的地可能是存储设施或另一个过滤、转换和转发设施。

以下是一些有趣的组件，可以帮助您构建统一的日志层。

#### Logstash

Logstash 是最受欢迎的统一日志层解决方案之一。目前，它由 Elastic 公司拥有，该公司是 Elasticsearch 背后的公司。如果您听说过 ELK 堆栈（现在称为 Elastic Stack），Logstash 是该首字母缩写中的“L”。

Logstash 最初是用 Ruby 编写的，然后被移植到了 JRuby。不幸的是，这意味着它需要相当多的资源。因此，不建议在每台机器上运行 Logstash。相反，它主要用作轻量级的日志转发器，每台机器部署轻量级的 Filebeat 来执行收集。

#### Filebeat

Filebeat 是 Beats 系列产品的一部分。它的目标是提供一个轻量级的 Logstash 替代方案，可以直接与应用程序一起使用。

这样，Beats 提供了低开销，而集中式 Logstash 安装执行所有繁重的工作，包括转换、过滤和转发。

除了 Filebeat 之外，Beats 系列的其他产品如下：

+   用于性能的 Metricbeat

+   用于网络数据的 Packetbeat

+   用于审计数据的 Auditbeat

+   用于运行时间监控的心跳

#### Fluentd

Fluentd 是 Logstash 的主要竞争对手。它也是一些云提供商的首选工具。

由于其使用插件的模块化方法，您可以找到用于数据源（如 Ruby 应用程序、Docker 容器、SNMP 或 MQTT 协议）、数据输出（如 Elastic Stack、SQL 数据库、Sentry、Datadog 或 Slack）以及其他各种过滤器和中间件的插件。

Fluentd 应该比 Logstash 占用更少的资源，但仍然不是一个适合大规模运行的完美解决方案。与与 Fluentd 配合使用的 Filebeat 的对应物称为 Fluent Bit。

#### Fluent Bit

Fluent Bit 是用 C 编写的，提供了一个更快、更轻的解决方案，可以插入到 Fluentd 中。作为日志处理器和转发器，它还具有许多输入和输出的集成。

除了日志收集，Fluent Bit 还可以监视 Linux 系统上的 CPU 和内存指标。它可以与 Fluentd 一起使用，也可以直接转发到 Elasticsearch 或 InfluxDB。

#### Vector

虽然 Logstash 和 Fluentd 是稳定、成熟和经过验证的解决方案，但在统一日志层空间中也有一些更新的提议。

其中之一是 Vector，旨在通过单一工具处理所有可观察性数据。为了与竞争对手区分，它专注于性能和正确性。这也体现在技术选择上。Vector 使用 Rust 作为引擎，Lua 作为脚本语言（而不是 Logstash 和 Fluentd 使用的自定义领域特定语言）。

在撰写本文时，它尚未达到稳定的 1.0 版本，因此在这一点上，不应将其视为生产就绪。

### 日志聚合

日志聚合解决了由于过多数据而产生的另一个问题：如何存储和访问日志。统一的日志层使日志即使在机器故障时也可用，而日志聚合的任务是帮助我们快速找到我们正在寻找的信息。

允许存储、索引和查询大量数据的两种可能产品是 Elasticsearch 和 Loki。

#### Elasticsearch

Elasticsearch 是自托管日志聚合的最流行解决方案。这是（以前的）ELK Stack 中的“E”。它具有基于 Apache Lucene 的出色搜索引擎。

作为其领域的事实标准，Elasticsearch 具有许多集成，并且在社区和商业服务方面得到了很好的支持。一些云提供商提供 Elasticsearch 作为托管服务，这使得在应用程序中引入 Elasticsearch 变得更容易。除此之外，制造 Elasticsearch 的 Elastic 公司还提供了一个不与任何特定云提供商绑定的托管解决方案。

#### Loki

Loki 旨在解决 Elasticsearch 中发现的一些缺点。Loki 的重点领域是水平扩展性和高可用性。它是从头开始构建的云原生解决方案。

Loki 的设计选择受到 Prometheus 和 Grafana 的启发。这并不奇怪，因为它是由负责 Grafana 的团队开发的。

虽然 Loki 应该是一个稳定的解决方案，但它并不像 Elasticsearch 那样受欢迎，这意味着可能会缺少一些集成，文档和社区支持也不会像 Elasticsearch 那样。Fluentd 和 Vector 都有支持 Loki 进行日志聚合的插件。

### 日志可视化

我们想考虑的日志堆栈的最后一部分是日志可视化。这有助于我们查询和分析日志。它以一种易于访问的方式呈现数据，因此所有感兴趣的方都可以检查，如运营商、开发人员、QA 或业务。

日志可视化工具使我们能够创建仪表板，使我们更容易阅读我们感兴趣的数据。有了这个，我们能够探索事件，寻找相关性，并从简单的用户界面中找到异常数据。

有两个专门用于日志可视化的主要产品。

#### Kibana

Kibana 是 ELK Stack 的最后一个元素。它在 Elasticsearch 之上提供了一个更简单的查询语言。尽管您可以使用 Kibana 查询和可视化不同类型的数据，但它主要专注于日志。

与 ELK Stack 的其他部分一样，它目前是可视化日志的事实标准。

#### Grafana

Grafana 是另一个数据可视化工具。直到最近，它主要专注于性能指标的时间序列数据。然而，随着 Loki 的引入，它现在也可以用于日志。

它的一个优点是它是以可插拔后端为目标构建的，因此很容易切换存储以适应您的需求。

## 监控

监控是从系统中收集与性能相关的指标的过程。与警报配对时，监控帮助我们了解系统何时表现如预期，以及何时发生故障。

我们最感兴趣的三种类型的指标如下：

+   可用性，让我们知道我们的资源中哪些是正常运行的，哪些已经崩溃或变得无响应。

+   资源利用率让我们了解工作负载如何适应系统。

+   性能，它向我们展示了在哪里以及���何改进服务质量。

监控的两种模型是推送和拉取。在前者中，每个受监视的对象（机器、应用程序和网络设备）定期将数据推送到中心点。在后者中，对象在配置的端点呈现数据，监控代理定期抓取数据。

拉取模型使得扩展更容易。这样，多个对象不会阻塞监控代理连接。相反，多个代理可以在准备好时收集数据，从而更好地利用可用资源。

两个具有 C++客户端库的监控解决方案是 Prometheus 和 InfluxDB。Prometheus 是一个拉取模型的例子，它专注于收集和存储时间序列数据。InfluxDB 默认使用推送模型。除了监控，它还在物联网、传感器网络和家庭自动化方面很受欢迎。

Prometheus 和 InfluxDB 通常与 Grafana 一起用于可视化数据和管理仪表板。两者都内置了警报功能，但也可以通过 Grafana 与外部警报系统集成。

## 跟踪

跟踪提供的信息通常比事件日志更低级。另一个重要的区别是，跟踪存储每个事务的 ID，因此很容易可视化整个工作流程。这个 ID 通常被称为跟踪 ID、事务 ID 或相关 ID。

与事件日志不同，跟踪不是为了人类可读。它们由跟踪器处理。在实施跟踪时，有必要使用一个能够与系统的所有可能元素集成的跟踪解决方案：前端应用程序、后端应用程序和数据库。这样，跟踪有助于准确定位性能滞后的确切原因。

### OpenTracing

分布式跟踪中的一个标准是 OpenTracing。这个标准是由 Jaeger 的作者提出的，Jaeger 是一个开源的跟踪器。

OpenTracing 支持许多不同的跟踪器，除了 Jaeger，它还支持许多不同的编程语言。最重要的包括以下内容：

+   Go

+   C++

+   C#

+   Java

+   JavaScript

+   Objective-C

+   PHP

+   Python

+   Ruby

OpenTracing 最重要的特性是它是供应商中立的。这意味着一旦我们对应用程序进行了仪器化，我们就不需要修改整个代码库来切换到不同的跟踪器。这样，它可以防止供应商锁定。

### Jaeger

Jaeger 是一个跟踪器，可以与包括 Elasticsearch、Cassandra 和 Kafka 在内的各种后端一起使用。

它与 OpenTracing 兼容，这并不奇怪。由于它是一个 Cloud Native Computing Foundation 毕业的项目，它有很好的社区支持，这也意味着它与其他服务和框架的集成很好。

### OpenZipkin

OpenZipkin 是 Jaeger 的主要竞争对手。它已经在市场上存在了更长的时间。尽���这应该意味着它是一个更成熟的解决方案，但与 Jaeger 相比，它的受欢迎程度正在下降。特别是，OpenZipkin 中的 C++并没有得到积极的维护，这可能会导致未来的维护问题。

## 集成的可观察性解决方案

如果您不想自己构建可观察性层，那么有一些受欢迎的商业解决方案可能会考虑。它们都以软件即服务模式运行。我们不会在这里进行详细的比较，因为它们的提供可能在本书编写后发生重大变化。

这些服务如下：

+   Datadog

+   Splunk

+   Honeycomb

在本节中，您已经看到了在微服务中实现可观察性。接下来，我们将继续学习如何连接微服务。

# 连接微服务

微服务非常有用，因为它们可以以许多不同的方式与其他服务连接，从而创造新的价值。然而，由于微服务没有标准，因此连接它们的方法也没有统一的方式。

这意味着大多数情况下，当我们想要使用特定的微服务时，我们必须学会如何与其交互。好消息是，尽管在微服务中可以实现任何通信方法，但有一些流行的方法是大多数微服务遵循的。

在设计围绕微服务的架构时，如何连接微服务只是一个相关问题之一。另一个问题是连接到什么以及在哪里连接。这就是服务发现发挥作用的地方。通过服务发现，我们让微服务使用自动化手段发现和连接应用程序中的其他服务。

这三个问题，如何、什么和在哪里，将是我们接下来的话题。我们将介绍一些现代微服务使用的最流行的通信和发现方法。

## 应用程序编程接口（API）

就像软件库一样，微服务通常会暴露 API。这些 API 使得与微服务进行通信成为可能。由于典型的通信方式利用计算机网络，API 的最流行形式是 Web API。

在上一章中，我们已经涵盖了一些可能的网络服务方法。如今，微服务通常使用基于**表述状态转移**（**REST**）的网络服务。

## 远程过程调用

虽然诸如 REST 之类的 Web API 允许轻松调试和良好的互操作性，但与数据转换和使用 HTTP 进行传输相关的开销很大。

这种开销对一些微服务来说可能太大了，这就是轻量级**远程过程调用**（**RPCs**）的原因。

### Apache Thrift

Apache Thrift 是一种接口描述语言和二进制通信协议。它用作一种 RPC 方法，允许创建用多种语言构建的分布式和可扩展服务。

它支持多种二进制协议和传输方法。每种编程语言都使用本机数据类型，因此即使在现有代码库中也很容易引入。

### gRPC

如果您真的关心性能，通常会发现基于文本的解决方案不适合您。然而，REST 虽然优雅且易于理解，但可能对您的需求来说太慢了。如果是这种情况，您应该尝试围绕二进制协议构建您的 API。其中一种日益流行的协议是 gRPC。

gRPC，顾名思义，是最初由 Google 开发的 RPC 系统。它使用 HTTP/2 进行传输，并使用协议缓冲区作为多种编程语言之间的**接口描述语言**（**IDL**）以及数据序列化的可互操作性。也可以使用替代技术，例如 FlatBuffers。gRPC 可以同步和异步使用，并允许创建简单服务和流式服务。

假设您已决定使用`protobufs`，我们的 Greeter 服务定义可以如下所示：

```cpp
service Greeter {
 rpc Greet(GreetRequest) returns (GreetResponse);
}

message GreetRequest {
 string name = 1;
}

message GreetResponse {
 string reply = 1;
}
```

使用`protoc`编译器，您可以从此定义创建数据访问代码。假设您想为我们的 Greeter 创建一个同步服务器，可以按以下方式创建服务：

```cpp
class Greeter : public Greeter::Service {
  Status sendRequest(ServerContext *context, const GreetRequest 
*request,
                     GreetReply *reply) override {
    auto name = request->name();
    if (name.empty()) return Status::INVALID_ARGUMENT;
    reply->set_result("Hello " + name);
    return Status::OK;
  }
};
```

然后，您必须构建并运行服务器：

```cpp
int main() {
  Greeter service;
  ServerBuilder builder;
  builder.AddListeningPort("localhost", grpc::InsecureServerCredentials());
  builder.RegisterService(&service);

  auto server(builder.BuildAndStart());
  server->Wait();
}
```

就是这么简单。现在让我们来看一个用于消费此服务的客户端：

```cpp
  #include <grpcpp/grpcpp.h>

  #include <string>

  #include "grpc/service.grpc.pb.h"

  using grpc::ClientContext;
  using grpc::Status;

  int main() {
    std::string address("localhost:50000");
    auto channel =
        grpc::CreateChannel(address, grpc::InsecureChannelCredentials());
    auto stub = Greeter::NewStub(channel);

    GreetRequest request;
    request.set_name("World");

    GreetResponse reply;
    ClientContext context;
    Status status = stub->Greet(&context, request, &reply);

    if (status.ok()) {
      std::cout << reply.reply() << '\n';
    } else {
      std::cerr << "Error: " << status.error_code() << '\n';
    }
  }
```

这是一个简单的同步示例。要使其异步工作，您需要添加标签和`CompletionQueue`，如 gRPC 网站上所述。

gRPC 的一个有趣特性是它适用于 Android 和 iOS 上的移动应用程序。这意味着如果您在内部使用 gRPC，则无需提供额外的服务器来转换来自移动应用程序的流量。

在本节中，您了解了微服务使用的最流行的通信和发现方法。接下来，我们将看到如何扩展微服务。

# 扩展微服务

微服务的一个重要好处是它们比单体应用程序更有效地扩展。在相同的硬件基础设施下，您理论上可以从微服务中获得比单体应用程序更高的性能。

在实践中，好处并不那么直接。微服务及其相关辅助工具也会提供开销，对于规模较小的应用程序，可能不如最佳单体应用程序高效。

请记住，即使某些东西在“纸上”看起来不错，也不意味着它会成功。如果您想基于可扩展性或性能做出架构决策，最好准备计算和实验。这样，您将根据数据而不仅仅是情感行事。

## 每个主机部署单个服务的扩展

对于每个主机部署的单个服务，扩展微服务需要添加或删除承载微服务的额外机器。如果您的应用程序在云架构（公共或私有）上运行，许多提供商提供称为自动缩放组的概念。

自动缩放组定义了将在所有分组实例上运行的基本虚拟机映像。每当达到临界阈值（例如 80%的 CPU 使用）时，将创建一个新实例并将其添加到组中。由于自动缩放组在负载均衡器后运行，因此增加的流量将在现有实例和新实例之间分配，从而降低每个实例的平均负载。当流量激增后，扩展控制器会关闭多余的机器，以保持成本低廉。

不同的指标可以作为扩展事件的触发器。CPU 负载是最容易使用的指标之一，但可能不是最准确的指标。其他指标，例如队列中的消息数量，可能更适合您的应用程序。

以下是一个用于缩放策略的 Terraform 配置摘录：

```cpp
autoscaling_policy {
    max_replicas = 5
    min_replicas = 3

    cooldown_period = 60

    cpu_utilization {
      target = 0.8
    }
}
```

这意味着在任何给定时间，至少会有三个实例运行，最多为五个实例。一旦 CPU 负载达到所有组实例的平均 80%，扩展器将触发。发生这种情况时，将会启动一个新实例。新机器的指标只有在其运行至少 60 秒后才会被收集（冷却期）。

## 每个主机部署多个服务的扩展

这种扩展模式也适用于每个主机部署多个服务。您可能可以想象，这并不是最有效的方法。仅基于单个服务的减少吞吐量来扩展整套服务类似于扩展单体应用程序。

如果您使用此模式，扩展微服务的更好方法是使用编排器。如果您不想使用容器，Nomad 是一个与许多不同执行驱动程序兼容的绝佳选择。对于容器化工作负载，Docker Swarm 或 Kubernetes 都会帮助您。编排器是我们将在接下来的两章中回顾的一个主题。

# 总结

微服务是软件架构中的一个伟大新趋势。只要确保您了解危险并为其做好准备，它们可能会很合适。本章解释了帮助引入微服务的常见设计和迁移模式。我们还涵盖了诸如可观察性和连接性之类的高级主题，在建立基于微服务的架构时至关重要。

到目前为止，您应该能够将应用程序设计和分解为单独的微服务。然后，每个微服务都能够处理一部分工作负载。

虽然微服务本身是有效的，但它们在与容器结合使用时尤其受欢迎。容器是下一章的主题。

# 问题

1.  为什么微服务能帮助您更好地利用系统资源？

1.  微服务和单体架构如何共存（在不断发展的系统中）？

1.  哪种类型的团队最能从微服务中受益？

1.  引入微服务时为什么需要成熟的 DevOps 方法？

1.  统一的日志记录层是什么？

1.  日志记录和跟踪有何不同？

1.  为什么 REST 可能不是连接微服务的最佳选择？

1.  微服务的部署策略是什么？每种策略的好处是什么？

# 进一步阅读

+   *掌握分布式跟踪*：[`www.packtpub.com/product/mastering-distributed-tracing/9781788628464`](https://www.packtpub.com/product/mastering-distributed-tracing/9781788628464)

+   *使用 Kubernetes 进行微服务实践*：[`www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468`](https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468)

+   *Martin Fowler 的微服务*：[`martinfowler.com/articles/microservices.html`](https://martinfowler.com/articles/microservices.html)

+   微服务架构：[`microservices.io/`](https://microservices.io/)
