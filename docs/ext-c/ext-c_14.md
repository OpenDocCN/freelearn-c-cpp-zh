# 第十四章

# 同步

在上一章中，我们介绍了并发的基本概念和广泛使用的术语。在本章中，我们将关注使用程序中的并发可能引起的问题。像上一章一样，我们不会处理任何 C 源代码；相反，我们将专注于并发问题和解决它们的概念和理论背景。

作为本章的一部分，我们将学习以下内容：

+   **与并发相关的问题，即竞态条件和数据竞争**：我们将讨论多个任务之间共享状态的影响，以及同时访问共享变量如何导致问题。

+   **用于同步访问共享状态的并发控制技术**：我们将主要从理论角度讨论这些技术，并解释我们可以采取的方法来克服与并发相关的问题。

+   **POSIX 中的并发**：作为这个主题的一部分，我们将讨论 POSIX 如何标准化我们开发并发程序的方式。我们将简要解释并比较多线程和多进程程序。

在第一部分，我们将进一步讨论并发环境的非确定性如何导致并发问题，正如我们在上一章中提到的。我们还将讨论如何对这些问题进行分类。

# 并发问题

在上一章中，我们已经看到，当一些并发任务能够改变共享状态值时，可修改的共享状态可能会引起问题。进一步探讨这个问题，我们可能会问，可能会出现什么类型的问题？它们背后的主要原因是什么？我们将在本节中回答这些问题。

首先，我们需要区分可能发生的不同类型的并发问题。一些并发问题只有在没有并发控制机制的情况下才会存在，而另一些则是通过使用并发控制技术引入的。

关于第一组问题，它们发生在你可以看到不同的交错导致不同的*整体状态*时。在识别出这些问题之一后，下一步当然就是开始考虑一个合适的修复方案来解决该问题。

关于第二组问题，它们只有在实施修复措施之后才会出现。这意味着当你修复一个并发问题时，你可能会引入一个具有完全不同性质和不同根本原因的新问题；这就是并发程序难以处理的原因。

例如，假设您有许多任务，这些任务都具有对同一共享数据源的读写访问权限。在多次运行任务后，您发现为不同任务编写的算法并没有按预期工作。这导致意外崩溃或随机发生的逻辑错误。由于崩溃和错误结果的发生是随机的，不可预测的，您可以合理地假设这可能是并发问题。

您开始反复分析算法，最终找到问题；在共享数据源上存在*数据竞争*。现在您需要想出一个解决方案来尝试控制对共享数据源的访问。您实施了一个解决方案并再次运行系统，令人惊讶的是，您发现有时某些任务根本无法访问数据源。我们技术上称这些任务为*饥饿*。由于您的更改引入了一个与第一个问题完全不同性质的新问题！

因此，我们现在有两种不同的并发问题组，它们是：

+   在没有控制（同步）机制的情况下存在于并发系统中的问题。我们称它们为*固有并发问题*。

+   在第一组问题尝试解决后发生的问题。我们称它们为*后同步问题*。

将第一组称为*固有*的原因是因为这些问题在所有并发系统中固有存在。您无法避免它们，您必须通过使用控制机制来处理它们。从某种意义上说，它们可以被视为并发系统的属性，而不是问题。尽管如此，我们将它们视为问题，因为它们的非确定性性质干扰了我们开发所需确定性程序的能力。

第二组问题仅在您错误地使用控制机制时才会出现。请注意，控制机制本身并不存在问题，实际上它们是必要的，可以将确定性带回我们的程序中。然而，如果它们被错误地使用，它们可能会导致二级并发问题。这些二级问题，或称为并发后的问题，可以被视为程序员引入的新错误，而不是并发系统的固有属性。

在接下来的章节中，我们将介绍两组问题。首先，我们从固有问题开始，并讨论在并发环境中存在这些固有问题属性的主要原因。

# 固有并发问题

每个具有多个任务的并发系统都可以有许多可能的交错，这可以被视为系统的固有属性。根据我们迄今为止所学的知识，我们知道这种属性具有非确定性，这导致不同任务的指令在每个运行中以混乱的顺序执行，同时仍然遵循*发生之前约束*。请注意，这已经在上一章中解释过了。

交错本身并不是问题，正如我们之前解释的，它们是并发系统的固有属性。但在某些情况下，这种属性不能满足一些旨在保持的约束。这正是交错产生问题的时刻。

我们知道在多个任务并发执行时，可能会有许多交错。但问题只会在系统的某个约束（本应是不变的）在运行之间被交错改变时出现。因此，我们的目标是采用一些控制机制，有时被称为*同步机制*，以保持该约束不变和不变性。

这个约束通常通过一系列条件和标准来表示，从现在起我们将它们称为*不变约束*。这些约束可以涉及并发系统中的几乎所有内容。

不变约束可以是某些非常简单的东西，就像我们在前几章中给出的例子，其中程序应该在输出中打印两个 3。它们也可以非常复杂，比如在一个巨大的并发软件程序中保持所有外部数据源的数据完整性。

**注意**：

产生每个可能的交错是非常困难的。在某些情况下，特定的交错只有极低的概率才能发生。如果发生，可能只在一百万次中发生一次。

这是并发开发中另一个危险的方面。虽然某些交错可能只在一百万次中发生一次，但当它们出错时，错误会非常严重。例如，它们可能导致飞机坠毁或在脑部手术期间严重设备故障！

每个并发系统都有一些定义最不明确的不变约束。随着我们进入本章，我们将给出例子，并且对于每一个例子，我们将讨论其不变约束。这是因为我们需要这些约束来设计一个特定的并发系统，该系统能够满足这些约束并保持它们的不变性。

在并发系统中发生的交错应该满足已经定义的不变约束。如果不满足，系统就存在问题。这就是不变约束变得非常重要的地方。每当有交错不满足系统的不变约束时，我们说系统中存在*竞争条件*。

竞态条件是由并发系统的内在属性或换句话说，交错操作引起的。每当出现竞态条件时，系统的不变约束就有可能被忽略。

未满足不变约束条件的结果可能表现为逻辑错误或突然崩溃。有许多例子表明，存储在共享变量中的值并没有反映真实状态。这主要是因为存在不同的交错操作，破坏了共享变量的*数据完整性*。

我们将在本章后面解释与数据完整性相关的问题，但现在，让我们看看以下例子。正如我们之前所说的，我们必须在跳转到例子之前定义例子中的不变约束。*例子 14.1*在*代码框 14-1*中显示，只有一个不变约束，即共享`Counter`变量中的最终正确值应该是`3`。在这个例子中，有三个并发任务。每个任务都应该将`Counter`增加一，这是我们以下代码框中追求的逻辑：

```cpp
Concurrent System {
    Shared State {
      Counter : Integer = 0
    }

    Task T1 {
      A : Integer
        1.1\. A = Counter
        1.2\. A = A + 1
        1.2\. Counter = A
    }
    Task T2 {
      B : Integer
        2.1\. B = Counter
        2.2\. B = B + 1
        2.2\. Counter = B
    }
    Task T3 {
      A : Integer
        3.1\. A = Counter
        3.2\. A = A + 1
        3.2\. Counter = A
    }
}
```

代码框 14-1：三个并发任务操作单个共享变量的系统

在前面的代码框中，你可以看到用伪代码编写的并发系统。正如你所见，并发系统中有三个任务。还有一个共享状态的章节。在前面的系统中，`Counter`是唯一一个所有三个任务都可以访问的共享变量。

每个任务都可以有多个局部变量。这些局部变量仅对任务本身是私有的，其他任务无法看到它们。这就是为什么我们可以有两个具有相同`A`的局部变量，但每个变量都是不同的，并且仅属于其所有者任务。

注意，任务不能直接操作共享变量，它们只能读取或更改它们的值。这就是为什么你需要有一些局部变量的基本原因。正如你所见，任务只能增加局部变量，而不能直接增加共享变量。这与我们在多线程和多进程系统中看到的情况非常一致，这就是为什么我们选择了前面的配置来表示并发系统。

在*代码框 14-1*中展示的例子告诉我们，竞态条件可能导致逻辑错误。很容易找到一个交错操作，导致共享`Counter`变量的值为`2`。只需查看*代码框 14-2*中的交错操作：

```cpp
  Task Scheduler |    Task T1   |    Task T2   |  Task T3
---------------------------------------------------------
  Context Switch |              |              |
                 |  A = Counter |              | 
                 |  A = A + 1   |              | 
                 |  Counter = A |              | 
  Context Switch |              |              |
                 |              |  B = Counter |
                 |              |  B = B + 1   |
  Context Switch |              |              |
                 |              |              |  A = Counter
  Context Switch |              |              |
                 |              |  Counter = B |
  Context Switch |              |              |
                 |              |              |  A = A + 1
                 |              |              |  Counter = A
```

代码框 14-2：违反代码框 14.1 中定义的不变约束条件的交错操作

在这里，很容易追踪交错操作。指令`2.3`和`3.3`（如*代码框 14-1*所示）都在共享`Counter`变量中存储了值`2`。前面的情况被称为*数据竞争*，我们将在本节稍后详细解释。

下一个例子，在*代码框 14-3*中展示，演示了竞态条件如何导致崩溃。

**注意**：

在下一节中，我们将使用一个 C 伪代码示例。这是因为我们还没有介绍 POSIX API，这对于编写创建和管理线程或进程的 C 代码是必要的。

以下代码是一个示例，如果用 C 语言编写，可能会导致段错误：

```cpp
Concurrent System {
    Shared State {
      char *ptr = NULL; // A shared char pointer which is
                        // supposed to point to a memory
                        // address in the Heap space. It
                        // becomes null by default.
    }
    Task P {
        1.1\. ptr = (char*)malloc(10 * sizeof(char));
        1.2\. strcpy(ptr, "Hello!");
        1.3\. printf("%s\n", ptr);
    }
    Task Q {
        2.1\. free(ptr);
        2.2\. ptr = NULL;
    }
}
```

代码框 14-3：违反了代码框 14-1 中示例的不变约束的交织

我们在这个示例中关注的明显的不变约束之一是不要让任务崩溃，这在我们不变约束中是隐含包含的。如果一个任务无法完成其工作，那么首先拥有不变约束本身就是矛盾的。

有一些交织会导致前面的任务崩溃。接下来，我们将解释其中两种：

+   首先，假设指令 `2.1` 首先执行。由于 `ptr` 是空指针，因此任务 `Q` 将崩溃，而任务 `P` 继续执行。因此，在多线程使用场景中，如果两个任务（线程）属于同一进程，整个包含两个任务的程序将崩溃。崩溃的主要原因是在空指针上删除。

+   另一种交织情况是当指令 `2.2` 在 `1.2` 之前执行，但在 `1.1` 之后执行。在这种情况下，任务 `P` 将崩溃，而任务 `Q` 则无问题完成。崩溃的主要原因是对空指针进行解引用。

因此，正如你在前面的示例中看到的那样，并发系统中的竞态条件可能导致不同的情况，如逻辑错误或突然崩溃。显然需要妥善解决的两个问题。

值得花点时间确保我们理解，并非所有并发系统中的竞态条件都能轻易识别。一些竞态条件可能直到很久以后才会显现出来。这就是为什么我在本章开头说并发程序处理起来有问题的原因。

话虽如此，有时我们会使用 *竞态检测器* 来查找那些不太可能执行的代码分支中存在的竞态条件。实际上，它们可以用来识别导致竞态条件的交织。

**注意**：

竞态条件可以通过一组称为 *竞态检测器* 的程序来检测。它们根据是静态的还是动态的来分组。

*静态竞态检测器* 会遍历源代码，并尝试根据观察到的指令生成所有可能的交织，而 *动态竞态检测器* 首先运行程序，然后等待一个疑似竞态条件的代码执行。两者结合使用，以降低出现竞态条件的风险。

现在，是时候提出一个问题了。所有竞态条件背后是否有一个单一的根本原因？我们需要回答这个问题，以便提出一个能够消除竞态条件的解决方案。我们知道，每当一个交错操作不满足不变性约束时，就会发生竞态条件。因此，为了回答这个问题，我们需要对可能的不变性约束进行更深入的分析，并看看它们是如何被忽略的。

从我们在各种并发系统中观察到的结果来看，为了保持不变性约束得到满足，总有一些指令在不同的任务中找到，这些指令应该在所有交错操作中严格按顺序执行。

因此，遵循这个顺序的交错操作不会违反不变性约束。我们对这些交错操作感到满意，并观察到期望的输出。那些不保持严格顺序的交错操作将不满足不变性约束，因此可以被认为是问题交错操作。

对于这些交错操作，我们需要采用机制来恢复顺序并确保不变性约束始终得到满足。*示例 14.2*可以在*代码框 14-4*中看到。应该保持不变性的约束是**在输出中打印 1**。虽然这个约束有点不成熟，你不会在真实的并发应用中看到它，但它有助于我们理解我们正在讨论的概念：

```cpp
Concurrent System {
  Shared State {
    X : Integer = 0
  }
  Task P {
      1.1\. X = 1
  }
  Task Q {
      2.1\. print X
  }
}
```

代码框 14-4：一个存在竞态条件的非常简单的并发系统

前面的例子可以根据其交错操作有两个不同的输出。如果我们想在输出中打印`1`，这是由不变性约束强制执行的，那么我们需要为两个不同的任务中的指令定义一个严格的顺序。

为了这个目的，打印指令`2.1`必须只在指令`1.1`之后执行。由于存在另一个容易违反这种顺序的交错操作，因此违反了不变性约束，所以我们有竞态条件。我们需要在这些指令之间保持严格的顺序。然而，将它们放入期望的顺序并不是一件容易的事情。我们将在本章后面讨论恢复这种顺序的方法。

让我们看看下面的*示例 14.3*。在下面的代码中，我们有一个由三个任务组成的系统。我们应该注意，在这个系统中没有共享状态。然而，尽管如此，我们仍然有竞态条件。让我们定义以下系统的不变性约束为**始终先打印 1，然后是 2，最后是 3**：

```cpp
Concurrent System {
  Shared State {
  }
  Task P {
      1.1\. print 3
  }
  Task Q {
      2.1\. print 1
  }
  Task R {
      3.1\. print 2
  }
}
```

代码框 14-5：另一个非常简单的并发系统，存在竞态条件但没有共享状态

即使在这个非常简单的系统中，你也无法保证哪个任务会先开始，正因为如此，我们才有了竞态条件。因此，为了满足不变性约束，我们需要按照以下顺序执行指令：`2.1`，`3.1`，`1.1`。这个顺序必须在所有可能的交错操作中保持。

上述例子揭示了竞争条件的一个重要特性，即：在并发系统中，要产生竞争条件，我们不需要有共享状态。相反，为了避免竞争条件，我们需要始终保持某些指令的严格顺序。我们应该注意，竞争条件仅因为一小部分指令（通常称为临界区）执行顺序不当而出现，而其他指令可以按任何顺序执行。

同时拥有可写共享状态和针对该共享状态的具体不变约束，可以在针对该共享状态的读和写指令之间强加一个严格的顺序。关于可写共享状态的最重要约束之一是数据完整性。这简单意味着所有任务都应该始终能够读取共享状态的最新和最新鲜的值，并且在继续执行修改共享状态的自身指令之前，应该意识到对共享状态所做的任何更新。

*示例 14.4*，如*代码框 14-6*所示，解释了数据完整性约束，更重要的是，它说明了它如何容易被忽略：

```cpp
Concurrent System {
  Shared State {
    X : Integer = 2
  }
  Task P {
    A : Integer
      1.1\. A = X
      1.2\. A = A + 1
      1.3\. X = A
  }
  Task Q {
    B : Integer
      2.1\. B = X
      2.2\. B = B + 3
      2.3\. X = B
  }
}
```

代码框 14-6：一个因共享变量 X 的数据竞争而受苦的并发系统

考虑以下交错情况。首先，执行指令`1.1`。因此，`X`的值被复制到局部变量`A`。然而，任务`P`并不幸运，所以发生上下文切换，CPU 被分配给任务`Q`。然后执行指令`2.1`，接着将`X`的值复制到局部变量`B`。因此，变量`A`和`B`都有相同的值，`2`。

现在，任务`Q`很幸运，可以继续执行。然后执行指令`2.2`，`B`变为`5`。任务`Q`继续并将值`5`写入共享状态`X`。因此，`X`变为`5`。

现在，发生下一个上下文切换，CPU 被交还给任务`P`。它继续执行指令`1.2`。这就是完整性约束被遗漏的地方。

共享状态`X`已被任务`Q`更新，但任务`P`使用旧值`2`进行其余的计算。最终，它将`X`的值重置为`3`，这几乎不是程序员希望得到的结果。为了保持数据完整性的约束得到满足，我们必须确保指令`1.1`仅在指令`2.3`之后执行，或者指令`2.1`仅在指令`1.3`之后执行，否则数据完整性可能会受到损害。

**注意**：

你可能会问自己，为什么我们使用了局部变量`A`和`B`，而不是简单地写`X = X + 1`或`X = X + 3`。

正如我们在上一章中解释的，指令`X = X + 1`，在 C 语言中写作`X++`，不是一个*原子*指令。它仅仅意味着它不能在单个指令中完成，需要多个指令。这是因为我们在对变量进行操作时，永远不会直接访问内存中的变量。

我们总是使用一个临时变量，或者 CPU 寄存器，来保存最新的值，并在临时变量或寄存器上执行操作，然后将结果传回内存。因此，无论你如何编写它，总会有一个与任务本地关联的临时变量。

你会发现，在具有多个 CPU 核心的系统中的情况更糟。我们还有 CPU 缓存，它会缓存变量，并且不会立即将结果传回主内存中的变量。

让我们再讨论另一个定义。当某些交错顺序使与共享状态相关的数据完整性约束无效时，我们说我们在该共享状态下有一个数据竞争。

数据竞争与竞态条件非常相似，但为了产生数据竞争，我们需要在不同任务之间有一个共享状态，并且这个共享状态必须至少可以被其中一个任务修改（可写）。换句话说，共享状态不应该对所有任务都是只读的，而且至少应该有一个任务可能会根据其逻辑向共享状态写入。

正如我们之前所说的，对于只读共享状态，我们*不能*有数据竞争。这是由于这样一个事实：由于共享状态的价值不能被修改，因此无法破坏只读共享状态的数据完整性。

*示例 14.5*，在*代码框 14-7*中展示，说明了我们如何产生竞态条件，同时在一个只读的共享状态下不可能发生数据竞争：

```cpp
Concurrent System {
  Shared State {
    X : Integer (read-only) = 5
  }
  Task P {
    A : Integer
      1.1\. A = X
      1.2\. A = A + 1
      1.2\. print A
  }
  Task Q {
      2.1\. print X
  }
  Task R {
    B : Integer
      3.1\. B = X + 1
      3.2\. B = B + 1
      3.3\. print B
  }
}
```

代码框 14-7：具有只读共享状态的多线程系统

假设前一个示例的不变约束是**保持 X 的数据完整性，并首先打印 5，然后是 6，最后是 7**。当然，我们有一个竞态条件，因为不同的`print`指令之间需要一个严格的顺序。

然而，由于共享变量是只读的，因此不存在数据竞争。请注意，指令`1.2`和`3.2`只修改了它们的局部变量，因此它们不能被视为对共享状态的修改。

作为本节的最后一点：不要期望竞态条件能够轻易解决！你肯定需要采用一些同步机制，以便在来自不同任务的某些指令之间创建所需的顺序。这将迫使所有可能的交错顺序遵循给定的顺序。实际上，你将在下一节中看到，我们必须引入一些新的交错顺序，这些顺序遵循所需的顺序。

我们将在本章后面讨论这些机制；在那之前，我们需要解释在使用一些同步方法后出现的并发相关的问题。下一节将全部关于*同步后*的问题以及它们与内在问题的不同之处。

# 同步后问题

接下来，我们将讨论由于误用控制机制而预期会发生的三项关键问题。你可能会同时经历这些问题中的一个或所有这些问题，因为它们有不同的根本原因：

+   **新的内在问题**：应用控制机制可能会导致不同的竞争条件或数据竞争。控制机制是用来强制指令之间的严格顺序，这可能会导致新的内在问题出现。控制机制引入新的交错是体验新的并发相关行为和问题的基本原因。由于出现了新的竞争条件和新的数据竞争，新的逻辑错误和崩溃可能会发生。你必须通过所使用的同步技术，并根据你程序的逻辑进行调整，以修复这些新问题。

+   **饥饿**：当一个并发系统中的任务长时间无法访问共享资源，主要是因为采用了特定的控制机制，我们说该任务已经变得饥饿。饥饿的任务无法访问共享资源，因此无法有效地执行其目的。如果其他任务依赖于饥饿任务的协作，它们自己也可能变得饥饿。

+   **死锁**：当一个并发系统中的所有任务都在互相等待，没有任何一个任务在前进时，我们说达到了死锁。这主要由于控制机制被错误地应用，这反过来使得任务进入一个无限循环，等待其他任务释放共享资源或解锁锁对象等。这通常被称为*循环等待*。在任务等待期间，它们中的任何一个都无法继续执行，结果，系统将进入类似昏迷的状态。一些描述死锁情况的说明可以在[维基百科页面找到：h](https://en.wikipedia.org/wiki/Deadlock)ttps://en.wikipedia.org/wiki/Deadlock。

    在死锁情况下，所有任务都卡住了，互相等待。但通常情况下，只有一部分任务，可能只有一个或两个，卡住了，其余的可以继续。我们称这些为*半死锁*情况。我们将在接下来的章节中看到更多这样的半死锁情况。

+   **优先级反转**：存在这样的情况，在采用同步技术之后，一个优先级较高的任务使用共享资源时被一个低优先级任务阻塞，从而它们的优先级被反转。这是由于同步技术实现错误而可能发生的另一种次级问题。

并发系统中默认情况下不会出现饥饿；当没有同步技术被施加在操作系统的任务调度器上时，系统是公平的，不会允许任何任务出现饥饿。只有当程序员使用了某些控制机制时，才会导致饥饿。同样，死锁在并发系统中也不会出现，直到程序员介入。大多数死锁情况的主要原因是当锁被以这种方式使用时，并发系统中的所有任务都在等待彼此释放锁。通常，死锁在并发系统中比饥饿更常见。

现在，我们应该继续讨论控制机制。在下一节中，我们将讨论各种同步技术，这些技术可以用来克服竞争条件。

# 同步技术

在本节中，我们将讨论同步技术，或并发控制技术，或并发控制机制，这些技术被用来克服固有的并发相关问题。回顾我们之前所解释的内容，控制机制试图克服部分交错可能在一个系统中引起的问题。

每个并发系统都有自己的不变约束，并不是所有的交错都会满足所有这些约束。对于那些不满足系统不变约束的交错，我们需要发明一种方法来在指令之间施加特定的顺序。换句话说，我们应该*创建*满足不变约束的新交错，并用它们替换不良的交错。使用某种同步技术之后，我们将拥有一个完全新的具有一些新交错的并发系统，我们希望新系统将保持不变约束得到满足，并且不会产生任何同步后的问题。

注意，为了使用同步技术，我们需要编写新的代码并更改现有的代码。当你更改现有代码时，你实际上是在改变指令的顺序，从而改变交错。更改代码只是创建了一个新的具有新交错的并发系统。

新的交错是如何解决我们的并发问题的呢？通过引入新添加的工程交错，我们在不同任务的不同指令之间施加了一些额外的“发生之前”约束，从而保持不变约束得到满足。

注意，在单个任务中的两个相邻指令之间始终存在 happens-before 约束，但在并发系统中，两个不同任务的两个指令之间没有这些约束。通过使用同步技术，我们定义了一些新的 happens-before 约束，这些约束控制着两个不同任务之间执行的顺序。

拥有一个全新的并发系统意味着会面临新的、不同的问题。最初的并发系统是一个自然系统，其中任务调度器是唯一驱动上下文切换的实体。但在后来的系统中，我们面对的是一个人工和工程化的并发系统，其中任务调度器不是唯一的有效元素。用于保持系统不变性约束的并发控制机制是其他重要因素。因此，将在上一节中讨论的新问题，称为*后同步问题*，将会出现。

使用适当的控制技术来同步多个任务并使它们遵循特定的顺序取决于原始并发环境。例如，在多进程程序中使用的控制机制可能与在多线程程序中使用的机制不同。

由于这个原因，我们无法在不使用真实 C 代码的情况下详细讨论控制机制。因此，我们将以适用于所有并发系统、无论其实现方法如何的抽象方式来讨论它们。以下技术和概念在所有并发系统中都是有效的，但它们的实现方式极大地依赖于周围环境和系统的真实本质。

## 忙等待和自旋锁

作为一种通用解决方案，为了确保一个任务中的指令在另一个任务中的指令之后执行，前一个任务应该等待后一个任务首先执行其指令。在此期间，前一个任务可能会因为上下文切换而获得 CPU，但它不应该继续执行，而应该继续等待。换句话说，前一个任务应该暂停并等待，直到后一个任务执行了其指令。

当后一个任务能够完成其指令的执行时，有两种选择。要么前一个任务再次检查并看到后一个任务已经完成了其工作，要么应该有一种方式让后一个任务通知前一个任务，让它知道现在可以继续执行其指令。

描述的场景类似于两个人试图按照定义的顺序做某事的情况。其中一个人必须等待另一个人完成他们的工作，然后另一个人才能继续自己的工作。我们可以这样说，几乎所有控制机制都使用与此类似的方法，但它们的实现多种多样，并且主要取决于特定环境中的可用机制。我们将解释这些环境中的一个，即 POSIX 兼容的系统，以及其中可用的机制，作为本章最后部分的最后一部分。

让我们用一个例子来解释前面的控制技术，这是所有其他技术的核心。*示例 14.6*，在 *代码框 14-8* 中展示，是一个由两个并发任务组成的系统，我们希望定义的不变约束为**首先打印 A，然后打印 B**。在没有控制机制的情况下，代码框看起来如下：

```cpp
Concurrent System {
  Task P {
    1.1\. print 'A'
  }
  Task Q {
    2.1\. print 'B'
  }
}
```

代码框 14-8：在引入控制机制之前表示示例 14.6 的并发系统

很明显，我们有一个基于定义的不变约束的竞争条件。交织 `{2.1, 1.1}` 打印 `B` 然后是 `A`，这与不变约束相矛盾。因此，我们需要使用控制机制来保持前面指令之间的特定顺序。

我们希望只有在指令 `1.1` 执行之后才执行 `2.1`。以下在 *代码框 14-9* 中展示的伪代码演示了如何设计和应用之前解释的方法，以恢复指令之间的顺序：

```cpp
Concurrent System {
  Shared State {
    Done : Boolean = False
  }
  Task P {
    1.1\. print 'A'
    1.2\. Done = True
  }
  Task Q {
    2.1\. While Not Done Do Nothing
    2.2\. print 'B'
  }
}
```

代码框 14-9：使用忙等待解决示例 14.6 的解决方案

如您所见，我们不得不添加更多指令来同步任务。因此，看起来我们增加了一堆新的交织。更准确地说，我们面临的是一个与之前完全不同的并发系统。这个新系统有其自己的交织集，这些交织与旧系统中的交织不可比。

所有这些新的交织中有一个共同点，那就是指令 `1.1` 总是发生在指令 `2.2` 之前；这正是我们通过添加控制机制想要实现的目标。无论选择哪种交织方式或上下文切换如何发生，我们都强制在指令 `1.1` 和 `2.2` 之间建立了一个“先发生”的约束。

这怎么可能呢？在先前的系统中，我们引入了一个新的共享状态 `Done`，它是一个初始设置为 `False` 的布尔变量。每当任务 `P` 打印 `A` 时，它将 `Done` 设置为 `True`。然后，等待 `Done` 变为 `True` 的任务 `Q` 在第 `2.1` 行退出 `while` 循环并打印 `B`。换句话说，任务 `Q` 在 `while` 循环中等待，直到共享状态 `Done` 变为 `True`，这是任务 `P` 完成其 `print` 命令的指示。看起来提出的解决方案似乎一切正常，实际上它确实工作得很好。

尝试想象以下交错情况。当任务`P`失去 CPU 核心而任务`Q`获得 CPU 核心时，如果`Done`不为真，那么任务`Q`将保持在循环中，直到它再次失去 CPU 核心。这意味着，当任务`Q`拥有 CPU 核心时，所需的条件尚未满足，它不会离开循环，并试图使用其*时间片*来做几乎除了*轮询*和检查条件是否满足之外的事情。它一直做到 CPU 核心被收回。换句话说，任务`Q`等待并*浪费*了时间，直到 CPU 核心被归还给任务`P`，任务`P`现在可以打印`A`。

在技术术语中，我们说任务`Q`在满足特定条件之前处于*忙等待*状态。它持续监控（或轮询）一个条件，直到它变为真，然后退出忙等待。无论你称它为什么，任务`Q`尽管先前的解决方案完美解决了我们的问题，但仍然在浪费 CPU 的宝贵时间。

**注意**：

忙等待（Busy-waiting）并不是等待事件发生的有效方法，但它是一种简单的方法。由于在忙等待期间，任务无法执行任何特殊操作，它完全浪费了分配给它的时间片。在长时间等待中，通常会避免使用忙等待。浪费的 CPU 时间可以分配给其他任务，以便完成其部分工作。然而，在某些情况下，如果预计等待时间较短，则可以使用忙等待。

在实际的 C 程序中，以及其他编程语言中，*锁*通常用于强制执行某些严格的顺序。锁只是一个对象，或者是一个变量，我们使用它来等待某个条件满足或事件发生。请注意，在先前的例子中，`Done`不是一个锁，而是一个标志。

要理解术语*锁*，我们可以将其想象为在执行指令`2.2`之前尝试获取锁。只有获取到锁后，你才能继续并退出循环。在循环内部，我们正在等待锁变得可用。我们可以有各种类型的锁，我们将在未来的章节中解释。

在下一节中，我们将执行之前讨论的等待场景，但这次使用一种更有效的方法，不会浪费 CPU 核心的时间。它有许多名称，但我们可以称之为*等待/通知*或*休眠/通知*机制。

## 休眠/通知机制

与上一节中讨论的忙等待循环不同，我们可以想象另一种场景。任务`Q`可以选择休眠而不是在`Done`标志上忙等待，而任务`P`可以在将标志设置为`True`时通知它标志的变化。

换句话说，任务`Q`一旦发现标志不是`True`就会进入休眠状态，并让任务`P`更快地获取 CPU 核心并执行其逻辑。作为交换，任务`P`会在将标志修改为`True`后唤醒任务`Q`。实际上，这种方法是大多数操作系统的*实际*实现，以避免忙等待并更有效地引入控制机制。

以下伪代码演示了如何使用这种方法重写上一节给出的示例的解决方案：

```cpp
Concurrent System {
  Task P {
      1.1\. print 'A'
      1.2\. Notify Task Q
  }
  Task Q {
      2.1\. Go To Sleep Mode
      2.2\. print 'B'
  }
}
```

代码框 14-10：使用 sleep/notify 解决示例 14.6 的解决方案

在能够解释前面的伪代码之前，我们需要回顾一些新的概念。首先是任务如何*休眠*。只要任务处于休眠状态，它就不会获得任何 CPU 份额。当任务将自己置于休眠模式时，任务调度器会意识到这一点。之后，任务调度器不会给休眠中的任务分配任何时间片。

任务进入休眠状态的优点是什么？进入休眠状态的任务不会通过忙等待来浪费 CPU 时间。而不是启动忙等待来轮询条件，任务会进入休眠状态，并在条件满足时被通知。这将显著提高*CPU 利用率*因素，真正需要 CPU 份额的任务将获得它。

当一个任务进入休眠模式时，应该有一个机制来唤醒它。这个机制通常是通过*通知*或*信号*休眠中的任务来实现的。可以通知一个任务离开休眠模式，一旦它醒来并被通知，任务调度器就会将它放回队列，并再次给它分配 CPU。然后任务将在将其置于休眠模式的代码行之后继续执行。

在我们编写的代码中，任务`Q`一旦开始执行就会进入休眠模式。当它进入休眠模式时，它将不会获得任何 CPU 份额，直到它被任务`P`通知并唤醒。任务`P`只有在打印了`A`之后才会通知任务`Q`。然后，任务`Q`醒来并获取 CPU，然后继续并打印`B`。

使用这种方法没有忙等待，也没有浪费 CPU 时间。注意，当进入休眠模式并通知休眠中的任务时，两者都有特定的系统调用，并且大多数操作系统都支持，尤其是符合 POSIX 标准的操作系统。

乍一看，似乎前面的解决方案已经解决了我们的问题，并且以高效的方式解决了——确实如此！然而，存在一种交错，会导致后续同步问题。这发生在你按照以下顺序执行前面的系统时：

```cpp
1.1 print 'A'
1.2\. Notify Task Q
2.1\. Go To Sleep Mode
2.2\. print 'B'
```

代码框 14-11：将代码框 14-10 中展示的并发系统置于半死锁状态

在前面的交错中，任务 `P` 打印了 `A`，然后它通知了任务 `Q`，因为任务 `Q` 还没有进入睡眠状态，因为它还没有获得 CPU。当任务 `Q` 获得 CPU 时，它会立即进入睡眠模式。然而，没有其他任务在运行来通知它。因此，任务 `Q` 将不会再次获得 CPU，仅仅是因为任务调度器不会将 CPU 核心分配给一个睡眠任务。这是使用同步技术并观察其后果作为后同步问题的第一个例子。

为了解决这个问题，我们再次需要使用一个布尔标志。现在，任务 `Q` 在进入睡眠状态之前应该检查标志。这是我们的最终解决方案：

```cpp
Concurrent System {
  Shared State {
    Done : Boolean = False
  }
  Task P {
      1.1\. print 'A'
      1.2\. Done = True
      1.3\. Notify Task Q
  }
  Task Q {
      2.1\. While Not Done {
      2.2\.     Go To Sleep Mode If Done is False (Atomic)
      2.3\. }
      2.4\. print 'B'
  }
}
```

代码框 14-12：基于睡眠/通知方法的示例 14.6 的改进解决方案

正如你在前面的伪代码中所看到的，如果标志 `Done` 没有被设置为 `True`，任务 `Q` 会进入睡眠状态。指令 `2.2` 被放在一个循环中，该循环简单地检查标志，并且只有在 `Done` 为 `False` 时才会进入睡眠状态。关于指令 `2.2` 的重要一点是，它必须是一个原子指令，否则解决方案就不完整，并且会遭受相同的问题。

**注意**:

对于那些对并发系统有一定经验的人来说，将此指令声明为原子操作可能有点令人惊讶。背后的主要原因是我们前面提到的例子中，真正的可感知的同步只有在定义一个清晰的临界区并使用互斥锁来保护它时才会发生。随着我们继续前进，这一点变得更加明显，在经过更多概念性主题之后，我们最终可以提供一个真实和实际的解决方案。

循环是必需的，因为睡眠中的任务可能被系统中的任何东西通知，而不仅仅是任务 `P`。在真实系统中，操作系统和其他任务可以通知一个任务，但在这里，我们只对从任务 `P` 收到的通知感兴趣。

因此，当任务被通知并唤醒时，它应该再次检查标志，如果标志尚未设置，则返回睡眠状态。正如我们之前解释的那样，根据我们到目前为止的解释，这个解决方案似乎有效，但它不是一个完整的解决方案，因为它也可能在具有多个 CPU 核心的机器上引起半死锁情况。我们将在 *多处理器单元* 这一部分进一步解释这一点。

**注意**:

基于等待/通知机制的解决方案通常使用条件变量来开发。条件变量在 POSIX API 中也有对应物，我们将在一个专门的章节中从概念上介绍它们，该章节将很快出现。

所有的同步机制都涉及某种形式的等待。这是保持某些任务同步的唯一方法。在某个时刻，其中一些应该等待，而另一些应该继续。这就是我们需要引入 *信号量* 的地方；这些是在并发环境中使逻辑等待或继续的标准工具。我们将在下一节中关注这一点。

## 信号量和互斥锁

在 20 世纪 60 年代，Edsger Dijkstra，一位非常著名的荷兰计算机科学家和数学家，和他的团队为 Electrologica X8 计算机设计了一个名为*THE Multiprogramming System*或*THE OS*的新操作系统，当时它拥有自己独特的架构。

在 Unix 和后来的 C 语言发明之前不到 10 年，贝尔实验室正在使用汇编语言编写 THE OS。THE OS 是一个多任务操作系统，它有一个多级架构。最高级是用户，最低级是任务调度器。在 Unix 术语中，最低级相当于在内核环中同时拥有*任务调度器*和*进程管理单元*。Dijkstra 和他的团队为了克服某些并发相关困难，以及在不同任务之间共享不同资源，发明了*信号量*这一概念。

信号量简单地说是变量，或者对象，用于同步对共享资源的访问。我们将在本节中详细解释它们，并介绍一种特定的信号量类型，即互斥锁（mutexes），它们在并发程序中广泛使用，并且几乎存在于今天的任何编程语言中。

当一个任务即将访问一个共享资源，这可能是一个简单的变量或一个共享文件时，该任务应该首先检查一个预定义的信号量，并请求继续访问共享资源的权限。我们可以用一个类似例子来解释信号量和它的作用。

想象一位医生和一些希望被医生接诊的病人。假设没有预约机制，病人可以随时去看医生。我们的医生有一位秘书管理病人，将他们排队，并授予他们进入医生办公室的权限。

我们假设医生可以同时看多个病人（达到一定数量），这在我们的日常经验中有点不寻常，但你可以假设我们的医生是非凡的，可以同时看多个病人；也许多个病人愿意坐在同一个咨询室内。在某些实际用例中，信号量保护着可以被许多消费者使用的资源。所以，请现在暂时接受这个假设。

每当一位新病人到达医生的办公室时，他们应该首先去秘书那里注册。秘书有一张写在一张纸上的名单，他们会在这里写下新病人的名字。现在，病人应该等待秘书召唤他们，并授予他们进入医生办公室的权限。另一方面，每当病人离开医生的房间时，这个信息就会传给秘书，秘书会从名单上移除病人的名字。

在每个时刻，秘书的名单反映了医生房间内的病人以及正在被访问的病人，以及那些等待被访问的病人。当一个新病人离开医生的房间时，名单上等待的新病人可以进入医生的房间。这个过程一直持续到所有病人都看过医生。

现在，让我们将其映射到一个并发计算机系统，看看信号量是如何在我们的类比中做与秘书相同的事情的。

在这个例子中，医生是一个共享资源。他们可以被多个病人访问，这些病人类似于希望访问共享资源的任务。秘书是一个信号量。就像秘书有一个名单一样，每个信号量都有一个等待获取对共享资源访问权限的任务队列。医生的房间可以被认为是 *临界区*。

临界区简单地说是一组由信号量保护的指令。任务不能在没有等待信号量的情况下进入它。另一方面，保护临界区是信号量的工作。每当一个任务试图进入临界区时，它应该让一个特定的信号量知道这一点。

同样，当一个任务完成并想要退出临界区时，它应该让相同的信号量知道这一点。正如你所看到的，我们的医生例子和信号量之间有一个非常好的对应关系。让我们继续一个更程序化的例子，并尝试在其中找到信号量和其他元素。

**注意**：

临界区应该满足某些条件。这些条件将在我们通过本章的过程中进行解释。

以下示例，*示例 14.7*，在 *代码框 14-13* 中，又是关于两个任务尝试增加共享计数器的情况。我们已经在之前的多个地方讨论了这个例子，但这次，我们将基于信号量给出一个解决方案：

```cpp
Concurrent System {
  Shared State {
    S : Semaphore which allows only 1 task at a time
    Counter: Integer = 0
  }
  Task P {
    A : Local Integer
      1.1\. EnterCriticalSection(S)
      1.2\. A = Counter
      1.3\. A = A + 1
      1.4\. Counter = A
      1.5\. LeaveCriticalSection(S)
  }
  Task Q {
    B : Local Integer
      2.1\. EnterCriticalSection(S)
      2.2\. B = Counter
      2.3\. B = B + 2
      2.4\. Counter = B
      2.5\. LeaveCriticalSection(S)
  }
}
```

代码框 14-13：使用信号量同步两个任务

在先前的系统中，我们有两个不同的共享状态：一个共享信号量 `S`，它应该保护对另一个共享变量 `Counter` 的访问。`S` 只允许一次只有一个任务进入它所保护的临界区。临界区是由 `EnterCriticalSection(S)` 和 `LeaveCriticalSection(S)` 指令所包含的指令，正如你所看到的，每个任务都有一个由 `S` 保护的不同临界区。

要进入临界区，一个任务应该执行指令 `EnterCriticalSection(S)`。如果另一个任务已经在自己的临界区中，指令 `EnterCriticalSection(S)` 变成阻塞的，不会完成，因此当前任务应该等待直到信号量允许它通过并进入它的临界区。

`EnterCriticalSection(S)`指令可以根据场景有多种实现方式。它可以简单地是一个忙等待，或者它可以让等待的任务进入睡眠模式。后一种方法更为常见，等待其临界区的任务通常会进入睡眠状态。

在前面的例子中，信号量`S`被用来确保一次只有一个任务能够进入其临界区。但信号量更为通用，它们可以允许超过一个任务（在创建信号量时定义的某个数量）进入它们的临界区。一次只允许一个任务进入临界区的信号量通常被称为*二进制信号量*或*互斥锁*。互斥锁比信号量更常见，你将在并发代码中经常看到它们。POSIX API 公开了信号量和互斥锁，你可以根据情况使用它们。

术语**互斥锁**代表**互斥**。假设我们有两个任务，每个任务都有一个临界区访问相同的共享资源。为了有一个基于互斥且无竞态条件的解决方案，关于任务应该满足以下条件：

+   任何时候只有一个任务可以进入临界区，其他任务应该等待直到前一个任务离开临界区。

+   解决方案应该是无死锁的。等待在临界区后面的任务最终应该能够进入它。在某些情况下，假设了一个等待时间的上限（即*竞争时间*）。

+   临界区中的任务不能被*抢占*以允许其他任务进入临界区。换句话说，解决方案应该是*无抢占*和*协作*的。

互斥锁存在是为了允许基于互斥的解决方案得到发展。请注意，临界区也应该遵循类似的条件。它们应该只允许一个任务在其内部，并且它们应该是无死锁的。请注意，信号量也满足最后两个条件，但它们可以允许一次进入多个任务到它们的临界区。

我们可以说，互斥是并发中最重要的概念，是我们手中各种控制机制的主导因素。换句话说，在你知道的每一种同步技术中，你都会通过使用信号量和互斥锁（但主要是互斥锁）看到互斥的足迹。

信号量和互斥锁被称为*可锁定*对象。在另一种但更为正式的术语中，等待信号量并进入临界区的行为与*锁定*信号量相同。同样，离开临界区并更新信号量的行为与*解锁*信号量相同。

因此，锁定和解锁信号量可以被认为是两种算法，分别用于等待和获取临界区的访问权限以及释放临界区。例如，*自旋锁*是通过在信号量上忙等待来获取临界区的访问权限，当然，我们也可以有其他类型的锁定和解锁算法。当我们使用 POSIX API 开发并发程序时，我们将在第十六章“线程同步”中解释这些不同的锁定算法。

如果我们要根据锁定和解锁术语来编写前面的解决方案，它将类似于以下内容：

```cpp
Concurrent System {
  Shared State {
    S : Semaphore which allows only 1 task at a time
    Counter: Integer = 0
  }
  Task P {
    A : Local Integer
      1.1\. Lock(S)
      1.2\. A = Counter
      1.3\. A = A + 1
      1.4\. Counter = A
      1.5\. Unlock(S)
  }
  Task Q {
    B : Local Integer
      2.1\. Lock(S)
      2.2\. B = Counter
      2.3\. B = B + 2
      2.4\. Counter = B
      2.5\. Unlock(S)
  }
}
```

代码框 14-14：使用锁定和解锁操作与信号量一起工作

从现在起，我们将在我们的伪代码片段中使用锁定和解锁术语，这些术语在 POSIX API 中也得到了广泛应用。

我们将通过给出最终定义来完成本节。当多个任务都愿意进入临界区时，它们会尝试锁定一个信号量，但只有其中一定数量的任务（取决于信号量）可以获取锁并进入临界区。其他任务将等待获取锁。在信号量上等待获取锁的行为称为*竞争*。更多的任务会导致更多的竞争，而竞争时间则是衡量任务执行速度降低程度的指标。

显然，竞争中的任务获取锁需要一些时间，并且随着我们获取的任务越多，它们等待进入它们的临界区的时间应该越长。任务在竞争状态中等待的时间通常被称为*竞争时间*。竞争时间可以是并发系统的非功能性要求，应该被仔细监控，以防止任何性能下降。

我们可以得出结论，互斥锁是我们同步一些并发任务的主要工具。我们还在 POSIX 线程 API 和几乎支持并发的所有编程语言中都有互斥锁。除了互斥锁之外，*条件变量*在需要等待不定时间以满足特定条件时也起着重要作用。

我们将讨论条件变量，但在那之前，我们需要谈论内存屏障和具有多个处理器单元的并发环境，无论是多个 CPU 还是具有多个核心的 CPU。因此，下一节将专门讨论这个主题。

## 多处理器单元

当你的计算机系统中只有一个处理器单元，即只有一个核心的 CPU 时，试图访问主内存中特定地址的任务总是会读取最新的和最新的值，即使该地址已缓存在 CPU 核心中。在 CPU 核心内部缓存某些内存地址的值作为其*本地缓存*的一部分，甚至将这些地址的更改保留在缓存中，这是一种常见的做法。这将通过减少对主内存的读写操作次数来提高性能。在某些事件发生时，CPU 核心会将其本地缓存中的更改传播回主内存，以保持其缓存和主内存同步。

当你有多个处理器单元时，这些本地缓存仍然存在。当我们说多个处理器单元时，我们指的是一个具有多个核心的 CPU 或多个具有任意数量核心的 CPU。请注意，每个 CPU 核心都有自己的本地缓存。

因此，当两个不同的任务在两个不同的 CPU 核心上执行，并在主内存中操作相同的地址时，每个 CPU 核心都会在其自己的本地缓存中缓存相同内存地址的值。这意味着如果其中一个尝试写入共享内存地址，更改只会应用到其本地缓存，而不会应用到主内存和其他 CPU 核心的本地缓存。

这样做会导致许多不同的问题，因为当运行在另一个 CPU 核心中的任务试图从共享内存地址读取最新值时，它无法看到最新的更改，因为它会从其本地缓存中读取，而这个缓存中没有最新的更改。

这个问题，即每个 CPU 核心都有自己的不同本地缓存，通过在 CPU 核心之间引入*内存一致性协议*来解决。因此，通过遵循一致性协议，当其中一个 CPU 核心更改值时，所有运行在不同 CPU 核心上的任务都会在其本地缓存中看到相同的值。换句话说，我们说内存地址对所有其他处理器都是可见的。遵循内存一致性协议为所有在不同处理器单元上运行的任务提供了*内存可见性*。缓存一致性和内存可见性是在多于一个处理器单元上运行的并发系统中应考虑的两个重要因素。

让我们回到之前两节中解释的第一个基于 sleep-notify 的解决方案，即*示例 14.6*。对于*示例 14.6*的不变约束是要**在输出中首先有 A 然后是 B**。

以下伪代码是我们的最终解决方案，我们使用了 sleep/notify 机制来强制执行`print`指令之间的期望顺序。我们说这个解决方案不是无错误的，可能会产生同步后的问题。在接下来的段落中，我们将解释问题是如何出现的：

```cpp
Concurrent System {
  Shared State {
    Done : Boolean = False
  }
  Task P {
      1.1\. print 'A'
      1.2\. Done = True
      1.3\. Notify Task Q
  }
  Task Q {
      2.1\. While Not Done {
      2.2\.     Go To Sleep Mode If Done is False (Atomic)
      2.3\. }
      2.4\. print 'B'
  }
}
```

代码框 14-15：基于 sleep/notify 技术提出的针对示例 14.6 的解决方案

假设任务 `P` 和 `Q` 在不同的 CPU 核心上运行。在这种情况下，每个 CPU 核心在其本地缓存中都有一个共享变量 `Done` 的条目。请注意，再次声明，我们已将指令 `2.2` 声明为原子的，并且请注意，这是直到我们提出一个合适的基于互斥锁的解决方案来解决这个问题的一个基本假设。假设一个任务 `P` 执行指令 `1.2` 并通知可能正在睡眠的任务 `Q` 的交织。因此，任务 `P` 更新其本地缓存中 `Done` 的值，但这并不意味着它将其写回主内存或更新其他 CPU 核心的本地缓存。

话虽如此，我们无法保证我们会看到主内存和任务 `Q` 的本地缓存中的变化。因此，有可能当任务 `Q` 获得 CPU 并读取其本地缓存时，它会看到 `Done` 的值为 `False` 并进入睡眠模式，而任务 `P` 已经完成并提前发送了通知信号，任务 `P` 将不再发出任何通知信号。最终，任务 `Q` 将永远进入睡眠状态，并发生半死锁情况。

为了解决这个问题，需要使用内存屏障或内存栅栏。它们是像屏障一样的指令，在执行（通过）它们时，所有仅在一个本地缓存中更新的值都会传播到主内存和其他本地缓存。它们对在其他 CPU 核心中执行的所有任务可见。换句话说，内存屏障同步所有 CPU 核心的本地缓存和主内存。

最后，我们可以提出我们的完整解决方案如下。请注意，再次声明，我们已将指令 `2.3` 声明为原子的，并且请注意，这是直到我们提出一个合适的基于互斥锁的解决方案来解决这个问题的一个基本假设：

```cpp
Concurrent System {
  Shared State {
      Done : Boolean = False
  }
  Task P {
      1.1\. print 'A'
      1.2\. Done = True
      1.3\. Memory Barrier
      1.4\. Notify Task Q
  }
  Task Q {
      2.1\. Do {
      2.2\.     Memory Barrier
      2.3\.     Go To Sleep Mode If Done is False (Atomic)
      2.4\. } While Not Done
      2.5\. print 'B'
  }
}
```

代码框 14-16：使用内存屏障改进针对示例 14.6 提出的解决方案

通过在前面伪代码中使用内存屏障，我们确信对共享变量 `Done` 的任何更新都可以被任务 `Q` 看到。

注意，创建任务、锁定信号量和解锁信号量是三种充当内存屏障的操作，并同步所有 CPU 核心的本地缓存和主内存，并传播对共享状态所做的最近更改。

以下伪代码与前面的解决方案相同，但这次使用互斥锁。作为以下解决方案的一部分，我们将使用互斥锁并最终解决使我们声明指令 `Go To Sleep Mode If Done` 为 `False` 是原子的那个问题。尽管请注意，互斥锁是信号量，它允许每次只有一个任务处于临界区，并且，像信号量一样，锁定和解锁互斥锁可以充当内存屏障：

```cpp
Concurrent System {
  Shared State {
      Done : Boolean = False
      M : Mutex
  }
  Task P {
      1.1\. print 'A'
      1.2\. Lock(M)
      1.3\. Done = True
      1.4\. Unlock(M)
      1.5\. Notify Task Q
  }
  Task Q {
      2.1\. Lock(M)
      2.2\. While Not Done {
      2.3\.     Go To Sleep Mode And Unlock(M) (Atomic)
      2.4\.     Lock(M)
      2.5\. }
      2.6\. Unlock(M)
      2.7\. print 'B'
  }
}
```

代码框 14-17：使用互斥锁改进针对示例 14.6 提出的解决方案

指令 `Lock(M)` 和 `Unlock(M)` 充当内存屏障，因此确保所有任务中的内存可见性。作为提醒，`Lock(M)` 和 `Unlock(M)` 之间的指令在每个任务中都被认为是临界区。

注意，当一个任务锁定互斥锁（或信号量）时，有三种情况会导致互斥锁自动解锁：

+   任务使用 `Unlock` 命令解锁互斥锁。

+   当一个任务完成时，所有已锁定的互斥锁都会解锁。

+   当一个任务进入睡眠模式时，锁定的互斥锁会解锁。

    **注意**：

    前面的列表中的第三个项目点并不总是正确的。如果一个任务想在由互斥锁保护的临界区中睡眠一定的时间，它当然可以在不解锁互斥锁的情况下睡眠。这就是为什么我们将指令 `2.3` 声明为原子的，并且我们向其中添加了 `Unlock(M)`。为了完全理解这种场景，我们需要涉及到 *条件变量*，这些将在接下来的章节中简要介绍。

因此，当指令 `2.3` 作为原子指令执行时，已经锁定的互斥锁 `M` 变得解锁。当任务再次被通知时，它将使用指令 `2.4` 重新获取锁，然后它可以再次进入其临界区。

在本节的最后一点，当一个任务已经锁定互斥锁时，它不能再次锁定它，并且尝试进一步锁定通常会导致死锁情况。只有 *递归互斥锁* 可以被单个任务多次锁定。请注意，当递归互斥锁被锁定（无论锁定多少次）时，所有其他任务在尝试锁定它时都会被阻塞。锁定和解锁操作总是成对出现，因此如果一个任务已经锁定递归互斥锁两次，它也应该解锁两次。

到目前为止，我们已经讨论并使用了许多示例中的睡眠/通知技术。只有当你接触到一个新的概念：条件变量时，你才能完全理解睡眠/通知技术。条件变量与互斥锁一起构成了实现控制技术的基础，这些技术有效地同步了许多任务在单个共享资源上。但在那之前，让我们谈谈另一个可能的解决方案来 *示例 14.6*。

# 自旋锁

在开始讨论条件变量和睡眠/通知技术应该真正实现的方式之前，让我们稍微回顾一下，并使用忙等待与互斥锁一起为 *示例 14.6* 编写一个新的解决方案。作为提醒，该示例是关于 **首先在标准输出中打印 A 然后打印 B**。

以下是一个使用带有自旋锁算法的互斥锁的解决方案。互斥锁充当内存屏障，因此我们不会有任何内存可见性问题，并且它有效地同步了任务 `P` 和 `Q` 在 `Done` 共享标志上：

```cpp
Concurrent System {
  Shared State {
      Done : Boolean = False
      M : Mutex
  }
  Task P {
      1.1\. print 'A'
      1.2\. SpinLock(M)
      1.2\. Done = True
      1.3\. SpinUnlock(M)
  }
  Task Q {
      2.1  SpinLock(M)
      2.2\. While Not Done {
      2.3\.   SpinUnlock(M)
      2.4\.   SpinLock(M)
      2.5\. }
      2.6\. SpinUnlock(M)
      2.4\. print 'B'
  }
}
```

代码框 14-18：使用互斥量和自旋锁定算法解决示例 14.6 的解决方案

上述伪代码是第一个可以用 POSIX 线程 API 编写为有效 C 代码的解决方案。之前给出的所有伪代码都无法编写成真正的程序，因为它们要么过于抽象而无法实现，要么在某些场景下存在问题，比如在具有多个处理器单元的系统上运行。但前面的伪代码可以被翻译成任何支持并发的编程语言。

在前面的代码中，我们使用的是 *自旋锁*，它们简单地是忙等待算法。每次你锁定自旋锁互斥量时，它都会进入一个忙等待循环，直到互斥量变得可用，然后继续。

我认为前面的伪代码中的所有内容都很容易理解，除了指令 `2.3` 和 `2.4`，它们是在循环内部奇怪的连续加锁和解锁指令！实际上，这是代码中最美丽的一部分。当任务 `Q` 获取 CPU 核心时，一系列对自旋锁互斥量 `M` 的加锁和解锁操作正在进行。 

如果我们没有指令 `2.3` 和 `2.4` 会怎样？那么在指令 `2.1` 处的锁将保持互斥量锁定，直到指令 `2.6`，这意味着任务 `P` 永远找不到机会访问共享标志 `Done`。这些加锁和解锁指令允许任务 `P` 找到机会，并通过指令 `1.2` 更新标志 `Done`。否则，互斥量将一直被任务 `Q` 持有，任务 `P` 将永远无法继续到指令 `1.2`。换句话说，系统进入了一种半死锁状态。伪代码展示了加锁/解锁操作的美丽和谐，巧妙地使用自旋锁解决了我们的问题。

注意，在高性能系统中，与系统事件发生速率相比，将任务置于睡眠模式非常昂贵，因此自旋锁非常常见。当使用自旋锁时，任务应该编写得尽可能快地解锁互斥量。为了实现这一点，关键部分应该足够小。正如您在我们的代码中所看到的，我们有一个只有单个布尔检查（循环条件）的关键部分。

在下一节中，我们将探讨条件变量及其属性。

## 条件变量

我们在前面几节中提供的解决方案，以满足 *示例 14.6*，无法使用编程语言实现，因为我们不知道如何将任务置于睡眠模式，以及如何程序化地通知另一个任务。在本节中，我们将介绍条件变量，这是一个新的概念，可以帮助我们使任务等待并相应地得到通知。

条件变量是简单的变量（或对象），可以用来将任务置于睡眠模式或通知其他睡眠任务并将它们唤醒。请注意，这里讨论的睡眠模式与为了延迟而睡眠几秒钟或几毫秒是不同的，它特别意味着任务不想再获得任何 CPU 份额。像用于保护关键区的互斥锁一样，条件变量用于在不同的任务之间启用 *信号*。

再次，就像具有相关 *锁定* 和 *解锁* 操作的互斥锁一样，条件变量有 *睡眠* 和 *通知* 操作。然而，每种编程语言在这里都有自己的术语，在某些语言中，你可能找到的是 *等待* 和 *信号* 而不是睡眠和通知，但它们背后的逻辑是相同的。

条件变量必须与互斥锁一起使用。使用没有互斥锁的条件变量的解决方案简单地缺乏 *互斥排他* 属性。记住，条件变量必须被多个任务共享才有用，作为一个共享资源，我们需要同步访问它。这通常是通过一个互斥锁来实现的，该锁保护关键区。以下伪代码展示了我们如何使用条件变量和互斥锁等待某个条件，或一般的事件，特别是等待共享标志 `Done` 在 *示例 14.6* 中变为 `True`：

```cpp
Concurrent System {
  Shared State {
      Done : Boolean = False
      CV   : Condition Variable
      M    : Mutex
  }
  Task P {
        1.1\. print 'A'
        1.2\. Lock(M)
        1.3\. Done = True
        1.4\. Notify(CV)
        1.5\. Unlock(M)
  }
  Task Q {
        2.1\. Lock(M)
        2.2\. While Not Done {
        2.3\.     Sleep(M, CV)
        2.4\. }
        2.5\. Unlock(M)
        2.6\. print 'B'
  }
}
```

代码框 14-19：使用条件变量解决示例 14.6 的方案

前面的解决方案是使用条件变量在并发系统中在两个指令之间实现严格顺序的最真实方式。指令 `1.4` 和 `2.3` 正在使用条件变量 `CV`。正如你所见，`Sleep` 操作需要了解互斥锁 `M` 和条件变量 `CV`，因为它需要在任务 `Q` 睡觉时解锁 `M`，并在它被通知时重新获取 `M` 的锁。

注意，当任务 `Q` 被通知时，它将继续其 `Sleep` 操作内部的逻辑，再次锁定 `M` 是其中的一部分。指令 `1.4` 也只有在获得 `M` 的锁时才会起作用，否则会发生竞争条件。去探索可能的交错情况，看看前面的互斥锁和条件变量将如何始终在指令 `1.1` 和 `2.6` 之间强制执行所需的顺序，这将是一个好且有益的挑战。

作为本节最后的定义，一个互斥对象与一个条件变量通常被称为 *监视器* 对象。我们还有一个与并发相关的设计模式，称为 *监视器对象*，它涉及到使用前面的技术来重新排序某些并发任务中的指令。

在前面的章节中，我们展示了如何使用信号量、互斥锁和条件变量以及锁定、解锁、睡眠和通知算法来实现控制机制，这些机制用于在各个并发任务中的某些指令之间强制执行严格的顺序，并保护关键部分。这些概念将在接下来的章节中使用，以便用 C 语言编写多线程和多进程程序。下一节将讨论 POSIX 标准中实现的并发支持，许多 Unix-like 操作系统都提供了这种支持。

# POSIX 中的并发

正如我们在前面的章节中解释的那样，并发或多任务是由操作系统内核提供的一种功能。并非所有内核从出生起就是并发的，但今天大多数内核都支持并发。知道 Unix 的第一个版本不是并发的，但它在诞生后很快就获得了这一特性，这是令人欣慰的。

如果你记得*第十章*，*Unix – 历史 与 架构*，我们解释了单 Unix 规范和 POSIX 如何试图标准化 Unix-like 操作系统 shell 环暴露的 API。并发一直是这些标准的一部分，到目前为止，它已经允许许多开发者为符合 POSIX 标准的操作系统编写并发程序。POSIX 中的并发支持已经在广泛的操作系统（如 Linux 和 macOS）中得到广泛使用和实现。

在符合 POSIX 标准的操作系统中的并发通常以两种方式提供。你可以让一个并发程序以不同的进程执行，这被称为*多进程*，或者你可以让你的并发程序作为同一进程的一部分以不同的线程运行，这被称为*多线程*。在本节中，我们将讨论这两种方法，并从程序员的角度进行比较。但在那之前，我们需要更多地了解支持并发的内核的内部结构。下一节简要地解释了在这样的内核中你会找到什么。

## 支持并发的内核

几乎所有正在开发和维护的内核都是多任务的。正如我们已经知道的，每个内核都有一个*任务调度单元*，它将 CPU 核心在许多运行中的进程和线程之间共享，这些进程和线程通常在本章和上一章中被统称为任务。

在继续前进之前，我们需要描述进程和线程以及它们在并发方面的区别。每次运行程序时，都会创建一个新的进程，程序的逻辑就在该进程中运行。进程是相互隔离的，一个进程无法访问另一个进程的内部，比如它的内存。

线程与进程非常相似，但它们是局部于某个进程的。它们通过拥有多个执行线程来引入单个进程的并发性，这些线程共同以并发方式执行多个指令序列。单个线程不能在两个进程之间共享，它是局部的，并绑定到其所属进程。进程中的所有线程都能够作为共享资源访问其所属进程的内存，而每个线程都有自己的堆栈区域，当然，同一进程中的其他线程也可以访问。此外，进程和线程都可以使用 CPU 份额，并且大多数内核中的任务调度器使用相同的**调度**算法来在它们之间共享 CPU 核心。

注意，当我们谈论内核级别时，我们更喜欢使用**任务**这个词而不是**线程**或**进程**。从内核的角度来看，有一个等待获得 CPU 核心以执行其指令的任务队列，而任务调度单元的职责是以公平的方式为所有这些任务提供这种设施。

**注意**：

在类 Unix 内核中，我们通常将**任务**这个词用于进程和线程。实际上，线程或进程是**用户空间**术语，不能用于内核术语。因此，类 Unix 内核有任务调度单元，试图在各个任务之间公平地管理对 CPU 核心的访问。

在不同的内核中，任务调度器使用不同的策略和算法来进行调度。但它们中的大多数都可以分为两大类调度算法：

+   协同调度

+   抢占式调度

协同调度是指将 CPU 核心分配给一个任务，并等待该任务的合作以释放 CPU 核心。这种方法在大多数正常情况下不是**抢占式**的，因为没有强制手段从任务中收回 CPU 核心。应该有一个高优先级的**抢占信号**来使调度器通过抢占收回 CPU 核心。否则，调度器和系统中的所有任务都应该等待直到活动任务随意释放 CPU 核心。现代内核通常不是这样设计的，但你仍然可以找到为非常特定的应用，如**实时处理**，采用协同调度的内核。早期版本的 macOS 和 Windows 使用协同调度，但现在它们使用抢占式调度方法。

与协作调度相比，我们有抢占式调度。在抢占式调度中，任务被允许使用 CPU 核心，直到被调度器接管。在一种特定的抢占式调度中，任务被允许在一定时间内使用给定的 CPU 核心。这种类型的抢占式调度被称为**时间共享**，它是当前内核中最常用的调度策略。任务被分配到 CPU 的时间间隔在不同的学术来源中可能有不同的名称，它可以被称为**时间片**、**时间槽**或**量子**。

根据使用的算法，还有各种基于时间共享的调度类型。**轮询**是最广泛使用的时间共享算法，并被各种内核采用，当然也有一些修改。轮询算法允许对共享资源（在这种情况下是 CPU 核心）进行公平且**无饥饿**的访问。

尽管轮询算法简单且没有优先级，但它可以被修改以允许任务具有多个优先级。在现代内核中，通常需要不同的优先级，因为有一些类型的任务是由内核本身或其他内核中的重要单元发起的，并且这些任务应该在任何其他普通任务之前得到服务。

正如我们之前所说的，将并发引入软件有两种方式。第一种方法是多进程，它使用**用户进程**在多任务环境中并行执行任务。第二种方法是多线程，它使用**用户线程**将任务分解为单个进程内的并行执行流。在大型软件项目中，同时使用这两种技术也是非常常见的。尽管这两种技术都为软件带来了并发性，但它们在本质上有根本的不同。

在接下来的两个部分中，我们将更详细地讨论多进程和多线程。在接下来的两个章节中，我们将介绍 C 语言中的多线程开发，而在之后的两个章节中，我们将讨论多进程。

# 多进程

多进程简单来说就是使用进程来完成并发任务。一个很好的例子是网络服务器中使用的**通用网关接口**（**CGI**）标准。采用这种技术的网络服务器为每个 HTTP 请求启动一个新的**解释器进程**。这样，它们可以同时处理多个请求。

在这样的网络服务器上，为了处理高吞吐量的请求，你可能会看到许多解释器进程同时被生成并运行，每个进程都处理不同的 HTTP 请求。由于它们是不同的进程，它们是隔离的，无法看到彼此的内存区域。幸运的是，在 CGI 用例中，解释器进程不需要相互通信或共享数据。但情况并不总是如此。

有许多例子表明，多个进程正在执行一些并发任务，并且它们需要共享关键信息片段，以便让软件继续运行。作为一个例子，我们可以参考 Hadoop 基础设施。Hadoop 集群中有许多节点，每个节点都有多个进程来保持集群的运行。

这些进程需要不断共享信息片段，以保持集群的运行。有许多这样的分布式系统示例，具有多个节点，如 Gluster、Kafka 和加密货币网络。所有这些都需要在不同节点上的进程之间进行大量的互通信息传递和消息传递，以保持运行。

只要进程或线程在没有共享状态的情况下运行，多进程和多线程之间并没有太大的区别。你可能可以使用进程代替线程，反之亦然。但是，一旦在它们之间引入共享状态，使用进程或线程，甚至两者的组合，我们就会看到巨大的差异。一个差异在于可用的同步技术。虽然用于使用这些机制的 API 大致相同，但在多进程环境中的工作复杂度要高得多，并且底层实现也不同。多进程和多线程之间的另一个差异是我们用于共享状态的技术。虽然线程能够使用所有可用于进程的技术，但它们有这样一个优势：它们可以使用相同的内存区域来共享状态。正如你将在接下来的章节中看到的，这造成了很大的差异。

为了更详细地说明，进程有一个私有内存，其他进程无法读取或修改它，因此使用进程的内存与其他进程共享某物并不那么容易。但是，使用线程就简单得多。同一个进程内的所有线程都可以访问同一个进程的内存；因此，它们可以使用它来存储共享状态。

接下来，你可以找到进程可以用来访问彼此之间共享状态的技术。关于这些技术的更多信息将在接下来的章节中给出：

+   **文件系统**：这可以被认为是多个进程之间共享数据的最简单方式。这种方法非常古老，并且几乎所有的操作系统都支持它。例如，在软件项目中，许多进程都会读取配置文件。如果文件将要被某个进程写入，应该采用同步技术来防止数据竞争和其他并发相关的问题。

+   **内存映射文件**：在所有符合 POSIX 标准的操作系统和 Microsoft Windows 中，我们可以拥有映射到磁盘上文件的内存区域。这些内存区域可以在多个进程之间共享，以便读取和修改。

    这种技术与文件系统方法非常相似，但它减少了使用文件 API 将数据流到和从文件描述符带来的头痛。如果映射区域的内容可以被任何有权访问它的进程修改，应采用适当的同步机制。

+   **网络**：对于位于不同计算机上的进程，唯一的通信方式是通过使用网络基础设施和套接字编程 API。套接字编程 API 是 SUS 和 POSIX 标准的一个重要部分，它几乎存在于每个操作系统中。

    关于这项技术的细节非常庞大，仅为了涵盖这项技术就有许多书籍存在。各种协议、各种架构、处理数据流的不同方法以及更多细节都作为这项技术的子部分存在。我们试图在*第二十章*，*套接字编程*中涵盖其中的一部分，但可能需要一本完全独立的书籍来探讨通过网络进行 IPC 的不同方面。

+   **信号**：在同一操作系统中运行的进程可以向彼此发送信号。虽然这主要用于传递命令信号，但它也可以用于共享一个小状态（有效载荷）。共享状态的价值可以携带在信号上，并由目标进程截获。

+   **共享内存**：在符合 POSIX 规范的操作系统和 Microsoft Windows 中，我们可以有一个区域内存被多个进程共享。因此，它们可以使用这个共享区域来存储变量并共享一些值。共享内存不能防止数据竞争，所以愿意将其用作可修改共享状态的占位符的进程需要采用适当的同步机制，以避免任何并发问题。共享内存区域可以同时被许多进程使用。

+   **管道**：在符合 POSIX 规范的操作系统和 Microsoft Windows 中，管道是单向通信通道。它们可以用来在两个进程之间传输共享状态。一个进程向管道写入，另一个进程从中读取。

    管道可以是命名的或匿名的，每种都有其特定的用例。当讨论单机上的各种可用 IPC 技术时，我们将在*第十九章*，*单主机 IPC 和套接字*中提供更多细节和示例。

+   **Unix 域套接字**：在符合 POSIX 标准的操作系统和最近的 Windows 10 中，我们有称为**Unix 套接字**的通信端点。位于同一台机器上并在同一操作系统中运行的进程可以使用**Unix 域套接字**通过全双工通道传递信息。Unix 域套接字与网络套接字非常相似，但所有数据都是通过内核传输的，因此它提供了一种非常快速的数据传输方式。多个进程可以使用同一个 Unix 域套接字来进行通信和共享数据。Unix 域套接字还可以用于特殊用途案例，例如在同一台机器上的进程之间传输文件描述符。Unix 域套接字的好处是，我们不需要使用与网络套接字相同的套接字编程 API。

+   **消息队列**：几乎每个操作系统都存在。消息队列在内核中维护，可以被各种进程用来发送和接收多个消息。进程不需要相互了解，它们只需要能够访问消息队列即可。

    这种技术仅用于使同一台机器上的进程能够相互通信。

+   **环境变量**：类 Unix 操作系统和 Microsoft Windows 提供了一组存储在操作系统本身的变量。

    这些变量被称为环境变量，并且它们可以供系统内的进程访问。

例如，本节第一段中介绍的方法在 CGI 实现中被广泛使用，尤其是在主 Web 服务器进程想要将 HTTP 请求数据传递给派生的解释器进程时。

关于使多个线程/进程同步的控制技术，你会发现，在多进程和多线程环境中使用的这些技术，与 POSIX 标准提供的 API 非常相似。但可能互斥量或条件变量的底层实现，在多线程和多进程使用中是不同的。我们将在接下来的章节中给出这方面的例子。

# 多线程

多线程是关于在并发环境中使用**用户线程**来执行并行任务。几乎找不到只有单个线程的非平凡程序；你遇到的几乎每个程序都是多线程的。线程只能存在于进程内部；我们不能有任何没有所有者的线程。每个进程至少有一个线程，通常称为**主线程**。使用单个线程执行所有任务的程序称为**单线程程序**。进程内的所有线程都可以访问相同的内存区域，这意味着我们不需要像在多进程中那样想出复杂的场景来共享数据。

由于线程与进程非常相似，它们可以使用进程用来共享或传递状态的任何技术。因此，上一节中解释的所有技术都可以由线程用来访问共享状态或在他们之间传输数据。但线程在这方面还有另一个优势，那就是可以访问相同的内存区域。因此，在多个线程之间共享数据的一种常见方法是通过声明一些变量来使用内存。

由于每个线程都有自己的堆栈内存，它可以用作保持共享状态的占位符。一个线程可以向另一个线程提供一个指向其堆栈内部某处的地址，并且另一个线程可以轻松访问它，因为这些内存地址都属于进程的堆栈段。线程还可以轻松访问进程拥有的相同堆空间，并将其用作占位符来存储它们的共享状态。我们将在下一章给出几个使用堆栈和堆区域作为共享状态占位符的示例。

同步技术也与进程使用的技巧非常相似。甚至 POSIX API 在进程和线程之间也是相同的。这很可能是因为符合 POSIX 的操作系统几乎以相同的方式处理进程和线程。在下一章中，我们将解释如何使用 POSIX API 在多线程程序中声明信号量、互斥量和条件变量等。

作为对 Windows 的最后一点说明，关于 POSIX 线程 API（pthreads），Microsoft Windows 不支持它。因此，Windows 有自己的 API，用于创建和管理线程。这个 API 是 Win32 本地库的一部分，我们在这本书中不会介绍，但您可以在网上找到许多涵盖它的资源。

# 摘要

在本章中，我们讨论了在开发并发程序时可能遇到的这些问题，以及我们应该采取的解决方案。以下是本章中我们讨论的主要要点。

+   我们已经涵盖了并发问题。在所有并发系统中，当不同的交错不满足系统的不变性约束时，都会存在固有问题。

+   我们讨论了在以糟糕和错误的方式使用同步技术后才会出现的问题。

+   我们探讨了保持不变性约束得到满足所使用的控制机制。

+   信号量是实现控制机制的关键工具。互斥量是信号量的一个特殊类别，它允许基于互斥条件，一次只允许一个任务进入临界区。

+   监视封装互斥量和条件变量的对象可以在任务等待满足条件时使用。

+   我们通过在 POSIX 标准中引入多进程和多线程，迈出了并发开发的第一步。

下一章是成对章节中的第一部分（*第十五章*，*线程执行*，和*第十六章*，*线程同步*），讨论了符合 POSIX 标准的操作系统中的多线程开发。*第十五章*，*线程执行*主要讲述了线程及其执行方式。*第十六章*，*线程同步*介绍了多线程环境中的可用并发控制机制，这两章共同传达了编写多线程程序所需的所有主题。
